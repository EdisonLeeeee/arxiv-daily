[
  {
    "id": "arXiv:2111.02399",
    "title": "Learning Pruned Structure and Weights Simultaneously from Scratch: an  Attention based Approach",
    "abstract": "As a deep learning model typically contains millions of trainable weights,\nthere has been a growing demand for a more efficient network structure with\nreduced storage space and improved run-time efficiency. Pruning is one of the\nmost popular network compression techniques. In this paper, we propose a novel\nunstructured pruning pipeline, Attention-based Simultaneous sparse structure\nand Weight Learning (ASWL). Unlike traditional channel-wise or weight-wise\nattention mechanism, ASWL proposed an efficient algorithm to calculate the\npruning ratio through layer-wise attention for each layer, and both weights for\nthe dense network and the sparse network are tracked so that the pruned\nstructure is simultaneously learned from randomly initialized weights. Our\nexperiments on MNIST, Cifar10, and ImageNet show that ASWL achieves superior\npruning results in terms of accuracy, pruning ratio and operating efficiency\nwhen compared with state-of-the-art network pruning methods.",
    "descriptor": "",
    "authors": [
      "Qisheng He",
      "Ming Dong",
      "Loren Schwiebert",
      "Weisong Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02399"
  },
  {
    "id": "arXiv:2111.02400",
    "title": "Deep AUC Maximization for Medical Image Classification: Challenges and  Opportunities",
    "abstract": "In this extended abstract, we will present and discuss opportunities and\nchallenges brought about by a new deep learning method by AUC maximization (aka\n\\underline{\\bf D}eep \\underline{\\bf A}UC \\underline{\\bf M}aximization or {\\bf\nDAM}) for medical image classification. Since AUC (aka area under ROC curve) is\na standard performance measure for medical image classification, hence directly\noptimizing AUC could achieve a better performance for learning a deep neural\nnetwork than minimizing a traditional loss function (e.g., cross-entropy loss).\nRecently, there emerges a trend of using deep AUC maximization for large-scale\nmedical image classification. In this paper, we will discuss these recent\nresults by highlighting (i) the advancements brought by stochastic non-convex\noptimization algorithms for DAM; (ii) the promising results on various medical\nimage classification problems. Then, we will discuss challenges and\nopportunities of DAM for medical image classification from three perspectives,\nfeature learning, large-scale optimization, and learning trustworthy AI models.",
    "descriptor": "\nComments: Medical Imaging meets NeurIPS 2021 workshop\n",
    "authors": [
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.02400"
  },
  {
    "id": "arXiv:2111.02405",
    "title": "Unsupervised embedding and similarity detection of microregions using  public transport schedules",
    "abstract": "The role of spatial data in tackling city-related tasks has been growing in\nrecent years. To use them in machine learning models, it is often necessary to\ntransform them into a vector representation, which has led to the development\nin the field of spatial data representation learning. There is also a growing\nvariety of spatial data types for which representation learning methods are\nproposed. Public transport timetables have so far not been used in the task of\nlearning representations of regions in a city. In this work, a method is\ndeveloped to embed public transport availability information into vector space.\nTo conduct experiments on its application, public transport timetables were\ncollected from 48 European cities. Using the H3 spatial indexing method, they\nwere divided into micro-regions. A method was also proposed to identify regions\nwith similar characteristics of public transport offers. On its basis, a\nmulti-level typology of public transport offers in the regions was defined.\nThis thesis shows that the proposed representation method makes it possible to\nidentify micro-regions with similar public transport characteristics between\nthe cities, and can be used to evaluate the quality of public transport\navailable in a city.",
    "descriptor": "\nComments: Master's thesis submitted at the Wroc{\\l}aw University of Science and Technology\n",
    "authors": [
      "Piotr Gramacki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02405"
  },
  {
    "id": "arXiv:2111.02434",
    "title": "Hamiltonian Dynamics with Non-Newtonian Momentum for Rapid Sampling",
    "abstract": "Sampling from an unnormalized probability distribution is a fundamental\nproblem in machine learning with applications including Bayesian modeling,\nlatent factor inference, and energy-based model training. After decades of\nresearch, variations of MCMC remain the default approach to sampling despite\nslow convergence. Auxiliary neural models can learn to speed up MCMC, but the\noverhead for training the extra model can be prohibitive. We propose a\nfundamentally different approach to this problem via a new Hamiltonian dynamics\nwith a non-Newtonian momentum. In contrast to MCMC approaches like Hamiltonian\nMonte Carlo, no stochastic step is required. Instead, the proposed\ndeterministic dynamics in an extended state space exactly sample the target\ndistribution, specified by an energy function, under an assumption of\nergodicity. Alternatively, the dynamics can be interpreted as a normalizing\nflow that samples a specified energy model without training. The proposed\nEnergy Sampling Hamiltonian (ESH) dynamics have a simple form that can be\nsolved with existing ODE solvers, but we derive a specialized solver that\nexhibits much better performance. ESH dynamics converge faster than their MCMC\ncompetitors enabling faster, more stable training of neural network energy\nmodels.",
    "descriptor": "\nComments: 31 pages, 19 figures. Advances in Neural Information Processing (NeurIPS), 2021\n",
    "authors": [
      "Greg Ver Steeg",
      "Aram Galstyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.02434"
  },
  {
    "id": "arXiv:2111.02444",
    "title": "Panoptic 3D Scene Reconstruction From a Single RGB Image",
    "abstract": "Understanding 3D scenes from a single image is fundamental to a wide variety\nof tasks, such as for robotics, motion planning, or augmented reality. Existing\nworks in 3D perception from a single RGB image tend to focus on geometric\nreconstruction only, or geometric reconstruction with semantic segmentation or\ninstance segmentation. Inspired by 2D panoptic segmentation, we propose to\nunify the tasks of geometric reconstruction, 3D semantic segmentation, and 3D\ninstance segmentation into the task of panoptic 3D scene reconstruction - from\na single RGB image, predicting the complete geometric reconstruction of the\nscene in the camera frustum of the image, along with semantic and instance\nsegmentations. We thus propose a new approach for holistic 3D scene\nunderstanding from a single RGB image which learns to lift and propagate 2D\nfeatures from an input image to a 3D volumetric scene representation. We\ndemonstrate that this holistic view of joint scene reconstruction, semantic,\nand instance segmentation is beneficial over treating the tasks independently,\nthus outperforming alternative approaches.",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "Manuel Dahnert",
      "Ji Hou",
      "Matthias Nie\u00dfner",
      "Angela Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02444"
  },
  {
    "id": "arXiv:2111.02445",
    "title": "Autonomous Attack Mitigation for Industrial Control Systems",
    "abstract": "Defending computer networks from cyber attack requires timely responses to\nalerts and threat intelligence. Decisions about how to respond involve\ncoordinating actions across multiple nodes based on imperfect indicators of\ncompromise while minimizing disruptions to network operations. Currently,\nplaybooks are used to automate portions of a response process, but often leave\ncomplex decision-making to a human analyst. In this work, we present a deep\nreinforcement learning approach to autonomous response and recovery in large\nindustrial control networks. We propose an attention-based neural architecture\nthat is flexible to the size of the network under protection. To train and\nevaluate the autonomous defender agent, we present an industrial control\nnetwork simulation environment suitable for reinforcement learning. Experiments\nshow that the learned agent can effectively mitigate advanced attacks that\nprogress with few observable signals over several months before execution. The\nproposed deep reinforcement learning approach outperforms a fully automated\nplaybook method in simulation, taking less disruptive actions while also\ndefending more nodes on the network. The learned policy is also more robust to\nchanges in attacker behavior than playbook approaches.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "John Mern",
      "Kyle Hatch",
      "Ryan Silva",
      "Cameron Hickert",
      "Tamim Sookoor",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02445"
  },
  {
    "id": "arXiv:2111.02447",
    "title": "On the Frequency Bias of Generative Models",
    "abstract": "The key objective of Generative Adversarial Networks (GANs) is to generate\nnew data with the same statistics as the provided training data. However,\nmultiple recent works show that state-of-the-art architectures yet struggle to\nachieve this goal. In particular, they report an elevated amount of high\nfrequencies in the spectral statistics which makes it straightforward to\ndistinguish real and generated images. Explanations for this phenomenon are\ncontroversial: While most works attribute the artifacts to the generator, other\nworks point to the discriminator. We take a sober look at those explanations\nand provide insights on what makes proposed measures against high-frequency\nartifacts effective. To achieve this, we first independently assess the\narchitectures of both the generator and discriminator and investigate if they\nexhibit a frequency bias that makes learning the distribution of high-frequency\ncontent particularly problematic. Based on these experiments, we make the\nfollowing four observations: 1) Different upsampling operations bias the\ngenerator towards different spectral properties. 2) Checkerboard artifacts\nintroduced by upsampling cannot explain the spectral discrepancies alone as the\ngenerator is able to compensate for these artifacts. 3) The discriminator does\nnot struggle with detecting high frequencies per se but rather struggles with\nfrequencies of low magnitude. 4) The downsampling operations in the\ndiscriminator can impair the quality of the training signal it provides. In\nlight of these findings, we analyze proposed measures against high-frequency\nartifacts in state-of-the-art GAN training but find that none of the existing\napproaches can fully resolve spectral artifacts yet. Our results suggest that\nthere is great potential in improving the discriminator and that this could be\nkey to match the distribution of the training data more closely.",
    "descriptor": "",
    "authors": [
      "Katja Schwarz",
      "Yiyi Liao",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02447"
  },
  {
    "id": "arXiv:2111.02450",
    "title": "Unified 3D Mesh Recovery of Humans and Animals by Learning Animal  Exercise",
    "abstract": "We propose an end-to-end unified 3D mesh recovery of humans and quadruped\nanimals trained in a weakly-supervised way. Unlike recent work focusing on a\nsingle target class only, we aim to recover 3D mesh of broader classes with a\nsingle multi-task model. However, there exists no dataset that can directly\nenable multi-task learning due to the absence of both human and animal\nannotations for a single object, e.g., a human image does not have animal pose\nannotations; thus, we have to devise a new way to exploit heterogeneous\ndatasets. To make the unstable disjoint multi-task learning jointly trainable,\nwe propose to exploit the morphological similarity between humans and animals,\nmotivated by animal exercise where humans imitate animal poses. We realize the\nmorphological similarity by semantic correspondences, called sub-keypoint,\nwhich enables joint training of human and animal mesh regression branches.\nBesides, we propose class-sensitive regularization methods to avoid a\nmean-shape bias and to improve the distinctiveness across multi-classes. Our\nmethod performs favorably against recent uni-modal models on various human and\nanimal datasets while being far more compact.",
    "descriptor": "\nComments: BMVC 2021, 10 pages excluding reference page\n",
    "authors": [
      "Kim Youwang",
      "Kim Ji-Yeon",
      "Kyungdon Joo",
      "Tae-Hyun Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02450"
  },
  {
    "id": "arXiv:2111.02452",
    "title": "Slapping Cats, Bopping Heads, and Oreo Shakes: Understanding Indicators  of Virality in TikTok Short Videos",
    "abstract": "Short videos have become one of the leading media used by younger generations\nto express themselves online and thus a driving force in shaping online\nculture. In this context, TikTok has emerged as a platform where viral videos\nare often posted first. In this paper, we study what elements of short videos\nposted on TikTok contribute to their virality. We apply a mixed-method approach\nto develop a codebook and identify important virality features. We do so\nvis-\\`a-vis three research hypotheses; namely, that: 1) the video content, 2)\nTikTok's recommendation algorithm, and 3) the popularity of the video creator\ncontribute to virality.\nWe collect and label a dataset of 400 TikTok videos and train classifiers to\nhelp us identify the features that influence virality the most. While the\nnumber of followers is the most powerful predictor, close-up and medium-shot\nscales also play an essential role. So does the lifespan of the video, the\npresence of text, and the point of view. Our research highlights the\ncharacteristics that distinguish viral from non-viral TikTok videos, laying the\ngroundwork for developing additional approaches to create more engaging online\ncontent and proactively identify possibly risky content that is likely to reach\na large audience.",
    "descriptor": "",
    "authors": [
      "Chen Ling",
      "Jeremy Blackburn",
      "Emiliano De Cristofaro",
      "Gianluca Stringhini"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02452"
  },
  {
    "id": "arXiv:2111.02455",
    "title": "\"We won't even challenge their lefty academic definition of racist:\"  Understanding the Use of e-Prints on Reddit and 4chan",
    "abstract": "The dissemination and the reach of scientific knowledge have increased at a\nblistering pace. In this context, e-print servers have played a central role by\nproviding scientists with a rapid and open mechanism for disseminating research\nwithout having to wait for the (lengthy) peer-review process. While helping the\nscientific community in several ways, e-print servers also provide scientific\ncommunicators and the general public with access to a wealth of knowledge\nwithout having to pay hefty subscription fees. Arguably, e-print servers' value\nhas never been so evident, for better or worse, as during the COVID-19\npandemic. This motivates us to study how e-print servers are positioned within\nthe greater Web, and how they are \"used\" on Web communities. Using data from\nReddit (2005-2021) and 4chan's Politically Incorrect board (2016--2021), we\nuncover a surprisingly diverse set of communities discussing e-print papers. We\nfind that real-world events and distinct factors influence the e-prints people\nare talking about. For instance, there was a sudden increase in the discussion\nof e-prints, corresponding to a surge in COVID-19 related research, in the\nfirst phase of the pandemic. We find a substantial difference in the\nconversation around e-prints and their actual content; in fact, e-prints are\noften being exploited to further conspiracy theories and/or extremist ideology.\nOverall, our work further highlights the need to quickly and effectively\nvalidate non peer-reviewed e-prints that get substantial press/social media\ncoverage, as well as mitigate wrongful interpretations of scientific outputs.",
    "descriptor": "",
    "authors": [
      "Satrio Baskoro Yudhoatmojo",
      "Emiliano De Cristofaro",
      "Jeremy Blackburn"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.02455"
  },
  {
    "id": "arXiv:2111.02459",
    "title": "Smart sensors network for accurate indirect heat accounting in apartment  buildings",
    "abstract": "A new method for accurate indirect heat accounting in apartment buildings has\nbeen recently developed by the Centre Suisse d'Electronique et de\nMicrotechnique (CSEM). It is based on a data driven approach aimed to the smart\nnetworking of any type of indirect heat allocation devices, which can provide,\nfor each heat delivery point of an apartment building, measurements or\nestimations of the temperature difference between the heat transfer fluid and\nthe indoor environment. The analysis of the data gathered from the devices\ninstalled on the heating bodies, together with the measurements of the overall\nbuilding heat consumption provided by direct heat metering, allows the\nevaluation of the characteristic thermal model parameters of heating bodies at\nactual installation and working conditions. Thus overcoming the negative impact\non accuracy of conventional indirect heat accounting due to off-design\noperation, in which these measurement systems normally operate. The method has\nbeen tested on conventional heat cost allocators (HCA), and on innovative smart\nradiator thermostatic valves developed by CSEM. The evaluations were carried\nout at the centralized heating system mock-up of the Istituto Nazionale di\nRicerca Metrologica (INRIM), and also in a real building in Neuchatel,\nSwitzerland. The method has proven to be an effective tool to improve the\naccuracy of indirect heat metering systems; compared to conventional HCA\nsystems, the error on the individual heating bill is reduced by 20% to 50%.",
    "descriptor": "\nComments: 33 pages, 11 figures, accepted for publication in the Journal of Building Engineering\n",
    "authors": [
      "Yves Stauffer",
      "Fabio Saba",
      "Rafael E. Carrillo",
      "Max Boegli",
      "Andrea Malengo",
      "Andreas Hutter"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02459"
  },
  {
    "id": "arXiv:2111.02468",
    "title": "Robust Auction Design in the Auto-bidding World",
    "abstract": "In classic auction theory, reserve prices are known to be effective for\nimproving revenue for the auctioneer against quasi-linear utility maximizing\nbidders. The introduction of reserve prices, however, usually do not help\nimprove total welfare of the auctioneer and the bidders. In this paper, we\nfocus on value maximizing bidders with return on spend constraints -- a\nparadigm that has drawn considerable attention recently as more advertisers\nadopt auto-bidding algorithms in advertising platforms -- and show that the\nintroduction of reserve prices has a novel impact on the market. Namely, by\nchoosing reserve prices appropriately the auctioneer can improve not only the\ntotal revenue but also the total welfare. Our results also demonstrate that\nreserve prices are robust to bidder types, i.e., reserve prices work well for\ndifferent bidder types, such as value maximizers and utility maximizers,\nwithout using bidder type information. We generalize these results for a\nvariety of auction mechanisms such as VCG, GSP, and first-price auctions.\nMoreover, we show how to combine these results with additive boosts to improve\nthe welfare of the outcomes of the auction further. Finally, we complement our\ntheoretical observations with an empirical study confirming the effectiveness\nof these ideas using data from online advertising auctions.",
    "descriptor": "",
    "authors": [
      "Santiago Balseiro",
      "Yuan Deng",
      "Jieming Mao",
      "Vahab Mirrokni",
      "Song Zuo"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.02468"
  },
  {
    "id": "arXiv:2111.02478",
    "title": "HOLZ: High-Order Entropy Encoding of Lempel-Ziv Factor Distances",
    "abstract": "We propose a new representation of the offsets of the Lempel-Ziv (LZ)\nfactorization based on the co-lexicographic order of the processed prefixes.\nThe selected offsets tend to approach the k-th order empirical entropy. Our\nevaluations show that this choice of offsets is superior to the rightmost LZ\nparsing and the bit-optimal LZ parsing on datasets with small high-order\nentropy.",
    "descriptor": "",
    "authors": [
      "Dominik K\u00f6ppl",
      "Gonzalo Navarro",
      "Nicola Prezza"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.02478"
  },
  {
    "id": "arXiv:2111.02480",
    "title": "Linear-time Minimization of Wheeler DFAs",
    "abstract": "Wheeler DFAs (WDFAs) are a sub-class of finite-state automata which is\nplaying an important role in the emerging field of compressed data structures:\nas opposed to general automata, WDFAs can be stored in just $\\log\\sigma + O(1)$\nbits per edge, $\\sigma$ being the alphabet's size, and support optimal-time\npattern matching queries on the substring closure of the language they\nrecognize. An important step to achieve further compression is minimization.\nWhen the input $\\mathcal A$ is a general deterministic finite-state automaton\n(DFA), the state-of-the-art is represented by the classic Hopcroft's algorithm,\nwhich runs in $O(|\\mathcal A|\\log |\\mathcal A|)$ time. This algorithm stands at\nthe core of the only existing minimization algorithm for Wheeler DFAs, which\ninherits its complexity. In this work, we show that the minimum WDFA equivalent\nto a given input WDFA can be computed in linear $O(|\\mathcal A|)$ time. When\nrun on de Bruijn WDFAs built from real DNA datasets, an implementation of our\nalgorithm reduces the number of nodes from 14% to 51% at a speed of more than 1\nmillion nodes per second.",
    "descriptor": "",
    "authors": [
      "Jarno Alanko",
      "Nicola Cotumaccio",
      "Nicola Prezza"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.02480"
  },
  {
    "id": "arXiv:2111.02481",
    "title": "Secure Namespaced Kernel Audit for Containers",
    "abstract": "Despite the wide usage of container-based cloud computing, container auditing\nfor security analysis relies mostly on built-in host audit systems, which often\nlack the ability to capture high-fidelity container logs. State-of-the-art\nreference-monitor-based audit techniques greatly improve the quality of audit\nlogs, but their system-wide architecture is too costly to be adapted for\nindividual containers. Moreover, these techniques typically require extensive\nkernel modifications, making them difficult to deploy in practical settings.\nIn this paper, we present saBPF (secure audit BPF), an extension of the eBPF\nframework capable of deploying secure system-level audit mechanisms at the\ncontainer granularity. We demonstrate the practicality of saBPF in Kubernetes\nby designing an audit framework, an intrusion detection system, and a\nlightweight access control mechanism. We evaluate saBPF and show that it is\ncomparable in performance and security guarantees to audit systems from the\nliterature that are implemented directly in the kernel.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Soo Yee Lim",
      "Bogdan Stelea",
      "Xueyuan Han",
      "Thomas Pasquier"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.02481"
  },
  {
    "id": "arXiv:2111.02484",
    "title": "Accelerated replica exchange stochastic gradient Langevin diffusion  enhanced Bayesian DeepONet for solving noisy parametric PDEs",
    "abstract": "The Deep Operator Networks~(DeepONet) is a fundamentally different class of\nneural networks that we train to approximate nonlinear operators, including the\nsolution operator of parametric partial differential equations (PDE). DeepONets\nhave shown remarkable approximation and generalization capabilities even when\ntrained with relatively small datasets. However, the performance of DeepONets\ndeteriorates when the training data is polluted with noise, a scenario that\noccurs very often in practice. To enable DeepONets training with noisy data, we\npropose using the Bayesian framework of replica-exchange Langevin diffusion.\nSuch a framework uses two particles, one for exploring and another for\nexploiting the loss function landscape of DeepONets. We show that the proposed\nframework's exploration and exploitation capabilities enable (1) improved\ntraining convergence for DeepONets in noisy scenarios and (2) attaching an\nuncertainty estimate for the predicted solutions of parametric PDEs. In\naddition, we show that replica-exchange Langeving Diffusion (remarkably) also\nimproves the DeepONet's mean prediction accuracy in noisy scenarios compared\nwith vanilla DeepONets trained with state-of-the-art gradient-based\noptimization algorithms (e.g. Adam). To reduce the potentially high\ncomputational cost of replica, in this work, we propose an accelerated training\nframework for replica-exchange Langevin diffusion that exploits the neural\nnetwork architecture of DeepONets to reduce its computational cost up to 25%\nwithout compromising the proposed framework's performance. Finally, we\nillustrate the effectiveness of the proposed Bayesian framework using a series\nof experiments on four parametric PDE problems.",
    "descriptor": "",
    "authors": [
      "Guang Lin",
      "Christian Moya",
      "Zecheng Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02484"
  },
  {
    "id": "arXiv:2111.02489",
    "title": "Communication-Efficient Separable Neural Network for Distributed  Inference on Edge Devices",
    "abstract": "The inference of Neural Networks is usually restricted by the resources\n(e.g., computing power, memory, bandwidth) on edge devices. In addition to\nimproving the hardware design and deploying efficient models, it is possible to\naggregate the computing power of many devices to enable the machine learning\nmodels. In this paper, we proposed a novel method of exploiting model\nparallelism to separate a neural network for distributed inferences. To achieve\na better balance between communication latency, computation latency, and\nperformance, we adopt neural architecture search (NAS) to search for the best\ntransmission policy and reduce the amount of communication. The best model we\nfound decreases by 86.6% of the amount of data transmission compared to the\nbaseline and does not impact performance much. Under proper specifications of\ndevices and configurations of models, our experiments show that the inference\nof large neural networks on edge clusters can be distributed and accelerated,\nwhich provides a new solution for the deployment of intelligent applications in\nthe internet of things (IoT).",
    "descriptor": "",
    "authors": [
      "Jun-Liang Lin",
      "Sheng-De Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02489"
  },
  {
    "id": "arXiv:2111.02500",
    "title": "Improving Pose Estimation through Contextual Activity Fusion",
    "abstract": "This research presents the idea of activity fusion into existing Pose\nEstimation architectures to enhance their predictive ability. This is motivated\nby the rise in higher level concepts found in modern machine learning\narchitectures, and the belief that activity context is a useful piece of\ninformation for the problem of pose estimation. To analyse this concept we take\nan existing deep learning architecture and augment it with an additional 1x1\nconvolution to fuse activity information into the model. We perform evaluation\nand comparison on a common pose estimation dataset, and show a performance\nimprovement over our baseline model, especially in uncommon poses and on\ntypically difficult joints. Additionally, we perform an ablative analysis to\nindicate that the performance improvement does in fact draw from the activity\ninformation.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "David Poulton",
      "Richard Klein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02500"
  },
  {
    "id": "arXiv:2111.02505",
    "title": "Shifting Polarization and Twitter News Influencers between two U.S.  Presidential Elections",
    "abstract": "Social media are decentralized, interactive, and transformative, empowering\nusers to produce and spread information to influence others. This has changed\nthe dynamics of political communication that were previously dominated by\ntraditional corporate news media. Having hundreds of millions of tweets\ncollected over the 2016 and 2020 U.S. presidential elections gave us a unique\nopportunity to measure the change in polarization and the diffusion of\npolitical information. We analyze the diffusion of political information among\nTwitter users and investigate the change of polarization between these\nelections and how this change affected the composition and polarization of\ninfluencers and their retweeters. We identify \"influencers\" by their ability to\nspread information and classify them into those affiliated with a media\norganization, a political organization, or unaffiliated. Most of the top\ninfluencers were affiliated with media organizations during both elections. We\nfound a clear increase from 2016 to 2020 in polarization among influencers and\namong those whom they influence. Moreover, 75% of the top influencers in 2020\nwere not present in 2016, demonstrating that such status is difficult to\nretain. Between 2016 and 2020, 10% of influencers affiliated with media were\nreplaced by center- or right-orientated influencers affiliated with political\norganizations and unaffiliated influencers.",
    "descriptor": "\nComments: 41 pages, 13 figures, 9 tables\n",
    "authors": [
      "James Flamino",
      "Alessandro Galezzi",
      "Stuart Feldman",
      "Michael W. Macy",
      "Brendan Cross",
      "Zhenkun Zhou",
      "Matteo Serafino",
      "Alexandre Bovet",
      "Hernan A. Makse",
      "Boleslaw K. Szymanski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.02505"
  },
  {
    "id": "arXiv:2111.02506",
    "title": "Real-Time Simulation of Level 1, Level 2, and Level 3 Electric Vehicle  Charging Systems",
    "abstract": "A charging system is required to convert ac electricity from the grid to dc\nelectricity to charge an electric vehicle (EV) battery. According to the\nSociety of Automatic Engineers (SAE) standard, EV chargers can be divided into\nthree levels based on power rating: Level 1, Level 2, and Level 3. This paper\ninvestigates the circuit topologies and control principles of EV charging\nsystems at each level. Three high-fidelity testbeds of EV charging systems for\na 10 kWh battery are designed and implemented in real-time digital simulator\nRT-Lab. The testbeds include modeling details such as switching of\nsemiconductors. Twenty-five minutes real-time simulation is conducted for each\ntestbed. Detailed dynamic performance of the circuits and the controls at every\nstage are presented to demonstrate the charging process. All three level EV\ncharging systems employ high-frequency transformer embedded dual active bridge\n(DAB) dc/dc converter to regulate battery side dc voltage and current. Hence,\naverage model-based linear system analysis is given to configure the parameters\nof the phase shift control adopted by the DAB dc/dc converter. In addition,\npower factor control (PFC) that is employed for Level 1 and Level 2\nsingle-phase ac charging systems, three-phase voltage source converter control\nthat is employed for Level 3 three-phase ac charging systems, are all analyzed.\nThe three testbeds, with their detailed circuit parameters and control\nparameters presented, can be used as reference testbeds for EV grid integration\nresearch.",
    "descriptor": "",
    "authors": [
      "Li Bao",
      "Lingling Fan",
      "Zhixin Miao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02506"
  },
  {
    "id": "arXiv:2111.02508",
    "title": "AlphaD3M: Machine Learning Pipeline Synthesis",
    "abstract": "We introduce AlphaD3M, an automatic machine learning (AutoML) system based on\nmeta reinforcement learning using sequence models with self play. AlphaD3M is\nbased on edit operations performed over machine learning pipeline primitives\nproviding explainability. We compare AlphaD3M with state-of-the-art AutoML\nsystems: Autosklearn, Autostacker, and TPOT, on OpenML datasets. AlphaD3M\nachieves competitive performance while being an order of magnitude faster,\nreducing computation time from hours to minutes, and is explainable by design.",
    "descriptor": "\nComments: ICML 2018 AutoML Workshop\n",
    "authors": [
      "Iddo Drori",
      "Yamuna Krishnamurthy",
      "Remi Rampin",
      "Raoni de Paula Lourenco",
      "Jorge Piazentin Ono",
      "Kyunghyun Cho",
      "Claudio Silva",
      "Juliana Freire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02508"
  },
  {
    "id": "arXiv:2111.02509",
    "title": "Clustering-based Multicast Scheme for UAV Networks",
    "abstract": "When an unmanned aerial vehicle (UAV) network is utilized as an aerial small\nbase station (BS), like a relay deployed far away from macro BSs, existing\nmulticast methods based on acknowledgement (ACK) feedback and retransmissions\nmay encounter severe delay and signaling overhead due to hostile wireless\nenvironments caused by a long-distance propagation and numerous UAVs. In this\npaper, a novel multicast scheme is designed for UAV networks serving as an\naerial small BS, where a UAV experiencing a packet loss will request the packet\nfrom other UAVs in the same cluster rather than relying on retransmissions of\nBSs. The technical details of the introduced multicast scheme are designed with\nthe carrier sense multiple access with collision avoidance (CSMA/CA) protocol\nfor practicability and without loss of generality. Then, the Poisson cluster\nprocess is employed to model UAV networks to capture their dynamic network\ntopology, based on which distance distributions are derived using tools of\nstochastic geometry for analytical tractability. Additionally, critical\nperformance indicators of the designed multicast scheme are analyzed. Through\nextensive simulation studies, the superiority of the designed multicast scheme\nis demonstrated and the system design insight related to the proper number of\nclusters is revealed.",
    "descriptor": "\nComments: 11 pages, 15 figures\n",
    "authors": [
      "Hao Song",
      "Lingjia Liu",
      "Bodong Shang",
      "Scott Pudlewski",
      "Elizabeth Serena Bentley"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02509"
  },
  {
    "id": "arXiv:2111.02512",
    "title": "Finite element approximation of the Levi-Civita connection and its  curvature in two dimensions",
    "abstract": "We construct finite element approximations of the Levi-Civita connection and\nits curvature on triangulations of oriented two-dimensional manifolds. Our\nconstruction relies on the Regge finite elements, which are piecewise\npolynomial symmetric (0,2)-tensor fields possessing single-valued\ntangential-tangential components along element interfaces. When used to\ndiscretize the Riemannian metric tensor, these piecewise polynomial tensor\nfields do not possess enough regularity to define connections and curvature in\nthe classical sense, but we show how to make sense of these quantities in a\ndistributional sense. We then show that these distributional quantities\nconverge in certain dual Sobolev norms to their smooth counterparts under\nrefinement of the triangulation. We also discuss projections of the\ndistributional curvature and distributional connection onto piecewise\npolynomial finite element spaces. We show that the relevant projection\noperators commute with certain linearized differential operators, yielding a\ncommutative diagram of differential complexes.",
    "descriptor": "",
    "authors": [
      "Yakov Berchenko-Kogan",
      "Evan S. Gawlik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2111.02512"
  },
  {
    "id": "arXiv:2111.02513",
    "title": "Evaluation of Tree Based Regression over Multiple Linear Regression for  Non-normally Distributed Data in Battery Performance",
    "abstract": "Battery performance datasets are typically non-normal and multicollinear.\nExtrapolating such datasets for model predictions needs attention to such\ncharacteristics. This study explores the impact of data normality in building\nmachine learning models. In this work, tree-based regression models and\nmultiple linear regressions models are each built from a highly skewed\nnon-normal dataset with multicollinearity and compared. Several techniques are\nnecessary, such as data transformation, to achieve a good multiple linear\nregression model with this dataset; the most useful techniques are discussed.\nWith these techniques, the best multiple linear regression model achieved an\nR^2 = 81.23% and exhibited no multicollinearity effect for the dataset used in\nthis study. Tree-based models perform better on this dataset, as they are\nnon-parametric, capable of handling complex relationships among variables and\nnot affected by multicollinearity. We show that bagging, in the use of Random\nForests, reduces overfitting. Our best tree-based model achieved accuracy of\nR^2 = 97.73%. This study explains why tree-based regressions promise as a\nmachine learning model for non-normally distributed, multicollinear data.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Shovan Chowdhury",
      "Yuxiao Lin",
      "Boryann Liaw",
      "Leslie Kerby"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02513"
  },
  {
    "id": "arXiv:2111.02514",
    "title": "Energy Efficiency of Uplink Cell-Free Massive MIMO With Transmit Power  Control in Measured Propagation Channel",
    "abstract": "Cell-free massive MIMO (CF-mMIMO) provides wireless connectivity for a large\nnumber of user equipments (UEs) using access points (APs) distributed across a\nwide area with high spectral efficiency (SE). The energy efficiency (EE) of the\nuplink is determined by (i) the transmit power control (TPC) algorithms, (ii)\nthe numbers, configurations, and locations of the APs and the UEs, and (iii)\nthe propagation channels between the APs and the UEs. This paper investigates\nall three aspects, based on extensive (~30,000 possible AP locations and 128\npossible UE locations) channel measurement data at 3.5 GHz. We compare three\ndifferent TPC algorithms, namely maximization of transmit power (max-power),\nmaximization of minimum SE (max-min SE), and maximization of minimum EE\n(max-min EE) while guaranteeing a target SE. We also compare various antenna\narrangements including fully-distributed and semi-distributed systems, where\nAPs can be located on a regular grid or randomly, and the UEs can be placed in\nclusters or far apart. Overall, we show that the max-min EE TPC is highly\neffective in improving the uplink EE, especially when no UE within a set of\nserved UEs is in a bad channel condition and when the BS antennas are\nfully-distributed.",
    "descriptor": "\nComments: 12 pages, 12 figures, IEEE Open Journal of Circuits and Systems. arXiv admin note: text overlap with arXiv:2108.02130\n",
    "authors": [
      "Thomas Choi",
      "Masaaki Ito",
      "Issei Kanno",
      "Jorge Gomez-Ponce",
      "Colton Bullard",
      "Takeo Ohseki",
      "Kosuke Yamazaki",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02514"
  },
  {
    "id": "arXiv:2111.02519",
    "title": "Athena 2.0: Contextualized Dialogue Management for an Alexa Prize  SocialBot",
    "abstract": "Athena 2.0 is an Alexa Prize SocialBot that has been a finalist in the last\ntwo Alexa Prize Grand Challenges. One reason for Athena's success is its novel\ndialogue management strategy, which allows it to dynamically construct\ndialogues and responses from component modules, leading to novel conversations\nwith every interaction. Here we describe Athena's system design and performance\nin the Alexa Prize during the 20/21 competition. A live demo of Athena as well\nas video recordings will provoke discussion on the state of the art in\nconversational AI.",
    "descriptor": "\nComments: Accepted to EMNLP 2021 System Demonstrations\n",
    "authors": [
      "Juraj Juraska",
      "Kevin K. Bowden",
      "Lena Reed",
      "Vrindavan Harrison",
      "Wen Cui",
      "Omkar Patil",
      "Rishi Rajasekaran",
      "Angela Ramirez",
      "Cecilia Li",
      "Eduardo Zamora",
      "Phillip Lee",
      "Jeshwanth Bheemanpally",
      "Rohan Pandey",
      "Adwait Ratnaparkhi",
      "Marilyn Walker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.02519"
  },
  {
    "id": "arXiv:2111.02521",
    "title": "Sequence-to-Sequence Modeling for Action Identification at High Temporal  Resolution",
    "abstract": "Automatic action identification from video and kinematic data is an important\nmachine learning problem with applications ranging from robotics to smart\nhealth. Most existing works focus on identifying coarse actions such as\nrunning, climbing, or cutting a vegetable, which have relatively long\ndurations. This is an important limitation for applications that require the\nidentification of subtle motions at high temporal resolution. For example, in\nstroke recovery, quantifying rehabilitation dose requires differentiating\nmotions with sub-second durations. Our goal is to bridge this gap. To this end,\nwe introduce a large-scale, multimodal dataset, StrokeRehab, as a new\naction-recognition benchmark that includes subtle short-duration actions\nlabeled at a high temporal resolution. These short-duration actions are called\nfunctional primitives, and consist of reaches, transports, repositions,\nstabilizations, and idles. The dataset consists of high-quality Inertial\nMeasurement Unit sensors and video data of 41 stroke-impaired patients\nperforming activities of daily living like feeding, brushing teeth, etc. We\nshow that current state-of-the-art models based on segmentation produce noisy\npredictions when applied to these data, which often leads to overcounting of\nactions. To address this, we propose a novel approach for high-resolution\naction identification, inspired by speech-recognition techniques, which is\nbased on a sequence-to-sequence model that directly predicts the sequence of\nactions. This approach outperforms current state-of-the-art methods on the\nStrokeRehab dataset, as well as on the standard benchmark datasets 50Salads,\nBreakfast, and Jigsaws.",
    "descriptor": "\nComments: Under review as a conference paper at ICLR 2022\n",
    "authors": [
      "Aakash Kaku",
      "Kangning Liu",
      "Avinash Parnandi",
      "Haresh Rengaraj Rajamohan",
      "Kannan Venkataramanan",
      "Anita Venkatesan",
      "Audre Wirtanen",
      "Natasha Pandit",
      "Heidi Schambra",
      "Carlos Fernandez-Granda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.02521"
  },
  {
    "id": "arXiv:2111.02523",
    "title": "Adding Safety Rules to Surgeon-Authored VR Training",
    "abstract": "Introduction: Safety criteria in surgical VR training are typically\nhard-coded and informally summarized. The Virtual Reality (VR) content creation\ninterface, TIPS-author, for the Toolkit for Illustration of Procedures in\nSurgery (TIPS) allows surgeon-educators (SEs) to create laparoscopic\nVR-training modules with force feedback. TIPS-author initializes anatomy shape\nand physical properties selected by the SE accessing a cloud data base of\nphysics-enabled pieces of anatomy. Methods: A new addition to TIPS-author are\nsafety rules that are set by the SE and are automatically monitored during\nsimulation. Errors are recorded as visual snapshots for feedback to the\ntrainee. This paper reports on the implementation and opportunistic evaluation\nof the snap-shot mechanism as a trainee feedback mechanism. TIPS was field\ntested at two surgical conferences, one before and one after adding the\nsnapshot feature. Results: While other ratings of TIPS remained unchanged for\nan overall Likert scale score of 5.24 out of 7 (7 equals very useful), the\nrating of the statement `The TIPS interface helps learners understand the force\nnecessary to explore the anatomy' improved from 5.04 to 5.35 out of 7 after the\nsnapshot mechanism was added. Conclusions: The ratings indicate the viability\nof the TIPS open-source2 E-authored surgical training units. Presenting\nSE-determined procedural missteps via the snapshot mechanism at the end of the\ntraining increases acceptance",
    "descriptor": "\nComments: How do I migrate this to cs.HC ? I need the identifier for a deadline and\n",
    "authors": [
      "Ruiliang Gao",
      "Sergei Kurenov",
      "Erik W. Black",
      "Jorg Peters"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.02523"
  },
  {
    "id": "arXiv:2111.02524",
    "title": "TOSCAdata: Modelling data pipeline applications in TOSCA",
    "abstract": "The serverless platform allows a customer to effectively use cloud resources\nand pay for the exact amount of used resources. A number of dedicated open\nsource and commercial cloud data management tools are available to handle the\nmassive amount of data. Such modern cloud data management tools are not enough\nmatured to integrate the generic cloud application with the serverless platform\ndue to the lack of mature and stable standards. One of the most popular and\nmature standards, TOSCA (Topology and Orchestration Specification for Cloud\nApplications), mainly focuses on application and service portability and\nautomated management of the generic cloud application components. This paper\nproposes the extension of the TOSCA standard, TOSCAdata, that focuses on the\nmodeling of data pipeline-based cloud applications. Keeping the requirements of\nmodern data pipeline cloud applications, TOSCAdata provides a number of TOSCA\nmodels that are independently deployable, schedulable, scalable, and re-usable,\nwhile effectively handling the flow and transformation of data in a pipeline\nmanner. We also demonstrate the applicability of proposed TOSCAdata models by\ntaking a web-based cloud application in the context of tourism promotion as a\nuse case scenario.",
    "descriptor": "\nComments: This is submitted to JSS-SI on Software Architecture and Artificial Intelligence and is currently under revision process\n",
    "authors": [
      "Chinmaya Kumar Dehury",
      "Pelle Jakovits",
      "Satish Narayana Srirama",
      "Giorgos Giotis",
      "Gaurav Garg"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.02524"
  },
  {
    "id": "arXiv:2111.02529",
    "title": "Shift Happens: Adjusting Classifiers",
    "abstract": "Minimizing expected loss measured by a proper scoring rule, such as Brier\nscore or log-loss (cross-entropy), is a common objective while training a\nprobabilistic classifier. If the data have experienced dataset shift where the\nclass distributions change post-training, then often the model's performance\nwill decrease, over-estimating the probabilities of some classes while\nunder-estimating the others on average. We propose unbounded and bounded\ngeneral adjustment (UGA and BGA) methods that transform all predictions to\n(re-)equalize the average prediction and the class distribution. These methods\nact differently depending on which proper scoring rule is to be minimized, and\nwe have a theoretical guarantee of reducing loss on test data, if the exact\nclass distribution is known. We also demonstrate experimentally that, when in\npractice the class distribution is known only approximately, there is often\nstill a reduction in loss depending on the amount of shift and the precision to\nwhich the class distribution is known.",
    "descriptor": "\nComments: ECML PKDD 2019 conference paper, 16 pages\n",
    "authors": [
      "Theodore James Thibault Heiser",
      "Mari-Liis Allikivi",
      "Meelis Kull"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02529"
  },
  {
    "id": "arXiv:2111.02531",
    "title": "Performance Analysis under IRS-User Association for Distributed IRSs  Assisted MISO Systems",
    "abstract": "Distributed intelligent reflecting surfaces (IRSs) deployed in multi-user\nwireless communication systems promise improved system performance. However,\nthe signal-to-interference-plus-noise ratio (SINR) analysis and IRSs\noptimization in such a system become challenging, due to the large number of\ninvolved parameters. The system optimization can be simplified if users are\nassociated with IRSs, which in turn focus on serving the associated users. We\nprovide a practical theoretical framework for the average SINR analysis of a\ndistributed IRSs-assisted multi-user MISO system, where IRSs are optimized to\nserve their associated users. In particular, we derive the average SINR\nexpression under maximum ratio transmission (MRT) precoding at the BS and\noptimized reflect beamforming configurations at the IRSs. A successive\nrefinement (SR) method is then outlined to optimize the IRS-user association\nparameters for the formulated max-min SINR problem which motivates\nuser-fairness. Simulations validate the average SINR analysis while confirming\nthe superiority of a distributed IRSs system over a centralized IRS system as\nwell as the gains with optimized IRS-user association as compared to random\nassociation.",
    "descriptor": "",
    "authors": [
      "Hibatallah Alwazani",
      "Qurrat-Ul-Ain Nadeem",
      "Anas Chaaban"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02531"
  },
  {
    "id": "arXiv:2111.02541",
    "title": "Asymptotic-Preserving Neural Networks for Multiscale Time-Dependent  Linear Transport Equations",
    "abstract": "In this paper we develop a neural network for the numerical simulation of\ntime-dependent linear transport equations with diffusive scaling and\nuncertainties. The goal of the network is to resolve the computational\nchallenges of curse-of-dimensionality and multiple scales of the problem. We\nfirst show that a standard Physics-Informed Neural Network (PINNs) fails to\ncapture the multiscale nature of the problem, hence justifies the need to use\nAsymptotic-Preserving Neural Networks (APNNs). We show that not all classical\nAP formulations are fit for the neural network approach. We construct a\nmicro-macro decomposition based neutral network, and also build in a mass\nconservation mechanism into the loss function, in order to capture the dynamic\nand multiscale nature of the solutions. Numerical examples are used to\ndemonstrate the effectiveness of this APNNs.",
    "descriptor": "",
    "authors": [
      "Shi Jin",
      "Zheng Ma",
      "Keke Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.02541"
  },
  {
    "id": "arXiv:2111.02542",
    "title": "Numerical implementation of efficient grid-free integral wall models in  unstructured-grid LES solvers",
    "abstract": "Two zonal wall-models based on integral form of the boundary layer\ndifferential equations, albeit with algebraic complexity, have been implemented\nin an unstructured-grid cell-centered finite-volume LES solver. The first model\nis a novel implementation of the ODE equilibrium wall model where the velocity\nprofile is expressed in the integral form using the constant shear-stress layer\nassumption and the integral is evaluated using a spectral quadrature method,\nresulting in a local and algebraic (grid-free) formulation. The second model,\nwhich closely follows the integral wall model of Yang et al. (Phys. Fluids 27,\n025112 (2015)), is based on the vertically-integrated thin-boundary-layer PDE\nalong with a prescribed composite velocity profile in the wall-modeled region.\nThe prescribed profile allows for a grid-free analytical integration of the PDE\nin the wall-normal direction, rendering this model algebraic in space. Several\nnumerical challenges unique to the implementation of these integral models in\nunstructured mesh environments are identified and possible remedies are\nproposed. The performance of the wall models is also assessed against the\ntraditional finite-volume-based ODE Equilibrium wall model.",
    "descriptor": "",
    "authors": [
      "Imran Hayat",
      "George Ilhwan Park"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2111.02542"
  },
  {
    "id": "arXiv:2111.02544",
    "title": "Polygon Placement Revisited: (Degree of Freedom + 1)-SUM Hardness and an  Improvement via Offline Dynamic Rectangle Union",
    "abstract": "We revisit the classical problem of determining the largest copy of a simple\npolygon $P$ that can be placed into a simple polygon $Q$. Despite significant\neffort, known algorithms require high polynomial running times. (Barequet and\nHar-Peled, 2001) give a lower bound of $n^{2-o(1)}$ under the 3SUM conjecture\nwhen $P$ and $Q$ are (convex) polygons with $\\Theta(n)$ vertices each. This\nleaves open whether we can establish (1) hardness beyond quadratic time and (2)\nany superlinear bound for constant-sized $P$ or $Q$.\nIn this paper, we affirmatively answer these questions under the $k$SUM\nconjecture, proving natural hardness results that increase with each degree of\nfreedom (scaling, $x$-translation, $y$-translation, rotation): (1) Finding the\nlargest copy of $P$ that can be $x$-translated into $Q$ requires time\n$n^{2-o(1)}$ under the 3SUM conjecture. (2) Finding the largest copy of $P$\nthat can be arbitrarily translated into $Q$ requires time $n^{2-o(1)}$ under\nthe 4SUM conjecture. (3) The above lower bounds are almost tight when one of\nthe polygons is of constant size: we obtain an $\\tilde O((pq)^{2.5})$-time\nalgorithm for orthogonal polygons $P,Q$ with $p$ and $q$ vertices,\nrespectively. (4) Finding the largest copy of $P$ that can be arbitrarily\nrotated and translated into $Q$ requires time $n^{3-o(1)}$ under the 5SUM\nconjecture.\nWe are not aware of any other such natural $($degree of freedom $+ 1)$-SUM\nhardness for a geometric optimization problem.",
    "descriptor": "\nComments: to appear at SODA 2020; shortened abstract\n",
    "authors": [
      "Marvin K\u00fcnnemann",
      "Andr\u00e9 Nusser"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.02544"
  },
  {
    "id": "arXiv:2111.02545",
    "title": "Multi-task Learning of Order-Consistent Causal Graphs",
    "abstract": "We consider the problem of discovering $K$ related Gaussian directed acyclic\ngraphs (DAGs), where the involved graph structures share a consistent causal\norder and sparse unions of supports. Under the multi-task learning setting, we\npropose a $l_1/l_2$-regularized maximum likelihood estimator (MLE) for learning\n$K$ linear structural equation models. We theoretically show that the joint\nestimator, by leveraging data across related tasks, can achieve a better sample\ncomplexity for recovering the causal order (or topological order) than separate\nestimations. Moreover, the joint estimator is able to recover non-identifiable\nDAGs, by estimating them together with some identifiable DAGs. Lastly, our\nanalysis also shows the consistency of union support recovery of the\nstructures. To allow practical implementation, we design a continuous\noptimization problem whose optimizer is the same as the joint estimator and can\nbe approximated efficiently by an iterative algorithm. We validate the\ntheoretical analysis and the effectiveness of the joint estimator in\nexperiments.",
    "descriptor": "\nComments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Xinshi Chen",
      "Haoran Sun",
      "Caleb Ellington",
      "Eric Xing",
      "Le Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.02545"
  },
  {
    "id": "arXiv:2111.02546",
    "title": "Isogeometric simulation of acoustic radiation",
    "abstract": "In this paper we discuss the numerical solution on a simple 2D domain of the\nHelmoltz equation with mixed boundary conditions. The so called radiation\nproblem depends on the wavenumber constant parameter k and it is inspired here\nby medical applications, where a transducer emits a pulse at a given frequency.\nThis problem has been successfully solved in the past with the classical Finite\nElement Method (FEM) for relative small values of k. But in modern applications\nthe values of k can be of order of thousands and FEM faces up several numerical\ndifficulties. To overcome these difficulties we solve the radiation problem\nusing the Isogeometric Analysis (IgA), a kind of generalization of FEM.\nStarting with the variational formulation of the radiation problem, we show\nwith details how to apply the isogeometric approach in order to compute the\ncoefficients of the approximated solution of radiation problem in terms of the\nB-spline basis functions. Our implementation of IgA using GeoPDEs software\nshows that isogeometric approach is superior than FEM, since it is able to\nreduce substantially the pollution error, especially for high values of k,\nproducing additionally smoother solutions which depend on less degrees of\nfreedom.",
    "descriptor": "\nComments: 20 pages, 8 figures\n",
    "authors": [
      "Victoria Hern\u00e1ndez Mederos",
      "Eduardo Moreno Hern\u00e1ndez",
      "Jorge Estrada Sarlabous",
      "Isidro A. Abell\u00f3 Ugalde",
      "Domenico Lahaye"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.02546"
  },
  {
    "id": "arXiv:2111.02548",
    "title": "Understanding Cross Domain Presentation Attack Detection for Visible  Face Recognition",
    "abstract": "Face signatures, including size, shape, texture, skin tone, eye color,\nappearance, and scars/marks, are widely used as discriminative, biometric\ninformation for access control. Despite recent advancements in facial\nrecognition systems, presentation attacks on facial recognition systems have\nbecome increasingly sophisticated. The ability to detect presentation attacks\nor spoofing attempts is a pressing concern for the integrity, security, and\ntrust of facial recognition systems. Multi-spectral imaging has been previously\nintroduced as a way to improve presentation attack detection by utilizing\nsensors that are sensitive to different regions of the electromagnetic spectrum\n(e.g., visible, near infrared, long-wave infrared). Although multi-spectral\npresentation attack detection systems may be discriminative, the need for\nadditional sensors and computational resources substantially increases\ncomplexity and costs. Instead, we propose a method that exploits information\nfrom infrared imagery during training to increase the discriminability of\nvisible-based presentation attack detection systems. We introduce (1) a new\ncross-domain presentation attack detection framework that increases the\nseparability of bonafide and presentation attacks using only visible spectrum\nimagery, (2) an inverse domain regularization technique for added training\nstability when optimizing our cross-domain presentation attack detection\nframework, and (3) a dense domain adaptation subnetwork to transform\nrepresentations between visible and non-visible domains.",
    "descriptor": "",
    "authors": [
      "Jennifer Hamblin",
      "Kshitij Nikhal",
      "Benjamin S. Riggan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02548"
  },
  {
    "id": "arXiv:2111.02550",
    "title": "Recommendations to clarify NASA open source requirements",
    "abstract": "The software community has specific definitions for terms such as \"open\nsource software,\" \"free software,\" and \"permissive license,\" but scientists\nproposing software development efforts to NASA are not always knowledgeable\nabout these definitions. Misunderstandings about the meaning of these terms can\nresult in problems of fairness with solicitations, because scientists who\ninterpret the terms differently than NASA intends may either needlessly limit\nthe scope of their proposed work, or unwittingly propose work that does not\ncomply with software licensing requirements. It is therefore recommended that\nNASA adopt definitions of the above terms that are in line with software\ncommunity usage, that these definitions be communicated as part of\nsolicitations to ensure a common understanding, and that proposals be required\nto identify what software licenses the proposers expect to use.",
    "descriptor": "",
    "authors": [
      "John D. Haiducek",
      "Thom R. Edwards",
      "Wade Duvall",
      "Sarah R. Cannon",
      "Kai Germaschewski",
      "Jason E. Kooi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Space Physics (physics.space-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.02550"
  },
  {
    "id": "arXiv:2111.02552",
    "title": "Is Bang-Bang Control All You Need? Solving Continuous Control with  Bernoulli Policies",
    "abstract": "Reinforcement learning (RL) for continuous control typically employs\ndistributions whose support covers the entire action space. In this work, we\ninvestigate the colloquially known phenomenon that trained agents often prefer\nactions at the boundaries of that space. We draw theoretical connections to the\nemergence of bang-bang behavior in optimal control, and provide extensive\nempirical evaluation across a variety of recent RL algorithms. We replace the\nnormal Gaussian by a Bernoulli distribution that solely considers the extremes\nalong each action dimension - a bang-bang controller. Surprisingly, this\nachieves state-of-the-art performance on several continuous control benchmarks\n- in contrast to robotic hardware, where energy and maintenance cost affect\ncontroller choices. Since exploration, learning,and the final solution are\nentangled in RL, we provide additional imitation learning experiments to reduce\nthe impact of exploration on our analysis. Finally, we show that our\nobservations generalize to environments that aim to model real-world challenges\nand evaluate factors to mitigate the emergence of bang-bang solutions. Our\nfindings emphasize challenges for benchmarking continuous control algorithms,\nparticularly in light of potential real-world applications.",
    "descriptor": "",
    "authors": [
      "Tim Seyde",
      "Igor Gilitschenski",
      "Wilko Schwarting",
      "Bartolomeo Stellato",
      "Martin Riedmiller",
      "Markus Wulfmeier",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.02552"
  },
  {
    "id": "arXiv:2111.02555",
    "title": "Implementing augmented reality technology to measure structural changes  across time",
    "abstract": "In recent years, augmented reality (AR) technology has been increasingly\nemployed in structural health monitoring (SHM). In the case of conditions\nfollowing a seismic event, inspections are conducted to evaluate the\nprogression of the damage pattern quantitatively and efficiently respond if the\ndisplacement pattern is determined to be unsafe. Additionally, quantification\nof nearby structural changes over short-term and long-term periods can provide\nbuilding inspectors with information to improve safety. This paper proposes the\nTime Machine Measure (TMM) application on an Augmented Reality (AR)\nHead-Mounted-Device (HMD) platform. The main function of the TMM application is\nto restore the saved meshes of a past environment and overlay them onto the\nreal environment so that inspectors can intuitively measure structural\ndeformation and other movement across time. The proposed TMM application was\nverified by experiments meant to simulate a real-world inspection.",
    "descriptor": "\nComments: 19 pages, 13 figures\n",
    "authors": [
      "Jiaqi Xu",
      "Elijah Wyckoff",
      "John-Wesley Hanson",
      "Fernando Moreu",
      "Derek Doyle"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.02555"
  },
  {
    "id": "arXiv:2111.02557",
    "title": "A Meta-Learned Neuron model for Continual Learning",
    "abstract": "Continual learning is the ability to acquire new knowledge without forgetting\nthe previously learned one, assuming no further access to past training data.\nNeural network approximators trained with gradient descent are known to fail in\nthis setting as they must learn from a stream of data-points sampled from a\nstationary distribution to converge. In this work, we replace the standard\nneuron by a meta-learned neuron model whom inference and update rules are\noptimized to minimize catastrophic interference. Our approach can memorize\ndataset-length sequences of training samples, and its learning capabilities\ngeneralize to any domain. Unlike previous continual learning methods, our\nmethod does not make any assumption about how tasks are constructed, delivered\nand how they relate to each other: it simply absorbs and retains training\nsamples one by one, whether the stream of input data is time-correlated or not.",
    "descriptor": "\nComments: 7 pages, preprint\n",
    "authors": [
      "Rodrigue Siry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.02557"
  },
  {
    "id": "arXiv:2111.02559",
    "title": "Schwarz Waveform Relaxation Physics-Informed Neural Networks for Solving  Advection-Diffusion-Reaction Equations",
    "abstract": "This paper develops a physics-informed neural network (PINN) based on the\nSchwarz waveform relaxation (SWR) method for solving local and nonlocal\nadvection-diffusion-reaction equations. Specifically, we derive the formulation\nby constructing subdomain-dependent local solutions by minimizing local loss\nfunctions, allowing the decomposition of the training process in different\ndomains in an embarrassingly parallel procedure. Provided the convergence of\nPINN, the overall proposed algorithm is convergent. By constructing local\nsolutions, one can, in particular, adapt the depth of the deep neural networks,\ndepending on the solution's spectral space and time complexity in each\nsubdomain. We present some numerical experiments based on classical and\nRobin-SWR to illustrate the performance and comment on the convergence of the\nproposed method.",
    "descriptor": "\nComments: 21 pages, 16 figures\n",
    "authors": [
      "Emmanuel Lorin",
      "Xu Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.02559"
  },
  {
    "id": "arXiv:2111.02569",
    "title": "RT-RCG: Neural Network and Accelerator Search Towards Effective and  Real-time ECG Reconstruction from Intracardiac Electrograms",
    "abstract": "There exists a gap in terms of the signals provided by pacemakers (i.e.,\nintracardiac electrogram (EGM)) and the signals doctors use (i.e., 12-lead\nelectrocardiogram (ECG)) to diagnose abnormal rhythms. Therefore, the former,\neven if remotely transmitted, are not sufficient for doctors to provide a\nprecise diagnosis, let alone make a timely intervention. To close this gap and\nmake a heuristic step towards real-time critical intervention in instant\nresponse to irregular and infrequent ventricular rhythms, we propose a new\nframework dubbed RT-RCG to automatically search for (1) efficient Deep Neural\nNetwork (DNN) structures and then (2)corresponding accelerators, to enable\nReal-Time and high-quality Reconstruction of ECG signals from EGM signals.\nSpecifically, RT-RCG proposes a new DNN search space tailored for ECG\nreconstruction from EGM signals, and incorporates a differentiable acceleration\nsearch (DAS) engine to efficiently navigate over the large and discrete\naccelerator design space to generate optimized accelerators. Extensive\nexperiments and ablation studies under various settings consistently validate\nthe effectiveness of our RT-RCG. To the best of our knowledge, RT-RCG is the\nfirst to leverage neural architecture search (NAS) to simultaneously tackle\nboth reconstruction efficacy and efficiency.",
    "descriptor": "\nComments: JETC Special issue on Hardware-Aware Learning for Medical Applications (Waiting assignment to batch)\n",
    "authors": [
      "Yongan Zhang",
      "Anton Banta",
      "Yonggan Fu",
      "Mathews M. John",
      "Allison Post",
      "Mehdi Razavi",
      "Joseph Cavallaro",
      "Behnaam Aazhang",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02569"
  },
  {
    "id": "arXiv:2111.02570",
    "title": "CLUES: Few-Shot Learning Evaluation in Natural Language Understanding",
    "abstract": "Most recent progress in natural language understanding (NLU) has been driven,\nin part, by benchmarks such as GLUE, SuperGLUE, SQuAD, etc. In fact, many NLU\nmodels have now matched or exceeded \"human-level\" performance on many tasks in\nthese benchmarks. Most of these benchmarks, however, give models access to\nrelatively large amounts of labeled data for training. As such, the models are\nprovided far more data than required by humans to achieve strong performance.\nThat has motivated a line of work that focuses on improving few-shot learning\nperformance of NLU models. However, there is a lack of standardized evaluation\nbenchmarks for few-shot NLU resulting in different experimental settings in\ndifferent papers. To help accelerate this line of work, we introduce CLUES\n(Constrained Language Understanding Evaluation Standard), a benchmark for\nevaluating the few-shot learning capabilities of NLU models. We demonstrate\nthat while recent models reach human performance when they have access to large\namounts of labeled data, there is a huge gap in performance in the few-shot\nsetting for most tasks. We also demonstrate differences between alternative\nmodel families and adaptation techniques in the few shot setting. Finally, we\ndiscuss several principles and choices in designing the experimental settings\nfor evaluating the true few-shot learning performance and suggest a unified\nstandardized approach to few-shot learning evaluation. We aim to encourage\nresearch on NLU models that can generalize to new tasks with a small number of\nexamples. Code and data for CLUES are available at\nhttps://github.com/microsoft/CLUES.",
    "descriptor": "\nComments: NeurIPS 2021 Datasets and Benchmarks Track\n",
    "authors": [
      "Subhabrata Mukherjee",
      "Xiaodong Liu",
      "Guoqing Zheng",
      "Saghar Hosseini",
      "Hao Cheng",
      "Greg Yang",
      "Christopher Meek",
      "Ahmed Hassan Awadallah",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02570"
  },
  {
    "id": "arXiv:2111.02571",
    "title": "Learning suction graspability considering grasp quality and robot  reachability for bin-picking",
    "abstract": "Deep learning has been widely used for inferring robust grasps. Although\nhuman-labeled RGB-D datasets were initially used to learn grasp configurations,\npreparation of this kind of large dataset is expensive. To address this\nproblem, images were generated by a physical simulator, and a physically\ninspired model (e.g., a contact model between a suction vacuum cup and object)\nwas used as a grasp quality evaluation metric to annotate the synthesized\nimages. However, this kind of contact model is complicated and requires\nparameter identification by experiments to ensure real world performance. In\naddition, previous studies have not considered manipulator reachability such as\nwhen a grasp configuration with high grasp quality is unable to reach the\ntarget due to collisions or the physical limitations of the robot. In this\nstudy, we propose an intuitive geometric analytic-based grasp quality\nevaluation metric. We further incorporate a reachability evaluation metric. We\nannotate the pixel-wise grasp quality and reachability by the proposed\nevaluation metric on synthesized images in a simulator to train an\nauto-encoder--decoder called suction graspability U-Net++ (SG-U-Net++).\nExperiment results show that our intuitive grasp quality evaluation metric is\ncompetitive with a physically-inspired metric. Learning the reachability helps\nto reduce motion planning computation time by removing obviously unreachable\ncandidates. The system achieves an overall picking speed of 560 PPH (pieces per\nhour).",
    "descriptor": "\nComments: 18 pages, 2 tables, 7 figures\n",
    "authors": [
      "Ping Jiang",
      "Junji Oaki",
      "Yoshiyuki Ishihara",
      "Junichiro Ooga",
      "Haifeng Han",
      "Atsushi Sugahara",
      "Seiji Tokura",
      "Haruna Eto",
      "Kazuma Komoda",
      "Akihito Ogawa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02571"
  },
  {
    "id": "arXiv:2111.02572",
    "title": "A Constant-Factor Approximation for Quasi-bipartite Directed Steiner  Tree on Minor-Free Graphs",
    "abstract": "We give the first constant-factor approximation algorithm for quasi-bipartite\ninstances of Directed Steiner Tree on graphs that exclude fixed minors. In\nparticular, for $K_r$-minor-free graphs our approximation guarantee is\n$O(r\\cdot\\sqrt{\\log r})$ and, further, for planar graphs our approximation\nguarantee is 20.\nOur algorithm uses the primal-dual scheme. We employ a more involved method\nof determining when to buy an edge while raising dual variables since, as we\nshow, the natural primal-dual scheme fails to raise enough dual value to pay\nfor the purchased solution. As a consequence, we also demonstrate integrality\ngap upper bounds on the standard cut-based linear programming relaxation for\nthe Directed Steiner Tree instances we consider.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Zachary Friggstad",
      "Ramin Mousavi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.02572"
  },
  {
    "id": "arXiv:2111.02574",
    "title": "Contextual Semantic Parsing for Multilingual Task-Oriented Dialogues",
    "abstract": "Robust state tracking for task-oriented dialogue systems currently remains\nrestricted to a few popular languages. This paper shows that given a\nlarge-scale dialogue data set in one language, we can automatically produce an\neffective semantic parser for other languages using machine translation. We\npropose automatic translation of dialogue datasets with alignment to ensure\nfaithful translation of slot values and eliminate costly human supervision used\nin previous benchmarks. We also propose a new contextual semantic parsing\nmodel, which encodes the formal slots and values, and only the last agent and\nuser utterances. We show that the succinct representation reduces the\ncompounding effect of translation errors, without harming the accuracy in\npractice.\nWe evaluate our approach on several dialogue state tracking benchmarks. On\nRiSAWOZ, CrossWOZ, CrossWOZ-EN, and MultiWOZ-ZH datasets we improve the state\nof the art by 11%, 17%, 20%, and 0.3% in joint goal accuracy. We present a\ncomprehensive error analysis for all three datasets showing erroneous\nannotations can obscure judgments on the quality of the model.\nFinally, we present RiSAWOZ English and German datasets, created using our\ntranslation methodology. On these datasets, accuracy is within 11% of the\noriginal showing that high-accuracy multilingual dialogue datasets are possible\nwithout relying on expensive human annotations.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Mehrad Moradshahi",
      "Victoria Tsai",
      "Giovanni Campagna",
      "Monica S. Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02574"
  },
  {
    "id": "arXiv:2111.02579",
    "title": "Reallocation Problems with Minimum Completion Time",
    "abstract": "Reallocation scheduling is one of the most fundamental problems in various\nareas such as supply chain management, logistics, and transportation science.\nIn this paper, we introduce the reallocation problem that models the scheduling\nin which products are with fixed cost, non-fungible, and reallocated in\nparallel, and comprehensively study the complexity of the problem under various\nsettings of the transition time, product size, and capacities. We show that the\nproblem can be solved in polynomial time for a fundamental setting where the\nproduct size and transition time are both uniform. We also show that the\nfeasibility of the problem is NP-complete even for little more general\nsettings, which implies that no polynomial-time algorithm constructs a feasible\nschedule of the problem unless P$=$NP. We then consider the relaxation of the\nproblem, which we call the capacity augmentation, and derive a reallocation\nschedule feasible with the augmentation such that the completion time is at\nmost the optimal of the original problem. When the warehouse capacity is\nsufficiently large, we design constant-factor approximation algorithms under\nall the settings. We also show the relationship between the reallocation\nproblem and the bin packing problem when the warehouse and carry-in capacities\nare sufficiently large.",
    "descriptor": "\nComments: 24 pages, 2 figures\n",
    "authors": [
      "Toshimasa Ishii",
      "Jun Kawahara",
      "Kazuhisa Makino",
      "Hirotaka Ono"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.02579"
  },
  {
    "id": "arXiv:2111.02580",
    "title": "Deep Direct Visual Servoing of Tendon-Driven Continuum Robots",
    "abstract": "Vision-based control has found a key place in the research to tackle the\nrequirement of the state feedback when controlling a continuum robot under\nphysical sensing limitations. Traditional visual servoing requires feature\nextraction and tracking while the imaging device captures the images, which\nlimits the controller's efficiency. We hypothesize that employing deep learning\nmodels and implementing direct visual servoing can effectively resolve the\nissue by eliminating the tracking requirement and controlling the continuum\nrobot without requiring an exact system model. In this paper, we control a\nsingle-section tendon-driven continuum robot utilizing a modified VGG-16 deep\nlearning network and an eye-in-hand direct visual servoing approach. The\nproposed algorithm is first developed in Blender using only one input image of\nthe target and then implemented on a real robot. The convergence and accuracy\nof the results in normal, shadowed, and occluded scenes reflected by the sum of\nabsolute difference between the normalized target and captured images prove the\neffectiveness and robustness of the proposed controller.",
    "descriptor": "\nComments: 7 pages, 10 figures, 1 table, Submitted to 2022 IEEE International Conference on Soft Robotics (RoboSoft)\n",
    "authors": [
      "Ibrahim Abdulhafiz",
      "Ali A. Nazari",
      "Taha Abbasi-Hashemi",
      "Amir Jalali",
      "Kourosh Zareinia",
      "Sajad Saeedi",
      "Farrokh Janabi-Sharifi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.02580"
  },
  {
    "id": "arXiv:2111.02581",
    "title": "Optimal Discrete Constellation Inputs for Aggregated LiFi-WiFi Networks",
    "abstract": "In this paper, we investigate the performance of a practical aggregated\nLiFi-WiFi system with the discrete constellation inputs from a practical view.\nWe derive the achievable rate expressions of the aggregated LiFi-WiFi system\nfor the first time. Then, we study the rate maximization problem via optimizing\nthe constellation distribution and power allocation jointly. Specifically, a\nmultilevel mercy-filling power allocation scheme is proposed by exploiting the\nrelationship between the mutual information and minimum mean-squared error\n(MMSE) of discrete inputs. Meanwhile, an inexact gradient descent method is\nproposed for obtaining the optimal probability distributions. To strike a\nbalance between the computational complexity and the transmission performance,\nwe further develop a framework that maximizes the lower bound of the achievable\nrate where the optimal power allocation can be obtained in closed forms and the\nconstellation distributions problem can be solved efficiently by Frank-Wolfe\nmethod. Extensive numerical results show that the optimized strategies are able\nto provide significant gains over the state-of-the-art schemes in terms of the\nachievable rate.",
    "descriptor": "\nComments: 14 pages, 13 figures, accepted by IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Shuai Ma",
      "Fan Zhang",
      "Songtao Lu",
      "Hang Li",
      "Ruixin Yang",
      "Sihua Shao",
      "Jiaheng Wang",
      "Shiyin Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02581"
  },
  {
    "id": "arXiv:2111.02583",
    "title": "CryptoNite: Revealing the Pitfalls of End-to-End Private Inference at  Scale",
    "abstract": "The privacy concerns of providing deep learning inference as a service have\nunderscored the need for private inference (PI) protocols that protect users'\ndata and the service provider's model using cryptographic methods. Recently\nproposed PI protocols have achieved significant reductions in PI latency by\nmoving the computationally heavy homomorphic encryption (HE) parts to an\noffline/pre-compute phase. Paired with recent optimizations that tailor\nnetworks for PI, these protocols have achieved performance levels that are\ntantalizingly close to being practical. In this paper, we conduct a rigorous\nend-to-end characterization of PI protocols and optimization techniques and\nfind that the current understanding of PI performance is overly optimistic.\nSpecifically, we find that offline storage costs of garbled circuits (GC), a\nkey cryptographic protocol used in PI, on user/client devices are prohibitively\nhigh and force much of the expensive offline HE computation to the online\nphase, resulting in a 10-1000$\\times$ increase to PI latency. We propose a\nmodified PI protocol that significantly reduces client-side storage costs for a\nsmall increase in online latency. Evaluated end-to-end, the modified protocol\noutperforms current protocols by reducing the mean PI latency by $4\\times$ for\nResNet18 on TinyImageNet. We conclude with a discussion of several recently\nproposed PI optimizations in light of the findings and note many actually\nincrease PI latency when evaluated from an end-to-end perspective.",
    "descriptor": "\nComments: 4 Figures and 3 Tables\n",
    "authors": [
      "Karthik Garimella",
      "Nandan Kumar Jha",
      "Zahra Ghodsi",
      "Siddharth Garg",
      "Brandon Reagen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.02583"
  },
  {
    "id": "arXiv:2111.02584",
    "title": "Real-time Wireless Transmitter Authorization: Adapting to Dynamic  Authorized Sets with Information Retrieval",
    "abstract": "As the Internet of Things (IoT) continues to grow, ensuring the security of\nsystems that rely on wireless IoT devices has become critically important. Deep\nlearning-based passive physical layer transmitter authorization systems have\nbeen introduced recently for this purpose, as they accommodate the limited\ncomputational and power budget of such devices. These systems have been shown\nto offer excellent outlier detection accuracies when trained and tested on a\nfixed authorized transmitter set. However in a real-life deployment, a need may\narise for transmitters to be added and removed as the authorized set of\ntransmitters changes. In such cases, the system could experience long\ndown-times, as retraining the underlying deep learning model is often a\ntime-consuming process. In this paper, we draw inspiration from information\nretrieval to address this problem: by utilizing feature vectors as RF\nfingerprints, we first demonstrate that training could be simplified to\nindexing those feature vectors into a database using locality sensitive hashing\n(LSH). Then we show that approximate nearest neighbor search could be performed\non the database to perform transmitter authorization that matches the accuracy\nof deep learning models, while allowing for more than 100x faster retraining.\nFurthermore, dimensionality reduction techniques are used on the feature\nvectors to show that the authorization latency of our technique could be\nreduced to approach that of traditional deep learning-based systems.",
    "descriptor": "\nComments: Submitted to IEEE DySPAN 2021\n",
    "authors": [
      "Samurdhi Karunaratne",
      "Samer Hanna",
      "Danijela Cabric"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02584"
  },
  {
    "id": "arXiv:2111.02585",
    "title": "InQSS: a speech intelligibility assessment model using a multi-task  learning network",
    "abstract": "Speech intelligibility assessment models are essential tools for researchers\nto evaluate and improve speech processing models. In this study, we propose\nInQSS, a speech intelligibility assessment model that uses both spectrogram and\nscattering coefficients as input features. In addition, InQSS uses a multi-task\nlearning network in which quality scores can guide the training of the speech\nintelligibility assessment. The resulting model can predict not only the\nintelligibility scores but also the quality scores of a speech. The\nexperimental results confirm that the scattering coefficients and quality\nscores are informative for intelligibility. Moreover, we released TMHINT-QI,\nwhich is a Chinese speech dataset that records the quality and intelligibility\nscores of clean, noisy, and enhanced speech.",
    "descriptor": "",
    "authors": [
      "Yu-Wen Chen",
      "Yu Tsao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.02585"
  },
  {
    "id": "arXiv:2111.02586",
    "title": "Building Damage Mapping with Self-PositiveUnlabeled Learning",
    "abstract": "Humanitarian organizations must have fast and reliable data to respond to\ndisasters. Deep learning approaches are difficult to implement in real-world\ndisasters because it might be challenging to collect ground truth data of the\ndamage situation (training data) soon after the event. The implementation of\nrecent self-paced positive-unlabeled learning (PU) is demonstrated in this work\nby successfully applying to building damage assessment with very limited\nlabeled data and a large amount of unlabeled data. Self-PU learning is compared\nwith the supervised baselines and traditional PU learning using different\ndatasets collected from the 2011 Tohoku earthquake, the 2018 Palu tsunami, and\nthe 2018 Hurricane Michael. By utilizing only a portion of labeled damaged\nsamples, we show how models trained with self-PU techniques may achieve\ncomparable performance as supervised learning.",
    "descriptor": "\nComments: 7 pages, 1 figure, Artificial Intelligence for Humanitarian Assistance and Disaster Response Workshop, NeurIPS 2021\n",
    "authors": [
      "Junshi Xia",
      "Naoto Yokoya",
      "Bruno Adriano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.02586"
  },
  {
    "id": "arXiv:2111.02591",
    "title": "Minimum-Complexity Graph Simplification under Fr\u00e9chet-Like Distances",
    "abstract": "Simplifying graphs is a very applicable problem in numerous domains,\nespecially in computational geometry. Given a geometric graph and a threshold,\nthe minimum-complexity graph simplification asks for computing an alternative\ngraph of minimum complexity so that the distance between the two graphs remains\nat most the threshold. In this paper, we propose several NP-hardness and\nalgorithmic results depending on the type of input and simplified graphs, the\nvertex placement of the simplified graph, and the distance measures between\nthem (graph and traversal distances [1,2]). In general, we show that for\narbitrary input and output graphs, the problem is NP-hard under some specific\nvertex-placement of the simplified graph. When the input and output are trees,\nand the graph distance is applied from the simplified tree to the input tree,\nwe give an $O(kn^5)$ time algorithm, where $k$ is the number of the leaves of\nthe two trees that are identical and $n$ is the number of vertices of the\ninput.",
    "descriptor": "\nComments: 27 pages, 13 figures\n",
    "authors": [
      "Omrit Filtser",
      "Majid Mirzanezhad",
      "Carola Wenk"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.02591"
  },
  {
    "id": "arXiv:2111.02593",
    "title": "Energy-Efficient Online Data Sensing and Processing in Wireless Powered  Edge Computing Systems",
    "abstract": "This paper focuses on developing energy-efficient online data processing\nstrategy of wireless powered MEC systems under stochastic fading channels. In\nparticular, we consider a hybrid access point (HAP) transmitting RF energy to\nand processing the sensing data offloaded from multiple WDs. Under an average\npower constraint of the HAP, we aim to maximize the long-term average data\nsensing rate of the WDs while maintaining task data queue stability. We\nformulate the problem as a multi-stage stochastic optimization to control the\nenergy transfer and task data processing in sequential time slots. Without the\nknowledge of future channel fading, it is very challenging to determine the\nsequential control actions that are tightly coupled by the battery and data\nbuffer dynamics. To solve the problem, we propose an online algorithm named\nLEESE that applies the perturbed Lyapunov optimization technique to decompose\nthe multi-stage stochastic problem into per-slot deterministic optimization\nproblems. We show that each per-slot problem can be equivalently transformed\ninto a convex optimization problem. To facilitate online implementation in\nlarge-scale MEC systems, instead of solving the per-slot problem with\noff-the-shelf convex algorithms, we propose a block coordinate descent\n(BCD)-based method that produces close-to-optimal solution in less than 0.04\\%\nof the computation delay. Simulation results demonstrate that the proposed\nLEESE algorithm can provide 21.9\\% higher data sensing rate than the\nrepresentative benchmark methods considered, while incurring sub-millisecond\ncomputation delay suitable for real-time control under fading channel.",
    "descriptor": "\nComments: This article has been submitted to IEEE for possible publication.Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Xian Li",
      "Suzhi Bi",
      "Yuan Zheng",
      "Hui Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02593"
  },
  {
    "id": "arXiv:2111.02598",
    "title": "Universal Private Estimators",
    "abstract": "We present $\\textit{universal}$ estimators for the statistical mean,\nvariance, and scale (in particular, the interquartile range) under pure\ndifferential privacy. These estimators are universal in the sense that they\nwork on an arbitrary, unknown distribution $\\mathcal{P}$ over $\\mathbb{R}$,\nwhile yielding strong utility guarantees except for ill-behaved $\\mathcal{P}$.\nFor certain distribution families like Gaussians or heavy-tailed distributions,\nwe show that our universal estimators match or improve existing estimators,\nwhich are often specifically designed for the given family and under\n$\\textit{priori}$ boundedness assumptions on the mean and variance of\n$\\mathcal{P}$. The removal of these boundedness assumptions is surprising, as\nexisting work believes that they are necessary under pure differential privacy.",
    "descriptor": "",
    "authors": [
      "Wei Dong",
      "Ke Yi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.02598"
  },
  {
    "id": "arXiv:2111.02599",
    "title": "Leveraging Time Irreversibility with Order-Contrastive Pre-training",
    "abstract": "Label-scarce, high-dimensional domains such as healthcare present a challenge\nfor modern machine learning techniques. To overcome the difficulties posed by a\nlack of labeled data, we explore an \"order-contrastive\" method for\nself-supervised pre-training on longitudinal data. We sample pairs of time\nsegments, switch the order for half of them, and train a model to predict\nwhether a given pair is in the correct order. Intuitively, the ordering task\nallows the model to attend to the least time-reversible features (for example,\nfeatures that indicate progression of a chronic disease). The same features are\noften useful for downstream tasks of interest. To quantify this, we study a\nsimple theoretical setting where we prove a finite-sample guarantee for the\ndownstream error of a representation learned with order-contrastive\npre-training. Empirically, in synthetic and longitudinal healthcare settings,\nwe demonstrate the effectiveness of order-contrastive pre-training in the\nsmall-data regime over supervised learning and other self-supervised\npre-training baselines. Our results indicate that pre-training methods designed\nfor particular classes of distributions and downstream tasks can improve the\nperformance of self-supervised learning.",
    "descriptor": "",
    "authors": [
      "Monica Agrawal",
      "Hunter Lang",
      "Michael Offin",
      "Lior Gazit",
      "David Sontag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02599"
  },
  {
    "id": "arXiv:2111.02603",
    "title": "On Semantic Cognition, Inductive Generalization, and Language Models",
    "abstract": "My doctoral research focuses on understanding semantic knowledge in neural\nnetwork models trained solely to predict natural language (referred to as\nlanguage models, or LMs), by drawing on insights from the study of concepts and\ncategories grounded in cognitive science. I propose a framework inspired by\n'inductive reasoning,' a phenomenon that sheds light on how humans utilize\nbackground knowledge to make inductive leaps and generalize from new pieces of\ninformation about concepts and their properties. Drawing from experiments that\nstudy inductive reasoning, I propose to analyze semantic inductive\ngeneralization in LMs using phenomena observed in human-induction literature,\ninvestigate inductive behavior on tasks such as implicit reasoning and emergent\nfeature recognition, and analyze and relate induction dynamics to the learned\nconceptual representation space.",
    "descriptor": "\nComments: Accepted at AAAI 2022 Doctoral Consortium\n",
    "authors": [
      "Kanishka Misra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02603"
  },
  {
    "id": "arXiv:2111.02604",
    "title": "Auto Tuning of Hadoop and Spark parameters",
    "abstract": "Data of the order of terabytes, petabytes, or beyond is known as Big Data.\nThis data cannot be processed using the traditional database software, and\nhence there comes the need for Big Data Platforms. By combining the\ncapabilities and features of various big data applications and utilities, Big\nData Platforms form a single solution. It is a platform that helps to develop,\ndeploy and manage the big data environment. Hadoop and Spark are the two\nopen-source Big Data Platforms provided by Apache. Both these platforms have\nmany configurational parameters, which can have unforeseen effects on the\nexecution time, accuracy, etc. Manual tuning of these parameters can be\ntiresome, and hence automatic ways should be needed to tune them. After\nstudying and analyzing various previous works in automating the tuning of these\nparameters, this paper proposes two algorithms - Grid Search with Finer Tuning\nand Controlled Random Search. The performance indicator studied in this paper\nis Execution Time. These algorithms help to tune the parameters automatically.\nExperimental results have shown a reduction in execution time of about 70% and\n50% for Hadoop and 81.19% and 77.77% for Spark by Grid Search with Finer Tuning\nand Controlled Random Search, respectively.",
    "descriptor": "\nComments: 12 Pages, 9 Figures, 12 Tables, Published with International Journal of Engineering Trends and Technology (IJETT)\n",
    "authors": [
      "Tanuja Patanshetti",
      "Ashish Anil Pawar",
      "Disha Patel",
      "Sanket Thakare"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02604"
  },
  {
    "id": "arXiv:2111.02607",
    "title": "Constrained Form-Finding of Tension-Compression Structures using  Automatic Differentiation",
    "abstract": "This paper proposes a computational approach to form-find pin-jointed, bar\nstructures subjected to combinations of tension and compression forces. The\ngenerated equilibrium states can meet force and geometric constraints via\ngradient-based optimization. We achieve this by extending the Combinatorial\nEquilibrium Modeling (CEM) framework in three important ways. Firstly, we\nintroduce a new topological object, the auxiliary trail, to expand the range of\nstructures that can be form-found with the framework. Secondly, we leverage\nautomatic differentiation (AD) to obtain an exact value of the gradient of the\nsequential and iterative calculations of the CEM form-finding algorithm,\ninstead of a numerical approximation. We finally encapsulate our research\ndevelopments into an open-source design tool written in Python that is usable\nacross different CAD platforms and operating systems. After studying four\ndifferent structures -- a self-stressed planar tensegrity, a tree canopy, a\ncurved suspension bridge, and a spiral staircase -- we show that our approach\nallows solving constrained form-finding problems on a diverse range of\nstructures more efficiently than in previous work.",
    "descriptor": "",
    "authors": [
      "Rafael Pastrana",
      "Patrick Ole Ohlbrock",
      "Thomas Oberbichler",
      "Pierluigi D'Acunto",
      "Stefana Parascho"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.02607"
  },
  {
    "id": "arXiv:2111.02613",
    "title": "Supporting GNSS Baseband Using Smartphone IMU and Ultra-Tight  Integration",
    "abstract": "A great surge of the global navigation satellite system (GNSS) development\nexcavates the potential of promoting pomposity in many state-of-art\ntechnologies, e.g., autonomous ground vehicles (AGVs). Nevertheless, the GNSS\nis fragile to the various ground interferences which significantly break down\nthe continuity of the navigation system. Meanwhile, the GNSS-based\nnext-generation navigation devices are being developed to be smaller, more\nlow-cost, and lightweight as forecasted by the commercial market. This work\naims to answer the question of whether the smartphone inertial measurement unit\n(IMU) is sufficient to support the GNSS baseband. Thus, a cascaded\nultra-tightly integrated GNSS/inertial navigation system (INS) technique, where\nthe consumer-level smartphone sensors are used, is proposed to improve the\nbaseband performance of GNSS software-defined radios (SDRs). To integrate the\nGNSS baseband, a Doppler value is predicted based on an integrated extended\nKalman filter (EKF) navigator where the pseudo-range-state-based measurements\nof GNSS and INS are fused, and it is used to assist the numerically controlled\noscillator (NCO) algorithms. Then, an ultra-tight integration platform is built\nwith an upgraded GNSS SDR of which baseband processing is integrated with the\nINS mechanization algorithm. Finally, by comparing with the previous\nalgorithms, both tracking-level and carrier-based positioning performances are\nassessed in the proposed platform for the smartphone-IMU-aided GNSS baseband\nvia kinematic AGV field tests. The experimental results demonstrate the\nperformance of the tracking ability and the high-precision positioning of the\nproposed ultra-tight integration algorithms using the smartphone IMU.",
    "descriptor": "\nComments: 12 pages, 16 figures\n",
    "authors": [
      "Yiran Luo",
      "You Li",
      "Jin Wang",
      "Naser El-Sheimy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02613"
  },
  {
    "id": "arXiv:2111.02614",
    "title": "Finding All Leftmost Separators of Size $\\leq k$",
    "abstract": "We define a notion called leftmost separator of size at most $k$. A leftmost\nseparator of size $k$ is a minimal separator $S$ that separates two given sets\nof vertices $X$ and $Y$ such that we \"cannot move $S$ more towards $X$\" such\nthat $|S|$ remains smaller than the threshold. One of the incentives is that by\nusing leftmost separators we can improve the time complexity of treewidth\napproximation. Treewidth approximation is a problem which is known to have a\nlinear time FPT algorithm in terms of input size, and only single exponential\nin terms of the parameter, treewidth. It is not known whether this result can\nbe improved theoretically. However, the coefficient of the parameter $k$ (the\ntreewidth) in the exponent is large. Hence, our goal is to decrease the\ncoefficient of $k$ in the exponent, in order to achieve a more practical\nalgorithm. Hereby, we trade a linear-time algorithm for an $\\mathcal{O}(n \\log\nn)$-time algorithm. The previous known $\\mathcal{O}(f(k) n \\log n)$-time\nalgorithms have dependences of $2^{24k}k!$, $2^{8.766k}k^2$ (a better analysis\nshows that it is $2^{7.671k}k^2$), and higher. In this paper, we present an\nalgorithm for treewidth approximation which runs in time\n$\\mathcal{O}(2^{6.755k}\\ n \\log n)$,\nFurthermore, we count the number of leftmost separators and give a tight\nupper bound for them. We show that the number of leftmost separators of size\n$\\leq k$ is at most $C_{k-1}$ (Catalan number). Then, we present an algorithm\nwhich outputs all leftmost separators in time\n$\\mathcal{O}(\\frac{4^k}{\\sqrt{k}}n)$.",
    "descriptor": "",
    "authors": [
      "Mahdi Belbasi",
      "Martin F\u00fcrer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.02614"
  },
  {
    "id": "arXiv:2111.02622",
    "title": "Lexically Aware Semi-Supervised Learning for OCR Post-Correction",
    "abstract": "Much of the existing linguistic data in many languages of the world is locked\naway in non-digitized books and documents. Optical character recognition (OCR)\ncan be used to produce digitized text, and previous work has demonstrated the\nutility of neural post-correction methods that improve the results of\ngeneral-purpose OCR systems on recognition of less-well-resourced languages.\nHowever, these methods rely on manually curated post-correction data, which are\nrelatively scarce compared to the non-annotated raw images that need to be\ndigitized.\nIn this paper, we present a semi-supervised learning method that makes it\npossible to utilize these raw images to improve performance, specifically\nthrough the use of self-training, a technique where a model is iteratively\ntrained on its own outputs. In addition, to enforce consistency in the\nrecognized vocabulary, we introduce a lexically-aware decoding method that\naugments the neural post-correction model with a count-based language model\nconstructed from the recognized texts, implemented using weighted finite-state\nautomata (WFSA) for efficient and effective decoding.\nResults on four endangered languages demonstrate the utility of the proposed\nmethod, with relative error reductions of 15-29%, where we find the combination\nof self-training and lexically-aware decoding essential for achieving\nconsistent improvements. Data and code are available at\nhttps://shrutirij.github.io/ocr-el/.",
    "descriptor": "\nComments: Accepted to the Transactions of the Association for Computational Linguistics (TACL)\n",
    "authors": [
      "Shruti Rijhwani",
      "Daisy Rosenblum",
      "Antonios Anastasopoulos",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.02622"
  },
  {
    "id": "arXiv:2111.02625",
    "title": "Qimera: Data-free Quantization with Synthetic Boundary Supporting  Samples",
    "abstract": "Model quantization is known as a promising method to compress deep neural\nnetworks, especially for inferences on lightweight mobile or edge devices.\nHowever, model quantization usually requires access to the original training\ndata to maintain the accuracy of the full-precision models, which is often\ninfeasible in real-world scenarios for security and privacy issues. A popular\napproach to perform quantization without access to the original data is to use\nsynthetically generated samples, based on batch-normalization statistics or\nadversarial learning. However, the drawback of such approaches is that they\nprimarily rely on random noise input to the generator to attain diversity of\nthe synthetic samples. We find that this is often insufficient to capture the\ndistribution of the original data, especially around the decision boundaries.\nTo this end, we propose Qimera, a method that uses superposed latent embeddings\nto generate synthetic boundary supporting samples. For the superposed\nembeddings to better reflect the original distribution, we also propose using\nan additional disentanglement mapping layer and extracting information from the\nfull-precision model. The experimental results show that Qimera achieves\nstate-of-the-art performances for various settings on data-free quantization.\nCode is available at https://github.com/iamkanghyunchoi/qimera.",
    "descriptor": "\nComments: Accepted to Neurips 2021\n",
    "authors": [
      "Kanghyun Choi",
      "Deokki Hong",
      "Noseong Park",
      "Youngsok Kim",
      "Jinho Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02625"
  },
  {
    "id": "arXiv:2111.02626",
    "title": "Characterizing Human Explanation Strategies to Inform the Design of  Explainable AI for Building Damage Assessment",
    "abstract": "Explainable AI (XAI) is a promising means of supporting human-AI\ncollaborations for high-stakes visual detection tasks, such as damage detection\ntasks from satellite imageries, as fully-automated approaches are unlikely to\nbe perfectly safe and reliable. However, most existing XAI techniques are not\ninformed by the understandings of task-specific needs of humans for\nexplanations. Thus, we took a first step toward understanding what forms of XAI\nhumans require in damage detection tasks. We conducted an online crowdsourced\nstudy to understand how people explain their own assessments, when evaluating\nthe severity of building damage based on satellite imagery. Through the study\nwith 60 crowdworkers, we surfaced six major strategies that humans utilize to\nexplain their visual damage assessments. We present implications of our\nfindings for the design of XAI methods for such visual detection contexts, and\ndiscuss opportunities for future research.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 Workshop on Artificial Intelligence for Humanitarian Assistance and Disaster Response (AI+HADR 2021)\n",
    "authors": [
      "Donghoon Shin",
      "Sachin Grover",
      "Kenneth Holstein",
      "Adam Perer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02626"
  },
  {
    "id": "arXiv:2111.02627",
    "title": "A Personalized Federated Learning Algorithm: an Application in Anomaly  Detection",
    "abstract": "Federated Learning (FL) has recently emerged as a promising method that\nemploys a distributed learning model structure to overcome data privacy and\ntransmission issues paused by central machine learning models. In FL, datasets\ncollected from different devices or sensors are used to train local models\n(clients) each of which shares its learning with a centralized model (server).\nHowever, this distributed learning approach presents unique learning challenges\nas the data used at local clients can be non-IID (Independent and Identically\nDistributed) and statistically diverse which decrease learning accuracy in the\ncentral model. In this paper, we overcome this problem by proposing a novel\nPersonalized Conditional FedAvg (PC-FedAvg) which aims to control weights\ncommunication and aggregation augmented with a tailored learning algorithm to\npersonalize the resulting models at each client. Our experimental validation on\ntwo datasets showed that our PC-FedAvg precisely constructed generalized\nclients' models and thus achieved higher accuracy compared to other\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Ali Anaissi",
      "Basem Suleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02627"
  },
  {
    "id": "arXiv:2111.02630",
    "title": "Network Structure and Feature Learning from Rich but Noisy Data",
    "abstract": "In the study of network structures, much attention has been devoted to\nnetwork reconstruction, which relies on partial edge-related information or\ndynamical processes on the network. However, there are cases where we are only\ngiven incomplete nodal data, and the nodal data are measured with different\nmethodologies. In this work, we present an unsupervised learning framework to\nconstruct networks from noisy and heterogeneous nodal data. First, we introduce\nthe creating nodes' context sets, which are used to generate random node\nsequences. Then, a three-layer neural network is adopted to train the node\nsequences to infer node vectors, enabling us to capture nodes with synergistic\nroles within the network. Further, the effectiveness of the method is validated\nthrough both synthetic data and real data. Finally, we compare the differences\nbetween the global thresholding method and the entropy-based method in edge\nselection. In summary, this work presents a neural network method for node\nvector learning from heterogeneous nodal data and an entropy-based method for\nedge selection.",
    "descriptor": "",
    "authors": [
      "Junyao Kuang",
      "Caterina Scoglio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.02630"
  },
  {
    "id": "arXiv:2111.02631",
    "title": "Lebesgue Constants For Cantor Sets",
    "abstract": "We evaluate the values of the Lebesgue constants in polynomial interpolation\nfor three types of Cantor sets. In all cases, the sequences of Lebesgue\nconstants are not bounded. This disproves the statement by Mergelyan.",
    "descriptor": "",
    "authors": [
      "Alexander Goncharov",
      "Yaman Paksoy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.02631"
  },
  {
    "id": "arXiv:2111.02632",
    "title": "A Fast Parallel Tensor Decomposition with Optimal Stochastic Gradient  Descent: an Application in Structural Damage Identification",
    "abstract": "Structural Health Monitoring (SHM) provides an economic approach which aims\nto enhance understanding the behavior of structures by continuously collects\ndata through multiple networked sensors attached to the structure. This data is\nthen utilized to gain insight into the health of a structure and make timely\nand economic decisions about its maintenance. The generated SHM sensing data is\nnon-stationary and exists in a correlated multi-way form which makes the\nbatch/off-line learning and standard two-way matrix analysis unable to capture\nall of these correlations and relationships. In this sense, the online tensor\ndata analysis has become an essential tool for capturing underlying structures\nin higher-order datasets stored in a tensor $\\mathcal{X} \\in \\mathbb{R} ^{I_1\n\\times \\dots \\times I_N} $. The CANDECOMP/PARAFAC (CP) decomposition has been\nextensively studied and applied to approximate X by N loading matrices A(1), .\n. . ,A(N) where N represents the order of the tensor. We propose a novel\nalgorithm, FP-CPD, to parallelize the CANDECOMP/PARAFAC (CP) decomposition of a\ntensor $\\mathcal{X} \\in \\mathbb{R} ^{I_1 \\times \\dots \\times I_N} $. Our\napproach is based on stochastic gradient descent (SGD) algorithm which allows\nus to parallelize the learning process and it is very useful in online setting\nsince it updates $\\mathcal{X}^{t+1}$ in one single step. Our SGD algorithm is\naugmented with Nesterov's Accelerated Gradient (NAG) and perturbation methods\nto accelerate and guarantee convergence. The experimental results using\nlaboratory-based and real-life structural datasets indicate fast convergence\nand good scalability.",
    "descriptor": "",
    "authors": [
      "Ali Anaissi",
      "Basem Suleiman",
      "Seid Miad Zandavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02632"
  },
  {
    "id": "arXiv:2111.02638",
    "title": "The Age of Information of Short-Packet Communications: Joint or  Distributed Encoding?",
    "abstract": "In this paper, we analyze the impact of different encoding schemes on the age\nof information (AoI) performance in a point-to-point system, where a source\ngenerates packets based on the status updates collected from multiple sensors\nand transmits the packets to a destination. In this system, we consider two\nencoding schemes, namely, the joint encoding scheme and the distributed\nencoding scheme. In the joint encoding scheme, the status updates from all the\nsensors are jointly encoded into a packet for transmission. In the distributed\nencoding scheme, the status update from each sensor is encoded individually and\nthe sensors' packets are transmitted following the round robin policy. To\nensure the freshness of packets, the zero-wait policy is adopted in both\nschemes, where a new packet is immediately generated once the source finishes\nthe transmission of the current packet. We derive closed-form expressions for\nthe average AoI achieved by these two encoding schemes and compare their\nperformances. Simulation results show that the distributed encoding scheme is\nmore appropriate for systems with a relatively large number of sensors,\ncompared with the joint encoding scheme.",
    "descriptor": "",
    "authors": [
      "Zhifeng Tang",
      "Nan Yang",
      "Parastoo Sadeghi",
      "Xiangyun Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02638"
  },
  {
    "id": "arXiv:2111.02642",
    "title": "On the Secrecy Design of STAR-RIS assisted Uplink NOMA Networks",
    "abstract": "This paper investigates the secure transmission in a simultaneously\ntransmitting and reflecting reconfigurable intelligent surface (STAR-RIS)\nassisted uplink non-orthogonal multiple access system, where the legitimate\nusers send confidential signals to the base station by exploiting STAR-RIS to\nreconfigure the electromagnetic propagation environment proactively. Depending\non the availability of the eavesdropping channel state information (CSI), both\nthe full CSI and statistical CSI of the eavesdropper are considered. For the\nfull eavesdropping CSI scenario, we adopt the adaptive-rate wiretap code scheme\nwith the aim of maximizing minimum secrecy capacity subject to the successive\ninterference cancellation decoding order constraints. To proceed, we propose an\nalternating hybrid beamforming (AHB) algorithm to jointly optimize the receive\nbeamforming, transmit power, and reflection/transmission coefficients. While\nfor the statistical eavesdropping CSI scenario, the constant-rate wiretap code\nscheme is employed to minimize the maximum secrecy outage probability (SOP)\nsubject to the quality-of-service requirements of legitimate users. Then, we\nderive the exact SOP expression under the constant-rate coding strategy and\ndevelop an extended AHB algorithm for the joint secrecy beamforming design.\nSimulation results demonstrate the effectiveness of the proposed scheme.\nMoreover, some useful guidance about the quantification of phase\nshift/amplitude and the deployment of STAR-RIS is provided.",
    "descriptor": "",
    "authors": [
      "Zheng Zhang",
      "Jian Chen",
      "Yuanwei Liu",
      "Qingqing Wu",
      "Bingtao He",
      "Long Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.02642"
  },
  {
    "id": "arXiv:2111.02643",
    "title": "Response Generation with Context-Aware Prompt Learning",
    "abstract": "Pre-trained language models (PLM) have marked a huge leap in neural dialogue\nmodeling. While PLMs are pre-trained on large-scale text corpora, they are\nusually fine-tuned on scarce dialogue data with specific domain knowledge and\ndialogue styles. However, tailoring the language models while fully utilizing\nprior knowledge in large pre-trained models remains a challenge. In this paper,\nwe present a novel approach for pre-trained dialogue modeling that casts the\ndialogue generation problem as a prompt-learning task. Instead of fine-tuning\non limited dialogue data, our approach, DialogPrompt, learns continuous prompt\nembeddings optimized for dialogue contexts, which appropriately elicit\nknowledge from the large pre-trained model. To encourage the model to better\nutilize the prompt embeddings, the prompt encoders are designed to be\nconditioned on the input dialogue context. Experiments on popular conversation\ndatasets show that our approach significantly outperforms the fine-tuning\nbaseline and the generic prompt-learning methods. Furthermore, human\nevaluations strongly support the superiority of DialogPrompt in regard to\nresponse generation quality.",
    "descriptor": "",
    "authors": [
      "Xiaodong Gu",
      "Kang Min Yoo",
      "Sang-Woo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.02643"
  },
  {
    "id": "arXiv:2111.02644",
    "title": "A Concentration Bound for LSPE($\u03bb$)",
    "abstract": "The popular LSPE($\\lambda$) algorithm for policy evaluation is revisited to\nderive a concentration bound that gives high probability performance guarantees\nfrom some time on.",
    "descriptor": "\nComments: 12 pages, submitted to JMLR\n",
    "authors": [
      "Vivek S. Borkar",
      "Siddharth Chandak",
      "Harsh Dolhare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02644"
  },
  {
    "id": "arXiv:2111.02646",
    "title": "Engaging Politically Diverse Audiences on Social Media",
    "abstract": "We study how political polarization is reflected in the social media posts\nused by media outlets to promote their content online. In particular, we track\nthe Twitter posts of several media outlets over the course of more than three\nyears (566K tweets), and the engagement with these tweets from other users\n(104M retweets), modeling the relationship between the tweet text and the\npolitical diversity of the audience. We build a tool that integrates our model\nand helps journalists craft tweets that are engaging to a politically diverse\naudience, guided by the model predictions. To test the real-world impact of the\ntool, we partner with the PBS documentary series Frontline and run a series of\nadvertising experiments on Twitter. We find that in seven out of the ten\nexperiments, the tweets selected by our model were indeed engaging to a more\npolitically diverse audience, illustrating the effectiveness of our approach.",
    "descriptor": "\nComments: To appear in ICWSM'22 (International AAAI Conference on Web and Social Media)\n",
    "authors": [
      "Martin Saveski",
      "Doug Beeferman",
      "David McClure",
      "Deb Roy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.02646"
  },
  {
    "id": "arXiv:2111.02649",
    "title": "Logically Sound Arguments for the Effectiveness of ML Safety Measures",
    "abstract": "We investigate the issues of achieving sufficient rigor in the arguments for\nthe safety of machine learning functions. By considering the known weaknesses\nof DNN-based 2D bounding box detection algorithms, we sharpen the metric of\nimprecise pedestrian localization by associating it with the safety goal. The\nsharpening leads to introducing a conservative post-processor after the\nstandard non-max-suppression as a counter-measure. We then propose a\nsemi-formal assurance case for arguing the effectiveness of the post-processor,\nwhich is further translated into formal proof obligations for demonstrating the\nsoundness of the arguments. Applying theorem proving not only discovers the\nneed to introduce missing claims and mathematical concepts but also reveals the\nlimitation of Dempster-Shafer's rules used in semi-formal argumentation.",
    "descriptor": "",
    "authors": [
      "Chih-Hong Cheng",
      "Tobias Schuster",
      "Simon Burton"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02649"
  },
  {
    "id": "arXiv:2111.02651",
    "title": "Temporal Fusion Based Mutli-scale Semantic Segmentation for Detecting  Concealed Baggage Threats",
    "abstract": "Detection of illegal and threatening items in baggage is one of the utmost\nsecurity concern nowadays. Even for experienced security personnel, manual\ndetection is a time-consuming and stressful task. Many academics have created\nautomated frameworks for detecting suspicious and contraband data from X-ray\nscans of luggage. However, to our knowledge, no framework exists that utilizes\ntemporal baggage X-ray imagery to effectively screen highly concealed and\noccluded objects which are barely visible even to the naked eye. To address\nthis, we present a novel temporal fusion driven multi-scale residual fashioned\nencoder-decoder that takes series of consecutive scans as input and fuses them\nto generate distinct feature representations of the suspicious and\nnon-suspicious baggage content, leading towards a more accurate extraction of\nthe contraband data. The proposed methodology has been thoroughly tested using\nthe publicly accessible GDXray dataset, which is the only dataset containing\ntemporally linked grayscale X-ray scans showcasing extremely concealed\ncontraband data. The proposed framework outperforms its competitors on the\nGDXray dataset on various metrics.",
    "descriptor": "\nComments: Accepted in IEEE SMC 2021\n",
    "authors": [
      "Muhammed Shafay",
      "Taimur Hassan",
      "Ernesto Damiani",
      "Naoufel Werghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.02651"
  },
  {
    "id": "arXiv:2111.02654",
    "title": "Speech recognition for air traffic control via feature learning and  end-to-end training",
    "abstract": "In this work, we propose a new automatic speech recognition (ASR) system\nbased on feature learning and an end-to-end training procedure for air traffic\ncontrol (ATC) systems. The proposed model integrates the feature learning\nblock, recurrent neural network (RNN), and connectionist temporal\nclassification loss to build an end-to-end ASR model. Facing the complex\nenvironments of ATC speech, instead of the handcrafted features, a learning\nblock is designed to extract informative features from raw waveforms for\nacoustic modeling. Both the SincNet and 1D convolution blocks are applied to\nprocess the raw waveforms, whose outputs are concatenated to the RNN layers for\nthe temporal modeling. Thanks to the ability to learn representations from raw\nwaveforms, the proposed model can be optimized in a complete end-to-end manner,\ni.e., from waveform to text. Finally, the multilingual issue in the ATC domain\nis also considered to achieve the ASR task by constructing a combined\nvocabulary of Chinese characters and English letters. The proposed approach is\nvalidated on a multilingual real-world corpus (ATCSpeech), and the experimental\nresults demonstrate that the proposed approach outperforms other baselines,\nachieving a 6.9\\% character error rate.",
    "descriptor": "\nComments: Submitted to IEEE ICASSP 2022\n",
    "authors": [
      "Peng Fan",
      "Dongyue Guo",
      "Yi Lin",
      "Bo Yang",
      "Jianwei Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.02654"
  },
  {
    "id": "arXiv:2111.02655",
    "title": "Cost-effective Network Disintegration through Targeted Enumeration",
    "abstract": "Although we are in a hyper-connected world, this connectivity has undesirable\naspects in nature and society. Finding an optimal subset of nodes or links to\ndisintegrate harmful networks is a fundamental problem in network science, with\npotential applications to anti-terrorist, epidemic control, and many other\nfields. The challenge of the network disintegration problem is to balance the\neffectiveness and efficiency of strategies. In this paper, we propose a\ncost-effective targeted enumeration method for network disintegration. Our\napproach includes two stages: searching the candidate objects and identifying\nthe optimal solution. In the first stage, we employ the rank aggregation method\nto generate a comprehensive node importance ranking, based on which we\ndetermine a small-scale candidate set of nodes to remove. In the second stage,\nwe use the enumeration method to find the optimal combination among the\ncandidate nodes. The extensive experimental results on synthetic and real-world\nnetworks demonstrate that our method achieves a satisfying trade-off between\neffectiveness and efficiency. The introduced two-stage targeted enumeration\nframework can be further extended to other combinational optimization problems.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Zhi-Gang Wang",
      "Ye Deng",
      "Zeng-Ru Di",
      "Jun Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.02655"
  },
  {
    "id": "arXiv:2111.02657",
    "title": "Average Sensitivity of Dynamic Programming",
    "abstract": "When processing data with uncertainty, it is desirable that the output of the\nalgorithm is stable against small perturbations in the input. Varma and Yoshida\n[SODA'21] recently formalized this idea and proposed the notion of average\nsensitivity of algorithms, which is roughly speaking, the average Hamming\ndistance between solutions for the original input and that obtained by deleting\none element from the input, where the average is taken over the deleted\nelement.\nIn this work, we consider average sensitivity of algorithms for problems that\ncan be solved by dynamic programming. We first present a\n$(1-\\delta)$-approximation algorithm for finding a maximum weight chain (MWC)\nin a transitive directed acyclic graph with average sensitivity\n$O(\\delta^{-1}\\log^3 n)$, where $n$ is the number of vertices in the graph. We\nthen show algorithms with small average sensitivity for various dynamic\nprogramming problems by reducing them to the MWC problem while preserving\naverage sensitivity, including the longest increasing subsequence problem, the\ninterval scheduling problem, the longest common subsequence problem, the\nlongest palindromic subsequence problem, the knapsack problem with integral\nweight, and the RNA folding problem. For the RNA folding problem, our reduction\nis highly nontrivial because a naive reduction generates an exponentially large\ngraph, which only provides a trivial average sensitivity bound.",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Soh Kumabe",
      "Yuichi Yoshida"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.02657"
  },
  {
    "id": "arXiv:2111.02659",
    "title": "Speed Maps: An Application to Guide Robots in Human Environments",
    "abstract": "We present the concept of speed maps: speed limits for mobile robots in human\nenvironments. Static speed maps allow for faster navigation on corridors while\nlimiting the speed around corners and in rooms. Dynamic speed maps put limits\non speed around humans. We demonstrate the concept for a mobile robot that\nguides people to annotated landmarks on the map. The robot keeps a metric map\nfor navigation and a semantic map to hold planar surfaces for tasking. The\nsystem supports automatic initialization upon the detection of a specially\ndesigned QR code. We show that speed maps not only can reduce the impact of a\npotential collision but can also reduce navigation time.",
    "descriptor": "\nComments: Published at 14th International Workshop on Human-Friendly Robotics (HFR), 2021\n",
    "authors": [
      "Akansel Cosgun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.02659"
  },
  {
    "id": "arXiv:2111.02662",
    "title": "TEE-based Selective Testing of Local Workers in Federated Learning  Systems",
    "abstract": "This paper considers a federated learning system composed of a central\ncoordinating server and multiple distributed local workers, all having access\nto trusted execution environments (TEEs). In order to ensure that the untrusted\nworkers correctly perform local learning, we propose a new TEE-based approach\nthat also combines techniques from applied cryptography, smart contract and\ngame theory. Theoretical analysis and implementation-based evaluations show\nthat, the proposed approach is secure, efficient and practical.",
    "descriptor": "",
    "authors": [
      "Wensheng Zhang",
      "Trent Muhr"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.02662"
  },
  {
    "id": "arXiv:2111.02664",
    "title": "Scientists are Working Overtime and at the Weekends: Comparison of  Publication Downloading from Copyrighted and Pirated Platforms",
    "abstract": "In this study, we track and analyze publication downloads from both\ncopyrighted and pirated platforms to reconstruct scientists' activity patterns\nfrom a holistic perspective. Scientists around the world are working overtime,\nbut scientists in different countries have different working patterns.\nScientists' preferences for different platforms are influenced by a variety of\nfactors such as working times and workplace arrangements. There are variations\nby country in terms of whether scientists prefer to work overtime at night, at\nthe weekend, or both at night and on the weekend. When scientists are working\novertime, they prefer to use Sci-Hub rather than copyrighted platforms to\naccess scholarly publications This may be because of the transition in their\nworking scenarios as they move from the office to home outside of work hours.",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Yu Geng",
      "Ren-Meng Cao",
      "Xiao-Pu Han",
      "Wen-Can Tian",
      "Guang-Yao Zhang",
      "Xian-Wen Wang"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.02664"
  },
  {
    "id": "arXiv:2111.02668",
    "title": "LVIS Challenge Track Technical Report 1st Place Solution: Distribution  Balanced and Boundary Refinement for Large Vocabulary Instance Segmentation",
    "abstract": "This report introduces the technical details of the team FuXi-Fresher for\nLVIS Challenge 2021. Our method focuses on the problem in following two\naspects: the long-tail distribution and the segmentation quality of mask and\nboundary. Based on the advanced HTC instance segmentation algorithm, we connect\ntransformer backbone(Swin-L) through composite connections inspired by CBNetv2\nto enhance the baseline results. To alleviate the problem of long-tail\ndistribution, we design a Distribution Balanced method which includes dataset\nbalanced and loss function balaced modules. Further, we use a Mask and Boundary\nRefinement method composed with mask scoring and refine-mask algorithms to\nimprove the segmentation quality. In addition, we are pleasantly surprised to\nfind that early stopping combined with EMA method can achieve a great\nimprovement. Finally, by using multi-scale testing and increasing the upper\nlimit of the number of objects detected per image, we achieved more than 45.4%\nboundary AP on the val set of LVIS Challenge 2021. On the test data of LVIS\nChallenge 2021, we rank 1st and achieve 48.1% AP. Notably, our APr 47.5% is\nvery closed to the APf 48.0%.",
    "descriptor": "",
    "authors": [
      "WeiFu Fu",
      "CongChong Nie",
      "Ting Sun",
      "Jun Liu",
      "TianLiang Zhang",
      "Yong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02668"
  },
  {
    "id": "arXiv:2111.02671",
    "title": "GraphSearchNet: Enhancing GNNs via Capturing Global Dependency for  Semantic Code Search",
    "abstract": "Code search aims to retrieve the relevant code fragments based on a natural\nlanguage query to improve the software productivity and quality. However,\nautomatic code search is challenging due to the semantic gap between the source\ncode and the query. Most existing approaches mainly consider the sequential\ninformation for embedding, where the structure information behind the text is\nnot fully considered. In this paper, we design a novel neural network\nframework, named GraphSearchNet, to enable an effective and accurate source\ncode search by jointly learning rich semantics of both source code and queries.\nSpecifically, we propose to encode both source code and queries into two graphs\nwith Bidirectional GGNN to capture the local structure information of the\ngraphs. Furthermore, we enhance BiGGNN by utilizing the effective multi-head\nattention to supplement the global dependency that BiGGNN missed. The extensive\nexperiments on both Java and Python datasets illustrate that GraphSearchNet\noutperforms current state-of-the-art works by a significant margin.",
    "descriptor": "",
    "authors": [
      "Shangqing Liu",
      "Xiaofei Xie",
      "Lei Ma",
      "Jingkai Siow",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02671"
  },
  {
    "id": "arXiv:2111.02673",
    "title": "Recurrent Neural Network Training with Convex Loss and Regularization  Functions by Extended Kalman Filtering",
    "abstract": "We investigate the use of extended Kalman filtering to train recurrent neural\nnetworks for data-driven nonlinear, possibly adaptive, model-based control\ndesign. We show that the approach can be applied to rather arbitrary convex\nloss functions and regularization terms on the network parameters. We show that\nthe learning method outperforms stochastic gradient descent in a nonlinear\nsystem identification benchmark and in training a linear system with binary\noutputs. We also explore the use of the algorithm in data-driven nonlinear\nmodel predictive control and its relation with disturbance models for\noffset-free tracking.",
    "descriptor": "",
    "authors": [
      "Alberto Bemporad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.02673"
  },
  {
    "id": "arXiv:2111.02679",
    "title": "MixSiam: A Mixture-based Approach to Self-supervised Representation  Learning",
    "abstract": "Recently contrastive learning has shown significant progress in learning\nvisual representations from unlabeled data. The core idea is training the\nbackbone to be invariant to different augmentations of an instance. While most\nmethods only maximize the feature similarity between two augmented data, we\nfurther generate more challenging training samples and force the model to keep\npredicting discriminative representation on these hard samples. In this paper,\nwe propose MixSiam, a mixture-based approach upon the traditional siamese\nnetwork. On the one hand, we input two augmented images of an instance to the\nbackbone and obtain the discriminative representation by performing an\nelement-wise maximum of two features. On the other hand, we take the mixture of\nthese augmented images as input, and expect the model prediction to be close to\nthe discriminative representation. In this way, the model could access more\nvariant data samples of an instance and keep predicting invariant\ndiscriminative representations for them. Thus the learned model is more robust\ncompared to previous contrastive learning methods. Extensive experiments on\nlarge-scale datasets show that MixSiam steadily improves the baseline and\nachieves competitive results with state-of-the-art methods. Our code will be\nreleased soon.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Xiaoyang Guo",
      "Tianhao Zhao",
      "Yutian Lin",
      "Bo Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02679"
  },
  {
    "id": "arXiv:2111.02682",
    "title": "TimeMatch: Unsupervised Cross-Region Adaptation by Temporal Shift  Estimation",
    "abstract": "The recent developments of deep learning models that capture the complex\ntemporal patterns of crop phenology have greatly advanced crop classification\nof Satellite Image Time Series (SITS). However, when applied to target regions\nspatially different from the training region, these models perform poorly\nwithout any target labels due to the temporal shift of crop phenology between\nregions. To address this unsupervised cross-region adaptation setting, existing\nmethods learn domain-invariant features without any target supervision, but not\nthe temporal shift itself. As a consequence, these techniques provide only\nlimited benefits for SITS. In this paper, we propose TimeMatch, a new\nunsupervised domain adaptation method for SITS that directly accounts for the\ntemporal shift. TimeMatch consists of two components: 1) temporal shift\nestimation, which estimates the temporal shift of the unlabeled target region\nwith a source-trained model, and 2) TimeMatch learning, which combines temporal\nshift estimation with semi-supervised learning to adapt a classifier to an\nunlabeled target region. We also introduce an open-access dataset for\ncross-region adaptation with SITS from four different regions in Europe. On\nthis dataset, we demonstrate that TimeMatch outperforms all competing methods\nby 11% in F1-score across five different adaptation scenarios, setting a new\nstate-of-the-art for cross-region adaptation.",
    "descriptor": "\nComments: Preprint submitted to the ISPRS Journal of Photogrammetry and Remote Sensing\n",
    "authors": [
      "Joachim Nyborg",
      "Charlotte Pelletier",
      "S\u00e9bastien Lef\u00e8vre",
      "Ira Assent"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02682"
  },
  {
    "id": "arXiv:2111.02687",
    "title": "CoreLM: Coreference-aware Language Model Fine-Tuning",
    "abstract": "Language Models are the underpin of all modern Natural Language Processing\n(NLP) tasks. The introduction of the Transformers architecture has contributed\nsignificantly into making Language Modeling very effective across many NLP\ntask, leading to significant advancements in the field. However, Transformers\ncome with a big computational cost, which grows quadratically with respect to\nthe input length. This presents a challenge as to understand long texts\nrequires a lot of context. In this paper, we propose a Fine-Tuning framework,\nnamed CoreLM, that extends the architecture of current Pretrained Language\nModels so that they incorporate explicit entity information. By introducing\nentity representations, we make available information outside the contextual\nspace of the model, which results in a better Language Model for a fraction of\nthe computational cost. We implement our approach using GPT2 and compare the\nfine-tuned model to the original. Our proposed model achieves a lower\nPerplexity in GUMBY and LAMBDADA datasets when compared to GPT2 and a\nfine-tuned version of GPT2 without any changes. We also compare the models'\nperformance in terms of Accuracy in LAMBADA and Children's Book Test, with and\nwithout the use of model-created coreference annotations.",
    "descriptor": "\nComments: 12 pages, 2 figures, Accepted at Fourth Workshop on Computational Models of Reference, Anaphora and Coreference\n",
    "authors": [
      "Nikolaos Stylianou",
      "Ioannis Vlahavas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02687"
  },
  {
    "id": "arXiv:2111.02688",
    "title": "The No Endmarker Theorem for One-Way Probabilistic Pushdown Automata",
    "abstract": "In various models of one-way pushdown automata, the explicit use of two\ndesignated endmarkers on a read-once input tape has proven to be extremely\nuseful for making a conscious, final decision on the acceptance/rejection of\neach input word right after reading the right endmarker. With no endmarkers, by\ncontrast, a machine must constantly stay in either accepting or rejecting\nstates at any moment since it never notices the end of the input instance. This\nsituation, however, helps us analyze the behavior of the machine whose tape\nhead makes the consecutive moves on all prefixes of a given extremely long\ninput word. Since those two machine formulations have their own advantages, it\nis natural to ask whether the endmarkers are truly necessary to correctly\nrecognize languages. In the deterministic and nondeterministic models, it is\nwell-known that the endmarkers are removable without changing the acceptance\ncriteria of each input instance. This paper proves that, for a more general\nmodel of one-way probabilistic pushdown automata, the endmarkers are also\nremovable. This is proven by employing probabilistic transformations from an\n\"endmarker\" machine to an equivalent \"no-endmarker\" machine at the cost of\ndouble exponential state complexity without compromising its error probability.\nBy setting this error probability appropriately, our proof also provides an\nalternative proof to both the deterministic and the nondeterministic models as\nwell.",
    "descriptor": "\nComments: (10pt, A4, p.17)\n",
    "authors": [
      "Tomoyuki Yamakami"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.02688"
  },
  {
    "id": "arXiv:2111.02698",
    "title": "A note on banded linear systems",
    "abstract": "In [2] a new factorization for infinite Hessenberg banded matrices was\nintroduced. In this note we prove that this kind of factorization can also be\nused for finite matrices. In addition, a new method for solving banded linear\nsystems is provided.",
    "descriptor": "",
    "authors": [
      "D. Barrios Rolan\u00eda",
      "J.C. Garc\u00eda-Ardila"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.02698"
  },
  {
    "id": "arXiv:2111.02703",
    "title": "Towards Smart Monitored AM: Open Source in-Situ Layer-wise 3D Printing  Image Anomaly Detection Using Histograms of Oriented Gradients and a  Physics-Based Rendering Engine",
    "abstract": "This study presents an open source method for detecting 3D printing anomalies\nby comparing images of printed layers from a stationary monocular camera with\nG-code-based reference images of an ideal process generated with Blender, a\nphysics rendering engine. Recognition of visual deviations was accomplished by\nanalyzing the similarity of histograms of oriented gradients (HOG) of local\nimage areas. The developed technique requires preliminary modeling of the\nworking environment to achieve the best match for orientation, color rendering,\nlighting, and other parameters of the printed part. The output of the algorithm\nis a level of mismatch between printed and synthetic reference layers. Twelve\nsimilarity and distance measures were implemented and compared for their\neffectiveness at detecting 3D printing errors on six different representative\nfailure types and their control error-free print images. The results show that\nalthough Kendall tau, Jaccard, and Sorensen similarities are the most\nsensitive, Pearson r, Spearman rho, cosine, and Dice similarities produce the\nmore reliable results. This open source method allows the program to notice\ncritical errors in the early stages of their occurrence and either pause\nmanufacturing processes for further investigation by an operator or in the\nfuture AI-controlled automatic error correction. The implementation of this\nnovel method does not require preliminary data for training, and the greatest\nefficiency can be achieved with the mass production of parts by either additive\nor subtractive manufacturing of the same geometric shape. It can be concluded\nthis open source method is a promising means of enabling smart distributed\nrecycling for additive manufacturing using complex feedstocks as well as other\nchallenging manufacturing environments.",
    "descriptor": "",
    "authors": [
      "Aliaksei Petsiuk",
      "Joshua M. Pearce"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.02703"
  },
  {
    "id": "arXiv:2111.02705",
    "title": "Benchmarking Multimodal AutoML for Tabular Data with Text Fields",
    "abstract": "We consider the use of automated supervised learning systems for data tables\nthat not only contain numeric/categorical columns, but one or more text fields\nas well. Here we assemble 18 multimodal data tables that each contain some text\nfields and stem from a real business application. Our publicly-available\nbenchmark enables researchers to comprehensively evaluate their own methods for\nsupervised learning with numeric, categorical, and text features. To ensure\nthat any single modeling strategy which performs well over all 18 datasets will\nserve as a practical foundation for multimodal text/tabular AutoML, the diverse\ndatasets in our benchmark vary greatly in: sample size, problem types (a mix of\nclassification and regression tasks), number of features (with the number of\ntext columns ranging from 1 to 28 between datasets), as well as how the\npredictive signal is decomposed between text vs. numeric/categorical features\n(and predictive interactions thereof). Over this benchmark, we evaluate various\nstraightforward pipelines to model such data, including standard two-stage\napproaches where NLP is used to featurize the text such that AutoML for tabular\ndata can then be applied. Compared with human data science teams, the fully\nautomated methodology that performed best on our benchmark (stack ensembling a\nmultimodal Transformer with various tree models) also manages to rank 1st place\nwhen fit to the raw text/tabular data in two MachineHack prediction\ncompetitions and 2nd place (out of 2380 teams) in Kaggle's Mercari Price\nSuggestion Challenge.",
    "descriptor": "\nComments: Proceedings of the Neural Information Processing Systems (NeurIPS) Track on Datasets and Benchmarks 2021\n",
    "authors": [
      "Xingjian Shi",
      "Jonas Mueller",
      "Nick Erickson",
      "Mu Li",
      "Alexander J. Smola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.02705"
  },
  {
    "id": "arXiv:2111.02706",
    "title": "A thread-safe Term Library",
    "abstract": "Terms are one of the fundamental data structures for computing. E.g. every\nexpression characterisable by a context free grammar is a term. Remarkably,\nterms are not yet standard in common programming languages although term\nlibraries have already been proposed in the 1990-ies. We developed a\nthread-safe Term Library. The biggest challenge is to implement hyper-efficient\nmulti-reader/single writer mutual exclusion for which we designed the new\nbusy-forbidden protocol. Model checking is used to show both the correctness of\nthe protocol and the library. Benchmarks show this Term Library to scale well,\nand to compare favourably with sequential versions. Using the new library in an\nexisting state space generation tool, very substantial speed ups can be\nobtained.",
    "descriptor": "",
    "authors": [
      "J.F. Groote",
      "M. Laveaux",
      "P.H.M. van Spaendonck"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02706"
  },
  {
    "id": "arXiv:2111.02709",
    "title": "Analog MIMO Communication for One-shot Distributed Principal Component  Analysis",
    "abstract": "A fundamental algorithm for data analytics at the edge of wireless networks\nis distributed principal component analysis (DPCA), which finds the most\nimportant information embedded in a distributed high-dimensional dataset by\ndistributed computation of a reduced-dimension data subspace, called principal\ncomponents (PCs). In this paper, to support one-shot DPCA in wireless systems,\nwe propose a framework of analog MIMO transmission featuring the uncoded analog\ntransmission of local PCs for estimating the global PCs. To cope with channel\ndistortion and noise, two maximum-likelihood (global) PC estimators are\npresented corresponding to the cases with and without receive channel state\ninformation (CSI). The first design, termed coherent PC estimator, is derived\nby solving a Procrustes problem and reveals the form of regularized channel\ninversion where the regulation attempts to alleviate the effects of both\nchannel noise and data noise. The second one, termed blind PC estimator, is\ndesigned based on the subspace channel-rotation-invariance property and\ncomputes a centroid of received local PCs on a Grassmann manifold. Using the\nmanifold-perturbation theory, tight bounds on the mean square subspace distance\n(MSSD) of both estimators are derived for performance evaluation. The results\nreveal simple scaling laws of MSSD concerning device population, data and\nchannel signal-to-noise ratios (SNRs), and array sizes. More importantly, both\nestimators are found to have identical scaling laws, suggesting the\ndispensability of CSI to accelerate DPCA. Simulation results validate the\nderived results and demonstrate the promising latency performance of the\nproposed analog MIMO.",
    "descriptor": "",
    "authors": [
      "Xu Chen",
      "Erik G. Larsson",
      "Kaibin Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02709"
  },
  {
    "id": "arXiv:2111.02717",
    "title": "Facial Emotion Recognition using Deep Residual Networks in Real-World  Environments",
    "abstract": "Automatic affect recognition using visual cues is an important task towards a\ncomplete interaction between humans and machines. Applications can be found in\ntutoring systems and human computer interaction. A critical step towards that\ndirection is facial feature extraction. In this paper, we propose a facial\nfeature extractor model trained on an in-the-wild and massively collected video\ndataset provided by the RealEyes company. The dataset consists of a million\nlabelled frames and 2,616 thousand subjects. As temporal information is\nimportant to the emotion recognition domain, we utilise LSTM cells to capture\nthe temporal dynamics in the data. To show the favourable properties of our\npre-trained model on modelling facial affect, we use the RECOLA database, and\ncompare with the current state-of-the-art approach. Our model provides the best\nresults in terms of concordance correlation coefficient.",
    "descriptor": "",
    "authors": [
      "Panagiotis Tzirakis",
      "D\u00e9nes Boros",
      "Elnar Hajiyev",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.02717"
  },
  {
    "id": "arXiv:2111.02719",
    "title": "SPEEDEX: A Scalable, Parallelizable, and Economically Efficient Digital  EXchange",
    "abstract": "SPEEDEX is a decentralized exchange (DEX) letting participants securely trade\nassets without giving any single party undue control over the market. SPEEDEX\noffers several advantages over prior DEXes. It achieves high throughput -- over\n100,000 transactions per second on 32-core servers, even with 70M open offers.\nIt eliminates internal arbitrage opportunities, so that a direct trade from\nasset $A$ to $B$ always receives as good a price as trading through some third\nasset such as USD\\@. Finally, it prevents frontrunning attacks that would\notherwise increase the effective bid-ask spread for small traders. SPEEDEX's\nkey design insight is to use an Arrow-Debreu exchange market structure that\nfixes the valuation of assets for all trades in a given block of transactions.\nNot only does this market structure provide fairness across trades, it makes\ntrade operations commutative and hence efficiently parallelizable.",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Geoffrey Ramseyer",
      "Ashish Goel",
      "David Mazi\u00e8res"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02719"
  },
  {
    "id": "arXiv:2111.02724",
    "title": "Tea Chrysanthemum Detection under Unstructured Environments Using the  TC-YOLO Model",
    "abstract": "Tea chrysanthemum detection at its flowering stage is one of the key\ncomponents for selective chrysanthemum harvesting robot development. However,\nit is a challenge to detect flowering chrysanthemums under unstructured field\nenvironments given the variations on illumination, occlusion and object scale.\nIn this context, we propose a highly fused and lightweight deep learning\narchitecture based on YOLO for tea chrysanthemum detection (TC-YOLO). First, in\nthe backbone component and neck component, the method uses the Cross-Stage\nPartially Dense Network (CSPDenseNet) as the main network, and embeds custom\nfeature fusion modules to guide the gradient flow. In the final head component,\nthe method combines the recursive feature pyramid (RFP) multiscale fusion\nreflow structure and the Atrous Spatial Pyramid Pool (ASPP) module with cavity\nconvolution to achieve the detection task. The resulting model was tested on\n300 field images, showing that under the NVIDIA Tesla P100 GPU environment, if\nthe inference speed is 47.23 FPS for each image (416 * 416), TC-YOLO can\nachieve the average precision (AP) of 92.49% on our own tea chrysanthemum\ndataset. In addition, this method (13.6M) can be deployed on a single mobile\nGPU, and it could be further developed as a perception system for a selective\nchrysanthemum harvesting robot in the future.",
    "descriptor": "",
    "authors": [
      "Chao Qi",
      "Junfeng Gao",
      "Simon Pearson",
      "Helen Harman",
      "Kunjie Chen",
      "Lei Shu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02724"
  },
  {
    "id": "arXiv:2111.02725",
    "title": "Effect of Miner Incentive on the Confirmation Time of Bitcoin  Transactions",
    "abstract": "Blockchain is a technology that provides a distributed ledger that stores\nprevious records while maintaining consistency and security. Bitcoin is the\nfirst and largest decentralized electronic cryptographic system that uses\nblockchain technology. It faces a challenge in making all the nodes synchronize\nand have the same overall view with the cost of scalability and performance. In\naddition, with miners' financial interest playing a significant role in\nchoosing transactions from the backlog, small fee or small fee per byte value\ntransactions will exhibit more delays. To study the issues related to the\nsystem's performance, we developed an $M(t)/M^N/1$ model. The backlog's arrival\nfollows an inhomogeneous Poison process to the system that has infinite buffer\ncapacity, and the service time is distributed exponentially, which removes $N$\ntransactions at time. Besides validating the model with measurement data, we\nhave used the model to study the reward distribution when miners take\ntransaction selection strategies like fee per byte, fee-based, and FIFO. The\nanalysis shows that smaller fee transactions exhibit higher waiting times, even\nwith increasing the block size. Moreover, the miner transaction selection\nstrategy impacts the final gain.",
    "descriptor": "",
    "authors": [
      "Befekadu G. Gebraselase",
      "Bjarne E. Helvik",
      "Yuming Jiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02725"
  },
  {
    "id": "arXiv:2111.02727",
    "title": "Failure Aware Semi-Centralized Virtual Network Embedding in Cloud  Computing Fat-Tree Data Center Networks",
    "abstract": "In Cloud Computing, the tenants opting for the Infrastructure as a Service\n(IaaS) send the resource requirements to the Cloud Service Provider (CSP) in\nthe form of Virtual Network (VN) consisting of a set of inter-connected Virtual\nMachines (VM). Embedding the VN onto the existing physical network is known as\nVirtual Network Embedding (VNE) problem. One of the major research challenges\nis to allocate the physical resources such that the failure of the physical\nresources would bring less impact onto the users' service. Additionally, the\nmajor challenge is to handle the embedding process of growing number of\nincoming users' VNs from the algorithm design point-of-view. Considering both\nof the above-mentioned research issues, a novel Failure aware Semi-Centralized\nVNE (FSC-VNE) algorithm is proposed for the Fat-Tree data center network with\nthe goal to reduce the impact of the resource failure onto the existing users.\nThe impact of failure of the Physical Machines (PMs), physical links and\nnetwork devices are taken into account while allocating the resources to the\nusers. The beauty of the proposed algorithm is that the VMs are assigned to\ndifferent PMs in a semi-centralized manner. In other words, the embedding\nalgorithm is executed by multiple physical servers in order to concurrently\nembed the VMs of a VN and reduces the embedding time. Extensive simulation\nresults show that the proposed algorithm can outperform over other VNE\nalgorithms.",
    "descriptor": "\nComments: The final version of this paper is published in IEEE Transactions on Cloud Computing\n",
    "authors": [
      "Chinmaya Kumar Dehury",
      "Prasan Kumar Sahoo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02727"
  },
  {
    "id": "arXiv:2111.02732",
    "title": "When Neural Networks Using Different Sensors Create Similar Features",
    "abstract": "Multimodal problems are omnipresent in the real world: autonomous driving,\nrobotic grasping, scene understanding, etc... We draw from the well-developed\nanalysis of similarity to provide an example of a problem where neural networks\nare trained from different sensors, and where the features extracted from these\nsensors still carry similar information. More precisely, we demonstrate that\nfor each sensor, the linear combination of the features from the last layer\nthat correlates the most with other sensors corresponds to the classification\ncomponents of the classification layer.",
    "descriptor": "",
    "authors": [
      "Hugues Moreau",
      "Andr\u00e9a Vassilev",
      "Liming Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02732"
  },
  {
    "id": "arXiv:2111.02735",
    "title": "A Fine-tuned Wav2vec 2.0/HuBERT Benchmark For Speech Emotion  Recognition, Speaker Verification and Spoken Language Understanding",
    "abstract": "Self-supervised speech representations such as wav2vec 2.0 and HuBERT are\nmaking revolutionary progress in Automatic Speech Recognition (ASR). However,\nself-supervised models have not been totally proved to produce better\nperformance on tasks other than ASR. In this work, we explore partial\nfine-tuning and entire fine-tuning on wav2vec 2.0 and HuBERT pre-trained models\nfor three non-ASR speech tasks : Speech Emotion Recognition, Speaker\nVerification and Spoken Language Understanding. We also compare pre-trained\nmodels with/without ASR fine-tuning. With simple down-stream frameworks, the\nbest scores reach 79.58% weighted accuracy for Speech Emotion Recognition on\nIEMOCAP, 2.36% equal error rate for Speaker Verification on VoxCeleb1, 87.51%\naccuracy for Intent Classification and 75.32% F1 for Slot Filling on SLURP,\nthus setting a new state-of-the-art for these three benchmarks, proving that\nfine-tuned wav2vec 2.0 and HuBERT models can better learn prosodic, voice-print\nand semantic representations.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Yingzhi Wang",
      "Abdelmoumene Boumadane",
      "Abdelwahab Heba"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.02735"
  },
  {
    "id": "arXiv:2111.02736",
    "title": "Deep Learning Methods for Daily Wildfire Danger Forecasting",
    "abstract": "Wildfire forecasting is of paramount importance for disaster risk reduction\nand environmental sustainability. We approach daily fire danger prediction as a\nmachine learning task, using historical Earth observation data from the last\ndecade to predict next-day's fire danger. To that end, we collect, pre-process\nand harmonize an open-access datacube, featuring a set of covariates that\njointly affect the fire occurrence and spread, such as weather conditions,\nsatellite-derived products, topography features and variables related to human\nactivity. We implement a variety of Deep Learning (DL) models to capture the\nspatial, temporal or spatio-temporal context and compare them against a Random\nForest (RF) baseline. We find that either spatial or temporal context is enough\nto surpass the RF, while a ConvLSTM that exploits the spatio-temporal context\nperforms best with a test Area Under the Receiver Operating Characteristic of\n0.926. Our DL-based proof-of-concept provides national-scale daily fire danger\nmaps at a much higher spatial resolution than existing operational solutions.",
    "descriptor": "\nComments: Accepted to the workshop on Artificial Intelligence for Humanitarian Assistance and Disaster Response at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Ioannis Prapas",
      "Spyros Kondylatos",
      "Ioannis Papoutsis",
      "Gustau Camps-Valls",
      "Michele Ronco",
      "Miguel-\u00c1ngel Fern\u00e1ndez-Torres",
      "Maria Piles Guillem",
      "Nuno Carvalhais"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02736"
  },
  {
    "id": "arXiv:2111.02737",
    "title": "MUVINE: Multi-stage Virtual Network Embedding in Cloud Data Centers  using Reinforcement Learning based Predictions",
    "abstract": "The recent advances in virtualization technology have enabled the sharing of\ncomputing and networking resources of cloud data centers among multiple users.\nVirtual Network Embedding (VNE) is highly important and is an integral part of\nthe cloud resource management. The lack of historical knowledge on cloud\nfunctioning and inability to foresee the future resource demand are two\nfundamental shortcomings of the traditional VNE approaches. The consequence of\nthose shortcomings is the inefficient embedding of virtual resources on\nSubstrate Nodes (SNs). On the contrary, application of Artificial Intelligence\n(AI) in VNE is still in the premature stage and needs further investigation.\nConsidering the underlying complexity of VNE that includes numerous parameters,\nintelligent solutions are required to utilize the cloud resources efficiently\nvia careful selection of appropriate SNs for the VNE. In this paper,\nReinforcement Learning based prediction model is designed for the efficient\nMulti-stage Virtual Network Embedding (MUVINE) among the cloud data centers.\nThe proposed MUVINE scheme is extensively simulated and evaluated against the\nrecent state-of-the-art schemes. The simulation outcomes show that the proposed\nMUVINE scheme consistently outperforms over the existing schemes and provides\nthe promising results.",
    "descriptor": "\nComments: The final version of this paper is published in IEEE Journal on Selected Areas in Communications\n",
    "authors": [
      "Hiren Kumar Thakkar",
      "Chinmaya Kumar Dehury",
      "Prasan Kumar Sahoo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02737"
  },
  {
    "id": "arXiv:2111.02740",
    "title": "Sequential Movie Genre Prediction using Average Transition Probability  with Clustering",
    "abstract": "In recent movie recommendations, predicting the user's sequential behavior\nand suggesting the next movie to watch is one of the most important issues.\nHowever, capturing such sequential behavior is not easy because each user's\nshort-term or long-term behavior must be taken into account. For this reason,\nmany research results show that the performance of recommending a specific\nmovie is not very high in a sequential recommendation. In this paper, we\npropose a cluster-based method for classifying users with similar movie\npurchase patterns and a movie genre prediction algorithm rather than the movie\nitself considering their short-term and long-term behaviors. The movie genre\nprediction does not recommend a specific movie, but it predicts the genre for\nthe next movie to watch in consideration of each user's preference for the\nmovie genre based on the genre included in the movie. Through this, it is\npossible to provide appropriate guidelines for recommending movies including\nthe genre to users who tend to prefer a specific genre. In particular, in this\npaper, users with similar genre preferences are organized into clusters to\nrecommend genres, and in clusters that do not have relatively specific\ntendencies, genre prediction is performed by appropriately trimming genres that\nare not necessary for recommendation in order to improve performance. We\nevaluate our method on well-known movie datasets, and qualitatively that it\ncaptures personalized dynamics and is able to make meaningful recommendations.",
    "descriptor": "\nComments: Submitted to a journal\n",
    "authors": [
      "Jihyeon Kim",
      "Jinkyung Kim",
      "Jaeyoung Choi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.02740"
  },
  {
    "id": "arXiv:2111.02741",
    "title": "Multi-scale 2D Representation Learning for weakly-supervised moment  retrieval",
    "abstract": "Video moment retrieval aims to search the moment most relevant to a given\nlanguage query. However, most existing methods in this community often require\ntemporal boundary annotations which are expensive and time-consuming to label.\nHence weakly supervised methods have been put forward recently by only using\ncoarse video-level label. Despite effectiveness, these methods usually process\nmoment candidates independently, while ignoring a critical issue that the\nnatural temporal dependencies between candidates in different temporal scales.\nTo cope with this issue, we propose a Multi-scale 2D Representation Learning\nmethod for weakly supervised video moment retrieval. Specifically, we first\nconstruct a two-dimensional map for each temporal scale to capture the temporal\ndependencies between candidates. Two dimensions in this map indicate the start\nand end time points of these candidates. Then, we select top-K candidates from\neach scale-varied map with a learnable convolutional neural network. With a\nnewly designed Moments Evaluation Module, we obtain the alignment scores of the\nselected candidates. At last, the similarity between captions and language\nquery is served as supervision for further training the candidates' selector.\nExperiments on two benchmark datasets Charades-STA and ActivityNet Captions\ndemonstrate that our approach achieves superior performance to state-of-the-art\nresults.",
    "descriptor": "\nComments: 8 pages, 4 figuers. Accepted for publication in 2020 25th International Conference on Pattern Recognition (ICPR)\n",
    "authors": [
      "Ding Li",
      "Rui Wu",
      "Yongqiang Tang",
      "Zhizhong Zhang",
      "Wensheng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02741"
  },
  {
    "id": "arXiv:2111.02749",
    "title": "Label Ranking through Nonparametric Regression",
    "abstract": "Label Ranking (LR) corresponds to the problem of learning a hypothesis that\nmaps features to rankings over a finite set of labels. We adopt a nonparametric\nregression approach to LR and obtain theoretical performance guarantees for\nthis fundamental practical problem. We introduce a generative model for Label\nRanking, in noiseless and noisy nonparametric regression settings, and provide\nsample complexity bounds for learning algorithms in both cases. In the\nnoiseless setting, we study the LR problem with full rankings and provide\ncomputationally efficient algorithms using decision trees and random forests in\nthe high-dimensional regime. In the noisy setting, we consider the more general\ncases of LR with incomplete and partial rankings from a statistical viewpoint\nand obtain sample complexity bounds using the One-Versus-One approach of\nmulticlass classification. Finally, we complement our theoretical contributions\nwith experiments, aiming to understand how the input regression noise affects\nthe observed output.",
    "descriptor": "",
    "authors": [
      "Dimitris Fotakis",
      "Alkis Kalavasis",
      "Eleni Psaroudaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02749"
  },
  {
    "id": "arXiv:2111.02751",
    "title": "FEAFA+: An Extended Well-Annotated Dataset for Facial Expression  Analysis and 3D Facial Animation",
    "abstract": "Nearly all existing Facial Action Coding System-based datasets that include\nfacial action unit (AU) intensity information annotate the intensity values\nhierarchically using A--E levels. However, facial expressions change\ncontinuously and shift smoothly from one state to another. Therefore, it is\nmore effective to regress the intensity value of local facial AUs to represent\nwhole facial expression changes, particularly in the fields of expression\ntransfer and facial animation. We introduce an extension of FEAFA in\ncombination with the relabeled DISFA database, which is available at\nhttps://www.iiplab.net/feafa+/ now. Extended FEAFA (FEAFA+) includes 150 video\nsequences from FEAFA and DISFA, with a total of 230,184 frames being manually\nannotated on floating-point intensity value of 24 redefined AUs using the\nExpression Quantitative Tool. We also list crude numerical results for posed\nand spontaneous subsets and provide a baseline comparison for the AU intensity\nregression task.",
    "descriptor": "",
    "authors": [
      "Wei Gan",
      "Jian Xue",
      "Ke Lu",
      "Yanfu Yan",
      "Pengcheng Gao",
      "Jiayi Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02751"
  },
  {
    "id": "arXiv:2111.02755",
    "title": "A Compound Logic for Modification Problems: Big Kingdoms Fall from  Within",
    "abstract": "We introduce a novel model-theoretic framework inspired from graph\nmodification and based on the interplay between model theory and algorithmic\ngraph minors. We propose a new compound logic operating with two types of\nsentences, expressing graph modification: the modulator sentence, defining some\nproperty of the modified part of the graph, and the target sentence, defining\nsome property of the resulting graph. In our framework, modulator sentences are\nin monadic second-order logic and have models of bounded treewidth, while\ntarget sentences express first-order logic properties along with\nminor-exclusion. Our logic captures problems that are not definable in first\norder logic and, moreover, may have instances of unbounded treewidth. Also, it\npermits the modelling of wide families of problems involving vertex/edge\nremovals, alternative modulator measures (such as elimination distance or\nG-treewidth), multistage modifications, and various cut problems. Our main\nresult is that, for this compound logic, model checking can be done in\nquadratic time. This algorithmic meta-theorem encompasses, unifies, and extends\nall known meta-algorithmic results on minor-closed graph classes. Moreover, all\nderived algorithms are constructive and this, as a byproduct, extends the\nconstructibility horizon of the algorithmic applications of the Graph Minors\ntheorem of Robertson and Seymour. The proposed logic can be seen as a general\nframework to capitalize on the potential of the irrelevant vertex technique.",
    "descriptor": "",
    "authors": [
      "Fedor V. Fomin",
      "Petr A. Golovach",
      "Ignasi Sau",
      "Giannos Stamoulis",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.02755"
  },
  {
    "id": "arXiv:2111.02757",
    "title": "Online Continual Learning via Multiple Deep Metric Learning and  Uncertainty-guided Episodic Memory Replay -- 3rd Place Solution for ICCV 2021  Workshop SSLAD Track 3A Continual Object Classification",
    "abstract": "Online continual learning in the wild is a very difficult task in machine\nlearning. Non-stationarity in online continual learning potentially brings\nabout catastrophic forgetting in neural networks. Specifically, online\ncontinual learning for autonomous driving with SODA10M dataset exhibits extra\nproblems on extremely long-tailed distribution with continuous distribution\nshift. To address these problems, we propose multiple deep metric\nrepresentation learning via both contrastive and supervised contrastive\nlearning alongside soft labels distillation to improve model generalization.\nMoreover, we exploit modified class-balanced focal loss for sensitive\npenalization in class imbalanced and hard-easy samples. We also store some\nsamples under guidance of uncertainty metric for rehearsal and perform online\nand periodical memory updates. Our proposed method achieves considerable\ngeneralization with average mean class accuracy (AMCA) 64.01% on validation and\n64.53% AMCA on test set.",
    "descriptor": "\nComments: 6 pages, 2 figures, 3 algorithms, 1 table\n",
    "authors": [
      "Muhammad Rifki Kurniawan",
      "Xing Wei",
      "Yihong Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02757"
  },
  {
    "id": "arXiv:2111.02759",
    "title": "Count-Less: A Counting Sketch for the Data Plane of High Speed Switches",
    "abstract": "Demands are increasing to measure per-flow statistics in the data plane of\nhigh-speed switches. Measuring flows with exact counting is infeasible due to\nprocessing and memory constraints, but a sketch is a promising candidate for\ncollecting approximately per-flow statistics in data plane in real-time. Among\nthem, Count-Min sketch is a versatile tool to measure spectral density of high\nvolume data using a small amount of memory and low processing overhead. Due to\nits simplicity and versatility, Count-Min sketch and its variants have been\nadopted in many works as a stand alone or even as a supporting measurement\ntool. However, Count-Min's estimation accuracy is limited owing to its data\nstructure not fully accommodating Zipfian distribution and the indiscriminate\nupdate algorithm without considering a counter value. This in turn degrades the\naccuracy of heavy hitter, heavy changer, cardinality, and entropy. To enhance\nmeasurement accuracy of Count-Min, there have been many and various attempts.\nOne of the most notable approaches is to cascade multiple sketches in a\nsequential manner so that either mouse or elephant flows should be filtered to\nseparate elephants from mouse flows such as Elastic sketch (an elephant filter\nleveraging TCAM + Count-Min) and FCM sketch (Count-Min-based layered mouse\nfilters). In this paper, we first show that these cascaded filtering approaches\nadopting a Pyramid-shaped data structure (allocating more counters for mouse\nflows) still suffer from under-utilization of memory, which gives us a room for\nbetter estimation. To this end, we are facing two challenges: one is (a) how to\nmake Count-Min's data structure accommodate more effectively Zipfian\ndistribution, and the other is (b) how to make update and query work without\ndelaying packet processing in the switch's data plane. Count-Less adopts a\ndifferent combination ...",
    "descriptor": "\nComments: 16 pages, 14 figures\n",
    "authors": [
      "SunYoung Kim",
      "Changhun Jung",
      "RhongHo Jang",
      "David Mohaisen",
      "DaeHun Nyang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.02759"
  },
  {
    "id": "arXiv:2111.02760",
    "title": "Medicines Question Answering System, MeQA",
    "abstract": "In this paper we present the first system in Spanish capable of answering\nquestions about medicines for human use, called MeQA (Medicines Question\nAnswering), a project created by the Spanish Agency for Medicines and Health\nProducts (AEMPS, for its acronym in Spanish). Online services that offer\nmedical help have proliferated considerably, mainly due to the current pandemic\nsituation due to COVID-19. For example, websites such as Doctoralia, Savia, or\nSaludOnNet, offer Doctor Answers type consultations, in which patients or users\ncan send questions to doctors and specialists, and receive an answer in less\nthan 24 hours. Many of the questions received are related to medicines for\nhuman use, and most can be answered through the leaflets. Therefore, a system\nsuch as MeQA capable of answering these types of questions automatically could\nalleviate the burden on these websites, and it would be of great use to such\npatients.",
    "descriptor": "",
    "authors": [
      "Jes\u00fas Santamar\u00eda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.02760"
  },
  {
    "id": "arXiv:2111.02764",
    "title": "Stabilization and Variations to the Adaptive Local Iterative Filtering  Algorithm: the Fast Resampled Iterative Filtering Method",
    "abstract": "Non-stationary signals are ubiquitous in real life. Many techniques have been\nproposed in the last decades which allow decomposing multi-component signals\ninto simple oscillatory mono-components, like the groundbreaking Empirical Mode\nDecomposition technique and the Iterative Filtering method. When a signal\ncontains mono-components that have rapid varying instantaneous frequencies, we\ncan think, for instance, to chirps or whistles, it becomes particularly hard\nfor most techniques to properly factor out these components. The Adaptive Local\nIterative Filtering technique has recently gained interest in many applied\nfields of research for being able to deal with non-stationary signals\npresenting amplitude and frequency modulation. In this work, we address the\nopen question of how to guarantee a priori convergence of this technique, and\npropose two new algorithms. The first method, called Stable Adaptive Local\nIterative Filtering, is a stabilized version of the Adaptive Local Iterative\nFiltering that we prove to be always convergent. The stability, however, comes\nat the cost of higher complexity in the calculations. The second technique,\ncalled Resampled Iterative Filtering, is a new generalization of the Iterative\nFiltering method. We prove that Resampled Iterative Filtering is guaranteed to\nconverge a priori for any kind of signal. Furthermore, in the discrete setting,\nby leveraging on the mathematical properties of the matrices involved, we show\nthat its calculations can be accelerated drastically. Finally, we present some\nartificial and real-life examples to show the powerfulness and performance of\nthe proposed methods.",
    "descriptor": "",
    "authors": [
      "Giovanni Barbarino",
      "Antonio Cicone"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.02764"
  },
  {
    "id": "arXiv:2111.02767",
    "title": "RLDS: an Ecosystem to Generate, Share and Use Datasets in Reinforcement  Learning",
    "abstract": "We introduce RLDS (Reinforcement Learning Datasets), an ecosystem for\nrecording, replaying, manipulating, annotating and sharing data in the context\nof Sequential Decision Making (SDM) including Reinforcement Learning (RL),\nLearning from Demonstrations, Offline RL or Imitation Learning. RLDS enables\nnot only reproducibility of existing research and easy generation of new\ndatasets, but also accelerates novel research. By providing a standard and\nlossless format of datasets it enables to quickly test new algorithms on a\nwider range of tasks. The RLDS ecosystem makes it easy to share datasets\nwithout any loss of information and to be agnostic to the underlying original\nformat when applying various data processing pipelines to large collections of\ndatasets. Besides, RLDS provides tools for collecting data generated by either\nsynthetic agents or humans, as well as for inspecting and manipulating the\ncollected data. Ultimately, integration with TFDS facilitates the sharing of RL\ndatasets with the research community.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Sabela Ramos",
      "Sertan Girgin",
      "L\u00e9onard Hussenot",
      "Damien Vincent",
      "Hanna Yakubovich",
      "Daniel Toyama",
      "Anita Gergely",
      "Piotr Stanczyk",
      "Raphael Marinier",
      "Jeremiah Harmsen",
      "Olivier Pietquin",
      "Nikola Momchev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02767"
  },
  {
    "id": "arXiv:2111.02770",
    "title": "Representation Edit Distance as a Measure of Novelty",
    "abstract": "Adaptation to novelty is viewed as learning to change and augment existing\nskills to confront unfamiliar situations. In this paper, we propose that the\namount of editing of an effective representation (the Representation Edit\nDistance or RED) used in a set of skill programs in an agent's mental model is\na measure of difficulty for adaptation to novelty. The RED is an intuitive\napproximation to the change in information content in bit strings measured by\ncomparing pre-novelty and post-novelty skill programs. We also present some\nnotional examples of how to use RED for predicting difficulty.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Joshua Alspector"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02770"
  },
  {
    "id": "arXiv:2111.02775",
    "title": "A Tutorial of Cyber-Syndrome viewed from Cyber-Physical-Social-Thinking  Space and Maslow's Hierarchy of Needs",
    "abstract": "With the increase of active Internet users, various physical, social, and\nmental disorders have recently emerged because of the excessive use of\ntechnology. Cyber-Syndrome is known as the condition that appears due to the\nexcessive interaction with the cyberspace, and it affects the users' physical,\nsocial, and mental states. In this paper, we discuss the etiology and symptoms\nof Cyber-Syndrome according to theories of Cyber-Physical-Social-Thinking\n(CPST) space and Maslow's Hierarchy of Needs. In addition, we also propose an\nentropy-based mechanism for recovery of Cyber-Syndrome, to provide potential\nguidance for clinical detection and diagnosis. Cyber-Syndrome has attracted\nmuch attention these days, and more in-depth exploration is needed in the\nfuture.",
    "descriptor": "",
    "authors": [
      "Feifei Shi",
      "Huansheng Ning",
      "Sahraoui Dhelim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.02775"
  },
  {
    "id": "arXiv:2111.02777",
    "title": "Fractional order logistic map; Numerical approach",
    "abstract": "In this paper the fractional order logistic map in the sense of Caputo's\nfractional differences is numerically approached. It is shown that the\nnecessary iterations number to avoid transients must be of order of thousand,\nnot of order of hundreds as commonly used in several works. Also, it is\nrevealed an interesting phenomenon according to which for every initial\ncondition it correspond a different bifurcation diagram. This phenomenon seems\nto appear also in other FO difference systems, fact which could represent an\nobstacle for the numerical analysis. A short Matlab code is used to obtain the\nresults.",
    "descriptor": "\nComments: submitted\n",
    "authors": [
      "Marius-F. Danca"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2111.02777"
  },
  {
    "id": "arXiv:2111.02778",
    "title": "Rapid wildfire response system based on drones",
    "abstract": "The wildfires in Australia make people suffer the losses caused by the\ndevastating disasters. To protect people's security and the country's\ndevelopment in vulnerable situations, we are expected to establish a set of\nefficient and sustainable fire-rescuing response mechanisms and tackle the\nproblems faced, including optimization of loadings and quantity of drones, time\nadaptability of the model, and the locations of radio-repeater drones. We\ndetermined the location of mobile emergency operation centers (EOC), which\nconduct drone launches and deploy rescue personnel. After figuring out where\nthe EOCs are located, we can establish the Drones Planning-programming\nBudgeting Model to detect the configuration of drones, including optimal\nnumbers and mix of SSA drones and Radio Repeater drones. To estimate the\nadaptability of our model in the next ten decades, we build a Holt-Winters\nseasonal model. We utilize the Drones Deployment Optimization model to optimize\nthe locations of hovering VHF/UHF radio-repeater drones. In addition,\nsensitivity analysis of the model is tested.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "U IengHou",
      "Bai Yuqian",
      "Luo QiFan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.02778"
  },
  {
    "id": "arXiv:2111.02779",
    "title": "Convergent and orthogonality preserving schemes for approximating the  Kohn-Sham orbitals",
    "abstract": "To obtain convergent numerical approximations without using any\northogonalization operations is of great importance in electronic structure\ncalculations. In this paper, we propose and analyze a class of iteration\nschemes for the discretized Kohn-Sham Density Functional Theory model, with\nwhich the iterative approximations are guaranteed to converge to the Kohn-Sham\norbitals exponentially without any orthogonalization as long as the initial\norbitals are orthogonal and the time step sizes are given properly. In\naddition, we present a feasible and efficient approach to get suitable time\nstep sizes.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Xiaoying Dai",
      "Liwei Zhang",
      "Aihui Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.02779"
  },
  {
    "id": "arXiv:2111.02780",
    "title": "Flood forecasting with machine learning models in an operational  framework",
    "abstract": "The operational flood forecasting system by Google was developed to provide\naccurate real-time flood warnings to agencies and the public, with a focus on\nriverine floods in large, gauged rivers. It became operational in 2018 and has\nsince expanded geographically. This forecasting system consists of four\nsubsystems: data validation, stage forecasting, inundation modeling, and alert\ndistribution. Machine learning is used for two of the subsystems. Stage\nforecasting is modeled with the Long Short-Term Memory (LSTM) networks and the\nLinear models. Flood inundation is computed with the Thresholding and the\nManifold models, where the former computes inundation extent and the latter\ncomputes both inundation extent and depth. The Manifold model, presented here\nfor the first time, provides a machine-learning alternative to hydraulic\nmodeling of flood inundation. When evaluated on historical data, all models\nachieve sufficiently high-performance metrics for operational use. The LSTM\nshowed higher skills than the Linear model, while the Thresholding and Manifold\nmodels achieved similar performance metrics for modeling inundation extent.\nDuring the 2021 monsoon season, the flood warning system was operational in\nIndia and Bangladesh, covering flood-prone regions around rivers with a total\narea of 287,000 km2, home to more than 350M people. More than 100M flood alerts\nwere sent to affected populations, to relevant authorities, and to emergency\norganizations. Current and future work on the system includes extending\ncoverage to additional flood-prone locations, as well as improving modeling\ncapabilities and accuracy.",
    "descriptor": "\nComments: 36 pages, 10 figures, 3 tables, 1 supplementary table (9 pages)\n",
    "authors": [
      "Sella Nevo",
      "Efrat Morin",
      "Adi Gerzi Rosenthal",
      "Asher Metzger",
      "Chen Barshai",
      "Dana Weitzner",
      "Dafi Voloshin",
      "Frederik Kratzert",
      "Gal Elidan",
      "Gideon Dror",
      "Gregory Begelman",
      "Grey Nearing",
      "Guy Shalev",
      "Hila Noga",
      "Ira Shavitt",
      "Liora Yuklea",
      "Moriah Royz",
      "Niv Giladi",
      "Nofar Peled Levi",
      "Ofir Reich",
      "Oren Gilon",
      "Ronnie Maor",
      "Shahar Timnat",
      "Tal Shechter",
      "Vladimir Anisimov",
      "Yotam Gigi",
      "Yuval Levin",
      "Zach Moshe",
      "Zvika Ben-Haim",
      "Avinatan Hassidim",
      "Yossi Matias"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02780"
  },
  {
    "id": "arXiv:2111.02782",
    "title": "Fast Solution Methods for Fractional Differential Equations in the  Modeling of Viscoelastic Materials",
    "abstract": "Fractional order models have proven to be a very useful tool for the modeling\nof the mechanical behaviour of viscoelastic materials. Traditional numerical\nsolution methods exhibit various undesired properties due to the non-locality\nof the fractional differential operators, in particular regarding the high\ncomputational complexity and the high memory requirements. The infinite state\nrepresentation is an approach on which one can base numerical methods that\novercome these obstacles. Such algorithms contain a number of parameters that\ninfluence the final result in nontrivial ways. Based on numerical experiments,\nwe initiate a study leading to good choices of these parameters.",
    "descriptor": "\nComments: 16 pages, 6 figures and 2 tables\n",
    "authors": [
      "Kai Diethelm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.02782"
  },
  {
    "id": "arXiv:2111.02784",
    "title": "On the Application of Data-Driven Deep Neural Networks in Linear and  Nonlinear Structural Dynamics",
    "abstract": "The use of deep neural network (DNN) models as surrogates for linear and\nnonlinear structural dynamical systems is explored. The goal is to develop DNN\nbased surrogates to predict structural response, i.e., displacements and\naccelerations, for given input (harmonic) excitations. In particular, the focus\nis on the development of efficient network architectures using fully-connected,\nsparsely-connected, and convolutional network layers, and on the corresponding\ntraining strategies that can provide a balance between the overall network\ncomplexity and prediction accuracy in the target dataspaces. For linear\ndynamics, sparsity patterns of the weight matrix in the network layers are used\nto construct convolutional DNNs with sparse layers. For nonlinear dynamics, it\nis shown that sparsity in network layers is lost, and efficient DNNs\narchitectures with fully-connected and convolutional network layers are\nexplored. A transfer learning strategy is also introduced to successfully train\nthe proposed DNNs, and various loading factors that influence the network\narchitectures are studied. It is shown that the proposed DNNs can be used as\neffective and accurate surrogates for predicting linear and nonlinear dynamical\nresponses under harmonic loadings.",
    "descriptor": "\nComments: 82 pages, 12 Tables, 42 Figures\n",
    "authors": [
      "Nan Feng",
      "Guodong Zhang",
      "Kapil Khandelwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.02784"
  },
  {
    "id": "arXiv:2111.02787",
    "title": "Balanced Q-learning: Combining the Influence of Optimistic and  Pessimistic Targets",
    "abstract": "The optimistic nature of the Q-learning target leads to an overestimation\nbias, which is an inherent problem associated with standard $Q-$learning. Such\na bias fails to account for the possibility of low returns, particularly in\nrisky scenarios. However, the existence of biases, whether overestimation or\nunderestimation, need not necessarily be undesirable. In this paper, we\nanalytically examine the utility of biased learning, and show that specific\ntypes of biases may be preferable, depending on the scenario. Based on this\nfinding, we design a novel reinforcement learning algorithm, Balanced\nQ-learning, in which the target is modified to be a convex combination of a\npessimistic and an optimistic term, whose associated weights are determined\nonline, analytically. We prove the convergence of this algorithm in a tabular\nsetting, and empirically demonstrate its superior learning performance in\nvarious environments.",
    "descriptor": "\nComments: 26 pages, 11 figures\n",
    "authors": [
      "Thommen George Karimpanal",
      "Hung Le",
      "Majid Abdolshah",
      "Santu Rana",
      "Sunil Gupta",
      "Truyen Tran",
      "Svetha Venkatesh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02787"
  },
  {
    "id": "arXiv:2111.02790",
    "title": "LassoBench: A High-Dimensional Hyperparameter Optimization Benchmark  Suite for Lasso",
    "abstract": "Even though Weighted Lasso regression has appealing statistical guarantees,\nit is typically avoided due to its complex search space described with\nthousands of hyperparameters. On the other hand, the latest progress with\nhigh-dimensional HPO methods for black-box functions demonstrates that\nhigh-dimensional applications can indeed be efficiently optimized. Despite this\ninitial success, the high-dimensional HPO approaches are typically applied to\nsynthetic problems with a moderate number of dimensions which limits its impact\nin scientific and engineering applications. To address this limitation, we\npropose LassoBench, a new benchmark suite tailored for an important open\nresearch topic in the Lasso community that is Weighted Lasso regression.\nLassoBench consists of benchmarks on both well-controlled synthetic setups\n(number of samples, SNR, ambient and effective dimensionalities, and multiple\nfidelities) and real-world datasets, which enable the use of many flavors of\nHPO algorithms to be improved and extended to the high-dimensional setting. We\nevaluate 5 state-of-the-art HPO methods and 3 baselines, and demonstrate that\nBayesian optimization, in particular, can improve over the methods commonly\nused for sparse regression while highlighting limitations of these frameworks\nin very high-dimensions. Remarkably, Bayesian optimization improve the Lasso\nbaselines on 60, 100, 300, and 1000 dimensional problems by 45.7%, 19.2%, 19.7%\nand 15.5%, respectively.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Kenan \u0160ehi\u0107",
      "Alexandre Gramfort",
      "Joseph Salmon",
      "Luigi Nardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02790"
  },
  {
    "id": "arXiv:2111.02791",
    "title": "A Cyber Threat Intelligence Sharing Scheme based on Federated Learning  for Network Intrusion Detection",
    "abstract": "The uses of Machine Learning (ML) in detection of network attacks have been\neffective when designed and evaluated in a single organisation. However, it has\nbeen very challenging to design an ML-based detection system by utilising\nheterogeneous network data samples originating from several sources. This is\nmainly due to privacy concerns and the lack of a universal format of datasets.\nIn this paper, we propose a collaborative federated learning scheme to address\nthese issues. The proposed framework allows multiple organisations to join\nforces in the design, training, and evaluation of a robust ML-based network\nintrusion detection system. The threat intelligence scheme utilises two\ncritical aspects for its application; the availability of network data traffic\nin a common format to allow for the extraction of meaningful patterns across\ndata sources. Secondly, the adoption of a federated learning mechanism to avoid\nthe necessity of sharing sensitive users' information between organisations. As\na result, each organisation benefits from other organisations cyber threat\nintelligence while maintaining the privacy of its data internally. The model is\ntrained locally and only the updated weights are shared with the remaining\nparticipants in the federated averaging process. The framework has been\ndesigned and evaluated in this paper by using two key datasets in a NetFlow\nformat known as NF-UNSW-NB15-v2 and NF-BoT-IoT-v2. Two other common scenarios\nare considered in the evaluation process; a centralised training method where\nthe local data samples are shared with other organisations and a localised\ntraining method where no threat intelligence is shared. The results demonstrate\nthe efficiency and effectiveness of the proposed framework by designing a\nuniversal ML model effectively classifying benign and intrusive traffic\noriginating from multiple organisations without the need for local data\nexchange.",
    "descriptor": "",
    "authors": [
      "Mohanad Sarhan",
      "Siamak Layeghy",
      "Nour Moustafa",
      "Marius Portmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.02791"
  },
  {
    "id": "arXiv:2111.02797",
    "title": "A general fractional total variation-Gaussian (GFTG) prior for Bayesian  inverse problems",
    "abstract": "In this paper, we investigate the imaging inverse problem by employing an\ninfinite-dimensional Bayesian inference method with a general fractional total\nvariation-Gaussian (GFTG) prior. This novel hybrid prior is a development for\nthe total variation-Gaussian (TG) prior and the non-local total\nvariation-Gaussian (NLTG) prior, which is a combination of the Gaussian prior\nand a general fractional total variation regularization term, which contains a\nwide class of fractional derivative. Compared to the TG prior, the GFTG prior\ncan effectively reduce the staircase effect, enhance the texture details of the\nimages and also provide a complete theoretical analysis in the\ninfinite-dimensional limit similarly to TG prior. The separability of the state\nspace in Bayesian inference is essential for developments of probability and\nintegration theory in infinite-dimensional setting, thus we first introduce the\ncorresponding general fractional Sobolev space and prove that the space is a\nseparable Banach space. Thereafter, we give the well-posedness and\nfinite-dimensional approximation of the posterior measure of the Bayesian\ninverse problem based on the GFTG prior, and then the samples are extracted\nfrom the posterior distribution by using the preconditioned Crank-Nicolson\n(pCN) algorithm. Finally, we give several numerical examples of image\nreconstruction under liner and nonlinear models to illustrate the advantages of\nthe proposed improved prior.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.15656\n",
    "authors": [
      "Li-Li Wang",
      "Ming-Hui Ding",
      "Guang-Hui Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.02797"
  },
  {
    "id": "arXiv:2111.02801",
    "title": "Gradient-enhanced physics-informed neural networks for forward and  inverse PDE problems",
    "abstract": "Deep learning has been shown to be an effective tool in solving partial\ndifferential equations (PDEs) through physics-informed neural networks (PINNs).\nPINNs embed the PDE residual into the loss function of the neural network, and\nhave been successfully employed to solve diverse forward and inverse PDE\nproblems. However, one disadvantage of the first generation of PINNs is that\nthey usually have limited accuracy even with many training points. Here, we\npropose a new method, gradient-enhanced physics-informed neural networks\n(gPINNs), for improving the accuracy and training efficiency of PINNs. gPINNs\nleverage gradient information of the PDE residual and embed the gradient into\nthe loss function. We tested gPINNs extensively and demonstrated the\neffectiveness of gPINNs in both forward and inverse PDE problems. Our numerical\nresults show that gPINN performs better than PINN with fewer training points.\nFurthermore, we combined gPINN with the method of residual-based adaptive\nrefinement (RAR), a method for improving the distribution of training points\nadaptively during training, to further improve the performance of gPINN,\nespecially in PDEs with solutions that have steep gradients.",
    "descriptor": "",
    "authors": [
      "Jeremy Yu",
      "Lu Lu",
      "Xuhui Meng",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.02801"
  },
  {
    "id": "arXiv:2111.02803",
    "title": "On Similarity",
    "abstract": "The objective quantification of similarity between two mathematical\nstructures constitutes a recurrent issue in science and technology. In the\npresent work, we developed a principled approach that took the Kronecker's\ndelta function of two scalar values as the prototypical reference for\nsimilarity quantification and then derived for more yielding indices, three of\nwhich bound between 0 and 1. Generalizations of these indices to take into\naccount the sign of the scalar values were then presented and developed to\nmultisets, vectors, and functions in real spaces. Several important results\nhave been obtained, including the interpretation of the Jaccard index as a\nyielding implementation of the Kronecker's delta function. When generalized to\nreal functions, the four described similarity indices become respective\nfunctionals, which can then be employed to obtain associated operations of\nconvolution and correlation.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Luciano da F. Costa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02803"
  },
  {
    "id": "arXiv:2111.02808",
    "title": "A Two-Stage Stochastic Programming Model for Blood Supply Chain  Management, Considering Facility Disruption and Service Level",
    "abstract": "In this paper, a blood supply chain network, where the occurrence of\ndisruption might interrupt the flow of Red Blood Cells, is dealt with. In\nprinciple, the probability of disruption is not the only property confiding the\nnetwork, but unprecedented fluctuations in supplies and demands also contribute\nto the network shortages and outdated blood units. Although the consideration\nof parameter uncertainties is of paramount importance in the real-world\ncircumstances for a decision-maker, she or he would be willing to monitor the\nnetwork in a properly broader perspective. Therefore, one of the eminent key\nperformance indicators known as service level turned our attention. To tackle\nuncertainties in the mentioned network - comprising of the four conventional\nlevels containing donors, blood collection facilities, blood banks, and\nhospitals - we present a two-stage stochastic programming model. Consequently,\na toy-example is randomly generated to validate the proposed model.\nFurthermore, numerical analysis led us to a comprehensive service level\nanalysis. Finally, potential pathways for future research are suggested.",
    "descriptor": "\nComments: This paper has been accepted by the 7th International Conference on Logistics and Supply Chain Management\n",
    "authors": [
      "Mohammad Arani",
      "Mohsen Momenitabar",
      "Zhila Dehdari Ebrahimi",
      "Xian Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.02808"
  },
  {
    "id": "arXiv:2111.02810",
    "title": "Monetarization of the Feasible Operation Region based on a Cost-Optimal  Flexibility Disaggregation",
    "abstract": "Hierarchical multi-(voltage-)level grid control strategies are an appropriate\ndesign concept for the coordination of future TSO/DSO- and\nDSO/DSO-interactions. Hierarchical approaches are based on the aggregation of\ndecentralized ancillary service potentials, represented by converter-coupled,\ncommunicable active and reactive power flexibility providing units (FPU) (e.g.\nwind turbines) at vertical system interfaces. The resulting PQ-polygon made\navailable by the DSO for a potential request of ancillary service flexibilities\nby the TSO is called feasible operation region (FOR). A monetarization of the\nFOR is necessary for the implementation as operational degree of freedom within\nhigher-level grid control. This paper presents an approach for the\nmonetarization of the FOR in the context of a hierarchical multi-level\nflexibility market by a cost structure using metadata from population based\noptimization methods. Multiple FPU flexibility polygons at a single bus are\naggregated for a reduction of the search space dimensions. The main\ncontribution of the proposed method is the cost-optimal disaggregation of a\nflexibility demand to the single FPUs within the aggregated FPU by a mixed\ninteger linear program (MILP). Therefore, a local flexibility market\nconsidering bids for the active and reactive power flexibilities by the FPUs\nstakeholders is assumed. The approach is applied within a case-study of the\nCigr\\'e medium voltage system.",
    "descriptor": "\nComments: 13 pages, 17 figures\n",
    "authors": [
      "Marcel Sarstedt",
      "Lutz Hofmann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02810"
  },
  {
    "id": "arXiv:2111.02813",
    "title": "WaveFake: A Data Set to Facilitate Audio Deepfake Detection",
    "abstract": "Deep generative modeling has the potential to cause significant harm to\nsociety. Recognizing this threat, a magnitude of research into detecting\nso-called \"Deepfakes\" has emerged. This research most often focuses on the\nimage domain, while studies exploring generated audio signals have, so-far,\nbeen neglected. In this paper we make three key contributions to narrow this\ngap. First, we provide researchers with an introduction to common signal\nprocessing techniques used for analyzing audio signals. Second, we present a\nnovel data set, for which we collected nine sample sets from five different\nnetwork architectures, spanning two languages. Finally, we supply practitioners\nwith two baseline models, adopted from the signal processing community, to\nfacilitate further research in this area.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 (Benchmark and Dataset Track); Code: this https URL; Data: this https URL\n",
    "authors": [
      "Joel Frank",
      "Lea Sch\u00f6nherr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.02813"
  },
  {
    "id": "arXiv:2111.02821",
    "title": "VOSySmonitoRV: a mixed-criticality solution on Linux-capable RISC-V  platforms",
    "abstract": "Embedded systems are pervasively used in many fields nowadays. In\nmixed-criticality environments (automotive, industry 4.0, drones, etc.) they\nneed to run real-time applications with certain time and safety constraints\nalongside a rich operating system (OS). This is usually possible thanks to\nvirtualization techniques, that leverage on hardware virtualization extensions\non the machine. However, these hardware extensions might not cope with the\nsecurity and safety requirements of the specific use case, and additionally,\nthey might not always be available. A notable example is the emerging RISC-V\narchitecture, that is today gaining a lot of traction in the mixed criticality\nfield, but that do not offer today hardware virtualization extensions. In this\npaper VOSySmonitoRV is proposed as a mixed-criticality solution for RISC-V\nsystems. VOSySmonitoRVallows the co-execution of two or more operating systems\nin a secure and isolated manner by running in the highest privileged machine\nlevel. A specific benchmark, measuring the interrupt latency and context switch\ntime is done to assess the system performance in mixed criticality systems.",
    "descriptor": "\nComments: Also available at this http URL\n",
    "authors": [
      "Flavia Caforio",
      "Pierpaolo Iannicelli",
      "Michele Paolino",
      "Daniel Raho"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2111.02821"
  },
  {
    "id": "arXiv:2111.02823",
    "title": "Convolutional generative adversarial imputation networks for  spatio-temporal missing data in storm surge simulations",
    "abstract": "Imputation of missing data is a task that plays a vital role in a number of\nengineering and science applications. Often such missing data arise in\nexperimental observations from limitations of sensors or post-processing\ntransformation errors. Other times they arise from numerical and algorithmic\nconstraints in computer simulations. One such instance and the application\nemphasis of this paper are numerical simulations of storm surge. The simulation\ndata corresponds to time-series surge predictions over a number of save points\nwithin the geographic domain of interest, creating a spatio-temporal imputation\nproblem where the surge points are heavily correlated spatially and temporally,\nand the missing values regions are structurally distributed at random. Very\nrecently, machine learning techniques such as neural network methods have been\ndeveloped and employed for missing data imputation tasks. Generative\nAdversarial Nets (GANs) and GAN-based techniques have particularly attracted\nattention as unsupervised machine learning methods. In this study, the\nGenerative Adversarial Imputation Nets (GAIN) performance is improved by\napplying convolutional neural networks instead of fully connected layers to\nbetter capture the correlation of data and promote learning from the adjacent\nsurge points. Another adjustment to the method needed specifically for the\nstudied data is to consider the coordinates of the points as additional\nfeatures to provide the model more information through the convolutional\nlayers. We name our proposed method as Convolutional Generative Adversarial\nImputation Nets (Conv-GAIN). The proposed method's performance by considering\nthe improvements and adaptations required for the storm surge data is assessed\nand compared to the original GAIN and a few other techniques. The results show\nthat Conv-GAIN has better performance than the alternative methods on the\nstudied data.",
    "descriptor": "",
    "authors": [
      "Ehsan Adeli",
      "Jize Zhang",
      "Alexandros A. Taflanidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.02823"
  },
  {
    "id": "arXiv:2111.02824",
    "title": "A unified concurrent-composition method to state/event inference and  concealment in discrete-event systems",
    "abstract": "A unified verification method based on a concurrent-composition structure is\nproposed to verify state/event-inference-based properties (e.g., strong\ndetectability, diagnosability, and predictability) and state-concealment-based\nproperties (e.g., opacity) of discrete-event systems modeled by labeled\nfinite-state automata. Hence, inference-based properties and concealment-based\nproperties have been unified into one unified mathematical framework.",
    "descriptor": "",
    "authors": [
      "Kuize Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.02824"
  },
  {
    "id": "arXiv:2111.02825",
    "title": "Whistleblower protection in the digital age -- why 'anonymous' is not  enough. Towards an interdisciplinary view of ethical dilemmas",
    "abstract": "When technology enters applications and processes with a long tradition of\ncontroversial societal debate, multi-faceted new ethical and legal questions\narise. This paper focusses on the process of whistleblowing, an activity with\nlarge impacts on democracy and business. Computer science can, for the first\ntime in history, provide for truly anonymous communication. We investigate this\nin relation to the values and rights of accountability, fairness and data\nprotection, focusing on opportunities and limitations of the anonymity that can\nbe provided computationally; possible consequences of outsourcing\nwhistleblowing support; and challenges for the interpretation and use of some\nrelevant laws. We conclude that to address these questions, whistleblowing and\nanonymous whistleblowing must rest on three pillars, forming a 'triangle of\nwhistleblowing protection and incentivisation' that combines anonymity in a\nformal and technical sense; whistleblower protection through laws; and\norganisational and political error culture.",
    "descriptor": "\nComments: 14 pages, 1 figure; currently (Nov. 2021) submitted to IRIE and under review\n",
    "authors": [
      "Bettina Berendt",
      "Stefan Schiffner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.02825"
  },
  {
    "id": "arXiv:2111.02827",
    "title": "Towards Learning to Speak and Hear Through Multi-Agent Communication  over a Continuous Acoustic Channel",
    "abstract": "While multi-agent reinforcement learning has been used as an effective means\nto study emergent communication between agents, existing work has focused\nalmost exclusively on communication with discrete symbols. Human communication\noften takes place (and emerged) over a continuous acoustic channel; human\ninfants acquire language in large part through continuous signalling with their\ncaregivers. We therefore ask: Are we able to observe emergent language between\nagents with a continuous communication channel trained through reinforcement\nlearning? And if so, what is the impact of channel characteristics on the\nemerging language? We propose an environment and training methodology to serve\nas a means to carry out an initial exploration of these questions. We use a\nsimple messaging environment where a \"speaker\" agent needs to convey a concept\nto a \"listener\". The Speaker is equipped with a vocoder that maps symbols to a\ncontinuous waveform, this is passed over a lossy continuous channel, and the\nListener needs to map the continuous signal to the concept. Using deep\nQ-learning, we show that basic compositionality emerges in the learned language\nrepresentations. We find that noise is essential in the communication channel\nwhen conveying unseen concept combinations. And we show that we can ground the\nemergent communication by introducing a caregiver predisposed to \"hearing\" or\n\"speaking\" English. Finally, we describe how our platform serves as a starting\npoint for future work that uses a combination of deep reinforcement learning\nand multi-agent systems to study our questions of continuous signalling in\nlanguage learning and emergence.",
    "descriptor": "\nComments: 12 pages, 6 figures, 3 tables; under review as a conference paper at ICLR 2022\n",
    "authors": [
      "Kevin Eloff",
      "Arnu Pretorius",
      "Okko R\u00e4s\u00e4nen",
      "Herman A. Engelbrecht",
      "Herman Kamper"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02827"
  },
  {
    "id": "arXiv:2111.02839",
    "title": "Optimised Playout Implementations for the Ludii General Game System",
    "abstract": "This paper describes three different optimised implementations of playouts,\nas commonly used by game-playing algorithms such as Monte-Carlo Tree Search.\nEach of the optimised implementations is applicable only to specific sets of\ngames, based on their rules. The Ludii general game system can automatically\ninfer, based on a game's description in its general game description language,\nwhether any optimised implementations are applicable. An empirical evaluation\ndemonstrates major speedups over a standard implementation, with a median\nresult of running playouts 5.08 times as fast, over 145 different games in\nLudii for which one of the optimised implementations is applicable.",
    "descriptor": "\nComments: Advances in Computer Games (ACG) 2021\n",
    "authors": [
      "Dennis J. N. J. Soemers",
      "\u00c9ric Piette",
      "Matthew Stephenson",
      "Cameron Browne"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02839"
  },
  {
    "id": "arXiv:2111.02840",
    "title": "Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of  Language Models",
    "abstract": "Large-scale pre-trained language models have achieved tremendous success\nacross a wide range of natural language understanding (NLU) tasks, even\nsurpassing human performance. However, recent studies reveal that the\nrobustness of these models can be challenged by carefully crafted textual\nadversarial examples. While several individual datasets have been proposed to\nevaluate model robustness, a principled and comprehensive benchmark is still\nmissing. In this paper, we present Adversarial GLUE (AdvGLUE), a new multi-task\nbenchmark to quantitatively and thoroughly explore and evaluate the\nvulnerabilities of modern large-scale language models under various types of\nadversarial attacks. In particular, we systematically apply 14 textual\nadversarial attack methods to GLUE tasks to construct AdvGLUE, which is further\nvalidated by humans for reliable annotations. Our findings are summarized as\nfollows. (i) Most existing adversarial attack algorithms are prone to\ngenerating invalid or ambiguous adversarial examples, with around 90% of them\neither changing the original semantic meanings or misleading human annotators\nas well. Therefore, we perform a careful filtering process to curate a\nhigh-quality benchmark. (ii) All the language models and robust training\nmethods we tested perform poorly on AdvGLUE, with scores lagging far behind the\nbenign accuracy. We hope our work will motivate the development of new\nadversarial attacks that are more stealthy and semantic-preserving, as well as\nnew robust language models against sophisticated adversarial attacks. AdvGLUE\nis available at https://adversarialglue.github.io.",
    "descriptor": "\nComments: Oral Presentation in NeurIPS 2021 (Datasets and Benchmarks Track). 24 pages, 4 figures, 12 tables\n",
    "authors": [
      "Boxin Wang",
      "Chejian Xu",
      "Shuohang Wang",
      "Zhe Gan",
      "Yu Cheng",
      "Jianfeng Gao",
      "Ahmed Hassan Awadallah",
      "Bo Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02840"
  },
  {
    "id": "arXiv:2111.02844",
    "title": "A text autoencoder from transformer for fast encoding language  representation",
    "abstract": "In recent years BERT shows apparent advantages and great potential in natural\nlanguage processing tasks. However, both training and applying BERT requires\nintensive time and resources for computing contextual language representations,\nwhich hinders its universality and applicability. To overcome this bottleneck,\nwe propose a deep bidirectional language model by using window masking\nmechanism at attention layer. This work computes contextual language\nrepresentations without random masking as does in BERT and maintains the deep\nbidirectional architecture like BERT. To compute the same sentence\nrepresentation, our method shows O(n) complexity less compared to other\ntransformer-based models with O($n^2$). To further demonstrate its superiority,\ncomputing context language representations on CPU environments is conducted, by\nusing the embeddings from the proposed method, logistic regression shows much\nhigher accuracy in terms of SMS classification. Moverover, the proposed method\nalso achieves significant higher performance in semantic similarity tasks.",
    "descriptor": "\nComments: 8 pages, 8 figures. arXiv admin note: text overlap with arXiv:2004.08097 by other authors\n",
    "authors": [
      "Tan Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02844"
  },
  {
    "id": "arXiv:2111.02845",
    "title": "Attacking Deep Reinforcement Learning-Based Traffic Signal Control  Systems with Colluding Vehicles",
    "abstract": "The rapid advancements of Internet of Things (IoT) and artificial\nintelligence (AI) have catalyzed the development of adaptive traffic signal\ncontrol systems (ATCS) for smart cities. In particular, deep reinforcement\nlearning (DRL) methods produce the state-of-the-art performance and have great\npotentials for practical applications. In the existing DRL-based ATCS, the\ncontrolled signals collect traffic state information from nearby vehicles, and\nthen optimal actions (e.g., switching phases) can be determined based on the\ncollected information. The DRL models fully \"trust\" that vehicles are sending\nthe true information to the signals, making the ATCS vulnerable to adversarial\nattacks with falsified information. In view of this, this paper first time\nformulates a novel task in which a group of vehicles can cooperatively send\nfalsified information to \"cheat\" DRL-based ATCS in order to save their total\ntravel time. To solve the proposed task, we develop CollusionVeh, a generic and\neffective vehicle-colluding framework composed of a road situation encoder, a\nvehicle interpreter, and a communication mechanism. We employ our method to\nattack established DRL-based ATCS and demonstrate that the total travel time\nfor the colluding vehicles can be significantly reduced with a reasonable\nnumber of learning episodes, and the colluding effect will decrease if the\nnumber of colluding vehicles increases. Additionally, insights and suggestions\nfor the real-world deployment of DRL-based ATCS are provided. The research\noutcomes could help improve the reliability and robustness of the ATCS and\nbetter protect the smart mobility systems.",
    "descriptor": "",
    "authors": [
      "Ao Qu",
      "Yihong Tang",
      "Wei Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.02845"
  },
  {
    "id": "arXiv:2111.02847",
    "title": "Stable and Compact Face Recognition via Unlabeled Data Driven Sparse  Representation-Based Classification",
    "abstract": "Sparse representation-based classification (SRC) has attracted much attention\nby casting the recognition problem as simple linear regression problem. SRC\nmethods, however, still is limited to enough labeled samples per category,\ninsufficient use of unlabeled samples, and instability of representation. For\ntackling these problems, an unlabeled data driven inverse projection\npseudo-full-space representation-based classification model is proposed with\nlow-rank sparse constraints. The proposed model aims to mine the hidden\nsemantic information and intrinsic structure information of all available data,\nwhich is suitable for few labeled samples and proportion imbalance between\nlabeled samples and unlabeled samples problems in frontal face recognition. The\nmixed Gauss-Seidel and Jacobian ADMM algorithm is introduced to solve the\nmodel. The convergence, representation capability and stability of the model\nare analyzed. Experiments on three public datasets show that the proposed\nLR-S-PFSRC model achieves stable results, especially for proportion imbalance\nof samples.",
    "descriptor": "\nComments: 43 pages, 10 figures, 3 tables\n",
    "authors": [
      "Xiaohui Yang",
      "Zheng Wang",
      "Huan Wu",
      "Licheng Jiao",
      "Yiming Xu",
      "Haolin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02847"
  },
  {
    "id": "arXiv:2111.02848",
    "title": "Data-Driven Market Segmentation in Hospitality Using Unsupervised  Machine Learning",
    "abstract": "Within hospitality, marketing departments use segmentation to create tailored\nstrategies to ensure personalized marketing. This study provides a data-driven\napproach by segmenting guest profiles via hierarchical clustering, based on an\nextensive set of features. The industry requires understandable outcomes that\ncontribute to adaptability for marketing departments to make data-driven\ndecisions and ultimately driving profit. A marketing department specified a\nbusiness question that guides the unsupervised machine learning algorithm.\nFeatures of guests change over time; therefore, there is a probability that\nguests transition from one segment to another. The purpose of the study is to\nprovide steps in the process from raw data to actionable insights, which serve\nas a guideline for how hospitality companies can adopt an algorithmic approach.",
    "descriptor": "",
    "authors": [
      "Rik van Leeuwen",
      "Ger Koole"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02848"
  },
  {
    "id": "arXiv:2111.02851",
    "title": "A Dynamic Programming Method to Construct Polar Codes with Improved  Performance",
    "abstract": "In the standard polar code construction, the message vector\n$(U_0,U_1,\\dots,U_{n-1})$ is divided into information bits and frozen bits\naccording to the reliability of each $U_i$ given $(U_0,U_1,\\dots,U_{i-1})$ and\nall the channel outputs. While this reliability function is the most suitable\nmeasure to choose information bits under the Successive Cancellation (SC)\ndecoder, there is a mismatch between this reliability function and the\nSuccessive Cancellation List (SCL) decoder because the SCL decoder also makes\nuse of the information from the future frozen bits.\nWe propose a Dynamic Programming (DP) construction of polar codes to resolve\nthis mismatch. Our DP construction chooses different sets of information bits\nfor different list sizes in order to optimize the performance of the\nconstructed code under the SCL decoder. Simulation results show that our\nDP-polar codes consistently demonstrate $0.3$--$1$dB improvement over the\nstandard polar codes under the SCL decoder with list size $32$ for various\nchoices of code lengths and code rates.",
    "descriptor": "\nComments: 17 pages, 2 figures\n",
    "authors": [
      "Guodong Li",
      "Min Ye",
      "Sihuang Hu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.02851"
  },
  {
    "id": "arXiv:2111.02853",
    "title": "Big Data Testing Techniques: Taxonomy, Challenges and Future Trends",
    "abstract": "Big Data is reforming many industrial domains by providing decision support\nthrough analyzing large volumes of data. Big Data testing aims to ensure that\nBig Data systems run smoothly and error-free while maintaining the performance\nand quality of data. However, because of the diversity and complexity of data,\ntesting Big Data is challenging. Though numerous researches deal with Big Data\ntesting, a comprehensive review to address testing techniques and challenges is\nnot conflate yet. Therefore, we have conducted a systematic review of the Big\nData testing techniques period (2010 - 2021). This paper discusses the\nprocessing of testing data by highlighting the techniques used in every\nprocessing phase. Furthermore, we discuss the challenges and future directions.\nOur finding shows that diverse functional, non-functional and combined\n(functional and non-functional) testing techniques have been used to solve\nspecific problems related to Big Data. At the same time, most of the testing\nchallenges have been faced during the MapReduce validation phase. In addition,\nthe combinatorial testing technique is one of the most applied techniques in\ncombination with other techniques (i.e., random testing, mutation testing,\ninput space partitioning and equivalence testing) to solve various functional\nfaults challenges faced during Big Data testing.",
    "descriptor": "",
    "authors": [
      "Iram Arshad",
      "Saeed Hamood Alsamhi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02853"
  },
  {
    "id": "arXiv:2111.02859",
    "title": "Large Scale Diverse Combinatorial Optimization: ESPN Fantasy Football  Player Trades",
    "abstract": "Even skilled fantasy football managers can be disappointed by their\nmid-season rosters as some players inevitably fall short of draft day\nexpectations. Team managers can quickly discover that their team has a low\nscore ceiling even if they start their best active players. A novel and diverse\ncombinatorial optimization system proposes high volume and unique player trades\nbetween complementary teams to balance trade fairness. Several algorithms\ncreate the valuation of each fantasy football player with an ensemble of\ncomputing models: Quantum Support Vector Classifier with Permutation Importance\n(QSVC-PI), Quantum Support Vector Classifier with Accumulated Local Effects\n(QSVC-ALE), Variational Quantum Circuit with Permutation Importance (VQC-PI),\nHybrid Quantum Neural Network with Permutation Importance (HQNN-PI), eXtreme\nGradient Boosting Classifier (XGB), and Subject Matter Expert (SME) rules. The\nvaluation of each player is personalized based on league rules, roster, and\nselections. The cost of trading away a player is related to a team's roster,\nsuch as the depth at a position, slot count, and position importance. Teams are\npaired together for trading based on a cosine dissimilarity score so that teams\ncan offset their strengths and weaknesses. A knapsack 0-1 algorithm computes\noutgoing players for each team. Postprocessors apply analytics and deep\nlearning models to measure 6 different objective measures about each trade.\nOver the 2020 and 2021 National Football League (NFL) seasons, a group of 24\nexperts from IBM and ESPN evaluated trade quality through 10 Football Error\nAnalysis Tool (FEAT) sessions. Our system started with 76.9% of high-quality\ntrades and was deployed for the 2021 season with 97.3% of high-quality trades.\nTo increase trade quantity, our quantum, classical, and rules-based computing\nhave 100% trade uniqueness. We use Qiskit's quantum simulators throughout our\nwork.",
    "descriptor": "\nComments: 16 pages, 6 figures, 30 equations\n",
    "authors": [
      "Aaron Baughman",
      "Daniel Bohm",
      "Micah Forster",
      "Eduardo Morales",
      "Jeff Powell",
      "Shaun McPartlin",
      "Raja Hebbar",
      "Kavitha Yogaraj"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02859"
  },
  {
    "id": "arXiv:2111.02862",
    "title": "Parameterized Knowledge Transfer for Personalized Federated Learning",
    "abstract": "In recent years, personalized federated learning (pFL) has attracted\nincreasing attention for its potential in dealing with statistical\nheterogeneity among clients. However, the state-of-the-art pFL methods rely on\nmodel parameters aggregation at the server side, which require all models to\nhave the same structure and size, and thus limits the application for more\nheterogeneous scenarios. To deal with such model constraints, we exploit the\npotentials of heterogeneous model settings and propose a novel training\nframework to employ personalized models for different clients. Specifically, we\nformulate the aggregation procedure in original pFL into a personalized group\nknowledge transfer training algorithm, namely, KT-pFL, which enables each\nclient to maintain a personalized soft prediction at the server side to guide\nthe others' local training. KT-pFL updates the personalized soft prediction of\neach client by a linear combination of all local soft predictions using a\nknowledge coefficient matrix, which can adaptively reinforce the collaboration\namong clients who own similar data distribution. Furthermore, to quantify the\ncontributions of each client to others' personalized training, the knowledge\ncoefficient matrix is parameterized so that it can be trained simultaneously\nwith the models. The knowledge coefficient matrix and the model parameters are\nalternatively updated in each round following the gradient descent way.\nExtensive experiments on various datasets (EMNIST, Fashion\\_MNIST, CIFAR-10)\nare conducted under different settings (heterogeneous models and data\ndistributions). It is demonstrated that the proposed framework is the first\nfederated learning paradigm that realizes personalized model training via\nparameterized group knowledge transfer while achieving significant performance\ngain comparing with state-of-the-art algorithms.",
    "descriptor": "",
    "authors": [
      "Jie Zhang",
      "Song Guo",
      "Xiaosong Ma",
      "Haozhao Wang",
      "Wencao Xu",
      "Feijie Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02862"
  },
  {
    "id": "arXiv:2111.02865",
    "title": "Testing using Privileged Information by Adapting Features with  Statistical Dependence",
    "abstract": "Given an imperfect predictor, we exploit additional features at test time to\nimprove the predictions made, without retraining and without knowledge of the\nprediction function. This scenario arises if training labels or data are\nproprietary, restricted, or no longer available, or if training itself is\nprohibitively expensive. We assume that the additional features are useful if\nthey exhibit strong statistical dependence to the underlying perfect predictor.\nThen, we empirically estimate and strengthen the statistical dependence between\nthe initial noisy predictor and the additional features via manifold denoising.\nAs an example, we show that this approach leads to improvement in real-world\nvisual attribute ranking. Project webpage: this http URL",
    "descriptor": "\nComments: Published at ICCV 2021. Webpage: this http URL\n",
    "authors": [
      "Kwang In Kim",
      "James Tompkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02865"
  },
  {
    "id": "arXiv:2111.02869",
    "title": "Earthquake detection at the edge: IoT crowdsensing network",
    "abstract": "Earthquake Early Warning state of the art systems rely on a network of\nsensors connected to a fusion center in a client-server paradigm. Instead, we\npropose moving computation to the edge, with detector nodes that probe the\nenvironment and process information from nearby probes to detect earthquakes\nlocally. Our approach tolerates multiple node faults and partial network\ndisruption and keeps all data locally, enhancing privacy. This paper describes\nour proposal's rationale and explains its architecture. We then present an\nimplementation using Raspberry, NodeMCU, and the Crowdquake machine learning\nmodel.",
    "descriptor": "",
    "authors": [
      "Enrico Bassetti",
      "Emanuele Panizzi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02869"
  },
  {
    "id": "arXiv:2111.02870",
    "title": "Extended Abstract Version: CNN-based Human Detection System for UAVs in  Search and Rescue",
    "abstract": "This paper proposes an approach for the task of searching and detecting human\nusing a convolutional neural network and a Quadcopter hardware platform. A\npre-trained CNN model is applied to a Raspberry Pi B and a single camera is\nequipped at the bottom of the Quadcopter. The Quadcopter uses\naccelerometer-gyroscope sensor and ultrasonic sensor for balancing control.\nHowever, these sensors are susceptible to noise caused by the driving forces\nsuch as the vibration of the motors, thus, noise processing is implemented.\nExperiments proved that the system works well on the Raspberry Pi B with a\nprocessing speed of 3 fps.",
    "descriptor": "\nComments: 3 pages, 5 figures. arXiv admin note: substantial text overlap with arXiv:2110.01930\n",
    "authors": [
      "Nikite Mesvan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02870"
  },
  {
    "id": "arXiv:2111.02874",
    "title": "Deep Artificial Intelligence for Fantasy Football Language Understanding",
    "abstract": "Fantasy sports allow fans to manage a team of their favorite athletes and\ncompete with friends. The fantasy platform aligns the real-world statistical\nperformance of athletes to fantasy scoring and has steadily risen in popularity\nto an estimated 9.1 million players per month with 4.4 billion player card\nviews on the ESPN Fantasy Football platform from 2018-2019. In parallel, the\nsports media community produces news stories, blogs, forum posts, tweets,\nvideos, podcasts and opinion pieces that are both within and outside the\ncontext of fantasy sports. However, human fantasy football players can only\nanalyze an average of 3.9 sources of information. Our work discusses the\nresults of a machine learning pipeline to manage an ESPN Fantasy Football team.\nThe use of trained statistical entity detectors and document2vector models\napplied to over 100,000 news sources and 2.3 million articles, videos and\npodcasts each day enables the system to comprehend natural language with an\nanalogy test accuracy of 100% and keyword test accuracy of 80%. Deep learning\nfeedforward neural networks provide player classifications such as if a player\nwill be a bust, boom, play with a hidden injury or play meaningful touches with\na cumulative 72% accuracy. Finally, a multiple regression ensemble uses the\ndeep learning output and ESPN projection data to provide a point projection for\neach of the top 500+ fantasy football players in 2018. The point projection\nmaintained a RMSE of 6.78 points. The best fit probability density function\nfrom a set of 24 is selected to visualize score spreads. Within the first 6\nweeks of the product launch, the total number of users spent a cumulative time\nof over 4.6 years viewing our AI insights. The training data for our models was\nprovided by a 2015 to 2016 web archive from Webhose, ESPN statistics, and\nRotowire injury reports. We used 2017 fantasy football data as a test set.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Aaron Baughman",
      "Micah Forester",
      "Jeff Powell",
      "Eduardo Morales",
      "Shaun McPartlin",
      "Daniel Bohm"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02874"
  },
  {
    "id": "arXiv:2111.02878",
    "title": "Unsupervised and Distributional Detection of Machine-Generated Text",
    "abstract": "The power of natural language generation models has provoked a flurry of\ninterest in automatic methods to detect if a piece of text is human or\nmachine-authored. The problem so far has been framed in a standard supervised\nway and consists in training a classifier on annotated data to predict the\norigin of one given new document. In this paper, we frame the problem in an\nunsupervised and distributional way: we assume that we have access to a large\ncollection of unannotated documents, a big fraction of which is\nmachine-generated. We propose a method to detect those machine-generated\ndocuments leveraging repeated higher-order n-grams, which we show over-appear\nin machine-generated text as compared to human ones. That weak signal is the\nstarting point of a self-training setting where pseudo-labelled documents are\nused to train an ensemble of classifiers. Our experiments show that leveraging\nthat signal allows us to rank suspicious documents accurately. Precision at\n5000 is over 90% for top-k sampling strategies, and over 80% for nucleus\nsampling for the largest model we used (GPT2-large). The drop with increased\nsize of model is small, which could indicate that the results hold for other\ncurrent and future large language models.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Matthias Gall\u00e9",
      "Jos Rozen",
      "Germ\u00e1n Kruszewski",
      "Hady Elsahar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.02878"
  },
  {
    "id": "arXiv:2111.02881",
    "title": "Defining Gaze Patterns for Process Model Literacy -- Exploring Visual  Routines in Process Models with Diverse Mappings",
    "abstract": "Process models depict crucial artifacts for organizations regarding\ndocumentation, communication, and collaboration. The proper comprehension of\nsuch models is essential for an effective application. An important aspect in\nprocess model literacy constitutes the question how the information presented\nin process models is extracted and processed by the human visual system? For\nsuch visuospatial tasks, the visual system deploys a set of elemental\noperations, from whose compositions different visual routines are produced.\nThis paper provides insights from an exploratory eye tracking study, in which\nvisual routines during process model comprehension were contemplated. More\nspecifically, n = 29 participants were asked to comprehend n = 18 process\nmodels expressed in the Business Process Model and Notation 2.0 reflecting\ndiverse mappings (i.e., straight, upward, downward) and complexity levels. The\nperformance measures indicated that even less complex process models pose a\nchallenge regarding their comprehension. The upward mapping confronted\nparticipants' attention with more challenges, whereas the downward mapping was\ncomprehended more effectively. Based on recorded eye movements, three gaze\npatterns applied during model comprehension were derived. Thereupon, we defined\na general model which identifies visual routines and corresponding elemental\noperations during process model comprehension. Finally, implications for\npractice as well as research and directions for future work are discussed in\nthis paper.",
    "descriptor": "",
    "authors": [
      "Michael Winter",
      "Heiko Neumann",
      "R\u00fcdiger Pryss",
      "Thomas Probst",
      "Manfred Reichert"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.02881"
  },
  {
    "id": "arXiv:2111.02885",
    "title": "Stochasticity Invariance Control in Pr$_{1-x}$Ca$_x$MnO$_3$ RRAM to  enable Large-Scale Stochastic Recurrent Neural Networks",
    "abstract": "Emerging non-volatile memories have been proposed for a wide range of\napplications from easing the von-Neumann bottleneck to neuromorphic\napplications. Specifically, scalable RRAMs based on Pr$_{1-x}$Ca$_x$MnO$_3$\n(PCMO) exhibit analog switching have been demonstrated as an integrating\nneuron, an analog synapse, and a voltage-controlled oscillator. More recently,\nthe inherent stochasticity of memristors has been proposed for efficient\nhardware implementations of Boltzmann Machines. However, as the problem size\nscales, the number of neurons increase and controlling the stochastic\ndistribution tightly over many iterations is necessary. This requires\nparametric control over stochasticity. Here, we characterize the stochastic Set\nin PCMO RRAMs. We identify that the Set time distribution depends on the\ninternal state of the device (i.e., resistance) in addition to external input\n(i.e., voltage pulse). This requires the confluence of contradictory properties\nlike stochastic switching as well as deterministic state control in the same\ndevice. Unlike, \"stochastic-everywhere\" filamentary memristors, in PCMO RRAMs,\nwe leverage the (i) stochastic Set in negative polarity and (ii) deterministic\nanalog Reset in positive polarity to demonstrate 100x reduced Set time\ndistribution drift. The impact on Boltzmann Machines' performance is analyzed\nand as opposed to the \"fixed external input stochasticity\", the\n\"state-monitored stochasticity\" can solve problems 20x larger in size. State\nmonitoring also tunes out the device-to-device variability effect on\ndistributions providing 10x better performance. In addition to the physical\ninsights, this study establishes the use of experimental stochasticity in PCMO\nRRAMs in stochastic recurrent neural networks reliably over many iterations.",
    "descriptor": "",
    "authors": [
      "Vivek Saraswat",
      "Udayan Ganguly"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02885"
  },
  {
    "id": "arXiv:2111.02887",
    "title": "Self-Supervised Radio-Visual Representation Learning for 6G Sensing",
    "abstract": "In future 6G cellular networks, a joint communication and sensing protocol\nwill allow the network to perceive the environment, opening the door for many\nnew applications atop a unified communication-perception infrastructure.\nHowever, interpreting the sparse radio representation of sensing scenes is\nchallenging, which hinders the potential of these emergent systems. We propose\nto combine radio and vision to automatically learn a radio-only sensing model\nwith minimal human intervention. We want to build a radio sensing model that\ncan feed on millions of uncurated data points. To this end, we leverage recent\nadvances in self-supervised learning and formulate a new label-free\nradio-visual co-learning scheme, whereby vision trains radio via cross-modal\nmutual information. We implement and evaluate our scheme according to the\ncommon linear classification benchmark, and report qualitative and quantitative\nperformance metrics. In our evaluation, the representation learnt by\nradio-visual self-supervision works well for a downstream sensing demonstrator,\nand outperforms its fully-supervised counterpart when less labelled data is\nused. This indicates that self-supervised learning could be an important\nenabler for future scalable radio sensing systems.",
    "descriptor": "",
    "authors": [
      "Mohammed Alloulah",
      "Akash Deep Singh",
      "Maximilian Arnold"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02887"
  },
  {
    "id": "arXiv:2111.02901",
    "title": "Certainty Volume Prediction for Unsupervised Domain Adaptation",
    "abstract": "Unsupervised domain adaptation (UDA) deals with the problem of classifying\nunlabeled target domain data while labeled data is only available for a\ndifferent source domain. Unfortunately, commonly used classification methods\ncannot fulfill this task adequately due to the domain gap between the source\nand target data. In this paper, we propose a novel uncertainty-aware domain\nadaptation setup that models uncertainty as a multivariate Gaussian\ndistribution in feature space. We show that our proposed uncertainty measure\ncorrelates with other common uncertainty quantifications and relates to\nsmoothing the classifier's decision boundary, therefore improving the\ngeneralization capabilities. We evaluate our proposed pipeline on challenging\nUDA datasets and achieve state-of-the-art results. Code for our method is\navailable at https://gitlab.com/tringwald/cvp.",
    "descriptor": "",
    "authors": [
      "Tobias Ringwald",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02901"
  },
  {
    "id": "arXiv:2111.02907",
    "title": "Model-Free Risk-Sensitive Reinforcement Learning",
    "abstract": "We extend temporal-difference (TD) learning in order to obtain\nrisk-sensitive, model-free reinforcement learning algorithms. This extension\ncan be regarded as modification of the Rescorla-Wagner rule, where the\n(sigmoidal) stimulus is taken to be either the event of over- or\nunderestimating the TD target. As a result, one obtains a stochastic\napproximation rule for estimating the free energy from i.i.d. samples generated\nby a Gaussian distribution with unknown mean and variance. Since the Gaussian\nfree energy is known to be a certainty-equivalent sensitive to the mean and the\nvariance, the learning rule has applications in risk-sensitive decision-making.",
    "descriptor": "\nComments: DeepMind Tech Report: 13 pages, 4 figures\n",
    "authors": [
      "Gr\u00e9goire Del\u00e9tang",
      "Jordi Grau-Moya",
      "Markus Kunesch",
      "Tim Genewein",
      "Rob Brekelmans",
      "Shane Legg",
      "Pedro A. Ortega"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02907"
  },
  {
    "id": "arXiv:2111.02915",
    "title": "Local Compatibility Boundary Conditions for High-Order Accurate  Finite-Difference Approximations of PDEs",
    "abstract": "We describe a new approach to derive numerical approximations of boundary\nconditions for high-order accurate finite-difference approximations. The\napproach, called the Local Compatibility Boundary Condition (LCBC) method, uses\nboundary conditions and compatibility boundary conditions derived from the\ngoverning equations, as well as interior and boundary grid values, to construct\na local polynomial, whose degree matches the order of accuracy of the interior\nscheme, centered at each boundary point. The local polynomial is then used to\nderive a discrete formula for each ghost point in terms of the data. This\napproach leads to centered approximations that are generally more accurate and\nstable than one-sided approximations. Moreover, the stencil approximations are\nlocal since they do not couple to neighboring ghost-point values which can\noccur with traditional compatibility conditions. The local polynomial is\nderived using continuous operators and derivatives which enables the automatic\nconstruction of stencil approximations at different orders of accuracy. The\nLCBC method is developed here for problems governed by second-order partial\ndifferential equations, and it is verified for a wide range of sample problems,\nboth time-dependent and time-independent, in two space dimensions and for\nschemes up to sixth-order accuracy.",
    "descriptor": "",
    "authors": [
      "Nour G. Al Hassanieh",
      "Jeffrey W. Banks",
      "William D. Henshaw",
      "Donald W. Schwendeman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.02915"
  },
  {
    "id": "arXiv:2111.02916",
    "title": "A Unified View of Relational Deep Learning for Polypharmacy Side Effect,  Combination Synergy, and Drug-Drug Interaction Prediction",
    "abstract": "In recent years, numerous machine learning models which attempt to solve\npolypharmacy side effect identification, drug-drug interaction prediction and\ncombination therapy design tasks have been proposed. Here, we present a unified\ntheoretical view of relational machine learning models which can address these\ntasks. We provide fundamental definitions, compare existing model architectures\nand discuss performance metrics, datasets and evaluation protocols. In\naddition, we emphasize possible high impact applications and important future\nresearch directions in this domain.",
    "descriptor": "",
    "authors": [
      "Benedek Rozemberczki",
      "Stephen Bonner",
      "Andriy Nikolov",
      "Michael Ughetto",
      "Sebastian Nilsson",
      "Eliseo Papa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.02916"
  },
  {
    "id": "arXiv:2111.02921",
    "title": "Map-Assisted Power Allocation and Constellation Design for mmWave WDM  with OAM in Short-Range LOS Environment",
    "abstract": "Consider a system that integrates positioning and single-user millimeter wave\n(mmWave) communication, where the communication part adopts wavelength division\nmultiplexing (WDM) and orbital angular momentum (OAM). This paper addresses the\npower allocation and high dimensional constellation design in short-range\nline-of-sight (LOS) environment, where the communication links are relatively\nstable. We propose a map-assisted method to replace online estimation, feedback\nand computation with the look-up table searching. We explore the possibility of\nusing a few patterns in the maps, and investigate the performance loss of using\nthe optimal solution of one position for other positions. For power allocation,\nwe first characterize the performance loss outside the OAM beam regions, where\nwe only use plane waves, and figure out that the loss is always small. However,\nin OAM beam regions, the performance loss has similar characteristics only at\nsome specific positions. Combining with numerical results, we illustrate that a\nfew patterns can be adopted for all receiver locations in the map. We also\ninvestigate the high dimensional constellation design and prove that the\npositions where the channel matrices are sufficiently close to be proportional\ncan employ a fixed constellation. Then, we figure out that the constellation\ndesign for all receiver locations can be represented by a few constellation\nsets.",
    "descriptor": "",
    "authors": [
      "Yuan Wang",
      "Chen Gong",
      "Zhengyuan Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02921"
  },
  {
    "id": "arXiv:2111.02922",
    "title": "Identifying nonlinear dynamical systems from multi-modal time series  data",
    "abstract": "Empirically observed time series in physics, biology, or medicine, are\ncommonly generated by some underlying dynamical system (DS) which is the target\nof scientific interest. There is an increasing interest to harvest machine\nlearning methods to reconstruct this latent DS in a completely data-driven,\nunsupervised way. In many areas of science it is common to sample time series\nobservations from many data modalities simultaneously, e.g.\nelectrophysiological and behavioral time series in a typical neuroscience\nexperiment. However, current machine learning tools for reconstructing DSs\nusually focus on just one data modality. Here we propose a general framework\nfor multi-modal data integration for the purpose of nonlinear DS identification\nand cross-modal prediction. This framework is based on dynamically\ninterpretable recurrent neural networks as general approximators of nonlinear\nDSs, coupled to sets of modality-specific decoder models from the class of\ngeneralized linear models. Both an expectation-maximization and a variational\ninference algorithm for model training are advanced and compared. We show on\nnonlinear DS benchmarks that our algorithms can efficiently compensate for too\nnoisy or missing information in one data channel by exploiting other channels,\nand demonstrate on experimental neuroscience data how the algorithm learns to\nlink different data domains to the underlying dynamics",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Philine Lou Bommer",
      "Daniel Kramer",
      "Carlo Tombolini",
      "Georgia Koppe",
      "Daniel Durstewitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.02922"
  },
  {
    "id": "arXiv:2111.02925",
    "title": "SZ3: A Modular Framework for Composing Prediction-Based Error-Bounded  Lossy Compressors",
    "abstract": "Today's scientific simulations require a significant reduction of data volume\nbecause of extremely large amounts of data they produce and the limited I/O\nbandwidth and storage space. Error-bounded lossy compressor has been considered\none of the most effective solutions to the above problem. In practice, however,\nthe best-fit compression method often needs to be customized/optimized in\nparticular because of diverse characteristics in different datasets and various\nuser requirements on the compression quality and performance. In this paper, we\ndevelop a novel modular, composable compression framework (namely SZ3), which\ninvolves three significant contributions. (1) SZ3 features a modular\nabstraction for the prediction-based compression framework such that the new\ncompression modules can be plugged in easily. (2) SZ3 supports multialgorithm\npredictors and can automatically select the best-fit predictor for each data\nblock based on the designed error estimation criterion. (3) SZ3 allows users to\neasily compose different compression pipelines on demand, such that both\ncompression quality and performance can be significantly improved for their\nspecific datasets and requirements. (4) In addition, we evaluate several lossy\ncompressors composed from SZ3 using the real-world datasets. Specifically, we\nleverage SZ3 to improve the compression quality and performance for different\nuse-cases, including GAMESS quantum chemistry dataset and Advanced Photon\nSource (APS) instrument dataset. Experiments show that our customized\ncompression pipelines lead to up to 20% improvement in compression ratios under\nthe same data distortion compared with the state-of-the-art approaches.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Xin Liang",
      "Kai Zhao",
      "Sheng Di",
      "Sihuan Li",
      "Robert Underwood",
      "Ali M. Gok",
      "Jiannan Tian",
      "Junjing Deng",
      "Jon C. Calhoun",
      "Dingwen Tao",
      "Zizhong Chen",
      "Franck Cappello"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02925"
  },
  {
    "id": "arXiv:2111.02926",
    "title": "OpenFWI: Benchmark Seismic Datasets for Machine Learning-Based Full  Waveform Inversion",
    "abstract": "We present OpenFWI, a collection of large-scale open-source benchmark\ndatasets for seismic full waveform inversion (FWI). OpenFWI is the\nfirst-of-its-kind in the geoscience and machine learning community to\nfacilitate diversified, rigorous, and reproducible research on machine\nlearning-based FWI. OpenFWI includes datasets of multiple scales, encompasses\ndiverse domains, and covers various levels of model complexity. Along with the\ndataset, we also perform an empirical study on each dataset with a\nfully-convolutional deep learning model. OpenFWI has been meticulously\nmaintained and will be regularly updated with new data and experimental\nresults. We appreciate the inputs from the community to help us further improve\nOpenFWI. At the current version, we publish seven datasets in OpenFWI, of which\none is specified for 3D FWI and the rest are for 2D scenarios. All datasets and\nrelated information can be accessed through our website at\nhttps://openfwi.github.io/.",
    "descriptor": "",
    "authors": [
      "Chengyuan Deng",
      "Yinan Feng",
      "Shihang Feng",
      "Peng Jin",
      "Xitong Zhang",
      "Qili Zeng",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02926"
  },
  {
    "id": "arXiv:2111.02936",
    "title": "Causal versus Marginal Shapley Values for Robotic Lever Manipulation  Controlled using Deep Reinforcement Learning",
    "abstract": "We investigate the effect of including domain knowledge about a robotic\nsystem's causal relations when generating explanations. To this end, we compare\ntwo methods from explainable artificial intelligence, the popular KernelSHAP\nand the recent causal SHAP, on a deep neural network trained using deep\nreinforcement learning on the task of controlling a lever using a robotic\nmanipulator. A primary disadvantage of KernelSHAP is that its explanations\nrepresent only the features' direct effects on a model's output, not\nconsidering the indirect effects a feature can have on the output by affecting\nother features. Causal SHAP uses a partial causal ordering to alter\nKernelSHAP's sampling procedure to incorporate these indirect effects. This\npartial causal ordering defines the causal relations between the features, and\nwe specify this using domain knowledge about the lever control task. We show\nthat enabling an explanation method to account for indirect effects and\nincorporating some domain knowledge can lead to explanations that better agree\nwith human intuition. This is especially favorable for a real-world robotics\ntask, where there is considerable causality at play, and in addition, the\nrequired domain knowledge is often handily available.",
    "descriptor": "\nComments: Submitted to the American Control Conference 2022\n",
    "authors": [
      "Sindre Benjamin Remman",
      "Inga Str\u00fcmke",
      "Anastasios M. Lekkas"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02936"
  },
  {
    "id": "arXiv:2111.02938",
    "title": "Source-Level Bitwise Branching for Temporal Verification",
    "abstract": "There is increasing interest in applying verification tools to programs that\nhave bitvector operations. SMT solvers, which serve as a foundation for these\ntools, have thus increased support for bitvector reasoning through bit-blasting\nand linear arithmetic approximations. Still, verification tools are limited on\ntermination and LTL verification of bitvector programs. In this work, we show\nthat similar linear arithmetic approximation of bitvector operations can be\ndone at the source level through transformations. Specifically, we introduce\nnew paths that over-approximate bitvector operations with linear\nconditions/constraints, increasing branching but allowing us to better exploit\nthe well-developed integer reasoning and interpolation of verification tools.\nWe present two sets of rules, namely rewriting rules and weakening rules, that\ncan be implemented as bitwise branching of program transformation, the\nbranching path can facilitate verification tools widen verification tasks over\nbitvector programs. Our experiment shows this exploitation of integer reasoning\nand interpolation enables competitive termination verification of bitvector\nprograms and leads to the first effective technique for LTL verification of\nbitvector programs.",
    "descriptor": "\nComments: 2 pages, 1 figure, 1 table, accepted to FMCAD2021 Student Forum. arXiv admin note: substantial text overlap with arXiv:2105.05159\n",
    "authors": [
      "Yuandong Cyrus Liu",
      "Ton-Chanh Le",
      "Eric Koskinen"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.02938"
  },
  {
    "id": "arXiv:2111.02943",
    "title": "idSTLPy: A Python Toolbox for Active Perception and Control",
    "abstract": "This paper describes a Python toolbox for active perception and control\nsynthesis of probabilistic signal temporal logic (PrSTL) formulas of switched\nlinear systems with additive Gaussian disturbances and measurement noises. We\nimplement a counterexample-guided synthesis strategy that combines Bounded\nModel Checking, linear programming, and sampling-based motion planning\ntechniques. We illustrate our approach and the toolbox throughout the paper\nwith a motion planning example for a vehicle with noisy localization. The code\nis available at \\url{https://codeocean.com/capsule/0013534/tree}.",
    "descriptor": "\nComments: 6 pages. arXiv admin note: text overlap with arXiv:2111.02226\n",
    "authors": [
      "Rafael Rodrigues da Silva",
      "Kunal Yadav",
      "Hai Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02943"
  },
  {
    "id": "arXiv:2111.02947",
    "title": "Variational Inference with Holder Bounds",
    "abstract": "The recent introduction of thermodynamic integration techniques has provided\na new framework for understanding and improving variational inference (VI). In\nthis work, we present a careful analysis of the thermodynamic variational\nobjective (TVO), bridging the gap between existing variational objectives and\nshedding new insights to advance the field. In particular, we elucidate how the\nTVO naturally connects the three key variational schemes, namely the\nimportance-weighted VI, Renyi-VI, and MCMC-VI, which subsumes most VI\nobjectives employed in practice. To explain the performance gap between theory\nand practice, we reveal how the pathological geometry of thermodynamic curves\nnegatively affects TVO. By generalizing the integration path from the geometric\nmean to the weighted Holder mean, we extend the theory of TVO and identify new\nopportunities for improving VI. This motivates our new VI objectives, named the\nHolder bounds, which flatten the thermodynamic curves and promise to achieve a\none-step approximation of the exact marginal log-likelihood. A comprehensive\ndiscussion on the choices of numerical estimators is provided. We present\nstrong empirical evidence on both synthetic and real-world datasets to support\nour claims.",
    "descriptor": "",
    "authors": [
      "Junya Chen",
      "Danni Lu",
      "Zidi Xiu",
      "Ke Bai",
      "Lawrence Carin",
      "Chenyang Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.02947"
  },
  {
    "id": "arXiv:2111.02949",
    "title": "Finite-Time Consensus Learning for Decentralized Optimization with  Nonlinear Gossiping",
    "abstract": "Distributed learning has become an integral tool for scaling up machine\nlearning and addressing the growing need for data privacy. Although more robust\nto the network topology, decentralized learning schemes have not gained the\nsame level of popularity as their centralized counterparts for being less\ncompetitive performance-wise. In this work, we attribute this issue to the lack\nof synchronization among decentralized learning workers, showing both\nempirically and theoretically that the convergence rate is tied to the\nsynchronization level among the workers. Such motivated, we present a novel\ndecentralized learning framework based on nonlinear gossiping (NGO), that\nenjoys an appealing finite-time consensus property to achieve better\nsynchronization. We provide a careful analysis of its convergence and discuss\nits merits for modern distributed optimization applications, such as deep\nneural networks. Our analysis on how communication delay and randomized chats\naffect learning further enables the derivation of practical variants that\naccommodate asynchronous and randomized communications. To validate the\neffectiveness of our proposal, we benchmark NGO against competing solutions\nthrough an extensive set of tests, with encouraging results reported.",
    "descriptor": "",
    "authors": [
      "Junya Chen",
      "Sijia Wang",
      "Lawrence Carin",
      "Chenyang Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02949"
  },
  {
    "id": "arXiv:2111.02964",
    "title": "Using Graph-Theoretic Machine Learning to Predict Human Driver Behavior",
    "abstract": "Studies have shown that autonomous vehicles (AVs) behave conservatively in a\ntraffic environment composed of human drivers and do not adapt to local\nconditions and socio-cultural norms. It is known that socially aware AVs can be\ndesigned if there exists a mechanism to understand the behaviors of human\ndrivers. We present an approach that leverages machine learning to predict, the\nbehaviors of human drivers. This is similar to how humans implicitly interpret\nthe behaviors of drivers on the road, by only observing the trajectories of\ntheir vehicles. We use graph-theoretic tools to extract driver behavior\nfeatures from the trajectories and machine learning to obtain a computational\nmapping between the extracted trajectory of a vehicle in traffic and the driver\nbehaviors. Compared to prior approaches in this domain, we prove that our\nmethod is robust, general, and extendable to broad-ranging applications such as\nautonomous navigation. We evaluate our approach on real-world traffic datasets\ncaptured in the U.S., India, China, and Singapore, as well as in simulation.",
    "descriptor": "",
    "authors": [
      "Rohan Chandra",
      "Aniket Bera",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.02964"
  },
  {
    "id": "arXiv:2111.02966",
    "title": "Consistent Estimation for PCA and Sparse Regression with Oblivious  Outliers",
    "abstract": "We develop machinery to design efficiently computable and consistent\nestimators, achieving estimation error approaching zero as the number of\nobservations grows, when facing an oblivious adversary that may corrupt\nresponses in all but an $\\alpha$ fraction of the samples. As concrete examples,\nwe investigate two problems: sparse regression and principal component analysis\n(PCA). For sparse regression, we achieve consistency for optimal sample size\n$n\\gtrsim (k\\log d)/\\alpha^2$ and optimal error rate $O(\\sqrt{(k\\log d)/(n\\cdot\n\\alpha^2)})$ where $n$ is the number of observations, $d$ is the number of\ndimensions and $k$ is the sparsity of the parameter vector, allowing the\nfraction of inliers to be inverse-polynomial in the number of samples. Prior to\nthis work, no estimator was known to be consistent when the fraction of inliers\n$\\alpha$ is $o(1/\\log \\log n)$, even for (non-spherical) Gaussian design\nmatrices. Results holding under weak design assumptions and in the presence of\nsuch general noise have only been shown in dense setting (i.e., general linear\nregression) very recently by d'Orsi et al. [dNS21]. In the context of PCA, we\nattain optimal error guarantees under broad spikiness assumptions on the\nparameter matrix (usually used in matrix completion). Previous works could\nobtain non-trivial guarantees only under the assumptions that the measurement\nnoise corresponding to the inliers is polynomially small in $n$ (e.g., Gaussian\nwith variance $1/n^2$).\nTo devise our estimators, we equip the Huber loss with non-smooth\nregularizers such as the $\\ell_1$ norm or the nuclear norm, and extend d'Orsi\net al.'s approach [dNS21] in a novel way to analyze the loss function. Our\nmachinery appears to be easily applicable to a wide range of estimation\nproblems.",
    "descriptor": "\nComments: To appear in NeurIPS 2021\n",
    "authors": [
      "Tommaso d'Orsi",
      "Chih-Hung Liu",
      "Rajai Nasser",
      "Gleb Novikov",
      "David Steurer",
      "Stefan Tiegel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.02966"
  },
  {
    "id": "arXiv:2111.02967",
    "title": "An Empirical Comparison of the Quadratic Sieve Factoring Algorithm and  the Pollard Rho Factoring Algorithm",
    "abstract": "One of the most significant challenges on cryptography today is the problem\nof factoring large integers since there are no algorithms that can factor in\npolynomial time, and factoring large numbers more than some limits(200 digits)\nremain difficult. The security of the current cryptosystems depends on the\nhardness of factoring large public keys. In this work, we want to implement two\nexisting factoring algorithms - pollard-rho and quadratic sieve - and compare\ntheir performance. In addition, we want to analyze how close is the theoretical\ntime complexity of both algorithms compared to their actual time complexity and\nhow bit length of numbers can affect quadratic sieve's performance. Finally, we\nverify whether the quadratic sieve would do better than pollard-rho for\nfactoring numbers smaller than 80 bits.",
    "descriptor": "",
    "authors": [
      "Zongxia Li",
      "William Gasarch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.02967"
  },
  {
    "id": "arXiv:2111.02972",
    "title": "Stein Variational Probabilistic Roadmaps",
    "abstract": "Efficient and reliable generation of global path plans are necessary for safe\nexecution and deployment of autonomous systems. In order to generate planning\ngraphs which adequately resolve the topology of a given environment, many\nsampling-based motion planners resort to coarse, heuristically-driven\nstrategies which often fail to generalize to new and varied surroundings.\nFurther, many of these approaches are not designed to contend with\npartial-observability. We posit that such uncertainty in environment geometry\ncan, in fact, help \\textit{drive} the sampling process in generating feasible,\nand probabilistically-safe planning graphs. We propose a method for\nProbabilistic Roadmaps which relies on particle-based Variational Inference to\nefficiently cover the posterior distribution over feasible regions in\nconfiguration space. Our approach, Stein Variational Probabilistic Roadmap\n(SV-PRM), results in sample-efficient generation of planning-graphs and large\nimprovements over traditional sampling approaches. We demonstrate the approach\non a variety of challenging planning problems, including real-world\nprobabilistic occupancy maps and high-dof manipulation problems common in\nrobotics.",
    "descriptor": "\nComments: Pre-print\n",
    "authors": [
      "Alexander Lambert",
      "Brian Hou",
      "Rosario Scalise",
      "Siddhartha S. Srinivasa",
      "Byron Boots"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.02972"
  },
  {
    "id": "arXiv:2111.02977",
    "title": "Game-based decision algorithm for socially compatible automated driving:  a case study of unsignalized intersection driving",
    "abstract": "Smooth and harmonic interacting with other vehicles is one of the ultimate\ngoals of driving automation. However, recent reports of demonstrative\ndeployments of automated vehicles (AVs) indicate that AVs are still difficult\nto meet the expectation of other interacting drivers, which leads to several AV\naccidents involving human-driven vehicles (HVs). This is most likely due to the\nlack of understanding about the dynamic interaction process, especially about\nthe human drivers. By investigating the causes of 4,300 video clips of traffic\naccidents, it is found that the limited dynamic visual field of drivers is one\nleading factor in inter-vehicle interaction accidents, especially for those\ninvolving trucks. Taking the interaction with a human-driven truck at an\nunsignalized intersection as an example scenario, a game-theoretic decision\nalgorithm considering social compatibility is proposed. Starting from a\nprobabilistic model for the visual field characteristics of truck drivers,\nsocial fitness and reciprocal altruism in decision are incorporated in the game\npayoff design. Results of human-in-the-loop experiments show that the proposed\nsocially compatible algorithm can effectively improve both safety and time\nefficiency, and make AV decision more in line with the expectation of\ninteracting human drivers. It can be viewed as a promising solution to handling\nthe interactive issues between automated and human-driven vehicles.",
    "descriptor": "\nComments: 20 pages,15 figures\n",
    "authors": [
      "Daofei Li",
      "Ao Liu",
      "Hao Pan",
      "Wentao Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02977"
  },
  {
    "id": "arXiv:2111.02979",
    "title": "Barrier States Embedded Iterative Dynamic Game for Robust and Safe  Trajectory Optimization",
    "abstract": "Considering uncertainties and disturbances is an important, yet challenging,\nstep in successful decision making. The problem becomes more challenging in\nsafety-constrained environments. In this paper, we propose a robust and safe\ntrajectory optimization algorithm through solving a constrained min-max optimal\ncontrol problem. The proposed method leverages a game theoretic differential\ndynamic programming approach with barrier states to handle parametric and\nnon-parametric uncertainties in safety-critical control systems. Barrier states\nare embedded into the differential game's dynamics and cost to portray the\nconstrained environment in a higher dimensional state space and certify the\nsafety of the optimized trajectory. Moreover, we propose to perform line-search\nin a Stackleberg (leader-follower) game fashion which is shown to increase\nrobustness of our controller. The proposed algorithm is evaluated on a\nvelocity-constrained inverted pendulum model that has a 50% error in the\nmodel's parameters to show its efficacy in such a comprehensible system. The\nalgorithm is subsequently implemented on a quadrotor in a windy environment in\nwhich sinusoidal wind turbulences applied in all directions.",
    "descriptor": "",
    "authors": [
      "Hassan Almubarak",
      "Evangelos A. Theodorou",
      "Nader Sadegh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02979"
  },
  {
    "id": "arXiv:2111.02985",
    "title": "A Quantization QoE Evaluation Approach in6DoF Point Cloud Video  Streaming",
    "abstract": "Point cloud video has been widely used by augmented reality (AR) and virtual\nreality (VR) applications as it allows users to have an immersive experience of\nsix degrees of freedom (6DoFs). Yet there is still a lack of research on\nquality of experience (QoE) model of point cloud video streaming, which cannot\nprovide optimization metric for streaming systems. Besides, position and color\ninformation contained in each pixel of point cloud video, and viewport distance\neffect caused by 6DoFs viewing procedure make the traditional objective quality\nevaluation metric cannot be directly used in point cloud video streaming\nsystem. In this paper we first analyze the subjective and objective factors\nrelated to QoE model. Then an experimental system to simulate point cloud video\nstreaming is setup and detailed subjective quality evaluation experiments are\ncarried out. Based on collected mean opinion score (MOS) data, we propose a QoE\nmodel for point cloud video streaming. We also verify the model by actual\nsubjective scoring, and the results show that the proposed QoE model can\naccurately reflect users' visual perception. We also make the experimental\ndatabase public to promote the QoE research of point cloud video streaming.",
    "descriptor": "",
    "authors": [
      "Jie Li",
      "Xiao Wang",
      "Zhi Liu",
      "Qiyue Li"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.02985"
  },
  {
    "id": "arXiv:2111.02987",
    "title": "Numerical Approximation in CFD Problems Using Physics Informed Machine  Learning",
    "abstract": "The thesis focuses on various techniques to find an alternate approximation\nmethod that could be universally used for a wide range of CFD problems but with\nlow computational cost and low runtime. Various techniques have been explored\nwithin the field of machine learning to gauge the utility in fulfilling the\ncore ambition. Steady advection diffusion problem has been used as the test\ncase to understand the level of complexity up to which a method can provide\nsolution. Ultimately, the focus stays over physics informed machine learning\ntechniques where solving differential equations is possible without any\ntraining with computed data. The prevalent methods by I.E. Lagaris et.al. and\nM. Raissi et.al are explored thoroughly. The prevalent methods cannot solve\nadvection dominant problems. A physics informed method, called as Distributed\nPhysics Informed Neural Network (DPINN), is proposed to solve advection\ndominant problems. It increases the lexibility and capability of older methods\nby splitting the domain and introducing other physics-based constraints as mean\nsquared loss terms. Various experiments are done to explore the end to end\npossibilities with the method. Parametric study is also done to understand the\nbehavior of the method to different tunable parameters. The method is tested\nover steady advection-diffusion problems and unsteady square pulse problems.\nVery accurate results are recorded. Extreme learning machine (ELM) is a very\nfast neural network algorithm at the cost of tunable parameters. The ELM based\nvariant of the proposed model is tested over the advection-diffusion problem.\nELM makes the complex optimization simpler and Since the method is\nnon-iterative, the solution is recorded in a single shot. The ELM based variant\nseems to work better than the simple DPINN method. Simultaneously scope for\nvarious development in future are hinted throughout the thesis.",
    "descriptor": "",
    "authors": [
      "Siddharth Rout",
      "Vikas Dwivedi",
      "Balaji Srinivasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02987"
  },
  {
    "id": "arXiv:2111.02992",
    "title": "The Shortest Even Cycle Problem is Tractable",
    "abstract": "Given a directed graph, we show how to efficiently find a shortest (directed,\nsimple) cycle on an even number of vertices. As far as we know, no\npolynomial-time algorithm was previously known for this problem. In fact,\nfinding any even cycle in a directed graph in polynomial time was open for more\nthan two decades until Robertson, Seymour, and Thomas (Ann. of Math. (2) 1999)\nand, independently, McCuaig (Electron. J. Combin. 2004; announced jointly at\nSTOC 1997) gave an efficiently testable structural characterisation of\neven-cycle-free directed graphs.\nMethodologically, our algorithm relies on algebraic fingerprinting and\nrandomized polynomial identity testing over a finite field, and uses a\ngenerating polynomial implicit in Vazirani and Yannakakis ( Discrete Appl.\nMath. 1989) that enumerates weighted cycle covers as a difference of a\npermanent and a determinant polynomial. The need to work with the permanent is\nwhere our main technical contribution occurs. We design a family of finite\ncommutative rings of characteristic 4 that simultaneously (i) give a\nnondegenerate representation for the generating polynomial identity via the\npermanent and the determinant, (ii) support efficient permanent computations,\nand (iii) enable emulation of finite-field arithmetic in characteristic 2. Here\nour work is foreshadowed by that of Bj\\\"orklund and Husfeldt (SIAM J. Comput.\n2019), who used a considerably less efficient ring design to obtain a\npolynomial-time algorithm for the shortest two disjoint paths problem.\nBuilding on work of Gilbert and Tarjan (Numer. Math. 1978) as well as Alon\nand Yuster (J. ACM 2013), we also show how ideas from the nested dissection\ntechnique for solving linear equation systems leads to faster algorithm designs\nwhen we have control on the separator structure of the input graph; for\nexample, this happens when the input has bounded genus.",
    "descriptor": "",
    "authors": [
      "Andreas Bj\u00f6rklund",
      "Thore Husfeldt",
      "Petteri Kaski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.02992"
  },
  {
    "id": "arXiv:2111.02994",
    "title": "Towards an Understanding of Default Policies in Multitask Policy  Optimization",
    "abstract": "Much of the recent success of deep reinforcement learning has been driven by\nregularized policy optimization (RPO) algorithms, with strong performance\nacross multiple domains. In this family of methods, agents are trained to\nmaximize cumulative reward while penalizing deviation in behavior from some\nreference, or default policy. In addition to empirical success, there is a\nstrong theoretical foundation for understanding RPO methods applied to single\ntasks, with connections to natural gradient, trust region, and variational\napproaches. However, there is limited formal understanding of desirable\nproperties for default policies in the multitask setting, an increasingly\nimportant domain as the field shifts towards training more generally capable\nagents. Here, we take a first step towards filling this gap by formally linking\nthe quality of the default policy to its effect on optimization. Using these\nresults, we then derive a principled RPO algorithm for multitask learning with\nstrong performance guarantees.",
    "descriptor": "",
    "authors": [
      "Ted Moskovitz",
      "Michael Arbel",
      "Jack Parker-Holder",
      "Aldo Pacchiano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02994"
  },
  {
    "id": "arXiv:2111.02995",
    "title": "Unsupervised Change Detection of Extreme Events Using ML On-Board",
    "abstract": "In this paper, we introduce RaVAEn, a lightweight, unsupervised approach for\nchange detection in satellite data based on Variational Auto-Encoders (VAEs)\nwith the specific purpose of on-board deployment. Applications such as disaster\nmanagement enormously benefit from the rapid availability of satellite\nobservations. Traditionally, data analysis is performed on the ground after all\ndata is transferred - downlinked - to a ground station. Constraint on the\ndownlink capabilities therefore affects any downstream application. In\ncontrast, RaVAEn pre-processes the sampled data directly on the satellite and\nflags changed areas to prioritise for downlink, shortening the response time.\nWe verified the efficacy of our system on a dataset composed of time series of\ncatastrophic events - which we plan to release alongside this publication -\ndemonstrating that RaVAEn outperforms pixel-wise baselines. Finally we tested\nour approach on resource-limited hardware for assessing computational and\nmemory limitations.",
    "descriptor": "\nComments: 5 pages (+2 in appendix), 5 figures (+1 in appendix), 2 tables (+3 in appendix), NeurIPS Workshop on Artificial Intelligence for Humanitarian Assistance and Disaster Response Workshop (AI+HADR), 2021\n",
    "authors": [
      "V\u00edt R\u016f\u017ei\u010dka",
      "Anna Vaughan",
      "Daniele De Martini",
      "James Fulton",
      "Valentina Salvatelli",
      "Chris Bridges",
      "Gonzalo Mateo-Garcia",
      "Valentina Zantedeschi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02995"
  },
  {
    "id": "arXiv:2111.02997",
    "title": "Global Optimality and Finite Sample Analysis of Softmax Off-Policy Actor  Critic under State Distribution Mismatch",
    "abstract": "In this paper, we establish the global optimality and convergence rate of an\noff-policy actor critic algorithm in the tabular setting without using density\nratio to correct the discrepancy between the state distribution of the behavior\npolicy and that of the target policy. Our work goes beyond existing works on\nthe optimality of policy gradient methods in that existing works use the exact\npolicy gradient for updating the policy parameters while we use an approximate\nand stochastic update step. Our update step is not a gradient update because we\ndo not use a density ratio to correct the state distribution, which aligns well\nwith what practitioners do. Our update is approximate because we use a learned\ncritic instead of the true value function. Our update is stochastic because at\neach step the update is done for only the current state action pair. Moreover,\nwe remove several restrictive assumptions from existing works in our analysis.\nCentral to our work is the finite sample analysis of a generic stochastic\napproximation algorithm with time-inhomogeneous update operators on\ntime-inhomogeneous Markov chains, based on its uniform contraction properties.",
    "descriptor": "",
    "authors": [
      "Shangtong Zhang",
      "Remi Tachet",
      "Romain Laroche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02997"
  },
  {
    "id": "arXiv:2111.02998",
    "title": "Small model property reflects in games and automata",
    "abstract": "Small model property is an important property that implies decidability. We\nshow that the small model size is directly related to some important resources\nin games and automata for checking provability.",
    "descriptor": "",
    "authors": [
      "Maciej Zielenkiewicz"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.02998"
  },
  {
    "id": "arXiv:2111.03000",
    "title": "Reducing the impact of out of vocabulary words in the translation of  natural language questions into SPARQL queries",
    "abstract": "Accessing the large volumes of information available in public knowledge\nbases might be complicated for those users unfamiliar with the SPARQL query\nlanguage. Automatic translation of questions posed in natural language in\nSPARQL has the potential of overcoming this problem. Existing systems based on\nneural-machine translation are very effective but easily fail in recognizing\nwords that are Out Of the Vocabulary (OOV) of the training set. This is a\nserious issue while querying large ontologies. In this paper, we combine Named\nEntity Linking, Named Entity Recognition, and Neural Machine Translation to\nperform automatic translation of natural language questions into SPARQL\nqueries. We demonstrate empirically that our approach is more effective and\nresilient to OOV words than existing approaches by running the experiments on\nMonument, QALD-9, and LC-QuAD v1, which are well-known datasets for Question\nAnswering over DBpedia.",
    "descriptor": "\nComments: 17 pages, 2 figures. This work constitutes a draft pending submission to a journal\n",
    "authors": [
      "Manuel A. Borroto Santana",
      "Francesco Ricca",
      "Bernardo Cuteri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03000"
  },
  {
    "id": "arXiv:2111.03003",
    "title": "Scanflow: A multi-graph framework for Machine Learning workflow  management, supervision, and debugging",
    "abstract": "Machine Learning (ML) is more than just training models, the whole workflow\nmust be considered. Once deployed, a ML model needs to be watched and\nconstantly supervised and debugged to guarantee its validity and robustness in\nunexpected situations. Debugging in ML aims to identify (and address) the model\nweaknesses in not trivial contexts. Several techniques have been proposed to\nidentify different types of model weaknesses, such as bias in classification,\nmodel decay, adversarial attacks, etc., yet there is not a generic framework\nthat allows them to work in a collaborative, modular, portable, iterative way\nand, more importantly, flexible enough to allow both human- and machine-driven\ntechniques. In this paper, we propose a novel containerized directed graph\nframework to support and accelerate end-to-end ML workflow management,\nsupervision, and debugging. The framework allows defining and deploying ML\nworkflows in containers, tracking their metadata, checking their behavior in\nproduction, and improving the models by using both learned and human-provided\nknowledge. We demonstrate these capabilities by integrating in the framework\ntwo hybrid systems to detect data drift distribution which identify the samples\nthat are far from the latent space of the original distribution, ask for human\nintervention, and whether retrain the model or wrap it with a filter to remove\nthe noise of corrupted data at inference time. We test these systems on\nMNIST-C, CIFAR-10-C, and FashionMNIST-C datasets, obtaining promising accuracy\nresults with the help of human involvement.",
    "descriptor": "",
    "authors": [
      "Gusseppe Bravo-Rocca",
      "Peini Liu",
      "Jordi Guitart",
      "Ajay Dholakia",
      "David Ellison",
      "Jeffrey Falkanger",
      "Miroslav Hodak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.03003"
  },
  {
    "id": "arXiv:2111.03005",
    "title": "Parallel Global Edge Switching for the Uniform Sampling of Simple Graphs  with Prescribed Degrees",
    "abstract": "The uniform sampling of simple graphs matching a prescribed degree sequence\nis an important tool in network science, e.g., to construct graph generators or\nnull-models. Here, the Edge Switching Markov Chain (ES-MC) is a common choice.\nGiven an arbitrary simple graph with the required degree sequence, ES-MC\ncarries out a large number of small changes involving at most four edges to\neventually obtain a uniform sample. In practice, reasonably short runs\nefficiently yield approximate uniform samples.\nWe first engineer a simple sequential ES-MC implementation representing the\ngraph in a hash-set. Despite its simplicity and to the best of our knowledge,\nour implementation significantly outperforms all openly available solutions.\nSecondly, we propose the Global Edge Switching Markov Chain (G-ES-MC) and\nshow that it, too, converges to a uniform distribution. We provide empirical\nevidence that G-ES-MC requires not more switches than ES-MC (and often fewer).\nThirdly, we engineer shared-memory parallel algorithms for ES-MC and G-ES-MC;\nwe find that they benefit from the easier dependency structure of the G-ES-MC.\nIn an empirical evaluation, we demonstrate the scalability of our\nimplementations.",
    "descriptor": "",
    "authors": [
      "Daniel Allendorf",
      "Ulrich Meyer",
      "Manuel Penschuck",
      "Hung Tran"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.03005"
  },
  {
    "id": "arXiv:2111.03013",
    "title": "Nyx-Net: Network Fuzzing with Incremental Snapshots",
    "abstract": "Coverage-guided fuzz testing (\"fuzzing\") has become mainstream and we have\nobserved lots of progress in this research area recently. However, it is still\nchallenging to efficiently test network services with existing coverage-guided\nfuzzing methods. In this paper, we introduce the design and implementation of\nNyx-Net, a novel snapshot-based fuzzing approach that can successfully fuzz a\nwide range of targets spanning servers, clients, games, and even Firefox's\nInter-Process Communication (IPC) interface. Compared to state-of-the-art\nmethods, Nyx-Net improves test throughput by up to 300x and coverage found by\nup to 70%. Additionally, Nyx-Net is able to find crashes in two of\nProFuzzBench's targets that no other fuzzer found previously. When using\nNyx-Net to play the game Super Mario, Nyx-Net shows speedups of 10-30x compared\nto existing work. Under some circumstances, Nyx-Net is even able play \"faster\nthan light\": solving the level takes less wall-clock time than playing the\nlevel perfectly even once. Nyx-Net is able to find previously unknown bugs in\nservers such as Lighttpd, clients such as MySQL client, and even Firefox's IPC\nmechanism - demonstrating the strength and versatility of the proposed\napproach. Lastly, our prototype implementation was awarded a $20.000 bug bounty\nfor enabling fuzzing on previously unfuzzable code in Firefox and solving a\nlong-standing problem at Mozilla.",
    "descriptor": "",
    "authors": [
      "Sergej Schumilo",
      "Cornelius Aschermann",
      "Andrea Jemmett",
      "Ali Abbasi",
      "Thorsten Holz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.03013"
  },
  {
    "id": "arXiv:2111.03015",
    "title": "Modeling Techniques for Machine Learning Fairness: A Survey",
    "abstract": "Machine learning models are becoming pervasive in high-stakes applications.\nDespite their clear benefits in terms of performance, the models could show\nbias against minority groups and result in fairness issues in a decision-making\nprocess, leading to severe negative impacts on the individuals and the society.\nIn recent years, various techniques have been developed to mitigate the bias\nfor machine learning models. Among them, in-processing methods have drawn\nincreasing attention from the community, where fairness is directly taken into\nconsideration during model design to induce intrinsically fair models and\nfundamentally mitigate fairness issues in outputs and representations. In this\nsurvey, we review the current progress of in-processing bias mitigation\ntechniques. Based on where the fairness is achieved in the model, we categorize\nthem into explicit and implicit methods, where the former directly incorporates\nfairness metrics in training objectives, and the latter focuses on refining\nlatent representation learning. Finally, we conclude the survey with a\ndiscussion of the research challenges in this community to motivate future\nexploration.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Mingyang Wan",
      "Daochen Zha",
      "Ninghao Liu",
      "Na Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03015"
  },
  {
    "id": "arXiv:2111.03017",
    "title": "MT3: Multi-Task Multitrack Music Transcription",
    "abstract": "Automatic Music Transcription (AMT), inferring musical notes from raw audio,\nis a challenging task at the core of music understanding. Unlike Automatic\nSpeech Recognition (ASR), which typically focuses on the words of a single\nspeaker, AMT often requires transcribing multiple instruments simultaneously,\nall while preserving fine-scale pitch and timing information. Further, many AMT\ndatasets are \"low-resource\", as even expert musicians find music transcription\ndifficult and time-consuming. Thus, prior work has focused on task-specific\narchitectures, tailored to the individual instruments of each task. In this\nwork, motivated by the promising results of sequence-to-sequence transfer\nlearning for low-resource Natural Language Processing (NLP), we demonstrate\nthat a general-purpose Transformer model can perform multi-task AMT, jointly\ntranscribing arbitrary combinations of musical instruments across several\ntranscription datasets. We show this unified training framework achieves\nhigh-quality transcription results across a range of datasets, dramatically\nimproving performance for low-resource instruments (such as guitar), while\npreserving strong performance for abundant instruments (such as piano).\nFinally, by expanding the scope of AMT, we expose the need for more consistent\nevaluation metrics and better dataset alignment, and provide a strong baseline\nfor this new direction of multi-task AMT.",
    "descriptor": "",
    "authors": [
      "Josh Gardner",
      "Ian Simon",
      "Ethan Manilow",
      "Curtis Hawthorne",
      "Jesse Engel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.03017"
  },
  {
    "id": "arXiv:2111.03026",
    "title": "B-Pref: Benchmarking Preference-Based Reinforcement Learning",
    "abstract": "Reinforcement learning (RL) requires access to a reward function that\nincentivizes the right behavior, but these are notoriously hard to specify for\ncomplex tasks. Preference-based RL provides an alternative: learning policies\nusing a teacher's preferences without pre-defined rewards, thus overcoming\nconcerns associated with reward engineering. However, it is difficult to\nquantify the progress in preference-based RL due to the lack of a commonly\nadopted benchmark. In this paper, we introduce B-Pref: a benchmark specially\ndesigned for preference-based RL. A key challenge with such a benchmark is\nproviding the ability to evaluate candidate algorithms quickly, which makes\nrelying on real human input for evaluation prohibitive. At the same time,\nsimulating human input as giving perfect preferences for the ground truth\nreward function is unrealistic. B-Pref alleviates this by simulating teachers\nwith a wide array of irrationalities, and proposes metrics not solely for\nperformance but also for robustness to these potential irrationalities. We\nshowcase the utility of B-Pref by using it to analyze algorithmic design\nchoices, such as selecting informative queries, for state-of-the-art\npreference-based RL algorithms. We hope that B-Pref can serve as a common\nstarting point to study preference-based RL more systematically. Source code is\navailable at https://github.com/rll-research/B-Pref.",
    "descriptor": "\nComments: NeurIPS Datasets and Benchmarks Track 2021. Code is available at this https URL\n",
    "authors": [
      "Kimin Lee",
      "Laura Smith",
      "Anca Dragan",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.03026"
  },
  {
    "id": "arXiv:2111.03030",
    "title": "An Interpretable Graph Generative Model with Heterophily",
    "abstract": "Many models for graphs fall under the framework of edge-independent dot\nproduct models. These models output the probabilities of edges existing between\nall pairs of nodes, and the probability of a link between two nodes increases\nwith the dot product of vectors associated with the nodes. Recent work has\nshown that these models are unable to capture key structures in real-world\ngraphs, particularly heterophilous structures, wherein links occur between\ndissimilar nodes. We propose the first edge-independent graph generative model\nthat is a) expressive enough to capture heterophily, b) produces nonnegative\nembeddings, which allow link predictions to be interpreted in terms of\ncommunities, and c) optimizes effectively on real-world graphs with gradient\ndescent on a cross-entropy loss. Our theoretical results demonstrate the\nexpressiveness of our model in its ability to exactly reconstruct a graph using\na number of clusters that is linear in the maximum degree, along with its\nability to capture both heterophily and homophily in the data. Further, our\nexperiments demonstrate the effectiveness of our model for a variety of\nimportant application tasks such as multi-label clustering and link prediction.",
    "descriptor": "",
    "authors": [
      "Sudhanshu Chanpuriya",
      "Ryan A. Rossi",
      "Anup Rao",
      "Tung Mai",
      "Nedim Lipka",
      "Zhao Song",
      "Cameron Musco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.03030"
  },
  {
    "id": "arXiv:2111.03033",
    "title": "Computational thresholds for the fixed-magnetization Ising model",
    "abstract": "The ferromagnetic Ising model is a model of a magnetic material and a central\ntopic in statistical physics. It also plays a starring role in the algorithmic\nstudy of approximate counting: approximating the partition function of the\nferromagnetic Ising model with uniform external field is tractable at all\ntemperatures and on all graphs, due to the randomized algorithm of Jerrum and\nSinclair. Here we show that hidden inside the model are hard computational\nproblems. For the class of bounded-degree graphs we find computational\nthresholds for the approximate counting and sampling problems for the\nferromagnetic Ising model at fixed magnetization (that is, fixing the number of\n$+1$ and $-1$ spins). In particular, letting $\\beta_c(\\Delta)$ denote the\ncritical inverse temperature of the zero-field Ising model on the infinite\n$\\Delta$-regular tree, and $\\eta_{\\Delta,\\beta,1}^+$ denote the mean\nmagnetization of the zero-field $+$ measure on the infinite $\\Delta$-regular\ntree at inverse temperature $\\beta$, we prove, for the class of graphs of\nmaximum degree $\\Delta$:\n1. For $\\beta < \\beta_c(\\Delta)$ there is an FPRAS and efficient sampling\nscheme for the fixed-magnetization Ising model for all magnetizations $\\eta$.\n2. For $\\beta > \\beta_c(\\Delta)$, there is an FPRAS and efficient sampling\nscheme for the fixed-magnetization Ising model for magnetizations $\\eta$ such\nthat $|\\eta| >\\eta_{\\Delta,\\beta,1}^+ $.\n3. For $\\beta > \\beta_c(\\Delta)$, there is no FPRAS for the\nfixed-magnetization Ising model for magnetizations $\\eta$ such that $|\\eta|\n<\\eta_{\\Delta,\\beta,1}^+ $ unless NP=RP\\@.",
    "descriptor": "",
    "authors": [
      "Charlie Carlson",
      "Ewan Davies",
      "Alexandra Kolla",
      "Will Perkins"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.03033"
  },
  {
    "id": "arXiv:2111.03039",
    "title": "Towards Panoptic 3D Parsing for Single Image in the Wild",
    "abstract": "Performing single image holistic understanding and 3D reconstruction is a\ncentral task in computer vision. This paper presents an integrated system that\nperforms holistic image segmentation, object detection, instance segmentation,\ndepth estimation, and object instance 3D reconstruction for indoor and outdoor\nscenes from a single RGB image. We name our system panoptic 3D parsing in which\npanoptic segmentation (\"stuff\" segmentation and \"things\"\ndetection/segmentation) with 3D reconstruction is performed. We design a\nstage-wise system where a complete set of annotations is absent. Additionally,\nwe present an end-to-end pipeline trained on a synthetic dataset with a full\nset of annotations. We show results on both indoor (3D-FRONT) and outdoor (COCO\nand Cityscapes) scenes. Our proposed panoptic 3D parsing framework points to a\npromising direction in computer vision. It can be applied to various\napplications, including autonomous driving, mapping, robotics, design, computer\ngraphics, robotics, human-computer interaction, and augmented reality.",
    "descriptor": "",
    "authors": [
      "Sainan Liu",
      "Vincent Nguyen",
      "Yuan Gao",
      "Subarna Tripathi",
      "Zhuowen Tu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.03039"
  },
  {
    "id": "arXiv:2111.03042",
    "title": "Unsupervised Learning of Compositional Energy Concepts",
    "abstract": "Humans are able to rapidly understand scenes by utilizing concepts extracted\nfrom prior experience. Such concepts are diverse, and include global scene\ndescriptors, such as the weather or lighting, as well as local scene\ndescriptors, such as the color or size of a particular object. So far,\nunsupervised discovery of concepts has focused on either modeling the global\nscene-level or the local object-level factors of variation, but not both. In\nthis work, we propose COMET, which discovers and represents concepts as\nseparate energy functions, enabling us to represent both global concepts as\nwell as objects under a unified framework. COMET discovers energy functions\nthrough recomposing the input image, which we find captures independent factors\nwithout additional supervision. Sample generation in COMET is formulated as an\noptimization process on underlying energy functions, enabling us to generate\nimages with permuted and composed concepts. Finally, discovered visual concepts\nin COMET generalize well, enabling us to compose concepts between separate\nmodalities of images as well as with other concepts discovered by a separate\ninstance of COMET trained on a different dataset. Code and data available at\nhttps://energy-based-model.github.io/comet/.",
    "descriptor": "\nComments: NeurIPS 2021, website and code at this https URL\n",
    "authors": [
      "Yilun Du",
      "Shuang Li",
      "Yash Sharma",
      "Joshua B. Tenenbaum",
      "Igor Mordatch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03042"
  },
  {
    "id": "arXiv:2111.03043",
    "title": "A System for General In-Hand Object Re-Orientation",
    "abstract": "In-hand object reorientation has been a challenging problem in robotics due\nto high dimensional actuation space and the frequent change in contact state\nbetween the fingers and the objects. We present a simple model-free framework\nthat can learn to reorient objects with both the hand facing upwards and\ndownwards. We demonstrate the capability of reorienting over 2000 geometrically\ndifferent objects in both cases. The learned policies show strong zero-shot\ntransfer performance on new objects. We provide evidence that these policies\nare amenable to real-world operation by distilling them to use observations\neasily available in the real world. The videos of the learned policies are\navailable at: https://taochenshh.github.io/projects/in-hand-reorientation.",
    "descriptor": "\nComments: Accepted as an oral paper by CORL (Conference on Robot Learning); Keywords: dexterous manipulation, in-hand manipulation, object reorientation\n",
    "authors": [
      "Tao Chen",
      "Jie Xu",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03043"
  },
  {
    "id": "arXiv:2111.03044",
    "title": "A Unified Approach to Coreset Learning",
    "abstract": "Coreset of a given dataset and loss function is usually a small weighed set\nthat approximates this loss for every query from a given set of queries.\nCoresets have shown to be very useful in many applications. However, coresets\nconstruction is done in a problem dependent manner and it could take years to\ndesign and prove the correctness of a coreset for a specific family of queries.\nThis could limit coresets use in practical applications. Moreover, small\ncoresets provably do not exist for many problems.\nTo address these limitations, we propose a generic, learning-based algorithm\nfor construction of coresets. Our approach offers a new definition of coreset,\nwhich is a natural relaxation of the standard definition and aims at\napproximating the \\emph{average} loss of the original data over the queries.\nThis allows us to use a learning paradigm to compute a small coreset of a given\nset of inputs with respect to a given loss function using a training set of\nqueries. We derive formal guarantees for the proposed approach. Experimental\nevaluation on deep networks and classic machine learning problems show that our\nlearned coresets yield comparable or even better results than the existing\nalgorithms with worst-case theoretical guarantees (that may be too pessimistic\nin practice). Furthermore, our approach applied to deep network pruning\nprovides the first coreset for a full deep network, i.e., compresses all the\nnetwork at once, and not layer by layer or similar divide-and-conquer methods.",
    "descriptor": "",
    "authors": [
      "Alaa Maalouf",
      "Gilad Eini",
      "Ben Mussay",
      "Dan Feldman",
      "Margarita Osadchy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03044"
  },
  {
    "id": "arXiv:2111.03046",
    "title": "Introduction to Coresets: Approximated Mean",
    "abstract": "A \\emph{strong coreset} for the mean queries of a set $P$ in ${\\mathbb{R}}^d$\nis a small weighted subset $C\\subseteq P$, which provably approximates its sum\nof squared distances to any center (point) $x\\in {\\mathbb{R}}^d$. A \\emph{weak\ncoreset} is (also) a small weighted subset $C$ of $P$, whose mean approximates\nthe mean of $P$. While computing the mean of $P$ can be easily computed in\nlinear time, its coreset can be used to solve harder constrained version, and\nis in the heart of generalizations such as coresets for $k$-means clustering.\nIn this paper, we survey most of the mean coreset construction techniques, and\nsuggest a unified analysis methodology for providing and explaining classical\nand modern results including step-by-step proofs. In particular, we collected\nfolklore and scattered related results, some of which are not formally stated\nelsewhere. Throughout this survey, we present, explain, and prove a set of\ntechniques, reductions, and algorithms very widespread and crucial in this\nfield. However, when put to use in the (relatively simple) mean problem, such\ntechniques are much simpler to grasp. The survey may help guide new researchers\nunfamiliar with the field, and introduce them to the very basic foundations of\ncoresets, through a simple, yet fundamental, problem. Experts in this area\nmight appreciate the unified analysis flow, and the comparison table for\nexisting results. Finally, to encourage and help practitioners and software\nengineers, we provide full open source code for all presented algorithms.",
    "descriptor": "",
    "authors": [
      "Alaa Maalouf",
      "Ibrahim Jubran",
      "Dan Feldman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.03046"
  },
  {
    "id": "arXiv:2111.03048",
    "title": "Imagine Networks",
    "abstract": "In this paper, we introduce an Imagine Network that can simulate itself\nthrough graph tree neural networks. Among the graph tree neural networks\nmodels, association, deduction, and memory networks are learned, and a network\nis created by combining the discriminator and reinforcement learning models.\nThis model can learn various datasets or data samples generated in environments\nand generate new data samples.",
    "descriptor": "\nComments: This paper is the part of the graph tree neural networks series we are studying\n",
    "authors": [
      "Seokjun Kim",
      "Jaeeun Jang",
      "Hyeoncheol Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.03048"
  },
  {
    "id": "arXiv:2111.03056",
    "title": "Bootstrap Your Object Detector via Mixed Training",
    "abstract": "We introduce MixTraining, a new training paradigm for object detection that\ncan improve the performance of existing detectors for free. MixTraining\nenhances data augmentation by utilizing augmentations of different strengths\nwhile excluding the strong augmentations of certain training samples that may\nbe detrimental to training. In addition, it addresses localization noise and\nmissing labels in human annotations by incorporating pseudo boxes that can\ncompensate for these errors. Both of these MixTraining capabilities are made\npossible through bootstrapping on the detector, which can be used to predict\nthe difficulty of training on a strong augmentation, as well as to generate\nreliable pseudo boxes thanks to the robustness of neural networks to labeling\nerror. MixTraining is found to bring consistent improvements across various\ndetectors on the COCO dataset. In particular, the performance of Faster R-CNN\n\\cite{ren2015faster} with a ResNet-50 \\cite{he2016deep} backbone is improved\nfrom 41.7 mAP to 44.0 mAP, and the accuracy of Cascade-RCNN\n\\cite{cai2018cascade} with a Swin-Small \\cite{liu2021swin} backbone is raised\nfrom 50.9 mAP to 52.8 mAP. The code and models will be made publicly available\nat \\url{https://github.com/MendelXu/MixTraining}.",
    "descriptor": "",
    "authors": [
      "Mengde Xu",
      "Zheng Zhang",
      "Fangyun Wei",
      "Yutong Lin",
      "Yue Cao",
      "Stephen Lin",
      "Han Hu",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.03056"
  },
  {
    "id": "arXiv:2111.03059",
    "title": "Engagement Decision Support for Beyond Visual Range Air Combat",
    "abstract": "This work aims to provide an engagement decision support tool for Beyond\nVisual Range (BVR) air combat in the context of Defensive Counter Air (DCA)\nmissions. In BVR air combat, engagement decision refers to the choice of the\nmoment the pilot engages a target by assuming an offensive stance and executing\ncorresponding maneuvers. To model this decision, we use the Brazilian Air\nForce's Aerospace Simulation Environment (\\textit{Ambiente de Simula\\c{c}\\~ao\nAeroespacial - ASA} in Portuguese), which generated 3,729 constructive\nsimulations lasting 12 minutes each and a total of 10,316 engagements. We\nanalyzed all samples by an operational metric called the DCA index, which\nrepresents, based on the experience of subject matter experts, the degree of\nsuccess in this type of mission. This metric considers the distances of the\naircraft of the same team and the opposite team, the point of Combat Air\nPatrol, and the number of missiles used. By defining the engagement status\nright before it starts and the average of the DCA index throughout the\nengagement, we create a supervised learning model to determine the quality of a\nnew engagement. An algorithm based on decision trees, working with the XGBoost\nlibrary, provides a regression model to predict the DCA index with a\ncoefficient of determination close to 0.8 and a Root Mean Square Error of 0.05\nthat can furnish parameters to the BVR pilot to decide whether or not to\nengage. Thus, using data obtained through simulations, this work contributes by\nbuilding a decision support system based on machine learning for BVR air\ncombat.",
    "descriptor": "",
    "authors": [
      "Joao P. A. Dantas",
      "Andre N. Costa",
      "Diego Geraldo",
      "Marcos R. O. A. Maximo",
      "Takashi Yoneyama"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.03059"
  },
  {
    "id": "arXiv:2111.03062",
    "title": "Generalization in Dexterous Manipulation via Geometry-Aware Multi-Task  Learning",
    "abstract": "Dexterous manipulation of arbitrary objects, a fundamental daily task for\nhumans, has been a grand challenge for autonomous robotic systems. Although\ndata-driven approaches using reinforcement learning can develop specialist\npolicies that discover behaviors to control a single object, they often exhibit\npoor generalization to unseen ones. In this work, we show that policies learned\nby existing reinforcement learning algorithms can in fact be generalist when\ncombined with multi-task learning and a well-chosen object representation. We\nshow that a single generalist policy can perform in-hand manipulation of over\n100 geometrically-diverse real-world objects and generalize to new objects with\nunseen shape or size. Interestingly, we find that multi-task learning with\nobject point cloud representations not only generalizes better but even\noutperforms the single-object specialist policies on both training as well as\nheld-out test objects. Video results at\nhttps://huangwl18.github.io/geometry-dex",
    "descriptor": "\nComments: Website at this https URL\n",
    "authors": [
      "Wenlong Huang",
      "Igor Mordatch",
      "Pieter Abbeel",
      "Deepak Pathak"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.03062"
  },
  {
    "id": "arXiv:1502.07481",
    "title": "Cluster Synchronization of Coupled Systems with Nonidentical Linear  Dynamics",
    "abstract": "This paper considers the cluster synchronization problem of generic linear\ndynamical systems whose system models are distinct in different clusters. These\nnonidentical linear models render control design and coupling conditions highly\ncorrelated if static couplings are used for all individual systems. In this\npaper, a dynamic coupling structure, which incorporates a global weighting\nfactor and a vanishing auxiliary control variable, is proposed for each agent\nand is shown to be a feasible solution. Lower bounds on the global and local\nweighting factors are derived under the condition that every interaction\nsubgraph associated with each cluster admits a directed spanning tree. The\nspanning tree requirement is further shown to be a necessary condition when the\nclusters connect acyclically with each other. Simulations for two applications,\ncluster heading alignment of nonidentical ships and cluster phase\nsynchronization of nonidentical harmonic oscillators, illustrate essential\nparts of the derived theoretical results.",
    "descriptor": "\nComments: accepted version by International Journal of Robust and Nonlinear Control\n",
    "authors": [
      "Zhongchang Liu",
      "Wing Shing Wong",
      "Hui Cheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1502.07481"
  },
  {
    "id": "arXiv:2111.02398",
    "title": "Transparency of Deep Neural Networks for Medical Image Analysis: A  Review of Interpretability Methods",
    "abstract": "Artificial Intelligence has emerged as a useful aid in numerous clinical\napplications for diagnosis and treatment decisions. Deep neural networks have\nshown same or better performance than clinicians in many tasks owing to the\nrapid increase in the available data and computational power. In order to\nconform to the principles of trustworthy AI, it is essential that the AI system\nbe transparent, robust, fair and ensure accountability. Current deep neural\nsolutions are referred to as black-boxes due to a lack of understanding of the\nspecifics concerning the decision making process. Therefore, there is a need to\nensure interpretability of deep neural networks before they can be incorporated\nin the routine clinical workflow. In this narrative review, we utilized\nsystematic keyword searches and domain expertise to identify nine different\ntypes of interpretability methods that have been used for understanding deep\nlearning models for medical image analysis applications based on the type of\ngenerated explanations and technical similarities. Furthermore, we report the\nprogress made towards evaluating the explanations produced by various\ninterpretability methods. Finally we discuss limitations, provide guidelines\nfor using interpretability methods and future directions concerning the\ninterpretability of deep neural networks for medical imaging analysis.",
    "descriptor": "",
    "authors": [
      "Zohaib Salahuddin",
      "Henry C Woodruff",
      "Avishek Chatterjee",
      "Philippe Lambin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02398"
  },
  {
    "id": "arXiv:2111.02402",
    "title": "Skin Cancer Classification using Inception Network and Transfer Learning",
    "abstract": "Medical data classification is typically a challenging task due to imbalance\nbetween classes. In this paper, we propose an approach to classify\ndermatoscopic images from HAM10000 (Human Against Machine with 10000 training\nimages) dataset, consisting of seven imbalanced types of skin lesions, with\ngood precision and low resources requirements. Classification is done by using\na pretrained convolutional neural network. We evaluate the accuracy and\nperformance of the proposal and illustrate possible extensions.",
    "descriptor": "\nComments: International Conference on Computational Science and Its Applications, ICCSA 2020\n",
    "authors": [
      "Priscilla Benedetti",
      "Damiano Perri",
      "Marco Simonetti",
      "Osvaldo Gervasi",
      "Gianluca Reali",
      "Mauro Femminella"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02402"
  },
  {
    "id": "arXiv:2111.02403",
    "title": "WORD: Revisiting Organs Segmentation in the Whole Abdominal Region",
    "abstract": "Whole abdominal organs segmentation plays an important role in abdomen lesion\ndiagnosis, radiotherapy planning, and follow-up. However, delineating all\nabdominal organs by oncologists manually is time-consuming and very expensive.\nRecently, deep learning-based medical image segmentation has shown the\npotential to reduce manual delineation efforts, but it still requires a\nlarge-scale fine annotated dataset for training. Although many efforts in this\ntask, there are still few large image datasets covering the whole abdomen\nregion with accurate and detailed annotations for the whole abdominal organ\nsegmentation. In this work, we establish a large-scale \\textit{W}hole abdominal\n\\textit{OR}gans \\textit{D}ataset (\\textit{WORD}) for algorithms research and\nclinical applications development. This dataset contains 150 abdominal CT\nvolumes (30495 slices) and each volume has 16 organs with fine pixel-level\nannotations and scribble-based sparse annotation, which may be the largest\ndataset with whole abdominal organs annotation. Several state-of-the-art\nsegmentation methods are evaluated on this dataset. And, we also invited\nclinical oncologists to revise the model predictions to measure the gap between\nthe deep learning method and real oncologists. We further introduce and\nevaluate a new scribble-based weakly supervised segmentation on this dataset.\nThe work provided a new benchmark for the abdominal multi-organ segmentation\ntask and these experiments can serve as the baseline for future research and\nclinical application development. The codebase and dataset will be released at:\nhttps://github.com/HiLab-git/WORD",
    "descriptor": "\nComments: Tech report (10pages, 4 figures and 7 tables), work is ongoing, any comments and suggestions are welcome, this https URL\n",
    "authors": [
      "Xiangde Luo",
      "Wenjun Liao",
      "Jianghong Xiao",
      "Tao Song",
      "Xiaofan Zhang",
      "Kang Li",
      "Guotai Wang",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02403"
  },
  {
    "id": "arXiv:2111.02408",
    "title": "Partial supervision for the FeTA challenge 2021",
    "abstract": "This paper describes our method for our participation in the FeTA\nchallenge2021 (team name: TRABIT). The performance of convolutional neural\nnetworks for medical image segmentation is thought to correlate positively with\nthe number of training data. The FeTA challenge does not restrict participants\nto using only the provided training data but also allows for using other\npublicly available sources. Yet, open access fetal brain data remains limited.\nAn advantageous strategy could thus be to expand the training data to cover\nbroader perinatal brain imaging sources. Perinatal brain MRIs, other than the\nFeTA challenge data, that are currently publicly available, span normal and\npathological fetal atlases as well as neonatal scans. However, perinatal brain\nMRIs segmented in different datasets typically come with different annotation\nprotocols. This makes it challenging to combine those datasets to train a deep\nneural network. We recently proposed a family of loss functions, the label-set\nloss functions, for partially supervised learning. Label-set loss functions\nallow to train deep neural networks with partially segmented images, i.e.\nsegmentations in which some classes may be grouped into super-classes. We\npropose to use label-set loss functions to improve the segmentation performance\nof a state-of-the-art deep learning pipeline for multi-class fetal brain\nsegmentation by merging several publicly available datasets. To promote\ngeneralisability, our approach does not introduce any additional\nhyper-parameters tuning.",
    "descriptor": "\nComments: Accepted as a poster at the MICCAI 2021 Perinatal, Preterm and Paediatric Image Analysis (PIPPI) workshop\n",
    "authors": [
      "Lucas Fidon",
      "Michael Aertsen",
      "Suprosanna Shit",
      "Philippe Demaerel",
      "S\u00e9bastien Ourselin",
      "Jan Deprest",
      "Tom Vercauteren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02408"
  },
  {
    "id": "arXiv:2111.02409",
    "title": "Breast Cancer Classification Using: Pixel Interpolation",
    "abstract": "Image Processing represents the backbone research area within engineering and\ncomputer science specialization. It is promptly growing technologies today, and\nits applications founded in various aspects of biomedical fields especially in\ncancer disease. Breast cancer is considered the fatal one of all cancer types\naccording to recent statistics all over the world. It is the most commonly\ncancer in women and the second reason of cancer death between females. About\n23% of the total cancer cases in both developing and developed countries. In\nthis work, an interpolation process was used to classify the breast cancer into\nmain types, benign and malignant. This scheme dependent on the morphologic\nspectrum of mammographic masses. Malignant tumors had irregular shape percent\nhigher than the benign tumors. By this way the boundary of the tumor will be\ninterpolated by additional pixels to make the boundary smoothen as possible,\nthese needed pixels is proportional with irregularity shape of the tumor, so\nthat the increasing in interpolated pixels meaning the tumor goes toward the\nmalignant case. The proposed system is implemented using MATLAB programming and\ntested over several images taken from the Mammogram Image Analysis Society\n(MIAS) image database. The MIAS offers a regular classification for\nmammographic studies. The system works faster so that any radiologist can take\na clear decision about the appearance of calcifications by visual inspection.",
    "descriptor": "\nComments: 9 pages, 9 figures, Acta Scientific Computer Sciences\n",
    "authors": [
      "Osama Rezq Shahin",
      "Hamdy Mohammed Kelash",
      "Gamal Mahrous Attiya",
      "Osama Slah Farg Allah"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02409"
  },
  {
    "id": "arXiv:2111.02426",
    "title": "Weighted Quantum Channel Compiling through Proximal Policy Optimization",
    "abstract": "We propose a general and systematic strategy to compile arbitrary quantum\nchannels without using ancillary qubits, based on proximal policy optimization\n-- a powerful deep reinforcement learning algorithm. We rigorously prove that,\nin sharp contrast to the case of compiling unitary gates, it is impossible to\ncompile an arbitrary channel to arbitrary precision with any given finite\nelementary channel set, regardless of the length of the decomposition sequence.\nHowever, for a fixed accuracy $\\epsilon$ one can construct a universal set with\nconstant number of $\\epsilon$-dependent elementary channels, such that an\narbitrary quantum channel can be decomposed into a sequence of these elementary\nchannels followed by a unitary gate, with the sequence length bounded by\n$O(\\frac{1}{\\epsilon}\\log\\frac{1}{\\epsilon})$. Through a concrete example\nconcerning topological compiling of Majorana fermions, we show that our\nproposed algorithm can conveniently and effectively reduce the use of expensive\nelementary gates through adding the weighted cost into the reward function of\nthe proximal policy optimization.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Weiyuan Gong",
      "Si Jiang",
      "Dong-Ling Deng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02426"
  },
  {
    "id": "arXiv:2111.02449",
    "title": "Effective Resistance for Pandemics: Mobility Network Sparsification for  High-Fidelity Epidemic Simulation",
    "abstract": "Network science has increasingly become central to the field of epidemiology\nand our ability to respond to infectious disease threats. However, many\nnetworks derived from modern datasets are very dense, such as mobility networks\nwhere each location has links to a large number of destinations. As a result,\nsimulating large-scale epidemics using data-driven networks requires\nsubstantial computational resources and in many cases is practically\ninfeasible. One way to reduce the computational cost of simulating epidemics on\nthese networks is sparsification, where a representative subset of edges is\nselected based on some measure of their importance. We test several\nsparsification strategies, ranging from naive thresholding to random sampling\nof edges, on mobility data from the U.S. Following recent work in computer\nscience, we find that the most accurate approach uses the effective resistances\nof edges, which prioritizes edges that are the only efficient way to travel\nbetween their endpoints. The resulting sparse network preserves many aspects of\nthe behavior of an SIR model, including global quantities, like the epidemic\nsize, and details of stochastic events at individual nodes, including the\nprobability each node becomes infected and its distribution of arrival times.\nThis holds even when the sparse network preserves fewer than $10\\%$ of the\nedges of the original network. In addition to its practical utility, this\nmethod helps illuminate which links of a weighted, undirected network are most\nimportant to disease spread.",
    "descriptor": "",
    "authors": [
      "Alexander M. Mercier",
      "Samuel V. Scarpino",
      "Cristopher Moore"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.02449"
  },
  {
    "id": "arXiv:2111.02458",
    "title": "Perturb-and-max-product: Sampling and learning in discrete energy-based  models",
    "abstract": "Perturb-and-MAP offers an elegant approach to approximately sample from a\nenergy-based model (EBM) by computing the maximum-a-posteriori (MAP)\nconfiguration of a perturbed version of the model. Sampling in turn enables\nlearning. However, this line of research has been hindered by the general\nintractability of the MAP computation. Very few works venture outside tractable\nmodels, and when they do, they use linear programming approaches, which as we\nwill show, have several limitations. In this work we present\nperturb-and-max-product (PMP), a parallel and scalable mechanism for sampling\nand learning in discrete EBMs. Models can be arbitrary as long as they are\nbuilt using tractable factors. We show that (a) for Ising models, PMP is orders\nof magnitude faster than Gibbs and Gibbs-with-Gradients (GWG) at learning and\ngenerating samples of similar or better quality; (b) PMP is able to learn and\nsample from RBMs; (c) in a large, entangled graphical model in which Gibbs and\nGWG fail to mix, PMP succeeds.",
    "descriptor": "",
    "authors": [
      "Miguel Lazaro-Gredilla",
      "Antoine Dedieu",
      "Dileep George"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02458"
  },
  {
    "id": "arXiv:2111.02461",
    "title": "Automatic ultrasound vessel segmentation with deep spatiotemporal  context learning",
    "abstract": "Accurate, real-time segmentation of vessel structures in ultrasound image\nsequences can aid in the measurement of lumen diameters and assessment of\nvascular diseases. This, however, remains a challenging task, particularly for\nextremely small vessels that are difficult to visualize. We propose to leverage\nthe rich spatiotemporal context available in ultrasound to improve segmentation\nof small-scale lower-extremity arterial vasculature. We describe efficient deep\nlearning methods that incorporate temporal, spatial, and feature-aware\ncontextual embeddings at multiple resolution scales while jointly utilizing\ninformation from B-mode and Color Doppler signals. Evaluating on femoral and\ntibial artery scans performed on healthy subjects by an expert\nultrasonographer, and comparing to consensus expert ground-truth annotations of\ninner lumen boundaries, we demonstrate real-time segmentation using the\ncontext-aware models and show that they significantly outperform comparable\nbaseline approaches.",
    "descriptor": "",
    "authors": [
      "Baichuan Jiang",
      "Alvin Chen",
      "Shyam Bharat",
      "Mingxin Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02461"
  },
  {
    "id": "arXiv:2111.02467",
    "title": "Fundamental limitations on device-independent quantum conference key  agreement",
    "abstract": "We provide several general upper bounds on device-independent conference key\nagreement (DI-CKA) against the quantum adversary. They include bounds by\nreduced entanglement measures and those based on multipartite secrecy monotones\nsuch as reduced cc-squashed entanglement. We compare the latter bound with the\nknown lower bound for the protocol of conference key distillation based on the\nparity-CHSH game. We also show that the gap between DI-CKA rate and the rate of\ndevice-dependent is inherited from the bipartite gap between device-independent\nand device-dependent key rates, giving examples that exhibit the strict gap.",
    "descriptor": "\nComments: 15 pages, 2 figures. See also the parallel work by Aby Philip, Eneet Kaur, Peter Bierhorst, and Mark M. Wilde titled \"Intrinsic Non-Locality and Device-Independent Conference Key Agreement\" appearing on arXiv along with this work\n",
    "authors": [
      "Karol Horodecki",
      "Marek Winczewski",
      "Siddhartha Das"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.02467"
  },
  {
    "id": "arXiv:2111.02493",
    "title": "Roadmap on Signal Processing for Next Generation Measurement Systems",
    "abstract": "Signal processing is a fundamental component of almost any sensor-enabled\nsystem, with a wide range of applications across different scientific\ndisciplines. Time series data, images, and video sequences comprise\nrepresentative forms of signals that can be enhanced and analysed for\ninformation extraction and quantification. The recent advances in artificial\nintelligence and machine learning are shifting the research attention towards\nintelligent, data-driven, signal processing. This roadmap presents a critical\noverview of the state-of-the-art methods and applications aiming to highlight\nfuture challenges and research opportunities towards next generation\nmeasurement systems. It covers a broad spectrum of topics ranging from basic to\nindustrial research, organized in concise thematic sections that reflect the\ntrends and the impacts of current and future developments per research field.\nFurthermore, it offers guidance to researchers and funding agencies in\nidentifying new prospects.",
    "descriptor": "\nComments: Pre-print accepted for open access publication in Measurement Science and Technology\n",
    "authors": [
      "D.K. Iakovidis",
      "M. Ooi",
      "Y.C. Kuang",
      "S. Damidenko",
      "A. Shestakov",
      "V. Sinistin",
      "M. Henry",
      "A. Sciacchitano",
      "A. Discetti",
      "S. Donati",
      "M. Norgia",
      "A. Menychtas",
      "I. Maglogiannis",
      "S.C. Wriessnegger",
      "L.A. Barradas Chacon",
      "G. Dimas",
      "D. Filos",
      "A.H. Aletras",
      "J. T\u00f6ger",
      "F. Dong",
      "S. Ren",
      "A. Uhl",
      "J. Paziewski",
      "J. Geng",
      "F. Fioranelli",
      "R.M. Narayanan",
      "C. Fernandez",
      "C. Stiller",
      "K. Malamousi",
      "S. Kamnis",
      "K. Delibasis",
      "D. Wang",
      "J. Zhang",
      "R.X. Gao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2111.02493"
  },
  {
    "id": "arXiv:2111.02520",
    "title": "Resampling and super-resolution of hexagonally sampled images using deep  learning",
    "abstract": "Super-resolution (SR) aims to increase the resolution of imagery.\nApplications include security, medical imaging, and object recognition. We\npropose a deep learning-based SR system that takes a hexagonally sampled\nlow-resolution image as an input and generates a rectangularly sampled SR image\nas an output. For training and testing, we use a realistic observation model\nthat includes optical degradation from diffraction and sensor degradation from\ndetector integration. Our SR approach first uses non-uniform interpolation to\npartially upsample the observed hexagonal imagery and convert it to a\nrectangular grid. We then leverage a state-of-the-art convolutional neural\nnetwork (CNN) architecture designed for SR known as Residual Channel Attention\nNetwork (RCAN). In particular, we use RCAN to further upsample and restore the\nimagery to produce the final SR image estimate. We demonstrate that this system\nis superior to applying RCAN directly to rectangularly sampled LR imagery with\nequivalent sample density. The theoretical advantages of hexagonal sampling are\nwell known. However, to the best of our knowledge, the practical benefit of\nhexagonal sampling in light of modern processing techniques such as RCAN SR is\nheretofore untested. Our SR system demonstrates a notable advantage of\nhexagonally sampled imagery when employing a modified RCAN for hexagonal SR.",
    "descriptor": "\nComments: 31 pages, 16 figures, 5 tables. \\c{opyright} 2021 Society of Photo-Optical Instrumentation Engineers (SPIE)\n",
    "authors": [
      "Dylan Flaute",
      "Russell C. Hardie",
      "Hamed Elwarfalli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02520"
  },
  {
    "id": "arXiv:2111.02592",
    "title": "Conformal prediction for text infilling and part-of-speech prediction",
    "abstract": "Modern machine learning algorithms are capable of providing remarkably\naccurate point-predictions; however, questions remain about their statistical\nreliability. Unlike conventional machine learning methods, conformal prediction\nalgorithms return confidence sets (i.e., set-valued predictions) that\ncorrespond to a given significance level. Moreover, these confidence sets are\nvalid in the sense that they guarantee finite sample control over type 1 error\nprobabilities, allowing the practitioner to choose an acceptable error rate. In\nour paper, we propose inductive conformal prediction (ICP) algorithms for the\ntasks of text infilling and part-of-speech (POS) prediction for natural\nlanguage data. We construct new conformal prediction-enhanced bidirectional\nencoder representations from transformers (BERT) and bidirectional long\nshort-term memory (BiLSTM) algorithms for POS tagging and a new conformal\nprediction-enhanced BERT algorithm for text infilling. We analyze the\nperformance of the algorithms in simulations using the Brown Corpus, which\ncontains over 57,000 sentences. Our results demonstrate that the ICP algorithms\nare able to produce valid set-valued predictions that are small enough to be\napplicable in real-world applications. We also provide a real data example for\nhow our proposed set-valued predictions can improve machine generated audio\ntranscriptions.",
    "descriptor": "",
    "authors": [
      "Neil Dey",
      "Jing Ding",
      "Jack Ferrell",
      "Carolina Kapper",
      "Maxwell Lovig",
      "Emiliano Planchon",
      "Jonathan P Williams"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02592"
  },
  {
    "id": "arXiv:2111.02595",
    "title": "An Information-Theoretic Framework for Identifying Age-Related Genes  Using Human Dermal Fibroblast Transcriptome Data",
    "abstract": "Investigation of age-related genes is of great importance for multiple\npurposes, for instance, improving our understanding of the mechanism of ageing,\nincreasing life expectancy, age prediction, and other healthcare applications.\nIn his work, starting with a set of 27,142 genes, we develop an\ninformation-theoretic framework for identifying genes that are associated with\naging by applying unsupervised and semi-supervised learning techniques on human\ndermal fibroblast gene expression data. First, we use unsupervised learning and\napply information-theoretic measures to identify key features for effective\nrepresentation of gene expression values in the transcriptome data. Using the\nidentified features, we perform clustering on the data. Finally, we apply\nsemi-supervised learning on the clusters using different distance measures to\nidentify novel genes that are potentially associated with aging. Performance\nassessment for both unsupervised and semi-supervised methods show the\neffectiveness of the framework.",
    "descriptor": "\nComments: 8 pages, 1 figure, Accepted to 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)\n",
    "authors": [
      "Salman Mohamadi",
      "Donald Adjeroh"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02595"
  },
  {
    "id": "arXiv:2111.02601",
    "title": "Optimal Recovery from Inaccurate Data in Hilbert Spaces: Regularize, but  what of the Parameter?",
    "abstract": "In Optimal Recovery, the task of learning a function from observational data\nis tackled deterministically by adopting a worst-case perspective tied to an\nexplicit model assumption made on the functions to be learned. Working in the\nframework of Hilbert spaces, this article considers a model assumption based on\napproximability. It also incorporates observational inaccuracies modeled via\nadditive errors bounded in $\\ell_2$. Earlier works have demonstrated that\nregularization provide algorithms that are optimal in this situation, but did\nnot fully identify the desired hyperparameter. This article fills the gap in\nboth a local scenario and a global scenario. In the local scenario, which\namounts to the determination of Chebyshev centers, the semidefinite recipe of\nBeck and Eldar (legitimately valid in the complex setting only) is complemented\nby a more direct approach, with the proviso that the observational functionals\nhave orthonormal representers. In the said approach, the desired parameter is\nthe solution to an equation that can be resolved via standard methods. In the\nglobal scenario, where linear algorithms rule, the parameter elusive in the\nworks of Micchelli et al. is found as the byproduct of a semidefinite program.\nAdditionally and quite surprisingly, in case of observational functionals with\northonormal representers, it is established that any regularization parameter\nis optimal.",
    "descriptor": "",
    "authors": [
      "Simon Foucart",
      "Chunyang Liao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02601"
  },
  {
    "id": "arXiv:2111.02636",
    "title": "A control method for solving high-dimensional Hamiltonian systems  through deep neural networks",
    "abstract": "In this paper, we mainly focus on solving high-dimensional stochastic\nHamiltonian systems with boundary condition, and propose a novel method from\nthe view of the stochastic control. In order to obtain the approximated\nsolution of the Hamiltonian system, we first introduce a corresponding\nstochastic optimal control problem such that the Hamiltonian system of control\nproblem is exactly what we need to solve, then develop two different algorithms\nsuitable for different cases of the control problem and approximate the\nstochastic control via deep neural networks. From the numerical results,\ncomparing with the Deep FBSDE method which was developed previously from the\nview of solving FBSDEs, the novel algorithms converge faster, which means that\nthey require fewer training steps, and demonstrate more stable convergences for\ndifferent Hamiltonian systems.",
    "descriptor": "",
    "authors": [
      "Shaolin Ji",
      "Shige Peng",
      "Ying Peng",
      "Xichuan Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02636"
  },
  {
    "id": "arXiv:2111.02645",
    "title": "Global Controllability for General Nonlinear Systems",
    "abstract": "This note studies the global controllability of a general nonlinear system by\nextending it to affine one. The state space of the obtained affine system\nadmits a nature foliation, each leaf of which is diffeomorphic to the state\nspace of the original system. Through this foliation, the global\ncontrollability of these two kinds of systems are closely related and we prove\nthat they are indeed equivalent. The result is then extended to the case with\nbounded inputs to make it practically more useful. To demonstrate the power of\nour approach, several examples are presented.",
    "descriptor": "",
    "authors": [
      "Yuanyuan Liu",
      "Wei Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02645"
  },
  {
    "id": "arXiv:2111.02666",
    "title": "Sensory attenuation develops as a result of sensorimotor experience",
    "abstract": "The brain attenuates its responses to self-produced exteroceptions (e.g., we\ncannot tickle ourselves). Is this phenomenon, called sensory attenuation,\nenabled innately, or is it acquired through learning? To explore the latter\npossibility, we created a neural network model consisting of sensory\n(proprioceptive and exteroceptive), association, and executive areas. A\nsimulated robot controlled by the network learned to acquire motor patterns\nwith self-produced or externally produced exteroceptive feedback. We found that\nthe robot first increased responses in sensory and association areas for both\nself-produced and externally produced conditions in the early stage of\nlearning, but then, gradually it attenuated responses in sensory areas only for\nself-produced conditions. The robot spontaneously acquired a capacity to switch\n(attenuate or amplify) responses in sensory areas depending on the conditions\nby switching the neural state of the executive area. This suggests that\nproactive control of sensory-information flow inside the network was\nself-organized through learning. We also found that innate alterations in the\nmodulation of sensory-information flow induced some characteristics analogous\nto schizophrenia and autism spectrum disorder. This study provides a novel\nperspective on neural mechanisms underlying perceptual phenomena and\npsychiatric disorders.",
    "descriptor": "",
    "authors": [
      "Hayato Idei",
      "Wataru Ohata",
      "Yuichi Yamashita",
      "Tetsuya Ogata",
      "Jun Tani"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.02666"
  },
  {
    "id": "arXiv:2111.02674",
    "title": "Voice Conversion Can Improve ASR in Very Low-Resource Settings",
    "abstract": "Voice conversion (VC) has been proposed to improve speech recognition systems\nin low-resource languages by using it to augment limited training data. But\nuntil recently, practical issues such as compute speed have limited the use of\nVC for this purpose. Moreover, it is still unclear whether a VC model trained\non one well-resourced language can be applied to speech from another\nlow-resource language for the purpose of data augmentation. In this work we\nassess whether a VC system can be used cross-lingually to improve low-resource\nspeech recognition. Concretely, we combine several recent techniques to design\nand train a practical VC system in English, and then use this system to augment\ndata for training a speech recognition model in several low-resource languages.\nWe find that when using a sensible amount of augmented data, speech recognition\nperformance is improved in all four low-resource languages considered.",
    "descriptor": "\nComments: 5 page, 4 tables, 2 figures. Submitted to ICASSP 2022\n",
    "authors": [
      "Matthew Baas",
      "Herman Kamper"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.02674"
  },
  {
    "id": "arXiv:2111.02676",
    "title": "A semi-automatic ultrasound image analysis system for the grading  diagnosis of COVID-19 pneumonia",
    "abstract": "This paper proposes a semi-automatic system based on quantitative\ncharacterization of the specific image patterns in lung ultrasound (LUS)\nimages, in order to assess the lung conditions of patients with COVID-19\npneumonia, as well as to differentiate between the severe / and no-severe\ncases. Specifically, four parameters are extracted from each LUS image, namely\nthe thickness (TPL) and roughness (RPL) of the pleural line, and the\naccumulated with (AWBL) and acoustic coefficient (ACBL) of B lines. 27 patients\nare enrolled in this study, which are grouped into 13 moderate patients, 7\nsevere patients and 7 critical patients. Furthermore, the severe and critical\npatients are regarded as the severe cases, and the moderate patients are\nregarded as the non-severe cases. Biomarkers among different groups are\ncompared. Each single biomarker and a classifier with all the biomarkers as\ninput are utilized for the binary diagnosis of severe case and non-severe case,\nrespectively. The classifier achieves the best classification performance among\nall the compared methods (area under the receiver operating characteristics\ncurve = 0.93, sensitivity = 0.93, specificity = 0.85). The proposed image\nanalysis system could be potentially applied to the grading and prognosis\nevaluation of patients with COVID-19 pneumonia.",
    "descriptor": "",
    "authors": [
      "Yuanyuan Wang",
      "Yao Zhang",
      "Qiong He",
      "Hongen Liao",
      "Jianwen Luo"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.02676"
  },
  {
    "id": "arXiv:2111.02692",
    "title": "Human Age Estimation from Gene Expression Data using Artificial Neural  Networks",
    "abstract": "The study of signatures of aging in terms of genomic biomarkers can be\nuniquely helpful in understanding the mechanisms of aging and developing models\nto accurately predict the age. Prior studies have employed gene expression and\nDNA methylation data aiming at accurate prediction of age. In this line, we\npropose a new framework for human age estimation using information from human\ndermal fibroblast gene expression data. First, we propose a new spatial\nrepresentation as well as a data augmentation approach for gene expression\ndata. Next in order to predict the age, we design an architecture of neural\nnetwork and apply it to this new representation of the original and augmented\ndata, as an ensemble classification approach. Our experimental results suggest\nthe superiority of the proposed framework over state-of-the-art age estimation\nmethods using DNA methylation and gene expression data.",
    "descriptor": "\nComments: 8 pages, 5 figures, This paper is accepted to 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)\n",
    "authors": [
      "Salman Mohamadi",
      "Gianfranco.Doretto",
      "Nasser M. Nasrabadi",
      "Donald A. Adjeroh"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02692"
  },
  {
    "id": "arXiv:2111.02702",
    "title": "Ex$^2$MCMC: Sampling through Exploration Exploitation",
    "abstract": "We develop an Explore-Exploit Markov chain Monte Carlo algorithm\n($\\operatorname{Ex^2MCMC}$) that combines multiple global proposals and local\nmoves. The proposed method is massively parallelizable and extremely\ncomputationally efficient. We prove $V$-uniform geometric ergodicity of\n$\\operatorname{Ex^2MCMC}$ under realistic conditions and compute explicit\nbounds on the mixing rate showing the improvement brought by the multiple\nglobal moves. We show that $\\operatorname{Ex^2MCMC}$ allows fine-tuning of\nexploitation (local moves) and exploration (global moves) via a novel approach\nto proposing dependent global moves. Finally, we develop an adaptive scheme,\n$\\operatorname{FlEx^2MCMC}$, that learns the distribution of global moves using\nnormalizing flows. We illustrate the efficiency of $\\operatorname{Ex^2MCMC}$\nand its adaptive versions on many classical sampling benchmarks. We also show\nthat these algorithms improve the quality of sampling GANs as energy-based\nmodels.",
    "descriptor": "",
    "authors": [
      "Evgeny Lagutin",
      "Daniil Selikhanovych",
      "Achille Thin",
      "Sergey Samsonov",
      "Alexey Naumov",
      "Denis Belomestny",
      "Maxim Panov",
      "Eric Moulines"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02702"
  },
  {
    "id": "arXiv:2111.02708",
    "title": "Quasi-Newton Methods for Saddle Point Problems",
    "abstract": "This paper studies quasi-Newton methods for solving\nstrongly-convex-strongly-concave saddle point problems (SPP). We propose a\nvariant of general greedy Broyden family update for SPP, which has explicit\nlocal superlinear convergence rate of ${\\mathcal\nO}\\big(\\big(1-\\frac{1}{n\\kappa^2}\\big)^{k(k-1)/2}\\big)$, where $n$ is\ndimensions of the problem, $\\kappa$ is the condition number and $k$ is the\nnumber of iterations. The design and analysis of proposed algorithm are based\non estimating the square of indefinite Hessian matrix, which is different from\nclassical quasi-Newton methods in convex optimization. We also present two\nspecific Broyden family algorithms with BFGS-type and SR1-type updates, which\nenjoy the faster local convergence rate of $\\mathcal\nO\\big(\\big(1-\\frac{1}{n}\\big)^{k(k-1)/2}\\big)$.",
    "descriptor": "",
    "authors": [
      "Chengchang Liu",
      "Luo Luo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02708"
  },
  {
    "id": "arXiv:2111.02710",
    "title": "Towards dynamic multi-modal phenotyping using chest radiographs and  physiological data",
    "abstract": "The healthcare domain is characterized by heterogeneous data modalities, such\nas imaging and physiological data. In practice, the variety of medical data\nassists clinicians in decision-making. However, most of the current\nstate-of-the-art deep learning models solely rely upon carefully curated data\nof a single modality. In this paper, we propose a dynamic training approach to\nlearn modality-specific data representations and to integrate auxiliary\nfeatures, instead of solely relying on a single modality. Our preliminary\nexperiments results for a patient phenotyping task using physiological data in\nMIMIC-IV & chest radiographs in the MIMIC- CXR dataset show that our proposed\napproach achieves the highest area under the receiver operating characteristic\ncurve (AUROC) (0.764 AUROC) compared to the performance of the benchmark method\nin previous work, which only used physiological data (0.740 AUROC). For a set\nof five recurring or chronic diseases with periodic acute episodes, including\ncardiac dysrhythmia, conduction disorders, and congestive heart failure, the\nAUROC improves from 0.747 to 0.798. This illustrates the benefit of leveraging\nthe chest imaging modality in the phenotyping task and highlights the potential\nof multi-modal learning in medical applications.",
    "descriptor": "\nComments: Accepted in medical imaging meets NeurIPS 2021\n",
    "authors": [
      "Nasir Hayat",
      "Krzysztof J. Geras",
      "Farah E. Shamout"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02710"
  },
  {
    "id": "arXiv:2111.02763",
    "title": "A Riemannian Accelerated Proximal Extragradient Framework and its  Implications",
    "abstract": "The study of accelerated gradient methods in Riemannian optimization has\nrecently witnessed notable progress. However, in contrast with the Euclidean\nsetting, a systematic understanding of acceleration is still lacking in the\nRiemannian setting. We revisit the \\emph{Accelerated Hybrid Proximal\nExtragradient} (A-HPE) method of \\citet{monteiro2013accelerated}, a powerful\nframework for obtaining accelerated Euclidean methods. Subsequently, we propose\na Riemannian version of A-HPE. The basis of our analysis of Riemannian A-HPE is\na set of insights into Euclidean A-HPE, which we combine with a careful control\nof distortion caused by Riemannian geometry. We describe a number of Riemannian\naccelerated gradient methods as concrete instances of our framework.",
    "descriptor": "",
    "authors": [
      "Jikai Jin",
      "Suvrit Sra"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.02763"
  },
  {
    "id": "arXiv:2111.02771",
    "title": "The role of MRI physics in brain segmentation CNNs: achieving  acquisition invariance and instructive uncertainties",
    "abstract": "Being able to adequately process and combine data arising from different\nsites is crucial in neuroimaging, but is difficult, owing to site, sequence and\nacquisition-parameter dependent biases. It is important therefore to design\nalgorithms that are not only robust to images of differing contrasts, but also\nbe able to generalise well to unseen ones, with a quantifiable measure of\nuncertainty. In this paper we demonstrate the efficacy of a physics-informed,\nuncertainty-aware, segmentation network that employs augmentation-time MR\nsimulations and homogeneous batch feature stratification to achieve acquisition\ninvariance. We show that the proposed approach also accurately extrapolates to\nout-of-distribution sequence samples, providing well calibrated volumetric\nbounds on these. We demonstrate a significant improvement in terms of\ncoefficients of variation, backed by uncertainty based volumetric validation.",
    "descriptor": "\nComments: 10 pages, 3 figures, published in: Simulation and Synthesis in Medical Imaging 6th International Workshop, SASHIMI 2021, Held in Conjunction with MICCAI 2021, Strasbourg, France, September 27, 2021, Proceedings\n",
    "authors": [
      "Pedro Borges",
      "Richard Shaw",
      "Thomas Varsavsky",
      "Kerstin Klaser",
      "David Thomas",
      "Ivana Drobnjak",
      "Sebastien Ourselin",
      "M Jorge Cardoso"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.02771"
  },
  {
    "id": "arXiv:2111.02773",
    "title": "Danzer's Problem, Effective Constructions of Dense Forests and Digital  Sequences",
    "abstract": "A 1965 problem due to Danzer asks whether there exists a set in Euclidean\nspace with finite density intersecting any convex body of volume one. A recent\napproach to this problem is concerned with the construction of dense forests\nand is obtained by a suitable weakening of the volume constraint. A dense\nforest is a discrete point set of finite density getting uniformly close to\nlong enough line segments. The distribution of points in a dense forest is then\nquantified in terms of a visibility function. Another way to weaken the\nassumptions in Danzer's problem is by relaxing the density constraint. In this\nrespect, a new concept is introduced in this paper, namely that of an optical\nforest. An optical forest in $\\mathbb{R}^{d}$ is a point set with optimal\nvisibility but not necessarily with finite density. In the literature, the best\nconstructions of Danzer sets and dense forests lack effectivity. The goal of\nthis paper is to provide constructions of dense and optical forests which yield\nthe best known results in any dimension $d \\ge 2$ both in terms of visibility\nand density bounds and effectiveness. Namely, there are three main results in\nthis work: (1) the construction of a dense forest with the best known\nvisibility bound which, furthermore, enjoys the property of being\ndeterministic; (2) the deterministic construction of an optical forest with a\ndensity failing to be finite only up to a logarithm and (3) the construction of\na planar Peres-type forest (that is, a dense forest obtained from a\nconstruction due to Peres) with the best known visibility bound. This is\nachieved by constructing a deterministic digital sequence satisfying strong\ndispersion properties.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Ioannis Tsokanos"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2111.02773"
  },
  {
    "id": "arXiv:2111.02802",
    "title": "Distributed Sparse Feature Selection in Communication-Restricted  Networks",
    "abstract": "This paper aims to propose and theoretically analyze a new distributed scheme\nfor sparse linear regression and feature selection. The primary goal is to\nlearn the few causal features of a high-dimensional dataset based on noisy\nobservations from an unknown sparse linear model. However, the presumed\ntraining set which includes $n$ data samples in $\\mathbb{R}^p$ is already\ndistributed over a large network with $N$ clients connected through extremely\nlow-bandwidth links. Also, we consider the asymptotic configuration of $1\\ll\nN\\ll n\\ll p$. In order to infer the causal dimensions from the whole dataset,\nwe propose a simple, yet effective method for information sharing in the\nnetwork. In this regard, we theoretically show that the true causal features\ncan be reliably recovered with negligible bandwidth usage of $O\\left(N\\log\np\\right)$ across the network. This yields a significantly lower communication\ncost in comparison with the trivial case of transmitting all the samples to a\nsingle node (centralized scenario), which requires $O\\left(np\\right)$\ntransmissions. Even more sophisticated schemes such as ADMM still have a\ncommunication complexity of $O\\left(Np\\right)$. Surprisingly, our sample\ncomplexity bound is proved to be the same (up to a constant factor) as the\noptimal centralized approach for a fixed performance measure in each node,\nwhile that of a na\\\"{i}ve decentralized technique grows linearly with $N$.\nTheoretical guarantees in this paper are based on the recent analytic framework\nof debiased LASSO in Javanmard et al. (2019), and are supported by several\ncomputer experiments performed on both synthetic and real-world datasets.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Signal Processing, 14 pages\n",
    "authors": [
      "Hanie Barghi",
      "Amir Najafi",
      "Seyed Abolfazl Motahari"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02802"
  },
  {
    "id": "arXiv:2111.02834",
    "title": "Optimal Pairs Trading with Time-Varying Volatility",
    "abstract": "We propose a pairs trading model that incorporates a time-varying volatility\nof the Constant Elasticity of Variance type. Our approach is based on\nstochastic control techniques; given a fixed time horizon and a portfolio of\ntwo co-integrated assets, we define the trading strategies as the portfolio\nweights maximizing the expected power utility from terminal wealth. We compute\nthe optimal pairs strategies by using a Finite Difference method. Finally, we\nillustrate our results by conducting tests on historical market data at daily\nfrequency. The parameters are estimated by the Generalized Method of Moments.",
    "descriptor": "",
    "authors": [
      "T. N. Li",
      "A. Tourin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2111.02834"
  },
  {
    "id": "arXiv:2111.02842",
    "title": "Adversarial Attacks on Graph Classification via Bayesian Optimisation",
    "abstract": "Graph neural networks, a popular class of models effective in a wide range of\ngraph-based learning tasks, have been shown to be vulnerable to adversarial\nattacks. While the majority of the literature focuses on such vulnerability in\nnode-level classification tasks, little effort has been dedicated to analysing\nadversarial attacks on graph-level classification, an important problem with\nnumerous real-life applications such as biochemistry and social network\nanalysis. The few existing methods often require unrealistic setups, such as\naccess to internal information of the victim models, or an impractically-large\nnumber of queries. We present a novel Bayesian optimisation-based attack method\nfor graph classification models. Our method is black-box, query-efficient and\nparsimonious with respect to the perturbation applied. We empirically validate\nthe effectiveness and flexibility of the proposed method on a wide range of\ngraph classification tasks involving varying graph properties, constraints and\nmodes of attack. Finally, we analyse common interpretable patterns behind the\nadversarial samples produced, which may shed further light on the adversarial\nrobustness of graph classification models.",
    "descriptor": "\nComments: NeurIPS 2021. 11 pages, 8 figures, 2 tables (24 pages, 17 figures, 8 tables including references and appendices)\n",
    "authors": [
      "Xingchen Wan",
      "Henry Kenlay",
      "Binxin Ru",
      "Arno Blaas",
      "Michael A. Osborne",
      "Xiaowen Dong"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02842"
  },
  {
    "id": "arXiv:2111.02871",
    "title": "Polymer-based composites for engineering organic memristive devices",
    "abstract": "Memristive materials are related to neuromorphic applications as they can\ncombine information processing with memory storage in a single computational\nelement, just as biological neurons. Many of these bioinspired materials\nemulate the characteristics of memory and learning processes that happen in the\nbrain. In this work, we report the memristive properties of a two-terminal\n(2-T) organic device based on ionic migration mediated by an ion-transport\npolymer. The material possesses unique memristive properties: it is reversibly\nswitchable, shows tens of conductive states, presents Hebbian learning\ndemonstrated by spiking time dependent plasticity (STDP), and behaves with both\nshort- (STM) and long-term memory (LTM) in a single device. The origin and\nsynergy of both learning phenomena were theoretically explained by means of the\nchemical interaction between ionic electrolytes and the ion-conductive\nmediator. Further discussion on the transport mechanism was included to explain\nthe dynamic behaviour of these ionic devices under a variable electric field.\nWe propose this polymer-based composite as an outstanding neuromorphic material\nfor being tunable, cheap, flexible, easy to process, reproducible, and more\nbiocompatible than their inorganic analogues.",
    "descriptor": "\nComments: 20 pages main document, 10 pages SI\n",
    "authors": [
      "Carlos David Prado-Socorro",
      "Silvia Gim\u00e9nez-Santamarina",
      "Lorenzo Mardegan",
      "Luis Escalera-Moreno",
      "Henk J. Bolink",
      "Salvador Cardona-Serra",
      "Eugenio Coronado"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.02871"
  },
  {
    "id": "arXiv:2111.02893",
    "title": "Symmetry-Aware Autoencoders: s-PCA and s-nlPCA",
    "abstract": "Nonlinear principal component analysis (nlPCA) via autoencoders has attracted\nattention in the dynamical systems community due to its larger compression rate\nwhen compared to linear principal component analysis (PCA). These model\nreduction methods experience an increase in the dimensionality of the latent\nspace when applied to datasets that exhibit globally invariant samples due to\nthe presence of symmetries. In this study, we introduce a novel machine\nlearning embedding in the autoencoder, which uses spatial transformer networks\nand Siamese networks to account for continuous and discrete symmetries,\nrespectively. The spatial transformer network discovers the optimal shift for\nthe continuous translation or rotation so that invariant samples are aligned in\nthe periodic directions. Similarly, the Siamese networks collapse samples that\nare invariant under discrete shifts and reflections. Thus, the proposed\nsymmetry-aware autoencoder is invariant to predetermined input transformations\ndictating the dynamics of the underlying physical system. This embedding can be\nemployed with both linear and nonlinear reduction methods, which we term\nsymmetry-aware PCA (s-PCA) and symmetry-aware nlPCA (s-nlPCA). We apply the\nproposed framework to 3 fluid flow problems: Burgers' equation, the simulation\nof the flow through a step diffuser and the Kolmogorov flow to showcase the\ncapabilities for cases exhibiting only continuous symmetries, only discrete\nsymmetries or a combination of both.",
    "descriptor": "\nComments: 29 pages, 24 Figures, 6 Tables\n",
    "authors": [
      "Simon Kneer",
      "Taraneh Sayadi",
      "Denis Sipp",
      "Peter Schmid",
      "Georgios Rigas"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.02893"
  },
  {
    "id": "arXiv:2111.02930",
    "title": "Decoupled coordinates for machine learning-based molecular fragment  linking",
    "abstract": "Recent developments in machine-learning based molecular fragment linking have\ndemonstrated the importance of informing the generation process with structural\ninformation specifying the relative orientation of the fragments to be linked.\nHowever, such structural information has not yet been provided in the form of a\ncomplete relative coordinate system. Mathematical details for a decoupled set\nof bond lengths, bond angles and torsion angles are elaborated and the\ncoordinate system is demonstrated to be complete. Significant impact on the\nquality of the generated linkers is demonstrated numerically. The amount of\nreliable information within the different types of degrees of freedom is\ninvestigated. Ablation studies and an information-theoretical analysis are\nperformed. The presented benefits suggest the application of a complete and\ndecoupled relative coordinate system as a standard good practice in linker\ndesign.",
    "descriptor": "\nComments: 16 pages, 5 Figures\n",
    "authors": [
      "Markus Fleck",
      "Noah Weber",
      "Christopher Trummer"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02930"
  },
  {
    "id": "arXiv:2111.02939",
    "title": "Effective weak and vague convergence of measures on the real line",
    "abstract": "We expand our effective framework for weak convergence of measures on the\nreal line by showing that effective convergence in the Prokhorov metric is\nequivalent to effective weak convergence. In addition, we establish a framework\nfor the study of the effective theory of vague convergence of measures. We\nintroduce a uniform notion and a non-uniform notion of vague convergence, and\nwe show that both these notions are equivalent. However, limits under effective\nvague convergence may not be computable even when they are finite. We give an\nexample of a finite incomputable effective vague limit measure, and we provide\na necessary and sufficient condition so that effective vague convergence\nproduces a computable limit. Finally, we determine a sufficient condition for\nwhich effective weak and vague convergence of measures coincide. As a\ncorollary, we obtain an effective version of the equivalence between classical\nweak and vague convergence of sequences of probability measures.",
    "descriptor": "",
    "authors": [
      "Diego A. Rojas"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.02939"
  },
  {
    "id": "arXiv:2111.02960",
    "title": "Use of low-fidelity models with machine-learning error correction for  well placement optimization",
    "abstract": "Well placement optimization is commonly performed using population-based\nglobal stochastic search algorithms. These optimizations are computationally\nexpensive due to the large number of multiphase flow simulations that must be\nconducted. In this work, we present an optimization framework in which these\nsimulations are performed with low-fidelity (LF) models. These LF models are\nconstructed from the underlying high-fidelity (HF) geomodel using a global\ntransmissibility upscaling procedure. Tree-based machine-learning methods,\nspecifically random forest and light gradient boosting machine, are applied to\nestimate the error in objective function value (in this case net present value,\nNPV) associated with the LF models. In the offline (preprocessing) step,\npreliminary optimizations are performed using LF models, and a clustering\nprocedure is applied to select a representative set of 100--150 well\nconfigurations to use for training. HF simulation is then performed for these\nconfigurations, and the tree-based models are trained using an appropriate set\nof features. In the online (runtime) step, optimization with LF models, with\nthe machine-learning correction, is conducted. Differential evolution is used\nfor all optimizations. Results are presented for two example cases involving\nthe placement of vertical wells in 3D bimodal channelized geomodels. We compare\nthe performance of our procedure to optimization using HF models. In the first\ncase, 25 optimization runs are performed with both approaches. Our method\nprovides an overall speedup factor of 46 relative to optimization using HF\nmodels, with the best-case NPV within 1% of the HF result. In the second case\nfewer HF optimization runs are conducted (consistent with actual practice), and\nthe overall speedup factor with our approach is about 8. In this case, the\nbest-case NPV from our procedure exceeds the HF result by 3.8%",
    "descriptor": "",
    "authors": [
      "Haoyu Tang",
      "Louis J. Durlofsky"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02960"
  },
  {
    "id": "arXiv:2111.02974",
    "title": "The discrepancy of unsatisfiable matrices and a lower bound for the  Koml\u00f3s conjecture constant",
    "abstract": "We construct simple, explicit matrices with columns having unit $\\ell^2$ norm\nand discrepancy approaching $1 + \\sqrt{2} \\approx 2.414$. This number gives a\nlower bound, the strongest known as far as we are aware, on the constant\nappearing in the Koml\\'{o}s conjecture. The \"unsatisfiable matrices\" giving\nthis bound are built by scaling the entries of clause-variable matrices of\ncertain unsatisfiable Boolean formulas. We show that, for a given formula, such\na scaling maximizing a lower bound on the discrepancy may be computed with a\nconvex second-order cone program. Using a dual certificate for this program, we\nshow that our lower bound is optimal among those using unsatisfiable matrices\nbuilt from formulas admitting read-once resolution proofs of unsatisfiability.\nWe also conjecture that a generalization of this certificate shows that our\nbound is optimal among all bounds using unsatisfiable matrices.",
    "descriptor": "\nComments: 19 pages, 2 figures\n",
    "authors": [
      "Dmitriy Kunisky"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.02974"
  },
  {
    "id": "arXiv:2111.02999",
    "title": "Quantum search-to-decision reductions and the state synthesis problem",
    "abstract": "It is a useful fact in classical computer science that many search problems\nare reducible to decision problems; this has led to decision problems being\nregarded as the $\\textit{de facto}$ computational task to study in complexity\ntheory. In this work, we explore search-to-decision reductions for quantum\nsearch problems, wherein a quantum algorithm makes queries to a classical\ndecision oracle to output a desired quantum state. In particular, we focus on\nsearch-to-decision reductions for $\\mathsf{QMA}$, and show that there exists a\nquantum polynomial-time algorithm that can generate a witness for a\n$\\mathsf{QMA}$ problem up to inverse polynomial precision by making one query\nto a $\\mathsf{PP}$ decision oracle. We complement this result by showing that\n$\\mathsf{QMA}$-search does $\\textit{not}$ reduce to $\\mathsf{QMA}$-decision in\npolynomial-time, relative to a quantum oracle.\nWe also explore the more general $\\textit{state synthesis problem}$, in which\nthe goal is to efficiently synthesize a target state by making queries to a\nclassical oracle encoding the state. We prove that there exists a classical\noracle with which any quantum state can be synthesized to inverse polynomial\nprecision using only one oracle query and to inverse exponential precision\nusing two oracle queries. This answers an open question of Aaronson from 2016,\nwho presented a state synthesis algorithm that makes $O(n)$ queries to a\nclassical oracle to prepare an $n$-qubit state, and asked if the query\ncomplexity could be made sublinear.",
    "descriptor": "\nComments: Comments are welcome and encouraged!\n",
    "authors": [
      "Sandy Irani",
      "Anand Natarajan",
      "Chinmay Nirkhe",
      "Sujit Rao",
      "Henry Yuen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.02999"
  },
  {
    "id": "arXiv:2111.03009",
    "title": "Computation of Input Disturbance Sets for Constrained Output  Reachability",
    "abstract": "Linear models with additive unknown-but-bounded input disturbances are\nextensively used to model uncertainty in robust control systems design.\nTypically, the disturbance set is either assumed to be known a priori or\nestimated from data through set-membership identification. However, the problem\nof computing a suitable input disturbance set in case the set of possible\noutput values is assigned a priori has received relatively little attention.\nThis problem arises in many contexts, such as in supervisory control, actuator\ndesign, decentralized control, and others. In this paper, we propose a method\nto compute input disturbance sets (and the corresponding set of states) such\nthat the resulting set of outputs matches as closely as possible a given set of\noutputs, while additionally satisfying strict (inner or outer) inclusion\nconstraints. We formulate the problem as an optimization problem by relying on\nthe concept of robust invariance. The effectiveness of the approach is\ndemonstrated in numerical examples that illustrate how to solve safe reference\nset and input-constraint set computation problems.",
    "descriptor": "",
    "authors": [
      "Sampath Kumar Mulagaleti",
      "Alberto Bemporad",
      "Mario Zanon"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.03009"
  },
  {
    "id": "arXiv:2111.03016",
    "title": "Graph neural network initialisation of quantum approximate optimisation",
    "abstract": "Approximate combinatorial optimisation has emerged as one of the most\npromising application areas for quantum computers, particularly those in the\nnear term. In this work, we focus on the quantum approximate optimisation\nalgorithm (QAOA) for solving the Max-Cut problem. Specifically, we address two\nproblems in the QAOA, how to select initial parameters, and how to subsequently\ntrain the parameters to find an optimal solution. For the former, we propose\ngraph neural networks (GNNs) as an initialisation routine for the QAOA\nparameters, adding to the literature on warm-starting techniques. We show the\nGNN approach generalises across not only graph instances, but also to\nincreasing graph sizes, a feature not available to other warm-starting\ntechniques. For training the QAOA, we test several optimisers for the MaxCut\nproblem. These include quantum aware/agnostic optimisers proposed in literature\nand we also incorporate machine learning techniques such as reinforcement and\nmeta-learning. With the incorporation of these initialisation and optimisation\ntoolkits, we demonstrate how the QAOA can be trained as an end-to-end\ndifferentiable pipeline.",
    "descriptor": "\nComments: 12 pages, 8 Figures\n",
    "authors": [
      "Nishant Jain",
      "Brian Coyle",
      "Elham Kashefi",
      "Niraj Kumar"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03016"
  },
  {
    "id": "arXiv:2111.03020",
    "title": "Efficacy the of Confinement Policies on the COVID-19 Spread Dynamics in  the Early Period of the Pandemic",
    "abstract": "In this study, we propose a clustering-based approach on time-series data to\ncapture COVID-19 spread patterns in the early period of the pandemic. We\nanalyze the spread dynamics based on the early and post stages of COVID-19 for\ndifferent countries based on different geographical locations. Furthermore, we\ninvestigate the confinement policies and the effect they made on the spread. We\nfound that implementations of the same confinement policies exhibit different\nresults in different countries. Specifically, lockdowns become less effective\nin densely populated regions, because of the reluctance to comply with social\ndistancing measures. Lack of testing, contact tracing, and social awareness in\nsome countries forestall people from self-isolation and maintaining social\ndistance. Large labor camps with unhealthy living conditions also aid in high\ncommunity transmissions in countries depending on foreign labor. Distrust in\ngovernment policies and fake news instigate the spread in both developed and\nunder-developed countries. Large social gatherings play a vital role in causing\nrapid outbreaks almost everywhere. While some countries were able to contain\nthe spread by implementing strict and widely adopted confinement policies, some\nothers contained the spread with the help of social distancing measures and\nrigorous testing capacity. An early and rapid response at the beginning of the\npandemic is necessary to contain the spread, yet it is not always sufficient.",
    "descriptor": "",
    "authors": [
      "Mehedi Hassan",
      "Md Enamul Haque",
      "Mehmet Engin Tozal"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03020"
  },
  {
    "id": "arXiv:2111.03022",
    "title": "Lipid domain coarsening and fluidity in multicomponent lipid vesicles: A  continuum based model and its experimental validation",
    "abstract": "Liposomes that achieve a heterogeneous and spatially organized surface\nthrough phase separation have been recognized to be a promising platform for\ndelivery purposes. However, their design and optimization through\nexperimentation can be expensive and time-consuming. To assist with the design\nand reduce the associated cost, we propose a computational platform for\nmodeling membrane coarsening dynamics based on the principles of continuum\nmechanics and thermodynamics. This model couples phase separation to lateral\nflow and accounts for different membrane fluidity within the different phases,\nwhich is known to affect the coarsening dynamics on lipid membranes. The\nsimulation results are in agreement with the experimental data in terms of\nliquid ordered domains area fraction, total domains perimeter over time and\ntotal number of domains over time for two different membrane compositions\n(DOPC:DPPC with a 1:1 molar ratio with 15% Chol and DOPC:DPPC with a 1:2 molar\nratio with 25% Chol) that yield opposite and nearly inverse phase behavior.\nThis quantitative validation shows that the developed platform can be a\nvaluable tool in complementing experimental practice. Keywords: Multicomponent\nMembranes; Membrane fluidity; Membrane Phase Separation; Computational\nModeling; Fluorescence Microscopy; Liposomes",
    "descriptor": "\nComments: 21 pages, 13 figures\n",
    "authors": [
      "Y. Wang",
      "Y. Palzhanov",
      "A. Quaini",
      "M. Olshanskii",
      "S. Majd"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.03022"
  },
  {
    "id": "arXiv:2111.03029",
    "title": "Causal inference with imperfect instrumental variables",
    "abstract": "Instrumental variables allow for quantification of cause and effect\nrelationships even in the absence of interventions. To achieve this, a number\nof causal assumptions must be met, the most important of which is the\nindependence assumption, which states that the instrument and any confounding\nfactor must be independent. However, if this independence condition is not met,\ncan we still work with imperfect instrumental variables? Imperfect instruments\ncan manifest themselves by violations of the instrumental inequalities that\nconstrain the set of correlations in the scenario. In this paper, we establish\na quantitative relationship between such violations of instrumental\ninequalities and the minimal amount of measurement dependence required to\nexplain them. As a result, we provide adapted inequalities that are valid in\nthe presence of a relaxed measurement dependence assumption in the instrumental\nscenario. This allows for the adaptation of existing and new lower bounds on\nthe average causal effect for instrumental scenarios with binary outcomes.\nFinally, we discuss our findings in the context of quantum mechanics.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Nikolai Miklin",
      "Mariami Gachechiladze",
      "George Moreno",
      "Rafael Chaves"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.03029"
  },
  {
    "id": "arXiv:2111.03034",
    "title": "Optimal Mixing Time for the Ising Model in the Uniqueness Regime",
    "abstract": "We prove an optimal $O(n \\log n)$ mixing time of the Glauber dynamics for the\nIsing models with edge activity $\\beta \\in \\left(\\frac{\\Delta-2}{\\Delta},\n\\frac{\\Delta}{\\Delta-2}\\right)$. This mixing time bound holds even if the\nmaximum degree $\\Delta$ is unbounded.\nWe refine the boosting technique developed in [CFYZ21], and prove a new\nboosting theorem by utilizing the entropic independence defined in [AJK+21].\nThe theorem relates the modified log-Sobolev (MLS) constant of the Glauber\ndynamics for a near-critical Ising model to that for an Ising model in a\nsub-critical regime.",
    "descriptor": "",
    "authors": [
      "Xiaoyu Chen",
      "Weiming Feng",
      "Yitong Yin",
      "Xinyuan Zhang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.03034"
  },
  {
    "id": "arXiv:2111.03040",
    "title": "Extended Principal Component Analysis",
    "abstract": "Principal Component Analysis (PCA) is a transform for finding the principal\ncomponents (PCs) that represent features of random data. PCA also provides a\nreconstruction of the PCs to the original data. We consider an extension of PCA\nwhich allows us to improve the associated accuracy and diminish the numerical\nload, in comparison with known techniques. This is achieved due to the special\nstructure of the proposed transform which contains two matrices $T_0$ and\n$T_1$, and a special transformation $\\mathcal{f}$ of the so called auxiliary\nrandom vector $\\mathbf w$. For this reason, we call it the three-term PCA. In\nparticular, we show that the three-term PCA always exists, i.e. is applicable\nto the case of singular data. Both rigorous theoretical justification of the\nthree-term PCA and simulations with real-world data are provided.",
    "descriptor": "",
    "authors": [
      "Pablo Soto-Quiros",
      "Anatoli Torokhti"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.03040"
  },
  {
    "id": "arXiv:2111.03047",
    "title": "A deep ensemble approach to X-ray polarimetry",
    "abstract": "X-ray polarimetry will soon open a new window on the high energy universe\nwith the launch of NASA's Imaging X-ray Polarimetry Explorer (IXPE).\nPolarimeters are currently limited by their track reconstruction algorithms,\nwhich typically use linear estimators and do not consider individual event\nquality. We present a modern deep learning method for maximizing the\nsensitivity of X-ray telescopic observations with imaging polarimeters, with a\nfocus on the gas pixel detectors (GPDs) to be flown on IXPE. We use a weighted\nmaximum likelihood combination of predictions from a deep ensemble of ResNets,\ntrained on Monte Carlo event simulations. We derive and apply the optimal event\nweighting for maximizing the polarization signal-to-noise ratio (SNR) in track\nreconstruction algorithms. For typical power-law source spectra, our method\nimproves on the current state of the art, providing a ~40% decrease in required\nexposure times for a given SNR.",
    "descriptor": "\nComments: Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021)\n",
    "authors": [
      "A.L.Peirson",
      "R.W.Romani"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03047"
  },
  {
    "id": "arXiv:1502.07481",
    "title": "Cluster Synchronization of Coupled Systems with Nonidentical Linear  Dynamics",
    "abstract": "Comments: accepted version by International Journal of Robust and Nonlinear Control",
    "descriptor": "\nComments: accepted version by International Journal of Robust and Nonlinear Control\n",
    "authors": [
      "Zhongchang Liu",
      "Wing Shing Wong",
      "Hui Cheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1502.07481"
  },
  {
    "id": "arXiv:1809.04393",
    "title": "Maximizing the Diversity of Exposure in a Social Network",
    "abstract": "Maximizing the Diversity of Exposure in a Social Network",
    "descriptor": "",
    "authors": [
      "Cigdem Aslay",
      "Antonis Matakos",
      "Esther Galbrun",
      "Aristides Gionis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/1809.04393"
  },
  {
    "id": "arXiv:1809.07005",
    "title": "Tail redundancy and its characterization of compression of memoryless  sources",
    "abstract": "Tail redundancy and its characterization of compression of memoryless  sources",
    "descriptor": "",
    "authors": [
      "Maryam Hosseini",
      "Narayana Santhanam"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1809.07005"
  },
  {
    "id": "arXiv:1906.06069",
    "title": "Combinatorial generation via permutation languages. I. Fundamentals",
    "abstract": "Combinatorial generation via permutation languages. I. Fundamentals",
    "descriptor": "",
    "authors": [
      "Elizabeth Hartung",
      "Hung Phuc Hoang",
      "Torsten M\u00fctze",
      "Aaron Williams"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1906.06069"
  },
  {
    "id": "arXiv:1907.10331",
    "title": "YourAdvalue: Measuring Advertising Price Dynamics without Bankrupting  User Privacy",
    "abstract": "Comments: 16 pages, 17 Figures, 5 tables, 50 References",
    "descriptor": "\nComments: 16 pages, 17 Figures, 5 tables, 50 References\n",
    "authors": [
      "Michalis Pachilakis",
      "Panagiotis Papadopoulos",
      "Nikolaos Laoutaris",
      "Evangelos P. Markatos",
      "Nicolas Kourtellis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/1907.10331"
  },
  {
    "id": "arXiv:1910.05936",
    "title": "Symmetric binary Steinhaus triangles and parity-regular Steinhaus graphs",
    "abstract": "Comments: 50 pages, 23 figures, 6 tables",
    "descriptor": "\nComments: 50 pages, 23 figures, 6 tables\n",
    "authors": [
      "Jonathan Chappelon"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/1910.05936"
  },
  {
    "id": "arXiv:1911.04971",
    "title": "Deep Variational Semi-Supervised Novelty Detection",
    "abstract": "Comments: NeurIPS 2021 Workshop on DGMs and Downstream Applications",
    "descriptor": "\nComments: NeurIPS 2021 Workshop on DGMs and Downstream Applications\n",
    "authors": [
      "Tal Daniel",
      "Thanard Kurutach",
      "Aviv Tamar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.04971"
  },
  {
    "id": "arXiv:1911.11093",
    "title": "A sharp relative-error bound for the Helmholtz $h$-FEM at high frequency",
    "abstract": "A sharp relative-error bound for the Helmholtz $h$-FEM at high frequency",
    "descriptor": "",
    "authors": [
      "David Lafontaine",
      "Euan A. Spence",
      "Jared Wunsch"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1911.11093"
  },
  {
    "id": "arXiv:2001.00939",
    "title": "Relative Flatness and Generalization",
    "abstract": "Comments: The first two authors made equal contribution; Accepted for publication at NeurIPS 2021; arXiv admin note: substantial text overlap with arXiv:1912.00058",
    "descriptor": "\nComments: The first two authors made equal contribution; Accepted for publication at NeurIPS 2021; arXiv admin note: substantial text overlap with arXiv:1912.00058\n",
    "authors": [
      "Henning Petzka",
      "Michael Kamp",
      "Linara Adilova",
      "Cristian Sminchisescu",
      "Mario Boley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.00939"
  },
  {
    "id": "arXiv:2002.03757",
    "title": "Distributed Learning with Dependent Samples",
    "abstract": "Comments: 17 pages, 8 figures",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Zirui Sun",
      "Shao-Bo Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.03757"
  },
  {
    "id": "arXiv:2003.04358",
    "title": "Cross modal video representations for weakly supervised active speaker  localization",
    "abstract": "Cross modal video representations for weakly supervised active speaker  localization",
    "descriptor": "",
    "authors": [
      "Rahul Sharma",
      "Krishna Somandepalli",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2003.04358"
  },
  {
    "id": "arXiv:2003.14265",
    "title": "A Framework for Adversarially Robust Streaming Algorithms",
    "abstract": "Comments: Conference version in PODS 2020. Version 3 addressing journal referees' comments; improved exposition of sketch switching",
    "descriptor": "\nComments: Conference version in PODS 2020. Version 3 addressing journal referees' comments; improved exposition of sketch switching\n",
    "authors": [
      "Omri Ben-Eliezer",
      "Rajesh Jayaram",
      "David P. Woodruff",
      "Eylon Yogev"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2003.14265"
  },
  {
    "id": "arXiv:2005.13815",
    "title": "Adversarial Classification via Distributional Robustness with  Wasserstein Ambiguity",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Nam Ho-Nguyen",
      "Stephen J. Wright"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.13815"
  },
  {
    "id": "arXiv:2006.01958",
    "title": "Nucleus Decomposition in Probabilistic Graphs: Hardness and Algorithms",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Fatemeh Esfahani",
      "Venkatesh Srinivasan",
      "Alex Thomo",
      "Kui Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2006.01958"
  },
  {
    "id": "arXiv:2006.02567",
    "title": "Extracting a Knowledge Base of COVID-19 Events from Social Media",
    "abstract": "Extracting a Knowledge Base of COVID-19 Events from Social Media",
    "descriptor": "",
    "authors": [
      "Shi Zong",
      "Ashutosh Baheti",
      "Wei Xu",
      "Alan Ritter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2006.02567"
  },
  {
    "id": "arXiv:2006.05211",
    "title": "Stability properties of a projector-splitting scheme for dynamical low  rank approximation of random parabolic equations",
    "abstract": "Comments: 48 pages, 14 figures",
    "descriptor": "\nComments: 48 pages, 14 figures\n",
    "authors": [
      "Yoshihito Kazashi",
      "Fabio Nobile",
      "Eva Vidli\u010dkov\u00e1"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.05211"
  },
  {
    "id": "arXiv:2006.09092",
    "title": "Learning Rates as a Function of Batch Size: A Random Matrix Theory  Approach to Neural Network Training",
    "abstract": "Learning Rates as a Function of Batch Size: A Random Matrix Theory  Approach to Neural Network Training",
    "descriptor": "",
    "authors": [
      "Diego Granziol",
      "Stefan Zohren",
      "Stephen Roberts"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.09092"
  },
  {
    "id": "arXiv:2006.10916",
    "title": "Probabilistic Fair Clustering",
    "abstract": "Probabilistic Fair Clustering",
    "descriptor": "",
    "authors": [
      "Seyed A. Esmaeili",
      "Brian Brubach",
      "Leonidas Tsepenekas",
      "John P. Dickerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10916"
  },
  {
    "id": "arXiv:2006.12469",
    "title": "Attention-based Quantum Tomography",
    "abstract": "Attention-based Quantum Tomography",
    "descriptor": "",
    "authors": [
      "Peter Cha",
      "Paul Ginsparg",
      "Felix Wu",
      "Juan Carrasquilla",
      "Peter L. McMahon",
      "Eun-Ah Kim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.12469"
  },
  {
    "id": "arXiv:2006.16190",
    "title": "Reachability in arborescence packings",
    "abstract": "Reachability in arborescence packings",
    "descriptor": "",
    "authors": [
      "Florian H\u00f6rsch",
      "Zolt\u00e1n Szigeti"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2006.16190"
  },
  {
    "id": "arXiv:2007.04080",
    "title": "Decoder Ties Do Not Affect the Error Exponent of the Memoryless Binary  Symmetric Channel",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2001.01159",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2001.01159\n",
    "authors": [
      "Ling-Hua Chang",
      "Po-Ning Chen",
      "Fady Alajaji",
      "Yunghsiang S. Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2007.04080"
  },
  {
    "id": "arXiv:2009.13240",
    "title": "Texture Memory-Augmented Deep Patch-Based Image Inpainting",
    "abstract": "Comments: Published on TIP. Project Page: this https URL",
    "descriptor": "\nComments: Published on TIP. Project Page: this https URL\n",
    "authors": [
      "Rui Xu",
      "Minghao Guo",
      "Jiaqi Wang",
      "Xiaoxiao Li",
      "Bolei Zhou",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2009.13240"
  },
  {
    "id": "arXiv:2010.02502",
    "title": "Denoising Diffusion Implicit Models",
    "abstract": "Comments: ICLR 2021; updated connections with ODEs at page 6",
    "descriptor": "\nComments: ICLR 2021; updated connections with ODEs at page 6\n",
    "authors": [
      "Jiaming Song",
      "Chenlin Meng",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.02502"
  },
  {
    "id": "arXiv:2010.02917",
    "title": "A Contrastive Learning Approach for Training Variational Autoencoder  Priors",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Jyoti Aneja",
      "Alexander Schwing",
      "Jan Kautz",
      "Arash Vahdat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.02917"
  },
  {
    "id": "arXiv:2010.09326",
    "title": "Symmetric Private Polynomial Computation From Lagrange Encoding",
    "abstract": "Symmetric Private Polynomial Computation From Lagrange Encoding",
    "descriptor": "",
    "authors": [
      "Jinbao Zhu",
      "Qifa Yan",
      "Xiaohu Tang",
      "Songze Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.09326"
  },
  {
    "id": "arXiv:2010.13018",
    "title": "Adversarial Robust Low Rank Matrix Estimation: Compressed Sensing and  Matrix Completion",
    "abstract": "Comments: 46 pages",
    "descriptor": "\nComments: 46 pages\n",
    "authors": [
      "Takeyuki Sasai",
      "Hironori Fujisawa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2010.13018"
  },
  {
    "id": "arXiv:2010.16402",
    "title": "Why Do Better Loss Functions Lead to Less Transferable Features?",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Simon Kornblith",
      "Ting Chen",
      "Honglak Lee",
      "Mohammad Norouzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.16402"
  },
  {
    "id": "arXiv:2011.03141",
    "title": "Quantum randomized encoding, verification of quantum computing,  no-cloning, and blind quantum computing",
    "abstract": "Comments: 31 pages. New result (Theorem 3) on the impossibility of computationally secure case is added",
    "descriptor": "\nComments: 31 pages. New result (Theorem 3) on the impossibility of computationally secure case is added\n",
    "authors": [
      "Tomoyuki Morimae"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.03141"
  },
  {
    "id": "arXiv:2011.10369",
    "title": "ONION: A Simple and Effective Defense Against Textual Backdoor Attacks",
    "abstract": "Comments: Accepted by the main conference of EMNLP 2021 as a short paper. The camera-ready version",
    "descriptor": "\nComments: Accepted by the main conference of EMNLP 2021 as a short paper. The camera-ready version\n",
    "authors": [
      "Fanchao Qi",
      "Yangyi Chen",
      "Mukai Li",
      "Yuan Yao",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2011.10369"
  },
  {
    "id": "arXiv:2011.13843",
    "title": "SFTrack++: A Fast Learnable Spectral Segmentation Approach for  Space-Time Consistent Tracking",
    "abstract": "Comments: Accepted at Neural Information Processing Systems (NeurIPS) 2020 - Pre-registration Workshop and at The International Conference on Computer Vision (ICCV) 2021 - Structured Representations for Video Understanding Workshop",
    "descriptor": "\nComments: Accepted at Neural Information Processing Systems (NeurIPS) 2020 - Pre-registration Workshop and at The International Conference on Computer Vision (ICCV) 2021 - Structured Representations for Video Understanding Workshop\n",
    "authors": [
      "Elena Burceanu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.13843"
  },
  {
    "id": "arXiv:2012.01102",
    "title": "An Analytic Propositional Proof System on Graphs",
    "abstract": "An Analytic Propositional Proof System on Graphs",
    "descriptor": "",
    "authors": [
      "Matteo Acclavio",
      "Ross Horne",
      "Lutz Strassburger"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2012.01102"
  },
  {
    "id": "arXiv:2012.02670",
    "title": "Unleashing the Tiger: Inference Attacks on Split Learning",
    "abstract": "Comments: ACM Conference on Computer and Communications Security 2021 (CCS21)",
    "descriptor": "\nComments: ACM Conference on Computer and Communications Security 2021 (CCS21)\n",
    "authors": [
      "Dario Pasquini",
      "Giuseppe Ateniese",
      "Massimo Bernaschi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.02670"
  },
  {
    "id": "arXiv:2012.08086",
    "title": "Approximation by linear combinations of translates of a single function",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1212.6160, arXiv:1702.08603",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1212.6160, arXiv:1702.08603\n",
    "authors": [
      "Dinh D\u0169ng",
      "Vu Nhat Huy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.08086"
  },
  {
    "id": "arXiv:2012.13344",
    "title": "Generating Long-term Continuous Multi-type Generation Profiles",
    "abstract": "Comments: 3 pages",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "Ming Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.13344"
  },
  {
    "id": "arXiv:2012.13787",
    "title": "Degrees of Freedom of the $K$-User Interference Channel in the Presence  of Intelligent Reflecting Surfaces",
    "abstract": "Degrees of Freedom of the $K$-User Interference Channel in the Presence  of Intelligent Reflecting Surfaces",
    "descriptor": "",
    "authors": [
      "Ali H. Abdollahi Bafghi",
      "Vahid Jamali",
      "Masoumeh Nasiri-Kenari",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.13787"
  },
  {
    "id": "arXiv:2101.02868",
    "title": "Spatial-spectral Terahertz Networks",
    "abstract": "Comments: accepted by the IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: accepted by the IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Zheng Lin",
      "Lifeng Wang",
      "Bo Tan",
      "Xiang Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.02868"
  },
  {
    "id": "arXiv:2102.01046",
    "title": "Impossible Tuning Made Possible: A New Expert Algorithm and Its  Applications",
    "abstract": "Impossible Tuning Made Possible: A New Expert Algorithm and Its  Applications",
    "descriptor": "",
    "authors": [
      "Liyu Chen",
      "Haipeng Luo",
      "Chen-Yu Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2102.01046"
  },
  {
    "id": "arXiv:2102.06514",
    "title": "Large-Scale Representation Learning on Graphs via Bootstrapping",
    "abstract": "Large-Scale Representation Learning on Graphs via Bootstrapping",
    "descriptor": "",
    "authors": [
      "Shantanu Thakoor",
      "Corentin Tallec",
      "Mohammad Gheshlaghi Azar",
      "Mehdi Azabou",
      "Eva L. Dyer",
      "R\u00e9mi Munos",
      "Petar Veli\u010dkovi\u0107",
      "Michal Valko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06514"
  },
  {
    "id": "arXiv:2102.07724",
    "title": "Locality and Centrality: The Variety ZG",
    "abstract": "Comments: 31 pages. Corrected small errors and improved the presentation. Submitted",
    "descriptor": "\nComments: 31 pages. Corrected small errors and improved the presentation. Submitted\n",
    "authors": [
      "Antoine Amarilli",
      "Charles Paperman"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2102.07724"
  },
  {
    "id": "arXiv:2102.08009",
    "title": "EfficientLPS: Efficient LiDAR Panoptic Segmentation",
    "abstract": "Comments: Ranked #1 on SemanticKITTI and nuScenes panoptic segmentation benchmarks",
    "descriptor": "\nComments: Ranked #1 on SemanticKITTI and nuScenes panoptic segmentation benchmarks\n",
    "authors": [
      "Kshitij Sirohi",
      "Rohit Mohan",
      "Daniel B\u00fcscher",
      "Wolfram Burgard",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.08009"
  },
  {
    "id": "arXiv:2102.08087",
    "title": "Making the most of your day: online learning for optimal allocation of  time",
    "abstract": "Comments: NeurIPS 2021 camera ready",
    "descriptor": "\nComments: NeurIPS 2021 camera ready\n",
    "authors": [
      "Etienne Boursier",
      "Tristan Garrec",
      "Vianney Perchet",
      "Marco Scarsini"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2102.08087"
  },
  {
    "id": "arXiv:2102.09407",
    "title": "Deep Rational Reinforcement Learning",
    "abstract": "Comments: Main paper: 8 pages, References: 2 pages, Appendix: 5 pages. Main paper: 6 figures, Appendix: 5 figures. Rational Activation Functions repository: this https URL Rational Supervised Learning: this https URL Rational Reinforcement Learning: this https URL",
    "descriptor": "\nComments: Main paper: 8 pages, References: 2 pages, Appendix: 5 pages. Main paper: 6 figures, Appendix: 5 figures. Rational Activation Functions repository: this https URL Rational Supervised Learning: this https URL Rational Reinforcement Learning: this https URL\n",
    "authors": [
      "Quentin Delfosse",
      "Patrick Schramowski",
      "Martin Mundt",
      "Alejandro Molina",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09407"
  },
  {
    "id": "arXiv:2102.10395",
    "title": "On Calibration and Out-of-domain Generalization",
    "abstract": "Comments: 24 pages, 6 figures",
    "descriptor": "\nComments: 24 pages, 6 figures\n",
    "authors": [
      "Yoav Wald",
      "Amir Feder",
      "Daniel Greenfeld",
      "Uri Shalit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.10395"
  },
  {
    "id": "arXiv:2102.12060",
    "title": "Teach Me to Explain: A Review of Datasets for Explainable NLP",
    "abstract": "Comments: v3: NeurIPS 2021 accepted paper camera-ready version. The content of v3 is almost the same as of v1-2 but is more condensed. 10 pages main, 6 pages appendix",
    "descriptor": "\nComments: v3: NeurIPS 2021 accepted paper camera-ready version. The content of v3 is almost the same as of v1-2 but is more condensed. 10 pages main, 6 pages appendix\n",
    "authors": [
      "Sarah Wiegreffe",
      "Ana Marasovi\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12060"
  },
  {
    "id": "arXiv:2102.12061",
    "title": "Deep Video Prediction for Time Series Forecasting",
    "abstract": "Comments: Published in ICAIF 2021 (ACM International Conference on AI in Finance)",
    "descriptor": "\nComments: Published in ICAIF 2021 (ACM International Conference on AI in Finance)\n",
    "authors": [
      "Zhen Zeng",
      "Tucker Balch",
      "Manuela Veloso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2102.12061"
  },
  {
    "id": "arXiv:2103.00185",
    "title": "Economic Dispatch of a Single Micro-Gas Turbine Under CHP Operation with  Uncertain Demands",
    "abstract": "Comments: 16 pages, 8 figures",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Miel Sharf",
      "Iliya Romm",
      "Michael Palman",
      "Daniel Zelazo",
      "Beni Cukurel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.00185"
  },
  {
    "id": "arXiv:2103.03055",
    "title": "Self-supervised deep convolutional neural network for chest X-ray  classification",
    "abstract": "Comments: The work was published by IEEE Access. DOI: 10.1109/ACCESS.2021.3125324",
    "descriptor": "\nComments: The work was published by IEEE Access. DOI: 10.1109/ACCESS.2021.3125324\n",
    "authors": [
      "Matej Gazda",
      "Jakub Gazda",
      "Jan Plavka",
      "Peter Drotar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2103.03055"
  },
  {
    "id": "arXiv:2103.03629",
    "title": "Self-supervised Mean Teacher for Semi-supervised Chest X-ray  Classification",
    "abstract": "Comments: MLMI-MICCAI 2021",
    "descriptor": "\nComments: MLMI-MICCAI 2021\n",
    "authors": [
      "Fengbei Liu",
      "Yu Tian",
      "Filipe R. Cordeiro",
      "Vasileios Belagiannis",
      "Ian Reid",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03629"
  },
  {
    "id": "arXiv:2103.03975",
    "title": "Global canopy height regression and uncertainty estimation from GEDI  LIDAR waveforms with deep ensembles",
    "abstract": "Global canopy height regression and uncertainty estimation from GEDI  LIDAR waveforms with deep ensembles",
    "descriptor": "",
    "authors": [
      "Nico Lang",
      "Nikolai Kalischek",
      "John Armston",
      "Konrad Schindler",
      "Ralph Dubayah",
      "Jan Dirk Wegner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03975"
  },
  {
    "id": "arXiv:2103.05249",
    "title": "Negative Imaginary State Feedback Equivalence for Systems of Relative  Degree One and Relative Degree Two",
    "abstract": "Comments: 12 pages, 2 figures",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Kanghong Shi",
      "Ian R. Petersen",
      "Igor G. Vladimirov"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.05249"
  },
  {
    "id": "arXiv:2103.06720",
    "title": "Variational inference with a quantum computer",
    "abstract": "Comments: 17 pages, 9 figures, 1 table; As published in Phys. Rev. Applied",
    "descriptor": "\nComments: 17 pages, 9 figures, 1 table; As published in Phys. Rev. Applied\n",
    "authors": [
      "Marcello Benedetti",
      "Brian Coyle",
      "Mattia Fiorentini",
      "Michael Lubasch",
      "Matthias Rosenkranz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06720"
  },
  {
    "id": "arXiv:2103.07935",
    "title": "Scale-aware Neural Network for Semantic Segmentation of Multi-resolution  Remote Sensing Images",
    "abstract": "Scale-aware Neural Network for Semantic Segmentation of Multi-resolution  Remote Sensing Images",
    "descriptor": "",
    "authors": [
      "Libo Wang",
      "Ce Zhang",
      "Rui Li",
      "Chenxi Duan",
      "Xiaoliang Meng",
      "Peter M. Atkinson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.07935"
  },
  {
    "id": "arXiv:2103.08250",
    "title": "Hierarchical forecasting with a top-down alignment of independent level  forecasts",
    "abstract": "Hierarchical forecasting with a top-down alignment of independent level  forecasts",
    "descriptor": "",
    "authors": [
      "Matthias Anderer",
      "Feng Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2103.08250"
  },
  {
    "id": "arXiv:2103.09748",
    "title": "On the Whitney extension problem for near isometries and beyond",
    "abstract": "Comments: This paper is PART of a series, the others being [arXiv:1411.2451, arXiv:1411.2468, arXiv:1505.06950, arXiv:1705.06146, arXiv:1610.08138, arXiv:4011662]",
    "descriptor": "\nComments: This paper is PART of a series, the others being [arXiv:1411.2451, arXiv:1411.2468, arXiv:1505.06950, arXiv:1705.06146, arXiv:1610.08138, arXiv:4011662]\n",
    "authors": [
      "Steven B. Damelin"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.09748"
  },
  {
    "id": "arXiv:2103.12407",
    "title": "Detecting Hate Speech with GPT-3",
    "abstract": "Comments: 16 pages, 1 figure, 7 tables",
    "descriptor": "\nComments: 16 pages, 1 figure, 7 tables\n",
    "authors": [
      "Ke-Li Chiu",
      "Rohan Alexander"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.12407"
  },
  {
    "id": "arXiv:2103.14417",
    "title": "Self-Supervised Learning in Multi-Task Graphs through Iterative  Consensus Shift",
    "abstract": "Comments: Accepted at The British Machine Vision Conference (BMVC) 2021, 12 pages, 6 figures, 5 tables",
    "descriptor": "\nComments: Accepted at The British Machine Vision Conference (BMVC) 2021, 12 pages, 6 figures, 5 tables\n",
    "authors": [
      "Emanuela Haller",
      "Elena Burceanu",
      "Marius Leordeanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14417"
  },
  {
    "id": "arXiv:2103.14510",
    "title": "Limitations on Uncloneable Encryption and Simultaneous One-Way-to-Hiding",
    "abstract": "Comments: v2 and v3: several fixes, including a missing attribution to Broadbent and Lord",
    "descriptor": "\nComments: v2 and v3: several fixes, including a missing attribution to Broadbent and Lord\n",
    "authors": [
      "Christian Majenz",
      "Christian Schaffner",
      "Mehrdad Tahmasbi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.14510"
  },
  {
    "id": "arXiv:2103.15798",
    "title": "Rethinking Neural Operations for Diverse Tasks",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Nicholas Roberts",
      "Mikhail Khodak",
      "Tri Dao",
      "Liam Li",
      "Christopher R\u00e9",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.15798"
  },
  {
    "id": "arXiv:2104.02821",
    "title": "Towards Measuring Fairness in AI: the Casual Conversations Dataset",
    "abstract": "Towards Measuring Fairness in AI: the Casual Conversations Dataset",
    "descriptor": "",
    "authors": [
      "Caner Hazirbas",
      "Joanna Bitton",
      "Brian Dolhansky",
      "Jacqueline Pan",
      "Albert Gordo",
      "Cristian Canton Ferrer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.02821"
  },
  {
    "id": "arXiv:2104.05117",
    "title": "Tracking Normalized Network Traffic Entropy to Detect DDoS Attacks in P4",
    "abstract": "Comments: Accepted by TDSC on 24/09/2021",
    "descriptor": "\nComments: Accepted by TDSC on 24/09/2021\n",
    "authors": [
      "Damu Ding",
      "Marco Savi",
      "Domenico Siracusa"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.05117"
  },
  {
    "id": "arXiv:2104.05771",
    "title": "Online Weighted Matching with a Sample",
    "abstract": "Comments: To appear in SODA 2022",
    "descriptor": "\nComments: To appear in SODA 2022\n",
    "authors": [
      "Haim Kaplan",
      "David Naori",
      "Danny Raz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.05771"
  },
  {
    "id": "arXiv:2104.06004",
    "title": "Detecting Escalation Level from Speech with Transfer Learning and  Acoustic-Lexical Information Fusion",
    "abstract": "Detecting Escalation Level from Speech with Transfer Learning and  Acoustic-Lexical Information Fusion",
    "descriptor": "",
    "authors": [
      "Ziang Zhou",
      "Yanze Xu",
      "Ming Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.06004"
  },
  {
    "id": "arXiv:2104.06731",
    "title": "High Order Residual Distribution Conservative Finite Difference HWENO  Scheme for Steady State Problems",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1810.06866",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1810.06866\n",
    "authors": [
      "Jianfang Lin",
      "Yupeng Ren",
      "R\u00e9mi Abgrall",
      "Jianxian Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.06731"
  },
  {
    "id": "arXiv:2104.07365",
    "title": "D-Cliques: Compensating for Data Heterogeneity with Topology in  Decentralized Federated Learning",
    "abstract": "Comments: 18 pages, 26 figures. Revision v4: Made title and abstract more specific (data heterogeneity), added generalized clique construction algorithm (Greedy Swap), updated main text experiments to use generalized partitioning scheme, reorganized paper structure, re-ran and added previous experiments in appendix using updated simulator",
    "descriptor": "\nComments: 18 pages, 26 figures. Revision v4: Made title and abstract more specific (data heterogeneity), added generalized clique construction algorithm (Greedy Swap), updated main text experiments to use generalized partitioning scheme, reorganized paper structure, re-ran and added previous experiments in appendix using updated simulator\n",
    "authors": [
      "Aur\u00e9lien Bellet",
      "Anne-Marie Kermarrec",
      "Erick Lavoie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.07365"
  },
  {
    "id": "arXiv:2104.11274",
    "title": "Landmark-Aware and Part-based Ensemble Transfer Learning Network for  Facial Expression Recognition from Static images",
    "abstract": "Landmark-Aware and Part-based Ensemble Transfer Learning Network for  Facial Expression Recognition from Static images",
    "descriptor": "",
    "authors": [
      "Rohan Wadhawan",
      "Tapan K. Gandhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.11274"
  },
  {
    "id": "arXiv:2104.11456",
    "title": "Hierarchical adaptive low-rank format with applications to discretized  PDEs",
    "abstract": "Hierarchical adaptive low-rank format with applications to discretized  PDEs",
    "descriptor": "",
    "authors": [
      "Stefano Massei",
      "Leonardo Robol",
      "Daniel Kressner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.11456"
  },
  {
    "id": "arXiv:2105.02468",
    "title": "Relative stability toward diffeomorphisms indicates performance in deep  nets",
    "abstract": "Comments: NeurIPS 2021 Conference",
    "descriptor": "\nComments: NeurIPS 2021 Conference\n",
    "authors": [
      "Leonardo Petrini",
      "Alessandro Favero",
      "Mario Geiger",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.02468"
  },
  {
    "id": "arXiv:2105.03925",
    "title": "On the Distribution of the Information Density of Gaussian Random  Vectors: Explicit Formulas and Tight Approximations",
    "abstract": "Comments: This extended version of the manuscript replaces the previous versions and is submitted to the journal \"Problems of Information Transmission\". An implementation in Python allowing efficient numerical calculations related to the main results of the paper is publicly available on GitLab: this https URL",
    "descriptor": "\nComments: This extended version of the manuscript replaces the previous versions and is submitted to the journal \"Problems of Information Transmission\". An implementation in Python allowing efficient numerical calculations related to the main results of the paper is publicly available on GitLab: this https URL\n",
    "authors": [
      "Jonathan Huffmann",
      "Martin Mittelbach"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.03925"
  },
  {
    "id": "arXiv:2105.11383",
    "title": "Coercivity, essential norms, and the Galerkin method for second-kind  integral equations on polyhedral and Lipschitz domains",
    "abstract": "Coercivity, essential norms, and the Galerkin method for second-kind  integral equations on polyhedral and Lipschitz domains",
    "descriptor": "",
    "authors": [
      "Simon N. Chandler-Wilde",
      "Euan A. Spence"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.11383"
  },
  {
    "id": "arXiv:2105.13600",
    "title": "Placement Optimization and Power Control in Intelligent Reflecting  Surface Aided Multiuser System",
    "abstract": "Comments: To appear in GLOBECOM 2021. This paper focuses on the multi-IRS placement optimization and downlink AP power control for achieving max-min throughput in a single-cell multi-user system. A ring-based IRS placement scheme is proposed which utilizes the near-AP/near-user deployment modes. Closed-form power control policy is devised to equalize the users' non-outage probability",
    "descriptor": "\nComments: To appear in GLOBECOM 2021. This paper focuses on the multi-IRS placement optimization and downlink AP power control for achieving max-min throughput in a single-cell multi-user system. A ring-based IRS placement scheme is proposed which utilizes the near-AP/near-user deployment modes. Closed-form power control policy is devised to equalize the users' non-outage probability\n",
    "authors": [
      "Bifeng Ling",
      "Jiangbin Lyu",
      "Liqun Fu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.13600"
  },
  {
    "id": "arXiv:2105.14950",
    "title": "A New Transmit Antenna Selection Technique for Physical Layer Security  with Strong Eavesdropping",
    "abstract": "Comments: 4 pages, 4 figures, journal article.This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 4 pages, 4 figures, journal article.This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Gonzalo J. Anaya-L\u00f3pez",
      "J. Carlos Ruiz-Sicilia",
      "F. Javier L\u00f3pez-Mart\u00ednez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.14950"
  },
  {
    "id": "arXiv:2106.00421",
    "title": "OpenBox: A Generalized Black-box Optimization Service",
    "abstract": "OpenBox: A Generalized Black-box Optimization Service",
    "descriptor": "",
    "authors": [
      "Yang Li",
      "Yu Shen",
      "Wentao Zhang",
      "Yuanwei Chen",
      "Huaijun Jiang",
      "Mingchao Liu",
      "Jiawei Jiang",
      "Jinyang Gao",
      "Wentao Wu",
      "Zhi Yang",
      "Ce Zhang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00421"
  },
  {
    "id": "arXiv:2106.00792",
    "title": "Latent Space Refinement for Deep Generative Models",
    "abstract": "Comments: 15 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 15 pages, 5 figures, 3 tables\n",
    "authors": [
      "Ramon Winterhalder",
      "Marco Bellagente",
      "Benjamin Nachman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.00792"
  },
  {
    "id": "arXiv:2106.00845",
    "title": "Energy-aware optimization of UAV base stations placement via  decentralized multi-agent Q-learning",
    "abstract": "Comments: Accepted paper for presentation and publication in the Proceedings of IEEE CCNC 2022, Las Vegas, USA",
    "descriptor": "\nComments: Accepted paper for presentation and publication in the Proceedings of IEEE CCNC 2022, Las Vegas, USA\n",
    "authors": [
      "Babatunji Omoniwa",
      "Boris Galkin",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.00845"
  },
  {
    "id": "arXiv:2106.01151",
    "title": "Towards Deeper Deep Reinforcement Learning with Spectral Normalization",
    "abstract": "Comments: accepted NeurIPS 2021",
    "descriptor": "\nComments: accepted NeurIPS 2021\n",
    "authors": [
      "Johan Bjorck",
      "Carla P. Gomes",
      "Kilian Q. Weinberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01151"
  },
  {
    "id": "arXiv:2106.02097",
    "title": "A Consciousness-Inspired Planning Agent for Model-Based Reinforcement  Learning",
    "abstract": "Comments: NeurIPS camera-ready version",
    "descriptor": "\nComments: NeurIPS camera-ready version\n",
    "authors": [
      "Mingde Zhao",
      "Zhen Liu",
      "Sitao Luan",
      "Shuyuan Zhang",
      "Doina Precup",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02097"
  },
  {
    "id": "arXiv:2106.02212",
    "title": "Fuzzy Clustering with Similarity Queries",
    "abstract": "Comments: 42 pages, 7 figures (Accepted to NeurIPS 2021)",
    "descriptor": "\nComments: 42 pages, 7 figures (Accepted to NeurIPS 2021)\n",
    "authors": [
      "Wasim Huleihel",
      "Arya Mazumdar",
      "Soumyabrata Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02212"
  },
  {
    "id": "arXiv:2106.02519",
    "title": "Consensus Based Sampling",
    "abstract": "Consensus Based Sampling",
    "descriptor": "",
    "authors": [
      "J. A. Carrillo",
      "F. Hoffmann",
      "A. M. Stuart",
      "U. Vaes"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02519"
  },
  {
    "id": "arXiv:2106.02666",
    "title": "Counterfactual Explanations Can Be Manipulated",
    "abstract": "Counterfactual Explanations Can Be Manipulated",
    "descriptor": "",
    "authors": [
      "Dylan Slack",
      "Sophie Hilgard",
      "Himabindu Lakkaraju",
      "Sameer Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02666"
  },
  {
    "id": "arXiv:2106.02749",
    "title": "Predify: Augmenting deep neural networks with brain-inspired predictive  coding dynamics",
    "abstract": "Comments: Paper presented at NeurIPS 2021",
    "descriptor": "\nComments: Paper presented at NeurIPS 2021\n",
    "authors": [
      "Bhavin Choksi",
      "Milad Mozafari",
      "Callum Biggs O'May",
      "Benjamin Ador",
      "Andrea Alamia",
      "Rufin VanRullen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.02749"
  },
  {
    "id": "arXiv:2106.03279",
    "title": "Learning MDPs from Features: Predict-Then-Optimize for Sequential  Decision Problems by Reinforcement Learning",
    "abstract": "Learning MDPs from Features: Predict-Then-Optimize for Sequential  Decision Problems by Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Kai Wang",
      "Sanket Shah",
      "Haipeng Chen",
      "Andrew Perrault",
      "Finale Doshi-Velez",
      "Milind Tambe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03279"
  },
  {
    "id": "arXiv:2106.04228",
    "title": "Decentralized Learning in Online Queuing Systems",
    "abstract": "Comments: NeurIPS 2021 camera ready",
    "descriptor": "\nComments: NeurIPS 2021 camera ready\n",
    "authors": [
      "Flore Sentenac",
      "Etienne Boursier",
      "Vianney Perchet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.04228"
  },
  {
    "id": "arXiv:2106.04502",
    "title": "Federated Hyperparameter Tuning: Challenges, Baselines, and Connections  to Weight-Sharing",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Mikhail Khodak",
      "Renbo Tu",
      "Tian Li",
      "Liam Li",
      "Maria-Florina Balcan",
      "Virginia Smith",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04502"
  },
  {
    "id": "arXiv:2106.05064",
    "title": "Sharp Elements and the Scott Topology of Continuous Dcpos",
    "abstract": "Comments: A shorter version of this paper will appear in EPTCS, proceedings of MFPS 2021. v4: Changes in style file only",
    "descriptor": "\nComments: A shorter version of this paper will appear in EPTCS, proceedings of MFPS 2021. v4: Changes in style file only\n",
    "authors": [
      "Tom de Jong"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.05064"
  },
  {
    "id": "arXiv:2106.05238",
    "title": "I Don't Need $\\mathbf{u}$: Identifiable Non-Linear ICA Without Side  Information",
    "abstract": "Comments: 11 pages plus appendix",
    "descriptor": "\nComments: 11 pages plus appendix\n",
    "authors": [
      "Matthew Willetts",
      "Brooks Paige"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.05238"
  },
  {
    "id": "arXiv:2106.05932",
    "title": "Early-stopped neural networks are consistent",
    "abstract": "Early-stopped neural networks are consistent",
    "descriptor": "",
    "authors": [
      "Ziwei Ji",
      "Justin D. Li",
      "Matus Telgarsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.05932"
  },
  {
    "id": "arXiv:2106.05951",
    "title": "Support Recovery of Sparse Signals from a Mixture of Linear Measurements",
    "abstract": "Comments: 27 pages, Accepted in NeurIPS 2021",
    "descriptor": "\nComments: 27 pages, Accepted in NeurIPS 2021\n",
    "authors": [
      "Venkata Gandikota",
      "Arya Mazumdar",
      "Soumyabrata Pal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05951"
  },
  {
    "id": "arXiv:2106.06333",
    "title": "Invariant Information Bottleneck for Domain Generalization",
    "abstract": "Comments: The work is in progress",
    "descriptor": "\nComments: The work is in progress\n",
    "authors": [
      "Bo Li",
      "Yifei Shen",
      "Yezhen Wang",
      "Wenzhen Zhu",
      "Colorado J. Reed",
      "Jun Zhang",
      "Dongsheng Li",
      "Kurt Keutzer",
      "Han Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06333"
  },
  {
    "id": "arXiv:2106.06515",
    "title": "Probability Paths and the Structure of Predictions over Time",
    "abstract": "Probability Paths and the Structure of Predictions over Time",
    "descriptor": "",
    "authors": [
      "Zhiyuan Jerry Lin",
      "Hao Sheng",
      "Sharad Goel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06515"
  },
  {
    "id": "arXiv:2106.09261",
    "title": "Federated Learning Framework with Straggling Mitigation and  Privacy-Awareness for AI-based Mobile Application Services",
    "abstract": "Comments: 18 pages (submitted to an IEEE journal)",
    "descriptor": "\nComments: 18 pages (submitted to an IEEE journal)\n",
    "authors": [
      "Yuris Mulya Saputra",
      "Diep N. Nguyen",
      "Dinh Thai Hoang",
      "Quoc-Viet Pham",
      "Eryk Dutkiewicz",
      "Won-Joo Hwang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09261"
  },
  {
    "id": "arXiv:2106.09352",
    "title": "Large Scale Private Learning via Low-rank Reparametrization",
    "abstract": "Comments: Published as a conference paper in International Conference on Machine Learning (ICML 2021). Source code available at this https URL",
    "descriptor": "\nComments: Published as a conference paper in International Conference on Machine Learning (ICML 2021). Source code available at this https URL\n",
    "authors": [
      "Da Yu",
      "Huishuai Zhang",
      "Wei Chen",
      "Jian Yin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09352"
  },
  {
    "id": "arXiv:2106.10129",
    "title": "Towards Robotic Laboratory Automation Plug & Play: The \"LAPP\" Framework",
    "abstract": "Towards Robotic Laboratory Automation Plug & Play: The \"LAPP\" Framework",
    "descriptor": "",
    "authors": [
      "\u00c1d\u00e1m Wolf",
      "David Wolton",
      "Josef Trapl",
      "Julien Janda",
      "Stefan Romeder-Finger",
      "Thomas Gatternig",
      "Jean-Baptiste Farcet",
      "P\u00e9ter Galambos",
      "K\u00e1roly Sz\u00e9ll"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10129"
  },
  {
    "id": "arXiv:2106.10311",
    "title": "Universal Rate-Distortion-Perception Representations for Lossy  Compression",
    "abstract": "Universal Rate-Distortion-Perception Representations for Lossy  Compression",
    "descriptor": "",
    "authors": [
      "George Zhang",
      "Jingjing Qian",
      "Jun Chen",
      "Ashish Khisti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10311"
  },
  {
    "id": "arXiv:2106.10430",
    "title": "Multi-Contextual Design of Convolutional Neural Network for Steganalysis",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Brijesh Singh",
      "Arijit Sur",
      "Pinaki Mitra"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.10430"
  },
  {
    "id": "arXiv:2106.11853",
    "title": "Credal Self-Supervised Learning",
    "abstract": "Comments: 18 pages, 3 figures, 7 tables, NeurIPS 2021",
    "descriptor": "\nComments: 18 pages, 3 figures, 7 tables, NeurIPS 2021\n",
    "authors": [
      "Julian Lienen",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11853"
  },
  {
    "id": "arXiv:2106.12831",
    "title": "Extraction of common conceptual components from multiple ontologies",
    "abstract": "Extraction of common conceptual components from multiple ontologies",
    "descriptor": "",
    "authors": [
      "Luigi Asprino",
      "Valentina Anita Carriero",
      "Valentina Presutti"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.12831"
  },
  {
    "id": "arXiv:2106.15011",
    "title": "Are conditional GANs explicitly conditional?",
    "abstract": "Comments: BMVC2021",
    "descriptor": "\nComments: BMVC2021\n",
    "authors": [
      "Houssem-eddine Boulahbal",
      "Adrian Voicila",
      "Andrew Comport"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15011"
  },
  {
    "id": "arXiv:2106.15566",
    "title": "Near-Optimal Explainable $k$-Means for All Dimensions",
    "abstract": "Comments: 34 pages, 2 figures, to appear in SODA 2022",
    "descriptor": "\nComments: 34 pages, 2 figures, to appear in SODA 2022\n",
    "authors": [
      "Moses Charikar",
      "Lunjia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15566"
  },
  {
    "id": "arXiv:2106.15753",
    "title": "RCNN-SliceNet: A Slice and Cluster Approach for Nuclei Centroid  Detection in Three-Dimensional Fluorescence Microscopy Images",
    "abstract": "RCNN-SliceNet: A Slice and Cluster Approach for Nuclei Centroid  Detection in Three-Dimensional Fluorescence Microscopy Images",
    "descriptor": "",
    "authors": [
      "Liming Wu",
      "Shuo Han",
      "Alain Chen",
      "Paul Salama",
      "Kenneth W. Dunn",
      "Edward J. Delp"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15753"
  },
  {
    "id": "arXiv:2107.00052",
    "title": "Stochastic Gradient Descent-Ascent and Consensus Optimization for Smooth  Games: Convergence Analysis under Expected Co-coercivity",
    "abstract": "Comments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Nicolas Loizou",
      "Hugo Berard",
      "Gauthier Gidel",
      "Ioannis Mitliagkas",
      "Simon Lacoste-Julien"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00052"
  },
  {
    "id": "arXiv:2107.00717",
    "title": "SIMILAR: Submodular Information Measures Based Active Learning In  Realistic Scenarios",
    "abstract": "Comments: To Appear In Thirty-fifth Conference on Neural Information Processing Systems, NeurIPS 2021",
    "descriptor": "\nComments: To Appear In Thirty-fifth Conference on Neural Information Processing Systems, NeurIPS 2021\n",
    "authors": [
      "Suraj Kothawade",
      "Nathan Beck",
      "Krishnateja Killamsetty",
      "Rishabh Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00717"
  },
  {
    "id": "arXiv:2107.01863",
    "title": "On the Performance of Various Deep Transfer Learning CNN Models in  Glitch Waveform Identification in Gravitational-Wave Data",
    "abstract": "Comments: Presented at PUP College of Science Research Colloquium",
    "descriptor": "\nComments: Presented at PUP College of Science Research Colloquium\n",
    "authors": [
      "Reymond Mesuga",
      "Brian James Bayanay"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Space Physics (physics.space-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.01863"
  },
  {
    "id": "arXiv:2107.01952",
    "title": "Partition and Code: learning how to compress graphs",
    "abstract": "Comments: Published at NeurIPS 2021",
    "descriptor": "\nComments: Published at NeurIPS 2021\n",
    "authors": [
      "Giorgos Bouritsas",
      "Andreas Loukas",
      "Nikolaos Karalias",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01952"
  },
  {
    "id": "arXiv:2107.02990",
    "title": "Test for non-negligible adverse shifts",
    "abstract": "Comments: 14 pages, 4 figures, preprint",
    "descriptor": "\nComments: 14 pages, 4 figures, preprint\n",
    "authors": [
      "Vathy M. Kamulete"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.02990"
  },
  {
    "id": "arXiv:2107.05796",
    "title": "Co-evolution of Opinion and Social Tie Dynamics Towards Structural  Balance",
    "abstract": "Co-evolution of Opinion and Social Tie Dynamics Towards Structural  Balance",
    "descriptor": "",
    "authors": [
      "Haotian Wang",
      "Feng Luo",
      "Jie Gao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.05796"
  },
  {
    "id": "arXiv:2107.07792",
    "title": "Tight Bounds for Approximate Near Neighbor Searching for Time Series  under the Fr\u00e9chet Distance",
    "abstract": "Comments: to appear at SODA 2020",
    "descriptor": "\nComments: to appear at SODA 2020\n",
    "authors": [
      "Karl Bringmann",
      "Anne Driemel",
      "Andr\u00e9 Nusser",
      "Ioannis Psarros"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.07792"
  },
  {
    "id": "arXiv:2107.08399",
    "title": "A Method for Estimating the Entropy of Time Series Using Artificial  Neural Networks",
    "abstract": "Comments: 15 pages, 14 figures, 1 table",
    "descriptor": "\nComments: 15 pages, 14 figures, 1 table\n",
    "authors": [
      "Andrei Velichko",
      "Hanif Heidari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2107.08399"
  },
  {
    "id": "arXiv:2107.09323",
    "title": "Transfer Learning for Credit Card Fraud Detection: A Journey from  Research to Production",
    "abstract": "Transfer Learning for Credit Card Fraud Detection: A Journey from  Research to Production",
    "descriptor": "",
    "authors": [
      "Wissam Siblini",
      "Guillaume Coter",
      "R\u00e9my Fabry",
      "Liyun He-Guelton",
      "Fr\u00e9d\u00e9ric Obl\u00e9",
      "Bertrand Lebichot",
      "Yann-A\u00ebl Le Borgne",
      "Gianluca Bontempi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.09323"
  },
  {
    "id": "arXiv:2107.13659",
    "title": "Quantum Annealing Algorithms for Boolean Tensor Networks",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Elijah Pelofske",
      "Georg Hahn",
      "Daniel O'Malley",
      "Hristo N. Djidjev",
      "Boian S. Alexandrov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2107.13659"
  },
  {
    "id": "arXiv:2107.14483",
    "title": "ManiSkill: Generalizable Manipulation Skill Benchmark with Large-Scale  Demonstrations",
    "abstract": "Comments: NeurIPS 2021 Track on Datasets and Benchmarks; code: this https URL",
    "descriptor": "\nComments: NeurIPS 2021 Track on Datasets and Benchmarks; code: this https URL\n",
    "authors": [
      "Tongzhou Mu",
      "Zhan Ling",
      "Fanbo Xiang",
      "Derek Yang",
      "Xuanlin Li",
      "Stone Tao",
      "Zhiao Huang",
      "Zhiwei Jia",
      "Hao Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.14483"
  },
  {
    "id": "arXiv:2108.01455",
    "title": "FEBR: Expert-Based Recommendation Framework for beneficial and  personalized content",
    "abstract": "Comments: Preprint. Under review",
    "descriptor": "\nComments: Preprint. Under review\n",
    "authors": [
      "Mohamed Lechiakh",
      "Alexandre Maurer"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.01455"
  },
  {
    "id": "arXiv:2108.03272",
    "title": "iGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday  Household Tasks",
    "abstract": "Comments: Accepted at Conference on Robot Learning (CoRL) 2021. Project website: this http URL",
    "descriptor": "\nComments: Accepted at Conference on Robot Learning (CoRL) 2021. Project website: this http URL\n",
    "authors": [
      "Chengshu Li",
      "Fei Xia",
      "Roberto Mart\u00edn-Mart\u00edn",
      "Michael Lingelbach",
      "Sanjana Srivastava",
      "Bokui Shen",
      "Kent Vainio",
      "Cem Gokmen",
      "Gokul Dharan",
      "Tanish Jain",
      "Andrey Kurenkov",
      "C. Karen Liu",
      "Hyowon Gweon",
      "Jiajun Wu",
      "Li Fei-Fei",
      "Silvio Savarese"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.03272"
  },
  {
    "id": "arXiv:2108.03997",
    "title": "A new step for computing",
    "abstract": "Comments: in French",
    "descriptor": "\nComments: in French\n",
    "authors": [
      "Xavier Vasques"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.03997"
  },
  {
    "id": "arXiv:2108.04927",
    "title": "Embodied BERT: A Transformer Model for Embodied, Language-guided Visual  Task Completion",
    "abstract": "Comments: Accepted at Novel Ideas in Learning-to-Learn through Interaction (NILLI) workshop @ EMNLP 2021",
    "descriptor": "\nComments: Accepted at Novel Ideas in Learning-to-Learn through Interaction (NILLI) workshop @ EMNLP 2021\n",
    "authors": [
      "Alessandro Suglia",
      "Qiaozi Gao",
      "Jesse Thomason",
      "Govind Thattai",
      "Gaurav Sukhatme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04927"
  },
  {
    "id": "arXiv:2108.13217",
    "title": "Equivariant relative submajorization",
    "abstract": "Comments: 24 pages, v2: minor corrections, one application slightly extended",
    "descriptor": "\nComments: 24 pages, v2: minor corrections, one application slightly extended\n",
    "authors": [
      "Gergely Bunth",
      "P\u00e9ter Vrana"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.13217"
  },
  {
    "id": "arXiv:2109.00685",
    "title": "Excess Capacity and Backdoor Poisoning",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Naren Sarayu Manoj",
      "Avrim Blum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.00685"
  },
  {
    "id": "arXiv:2109.01461",
    "title": "Dive into Layers: Neural Network Capacity Bounding using Algebraic  Geometry",
    "abstract": "Dive into Layers: Neural Network Capacity Bounding using Algebraic  Geometry",
    "descriptor": "",
    "authors": [
      "Ji Yang",
      "Lu Sang",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.01461"
  },
  {
    "id": "arXiv:2109.02538",
    "title": "Bounding Means of Discrete Distributions",
    "abstract": "Comments: 9 pages, 8 figures",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Eric Bax",
      "Fr\u00e9d\u00e9ric Ouimet"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2109.02538"
  },
  {
    "id": "arXiv:2109.02791",
    "title": "Safety-Critical Modular Deep Reinforcement Learning with Temporal Logic  through Gaussian Processes and Control Barrier Functions",
    "abstract": "Comments: Under Review. arXiv admin note: text overlap with arXiv:2102.12855",
    "descriptor": "\nComments: Under Review. arXiv admin note: text overlap with arXiv:2102.12855\n",
    "authors": [
      "Mingyu Cai",
      "Cristian-Ioan Vasile"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02791"
  },
  {
    "id": "arXiv:2109.03582",
    "title": "Higher Order Kernel Mean Embeddings to Capture Filtrations of Stochastic  Processes",
    "abstract": "Comments: Published at NeurIPS 2021",
    "descriptor": "\nComments: Published at NeurIPS 2021\n",
    "authors": [
      "Cristopher Salvi",
      "Maud Lemercier",
      "Chong Liu",
      "Blanka Hovarth",
      "Theodoros Damoulas",
      "Terry Lyons"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03582"
  },
  {
    "id": "arXiv:2109.03592",
    "title": "Strong Scaling of OpenACC enabled Nek5000 on several GPU based HPC  systems",
    "abstract": "Comments: 9 pages, 8 figures. Submitted to HPC-Asia 2022 conference, updated to address reviewers comments",
    "descriptor": "\nComments: 9 pages, 8 figures. Submitted to HPC-Asia 2022 conference, updated to address reviewers comments\n",
    "authors": [
      "Jonathan Vincent",
      "Jing Gong",
      "Martin Karp",
      "Adam Peplinski",
      "Niclas Jansson",
      "Artur Podobas",
      "Andreas Jocksch",
      "Jie Yao",
      "Fazle Hussain",
      "Stefano Markidis",
      "Matts Karlsson",
      "Dirk Pleiter",
      "Erwin Laure",
      "Philipp Schlatter"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.03592"
  },
  {
    "id": "arXiv:2109.04847",
    "title": "Active learning for reducing labeling effort in text classification  tasks",
    "abstract": "Comments: Accepted as a conference paper at the joint 33rd Benelux Conference on Artificial Intelligence and the 30th Belgian Dutch Conference on Machine Learning (BNAIC/BENELEARN 2021). This camera-ready version submitted to BNAIC/BENELEARN, adds several improvements including a more thorough discussion of related work plus an extended discussion section. 28 pages including references and appendices",
    "descriptor": "\nComments: Accepted as a conference paper at the joint 33rd Benelux Conference on Artificial Intelligence and the 30th Belgian Dutch Conference on Machine Learning (BNAIC/BENELEARN 2021). This camera-ready version submitted to BNAIC/BENELEARN, adds several improvements including a more thorough discussion of related work plus an extended discussion section. 28 pages including references and appendices\n",
    "authors": [
      "Pieter Floris Jacobs",
      "Gideon Maillette de Buy Wenniger",
      "Marco Wiering",
      "Lambert Schomaker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04847"
  },
  {
    "id": "arXiv:2109.05070",
    "title": "Instance-Conditioned GAN",
    "abstract": "Comments: Accepted at NeurIPS2021",
    "descriptor": "\nComments: Accepted at NeurIPS2021\n",
    "authors": [
      "Arantxa Casanova",
      "Marl\u00e8ne Careil",
      "Jakob Verbeek",
      "Michal Drozdzal",
      "Adriana Romero-Soriano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05070"
  },
  {
    "id": "arXiv:2109.11313",
    "title": "Physics-informed neural networks for 1D sound field predictions with  parameterized sources and impedance boundaries",
    "abstract": "Comments: 19 pages (double line spacing), 3 figures, 2 tables",
    "descriptor": "\nComments: 19 pages (double line spacing), 3 figures, 2 tables\n",
    "authors": [
      "Nikolas Borrel-Jensen",
      "Allan P. Engsig-Karup",
      "Cheol-Ho Jeong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.11313"
  },
  {
    "id": "arXiv:2109.11541",
    "title": "CSAGN: Conversational Structure Aware Graph Network for Conversational  Semantic Role Labeling",
    "abstract": "Comments: To appear in EMNLP 2021",
    "descriptor": "\nComments: To appear in EMNLP 2021\n",
    "authors": [
      "Han Wu",
      "Kun Xu",
      "Linqi Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.11541"
  },
  {
    "id": "arXiv:2109.14199",
    "title": "Who speaks like a style of Vitamin: Towards Syntax-Aware  DialogueSummarization using Multi-task Learning",
    "abstract": "Comments: This work has been accepted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been accepted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Seolhwa Lee",
      "Kisu Yang",
      "Chanjun Park",
      "Jo\u00e3o Sedoc",
      "Heuiseok Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.14199"
  },
  {
    "id": "arXiv:2109.14382",
    "title": "UFO-ViT: High Performance Linear Vision Transformer without Softmax",
    "abstract": "UFO-ViT: High Performance Linear Vision Transformer without Softmax",
    "descriptor": "",
    "authors": [
      "Jeong-geun Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.14382"
  },
  {
    "id": "arXiv:2109.15296",
    "title": "Electronic Observables for Relaxed Bilayer 2D Heterostructures in  Momentum Space",
    "abstract": "Comments: 33 pages, 6 figures",
    "descriptor": "\nComments: 33 pages, 6 figures\n",
    "authors": [
      "Daniel Massatt",
      "Stephen Carr",
      "Mitchell Luskin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.15296"
  },
  {
    "id": "arXiv:2110.00115",
    "title": "Comparing Sequential Forecasters",
    "abstract": "Comments: Code and data sources available at this https URL",
    "descriptor": "\nComments: Code and data sources available at this https URL\n",
    "authors": [
      "Yo Joong Choe",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.00115"
  },
  {
    "id": "arXiv:2110.00530",
    "title": "A survey on datasets for fairness-aware machine learning",
    "abstract": "Comments: 49 pages, 33 figures, 20 tables",
    "descriptor": "\nComments: 49 pages, 33 figures, 20 tables\n",
    "authors": [
      "Tai Le Quy",
      "Arjun Roy",
      "Vasileios Iosifidis",
      "Eirini Ntoutsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00530"
  },
  {
    "id": "arXiv:2110.01069",
    "title": "Hinged Truchet tiling fractals",
    "abstract": "Comments: 15 pages, 21 figures; update to correct spellings",
    "descriptor": "\nComments: 15 pages, 21 figures; update to correct spellings\n",
    "authors": [
      "H Verrill"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.01069"
  },
  {
    "id": "arXiv:2110.01396",
    "title": "Non-linear Gaussian smoothing with Taylor moment expansion",
    "abstract": "Comments: 5 pages, 1 figure",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Zheng Zhao",
      "Simo S\u00e4rkk\u00e4"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.01396"
  },
  {
    "id": "arXiv:2110.02224",
    "title": "Transparent Forwarders: An Unnoticed Component of the Open DNS  Infrastructure",
    "abstract": "Comments: Proc. of ACM CoNEXT'21, camera-ready",
    "descriptor": "\nComments: Proc. of ACM CoNEXT'21, camera-ready\n",
    "authors": [
      "Marcin Nawrocki",
      "Maynard Koch",
      "Thomas C. Schmidt",
      "Matthias W\u00e4hlisch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.02224"
  },
  {
    "id": "arXiv:2110.02743",
    "title": "Towards efficient end-to-end speech recognition with  biologically-inspired neural networks",
    "abstract": "Comments: Accepted at the Efficient Natural Language and Speech Processing workshop at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at the Efficient Natural Language and Speech Processing workshop at NeurIPS 2021\n",
    "authors": [
      "Thomas Bohnstingl",
      "Ayush Garg",
      "Stanis\u0142aw Wo\u017aniak",
      "George Saon",
      "Evangelos Eleftheriou",
      "Angeliki Pantazi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.02743"
  },
  {
    "id": "arXiv:2110.04400",
    "title": "HydraSum: Disentangling Stylistic Features in Text Summarization using  Multi-Decoder Models",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Tanya Goyal",
      "Nazneen Fatema Rajani",
      "Wenhao Liu",
      "Wojciech Kry\u015bci\u0144ski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04400"
  },
  {
    "id": "arXiv:2110.05555",
    "title": "QAOAKit: A Toolkit for Reproducible Study, Application, and Verification  of the QAOA",
    "abstract": "Comments: Fixed typo, missing fonts on macOS",
    "descriptor": "\nComments: Fixed typo, missing fonts on macOS\n",
    "authors": [
      "Ruslan Shaydulin",
      "Kunal Marwaha",
      "Jonathan Wurtz",
      "Phillip C. Lotshaw"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.05555"
  },
  {
    "id": "arXiv:2110.06980",
    "title": "Output Space Entropy Search Framework for Multi-Objective Bayesian  Optimization",
    "abstract": "Comments: Accepted to Journal of Artificial Intelligence Research. arXiv admin note: substantial text overlap with arXiv:2009.05700, arXiv:2009.01721, arXiv:2011.01542",
    "descriptor": "\nComments: Accepted to Journal of Artificial Intelligence Research. arXiv admin note: substantial text overlap with arXiv:2009.05700, arXiv:2009.01721, arXiv:2011.01542\n",
    "authors": [
      "Syrine Belakaria",
      "Aryan Deshwal",
      "Janardhan Rao Doppa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06980"
  },
  {
    "id": "arXiv:2110.07897",
    "title": "Improving Unsupervised Domain Adaptive Re-Identification via  Source-Guided Selection of Pseudo-Labeling Hyperparameters",
    "abstract": "Comments: Preprint version. Accepted in IEEE Access (see IEEE Access for final version)",
    "descriptor": "\nComments: Preprint version. Accepted in IEEE Access (see IEEE Access for final version)\n",
    "authors": [
      "Fabian Dubourvieux",
      "Ang\u00e9lique Loesch",
      "Romaric Audigier",
      "Samia Ainouz",
      "St\u00e9phane Canu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07897"
  },
  {
    "id": "arXiv:2110.09319",
    "title": "Incremental Cross-Domain Adaptation for Robust Retinopathy Screening via  Bayesian Deep Learning",
    "abstract": "Comments: Accepted in IEEE Transactions on Instrumentation and Measurement. Source code is available at this https URL",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Instrumentation and Measurement. Source code is available at this https URL\n",
    "authors": [
      "Taimur Hassan",
      "Bilal Hassan",
      "Muhammad Usman Akram",
      "Shahrukh Hashmi",
      "Abdel Hakim Taguri",
      "Naoufel Werghi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09319"
  },
  {
    "id": "arXiv:2110.10055",
    "title": "The fully compressed subgroup membership problem",
    "abstract": "Comments: 11 pages, 2 figures",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Marco Linton"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.10055"
  },
  {
    "id": "arXiv:2110.11128",
    "title": "A Strong Baseline for Semi-Supervised Incremental Few-Shot Learning",
    "abstract": "Comments: Accepted by BMVC2021",
    "descriptor": "\nComments: Accepted by BMVC2021\n",
    "authors": [
      "Linlan Zhao",
      "Dashan Guo",
      "Yunlu Xu",
      "Liang Qiao",
      "Zhanzhan Cheng",
      "Shiliang Pu",
      "Yi Niu",
      "Xiangzhong Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11128"
  },
  {
    "id": "arXiv:2110.11144",
    "title": "RCT: Random Consistency Training for Semi-supervised Sound Event  Detection",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Nian Shao",
      "Erfan Loweimi",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.11144"
  },
  {
    "id": "arXiv:2110.12654",
    "title": "Facilitating Database Tuning with Hyper-Parameter Optimization: A  Comprehensive Experimental Evaluation",
    "abstract": "Facilitating Database Tuning with Hyper-Parameter Optimization: A  Comprehensive Experimental Evaluation",
    "descriptor": "",
    "authors": [
      "Xinyi Zhang",
      "Zhuo Chang",
      "Yang Li",
      "Hong Wu",
      "Jian Tan",
      "Feifei Li",
      "Bin Cui"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.12654"
  },
  {
    "id": "arXiv:2110.14120",
    "title": "ScaleCert: Scalable Certified Defense against Adversarial Patches with  Sparse Superficial Layers",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Husheng Han",
      "Kaidi Xu",
      "Xing Hu",
      "Xiaobing Chen",
      "Ling Liang",
      "Zidong Du",
      "Qi Guo",
      "Yanzhi Wang",
      "Yunji Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14120"
  },
  {
    "id": "arXiv:2110.14434",
    "title": "Nonnegative Tucker Decomposition with Beta-divergence for Music  Structure Analysis of audio signals",
    "abstract": "Comments: 4 pages, 2 figures, 1 table, 1 algorithm, submitted to ICASSP 2022",
    "descriptor": "\nComments: 4 pages, 2 figures, 1 table, 1 algorithm, submitted to ICASSP 2022\n",
    "authors": [
      "Axel Marmoret",
      "Florian Voorwinden",
      "Valentin Leplat",
      "J\u00e9r\u00e9my E. Cohen",
      "Fr\u00e9d\u00e9ric Bimbot"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.14434"
  },
  {
    "id": "arXiv:2110.15225",
    "title": "Pruning Attention Heads of Transformer Models Using A* Search: A Novel  Approach to Compress Big NLP Architectures",
    "abstract": "Comments: 23 Pages, 18 figures, 3 tables",
    "descriptor": "\nComments: 23 Pages, 18 figures, 3 tables\n",
    "authors": [
      "Archit Parnami",
      "Rahul Singh",
      "Tarun Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15225"
  },
  {
    "id": "arXiv:2111.00452",
    "title": "Experimental Study on the Imitation of the Human Head-and-Eye Pose Using  the 3-DOF Agile Eye Parallel Robot with ROS and Mediapipe Framework",
    "abstract": "Experimental Study on the Imitation of the Human Head-and-Eye Pose Using  the 3-DOF Agile Eye Parallel Robot with ROS and Mediapipe Framework",
    "descriptor": "",
    "authors": [
      "Amirmohammad Radmehr",
      "Milad Asgari",
      "Mehdi Tale Masouleh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00452"
  },
  {
    "id": "arXiv:2111.00602",
    "title": "On the Optimal Time/Space Tradeoff for Hash Tables",
    "abstract": "Comments: 48 pages",
    "descriptor": "\nComments: 48 pages\n",
    "authors": [
      "Michael A. Bender",
      "Mart\u00edn Farach-Colton",
      "John Kuszmaul",
      "William Kuszmaul",
      "Mingmou Liu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.00602"
  },
  {
    "id": "arXiv:2111.00658",
    "title": "RMNA: A Neighbor Aggregation-Based Knowledge Graph Representation  Learning Model Using Rule Mining",
    "abstract": "Comments: 22 pages, 2 figures",
    "descriptor": "\nComments: 22 pages, 2 figures\n",
    "authors": [
      "Ling Chen",
      "Jun Cui",
      "Xing Tang",
      "Chaodu Song",
      "Yuntao Qian",
      "Yansheng Li",
      "Yongjun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00658"
  },
  {
    "id": "arXiv:2111.00791",
    "title": "Learning Event-based Spatio-Temporal Feature Descriptors via Local  Synaptic Plasticity: A Biologically-realistic Perspective of Computer Vision",
    "abstract": "Learning Event-based Spatio-Temporal Feature Descriptors via Local  Synaptic Plasticity: A Biologically-realistic Perspective of Computer Vision",
    "descriptor": "",
    "authors": [
      "Ali Safa",
      "Hichem Sahli",
      "Andr\u00e9 Bourdoux",
      "Ilja Ocket",
      "Francky Catthoor",
      "Georges Gielen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.00791"
  },
  {
    "id": "arXiv:2111.00993",
    "title": "Egocentric Human Trajectory Forecasting with a Wearable Camera and  Multi-Modal Fusion",
    "abstract": "Egocentric Human Trajectory Forecasting with a Wearable Camera and  Multi-Modal Fusion",
    "descriptor": "",
    "authors": [
      "Jianing Qiu",
      "Lipeng Chen",
      "Xiao Gu",
      "Frank P.-W. Lo",
      "Ya-Yen Tsai",
      "Jiankai Sun",
      "Jiaqi Liu",
      "Benny Lo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00993"
  },
  {
    "id": "arXiv:2111.00998",
    "title": "PDE-READ: Human-readable Partial Differential Equation Discovery using  Deep Learning",
    "abstract": "Comments: 32 pages, 14 figures",
    "descriptor": "\nComments: 32 pages, 14 figures\n",
    "authors": [
      "Robert Stephany",
      "Christopher Earls"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00998"
  },
  {
    "id": "arXiv:2111.01225",
    "title": "Identifying causal associations in tweets using deep learning: Use case  on diabetes-related tweets from 2017-2021",
    "abstract": "Comments: 6 Figures, 4 Tables",
    "descriptor": "\nComments: 6 Figures, 4 Tables\n",
    "authors": [
      "Adrian Ahne",
      "Vivek Khetan",
      "Xavier Tannier",
      "Md Imbessat Hassan Rizvi",
      "Thomas Czernichow",
      "Francisco Orchard",
      "Charline Bour",
      "Andrew Fano",
      "Guy Fagherazzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01225"
  },
  {
    "id": "arXiv:2111.01228",
    "title": "OPF-Learn: An Open-Source Framework for Creating Representative AC  Optimal Power Flow Datasets",
    "abstract": "Comments: 5 pages, 3 figures, 2 Tables. Accepted at ISGT-NA'2022",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 Tables. Accepted at ISGT-NA'2022\n",
    "authors": [
      "Trager Joswig-Jones",
      "Kyri Baker",
      "Ahmed S. Zamzam"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.01228"
  },
  {
    "id": "arXiv:2111.01245",
    "title": "Learning Eye-in-Hand Camera Calibration from a Single Image",
    "abstract": "Comments: Published at the 2021 Conference on Robot Learning (CoRL). Webpage and video: this https URL",
    "descriptor": "\nComments: Published at the 2021 Conference on Robot Learning (CoRL). Webpage and video: this https URL\n",
    "authors": [
      "Eugene Valassakis",
      "Kamil Dreczkowski",
      "Edward Johns"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01245"
  },
  {
    "id": "arXiv:2111.01374",
    "title": "A Game of Primes",
    "abstract": "Comments: This paper is being reviewed by SN Computer Science",
    "descriptor": "\nComments: This paper is being reviewed by SN Computer Science\n",
    "authors": [
      "Raghavendra Bhat"
    ],
    "subjectives": [
      "General Mathematics (math.GM)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.01374"
  },
  {
    "id": "arXiv:2111.01549",
    "title": "Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by  Finding Flat Minima",
    "abstract": "Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by  Finding Flat Minima",
    "descriptor": "",
    "authors": [
      "Guangyuan Shi",
      "Jiaxin Chen",
      "Wenlong Zhang",
      "Li-Ming Zhan",
      "Xiao-Ming Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01549"
  },
  {
    "id": "arXiv:2111.01701",
    "title": "Improve Single-Point Zeroth-Order Optimization Using High-Pass and  Low-Pass Filters",
    "abstract": "Improve Single-Point Zeroth-Order Optimization Using High-Pass and  Low-Pass Filters",
    "descriptor": "",
    "authors": [
      "Xin Chen",
      "Yujie Tang",
      "Na Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01701"
  },
  {
    "id": "arXiv:2111.01868",
    "title": "From Strings to Data Science: a Practical Framework for Automated String  Handling",
    "abstract": "From Strings to Data Science: a Practical Framework for Automated String  Handling",
    "descriptor": "",
    "authors": [
      "John W. van Lith",
      "Joaquin Vanschoren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01868"
  },
  {
    "id": "arXiv:2111.01881",
    "title": "Stochastic simulation of residential building occupant-driven energy use  in a bottom-up model of the U.S. housing stock",
    "abstract": "Stochastic simulation of residential building occupant-driven energy use  in a bottom-up model of the U.S. housing stock",
    "descriptor": "",
    "authors": [
      "Jianli Chen",
      "Rajendra Adhikari",
      "Eric Wilson",
      "Joseph Robertson",
      "Anthony Fontanini",
      "Ben Polly",
      "Opeoluwa Olawale"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2111.01881"
  },
  {
    "id": "arXiv:2111.01968",
    "title": "A Survey on Epistemic (Model) Uncertainty in Supervised Learning: Recent  Advances and Applications",
    "abstract": "Comments: 45pages, 4 figures",
    "descriptor": "\nComments: 45pages, 4 figures\n",
    "authors": [
      "Xinlei Zhou",
      "Han Liu",
      "Farhad Pourpanah",
      "Tieyong Zeng",
      "Xizhao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01968"
  },
  {
    "id": "arXiv:2111.01988",
    "title": "Belief Propagation based Joint Detection and Decoding for Resistive  Random Access Memories",
    "abstract": "Comments: 34 pages, 17 figures",
    "descriptor": "\nComments: 34 pages, 17 figures\n",
    "authors": [
      "Ce Sun",
      "Kui Cai",
      "Guanghui Song",
      "Tony Q. S. Quek",
      "Zesong Fei"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.01988"
  },
  {
    "id": "arXiv:2111.02038",
    "title": "Can We Achieve Fairness Using Semi-Supervised Learning?",
    "abstract": "Can We Achieve Fairness Using Semi-Supervised Learning?",
    "descriptor": "",
    "authors": [
      "Joymallya Chakraborty",
      "Huy Tu",
      "Suvodeep Majumder",
      "Tim Menzies"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02038"
  },
  {
    "id": "arXiv:2111.02188",
    "title": "BERT-DRE: BERT with Deep Recursive Encoder for Natural Language Sentence  Matching",
    "abstract": "BERT-DRE: BERT with Deep Recursive Encoder for Natural Language Sentence  Matching",
    "descriptor": "",
    "authors": [
      "Ehsan Tavan",
      "Ali Rahmati",
      "Maryam Najafi",
      "Saeed Bibak",
      "Zahed Rahmati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.02188"
  },
  {
    "id": "arXiv:2111.02212",
    "title": "Swarm intelligence algorithms applied to Virtual Reference Feedback  Tuning to increase controller robustness -- a one-shot technique",
    "abstract": "Comments: 35 pages, 10 figures, journal",
    "descriptor": "\nComments: 35 pages, 10 figures, journal\n",
    "authors": [
      "L. V. Fiorio",
      "C. L. Remes",
      "Y. R. de Novaes"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02212"
  },
  {
    "id": "arXiv:2111.02259",
    "title": "A Case Study and Qualitative Analysis of Simple Cross-Lingual Opinion  Mining",
    "abstract": "Comments: 10 pages, 2 tables, 5 figures, full paper, peer-reviewed, published at KDIR/IC3k 2021 conference",
    "descriptor": "\nComments: 10 pages, 2 tables, 5 figures, full paper, peer-reviewed, published at KDIR/IC3k 2021 conference\n",
    "authors": [
      "Gerhard Hagerer",
      "Wing Sheung Leung",
      "Qiaoxi Liu",
      "Hannah Danner",
      "Georg Groh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.02259"
  }
]
[
  {
    "id": "arXiv:2111.01127",
    "title": "NSS-VAEs: Generative Scene Decomposition for Visual Navigable Space  Construction",
    "abstract": "Detecting navigable space is the first and also a critical step for\nsuccessful robot navigation. In this work, we treat the visual navigable space\nsegmentation as a scene decomposition problem and propose a new network,\nNSS-VAEs (Navigable Space Segmentation Variational AutoEncoders), a\nrepresentation-learning-based framework to enable robots to learn the navigable\nspace segmentation in an unsupervised manner. Different from prevalent\nsegmentation techniques which heavily rely on supervised learning strategies\nand typically demand immense pixel-level annotated images, the proposed\nframework leverages a generative model - Variational Auto-Encoder (VAE) - to\nlearn a probabilistic polyline representation that compactly outlines the\ndesired navigable space boundary. Uniquely, our method also assesses the\nprediction uncertainty related to the unstructuredness of the scenes, which is\nimportant for robot navigation in unstructured environments. Through extensive\nexperiments, we have validated that our proposed method can achieve remarkably\nhigh accuracy (>90%) even without a single label. We also show that the\nprediction of NSS-VAEs can be further improved using few labels with results\nsignificantly outperforming the SOTA fully supervised-learning-based method.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2111.00063\n",
    "authors": [
      "Zheng Chen",
      "Lantao Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.01127"
  },
  {
    "id": "arXiv:2111.01131",
    "title": "Hierarchical Decision Ensembles- An inferential framework for uncertain  Human-AI collaboration in forensic examinations",
    "abstract": "Forensic examination of evidence like firearms and toolmarks, traditionally\ninvolves a visual and therefore subjective assessment of similarity of two\nquestioned items. Statistical models are used to overcome this subjectivity and\nallow specification of error rates. These models are generally quite complex\nand produce abstract results at different levels of the analysis. Presenting\nsuch metrics and complicated results to examiners is challenging, as examiners\ngenerally do not have substantial statistical training to accurately interpret\nresults. This creates distrust in statistical modelling and lowers the rate of\nacceptance of more objective measures that the discipline at large is striving\nfor. We present an inferential framework for assessing the model and its\noutput. The framework is designed to calibrate trust in forensic experts by\nbridging the gap between domain specific knowledge and predictive model\nresults, allowing forensic examiners to validate the claims of the predictive\nmodel while critically assessing results.",
    "descriptor": "\nComments: 33 pages, 17 figures\n",
    "authors": [
      "Ganesh Krishnan",
      "Heike Hofmann"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.01131"
  },
  {
    "id": "arXiv:2111.01135",
    "title": "Arch-Net: Model Distillation for Architecture Agnostic Model Deployment",
    "abstract": "Vast requirement of computation power of Deep Neural Networks is a major\nhurdle to their real world applications. Many recent Application Specific\nIntegrated Circuit (ASIC) chips feature dedicated hardware support for Neural\nNetwork Acceleration. However, as ASICs take multiple years to develop, they\nare inevitably out-paced by the latest development in Neural Architecture\nResearch. For example, Transformer Networks do not have native support on many\npopular chips, and hence are difficult to deploy. In this paper, we propose\nArch-Net, a family of Neural Networks made up of only operators efficiently\nsupported across most architectures of ASICs. When a Arch-Net is produced, less\ncommon network constructs, like Layer Normalization and Embedding Layers, are\neliminated in a progressive manner through label-free Blockwise Model\nDistillation, while performing sub-eight bit quantization at the same time to\nmaximize performance. Empirical results on machine translation and image\nclassification tasks confirm that we can transform latest developed Neural\nArchitectures into fast running and as-accurate Arch-Net, ready for deployment\non multiple mass-produced ASIC chips. The code will be available at\nhttps://github.com/megvii-research/Arch-Net.",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Weixin Xu",
      "Zipeng Feng",
      "Shuangkang Fang",
      "Song Yuan",
      "Yi Yang",
      "Shuchang Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01135"
  },
  {
    "id": "arXiv:2111.01136",
    "title": "ASMDD: Arabic Speech Mispronunciation Detection Dataset",
    "abstract": "The largest dataset of Arabic speech mispronunciation detections in Egyptian\ndialogues is introduced. The dataset is composed of annotated audio files\nrepresenting the top 100 words that are most frequently used in the Arabic\nlanguage, pronounced by 100 Egyptian children (aged between 2 and 8 years old).\nThe dataset is collected and annotated on segmental pronunciation error\ndetections by expert listeners.",
    "descriptor": "\nComments: 3 pages, 2 tables, 2 figures, dataset link: this https URL\n",
    "authors": [
      "Salah A. Aly",
      "Abdelrahman Salah",
      "Hesham M. Eraqi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.01136"
  },
  {
    "id": "arXiv:2111.01166",
    "title": "Investigating the locality of neural network training dynamics",
    "abstract": "A fundamental quest in the theory of deep-learning is to understand the\nproperties of the trajectories in the weight space that a learning algorithm\ntakes. One such property that had very recently been isolated is that of \"local\nelasticity\" ($S_{\\rm rel}$), which quantifies the propagation of influence of a\nsampled data point on the prediction at another data point. In this work, we\nperform a comprehensive study of local elasticity by providing new theoretical\ninsights and more careful empirical evidence of this property in a variety of\nsettings. Firstly, specific to the classification setting, we suggest a new\ndefinition of the original idea of $S_{\\rm rel}$. Via experiments on\nstate-of-the-art neural networks training on SVHN, CIFAR-10 and CIFAR-100 we\ndemonstrate how our new $S_{\\rm rel}$ detects the property of the weight\nupdates preferring to make changes in predictions within the same class of the\nsampled data. Next, we demonstrate via examples of neural nets doing regression\nthat the original $S_{\\rm rel}$ reveals a $2-$phase behaviour: that their\ntraining proceeds via an initial elastic phase when $S_{\\rm rel}$ changes\nrapidly and an eventual inelastic phase when $S_{\\rm rel}$ remains large.\nLastly, we give multiple examples of learning via gradient flows for which one\ncan get a closed-form expression of the original $S_{\\rm rel}$ function. By\nstudying the plots of these derived formulas we given a theoretical\ndemonstration of some of the experimentally detected properties of $S_{\\rm\nrel}$ in the regression setting.",
    "descriptor": "\nComments: 13 pages (double column) + 6 pages (single column)\n",
    "authors": [
      "Soham Dan",
      "Phanideep Gampa",
      "Anirbit Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01166"
  },
  {
    "id": "arXiv:2111.01177",
    "title": "Don't Generate Me: Training Differentially Private Generative Models  with Sinkhorn Divergence",
    "abstract": "Although machine learning models trained on massive data have led to\nbreak-throughs in several areas, their deployment in privacy-sensitive domains\nremains limited due to restricted access to data. Generative models trained\nwith privacy constraints on private data can sidestep this challenge, providing\nindirect access to private data instead. We propose DP-Sinkhorn, a novel\noptimal transport-based generative method for learning data distributions from\nprivate data with differential privacy. DP-Sinkhorn minimizes the Sinkhorn\ndivergence, a computationally efficient approximation to the exact optimal\ntransport distance, between the model and data in a differentially private\nmanner and uses a novel technique for control-ling the bias-variance trade-off\nof gradient estimates. Unlike existing approaches for training differentially\nprivate generative models, which are mostly based on generative adversarial\nnetworks, we do not rely on adversarial objectives, which are notoriously\ndifficult to optimize, especially in the presence of noise imposed by privacy\nconstraints. Hence, DP-Sinkhorn is easy to train and deploy. Experimentally, we\nimprove upon the state-of-the-art on multiple image modeling benchmarks and\nshow differentially private synthesis of informative RGB images. Project\npage:https://nv-tlabs.github.io/DP-Sinkhorn.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021. 13 pages, 7 pages of supplementary; 6 tables, 8 figures\n",
    "authors": [
      "Tianshi Cao",
      "Alex Bie",
      "Arash Vahdat",
      "Sanja Fidler",
      "Karsten Kreis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.01177"
  },
  {
    "id": "arXiv:2111.01181",
    "title": "Convergent adaptive hybrid higher-order schemes for convex minimization",
    "abstract": "This paper proposes two convergent adaptive mesh-refining algorithms for the\nhybrid high-order method in convex minimization problems with two-sided\np-growth. Examples include the p-Laplacian, an optimal design problem in\ntopology optimization, and the convexified double-well problem. The hybrid\nhigh-order method utilizes a gradient reconstruction in the space of piecewise\nRaviart-Thomas finite element functions without stabilization on triangulations\ninto simplices or in the space of piecewise polynomials with stabilization on\npolytopal meshes. The main results imply the convergence of the energy and,\nunder further convexity properties, of the approximations of the primal resp.\ndual variable. Numerical experiments illustrate an efficient approximation of\nsingular minimizers and improved convergence rates for higher polynomial\ndegrees. Computer simulations provide striking numerical evidence that an\nadopted adaptive HHO algorithm can overcome the Lavrentiev gap phenomenon even\nwith empirical higher convergence rates.",
    "descriptor": "",
    "authors": [
      "Carsten Carstensen",
      "Ngoc Tien Tran"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.01181"
  },
  {
    "id": "arXiv:2111.01186",
    "title": "Combining Latent Space and Structured Kernels for Bayesian Optimization  over Combinatorial Spaces",
    "abstract": "We consider the problem of optimizing combinatorial spaces (e.g., sequences,\ntrees, and graphs) using expensive black-box function evaluations. For example,\noptimizing molecules for drug design using physical lab experiments. Bayesian\noptimization (BO) is an efficient framework for solving such problems by\nintelligently selecting the inputs with high utility guided by a learned\nsurrogate model. A recent BO approach for combinatorial spaces is through a\nreduction to BO over continuous spaces by learning a latent representation of\nstructures using deep generative models (DGMs). The selected input from the\ncontinuous space is decoded into a discrete structure for performing function\nevaluation. However, the surrogate model over the latent space only uses the\ninformation learned by the DGM, which may not have the desired inductive bias\nto approximate the target black-box function. To overcome this drawback, this\npaper proposes a principled approach referred as LADDER. The key idea is to\ndefine a novel structure-coupled kernel that explicitly integrates the\nstructural information from decoded structures with the learned latent space\nrepresentation for better surrogate modeling. Our experiments on real-world\nbenchmarks show that LADDER significantly improves over the BO over latent\nspace method, and performs better or similar to state-of-the-art methods.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Aryan Deshwal",
      "Janardhan Rao Doppa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01186"
  },
  {
    "id": "arXiv:2111.01193",
    "title": "Transformers for prompt-level EMA non-response prediction",
    "abstract": "Ecological Momentary Assessments (EMAs) are an important psychological data\nsource for measuring current cognitive states, affect, behavior, and\nenvironmental factors from participants in mobile health (mHealth) studies and\ntreatment programs. Non-response, in which participants fail to respond to EMA\nprompts, is an endemic problem. The ability to accurately predict non-response\ncould be utilized to improve EMA delivery and develop compliance interventions.\nPrior work has explored classical machine learning models for predicting\nnon-response. However, as increasingly large EMA datasets become available,\nthere is the potential to leverage deep learning models that have been\neffective in other fields. Recently, transformer models have shown\nstate-of-the-art performance in NLP and other domains. This work is the first\nto explore the use of transformers for EMA data analysis. We address three key\nquestions in applying transformers to EMA data: 1. Input representation, 2.\nencoding temporal information, 3. utility of pre-training on improving\ndownstream prediction task performance. The transformer model achieves a\nnon-response prediction AUC of 0.77 and is significantly better than classical\nML and LSTM-based deep learning models. We will make our a predictive model\ntrained on a corpus of 40K EMA samples freely-available to the research\ncommunity, in order to facilitate the development of future transformer-based\nEMA analysis works.",
    "descriptor": "",
    "authors": [
      "Supriya Nagesh",
      "Alexander Moreno",
      "Stephanie M. Carpenter",
      "Jamie Yap",
      "Soujanya Chatterjee",
      "Steven Lloyd Lizotte",
      "Neng Wan",
      "Santosh Kumar",
      "Cho Lam",
      "David W. Wetter",
      "Inbal Nahum-Shani",
      "James M. Rehg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01193"
  },
  {
    "id": "arXiv:2111.01195",
    "title": "A Tool for Reliability Assessment of Smart and Active Distribution  Systems -- RELSAD",
    "abstract": "With increased penetration of new technology in the distribution systems such\nas renewable energy resources, flexible resources, and information and\ncommunication technology, the distribution systems become more complex and\ndynamic. The traditional reliability analysis methods do not consider the new\ncomponents and technology and new considerations need to be taken to address\nthese new changes in the distribution system. This paper presents an\nopen-source reliability assessment tool for smart and active distribution\nsystems (RELSAD). The tool aims to function as a foundation for reliability\ncalculation in the smart and active distribution systems, where these new\ncomponents and technologies are included. The tool is made as a Python package\nbuilt up based on an object-oriented programming approach. The method will be\nillustrated on the IEEE 33-bus system with the inclusion of generation,\nbattery, and ICT.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Stine Fleischer Myhre",
      "Olav Bjarte Fosso",
      "Poul Einar Heegaard",
      "Oddbj\u00f8rn Gjerde"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01195"
  },
  {
    "id": "arXiv:2111.01196",
    "title": "Dynamic Geometric Set Cover, Revisited",
    "abstract": "Geometric set cover is a classical problem in computational geometry, which\nhas been extensively studied in the past. In the dynamic version of the\nproblem, points and ranges may be inserted and deleted, and our goal is to\nefficiently maintain a set cover solution (satisfying certain quality\nrequirement). In this paper, we give a plethora of new dynamic geometric set\ncover data structures in 1D and 2D, which significantly improve and extend the\nprevious results:\n1. The first data structure for $(1+\\varepsilon)$-approximate dynamic\ninterval set cover with polylogarithmic amortized update time. Specifically, we\nachieve an update time of $O(\\log^3 n/\\varepsilon)$, improving the\n$O(n^\\delta/\\varepsilon)$ bound of Agarwal et al. [SoCG'20], where $\\delta>0$\ndenotes an arbitrarily small constant.\n2. A data structure for $O(1)$-approximate dynamic unit-square set cover with\n$2^{O(\\sqrt{\\log n})}$ amortized update time, substantially improving the\n$O(n^{1/2+\\delta})$ update time of Agarwal et al. [SoCG'20].\n3. A data structure for $O(1)$-approximate dynamic square set cover with\n$O(n^{1/2+\\delta})$ randomized amortized update time, improving the\n$O(n^{2/3+\\delta})$ update time of Chan and He [SoCG'21].\n4. A data structure for $O(1)$-approximate dynamic 2D halfplane set cover\nwith $O(n^{17/23+\\delta})$ randomized amortized update time. The previous\nsolution for halfplane set cover by Chan and He [SoCG'21] is slower and can\nonly report the size of the approximate solution.\n5. The first sublinear results for the \\textit{weighted} version of dynamic\ngeometric set cover. Specifically, we give a data structure for\n$(3+o(1))$-approximate dynamic weighted interval set cover with\n$2^{O(\\sqrt{\\log n \\log\\log n})}$ amortized update time and a data structure\nfor $O(1)$-approximate dynamic weighted unit-square set cover with\n$O(n^\\delta)$ amortized update time.",
    "descriptor": "\nComments: to appear in SODA 2022\n",
    "authors": [
      "Timothy M. Chan",
      "Qizheng He",
      "Subhash Suri",
      "Jie Xue"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2111.01196"
  },
  {
    "id": "arXiv:2111.01201",
    "title": "Unintended Selection: Persistent Qualification Rate Disparities and  Interventions",
    "abstract": "Realistically -- and equitably -- modeling the dynamics of group-level\ndisparities in machine learning remains an open problem. In particular, we\ndesire models that do not suppose inherent differences between artificial\ngroups of people -- but rather endogenize disparities by appeal to unequal\ninitial conditions of insular subpopulations. In this paper, agents each have a\nreal-valued feature $X$ (e.g., credit score) informed by a \"true\" binary label\n$Y$ representing qualification (e.g., for a loan). Each agent alternately (1)\nreceives a binary classification label $\\hat{Y}$ (e.g., loan approval) from a\nBayes-optimal machine learning classifier observing $X$ and (2) may update\ntheir qualification $Y$ by imitating successful strategies (e.g., seek a raise)\nwithin an isolated group $G$ of agents to which they belong. We consider the\ndisparity of qualification rates $\\Pr(Y=1)$ between different groups and how\nthis disparity changes subject to a sequence of Bayes-optimal classifiers\nrepeatedly retrained on the global population. We model the evolving\nqualification rates of each subpopulation (group) using the replicator\nequation, which derives from a class of imitation processes. We show that\ndifferences in qualification rates between subpopulations can persist\nindefinitely for a set of non-trivial equilibrium states due to uniformed\nclassifier deployments, even when groups are identical in all aspects except\ninitial qualification densities. We next simulate the effects of commonly\nproposed fairness interventions on this dynamical system along with a new\nfeedback control mechanism capable of permanently eliminating group-level\nqualification rate disparities. We conclude by discussing the limitations of\nour model and findings and by outlining potential future work.",
    "descriptor": "\nComments: 39 pages, 10 figures, to be published in the Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Reilly Raab",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01201"
  },
  {
    "id": "arXiv:2111.01203",
    "title": "One Proxy Device Is Enough for Hardware-Aware Neural Architecture Search",
    "abstract": "Convolutional neural networks (CNNs) are used in numerous real-world\napplications such as vision-based autonomous driving and video content\nanalysis. To run CNN inference on various target devices, hardware-aware neural\narchitecture search (NAS) is crucial. A key requirement of efficient\nhardware-aware NAS is the fast evaluation of inference latencies in order to\nrank different architectures. While building a latency predictor for each\ntarget device has been commonly used in state of the art, this is a very\ntime-consuming process, lacking scalability in the presence of extremely\ndiverse devices. In this work, we address the scalability challenge by\nexploiting latency monotonicity -- the architecture latency rankings on\ndifferent devices are often correlated. When strong latency monotonicity\nexists, we can re-use architectures searched for one proxy device on new target\ndevices, without losing optimality. In the absence of strong latency\nmonotonicity, we propose an efficient proxy adaptation technique to\nsignificantly boost the latency monotonicity. Finally, we validate our approach\nand conduct experiments with devices of different platforms on multiple\nmainstream search spaces, including MobileNet-V2, MobileNet-V3, NAS-Bench-201,\nProxylessNAS and FBNet. Our results highlight that, by using just one proxy\ndevice, we can find almost the same Pareto-optimal architectures as the\nexisting per-device NAS, while avoiding the prohibitive cost of building a\nlatency predictor for each device.",
    "descriptor": "\nComments: Accepted by the ACM SIGMETRICS 2022. Published in the Proceedings of the ACM on Measurement and Analysis of Computing Systems, vol. 5, no. 3, Article 34, December 2021\n",
    "authors": [
      "Bingqian Lu",
      "Jianyi Yang",
      "Weiwen Jiang",
      "Yiyu Shi",
      "Shaolei Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01203"
  },
  {
    "id": "arXiv:2111.01205",
    "title": "Evaluating robustness of You Only Hear Once(YOHO) Algorithm on noisy  audios in the VOICe Dataset",
    "abstract": "Sound event detection (SED) in machine listening entails identifying the\ndifferent sounds in an audio file and identifying the start and end time of a\nparticular sound event in the audio. SED finds use in various applications such\nas audio surveillance, speech recognition, and context-based indexing and\nretrieval of data in a multimedia database. However, in real-life scenarios,\nthe audios from various sources are seldom devoid of any interfering noise or\ndisturbance. In this paper, we test the performance of the You Only Hear Once\n(YOHO) algorithm on noisy audio data. Inspired by the You Only Look Once (YOLO)\nalgorithm in computer vision, the YOHO algorithm can match the performance of\nthe various state-of-the-art algorithms on datasets such as Music Speech\nDetection Dataset, TUT Sound Event, and Urban-SED datasets but at lower\ninference times. In this paper, we explore the performance of the YOHO\nalgorithm on the VOICe dataset containing audio files with noise at different\nsound-to-noise ratios (SNR). YOHO could outperform or at least match the best\nperforming SED algorithms reported in the VOICe dataset paper and make\ninferences in less time.",
    "descriptor": "\nComments: 7 pages, 1 figure, 3 tables, Efficient Natural Language and Speech Processing Workshop, NeurIPS 2021\n",
    "authors": [
      "Soham Tiwari",
      "Kshitiz Lakhotia",
      "Manjunath Mulimani"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.01205"
  },
  {
    "id": "arXiv:2111.01207",
    "title": "Sig-Wasserstein GANs for Time Series Generation",
    "abstract": "Synthetic data is an emerging technology that can significantly accelerate\nthe development and deployment of AI machine learning pipelines. In this work,\nwe develop high-fidelity time-series generators, the SigWGAN, by combining\ncontinuous-time stochastic models with the newly proposed signature $W_1$\nmetric. The former are the Logsig-RNN models based on the stochastic\ndifferential equations, whereas the latter originates from the universal and\nprincipled mathematical features to characterize the measure induced by time\nseries. SigWGAN allows turning computationally challenging GAN min-max problem\ninto supervised learning while generating high fidelity samples. We validate\nthe proposed model on both synthetic data generated by popular quantitative\nrisk models and empirical financial data. Codes are available at\nhttps://github.com/SigCGANs/Sig-Wasserstein-GANs.git.",
    "descriptor": "\nComments: This paper is accepted by the 2nd ACM International Conference on AI in Finance 2021\n",
    "authors": [
      "Hao Ni",
      "Lukasz Szpruch",
      "Marc Sabate-Vidales",
      "Baoren Xiao",
      "Magnus Wiese",
      "Shujian Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01207"
  },
  {
    "id": "arXiv:2111.01210",
    "title": "Understanding the Use of Voice Assistants by Older Adults",
    "abstract": "Older adults are using voice-based technologies in a variety of different\ncontexts and are uniquely positioned to benefit from smart speakers' handsfree,\nvoice-based interface. In order to better understand the ways in which older\nadults engage with and learn how to use smart speakers, we conducted\nqualitative, semi-structured interviews with four older adults who own smart\nspeakers. Emerging findings indicate that older adults benefit from smart\nspeakers as both an assistive and a social technology. Findings also suggest\nthat when older adults learn new technologies in a formal, communal environment\nthere is successful adoption.",
    "descriptor": "\nComments: CSCW '18: Accessible Voice Interface Workshop, Companion of the 2018 ACM Conference on Computer Supported Cooperative Work and Social Computing\n",
    "authors": [
      "Margot Hanley",
      "Shiri Azenkot"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.01210"
  },
  {
    "id": "arXiv:2111.01215",
    "title": "Gradient Frequency Modulation for Visually Explaining Video  Understanding Models",
    "abstract": "In many applications, it is essential to understand why a machine learning\nmodel makes the decisions it does, but this is inhibited by the black-box\nnature of state-of-the-art neural networks. Because of this, increasing\nattention has been paid to explainability in deep learning, including in the\narea of video understanding. Due to the temporal dimension of video data, the\nmain challenge of explaining a video action recognition model is to produce\nspatiotemporally consistent visual explanations, which has been ignored in the\nexisting literature. In this paper, we propose Frequency-based Extremal\nPerturbation (F-EP) to explain a video understanding model's decisions. Because\nthe explanations given by perturbation methods are noisy and non-smooth both\nspatially and temporally, we propose to modulate the frequencies of gradient\nmaps from the neural network model with a Discrete Cosine Transform (DCT). We\nshow in a range of experiments that F-EP provides more spatiotemporally\nconsistent explanations that more faithfully represent the model's decisions\ncompared to the existing state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Xinmiao Lin",
      "Wentao Bao",
      "Matthew Wright",
      "Yu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01215"
  },
  {
    "id": "arXiv:2111.01216",
    "title": "Learning To Generate Piano Music With Sustain Pedals",
    "abstract": "Recent years have witnessed a growing interest in research related to the\ndetection of piano pedals from audio signals in the music information retrieval\ncommunity. However, to our best knowledge, recent generative models for\nsymbolic music have rarely taken piano pedals into account. In this work, we\nemploy the transcription model proposed by Kong et al. to get pedal information\nfrom the audio recordings of piano performance in the AILabs1k7 dataset, and\nthen modify the Compound Word Transformer proposed by Hsiao et al. to build a\nTransformer decoder that generates pedal-related tokens along with other\nmusical tokens. While the work is done by using inferred sustain pedal\ninformation as training data, the result shows hope for further improvement and\nthe importance of the involvement of sustain pedal in tasks of piano\nperformance generations.",
    "descriptor": "",
    "authors": [
      "Joann Ching",
      "Yi-Hsuan Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.01216"
  },
  {
    "id": "arXiv:2111.01218",
    "title": "Confidentiality and Integrity Mechanisms for Microservices Communication",
    "abstract": "The microservices architecture tries to deal with the challenges posed by\ndistributed systems, such as scalability, availability, and system deployment;\nby means of highly cohesive, heterogeneous, and independent microservices.\nHowever, this architecture also brings new security challenges related to\ncommunication, system design, development, and operation. The literature\ncontains spread information regarding security related solutions for\nmicroservices-based systems, but this spread makes difficult for practitioners\nto adopt novel security related solutions. In this study, we aim to present a\ncatalogue of security solutions based on algorithms, protocols, standards, or\nimplementations; supporting principles or characteristics of information\nsecurity, also considering the three possible states of data, according to the\nMcCumber Cube. Our research follows a Systematic Literature Review,\nsynthesizing the results with a meta-aggregation process. We identified a total\nof 30 primary studies, yielding 71 security solutions for the communication of\nmicroservices.",
    "descriptor": "\nComments: Computer Science & Information Technology (CS & IT). 16 pages, 4 Figures, 5 tables\n",
    "authors": [
      "Lenin Leines-Vite",
      "Juan Carlos P\u00e9rez-Arriaga",
      "Xavier Lim\u00f3n"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.01218"
  },
  {
    "id": "arXiv:2111.01221",
    "title": "Robust Federated Learning via Over-The-Air Computation",
    "abstract": "This paper investigates the robustness of over-the-air federated learning to\nByzantine attacks. The simple averaging of the model updates via over-the-air\ncomputation makes the learning task vulnerable to random or intended\nmodifications of the local model updates of some malicious clients. We propose\na robust transmission and aggregation framework to such attacks while\npreserving the benefits of over-the-air computation for federated learning. For\nthe proposed robust federated learning, the participating clients are randomly\ndivided into groups and a transmission time slot is allocated to each group.\nThe parameter server aggregates the results of the different groups using a\nrobust aggregation technique and conveys the result to the clients for another\ntraining round. We also analyze the convergence of the proposed algorithm.\nNumerical simulations confirm the robustness of the proposed approach to\nByzantine attacks.",
    "descriptor": "",
    "authors": [
      "Houssem Sifaou",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01221"
  },
  {
    "id": "arXiv:2111.01222",
    "title": "Kernel Deformed Exponential Families for Sparse Continuous Attention",
    "abstract": "Attention mechanisms take an expectation of a data representation with\nrespect to probability weights. This creates summary statistics that focus on\nimportant features. Recently, (Martins et al. 2020, 2021) proposed continuous\nattention mechanisms, focusing on unimodal attention densities from the\nexponential and deformed exponential families: the latter has sparse support.\n(Farinhas et al. 2021) extended this to use Gaussian mixture attention\ndensities, which are a flexible class with dense support. In this paper, we\nextend this to two general flexible classes: kernel exponential families and\nour new sparse counterpart kernel deformed exponential families. Theoretically,\nwe show new existence results for both kernel exponential and deformed\nexponential families, and that the deformed case has similar approximation\ncapabilities to kernel exponential families. Experiments show that kernel\ndeformed exponential families can attend to multiple compact regions of the\ndata domain.",
    "descriptor": "",
    "authors": [
      "Alexander Moreno",
      "Supriya Nagesh",
      "Zhenke Wu",
      "Walter Dempsey",
      "James M. Rehg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01222"
  },
  {
    "id": "arXiv:2111.01225",
    "title": "Identifying causal associations in tweets using deep learning: Use case  on diabetes-related tweets from 2017-2021",
    "abstract": "Objective: Leveraging machine learning methods, we aim to extract both\nexplicit and implicit cause-effect associations in patient-reported,\ndiabetes-related tweets and provide a tool to better understand opinion,\nfeelings and observations shared within the diabetes online community from a\ncausality perspective. Materials and Methods: More than 30 million\ndiabetes-related tweets in English were collected between April 2017 and\nJanuary 2021. Deep learning and natural language processing methods were\napplied to focus on tweets with personal and emotional content. A\ncause-effect-tweet dataset was manually labeled and used to train 1) a\nfine-tuned Bertweet model to detect causal sentences containing a causal\nassociation 2) a CRF model with BERT based features to extract possible\ncause-effect associations. Causes and effects were clustered in a\nsemi-supervised approach and visualised in an interactive cause-effect-network.\nResults: Causal sentences were detected with a recall of 68% in an imbalanced\ndataset. A CRF model with BERT based features outperformed a fine-tuned BERT\nmodel for cause-effect detection with a macro recall of 68%. This led to 96,676\nsentences with cause-effect associations. \"Diabetes\" was identified as the\ncentral cluster followed by \"Death\" and \"Insulin\". Insulin pricing related\ncauses were frequently associated with \"Death\". Conclusions: A novel\nmethodology was developed to detect causal sentences and identify both explicit\nand implicit, single and multi-word cause and corresponding effect as expressed\nin diabetes-related tweets leveraging BERT-based architectures and visualised\nas cause-effect-network. Extracting causal associations on real-life, patient\nreported outcomes in social media data provides a useful complementary source\nof information in diabetes research.",
    "descriptor": "\nComments: 6 Figures, 4 Tables\n",
    "authors": [
      "Adrian Ahne",
      "Vivek Khetan",
      "Xavier Tannier",
      "Md Imbessat Hassan Rizvi",
      "Thomas Czernichow",
      "Francisco Orchard",
      "Charline Bour",
      "Andrew Fano",
      "Guy Fagherazzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01225"
  },
  {
    "id": "arXiv:2111.01228",
    "title": "OPF-Learn: An Open-Source Framework for Creating Representative AC  Optimal Power Flow Datasets",
    "abstract": "Increasing levels of renewable generation motivate a growing interest in\ndata-driven approaches for AC optimal power flow (AC OPF) to manage\nuncertainty; however, a lack of disciplined dataset creation and benchmarking\nprohibits useful comparison among approaches in the literature. To instill\nconfidence, models must be able to reliably predict solutions across a wide\nrange of operating conditions. This paper develops the OPF-Learn package for\nJulia and Python, which uses a computationally efficient approach to create\nrepresentative datasets that span a wide spectrum of the AC OPF feasible\nregion. Load profiles are uniformly sampled from a convex set that contains the\nAC OPF feasible set. For each infeasible point found, the convex set is reduced\nusing infeasibility certificates, found by using properties of a relaxed\nformulation. The framework is shown to generate datasets that are more\nrepresentative of the entire feasible space versus traditional techniques seen\nin the literature, improving machine learning model performance.",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 Tables. Accepted at ISGT-NA'2022\n",
    "authors": [
      "Trager Joswig-Jones",
      "Ahmed S. Zamzam",
      "Kyri Baker"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.01228"
  },
  {
    "id": "arXiv:2111.01229",
    "title": "Impact of network topology on efficiency of proximity measures for  community detection",
    "abstract": "Many community detection algorithms require the introduction of a measure on\nthe set of nodes. Previously, a lot of efforts have been made to find the\ntop-performing measures. In most cases, experiments were conducted on several\ndatasets or random graphs. However, graphs representing real systems can be\ncompletely different in topology: the difference can be in the size of the\nnetwork, the structure of clusters, the distribution of degrees, the density of\nedges, and so on. Therefore, it is necessary to explicitly check whether the\nadvantage of one measure over another is preserved for different network\ntopologies. In this paper, we consider the efficiency of several proximity\nmeasures for clustering networks with different structures. The results show\nthat the efficiency of measures really depends on the network topology in some\ncases. However, it is possible to find measures that behave well for most\ntopologies.",
    "descriptor": "",
    "authors": [
      "Rinat Aynulin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.01229"
  },
  {
    "id": "arXiv:2111.01231",
    "title": "Switch Point biased Self-Training: Re-purposing Pretrained Models for  Code-Switching",
    "abstract": "Code-switching (CS), a ubiquitous phenomenon due to the ease of communication\nit offers in multilingual communities still remains an understudied problem in\nlanguage processing. The primary reasons behind this are: (1) minimal efforts\nin leveraging large pretrained multilingual models, and (2) the lack of\nannotated data. The distinguishing case of low performance of multilingual\nmodels in CS is the intra-sentence mixing of languages leading to switch\npoints. We first benchmark two sequence labeling tasks -- POS and NER on 4\ndifferent language pairs with a suite of pretrained models to identify the\nproblems and select the best performing model, char-BERT, among them\n(addressing (1)). We then propose a self training method to repurpose the\nexisting pretrained models using a switch-point bias by leveraging unannotated\ndata (addressing (2)). We finally demonstrate that our approach performs well\non both tasks by reducing the gap between the switch point performance while\nretaining the overall performance on two distinct language pairs in both the\ntasks. Our code is available here:\nhttps://github.com/PC09/EMNLP2021-Switch-Point-biased-Self-Training.",
    "descriptor": "\nComments: Accepted at EMNLP Findings 2021\n",
    "authors": [
      "Parul Chopra",
      "Sai Krishna Rallabandi",
      "Alan W Black",
      "Khyathi Raghavi Chandu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.01231"
  },
  {
    "id": "arXiv:2111.01233",
    "title": "Conservative Integrators for Vortex Blob Methods",
    "abstract": "Conservative symmetric second-order one-step integrators are derived using\nthe Discrete Multiplier Method for a family of vortex-blob models approximating\nthe incompressible Euler's equations on the plane. Conservative properties and\nsecond order convergence are proved. A rational function approximation was used\nto approximate the exponential integral that appears in the Hamiltonian.\nNumerical experiments are shown to verify the conservative property of these\nintegrators, their second-order accuracy, and as well as the resulting spatial\nand temporal accuracy of the vortex blob method. Moreover, the derived implicit\nconservative integrators are shown to be better at preserving conserved\nquantities than standard higher-order explicit integrators on comparable\ncomputation times.",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Cem Gormezano",
      "Jean-Christophe Nave",
      "Andy T. S. Wan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2111.01233"
  },
  {
    "id": "arXiv:2111.01235",
    "title": "Low-Cost Algorithmic Recourse for Users With Uncertain Cost Functions",
    "abstract": "The problem of identifying algorithmic recourse for people affected by\nmachine learning model decisions has received much attention recently. Some\nrecent works model user-incurred cost, which is directly linked to user\nsatisfaction. But they assume a single global cost function that is shared\nacross all users. This is an unrealistic assumption when users have dissimilar\npreferences about their willingness to act upon a feature and different costs\nassociated with changing that feature. In this work, we formalize the notion of\nuser-specific cost functions and introduce a new method for identifying\nactionable recourses for users. By default, we assume that users' cost\nfunctions are hidden from the recourse method, though our framework allows\nusers to partially or completely specify their preferences or cost function. We\npropose an objective function, Expected Minimum Cost (EMC), based on two key\nideas: (1) when presenting a set of options to a user, it is vital that there\nis at least one low-cost solution the user could adopt; (2) when we do not know\nthe user's true cost function, we can approximately optimize for user\nsatisfaction by first sampling plausible cost functions, then finding a set\nthat achieves a good cost for the user in expectation. We optimize EMC with a\nnovel discrete optimization algorithm, Cost-Optimized Local Search (COLS),\nwhich is guaranteed to improve the recourse set quality over iterations.\nExperimental evaluation on popular real-world datasets with simulated user\ncosts demonstrates that our method satisfies up to 25.89 percentage points more\nusers compared to strong baseline methods. Using standard fairness metrics, we\nalso show that our method can provide more fair solutions across demographic\ngroups than comparable methods, and we verify that our method is robust to\nmisspecification of the cost function distribution.",
    "descriptor": "\nComments: 26 pages, 6 figures, 8 tables, 5 algorithms\n",
    "authors": [
      "Prateek Yadav",
      "Peter Hase",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.01235"
  },
  {
    "id": "arXiv:2111.01236",
    "title": "HRViT: Multi-Scale High-Resolution Vision Transformer",
    "abstract": "Vision transformers (ViTs) have attracted much attention for their superior\nperformance on computer vision tasks. To address their limitations of\nsingle-scale low-resolution representations, prior work adapts ViTs to\nhigh-resolution dense prediction tasks with hierarchical architectures to\ngenerate pyramid features. However, multi-scale representation learning is\nstill under-explored on ViTs, given their classification-like sequential\ntopology. To enhance ViTs with more capability to learn semantically-rich and\nspatially-precise multi-scale representations, in this work, we present an\nefficient integration of high-resolution multi-branch architectures with vision\ntransformers, dubbed HRViT, pushing the Pareto front of dense prediction tasks\nto a new level. We explore heterogeneous branch design, reduce the redundancy\nin linear layers, and augment the model nonlinearity to balance the model\nperformance and hardware efficiency. The proposed HRViT achieves 50.20% mIoU on\nADE20K and 83.16% mIoU on Cityscapes for semantic segmentation tasks,\nsurpassing state-of-the-art MiT and CSWin with an average of +1.78 mIoU\nimprovement, 28% parameter reduction, and 21% FLOPs reduction, demonstrating\nthe potential of HRViT as strong vision backbones.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Jiaqi Gu",
      "Hyoukjun Kwon",
      "Dilin Wang",
      "Wei Ye",
      "Meng Li",
      "Yu-Hsin Chen",
      "Liangzhen Lai",
      "Vikas Chandra",
      "David Z. Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01236"
  },
  {
    "id": "arXiv:2111.01243",
    "title": "Recent Advances in Natural Language Processing via Large Pre-Trained  Language Models: A Survey",
    "abstract": "Large, pre-trained transformer-based language models such as BERT have\ndrastically changed the Natural Language Processing (NLP) field. We present a\nsurvey of recent work that uses these large language models to solve NLP tasks\nvia pre-training then fine-tuning, prompting, or text generation approaches. We\nalso present approaches that use pre-trained language models to generate data\nfor training augmentation or other purposes. We conclude with discussions on\nlimitations and suggested directions for future research.",
    "descriptor": "",
    "authors": [
      "Bonan Min",
      "Hayley Ross",
      "Elior Sulem",
      "Amir Pouran Ben Veyseh",
      "Thien Huu Nguyen",
      "Oscar Sainz",
      "Eneko Agirre",
      "Ilana Heinz",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01243"
  },
  {
    "id": "arXiv:2111.01245",
    "title": "Learning Eye-in-Hand Camera Calibration from a Single Image",
    "abstract": "Eye-in-hand camera calibration is a fundamental and long-studied problem in\nrobotics. We present a study on using learning-based methods for solving this\nproblem online from a single RGB image, whilst training our models with\nentirely synthetic data. We study three main approaches: one direct regression\nmodel that directly predicts the extrinsic matrix from an image, one sparse\ncorrespondence model that regresses 2D keypoints and then uses PnP, and one\ndense correspondence model that uses regressed depth and segmentation maps to\nenable ICP pose estimation. In our experiments, we benchmark these methods\nagainst each other and against well-established classical methods, to find the\nsurprising result that direct regression outperforms other approaches, and we\nperform noise-sensitivity analysis to gain further insights into these results.",
    "descriptor": "\nComments: Published at the 2021 Conference on Robot Learning (CoRL). Webpage and video: this https URL\n",
    "authors": [
      "Eugene Valassakis",
      "Kamil Dreczkowski",
      "Edward Johns"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01245"
  },
  {
    "id": "arXiv:2111.01253",
    "title": "Neural Scene Flow Prior",
    "abstract": "Before the deep learning revolution, many perception algorithms were based on\nruntime optimization in conjunction with a strong prior/regularization penalty.\nA prime example of this in computer vision is optical and scene flow.\nSupervised learning has largely displaced the need for explicit regularization.\nInstead, they rely on large amounts of labeled data to capture prior\nstatistics, which are not always readily available for many problems. Although\noptimization is employed to learn the neural network, the weights of this\nnetwork are frozen at runtime. As a result, these learning solutions are\ndomain-specific and do not generalize well to other statistically different\nscenarios. This paper revisits the scene flow problem that relies predominantly\non runtime optimization and strong regularization. A central innovation here is\nthe inclusion of a neural scene flow prior, which uses the architecture of\nneural networks as a new type of implicit regularizer. Unlike learning-based\nscene flow methods, optimization occurs at runtime, and our approach needs no\noffline datasets -- making it ideal for deployment in new environments such as\nautonomous driving. We show that an architecture based exclusively on\nmultilayer perceptrons (MLPs) can be used as a scene flow prior. Our method\nattains competitive -- if not better -- results on scene flow benchmarks. Also,\nour neural prior's implicit and continuous scene flow representation allows us\nto estimate dense long-term correspondences across a sequence of point clouds.\nThe dense motion information is represented by scene flow fields where points\ncan be propagated through time by integrating motion vectors. We demonstrate\nsuch a capability by accumulating a sequence of lidar point clouds.",
    "descriptor": "\nComments: accepted by NeurIPS 2021 as \"spotlight\"\n",
    "authors": [
      "Xueqian Li",
      "Jhony Kaesemodel Pontes",
      "Simon Lucey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01253"
  },
  {
    "id": "arXiv:2111.01256",
    "title": "Reverse engineering recurrent neural networks with Jacobian switching  linear dynamical systems",
    "abstract": "Recurrent neural networks (RNNs) are powerful models for processing\ntime-series data, but it remains challenging to understand how they function.\nImproving this understanding is of substantial interest to both the machine\nlearning and neuroscience communities. The framework of reverse engineering a\ntrained RNN by linearizing around its fixed points has provided insight, but\nthe approach has significant challenges. These include difficulty choosing\nwhich fixed point to expand around when studying RNN dynamics and error\naccumulation when reconstructing the nonlinear dynamics with the linearized\ndynamics. We present a new model that overcomes these limitations by\nco-training an RNN with a novel switching linear dynamical system (SLDS)\nformulation. A first-order Taylor series expansion of the co-trained RNN and an\nauxiliary function trained to pick out the RNN's fixed points govern the SLDS\ndynamics. The results are a trained SLDS variant that closely approximates the\nRNN, an auxiliary function that can produce a fixed point for each point in\nstate-space, and a trained nonlinear RNN whose dynamics have been regularized\nsuch that its first-order terms perform the computation, if possible. This\nmodel removes the post-training fixed point optimization and allows us to\nunambiguously study the learned dynamics of the SLDS at any point in\nstate-space. It also generalizes SLDS models to continuous manifolds of\nswitching points while sharing parameters across switches. We validate the\nutility of the model on two synthetic tasks relevant to previous work reverse\nengineering RNNs. We then show that our model can be used as a drop-in in more\ncomplex architectures, such as LFADS, and apply this LFADS hybrid to analyze\nsingle-trial spiking activity from the motor system of a non-human primate.",
    "descriptor": "\nComments: 23 pages, 9 figures\n",
    "authors": [
      "Jimmy T.H. Smith",
      "Scott W. Linderman",
      "David Sussillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01256"
  },
  {
    "id": "arXiv:2111.01257",
    "title": "Implicit Model Specialization through DAG-based Decentralized Federated  Learning",
    "abstract": "Federated learning allows a group of distributed clients to train a common\nmachine learning model on private data. The exchange of model updates is\nmanaged either by a central entity or in a decentralized way, e.g. by a\nblockchain. However, the strong generalization across all clients makes these\napproaches unsuited for non-independent and identically distributed (non-IID)\ndata.\nWe propose a unified approach to decentralization and personalization in\nfederated learning that is based on a directed acyclic graph (DAG) of model\nupdates. Instead of training a single global model, clients specialize on their\nlocal data while using the model updates from other clients dependent on the\nsimilarity of their respective data. This specialization implicitly emerges\nfrom the DAG-based communication and selection of model updates. Thus, we\nenable the evolution of specialized models, which focus on a subset of the data\nand therefore cover non-IID data better than federated learning in a\ncentralized or blockchain-based setup.\nTo the best of our knowledge, the proposed solution is the first to unite\npersonalization and poisoning robustness in fully decentralized federated\nlearning. Our evaluation shows that the specialization of models emerges\ndirectly from the DAG-based communication of model updates on three different\ndatasets. Furthermore, we show stable model accuracy and less variance across\nclients when compared to federated averaging.",
    "descriptor": "\nComments: to be published in Middleware '21\n",
    "authors": [
      "Jossekin Beilharz",
      "Bjarne Pfitzner",
      "Robert Schmid",
      "Paul Geppert",
      "Bernd Arnrich",
      "Andreas Polze"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01257"
  },
  {
    "id": "arXiv:2111.01258",
    "title": "Safe Online Gain Optimization for Variable Impedance Control",
    "abstract": "Smooth behaviors are preferable for many contact-rich manipulation tasks.\nImpedance control arises as an effective way to regulate robot movements by\nmimicking a mass-spring-damping system. Consequently, the robot behavior can be\ndetermined by the impedance gains. However, tuning the impedance gains for\ndifferent tasks is tricky, especially for unstructured environments. Moreover,\nonline adapting the optimal gains to meet the time-varying performance index is\neven more challenging. In this paper, we present Safe Online Gain Optimization\nfor Variable Impedance Control (Safe OnGO-VIC). By reformulating the dynamics\nof impedance control as a control-affine system, in which the impedance gains\nare the inputs, we provide a novel perspective to understand variable impedance\ncontrol. Additionally, we innovatively formulate an optimization problem with\nonline collected force information to obtain the optimal impedance gains in\nreal-time. Safety constraints are also embedded in the proposed framework to\navoid unwanted collisions. We experimentally validated the proposed algorithm\non three manipulation tasks. Comparison results with a constant gain baseline\nand an adaptive control method prove that the proposed algorithm is effective\nand generalizable to different scenarios.",
    "descriptor": "",
    "authors": [
      "Changhao Wang",
      "Zhian Kuang",
      "Xiang Zhang",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01258"
  },
  {
    "id": "arXiv:2111.01259",
    "title": "Verifying Contracts for Perturbed Control Systems using Linear  Programming",
    "abstract": "Verifying specifications for large-scale control systems is of utmost\nimportance, but can be hard in practice as most formal verification methods can\nnot handle high-dimensional dynamics. Contract theory has been proposed as a\nmodular alternative to formal verification in which specifications are defined\nby assumptions on the inputs to a component and guarantees on its outputs. In\nthis paper, we present linear-programming-based tools for verifying contracts\nfor control systems. We first consider the problem of verifying contracts\ndefined by time-invariant inequalities for unperturbed systems. We use\n$k$-induction to show that contract verification can be achieved by considering\na collection of implications between inequalities, which are then recast as\nlinear programs. We then move our attention to perturbed systems. We present a\ncomparison-based framework, verifying that a perturbed system satisfies a\ncontract by checking that the corresponding unperturbed system satisfies a\nrobustified (and $\\epsilon$-approximated) contract. In both cases, we present\nexplicit algorithms for contract verification, proving their correctness and\nanalyzing their complexity. We also demonstrate the verification process for\ntwo case studies, one considering a two-vehicle autonomous driving scenario,\nand one considering formation control of a multi-agent system.",
    "descriptor": "\nComments: 16 pages, 2 figures\n",
    "authors": [
      "Miel Sharf",
      "Bart Besselink",
      "Karl Henrik Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.01259"
  },
  {
    "id": "arXiv:2111.01261",
    "title": "Joint Detection of Motion Boundaries and Occlusions",
    "abstract": "We propose MONet, a convolutional neural network that jointly detects motion\nboundaries (MBs) and occlusion regions (Occs) in video both forward and\nbackward in time. Detection is difficult because optical flow is discontinuous\nalong MBs and undefined in Occs, while many flow estimators assume smoothness\nand a flow defined everywhere. To reason in the two time directions\nsimultaneously, we direct-warp the estimated maps between the two frames. Since\nappearance mismatches between frames often signal vicinity to MBs or Occs, we\nconstruct a cost block that for each feature in one frame records the lowest\ndiscrepancy with matching features in a search range. This cost block is\ntwo-dimensional, and much less expensive than the four-dimensional cost volumes\nused in flow analysis. Cost-block features are computed by an encoder, and MB\nand Occ estimates are computed by a decoder. We found that arranging decoder\nlayers fine-to-coarse, rather than coarse-to-fine, improves performance. MONet\noutperforms the prior state of the art for both tasks on the Sintel and\nFlyingChairsOcc benchmarks without any fine-tuning on them.",
    "descriptor": "",
    "authors": [
      "Hannah Halin Kim",
      "Shuzhi Yu",
      "Carlo Tomasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01261"
  },
  {
    "id": "arXiv:2111.01263",
    "title": "Optimized Passive Optical Networks with Cascaded-AWGRs for Data Centers",
    "abstract": "The use of Passive Optical Networks (PONs) in modern and future data centers\ncan provide energy efficiency, high capacity, low cost, scalability, and\nelasticity. This paper introduces a passive optical network design with 2-tier\ncascaded Arrayed Waveguide Grating Routers (AWGRs) to connect groups of racks\n(i.e. cells) within a data center. This design employs a Software-Defined\nNetworking (SDN) controller to manage the routing and assignment of the\nnetworking resource while introducing multiple paths between any two cells to\nimprove routing, load balancing and resilience. We provide benchmarking results\nfor the power consumption to compare the energy efficiency of this design to\nstate-of-the-art data centers. The results indicate that the cascaded AWGRs\narchitecture can achieve up to 43% saving in the networking power consumption\ncompared to Fat-Tree data center architecture.",
    "descriptor": "",
    "authors": [
      "Mohammed Alharthi",
      "Sanaa H. Mohamed",
      "Barzan Yosuf",
      "Taisir E. H. El-Gorashi",
      "Jaafar M. H. Elmirghani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.01263"
  },
  {
    "id": "arXiv:2111.01264",
    "title": "Human-Level Control without Server-Grade Hardware",
    "abstract": "Deep Q-Network (DQN) marked a major milestone for reinforcement learning,\ndemonstrating for the first time that human-level control policies could be\nlearned directly from raw visual inputs via reward maximization. Even years\nafter its introduction, DQN remains highly relevant to the research community\nsince many of its innovations have been adopted by successor methods.\nNevertheless, despite significant hardware advances in the interim, DQN's\noriginal Atari 2600 experiments remain costly to replicate in full. This poses\nan immense barrier to researchers who cannot afford state-of-the-art hardware\nor lack access to large-scale cloud computing resources. To facilitate improved\naccess to deep reinforcement learning research, we introduce a DQN\nimplementation that leverages a novel concurrent and synchronized execution\nframework designed to maximally utilize a heterogeneous CPU-GPU desktop system.\nWith just one NVIDIA GeForce GTX 1080 GPU, our implementation reduces the\ntraining time of a 200-million-frame Atari experiment from 25 hours to just 9\nhours. The ideas introduced in our paper should be generalizable to a large\nnumber of off-policy deep reinforcement learning methods.",
    "descriptor": "\nComments: 13 pages, 3 figures, 5 tables\n",
    "authors": [
      "Brett Daley",
      "Christopher Amato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01264"
  },
  {
    "id": "arXiv:2111.01271",
    "title": "Brain dynamics via Cumulative Auto-Regressive Self-Attention",
    "abstract": "Multivariate dynamical processes can often be intuitively described by a\nweighted connectivity graph between components representing each individual\ntime-series. Even a simple representation of this graph as a Pearson\ncorrelation matrix may be informative and predictive as demonstrated in the\nbrain imaging literature. However, there is a consensus expectation that\npowerful graph neural networks (GNNs) should perform better in similar\nsettings. In this work, we present a model that is considerably shallow than\ndeep GNNs, yet outperforms them in predictive accuracy in a brain imaging\napplication. Our model learns the autoregressive structure of individual time\nseries and estimates directed connectivity graphs between the learned\nrepresentations via a self-attention mechanism in an end-to-end fashion. The\nsupervised training of the model as a classifier between patients and controls\nresults in a model that generates directed connectivity graphs and highlights\nthe components of the time-series that are predictive for each subject. We\ndemonstrate our results on a functional neuroimaging dataset classifying\nschizophrenia patients and controls.",
    "descriptor": "\nComments: Machine Learning for Health (ML4H) - Extended Abstract\n",
    "authors": [
      "Usman Mahmood",
      "Zening Fu",
      "Vince Calhoun",
      "Sergey Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01271"
  },
  {
    "id": "arXiv:2111.01272",
    "title": "Sequence Transduction with Graph-based Supervision",
    "abstract": "The recurrent neural network transducer (RNN-T) objective plays a major role\nin building today's best automatic speech recognition (ASR) systems for\nproduction. Similarly to the connectionist temporal classification (CTC)\nobjective, the RNN-T loss uses specific rules that define how a set of\nalignments is generated to form a lattice for the full-sum training. However,\nit is yet largely unknown if these rules are optimal and do lead to the best\npossible ASR results. In this work, we present a new transducer objective\nfunction that generalizes the RNN-T loss to accept a graph representation of\nthe labels, thus providing a flexible and efficient framework to manipulate\ntraining lattices, for example for restricting alignments or studying different\ntransition rules. We demonstrate that transducer-based ASR with CTC-like\nlattice achieves better results compared to standard RNN-T, while also ensuring\na strictly monotonic alignment, which will allow better optimization of the\ndecoding procedure. For example, the proposed CTC-like transducer system\nachieves a word error rate of 5.9% for the test-other condition of LibriSpeech,\ncorresponding to an improvement of 4.8% relative to an equivalent RNN-T based\nsystem.",
    "descriptor": "\nComments: Submitted to IEEE ICASSP 2022\n",
    "authors": [
      "Niko Moritz",
      "Takaaki Hori",
      "Shinji Watanabe",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.01272"
  },
  {
    "id": "arXiv:2111.01273",
    "title": "Network Clustering for Latent State and Changepoint Detection",
    "abstract": "Network models provide a powerful and flexible framework for analyzing a wide\nrange of structured data sources. In many situations of interest, however,\nmultiple networks can be constructed to capture different aspects of an\nunderlying phenomenon or to capture changing behavior over time. In such\nsettings, it is often useful to cluster together related networks in attempt to\nidentify patterns of common structure. In this paper, we propose a convex\napproach for the task of network clustering. Our approach uses a convex fusion\npenalty to induce a smoothly-varying tree-like cluster structure, eliminating\nthe need to select the number of clusters a priori. We provide an efficient\nalgorithm for convex network clustering and demonstrate its effectiveness on\nsynthetic examples.",
    "descriptor": "",
    "authors": [
      "Madeline Navarro",
      "Genevera I. Allen",
      "Michael Weylandt"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01273"
  },
  {
    "id": "arXiv:2111.01276",
    "title": "Multi network InfoMax: A pre-training method involving graph  convolutional networks",
    "abstract": "Discovering distinct features and their relations from data can help us\nuncover valuable knowledge crucial for various tasks, e.g., classification. In\nneuroimaging, these features could help to understand, classify, and possibly\nprevent brain disorders. Model introspection of highly performant\noverparameterized deep learning (DL) models could help find these features and\nrelations. However, to achieve high-performance level DL models require\nnumerous labeled training samples ($n$) rarely available in many fields. This\npaper presents a pre-training method involving graph convolutional/neural\nnetworks (GCNs/GNNs), based on maximizing mutual information between two\nhigh-level embeddings of an input sample. Many of the recently proposed\npre-training methods pre-train one of many possible networks of an\narchitecture. Since almost every DL model is an ensemble of multiple networks,\nwe take our high-level embeddings from two different networks of a model --a\nconvolutional and a graph network--. The learned high-level graph latent\nrepresentations help increase performance for downstream graph classification\ntasks and bypass the need for a high number of labeled data samples. We apply\nour method to a neuroimaging dataset for classifying subjects into healthy\ncontrol (HC) and schizophrenia (SZ) groups. Our experiments show that the\npre-trained model significantly outperforms the non-pre-trained model and\nrequires $50\\%$ less data for similar performance.",
    "descriptor": "\nComments: Machine Learning for Health (ML4H) - Extended Abstract\n",
    "authors": [
      "Usman Mahmood",
      "Zening Fu",
      "Vince Calhoun",
      "Sergey Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01276"
  },
  {
    "id": "arXiv:2111.01294",
    "title": "Learning to Operate an Electric Vehicle Charging Station Considering  Vehicle-grid Integration",
    "abstract": "The rapid adoption of electric vehicles (EVs) calls for the widespread\ninstallation of EV charging stations. To maximize the profitability of charging\nstations, intelligent controllers that provide both charging and electric grid\nservices are in great need. However, it is challenging to determine the optimal\ncharging schedule due to the uncertain arrival time and charging demands of\nEVs. In this paper, we propose a novel centralized allocation and decentralized\nexecution (CADE) reinforcement learning (RL) framework to maximize the charging\nstation's profit. In the centralized allocation process, EVs are allocated to\neither the waiting or charging spots. In the decentralized execution process,\neach charger makes its own charging/discharging decision while learning the\naction-value functions from a shared replay memory. This CADE framework\nsignificantly improves the scalability and sample efficiency of the RL\nalgorithm. Numerical results show that the proposed CADE framework is both\ncomputationally efficient and scalable, and significantly outperforms the\nbaseline model predictive control (MPC). We also provide an in-depth analysis\nof the learned action-value function to explain the inner working of the\nreinforcement learning agent.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Zuzhao Ye",
      "Yuanqi Gao",
      "Nanpeng Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01294"
  },
  {
    "id": "arXiv:2111.01297",
    "title": "Deep neural networks as nested dynamical systems",
    "abstract": "There is an analogy that is often made between deep neural networks and\nactual brains, suggested by the nomenclature itself: the \"neurons\" in deep\nneural networks should correspond to neurons (or nerve cells, to avoid\nconfusion) in the brain. We claim, however, that this analogy doesn't even type\ncheck: it is structurally flawed. In agreement with the slightly glib summary\nof Hebbian learning as \"cells that fire together wire together\", this article\nmakes the case that the analogy should be different. Since the \"neurons\" in\ndeep neural networks are managing the changing weights, they are more akin to\nthe synapses in the brain; instead, it is the wires in deep neural networks\nthat are more like nerve cells, in that they are what cause the information to\nflow. An intuition that nerve cells seem like more than mere wires is exactly\nright, and is justified by a precise category-theoretic analogy which we will\nexplore in this article. Throughout, we will continue to highlight the error in\nequating artificial neurons with nerve cells by leaving \"neuron\" in quotes or\nby calling them artificial neurons.\nWe will first explain how to view deep neural networks as nested dynamical\nsystems with a very restricted sort of interaction pattern, and then explain a\nmore general sort of interaction for dynamical systems that is useful\nthroughout engineering, but which fails to adapt to changing circumstances. As\nmentioned, an analogy is then forced upon us by the mathematical formalism in\nwhich they are both embedded. We call the resulting encompassing generalization\ndeeply interacting learning systems: they have complex interaction as in\ncontrol theory, but adaptation to circumstances as in deep neural networks.",
    "descriptor": "",
    "authors": [
      "David I. Spivak",
      "Timothy Hosgood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Category Theory (math.CT)",
      "Dynamical Systems (math.DS)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2111.01297"
  },
  {
    "id": "arXiv:2111.01300",
    "title": "Masking Modalities for Cross-modal Video Retrieval",
    "abstract": "Pre-training on large scale unlabelled datasets has shown impressive\nperformance improvements in the fields of computer vision and natural language\nprocessing. Given the advent of large-scale instructional video datasets, a\ncommon strategy for pre-training video encoders is to use the accompanying\nspeech as weak supervision. However, as speech is used to supervise the\npre-training, it is never seen by the video encoder, which does not learn to\nprocess that modality. We address this drawback of current pre-training\nmethods, which fail to exploit the rich cues in spoken language. Our proposal\nis to pre-train a video encoder using all the available video modalities as\nsupervision, namely, appearance, sound, and transcribed speech. We mask an\nentire modality in the input and predict it using the other two modalities.\nThis encourages each modality to collaborate with the others, and our video\nencoder learns to process appearance and audio as well as speech. We show the\nsuperior performance of our \"modality masking\" pre-training approach for video\nretrieval on the How2R, YouCook2 and Condensed Movies datasets.",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Valentin Gabeur",
      "Arsha Nagrani",
      "Chen Sun",
      "Karteek Alahari",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01300"
  },
  {
    "id": "arXiv:2111.01302",
    "title": "Differential Flatness and Flatness Inspired Control of Aerial  Manipulators based on Lagrangian Reduction",
    "abstract": "This paper shows that the dynamics of a general class of aerial manipulators,\nconsist of an underactuated multi-rotor base with an arbitrary k-linked\narticulated manipulator, are differentially flat. Methods of Lagrangian\nReduction under broken symmetries produce reduced equations of motion whose key\nvariables: center-of-mass linear momentum, vehicle yaw angle, and manipulator\nrelative joint angles become the flat outputs. Utilizing flatness theory and a\nsecond-order dynamic extension of the thrust input, we transform the mechanics\nof aerial manipulators to their equivalent trivial form with a valid relative\ndegree. Using this flatness transformation, a quadratic programming-based\ncontroller is proposed within a Control Lyapunov Function (CLF-QP) framework,\nand its performance is verified in simulation.",
    "descriptor": "",
    "authors": [
      "Skylar X. Wei",
      "Peder Harderup",
      "Joel Burdick"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.01302"
  },
  {
    "id": "arXiv:2111.01306",
    "title": "On the Current and Emerging Challenges of Developing Fair and Ethical AI  Solutions in Financial Services",
    "abstract": "Artificial intelligence (AI) continues to find more numerous and more\ncritical applications in the financial services industry, giving rise to fair\nand ethical AI as an industry-wide objective. While many ethical principles and\nguidelines have been published in recent years, they fall short of addressing\nthe serious challenges that model developers face when building ethical AI\nsolutions. We survey the practical and overarching issues surrounding model\ndevelopment, from design and implementation complexities, to the shortage of\ntools, and the lack of organizational constructs. We show how practical\nconsiderations reveal the gaps between high-level principles and concrete,\ndeployed AI applications, with the aim of starting industry-wide conversations\ntoward solution approaches.",
    "descriptor": "\nComments: 10 pages; expanded from conference version\n",
    "authors": [
      "Eren Kurshan",
      "Jiahao Chen",
      "Victor Storchan",
      "Hongda Shen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.01306"
  },
  {
    "id": "arXiv:2111.01312",
    "title": "DaDRA: A Python Library for Data-Driven Reachability Analysis",
    "abstract": "Reachability analysis is used to determine all possible states that a system\nacting under uncertainty may reach. It is a critical component to obtain\nguarantees of various safety-critical systems both for safety verification and\ncontroller synthesis. Though traditional approaches to reachability analysis\nprovide formal guarantees of the reachable set, they involve complex algorithms\nthat require full system information, which is impractical for use in real\nworld settings. We present DaDRA, a Python library that allows for data-driven\nreachability analysis with arbitrarily robust probabilistic guarantees. We\ndemonstrate the practical functionality of DaDRA on various systems including:\nan analytically intractable chaotic system, benchmarks for systems with\nnonlinear dynamics, and a realistic system acting under complex disturbance\nsignals and controlled with an intricate controller across multiple dimensions.",
    "descriptor": "",
    "authors": [
      "Jared Mejia",
      "Alex Devonport",
      "Murat Arcak"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01312"
  },
  {
    "id": "arXiv:2111.01314",
    "title": "Explaining Documents' Relevance to Search Queries",
    "abstract": "We present GenEx, a generative model to explain search results to users\nbeyond just showing matches between query and document words. Adding GenEx\nexplanations to search results greatly impacts user satisfaction and search\nperformance. Search engines mostly provide document titles, URLs, and snippets\nfor each result. Existing model-agnostic explanation methods similarly focus on\nword matching or content-based features. However, a recent user study shows\nthat word matching features are quite obvious to users and thus of slight\nvalue. GenEx explains a search result by providing a terse description for the\nquery aspect covered by that result. We cast the task as a sequence\ntransduction problem and propose a novel model based on the Transformer\narchitecture. To represent documents with respect to the given queries and yet\nnot generate the queries themselves as explanations, two query-attention layers\nand masked-query decoding are added to the Transformer architecture. The model\nis trained without using any human-generated explanations. Training data are\ninstead automatically constructed to ensure a tolerable noise level and a\ngeneralizable learned model. Experimental evaluation shows that our explanation\nmodels significantly outperform the baseline models. Evaluation through user\nstudies also demonstrates that our explanation model generates short yet useful\nexplanations.",
    "descriptor": "",
    "authors": [
      "Razieh Rahimi",
      "Youngwoo Kim",
      "Hamed Zamani",
      "James Allan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.01314"
  },
  {
    "id": "arXiv:2111.01315",
    "title": "FC-based shock-dynamics solver with neural-network localized  artificial-viscosity assignment",
    "abstract": "This paper presents a spectral scheme for the numerical solution of nonlinear\nconservation laws in non-periodic domains under arbitrary boundary conditions.\nThe approach relies on the use of the Fourier Continuation (FC) method for\nspectral representation of non-periodic functions in conjunction with smooth\nlocalized artificial viscosity assignments produced by means of a\nShock-Detecting Neural Network (SDNN). Like previous shock capturing schemes\nand artificial viscosity techniques, the combined FC-SDNN strategy effectively\ncontrols spurious oscillations in the proximity of discontinuities. Thanks to\nits use of a localized but smooth artificial viscosity term, whose support is\nrestricted to a vicinity of flow-discontinuity points, the algorithm enjoys\nspectral accuracy and low dissipation away from flow discontinuities, and, in\nsuch regions, it produces smooth numerical solutions -- as evidenced by an\nessential absence of spurious oscillations in level set lines. The FC-SDNN\nviscosity assignment, which does not require use of problem-dependent\nalgorithmic parameters, induces a significantly lower overall dissipation than\nother methods, including the Fourier-spectral versions of the previous entropy\nviscosity method. The character of the proposed algorithm is illustrated with a\nvariety of numerical results for the linear advection, Burgers and Euler\nequations in one and two-dimensional non-periodic spatial domains.",
    "descriptor": "\nComments: 40 pages, 17 figures, 1 table, 1 algorithm\n",
    "authors": [
      "Oscar P. Bruno",
      "Jan S. Hesthaven",
      "Daniel V. Leibovici"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.01315"
  },
  {
    "id": "arXiv:2111.01321",
    "title": "A Network Science Perspective to Personalized Learning",
    "abstract": "The modern educational ecosystem is not one-size fits all. Scholars are\naccustomed to personalization in their everyday life and expect the same from\neducation systems. Additionally, the COVID-19 pandemic placed us all in an\nacute teaching and learning laboratory experimentation which now creates\nexpectations of self-paced learning and interactions with focused educational\nmaterials. Consequently, we examine how learning objectives can be achieved\nthrough a learning platform that offers content choices and multiple modalities\nof engagement to support self-paced learning, and propose an approach to\npersonalized education based on network science. This framework brings the\nattention to learning experiences, rather than teaching experiences, by\nproviding the learner engagement and content choices supported by a network of\nknowledge, based on and driven by individual skills and goals. We conclude with\na discussion of a prototype of such a learning platform, called CHUNK Learning.",
    "descriptor": "",
    "authors": [
      "Ralucca Gera",
      "Akrati Saxena",
      "D'Marie Bartolf",
      "Simona Tick"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.01321"
  },
  {
    "id": "arXiv:2111.01322",
    "title": "Diverse Distributions of Self-Supervised Tasks for Meta-Learning in NLP",
    "abstract": "Meta-learning considers the problem of learning an efficient learning process\nthat can leverage its past experience to accurately solve new tasks. However,\nthe efficacy of meta-learning crucially depends on the distribution of tasks\navailable for training, and this is often assumed to be known a priori or\nconstructed from limited supervised datasets. In this work, we aim to provide\ntask distributions for meta-learning by considering self-supervised tasks\nautomatically proposed from unlabeled text, to enable large-scale meta-learning\nin NLP. We design multiple distributions of self-supervised tasks by\nconsidering important aspects of task diversity, difficulty, type, domain, and\ncurriculum, and investigate how they affect meta-learning performance. Our\nanalysis shows that all these factors meaningfully alter the task distribution,\nsome inducing significant improvements in downstream few-shot accuracy of the\nmeta-learned models. Empirically, results on 20 downstream tasks show\nsignificant improvements in few-shot learning -- adding up to +4.2% absolute\naccuracy (on average) to the previous unsupervised meta-learning method, and\nperform comparably to supervised methods on the FewRel 2.0 benchmark.",
    "descriptor": "\nComments: To appear at EMNLP 2021\n",
    "authors": [
      "Trapit Bansal",
      "Karthick Gunasekaran",
      "Tong Wang",
      "Tsendsuren Munkhdalai",
      "Andrew McCallum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01322"
  },
  {
    "id": "arXiv:2111.01323",
    "title": "Exploring the Semi-supervised Video Object Segmentation Problem from a  Cyclic Perspective",
    "abstract": "Modern video object segmentation (VOS) algorithms have achieved remarkably\nhigh performance in a sequential processing order, while most of currently\nprevailing pipelines still show some obvious inadequacy like accumulative\nerror, unknown robustness or lack of proper interpretation tools. In this\npaper, we place the semi-supervised video object segmentation problem into a\ncyclic workflow and find the defects above can be collectively addressed via\nthe inherent cyclic property of semi-supervised VOS systems. Firstly, a cyclic\nmechanism incorporated to the standard sequential flow can produce more\nconsistent representations for pixel-wise correspondance. Relying on the\naccurate reference mask in the starting frame, we show that the error\npropagation problem can be mitigated. Next, a simple gradient correction\nmodule, which naturally extends the offline cyclic pipeline to an online\nmanner, can highlight the high-frequent and detailed part of results to further\nimprove the segmentation quality while keeping feasible computation cost.\nMeanwhile such correction can protect the network from severe performance\ndegration resulted from interference signals. Finally we develop cycle\neffective receptive field (cycle-ERF) based on gradient correction process to\nprovide a new perspective into analyzing object-specific regions of interests.\nWe conduct comprehensive comparison and detailed analysis on challenging\nbenchmarks of DAVIS16, DAVIS17 and Youtube-VOS, demonstrating that the cyclic\nmechanism is helpful to enhance segmentation quality, improve the robustness of\nVOS systems, and further provide qualitative comparison and interpretation on\nhow different VOS algorithms work. The code of this project can be found at\nhttps://github.com/lyxok1/STM-Training",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2010.12176\n",
    "authors": [
      "Yuxi Li",
      "Ning Xu",
      "Wenjie Yang",
      "John See",
      "Weiyao Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01323"
  },
  {
    "id": "arXiv:2111.01325",
    "title": "Attribute-Based Deep Periocular Recognition: Leveraging Soft Biometrics  to Improve Periocular Recognition",
    "abstract": "In recent years, periocular recognition has been developed as a valuable\nbiometric identification approach, especially in wild environments (for\nexample, masked faces due to COVID-19 pandemic) where facial recognition may\nnot be applicable. This paper presents a new deep periocular recognition\nframework called attribute-based deep periocular recognition (ADPR), which\npredicts soft biometrics and incorporates the prediction into a periocular\nrecognition algorithm to determine identity from periocular images with high\naccuracy. We propose an end-to-end framework, which uses several shared\nconvolutional neural network (CNN)layers (a common network) whose output feeds\ntwo separate dedicated branches (modality dedicated layers); the first branch\nclassifies periocular images while the second branch predicts softn biometrics.\nNext, the features from these two branches are fused together for a final\nperiocular recognition. The proposed method is different from existing methods\nas it not only uses a shared CNN feature space to train these two tasks\njointly, but it also fuses predicted soft biometric features with the\nperiocular features in the training step to improve the overall periocular\nrecognition performance. Our proposed model is extensively evaluated using four\ndifferent publicly available datasets. Experimental results indicate that our\nsoft biometric based periocular recognition approach outperforms other\nstate-of-the-art methods for periocular recognition in wild environments.",
    "descriptor": "\nComments: Accepted to be published in WACV 2022\n",
    "authors": [
      "Veeru Talreja",
      "Nasser M. Nasrabadi",
      "Matthew C. Valenti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.01325"
  },
  {
    "id": "arXiv:2111.01334",
    "title": "Measuring and utilizing temporal network dissimilarity",
    "abstract": "Quantifying the structural and functional differences of temporal networks is\na fundamental and challenging problem in the era of big data. This work\nproposes a temporal dissimilarity measure for temporal network comparison based\non the fastest arrival distance distribution and spectral entropy based\nJensen-Shannon divergence. Experimental results on both synthetic and empirical\ntemporal networks show that the proposed measure could discriminate diverse\ntemporal networks with different structures by capturing various topological\nand temporal properties. Moreover, the proposed measure can discern the\nfunctional distinctions and is found effective applications in temporal network\nclassification and spreadability discrimination.",
    "descriptor": "",
    "authors": [
      "Xiu-Xiu Zhan",
      "Chuang Liu",
      "Zhipeng Wang",
      "Huijuang Wang",
      "Petter Holme",
      "Zi-Ke Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.01334"
  },
  {
    "id": "arXiv:2111.01340",
    "title": "Adapting to the Long Tail: A Meta-Analysis of Transfer Learning Research  for Language Understanding Tasks",
    "abstract": "Natural language understanding (NLU) has made massive progress driven by\nlarge benchmarks, paired with research on transfer learning to broaden its\nimpact. Benchmarks are dominated by a small set of frequent phenomena, leaving\na long tail of infrequent phenomena underrepresented. In this work, we reflect\non the question: have transfer learning methods sufficiently addressed\nperformance of benchmark-trained models on the long tail? Since benchmarks do\nnot list included/excluded phenomena, we conceptualize the long tail using\nmacro-level dimensions such as underrepresented genres, topics, etc. We assess\ntrends in transfer learning research through a qualitative meta-analysis of 100\nrepresentative papers on transfer learning for NLU. Our analysis asks three\nquestions: (i) Which long tail dimensions do transfer learning studies target?\n(ii) Which properties help adaptation methods improve performance on the long\ntail? (iii) Which methodological gaps have greatest negative impact on long\ntail performance? Our answers to these questions highlight major avenues for\nfuture research in transfer learning for the long tail. Lastly, we present a\ncase study comparing the performance of various adaptation methods on clinical\nnarratives to show how systematically conducted meta-experiments can provide\ninsights that enable us to make progress along these future avenues.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Aakanksha Naik",
      "Jill Lehman",
      "Carolyn Rose"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.01340"
  },
  {
    "id": "arXiv:2111.01341",
    "title": "Lipschitz widths",
    "abstract": "This paper introduces a measure, called Lipschitz widths, of the optimal\nperformance possible of certain nonlinear methods of approximation. It\ndiscusses their relation to entropy numbers and other well known widths such as\nthe Kolmogorov and the stable manifold widths. It also shows that the Lipschitz\nwidths provide a theoretical benchmark for the approximation quality achieved\nvia deep neural networks.",
    "descriptor": "",
    "authors": [
      "Guergana Petrova",
      "Przemyslaw Wojtaszczyk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.01341"
  },
  {
    "id": "arXiv:2111.01342",
    "title": "Attention-Guided Generative Adversarial Network for Whisper to Normal  Speech Conversion",
    "abstract": "Whispered speech is a special way of pronunciation without using vocal cord\nvibration. A whispered speech does not contain a fundamental frequency, and its\nenergy is about 20dB lower than that of a normal speech. Converting a whispered\nspeech into a normal speech can improve speech quality and intelligibility. In\nthis paper, a novel attention-guided generative adversarial network model\nincorporating an autoencoder, a Siamese neural network, and an identity mapping\nloss function for whisper to normal speech conversion (AGAN-W2SC) is proposed.\nThe proposed method avoids the challenge of estimating the fundamental\nfrequency of the normal voiced speech converted from a whispered speech.\nSpecifically, the proposed model is more amendable to practical applications\nbecause it does not need to align speech features for training. Experimental\nresults demonstrate that the proposed AGAN-W2SC can obtain improved speech\nquality and intelligibility compared with dynamic-time-warping-based methods.",
    "descriptor": "",
    "authors": [
      "Teng Gao",
      "Jian Zhou",
      "Huabin Wang",
      "Liang Tao",
      "Hon Keung Kwan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.01342"
  },
  {
    "id": "arXiv:2111.01353",
    "title": "Can Vision Transformers Perform Convolution?",
    "abstract": "Several recent studies have demonstrated that attention-based networks, such\nas Vision Transformer (ViT), can outperform Convolutional Neural Networks\n(CNNs) on several computer vision tasks without using convolutional layers.\nThis naturally leads to the following questions: Can a self-attention layer of\nViT express any convolution operation? In this work, we prove that a single ViT\nlayer with image patches as the input can perform any convolution operation\nconstructively, where the multi-head attention mechanism and the relative\npositional encoding play essential roles. We further provide a lower bound on\nthe number of heads for Vision Transformers to express CNNs. Corresponding with\nour analysis, experimental results show that the construction in our proof can\nhelp inject convolutional bias into Transformers and significantly improve the\nperformance of ViT in low data regimes.",
    "descriptor": "",
    "authors": [
      "Shanda Li",
      "Xiangning Chen",
      "Di He",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01353"
  },
  {
    "id": "arXiv:2111.01354",
    "title": "SmartKC: Smartphone-based Corneal Topographer for Keratoconus Detection",
    "abstract": "Keratoconus is a severe eye disease affecting the cornea (the clear,\ndome-shaped outer surface of the eye), causing it to become thin and develop a\nconical bulge. The diagnosis of keratoconus requires sophisticated ophthalmic\ndevices which are non-portable and very expensive. This makes early detection\nof keratoconus inaccessible to large populations in low- and middle-income\ncountries, making it a leading cause for partial/complete blindness among such\npopulations. We propose SmartKC, a low-cost, smartphone-based keratoconus\ndiagnosis system comprising of a 3D-printed placido's disc attachment, an LED\nlight strip, and an intelligent smartphone app to capture the reflection of the\nplacido rings on the cornea. An image processing pipeline analyzes the corneal\nimage and uses the smartphone's camera parameters, the placido rings' 3D\nlocation, the pixel location of the reflected placido rings and the setup's\nworking distance to construct the corneal surface, via the Arc-Step method and\nZernike polynomials based surface fitting. In a clinical study with 101\ndistinct eyes, we found that SmartKC achieves a sensitivity of 87.8% and a\nspecificity of 80.4%. Moreover, the quantitative curvature estimates (sim-K)\nstrongly correlate with a gold-standard medical device (Pearson correlation\ncoefficient =0.77). Our results indicate that SmartKC has the potential to be\nused as a keratoconus screening tool under real-world medical settings.",
    "descriptor": "\nComments: Accepted for publication in Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT) 2021\n",
    "authors": [
      "Siddhartha Gairola",
      "Murtuza Bohra",
      "Nadeem Shaheer",
      "Navya Jayaprakash",
      "Pallavi Joshi",
      "Anand Balasubramaniam",
      "Kaushik Murali",
      "Nipun Kwatra",
      "Mohit Jain"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.01354"
  },
  {
    "id": "arXiv:2111.01355",
    "title": "Real-time Forecasting of Dockless Scooter-Sharing Demand: A  Context-Aware Spatio-Temporal Multi-Graph Convolutional Network Approach",
    "abstract": "Real-time demand forecasting for shared micromobility can greatly enhance its\npotential benefits and mitigate its adverse effects on urban mobility. The deep\nlearning models provide researchers powerful tools to deal with the real-time\ndockless scooter-sharing demand prediction problem, but existing studies have\nnot fully incorporated the features that are highly associated with the demand,\nsuch as weather conditions, demographic characteristics, and transportation\nsupply. This paper proposes a novel deep learning model named Context-Aware\nSpatio-Temporal Multi-Graph Convolutional Network (CA-STMGCN) to forecast the\nreal-time spatiotemporal dockless scooter-sharing demand. The proposed model\napplies a graph convolutional network (GCN) component that uses spatial\nadjacency graph, functional similarity graph, demographic similarity graph, and\ntransportation supply similarity graph as input to extract spatial dependency\nand attach it to historical demand data. Then, we use a gated recurrent unit\ncomponent to process the output of GCN and weather condition data to capture\ntemporal dependency. A fully connected neural network layer is used to generate\nthe final prediction. The proposed model is evaluated using the real-world\ndockless scooter-sharing demand data in Washington, D.C. The results show that\nCA-STMGCN significantly outperforms all the selected benchmark models, and the\nmost important model component is the weather information. The proposed model\ncan help the operators develop optimal vehicle rebalancing schemes and guide\ncities to regulate the dockless scooter-sharing usage.",
    "descriptor": "",
    "authors": [
      "Yiming Xu",
      "Mudit Paliwal",
      "Xilei Zhao"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.01355"
  },
  {
    "id": "arXiv:2111.01356",
    "title": "DeepParticle: learning invariant measure by a deep neural network  minimizing Wasserstein distance on data generated from an interacting  particle method",
    "abstract": "We introduce the so called DeepParticle method to learn and generate\ninvariant measures of stochastic dynamical systems with physical parameters\nbased on data computed from an interacting particle method (IPM). We utilize\nthe expressiveness of deep neural networks (DNNs) to represent the transform of\nsamples from a given input (source) distribution to an arbitrary target\ndistribution, neither assuming distribution functions in closed form nor a\nfinite state space for the samples. In training, we update the network weights\nto minimize a discrete Wasserstein distance between the input and target\nsamples. To reduce computational cost, we propose an iterative\ndivide-and-conquer (a mini-batch interior point) algorithm, to find the optimal\ntransition matrix in the Wasserstein distance. We present numerical results to\ndemonstrate the performance of our method for accelerating IPM computation of\ninvariant measures of stochastic dynamical systems arising in computing\nreaction-diffusion front speeds through chaotic flows. The physical parameter\nis a large Pecl\\'et number reflecting the advection dominated regime of our\ninterest.",
    "descriptor": "",
    "authors": [
      "Zhongjian Wang",
      "Jack Xin",
      "Zhiwen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.01356"
  },
  {
    "id": "arXiv:2111.01359",
    "title": "Unfoldings and Nets of Regular Polytopes",
    "abstract": "Over a decade ago, it was shown that every edge unfolding of the Platonic\nsolids was without self-overlap, yielding a valid net. We consider this\nproperty for regular polytopes in arbitrary dimensions, notably the simplex,\ncube, and orthoplex. It was recently proven that all unfoldings of the $n$-cube\nyield nets. We show this is also true for the $n$-simplex and the $4$-orthoplex\nbut demonstrate its surprising failure for any orthoplex of higher dimension.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Satyan L. Devadoss",
      "Matthew Harvey"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.01359"
  },
  {
    "id": "arXiv:2111.01363",
    "title": "Knowledge Cross-Distillation for Membership Privacy",
    "abstract": "A membership inference attack (MIA) poses privacy risks on the training data\nof a machine learning model. With an MIA, an attacker guesses if the target\ndata are a member of the training dataset. The state-of-the-art defense against\nMIAs, distillation for membership privacy (DMP), requires not only private data\nto protect but a large amount of unlabeled public data. However, in certain\nprivacy-sensitive domains, such as medical and financial, the availability of\npublic data is not obvious. Moreover, a trivial method to generate the public\ndata by using generative adversarial networks significantly decreases the model\naccuracy, as reported by the authors of DMP. To overcome this problem, we\npropose a novel defense against MIAs using knowledge distillation without\nrequiring public data. Our experiments show that the privacy protection and\naccuracy of our defense are comparable with those of DMP for the benchmark\ntabular datasets used in MIA researches, Purchase100 and Texas100, and our\ndefense has much better privacy-utility trade-off than those of the existing\ndefenses without using public data for image dataset CIFAR10.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Rishav Chourasia",
      "Batnyam Enkhtaivan",
      "Kunihiro Ito",
      "Junki Mori",
      "Isamu Teranishi",
      "Hikaru Tsuchida"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01363"
  },
  {
    "id": "arXiv:2111.01364",
    "title": "Learning to Explore by Reinforcement over High-Level Options",
    "abstract": "Autonomous 3D environment exploration is a fundamental task for various\napplications such as navigation. The goal of exploration is to investigate a\nnew environment and build its occupancy map efficiently. In this paper, we\npropose a new method which grants an agent two intertwined options of\nbehaviors: \"look-around\" and \"frontier navigation\". This is implemented by an\noption-critic architecture and trained by reinforcement learning algorithms. In\neach timestep, an agent produces an option and a corresponding action according\nto the policy. We also take advantage of macro-actions by incorporating classic\npath-planning techniques to increase training efficiency. We demonstrate the\neffectiveness of the proposed method on two publicly available 3D environment\ndatasets and the results show our method achieves higher coverage than\ncompeting techniques with better efficiency.",
    "descriptor": "",
    "authors": [
      "Liu Juncheng",
      "McCane Brendan",
      "Mills Steven"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01364"
  },
  {
    "id": "arXiv:2111.01365",
    "title": "Koopman Q-learning: Offline Reinforcement Learning via Symmetries of  Dynamics",
    "abstract": "Offline reinforcement learning leverages large datasets to train policies\nwithout interactions with the environment. The learned policies may then be\ndeployed in real-world settings where interactions are costly or dangerous.\nCurrent algorithms over-fit to the training dataset and as a consequence\nperform poorly when deployed to out-of-distribution generalizations of the\nenvironment. We aim to address these limitations by learning a Koopman latent\nrepresentation which allows us to infer symmetries of the system's underlying\ndynamic. The latter is then utilized to extend the otherwise static offline\ndataset during training; this constitutes a novel data augmentation framework\nwhich reflects the system's dynamic and is thus to be interpreted as an\nexploration of the environments phase space. To obtain the symmetries we employ\nKoopman theory in which nonlinear dynamics are represented in terms of a linear\noperator acting on the space of measurement functions of the system and thus\nsymmetries of the dynamics may be inferred directly. We provide novel\ntheoretical results on the existence and nature of symmetries relevant for\ncontrol systems such as reinforcement learning settings. Moreover, we\nempirically evaluate our method on several benchmark offline reinforcement\nlearning tasks and datasets including D4RL, Metaworld and Robosuite and find\nthat by using our framework we consistently improve the state-of-the-art for\nQ-learning methods.",
    "descriptor": "",
    "authors": [
      "Matthias Weissenbacher",
      "Samarth Sinha",
      "Animesh Garg",
      "Yoshinobu Kawahara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01365"
  },
  {
    "id": "arXiv:2111.01366",
    "title": "Improved Loss Function-Based Prediction Method of Extreme Temperatures  in Greenhouses",
    "abstract": "The prediction of extreme greenhouse temperatures to which crops are\nsusceptible is essential in the field of greenhouse planting. It can help avoid\nheat or freezing damage and economic losses. Therefore, it's important to\ndevelop models that can predict them accurately. Due to the lack of extreme\ntemperature data in datasets, it is challenging for models to accurately\npredict it. In this paper, we propose an improved loss function, which is\nsuitable for a variety of machine learning models. By increasing the weight of\nextreme temperature samples and reducing the possibility of misjudging extreme\ntemperature as normal, the proposed loss function can enhance the prediction\nresults in extreme situations. To verify the effectiveness of the proposed\nmethod, we implement the improved loss function in LightGBM, long short-term\nmemory, and artificial neural network and conduct experiments on a real-world\ngreenhouse dataset. The results show that the performance of models with the\nimproved loss function is enhanced compared to the original models in extreme\ncases. The improved models can be used to guarantee the timely judgment of\nextreme temperatures in agricultural greenhouses, thereby preventing\nunnecessary losses caused by incorrect predictions.",
    "descriptor": "",
    "authors": [
      "Liao Qu",
      "Shuaiqi Huang",
      "Yunsong Jia",
      "Xiang Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01366"
  },
  {
    "id": "arXiv:2111.01369",
    "title": "Wafer-level Variation Modeling for Multi-site RF IC Testing via  Hierarchical Gaussian Process",
    "abstract": "Wafer-level performance prediction has been attracting attention to reduce\nmeasurement costs without compromising test quality in production tests.\nAlthough several efficient methods have been proposed, the site-to-site\nvariation, which is often observed in multi-site testing for radio frequency\ncircuits, has not yet been sufficiently addressed. In this paper, we propose a\nwafer-level performance prediction method for multi-site testing that can\nconsider the site-to-site variation. The proposed method is based on the\nGaussian process, which is widely used for wafer-level spatial correlation\nmodeling, improving the prediction accuracy by extending hierarchical modeling\nto exploit the test site information provided by test engineers. In addition,\nwe propose an active test-site sampling method to maximize measurement cost\nreduction. Through experiments using industrial production test data, we\ndemonstrate that the proposed method can reduce the estimation error to 1/19 of\nthat obtained using a conventional method. Moreover, we demonstrate that the\nproposed sampling method can reduce the number of the measurements by 97% while\nachieving sufficient estimation accuracy.",
    "descriptor": "\nComments: 10 pages, 13 figures\n",
    "authors": [
      "Michihiro Shintani",
      "Riaz-Ul-Haque Mian",
      "Tomoki Nakamura",
      "Masuo Kajiyama",
      "Makoto Eiki",
      "Michiko Inoue"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.01369"
  },
  {
    "id": "arXiv:2111.01370",
    "title": "FedGraph: Federated Graph Learning with Intelligent Sampling",
    "abstract": "Federated learning has attracted much research attention due to its privacy\nprotection in distributed machine learning. However, existing work of federated\nlearning mainly focuses on Convolutional Neural Network (CNN), which cannot\nefficiently handle graph data that are popular in many applications. Graph\nConvolutional Network (GCN) has been proposed as one of the most promising\ntechniques for graph learning, but its federated setting has been seldom\nexplored. In this paper, we propose FedGraph for federated graph learning among\nmultiple computing clients, each of which holds a subgraph. FedGraph provides\nstrong graph learning capability across clients by addressing two unique\nchallenges. First, traditional GCN training needs feature data sharing among\nclients, leading to risk of privacy leakage. FedGraph solves this issue using a\nnovel cross-client convolution operation. The second challenge is high GCN\ntraining overhead incurred by large graph size. We propose an intelligent graph\nsampling algorithm based on deep reinforcement learning, which can\nautomatically converge to the optimal sampling policies that balance training\nspeed and accuracy. We implement FedGraph based on PyTorch and deploy it on a\ntestbed for performance evaluation. The experimental results of four popular\ndatasets demonstrate that FedGraph significantly outperforms existing work by\nenabling faster convergence to higher accuracy.",
    "descriptor": "\nComments: Accepted by IEEE TPDS\n",
    "authors": [
      "Fahao Chen",
      "Peng Li",
      "Toshiaki Miyazaki",
      "Celimuge Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.01370"
  },
  {
    "id": "arXiv:2111.01371",
    "title": "Envelope Imbalance Learning Algorithm based on Multilayer Fuzzy C-means  Clustering and Minimum Interlayer discrepancy",
    "abstract": "Imbalanced learning is important and challenging since the problem of the\nclassification of imbalanced datasets is prevalent in machine learning and data\nmining fields. Sampling approaches are proposed to address this issue, and\ncluster-based oversampling methods have shown great potential as they aim to\nsimultaneously tackle between-class and within-class imbalance issues. However,\nall existing clustering methods are based on a one-time approach. Due to the\nlack of a priori knowledge, improper setting of the number of clusters often\nexists, which leads to poor clustering performance. Besides, the existing\nmethods are likely to generate noisy instances. To solve these problems, this\npaper proposes a deep instance envelope network-based imbalanced learning\nalgorithm with the multilayer fuzzy c-means (MlFCM) and a minimum interlayer\ndiscrepancy mechanism based on the maximum mean discrepancy (MIDMD). This\nalgorithm can guarantee high quality balanced instances using a deep instance\nenvelope network in the absence of prior knowledge. In the experimental\nsection, thirty-three popular public datasets are used for verification, and\nover ten representative algorithms are used for comparison. The experimental\nresults show that the proposed approach significantly outperforms other popular\nmethods.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Fan Li",
      "Xiaoheng Zhang",
      "Pin Wang",
      "Yongming Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01371"
  },
  {
    "id": "arXiv:2111.01376",
    "title": "SEED: Series Elastic End Effectors in 6D for Visuotactile Tool Use",
    "abstract": "We propose the framework of Series Elastic End Effectors in 6D (SEED), which\ncombines a spatially compliant element with visuotactile sensing to grasp and\nmanipulate tools in the wild. Our framework generalizes the benefits of series\nelasticity to 6-dof, while providing an abstraction of control using\nvisuotactile sensing. We propose an algorithm for relative pose estimation from\nvisuotactile sensing, and a spatial hybrid force-position controller capable of\nachieving stable force interaction with the environment. We demonstrate the\neffectiveness of our framework on tools that require regulation of spatial\nforces. Video link: https://youtu.be/2-YuIfspDrk",
    "descriptor": "\nComments: Submitted to Robosoft 2022\n",
    "authors": [
      "H.J. Terry Suh",
      "Naveen Kuppuswamy",
      "Tao Pang",
      "Paul Mitiguy",
      "Alex Alspach",
      "Russ Tedrake"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.01376"
  },
  {
    "id": "arXiv:2111.01378",
    "title": "Finding the KT partition of a weighted graph in near-linear time",
    "abstract": "In a breakthrough work, Kawarabayashi and Thorup (J.~ACM'19) gave a\nnear-linear time deterministic algorithm for minimum cut in a simple graph $G =\n(V,E)$. A key component is finding the $(1+\\varepsilon)$-KT partition of $G$,\nthe coarsest partition $\\{P_1, \\ldots, P_k\\}$ of $V$ such that for every\nnon-trivial $(1+\\varepsilon)$-near minimum cut with sides $\\{S, \\bar{S}\\}$ it\nholds that $P_i$ is contained in either $S$ or $\\bar{S}$, for $i=1, \\ldots, k$.\nHere we give a near-linear time randomized algorithm to find the\n$(1+\\varepsilon)$-KT partition of a weighted graph. Our algorithm is quite\ndifferent from that of Kawarabayashi and Thorup and builds on Karger's\nframework of tree-respecting cuts (J.~ACM'00).\nWe describe applications of the algorithm. (i) The algorithm makes progress\ntowards a more efficient algorithm for constructing the polygon representation\nof the set of near-minimum cuts in a graph. This is a generalization of the\ncactus representation initially described by Bencz\\'ur (FOCS'95). (ii) We\nimprove the time complexity of a recent quantum algorithm for minimum cut in a\nsimple graph in the adjacency list model from $\\widetilde O(n^{3/2})$ to\n$\\widetilde O(\\sqrt{mn})$. (iii) We describe a new type of randomized algorithm\nfor minimum cut in simple graphs with complexity $O(m + n \\log^6 n)$. For\nslightly dense graphs this matches the complexity of the current best $O(m + n\n\\log^2 n)$ algorithm which uses a different approach based on random\ncontractions.\nThe key technical contribution of our work is the following. Given a weighted\ngraph $G$ with $m$ edges and a spanning tree $T$, consider the graph $H$ whose\nnodes are the edges of $T$, and where there is an edge between two nodes of $H$\niff the corresponding 2-respecting cut of $T$ is a non-trivial near-minimum cut\nof $G$. We give a $O(m \\log^4 n)$ time deterministic algorithm to compute a\nspanning forest of $H$.",
    "descriptor": "",
    "authors": [
      "Simon Apers",
      "Pawe\u0142 Gawrychowski",
      "Troy Lee"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.01378"
  },
  {
    "id": "arXiv:2111.01383",
    "title": "A Comparative Analysis of Machine Learning Algorithms for Intrusion  Detection in Edge-Enabled IoT Networks",
    "abstract": "A significant increase in the number of interconnected devices and data\ncommunication through wireless networks has given rise to various threats,\nrisks and security concerns. Internet of Things (IoT) applications is deployed\nin almost every field of daily life, including sensitive environments. The edge\ncomputing paradigm has complemented IoT applications by moving the\ncomputational processing near the data sources. Among various security models,\nMachine Learning (ML) based intrusion detection is the most conceivable defense\nmechanism to combat the anomalous behavior in edge-enabled IoT networks. The ML\nalgorithms are used to classify the network traffic into normal and malicious\nattacks. Intrusion detection is one of the challenging issues in the area of\nnetwork security. The research community has proposed many intrusion detection\nsystems. However, the challenges involved in selecting suitable algorithm(s) to\nprovide security in edge-enabled IoT networks exist. In this paper, a\ncomparative analysis of conventional machine learning classification algorithms\nhas been performed to categorize the network traffic on NSL-KDD dataset using\nJupyter on Pycharm tool. It can be observed that Multi-Layer Perception (MLP)\nhas dependencies between input and output and relies more on network\nconfiguration for intrusion detection. Therefore, MLP can be more appropriate\nfor edge-based IoT networks with a better training time of 1.2 seconds and\ntesting accuracy of 79%.",
    "descriptor": "",
    "authors": [
      "Poornima Mahadevappa",
      "Syeda Mariam Muzammal",
      "Raja Kumar Murugesan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01383"
  },
  {
    "id": "arXiv:2111.01387",
    "title": "Understanding Entropic Regularization in GANs",
    "abstract": "Generative Adversarial Networks are a popular method for learning\ndistributions from data by modeling the target distribution as a function of a\nknown distribution. The function, often referred to as the generator, is\noptimized to minimize a chosen distance measure between the generated and\ntarget distributions. One commonly used measure for this purpose is the\nWasserstein distance. However, Wasserstein distance is hard to compute and\noptimize, and in practice entropic regularization techniques are used to\nimprove numerical convergence. The influence of regularization on the learned\nsolution, however, remains not well-understood. In this paper, we study how\nseveral popular entropic regularizations of Wasserstein distance impact the\nsolution in a simple benchmark setting where the generator is linear and the\ntarget distribution is high-dimensional Gaussian. We show that entropy\nregularization promotes the solution sparsification, while replacing the\nWasserstein distance with the Sinkhorn divergence recovers the unregularized\nsolution. Both regularization techniques remove the curse of dimensionality\nsuffered by Wasserstein distance. We show that the optimal generator can be\nlearned to accuracy $\\epsilon$ with $O(1/\\epsilon^2)$ samples from the target\ndistribution. We thus conclude that these regularization techniques can improve\nthe quality of the generator learned from empirical data for a large class of\ndistributions.",
    "descriptor": "\nComments: 29 pages, 7 figures\n",
    "authors": [
      "Daria Reshetova",
      "Yikun Bai",
      "Xiugang Wu",
      "Ayfer Ozgur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01387"
  },
  {
    "id": "arXiv:2111.01391",
    "title": "Simulation of Parallel-Jaw Grasping using Incremental Potential Contact  Models",
    "abstract": "Soft compliant jaw tips are almost universally used with parallel-jaw robot\ngrippers due to their ability to increase contact area and friction between the\njaws and the object to be manipulated. However, interactions between the\ncompliant surfaces and rigid objects are notoriously difficult to model. We\nintroduce IPC-GraspSim, a novel simulator using Incremental Potential Contact\n(IPC) - a deformation model developed in 2020 for computer graphics - that\nmodels both the dynamics and the deformation of compliant jaw tips during\ngrasping. IPC-GraspSim is evaluated using a set of 2,000 physical grasps across\n16 adversarial objects where standard analytic models perform poorly. In\ncomparison to both analytic quasistatic contact models (soft point contact,\nREACH, 6DFC) and dynamic grasp simulators (Isaac Gym with FleX backend),\nresults suggest that IPC-GraspSim more accurately models real-world grasps,\nincreasing F1 score by 9%. All data, code, videos, and supplementary material\nare available at https://sites.google.com/berkeley.edu/ipcgraspsim.",
    "descriptor": "",
    "authors": [
      "Chung Min Kim",
      "Michael Danielczuk",
      "Isabella Huang",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.01391"
  },
  {
    "id": "arXiv:2111.01392",
    "title": "Overlapping and nonoverlapping models",
    "abstract": "Consider a directed network with $K_{r}$ row communities and $K_{c}$ column\ncommunities. Previous works found that modeling directed networks in which all\nnodes have overlapping property requires $K_{r}=K_{c}$ for identifiability. In\nthis paper, we propose an overlapping and nonoverlapping model to study\ndirected networks in which row nodes have overlapping property while column\nnodes do not. The proposed model is identifiable when $K_{r}\\leq K_{c}$.\nMeanwhile, we provide one identifiable model as extension of ONM to model\ndirected networks with variation in node degree. Two spectral algorithms with\ntheoretical guarantee on consistent estimations are designed to fit the models.\nA small scale of numerical studies are used to illustrate the algorithms.",
    "descriptor": "",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.01392"
  },
  {
    "id": "arXiv:2111.01393",
    "title": "Time Series Comparisons in Deep Space Network",
    "abstract": "The Deep Space Network is NASA's international array of antennas that support\ninterplanetary spacecraft missions. A track is a block of multi-dimensional\ntime series from the beginning to end of DSN communication with the target\nspacecraft, containing thousands of monitor data items lasting several hours at\na frequency of 0.2-1Hz. Monitor data on each track reports on the performance\nof specific spacecraft operations and the DSN itself. DSN is receiving signals\nfrom 32 spacecraft across the solar system. DSN has pressure to reduce costs\nwhile maintaining the quality of support for DSN mission users. DSN Link\nControl Operators need to simultaneously monitor multiple tracks and identify\nanomalies in real time. DSN has seen that as the number of missions increases,\nthe data that needs to be processed increases over time. In this project, we\nlook at the last 8 years of data for analysis. Any anomaly in the track\nindicates a problem with either the spacecraft, DSN equipment, or weather\nconditions. DSN operators typically write Discrepancy Reports for further\nanalysis. It is recognized that it would be quite helpful to identify 10\nsimilar historical tracks out of the huge database to quickly find and match\nanomalies. This tool has three functions: (1) identification of the top 10\nsimilar historical tracks, (2) detection of anomalies compared to the reference\nnormal track, and (3) comparison of statistical differences between two given\ntracks. The requirements for these features were confirmed by survey responses\nfrom 21 DSN operators and engineers. The preliminary machine learning model has\nshown promising performance (AUC=0.92). We plan to increase the number of data\nsets and perform additional testing to improve performance further before its\nplanned integration into the track visualizer interface to assist DSN field\noperators and engineers.",
    "descriptor": "\nComments: 7 pages, 8 figures, AIAA-ASCEND 2021\n",
    "authors": [
      "Kyongsik Yun",
      "Rishi Verma",
      "Umaa Rebbapragada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2111.01393"
  },
  {
    "id": "arXiv:2111.01394",
    "title": "Solving Partial Differential Equations with Point Source Based on  Physics-Informed Neural Networks",
    "abstract": "In recent years, deep learning technology has been used to solve partial\ndifferential equations (PDEs), among which the physics-informed neural networks\n(PINNs) emerges to be a promising method for solving both forward and inverse\nPDE problems. PDEs with a point source that is expressed as a Dirac delta\nfunction in the governing equations are mathematical models of many physical\nprocesses. However, they cannot be solved directly by conventional PINNs method\ndue to the singularity brought by the Dirac delta function. We propose a\nuniversal solution to tackle this problem with three novel techniques. Firstly\nthe Dirac delta function is modeled as a continuous probability density\nfunction to eliminate the singularity; secondly a lower bound constrained\nuncertainty weighting algorithm is proposed to balance the PINNs losses between\npoint source area and other areas; and thirdly a multi-scale deep neural\nnetwork with periodic activation function is used to improve the accuracy and\nconvergence speed of the PINNs method. We evaluate the proposed method with\nthree representative PDEs, and the experimental results show that our method\noutperforms existing deep learning-based methods with respect to the accuracy,\nthe efficiency and the versatility.",
    "descriptor": "",
    "authors": [
      "Xiang Huang",
      "Hongsheng Liu",
      "Beiji Shi",
      "Zidong Wang",
      "Kang Yang",
      "Yang Li",
      "Bingya Weng",
      "Min Wang",
      "Haotian Chu",
      "Jing Zhou",
      "Fan Yu",
      "Bei Hua",
      "Lei Chen",
      "Bin Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.01394"
  },
  {
    "id": "arXiv:2111.01395",
    "title": "Training Certifiably Robust Neural Networks with Efficient Local  Lipschitz Bounds",
    "abstract": "Certified robustness is a desirable property for deep neural networks in\nsafety-critical applications, and popular training algorithms can certify\nrobustness of a neural network by computing a global bound on its Lipschitz\nconstant. However, such a bound is often loose: it tends to over-regularize the\nneural network and degrade its natural accuracy. A tighter Lipschitz bound may\nprovide a better tradeoff between natural and certified accuracy, but is\ngenerally hard to compute exactly due to non-convexity of the network. In this\nwork, we propose an efficient and trainable \\emph{local} Lipschitz upper bound\nby considering the interactions between activation functions (e.g. ReLU) and\nweight matrices. Specifically, when computing the induced norm of a weight\nmatrix, we eliminate the corresponding rows and columns where the activation\nfunction is guaranteed to be a constant in the neighborhood of each given data\npoint, which provides a provably tighter bound than the global Lipschitz\nconstant of the neural network. Our method can be used as a plug-in module to\ntighten the Lipschitz bound in many certifiable training algorithms.\nFurthermore, we propose to clip activation functions (e.g., ReLU and MaxMin)\nwith a learnable upper threshold and a sparsity loss to assist the network to\nachieve an even tighter local Lipschitz bound. Experimentally, we show that our\nmethod consistently outperforms state-of-the-art methods in both clean and\ncertified accuracy on MNIST, CIFAR-10 and TinyImageNet datasets with various\nnetwork architectures.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Yujia Huang",
      "Huan Zhang",
      "Yuanyuan Shi",
      "J Zico Kolter",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01395"
  },
  {
    "id": "arXiv:2111.01396",
    "title": "Boundary Distribution Estimation to Precise Object Detection",
    "abstract": "In principal modern detectors, the task of object localization is implemented\nby the box subnet which concentrates on bounding box regression. The box subnet\ncustomarily predicts the position of the object by regressing box center\nposition and scaling factors. Although this approach is frequently adopted, we\nobserve that the result of localization remains defective, which makes the\nperformance of the detector unsatisfactory. In this paper, we prove the flaws\nin the previous method through theoretical analysis and experimental\nverification and propose a novel solution to detect objects precisely. Rather\nthan plainly focusing on center and size, our approach refines the edges of the\nbounding box on previous localization results by estimating the distribution at\nthe boundary of the object. Experimental results have shown the potentiality\nand generalization of our proposed method.",
    "descriptor": "",
    "authors": [
      "Haoran Zhou",
      "Hang Huang",
      "Rui Zhao",
      "Wei Wang",
      "Qingguo Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01396"
  },
  {
    "id": "arXiv:2111.01398",
    "title": "Integrating Pretrained Language Model for Dialogue Policy Learning",
    "abstract": "Reinforcement Learning (RL) has been witnessed its potential for training a\ndialogue policy agent towards maximizing the accumulated rewards given from\nusers. However, the reward can be very sparse for it is usually only provided\nat the end of a dialog session, which causes unaffordable interaction\nrequirements for an acceptable dialog agent. Distinguished from many efforts\ndedicated to optimizing the policy and recovering the reward alternatively\nwhich suffers from easily getting stuck in local optima and model collapse, we\ndecompose the adversarial training into two steps: 1) we integrate a\npre-trained language model as a discriminator to judge whether the current\nsystem action is good enough for the last user action (i.e., \\textit{next\naction prediction}); 2) the discriminator gives and extra local dense reward to\nguide the agent's exploration. The experimental result demonstrates that our\nmethod significantly improves the complete rate (~4.4\\%) and success rate\n(~8.0\\%) of the dialogue system.",
    "descriptor": "",
    "authors": [
      "Hongru Wang",
      "Huimin Wang",
      "Zezhong Wang",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01398"
  },
  {
    "id": "arXiv:2111.01400",
    "title": "Cognitive Load and Productivity Implications in Human-Chatbot  Interaction",
    "abstract": "The increasing progress in artificial intelligence and respective machine\nlearning technology has fostered the proliferation of chatbots to the point\nwhere today they are being embedded into various human-technology interaction\ntasks. In enterprise contexts, the use of chatbots seeks to reduce labor costs\nand consequently increase productivity. For simple, repetitive customer service\ntasks such already proves beneficial, yet more complex collaborative knowledge\nwork seems to require a better understanding of how the technology may best be\nintegrated. Particularly, the additional mental burden which accompanies the\nuse of these natural language based artificial assistants, often remains\noverlooked. To this end, cognitive load theory implies that unnecessary use of\ntechnology can induce additional extrinsic load and thus may have a contrary\neffect on users' productivity. The research presented in this paper thus\nreports on a study assessing cognitive load and productivity implications of\nhuman chatbot interaction in a realistic enterprise setting. A/B testing\nsoftware-only vs. software + chatbot interaction, and the NASA TLX were used to\nevaluate and compare the cognitive load of two user groups. Results show that\nchatbot users experienced less cognitive load and were more productive than\nsoftware-only users. Furthermore, they show lower frustration levels and better\noverall performance (i.e, task quality) despite their slightly longer average\ntask completion time.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Johanna Schmidhuber",
      "Stephan Schl\u00f6gl",
      "Christian Ploder"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.01400"
  },
  {
    "id": "arXiv:2111.01406",
    "title": "Dazed and Confused: What's Wrong with Crypto Libraries?",
    "abstract": "Recent studies have shown that developers have difficulties in using\ncryptographic APIs, which often led to security flaws. We are interested to\ntackle this matter by looking into what types of problems exist in various\ncrypto libraries. We manually studied 500 posts on Stack Overflow associated\nwith 20 popular crypto libraries. We realized there are 10 themes in the\ndiscussions. Interestingly, there were only two questions related to attacks\nagainst cryptography. There were 63 discussions in which developers had\ninteroperability issues when working with more than a crypto library. The\nmajority of posts (i.e. 112) were about encryption/decryption problems and 111\nwere about installation/compilation issues of crypto libraries. Overall, we\nrealize that the crypto libraries are frequently involved in more than five\nthemes of discussions. We believe the current initial findings can help team\nleaders and experienced developers to correctly guide the team members in the\ndomain of cryptography. Moreover, future research should investigate the\nsimilarity of problems at the API level among popular crypto libraries.",
    "descriptor": "\nComments: 18th Annual International Conference on Privacy, Security and Trust (PST2021)\n",
    "authors": [
      "Mohammadreza Hazhirpasand",
      "Oscar Nierstrasz",
      "Mohammad Ghafari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.01406"
  },
  {
    "id": "arXiv:2111.01413",
    "title": "A Minmax Utilization Algorithm for Network Traffic Scheduling of  Industrial Robots",
    "abstract": "Emerging 5G and beyond wireless industrial virtualized networks are expected\nto support a significant number of robotic manipulators. Depending on the\nprocesses involved, these industrial robots might result in significant volume\nof multi-modal traffic that will need to traverse the network all the way to\nthe (public/private) edge cloud, where advanced processing, control and service\norchestration will be taking place. In this paper, we perform the traffic\nengineering by capitalizing on the underlying pseudo-deterministic nature of\nthe repetitive processes of robotic manipulators in an industrial environment\nand propose an integer linear programming (ILP) model to minimize the maximum\naggregate traffic in the network. The task sequence and time gap requirements\nare also considered in the proposed model. To tackle the curse of\ndimensionality in ILP, we provide a random search algorithm with quadratic time\ncomplexity. Numerical investigations reveal that the proposed scheme can reduce\nthe peak data rate up to 53.4% compared with the nominal case where robotic\nmanipulators operate in an uncoordinated fashion, resulting in significant\nimprovement in the utilization of the underlying network resources.",
    "descriptor": "\nComments: 6 pages, 4 figures, 2 tables\n",
    "authors": [
      "Yantong Wang",
      "Vasilis Friderikos",
      "Sebastian Andraos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2111.01413"
  },
  {
    "id": "arXiv:2111.01414",
    "title": "A Review of Dialogue Systems: From Trained Monkeys to Stochastic Parrots",
    "abstract": "In spoken dialogue systems, we aim to deploy artificial intelligence to build\nautomated dialogue agents that can converse with humans. Dialogue systems are\nincreasingly being designed to move beyond just imitating conversation and also\nimprove from such interactions over time. In this survey, we present a broad\noverview of methods developed to build dialogue systems over the years.\nDifferent use cases for dialogue systems ranging from task-based systems to\nopen domain chatbots motivate and necessitate specific systems. Starting from\nsimple rule-based systems, research has progressed towards increasingly complex\narchitectures trained on a massive corpus of datasets, like deep learning\nsystems. Motivated with the intuition of resembling human dialogues, progress\nhas been made towards incorporating emotions into the natural language\ngenerator, using reinforcement learning. While we see a trend of highly\nmarginal improvement on some metrics, we find that limited justification exists\nfor the metrics, and evaluation practices are not uniform. To conclude, we flag\nthese concerns and highlight possible research directions.",
    "descriptor": "",
    "authors": [
      "Atharv Singh Patlan",
      "Shiven Tripathi",
      "Shubham Korde"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01414"
  },
  {
    "id": "arXiv:2111.01415",
    "title": "iCallee: Recovering Call Graphs for Binaries",
    "abstract": "Recovering programs' call graphs is crucial for inter-procedural analysis\ntasks and applications based on them. The core challenge is recognizing targets\nof indirect calls (i.e., indirect callees). It becomes more challenging if\ntarget programs are in binary forms, due to information loss in binaries.\nExisting indirect callee recognition solutions for binaries all have high false\npositives and negatives, making call graphs inaccurate.\nIn this paper, we propose a new solution iCallee based on the Siamese Neural\nNetwork, inspired by the advances in question-answering applications. The key\ninsight is that, neural networks can learn to answer whether a callee function\nis a potential target of an indirect callsite by comprehending their contexts,\ni.e., instructions nearby callsites and of callees. Following this insight, we\nfirst preprocess target binaries to extract contexts of callsites and callees.\nThen, we build a customized Natural Language Processing (NLP) model applicable\nto assembly language. Further, we collect abundant pairs of callsites and\ncallees, and embed their contexts with the NLP model, then train a Siamese\nnetwork and a classifier to answer the callsite-callee question. We have\nimplemented a prototype of iCallee and evaluated it on several groups of\ntargets. Evaluation results showed that, our solution could match callsites to\ncallees with an F1-Measure of 93.7%, recall of 93.8%, and precision of 93.5%,\nmuch better than state-of-the-art solutions. To show its usefulness, we apply\niCallee to two specific applications - binary code similarity detection and\nbinary program hardening, and found that it could greatly improve\nstate-of-the-art solutions.",
    "descriptor": "",
    "authors": [
      "Wenyu Zhu",
      "Zhiyao Feng",
      "Zihan Zhang",
      "Chao Zhang",
      "Zhijian Ou",
      "Min Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.01415"
  },
  {
    "id": "arXiv:2111.01418",
    "title": "A Pixel-Level Meta-Learner for Weakly Supervised Few-Shot Semantic  Segmentation",
    "abstract": "Few-shot semantic segmentation addresses the learning task in which only few\nimages with ground truth pixel-level labels are available for the novel classes\nof interest. One is typically required to collect a large mount of data (i.e.,\nbase classes) with such ground truth information, followed by meta-learning\nstrategies to address the above learning task. When only image-level semantic\nlabels can be observed during both training and testing, it is considered as an\neven more challenging task of weakly supervised few-shot semantic segmentation.\nTo address this problem, we propose a novel meta-learning framework, which\npredicts pseudo pixel-level segmentation masks from a limited amount of data\nand their semantic labels. More importantly, our learning scheme further\nexploits the produced pixel-level information for query image inputs with\nsegmentation guarantees. Thus, our proposed learning model can be viewed as a\npixel-level meta-learner. Through extensive experiments on benchmark datasets,\nwe show that our model achieves satisfactory performances under fully\nsupervised settings, yet performs favorably against state-of-the-art methods\nunder weakly supervised settings.",
    "descriptor": "\nComments: Accepted to WACV 2022\n",
    "authors": [
      "Yuan-Hao Lee",
      "Fu-En Yang",
      "Yu-Chiang Frank Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01418"
  },
  {
    "id": "arXiv:2111.01419",
    "title": "The Multiplicative Compound of a Matrix Pencil with Applications to  Difference-Algebraic Equations",
    "abstract": "The multiplicative and additive compounds of a matrix have important\napplications in geometry, linear algebra, and dynamical systems described by\ndifference equations and by ordinary differential equations. Here, we introduce\na generalization of the multiplicative compound to matrix pencils. We analyze\nthe properties of this new compound and describe several applications to the\nanalysis of discrete-time dynamical systems described by difference-algebraic\nequations.",
    "descriptor": "",
    "authors": [
      "Ron Ofir",
      "Michael Margaliot"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01419"
  },
  {
    "id": "arXiv:2111.01421",
    "title": "The Security Risk of Lacking Compiler Protection in WebAssembly",
    "abstract": "WebAssembly is increasingly used as the compilation target for cross-platform\napplications. In this paper, we investigate whether one can rely on the\nsecurity measures enforced by existing C compilers when compiling C programs to\nWebAssembly. We compiled 4,469 C programs with known buffer overflow\nvulnerabilities to x86 code and to WebAssembly, and observed the outcome of the\nexecution of the generated code to differ for 1,088 programs. Through manual\ninspection, we identified that the root cause for these is the lack of security\nmeasures such as stack canaries in the generated WebAssembly: while x86 code\ncrashes upon a stack-based buffer overflow, the corresponding WebAssembly\ncontinues to be executed. We conclude that compiling an existing C program to\nWebAssembly without additional precautions may hamper its security, and we\nencourage more research in this direction.",
    "descriptor": "\nComments: The 21st IEEE International Conference on Software Quality, Reliability and Security (QRS 2021)\n",
    "authors": [
      "Quentin Sti\u00e9venart",
      "Coen De Roover",
      "Mohammad Ghafari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.01421"
  },
  {
    "id": "arXiv:2111.01422",
    "title": "Fast Algorithms for Hop-Constrained Flows and Moving Cuts",
    "abstract": "Hop-constrained flows and their duals, moving cuts, are two fundamental\nquantities in network optimization. Up to poly-logarithmic factors, they\ncharacterize how quickly a network can accomplish numerous distributed\nprimitives. In this work, we give the first efficient algorithms for computing\n$(1 \\pm \\epsilon) $-optimal $h$-hop-constrained flows and moving cuts with high\nprobability. Our algorithms take $\\tilde{O}(m \\cdot \\text{poly}(h))$ sequential\ntime, $\\tilde{O}(\\text{poly}(h))$ parallel time and $\\tilde{O}(\\text{poly}(h))$\ndistributed CONGEST time. We use these algorithms to efficiently compute\nhop-constrained cutmatches, an object at the heart of recent advances in\nexpander decompositions.",
    "descriptor": "",
    "authors": [
      "Bernhard Haeupler",
      "D Ellis Hershkowitz",
      "Thatchaphol Saranurak"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.01422"
  },
  {
    "id": "arXiv:2111.01425",
    "title": "Rational Agreement in the Presence of Crash Faults",
    "abstract": "Blockchain systems need to solve consensus despite the presence of rational\nusers and failures. The notion of $(k,t)$-robustness has shown instrumental to\nlist problems that cannot be solved if $k$ players are rational and $t$ players\nare Byzantine or act arbitrarily. What is less clear is whether one can solve\nsuch problems if the faults are benign.\nIn this paper, we bridge the gap between games that are robust against\nByzantine players and games that are robust against crash players. Our first\nresult is an impossibility result:\nWe show that no $(k,t)$-robust consensus protocol can solve consensus in the\ncrash model if $k+2t\\geq n$ unless there is a particular punishment strategy,\ncalled the $(k,t)$-baiting strategy. This reveals the need to introduce baiting\nas the act of rewarding a colluding node when betraying its coalition, to make\nblockchains more secure.\nOur second result is an equivalence relation between crash fault tolerant\ngames and Byzantine fault tolerant games, which raises an interesting research\nquestion on the power of baiting to solve consensus. To this end, we show, on\nthe one hand, that a $(k,t)$-robust consensus protocol becomes $(k+t,t)$-robust\nin the crash model. We show, on the other hand, that the existence of a\n$(k,t)$-robust consensus protocol in the crash model that does not make use of\na baiting strategy implies the existence of a $(k-t,t)$-robust consensus\nprotocol in the Byzantine model, with the help of cryptography.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.04357\n",
    "authors": [
      "Alejandro Ranchal-Pedrosa",
      "Vincent Gramoli"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.01425"
  },
  {
    "id": "arXiv:2111.01430",
    "title": "CycleGAN with Dual Adversarial Loss for Bone-Conducted Speech  Enhancement",
    "abstract": "Compared with air-conducted speech, bone-conducted speech has the unique\nadvantage of shielding background noise. Enhancement of bone-conducted speech\nhelps to improve its quality and intelligibility. In this paper, a novel\nCycleGAN with dual adversarial loss (CycleGAN-DAL) is proposed for\nbone-conducted speech enhancement. The proposed method uses an adversarial loss\nand a cycle-consistent loss simultaneously to learn forward and cyclic mapping,\nin which the adversarial loss is replaced with the classification adversarial\nloss and the defect adversarial loss to consolidate the forward mapping.\nCompared with conventional baseline methods, it can learn feature mapping\nbetween bone-conducted speech and target speech without additional\nair-conducted speech assistance. Moreover, the proposed method also avoids the\noversmooth problem which is occurred commonly in conventional statistical based\nmodels. Experimental results show that the proposed method outperforms baseline\nmethods such as CycleGAN, GMM, and BLSTM. Keywords: Bone-conducted speech\nenhancement, dual adversarial loss, Parallel CycleGAN, high frequency speech\nreconstruction",
    "descriptor": "",
    "authors": [
      "Qing Pan",
      "Teng Gao",
      "Jian Zhou",
      "Huabin Wang",
      "Liang Tao",
      "Hon Keung Kwan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.01430"
  },
  {
    "id": "arXiv:2111.01431",
    "title": "Graph Tree Deductive Networks",
    "abstract": "In this paper, we introduce Graph Tree Deductive Networks, a network that\nperforms deductive reasoning. To have high-dimensional thinking, combining\nvarious axioms and putting the results back into another axiom is necessary to\nproduce new relationships and results. For example, it would be given two\npropositions: \"Socrates is a man.\" and \"All men are mortals.\" and two\npropositions could be used to infer the new proposition, \"Therefore Socrates is\nmortal.\". To evaluate, we used MNIST Dataset, a handwritten numerical image\ndataset, to apply it to the group theory and show the results of performing\ndeductive learning.",
    "descriptor": "\nComments: A simple experiment was conducted as a series of graph tree neural networks\n",
    "authors": [
      "Seokjun Kim",
      "Jaeeun Jang",
      "Hyeoncheol Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01431"
  },
  {
    "id": "arXiv:2111.01432",
    "title": "Practical and Light-weight Secure Aggregation for Federated Submodel  Learning",
    "abstract": "Recently, Niu, et. al. introduced a new variant of Federated Learning (FL),\ncalled Federated Submodel Learning (FSL). Different from traditional FL, each\nclient locally trains the submodel (e.g., retrieved from the servers) based on\nits private data and uploads a submodel at its choice to the servers. Then all\nclients aggregate all their submodels and finish the iteration. Inevitably, FSL\nintroduces two privacy-preserving computation tasks, i.e., Private Submodel\nRetrieval (PSR) and Secure Submodel Aggregation (SSA). Existing work fails to\nprovide a loss-less scheme, or has impractical efficiency. In this work, we\nleverage Distributed Point Function (DPF) and cuckoo hashing to construct a\npractical and light-weight secure FSL scheme in the two-server setting. More\nspecifically, we propose two basic protocols with few optimisation techniques,\nwhich ensures our protocol practicality on specific real-world FSL tasks. Our\nexperiments show that our proposed protocols can finish in less than 1 minute\nwhen weight sizes $\\leq 2^{15}$, we also demonstrate protocol efficiency by\ncomparing with existing work and by handling a real-world FSL task.",
    "descriptor": "",
    "authors": [
      "Jamie Cui",
      "Cen Chen",
      "Tiandi Ye",
      "Li Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.01432"
  },
  {
    "id": "arXiv:2111.01439",
    "title": "The Secrecy Gain of Formally Unimodular Lattices on the Gaussian Wiretap  Channel",
    "abstract": "We consider lattice coding for the Gaussian wiretap channel, where the\nchallenge is to ensure reliable communication between two authorized parties\nwhile preventing an eavesdropper from learning the transmitted messages.\nRecently, a measure called the secrecy function of a lattice coding scheme was\nproposed as a design criterion to characterize the eavesdropper's probability\nof correct decision. In this paper, the family of formally unimodular lattices\nis presented and shown to possess the same secrecy function behavior as\nunimodular and isodual lattices. Based on Construction A, we provide a\nuniversal approach to determine the secrecy gain, i.e., the maximum value of\nthe secrecy function, for formally unimodular lattices obtained from formally\nself-dual codes. Furthermore, we show that formally unimodular lattices can\nachieve higher secrecy gain than the best-known unimodular lattices from the\nliterature.",
    "descriptor": "",
    "authors": [
      "Maiara F. Bollauf",
      "Hsuan-Yin Lin",
      "\u00d8yvind Ytrehus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.01439"
  },
  {
    "id": "arXiv:2111.01440",
    "title": "HHP-Net: A light Heteroscedastic neural network for Head Pose estimation  with uncertainty",
    "abstract": "In this paper we introduce a novel method to estimate the head pose of people\nin single images starting from a small set of head keypoints. To this purpose,\nwe propose a regression model that exploits keypoints computed automatically by\n2D pose estimation algorithms and outputs the head pose represented by yaw,\npitch, and roll. Our model is simple to implement and more efficient with\nrespect to the state of the art -- faster in inference and smaller in terms of\nmemory occupancy -- with comparable accuracy. Our method also provides a\nmeasure of the heteroscedastic uncertainties associated with the three angles,\nthrough an appropriately designed loss function; we show there is a correlation\nbetween error and uncertainty values, thus this extra source of information may\nbe used in subsequent computational steps. As an example application, we\naddress social interaction analysis in images: we propose an algorithm for a\nquantitative estimation of the level of interaction between people, starting\nfrom their head poses and reasoning on their mutual positions. The code is\navailable at https://github.com/cantarinigiorgio/HHP-Net.",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Giorgio Cantarini",
      "Federico Figari Tomenotti",
      "Nicoletta Noceti",
      "Francesca Odone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01440"
  },
  {
    "id": "arXiv:2111.01454",
    "title": "Conservative Time Discretization: A Comparative Study",
    "abstract": "We present the first review of methods to overapproximate the set of\nreachable states of linear time-invariant systems subject to uncertain initial\nstates and input signals for short time horizons. These methods are fundamental\nto state-of-the-art reachability algorithms for long time horizons, which\nproceed in two steps: they first use such a method to discretize the system for\na short time horizon, and then they efficiently obtain a solution of the new\ndiscrete system for the long time horizon. Traditionally, both qualitative and\nquantitative comparison between different reachability algorithms has only\nconsidered the combination of both steps. In this paper we study the first step\nin isolation. We perform a variety of numerical experiments for six fundamental\ndiscretization methods from the literature. As we show, these methods have\ndifferent trade-offs regarding accuracy and computational cost and, depending\non the characteristics of the system, some methods may be preferred over\nothers. We also discuss preprocessing steps to improve the results and\nefficient implementation strategies.",
    "descriptor": "",
    "authors": [
      "Marcelo Forets",
      "Christian Schilling"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.01454"
  },
  {
    "id": "arXiv:2111.01455",
    "title": "Learning a perceptual manifold with deep features for animation video  resequencing",
    "abstract": "We propose a novel deep learning framework for animation video resequencing.\nOur system produces new video sequences by minimizing a perceptual distance of\nimages from an existing animation video clip. To measure perceptual distance,\nwe utilize the activations of convolutional neural networks and learn a\nperceptual distance by training these features on a small network with data\ncomprised of human perceptual judgments. We show that with this perceptual\nmetric and graph-based manifold learning techniques, our framework can produce\nnew smooth and visually appealing animation video results for a variety of\nanimation video styles. In contrast to previous work on animation video\nresequencing, the proposed framework applies to wide range of image styles and\ndoes not require hand-crafted feature extraction, background subtraction, or\nfeature correspondence. In addition, we also show that our framework has\napplications to appealing arrange unordered collections of images.",
    "descriptor": "\nComments: Under major revision; Project website: this http URL\n",
    "authors": [
      "Charles C.Morace",
      "Thi-Ngoc-Hanh Le",
      "Sheng-Yi Yao",
      "Shang-Wei Zhang",
      "Tong-Yee Lee"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.01455"
  },
  {
    "id": "arXiv:2111.01456",
    "title": "WaveSense: Efficient Temporal Convolutions with Spiking Neural Networks  for Keyword Spotting",
    "abstract": "Ultra-low power local signal processing is a crucial aspect for edge\napplications on always-on devices. Neuromorphic processors emulating spiking\nneural networks show great computational power while fulfilling the limited\npower budget as needed in this domain. In this work we propose spiking neural\ndynamics as a natural alternative to dilated temporal convolutions. We extend\nthis idea to WaveSense, a spiking neural network inspired by the WaveNet\narchitecture. WaveSense uses simple neural dynamics, fixed time-constants and a\nsimple feed-forward architecture and hence is particularly well suited for a\nneuromorphic implementation. We test the capabilities of this model on several\ndatasets for keyword-spotting. The results show that the proposed network beats\nthe state of the art of other spiking neural networks and reaches near\nstate-of-the-art performance of artificial neural networks such as CNNs and\nLSTMs.",
    "descriptor": "",
    "authors": [
      "Philipp Weidel",
      "Sadique Sheik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.01456"
  },
  {
    "id": "arXiv:2111.01457",
    "title": "Synthesizing Speech from Intracranial Depth Electrodes using an  Encoder-Decoder Framework",
    "abstract": "Speech Neuroprostheses have the potential to enable communication for people\nwith dysarthria or anarthria. Recent advances have demonstrated high-quality\ntext decoding and speech synthesis from electrocorticographic grids placed on\nthe cortical surface. Here, we investigate a less invasive measurement\nmodality, namely stereotactic EEG (sEEG) that provides sparse sampling from\nmultiple brain regions, including subcortical regions. To evaluate whether sEEG\ncan also be used to synthesize high-quality audio from neural recordings, we\nemploy a recurrent encoder-decoder framework based on modern deep learning\nmethods. We demonstrate that high-quality speech can be reconstructed from\nthese minimally invasive recordings, despite a limited amount of training data.\nFinally, we utilize variational feature dropout to successfully identify the\nmost informative electrode contacts.",
    "descriptor": "",
    "authors": [
      "Jonas Kohler",
      "Maarten C. Ottenhoff",
      "Sophocles Goulis",
      "Miguel Angrick",
      "Albert J. Colon",
      "Louis Wagner",
      "Simon Tousseyn",
      "Pieter L. Kubben",
      "Christian Herff"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01457"
  },
  {
    "id": "arXiv:2111.01460",
    "title": "Geometry-aware Bayesian Optimization in Robotics using Riemannian  Mat\u00e9rn Kernels",
    "abstract": "Bayesian optimization is a data-efficient technique which can be used for\ncontrol parameter tuning, parametric policy adaptation, and structure design in\nrobotics. Many of these problems require optimization of functions defined on\nnon-Euclidean domains like spheres, rotation groups, or spaces of\npositive-definite matrices. To do so, one must place a Gaussian process prior,\nor equivalently define a kernel, on the space of interest. Effective kernels\ntypically reflect the geometry of the spaces they are defined on, but designing\nthem is generally non-trivial. Recent work on the Riemannian Mat\\'ern kernels,\nbased on stochastic partial differential equations and spectral theory of the\nLaplace-Beltrami operator, offers promising avenues towards constructing such\ngeometry-aware kernels. In this paper, we study techniques for implementing\nthese kernels on manifolds of interest in robotics, demonstrate their\nperformance on a set of artificial benchmark functions, and illustrate\ngeometry-aware Bayesian optimization for a variety of robotic applications,\ncovering orientation control, manipulability optimization, and motion planning,\nwhile showing its improved performance.",
    "descriptor": "\nComments: Published in the Conference on Robot Learning (CoRL) 2021. Source code: this https URL . Video: this https URL\n",
    "authors": [
      "No\u00e9mie Jaquier",
      "Viacheslav Borovitskiy",
      "Andrei Smolensky",
      "Alexander Terenin",
      "Tamim Asfour",
      "Leonel Rozo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01460"
  },
  {
    "id": "arXiv:2111.01465",
    "title": "System Combination for Grammatical Error Correction Based on Integer  Programming",
    "abstract": "In this paper, we propose a system combination method for grammatical error\ncorrection (GEC), based on nonlinear integer programming (IP). Our method\noptimizes a novel F score objective based on error types, and combines multiple\nend-to-end GEC systems. The proposed IP approach optimizes the selection of a\nsingle best system for each grammatical error type present in the data.\nExperiments of the IP approach on combining state-of-the-art standalone GEC\nsystems show that the combined system outperforms all standalone systems. It\nimproves F0.5 score by 3.61% when combining the two best participating systems\nin the BEA 2019 shared task, and achieves F0.5 score of 73.08%. We also perform\nexperiments to compare our IP approach with another state-of-the-art system\ncombination method for GEC, demonstrating IP's competitive combination\ncapability.",
    "descriptor": "\nComments: Accepted for RANLP 2021\n",
    "authors": [
      "Ruixi Lin",
      "Hwee Tou Ng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.01465"
  },
  {
    "id": "arXiv:2111.01466",
    "title": "Trace maximization algorithm for the approximate tensor diagonalization",
    "abstract": "In this paper we develop a Jacobi-type algorithm for the (approximate)\ndiagonalization of tensors of order $d\\geq3$ via tensor trace maximization. For\na general tensor this is an alternating least squares algorithm and the\nrotation matrices are chosen in each mode one-by-one to maximize the tensor\ntrace. On the other hand, for symmetric tensors we discuss a\nstructure-preserving variant of this algorithm where in each iteration the same\nrotation is applied in all modes. We show that both versions of the algorithm\nconverge to the stationary points of the corresponding objective functions.",
    "descriptor": "\nComments: 19 pages, 6 figures\n",
    "authors": [
      "Erna Begovic",
      "Ana Boksic"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.01466"
  },
  {
    "id": "arXiv:2111.01470",
    "title": "Practical error bounds for properties in plane-wave electronic structure  calculations",
    "abstract": "We propose accurate computable error bounds for quantities of interest in\nelectronic structure calculations, in particular ground-state density matrices\nand energies, and interatomic forces. These bounds are based on an estimation\nof the error in terms of the residual of the solved equations, which is then\nefficiently approximated with computable terms. After providing coarse bounds\nbased on an analysis of the inverse Jacobian, we improve on these bounds by\nsolving a linear problem in a small dimension that involves a Schur complement.\nWe numerically show how accurate these bounds are on a few representative\nmaterials, namely silicon, gallium arsenide and titanium dioxide.",
    "descriptor": "",
    "authors": [
      "Eric Canc\u00e8s",
      "Genevi\u00e8ve Dusson",
      "Gaspard Kemlin",
      "Antoine Levitt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2111.01470"
  },
  {
    "id": "arXiv:2111.01471",
    "title": "Zero-Shot Translation using Diffusion Models",
    "abstract": "In this work, we show a novel method for neural machine translation (NMT),\nusing a denoising diffusion probabilistic model (DDPM), adjusted for textual\ndata, following recent advances in the field. We show that it's possible to\ntranslate sentences non-autoregressively using a diffusion model conditioned on\nthe source sentence. We also show that our model is able to translate between\npairs of languages unseen during training (zero-shot learning).",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Eliya Nachmani",
      "Shaked Dovrat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01471"
  },
  {
    "id": "arXiv:2111.01472",
    "title": "Some Questions of Uniformity in Algorithmic Randomness",
    "abstract": "The $\\Omega$ numbers-the halting probabilities of universal prefix-free\nmachines-are known to be exactly the Martin-L{\\\"o}f random left-c.e. reals. We\nshow that one cannot uniformly produce, from a Martin-L{\\\"o}f random left-c.e.\nreal $\\alpha$, a universal prefix-free machine U whose halting probability is\n$\\alpha$. We also answer a question of Barmpalias and Lewis-Pye by showing that\ngiven a left-c.e. real $\\alpha$, one cannot uniformly produce a left-c.e. real\n$\\beta$ such that $\\alpha$ -- $\\beta$ is neither left-c.e. nor right-c.e.",
    "descriptor": "",
    "authors": [
      "Laurent Bienvenu",
      "Barbara Csima",
      "Matthew Harrison-Trainor"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.01472"
  },
  {
    "id": "arXiv:2111.01479",
    "title": "Dealing With Misspecification In Fixed-Confidence Linear Top-m  Identification",
    "abstract": "We study the problem of the identification of m arms with largest means under\na fixed error rate $\\delta$ (fixed-confidence Top-m identification), for\nmisspecified linear bandit models. This problem is motivated by practical\napplications, especially in medicine and recommendation systems, where linear\nmodels are popular due to their simplicity and the existence of efficient\nalgorithms, but in which data inevitably deviates from linearity. In this work,\nwe first derive a tractable lower bound on the sample complexity of any\n$\\delta$-correct algorithm for the general Top-m identification problem. We\nshow that knowing the scale of the deviation from linearity is necessary to\nexploit the structure of the problem. We then describe the first algorithm for\nthis setting, which is both practical and adapts to the amount of\nmisspecification. We derive an upper bound to its sample complexity which\nconfirms this adaptivity and that matches the lower bound when $\\delta$\n$\\rightarrow$ 0. Finally, we evaluate our algorithm on both synthetic and\nreal-world data, showing competitive performance with respect to existing\nbaselines.",
    "descriptor": "\nComments: Virtual conference\n",
    "authors": [
      "Cl\u00e9mence R\u00e9da",
      "Andrea Tirinzoni",
      "R\u00e9my Degenne"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.01479"
  },
  {
    "id": "arXiv:2111.01480",
    "title": "Variational message passing (VMP) applied to LDA",
    "abstract": "Variational Bayes (VB) applied to latent Dirichlet allocation (LDA) is the\noriginal inference mechanism for LDA. Many variants of VB for LDA, as well as\nfor VB in general, have been developed since LDA's inception in 2013, but\nstandard VB is still widely applied to LDA. Variational message passing (VMP)\nis the message passing equivalent of VB and is a useful tool for constructing a\nvariational inference solution for a large variety of conjugate exponential\ngraphical models (there is also a non conjugate variant available for other\nmodels). In this article we present the VMP equations for LDA and also provide\na brief discussion of the equations. We hope that this will assist others when\nderiving variational inference solutions to other similar graphical models.",
    "descriptor": "\nComments: 14 pages, 5 Figures, 25 references. Not yet submitted anywhere\n",
    "authors": [
      "Rebecca M.C. Taylor",
      "Johan A. du Preez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01480"
  },
  {
    "id": "arXiv:2111.01482",
    "title": "DAGSurv: Directed Acyclic Graph Based Survival Analysis Using Deep  Neural Networks",
    "abstract": "Causal structures for observational survival data provide crucial information\nregarding the relationships between covariates and time-to-event. We derive\nmotivation from the information theoretic source coding argument, and show that\nincorporating the knowledge of the directed acyclic graph (DAG) can be\nbeneficial if suitable source encoders are employed. As a possible source\nencoder in this context, we derive a variational inference based conditional\nvariational autoencoder for causal structured survival prediction, which we\nrefer to as DAGSurv. We illustrate the performance of DAGSurv on low and\nhigh-dimensional synthetic datasets, and real-world datasets such as METABRIC\nand GBSG. We demonstrate that the proposed method outperforms other survival\nanalysis baselines such as Cox Proportional Hazards, DeepSurv and Deephit,\nwhich are oblivious to the underlying causal relationship between data\nentities.",
    "descriptor": "\nComments: 16 pages, Accepted at ACML 2021\n",
    "authors": [
      "Ansh Kumar Sharma",
      "Rahul Kukreja",
      "Ranjitha Prasad",
      "Shilpa Rao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01482"
  },
  {
    "id": "arXiv:2111.01484",
    "title": "ArchABM: an agent-based simulator of human interaction with the built  environment. $CO_2$ and viral load analysis for indoor air quality",
    "abstract": "Recent evidence suggests that SARS-CoV-2, which is the virus causing a global\npandemic in 2020, is predominantly transmitted via airborne aerosols in indoor\nenvironments. This calls for novel strategies when assessing and controlling a\nbuilding's indoor air quality (IAQ). IAQ can generally be controlled by\nventilation and/or policies to regulate human-building-interaction. However, in\na building, occupants use rooms in different ways, and it may not be obvious\nwhich measure or combination of measures leads to a cost- and energy-effective\nsolution ensuring good IAQ across the entire building. Therefore, in this\narticle, we introduce a novel agent-based simulator, ArchABM, designed to\nassist in creating new or adapt existing buildings by estimating adequate room\nsizes, ventilation parameters and testing the effect of policies while taking\ninto account IAQ as a result of complex human-building interaction patterns. A\nrecently published aerosol model was adapted to calculate time-dependent carbon\ndioxide ($CO_2$) and virus quanta concentrations in each room and inhaled\n$CO_2$ and virus quanta for each occupant over a day as a measure of\nphysiological response. ArchABM is flexible regarding the aerosol model and the\nbuilding layout due to its modular architecture, which allows implementing\nfurther models, any number and size of rooms, agents, and actions reflecting\nhuman-building interaction patterns. We present a use case based on a real\nfloor plan and working schedules adopted in our research center. This study\ndemonstrates how advanced simulation tools can contribute to improving IAQ\nacross a building, thereby ensuring a healthy indoor environment.",
    "descriptor": "\nComments: 28 pages, 15 figures, 5 tables. Accepted on Building and Environment Journal, Special Issue on Human interaction with the built environment\n",
    "authors": [
      "I\u00f1igo Martinez",
      "Jan L. Bruse",
      "Ane M. Florez-Tapia",
      "Elisabeth Viles",
      "Igor G. Olaizola"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.01484"
  },
  {
    "id": "arXiv:2111.01485",
    "title": "A strong call-by-need calculus",
    "abstract": "We present a call-by-need $\\lambda$-calculus that enables strong reduction\n(that is, reduction inside the body of abstractions) and guarantees that\narguments are only evaluated if needed and at most once. This calculus uses\nexplicit substitutions and subsumes the existing strong-call-by-need strategy,\nbut allows for more reduction sequences, and often shorter ones, while\npreserving the neededness. The calculus is shown to be normalizing in a strong\nsense: Whenever a $\\lambda$-term t admits a normal form n in the\n$\\lambda$-calculus, then any reduction sequence from t in the calculus\neventually reaches a representative of the normal form n. We also exhibit a\nrestriction of this calculus that has the diamond property and that only\nperforms reduction sequences of minimal length, which makes it systematically\nbetter than the existing strategy. We have used the Abella proof assistant to\nformalize part of this calculus, and discuss how this experiment affected its\ndesign. In particular, it led us to derive a new description of call-by-need\nreduction based on inductive rules.",
    "descriptor": "",
    "authors": [
      "Thibaut Balabonski",
      "Antoine Lanco",
      "Guillaume Melquiond"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.01485"
  },
  {
    "id": "arXiv:2111.01495",
    "title": "Constructing Neural Network-Based Models for Simulating Dynamical  Systems",
    "abstract": "Dynamical systems see widespread use in natural sciences like physics,\nbiology, chemistry, as well as engineering disciplines such as circuit\nanalysis, computational fluid dynamics, and control. For simple systems, the\ndifferential equations governing the dynamics can be derived by applying\nfundamental physical laws. However, for more complex systems, this approach\nbecomes exceedingly difficult. Data-driven modeling is an alternative paradigm\nthat seeks to learn an approximation of the dynamics of a system using\nobservations of the true system. In recent years, there has been an increased\ninterest in data-driven modeling techniques, in particular neural networks have\nproven to provide an effective framework for solving a wide range of tasks.\nThis paper provides a survey of the different ways to construct models of\ndynamical systems using neural networks. In addition to the basic overview, we\nreview the related literature and outline the most significant challenges from\nnumerical simulations that this modeling paradigm must overcome. Based on the\nreviewed literature and identified challenges, we provide a discussion on\npromising research areas.",
    "descriptor": "",
    "authors": [
      "Christian M\u00f8ldrup Legaard",
      "Thomas Schranz",
      "Gerald Schweiger",
      "J\u00e1n Drgo\u0148a",
      "Basak Falay",
      "Cl\u00e1udio Gomes",
      "Alexandros Iosifidis",
      "Mahdi Abkar",
      "Peter Gorm Larsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01495"
  },
  {
    "id": "arXiv:2111.01496",
    "title": "Quality change: norm or exception? Measurement, Analysis and Detection  of Quality Change in Wikipedia",
    "abstract": "Wikipedia has been turned into an immensely popular crowd-sourced\nencyclopedia for information dissemination on numerous versatile topics in the\nform of subscription free content. It allows anyone to contribute so that the\narticles remain comprehensive and updated. For enrichment of content without\ncompromising standards, the Wikipedia community enumerates a detailed set of\nguidelines, which should be followed. Based on these, articles are categorized\ninto several quality classes by the Wikipedia editors with increasing adherence\nto guidelines. This quality assessment task by editors is laborious as well as\ndemands platform expertise. As a first objective, in this paper, we study\nevolution of a Wikipedia article with respect to such quality scales. Our\nresults show novel non-intuitive patterns emerging from this exploration. As a\nsecond objective we attempt to develop an automated data driven approach for\nthe detection of the early signals influencing the quality change of articles.\nWe posit this as a change point detection problem whereby we represent an\narticle as a time series of consecutive revisions and encode every revision by\na set of intuitive features. Finally, various change point detection algorithms\nare used to efficiently and accurately detect the future change points. We also\nperform various ablation studies to understand which group of features are most\neffective in identifying the change points. To the best of our knowledge, this\nis the first work that rigorously explores English Wikipedia article quality\nlife cycle from the perspective of quality indicators and provides a novel\nunsupervised page level approach to detect quality switch, which can help in\nautomatic content monitoring in Wikipedia thus contributing significantly to\nthe CSCW community.",
    "descriptor": "",
    "authors": [
      "Paramita Das",
      "Bhanu Prakash Reddy Guda",
      "Sasi Bhusan Seelaboyina",
      "Soumya Sarkar",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.01496"
  },
  {
    "id": "arXiv:2111.01501",
    "title": "Constructing a software requirements specification and design for  electronic IT news magazine system",
    "abstract": "Requirements engineering process intends to obtain software services and\nconstraints. This process is essential to meet the customer's needs and\nexpectations. This process includes three main activities in general. These are\ndetecting requirements by interacting with software stakeholders, transferring\nthese requirements into a standard document, and examining that the\nrequirements really define the software that the client needs. Functional\nrequirements are services that the software should deliver to the end-user. In\naddition, functional requirements describe how the software should respond to\nspecific inputs, and how the software should behave in certain circumstances.\nThis paper aims to develop a software requirements specification document of\nthe electronic IT news magazine system. The electronic magazine provides users\nto post and view up-to-date IT news. Still, there is a lack in the literature\nof comprehensive studies about the construction of the electronic magazine\nsoftware specification and design in conformance with the contemporary software\ndevelopment processes. Moreover, there is a need for a suitable research\nframework to support the requirements engineering process. The novelty of this\npaper is the construction of software specification and design of the\nelectronic magazine by following the Al-Msie'deen research framework. All the\ndocuments of software requirements specification and design have been\nconstructed to conform to the agile usage-centered design technique and the\nproposed research framework. A requirements specification and design are\nsuggested and followed for the construction of the electronic magazine\nsoftware. This study proved that involving users extensively in the process of\nsoftware requirements specification and design will lead to the creation of\ndependable and acceptable software systems.",
    "descriptor": "\nComments: 15 pages, 9 figures, 4 tables\n",
    "authors": [
      "Ra'Fat Al-Msie'deen",
      "Anas H. Blasi",
      "Mohammed A. Alsuwaiket"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.01501"
  },
  {
    "id": "arXiv:2111.01504",
    "title": "Towards Enabling I/O Awareness in Task-based Programming Models",
    "abstract": "Storage systems have not kept the same technology improvement rate as\ncomputing systems. As applications produce more and more data, I/O becomes the\nlimiting factor for increasing application performance. I/O congestion caused\nby concurrent access to storage devices is one of the main obstacles that cause\nI/O performance degradation and, consequently, total performance degradation.\nAlthough task-based programming models made it possible to achieve higher\nlevels of parallelism by enabling the execution of tasks in large-scale\ndistributed platforms, this parallelism only benefited the compute workload of\nthe application. Previous efforts addressing I/O performance bottlenecks either\nfocused on optimizing fine-grained I/O access patterns using I/O libraries or\navoiding system-wide I/O congestion by minimizing interference between multiple\napplications.\nIn this paper, we propose enabling I/O Awareness in task-based programming\nmodels for improving the total performance of applications. An I/O aware\nprogramming model is able to create more parallelism and mitigate the causes of\nI/O performance degradation. On the one hand, more parallelism can be created\nby supporting special tasks for executing I/O workloads, called I/O tasks, that\ncan overlap with the execution of compute tasks. On the other hand, I/O\ncongestion can be mitigated by constraining I/O tasks scheduling. We propose\ntwo approaches for specifying such constraints: explicitly set by the users or\nautomatically inferred and tuned during application's execution to optimize the\nexecution of variable I/O workloads on a certain storage infrastructure.\nOur experiments on the MareNostrum 4 Supercomputer demonstrate that using I/O\naware programming model can achieve up to 43% total performance improvement as\ncompared to the I/O non-aware implementation.",
    "descriptor": "",
    "authors": [
      "Hatem Elshazly",
      "Jorge Ejarque",
      "Francesc Lordan",
      "Rosa M. Badia"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.01504"
  },
  {
    "id": "arXiv:2111.01510",
    "title": "A Hybrid Approach for Learning to Shift and Grasp with Elaborate Motion  Primitives",
    "abstract": "Many possible fields of application of robots in real world settings hinge on\nthe ability of robots to grasp objects. As a result, robot grasping has been an\nactive field of research for many years. With our publication we contribute to\nthe endeavor of enabling robots to grasp, with a particular focus on bin\npicking applications. Bin picking is especially challenging due to the often\ncluttered and unstructured arrangement of objects and the often limited\ngraspability of objects by simple top down grasps. To tackle these challenges,\nwe propose a fully self-supervised reinforcement learning approach based on a\nhybrid discrete-continuous adaptation of soft actor-critic (SAC). We employ\nparametrized motion primitives for pushing and grasping movements in order to\nenable a flexibly adaptable behavior to the difficult setups we consider.\nFurthermore, we use data augmentation to increase sample efficiency. We\ndemonnstrate our proposed method on challenging picking scenarios in which\nplanar grasp learning or action discretization methods would face a lot of\ndifficulties",
    "descriptor": "",
    "authors": [
      "Zohar Feldman",
      "Hanna Ziesche",
      "Ngo Anh Vien",
      "Dotan Di Castro"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01510"
  },
  {
    "id": "arXiv:2111.01515",
    "title": "Detection of Hate Speech using BERT and Hate Speech Word Embedding with  Deep Model",
    "abstract": "The enormous amount of data being generated on the web and social media has\nincreased the demand for detecting online hate speech. Detecting hate speech\nwill reduce their negative impact and influence on others. A lot of effort in\nthe Natural Language Processing (NLP) domain aimed to detect hate speech in\ngeneral or detect specific hate speech such as religion, race, gender, or\nsexual orientation. Hate communities tend to use abbreviations, intentional\nspelling mistakes, and coded words in their communication to evade detection,\nadding more challenges to hate speech detection tasks. Thus, word\nrepresentation will play an increasingly pivotal role in detecting hate speech.\nThis paper investigates the feasibility of leveraging domain-specific word\nembedding in Bidirectional LSTM based deep model to automatically\ndetect/classify hate speech. Furthermore, we investigate the use of the\ntransfer learning language model (BERT) on hate speech problem as a binary\nclassification task. The experiments showed that domainspecific word embedding\nwith the Bidirectional LSTM based deep model achieved a 93% f1-score while BERT\nachieved up to 96% f1-score on a combined balanced dataset from available hate\nspeech datasets.",
    "descriptor": "",
    "authors": [
      "Hind Saleh",
      "Areej Alhothali",
      "Kawthar Moria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.01515"
  },
  {
    "id": "arXiv:2111.01516",
    "title": "FedFly: Towards Migration in Edge-based Distributed Federated Learning",
    "abstract": "Federated learning (FL) is a privacy-preserving distributed machine learning\ntechnique that trains models without having direct access to the original data\ngenerated on devices. Since devices may be resource constrained, offloading can\nbe used to improve FL performance by transferring computational workload from\ndevices to edge servers. However, due to mobility, devices participating in FL\nmay leave the network during training and need to connect to a different edge\nserver. This is challenging because the offloaded computations from edge server\nneed to be migrated. In line with this assertion, we present FedFly, which is,\nto the best of our knowledge, the first work to migrate a deep neural network\n(DNN) when devices move between edge servers during FL training. Our empirical\nresults on the CIFAR-10 dataset, with both balanced and imbalanced data\ndistribution support our claims that FedFly can reduce training time by up to\n33% when a device moves after 50% of the training is completed, and by up to\n45% when 90% of the training is completed when compared to state-of-the-art\noffloading approach in FL. FedFly has negligible overhead of 2 seconds and does\nnot compromise accuracy. Finally, we highlight a number of open research issues\nfor further investigation. FedFly can be downloaded from\nhttps://github.com/qub-blesson/FedFly",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Rehmat Ullah",
      "Di Wu",
      "Paul Harvey",
      "Peter Kilpatrick",
      "Ivor Spence",
      "Blesson Varghese"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01516"
  },
  {
    "id": "arXiv:2111.01526",
    "title": "A modified gravity model based on network efficiency for vital nodes  identification in complex networks",
    "abstract": "Vital nodes identification is an essential problem in network science.\nVarious methods have been proposed to solve this problem. In particular, based\non the gravity model, a series of improved gravity models are proposed to find\nvital nodes better in complex networks. However, they still have the room to be\nimproved. In this paper, a novel and improved gravity model, which is named\nnetwork efficiency gravity centrality model (NEG), integrates gravity model and\nnetwork efficiency is proposed. Compared to other methods based on different\ngravity models, the proposed method considers the effect of the nodes on\nstructure robustness of the network better. To solidate the superiority of the\nproposed method, experiments on varieties of real-world networks are carried\nout.",
    "descriptor": "\nComments: Submitted to Applied Intelligence\n",
    "authors": [
      "Hanwen Li",
      "Qiuyan Shang",
      "Yong Deng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01526"
  },
  {
    "id": "arXiv:2111.01527",
    "title": "Household Cloth Object Set: Fostering Benchmarking in Deformable Object  Manipulation",
    "abstract": "Benchmarking of robotic manipulations is one of the open issues in robotic\nresearch. An important factor that has enabled progress in this area in the\nlast decade is the existence of common object sets that have been shared among\ndifferent research groups. However, the existing object sets are very limited\nwhen it comes to cloth-like objects that have unique particularities and\nchallenges. This paper is a first step towards the design of a cloth object set\nto be distributed among research groups from the robotics cloth manipulation\ncommunity. We present a set of household cloth objects and related tasks that\nserve to expose the challenges related to gathering such an object set and\npropose a roadmap to the design of common benchmarks in cloth manipulation\ntasks, with the intention to set the grounds for a future debate in the\ncommunity that will be necessary to foster benchmarking for the manipulation of\ncloth-like objects. Some RGB-D and object scans are also collected as examples\nfor the objects in relevant configurations. More details about the cloth set\nare shared in\nthis http URL",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Irene Garcia-Camacho",
      "J\u00falia Borr\u00e0s",
      "Berk Calli",
      "Adam Norton",
      "Guillem Aleny\u00e0"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.01527"
  },
  {
    "id": "arXiv:2111.01528",
    "title": "HydraText: Multi-objective Optimization for Adversarial Textual Attack",
    "abstract": "The field of adversarial textual attack has significantly grown over the last\nyears, where the commonly considered objective is to craft adversarial examples\nthat can successfully fool the target models. However, the imperceptibility of\nattacks, which is also an essential objective, is often left out by previous\nstudies. In this work, we advocate considering both objectives at the same\ntime, and propose a novel multi-optimization approach (dubbed HydraText) with\nprovable performance guarantee to achieve successful attacks with high\nimperceptibility. We demonstrate the efficacy of HydraText through extensive\nexperiments under both score-based and decision-based settings, involving five\nmodern NLP models across five benchmark datasets. In comparison to existing\nstate-of-the-art attacks, HydraText consistently achieves simultaneously higher\nsuccess rates, lower modification rates, and higher semantic similarity to the\noriginal texts. A human evaluation study shows that the adversarial examples\ncrafted by HydraText maintain validity and naturality well. Finally, these\nexamples also exhibit good transferability and can bring notable robustness\nimprovement to the target models by adversarial training.",
    "descriptor": "",
    "authors": [
      "Shengcai Liu",
      "Ning Lu",
      "Cheng Chen",
      "Chao Qian",
      "Ke Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.01528"
  },
  {
    "id": "arXiv:2111.01531",
    "title": "Generating synthetic transactional profiles",
    "abstract": "Financial institutions use clients' payment transactions in numerous banking\napplications. Transactions are very personal and rich in behavioural patterns,\noften unique to individuals, which make them equivalent to personally\nidentifiable information in some cases. In this paper, we generate synthetic\ntransactional profiles using machine learning techniques with the goal to\npreserve both data utility and privacy. A challenge we faced was to deal with\nsparse vectors due to the few spending categories a client uses compared to all\nthe ones available. We measured data utility by calculating common insights\nused by the banking industry on both the original and the synthetic data-set.\nOur approach shows that neural network models can generate valuable synthetic\ndata in such context. Finally, we tried privacy-preserving techniques and\nobserved its effect on models' performances.",
    "descriptor": "",
    "authors": [
      "Hadrien Lautraite",
      "Patrick Mesana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01531"
  },
  {
    "id": "arXiv:2111.01537",
    "title": "Physical Channel Modeling for RIS-Empowered Wireless Networks in Sub-6  GHz Bands",
    "abstract": "Reconfigurable intelligent surface (RIS)-assisted communications is one of\nthe promising candidates for next generation wireless networks by controlling\nthe propagation environment dynamically. In this study, a channel modeling\nstrategy for RIS-assisted wireless networks is introduced in sub-6 GHz bands by\nconsidering both far-field and near-field behaviours in transmission. We also\nproposed an open-source physical channel simulator for sub-6 GHz bands where\noperating frequency, propagation environment, terminal locations, RIS location\nand size can be adjusted. It is demonstrated via extensive computer simulations\nthat an improved achievable rate performance is obtained in the presence of\nRISs for both near-field and far-field conditions.",
    "descriptor": "",
    "authors": [
      "Fatih Kilinc",
      "Ibrahim Yildirim",
      "Ertugrul Basar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.01537"
  },
  {
    "id": "arXiv:2111.01540",
    "title": "MillenniumDB: A Persistent, Open-Source, Graph Database",
    "abstract": "In this systems paper, we present MillenniumDB: a novel graph database engine\nthat is modular, persistent, and open source. MillenniumDB is based on a graph\ndata model, which we call domain graphs, that provides a simple abstraction\nupon which a variety of popular graph models can be supported. The engine\nitself is founded on a combination of tried and tested techniques from\nrelational data management, state-of-the-art algorithms for worst-case-optimal\njoins, as well as graph-specific algorithms for evaluating path queries. In\nthis paper, we present the main design principles underlying MillenniumDB,\ndescribing the abstract graph model and query semantics supported, the concrete\ndata model and query syntax implemented, as well as the storage, indexing,\nquery planning and query evaluation techniques used. We evaluate MillenniumDB\nover real-world data and queries from the Wikidata knowledge graph, where we\nfind that it outperforms other popular persistent graph database engines\n(including both enterprise and open source alternatives) that support similar\nquery features.",
    "descriptor": "",
    "authors": [
      "Domagoj Vrgoc",
      "Carlos Rojas",
      "Renzo Angles",
      "Marcelo Arenas",
      "Diego Arroyuelo",
      "Carlos Buil Aranda",
      "Aidan Hogan",
      "Gonzalo Navarro",
      "Cristian Riveros",
      "Juan Romero"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.01540"
  },
  {
    "id": "arXiv:2111.01543",
    "title": "UQuAD1.0: Development of an Urdu Question Answering Training Data for  Machine Reading Comprehension",
    "abstract": "In recent years, low-resource Machine Reading Comprehension (MRC) has made\nsignificant progress, with models getting remarkable performance on various\nlanguage datasets. However, none of these models have been customized for the\nUrdu language. This work explores the semi-automated creation of the Urdu\nQuestion Answering Dataset (UQuAD1.0) by combining machine-translated SQuAD\nwith human-generated samples derived from Wikipedia articles and Urdu RC\nworksheets from Cambridge O-level books. UQuAD1.0 is a large-scale Urdu dataset\nintended for extractive machine reading comprehension tasks consisting of 49k\nquestion Answers pairs in question, passage, and answer format. In UQuAD1.0,\n45000 pairs of QA were generated by machine translation of the original\nSQuAD1.0 and approximately 4000 pairs via crowdsourcing. In this study, we used\ntwo types of MRC models: rule-based baseline and advanced Transformer-based\nmodels. However, we have discovered that the latter outperforms the others;\nthus, we have decided to concentrate solely on Transformer-based architectures.\nUsing XLMRoBERTa and multi-lingual BERT, we acquire an F1 score of 0.66 and\n0.63, respectively.",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Samreen Kazi",
      "Shakeel Khoja"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01543"
  },
  {
    "id": "arXiv:2111.01549",
    "title": "Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by  Finding Flat Minima",
    "abstract": "This paper considers incremental few-shot learning, which requires a model to\ncontinually recognize new categories with only a few examples provided. Our\nstudy shows that existing methods severely suffer from catastrophic forgetting,\na well-known problem in incremental learning, which is aggravated due to data\nscarcity and imbalance in the few-shot setting. Our analysis further suggests\nthat to prevent catastrophic forgetting, actions need to be taken in the\nprimitive stage -- the training of base classes instead of later few-shot\nlearning sessions. Therefore, we propose to search for flat local minima of the\nbase training objective function and then fine-tune the model parameters within\nthe flat region on new tasks. In this way, the model can efficiently learn new\nclasses while preserving the old ones. Comprehensive experimental results\ndemonstrate that our approach outperforms all prior state-of-the-art methods\nand is very close to the approximate upper bound. The source code is available\nat https://github.com/moukamisama/F2M.",
    "descriptor": "",
    "authors": [
      "Guangyuan Shi",
      "Jiaxin Chen",
      "Wenlong Zhang",
      "Li-Ming Zhan",
      "Xiao-Ming Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01549"
  },
  {
    "id": "arXiv:2111.01550",
    "title": "A Comprehensive Survey on Nanophotonics Neural Networks",
    "abstract": "In the last years, materializations of neuromorphic circuits based on\nnanophotonic arrangements have been proposed, which contain complete optical\ncircuits, laser, photodetectors, photonic crystals, optical fibers, flat\nwaveguides, and other passive optical elements of nanostructured materials,\nwhich eliminate the time of simultaneous processing of big groups of data,\ntaking advantage of the quantum perspective and thus highly increasing the\npotentials of contemporary intelligent computational systems. This article is\nan effort to record and study the research that has been conducted concerning\nthe methods of development and materi-alization of neuromorphic circuits of\nNeural Networks of nanophotonic arrangements. In particular, an investigative\nstudy of the methods of developing nanophotonic neuromorphic processors, their\noriginality in neuronic architectural structure, their training methods and\ntheir optimization has been realized along with the study of special issues\nsuch as optical activation functions and cost functions.",
    "descriptor": "",
    "authors": [
      "Konstantinos Demertzis",
      "Georgios Papadopoulos",
      "Lazaros Iliadis",
      "Lykourgos Magafas"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2111.01550"
  },
  {
    "id": "arXiv:2111.01551",
    "title": "Classifying Approximation Algorithms: Understanding the APX Complexity  Class",
    "abstract": "We are interested in the intersection of approximation algorithms and\ncomplexity theory, in particular focusing on the complexity class APX.\nInformally, APX $\\subseteq$ NPO is the complexity class comprising optimization\nproblems where the ratio $\\frac{OPT(I)}{ALG(I)} \\leq c$ for all instances I. We\nwill do a deep dive into studying APX as a complexity class, in particular,\ninvestigating how researchers have defined PTAS and L reductions, as well as\nthe notion of APX-completeness, thereby clarifying where APX lies on the\npolynomial hierarchy. We will discuss the relationship of this class with\nFPTAS, PTAS, APX, log-APX and poly-APX). We will sketch the proof that Max\n3-SAT is APX-hard, and compare this complexity class in relation to $BPP$,\n$ZPP$ to elucidate whether randomization is powerful enough to achieve certain\napproximation guarantees and introduce techniques that complement the design of\napproximation algorithms such as through \\textit{primal-dual} analysis,\n\\textit{local search} and \\textit{semi-definite programming}. Through the PCP\ntheorem, we will explore the fundamental relationship between hardness of\napproximation and randomness, and will recast the way we look at the complexity\nclass NP. We will finish by looking at the \\textit{\"real world\"} applications\nof this material in Economics. Finally, we will touch upon recent breakthroughs\nin the Metric Travelling Salesman and asymmetric travelling salesman problem,\nas well original directions for future research, such as quantifying the amount\nof additional compute power that access to an APX oracle provides, elucidating\nfundamental combinatorial properties of log-APX problems and unique ways to\nattack the problem of whether the minimum set-cover problem is self-improvable.",
    "descriptor": "",
    "authors": [
      "Arthur Lee",
      "Bruce Xu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.01551"
  },
  {
    "id": "arXiv:2111.01555",
    "title": "Likelihood-Free Inference in State-Space Models with Unknown Dynamics",
    "abstract": "We introduce a method for inferring and predicting latent states in the\nimportant and difficult case of state-space models where observations can only\nbe simulated, and transition dynamics are unknown. In this setting, the\nlikelihood of observations is not available and only synthetic observations can\nbe generated from a black-box simulator. We propose a way of doing\nlikelihood-free inference (LFI) of states and state prediction with a limited\nnumber of simulations. Our approach uses a multi-output Gaussian process for\nstate inference, and a Bayesian Neural Network as a model of the transition\ndynamics for state prediction. We improve upon existing LFI methods for the\ninference task, while also accurately learning transition dynamics. The\nproposed method is necessary for modelling inverse problems in dynamical\nsystems with computationally expensive simulations, as demonstrated in\nexperiments with non-stationary user models.",
    "descriptor": "\nComments: 20 pages, 8 figures, uses arxiv.sty\n",
    "authors": [
      "Alexander Aushev",
      "Thong Tran",
      "Henri Pesonen",
      "Andrew Howes",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01555"
  },
  {
    "id": "arXiv:2111.01564",
    "title": "MultiplexNet: Towards Fully Satisfied Logical Constraints in Neural  Networks",
    "abstract": "We propose a novel way to incorporate expert knowledge into the training of\ndeep neural networks. Many approaches encode domain constraints directly into\nthe network architecture, requiring non-trivial or domain-specific engineering.\nIn contrast, our approach, called MultiplexNet, represents domain knowledge as\na logical formula in disjunctive normal form (DNF) which is easy to encode and\nto elicit from human experts. It introduces a Categorical latent variable that\nlearns to choose which constraint term optimizes the error function of the\nnetwork and it compiles the constraints directly into the output of existing\nlearning algorithms. We demonstrate the efficacy of this approach empirically\non several classical deep learning tasks, such as density estimation and\nclassification in both supervised and unsupervised settings where prior\nknowledge about the domains was expressed as logical constraints. Our results\nshow that the MultiplexNet approach learned to approximate unknown\ndistributions well, often requiring fewer data samples than the alternative\napproaches. In some cases, MultiplexNet finds better solutions than the\nbaselines; or solutions that could not be achieved with the alternative\napproaches. Our contribution is in encoding domain knowledge in a way that\nfacilitates inference that is shown to be both efficient and general; and\ncritically, our approach guarantees 100% constraint satisfaction in a network's\noutput.",
    "descriptor": "\nComments: Submitted to AAAI2022\n",
    "authors": [
      "Nicholas Hoernle",
      "Rafael Michael Karampatsis",
      "Vaishak Belle",
      "Kobi Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2111.01564"
  },
  {
    "id": "arXiv:2111.01566",
    "title": "Strategyproof and Proportionally Fair Facility Location",
    "abstract": "We focus on a simple, one-dimensional collective decision problem (often\nreferred to as the facility location problem) and explore issues of\nstrategyproofness and proportional fairness. We present several\ncharacterization results for mechanisms that satisfy strategyproofness and\nvarying levels of proportional fairness. We also characterize one of the\nmechanisms as the unique equilibrium outcome for any mechanism that satisfies\nnatural fairness and monotonicity properties. Finally, we identify\nstrategyproof and proportionally fair mechanisms that provide the best\nwelfare-optimal approximation among all mechanisms that satisfy the\ncorresponding fairness axiom.",
    "descriptor": "",
    "authors": [
      "Haris Aziz",
      "Alexander Lam",
      "Barton E. Lee",
      "Toby Walsh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2111.01566"
  },
  {
    "id": "arXiv:2111.01570",
    "title": "Privacy-Preserving Communication-Efficient Federated Multi-Armed Bandits",
    "abstract": "Communication bottleneck and data privacy are two critical concerns in\nfederated multi-armed bandit (MAB) problems, such as situations in\ndecision-making and recommendations of connected vehicles via wireless. In this\npaper, we design the privacy-preserving communication-efficient algorithm in\nsuch problems and study the interactions among privacy, communication and\nlearning performance in terms of the regret. To be specific, we design\nprivacy-preserving learning algorithms and communication protocols and derive\nthe learning regret when networked private agents are performing online bandit\nlearning in a master-worker, a decentralized and a hybrid structure. Our bandit\nlearning algorithms are based on epoch-wise sub-optimal arm eliminations at\neach agent and agents exchange learning knowledge with the server/each other at\nthe end of each epoch. Furthermore, we adopt the differential privacy (DP)\napproach to protect the data privacy at each agent when exchanging information;\nand we curtail communication costs by making less frequent communications with\nfewer agents participation. By analyzing the regret of our proposed algorithmic\nframework in the master-worker, decentralized and hybrid structures, we\ntheoretically show tradeoffs between regret and communication costs/privacy.\nFinally, we empirically show these trade-offs which are consistent with our\ntheoretical analysis.",
    "descriptor": "",
    "authors": [
      "Tan Li",
      "Linqi Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.01570"
  },
  {
    "id": "arXiv:2111.01576",
    "title": "Provably efficient, succinct, and precise explanations",
    "abstract": "We consider the problem of explaining the predictions of an arbitrary\nblackbox model $f$: given query access to $f$ and an instance $x$, output a\nsmall set of $x$'s features that in conjunction essentially determines $f(x)$.\nWe design an efficient algorithm with provable guarantees on the succinctness\nand precision of the explanations that it returns. Prior algorithms were either\nefficient but lacked such guarantees, or achieved such guarantees but were\ninefficient.\nWe obtain our algorithm via a connection to the problem of {\\sl implicitly}\nlearning decision trees. The implicit nature of this learning task allows for\nefficient algorithms even when the complexity of $f$ necessitates an\nintractably large surrogate decision tree. We solve the implicit learning\nproblem by bringing together techniques from learning theory, local computation\nalgorithms, and complexity theory.\nOur approach of \"explaining by implicit learning\" shares elements of two\npreviously disparate methods for post-hoc explanations, global and local\nexplanations, and we make the case that it enjoys advantages of both.",
    "descriptor": "",
    "authors": [
      "Guy Blanc",
      "Jane Lange",
      "Li-Yang Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.01576"
  },
  {
    "id": "arXiv:2111.01577",
    "title": "Do Names Echo Semantics? A Large-Scale Study of Identifiers Used in  C++'s Named Casts",
    "abstract": "Developers relax restrictions on a type to reuse methods with other types.\nWhile type casts are prevalent, in weakly typed languages such as C++, they are\nalso extremely permissive. If type conversions are performed without care, they\ncan lead to software bugs. Therefore, there is a clear need to check whether a\ntype conversion is essential and used adequately according to the developer's\nintent. In this paper, we propose a technique to judge the fidelity of type\nconversions from an explicit cast operation, using the identifiers in an\nassignment. We measure accord in the identifiers using entropy and use it to\ncheck if the semantics of the source expression in the cast match the semantics\nof the variable it is being assigned. We present the results of running our\ntool on 34 components of the Chromium project, which collectively account for\n27MLOC. Our tool identified 1,368 cases of discord indicating potential\nanti-patterns in the usage of explicit casts. We performed a manual evaluation\nof a random-uniform sample of these cases. Our evaluation shows that our tool\nidentified 25.6% cases representing incorrect implementations of named casts\nand 28.04% cases representing imprecise names of identifiers.",
    "descriptor": "\nComments: The manuscript has 21 pages and it contains 22 Figures and a table. The preprint is submitted and currently under review at Journal of Systems and Software Elsevier\n",
    "authors": [
      "Constantin Cezar Petrescu",
      "Sam Smith",
      "Rafail Giavrimis",
      "Santanu Kumar Dash"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Theory (cs.IT)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.01577"
  },
  {
    "id": "arXiv:2111.01582",
    "title": "LMdiff: A Visual Diff Tool to Compare Language Models",
    "abstract": "While different language models are ubiquitous in NLP, it is hard to contrast\ntheir outputs and identify which contexts one can handle better than the other.\nTo address this question, we introduce LMdiff, a tool that visually compares\nprobability distributions of two models that differ, e.g., through finetuning,\ndistillation, or simply training with different parameter sizes. LMdiff allows\nthe generation of hypotheses about model behavior by investigating text\ninstances token by token and further assists in choosing these interesting text\ninstances by identifying the most interesting phrases from large corpora. We\nshowcase the applicability of LMdiff for hypothesis generation across multiple\ncase studies. A demo is available at this http URL .",
    "descriptor": "\nComments: EMNLP 2021 Demo Paper\n",
    "authors": [
      "Hendrik Strobelt",
      "Benjamin Hoover",
      "Arvind Satyanarayan",
      "Sebastian Gehrmann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.01582"
  },
  {
    "id": "arXiv:2111.01584",
    "title": "Fitness Landscape Footprint: A Framework to Compare Neural Architecture  Search Problems",
    "abstract": "Neural architecture search is a promising area of research dedicated to\nautomating the design of neural network models. This field is rapidly growing,\nwith a surge of methodologies ranging from Bayesian optimization,neuroevoltion,\nto differentiable search, and applications in various contexts. However,\ndespite all great advances, few studies have presented insights on the\ndifficulty of the problem itself, thus the success (or fail) of these\nmethodologies remains unexplained. In this sense, the field of optimization has\ndeveloped methods that highlight key aspects to describe optimization problems.\nThe fitness landscape analysis stands out when it comes to characterize\nreliably and quantitatively search algorithms. In this paper, we propose to use\nfitness landscape analysis to study a neural architecture search problem.\nParticularly, we introduce the fitness landscape footprint, an aggregation of\neight (8)general-purpose metrics to synthesize the landscape of an architecture\nsearch problem. We studied two problems, the classical image classification\nbenchmark CIFAR-10, and the Remote-Sensing problem So2Sat LCZ42. The results\npresent a quantitative appraisal of the problems, allowing to characterize the\nrelative difficulty and other characteristics, such as the ruggedness or the\npersistence, that helps to tailor a search strategy to the problem. Also, the\nfootprint is a tool that enables the comparison of multiple problems.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Kalifou Ren\u00e9 Traor\u00e9",
      "Andr\u00e9s Camero",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.01584"
  },
  {
    "id": "arXiv:2111.01585",
    "title": "Is RIS-Aided Massive MIMO Promising with ZF Detectors and Imperfect CSI?",
    "abstract": "This paper provides a theoretical framework for understanding the performance\nof reconfigurable intelligent surface (RIS)-aided massive multiple-input\nmultiple-output (MIMO) with zero-forcing (ZF) detectors under imperfect channel\nstate information (CSI). We first propose a low-overhead minimum mean square\nerror (MMSE) channel estimator, and then derive and analyze closed-form\nexpressions for the uplink achievable rate. Our analytical results demonstrate\nthat: $1)$ regardless of the RIS phase shift design, the rate of all users\nscales at least on the order of\n$\\mathcal{O}\\left(\\log_2\\left(MN\\right)\\right)$, where $M$ and $N$ are the\nnumbers of antennas and reflecting elements, respectively; $2)$ by aligning the\nRIS phase shifts to one user, the rate of this user can at most scale on the\norder of $\\mathcal{O}\\left(\\log_2\\left(MN^2\\right)\\right)$; $3)$ either $M$ or\nthe transmit power can be reduced inversely proportional to $N$, while\nmaintaining a given rate. Furthermore, we propose two low-complexity\nmajorization-minimization (MM)-based algorithms to optimize the sum user rate\nand the minimum user rate, respectively, where closed-form solutions are\nobtained in each iteration. Finally, simulation results validate all derived\nanalytical results. Our simulation results also show that the maximum sum rate\ncan be closely approached by simply aligning the RIS phase shifts to an\narbitrary user.",
    "descriptor": "\nComments: Submitted to IEEE journal. Keywords: Reconfigurable Intelligent Surface, Intelligent Reflecting Surface, Massive MIMO, Channel estimation, zero-forcing\n",
    "authors": [
      "Kangda Zhi",
      "Cunhua Pan",
      "Gui Zhou",
      "Hong Ren",
      "Maged Elkashlan",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.01585"
  },
  {
    "id": "arXiv:2111.01587",
    "title": "Procedural Generalization by Planning with Self-Supervised World Models",
    "abstract": "One of the key promises of model-based reinforcement learning is the ability\nto generalize using an internal model of the world to make predictions in novel\nenvironments and tasks. However, the generalization ability of model-based\nagents is not well understood because existing work has focused on model-free\nagents when benchmarking generalization. Here, we explicitly measure the\ngeneralization ability of model-based agents in comparison to their model-free\ncounterparts. We focus our analysis on MuZero (Schrittwieser et al., 2020), a\npowerful model-based agent, and evaluate its performance on both procedural and\ntask generalization. We identify three factors of procedural generalization --\nplanning, self-supervised representation learning, and procedural data\ndiversity -- and show that by combining these techniques, we achieve\nstate-of-the art generalization performance and data efficiency on Procgen\n(Cobbe et al., 2019). However, we find that these factors do not always provide\nthe same benefits for the task generalization benchmarks in Meta-World (Yu et\nal., 2019), indicating that transfer remains a challenge and may require\ndifferent approaches than procedural generalization. Overall, we suggest that\nbuilding generalizable agents requires moving beyond the single-task,\nmodel-free paradigm and towards self-supervised model-based agents that are\ntrained in rich, procedural, multi-task environments.",
    "descriptor": "",
    "authors": [
      "Ankesh Anand",
      "Jacob Walker",
      "Yazhe Li",
      "Eszter V\u00e9rtes",
      "Julian Schrittwieser",
      "Sherjil Ozair",
      "Th\u00e9ophane Weber",
      "Jessica B. Hamrick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01587"
  },
  {
    "id": "arXiv:2111.01589",
    "title": "Nonstochastic Bandits and Experts with Arm-Dependent Delays",
    "abstract": "We study nonstochastic bandits and experts in a delayed setting where delays\ndepend on both time and arms. While the setting in which delays only depend on\ntime has been extensively studied, the arm-dependent delay setting better\ncaptures real-world applications at the cost of introducing new technical\nchallenges. In the full information (experts) setting, we design an algorithm\nwith a first-order regret bound that reveals an interesting trade-off between\ndelays and losses. We prove a similar first-order regret bound also for the\nbandit setting, when the learner is allowed to observe how many losses are\nmissing. These are the first bounds in the delayed setting that depend on the\nlosses and delays of the best arm only. When in the bandit setting no\ninformation other than the losses is observed, we still manage to prove a\nregret bound through a modification to the algorithm of Zimmert and Seldin\n(2020). Our analyses hinge on a novel bound on the drift, measuring how much\nbetter an algorithm can perform when given a look-ahead of one round.",
    "descriptor": "",
    "authors": [
      "Dirk van der Hoeven",
      "Nicol\u00f2 Cesa-Bianchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01589"
  },
  {
    "id": "arXiv:2111.01590",
    "title": "Detect-and-Segment: a Deep Learning Approach to Automate Wound Image  Segmentation",
    "abstract": "Chronic wounds significantly impact quality of life. If not properly managed,\nthey can severely deteriorate. Image-based wound analysis could aid in\nobjectively assessing the wound status by quantifying important features that\nare related to healing. However, the high heterogeneity of the wound types,\nimage background composition, and capturing conditions challenge the robust\nsegmentation of wound images. We present Detect-and-Segment (DS), a deep\nlearning approach to produce wound segmentation maps with high generalization\ncapabilities. In our approach, dedicated deep neural networks detected the\nwound position, isolated the wound from the uninformative background, and\ncomputed the wound segmentation map. We evaluated this approach using one data\nset with images of diabetic foot ulcers. For further testing, 4 supplemental\nindependent data sets with larger variety of wound types from different body\nlocations were used. The Matthews' correlation coefficient (MCC) improved from\n0.29 when computing the segmentation on the full image to 0.85 when combining\ndetection and segmentation in the same approach. When tested on the wound\nimages drawn from the supplemental data sets, the DS approach increased the\nmean MCC from 0.17 to 0.85. Furthermore, the DS approach enabled the training\nof segmentation models with up to 90% less training data while maintaining the\nsegmentation performance.",
    "descriptor": "",
    "authors": [
      "Gaetano Scebba",
      "Jia Zhang",
      "Sabrina Catanzaro",
      "Carina Mihai",
      "Oliver Distler",
      "Martin Berli",
      "Walter Karlen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.01590"
  },
  {
    "id": "arXiv:2111.01591",
    "title": "Estimating 3D Motion and Forces of Human-Object Interactions from  Internet Videos",
    "abstract": "In this paper, we introduce a method to automatically reconstruct the 3D\nmotion of a person interacting with an object from a single RGB video. Our\nmethod estimates the 3D poses of the person together with the object pose, the\ncontact positions and the contact forces exerted on the human body. The main\ncontributions of this work are three-fold. First, we introduce an approach to\njointly estimate the motion and the actuation forces of the person on the\nmanipulated object by modeling contacts and the dynamics of the interactions.\nThis is cast as a large-scale trajectory optimization problem. Second, we\ndevelop a method to automatically recognize from the input video the 2D\nposition and timing of contacts between the person and the object or the\nground, thereby significantly simplifying the complexity of the optimization.\nThird, we validate our approach on a recent video+MoCap dataset capturing\ntypical parkour actions, and demonstrate its performance on a new dataset of\nInternet videos showing people manipulating a variety of tools in unconstrained\nenvironments.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1904.02683\n",
    "authors": [
      "Zongmian Li",
      "Jiri Sedlar",
      "Justin Carpentier",
      "Ivan Laptev",
      "Nicolas Mansard",
      "Josef Sivic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01591"
  },
  {
    "id": "arXiv:2111.01592",
    "title": "Trajectory Prediction with Graph-based Dual-scale Context Fusion",
    "abstract": "Motion prediction for traffic participants is essential for a safe and robust\nautomated driving system, especially in cluttered urban environments. However,\nit is highly challenging due to the complex road topology as well as the\nuncertain intentions of the other agents. In this paper, we present a\ngraph-based trajectory prediction network named the Dual Scale Predictor (DSP),\nwhich encodes both the static and dynamical driving context in a hierarchical\nmanner. Different from methods based on a rasterized map or sparse lane graph,\nwe consider the driving context as a graph with two layers, focusing on both\ngeometrical and topological features. Graph neural networks (GNNs) are applied\nto extract features with different levels of granularity, and features are\nsubsequently aggregated with attention-based inter-layer networks, realizing\nbetter local-global feature fusion. Following the recent goal-driven trajectory\nprediction pipeline, goal candidates with high likelihood for the target agent\nare extracted, and predicted trajectories are generated conditioned on these\ngoals. Thanks to the proposed dual-scale context fusion network, our DSP is\nable to generate accurate and human-like multi-modal trajectories. We evaluate\nthe proposed method on the large-scale Argoverse motion forecasting benchmark,\nand it achieves promising results, outperforming the recent state-of-the-art\nmethods.",
    "descriptor": "",
    "authors": [
      "Lu Zhang",
      "Peiliang Li",
      "Jing Chen",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01592"
  },
  {
    "id": "arXiv:2111.01594",
    "title": "Mean Field and Refined Mean Field Approximations for Heterogeneous  Systems: It Works!",
    "abstract": "Mean field approximation is a powerful technique to study the performance of\nlarge stochastic systems represented as $n$ interacting objects. Applications\ninclude load balancing models, epidemic spreading, cache replacement policies,\nor large-scale data centers. Mean field approximation is asymptotically exact\nfor systems composed of $n$ homogeneous objects under mild conditions. In this\npaper, we study what happens when objects are heterogeneous. This can represent\nservers with different speeds or contents with different popularities. We\ndefine an interaction model that allows obtaining asymptotic convergence\nresults for stochastic systems with heterogeneous object behavior, and show\nthat the error of the mean field approximation is of order $O(1/n)$. More\nimportantly, we show how to adapt the refined mean field approximation,\ndeveloped by Gast et al. 2019, and show that the error of this approximation is\nreduced to $O(1/n^2)$. To illustrate the applicability of our result, we\npresent two examples. The first addresses a list-based cache replacement model\nRANDOM($m$), which is an extension of the RANDOM policy. The second is a\nheterogeneous supermarket model. These examples show that the proposed\napproximations are computationally tractable and very accurate. They also show\nthat for moderate system sizes ($n\\approx30$) the refined mean field\napproximation tends to be more accurate than simulations for any reasonable\nsimulation time.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Sebastian Allmeier",
      "Nicolas Gast"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.01594"
  },
  {
    "id": "arXiv:2111.01602",
    "title": "Stochastic Online Linear Regression: the Forward Algorithm to Replace  Ridge",
    "abstract": "We consider the problem of online linear regression in the stochastic\nsetting. We derive high probability regret bounds for online ridge regression\nand the forward algorithm. This enables us to compare online regression\nalgorithms more accurately and eliminate assumptions of bounded observations\nand predictions. Our study advocates for the use of the forward algorithm in\nlieu of ridge due to its enhanced bounds and robustness to the regularization\nparameter. Moreover, we explain how to integrate it in algorithms involving\nlinear function approximation to remove a boundedness assumption without\ndeteriorating theoretical bounds. We showcase this modification in linear\nbandit settings where it yields improved regret bounds. Last, we provide\nnumerical experiments to illustrate our results and endorse our intuitions.",
    "descriptor": "\nComments: 11+12 pages. To be published in the proceedings of NeurIPS 2021\n",
    "authors": [
      "Reda Ouhamma",
      "Odalric Maillard",
      "Vianney Perchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01602"
  },
  {
    "id": "arXiv:2111.01604",
    "title": "A Critical Study on the Recent Deep Learning Based Semi-Supervised Video  Anomaly Detection Methods",
    "abstract": "Video anomaly detection is one of the hot research topics in computer vision\nnowadays, as abnormal events contain a high amount of information. Anomalies\nare one of the main detection targets in surveillance systems, usually needing\nreal-time actions. Regarding the availability of labeled data for training\n(i.e., there is not enough labeled data for abnormalities), semi-supervised\nanomaly detection approaches have gained interest recently. This paper\nintroduces the researchers of the field to a new perspective and reviews the\nrecent deep-learning based semi-supervised video anomaly detection approaches,\nbased on a common strategy they use for anomaly detection. Our goal is to help\nresearchers develop more effective video anomaly detection methods. As the\nselection of a right Deep Neural Network plays an important role for several\nparts of this task, a quick comparative review on DNNs is prepared first.\nUnlike previous surveys, DNNs are reviewed from a spatiotemporal feature\nextraction viewpoint, customized for video anomaly detection. This part of the\nreview can help researchers in this field select suitable networks for\ndifferent parts of their methods. Moreover, some of the state-of-the-art\nanomaly detection methods, based on their detection strategy, are critically\nsurveyed. The review provides a novel and deep look at existing methods and\nresults in stating the shortcomings of these approaches, which can be a hint\nfor future works.",
    "descriptor": "",
    "authors": [
      "Mohammad Baradaran",
      "Robert Bergevin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01604"
  },
  {
    "id": "arXiv:2111.01605",
    "title": "Profit Sharing Contracts between Content and Service Providers for  Enhanced Network Quality",
    "abstract": "It has been a long demand of Internet Service Providers (ISPs) that the\nContent Providers (CPs) share their profits for investments in network\ninfrastructure. In this paper, we study profit sharing contracts between a CP\nwith multiple ISPs. Each ISP commits to improving the Quality of Service (QoS)\nfor the end-users through higher investments efforts. The CP agrees to share\nthe profits due to the resulting higher demand for its content. We first model\nnon-cooperative interaction between the CP and the ISPs as a two-stage\nStackelberg game. CP is the leader that decides what fraction of its profits\nwill be shared with the ISPs. Each ISP then simultaneously decides the amount\nof effort (investment) to enhance network quality. Here, CP cannot observe\nindividual effort by the ISPs, which poses a challenge for the CP to decide how\nto share the profits with each ISP. Therefore, we also investigate a\ncooperative scenario, where the CP only decides the total share it gives to the\nISPs, and each ISP then cooperatively shares the profit among themselves. We\nstudy the effect of such cooperation between the ISPs by building a Nash\nBargaining based model. We show that the collaboration improves total effort by\nthe ISPs and the payoff of the CP.",
    "descriptor": "",
    "authors": [
      "Fehmina Malik",
      "Manjesh K. Hanawal Yezekael Hayel"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.01605"
  },
  {
    "id": "arXiv:2111.01606",
    "title": "PolyTrack: Tracking with Bounding Polygons",
    "abstract": "In this paper, we present a novel method called PolyTrack for fast\nmulti-object tracking and segmentation using bounding polygons. Polytrack\ndetects objects by producing heatmaps of their center keypoint. For each of\nthem, a rough segmentation is done by computing a bounding polygon over each\ninstance instead of the traditional bounding box. Tracking is done by taking\ntwo consecutive frames as input and computing a center offset for each object\ndetected in the first frame to predict its location in the second frame. A\nKalman filter is also applied to reduce the number of ID switches. Since our\ntarget application is automated driving systems, we apply our method on urban\nenvironment videos. We trained and evaluated PolyTrack on the MOTS and\nKITTIMOTS datasets. Results show that tracking polygons can be a good\nalternative to bounding box and mask tracking. The code of PolyTrack is\navailable at https://github.com/gafaua/PolyTrack.",
    "descriptor": "\nComments: NeurIPS 2021 Machine Learning for Autonomous Driving Workshop\n",
    "authors": [
      "Gaspar Faure",
      "Hughes Perreault",
      "Guillaume-Alexandre Bilodeau",
      "Nicolas Saunier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01606"
  },
  {
    "id": "arXiv:2111.01616",
    "title": "OnSlicing: Online End-to-End Network Slicing with Reinforcement Learning",
    "abstract": "Network slicing allows mobile network operators to virtualize infrastructures\nand provide customized slices for supporting various use cases with\nheterogeneous requirements. Online deep reinforcement learning (DRL) has shown\npromising potential in solving network problems and eliminating the\nsimulation-to-reality discrepancy. Optimizing cross-domain resources with\nonline DRL is, however, challenging, as the random exploration of DRL violates\nthe service level agreement (SLA) of slices and resource constraints of\ninfrastructures. In this paper, we propose OnSlicing, an online end-to-end\nnetwork slicing system, to achieve minimal resource usage while satisfying\nslices' SLA. OnSlicing allows individualized learning for each slice and\nmaintains its SLA by using a novel constraint-aware policy update method and\nproactive baseline switching mechanism. OnSlicing complies with resource\nconstraints of infrastructures by using a unique design of action modification\nin slices and parameter coordination in infrastructures. OnSlicing further\nmitigates the poor performance of online learning during the early learning\nstage by offline imitating a rule-based solution. Besides, we design four new\ndomain managers to enable dynamic resource configuration in radio access,\ntransport, core, and edge networks, respectively, at a timescale of subseconds.\nWe implement OnSlicing on an end-to-end slicing testbed designed based on\nOpenAirInterface with both 4G LTE and 5G NR, OpenDayLight SDN platform, and\nOpenAir-CN core network. The experimental results show that OnSlicing achieves\n61.3% usage reduction as compared to the rule-based solution and maintains\nnearly zero violation (0.06%) throughout the online learning phase. As online\nlearning is converged, OnSlicing reduces 12.5% usage without any violations as\ncompared to the state-of-the-art online DRL solution.",
    "descriptor": "\nComments: This paper is accepted by CoNEXT 2021\n",
    "authors": [
      "Qiang Liu",
      "Nakjung Choi",
      "Tao Han"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01616"
  },
  {
    "id": "arXiv:2111.01619",
    "title": "StyleGAN of All Trades: Image Manipulation with Only Pretrained StyleGAN",
    "abstract": "Recently, StyleGAN has enabled various image manipulation and editing tasks\nthanks to the high-quality generation and the disentangled latent space.\nHowever, additional architectures or task-specific training paradigms are\nusually required for different tasks. In this work, we take a deeper look at\nthe spatial properties of StyleGAN. We show that with a pretrained StyleGAN\nalong with some operations, without any additional architecture, we can perform\ncomparably to the state-of-the-art methods on various tasks, including image\nblending, panorama generation, generation from a single image, controllable and\nlocal multimodal image to image translation, and attributes transfer. The\nproposed method is simple, effective, efficient, and applicable to any existing\npretrained StyleGAN model.",
    "descriptor": "",
    "authors": [
      "Min Jin Chong",
      "Hsin-Ying Lee",
      "David Forsyth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01619"
  },
  {
    "id": "arXiv:2111.01623",
    "title": "A Tri-attention Fusion Guided Multi-modal Segmentation Network",
    "abstract": "In the field of multimodal segmentation, the correlation between different\nmodalities can be considered for improving the segmentation results.\nConsidering the correlation between different MR modalities, in this paper, we\npropose a multi-modality segmentation network guided by a novel tri-attention\nfusion. Our network includes N model-independent encoding paths with N image\nsources, a tri-attention fusion block, a dual-attention fusion block, and a\ndecoding path. The model independent encoding paths can capture\nmodality-specific features from the N modalities. Considering that not all the\nfeatures extracted from the encoders are useful for segmentation, we propose to\nuse dual attention based fusion to re-weight the features along the modality\nand space paths, which can suppress less informative features and emphasize the\nuseful ones for each modality at different positions. Since there exists a\nstrong correlation between different modalities, based on the dual attention\nfusion block, we propose a correlation attention module to form the\ntri-attention fusion block. In the correlation attention module, a correlation\ndescription block is first used to learn the correlation between modalities and\nthen a constraint based on the correlation is used to guide the network to\nlearn the latent correlated features which are more relevant for segmentation.\nFinally, the obtained fused feature representation is projected by the decoder\nto obtain the segmentation results. Our experiment results tested on BraTS 2018\ndataset for brain tumor segmentation demonstrate the effectiveness of our\nproposed method.",
    "descriptor": "\nComments: 33 pages, 11 figures, accepted by Pattern Recognition on 01 November 2021. arXiv admin note: substantial text overlap with arXiv:2102.03111\n",
    "authors": [
      "Tongxue Zhou",
      "Su Ruan",
      "Pierre Vera",
      "St\u00e9phane Canu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.01623"
  },
  {
    "id": "arXiv:2111.01625",
    "title": "Learning Robotic Ultrasound Scanning Skills via Human Demonstrations and  Guided Explorations",
    "abstract": "Medical ultrasound has become a routine examination approach nowadays and is\nwidely adopted for different medical applications, so it is desired to have a\nrobotic ultrasound system to perform the ultrasound scanning autonomously.\nHowever, the ultrasound scanning skill is considerably complex, which highly\ndepends on the experience of the ultrasound physician. In this paper, we\npropose a learning-based approach to learn the robotic ultrasound scanning\nskills from human demonstrations. First, the robotic ultrasound scanning skill\nis encapsulated into a high-dimensional multi-modal model, which takes the\nultrasound images, the pose/position of the probe and the contact force into\naccount. Second, we leverage the power of imitation learning to train the\nmulti-modal model with the training data collected from the demonstrations of\nexperienced ultrasound physicians. Finally, a post-optimization procedure with\nguided explorations is proposed to further improve the performance of the\nlearned model. Robotic experiments are conducted to validate the advantages of\nour proposed framework and the learned models.",
    "descriptor": "",
    "authors": [
      "Xutian Deng",
      "Yiting Chen",
      "Fei Chen",
      "Miao Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01625"
  },
  {
    "id": "arXiv:2111.01628",
    "title": "Human Attention in Fine-grained Classification",
    "abstract": "The way humans attend to, process and classify a given image has the\npotential to vastly benefit the performance of deep learning models. Exploiting\nwhere humans are focusing can rectify models when they are deviating from\nessential features for correct decisions. To validate that human attention\ncontains valuable information for decision-making processes such as\nfine-grained classification, we compare human attention and model explanations\nin discovering important features. Towards this goal, we collect human gaze\ndata for the fine-grained classification dataset CUB and build a dataset named\nCUB-GHA (Gaze-based Human Attention). Furthermore, we propose the Gaze\nAugmentation Training (GAT) and Knowledge Fusion Network (KFN) to integrate\nhuman gaze knowledge into classification models. We implement our proposals in\nCUB-GHA and the recently released medical dataset CXR-Eye of chest X-ray\nimages, which includes gaze data collected from a radiologist. Our result\nreveals that integrating human attention knowledge benefits classification\neffectively, e.g. improving the baseline by 4.38% on CXR. Hence, our work\nprovides not only valuable insights into understanding human attention in\nfine-grained classification, but also contributes to future research in\nintegrating human gaze with computer vision tasks. CUB-GHA and code are\navailable at https://github.com/yaorong0921/CUB-GHA.",
    "descriptor": "\nComments: 19 pages, 9 figures\n",
    "authors": [
      "Yao Rong",
      "Wenjia Xu",
      "Zeynep Akata",
      "Enkelejda Kasneci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01628"
  },
  {
    "id": "arXiv:2111.01629",
    "title": "Accelerating Algebraic Multigrid Methods via Artificial Neural Networks",
    "abstract": "We present a novel Deep Learning-based algorithm to accelerate - through the\nuse of Artificial Neural Networks (ANNs) - the convergence of Algebraic\nMultigrid (AMG) methods for the iterative solution of the linear systems of\nequations stemming from Finite Element discretizations of Partial Differential\nEquations. We show that ANNs can be be successfully used to predict the strong\nconnection parameter that enters in the construction of the sequence of\nincreasingly smaller matrix problems standing at the basis of the AMG\nalgorithm, so as to maximize the corresponding convergence factor of the AMG\nscheme. To demonstrate the practical capabilities of the proposed algorithm,\nwhich we call AMG-ANN, we consider the iterative solution via the AMG method of\nthe algebraic system of equations stemming from Finite Element discretizations\nof a two-dimensional elliptic equation with a highly heterogeneous diffusion\ncoefficient. We train (off-line) our ANN with a rich data-set and present an\nin-depth analysis of the effects of tuning the strong threshold parameter on\nthe convergence factor of the resulting AMG iterative scheme.",
    "descriptor": "",
    "authors": [
      "Paola F. Antonietti",
      "Matteo Caldana",
      "Luca Dede'"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.01629"
  },
  {
    "id": "arXiv:2111.01631",
    "title": "SO{U}RCERER: Developer-Driven Security Testing Framework for Android  Apps",
    "abstract": "Frequently advised secure development recommendations often fall short in\npractice for app developers. Tool-driven (e.g., using static analysis tools)\napproaches lack context and domain-specific requirements of an app being\ntested. App developers struggle to find an actionable and prioritized list of\nvulnerabilities from a laundry list of security warnings reported by static\nanalysis tools. Process-driven (e.g., applying threat modeling methods)\napproaches require substantial resources (e.g., security testing team, budget)\nand security expertise, which small to medium-scale app dev teams could barely\nafford. To help app developers securing their apps, we propose SO{U}RCERER, a\nguiding framework for Android app developers for security testing. SO{U}RCERER\nguides developers to identify domain-specific assets of an app, detect and\nprioritize vulnerabilities, and mitigate those vulnerabilities based on secure\ndevelopment guidelines. We evaluated SO{U}RCERER with a case study on analyzing\nand testing 36 Android mobile money apps. We found that by following activities\nguided by SO{U}RCERER, an app developer could get a concise and actionable list\nof vulnerabilities (24-61% fewer security warnings produced by SO{U}RCERER than\na standalone static analyzer), directly affecting a mobile money app's critical\nassets, and devise a mitigation plan. Our findings from this preliminary study\nindicate a viable approach to Android app security testing without being\noverwhelmingly complex for app developers.",
    "descriptor": "\nComments: Accepted at the 2021 Automated Software Engineering Workshop\n",
    "authors": [
      "Muhammad Sajidur Rahman",
      "Blas Cojusner",
      "Ryon Kennedy",
      "Prerit Pathak",
      "Lin Qi",
      "Byron Williams"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.01631"
  },
  {
    "id": "arXiv:2111.01632",
    "title": "Elucidating Noisy Data via Uncertainty-Aware Robust Learning",
    "abstract": "Robust learning methods aim to learn a clean target distribution from noisy\nand corrupted training data where a specific corruption pattern is often\nassumed a priori. Our proposed method can not only successfully learn the clean\ntarget distribution from a dirty dataset but also can estimate the underlying\nnoise pattern. To this end, we leverage a mixture-of-experts model that can\ndistinguish two different types of predictive uncertainty, aleatoric and\nepistemic uncertainty. We show that the ability to estimate the uncertainty\nplays a significant role in elucidating the corruption patterns as these two\nobjectives are tightly intertwined. We also present a novel validation scheme\nfor evaluating the performance of the corruption pattern estimation. Our\nproposed method is extensively assessed in terms of both robustness and\ncorruption pattern estimation through a number of domains, including computer\nvision and natural language processing.",
    "descriptor": "",
    "authors": [
      "Jeongeun Park",
      "Seungyoun Shin",
      "Sangheum Hwang",
      "Sungjoon Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01632"
  },
  {
    "id": "arXiv:2111.01633",
    "title": "Neural Program Generation Modulo Static Analysis",
    "abstract": "State-of-the-art neural models of source code tend to be evaluated on the\ngeneration of individual expressions and lines of code, and commonly fail on\nlong-horizon tasks such as the generation of entire method bodies. We propose\nto address this deficiency using weak supervision from a static program\nanalyzer. Our neurosymbolic method allows a deep generative model to\nsymbolically compute, using calls to a static-analysis tool, long-distance\nsemantic relationships in the code that it has already generated. During\ntraining, the model observes these relationships and learns to generate\nprograms conditioned on them. We apply our approach to the problem of\ngenerating entire Java methods given the remainder of the class that contains\nthe method. Our experiments show that the approach substantially outperforms\nstate-of-the-art transformers and a model that explicitly tries to learn\nprogram semantics on this task, both in terms of producing programs free of\nbasic semantic errors and in terms of syntactically matching the ground truth.",
    "descriptor": "\nComments: Accepted for publication at Neurips 2021\n",
    "authors": [
      "Rohan Mukherjee",
      "Yeming Wen",
      "Dipak Chaudhari",
      "Thomas W. Reps",
      "Swarat Chaudhuri",
      "Chris Jermaine"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01633"
  },
  {
    "id": "arXiv:2111.01634",
    "title": "Towards Enabling High-Five Over WiFi",
    "abstract": "The next frontier for immersive applications is enabling sentience over the\nInternet. Tactile Internet (TI) envisages transporting skills by providing\nUltra-Low Latency (ULL) communications for transporting touch senses. In this\nwork, we focus our study on the first/last mile communication, where the future\ngeneration WiFi-7 is pitched as the front-runner for ULL applications. We\ndiscuss a few candidate features of WiFi-7 and highlight its major pitfalls\nwith respect to ULL communication. Further, through a specific implementation\nof WiFi-7 (vanilla WiFi-7) in our custom simulator, we demonstrate the impact\nof one of the pitfalls - standard practice of using jitter buffer in\nconjunction with frame aggregation - on TI communication. To circumvent this,\nwe propose Non-Buffered Scheme (NoBuS) - a simple MAC layer enhancement for\nenabling TI applications on WiFi-7. NoBuS trades off packet loss for latency\nenabling swift synchronization between the master and controlled domains. Our\nfindings reveal that employing NoBuS yields a significant improvement in RMSE\nof TI signals. Further, we show that the worst-case WiFi latency with NoBuS is\n3.72 ms - an order of magnitude lower than vanilla WiFi-7 even under highly\ncongested network conditions.",
    "descriptor": "",
    "authors": [
      "Vineet Gokhale",
      "Mohamad Eid",
      "Kees Kroep",
      "R. Venkatesha Prasad",
      "Vijay Rao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.01634"
  },
  {
    "id": "arXiv:2111.01635",
    "title": "Characterizing and Understanding the Generalization Error of Transfer  Learning with Gibbs Algorithm",
    "abstract": "We provide an information-theoretic analysis of the generalization ability of\nGibbs-based transfer learning algorithms by focusing on two popular transfer\nlearning approaches, $\\alpha$-weighted-ERM and two-stage-ERM. Our key result is\nan exact characterization of the generalization behaviour using the conditional\nsymmetrized KL information between the output hypothesis and the target\ntraining samples given the source samples. Our results can also be applied to\nprovide novel distribution-free generalization error upper bounds on these two\naforementioned Gibbs algorithms. Our approach is versatile, as it also\ncharacterizes the generalization errors and excess risks of these two Gibbs\nalgorithms in the asymptotic regime, where they converge to the\n$\\alpha$-weighted-ERM and two-stage-ERM, respectively. Based on our theoretical\nresults, we show that the benefits of transfer learning can be viewed as a\nbias-variance trade-off, with the bias induced by the source distribution and\nthe variance induced by the lack of target samples. We believe this viewpoint\ncan guide the choice of transfer learning algorithms in practice.",
    "descriptor": "",
    "authors": [
      "Yuheng Bu",
      "Gholamali Aminian",
      "Laura Toni",
      "Miguel Rodrigues",
      "Gregory Wornell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01635"
  },
  {
    "id": "arXiv:2111.01645",
    "title": "Energy and Resource Efficiency by User Traffic Prediction and  Classification in Cellular Networks",
    "abstract": "There is a lack of research on the analysis of per-user traffic in cellular\nnetworks, for deriving and following traffic-aware network management.\n\\textcolor{black}{In fact, the legacy design approach, in which resource\nprovisioning and operation control are performed based on the cell-aggregated\ntraffic scenarios, are not so energy- and cost-efficient and need to be\nsubstituted with user-centric predictive analysis of mobile network traffic and\nproactive network resource management.} Here, we shed light on this problem by\ndesigning traffic prediction tools that utilize standard machine learning (ML)\ntools, including long short-term memory (LSTM) and autoregressive integrated\nmoving average (ARIMA) on top of per-user data. We present an expansive\nempirical evaluation of the designed solutions over a real network traffic\ndataset. Within this analysis, the impact of different parameters, such as the\ntime granularity, the length of future predictions, and feature selection are\ninvestigated. As a potential application of these solutions, we present an\nML-powered Discontinuous reception (DRX) scheme for energy saving. Towards this\nend, we leverage the derived ML models for dynamic DRX parameter adaptation to\nuser traffic. The performance evaluation results demonstrate the superiority of\nLSTM over ARIMA in general, especially when the length of the training time\nseries is high enough, and it is augmented by a \\textit{wisely}-selected set of\nfeatures. Furthermore, the results show that adaptation of DRX parameters by\nonline prediction of future traffic provides much more energy-saving at low\nlatency cost in comparison with the legacy cell-wide DRX parameter adaptation.",
    "descriptor": "\nComments: IEEE Transactions on Green Communications and Networking, 2021. arXiv admin note: text overlap with arXiv:1906.00939\n",
    "authors": [
      "Amin Azari",
      "Fateme Salehi",
      "Panagiotis Papapetrou",
      "Cicek Cavdar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01645"
  },
  {
    "id": "arXiv:2111.01654",
    "title": "Modeling and Automating Public Announcement Logic with Rela\\-tivized  Common Knowledge as a Fragment of HOL in LogiKEy",
    "abstract": "A shallow semantical embedding for public announcement logic with relativized\ncommon knowledge is presented. This embedding enables the first-time automation\nof this logic with off-the-shelf theorem provers for classical higher-order\nlogic. It is demonstrated (i) how meta-theoretical studies can be automated\nthis way, and (ii) how non-trivial reasoning in the target logic (public\nannouncement logic), required e.g. to obtain a convincing encoding and\nautomation of the wise men puzzle, can be realized.\nKey to the presented semantical embedding is that evaluation domains are\nmodeled explicitly and treated as an additional parameter in the encodings of\nthe constituents of the embedded target logic; in previous related works, e.g.\non the embedding of normal modal logics, evaluation domains were implicitly\nshared between meta-logic and target logic.\nThe work presented in this article constitutes an important addition to the\npluralist \\logikey\\ knowledge engineering methodology, which enables\nexperimentation with logics and their combinations, with general and domain\nknowledge, and with concrete use cases -- all at the same time.",
    "descriptor": "\nComments: 28 pages, 5 figures. arXiv admin note: substantial text overlap with arXiv:2010.00810\n",
    "authors": [
      "Christoph Benzm\u00fcller",
      "Sebastian Reiche"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.01654"
  },
  {
    "id": "arXiv:2111.01657",
    "title": "LogLAB: Attention-Based Labeling of Log Data Anomalies via Weak  Supervision",
    "abstract": "With increasing scale and complexity of cloud operations, automated detection\nof anomalies in monitoring data such as logs will be an essential part of\nmanaging future IT infrastructures. However, many methods based on artificial\nintelligence, such as supervised deep learning models, require large amounts of\nlabeled training data to perform well. In practice, this data is rarely\navailable because labeling log data is expensive, time-consuming, and requires\na deep understanding of the underlying system. We present LogLAB, a novel\nmodeling approach for automated labeling of log messages without requiring\nmanual work by experts. Our method relies on estimated failure time windows\nprovided by monitoring systems to produce precise labeled datasets in\nretrospect. It is based on the attention mechanism and uses a custom objective\nfunction for weak supervision deep learning techniques that accounts for\nimbalanced data. Our evaluation shows that LogLAB consistently outperforms nine\nbenchmark approaches across three different datasets and maintains an F1-score\nof more than 0.98 even at large failure time windows.",
    "descriptor": "\nComments: Paper accepted on ICSOC 2021. Will be published in December 2021\n",
    "authors": [
      "Thorsten Wittkopp",
      "Philipp Wiesner",
      "Dominik Scheinert",
      "Alexander Acker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01657"
  },
  {
    "id": "arXiv:2111.01662",
    "title": "OSOA: One-Shot Online Adaptation of Deep Generative Models for Lossless  Compression",
    "abstract": "Explicit deep generative models (DGMs), e.g., VAEs and Normalizing Flows,\nhave shown to offer an effective data modelling alternative for lossless\ncompression. However, DGMs themselves normally require large storage space and\nthus contaminate the advantage brought by accurate data density estimation. To\neliminate the requirement of saving separate models for different target\ndatasets, we propose a novel setting that starts from a pretrained deep\ngenerative model and compresses the data batches while adapting the model with\na dynamical system for only one epoch. We formalise this setting as that of\nOne-Shot Online Adaptation (OSOA) of DGMs for lossless compression and propose\na vanilla algorithm under this setting. Experimental results show that vanilla\nOSOA can save significant time versus training bespoke models and space versus\nusing one model for all targets. With the same adaptation step number or\nadaptation time, it is shown vanilla OSOA can exhibit better space efficiency,\ne.g., $47\\%$ less space, than fine-tuning the pretrained model and saving the\nfine-tuned model. Moreover, we showcase the potential of OSOA and motivate more\nsophisticated OSOA algorithms by showing further space or time efficiency with\nmultiple updates per batch and early stopping.",
    "descriptor": "",
    "authors": [
      "Chen Zhang",
      "Shifeng Zhang",
      "Fabio Maria Carlucci",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01662"
  },
  {
    "id": "arXiv:2111.01663",
    "title": "Classification of Goods Using Text Descriptions With Sentences Retrieval",
    "abstract": "The task of assigning and validating internationally accepted commodity code\n(HS code) to traded goods is one of the critical functions at the customs\noffice. This decision is crucial to importers and exporters, as it determines\nthe tariff rate. However, similar to court decisions made by judges, the task\ncan be non-trivial even for experienced customs officers. The current paper\nproposes a deep learning model to assist this seemingly challenging HS code\nclassification. Together with Korea Customs Service, we built a decision model\nbased on KoELECTRA that suggests the most likely heading and subheadings (i.e.,\nthe first four and six digits) of the HS code. Evaluation on 129,084 past cases\nshows that the top-3 suggestions made by our model have an accuracy of 95.5% in\nclassifying 265 subheadings. This promising result implies algorithms may\nreduce the time and effort taken by customs officers substantially by assisting\nthe HS code classification task.",
    "descriptor": "",
    "authors": [
      "Eunji Lee",
      "Sundong Kim",
      "Sihyun Kim",
      "Sungwon Park",
      "Meeyoung Cha",
      "Soyeon Jung",
      "Suyoung Yang",
      "Yeonsoo Choi",
      "Sungdae Ji",
      "Minsoo Song",
      "Heeja Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.01663"
  },
  {
    "id": "arXiv:2111.01667",
    "title": "International Comparative Studies on the Software Testing Profession",
    "abstract": "This work attempts to fill a gap by exploring the human dimension in\nparticular, by trying to understand the motivation of software professionals\nfor taking up and sustaining their careers as software testers. Towards that\ngoal, four surveys were conducted in four countries - India, Canada, Cuba, and\nChina - to try to understand how professional software engineers perceive and\nvalue work-related factors that could influence their motivation to start or\nmove into software testing careers. From our sample of 220 software\nprofessionals, we observed that very few were keen to take up testing careers.\nSome aspects of software testing, such as the potential for learning\nopportunities and the importance of the job, appear to be common motivators\nacross the four countries, whereas the treatment of testers as second-class\ncitizens and the complexity of the job appeared to be the most prominent\nde-motivators.",
    "descriptor": "\nComments: 6 pages. arXiv admin note: substantial text overlap with arXiv:2103.06343, arXiv:1906.06144\n",
    "authors": [
      "Luiz Fernando Capretz",
      "Pradeep Waychal",
      "Jingdong Jia",
      "Yadira Lizama",
      "Daniel Varona"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.01667"
  },
  {
    "id": "arXiv:2111.01673",
    "title": "Relational Self-Attention: What's Missing in Attention for Video  Understanding",
    "abstract": "Convolution has been arguably the most important feature transform for modern\nneural networks, leading to the advance of deep learning. Recent emergence of\nTransformer networks, which replace convolution layers with self-attention\nblocks, has revealed the limitation of stationary convolution kernels and\nopened the door to the era of dynamic feature transforms. The existing dynamic\ntransforms, including self-attention, however, are all limited for video\nunderstanding where correspondence relations in space and time, i.e., motion\ninformation, are crucial for effective representation. In this work, we\nintroduce a relational feature transform, dubbed the relational self-attention\n(RSA), that leverages rich structures of spatio-temporal relations in videos by\ndynamically generating relational kernels and aggregating relational contexts.\nOur experiments and ablation studies show that the RSA network substantially\noutperforms convolution and self-attention counterparts, achieving the state of\nthe art on the standard motion-centric benchmarks for video action recognition,\nsuch as Something-Something-V1 & V2, Diving48, and FineGym.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Manjin Kim",
      "Heeseung Kwon",
      "Chunyu Wang",
      "Suha Kwak",
      "Minsu Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01673"
  },
  {
    "id": "arXiv:2111.01674",
    "title": "Minimizing Energy Consumption Leads to the Emergence of Gaits in Legged  Robots",
    "abstract": "Legged locomotion is commonly studied and expressed as a discrete set of gait\npatterns, like walk, trot, gallop, which are usually treated as given and\npre-programmed in legged robots for efficient locomotion at different speeds.\nHowever, fixing a set of pre-programmed gaits limits the generality of\nlocomotion. Recent animal motor studies show that these conventional gaits are\nonly prevalent in ideal flat terrain conditions while real-world locomotion is\nunstructured and more like bouts of intermittent steps. What principles could\nlead to both structured and unstructured patterns across mammals and how to\nsynthesize them in robots? In this work, we take an analysis-by-synthesis\napproach and learn to move by minimizing mechanical energy. We demonstrate that\nlearning to minimize energy consumption plays a key role in the emergence of\nnatural locomotion gaits at different speeds in real quadruped robots. The\nemergent gaits are structured in ideal terrains and look similar to that of\nhorses and sheep. The same approach leads to unstructured gaits in rough\nterrains which is consistent with the findings in animal motor control. We\nvalidate our hypothesis in both simulation and real hardware across natural\nterrains. Videos at https://energy-locomotion.github.io",
    "descriptor": "\nComments: CoRL 2021. Website at this https URL\n",
    "authors": [
      "Zipeng Fu",
      "Ashish Kumar",
      "Jitendra Malik",
      "Deepak Pathak"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01674"
  },
  {
    "id": "arXiv:2111.01676",
    "title": "Towards text-based phishing detection",
    "abstract": "This paper reports on an experiment into text-based phishing detection using\nreadily available resources and without the use of semantics. The developed\nalgorithm is a modified version of previously published work that works with\nthe same tools. The results obtained in recognizing phishing emails are\nconsiderably better than the previously reported work; but the rate of text\nfalsely identified as phishing is slightly worse. It is expected that adding\nsemantic component will reduce the false positive rate while preserving the\ndetection accuracy.",
    "descriptor": "\nComments: Society for Design and Process Science (SDPS) 2013, pp.187-192 this https URL\n",
    "authors": [
      "Gilchan Park",
      "Julia M. Taylor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.01676"
  },
  {
    "id": "arXiv:2111.01677",
    "title": "Top1 Solution of QQ Browser 2021 Ai Algorithm Competition Track 1 :  Multimodal Video Similarity",
    "abstract": "In this paper, we describe the solution to the QQ Browser 2021 Ai Algorithm\nCompetition (AIAC) Track 1. We use the multi-modal transformer model for the\nvideo embedding extraction. In the pretrain phase, we train the model with\nthree tasks, (1) Video Tag Classification (VTC), (2) Mask Language Modeling\n(MLM) and (3) Mask Frame Modeling (MFM). In the finetune phase, we train the\nmodel with video similarity based on rank normalized human labels. Our full\npipeline, after ensembling several models, scores 0.852 on the leaderboard,\nwhich we achieved the 1st place in the competition. The source codes have been\nreleased at Github.",
    "descriptor": "",
    "authors": [
      "Zhuoran Ma",
      "Majing Lou",
      "Xuan Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01677"
  },
  {
    "id": "arXiv:2111.01681",
    "title": "Saliency detection with moving camera via background model completion",
    "abstract": "To detect saliency in video is a fundamental step in many computer vision\nsystems. Saliency is the significant target(s) in the video. The object of\ninterest is further analyzed for high-level applications. The segregation of\nsaliency and the background can be made if they exhibit different visual cues.\nTherefore, saliency detection is often formulated as background subtraction.\nHowever, saliency detection is challenging. For instance, dynamic background\ncan result in false positive errors. In another scenario, camouflage will lead\nto false negative errors. With moving camera, the captured scenes are even more\ncomplicated to handle. We propose a new framework, called saliency detection\nvia background model completion (SD-BMC), that comprises of a background\nmodeler and the deep learning background/foreground segmentation network. The\nbackground modeler generates an initial clean background image from a short\nimage sequence. Based on the idea of video completion, a good background frame\ncan be synthesized with the co-existence of changing background and moving\nobjects. We adopt the background/foreground segmenter, although pre-trained\nwith a specific video dataset, can also detect saliency in unseen videos. The\nbackground modeler can adjust the background image dynamically when the\nbackground/foreground segmenter output deteriorates during processing of a long\nvideo. To the best of our knowledge, our framework is the first one to adopt\nvideo completion for background modeling and saliency detection in videos\ncaptured by moving camera. The results, obtained from the PTZ videos, show that\nour proposed framework outperforms some deep learning-based background\nsubtraction models by 11% or more. With more challenging videos, our framework\nalso outperforms many high ranking background subtraction methods by more than\n3%.",
    "descriptor": "",
    "authors": [
      "Yupei Zhang",
      "Kwok-Leung Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.01681"
  },
  {
    "id": "arXiv:2111.01683",
    "title": "Using Synthetic Images To Uncover Population Biases In Facial Landmarks  Detection",
    "abstract": "In order to analyze a trained model performance and identify its weak spots,\none has to set aside a portion of the data for testing. The test set has to be\nlarge enough to detect statistically significant biases with respect to all the\nrelevant sub-groups in the target population. This requirement may be difficult\nto satisfy, especially in data-hungry applications. We propose to overcome this\ndifficulty by generating synthetic test set. We use the face landmarks\ndetection task to validate our proposal by showing that all the biases observed\non real datasets are also seen on a carefully designed synthetic dataset. This\nshows that synthetic test sets can efficiently detect a model's weak spots and\novercome limitations of real test set in terms of quantity and/or diversity.",
    "descriptor": "\nComments: to be published in DCAI workshop / NEURIPS 2021\n",
    "authors": [
      "Ran Shadmi",
      "Jonathan Laserson",
      "Gil Elbaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01683"
  },
  {
    "id": "arXiv:2111.01684",
    "title": "Rethinking the Knowledge Distillation From the Perspective of Model  Calibration",
    "abstract": "Recent years have witnessed dramatically improvements in the knowledge\ndistillation, which can generate a compact student model for better efficiency\nwhile retaining the model effectiveness of the teacher model. Previous studies\nfind that: more accurate teachers do not necessary make for better teachers due\nto the mismatch of abilities. In this paper, we aim to analysis the phenomenon\nfrom the perspective of model calibration. We found that the larger teacher\nmodel may be too over-confident, thus the student model cannot effectively\nimitate. While, after the simple model calibration of the teacher model, the\nsize of the teacher model has a positive correlation with the performance of\nthe student model.",
    "descriptor": "",
    "authors": [
      "Lehan Yang",
      "Jincen Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01684"
  },
  {
    "id": "arXiv:2111.01689",
    "title": "Improving Classifier Training Efficiency for Automatic Cyberbullying  Detection with Feature Density",
    "abstract": "We study the effectiveness of Feature Density (FD) using different\nlinguistically-backed feature preprocessing methods in order to estimate\ndataset complexity, which in turn is used to comparatively estimate the\npotential performance of machine learning (ML) classifiers prior to any\ntraining. We hypothesise that estimating dataset complexity allows for the\nreduction of the number of required experiments iterations. This way we can\noptimize the resource-intensive training of ML models which is becoming a\nserious issue due to the increases in available dataset sizes and the ever\nrising popularity of models based on Deep Neural Networks (DNN). The problem of\nconstantly increasing needs for more powerful computational resources is also\naffecting the environment due to alarmingly-growing amount of CO2 emissions\ncaused by training of large-scale ML models. The research was conducted on\nmultiple datasets, including popular datasets, such as Yelp business review\ndataset used for training typical sentiment analysis models, as well as more\nrecent datasets trying to tackle the problem of cyberbullying, which, being a\nserious social problem, is also a much more sophisticated problem form the\npoint of view of linguistic representation. We use cyberbullying datasets\ncollected for multiple languages, namely English, Japanese and Polish. The\ndifference in linguistic complexity of datasets allows us to additionally\ndiscuss the efficacy of linguistically-backed word preprocessing.",
    "descriptor": "\nComments: 73 pages, 4 figures, 19 tables, Information Processing and Management, Vol. 58, Issue 5, September 2021, paper ID: 102616\n",
    "authors": [
      "Juuso Eronen",
      "Michal Ptaszynski",
      "Fumito Masui",
      "Aleksander Pohl",
      "Gniewosz Leliwa",
      "Michal Wroczynski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.01689"
  },
  {
    "id": "arXiv:2111.01694",
    "title": "Small-Signal Stability Techniques for Power System Modal Analysis,  Control, and Numerical Integration",
    "abstract": "This thesis proposes novel Small-Signal Stability Analysis (SSSA)-based\ntechniques that contribute to electric power system modal analysis, automatic\ncontrol, and numerical integration. Modal analysis is a fundamental tool for\npower system stability analysis and control. The thesis proposes a SSSA\napproach to determine the Participation Factors (PFs) of algebraic variables in\npower system dynamic modes. The thesis also explores SSSA techniques for the\ndesign of power system controllers. The contributions on this topic are\ntwofold: i) Investigate a promising control approach, that is to synthesize\nautomatic regulators for power systems based on the theory of fractional\ncalculus. ii) Propose a novel perspective on the potential impact of time\ndelays on power system stability. Through SSSA, the thesis systematically\nidentifies the control parameter settings for which delays in PSSs improve the\ndamping of a power system. Both analytical and simulation-based results are\npresented. Finally, SSSA is utilized in the thesis to systematically propose a\ndelay-based method to reduce the coupling of the equations of power system\nmodels for transient stability analysis. The method consists in identifying the\nvariables that, when subjected to a delay equal to the time step of the\nnumerical integration, leave practically unchanged the system trajectories.\nSuch an one-step-delay approximation increases the sparsity of the system\nJacobian matrices and can be used in conjunction with state-of-the-art\ntechniques for the integration of DAEs. The proposed approach is evaluated in\nterms of accuracy, convergence and computational burden. Throughout the thesis,\nthe proposed techniques are duly validated through numerical tests based on\nreal-world network models.",
    "descriptor": "",
    "authors": [
      "Georgios Tzounas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01694"
  },
  {
    "id": "arXiv:2111.01697",
    "title": "Low-Rank+Sparse Tensor Compression for Neural Networks",
    "abstract": "Low-rank tensor compression has been proposed as a promising approach to\nreduce the memory and compute requirements of neural networks for their\ndeployment on edge devices. Tensor compression reduces the number of parameters\nrequired to represent a neural network weight by assuming network weights\npossess a coarse higher-order structure. This coarse structure assumption has\nbeen applied to compress large neural networks such as VGG and ResNet. However\nmodern state-of-the-art neural networks for computer vision tasks (i.e.\nMobileNet, EfficientNet) already assume a coarse factorized structure through\ndepthwise separable convolutions, making pure tensor decomposition a less\nattractive approach. We propose to combine low-rank tensor decomposition with\nsparse pruning in order to take advantage of both coarse and fine structure for\ncompression. We compress weights in SOTA architectures (MobileNetv3,\nEfficientNet, Vision Transformer) and compare this approach to sparse pruning\nand tensor decomposition alone.",
    "descriptor": "",
    "authors": [
      "Cole Hawkins",
      "Haichuan Yang",
      "Meng Li",
      "Liangzhen Lai",
      "Vikas Chandra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01697"
  },
  {
    "id": "arXiv:2111.01705",
    "title": "AI Ethics Statements -- Analysis and lessons learnt from NeurIPS Broader  Impact Statements",
    "abstract": "Ethics statements have been proposed as a mechanism to increase transparency\nand promote reflection on the societal impacts of published research. In 2020,\nthe machine learning (ML) conference NeurIPS broke new ground by requiring that\nall papers include a broader impact statement. This requirement was removed in\n2021, in favour of a checklist approach. The 2020 statements therefore provide\na unique opportunity to learn from the broader impact experiment: to\ninvestigate the benefits and challenges of this and similar governance\nmechanisms, as well as providing an insight into how ML researchers think about\nthe societal impacts of their own work. Such learning is needed as NeurIPS and\nother venues continue to question and adapt their policies. To enable this, we\nhave created a dataset containing the impact statements from all NeurIPS 2020\npapers, along with additional information such as affiliation type, location\nand subject area, and a simple visualisation tool for exploration. We also\nprovide an initial quantitative analysis of the dataset, covering\nrepresentation, engagement, common themes, and willingness to discuss potential\nharms alongside benefits. We investigate how these vary by geography,\naffiliation type and subject area. Drawing on these findings, we discuss the\npotential benefits and negative outcomes of ethics statement requirements, and\ntheir possible causes and associated challenges. These lead us to several\nlessons to be learnt from the 2020 requirement: (i) the importance of creating\nthe right incentives, (ii) the need for clear expectations and guidance, and\n(iii) the importance of transparency and constructive deliberation. We\nencourage other researchers to use our dataset to provide additional analysis,\nto further our understanding of how researchers responded to this requirement,\nand to investigate the benefits and challenges of this and related mechanisms.",
    "descriptor": "",
    "authors": [
      "Carolyn Ashurst",
      "Emmie Hine",
      "Paul Sedille",
      "Alexis Carlier"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01705"
  },
  {
    "id": "arXiv:2111.01706",
    "title": "Assessing Effectiveness of Using Internal Signals for Check-Worthy Claim  Identification in Unlabeled Data for Automated Fact-Checking",
    "abstract": "While recent work on automated fact-checking has focused mainly on verifying\nand explaining claims, for which the list of claims is readily available,\nidentifying check-worthy claim sentences from a text remains challenging.\nCurrent claim identification models rely on manual annotations for each\nsentence in the text, which is an expensive task and challenging to conduct on\na frequent basis across multiple domains. This paper explores methodology to\nidentify check-worthy claim sentences from fake news articles, irrespective of\ndomain, without explicit sentence-level annotations. We leverage two internal\nsupervisory signals - headline and the abstractive summary - to rank the\nsentences based on semantic similarity. We hypothesize that this ranking\ndirectly correlates to the check-worthiness of the sentences. To assess the\neffectiveness of this hypothesis, we build pipelines that leverage the ranking\nof sentences based on either the headline or the abstractive summary. The\ntop-ranked sentences are used for the downstream fact-checking tasks of\nevidence retrieval and the article's veracity prediction by the pipeline. Our\nfindings suggest that the top 3 ranked sentences contain enough information for\nevidence-based fact-checking of a fake news article. We also show that while\nthe headline has more gisting similarity with how a fact-checking website\nwrites a claim, the summary-based pipeline is the most promising for an\nend-to-end fact-checking system.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Archita Pathak",
      "Rohini K. Srihari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.01706"
  },
  {
    "id": "arXiv:2111.01714",
    "title": "Meta-Learning the Search Distribution of Black-Box Random Search Based  Adversarial Attacks",
    "abstract": "Adversarial attacks based on randomized search schemes have obtained\nstate-of-the-art results in black-box robustness evaluation recently. However,\nas we demonstrate in this work, their efficiency in different query budget\nregimes depends on manual design and heuristic tuning of the underlying\nproposal distributions. We study how this issue can be addressed by adapting\nthe proposal distribution online based on the information obtained during the\nattack. We consider Square Attack, which is a state-of-the-art score-based\nblack-box attack, and demonstrate how its performance can be improved by a\nlearned controller that adjusts the parameters of the proposal distribution\nonline during the attack. We train the controller using gradient-based\nend-to-end training on a CIFAR10 model with white box access. We demonstrate\nthat plugging the learned controller into the attack consistently improves its\nblack-box robustness estimate in different query regimes by up to 20% for a\nwide range of different models with black-box access. We further show that the\nlearned adaptation principle transfers well to the other data distributions\nsuch as CIFAR100 or ImageNet and to the targeted attack setting.",
    "descriptor": "\nComments: accepted at NeurIPS 2021\n",
    "authors": [
      "Maksym Yatsura",
      "Jan Hendrik Metzen",
      "Matthias Hein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01714"
  },
  {
    "id": "arXiv:2111.01715",
    "title": "Absolute distance prediction based on deep learning object detection and  monocular depth estimation models",
    "abstract": "Determining the distance between the objects in a scene and the camera sensor\nfrom 2D images is feasible by estimating depth images using stereo cameras or\n3D cameras. The outcome of depth estimation is relative distances that can be\nused to calculate absolute distances to be applicable in reality. However,\ndistance estimation is very challenging using 2D monocular cameras. This paper\npresents a deep learning framework that consists of two deep networks for depth\nestimation and object detection using a single image. Firstly, objects in the\nscene are detected and localized using the You Only Look Once (YOLOv5) network.\nIn parallel, the estimated depth image is computed using a deep autoencoder\nnetwork to detect the relative distances. The proposed object detection based\nYOLO was trained using a supervised learning technique, in turn, the network of\ndepth estimation was self-supervised training. The presented distance\nestimation framework was evaluated on real images of outdoor scenes. The\nachieved results show that the proposed framework is promising and it yields an\naccuracy of 96% with RMSE of 0.203 of the correct absolute distance.",
    "descriptor": "\nComments: 10 pages, Submitted to 23rd International Conference of the Catalan Association for Artificial Intelligence (CCIA 2021)\n",
    "authors": [
      "Armin Masoumian",
      "David G. F. Marei",
      "Saddam Abdulwahab",
      "Julian Cristiano",
      "Domenec Puig",
      "Hatem A. Rashwan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01715"
  },
  {
    "id": "arXiv:2111.01717",
    "title": "MixFace: Improving Face Verification Focusing on Fine-grained Conditions",
    "abstract": "The performance of face recognition has become saturated for public benchmark\ndatasets such as LFW, CFP-FP, and AgeDB, owing to the rapid advances in CNNs.\nHowever, the effects of faces with various fine-grained conditions on FR models\nhave not been investigated because of the absence of such datasets. This paper\nanalyzes their effects in terms of different conditions and loss functions\nusing K-FACE, a recently introduced FR dataset with fine-grained conditions. We\npropose a novel loss function, MixFace, that combines classification and metric\nlosses. The superiority of MixFace in terms of effectiveness and robustness is\ndemonstrated experimentally on various benchmark datasets.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Junuk Jung",
      "Sungbin Son",
      "Joochan Park",
      "Yongjun Park",
      "Seonhoon Lee",
      "Heung-Seon Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01717"
  },
  {
    "id": "arXiv:2111.01718",
    "title": "Competitive Algorithms for Online Weighted Bipartite Matching and its  Variants",
    "abstract": "Online bipartite matching has been extensively studied. In the unweighted\nsetting, Karp et al. gave an optimal $(1 - 1/e)$-competitive randomized\nalgorithm. In the weighted setting, optimal algorithms have been achieved only\nunder assumptions on the edge weights. For the general case, little was known\nbeyond the trivial $1/2$-competitive greedy algorithm. Recently, Fahrbach et\nal. have presented an 0.5086-competitive algorithm (for the problem in a model,\nnamely free-disposal), overcoming the long-standing barrier of 1/2. Besides, in\ndesigning competitive algorithms for the online matching problem and its\nvariants, several techniques have been developed, in particular the primal-dual\nmethod. Specifically, Devanur et al. gave a primal-dual framework, unifying\nprevious approaches and Devanur and Jain provided another scheme for a\ngeneralization of the online matching problem.\nIn this paper, we present competitive algorithms for the online weighted\nbipartite matching in different models; in particular we achieve the optimal\n$(1-1/e)$ competitive ratio in the free-disposal model and in other model,\nnamely stochastic reward. Our work also unifies the previous approaches by the\nmean of the primal-dual technique with configuration linear programs.",
    "descriptor": "",
    "authors": [
      "Nguyen Kim Thang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.01718"
  },
  {
    "id": "arXiv:2111.01722",
    "title": "Predicting the Location of Bicycle-sharing Stations using OpenStreetMap  Data",
    "abstract": "Planning the layout of bicycle-sharing stations is a complex process,\nespecially in cities where bicycle sharing systems are just being implemented.\nUrban planners often have to make a lot of estimates based on both publicly\navailable data and privately provided data from the administration and then use\nthe Location-Allocation model popular in the field. Many municipalities in\nsmaller cities may have difficulty hiring specialists to carry out such\nplanning. This thesis proposes a new solution to streamline and facilitate the\nprocess of such planning by using spatial embedding methods. Based only on\npublicly available data from OpenStreetMap, and station layouts from 34 cities\nin Europe, a method has been developed to divide cities into micro-regions\nusing the Uber H3 discrete global grid system and to indicate regions where it\nis worth placing a station based on existing systems in different cities using\ntransfer learning. The result of the work is a mechanism to support planners in\ntheir decision making when planning a station layout with a choice of reference\ncities.",
    "descriptor": "\nComments: Codebase and interactive website available at this https URL arXiv admin note: text overlap with arXiv:2111.00990\n",
    "authors": [
      "Kamil Raczycki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.01722"
  },
  {
    "id": "arXiv:2111.01723",
    "title": "CPSeg: Cluster-free Panoptic Segmentation of 3D LiDAR Point Clouds",
    "abstract": "A fast and accurate panoptic segmentation system for LiDAR point clouds is\ncrucial for autonomous driving vehicles to understand the surrounding objects\nand scenes. Existing approaches usually rely on proposals or clustering to\nsegment foreground instances. As a result, they struggle to achieve real-time\nperformance. In this paper, we propose a novel real-time end-to-end panoptic\nsegmentation network for LiDAR point clouds, called CPSeg. In particular, CPSeg\ncomprises a shared encoder, a dual decoder, a task-aware attention module (TAM)\nand a cluster-free instance segmentation head. TAM is designed to enforce these\ntwo decoders to learn rich task-aware features for semantic and instance\nembedding. Moreover, CPSeg incorporates a new cluster-free instance\nsegmentation head to dynamically pillarize foreground points according to the\nlearned embedding. Then, it acquires instance labels by finding connected\npillars with a pairwise embedding comparison. Thus, the conventional\nproposal-based or clustering-based instance segmentation is transformed into a\nbinary segmentation problem on the pairwise embedding comparison matrix. To\nhelp the network regress instance embedding, a fast and deterministic depth\ncompletion algorithm is proposed to calculate surface normal of each point\ncloud in real-time. The proposed method is benchmarked on two large-scale\nautonomous driving datasets, namely, SemanticKITTI and nuScenes. Notably,\nextensive experimental results show that CPSeg achieves the state-of-the-art\nresults among real-time approaches on both datasets.",
    "descriptor": "",
    "authors": [
      "Enxu Li",
      "Ryan Razani",
      "Yixuan Xu",
      "Bingbing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01723"
  },
  {
    "id": "arXiv:2111.01726",
    "title": "Instructive artificial intelligence (AI) for human training, assistance,  and explainability",
    "abstract": "We propose a novel approach to explainable AI (XAI) based on the concept of\n\"instruction\" from neural networks. In this case study, we demonstrate how a\nsuperhuman neural network might instruct human trainees as an alternative to\ntraditional approaches to XAI. Specifically, an AI examines human actions and\ncalculates variations on the human strategy that lead to better performance.\nExperiments with a JHU/APL-developed AI player for the cooperative card game\nHanabi suggest this technique makes unique contributions to explainability\nwhile improving human performance. One area of focus for Instructive AI is in\nthe significant discrepancies that can arise between a human's actual strategy\nand the strategy they profess to use. This inaccurate self-assessment presents\na barrier for XAI, since explanations of an AI's strategy may not be properly\nunderstood or implemented by human recipients. We have developed and are\ntesting a novel, Instructive AI approach that estimates human strategy by\nobserving human actions. With neural networks, this allows a direct calculation\nof the changes in weights needed to improve the human strategy to better\nemulate a more successful AI. Subjected to constraints (e.g. sparsity) these\nweight changes can be interpreted as recommended changes to human strategy\n(e.g. \"value A more, and value B less\"). Instruction from AI such as this\nfunctions both to help humans perform better at tasks, but also to better\nunderstand, anticipate, and correct the actions of an AI. Results will be\npresented on AI instruction's ability to improve human decision-making and\nhuman-AI teaming in Hanabi.",
    "descriptor": "\nComments: 10 pages, 6 figures, to be published in SPIE Defense & Commercial Sensing (Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications IV) proceedings (April 2022)\n",
    "authors": [
      "Nicholas Kantack",
      "Nina Cohen",
      "Nathan Bos",
      "Corey Lowman",
      "James Everett",
      "Timothy Endres"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01726"
  },
  {
    "id": "arXiv:2111.01730",
    "title": "A Butterfly-Accelerated Volume Integral Equation Solver for Broad  Permittivity and Large-Scale Electromagnetic Analysis",
    "abstract": "A butterfly-accelerated volume integral equation (VIE) solver is proposed for\nfast and accurate electromagnetic (EM) analysis of scattering from\nheterogeneous objects. The proposed solver leverages the hierarchical\noff-diagonal butterfly (HOD-BF) scheme to construct the system matrix and\nobtain its approximate inverse, used as a preconditioner. Complexity analysis\nand numerical experiments validate the $O(N\\log^2N)$ construction cost of the\nHOD-BF-compressed system matrix and $O(N^{1.5}\\log N)$ inversion cost for the\npreconditioner, where $N$ is the number of unknowns in the high-frequency EM\nscattering problem. For many practical scenarios, the proposed VIE solver\nrequires less memory and computational time to construct the system matrix and\nobtain its approximate inverse compared to a $\\mathcal{H}$ matrix-accelerated\nVIE solver. The accuracy and efficiency of the proposed solver have been\ndemonstrated via its application to the EM analysis of large-scale canonical\nand real-world structures comprising of broad permittivity values and involving\nmillions of unknowns.",
    "descriptor": "",
    "authors": [
      "Sadeed B. Sayed",
      "Yang Liu",
      "Luis J. Gomez",
      "Abdulkadir C. Yucel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.01730"
  },
  {
    "id": "arXiv:2111.01732",
    "title": "Spatio-Temporal Variational Gaussian Processes",
    "abstract": "We introduce a scalable approach to Gaussian process inference that combines\nspatio-temporal filtering with natural gradient variational inference,\nresulting in a non-conjugate GP method for multivariate data that scales\nlinearly with respect to time. Our natural gradient approach enables\napplication of parallel filtering and smoothing, further reducing the temporal\nspan complexity to be logarithmic in the number of time steps. We derive a\nsparse approximation that constructs a state-space model over a reduced set of\nspatial inducing points, and show that for separable Markov kernels the full\nand sparse cases exactly recover the standard variational GP, whilst exhibiting\nfavourable computational properties. To further improve the spatial scaling we\npropose a mean-field assumption of independence between spatial locations\nwhich, when coupled with sparsity and parallelisation, leads to an efficient\nand accurate method for large spatio-temporal problems.",
    "descriptor": "",
    "authors": [
      "Oliver Hamelijnck",
      "William J. Wilkinson",
      "Niki A. Loppi",
      "Arno Solin",
      "Theodoros Damoulas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01732"
  },
  {
    "id": "arXiv:2111.01740",
    "title": "Personalized One-Shot Lipreading for an ALS Patient",
    "abstract": "Lipreading or visually recognizing speech from the mouth movements of a\nspeaker is a challenging and mentally taxing task. Unfortunately, multiple\nmedical conditions force people to depend on this skill in their day-to-day\nlives for essential communication. Patients suffering from Amyotrophic Lateral\nSclerosis (ALS) often lose muscle control, consequently their ability to\ngenerate speech and communicate via lip movements. Existing large datasets do\nnot focus on medical patients or curate personalized vocabulary relevant to an\nindividual. Collecting a large-scale dataset of a patient, needed to train\nmod-ern data-hungry deep learning models is, however, extremely challenging. In\nthis work, we propose a personalized network to lipread an ALS patient using\nonly one-shot examples. We depend on synthetically generated lip movements to\naugment the one-shot scenario. A Variational Encoder based domain adaptation\ntechnique is used to bridge the real-synthetic domain gap. Our approach\nsignificantly improves and achieves high top-5accuracy with 83.2% accuracy\ncompared to 62.6% achieved by comparable methods for the patient. Apart from\nevaluating our approach on the ALS patient, we also extend it to people with\nhearing impairment relying extensively on lip movements to communicate.",
    "descriptor": "",
    "authors": [
      "Bipasha Sen",
      "Aditya Agarwal",
      "Rudrabha Mukhopadhyay",
      "Vinay Namboodiri",
      "C V Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.01740"
  },
  {
    "id": "arXiv:2111.01742",
    "title": "LogAvgExp Provides a Principled and Performant Global Pooling Operator",
    "abstract": "We seek to improve the pooling operation in neural networks, by applying a\nmore theoretically justified operator. We demonstrate that LogSumExp provides a\nnatural OR operator for logits. When one corrects for the number of elements\ninside the pooling operator, this becomes $\\text{LogAvgExp} :=\n\\log(\\text{mean}(\\exp(x)))$. By introducing a single temperature parameter,\nLogAvgExp smoothly transitions from the max of its operands to the mean (found\nat the limiting cases $t \\to 0^+$ and $t \\to +\\infty$). We experimentally\ntested LogAvgExp, both with and without a learnable temperature parameter, in a\nvariety of deep neural network architectures for computer vision.",
    "descriptor": "",
    "authors": [
      "Scott C. Lowe",
      "Thomas Trappenberg",
      "Sageev Oore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01742"
  },
  {
    "id": "arXiv:2111.01743",
    "title": "Designing Inherently Interpretable Machine Learning Models",
    "abstract": "Interpretable machine learning (IML) becomes increasingly important in highly\nregulated industry sectors related to the health and safety or fundamental\nrights of human beings. In general, the inherently IML models should be adopted\nbecause of their transparency and explainability, while black-box models with\nmodel-agnostic explainability can be more difficult to defend under regulatory\nscrutiny. For assessing inherent interpretability of a machine learning model,\nwe propose a qualitative template based on feature effects and model\narchitecture constraints. It provides the design principles for\nhigh-performance IML model development, with examples given by reviewing our\nrecent works on ExNN, GAMI-Net, SIMTree, and the Aletheia toolkit for local\nlinear interpretability of deep ReLU networks. We further demonstrate how to\ndesign an interpretable ReLU DNN model with evaluation of conceptual soundness\nfor a real case study of predicting credit default in home lending. We hope\nthat this work will provide a practical guide of developing inherently IML\nmodels in high risk applications in banking industry, as well as other sectors.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2011.04041\n",
    "authors": [
      "Agus Sudjianto",
      "Aijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01743"
  },
  {
    "id": "arXiv:2111.01744",
    "title": "UnProjection: Leveraging Inverse-Projections for Visual Analytics of  High-Dimensional Data",
    "abstract": "Projection techniques are often used to visualize high-dimensional data,\nallowing users to better understand the overall structure of multi-dimensional\nspaces on a 2D screen. Although many such methods exist, comparably little work\nhas been done on generalizable methods of inverse-projection -- the process of\nmapping the projected points, or more generally, the projection space back to\nthe original high-dimensional space. In this paper we present NNInv, a deep\nlearning technique with the ability to approximate the inverse of any\nprojection or mapping. NNInv learns to reconstruct high-dimensional data from\nany arbitrary point on a 2D projection space, giving users the ability to\ninteract with the learned high-dimensional representation in a visual analytics\nsystem. We provide an analysis of the parameter space of NNInv, and offer\nguidance in selecting these parameters. We extend validation of the\neffectiveness of NNInv through a series of quantitative and qualitative\nanalyses. We then demonstrate the method's utility by applying it to three\nvisualization tasks: interactive instance interpolation, classifier agreement,\nand gradient visualization.",
    "descriptor": "",
    "authors": [
      "Mateus Espadoto",
      "Gabriel Appleby",
      "Ashley Suh",
      "Dylan Cashman",
      "Mingwei Li",
      "Carlos Scheidegger",
      "Erik W Anderson",
      "Remco Chang",
      "Alexandru C Telea"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01744"
  },
  {
    "id": "arXiv:2111.01750",
    "title": "Spiking Generative Adversarial Networks With a Neural Network  Discriminator: Local Training, Bayesian Models, and Continual Meta-Learning",
    "abstract": "Neuromorphic data carries information in spatio-temporal patterns encoded by\nspikes. Accordingly, a central problem in neuromorphic computing is training\nspiking neural networks (SNNs) to reproduce spatio-temporal spiking patterns in\nresponse to given spiking stimuli. Most existing approaches model the\ninput-output behavior of an SNN in a deterministic fashion by assigning each\ninput to a specific desired output spiking sequence. In contrast, in order to\nfully leverage the time-encoding capacity of spikes, this work proposes to\ntrain SNNs so as to match distributions of spiking signals rather than\nindividual spiking signals. To this end, the paper introduces a novel hybrid\narchitecture comprising a conditional generator, implemented via an SNN, and a\ndiscriminator, implemented by a conventional artificial neural network (ANN).\nThe role of the ANN is to provide feedback during training to the SNN within an\nadversarial iterative learning strategy that follows the principle of\ngenerative adversarial network (GANs). In order to better capture multi-modal\nspatio-temporal distribution, the proposed approach -- termed SpikeGAN -- is\nfurther extended to support Bayesian learning of the generator's weight.\nFinally, settings with time-varying statistics are addressed by proposing an\nonline meta-learning variant of SpikeGAN. Experiments bring insights into the\nmerits of the proposed approach as compared to existing solutions based on\n(static) belief networks and maximum likelihood (or empirical risk\nminimization).",
    "descriptor": "",
    "authors": [
      "Bleema Rosenfeld",
      "Osvaldo Simeone",
      "Bipin Rajendran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.01750"
  },
  {
    "id": "arXiv:2111.01754",
    "title": "Meta-Learning to Improve Pre-Training",
    "abstract": "Pre-training (PT) followed by fine-tuning (FT) is an effective method for\ntraining neural networks, and has led to significant performance improvements\nin many domains. PT can incorporate various design choices such as task and\ndata reweighting strategies, augmentation policies, and noise models, all of\nwhich can significantly impact the quality of representations learned. The\nhyperparameters introduced by these strategies therefore must be tuned\nappropriately. However, setting the values of these hyperparameters is\nchallenging. Most existing methods either struggle to scale to high dimensions,\nare too slow and memory-intensive, or cannot be directly applied to the\ntwo-stage PT and FT learning process. In this work, we propose an efficient,\ngradient-based algorithm to meta-learn PT hyperparameters. We formalize the PT\nhyperparameter optimization problem and propose a novel method to obtain PT\nhyperparameter gradients by combining implicit differentiation and\nbackpropagation through unrolled optimization. We demonstrate that our method\nimproves predictive performance on two real-world domains. First, we optimize\nhigh-dimensional task weighting hyperparameters for multitask pre-training on\nprotein-protein interaction graphs and improve AUROC by up to 3.9%. Second, we\noptimize a data augmentation neural network for self-supervised PT with SimCLR\non electrocardiography data and improve AUROC by up to 1.9%.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Aniruddh Raghu",
      "Jonathan Lorraine",
      "Simon Kornblith",
      "Matthew McDermott",
      "David Duvenaud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01754"
  },
  {
    "id": "arXiv:2111.01758",
    "title": "Universal Path Gain Laws for Common Wireless Communication Environments",
    "abstract": "Simple and accurate expressions for path gain are derived from\nelectromagnetic fundamentals in a wide variety of common environments,\nincluding Line-of-Sight (LOS) and Non-Line-of-Sight (NLOS) indoor urban\ncanyons, urban/rural macro, outdoor-indoor and suburban streets with\nvegetation. Penetration into a scattering region, sometimes aided by guiding,\nis the \"universal\" phenomenon shared by the diverse morphologies. Root Mean\nSquare (RMS) errors against extensive measurements are under 5 dB, better than\n3GPP models by 1-12 dB RMS, depending on environment. In urban canyons the\nmodels have 4.7 dB RMS error, as compared to 7.9 dB from linear fit to data and\n13.9/17.2 dB from LOS/NLOS 3GPP models. The theoretical path gains depend on\ndistance as a power law with exponents from a small set {1.5, 2, 2.5, 4},\nspecific to each morphology. This provides a theoretical justification for\nwidely used power law empirical models. Only coarse environmental data is\nneeded as parameters: street width, building height, vegetation depth, wall\nmaterial and antenna heights.",
    "descriptor": "\nComments: accepted for publication in IEEE Transactions on Antennas and Propagation\n",
    "authors": [
      "Dmitry Chizhik",
      "Jinfeng Du",
      "Reinaldo A. Valenzuela"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.01758"
  },
  {
    "id": "arXiv:2111.01759",
    "title": "Truly Low-Space Element Distinctness and Subset Sum via Pseudorandom  Hash Functions",
    "abstract": "We consider low-space algorithms for the classic Element Distinctness\nproblem: given an array of $n$ input integers with $O(\\log n)$ bit-length,\ndecide whether or not all elements are pairwise distinct. Beame, Clifford, and\nMachmouchi [FOCS 2013] gave an $\\tilde O(n^{1.5})$-time randomized algorithm\nfor Element Distinctness using only $O(\\log n)$ bits of working space. However,\ntheir algorithm assumes a random oracle (in particular, read-only random access\nto polynomially many random bits), and it was asked as an open question whether\nthis assumption can be removed.\nIn this paper, we positively answer this question by giving an $\\tilde\nO(n^{1.5})$-time randomized algorithm using $O(\\log ^3 n\\log \\log n)$ bits of\nspace, with one-way access to random bits. As a corollary, we also obtain a\n$\\operatorname{\\mathrm{poly}}(n)$-space $O^*(2^{0.86n})$-time randomized\nalgorithm for the Subset Sum problem, removing the random oracles required in\nthe algorithm of Bansal, Garg, Nederlof, and Vyas [STOC 2017].\nThe main technique underlying our results is a pseudorandom hash family based\non iterative restrictions, which can fool the cycle-finding procedure in the\nalgorithms of Beame et al. and Bansal et al.",
    "descriptor": "\nComments: To appear in SODA 2022\n",
    "authors": [
      "Lijie Chen",
      "Ce Jin",
      "R. Ryan Williams",
      "Hongxun Wu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.01759"
  },
  {
    "id": "arXiv:2111.01760",
    "title": "Increasing Liquid State Machine Performance with Edge-of-Chaos Dynamics  Organized by Astrocyte-modulated Plasticity",
    "abstract": "The liquid state machine (LSM) combines low training complexity and\nbiological plausibility, which has made it an attractive machine learning\nframework for edge and neuromorphic computing paradigms. Originally proposed as\na model of brain computation, the LSM tunes its internal weights without\nbackpropagation of gradients, which results in lower performance compared to\nmulti-layer neural networks. Recent findings in neuroscience suggest that\nastrocytes, a long-neglected non-neuronal brain cell, modulate synaptic\nplasticity and brain dynamics, tuning brain networks to the vicinity of the\ncomputationally optimal critical phase transition between order and chaos.\nInspired by this disruptive understanding of how brain networks self-tune, we\npropose the neuron-astrocyte liquid state machine (NALSM) that addresses\nunder-performance through self-organized near-critical dynamics. Similar to its\nbiological counterpart, the astrocyte model integrates neuronal activity and\nprovides global feedback to spike-timing-dependent plasticity (STDP), which\nself-organizes NALSM dynamics around a critical branching factor that is\nassociated with the edge-of-chaos. We demonstrate that NALSM achieves\nstate-of-the-art accuracy versus comparable LSM methods, without the need for\ndata-specific hand-tuning. With a top accuracy of 97.61% on MNIST, 97.51% on\nN-MNIST, and 85.84% on Fashion-MNIST, NALSM achieved comparable performance to\ncurrent fully-connected multi-layer spiking neural networks trained via\nbackpropagation. Our findings suggest that the further development of\nbrain-inspired machine learning methods has the potential to reach the\nperformance of deep learning, with the added benefits of supporting robust and\nenergy-efficient neuromorphic computing on the edge.",
    "descriptor": "\nComments: 23 pages, 9 figures, NeurIPS 2021\n",
    "authors": [
      "Vladimir A. Ivanov",
      "Konstantinos P. Michmizos"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2111.01760"
  },
  {
    "id": "arXiv:2111.01761",
    "title": "Two neural-network-based methods for solving obstacle problems",
    "abstract": "Two neural-network-based numerical schemes are proposed to solve the\nclassical obstacle problems. The schemes are based on the universal\napproximation property of neural networks, and the cost functions are taken as\nthe energy minimization of the obstacle problems. We rigorously prove the\nconvergence of the two schemes and derive the convergence rates with the number\nof neurons $N$. In the simulations, we use two example problems (1-D & 2-D) to\nverify the convergence rate of the methods and the quality of the results.",
    "descriptor": "",
    "authors": [
      "Xinyue Evelyn Zhao",
      "Wenrui Hao",
      "Bei Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.01761"
  },
  {
    "id": "arXiv:2111.01763",
    "title": "Modelling COVID-19 Pandemic Dynamics Using Transparent, Interpretable,  Parsimonious and Simulatable (TIPS) Machine Learning Models: A Case Study  from Systems Thinking and System Identification Perspectives",
    "abstract": "Since the outbreak of COVID-19, an astronomical number of publications on the\npandemic dynamics appeared in the literature, of which many use the susceptible\ninfected removed (SIR) and susceptible exposed infected removed (SEIR) models,\nor their variants, to simulate and study the spread of the coronavirus. SIR and\nSEIR are continuous-time models which are a class of initial value problems\n(IVPs) of ordinary differential equations (ODEs). Discrete-time models such as\nregression and machine learning have also been applied to analyze COVID-19\npandemic data (e.g. predicting infection cases), but most of these methods use\nsimplified models involving a small number of input variables pre-selected\nbased on a priori knowledge, or use very complicated models (e.g. deep\nlearning), purely focusing on certain prediction purposes and paying little\nattention to the model interpretability. There have been relatively fewer\nstudies focusing on the investigations of the inherent time-lagged or\ntime-delayed relationships e.g. between the reproduction number (R number),\ninfection cases, and deaths, analyzing the pandemic spread from a systems\nthinking and dynamic perspective. The present study, for the first time,\nproposes using systems engineering and system identification approach to build\ntransparent, interpretable, parsimonious and simulatable (TIPS) dynamic machine\nlearning models, establishing links between the R number, the infection cases\nand deaths caused by COVID-19. The TIPS models are developed based on the\nwell-known NARMAX (Nonlinear AutoRegressive Moving Average with eXogenous\ninputs) model, which can help better understand the COVID-19 pandemic dynamics.\nA case study on the UK COVID-19 data is carried out, and new findings are\ndetailed. The proposed method and the associated new findings are useful for\nbetter understanding the spread dynamics of the COVID-19 pandemic.",
    "descriptor": "\nComments: 14 pages, 4 figures, 2 tables\n",
    "authors": [
      "Hua-Liang Wei",
      "S.A. Billings"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.01763"
  },
  {
    "id": "arXiv:2111.01773",
    "title": "Data-Driven System Identification of 6-DoF Ship Motion in Waves with  Neural Networks",
    "abstract": "Critical evaluation and understanding of ship responses in the ocean is\nimportant for not only the design and engineering of future platforms but also\nthe operation and safety of those that are currently deployed. Simulations or\nexperiments are typically performed in nominal sea conditions during ship\ndesign or prior to deployment and the results may not be reflective of the\ninstantaneous state of the vessel and the ocean environment while deployed.\nShort-term temporal predictions of ship responses given the current wave\nenvironment and ship state would enable enhanced decision-making onboard for\nboth manned and unmanned vessels. However, the current state-of-the-art in\nnumerical hydrodynamic simulation tools are too computationally expensive to be\nemployed for real-time ship motion forecasting and the computationally\nefficient tools are too low fidelity to provide accurate responses. A\nmethodology is developed with long short-term memory (LSTM) neural networks to\nrepresent the motions of a free running David Taylor Model Basin (DTMB) 5415\ndestroyer operating at 20 knots in Sea State 7 stern-quartering irregular seas.\nCase studies are performed for both course-keeping and turning circle\nscenarios. An estimate of the vessel's encounter frame is made with the\ntrajectories observed in the training dataset. Wave elevation time histories\nare given by artificial wave probes that travel with the estimated encounter\nframe and serve as input into the neural network, while the output is the 6-DOF\ntemporal ship motion response. Overall, the neural network is able to predict\nthe temporal response of the ship due to unseen waves accurately, which makes\nthis methodology suitable for system identification and real-time ship motion\nforecasting. The methodology, the dependence of model accuracy on wave probe\nand training data quantity and the estimated encounter frame are all detailed.",
    "descriptor": "",
    "authors": [
      "Kevin M. Silva",
      "Kevin J. Maki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.01773"
  },
  {
    "id": "arXiv:2111.01777",
    "title": "A Framework for Real-World Multi-Robot Systems Running Decentralized  GNN-Based Policies",
    "abstract": "Graph Neural Networks (GNNs) are a paradigm-shifting neural architecture to\nfacilitate the learning of complex multi-agent behaviors. Recent work has\ndemonstrated remarkable performance in tasks such as flocking, multi-agent path\nplanning and cooperative coverage. However, the policies derived through\nGNN-based learning schemes have not yet been deployed to the real-world on\nphysical multi-robot systems. In this work, we present the design of a system\nthat allows for fully decentralized execution of GNN-based policies. We create\na framework based on ROS2 and elaborate its details in this paper. We\ndemonstrate our framework on a case-study that requires tight coordination\nbetween robots, and present first-of-a-kind results that show successful\nreal-world deployment of GNN-based policies on a decentralized multi-robot\nsystem relying on Adhoc communication. A video demonstration of this case-study\ncan be found online. https://www.youtube.com/watch?v=COh-WLn4iO4",
    "descriptor": "\nComments: Submitted to IEEE ICRA (International Conference on Robotics and Automation) 2022\n",
    "authors": [
      "Jan Blumenkamp",
      "Steven Morad",
      "Jennifer Gielis",
      "Qingbiao Li",
      "Amanda Prorok"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01777"
  },
  {
    "id": "arXiv:2111.01778",
    "title": "Location inference on social media data for agile monitoring of public  health crises: An application to opioid use and abuse during the Covid-19  pandemic",
    "abstract": "The Covid-19 pandemic has intersected with the opioid epidemic to create a\nunique public health crisis, with the health and economic consequences of the\nvirus and associated lockdowns compounding pre-existing social and economic\nstressors associated with rising opioid and heroin use and abuse. In order to\nbetter understand these interlocking crises, we use social media data to\nextract qualitative and quantitative insights on the experiences of opioid\nusers during the Covid-19 pandemic. In particular, we use an unsupervised\nlearning approach to create a rich geolocated data source for public health\nsurveillance and analysis. To do this we first infer the location of 26,000\nReddit users that participate in opiate-related sub-communities (subreddits) by\ncombining named entity recognition, geocoding, density-based clustering, and\nheuristic methods. Our strategy achieves 63 percent accuracy at state-level\nlocation inference on a manually-annotated reference dataset. We then leverage\nthe geospatial nature of our user cohort to answer policy-relevant questions\nabout the impact of varying state-level policy approaches that balance economic\nversus health concerns during Covid-19. We find that state government\nstrategies that prioritized economic reopening over curtailing the spread of\nthe virus created a markedly different environment and outcomes for opioid\nusers. Our results demonstrate that geospatial social media data can be used\nfor agile monitoring of complex public health crises.",
    "descriptor": "\nComments: 10 pages, 7 figures, 5 tables\n",
    "authors": [
      "Angela E. Kilby",
      "Charlie Denhart"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2111.01778"
  },
  {
    "id": "arXiv:2111.01780",
    "title": "Game of Life on Graphs",
    "abstract": "We consider a specific graph dynamical system inspired by the famous Conway's\nGame of Life in this work. We study the properties of the dynamical system on\ndifferent graphs and introduce a new efficient heuristic for graph isomorphism\ntesting. We use the evolution of our system to extract features from a graph in\na deterministic way and observe that the extracted features are unique and the\ndistance induced by that features satisfy triangle inequality for all connected\ngraphs with up to ten vertices.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Mikhail Krechetov"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.01780"
  },
  {
    "id": "arXiv:2111.01784",
    "title": "Towards the 5/6-Density Conjecture of Pinwheel Scheduling",
    "abstract": "Pinwheel Scheduling aims to find a perpetual schedule for unit-length tasks\non a single machine subject to given maximal time spans (a.k.a. frequencies)\nbetween any two consecutive executions of the same task. The density of a\nPinwheel Scheduling instance is the sum of the inverses of these task\nfrequencies; the 5/6-Conjecture (Chan and Chin, 1993) states that any Pinwheel\nScheduling instance with density at most 5/6 is schedulable. We formalize the\nnotion of Pareto surfaces for Pinwheel Scheduling and exploit novel structural\ninsights to engineer an efficient algorithm for computing them. This allows us\nto (1) confirm the 5/6-Conjecture for all Pinwheel Scheduling instances with at\nmost 12 tasks and (2) to prove that a given list of only 23 schedules solves\nall schedulable Pinwheel Scheduling instances with at most 5 tasks.",
    "descriptor": "\nComments: Accepted at ALENEX 2022\n",
    "authors": [
      "Leszek G\u0105sieniec",
      "Benjamin Smith",
      "Sebastian Wild"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.01784"
  },
  {
    "id": "arXiv:2111.01785",
    "title": "PatchGame: Learning to Signal Mid-level Patches in Referential Games",
    "abstract": "We study a referential game (a type of signaling game) where two agents\ncommunicate with each other via a discrete bottleneck to achieve a common goal.\nIn our referential game, the goal of the speaker is to compose a message or a\nsymbolic representation of \"important\" image patches, while the task for the\nlistener is to match the speaker's message to a different view of the same\nimage. We show that it is indeed possible for the two agents to develop a\ncommunication protocol without explicit or implicit supervision. We further\ninvestigate the developed protocol and show the applications in speeding up\nrecent Vision Transformers by using only important patches, and as pre-training\nfor downstream recognition tasks (e.g., classification). Code available at\nhttps://github.com/kampta/PatchGame.",
    "descriptor": "\nComments: To appear at NeurIPS 2021\n",
    "authors": [
      "Kamal Gupta",
      "Gowthami Somepalli",
      "Anubhav Gupta",
      "Vinoj Jayasundara",
      "Matthias Zwicker",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01785"
  },
  {
    "id": "arXiv:2111.00459",
    "title": "Graph Neural Network based scheduling : Improved throughput under a  generalized interference model",
    "abstract": "In this work, we propose a Graph Convolutional Neural Networks (GCN) based\nscheduling algorithm for adhoc networks. In particular, we consider a\ngeneralized interference model called the $k$-tolerant conflict graph model and\ndesign an efficient approximation for the well-known Max-Weight scheduling\nalgorithm. A notable feature of this work is that the proposed method do not\nrequire labelled data set (NP-hard to compute) for training the neural network.\nInstead, we design a loss function that utilises the existing greedy approaches\nand trains a GCN that improves the performance of greedy approaches. Our\nextensive numerical experiments illustrate that using our GCN approach, we can\nsignificantly ($4$-$20$ percent) improve the performance of the conventional\ngreedy approach.",
    "descriptor": "\nComments: 10 pages, Accepted at EAI VALUETOOLS 2021 - 14th EAI International Conference on Performance Evaluation Methodologies and Tools\n",
    "authors": [
      "S. Ramakrishnan",
      "Jaswanthi Mandalapu",
      "Subrahmanya Swamy Peruru",
      "Bhavesh Jain",
      "Eitan Altman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.00459"
  },
  {
    "id": "arXiv:2111.01134",
    "title": "Comparing Bayesian Models for Organ Contouring in Headand Neck  Radiotherapy",
    "abstract": "Deep learning models for organ contouring in radiotherapy are poised for\nclinical usage, but currently, there exist few tools for automated quality\nassessment (QA) of the predicted contours. Using Bayesian models and their\nassociated uncertainty, one can potentially automate the process of detecting\ninaccurate predictions. We investigate two Bayesian models for auto-contouring,\nDropOut and FlipOut, using a quantitative measure - expected calibration error\n(ECE) and a qualitative measure - region-based accuracy-vs-uncertainty (R-AvU)\ngraphs. It is well understood that a model should have low ECE to be considered\ntrustworthy. However, in a QA context, a model should also have high\nuncertainty in inaccurate regions and low uncertainty in accurate regions. Such\nbehaviour could direct visual attention of expert users to potentially\ninaccurate regions, leading to a speed up in the QA process. Using R-AvU\ngraphs, we qualitatively compare the behaviour of different models in accurate\nand inaccurate regions. Experiments are conducted on the MICCAI2015 Head and\nNeck Segmentation Challenge and on the DeepMindTCIA CT dataset using three\nmodels: DropOut-DICE, Dropout-CE (Cross Entropy) and FlipOut-CE. Quantitative\nresults show that DropOut-DICE has the highest ECE, while Dropout-CE and\nFlipOut-CE have the lowest ECE. To better understand the difference between\nDropOut-CE and FlipOut-CE, we use the R-AvU graph which shows that FlipOut-CE\nhas better uncertainty coverage in inaccurate regions than DropOut-CE. Such a\ncombination of quantitative and qualitative metrics explores a new approach\nthat helps to select which model can be deployed as a QA tool in clinical\nsettings.",
    "descriptor": "\nComments: 4 pages, 3 figures, To be published in \"SPIE Medical Imaging 2022\"\n",
    "authors": [
      "Prerak Mody",
      "Nicolas Chaves-de-Plaza",
      "Klaus Hildebrandt",
      "Rene van Egmond",
      "Huib de Ridder",
      "Marius Staring"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01134"
  },
  {
    "id": "arXiv:2111.01137",
    "title": "Stock Price Prediction Using Time Series, Econometric, Machine Learning,  and Deep Learning Models",
    "abstract": "For a long-time, researchers have been developing a reliable and accurate\npredictive model for stock price prediction. According to the literature, if\npredictive models are correctly designed and refined, they can painstakingly\nand faithfully estimate future stock values. This paper demonstrates a set of\ntime series, econometric, and various learning-based models for stock price\nprediction. The data of Infosys, ICICI, and SUN PHARMA from the period of\nJanuary 2004 to December 2019 was used here for training and testing the models\nto know which model performs best in which sector. One time series model\n(Holt-Winters Exponential Smoothing), one econometric model (ARIMA), two\nmachine Learning models (Random Forest and MARS), and two deep learning-based\nmodels (simple RNN and LSTM) have been included in this paper. MARS has been\nproved to be the best performing machine learning model, while LSTM has proved\nto be the best performing deep learning model. But overall, for all three\nsectors - IT (on Infosys data), Banking (on ICICI data), and Health (on SUN\nPHARMA data), MARS has proved to be the best performing model in sales\nforecasting.",
    "descriptor": "\nComments: This is the accepted version of our paper in the international conference, IEEE Mysurucon'21, which was organized in Hassan, Karnataka, India from October 24, 2021 to October 25, 2021. The paper is 8 pages long, and it contains 20 figures and 22 tables. This is the preprint of the conference paper\n",
    "authors": [
      "Ananda Chatterjee",
      "Hrisav Bhowmick",
      "Jaydip Sen"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2111.01137"
  },
  {
    "id": "arXiv:2111.01187",
    "title": "Safe PDE Backstepping QP Control with High Relative Degree CBFs: Stefan  Model with Actuator Dynamics",
    "abstract": "High-relative-degree control barrier functions (hi-rel-deg CBFs) play a\nprominent role in automotive safety and in robotics. In this paper we launch a\ngeneralization of this concept for PDE control, treating a specific,\nphysically-relevant model of thermal dynamics where the boundary of the PDE\nmoves due to a liquid-solid phase change -- the so-called Stefan model. The\nfamiliar QP design is employed to ensure safety but with CBFs that are\ninfinite-dimensional (including one control barrier \"functional\") and with safe\nsets that are infinite-dimensional as well. Since, in the presence of actuator\ndynamics, at the boundary of the Stefan system, this system's main CBF is of\nrelative degree two, an additional CBF is constructed, by backstepping design,\nwhich ensures the positivity of all the CBFs without any additional\nrestrictions on the initial conditions. It is shown that the \"safety filter\"\ndesigned in the paper guarantees safety in the presence of an arbitrary\noperator input. This is similar to an automotive system in which a safety\nfeedback law overrides -- but only when necessary -- the possibly unsafe\nsteering, acceleration, or braking by a vigorous but inexperienced driver.\nSimulations have been performed for a process in metal additive manufacturing,\nwhich show that the operator's heat-and-cool commands to the Stefan model are\nbeing obeyed but without the liquid ever freezing.",
    "descriptor": "\nComments: 13 pages, 15 figures, submitted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Shumon Koga",
      "Miroslav Krstic"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01187"
  },
  {
    "id": "arXiv:2111.01213",
    "title": "Finite Representation Property for Relation Algebra Reducts",
    "abstract": "The decision problem of membership in the Representation Class of Relation\nAlgebras (RRA) for finite structures is undecidable. However, this does not\nhold for many Relation Algebra reduct languages. Two well known properties that\nare sufficient for decidability are the Finite Axiomatisability (FA) of the\nrepresentation class and the Finite Representation Property (FRP). Furthermore,\nneither of the properties is stronger that the other, and thus, neither is also\na necessary condition. Although many results are known in the area of FA, the\nFRP remains unknown for the majority of the reduct languages. Here we\nconjecture that the FRP fails for a Relation Algebra reduct if and only if it\ncontains both composition and negation, or both composition and meet. We then\nshow the right-to-left implication of the conjecture holds and present\npreliminary results that suggest the left-to-right implication.",
    "descriptor": "",
    "authors": [
      "Ja\u0161 \u0160emrl"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.01213"
  },
  {
    "id": "arXiv:2111.01223",
    "title": "A framework for causal segmentation analysis with machine learning in  large-scale digital experiments",
    "abstract": "We present an end-to-end methodological framework for causal segment\ndiscovery that aims to uncover differential impacts of treatments across\nsubgroups of users in large-scale digital experiments. Building on recent\ndevelopments in causal inference and non/semi-parametric statistics, our\napproach unifies two objectives: (1) the discovery of user segments that stand\nto benefit from a candidate treatment based on subgroup-specific treatment\neffects, and (2) the evaluation of causal impacts of dynamically assigning\nunits to a study's treatment arm based on their predicted segment-specific\nbenefit or harm. Our proposal is model-agnostic, capable of incorporating\nstate-of-the-art machine learning algorithms into the estimation procedure, and\nis applicable in randomized A/B tests and quasi-experiments. An open source R\npackage implementation, sherlock, is introduced.",
    "descriptor": "\nComments: Accepted by the 8th annual Conference on Digital Experimentation (CODE) at MIT\n",
    "authors": [
      "Nima S. Hejazi",
      "Wenjing Zheng",
      "Sathya Anand"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01223"
  },
  {
    "id": "arXiv:2111.01254",
    "title": "Unique Games hardness of Quantum Max-Cut, and a vector-valued Borell's  inequality",
    "abstract": "The Gaussian noise stability of a function $f:\\mathbb{R}^n \\to \\{-1, 1\\}$ is\nthe expected value of $f(\\boldsymbol{x}) \\cdot f(\\boldsymbol{y})$ over\n$\\rho$-correlated Gaussian random variables $\\boldsymbol{x}$ and\n$\\boldsymbol{y}$. Borell's inequality states that for $-1 \\leq \\rho \\leq 0$,\nthis is minimized by the halfspace $f(x) = \\mathrm{sign}(x_1)$. In this work,\nwe generalize this result to hold for functions $f:\\mathbb{R}^n \\to S^{k-1}$\nwhich output $k$-dimensional unit vectors. Our main result shows that the\nexpected value of $\\langle f(\\boldsymbol{x}), f(\\boldsymbol{y})\\rangle$ over\n$\\rho$-correlated Gaussians $\\boldsymbol{x}$ and $\\boldsymbol{y}$ is minimized\nby the function $f(x) = x_{\\leq k} / \\Vert x_{\\leq k} \\Vert$, where $x_{\\leq k}\n= (x_1, \\ldots, x_k)$.\nAs an application, we show several hardness of approximation results for\nQuantum Max-Cut, a special case of the local Hamiltonian problem related to the\nanti-ferromagnetic Heisenberg model. Quantum Max-Cut is a natural quantum\nanalogue of classical Max-Cut and has become testbed for designing quantum\napproximation algorithms. We show the following:\n1. The integrality gap of the basic SDP is $0.498$, matching an existing\nrounding algorithm. Combined with existing approximation results for Quantum\nMax-Cut, this shows that the basic SDP does not achieve the optimal\napproximation ratio.\n2. It is Unique Games-hard (UG-hard) to compute a\n$(0.956+\\varepsilon)$-approximation to the value of the best product state,\nmatching an existing approximation algorithm. This result may be viewed as\napplying to a generalization of Max-Cut where one seeks to assign\n$3$-dimensional unit vectors to each vertex; we also give tight hardness\nresults for the analogous $k$-dimensional generalization of Max-Cut.\n3. It is UG-hard to compute a $(0.956+\\varepsilon)$-approximation to the\nvalue of the best (possibly entangled) state.",
    "descriptor": "\nComments: 78 pages\n",
    "authors": [
      "Yeongwoo Hwang",
      "Joe Neeman",
      "Ojas Parekh",
      "Kevin Thompson",
      "John Wright"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.01254"
  },
  {
    "id": "arXiv:2111.01262",
    "title": "Minimax Optimization: The Case of Convex-Submodular",
    "abstract": "Minimax optimization has been central in addressing various applications in\nmachine learning, game theory, and control theory. Prior literature has thus\nfar mainly focused on studying such problems in the continuous domain, e.g.,\nconvex-concave minimax optimization is now understood to a significant extent.\nNevertheless, minimax problems extend far beyond the continuous domain to mixed\ncontinuous-discrete domains or even fully discrete domains. In this paper, we\nstudy mixed continuous-discrete minimax problems where the minimization is over\na continuous variable belonging to Euclidean space and the maximization is over\nsubsets of a given ground set. We introduce the class of convex-submodular\nminimax problems, where the objective is convex with respect to the continuous\nvariable and submodular with respect to the discrete variable. Even though such\nproblems appear frequently in machine learning applications, little is known\nabout how to address them from algorithmic and theoretical perspectives. For\nsuch problems, we first show that obtaining saddle points are hard up to any\napproximation, and thus introduce new notions of (near-) optimality. We then\nprovide several algorithmic procedures for solving convex and\nmonotone-submodular minimax problems and characterize their convergence rates,\ncomputational complexity, and quality of the final solution according to our\nnotions of optimally. Our proposed algorithms are iterative and combine tools\nfrom both discrete and continuous optimization. Finally, we provide numerical\nexperiments to showcase the effectiveness of our purposed methods.",
    "descriptor": "",
    "authors": [
      "Arman Adibi",
      "Aryan Mokhtari",
      "Hamed Hassani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01262"
  },
  {
    "id": "arXiv:2111.01266",
    "title": "Quantifying Shareability in Transportation Networks: The Maximum Network  Flow Overlap Problem",
    "abstract": "Cities across the world vary in terms of their urban forms, transportation\nnetworks, and travel demand patterns with the variation affecting the viability\nof different shared mobility modes ranging from mass transit to ridesharing.\nThis study proposes a modeling framework to quantify the shareability of person\nflows in any city as a function of two inputs--the underlying transportation\n(street) network and origin-destination (OD) travel demand in the network--as a\nfirst step toward a deeper understanding of the joint influence of these\nfactors on the viability of shared mobility modes. This study conceptualizes\nflow overlap to denote, for a person trip traversing a given path, the weighted\n(by link distance) average number of other travelers sharing the links along\nthe person's path. The study extends this concept and formulates the Maximum\nNetwork Flow Overlap Problem (MNFLOP) to assign all O-D person flows to the\nnetwork paths that maximize flow overlap in the region. The study also proposes\nan MNFLOP variant with a second objective function term, OD flow detours, to\ncapture the trade-off between minimizing travel distance/time and increasing\nshareability. The study utilizes the MNFLOP output to calculate measures of\nshareability at various levels of aggregation, including, single location,\nsingle and multiple ODs, individual links, and network level. The study applies\nthe MNFLOP to networks in Sioux Falls and Chicago. Results show that with minor\nincreases in traveler detour, it is possible to significantly increase flow\noverlap relative to assigning all OD flows to their shortest paths. Origin\nlevel measures of flow overlap indicate potential to share trips even from\nlocations with low demand, as long as the trips can be concentrated onto a few\npaths, showing that critical demand assessment for operating shared mobility\nmodes is guided by both magnitude and directionality of demand.",
    "descriptor": "",
    "authors": [
      "Navjyoth Sarma JS",
      "Michael F Hyland"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01266"
  },
  {
    "id": "arXiv:2111.01270",
    "title": "Deep learning of multi-resolution X-Ray micro-CT images for multi-scale  modelling",
    "abstract": "There are inherent field-of-view and resolution trade-offs in X-Ray\nmicro-computed tomography imaging, which limit the characterization, analysis\nand model development of multi-scale porous systems. In this paper, we overcome\nthese tradeoffs by developing a 3D Enhanced Deep Super Resolution (EDSR)\nconvolutional neural network to create enhanced, high-resolution data over\nlarge spatial scales from low-resolution data. Paired high-resolution (HR,\n2$\\mu$m) and low resolution (LR, 6$\\mu$m) image data from a Bentheimer rock\nsample are used to train the network. Unseen LR and HR data from the training\nsample, and another sample with a distinct micro-structure, are used to\nvalidate the network with various metrics: textual analysis, segmentation\nbehaviour and pore-network model (PNM) multiphase flow simulations. The\nvalidated EDSR network is used to generate ~1000 high-resolution REV subvolume\nimages for each full core sample of length 6-7cm (total image sizes are\n~6000x6000x32000 voxels). Each subvolume has distinct petrophysical properties\npredicted from PNMs, which are combined to create a 3D continuum-scale model of\neach sample. Drainage immiscible flow at low capillary number is simulated\nacross a range of fractional flows and compared directly to experimental\npressures and 3D saturations on a 1:1 basis. The EDSR generated model is more\naccurate than the base LR model at predicting experimental behaviour in the\npresence of heterogeneities, especially in flow regimes where a wide\ndistribution of pore-sizes are encountered. The models are generally accurate\nat predicting saturations to within the experimental repeatability and relative\npermeability across three orders of magnitude. The demonstrated workflow is a\nfully predictive, without calibration, and opens up the possibility to image,\nsimulate and analyse flow in truly multi-scale heterogeneous systems that are\notherwise intractable.",
    "descriptor": "\nComments: 21 pages, 9 figures\n",
    "authors": [
      "Samuel J. Jackson",
      "Yufu Niu",
      "Sojwal Manoorkar",
      "Peyman Mostaghimi",
      "Ryan T. Armstrong"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2111.01270"
  },
  {
    "id": "arXiv:2111.01275",
    "title": "Recurrent neural network models for working memory of continuous  variables: activity manifolds, connectivity patterns, and dynamic codes",
    "abstract": "Many daily activities and psychophysical experiments involve keeping multiple\nitems in working memory. When items take continuous values (e.g., orientation,\ncontrast, length, loudness) they must be stored in a continuous structure of\nappropriate dimensions. We investigate how this structure is represented in\nneural circuits by training recurrent networks to report two previously shown\nstimulus orientations. We find the activity manifold for the two orientations\nresembles a Clifford torus. Although a Clifford and standard torus (the surface\nof a donut) are topologically equivalent, they have important functional\ndifferences. A Clifford torus treats the two orientations equally and keeps\nthem in orthogonal subspaces, as demanded by the task, whereas a standard torus\ndoes not. We find and characterize the connectivity patterns that support the\nClifford torus. Moreover, in addition to attractors that store information via\npersistent activity, our networks also use a dynamic code where units change\ntheir tuning to prevent new sensory input from overwriting the previously\nstored one. We argue that such dynamic codes are generally required whenever\nmultiple inputs enter a memory system via shared connections. Finally, we apply\nour framework to a human psychophysics experiment in which subjects reported\ntwo remembered orientations. By varying the training conditions of the RNNs, we\ntest and support the hypothesis that human behavior is a product of both neural\nnoise and reliance on the more stable and behaviorally relevant memory of the\nordinal relationship between the two orientations. This suggests that suitable\ninductive biases in RNNs are important for uncovering how the human brain\nimplements working memory. Together, these results offer an understanding of\nthe neural computations underlying a class of visual decoding tasks, bridging\nthe scales from human behavior to synaptic connectivity.",
    "descriptor": "",
    "authors": [
      "Christopher J. Cueva",
      "Adel Ardalan",
      "Misha Tsodyks",
      "Ning Qian"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.01275"
  },
  {
    "id": "arXiv:2111.01320",
    "title": "AVASpeech-SMAD: A Strongly Labelled Speech and Music Activity Detection  Dataset with Label Co-Occurrence",
    "abstract": "We propose a dataset, AVASpeech-SMAD, to assist speech and music activity\ndetection research. With frame-level music labels, the proposed dataset extends\nthe existing AVASpeech dataset, which originally consists of 45 hours of audio\nand speech activity labels. To the best of our knowledge, the proposed\nAVASpeech-SMAD is the first open-source dataset that features strong polyphonic\nlabels for both music and speech. The dataset was manually annotated and\nverified via an iterative cross-checking process. A simple automatic\nexamination was also implemented to further improve the quality of the labels.\nEvaluation results from two state-of-the-art SMAD systems are also provided as\na benchmark for future reference.",
    "descriptor": "",
    "authors": [
      "Yun-Ning Hung",
      "Karn N. Watcharasupat",
      "Chih-Wei Wu",
      "Iroro Orife",
      "Kelian Li",
      "Pavan Seshadri",
      "Junyoung Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.01320"
  },
  {
    "id": "arXiv:2111.01326",
    "title": "Cross-lingual Transfer for Speech Processing using Acoustic Language  Similarity",
    "abstract": "Speech processing systems currently do not support the vast majority of\nlanguages, in part due to the lack of data in low-resource languages.\nCross-lingual transfer offers a compelling way to help bridge this digital\ndivide by incorporating high-resource data into low-resource systems. Current\ncross-lingual algorithms have shown success in text-based tasks and\nspeech-related tasks over some low-resource languages. However, scaling up\nspeech systems to support hundreds of low-resource languages remains unsolved.\nTo help bridge this gap, we propose a language similarity approach that can\nefficiently identify acoustic cross-lingual transfer pairs across hundreds of\nlanguages. We demonstrate the effectiveness of our approach in language family\nclassification, speech recognition, and speech synthesis tasks.",
    "descriptor": "",
    "authors": [
      "Peter Wu",
      "Jiatong Shi",
      "Yifan Zhong",
      "Shinji Watanabe",
      "Alan W Black"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.01326"
  },
  {
    "id": "arXiv:2111.01338",
    "title": "Federated Split Vision Transformer for COVID-19CXR Diagnosis using  Task-Agnostic Training",
    "abstract": "Federated learning, which shares the weights of the neural network across\nclients, is gaining attention in the healthcare sector as it enables training\non a large corpus of decentralized data while maintaining data privacy. For\nexample, this enables neural network training for COVID-19 diagnosis on chest\nX-ray (CXR) images without collecting patient CXR data across multiple\nhospitals. Unfortunately, the exchange of the weights quickly consumes the\nnetwork bandwidth if highly expressive network architecture is employed.\nSo-called split learning partially solves this problem by dividing a neural\nnetwork into a client and a server part, so that the client part of the network\ntakes up less extensive computation resources and bandwidth. However, it is not\nclear how to find the optimal split without sacrificing the overall network\nperformance. To amalgamate these methods and thereby maximize their distinct\nstrengths, here we show that the Vision Transformer, a recently developed deep\nlearning architecture with straightforward decomposable configuration, is\nideally suitable for split learning without sacrificing performance. Even under\nthe non-independent and identically distributed data distribution which\nemulates a real collaboration between hospitals using CXR datasets from\nmultiple sources, the proposed framework was able to attain performance\ncomparable to data-centralized training. In addition, the proposed framework\nalong with heterogeneous multi-task clients also improves individual task\nperformances including the diagnosis of COVID-19, eliminating the need for\nsharing large weights with innumerable parameters. Our results affirm the\nsuitability of Transformer for collaborative learning in medical imaging and\npave the way forward for future real-world implementations.",
    "descriptor": "",
    "authors": [
      "Sangjoon Park",
      "Gwanghyun Kim",
      "Jeongsol Kim",
      "Boah Kim",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01338"
  },
  {
    "id": "arXiv:2111.01348",
    "title": "Faster Convex Lipschitz Regression via 2-block ADMM",
    "abstract": "The task of approximating an arbitrary convex function arises in several\nlearning problems such as convex regression, learning with a difference of\nconvex (DC) functions, and approximating Bregman divergences. In this paper, we\nshow how a broad class of convex function learning problems can be solved via a\n2-block ADMM approach, where updates for each block can be computed in closed\nform. For the task of convex Lipschitz regression, we establish that our\nproposed algorithm converges at the rate of $O(n^3 d^{1.5}+n^2 d^{2.5}+n d^3)$\nfor a dataset $X \\in R^{n\\times d}$. This new rate improves the state of the\nart $O(n^5d^2$) available by interior point methods if $d = o( n^4)$. Further\nwe provide similar solvers for DC regression and Bregman divergence learning.\nUnlike previous approaches, our method is amenable to the use of GPUs. We\ndemonstrate on regression and metric learning experiments that our approach is\nup to 20 times faster than the existing method, and produces results that are\ncomparable to state-of-the-art.",
    "descriptor": "\nComments: 21 pages, 4 figures. Paper under review\n",
    "authors": [
      "Ali Siahkamari",
      "Durmus Alp Emre Acar",
      "Christopher Liao",
      "Kelly Geyer",
      "Venkatesh Saligrama",
      "Brian Kulis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01348"
  },
  {
    "id": "arXiv:2111.01350",
    "title": "Constructing High-Order Signed Distance Maps from Computed Tomography  Data with Application to Bone Morphometry",
    "abstract": "An algorithm is presented for constructing high-order signed distance fields\nfor two phase materials imaged with computed tomography. The signed distance\nfield is high-order in that it is free of the quantization artifact associated\nwith the distance transform of sampled signals. The narrowband is solved using\na closest point algorithm extended for implicit embeddings that are not a\nsigned distance field. The high-order fast sweeping algorithm is used to extend\nthe narrowband to the remainder of the domain. The order of accuracy of the\nnarrowband and extension methods are verified on ideal implicit surfaces. The\nmethod is applied to ten excised cubes of bovine trabecular bone. Localization\nof the surface, estimation of phase densities, and local morphometry is\nvalidated with these subjects. Since the embedding is high-order, gradients and\nthus curvatures can be accurately estimated locally in the image data.",
    "descriptor": "\nComments: 14 pages, 14 figures\n",
    "authors": [
      "Bryce A. Besler",
      "Tannis D. Kemp",
      "Nils D. Forkert",
      "Steven K. Boyd"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01350"
  },
  {
    "id": "arXiv:2111.01351",
    "title": "Major Depressive Disorder Recognition and Cognitive Analysis Based on  Multi-layer Brain Functional Connectivity Networks",
    "abstract": "On the increase of major depressive disorders (MDD), many researchers paid\nattention to their recognition and treatment. Existing MDD recognition\nalgorithms always use a single time-frequency domain method method, but the\nsingle time-frequency domain method is too simple and is not conducive to\nsimulating the complex link relationship between brain functions. To solve this\nproblem, this paper proposes a recognition method based on multi-layer brain\nfunctional connectivity networks (MBFCN) for major depressive disorder and\nconducts cognitive analysis. Cognitive analysis based on the proposed MBFCN\nfinds that the Alpha-Beta1 frequency band is the key sub-band for recognizing\nMDD. The connections between the right prefrontal lobe and the temporal lobe of\nthe extremely depressed disorders (EDD) are deficient in the brain functional\nconnectivity networks (BFCN) based on phase lag index (PLI). Furthermore,\npotential biomarkers by the significance analysis of depression features and\nPHQ-9 can be found.",
    "descriptor": "",
    "authors": [
      "Xiaofang Sun",
      "Xiangwei Zheng",
      "Yonghui Xu",
      "Lizhen Cui",
      "Bin Hu"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01351"
  },
  {
    "id": "arXiv:2111.01361",
    "title": "Outlier-Robust Optimal Transport: Duality, Structure, and Statistical  Applications",
    "abstract": "The Wasserstein distance, rooted in optimal transport (OT) theory, is a\npopular discrepancy measure between probability distributions with various\napplications to statistics and machine learning. Despite their rich structure\nand demonstrated utility, Wasserstein distances are sensitive to outliers in\nthe considered distributions, which hinders applicability in practice. Inspired\nby the Huber contamination model, we propose a new outlier-robust Wasserstein\ndistance $\\mathsf{W}_p^\\varepsilon$ which allows for $\\varepsilon$ outlier mass\nto be removed from each contaminated distribution. Our formulation amounts to a\nhighly regular optimization problem that lends itself better for analysis\ncompared to previously considered frameworks. Leveraging this, we conduct a\nthorough theoretical study of $\\mathsf{W}_p^\\varepsilon$, encompassing\ncharacterization of optimal perturbations, regularity, duality, and statistical\nestimation and robustness results. In particular, by decoupling the\noptimization variables, we arrive at a simple dual form for\n$\\mathsf{W}_p^\\varepsilon$ that can be implemented via an elementary\nmodification to standard, duality-based OT solvers. We illustrate the benefits\nof our framework via applications to generative modeling with contaminated\ndatasets.",
    "descriptor": "",
    "authors": [
      "Sloan Nietert",
      "Rachel Cummings",
      "Ziv Goldfeld"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01361"
  },
  {
    "id": "arXiv:2111.01374",
    "title": "A Game of Primes",
    "abstract": "The basis for most of the ideas mentioned in this paper is the theory of\ncellular automata. A cellular automata contains a regular grid of cells, with\neach cell having a pre-defined set of finite states. The initial state is\ndetermined at time/state zero. At this point all the cells are assigned their\nrespective starting states. The automata is defined by a set of simple rules\nthat decide the subsequent states of the cells. We aim to create a cellular\nautomata of prime numbers and come up with some axioms, theorems and\nconjectures for the same.",
    "descriptor": "\nComments: This paper is being reviewed by SN Computer Science\n",
    "authors": [
      "Raghavendra Bhat"
    ],
    "subjectives": [
      "General Mathematics (math.GM)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.01374"
  },
  {
    "id": "arXiv:2111.01404",
    "title": "Cascadable all-optical NAND gates using diffractive networks",
    "abstract": "Owing to its potential advantages such as scalability, low latency and power\nefficiency, optical computing has seen rapid advances over the last decades. A\ncore unit of a potential all-optical processor would be the NAND gate, which\ncan be cascaded to perform an arbitrary logical operation. Here, we present the\ndesign and analysis of cascadable all-optical NAND gates using diffractive\nneural networks. We encoded the logical values at the input and output planes\nof a diffractive NAND gate using the relative optical power of two\nspatially-separated apertures. Based on this architecture, we numerically\noptimized the design of a diffractive neural network composed of 4 passive\nlayers to all-optically perform NAND operation using the diffraction of light,\nand cascaded these diffractive NAND gates to perform complex logical functions\nby successively feeding the output of one diffractive NAND gate into another.\nWe demonstrated the cascadability of our diffractive NAND gates by using\nidentical diffractive designs to all-optically perform AND and OR operations,\nas well as a half-adder. Cascadable all-optical NAND gates composed of\nspatially-engineered passive diffractive layers can serve as a core component\nof various optical computing platforms.",
    "descriptor": "\nComments: 24 Pages, 5 Figures\n",
    "authors": [
      "Yi Luo",
      "Deniz Mengu",
      "Aydogan Ozcan"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.01404"
  },
  {
    "id": "arXiv:2111.01409",
    "title": "Efficient Learning of the Parameters of Non-Linear Models using  Differentiable Resampling in Particle Filters",
    "abstract": "It has been widely documented that the sampling and resampling steps in\nparticle filters cannot be differentiated. The {\\itshape reparameterisation\ntrick} was introduced to allow the sampling step to be reformulated into a\ndifferentiable function. We extend the {\\itshape reparameterisation trick} to\ninclude the stochastic input to resampling therefore limiting the\ndiscontinuities in the gradient calculation after this step. Knowing the\ngradients of the prior and likelihood allows us to run particle Markov Chain\nMonte Carlo (p-MCMC) and use the No-U-Turn Sampler (NUTS) as the proposal when\nestimating parameters.\nWe compare the Metropolis-adjusted Langevin algorithm (MALA), Hamiltonian\nMonte Carlo with different number of steps and NUTS. We consider two\nstate-space models and show that NUTS improves the mixing of the Markov chain\nand can produce more accurate results in less computational time.",
    "descriptor": "\nComments: 28 pages, 9 figures\n",
    "authors": [
      "Conor Rosato",
      "Paul Horridge",
      "Thomas B. Sch\u00f6n",
      "Simon Maskell"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01409"
  },
  {
    "id": "arXiv:2111.01436",
    "title": "Learning Size and Shape of Calabi-Yau Spaces",
    "abstract": "We present a new machine learning library for computing metrics of string\ncompactification spaces. We benchmark the performance on Monte-Carlo sampled\nintegrals against previous numerical approximations and find that our neural\nnetworks are more sample- and computation-efficient. We are the first to\nprovide the possibility to compute these metrics for arbitrary, user-specified\nshape and size parameters of the compact space and observe a linear relation\nbetween optimization of the partial differential equation we are training\nagainst and vanishing Ricci curvature.",
    "descriptor": "\nComments: 5 pages, 2 figures, to appear in: NeurIPS 2021 - ML4PS\n",
    "authors": [
      "Magdalena Larfors",
      "Andre Lukas",
      "Fabian Ruehle",
      "Robin Schneider"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01436"
  },
  {
    "id": "arXiv:2111.01481",
    "title": "The supersingular isogeny path and endomorphism ring problems are  equivalent",
    "abstract": "We prove that the path-finding problem in $\\ell$-isogeny graphs and the\nendomorphism ring problem for supersingular elliptic curves are equivalent\nunder reductions of polynomial expected time, assuming the generalised Riemann\nhypothesis. The presumed hardness of these problems is foundational for\nisogeny-based cryptography. As an essential tool, we develop a rigorous\nalgorithm for the quaternion analog of the path-finding problem, building upon\nthe heuristic method of Kohel, Lauter, Petit and Tignol. This problem, and its\n(previously heuristic) resolution, are both a powerful cryptanalytic tool and a\nbuilding-block for cryptosystems.",
    "descriptor": "\nComments: FOCS 2021\n",
    "authors": [
      "Benjamin Wesolowski"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.01481"
  },
  {
    "id": "arXiv:2111.01505",
    "title": "Out of distribution detection for skin and malaria images",
    "abstract": "Deep neural networks have shown promising results in disease detection and\nclassification using medical image data. However, they still suffer from the\nchallenges of handling real-world scenarios especially reliably detecting\nout-of-distribution (OoD) samples. We propose an approach to robustly classify\nOoD samples in skin and malaria images without the need to access labeled OoD\nsamples during training. Specifically, we use metric learning along with\nlogistic regression to force the deep networks to learn much rich class\nrepresentative features. To guide the learning process against the OoD\nexamples, we generate ID similar-looking examples by either removing\nclass-specific salient regions in the image or permuting image parts and\ndistancing them away from in-distribution samples. During inference time, the\nK-reciprocal nearest neighbor is employed to detect out-of-distribution\nsamples. For skin cancer OoD detection, we employ two standard benchmark skin\ncancer ISIC datasets as ID, and six different datasets with varying difficulty\nlevels were taken as out of distribution. For malaria OoD detection, we use the\nBBBC041 malaria dataset as ID and five different challenging datasets as out of\ndistribution. We achieved state-of-the-art results, improving 5% and 4% in\nTNR@TPR95% over the previous state-of-the-art for skin cancer and malaria OoD\ndetection respectively.",
    "descriptor": "",
    "authors": [
      "Muhammad Zaida",
      "Shafaqat Ali",
      "Mohsen Ali",
      "Sarfaraz Hussein",
      "Asma Saadia",
      "Waqas Sultani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01505"
  },
  {
    "id": "arXiv:2111.01511",
    "title": "ISP-Agnostic Image Reconstruction for Under-Display Cameras",
    "abstract": "Under-display cameras have been proposed in recent years as a way to reduce\nthe form factor of mobile devices while maximizing the screen area.\nUnfortunately, placing the camera behind the screen results in significant\nimage distortions, including loss of contrast, blur, noise, color shift,\nscattering artifacts, and reduced light sensitivity. In this paper, we propose\nan image-restoration pipeline that is ISP-agnostic, i.e. it can be combined\nwith any legacy ISP to produce a final image that matches the appearance of\nregular cameras using the same ISP. This is achieved with a deep learning\napproach that performs a RAW-to-RAW image restoration. To obtain large\nquantities of real under-display camera training data with sufficient contrast\nand scene diversity, we furthermore develop a data capture method utilizing an\nHDR monitor, as well as a data augmentation method to generate suitable HDR\ncontent. The monitor data is supplemented with real-world data that has less\nscene diversity but allows us to achieve fine detail recovery without being\nlimited by the monitor resolution. Together, this approach successfully\nrestores color and contrast as well as image detail.",
    "descriptor": "",
    "authors": [
      "Miao Qi",
      "Yuqi Li",
      "Wolfgang Heidrich"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01511"
  },
  {
    "id": "arXiv:2111.01533",
    "title": "A comparison of mixed-variables Bayesian optimization approaches",
    "abstract": "Most real optimization problems are defined over a mixed search space where\nthe variables are both discrete and continuous. In engineering applications,\nthe objective function is typically calculated with a numerically costly\nblack-box simulation.General mixed and costly optimization problems are\ntherefore of a great practical interest, yet their resolution remains in a\nlarge part an open scientific question. In this article, costly mixed problems\nare approached through Gaussian processes where the discrete variables are\nrelaxed into continuous latent variables. The continuous space is more easily\nharvested by classical Bayesian optimization techniques than a mixed space\nwould. Discrete variables are recovered either subsequently to the continuous\noptimization, or simultaneously with an additional continuous-discrete\ncompatibility constraint that is handled with augmented Lagrangians. Several\npossible implementations of such Bayesian mixed optimizers are compared. In\nparticular, the reformulation of the problem with continuous latent variables\nis put in competition with searches working directly in the mixed space. Among\nthe algorithms involving latent variables and an augmented Lagrangian, a\nparticular attention is devoted to the Lagrange multipliers for which a local\nand a global estimation techniques are studied. The comparisons are based on\nthe repeated optimization of three analytical functions and a beam design\nproblem.",
    "descriptor": "\nComments: Submited to AMSES : Efficient Strategies for Surrogate-Based Optimization Including Multifidelity and Reduced-Order Models\n",
    "authors": [
      "Jhouben Cuesta-Ramirez",
      "Rodolphe Le Riche",
      "Olivier Roustant",
      "Guillaume Perrin",
      "Cedric Durantin",
      "Alain Gliere"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01533"
  },
  {
    "id": "arXiv:2111.01536",
    "title": "Learning Circular Hidden Quantum Markov Models: A Tensor Network  Approach",
    "abstract": "In this paper, we propose circular Hidden Quantum Markov Models (c-HQMMs),\nwhich can be applied for modeling temporal data in quantum datasets (with\nclassical datasets as a special case). We show that c-HQMMs are equivalent to a\nconstrained tensor network (more precisely, circular Local Purified State with\npositive-semidefinite decomposition) model. This equivalence enables us to\nprovide an efficient learning model for c-HQMMs. The proposed learning approach\nis evaluated on six real datasets and demonstrates the advantage of c-HQMMs on\nmultiple datasets as compared to HQMMs, circular HMMs, and HMMs.",
    "descriptor": "",
    "authors": [
      "Mohammad Ali Javidian",
      "Vaneet Aggarwal",
      "Zubin Jacob"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01536"
  },
  {
    "id": "arXiv:2111.01544",
    "title": "Comprehensive and Clinically Accurate Head and Neck Organs at Risk  Delineation via Stratified Deep Learning: A Large-scale Multi-Institutional  Study",
    "abstract": "Accurate organ at risk (OAR) segmentation is critical to reduce the\nradiotherapy post-treatment complications. Consensus guidelines recommend a set\nof more than 40 OARs in the head and neck (H&N) region, however, due to the\npredictable prohibitive labor-cost of this task, most institutions choose a\nsubstantially simplified protocol by delineating a smaller subset of OARs and\nneglecting the dose distributions associated with other OARs. In this work we\npropose a novel, automated and highly effective stratified OAR segmentation\n(SOARS) system using deep learning to precisely delineate a comprehensive set\nof 42 H&N OARs. SOARS stratifies 42 OARs into anchor, mid-level, and small &\nhard subcategories, with specifically derived neural network architectures for\neach category by neural architecture search (NAS) principles. We built SOARS\nmodels using 176 training patients in an internal institution and independently\nevaluated on 1327 external patients across six different institutions. It\nconsistently outperformed other state-of-the-art methods by at least 3-5% in\nDice score for each institutional evaluation (up to 36% relative error\nreduction in other metrics). More importantly, extensive multi-user studies\nevidently demonstrated that 98% of the SOARS predictions need only very minor\nor no revisions for direct clinical acceptance (saving 90% radiation\noncologists workload), and their segmentation and dosimetric accuracy are\nwithin or smaller than the inter-user variation. These findings confirmed the\nstrong clinical applicability of SOARS for the OAR delineation process in H&N\ncancer radiotherapy workflows, with improved efficiency, comprehensiveness, and\nquality.",
    "descriptor": "",
    "authors": [
      "Dazhou Guo",
      "Jia Ge",
      "Xianghua Ye",
      "Senxiang Yan",
      "Yi Xin",
      "Yuchen Song",
      "Bing-shen Huang",
      "Tsung-Min Hung",
      "Zhuotun Zhu",
      "Ling Peng",
      "Yanping Ren",
      "Rui Liu",
      "Gong Zhang",
      "Mengyuan Mao",
      "Xiaohua Chen",
      "Zhongjie Lu",
      "Wenxiang Li",
      "Yuzhen Chen",
      "Lingyun Huang",
      "Jing Xiao",
      "Adam P. Harrison",
      "Le Lu",
      "Chien-Yu Lin",
      "Dakai Jin",
      "Tsung-Ying Ho"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.01544"
  },
  {
    "id": "arXiv:2111.01556",
    "title": "Accounting for Dependencies in Deep Learning Based Multiple Instance  Learning for Whole Slide Imaging",
    "abstract": "Multiple instance learning (MIL) is a key algorithm for classification of\nwhole slide images (WSI). Histology WSIs can have billions of pixels, which\ncreate enormous computational and annotation challenges. Typically, such images\nare divided into a set of patches (a bag of instances), where only bag-level\nclass labels are provided. Deep learning based MIL methods calculate instance\nfeatures using convolutional neural network (CNN). Our proposed approach is\nalso deep learning based, with the following two contributions: Firstly, we\npropose to explicitly account for dependencies between instances during\ntraining by embedding self-attention Transformer blocks to capture dependencies\nbetween instances. For example, a tumor grade may depend on the presence of\nseveral particular patterns at different locations in WSI, which requires to\naccount for dependencies between patches. Secondly, we propose an instance-wise\nloss function based on instance pseudo-labels. We compare the proposed\nalgorithm to multiple baseline methods, evaluate it on the PANDA challenge\ndataset, the largest publicly available WSI dataset with over 11K images, and\ndemonstrate state-of-the-art results.",
    "descriptor": "\nComments: MICCAI 2021\n",
    "authors": [
      "Andriy Myronenko",
      "Ziyue Xu",
      "Dong Yang",
      "Holger Roth",
      "Daguang Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.01556"
  },
  {
    "id": "arXiv:2111.01557",
    "title": "PointNu-Net: Simultaneous Multi-tissue Histology Nuclei Segmentation and  Classification in the Clinical Wild",
    "abstract": "Automatic nuclei segmentation and classification plays a vital role in\ndigital pathology. However, previous works are mostly built on data with\nlimited diversity and small sizes, making the results questionable or\nmisleading in actual downstream tasks. In this paper, we aim to build a\nreliable and robust method capable of dealing with data from the 'the clinical\nwild'. Specifically, we study and design a new method to simultaneously detect,\nsegment, and classify nuclei from Haematoxylin and Eosin (H&E) stained\nhistopathology data, and evaluate our approach using the recent largest\ndataset: PanNuke. We address the detection and classification of each nuclei as\na novel semantic keypoint estimation problem to determine the center point of\neach nuclei. Next, the corresponding class-agnostic masks for nuclei center\npoints are obtained using dynamic instance segmentation. By decoupling two\nsimultaneous challenging tasks, our method can benefit from class-aware\ndetection and class-agnostic segmentation, thus leading to a significant\nperformance boost. We demonstrate the superior performance of our proposed\napproach for nuclei segmentation and classification across 19 different tissue\ntypes, delivering new benchmark results.",
    "descriptor": "\nComments: 10 pages,7 figures, journal\n",
    "authors": [
      "Kai Yao",
      "Kaizhu Huang",
      "Jie Sun",
      "Amir Hussain",
      "Curran Jude"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.01557"
  },
  {
    "id": "arXiv:2111.01560",
    "title": "Efficient Learning of Quadratic Variance Function Directed Acyclic  Graphs via Topological Layers",
    "abstract": "Directed acyclic graph (DAG) models are widely used to represent causal\nrelationships among random variables in many application domains. This paper\nstudies a special class of non-Gaussian DAG models, where the conditional\nvariance of each node given its parents is a quadratic function of its\nconditional mean. Such a class of non-Gaussian DAG models are fairly flexible\nand admit many popular distributions as special cases, including Poisson,\nBinomial, Geometric, Exponential, and Gamma. To facilitate learning, we\nintroduce a novel concept of topological layers, and develop an efficient DAG\nlearning algorithm. It first reconstructs the topological layers in a\nhierarchical fashion and then recoveries the directed edges between nodes in\ndifferent layers, which requires much less computational cost than most\nexisting algorithms in literature. Its advantage is also demonstrated in a\nnumber of simulated examples, as well as its applications to two real-life\ndatasets, including an NBA player statistics data and a cosmetic sales data\ncollected by Alibaba.",
    "descriptor": "",
    "authors": [
      "Wei Zhou",
      "Xin He",
      "Wei Zhong",
      "Junhui Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01560"
  },
  {
    "id": "arXiv:2111.01561",
    "title": "Sub-cortical structure segmentation database for young population",
    "abstract": "Segmentation of sub-cortical structures from MRI scans is of interest in many\nneurological diagnosis. Since this is a laborious task machine learning and\nspecifically deep learning (DL) methods have become explored. The structural\ncomplexity of the brain demands a large, high quality segmentation dataset to\ndevelop good DL-based solutions for sub-cortical structure segmentation.\nTowards this, we are releasing a set of 114, 1.5 Tesla, T1 MRI scans with\nmanual delineations for 14 sub-cortical structures. The scans in the dataset\nwere acquired from healthy young (21-30 years) subjects ( 58 male and 56\nfemale) and all the structures are manually delineated by experienced radiology\nexperts. Segmentation experiments have been conducted with this dataset and\nresults demonstrate that accurate results can be obtained with deep-learning\nmethods.",
    "descriptor": "",
    "authors": [
      "Jayanthi Sivaswamy",
      "Alphin J Thottupattu",
      "Mythri V",
      "Raghav Mehta",
      "R Sheelakumari",
      "Chandrasekharan Kesavadas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.01561"
  },
  {
    "id": "arXiv:2111.01562",
    "title": "Evaluating deep transfer learning for whole-brain cognitive decoding",
    "abstract": "Research in many fields has shown that transfer learning (TL) is well-suited\nto improve the performance of deep learning (DL) models in datasets with small\nnumbers of samples. This empirical success has triggered interest in the\napplication of TL to cognitive decoding analyses with functional neuroimaging\ndata. Here, we systematically evaluate TL for the application of DL models to\nthe decoding of cognitive states (e.g., viewing images of faces or houses) from\nwhole-brain functional Magnetic Resonance Imaging (fMRI) data. We first\npre-train two DL architectures on a large, public fMRI dataset and subsequently\nevaluate their performance in an independent experimental task and a fully\nindependent dataset. The pre-trained models consistently achieve higher\ndecoding accuracies and generally require less training time and data than\nmodel variants that were not pre-trained, clearly underlining the benefits of\npre-training. We demonstrate that these benefits arise from the ability of the\npre-trained models to reuse many of their learned features when training with\nnew data, providing deeper insights into the mechanisms giving rise to the\nbenefits of pre-training. Yet, we also surface nuanced challenges for\nwhole-brain cognitive decoding with DL models when interpreting the decoding\ndecisions of the pre-trained models, as these have learned to utilize the fMRI\ndata in unforeseen and counterintuitive ways to identify individual cognitive\nstates.",
    "descriptor": "",
    "authors": [
      "Armin W. Thomas",
      "Ulman Lindenberger",
      "Wojciech Samek",
      "Klaus-Robert M\u00fcller"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01562"
  },
  {
    "id": "arXiv:2111.01593",
    "title": "Design of Tight Minimum-Sidelobe Windows by Riemannian Newton's Method",
    "abstract": "The short-time Fourier transform (STFT), or the discrete Gabor transform\n(DGT), has been extensively used in signal analysis and processing. Their\nproperties are characterized by a window function, and hence window design is a\nsignificant topic up to date. For signal processing, designing a pair of\nanalysis and synthesis windows is important because results of processing in\nthe time-frequency domain are affected by both of them. A tight window is a\nspecial window that can perfectly reconstruct a signal by using it for both\nanalysis and synthesis. It is known to make time-frequency-domain processing\nrobust to error, and therefore designing a better tight window is desired. In\nthis paper, we propose a method of designing tight windows that minimize the\nsidelobe energy. It is formulated as an optimization problem on an oblique\nmanifold, and a Riemannian Newton algorithm on this manifold is derived to\nefficiently obtain a solution.",
    "descriptor": "",
    "authors": [
      "Daichi Kitahara",
      "Kohei Yatabe"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Audio and Speech Processing (eess.AS)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.01593"
  },
  {
    "id": "arXiv:2111.01622",
    "title": "Towards an Optimal Hybrid Algorithm for EV Charging Stations Placement  using Quantum Annealing and Genetic Algorithms",
    "abstract": "Quantum Annealing is a heuristic for solving optimization problems that have\nseen a recent surge in usage owing to the success of D-Wave Systems. This paper\naims to find a good heuristic for solving the Electric Vehicle Charger\nPlacement (EVCP) problem, a problem that stands to be very important given the\ncosts of setting up an electric vehicle (EV) charger and the expected surge in\nelectric vehicles across the world. The same problem statement can also be\ngeneralised to the optimal placement of any entity in a grid and can be\nexplored for further uses. Finally, the authors introduce a novel heuristic\ncombining Quantum Annealing and Genetic Algorithms to solve the problem. The\nproposed hybrid approach entails seeding the genetic algorithm with the results\nof a quantum annealer. Our experiments show this method decreases the minimum\ndistance from POIs by 42.89% compared to vanilla quantum annealing over our\nsample EVCP datasets.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Aman Chandra",
      "Jitesh Lalwani",
      "Babita Jajodia"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.01622"
  },
  {
    "id": "arXiv:2111.01638",
    "title": "A Finite Characterization of Perfect Equilibria",
    "abstract": "Govindan and Klumpp [7] provided a characterization of perfect equilibria\nusing Lexicographic Probability Systems (LPSs). Their characterization was\nessentially finite in that they showed that there exists a finite bound on the\nnumber of levels in the LPS, but they did not compute it explicitly. In this\nnote, we draw on two recent developments in Real Algebraic Geometry to obtain a\nformula for this bound.",
    "descriptor": "",
    "authors": [
      "Ivonne Callejas",
      "Srihari Govindan",
      "Lucas Pahl"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2111.01638"
  },
  {
    "id": "arXiv:2111.01647",
    "title": "Information Spillover in Multiple Zero-sum Games",
    "abstract": "This paper considers an infinitely repeated three-player Bayesian game with\nlack of information on two sides, in which an informed player plays two\nzero-sum games simultaneously at each stage against two uninformed players.\nThis is a generalization of the Aumann et al. [1] two-player zero-sum one-sided\nincomplete information model. Under a correlated prior, the informed player\nfaces the problem of how to optimally disclose information among two uninformed\nplayers in order to maximize his long-term average payoffs. Our objective is to\nunderstand the adverse effects of \\information spillover\" from one game to the\nother in the equilibrium payoff set of the informed player. We provide\nconditions under which the informed player can fully overcome such adverse\neffects and characterize equilibrium payoffs. In a second result, we show how\nthe effects of information spillover on the equilibrium payoff set of the\ninformed player might be severe.",
    "descriptor": "",
    "authors": [
      "Lucas Pahl"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.01647"
  },
  {
    "id": "arXiv:2111.01652",
    "title": "Design and Evaluation of Active Noise Control on Machinery Noise",
    "abstract": "Construction workers and residents live near around construction sites are\nexposed to noises that might cause hearing loss, high blood pressure, heart\ndisease, sleep disturbance and stress. Regulations has been carried out by\nnational governments to limit the maximum permissible noise levels for\nconstruction works. A four-channel active noise control system mounted on the\nopening of an enclosure is designed to prevent the machinery noise from\nspreading around and retaining the heat diffusion path. Multi-channel FxLMS\nalgorithm in time domain is implemented on the main controller. A Genelec\nspeaker is placed inside the box as the primary noise source to play back\ndifferent types of noises. Analyses and experiments are carried out to\ninvestigate the controllable frequency range of this ANC system in detail.\nConsiderable noise reduction performance is achieved for different recorded\npractical construction noises.",
    "descriptor": "",
    "authors": [
      "Shulin Wen",
      "Duy Hai Nguyen",
      "Miqing Wang",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01652"
  },
  {
    "id": "arXiv:2111.01665",
    "title": "Explainable Medical Image Segmentation via Generative Adversarial  Networks and Layer-wise Relevance Propagation",
    "abstract": "This paper contributes to automating medical image segmentation by proposing\ngenerative adversarial network-based models to segment both polyps and\ninstruments in endoscopy images. A major contribution of this work is to\nprovide explanations for the predictions using a layer-wise relevance\npropagation approach designating which input image pixels are relevant to the\npredictions and to what extent. On the polyp segmentation task, the models\nachieved 0.84 of accuracy and 0.46 on Jaccard index. On the instrument\nsegmentation task, the models achieved 0.96 of accuracy and 0.70 on Jaccard\nindex. The code is available at https://github.com/Awadelrahman/MedAI.",
    "descriptor": "\nComments: Nordic Machine Intelligence\n",
    "authors": [
      "Awadelrahman M. A. Ahmed",
      "Leen A. M. Ali"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01665"
  },
  {
    "id": "arXiv:2111.01682",
    "title": "Progressive observation of Covid-19 vaccination effects on skin-cellular  structures by use of Intelligent Laser Speckle Classification (ILSC)",
    "abstract": "We have made a progressive observation of Covid-19 Astra Zeneca Vaccination\neffect on Skin cellular network and properties by use of well established\nIntelligent Laser Speckle Classification (ILSC) image based technique and\nmanaged to distinguish between three different subjects groups via their laser\nspeckle skin image samplings such as early-vaccinated, late-vaccinated and\nnon-vaccinated individuals. The results have proven that the ILSC technique in\nassociation with the optimised Bayesian network is capable of classifying skin\nchanges of vaccinated and non-vaccinated individuals and also of detecting\nprogressive development made on skin cellular properties for a month period.",
    "descriptor": "",
    "authors": [
      "Ahmet Orun",
      "Fatih Kurugollu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01682"
  },
  {
    "id": "arXiv:2111.01690",
    "title": "Recent Advances in End-to-End Automatic Speech Recognition",
    "abstract": "Recently, the speech community is seeing a significant trend of moving from\ndeep neural network based hybrid modeling to end-to-end (E2E) modeling for\nautomatic speech recognition (ASR). While E2E models achieve the\nstate-of-the-art results in most benchmarks in terms of ASR accuracy, hybrid\nmodels are still used in a large proportion of commercial ASR systems at the\ncurrent time. There are lots of practical factors that affect the production\nmodel deployment decision. Traditional hybrid models, being optimized for\nproduction for decades, are usually good at these factors. Without providing\nexcellent solutions to all these factors, it is hard for E2E models to be\nwidely commercialized. In this paper, we will overview the recent advances in\nE2E models, focusing on technologies addressing those challenges from the\nindustry's perspective.",
    "descriptor": "\nComments: invited paper submitted to APSIPA Transactions on Signal and Information Processing\n",
    "authors": [
      "Jinyu Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.01690"
  },
  {
    "id": "arXiv:2111.01692",
    "title": "Efficient hierarchical Bayesian inference for spatio-temporal regression  models in neuroimaging",
    "abstract": "Several problems in neuroimaging and beyond require inference on the\nparameters of multi-task sparse hierarchical regression models. Examples\ninclude M/EEG inverse problems, neural encoding models for task-based fMRI\nanalyses, and temperature monitoring of climate or CPU and GPU. In these\ndomains, both the model parameters to be inferred and the measurement noise may\nexhibit a complex spatio-temporal structure. Existing work either neglects the\ntemporal structure or leads to computationally demanding inference schemes.\nOvercoming these limitations, we devise a novel flexible hierarchical Bayesian\nframework within which the spatio-temporal dynamics of model parameters and\nnoise are modeled to have Kronecker product covariance structure. Inference in\nour framework is based on majorization-minimization optimization and has\nguaranteed convergence properties. Our highly efficient algorithms exploit the\nintrinsic Riemannian geometry of temporal autocovariance matrices. For\nstationary dynamics described by Toeplitz matrices, the theory of circulant\nembeddings is employed. We prove convex bounding properties and derive update\nrules of the resulting algorithms. On both synthetic and real neural data from\nM/EEG, we demonstrate that our methods lead to improved performance.",
    "descriptor": "\nComments: Accepted to the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Ali Hashemi",
      "Yijing Gao",
      "Chang Cai",
      "Sanjay Ghosh",
      "Klaus-Robert M\u00fcller",
      "Srikantan S. Nagarajan",
      "Stefan Haufe"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.01692"
  },
  {
    "id": "arXiv:2111.01701",
    "title": "Improve Single-Point Zeroth-Order Optimization Using High-Pass and  Low-Pass Filters from Extremum Seeking Control",
    "abstract": "Single-point zeroth-order optimization (SZO) is suitable for solving online\nblack-box optimization and simulation-based learning-to-control problems.\nHowever, the vanilla SZO method suffers from a larger variance and slow\nconvergence, which seriously limits its practical application. On the other\nhand, extremum seeking (ES) control is regarded as the continuous-time version\nof SZO, while they have been mostly studied separately in the control and\noptimization communities despite the close relation. In this work, we borrow\nthe idea of high-pass and low-pass filters from ES control to improve the\nperformance of SZO. Specifically, we develop a novel SZO method called HLF-SZO,\nby integrating a high-pass filter and a low-pass filter into the vanilla SZO\nmethod. Interestingly, it turns out that the integration of a high-pass filter\ncoincides with the residual-feedback SZO method, and the integration of a\nlow-pass filter can be interpreted as the momentum method. We prove that\nHLF-SZO achieves a $O(d/T^{\\frac{2}{3}})$ convergence rate for Lipschitz and\nsmooth objective functions (in both convex and nonconvex cases). Extensive\nnumerical experiments show that the high-pass filter can significantly reduce\nthe variance and the low-pass filter can accelerate the convergence. As a\nresult, the proposed HLF-SZO has a much smaller variance and much faster\nconvergence compared with the vanilla SZO method, and empirically outperforms\nthe state-of-the-art residual-feedback SZO method.",
    "descriptor": "",
    "authors": [
      "Xin Chen",
      "Yujie Tang",
      "Na Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01701"
  },
  {
    "id": "arXiv:2111.01710",
    "title": "Multi-input Architecture and Disentangled Representation Learning for  Multi-dimensional Modeling of Music Similarity",
    "abstract": "In the context of music information retrieval, similarity-based approaches\nare useful for a variety of tasks that benefit from a query-by-example\nscenario. Music however, naturally decomposes into a set of semantically\nmeaningful factors of variation. Current representation learning strategies\npursue the disentanglement of such factors from deep representations, resulting\nin highly interpretable models. This allows the modeling of music similarity\nperception, which is highly subjective and multi-dimensional. While the focus\nof prior work is on metadata driven notions of similarity, we suggest to\ndirectly model the human notion of multi-dimensional music similarity. To\nachieve this, we propose a multi-input deep neural network architecture, which\nsimultaneously processes mel-spectrogram, CENS-chromagram and tempogram in\norder to extract informative features for the different disentangled musical\ndimensions: genre, mood, instrument, era, tempo, and key. We evaluated the\nproposed music similarity approach using a triplet prediction task and found\nthat the proposed multi-input architecture outperforms a state of the art\nmethod. Furthermore, we present a novel multi-dimensional analysis in order to\nevaluate the influence of each disentangled dimension on the perception of\nmusic similarity.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Sebastian Ribecky",
      "Jakob Abe\u00dfer",
      "Hanna Lukashevich"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.01710"
  },
  {
    "id": "arXiv:2111.01713",
    "title": "Realistic galaxy image simulation via score-based generative models",
    "abstract": "We show that a Denoising Diffusion Probabalistic Model (DDPM), a class of\nscore-based generative model, can be used to produce realistic yet fake images\nthat mimic observations of galaxies. Our method is tested with Dark Energy\nSpectroscopic Instrument grz imaging of galaxies from the Photometry and\nRotation curve OBservations from Extragalactic Surveys (PROBES) sample and\ngalaxies selected from the Sloan Digital Sky Survey. Subjectively, the\ngenerated galaxies are highly realistic when compared with samples from the\nreal dataset. We quantify the similarity by borrowing from the deep generative\nlearning literature, using the `Fr\\'echet Inception Distance' to test for\nsubjective and morphological similarity. We also introduce the `Synthetic\nGalaxy Distance' metric to compare the emergent physical properties (such as\ntotal magnitude, colour and half light radius) of a ground truth parent and\nsynthesised child dataset. We argue that the DDPM approach produces sharper and\nmore realistic images than other generative methods such as Adversarial\nNetworks (with the downside of more costly inference), and could be used to\nproduce large samples of synthetic observations tailored to a specific imaging\nsurvey. We demonstrate two potential uses of the DDPM: (1) accurate in-painting\nof occluded data, such as satellite trails, and (2) domain transfer, where new\ninput images can be processed to mimic the properties of the DDPM training set.\nHere we `DESI-fy' cartoon images as a proof of concept for domain transfer.\nFinally, we suggest potential applications for score-based approaches that\ncould motivate further research on this topic within the astronomical\ncommunity.",
    "descriptor": "\nComments: 10 pages, 8 figures. Code: this https URL . Follow the Twitter bot @ThisIsNotAnApod for DDPM-generated APODs\n",
    "authors": [
      "Michael J. Smith",
      "James E. Geach",
      "Ryan A. Jackson",
      "Nikhil Arora",
      "Connor Stone",
      "St\u00e9phane Courteau"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01713"
  },
  {
    "id": "arXiv:2111.01721",
    "title": "Bayes-Newton Methods for Approximate Bayesian Inference with PSD  Guarantees",
    "abstract": "We formulate natural gradient variational inference (VI), expectation\npropagation (EP), and posterior linearisation (PL) as extensions of Newton's\nmethod for optimising the parameters of a Bayesian posterior distribution. This\nviewpoint explicitly casts inference algorithms under the framework of\nnumerical optimisation. We show that common approximations to Newton's method\nfrom the optimisation literature, namely Gauss-Newton and quasi-Newton methods\n(e.g., the BFGS algorithm), are still valid under this `Bayes-Newton'\nframework. This leads to a suite of novel algorithms which are guaranteed to\nresult in positive semi-definite covariance matrices, unlike standard VI and\nEP. Our unifying viewpoint provides new insights into the connections between\nvarious inference schemes. All the presented methods apply to any model with a\nGaussian prior and non-conjugate likelihood, which we demonstrate with (sparse)\nGaussian processes and state space models.",
    "descriptor": "\nComments: Code for methods and experiments: this https URL\n",
    "authors": [
      "William J. Wilkinson",
      "Simo S\u00e4rkk\u00e4",
      "Arno Solin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01721"
  },
  {
    "id": "arXiv:2111.01767",
    "title": "Regularization for Shuffled Data Problems via Exponential Family Priors  on the Permutation Group",
    "abstract": "In the analysis of data sets consisting of (X, Y)-pairs, a tacit assumption\nis that each pair corresponds to the same observation unit. If, however, such\npairs are obtained via record linkage of two files, this assumption can be\nviolated as a result of mismatch error rooting, for example, in the lack of\nreliable identifiers in the two files. Recently, there has been a surge of\ninterest in this setting under the term \"Shuffled data\" in which the underlying\ncorrect pairing of (X, Y)-pairs is represented via an unknown index\npermutation. Explicit modeling of the permutation tends to be associated with\nsubstantial overfitting, prompting the need for suitable methods of\nregularization. In this paper, we propose a flexible exponential family prior\non the permutation group for this purpose that can be used to integrate various\nstructures such as sparse and locally constrained shuffling. This prior turns\nout to be conjugate for canonical shuffled data problems in which the\nlikelihood conditional on a fixed permutation can be expressed as product over\nthe corresponding (X,Y)-pairs. Inference is based on the EM algorithm in which\nthe intractable E-step is approximated by the Fisher-Yates algorithm. The\nM-step is shown to admit a significant reduction from $n^2$ to $n$ terms if the\nlikelihood of (X,Y)-pairs has exponential family form as in the case of\ngeneralized linear models. Comparisons on synthetic and real data show that the\nproposed approach compares favorably to competing methods.",
    "descriptor": "\nComments: 25 pages, 5 figures\n",
    "authors": [
      "Zhenbang Wang",
      "Emanuel Ben-David",
      "Martin Slawski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.01767"
  },
  {
    "id": "arXiv:2111.01768",
    "title": "Nearly Optimal Algorithms for Level Set Estimation",
    "abstract": "The level set estimation problem seeks to find all points in a domain ${\\cal\nX}$ where the value of an unknown function $f:{\\cal X}\\rightarrow \\mathbb{R}$\nexceeds a threshold $\\alpha$. The estimation is based on noisy function\nevaluations that may be acquired at sequentially and adaptively chosen\nlocations in ${\\cal X}$. The threshold value $\\alpha$ can either be\n\\emph{explicit} and provided a priori, or \\emph{implicit} and defined relative\nto the optimal function value, i.e. $\\alpha = (1-\\epsilon)f(x_\\ast)$ for a\ngiven $\\epsilon > 0$ where $f(x_\\ast)$ is the maximal function value and is\nunknown. In this work we provide a new approach to the level set estimation\nproblem by relating it to recent adaptive experimental design methods for\nlinear bandits in the Reproducing Kernel Hilbert Space (RKHS) setting. We\nassume that $f$ can be approximated by a function in the RKHS up to an unknown\nmisspecification and provide novel algorithms for both the implicit and\nexplicit cases in this setting with strong theoretical guarantees. Moreover, in\nthe linear (kernel) setting, we show that our bounds are nearly optimal,\nnamely, our upper bounds match existing lower bounds for threshold linear\nbandits. To our knowledge this work provides the first instance-dependent,\nnon-asymptotic upper bounds on sample complexity of level-set estimation that\nmatch information theoretic lower bounds.",
    "descriptor": "\nComments: 9 pages + appendices. 6 Figures\n",
    "authors": [
      "Blake Mason",
      "Romain Camilleri",
      "Subhojyoti Mukherjee",
      "Kevin Jamieson",
      "Robert Nowak",
      "Lalit Jain"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01768"
  },
  {
    "id": "arXiv:2111.01774",
    "title": "Emergence and structure of decentralised trade networks around dark web  marketplaces",
    "abstract": "Dark web marketplaces (DWMs) are online platforms that facilitate illicit\ntrade among millions of users generating billions of dollars in annual revenue.\nRecently, two interview-based studies have suggested that DWMs may also promote\nthe emergence of direct user-to-user (U2U) trading relationships. Here, we\nquantify the scale of, and thoroughly investigate, U2U trading around DWMs by\nanalysing 31 million Bitcoin transactions among users of 40 DWMs between June\n2011 and Jan 2021. We find that half of the DWM users trade through U2U pairs\ngenerating a total trading volume greater than DWMs themselves. We then show\nthat hundreds of thousands of DWM users form stable trading pairs that are\npersistent over time. Users in stable pairs are typically the ones with the\nlargest trading volume on DWMs. Then, we show that new U2U pairs often form\nwhile both users are active on the same DWM, suggesting the marketplace may\nserve as a catalyst for new direct trading relationships. Finally, we reveal\nthat stable U2U pairs tend to survive DWM closures and that they were not\naffected by COVID-19, indicating that their trading activity is resilient to\nexternal shocks. Our work unveils sophisticated patterns of trade emerging in\nthe dark web and highlights the importance of investigating user behaviour\nbeyond the immediate buyer-seller network on a single marketplace.",
    "descriptor": "",
    "authors": [
      "Matthieu Nadini",
      "Alberto Bracci",
      "Abeer ElBahrawy",
      "Philip Gradwell",
      "Alexander Teytelboym",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.01774"
  },
  {
    "id": "arXiv:2111.01786",
    "title": "A Recommendation System to Enhance Midwives' Capacities in Low-Income  Countries",
    "abstract": "Maternal and child mortality is a public health problem that\ndisproportionately affects low- and middle-income countries. Every day, 800\nwomen and 6,700 newborns die from complications related to pregnancy or\nchildbirth. And for every maternal death, about 20 women suffer serious birth\ninjuries. However, nearly all of these deaths and negative health outcomes are\npreventable. Midwives are key to revert this situation, and thus it is\nessential to strengthen their capacities and the quality of their education.\nThis is the aim of the Safe Delivery App, a digital job aid and learning tool\nto enhance the knowledge, confidence and skills of health practitioners. Here,\nwe use the behavioral logs of the App to implement a recommendation system that\npresents each midwife with suitable contents to continue gaining expertise. We\nfocus on predicting the click-through rate, the probability that a given user\nwill click on a recommended content. We evaluate four deep learning models and\nshow that all of them produce highly accurate predictions.",
    "descriptor": "",
    "authors": [
      "Anna Guitart",
      "Afsaneh Heydari",
      "Eniola Olaleye",
      "Jelena Ljubicic",
      "Ana Fern\u00e1ndez del R\u00edo",
      "\u00c1frica Peri\u00e1\u00f1ez",
      "Lauren Bellhouse"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01786"
  },
  {
    "id": "arXiv:1805.09719",
    "title": "Learning convex polyhedra with margin",
    "abstract": "Learning convex polyhedra with margin",
    "descriptor": "",
    "authors": [
      "Lee-Ad Gottlieb",
      "Eran Kaufman",
      "Aryeh Kontorovich",
      "Gabriel Nivasch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1805.09719"
  },
  {
    "id": "arXiv:1902.03855",
    "title": "All those EPPA classes (Strengthenings of the Herwig-Lascar theorem)",
    "abstract": "Comments: 63 pages, 3 figures. Presentation improvements and corrections according to the referee's suggestions. New Sections 1.3, 2.2, 2.5 and 12.4. More detail in the proof on k-orientations",
    "descriptor": "\nComments: 63 pages, 3 figures. Presentation improvements and corrections according to the referee's suggestions. New Sections 1.3, 2.2, 2.5 and 12.4. More detail in the proof on k-orientations\n",
    "authors": [
      "Jan Hubi\u010dka",
      "Mat\u011bj Kone\u010dn\u00fd",
      "Jaroslav Ne\u0161et\u0159il"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Group Theory (math.GR)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/1902.03855"
  },
  {
    "id": "arXiv:1903.00715",
    "title": "Efficient Reinforcement Learning for StarCraft by Abstract Forward  Models and Transfer Learning",
    "abstract": "Efficient Reinforcement Learning for StarCraft by Abstract Forward  Models and Transfer Learning",
    "descriptor": "",
    "authors": [
      "Ruo-Ze Liu",
      "Haifeng Guo",
      "Xiaozhong Ji",
      "Yang Yu",
      "Zhen-Jia Pang",
      "Zitai Xiao",
      "Yuzhou Wu",
      "Tong Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1903.00715"
  },
  {
    "id": "arXiv:1906.05799",
    "title": "Deep Reinforcement Learning for Cyber Security",
    "abstract": "Deep Reinforcement Learning for Cyber Security",
    "descriptor": "",
    "authors": [
      "Thanh Thi Nguyen",
      "Vijay Janapa Reddi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.05799"
  },
  {
    "id": "arXiv:1908.08384",
    "title": "Covering convex bodies and the Closest Vector Problem",
    "abstract": "Comments: Minor changes to the previous version",
    "descriptor": "\nComments: Minor changes to the previous version\n",
    "authors": [
      "M\u00e1rton Nasz\u00f3di",
      "Moritz Venzin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1908.08384"
  },
  {
    "id": "arXiv:1910.03438",
    "title": "Fast Diameter Computation within Split Graphs",
    "abstract": "Fast Diameter Computation within Split Graphs",
    "descriptor": "",
    "authors": [
      "Guillaume Ducoffe",
      "Michel Habib",
      "Laurent Viennot"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1910.03438"
  },
  {
    "id": "arXiv:1910.05384",
    "title": "ORCCA: Optimal Randomized Canonical Correlation Analysis",
    "abstract": "ORCCA: Optimal Randomized Canonical Correlation Analysis",
    "descriptor": "",
    "authors": [
      "Yinsong Wang",
      "Shahin Shahrampour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.05384"
  },
  {
    "id": "arXiv:1910.05674",
    "title": "Structure-preserving Interpolatory Model Reduction for Port-Hamiltonian  Differential-Algebraic Systems",
    "abstract": "Structure-preserving Interpolatory Model Reduction for Port-Hamiltonian  Differential-Algebraic Systems",
    "descriptor": "",
    "authors": [
      "Chris A. Beattie",
      "Serkan Gugercin",
      "Volker Mehrmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/1910.05674"
  },
  {
    "id": "arXiv:1911.04853",
    "title": "Spatially-Stationary Model for Holographic MIMO Small-Scale Fading",
    "abstract": "Comments: 31 pages, 9 figures, JSAC Special Issue on Multiple Antenna Technologies for Beyond 5G",
    "descriptor": "\nComments: 31 pages, 9 figures, JSAC Special Issue on Multiple Antenna Technologies for Beyond 5G\n",
    "authors": [
      "Andrea Pizzo",
      "Thomas L. Marzetta",
      "Luca Sanguinetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/1911.04853"
  },
  {
    "id": "arXiv:2001.04385",
    "title": "Universal Differential Equations for Scientific Machine Learning",
    "abstract": "Comments: 5 figures, 2 tables, 11 supplemental figures, 29 pages, 25 supplemental pages",
    "descriptor": "\nComments: 5 figures, 2 tables, 11 supplemental figures, 29 pages, 25 supplemental pages\n",
    "authors": [
      "Christopher Rackauckas",
      "Yingbo Ma",
      "Julius Martensen",
      "Collin Warner",
      "Kirill Zubov",
      "Rohit Supekar",
      "Dominic Skinner",
      "Ali Ramadhan",
      "Alan Edelman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.04385"
  },
  {
    "id": "arXiv:2002.02051",
    "title": "Robust multigrid methods for nearly incompressible elasticity using  macro elements",
    "abstract": "Robust multigrid methods for nearly incompressible elasticity using  macro elements",
    "descriptor": "",
    "authors": [
      "Patrick E. Farrell",
      "Lawrence Mitchell",
      "L. Ridgway Scott",
      "Florian Wechsung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2002.02051"
  },
  {
    "id": "arXiv:2003.08904",
    "title": "RAB: Provable Robustness Against Backdoor Attacks",
    "abstract": "Comments: 31 pages, 5 figures, 7 tables",
    "descriptor": "\nComments: 31 pages, 5 figures, 7 tables\n",
    "authors": [
      "Maurice Weber",
      "Xiaojun Xu",
      "Bojan Karla\u0161",
      "Ce Zhang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.08904"
  },
  {
    "id": "arXiv:2005.11290",
    "title": "Internal Parametricity for Cubical Type Theory",
    "abstract": "Internal Parametricity for Cubical Type Theory",
    "descriptor": "",
    "authors": [
      "Evan Cavallo",
      "Robert Harper"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2005.11290"
  },
  {
    "id": "arXiv:2006.04202",
    "title": "Probabilistic Timed Automata with One Clock and Initialised  Clock-Dependent Probabilities",
    "abstract": "Probabilistic Timed Automata with One Clock and Initialised  Clock-Dependent Probabilities",
    "descriptor": "",
    "authors": [
      "Jeremy Sproston"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2006.04202"
  },
  {
    "id": "arXiv:2006.06555",
    "title": "Multi-Agent Reinforcement Learning in Stochastic Networked Systems",
    "abstract": "Multi-Agent Reinforcement Learning in Stochastic Networked Systems",
    "descriptor": "",
    "authors": [
      "Yiheng Lin",
      "Guannan Qu",
      "Longbo Huang",
      "Adam Wierman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.06555"
  },
  {
    "id": "arXiv:2006.06721",
    "title": "Backdoor Smoothing: Demystifying Backdoor Attacks on Deep Neural  Networks",
    "abstract": "Comments: 9 pages, 7 figures, under submission",
    "descriptor": "\nComments: 9 pages, 7 figures, under submission\n",
    "authors": [
      "Kathrin Grosse",
      "Taesung Lee",
      "Battista Biggio",
      "Youngja Park",
      "Michael Backes",
      "Ian Molloy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.06721"
  },
  {
    "id": "arXiv:2006.09647",
    "title": "Regulating algorithmic filtering on social media",
    "abstract": "Comments: 23 pages, 3 figures",
    "descriptor": "\nComments: 23 pages, 3 figures\n",
    "authors": [
      "Sarah H. Cen",
      "Devavrat Shah"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2006.09647"
  },
  {
    "id": "arXiv:2006.14841",
    "title": "Not all Failure Modes are Created Equal: Training Deep Neural Networks  for Explicable (Mis)Classification",
    "abstract": "Not all Failure Modes are Created Equal: Training Deep Neural Networks  for Explicable (Mis)Classification",
    "descriptor": "",
    "authors": [
      "Alberto Olmo",
      "Sailik Sengupta",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.14841"
  },
  {
    "id": "arXiv:2007.06319",
    "title": "In-place implementation of Quantum-Gimli",
    "abstract": "In-place implementation of Quantum-Gimli",
    "descriptor": "",
    "authors": [
      "Lars Schlieper"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2007.06319"
  },
  {
    "id": "arXiv:2007.07053",
    "title": "Unsupervised 3D Human Pose Representation with Viewpoint and Pose  Disentanglement",
    "abstract": "Comments: To appear in ECCV 2020. Code and models are available at: this https URL",
    "descriptor": "\nComments: To appear in ECCV 2020. Code and models are available at: this https URL\n",
    "authors": [
      "Qiang Nie",
      "Ziwei Liu",
      "Yunhui Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.07053"
  },
  {
    "id": "arXiv:2007.08792",
    "title": "Uncertainty Quantification and Deep Ensembles",
    "abstract": "Uncertainty Quantification and Deep Ensembles",
    "descriptor": "",
    "authors": [
      "Rahul Rahaman",
      "Alexandre H. Thiery"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.08792"
  },
  {
    "id": "arXiv:2007.10174",
    "title": "Multi-Server Weakly-Private Information Retrieval",
    "abstract": "Comments: To appear in IEEE Transactions on Information Theory. arXiv admin note: text overlap with arXiv:1901.06730",
    "descriptor": "\nComments: To appear in IEEE Transactions on Information Theory. arXiv admin note: text overlap with arXiv:1901.06730\n",
    "authors": [
      "Hsuan-Yin Lin",
      "Siddhartha Kumar",
      "Eirik Rosnes",
      "Alexandre Graell i Amat",
      "Eitan Yaakobi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2007.10174"
  },
  {
    "id": "arXiv:2009.05208",
    "title": "Complexity of Maximizing Convergence Time in Network Consensus Dynamics  Subject to Edge Removal",
    "abstract": "Complexity of Maximizing Convergence Time in Network Consensus Dynamics  Subject to Edge Removal",
    "descriptor": "",
    "authors": [
      "S. Rasoul Etesami"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Complexity (cs.CC)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2009.05208"
  },
  {
    "id": "arXiv:2009.07773",
    "title": "SideLine: How Delay-Lines (May) Leak Secrets from your SoC",
    "abstract": "SideLine: How Delay-Lines (May) Leak Secrets from your SoC",
    "descriptor": "",
    "authors": [
      "Joseph Gravellier",
      "Jean-Max Dutertre",
      "Yannick Teglia",
      "Philippe Loubet Moundi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2009.07773"
  },
  {
    "id": "arXiv:2010.00300",
    "title": "OutbreakFlow: Model-based Bayesian inference of disease outbreak  dynamics with invertible neural networks and its application to the COVID-19  pandemics in Germany",
    "abstract": "OutbreakFlow: Model-based Bayesian inference of disease outbreak  dynamics with invertible neural networks and its application to the COVID-19  pandemics in Germany",
    "descriptor": "",
    "authors": [
      "Stefan T. Radev",
      "Frederik Graw",
      "Simiao Chen",
      "Nico T. Mutters",
      "Vanessa M. Eichel",
      "Till B\u00e4rnighausen",
      "Ullrich K\u00f6the"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2010.00300"
  },
  {
    "id": "arXiv:2010.01748",
    "title": "Policy Learning Using Weak Supervision",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Jingkang Wang",
      "Hongyi Guo",
      "Zhaowei Zhu",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.01748"
  },
  {
    "id": "arXiv:2010.04030",
    "title": "Weakly Supervised Learning of Multi-Object 3D Scene Decompositions Using  Deep Shape Priors",
    "abstract": "Weakly Supervised Learning of Multi-Object 3D Scene Decompositions Using  Deep Shape Priors",
    "descriptor": "",
    "authors": [
      "Cathrin Elich",
      "Martin R. Oswald",
      "Marc Pollefeys",
      "Joerg Stueckler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.04030"
  },
  {
    "id": "arXiv:2010.05178",
    "title": "Further Investigation of the Survivability of Code Technical Debt Items",
    "abstract": "Comments: Submitted to the Journal of Software: Evolution and Process (JSME)",
    "descriptor": "\nComments: Submitted to the Journal of Software: Evolution and Process (JSME)\n",
    "authors": [
      "Ehsan Zabardast",
      "Kwabena Ebo Bennin",
      "Javier Gonzalez-Huerta"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2010.05178"
  },
  {
    "id": "arXiv:2010.08572",
    "title": "Horizon-independent Preconditioner Design for Linear Predictive Control",
    "abstract": "Horizon-independent Preconditioner Design for Linear Predictive Control",
    "descriptor": "",
    "authors": [
      "Ian McInerney",
      "Eric C. Kerrigan",
      "George A. Constantinides"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.08572"
  },
  {
    "id": "arXiv:2010.13363",
    "title": "Provable Memorization via Deep Neural Networks using Sub-linear  Parameters",
    "abstract": "Provable Memorization via Deep Neural Networks using Sub-linear  Parameters",
    "descriptor": "",
    "authors": [
      "Sejun Park",
      "Jaeho Lee",
      "Chulhee Yun",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.13363"
  },
  {
    "id": "arXiv:2011.02609",
    "title": "Cooperative Learning for P2P Energy Trading via Inverse Optimization and  Interval Analysis",
    "abstract": "Comments: Full version with title changed and additional contents has been accepted for publication in IEEE Access. DOI: 10.1109/ACCESS.2021.3125031",
    "descriptor": "\nComments: Full version with title changed and additional contents has been accepted for publication in IEEE Access. DOI: 10.1109/ACCESS.2021.3125031\n",
    "authors": [
      "Dinh Hoa Nguyen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2011.02609"
  },
  {
    "id": "arXiv:2011.11201",
    "title": "Modular Action Concept Grounding in Semantic Video Prediction",
    "abstract": "Modular Action Concept Grounding in Semantic Video Prediction",
    "descriptor": "",
    "authors": [
      "Wei Yu",
      "Wenxin Chen",
      "Songhenh Yin",
      "Steve Easterbrook",
      "Animesh Garg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.11201"
  },
  {
    "id": "arXiv:2011.12635",
    "title": "The Hydrostructure: a Universal Framework for Safe and Complete  Algorithms for Genome Assembly",
    "abstract": "The Hydrostructure: a Universal Framework for Safe and Complete  Algorithms for Genome Assembly",
    "descriptor": "",
    "authors": [
      "Massimo Cairo",
      "Shahbaz Khan",
      "Romeo Rizzi",
      "Sebastian Schmidt",
      "Alexandru I. Tomescu",
      "Elia C. Zirondelli"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2011.12635"
  },
  {
    "id": "arXiv:2012.10496",
    "title": "Factorization of Binary Matrices: Rank Relations, Uniqueness and Model  Selection of Boolean Decomposition",
    "abstract": "Factorization of Binary Matrices: Rank Relations, Uniqueness and Model  Selection of Boolean Decomposition",
    "descriptor": "",
    "authors": [
      "Derek DeSantis",
      "Erik Skau",
      "Duc P. Truong",
      "Boian Alexandrov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.10496"
  },
  {
    "id": "arXiv:2101.01484",
    "title": "QoE-driven Secure Video Transmission in Cloud-edge Collaborative  Networks",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Tantan Zhao",
      "Lijun He",
      "Xinyu Huang",
      "Fan Li"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2101.01484"
  },
  {
    "id": "arXiv:2101.01768",
    "title": "Multi-Cell, Multi-Channel Scheduling with Probabilistic Per-Packet  Real-Time Guarantee",
    "abstract": "Multi-Cell, Multi-Channel Scheduling with Probabilistic Per-Packet  Real-Time Guarantee",
    "descriptor": "",
    "authors": [
      "Zhibo Meng",
      "Hongwei Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2101.01768"
  },
  {
    "id": "arXiv:2101.06536",
    "title": "Deep Cox Mixtures for Survival Regression",
    "abstract": "Comments: Machine Learning for Healthcare Conference, 2021",
    "descriptor": "\nComments: Machine Learning for Healthcare Conference, 2021\n",
    "authors": [
      "Chirag Nagpal",
      "Steve Yadlowsky",
      "Negar Rostamzadeh",
      "Katherine Heller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.06536"
  },
  {
    "id": "arXiv:2101.11427",
    "title": "One Model to Serve All: Star Topology Adaptive Recommender for  Multi-Domain CTR Prediction",
    "abstract": "Comments: Accepted at CIKM 2021",
    "descriptor": "\nComments: Accepted at CIKM 2021\n",
    "authors": [
      "Xiang-Rong Sheng",
      "Liqin Zhao",
      "Guorui Zhou",
      "Xinyao Ding",
      "Binding Dai",
      "Qiang Luo",
      "Siran Yang",
      "Jingshan Lv",
      "Chi Zhang",
      "Hongbo Deng",
      "Xiaoqiang Zhu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.11427"
  },
  {
    "id": "arXiv:2102.03336",
    "title": "Machine Learning Applications on Neuroimaging for Diagnosis and  Prognosis of Epilepsy: A Review",
    "abstract": "Machine Learning Applications on Neuroimaging for Diagnosis and  Prognosis of Epilepsy: A Review",
    "descriptor": "",
    "authors": [
      "Jie Yuan",
      "Xuming Ran",
      "Keyin Liu",
      "Chen Yao",
      "Yi Yao",
      "Haiyan Wu",
      "Quanying Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.03336"
  },
  {
    "id": "arXiv:2102.03988",
    "title": "Ising Model Selection Using $\\ell_{1}$-Regularized Linear Regression: A  Statistical Mechanics Analysis",
    "abstract": "Comments: Accepted to NeurIPS 2021. Camera-ready version with supplementary materials",
    "descriptor": "\nComments: Accepted to NeurIPS 2021. Camera-ready version with supplementary materials\n",
    "authors": [
      "Xiangming Meng",
      "Tomoyuki Obuchi",
      "Yoshiyuki Kabashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.03988"
  },
  {
    "id": "arXiv:2102.07092",
    "title": "Learning Self-Similarity in Space and Time as Generalized Motion for  Video Action Recognition",
    "abstract": "Comments: Accepted to ICCV 2021",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Heeseung Kwon",
      "Manjin Kim",
      "Suha Kwak",
      "Minsu Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.07092"
  },
  {
    "id": "arXiv:2102.09759",
    "title": "Applications of deep learning in traffic congestion detection,  prediction and alleviation: A survey",
    "abstract": "Comments: 20 pages, 7 figures",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Nishant Kumar",
      "Martin Raubal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09759"
  },
  {
    "id": "arXiv:2102.09775",
    "title": "Characterizing and Mitigating Self-Admitted Technical Debt in Build  Systems",
    "abstract": "Characterizing and Mitigating Self-Admitted Technical Debt in Build  Systems",
    "descriptor": "",
    "authors": [
      "Tao Xiao",
      "Dong Wang",
      "Shane McIntosh",
      "Hideaki Hata",
      "Raula Gaikovina Kula",
      "Takashi Ishio",
      "Kenichi Matsumoto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2102.09775"
  },
  {
    "id": "arXiv:2102.09808",
    "title": "Improving Anytime Prediction with Parallel Cascaded Networks and a  Temporal-Difference Loss",
    "abstract": "Improving Anytime Prediction with Parallel Cascaded Networks and a  Temporal-Difference Loss",
    "descriptor": "",
    "authors": [
      "Michael L. Iuzzolino",
      "Michael C. Mozer",
      "Samy Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.09808"
  },
  {
    "id": "arXiv:2102.10090",
    "title": "Volunteer contributions to Wikipedia increased during COVID-19 mobility  restrictions",
    "abstract": "Volunteer contributions to Wikipedia increased during COVID-19 mobility  restrictions",
    "descriptor": "",
    "authors": [
      "Thorsten Ruprechter",
      "Manoel Horta Ribeiro",
      "Tiago Santos",
      "Florian Lemmerich",
      "Markus Strohmaier",
      "Robert West",
      "Denis Helic"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2102.10090"
  },
  {
    "id": "arXiv:2102.11137",
    "title": "Program Synthesis Guided Reinforcement Learning for Partially Observed  Environments",
    "abstract": "Program Synthesis Guided Reinforcement Learning for Partially Observed  Environments",
    "descriptor": "",
    "authors": [
      "Yichen David Yang",
      "Jeevana Priya Inala",
      "Osbert Bastani",
      "Yewen Pu",
      "Armando Solar-Lezama",
      "Martin Rinard"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.11137"
  },
  {
    "id": "arXiv:2102.11903",
    "title": "Neural ranking models for document retrieval",
    "abstract": "Comments: Published in the Information Retrieval Journal (2021)",
    "descriptor": "\nComments: Published in the Information Retrieval Journal (2021)\n",
    "authors": [
      "Mohamed Trabelsi",
      "Zhiyu Chen",
      "Brian D. Davison",
      "Jeff Heflin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.11903"
  },
  {
    "id": "arXiv:2103.00091",
    "title": "Design and Performance Characterization of RADICAL-Pilot on  Leadership-class Platforms",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1801.01843",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1801.01843\n",
    "authors": [
      "Andre Merzky",
      "Matteo Turilli",
      "Mikhail Titov",
      "Aymen Al-Saadi",
      "Shantenu Jha"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2103.00091"
  },
  {
    "id": "arXiv:2103.01242",
    "title": "Cryptonite: A Cryptic Crossword Benchmark for Extreme Ambiguity in  Language",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Avia Efrat",
      "Uri Shaham",
      "Dan Kilman",
      "Omer Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.01242"
  },
  {
    "id": "arXiv:2103.03991",
    "title": "Passing Through Narrow Gaps with Deep Reinforcement Learning",
    "abstract": "Comments: Submitted to 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
    "descriptor": "\nComments: Submitted to 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Brendan Tidd",
      "Akansel Cosgun",
      "Jurgen Leitner",
      "Nicolas Hudson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.03991"
  },
  {
    "id": "arXiv:2103.04804",
    "title": "Detecting quantum entanglement with unsupervised learning",
    "abstract": "Comments: Published version and comments are still welcome",
    "descriptor": "\nComments: Published version and comments are still welcome\n",
    "authors": [
      "Yiwei Chen",
      "Yu Pan",
      "Guofeng Zhang",
      "Shuming Cheng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.04804"
  },
  {
    "id": "arXiv:2103.11351",
    "title": "Cross-Dataset Collaborative Learning for Semantic Segmentation in  Autonomous Driving",
    "abstract": "Cross-Dataset Collaborative Learning for Semantic Segmentation in  Autonomous Driving",
    "descriptor": "",
    "authors": [
      "Li Wang",
      "Dong Li",
      "Han Liu",
      "Jinzhang Peng",
      "Lu Tian",
      "Yi Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11351"
  },
  {
    "id": "arXiv:2103.12347",
    "title": "Shared Latent Space of Font Shapes and Their Noisy Impressions",
    "abstract": "Comments: accepted at MMM2022",
    "descriptor": "\nComments: accepted at MMM2022\n",
    "authors": [
      "Jihun Kang",
      "Daichi Haraguchi",
      "Seiya Matsuda",
      "Akisato Kimura",
      "Seiichi Uchida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12347"
  },
  {
    "id": "arXiv:2103.13530",
    "title": "Pricing and Energy Trading in Peer-to-peer Zero Marginal-cost Microgrids",
    "abstract": "Pricing and Energy Trading in Peer-to-peer Zero Marginal-cost Microgrids",
    "descriptor": "",
    "authors": [
      "Jonathan Lee",
      "Rodrigo Henriquez-Auba",
      "Bala Kameshwar Poolla",
      "Duncan S. Callaway"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.13530"
  },
  {
    "id": "arXiv:2104.01065",
    "title": "Fairness and Communication-Based Semantics for Session-Typed Languages",
    "abstract": "Comments: Significantly expands the workshop version of this paper: Ryan Kavanagh. \"Substructural Observed Communication Semantics\". In: Proceedings of EXPRESS/SOS 2020. Electronic Proceedings in Theoretical Computer Science 322. Aug. 27, 2020, pp. 69-87. doi:10.4204/EPTCS.322.7 . arXiv:2008.13358v1 [cs.PL]",
    "descriptor": "\nComments: Significantly expands the workshop version of this paper: Ryan Kavanagh. \"Substructural Observed Communication Semantics\". In: Proceedings of EXPRESS/SOS 2020. Electronic Proceedings in Theoretical Computer Science 322. Aug. 27, 2020, pp. 69-87. doi:10.4204/EPTCS.322.7 . arXiv:2008.13358v1 [cs.PL]\n",
    "authors": [
      "Ryan Kavanagh"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2104.01065"
  },
  {
    "id": "arXiv:2104.02040",
    "title": "Segmentation of EM showers for neutrino experiments with deep graph  neural networks",
    "abstract": "Comments: 29 pages, 27 figures",
    "descriptor": "\nComments: 29 pages, 27 figures\n",
    "authors": [
      "Vladislav Belavin",
      "Ekaterina Trofimova",
      "Andrey Ustyuzhanin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2104.02040"
  },
  {
    "id": "arXiv:2104.05119",
    "title": "BurstLink: Techniques for Energy-Efficient Conventional and Virtual  Reality Video Display",
    "abstract": "Comments: The paper will be presented at MICRO 2021",
    "descriptor": "\nComments: The paper will be presented at MICRO 2021\n",
    "authors": [
      "Jawad Haj-Yahya",
      "Jisung Park",
      "Rahul Bera",
      "Juan G\u00f3mez Luna",
      "Efraim Rotem",
      "Taha Shahroodi",
      "Jeremie Kim",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2104.05119"
  },
  {
    "id": "arXiv:2104.07149",
    "title": "On the Robustness of Intent Classification and Slot Labeling in  Goal-oriented Dialog Systems to Real-world Noise",
    "abstract": "Comments: To be presented at NLP for Conversational AI, EMNLP 2021",
    "descriptor": "\nComments: To be presented at NLP for Conversational AI, EMNLP 2021\n",
    "authors": [
      "Sailik Sengupta",
      "Jason Krone",
      "Saab Mansour"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.07149"
  },
  {
    "id": "arXiv:2104.09330",
    "title": "Beyond tight deadlines: what are the business causes for technical debt?",
    "abstract": "Beyond tight deadlines: what are the business causes for technical debt?",
    "descriptor": "",
    "authors": [
      "Rodrigo Rebou\u00e7as de Almeida",
      "Christoph Treude",
      "Uir\u00e1 Kulesza"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2104.09330"
  },
  {
    "id": "arXiv:2104.12820",
    "title": "Universal Off-Policy Evaluation",
    "abstract": "Comments: Accepted at Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Accepted at Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Yash Chandak",
      "Scott Niekum",
      "Bruno Castro da Silva",
      "Erik Learned-Miller",
      "Emma Brunskill",
      "Philip S. Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.12820"
  },
  {
    "id": "arXiv:2105.01924",
    "title": "Novelty Detection and Analysis of Traffic Scenario Infrastructures in  the Latent Space of a Vision Transformer-Based Triplet Autoencoder",
    "abstract": "Comments: Copyright 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: Copyright 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Jonas Wurst",
      "Lakshman Balasubramanian",
      "Michael Botsch",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.01924"
  },
  {
    "id": "arXiv:2105.02716",
    "title": "Noether's Learning Dynamics: Role of Symmetry Breaking in Neural  Networks",
    "abstract": "Noether's Learning Dynamics: Role of Symmetry Breaking in Neural  Networks",
    "descriptor": "",
    "authors": [
      "Hidenori Tanaka",
      "Daniel Kunin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.02716"
  },
  {
    "id": "arXiv:2105.06742",
    "title": "Cybersecurity Anomaly Detection in Adversarial Environments",
    "abstract": "Comments: Presented at AAAI FSS-21: Artificial Intelligence in Government and Public Sector, Washington, DC, USA",
    "descriptor": "\nComments: Presented at AAAI FSS-21: Artificial Intelligence in Government and Public Sector, Washington, DC, USA\n",
    "authors": [
      "David A. Bierbrauer",
      "Alexander Chang",
      "Will Kritzer",
      "Nathaniel D. Bastian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.06742"
  },
  {
    "id": "arXiv:2105.07608",
    "title": "Hamiltonian Cycle Problem is in P",
    "abstract": "Comments: 40 pages, 9 figures",
    "descriptor": "\nComments: 40 pages, 9 figures\n",
    "authors": [
      "Aimin Hou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.07608"
  },
  {
    "id": "arXiv:2105.09680",
    "title": "KLUE: Korean Language Understanding Evaluation",
    "abstract": "Comments: 76 pages, 10 figures, 36 tables",
    "descriptor": "\nComments: 76 pages, 10 figures, 36 tables\n",
    "authors": [
      "Sungjoon Park",
      "Jihyung Moon",
      "Sungdong Kim",
      "Won Ik Cho",
      "Jiyoon Han",
      "Jangwon Park",
      "Chisung Song",
      "Junseong Kim",
      "Yongsook Song",
      "Taehwan Oh",
      "Joohong Lee",
      "Juhyun Oh",
      "Sungwon Lyu",
      "Younghoon Jeong",
      "Inkwon Lee",
      "Sangwoo Seo",
      "Dongjun Lee",
      "Hyunwoo Kim",
      "Myeonghwa Lee",
      "Seongbo Jang",
      "Seungwon Do",
      "Sunkyoung Kim",
      "Kyungtae Lim",
      "Jongwon Lee",
      "Kyumin Park",
      "Jamin Shin",
      "Seonghyun Kim",
      "Lucy Park",
      "Alice Oh",
      "Jung-Woo Ha",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.09680"
  },
  {
    "id": "arXiv:2105.11066",
    "title": "Policy Mirror Descent for Regularized Reinforcement Learning: A  Generalized Framework with Linear Convergence",
    "abstract": "Policy Mirror Descent for Regularized Reinforcement Learning: A  Generalized Framework with Linear Convergence",
    "descriptor": "",
    "authors": [
      "Wenhao Zhan",
      "Shicong Cen",
      "Baihe Huang",
      "Yuxin Chen",
      "Jason D. Lee",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.11066"
  },
  {
    "id": "arXiv:2105.11367",
    "title": "FedScale: Benchmarking Model and System Performance of Federated  Learning at Scale",
    "abstract": "FedScale: Benchmarking Model and System Performance of Federated  Learning at Scale",
    "descriptor": "",
    "authors": [
      "Fan Lai",
      "Yinwei Dai",
      "Xiangfeng Zhu",
      "Harsha V. Madhyastha",
      "Mosharaf Chowdhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.11367"
  },
  {
    "id": "arXiv:2105.12122",
    "title": "Optical coherent dot-product chip for sophisticated deep learning  regression",
    "abstract": "Optical coherent dot-product chip for sophisticated deep learning  regression",
    "descriptor": "",
    "authors": [
      "Shaofu Xu",
      "Jing Wang",
      "Haowen Shu",
      "Zhike Zhang",
      "Sicheng Yi",
      "Bowen Bai",
      "Xingjun Wang",
      "Jianguo Liu",
      "Weiwen Zou"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2105.12122"
  },
  {
    "id": "arXiv:2105.13133",
    "title": "Modeling of unsaturated flow through porous media using meshless methods",
    "abstract": "Comments: The sandy clay and loam soils are selected in this numerical test to simulate unsaturated flow through a two-dimensional homogeneous medium. The time evolution of the total mass per unit of length of the 2D numerical solutions and the solutions simulated by 1D-Hydrus for a computational domain of unit length (1D problem) are displayed in Figure 2",
    "descriptor": "\nComments: The sandy clay and loam soils are selected in this numerical test to simulate unsaturated flow through a two-dimensional homogeneous medium. The time evolution of the total mass per unit of length of the 2D numerical solutions and the solutions simulated by 1D-Hydrus for a computational domain of unit length (1D problem) are displayed in Figure 2\n",
    "authors": [
      "Mohamed Boujoudar",
      "Abdelaziz Beljadid",
      "Ahmed Taik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2105.13133"
  },
  {
    "id": "arXiv:2106.02383",
    "title": "PoDT: A Secure Multi-chains Consensus Scheme Against Diverse Miners  Behaviors Attacks in Blockchain Networks",
    "abstract": "Comments: 14 pages, 17 figures",
    "descriptor": "\nComments: 14 pages, 17 figures\n",
    "authors": [
      "Wenbo Zhang",
      "Tao Wang",
      "Jingyu Feng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.02383"
  },
  {
    "id": "arXiv:2106.03632",
    "title": "Quantifying and Improving Transferability in Domain Generalization",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Guojun Zhang",
      "Han Zhao",
      "Yaoliang Yu",
      "Pascal Poupart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03632"
  },
  {
    "id": "arXiv:2106.03898",
    "title": "SPANet: Generalized Permutationless Set Assignment for Particle Physics  using Symmetry Preserving Attention",
    "abstract": "Comments: added new sec6 and fig5, to be submitted to scipost",
    "descriptor": "\nComments: added new sec6 and fig5, to be submitted to scipost\n",
    "authors": [
      "Alexander Shmakov",
      "Michael James Fenton",
      "Ta-Wei Ho",
      "Shih-Chieh Hsu",
      "Daniel Whiteson",
      "Pierre Baldi"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.03898"
  },
  {
    "id": "arXiv:2106.04031",
    "title": "Balancing Asymptotic and Transient Efficiency Guarantees in Set Covering  Games",
    "abstract": "Balancing Asymptotic and Transient Efficiency Guarantees in Set Covering  Games",
    "descriptor": "",
    "authors": [
      "Rohit Konda",
      "Rahul Chandan",
      "David Grimsman",
      "Jason R. Marden"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.04031"
  },
  {
    "id": "arXiv:2106.04169",
    "title": "On Improving Adversarial Transferability of Vision Transformers",
    "abstract": "Comments: Code: this https URL",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Muzammal Naseer",
      "Kanchana Ranasinghe",
      "Salman Khan",
      "Fahad Shahbaz Khan",
      "Fatih Porikli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04169"
  },
  {
    "id": "arXiv:2106.04537",
    "title": "Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with  Recurrent Networks",
    "abstract": "Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with  Recurrent Networks",
    "descriptor": "",
    "authors": [
      "Avi Schwarzschild",
      "Eitan Borgnia",
      "Arjun Gupta",
      "Furong Huang",
      "Uzi Vishkin",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.04537"
  },
  {
    "id": "arXiv:2106.04627",
    "title": "Densely connected normalizing flows",
    "abstract": "Comments: Accepted at NeurIPS2021",
    "descriptor": "\nComments: Accepted at NeurIPS2021\n",
    "authors": [
      "Matej Grci\u0107",
      "Ivan Grubi\u0161i\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04627"
  },
  {
    "id": "arXiv:2106.05378",
    "title": "Parameter and Feature Selection in Stochastic Linear Bandits",
    "abstract": "Parameter and Feature Selection in Stochastic Linear Bandits",
    "descriptor": "",
    "authors": [
      "Ahmadreza Moradipari",
      "Berkay Turan",
      "Yasin Abbasi-Yadkori",
      "Mahnoosh Alizadeh",
      "Mohammad Ghavamzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05378"
  },
  {
    "id": "arXiv:2106.05386",
    "title": "Artificial Intelligence in Drug Discovery: Applications and Techniques",
    "abstract": "Comments: Accepted to Briefings in Bioinformatics",
    "descriptor": "\nComments: Accepted to Briefings in Bioinformatics\n",
    "authors": [
      "Jianyuan Deng",
      "Zhibo Yang",
      "Iwao Ojima",
      "Dimitris Samaras",
      "Fusheng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05386"
  },
  {
    "id": "arXiv:2106.06306",
    "title": "A survey on Functional Encryption",
    "abstract": "Comments: To appear in Advances in Mathematics of Communications, this https URL",
    "descriptor": "\nComments: To appear in Advances in Mathematics of Communications, this https URL\n",
    "authors": [
      "Carla Mascia",
      "Massimiliano Sala",
      "Irene Villa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.06306"
  },
  {
    "id": "arXiv:2106.06308",
    "title": "The Complexity of Sparse Tensor PCA",
    "abstract": "The Complexity of Sparse Tensor PCA",
    "descriptor": "",
    "authors": [
      "Davin Choo",
      "Tommaso d'Orsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06308"
  },
  {
    "id": "arXiv:2106.07085",
    "title": "Survey: Image Mixing and Deleting for Data Augmentation",
    "abstract": "Survey: Image Mixing and Deleting for Data Augmentation",
    "descriptor": "",
    "authors": [
      "Humza Naveed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07085"
  },
  {
    "id": "arXiv:2106.07504",
    "title": "Characterizing the risk of fairwashing",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Ulrich A\u00efvodji",
      "Hiromi Arai",
      "S\u00e9bastien Gambs",
      "Satoshi Hara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.07504"
  },
  {
    "id": "arXiv:2106.08208",
    "title": "SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients",
    "abstract": "Comments: To appear in NeurIPS 2021",
    "descriptor": "\nComments: To appear in NeurIPS 2021\n",
    "authors": [
      "Feihu Huang",
      "Junyi Li",
      "Heng Huang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08208"
  },
  {
    "id": "arXiv:2106.09012",
    "title": "A learning agent that acquires social norms from public sanctions in  decentralized multi-agent settings",
    "abstract": "A learning agent that acquires social norms from public sanctions in  decentralized multi-agent settings",
    "descriptor": "",
    "authors": [
      "Eugene Vinitsky",
      "Raphael K\u00f6ster",
      "John P. Agapiou",
      "Edgar Du\u00e9\u00f1ez-Guzm\u00e1n",
      "Alexander Sasha Vezhnevets",
      "Joel Z. Leibo"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.09012"
  },
  {
    "id": "arXiv:2106.09779",
    "title": "Private Federated Learning Without a Trusted Server: Optimal Algorithms  for Convex Losses",
    "abstract": "Comments: v2: Added lower bounds, edited paper structure, simplified presentation of informal results; v3: Improved Theorem 2.3 (non-i.i.d. upper bounds)",
    "descriptor": "\nComments: v2: Added lower bounds, edited paper structure, simplified presentation of informal results; v3: Improved Theorem 2.3 (non-i.i.d. upper bounds)\n",
    "authors": [
      "Andrew Lowy",
      "Meisam Razaviyayn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09779"
  },
  {
    "id": "arXiv:2106.13008",
    "title": "Autoformer: Decomposition Transformers with Auto-Correlation for  Long-Term Series Forecasting",
    "abstract": "Autoformer: Decomposition Transformers with Auto-Correlation for  Long-Term Series Forecasting",
    "descriptor": "",
    "authors": [
      "Haixu Wu",
      "Jiehui Xu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13008"
  },
  {
    "id": "arXiv:2106.14564",
    "title": "Two-point AG codes from the Beelen-Montanucci maximal curve",
    "abstract": "Two-point AG codes from the Beelen-Montanucci maximal curve",
    "descriptor": "",
    "authors": [
      "Leonardo Landi",
      "Lara Vicino"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.14564"
  },
  {
    "id": "arXiv:2106.14568",
    "title": "Deep Ensembling with No Overhead for either Training or Testing: The  All-Round Blessings of Dynamic Sparsity",
    "abstract": "Comments: preprint version",
    "descriptor": "\nComments: preprint version\n",
    "authors": [
      "Shiwei Liu",
      "Tianlong Chen",
      "Zahra Atashgahi",
      "Xiaohan Chen",
      "Ghada Sokar",
      "Elena Mocanu",
      "Mykola Pechenizkiy",
      "Zhangyang Wang",
      "Decebal Constantin Mocanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14568"
  },
  {
    "id": "arXiv:2106.15916",
    "title": "Communication conditions in virtual acoustic scenes in an underground  station",
    "abstract": "Comments: I3DA conference paper, 8 figures, 9 pages",
    "descriptor": "\nComments: I3DA conference paper, 8 figures, 9 pages\n",
    "authors": [
      "\u013dubo\u0161 Hl\u00e1dek",
      "Stephan D. Ewert",
      "Bernhard U. Seeber"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.15916"
  },
  {
    "id": "arXiv:2106.16122",
    "title": "Zombies in the Loop? Humans Trust Untrustworthy AI-Advisors for Ethical  Decisions",
    "abstract": "Zombies in the Loop? Humans Trust Untrustworthy AI-Advisors for Ethical  Decisions",
    "descriptor": "",
    "authors": [
      "Sebastian Kr\u00fcgel",
      "Andreas Ostermaier",
      "Matthias Uhl"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.16122"
  },
  {
    "id": "arXiv:2106.16187",
    "title": "Reinforcement Learning based Disease Progression Model for Alzheimer's  Disease",
    "abstract": "Comments: 10 pages main text, 3 page references, 11 page appendix",
    "descriptor": "\nComments: 10 pages main text, 3 page references, 11 page appendix\n",
    "authors": [
      "Krishnakant V. Saboo",
      "Anirudh Choudhary",
      "Yurui Cao",
      "Gregory A. Worrell",
      "David T. Jones",
      "Ravishankar K. Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16187"
  },
  {
    "id": "arXiv:2107.00820",
    "title": "Robust multigrid techniques for augmented Lagrangian preconditioning of  incompressible Stokes equations with extreme viscosity variations",
    "abstract": "Comments: 27 pages, 6 figures",
    "descriptor": "\nComments: 27 pages, 6 figures\n",
    "authors": [
      "Yu-hsuan Shih",
      "Georg Stadler",
      "Florian Wechsung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2107.00820"
  },
  {
    "id": "arXiv:2107.02071",
    "title": "fMBN-E: Efficient Unsupervised Network Structure Ensemble and Selection  for Clustering",
    "abstract": "fMBN-E: Efficient Unsupervised Network Structure Ensemble and Selection  for Clustering",
    "descriptor": "",
    "authors": [
      "Xiao-Lei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02071"
  },
  {
    "id": "arXiv:2107.02397",
    "title": "Deep Network Approximation: Achieving Arbitrary Accuracy with Fixed  Number of Neurons",
    "abstract": "Deep Network Approximation: Achieving Arbitrary Accuracy with Fixed  Number of Neurons",
    "descriptor": "",
    "authors": [
      "Zuowei Shen",
      "Haizhao Yang",
      "Shijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.02397"
  },
  {
    "id": "arXiv:2107.02909",
    "title": "Deep Mesh Prior: Unsupervised Mesh Restoration using Graph Convolutional  Networks",
    "abstract": "Comments: 10 pages, 9 figures and 2 tables",
    "descriptor": "\nComments: 10 pages, 9 figures and 2 tables\n",
    "authors": [
      "Shota Hattori",
      "Tatsuya Yatagawa",
      "Yutaka Ohtake",
      "Hiromasa Suzuki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2107.02909"
  },
  {
    "id": "arXiv:2107.03461",
    "title": "Comparing Machine Learning based Segmentation Models on Jet Fire  Radiation Zones",
    "abstract": "Comparing Machine Learning based Segmentation Models on Jet Fire  Radiation Zones",
    "descriptor": "",
    "authors": [
      "Carmina P\u00e9rez-Guerrero",
      "Adriana Palacios",
      "Gilberto Ochoa-Ruiz",
      "Christian Mata",
      "Miguel Gonzalez-Mendoza",
      "Luis Eduardo Falc\u00f3n-Morales"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.03461"
  },
  {
    "id": "arXiv:2107.03955",
    "title": "On Margins and Derandomisation in PAC-Bayes",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Felix Biggs",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.03955"
  },
  {
    "id": "arXiv:2107.07451",
    "title": "Data vs classifiers, who wins?",
    "abstract": "Comments: 34 pages, 7 figures and 9 tables",
    "descriptor": "\nComments: 34 pages, 7 figures and 9 tables\n",
    "authors": [
      "Lucas F. F. Cardoso",
      "Vitor C. A. Santos",
      "Regiane S. Kawasaki Franc\u00eas",
      "Ricardo B. C. Prud\u00eancio",
      "Ronnie C. O. Alves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07451"
  },
  {
    "id": "arXiv:2107.07994",
    "title": "Property-Aware Relation Networks for Few-Shot Molecular Property  Prediction",
    "abstract": "Comments: molecular property prediction, few-shot learning, meta learning",
    "descriptor": "\nComments: molecular property prediction, few-shot learning, meta learning\n",
    "authors": [
      "Yaqing Wang",
      "Abulikemu Abuduweili",
      "Quanming Yao",
      "Dejing Dou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07994"
  },
  {
    "id": "arXiv:2107.09834",
    "title": "Communication lower bounds for nested bilinear algorithms",
    "abstract": "Comments: 37 pages, 5 figures, 1 table. Update includes log-log convex/concave functions to fix previous bug in v1",
    "descriptor": "\nComments: 37 pages, 5 figures, 1 table. Update includes log-log convex/concave functions to fix previous bug in v1\n",
    "authors": [
      "Caleb Ju",
      "Yifan Zhang",
      "Edgar Solomonik"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.09834"
  },
  {
    "id": "arXiv:2107.11786",
    "title": "Deep Learning-based Frozen Section to FFPE Translation",
    "abstract": "Deep Learning-based Frozen Section to FFPE Translation",
    "descriptor": "",
    "authors": [
      "Kutsev Bengisu Ozyoruk",
      "Sermet Can",
      "Guliz Irem Gokceler",
      "Kayhan Basak",
      "Derya Demir",
      "Gurdeniz Serin",
      "Uguray Payam Hacisalihoglu",
      "Emirhan Kurtulu\u015f",
      "Berkan Darbaz",
      "Ming Y. Lu",
      "Tiffany Y. Chen",
      "Drew F. K. Williamson",
      "Funda Yilmaz",
      "Faisal Mahmood",
      "Mehmet Turan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.11786"
  },
  {
    "id": "arXiv:2107.12922",
    "title": "Griffin: Rethinking Sparse Optimization for Deep Learning Architectures",
    "abstract": "Comments: Accepted at the 28th IEEE International Symposium on High-Performance Computer Architecture - HPCA 2022",
    "descriptor": "\nComments: Accepted at the 28th IEEE International Symposium on High-Performance Computer Architecture - HPCA 2022\n",
    "authors": [
      "Jong Hoon Shin",
      "Ali Shafiee",
      "Ardavan Pedram",
      "Hamzah Abdel-Aziz",
      "Ling Li",
      "Joseph Hassoun"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.12922"
  },
  {
    "id": "arXiv:2107.13875",
    "title": "Spatio-temporal graph neural networks for multi-site PV power  forecasting",
    "abstract": "Comments: 10 pages, 7 figures, accepted for publication in IEEE Transactions on Sustainable Energy",
    "descriptor": "\nComments: 10 pages, 7 figures, accepted for publication in IEEE Transactions on Sustainable Energy\n",
    "authors": [
      "Jelena Simeunovi\u0107",
      "Baptiste Schubnel",
      "Pierre-Jean Alet",
      "Rafael E. Carrillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.13875"
  },
  {
    "id": "arXiv:2108.00238",
    "title": "Unlimited Neighborhood Interaction for Heterogeneous Trajectory  Prediction",
    "abstract": "Unlimited Neighborhood Interaction for Heterogeneous Trajectory  Prediction",
    "descriptor": "",
    "authors": [
      "Fang Zheng",
      "Le Wang",
      "Sanping Zhou",
      "Wei Tang",
      "Zhenxing Niu",
      "Nanning Zheng",
      "Gang Hua"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.00238"
  },
  {
    "id": "arXiv:2108.00376",
    "title": "The Aging Effect in Evolving Scientific Citation Networks",
    "abstract": "The Aging Effect in Evolving Scientific Citation Networks",
    "descriptor": "",
    "authors": [
      "Feng Hu",
      "Lin Ma",
      "Xiu-Xiu Zhan",
      "Yinzuo Zhou",
      "Chuang Liu",
      "Haixing Zhao",
      "Zi-Ke Zhang"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.00376"
  },
  {
    "id": "arXiv:2108.00559",
    "title": "A Machine-Learning-Based Direction-of-Origin Filter for the  Identification of Radio Frequency Interference in the Search for  Technosignatures",
    "abstract": "Comments: 26 pages, 14 figures, submitted for publication (submitted on July 28, 2021)",
    "descriptor": "\nComments: 26 pages, 14 figures, submitted for publication (submitted on July 28, 2021)\n",
    "authors": [
      "Pavlo Pinchuk",
      "Jean-Luc Margot"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.00559"
  },
  {
    "id": "arXiv:2108.01192",
    "title": "Multi-objective Recurrent Neural Networks Optimization for the Edge -- a  Quantization-based Approach",
    "abstract": "Multi-objective Recurrent Neural Networks Optimization for the Edge -- a  Quantization-based Approach",
    "descriptor": "",
    "authors": [
      "Nesma M. Rezk",
      "Tomas Nordstr\u00f6m",
      "Dimitrios Stathis",
      "Zain Ul-Abdin",
      "Eren Erdal Aksoy",
      "Ahmed Hemani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2108.01192"
  },
  {
    "id": "arXiv:2108.01598",
    "title": "Secure and Efficient Blockchain based Knowledge Sharing for Intelligent  Connected Vehicles",
    "abstract": "Comments: 12 pages, 13 figures",
    "descriptor": "\nComments: 12 pages, 13 figures\n",
    "authors": [
      "Haoye Chai",
      "Supeng Leng",
      "Fan Wu",
      "Jianhua He"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.01598"
  },
  {
    "id": "arXiv:2108.02430",
    "title": "Deep Neural Networks and PIDE discretizations",
    "abstract": "Deep Neural Networks and PIDE discretizations",
    "descriptor": "",
    "authors": [
      "Bastian Bohn",
      "Michael Griebel",
      "Dinesh Kannan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.02430"
  },
  {
    "id": "arXiv:2108.02842",
    "title": "Multimodal Meta-Learning for Time Series Regression",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Sebastian Pineda Arango",
      "Felix Heinrich",
      "Kiran Madhusudhanan",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.02842"
  },
  {
    "id": "arXiv:2108.03272",
    "title": "iGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday  Household Tasks",
    "abstract": "Comments: Accepted at Conference on Robot Learning (CoRL) 2021. Project website: this http URL",
    "descriptor": "\nComments: Accepted at Conference on Robot Learning (CoRL) 2021. Project website: this http URL\n",
    "authors": [
      "Chengshu Li",
      "Fei Xia",
      "Roberto Mart\u00edn-Mart\u00edn",
      "Michael Lingelbach",
      "Sanjana Srivastava",
      "Bokui Shen",
      "Kent Vainio",
      "Cem Gokmen",
      "Gokul Dharan",
      "Tanish Jain",
      "Andrey Kurenkov",
      "C. Karen Liu",
      "Hyowon Gweon",
      "Jiajun Wu",
      "Li Fei-Fei",
      "Silvio Savarese"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.03272"
  },
  {
    "id": "arXiv:2108.03458",
    "title": "Scientific X-ray",
    "abstract": "Scientific X-ray",
    "descriptor": "",
    "authors": [
      "Qi Li",
      "Xinbing Wang",
      "Luoyi Fu",
      "Chenghu Zhou"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.03458"
  },
  {
    "id": "arXiv:2108.07931",
    "title": "Learning Federated Representations and Recommendations with Limited  Negatives",
    "abstract": "Learning Federated Representations and Recommendations with Limited  Negatives",
    "descriptor": "",
    "authors": [
      "Lin Ning",
      "Karan Singhal",
      "Ellie X. Zhou",
      "Sushant Prakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.07931"
  },
  {
    "id": "arXiv:2108.07945",
    "title": "A Tighter Relation Between Hereditary Discrepancy and Determinant Lower  Bound",
    "abstract": "Comments: To appear in SOSA 2022. 8 pages",
    "descriptor": "\nComments: To appear in SOSA 2022. 8 pages\n",
    "authors": [
      "Haotian Jiang",
      "Victor Reis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.07945"
  },
  {
    "id": "arXiv:2108.08282",
    "title": "OACAL: Finding Module-consistent Specifications to Secure Systems from  Weakened User Obligations",
    "abstract": "Comments: 9 pages, 15 figures, 3 tables. This paper has been accepted for presentation at the 2021 IEEE Symposium Series on Computational Intelligence (SSCI) (SSCI 2021) and for publication in the conference proceedings published by IEEE",
    "descriptor": "\nComments: 9 pages, 15 figures, 3 tables. This paper has been accepted for presentation at the 2021 IEEE Symposium Series on Computational Intelligence (SSCI) (SSCI 2021) and for publication in the conference proceedings published by IEEE\n",
    "authors": [
      "Pengcheng Jiang",
      "Kenji Tei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08282"
  },
  {
    "id": "arXiv:2108.10629",
    "title": "Improving Generalization of Batch Whitening by Convolutional Unit  Optimization",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Yooshin Cho",
      "Hanbyel Cho",
      "Youngsoo Kim",
      "Junmo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.10629"
  },
  {
    "id": "arXiv:2108.11224",
    "title": "Multi-domain semantic segmentation with overlapping labels",
    "abstract": "Comments: 18 pages, 8 figures, 11 tables",
    "descriptor": "\nComments: 18 pages, 8 figures, 11 tables\n",
    "authors": [
      "Petra Bevandi\u0107",
      "Marin Or\u0161i\u0107",
      "Ivan Grubi\u0161i\u0107",
      "Josip \u0160ari\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11224"
  },
  {
    "id": "arXiv:2108.12188",
    "title": "A High-Fidelity Flow Solver for Unstructured Meshes on  Field-Programmable Gate Arrays",
    "abstract": "Comments: 12 pages, 3 figures, 3 tables, Accepted to HPC Asia 2022",
    "descriptor": "\nComments: 12 pages, 3 figures, 3 tables, Accepted to HPC Asia 2022\n",
    "authors": [
      "Martin Karp",
      "Artur Podobas",
      "Tobias Kenter",
      "Niclas Jansson",
      "Christian Plessl",
      "Philipp Schlatter",
      "Stefano Markidis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.12188"
  },
  {
    "id": "arXiv:2108.12486",
    "title": "Renting Servers in the Cloud: The Case of Equal Duration Jobs",
    "abstract": "Renting Servers in the Cloud: The Case of Equal Duration Jobs",
    "descriptor": "",
    "authors": [
      "Mahtab Masoori",
      "Lata Narayanan",
      "Denis Pankratov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.12486"
  },
  {
    "id": "arXiv:2109.01135",
    "title": "Sequence-to-Sequence Learning with Latent Neural Grammars",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Yoon Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01135"
  },
  {
    "id": "arXiv:2109.03100",
    "title": "Optimal Stroke Learning with Policy Gradient Approach for Robotic Table  Tennis",
    "abstract": "Optimal Stroke Learning with Policy Gradient Approach for Robotic Table  Tennis",
    "descriptor": "",
    "authors": [
      "Yapeng Gao",
      "Jonas Tebbe",
      "Andreas Zell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.03100"
  },
  {
    "id": "arXiv:2109.05112",
    "title": "Improved Latent Tree Induction with Distant Supervision via Span  Constraints",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Zhiyang Xu",
      "Andrew Drozdov",
      "Jay Yoon Lee",
      "Tim O'Gorman",
      "Subendhu Rongali",
      "Dylan Finkbeiner",
      "Shilpa Suresh",
      "Mohit Iyyer",
      "Andrew McCallum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05112"
  },
  {
    "id": "arXiv:2109.05466",
    "title": "Graph Attention Network Based Single-Pixel Compressive Direction of  Arrival Estimation",
    "abstract": "Comments: 5 pages, 4 figures",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "K\u00fcr\u015fat Tekb\u0131y\u0131k",
      "Okan Yurduseven",
      "G\u00fcne\u015f Karabulut Kurt"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05466"
  },
  {
    "id": "arXiv:2109.06610",
    "title": "Statistical limits of dictionary learning: random matrix theory and the  spectral replica method",
    "abstract": "Statistical limits of dictionary learning: random matrix theory and the  spectral replica method",
    "descriptor": "",
    "authors": [
      "Jean Barbier",
      "Nicolas Macris"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2109.06610"
  },
  {
    "id": "arXiv:2109.07103",
    "title": "Automatic Symmetry Discovery with Lie Algebra Convolutional Network",
    "abstract": "Automatic Symmetry Discovery with Lie Algebra Convolutional Network",
    "descriptor": "",
    "authors": [
      "Nima Dehmamy",
      "Robin Walters",
      "Yanchen Liu",
      "Dashun Wang",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2109.07103"
  },
  {
    "id": "arXiv:2109.07950",
    "title": "Learnable Multi-level Frequency Decomposition and Hierarchical Attention  Mechanism for Generalized Face Presentation Attack Detection",
    "abstract": "Comments: Accepted at IEEE Winter Conference on Applications of Computer Vision (WACV 2022)",
    "descriptor": "\nComments: Accepted at IEEE Winter Conference on Applications of Computer Vision (WACV 2022)\n",
    "authors": [
      "Meiling Fang",
      "Naser Damer",
      "Florian Kirchbuchner",
      "Arjan Kuijper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07950"
  },
  {
    "id": "arXiv:2109.08113",
    "title": "MeLT: Message-Level Transformer with Masked Document Representations as  Pre-Training for Stance Detection",
    "abstract": "MeLT: Message-Level Transformer with Masked Document Representations as  Pre-Training for Stance Detection",
    "descriptor": "",
    "authors": [
      "Matthew Matero",
      "Nikita Soni",
      "Niranjan Balasubramanian",
      "H. Andrew Schwartz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.08113"
  },
  {
    "id": "arXiv:2109.09010",
    "title": "Augmenting semantic lexicons using word embeddings and transfer learning",
    "abstract": "Comments: 17 pages, 8 figures",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Thayer Alshaabi",
      "Colin M. Van Oort",
      "Mikaela Irene Fudolig",
      "Michael V. Arnold",
      "Christopher M. Danforth",
      "Peter Sheridan Dodds"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.09010"
  },
  {
    "id": "arXiv:2109.09390",
    "title": "Socially Supervised Representation Learning: the Role of Subjectivity in  Learning Efficient Representations",
    "abstract": "Socially Supervised Representation Learning: the Role of Subjectivity in  Learning Efficient Representations",
    "descriptor": "",
    "authors": [
      "Julius Taylor",
      "Eleni Nisioti",
      "Cl\u00e9ment Moulin-Frier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.09390"
  },
  {
    "id": "arXiv:2109.10187",
    "title": "Oriented Object Detection in Aerial Images Based on Area Ratio of  Parallelogram",
    "abstract": "Oriented Object Detection in Aerial Images Based on Area Ratio of  Parallelogram",
    "descriptor": "",
    "authors": [
      "Xinyi Yu",
      "Mi Lin",
      "Jiangping Lu",
      "Linlin Ou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.10187"
  },
  {
    "id": "arXiv:2109.11808",
    "title": "A dynamic programming algorithm for informative measurements and  near-optimal path-planning",
    "abstract": "A dynamic programming algorithm for informative measurements and  near-optimal path-planning",
    "descriptor": "",
    "authors": [
      "Peter N. Loxley",
      "Ka Wai Cheung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.11808"
  },
  {
    "id": "arXiv:2109.11999",
    "title": "Mining Shape Expressions with ShapeIt",
    "abstract": "Mining Shape Expressions with ShapeIt",
    "descriptor": "",
    "authors": [
      "Ezio Bartocci",
      "Jyotirmoy Deshmukh",
      "Cristinel Mateis",
      "Eleonora Nesterini",
      "Dejan Nickovic",
      "Xin Qin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.11999"
  },
  {
    "id": "arXiv:2110.00318",
    "title": "MATE: Multi-Attribute Table Extraction",
    "abstract": "MATE: Multi-Attribute Table Extraction",
    "descriptor": "",
    "authors": [
      "Mahdi Esmailoghli",
      "Jorge-Arnulfo Quian\u00e9-Ruiz",
      "Ziawasch Abedjan"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.00318"
  },
  {
    "id": "arXiv:2110.00841",
    "title": "Transfer Learning Approaches for Knowledge Discovery in Grid-based  Geo-Spatiotemporal Data",
    "abstract": "Transfer Learning Approaches for Knowledge Discovery in Grid-based  Geo-Spatiotemporal Data",
    "descriptor": "",
    "authors": [
      "Aishwarya Sarkar",
      "Jien Zhang",
      "Chaoqun Lu",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00841"
  },
  {
    "id": "arXiv:2110.01445",
    "title": "Robust and Decomposable Average Precision for Image Retrieval",
    "abstract": "Robust and Decomposable Average Precision for Image Retrieval",
    "descriptor": "",
    "authors": [
      "Elias Ramzi",
      "Nicolas Thome",
      "Cl\u00e9ment Rambour",
      "Nicolas Audebert",
      "Xavier Bitot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.01445"
  },
  {
    "id": "arXiv:2110.01705",
    "title": "Let there be a clock on the beach: Reducing Object Hallucination in  Image Captioning",
    "abstract": "Comments: Accepted to WACV 2022",
    "descriptor": "\nComments: Accepted to WACV 2022\n",
    "authors": [
      "Ali Furkan Biten",
      "Lluis Gomez",
      "Dimosthenis Karatzas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01705"
  },
  {
    "id": "arXiv:2110.01895",
    "title": "Investigating the Impact of Pre-trained Language Models on Dialog  Evaluation",
    "abstract": "Comments: Accepted by IWSDS2021 (Long Paper)",
    "descriptor": "\nComments: Accepted by IWSDS2021 (Long Paper)\n",
    "authors": [
      "Chen Zhang",
      "Luis Fernando D'Haro",
      "Yiming Chen",
      "Thomas Friedrichs",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.01895"
  },
  {
    "id": "arXiv:2110.02473",
    "title": "The Power of Contrast for Feature Learning: A Theoretical Analysis",
    "abstract": "Comments: 44 pages",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Wenlong Ji",
      "Zhun Deng",
      "Ryumei Nakada",
      "James Zou",
      "Linjun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02473"
  },
  {
    "id": "arXiv:2110.03083",
    "title": "Vision-based Excavator Activity Analysis and Safety Monitoring System",
    "abstract": "Vision-based Excavator Activity Analysis and Safety Monitoring System",
    "descriptor": "",
    "authors": [
      "Sibo Zhang",
      "Liangjun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.03083"
  },
  {
    "id": "arXiv:2110.03469",
    "title": "Federated Learning from Small Datasets",
    "abstract": "Federated Learning from Small Datasets",
    "descriptor": "",
    "authors": [
      "Michael Kamp",
      "Jonas Fischer",
      "Jilles Vreeken"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.03469"
  },
  {
    "id": "arXiv:2110.03485",
    "title": "Cartoon Explanations of Image Classifiers",
    "abstract": "Cartoon Explanations of Image Classifiers",
    "descriptor": "",
    "authors": [
      "Stefan Kolek",
      "Duc Anh Nguyen",
      "Ron Levie",
      "Joan Bruna",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03485"
  },
  {
    "id": "arXiv:2110.05076",
    "title": "A Closer Look at Prototype Classifier for Few-shot Image Classification",
    "abstract": "Comments: 10 pages with 6 appendix section",
    "descriptor": "\nComments: 10 pages with 6 appendix section\n",
    "authors": [
      "Mingcheng Hou",
      "Issei Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05076"
  },
  {
    "id": "arXiv:2110.07067",
    "title": "Offline Reinforcement Learning for Autonomous Driving with Safety and  Exploration Enhancement",
    "abstract": "Comments: Machine Learning for Autonomous Driving Workshop on NeurIPS 2021",
    "descriptor": "\nComments: Machine Learning for Autonomous Driving Workshop on NeurIPS 2021\n",
    "authors": [
      "Tianyu Shi",
      "Dong Chen",
      "Kaian Chen",
      "Zhaojian Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.07067"
  },
  {
    "id": "arXiv:2110.07554",
    "title": "Looper: An end-to-end ML platform for product decisions",
    "abstract": "Comments: 10 pages + references, 5 figures",
    "descriptor": "\nComments: 10 pages + references, 5 figures\n",
    "authors": [
      "Igor L. Markov",
      "Hanson Wang",
      "Nitya Kasturi",
      "Shaun Singh",
      "Sze Wai Yuen",
      "Mia Garrard",
      "Sarah Tran",
      "Yin Huang",
      "Zehui Wang",
      "Igor Glotov",
      "Tanvi Gupta",
      "Boshuang Huang",
      "Peng Chen",
      "Xiaowen Xie",
      "Michael Belkin",
      "Sal Uryasev",
      "Sam Howie",
      "Eytan Bakshy",
      "Norm Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.07554"
  },
  {
    "id": "arXiv:2110.08642",
    "title": "Local Advantage Actor-Critic for Robust Multi-Agent Deep Reinforcement  Learning",
    "abstract": "Local Advantage Actor-Critic for Robust Multi-Agent Deep Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "Yuchen Xiao",
      "Xueguang Lyu",
      "Christopher Amato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.08642"
  },
  {
    "id": "arXiv:2110.09113",
    "title": "Salt and pepper noise removal method based on stationary Framelet  transform with non-convex sparsity regularization",
    "abstract": "Salt and pepper noise removal method based on stationary Framelet  transform with non-convex sparsity regularization",
    "descriptor": "",
    "authors": [
      "Yingpin Chen",
      "Yuming Huang",
      "Lingzhi Wang",
      "Huiying Huang",
      "Jianhua Song",
      "Chaoqun Yu",
      "Yanping Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09113"
  },
  {
    "id": "arXiv:2110.09469",
    "title": "Hybrid PUF: A Novel Way to Enhance the Security of Classical PUFs",
    "abstract": "Hybrid PUF: A Novel Way to Enhance the Security of Classical PUFs",
    "descriptor": "",
    "authors": [
      "Kaushik Chakraborty",
      "Mina Doosti",
      "Yao Ma",
      "Myrto Arapinis",
      "Elham Kashefi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.09469"
  },
  {
    "id": "arXiv:2110.10332",
    "title": "AI-Based Detection, Classification and Prediction/Prognosis in Medical  Imaging: Towards Radiophenomics",
    "abstract": "AI-Based Detection, Classification and Prediction/Prognosis in Medical  Imaging: Towards Radiophenomics",
    "descriptor": "",
    "authors": [
      "Fereshteh Yousefirizi",
      "Pierre Decazes",
      "Amine Amyar",
      "Su Ruan",
      "Babak Saboury",
      "Arman Rahmim"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.10332"
  },
  {
    "id": "arXiv:2110.10349",
    "title": "Distributed Reinforcement Learning for Privacy-Preserving Dynamic Edge  Caching",
    "abstract": "Comments: 15 pages, 9 figures, under review with the IEEE Journal on Selected Areas in Communications",
    "descriptor": "\nComments: 15 pages, 9 figures, under review with the IEEE Journal on Selected Areas in Communications\n",
    "authors": [
      "Shengheng Liu",
      "Chong Zheng",
      "Yongming Huang",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.10349"
  },
  {
    "id": "arXiv:2110.10394",
    "title": "Deep Learning for HDR Imaging: State-of-the-Art and Future Trends",
    "abstract": "Comments: IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), main paper",
    "descriptor": "\nComments: IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), main paper\n",
    "authors": [
      "Lin Wang",
      "Kuk-Jin Yoon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10394"
  },
  {
    "id": "arXiv:2110.10572",
    "title": "Estimation & Recognition under Perspective of Random-Fuzzy Dual  Interpretation of Unknown Quantity: with Demonstration of IMM Filter",
    "abstract": "Comments: 15 pages, 11 figures, code available, title changed",
    "descriptor": "\nComments: 15 pages, 11 figures, code available, title changed\n",
    "authors": [
      "Wei Mei",
      "Yunfeng Xu",
      "Limin Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.10572"
  },
  {
    "id": "arXiv:2110.11061",
    "title": "Polyadic Sets and Homomorphism Counting",
    "abstract": "Comments: 40 pages. v2: Presentation improved",
    "descriptor": "\nComments: 40 pages. v2: Presentation improved\n",
    "authors": [
      "Luca Reggio"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2110.11061"
  },
  {
    "id": "arXiv:2110.11283",
    "title": "The Effect of Wearing a Face Mask on Face Image Quality",
    "abstract": "Comments: Accepted at the 16th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2021",
    "descriptor": "\nComments: Accepted at the 16th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2021\n",
    "authors": [
      "Biying Fu",
      "Florian Kirchbuchner",
      "Naser Damer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.11283"
  },
  {
    "id": "arXiv:2110.11661",
    "title": "UVO Challenge on Video-based Open-World Segmentation 2021: 1st Place  Solution",
    "abstract": "Comments: Code:this https URL arXiv admin note: substantial text overlap with arXiv:2110.10239",
    "descriptor": "\nComments: Code:this https URL arXiv admin note: substantial text overlap with arXiv:2110.10239\n",
    "authors": [
      "Yuming Du",
      "Wen Guo",
      "Yang Xiao",
      "Vincent Lepetit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11661"
  },
  {
    "id": "arXiv:2110.12246",
    "title": "Parametric Variational Linear Units (PVLUs) in Deep Convolutional  Networks",
    "abstract": "Comments: Both authors contributed equally to this research, currently under review for publication at the Elsevier Journal of Computer Vision and Image Understanding",
    "descriptor": "\nComments: Both authors contributed equally to this research, currently under review for publication at the Elsevier Journal of Computer Vision and Image Understanding\n",
    "authors": [
      "Aarush Gupta",
      "Shikhar Ahuja"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12246"
  },
  {
    "id": "arXiv:2110.12616",
    "title": "Lower bounds on quantum query complexity for symmetric functions",
    "abstract": "Comments: 24 pages, 2 figures",
    "descriptor": "\nComments: 24 pages, 2 figures\n",
    "authors": [
      "Rajat Mittal",
      "Sanjay S Nair",
      "Sunayana Patro"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.12616"
  },
  {
    "id": "arXiv:2110.13067",
    "title": "Evolutionary Optimization of High-Coverage Budgeted Classifiers",
    "abstract": "Comments: Minor revisions, reformatting, and additional comparisons",
    "descriptor": "\nComments: Minor revisions, reformatting, and additional comparisons\n",
    "authors": [
      "Nolan H. Hamilton",
      "Errin W. Fulp"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13067"
  },
  {
    "id": "arXiv:2110.13746",
    "title": "H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction  of Humans in Motion",
    "abstract": "H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction  of Humans in Motion",
    "descriptor": "",
    "authors": [
      "Hongyi Xu",
      "Thiemo Alldieck",
      "Cristian Sminchisescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13746"
  },
  {
    "id": "arXiv:2110.14115",
    "title": "Metrics of research impact in astronomy: Predicting later impact from  metrics measured 10-15 years after the PhD",
    "abstract": "Comments: This preprint is being criticized based on a perception that it furthers bias against women and minorities. My book on the subject documents evidence for bias and develops machinery aimed in part to redress it. Further explanation is posted at this http URL . Wishing to protect PNAS from controversy, I have withdrawn the PNAS paper. I therefore withdraw the preprint",
    "descriptor": "\nComments: This preprint is being criticized based on a perception that it furthers bias against women and minorities. My book on the subject documents evidence for bias and develops machinery aimed in part to redress it. Further explanation is posted at this http URL . Wishing to protect PNAS from controversy, I have withdrawn the PNAS paper. I therefore withdraw the preprint\n",
    "authors": [
      "John Kormendy"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2110.14115"
  },
  {
    "id": "arXiv:2110.14124",
    "title": "A novel decompostion-based multiobjective evolutionary algorithm with an  application to engineering optimal design problems",
    "abstract": "A novel decompostion-based multiobjective evolutionary algorithm with an  application to engineering optimal design problems",
    "descriptor": "",
    "authors": [
      "Wang Chen",
      "Jian Chen",
      "Weitian Wu",
      "Xinmin Yang",
      "Hui Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.14124"
  },
  {
    "id": "arXiv:2110.14270",
    "title": "Counterfactual Shapley Additive Explanations",
    "abstract": "Comments: Camera-ready accepted at XAIF '21 (Workshop on Explainable AI in Finance) at ACM ICAIF '21 (this https URL)",
    "descriptor": "\nComments: Camera-ready accepted at XAIF '21 (Workshop on Explainable AI in Finance) at ACM ICAIF '21 (this https URL)\n",
    "authors": [
      "Emanuele Albini",
      "Jason Long",
      "Danial Dervovic",
      "Daniele Magazzeni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14270"
  },
  {
    "id": "arXiv:2110.14389",
    "title": "Charon: Load-Aware Load-Balancing in P4",
    "abstract": "Charon: Load-Aware Load-Balancing in P4",
    "descriptor": "",
    "authors": [
      "Carmine Rizzi",
      "Zhiyuan Yao",
      "Yoann Desmouceaux",
      "Mark Townsley",
      "Thomas Heide Clausen"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.14389"
  },
  {
    "id": "arXiv:2110.14864",
    "title": "Selective Sampling for Online Best-arm Identification",
    "abstract": "Comments: 42 pages, 2 figures, Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: 42 pages, 2 figures, Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Romain Camilleri",
      "Zhihan Xiong",
      "Maryam Fazel",
      "Lalit Jain",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14864"
  },
  {
    "id": "arXiv:2110.14875",
    "title": "Finding a Concise, Precise, and Exhaustive Set of Near Bi-Cliques in  Dynamic Graphs",
    "abstract": "Comments: To be published in WSDM 2022",
    "descriptor": "\nComments: To be published in WSDM 2022\n",
    "authors": [
      "Hyeonjeong Shin",
      "Taehyung Kwon",
      "Neil Shah",
      "Kijung Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.14875"
  },
  {
    "id": "arXiv:2110.14890",
    "title": "SMORE: Knowledge Graph Completion and Multi-hop Reasoning in Massive  Knowledge Graphs",
    "abstract": "SMORE: Knowledge Graph Completion and Multi-hop Reasoning in Massive  Knowledge Graphs",
    "descriptor": "",
    "authors": [
      "Hongyu Ren",
      "Hanjun Dai",
      "Bo Dai",
      "Xinyun Chen",
      "Denny Zhou",
      "Jure Leskovec",
      "Dale Schuurmans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.14890"
  },
  {
    "id": "arXiv:2110.14940",
    "title": "FocusFace: Multi-task Contrastive Learning for Masked Face Recognition",
    "abstract": "Comments: Accepted at the 16th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2021",
    "descriptor": "\nComments: Accepted at the 16th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2021\n",
    "authors": [
      "Pedro C. Neto",
      "Fadi Boutros",
      "Jo\u00e3o Ribeiro Pinto",
      "Naser Damer",
      "Ana F. Sequeira",
      "Jaime S. Cardoso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14940"
  },
  {
    "id": "arXiv:2110.15084",
    "title": "Using Non-Linear Causal Models to Study Aerosol-Cloud Interactions in  the Southeast Pacific",
    "abstract": "Using Non-Linear Causal Models to Study Aerosol-Cloud Interactions in  the Southeast Pacific",
    "descriptor": "",
    "authors": [
      "Andrew Jesson",
      "Peter Manshausen",
      "Alyson Douglas",
      "Duncan Watson-Parris",
      "Yarin Gal",
      "Philip Stier"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2110.15084"
  },
  {
    "id": "arXiv:2110.15122",
    "title": "CAFE: Catastrophic Data Leakage in Vertical Federated Learning",
    "abstract": "CAFE: Catastrophic Data Leakage in Vertical Federated Learning",
    "descriptor": "",
    "authors": [
      "Xiao Jin",
      "Pin-Yu Chen",
      "Chia-Yi Hsu",
      "Chia-Mu Yu",
      "Tianyi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15122"
  },
  {
    "id": "arXiv:2110.15412",
    "title": "Stochastic Mirror Descent: Convergence Analysis and Adaptive Variants  via the Mirror Stochastic Polyak Stepsize",
    "abstract": "Stochastic Mirror Descent: Convergence Analysis and Adaptive Variants  via the Mirror Stochastic Polyak Stepsize",
    "descriptor": "",
    "authors": [
      "Ryan D'Orazio",
      "Nicolas Loizou",
      "Issam Laradji",
      "Ioannis Mitliagkas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15412"
  },
  {
    "id": "arXiv:2110.15444",
    "title": "10 Security and Privacy Problems in Self-Supervised Learning",
    "abstract": "Comments: A book chapter",
    "descriptor": "\nComments: A book chapter\n",
    "authors": [
      "Jinyuan Jia",
      "Hongbin Liu",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15444"
  },
  {
    "id": "arXiv:2110.15715",
    "title": "An Effective Image Restorer: Denoising and Luminance Adjustment for  Low-photon-count Imaging",
    "abstract": "An Effective Image Restorer: Denoising and Luminance Adjustment for  Low-photon-count Imaging",
    "descriptor": "",
    "authors": [
      "Shansi Zhang",
      "Edmund Y. Lam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15715"
  },
  {
    "id": "arXiv:2110.15720",
    "title": "Weakly Supervised Concept Map Generation through Task-Guided Graph  Translation",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Jiaying Lu",
      "Xiangjue Dong",
      "Carl Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15720"
  },
  {
    "id": "arXiv:2111.00082",
    "title": "PiDRAM: A Holistic End-to-end FPGA-based Framework for  Processing-in-DRAM",
    "abstract": "Comments: 15 pages, 11 figures",
    "descriptor": "\nComments: 15 pages, 11 figures\n",
    "authors": [
      "Ataberk Olgun",
      "Juan G\u00f3mez Luna",
      "Konstantinos Kanellopoulos",
      "Behzad Salami",
      "Hasan Hassan",
      "O\u011fuz Ergin",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.00082"
  },
  {
    "id": "arXiv:2111.00116",
    "title": "Visual Explanations for Convolutional Neural Networks via Latent  Traversal of Generative Adversarial Networks",
    "abstract": "Comments: 2 pages, 2 figures, to appear as extended abstract at AAAI-22",
    "descriptor": "\nComments: 2 pages, 2 figures, to appear as extended abstract at AAAI-22\n",
    "authors": [
      "Amil Dravid",
      "Aggelos K. Katsaggelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.00116"
  },
  {
    "id": "arXiv:2111.00429",
    "title": "Enhancing Top-N Item Recommendations by Peer Collaboration",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Yang Sun",
      "Fajie Yuan",
      "Min Yang",
      "Alexandros Karatzoglou",
      "Shen Li",
      "Xiaoyan Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.00429"
  },
  {
    "id": "arXiv:2111.00598",
    "title": "Recognizing Families In the Wild (RFIW): The 5th Edition",
    "abstract": "Comments: 2021 Conference on Automatic Face and Gesture Recognition",
    "descriptor": "\nComments: 2021 Conference on Automatic Face and Gesture Recognition\n",
    "authors": [
      "Joseph P. Robinson",
      "Can Qin",
      "Ming Shao",
      "Matthew A. Turk",
      "Rama Chellappa",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00598"
  },
  {
    "id": "arXiv:2111.00660",
    "title": "Evaluation of Human and Machine Face Detection using a Novel Distinctive  Human Appearance Dataset",
    "abstract": "Evaluation of Human and Machine Face Detection using a Novel Distinctive  Human Appearance Dataset",
    "descriptor": "",
    "authors": [
      "Necdet Gurkan",
      "Jordan W. Suchow"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00660"
  },
  {
    "id": "arXiv:2111.00674",
    "title": "Distilling Object Detectors with Feature Richness",
    "abstract": "Comments: Accepted in NeurIPS 2021",
    "descriptor": "\nComments: Accepted in NeurIPS 2021\n",
    "authors": [
      "Zhixing Du",
      "Rui Zhang",
      "Ming Chang",
      "Xishan Zhang",
      "Shaoli Liu",
      "Tianshi Chen",
      "Yunji Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00674"
  },
  {
    "id": "arXiv:2111.00772",
    "title": "AdaPool: Exponential Adaptive Pooling for Information-Retaining  Downsampling",
    "abstract": "AdaPool: Exponential Adaptive Pooling for Information-Retaining  Downsampling",
    "descriptor": "",
    "authors": [
      "Alexandros Stergiou",
      "Ronald Poppe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00772"
  },
  {
    "id": "arXiv:2111.00801",
    "title": "Livestock Monitoring with Transformer",
    "abstract": "Comments: Accepted at BMVC 2021",
    "descriptor": "\nComments: Accepted at BMVC 2021\n",
    "authors": [
      "Bhavesh Tangirala",
      "Ishan Bhandari",
      "Daniel Laszlo",
      "Deepak K. Gupta",
      "Rajat M. Thomas",
      "Devanshu Arya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00801"
  },
  {
    "id": "arXiv:2111.00826",
    "title": "Teaching Fairness, Accountability, Confidentiality, and Transparency in  Artificial Intelligence through the Lens of Reproducibility",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Ana Lucic",
      "Maurits Bleeker",
      "Sami Jullien",
      "Samarth Bhargav",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00826"
  },
  {
    "id": "arXiv:2111.00856",
    "title": "Large-Scale Deep Learning Optimizations: A Comprehensive Survey",
    "abstract": "Large-Scale Deep Learning Optimizations: A Comprehensive Survey",
    "descriptor": "",
    "authors": [
      "Xiaoxin He",
      "Fuzhao Xue",
      "Xiaozhe Ren",
      "Yang You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00856"
  },
  {
    "id": "arXiv:2111.00868",
    "title": "A mathematical model of the vowel space",
    "abstract": "A mathematical model of the vowel space",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Berthommier"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Classical Physics (physics.class-ph)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2111.00868"
  },
  {
    "id": "arXiv:2111.00905",
    "title": "Smart Fashion: A Review of AI Applications in the Fashion & Apparel  Industry",
    "abstract": "Comments: 99 Pages, 79 Figures, 24 Tables, Full length manuscript",
    "descriptor": "\nComments: 99 Pages, 79 Figures, 24 Tables, Full length manuscript\n",
    "authors": [
      "Seyed Omid Mohammadi",
      "Ahmad Kalhor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00905"
  },
  {
    "id": "arXiv:2111.00929",
    "title": "Bounds all around: training energy-based models with bidirectional  bounds",
    "abstract": "Comments: This paper has been accepted by NeurIPS 2021",
    "descriptor": "\nComments: This paper has been accepted by NeurIPS 2021\n",
    "authors": [
      "Cong Geng",
      "Jia Wang",
      "Zhiyong Gao",
      "Jes Frellsen",
      "S\u00f8ren Hauberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00929"
  },
  {
    "id": "arXiv:2111.00947",
    "title": "Nested Multiple Instance Learning with Attention Mechanisms",
    "abstract": "Comments: Submitted to ICASSP 2022",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Saul Fuster",
      "Trygve Eftest\u00f8l",
      "Kjersti Engan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00947"
  },
  {
    "id": "arXiv:2111.00961",
    "title": "Robustness of deep learning algorithms in astronomy -- galaxy morphology  studies",
    "abstract": "Comments: Accepted in: Fourth Workshop on Machine Learning and the Physical Sciences (35th Conference on Neural Information Processing Systems; NeurIPS2021); final version",
    "descriptor": "\nComments: Accepted in: Fourth Workshop on Machine Learning and the Physical Sciences (35th Conference on Neural Information Processing Systems; NeurIPS2021); final version\n",
    "authors": [
      "A. \u0106iprijanovi\u0107",
      "D. Kafkes",
      "G. N. Perdue",
      "K. Pedro",
      "G. Snyder",
      "F. J. S\u00e1nchez",
      "S. Madireddy",
      "S. M. Wild",
      "B. Nord"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00961"
  },
  {
    "id": "arXiv:2111.00962",
    "title": "RefineGAN: Universally Generating Waveform Better than Ground Truth with  Highly Accurate Pitch and Intensity Responses",
    "abstract": "RefineGAN: Universally Generating Waveform Better than Ground Truth with  Highly Accurate Pitch and Intensity Responses",
    "descriptor": "",
    "authors": [
      "Shengyuan Xu",
      "Wenxiao Zhao",
      "Jing Guo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.00962"
  },
  {
    "id": "arXiv:2111.00995",
    "title": "Sign-to-Speech Model for Sign Language Understanding: A Case Study of  Nigerian Sign Language",
    "abstract": "Sign-to-Speech Model for Sign Language Understanding: A Case Study of  Nigerian Sign Language",
    "descriptor": "",
    "authors": [
      "Steven Kolawole",
      "Opeyemi Osakuade",
      "Nayan Saxena",
      "Babatunde Kazeem Olorisade"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00995"
  }
]
[
  {
    "id": "arXiv:2110.15362",
    "title": "BitTrain: Sparse Bitmap Compression for Memory-Efficient Training on the  Edge",
    "abstract": "Training on the Edge enables neural networks to learn continuously from new\ndata after deployment on memory-constrained edge devices. Previous work is\nmostly concerned with reducing the number of model parameters which is only\nbeneficial for inference. However, memory footprint from activations is the\nmain bottleneck for training on the edge. Existing incremental training methods\nfine-tune the last few layers sacrificing accuracy gains from re-training the\nwhole model. In this work, we investigate the memory footprint of training deep\nlearning models, and use our observations to propose BitTrain. In BitTrain, we\nexploit activation sparsity and propose a novel bitmap compression technique\nthat reduces the memory footprint during training. We save the activations in\nour proposed bitmap compression format during the forward pass of the training,\nand restore them during the backward pass for the optimizer computations. The\nproposed method can be integrated seamlessly in the computation graph of modern\ndeep learning frameworks. Our implementation is safe by construction, and has\nno negative impact on the accuracy of model training. Experimental results show\nup to 34% reduction in the memory footprint at a sparsity level of 50%. Further\npruning during training results in more than 70% sparsity, which can lead to up\nto 56% reduction in memory footprint. BitTrain advances the efforts towards\nbringing more machine learning capabilities to edge devices. Our source code is\navailable at https://github.com/scale-lab/BitTrain.",
    "descriptor": "\nComments: 12 pages, 13 figures, to appear in the proceedings of The Sixth ACM/IEEE Symposium on Edge Computing (SEC 2021)\n",
    "authors": [
      "Abdelrahman Hosny",
      "Marina Neseem",
      "Sherief Reda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.15362"
  },
  {
    "id": "arXiv:2110.15367",
    "title": "Neural Disparity Refinement for Arbitrary Resolution Stereo",
    "abstract": "We introduce a novel architecture for neural disparity refinement aimed at\nfacilitating deployment of 3D computer vision on cheap and widespread consumer\ndevices, such as mobile phones. Our approach relies on a continuous formulation\nthat enables to estimate a refined disparity map at any arbitrary output\nresolution. Thereby, it can handle effectively the unbalanced camera setup\ntypical of nowadays mobile phones, which feature both high and low resolution\nRGB sensors within the same device. Moreover, our neural network can process\nseamlessly the output of a variety of stereo methods and, by refining the\ndisparity maps computed by a traditional matching algorithm like SGM, it can\nachieve unpaired zero-shot generalization performance compared to\nstate-of-the-art end-to-end stereo models.",
    "descriptor": "\nComments: 3DV 2021 Oral paper. Project page: this https URL\n",
    "authors": [
      "Filippo Aleotti",
      "Fabio Tosi",
      "Pierluigi Zama Ramirez",
      "Matteo Poggi",
      "Samuele Salti",
      "Stefano Mattoccia",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15367"
  },
  {
    "id": "arXiv:2110.15383",
    "title": "New SAR target recognition based on YOLO and very deep multi-canonical  correlation analysis",
    "abstract": "Synthetic Aperture Radar (SAR) images are prone to be contaminated by noise,\nwhich makes it very difficult to perform target recognition in SAR images.\nInspired by great success of very deep convolutional neural networks (CNNs),\nthis paper proposes a robust feature extraction method for SAR image target\nclassification by adaptively fusing effective features from different CNN\nlayers. First, YOLOv4 network is fine-tuned to detect the targets from the\nrespective MF SAR target images. Second, a very deep CNN is trained from\nscratch on the moving and stationary target acquisition and recognition (MSTAR)\ndatabase by using small filters throughout the whole net to reduce the speckle\nnoise. Besides, using small-size convolution filters decreases the number of\nparameters in each layer and, therefore, reduces computation cost as the CNN\ngoes deeper. The resulting CNN model is capable of extracting very deep\nfeatures from the target images without performing any noise filtering or\npre-processing techniques. Third, our approach proposes to use the\nmulti-canonical correlation analysis (MCCA) to adaptively learn CNN features\nfrom different layers such that the resulting representations are highly\nlinearly correlated and therefore can achieve better classification accuracy\neven if a simple linear support vector machine is used. Experimental results on\nthe MSTAR dataset demonstrate that the proposed method outperforms the\nstate-of-the-art methods.",
    "descriptor": "\nComments: 20 pages. International Journal of Remote Sensing (2021)\n",
    "authors": [
      "Moussa Amrani",
      "Abdelatif Bey",
      "Abdenour Amamra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15383"
  },
  {
    "id": "arXiv:2110.15385",
    "title": "Data-driven Residual Generation for Early Fault Detection with Limited  Data",
    "abstract": "Traditionally, fault detection and isolation community has used system\ndynamic equations to generate diagnosers and to analyze detectability and\nisolability of the dynamic systems. Model-based fault detection and isolation\nmethods use system model to generate a set of residuals as the bases for fault\ndetection and isolation. However, in many complex systems it is not feasible to\ndevelop highly accurate models for the systems and to keep the models updated\nduring the system lifetime. Recently, data-driven solutions have received an\nimmense attention in the industries systems for several practical reasons.\nFirst, these methods do not require the initial investment and expertise for\ndeveloping accurate models. Moreover, it is possible to automatically update\nand retrain the diagnosers as the system or the environment change over time.\nFinally, unlike the model-based methods it is straight forward to combine time\nseries measurements such as pressure and voltage with other sources of\ninformation such as system operating hours to achieve a higher accuracy. In\nthis paper, we extend the traditional model-based fault detection and isolation\nconcepts such as residuals, and detectable and isolable faults to the\ndata-driven domain. We then propose an algorithm to automatically generate\nresiduals from the normal operating data. We present the performance of our\nproposed approach through a comparative case study.",
    "descriptor": "",
    "authors": [
      "Hamed Khorasgani",
      "Ahmed Farahat",
      "Chetan Gupta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15385"
  },
  {
    "id": "arXiv:2110.15387",
    "title": "Anticipation-driven Adaptive Architecture for Assisted Living",
    "abstract": "Anticipatory expression underlies human performance. Medical conditions and,\nespecially, aging result in diminished anticipatory action. In order to\nmitigate the loss, means for engaging still available resources (capabilities)\ncan be provided. In particular, anticipation-driven adaptive environments could\nbe beneficial in medical care, as well as in assisted living for those seeking\nsuch assistance. These adaptive environments are conceived to be individualized\nand individualizable, in order to stimulate independent action instead of\ncreating dependencies.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Mihai Nadin",
      "Asma Naz"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15387"
  },
  {
    "id": "arXiv:2110.15390",
    "title": "Adaptive Coalition Formation-Based Coordinated Voltage Regulation in  Distribution Networks",
    "abstract": "High penetrations of photovoltaic (PV) systems can cause severe voltage\nquality problems in distribution networks. This paper proposes a distributed\ncontrol strategy based on the dynamic formation of coalitions to coordinate a\nlarge number of PV inverters for voltage regulation. In this strategy, a\nrule-based coalition formation scheme deals with the zonal voltage difference\ncaused by the uneven integration of PV capacity. Under this scheme, PV\ninverters form into separate voltage regulation coalitions autonomously\naccording to local, neighbor as well as coalition voltage magnitude and\nregulation capacity information. To coordinate control within each coalition,\nwe develop a feedback-based leader-follower consensus algorithm which\neliminates the voltage violations caused by the fast fluctuations of load and\nPV generation. This algorithm allocates the required reactive power\ncontribution among the PV inverters according to their maximum available\ncapacity to promote an effective and fair use of the overall voltage regulation\ncapacity. Case studies based on realistic distribution networks and\nfield-recorded data validate the effectiveness of the proposed control\nstrategy. Moreover, comparison with a centralized network decomposition-based\nscheme shows the flexibility of coalition formation in organizing the\ndistributed PV inverters. The robustness and generalizability of the proposed\nstrategy are also demonstrated.",
    "descriptor": "",
    "authors": [
      "Yao Long",
      "Ryan T. Elliott",
      "Daniel S. Kirschen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.15390"
  },
  {
    "id": "arXiv:2110.15395",
    "title": "The Optimal Error Resilience of Interactive Communication Over Binary  Channels",
    "abstract": "In interactive coding, Alice and Bob wish to compute some function $f$ of\ntheir individual private inputs $x$ and $y$. They do this by engaging in a\nnon-adaptive (fixed order, fixed length) protocol to jointly compute $f(x,y)$.\nThe goal is to do this in an error-resilient way, such that even given some\nfraction of adversarial corruptions, both parties still learn $f(x,y)$.\nIn this work, we study the optimal error resilience of such a protocol in the\nface of adversarial bit flip or erasures. While the optimal error resilience of\nsuch a protocol over a large alphabet is well understood, the situation over\nthe binary alphabet has remained open. In this work, we resolve this problem of\ndetermining the optimal error resilience over binary channels. In particular,\nwe construct protocols achieving $\\frac16$ error resilience over the binary bit\nflip channel and $\\frac12$ error resilience over the binary erasure channel,\nfor both of which matching upper bounds are known. We remark that the\ncommunication complexity of our binary bit flip protocol is polynomial in the\nsize of the inputs, and the communication complexity of our binary erasure\nprotocol is linear in the size of the minimal noiseless protocol computing $f$.",
    "descriptor": "",
    "authors": [
      "Meghal Gupta",
      "Rachel Yun Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15395"
  },
  {
    "id": "arXiv:2110.15397",
    "title": "A Computationally Efficient Method for Learning Exponential Family  Distributions",
    "abstract": "We consider the question of learning the natural parameters of a $k$\nparameter minimal exponential family from i.i.d. samples in a computationally\nand statistically efficient manner. We focus on the setting where the support\nas well as the natural parameters are appropriately bounded. While the\ntraditional maximum likelihood estimator for this class of exponential family\nis consistent, asymptotically normal, and asymptotically efficient, evaluating\nit is computationally hard. In this work, we propose a computationally\nefficient estimator that is consistent as well as asymptotically normal under\nmild conditions. We provide finite sample guarantees to achieve an ($\\ell_2$)\nerror of $\\alpha$ in the parameter estimation with sample complexity\n$O(\\mathrm{poly}(k/\\alpha))$ and computational complexity\n${O}(\\mathrm{poly}(k/\\alpha))$. To establish these results, we show that, at\nthe population level, our method can be viewed as the maximum likelihood\nestimation of a re-parameterized distribution belonging to the same class of\nexponential family.",
    "descriptor": "",
    "authors": [
      "Abhin Shah",
      "Devavrat Shah",
      "Gregory W. Wornell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15397"
  },
  {
    "id": "arXiv:2110.15401",
    "title": "The role of mechano-electric feedbacks and hemodynamic coupling in  scar-related ventricular tachycardia",
    "abstract": "Mechano-electric feedbacks (MEFs), which model how mechanical stimuli are\ntransduced into electrical signals, have received sparse investigation by\nconsidering electromechanical simulations in simplified scenarios. In this\npaper, we study the effects of different MEFs modeling choices for myocardial\ndeformation and nonselective stretch-activated channels (SACs) in the\nmonodomain equation. We perform numerical simulations during ventricular\ntachycardia (VT) by employing a biophysically detailed and anatomically\naccurate 3D electromechanical model for the left ventricle (LV) coupled with a\n0D closed-loop model of the cardiocirculatory system. We model the\nelectromechanical substrate responsible for scar-related VT with a distribution\nof infarct and peri-infarct zones. Our mathematical framework takes into\naccount the hemodynamic effects of VT due to myocardial impairment and allows\nfor the classification of their hemodynamic nature, which can be either stable\nor unstable. By combining electrophysiological, mechanical and hemodynamic\nmodels, we observe that all MEFs may alter the propagation of the action\npotential and the morphology of the VT. In particular, we notice that the\npresence of myocardial deformation in the monodomain equation may change the VT\nbasis cycle length and the conduction velocity but do not affect the\nhemodynamic nature of the VT. Finally, nonselective SACs may affect wavefront\nstability, by possibly turning a hemodynamically stable VT into a\nhemodynamically unstable one and vice versa.",
    "descriptor": "",
    "authors": [
      "Matteo Salvador",
      "Francesco Regazzoni",
      "Stefano Pagani",
      "Luca Dede'",
      "Natalia Trayanova",
      "Alfio Quarteroni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2110.15401"
  },
  {
    "id": "arXiv:2110.15403",
    "title": "Selective Regression Under Fairness Criteria",
    "abstract": "Selective regression allows abstention from prediction if the confidence to\nmake an accurate prediction is not sufficient. In general, by allowing a reject\noption, one expects the performance of a regression model to increase at the\ncost of reducing coverage (i.e., by predicting fewer samples). However, as\nshown in this work, in some cases, the performance of minority group can\ndecrease while we reduce the coverage, and thus selective regression can\nmagnify disparities between different sensitive groups. We show that such an\nunwanted behavior can be avoided if we can construct features satisfying the\nsufficiency criterion, so that the mean prediction and the associated\nuncertainty are calibrated across all the groups. Further, to mitigate the\ndisparity in the performance across groups, we introduce two approaches based\non this calibration criterion: (a) by regularizing an upper bound of\nconditional mutual information under a Gaussian assumption and (b) by\nregularizing a contrastive loss for mean and uncertainty prediction. The\neffectiveness of these approaches are demonstrated on synthetic as well as\nreal-world datasets.",
    "descriptor": "",
    "authors": [
      "Abhin Shah",
      "Yuheng Bu",
      "Joshua Ka-Wing Lee",
      "Subhro Das",
      "Rameswar Panda",
      "Prasanna Sattigeri",
      "Gregory W. Wornell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15403"
  },
  {
    "id": "arXiv:2110.15405",
    "title": "Stand-alone device for IoT applications",
    "abstract": "Internet of Things (IoT) is a digital world of connected and talking devices,\nproviding room for countless and diverse smart applications. This paper\nproposes one such IoT enabled stand-alone device with numerous capabilities:\n(i) interaction with user, (ii) required application selection, (iii) data\nsensing, (iv) data publish, and (v) decision making and actuation. The\nalgorithm allows user to pick an application and input specific data for\ncalibration, which on completion enables the device for further working. To\nverify and test its capability, a smart home garden environment is created\nusing this device, temperature, humidity, soil moisture sensors and actuators.\nAs it is implicit that real-time communication is inevitable for an IoT\napplication, the sensor data is published to a Mosquitto MQTT broker to permit\nreal-time remote access. The decision taken by the device is sent to actuators\nvia relay, thus a continuous monitoring process is achieved. Results are\nobtained for the application which proves the device suitability for IoT\napplications.",
    "descriptor": "\nComments: 5 pages, 7 figures, yet to be published\n",
    "authors": [
      "Neha K Nawandar",
      "Naveen Cheggoju",
      "Vishal R Satpute"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.15405"
  },
  {
    "id": "arXiv:2110.15409",
    "title": "What makes us curious? analysis of a corpus of open-domain questions",
    "abstract": "Every day people ask short questions through smart devices or online forums\nto seek answers to all kinds of queries. With the increasing number of\nquestions collected it becomes difficult to provide answers to each of them,\nwhich is one of the reasons behind the growing interest in automated question\nanswering. Some questions are similar to existing ones that have already been\nanswered, while others could be answered by an external knowledge source such\nas Wikipedia. An important question is what can be revealed by analysing a\nlarge set of questions. In 2017, \"We the Curious\" science centre in Bristol\nstarted a project to capture the curiosity of Bristolians: the project\ncollected more than 10,000 questions on various topics. As no rules were given\nduring collection, the questions are truly open-domain, and ranged across a\nvariety of topics. One important aim for the science centre was to understand\nwhat concerns its visitors had beyond science, particularly on societal and\ncultural issues. We addressed this question by developing an Artificial\nIntelligence tool that can be used to perform various processing tasks:\ndetection of equivalence between questions; detection of topic and type; and\nanswering of the question. As we focused on the creation of a \"generalist\"\ntool, we trained it with labelled data from different datasets. We called the\nresulting model QBERT. This paper describes what information we extracted from\nthe automated analysis of the WTC corpus of open-domain questions.",
    "descriptor": "",
    "authors": [
      "Zhaozhen Xu",
      "Amelia Howarth",
      "Nicole Briggs",
      "Nello Cristianini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15409"
  },
  {
    "id": "arXiv:2110.15415",
    "title": "On the Use of CSI for the Generation of RF Fingerprints and Secret Keys",
    "abstract": "This paper presents a systematic approach to use channel state information\nfor authentication and secret key distillation for physical layer security\n(PLS). We use popular machine learning (ML) methods and signal processing-based\napproaches to disentangle the large scale fading and be used as a source of\nuniqueness, from the small scale fading, to be treated as a source of shared\nentropy secret key generation (SKG). The ML-based approaches are completely\nunsupervised and hence avoid exhaustive measurement campaigns. We also propose\nusing the Hilbert Schmidt independence criterion (HSIC); our simulation results\ndemonstrate that the extracted stochastic part of the channel state information\n(CSI) vectors are statistically independent.",
    "descriptor": "",
    "authors": [
      "Muralikrishnan Srinivasan",
      "Sotiris Skaperas",
      "Arsenia Chorti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.15415"
  },
  {
    "id": "arXiv:2110.15416",
    "title": "On computing root polynomials and minimal bases of matrix pencils",
    "abstract": "We revisit the notion of root polynomials, thoroughly studied in [F. Dopico\nand V. Noferini, Root polynomials and their role in the theory of matrix\npolynomials, Linear Algebra Appl. 584:37--78, 2020] for general polynomial\nmatrices, and show how they can efficiently be computed in the case of matrix\npencils. The staircase algorithm implicitly computes so-called zero directions,\nas defined in [P. Van Dooren, Computation of zero directions of transfer\nfunctions, Proceedings IEEE 32nd CDC, 3132--3137, 1993]. However, zero\ndirections generally do not provide the correct information on partial\nmultiplicities and minimal indices. These indices are instead provided by two\nspecial cases of zero directions, namely, root polynomials and vectors of a\nminimal basis of the pencil. We show how to extract, starting from the block\ntriangular pencil that the staircase algorithm computes, both a minimal basis\nand a maximal set of root polynomials in an efficient manner. Moreover, we\nargue that the accuracy of the computation of the root polynomials can be\nimproved by making use of iterative refinement.",
    "descriptor": "",
    "authors": [
      "Vanni Noferini",
      "Paul Van Dooren"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15416"
  },
  {
    "id": "arXiv:2110.15417",
    "title": "Vulnerability Characterization and Privacy Quantification for  Cyber-Physical Systems",
    "abstract": "Cyber-physical systems (CPS) data privacy protection during sharing,\naggregating, and publishing is a challenging problem. Several privacy\nprotection mechanisms have been developed in the literature to protect\nsensitive data from adversarial analysis and eliminate the risk of\nre-identifying the original properties of shared data. However, most of the\nexisting solutions have drawbacks, such as (i) lack of a proper vulnerability\ncharacterization model to accurately identify where privacy is needed, (ii)\nignoring data providers privacy preference, (iii) using uniform privacy\nprotection which may create inadequate privacy for some provider while\noverprotecting others, and (iv) lack of a comprehensive privacy quantification\nmodel assuring data privacy-preservation. To address these issues, we propose a\npersonalized privacy preference framework by characterizing and quantifying the\nCPS vulnerabilities as well as ensuring privacy. First, we introduce a standard\nvulnerability profiling library (SVPL) by arranging the nodes of an energy-CPS\nfrom maximum to minimum vulnerable based on their privacy loss. Based on this\nmodel, we present our personalized privacy framework (PDP) in which Laplace\nnoise is added based on the individual node's selected privacy preferences.\nFinally, combining these two proposed methods, we demonstrate that our privacy\ncharacterization and quantification model can attain better privacy\npreservation by eliminating the trade-off between privacy, utility, and risk of\nlosing information.",
    "descriptor": "\nComments: Accepted in the 2021 IEEE International Conference on Cyber, Physical and Social Computing\n",
    "authors": [
      "Arpan Bhattacharjee",
      "Shahriar Badsha",
      "Md Tamjid Hossain",
      "Charalambos Konstantinou",
      "Xueping Liang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.15417"
  },
  {
    "id": "arXiv:2110.15419",
    "title": "EPTAS and Subexponential Algorithm for Maximum Clique on Disk and Unit  Ball Graphs",
    "abstract": "A (unit) disk graph is the intersection graph of closed (unit) disks in the\nplane. Almost three decades ago, an elegant polynomial-time algorithm was found\nfor \\textsc{Maximum Clique} on unit disk graphs [Clark, Colbourn, Johnson;\nDiscrete Mathematics '90]. Since then, it has been an intriguing open question\nwhether or not tractability can be extended to general disk graphs. We show\nthat the disjoint union of two odd cycles is never the complement of a disk\ngraph nor of a unit (3-dimensional) ball graph. From that fact and existing\nresults, we derive a simple QPTAS and a subexponential algorithm running in\ntime $2^{\\tilde{O}(n^{2/3})}$ for \\textsc{Maximum Clique} on disk and unit ball\ngraphs. We then obtain a randomized EPTAS for computing the independence number\non graphs having no disjoint union of two odd cycles as an induced subgraph,\nbounded VC-dimension, and linear independence number. This, in combination with\nour structural results, yields a randomized EPTAS for \\textsc{Max Clique} on\ndisk and unit ball graphs. \\textsc{Max Clique} on unit ball graphs is\nequivalent to finding, given a collection of points in $\\mathbb R^3$, a maximum\nsubset of points with diameter at most some fixed value. In stark contrast,\n\\textsc{Maximum Clique} on ball graphs and unit $4$-dimensional ball graphs, as\nwell as intersection graphs of filled ellipses (even close to unit disks) or\nfilled triangles is unlikely to have such algorithms. Indeed, we show that, for\nall those problems, there is a constant ratio of approximation which cannot be\nattained even in time $2^{n^{1-\\varepsilon}}$, unless the Exponential Time\nHypothesis fails.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1712.05010, arXiv:1803.01822\n",
    "authors": [
      "Marthe Bonamy",
      "\u00c9douard Bonnet",
      "Nicolas Bousquet",
      "Pierre Charbit",
      "Panos Giannopoulos",
      "Eun Jung Kim",
      "Pawe\u0142 Rz\u0105\u017cewski",
      "Florian Sikora",
      "St\u00e9phan Thomass\u00e9"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.15419"
  },
  {
    "id": "arXiv:2110.15420",
    "title": "Iterative and greedy algorithms for the sparsity in levels model in  compressed sensing",
    "abstract": "Motivated by the question of optimal functional approximation via compressed\nsensing, we propose generalizations of the Iterative Hard Thresholding and the\nCompressive Sampling Matching Pursuit algorithms able to promote sparse in\nlevels signals. We show, by means of numerical experiments, that the proposed\nalgorithms are successfully able to outperform their unstructured variants when\nthe signal exhibits the sparsity structure of interest. Moreover, in the\ncontext of piecewise smooth function approximation, we numerically demonstrate\nthat the structure promoting decoders outperform their unstructured variants\nand the basis pursuit program when the encoder is structure agnostic.",
    "descriptor": "",
    "authors": [
      "Ben Adcock",
      "Simone Brugiapaglia",
      "Matthew King-Roskamp"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15420"
  },
  {
    "id": "arXiv:2110.15421",
    "title": "Recognizing k-leaf powers in polynomial time, for constant k",
    "abstract": "A graph $G$ is a $k$-leaf power if there exists a tree $T$ whose leaf set is\n$V(G)$, and such that $uv \\in E(G)$ if and only if the distance between $u$ and\n$v$ in $T$ is at most $k$. The graph classes of $k$-leaf powers have several\napplications in computational biology, but recognizing them has remained a\nchallenging algorithmic problem for the past two decades. The best known result\nis that $6$-leaf powers can be recognized in polynomial time. In this paper, we\npresent an algorithm that decides whether a graph $G$ is a $k$-leaf power in\ntime $O(n^{f(k)})$ for some function $f$ that depends only on $k$ (but has the\ngrowth rate of a power tower function).\nOur techniques are based on the fact that either a $k$-leaf power has a\ncorresponding tree of low maximum degree, in which case finding it is easy, or\nevery corresponding tree has large maximum degree. In the latter case, large\ndegree vertices in the tree imply that $G$ has redundant substructures which\ncan be pruned from the graph. In addition to solving a longstanding open\nproblem, we hope that the structural results presented in this work can lead to\nfurther results on $k$-leaf powers.",
    "descriptor": "",
    "authors": [
      "Manuel Lafond"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15421"
  },
  {
    "id": "arXiv:2110.15425",
    "title": "Cognac: Domain-Specific Compilation for Cognitive Models",
    "abstract": "This paper discusses our proposal and implementation of Cognac, a\ndomain-specific compilation tool based on LLVM to accelerate cognitive models.\nCognitive models explain the process of cognitive function and offer a path to\nhuman-like artificial intelligence. However, cognitive modeling is laborious,\nrequiring composition of many types of computational tasks, and suffers from\npoor performance as it relies on high-level languages like Python. In order to\ncontinue enjoying the flexibility of Python while achieving high performance,\nCognac uses domain-specific knowledge to compile Python-based cognitive models\ninto LLVM IR, carefully stripping away features like dynamic typing and memory\nmanagement that add overheads to the actual model. As we show, this permits\nsignificantly faster model execution. We also show that the code so generated\nenables using classical compiler data flow analysis passes to reveal properties\nabout data flow in cognitive models that are useful to cognitive scientists.\nCognac is publicly available, is being used by researchers in cognitive\nscience, and has led to patches that are currently being evaluated for\nintegration into mainline LLVM.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Jan Vesely",
      "Raghavendra Pradyumna Pothukuchi",
      "Ketaki Joshi",
      "Samyak Gupta",
      "Jonathan D. Cohen",
      "Abhishek Bhattacharjee"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.15425"
  },
  {
    "id": "arXiv:2110.15426",
    "title": "RadBERT-CL: Factually-Aware Contrastive Learning For Radiology Report  Classification",
    "abstract": "Radiology reports are unstructured and contain the imaging findings and\ncorresponding diagnoses transcribed by radiologists which include clinical\nfacts and negated and/or uncertain statements. Extracting pathologic findings\nand diagnoses from radiology reports is important for quality control,\npopulation health, and monitoring of disease progress. Existing works,\nprimarily rely either on rule-based systems or transformer-based pre-trained\nmodel fine-tuning, but could not take the factual and uncertain information\ninto consideration, and therefore generate false-positive outputs. In this\nwork, we introduce three sedulous augmentation techniques which retain factual\nand critical information while generating augmentations for contrastive\nlearning. We introduce RadBERT-CL, which fuses these information into BlueBert\nvia a self-supervised contrastive loss. Our experiments on MIMIC-CXR show\nsuperior performance of RadBERT-CL on fine-tuning for multi-class, multi-label\nreport classification. We illustrate that when few labeled data are available,\nRadBERT-CL outperforms conventional SOTA transformers (BERT/BlueBert) by\nsignificantly larger margins (6-11%). We also show that the representations\nlearned by RadBERT-CL can capture critical medical information in the latent\nspace.",
    "descriptor": "",
    "authors": [
      "Ajay Jaiswal",
      "Liyan Tang",
      "Meheli Ghosh",
      "Justin Rousseau",
      "Yifan Peng",
      "Ying Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15426"
  },
  {
    "id": "arXiv:2110.15430",
    "title": "Improving Noise Robustness of Contrastive Speech Representation Learning  with Speech Reconstruction",
    "abstract": "Noise robustness is essential for deploying automatic speech recognition\n(ASR) systems in real-world environments. One way to reduce the effect of noise\ninterference is to employ a preprocessing module that conducts speech\nenhancement, and then feed the enhanced speech to an ASR backend. In this work,\ninstead of suppressing background noise with a conventional cascaded pipeline,\nwe employ a noise-robust representation learned by a refined self-supervised\nframework for noisy speech recognition. We propose to combine a reconstruction\nmodule with contrastive learning and perform multi-task continual pre-training\non noisy data. The reconstruction module is used for auxiliary learning to\nimprove the noise robustness of the learned representation and thus is not\nrequired during inference. Experiments demonstrate the effectiveness of our\nproposed method. Our model substantially reduces the word error rate (WER) for\nthe synthesized noisy LibriSpeech test sets, and yields around 4.1/7.5% WER\nreduction on noisy clean/other test sets compared to data augmentation. For the\nreal-world noisy speech from the CHiME-4 challenge (1-channel track), we have\nobtained the state of the art ASR performance without any denoising front-end.\nMoreover, we achieve comparable performance to the best supervised approach\nreported with only 16% of labeled data.",
    "descriptor": "\nComments: 5 pages, 1 figure, submitted to ICASSP 2022\n",
    "authors": [
      "Heming Wang",
      "Yao Qian",
      "Xiaofei Wang",
      "Yiming Wang",
      "Chengyi Wang",
      "Shujie Liu",
      "Takuya Yoshioka",
      "Jinyu Li",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15430"
  },
  {
    "id": "arXiv:2110.15431",
    "title": "Universal Decision Models",
    "abstract": "Humans are universal decision makers: we reason causally to understand the\nworld; we act competitively to gain advantage in commerce, games, and war; and\nwe are able to learn to make better decisions through trial and error. In this\npaper, we propose Universal Decision Model (UDM), a mathematical formalism\nbased on category theory. Decision objects in a UDM correspond to instances of\ndecision tasks, ranging from causal models and dynamical systems such as Markov\ndecision processes and predictive state representations, to network multiplayer\ngames and Witsenhausen's intrinsic models, which generalizes all these previous\nformalisms. A UDM is a category of objects, which include decision objects,\nobservation objects, and solution objects. Bisimulation morphisms map between\ndecision objects that capture structure-preserving abstractions. We formulate\nuniversal properties of UDMs, including information integration, decision\nsolvability, and hierarchical abstraction. We describe universal functorial\nrepresentations of UDMs, and propose an algorithm for computing the minimal\nobject in a UDM using algebraic topology. We sketch out an application of UDMs\nto causal inference in network economics, using a complex multiplayer\nproducer-consumer two-sided marketplace.",
    "descriptor": "",
    "authors": [
      "Sridhar Mahadevan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15431"
  },
  {
    "id": "arXiv:2110.15433",
    "title": "Fuzzm: Finding Memory Bugs through Binary-Only Instrumentation and  Fuzzing of WebAssembly",
    "abstract": "WebAssembly binaries are often compiled from memory-unsafe languages, such as\nC and C++. Because of WebAssembly's linear memory and missing protection\nfeatures, e.g., stack canaries, source-level memory vulnerabilities are\nexploitable in compiled WebAssembly binaries, sometimes even more easily than\nin native code. This paper addresses the problem of detecting such\nvulnerabilities through the first binary-only fuzzer for WebAssembly. Our\napproach, called Fuzzm, combines canary instrumentation to detect overflows and\nunderflows on the stack and the heap, an efficient coverage instrumentation, a\nWebAssembly VM, and the input generation algorithm of the popular AFL fuzzer.\nBesides as an oracle for fuzzing, our canaries also serve as a stand-alone\nbinary hardening technique to prevent the exploitation of vulnerable binaries\nin production. We evaluate Fuzzm with 28 real-world WebAssembly binaries, some\ncompiled from source and some found in the wild without source code. The fuzzer\nexplores thousands of execution paths, triggers dozens of crashes, and performs\nhundreds of program executions per second. When used for binary hardening, the\napproach prevents previously published exploits against vulnerable WebAssembly\nbinaries while imposing low runtime overhead.",
    "descriptor": "\nComments: Source code repository: this https URL\n",
    "authors": [
      "Daniel Lehmann",
      "Martin Toldam Torp",
      "Michael Pradel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.15433"
  },
  {
    "id": "arXiv:2110.15438",
    "title": "InfoGCL: Information-Aware Graph Contrastive Learning",
    "abstract": "Various graph contrastive learning models have been proposed to improve the\nperformance of learning tasks on graph datasets in recent years. While\neffective and prevalent, these models are usually carefully customized. In\nparticular, although all recent researches create two contrastive views, they\ndiffer greatly in view augmentations, architectures, and objectives. It remains\nan open question how to build your graph contrastive learning model from\nscratch for particular graph learning tasks and datasets. In this work, we aim\nto fill this gap by studying how graph information is transformed and\ntransferred during the contrastive learning process and proposing an\ninformation-aware graph contrastive learning framework called InfoGCL. The key\npoint of this framework is to follow the Information Bottleneck principle to\nreduce the mutual information between contrastive parts while keeping\ntask-relevant information intact at both the levels of the individual module\nand the entire framework so that the information loss during graph\nrepresentation learning can be minimized. We show for the first time that all\nrecent graph contrastive learning methods can be unified by our framework. We\nempirically validate our theoretical analysis on both node and graph\nclassification benchmark datasets, and demonstrate that our algorithm\nsignificantly outperforms the state-of-the-arts.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Dongkuan Xu",
      "Wei Cheng",
      "Dongsheng Luo",
      "Haifeng Chen",
      "Xiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15438"
  },
  {
    "id": "arXiv:2110.15439",
    "title": "Dense Hierarchical Retrieval for Open-Domain Question Answering",
    "abstract": "Dense neural text retrieval has achieved promising results on open-domain\nQuestion Answering (QA), where latent representations of questions and passages\nare exploited for maximum inner product search in the retrieval process.\nHowever, current dense retrievers require splitting documents into short\npassages that usually contain local, partial, and sometimes biased context, and\nhighly depend on the splitting process. As a consequence, it may yield\ninaccurate and misleading hidden representations, thus deteriorating the final\nretrieval result. In this work, we propose Dense Hierarchical Retrieval (DHR),\na hierarchical framework that can generate accurate dense representations of\npassages by utilizing both macroscopic semantics in the document and\nmicroscopic semantics specific to each passage. Specifically, a document-level\nretriever first identifies relevant documents, among which relevant passages\nare then retrieved by a passage-level retriever. The ranking of the retrieved\npassages will be further calibrated by examining the document-level relevance.\nIn addition, hierarchical title structure and two negative sampling strategies\n(i.e., In-Doc and In-Sec negatives) are investigated. We apply DHR to\nlarge-scale open-domain QA datasets. DHR significantly outperforms the original\ndense passage retriever and helps an end-to-end QA system outperform the strong\nbaselines on multiple open-domain QA benchmarks.",
    "descriptor": "\nComments: EMNLP 2021 Findings\n",
    "authors": [
      "Ye Liu",
      "Kazuma Hashimoto",
      "Yingbo Zhou",
      "Semih Yavuz",
      "Caiming Xiong",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.15439"
  },
  {
    "id": "arXiv:2110.15440",
    "title": "HD-cos Networks: Efficient Neural Architectures for Secure Multi-Party  Computation",
    "abstract": "Multi-party computation (MPC) is a branch of cryptography where multiple\nnon-colluding parties execute a well designed protocol to securely compute a\nfunction. With the non-colluding party assumption, MPC has a cryptographic\nguarantee that the parties will not learn sensitive information from the\ncomputation process, making it an appealing framework for applications that\ninvolve privacy-sensitive user data. In this paper, we study training and\ninference of neural networks under the MPC setup. This is challenging because\nthe elementary operations of neural networks such as the ReLU activation\nfunction and matrix-vector multiplications are very expensive to compute due to\nthe added multi-party communication overhead. To address this, we propose the\nHD-cos network that uses 1) cosine as activation function, 2) the\nHadamard-Diagonal transformation to replace the unstructured linear\ntransformations. We show that both of the approaches enjoy strong theoretical\nmotivations and efficient computation under the MPC setup. We demonstrate on\nmultiple public datasets that HD-cos matches the quality of the more expensive\nbaselines.",
    "descriptor": "",
    "authors": [
      "Wittawat Jitkrittum",
      "Michal Lukasik",
      "Ananda Theertha Suresh",
      "Felix Yu",
      "Gang Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15440"
  },
  {
    "id": "arXiv:2110.15442",
    "title": "Scalable Uni-directional Pareto Optimality for Multi-Task Learning with  Constraints",
    "abstract": "We propose a scalable Pareto solver for Multi-Objective Optimization (MOO)\nproblems, including support for optimization under constraints. An important\napplication of this solver is to estimate high-dimensional neural models for\nMOO classification tasks. We demonstrate significant runtime and space\nimprovement using our solver \\vs prior methods, verify that solutions found are\ntruly Pareto optimal on a benchmark set of known non-convex MOO problems from\n{\\em operations research}, and provide a practical evaluation against prior\nmethods for Multi-Task Learning (MTL).",
    "descriptor": "",
    "authors": [
      "Soumyajit Gupta",
      "Gurpreet Singh",
      "Matthew Lease"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15442"
  },
  {
    "id": "arXiv:2110.15443",
    "title": "Equivariant $Q$ Learning in Spatial Action Spaces",
    "abstract": "Recently, a variety of new equivariant neural network model architectures\nhave been proposed that generalize better over rotational and reflectional\nsymmetries than standard models. These models are relevant to robotics because\nmany robotics problems can be expressed in a rotationally symmetric way. This\npaper focuses on equivariance over a visual state space and a spatial action\nspace -- the setting where the robot action space includes a subset of\n$\\rm{SE}(2)$. In this situation, we know a priori that rotations and\ntranslations in the state image should result in the same rotations and\ntranslations in the spatial action dimensions of the optimal policy. Therefore,\nwe can use equivariant model architectures to make $Q$ learning more sample\nefficient. This paper identifies when the optimal $Q$ function is equivariant\nand proposes $Q$ network architectures for this setting. We show experimentally\nthat this approach outperforms standard methods in a set of challenging\nmanipulation problems.",
    "descriptor": "\nComments: Accepted at Conference on Robot Learning (CoRL) 2021\n",
    "authors": [
      "Dian Wang",
      "Robin Walters",
      "Xupeng Zhu",
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.15443"
  },
  {
    "id": "arXiv:2110.15444",
    "title": "10 Security and Privacy Problems in Self-Supervised Learning",
    "abstract": "Self-supervised learning has achieved revolutionary progress in the past\nseveral years and is commonly believed to be a promising approach for\ngeneral-purpose AI. In particular, self-supervised learning aims to pre-train\nan encoder using a large amount of unlabeled data. The pre-trained encoder is\nlike an \"operating system\" of the AI ecosystem. In particular, the encoder can\nbe used as a feature extractor for many downstream tasks with little or no\nlabeled training data. Existing studies on self-supervised learning mainly\nfocused on pre-training a better encoder to improve its performance on\ndownstream tasks in non-adversarial settings, leaving its security and privacy\nin adversarial settings largely unexplored. A security or privacy issue of a\npre-trained encoder leads to a single point of failure for the AI ecosystem. In\nthis book chapter, we discuss 10 basic security and privacy problems for the\npre-trained encoders in self-supervised learning, including six confidentiality\nproblems, three integrity problems, and one availability problem. For each\nproblem, we discuss potential opportunities and challenges. We hope our book\nchapter will inspire future research on the security and privacy of\nself-supervised learning.",
    "descriptor": "\nComments: A book chapter\n",
    "authors": [
      "Jinyuan Jia",
      "Hongbin Liu",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15444"
  },
  {
    "id": "arXiv:2110.15447",
    "title": "On Wasted Contributions: Understanding the Dynamics of  Contributor-Abandoned Pull Requests",
    "abstract": "Pull-based development has enabled numerous volunteers to contribute to\nopen-source projects with fewer barriers. Nevertheless, a considerable amount\nof pull requests (PRs) with valid contributions are abandoned by their\ncontributors, wasting the effort and time put in by both their contributors and\nmaintainers. To gain a more comprehensive understanding of the underlying\ndynamics of contributor-abandoned PRs, we conduct a mixed-methods study using\nboth quantitative and qualitative methods. We curate a dataset consisting of\n265,325 PRs including 4,450 abandoned ones from ten popular and mature GitHub\nprojects and measure 16 features characterizing PRs, contributors, review\nprocesses, and projects. Using statistical and machine learning techniques, we\nobserve that complex PRs, novice contributors, and lengthy reviews have a\nhigher probability of abandonment and the rate of PR abandonment fluctuates\nalongside the projects' maturity or workload. To identify why contributors\nabandon their PRs, we also manually examine a random sample of 354 abandoned\nPRs. We find that the most frequent abandonment reasons are related to the\nobstacles faced by contributors, followed by the hurdles imposed by maintainers\nduring the review process. Finally, we survey the top core maintainers of the\nstudy projects to understand their perspectives on dealing with PR abandonment\nand on our findings.",
    "descriptor": "\nComments: Manuscript submitted to ACM Transactions on Software Engineering and Methodology\n",
    "authors": [
      "SayedHassan Khatoonabadi",
      "Diego Elias Costa",
      "Rabe Abdalkareem",
      "Emad Shihab"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.15447"
  },
  {
    "id": "arXiv:2110.15448",
    "title": "Automated Translation of Rebar Information from GPR Data into As-Built  BIM: A Deep Learning-based Approach",
    "abstract": "Building Information Modeling (BIM) is increasingly used in the construction\nindustry, but existing studies often ignore embedded rebars. Ground Penetrating\nRadar (GPR) provides a potential solution to develop as-built BIM with surface\nelements and rebars. However, automatically translating rebars from GPR into\nBIM is challenging since GPR cannot provide any information about the scanned\nelement. Thus, we propose an approach to link GPR data and BIM according to\nFaster R-CNN. A label is attached to each element scanned by GPR for capturing\nthe labeled images, which are used with other images to build a 3D model.\nMeanwhile, Faster R-CNN is introduced to identify the labels, and the\nprojection relationship between images and the model is used to localize the\nscanned elements in the 3D model. Two concrete buildings is selected to\nevaluate the proposed approach, and the results reveal that our method could\naccurately translate the rebars from GPR data into corresponding elements in\nBIM with correct distributions.",
    "descriptor": "\nComments: 8 pages, the 2021 ASCE International Conference on Computing in Civil Engineering\n",
    "authors": [
      "Zhongming Xiang",
      "Ge Ou",
      "Abbas Rashidi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15448"
  },
  {
    "id": "arXiv:2110.15453",
    "title": "Using Text Analytics for Health to Get Meaningful Insights from a Corpus  of COVID Scientific Papers",
    "abstract": "Since the beginning of COVID pandemic, there have been around 700000\nscientific papers published on the subject. A human researcher cannot possibly\nget acquainted with such a huge text corpus -- and therefore developing\nAI-based tools to help navigating this corpus and deriving some useful insights\nfrom it is highly needed. In this paper, we will use Text Analytics for Health\npre-trained service together with some cloud tools to extract some knowledge\nfrom scientific papers, gain insights, and build a tool to help researcher\nnavigate the paper collection in a meaningful way.",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Dmitry Soshnikov",
      "Vickie Soshnikova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.15453"
  },
  {
    "id": "arXiv:2110.15454",
    "title": "VigDet: Knowledge Informed Neural Temporal Point Process for  Coordination Detection on Social Media",
    "abstract": "Recent years have witnessed an increasing use of coordinated accounts on\nsocial media, operated by misinformation campaigns to influence public opinion\nand manipulate social outcomes. Consequently, there is an urgent need to\ndevelop an effective methodology for coordinated group detection to combat the\nmisinformation on social media. However, existing works suffer from various\ndrawbacks, such as, either limited performance due to extreme reliance on\npredefined signatures of coordination, or instead an inability to address the\nnatural sparsity of account activities on social media with useful prior domain\nknowledge. Therefore, in this paper, we propose a coordination detection\nframework incorporating neural temporal point process with prior knowledge such\nas temporal logic or pre-defined filtering functions. Specifically, when\nmodeling the observed data from social media with neural temporal point\nprocess, we jointly learn a Gibbs-like distribution of group assignment based\non how consistent an assignment is to (1) the account embedding space and (2)\nthe prior knowledge. To address the challenge that the distribution is hard to\nbe efficiently computed and sampled from, we design a theoretically guaranteed\nvariational inference approach to learn a mean-field approximation for it.\nExperimental results on a real-world dataset show the effectiveness of our\nproposed method compared to the SOTA model in both unsupervised and\nsemi-supervised settings. We further apply our model on a COVID-19 Vaccine\nTweets dataset. The detection result suggests the presence of suspicious\ncoordinated efforts on spreading misinformation about COVID-19 vaccines.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021. 17 pages, 5 figures\n",
    "authors": [
      "Yizhou Zhang",
      "Karishma Sharma",
      "Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.15454"
  },
  {
    "id": "arXiv:2110.15456",
    "title": "FAST: DNN Training Under Variable Precision Block Floating Point with  Stochastic Rounding",
    "abstract": "Block Floating Point (BFP) can efficiently support quantization for Deep\nNeural Network (DNN) training by providing a wide dynamic range via a shared\nexponent across a group of values. In this paper, we propose a Fast First,\nAccurate Second Training (FAST) system for DNNs, where the weights,\nactivations, and gradients are represented in BFP. FAST supports matrix\nmultiplication with variable precision BFP input operands, enabling incremental\nincreases in DNN precision throughout training. By increasing the BFP precision\nacross both training iterations and DNN layers, FAST can greatly shorten the\ntraining time while reducing overall hardware resource usage. Our FAST\nMultipler-Accumulator (fMAC) supports dot product computations under multiple\nBFP precisions. We validate our FAST system on multiple DNNs with different\ndatasets, demonstrating a 2-6$\\times$ speedup in training on a single-chip\nplatform over prior work based on \\textbf{mixed-precision or block} floating\npoint number systems while achieving similar performance in validation\naccuracy.",
    "descriptor": "",
    "authors": [
      "Sai Qian Zhang",
      "Bradley McDanel",
      "H.T. Kung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.15456"
  },
  {
    "id": "arXiv:2110.15457",
    "title": "DFL: High-Performance Blockchain-Based Federated Learning",
    "abstract": "Many researchers are trying to replace the aggregation server in federated\nlearning with a blockchain system to achieve better privacy, robustness and\nscalability. In this case, clients will upload their updated models to the\nblockchain ledger, and use a smart contract on the blockchain system to perform\nmodel averaging. However, running machine learning applications on the\nblockchain is almost impossible because a blockchain system, which usually\ntakes over half minute to generate a block, is extremely slow and unable to\nsupport machine learning applications.\nThis paper proposes a completely new public blockchain architecture called\nDFL, which is specially optimized for distributed federated machine learning.\nThis architecture inherits most traditional blockchain merits and achieves\nextremely high performance with low resource consumption by waiving global\nconsensus. To characterize the performance and robustness of our architecture,\nwe implement the architecture as a prototype and test it on a physical\nfour-node network. To test more nodes and more complex situations, we build a\nsimulator to simulate the network. The LeNet results indicate our system can\nreach over 90% accuracy for non-I.I.D. datasets even while facing model\npoisoning attacks, with the blockchain consuming less than 5% of hardware\nresources.",
    "descriptor": "\nComments: 11 pages, 17 figures\n",
    "authors": [
      "Yongding Tian",
      "Zhuoran Guo",
      "Jiaxuan Zhang",
      "Zaid Al-Ars"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.15457"
  },
  {
    "id": "arXiv:2110.15460",
    "title": "Human-Computer Interaction Glow Up: Examining Operational Trust and  Intention Towards Mars Autonomous Systems",
    "abstract": "Tactful coordination on earth between hundreds of operators from diverse\ndisciplines and backgrounds is needed to ensure that Martian rovers have a high\nlikelihood of achieving their science goals while enduring the harsh\nenvironment of the red planet. The operations team includes many individuals,\neach with independent and overlapping objectives, working to decide what to\nexecute on the Mars surface during the next planning period. The team must work\ntogether to understand each other's objectives and constraints within a fixed\ntime period, often requiring frequent revision. This study examines the\nchallenges faced during Mars surface operations, from high-level science\nobjectives to formulating a valid, safe, and optimal activity plan that is\nready to be radiated to the rover. Through this examination, we aim to\nilluminate how planning intent can be formulated and effectively communicated\nto future spacecrafts that will become more and more autonomous. Our findings\nreveal the intricate nature of human-to-human interactions that require a large\narray of soft skills and core competencies to communicate concurrently with\nscience and engineering teams during plan formulation. Additionally, our\nfindings exposed significant challenges in eliciting planning intent from\noperators, which will intensify in the future, as operators on the ground\nasynchronously co-operate the rover with the on board autonomy. Building a\nmarvellous robot and landing it onto the Mars surface are remarkable feats\n-however, ensuring that scientists can get the best out of the mission is an\nongoing challenge and will not cease to be a difficult task with increased\nautonomy.",
    "descriptor": "\nComments: 9 pages, 1 figure, to appear in Proceedings of the 2021 American Institute of Aeronautics and Astronautics ASCEND Conference (AIAA ASCEND 2021)\n",
    "authors": [
      "Thomas Chan",
      "Jeremy Argueta",
      "Jazlyn Armendariz",
      "Allison Graham",
      "Sarah Hwang",
      "Basak Ramaswamy",
      "So Young Kim",
      "Scott Davidoff"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.15460"
  },
  {
    "id": "arXiv:2110.15465",
    "title": "A hierarchical behavior prediction framework at signalized intersections",
    "abstract": "Road user behavior prediction is one of the most critical components in\ntrajectory planning for autonomous driving, especially in urban scenarios\ninvolving traffic signals. In this paper, a hierarchical framework is proposed\nto predict vehicle behaviors at a signalized intersection, using the traffic\nsignal information of the intersection. The framework is composed of two\nphases: a discrete intention prediction phase and a continuous trajectory\nprediction phase. In the discrete intention prediction phase, a Bayesian\nnetwork is adopted to predict the vehicle's high-level intention, after that,\nmaximum entropy inverse reinforcement learning is utilized to learn the human\ndriving model offline; during the online trajectory prediction phase, a driver\ncharacteristic is designed and updated to capture the different driving\npreferences between human drivers. We applied the proposed framework to one of\nthe most challenging scenarios in autonomous driving: the yellow light running\nscenario. Numerical experiment results are presented in the later part of the\npaper which show the viability of the method. The accuracy of the Bayesian\nnetwork for discrete intention prediction is 91.1%, and the prediction results\nare getting more and more accurate as the yellow time elapses. The average\nEuclidean distance error in continuous trajectory prediction is only 0.85 m in\nthe yellow light running scenario.",
    "descriptor": "\nComments: This work has been accepted to the IEEE 2021 International Conference on Intelligent Transportation Systems\n",
    "authors": [
      "Zhen Yang",
      "Rusheng Zhang",
      "Henry X. Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.15465"
  },
  {
    "id": "arXiv:2110.15473",
    "title": "AWSOM-LP: An Effective Log Parsing Technique Using Pattern Recognition  and Frequency Analysis",
    "abstract": "Logs provide users with useful insights to help with a variety of development\nand operations tasks. The problem is that logs are often unstructured, making\ntheir analysis a complex task. This is mainly due to the lack of guidelines and\nbest practices for logging, combined with a large number of logging libraries\nat the disposal of software developers. There exist studies that aim to parse\nautomatically large logs. The main objective is to extract templates from\nsamples of log data that are used to recognize future logs. In this paper, we\npropose AWSOM-LP, a powerful log parsing and abstraction tool, which is highly\naccurate, stable, and efficient. AWSOM-LP is built on the idea of applying\npattern recognition and frequency analysis. First, log events are organized\ninto patterns using a simple text processing method. Frequency analysis is then\napplied locally to instances of the same group to identify static and dynamic\ncontent of log events. When applied to 16 log datasets of the the LogPai\nproject, AWSOM-LP achieves an average grouping accuracy of 93.5%, which\noutperforms the accuracy of five leading log parsing tools namely, Logram,\nLenma, Drain, IPLoM and AEL. Additionally, AWSOM-LP can generate more than 80%\nof the final log templates from 10% to 50% of the entire log dataset and can\nparse up to a million log events in an average time of 5 minutes. AWSOM-LP is\navailable online as an open source. It can be used by practitioners and\nresearchers to parse effectively and efficiently large log files so as to\nsupport log analysis tasks.",
    "descriptor": "\nComments: Article submitted to IEEE Transactions on Software Engineering (TSE), 13 pages\n",
    "authors": [
      "Issam Sedki",
      "Abdelwahab Hamou-Lhadj",
      "Otmane Ait-Mohamed"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.15473"
  },
  {
    "id": "arXiv:2110.15481",
    "title": "Brick-by-Brick: Combinatorial Construction with Deep Reinforcement  Learning",
    "abstract": "Discovering a solution in a combinatorial space is prevalent in many\nreal-world problems but it is also challenging due to diverse complex\nconstraints and the vast number of possible combinations. To address such a\nproblem, we introduce a novel formulation, combinatorial construction, which\nrequires a building agent to assemble unit primitives (i.e., LEGO bricks)\nsequentially -- every connection between two bricks must follow a fixed rule,\nwhile no bricks mutually overlap. To construct a target object, we provide\nincomplete knowledge about the desired target (i.e., 2D images) instead of\nexact and explicit volumetric information to the agent. This problem requires a\ncomprehensive understanding of partial information and long-term planning to\nappend a brick sequentially, which leads us to employ reinforcement learning.\nThe approach has to consider a variable-sized action space where a large number\nof invalid actions, which would cause overlap between bricks, exist. To resolve\nthese issues, our model, dubbed Brick-by-Brick, adopts an action validity\nprediction network that efficiently filters invalid actions for an actor-critic\nnetwork. We demonstrate that the proposed method successfully learns to\nconstruct an unseen object conditioned on a single image or multiple views of a\ntarget object.",
    "descriptor": "\nComments: 21 pages, 13 figures, 7 tables. Accepted at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Hyunsoo Chung",
      "Jungtaek Kim",
      "Boris Knyazev",
      "Jinhwi Lee",
      "Graham W. Taylor",
      "Jaesik Park",
      "Minsu Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15481"
  },
  {
    "id": "arXiv:2110.15482",
    "title": "First order strong approximation of Ait-Sahalia-type interest rate model  with Poisson jumps",
    "abstract": "For Ait-Sahalia-type interest rate model with Poisson jumps, we are\ninterested in strong convergence of a novel time-stepping method, called\ntransformed jump-adapted backward Euler method (TJABEM). Under certain\nhypothesis, the considered model takes values in positive domain $(0,\\infty)$.\nIt is shown that the TJABEM can preserve the domain of the underlying problem.\nFurthermore, for the above model with non-globally Lipschitz drift and\ndiffusion coefficients, the strong convergence rate of order one of the TJABEM\nis recovered with respect to a $L^p$-error criterion. Finally, numerical\nexperiments are given to illustrate the theoretical results.",
    "descriptor": "",
    "authors": [
      "Ziyi Lei",
      "Siqing Gan",
      "Jing Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15482"
  },
  {
    "id": "arXiv:2110.15484",
    "title": "Cycle-Balanced Representation Learning For Counterfactual Inference",
    "abstract": "With the widespread accumulation of observational data, researchers obtain a\nnew direction to learn counterfactual effects in many domains (e.g., health\ncare and computational advertising) without Randomized Controlled Trials(RCTs).\nHowever, observational data suffer from inherent missing counterfactual\noutcomes, and distribution discrepancy between treatment and control groups due\nto behaviour preference. Motivated by recent advances of representation\nlearning in the field of domain adaptation, we propose a novel framework based\non Cycle-Balanced REpresentation learning for counterfactual inference (CBRE),\nto solve above problems. Specifically, we realize a robust balanced\nrepresentation for different groups using adversarial training, and meanwhile\nconstruct an information loop, such that preserve original data properties\ncyclically, which reduces information loss when transforming data into latent\nrepresentation space.Experimental results on three real-world datasets\ndemonstrate that CBRE matches/outperforms the state-of-the-art methods, and it\nhas a great potential to be applied to counterfactual inference.",
    "descriptor": "",
    "authors": [
      "Guanglin Zhou",
      "Lina Yao",
      "Xiwei Xu",
      "Chen Wang",
      "Liming Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15484"
  },
  {
    "id": "arXiv:2110.15485",
    "title": "Location-routing Optimisation for Urban Logistics Using Mobile Parcel  Locker Based on Hybrid Q-Learning Algorithm",
    "abstract": "Mobile parcel lockers (MPLs) have been recently introduced by urban logistics\noperators as a means to reduce traffic congestion and operational cost. Their\ncapability to relocate their position during the day has the potential to\nimprove customer accessibility and convenience (if deployed and planned\naccordingly), allowing customers to collect parcels at their preferred time\namong one of the multiple locations. This paper proposes an integer programming\nmodel to solve the Location Routing Problem for MPLs to determine the optimal\nconfiguration and locker routes. In solving this model, a Hybrid Q-Learning\nalgorithm-based Method (HQM) integrated with global and local search mechanisms\nis developed, the performance of which is examined for different problem sizes\nand benchmarked with genetic algorithms. Furthermore, we introduced two route\nadjustment strategies to resolve stochastic events that may cause delays. The\nresults show that HQM achieves 443.41% improvement on average in solution\nimprovement, compared with the 94.91% improvement of heuristic counterparts,\nsuggesting HQM enables a more efficient search for better solutions. Finally,\nwe identify critical factors that contribute to service delays and investigate\ntheir effects.",
    "descriptor": "\nComments: Accepted by Transportation Research Board 101st Annual Meeting (TRBAM 2022). Reference number: TRBAM-22-03253\n",
    "authors": [
      "Yubin Liu",
      "Qiming Ye",
      "Yuxiang Feng",
      "Jose Escribano-Macias",
      "Panagiotis Angeloudis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.15485"
  },
  {
    "id": "arXiv:2110.15489",
    "title": "GalilAI: Out-of-Task Distribution Detection using Causal Active  Experimentation for Safe Transfer RL",
    "abstract": "Out-of-distribution (OOD) detection is a well-studied topic in supervised\nlearning. Extending the successes in supervised learning methods to the\nreinforcement learning (RL) setting, however, is difficult due to the data\ngenerating process - RL agents actively query their environment for data, and\nthe data are a function of the policy followed by the agent. An agent could\nthus neglect a shift in the environment if its policy did not lead it to\nexplore the aspect of the environment that shifted. Therefore, to achieve safe\nand robust generalization in RL, there exists an unmet need for OOD detection\nthrough active experimentation. Here, we attempt to bridge this lacuna by first\ndefining a causal framework for OOD scenarios or environments encountered by RL\nagents in the wild. Then, we propose a novel task: that of Out-of-Task\nDistribution (OOTD) detection. We introduce an RL agent that actively\nexperiments in a test environment and subsequently concludes whether it is OOTD\nor not. We name our method GalilAI, in honor of Galileo Galilei, as it\ndiscovers, among other causal processes, that gravitational acceleration is\nindependent of the mass of a body. Finally, we propose a simple probabilistic\nneural network baseline for comparison, which extends extant Model-Based RL. We\nfind that GalilAI outperforms the baseline significantly. See visualizations of\nour method https://galil-ai.github.io/",
    "descriptor": "",
    "authors": [
      "Sumedh A Sontakke",
      "Stephen Iota",
      "Zizhao Hu",
      "Arash Mehrjou",
      "Laurent Itti",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15489"
  },
  {
    "id": "arXiv:2110.15491",
    "title": "Newtonian Mechanics Based Transient Stability PART VI: Machine  Transformation",
    "abstract": "This paper focuses on the transformations from the individual machine to the\nequivalent machine through the \"correction\" perspective of the inner-group\nmachine. The machines are first classified as the real machine with equation of\nmotion and the pseudo machine without equation of motion. Then, it is clarified\nthat both individual machine and equivalent machine are real machines, while\nthe superimposed machine is a pseudo machine. Based on the classifications of\nthe machines, two types of machine transformations are provided. The two types\nof machine transformations are based on the \"energy correction\" and \"trajectory\ncorrection\" of the inner-group machine, respectively. For the energy correction\ncase, it is clarified that the trajectory transformation completely fails,\nwhile the energy transformation mathematically holds yet it is physically\nmeaningless. For the trajectory correction case, it is clarified that both\nenergy transformation and trajectory transformation are established. The reason\nis that each trajectory-correction based individual machine has the same\nequation of motion, i.e., the motion of the equivalent Machine-CR. Simulation\nresults show that the machine transformation from the individual machine to the\nequivalent machine can be realized only through trajectory correction.",
    "descriptor": "\nComments: Index Terms-- Transient stability, transient energy, equal area criterion, transient energy corrections, trajectory corrections. This paper contains 16 pages and 38 figures\n",
    "authors": [
      "Songyan Wang",
      "Jilai Yu",
      "Aoife Foley",
      "Jingrui Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.15491"
  },
  {
    "id": "arXiv:2110.15497",
    "title": "Unsupervised Foreground Extraction via Deep Region Competition",
    "abstract": "We present Deep Region Competition (DRC), an algorithm designed to extract\nforeground objects from images in a fully unsupervised manner. Foreground\nextraction can be viewed as a special case of generic image segmentation that\nfocuses on identifying and disentangling objects from the background. In this\nwork, we rethink the foreground extraction by reconciling energy-based prior\nwith generative image modeling in the form of Mixture of Experts (MoE), where\nwe further introduce the learned pixel re-assignment as the essential inductive\nbias to capture the regularities of background regions. With this modeling, the\nforeground-background partition can be naturally found through\nExpectation-Maximization (EM). We show that the proposed method effectively\nexploits the interaction between the mixture components during the partitioning\nprocess, which closely connects to region competition, a seminal approach for\ngeneric image segmentation. Experiments demonstrate that DRC exhibits more\ncompetitive performances on complex real-world data and challenging\nmulti-object scenes compared with prior methods. Moreover, we show empirically\nthat DRC can potentially generalize to novel foreground objects even from\ncategories unseen during training.",
    "descriptor": "\nComments: To appear in NeurIPS 2021\n",
    "authors": [
      "Peiyu Yu",
      "Sirui Xie",
      "Xiaojian Ma",
      "Yixin Zhu",
      "Ying Nian Wu",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15497"
  },
  {
    "id": "arXiv:2110.15498",
    "title": "Learning Personal Food Preferences via Food Logs Embedding",
    "abstract": "Diet management is key to managing chronic diseases such as diabetes.\nAutomated food recommender systems may be able to assist by providing meal\nrecommendations that conform to a user's nutrition goals and food preferences.\nCurrent recommendation systems suffer from a lack of accuracy that is in part\ndue to a lack of knowledge of food preferences, namely foods users like to and\nare able to eat frequently. In this work, we propose a method for learning food\npreferences from food logs, a comprehensive but noisy source of information\nabout users' dietary habits. We also introduce accompanying metrics. The method\ngenerates and compares word embeddings to identify the parent food category of\neach food entry and then calculates the most popular. Our proposed approach\nidentifies 82% of a user's ten most frequently eaten foods. Our method is\npublicly available on (https://github.com/aametwally/LearningFoodPreferences)",
    "descriptor": "",
    "authors": [
      "Ahmed A. Metwally",
      "Ariel K. Leong",
      "Aman Desai",
      "Anvith Nagarjuna",
      "Dalia Perelman",
      "Michael Snyder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15498"
  },
  {
    "id": "arXiv:2110.15499",
    "title": "UDIS: Unsupervised Discovery of Bias in Deep Visual Recognition Models",
    "abstract": "Deep learning models have been shown to learn spurious correlations from data\nthat sometimes lead to systematic failures for certain subpopulations. Prior\nwork has typically diagnosed this by crowdsourcing annotations for various\nprotected attributes and measuring performance, which is both expensive to\nacquire and difficult to scale. In this work, we propose UDIS, an unsupervised\nalgorithm for surfacing and analyzing such failure modes. UDIS identifies\nsubpopulations via hierarchical clustering of dataset embeddings and surfaces\nsystematic failure modes by visualizing low performing clusters along with\ntheir gradient-weighted class-activation maps. We show the effectiveness of\nUDIS in identifying failure modes in models trained for image classification on\nthe CelebA and MSCOCO datasets.",
    "descriptor": "",
    "authors": [
      "Arvindkumar Krishnakumar",
      "Viraj Prabhu",
      "Sruthi Sudhakar",
      "Judy Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15499"
  },
  {
    "id": "arXiv:2110.15503",
    "title": "A Pre-processing Method for Fairness in Ranking",
    "abstract": "Fair ranking problems arise in many decision-making processes that often\nnecessitate a trade-off between accuracy and fairness.\nMany existing studies have proposed correction methods such as adding\nfairness constraints to a ranking model's loss.\nHowever, the challenge of correcting the data bias for fair ranking remains,\nand the trade-off of the ranking models leaves room for improvement.\nIn this paper, we propose a fair ranking framework that evaluates the order\nof training data in a pairwise manner as well as various fairness measurements\nin ranking.\nThis study is the first proposal of a pre-processing method that solves fair\nranking problems using the pairwise ordering method with our best knowledge.\nThe fair pairwise ordering method is prominent in training the fair ranking\nmodels because it ensures that the resulting ranking likely becomes parity\nacross groups.\nAs far as the fairness measurements in ranking are represented as a linear\nconstraint of the ranking models, we proved that the minimization of loss\nfunction subject to the constraints is reduced to the closed solution of the\nminimization problem augmented by weights to training data.\nThis closed solution inspires us to present a practical and stable algorithm\nthat iterates the optimization of weights and model parameters.\nThe empirical results over real-world datasets demonstrated that our method\noutperforms the existing methods in the trade-off between accuracy and fairness\nover real-world datasets and various fairness measurements.",
    "descriptor": "",
    "authors": [
      "Ryosuke Sonoda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15503"
  },
  {
    "id": "arXiv:2110.15508",
    "title": "Quasi-linear analysis of dispersion relation preservation for nonlinear  schemes",
    "abstract": "In numerical simulations of complex flows with discontinuities, it is\nnecessary to use nonlinear schemes. The spectrum of the scheme used have a\nsignificant impact on the resolution and stability of the computation. Based on\nthe approximate dispersion relation method, we combine the corresponding\nspectral property with the dispersion relation preservation proposed by De and\nEswaran (J. Comput. Phys. 218 (2006) 398-416) and propose a quasi-linear\ndispersion relation preservation (QL-DRP) analysis method, through which the\ngroup velocity of the nonlinear scheme can be determined. In particular, we\nderive the group velocity property when a high-order Runge-Kutta scheme is used\nand compare the performance of different time schemes with QL-DRP. The\nrationality of the QL-DRP method is verified by a numerical simulation and the\ndiscrete Fourier transform method. To further evaluate the performance of a\nnonlinear scheme in finding the group velocity, new hyperbolic equations are\ndesigned. The validity of QL-DRP and the group velocity preservation of several\nschemes are investigated using two examples of the equation for one-dimensional\nwave propagation and the new hyperbolic equations. The results show that the\nQL-DRP method integrated with high-order time schemes can determine the group\nvelocity for nonlinear schemes and evaluate their performance reasonably and\nefficiently.",
    "descriptor": "",
    "authors": [
      "Fengyuan Xu",
      "Pan Yan",
      "Qin Li",
      "Yancheng You"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.15508"
  },
  {
    "id": "arXiv:2110.15510",
    "title": "Monostatic sampling methods in limited-aperture configuration",
    "abstract": "We present monostatic sampling methods for limited-aperture scattering\nproblems in two dimensions. The direct sampling method (DSM) is well known to\nprovide a robust, stable, and fast numerical scheme for imaging inhomogeneities\nfrom multistatic measurements even with only one or two incident fields.\nHowever, in practical applications, monostatic measurements in limited-aperture\nconfiguration are frequently encountered. A monostatic sampling method (MSM)\nwas studied in full-aperture configuration in recent literature. In this paper,\nwe develop MSM in limited-aperture configuration and derive an asymptotic\nformula of the corresponding indicator function. Based on the asymptotic\nformula, we then analyze the imaging performance of the proposed method\ndepending on the range of measurement directions and the geometric, material\nproperties of inhomogeneities. Furthermore, we propose a modified numerical\nscheme with multi-frequency measurements that improve imaging performance,\nespecially for small anomalies. Numerical simulations are presented to validate\nthe analytical results.",
    "descriptor": "",
    "authors": [
      "Sangwoo Kang",
      "Mikyoung Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15510"
  },
  {
    "id": "arXiv:2110.15520",
    "title": "On Label Shift in Domain Adaptation via Wasserstein Distance",
    "abstract": "We study the label shift problem between the source and target domains in\ngeneral domain adaptation (DA) settings. We consider transformations\ntransporting the target to source domains, which enable us to align the source\nand target examples. Through those transformations, we define the label shift\nbetween two domains via optimal transport and develop theory to investigate the\nproperties of DA under various DA settings (e.g., closed-set, partial-set,\nopen-set, and universal settings). Inspired from the developed theory, we\npropose Label and Data Shift Reduction via Optimal Transport (LDROT) which can\nmitigate the data and label shifts simultaneously. Finally, we conduct\ncomprehensive experiments to verify our theoretical findings and compare LDROT\nwith state-of-the-art baselines.",
    "descriptor": "\nComments: 35 pages, 7 figures, 6 tables\n",
    "authors": [
      "Trung Le",
      "Dat Do",
      "Tuan Nguyen",
      "Huy Nguyen",
      "Hung Bui",
      "Nhat Ho",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15520"
  },
  {
    "id": "arXiv:2110.15521",
    "title": "ARviz -- An Augmented Reality-enabled Visualization Platform for ROS  Applications",
    "abstract": "Current robot interfaces such as teach pendants and 2D screen displays used\nfor task visualization and interaction often seem unintuitive and limited in\nterms of information flow. This compromises task efficiency as interacting with\nthe interface can distract the user from the task at hand. Augmented Reality\n(AR) technology offers the capability to create visually rich displays and\nintuitive interaction elements in situ. In recent years, AR has shown promising\npotential to enable effective human-robot interaction. We introduce ARviz - a\nversatile, extendable AR visualization platform built for robot applications\ndeveloped with the widely used Robot Operating System (ROS) framework. ARviz\naims to provide both a universal visualization platform with the capability of\ndisplaying any ROS message data type in AR, as well as a multimodal user\ninterface for interacting with robots over ROS. ARviz is built as a platform\nincorporating a collection of plugins that provide visualization and/or\ninteraction components. Users can also extend the platform by implementing new\nplugins to suit their needs. We present three use cases as well as two\npotential use cases to showcase the capabilities and benefits of the ARviz\nplatform for human-robot interaction applications. The open access source code\nfor our ARviz platform is available at: https://github.com/hri-group/arviz.",
    "descriptor": "\nComments: 9 pages, 10 figures, accepted for IEEE RAM - Special Issue on Extended Reality\n",
    "authors": [
      "Khoa C. Hoang",
      "Wesley P. Chan",
      "Steven Lay",
      "Akansel Cosgun",
      "Elizabeth A. Croft"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.15521"
  },
  {
    "id": "arXiv:2110.15522",
    "title": "ADDS: Adaptive Differentiable Sampling for Robust Multi-Party Learning",
    "abstract": "Distributed multi-party learning provides an effective approach for training\na joint model with scattered data under legal and practical constraints.\nHowever, due to the quagmire of a skewed distribution of data labels across\nparticipants and the computation bottleneck of local devices, how to build\nsmaller customized models for clients in various scenarios while providing\nupdates appliable to the central model remains a challenge. In this paper, we\npropose a novel adaptive differentiable sampling framework (ADDS) for robust\nand communication-efficient multi-party learning. Inspired by the idea of\ndropout in neural networks, we introduce a network sampling strategy in the\nmulti-party setting, which distributes different subnets of the central model\nto clients for updating, and the differentiable sampling rates allow each\nclient to extract optimal local architecture from the supernet according to its\nprivate data distribution. The approach requires minimal modifications to the\nexisting multi-party learning structure, and it is capable of integrating local\nupdates of all subnets into the supernet, improving the robustness of the\ncentral model. The proposed framework significantly reduces local computation\nand communication costs while speeding up the central model convergence, as we\ndemonstrated through experiments on real-world datasets.",
    "descriptor": "",
    "authors": [
      "Maoguo Gong",
      "Yuan Gao",
      "Yue Wu",
      "A.K.Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15522"
  },
  {
    "id": "arXiv:2110.15525",
    "title": "PEDENet: Image Anomaly Localization via Patch Embedding and Density  Estimation",
    "abstract": "A neural network targeting at unsupervised image anomaly localization, called\nthe PEDENet, is proposed in this work. PEDENet contains a patch embedding (PE)\nnetwork, a density estimation (DE) network, and an auxiliary network called the\nlocation prediction (LP) network. The PE network takes local image patches as\ninput and performs dimension reduction to get low-dimensional patch embeddings\nvia a deep encoder structure. Being inspired by the Gaussian Mixture Model\n(GMM), the DE network takes those patch embeddings and then predicts the\ncluster membership of an embedded patch. The sum of membership probabilities is\nused as a loss term to guide the learning process. The LP network is a\nMulti-layer Perception (MLP), which takes embeddings from two neighboring\npatches as input and predicts their relative location. The performance of the\nproposed PEDENet is evaluated extensively and benchmarked with that of\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Kaitai Zhang",
      "Bin Wang",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15525"
  },
  {
    "id": "arXiv:2110.15526",
    "title": "The Structure-Behavior Coalescence Method --Toward a Unified View of the  Software System in Model-Driven Engineering",
    "abstract": "In Model-Driven Engineering (MDE), the Unified Modeling Language (UML) 2.0\nspecification includes a metamodel that defines the language concepts and a\nuser model that defines how the language concepts are represented. In UML 2.0,\nan important use of metamodel is to provide an integrated semantic framework\nthat every diagram in the user model can be projected as a view of the\nmetamodel. However, most existing UML 2.0 metamodels lack the ability to serve\nas the basis for unifying different views of a software system. To overcome the\nshortcomings of the current UML 2.0 metamodel approaches, we developed\nOperation-Based Multi-Queue Structure-Behavior Coalescence Process Algebra\n(O-M-SBC-PA), which provides an integrated semantic framework that is able to\nintegrate structural and behavioral constructs. Using O-M-SBC-PA as the\nmetamodel of UML 2.0, each diagram in the user model can be projected as a view\nof the MDE metamodel.",
    "descriptor": "",
    "authors": [
      "William S. Chao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.15526"
  },
  {
    "id": "arXiv:2110.15527",
    "title": "Pre-training Co-evolutionary Protein Representation via A Pairwise  Masked Language Model",
    "abstract": "Understanding protein sequences is vital and urgent for biology, healthcare,\nand medicine. Labeling approaches are expensive yet time-consuming, while the\namount of unlabeled data is increasing quite faster than that of the labeled\ndata due to low-cost, high-throughput sequencing methods. In order to extract\nknowledge from these unlabeled data, representation learning is of significant\nvalue for protein-related tasks and has great potential for helping us learn\nmore about protein functions and structures. The key problem in the protein\nsequence representation learning is to capture the co-evolutionary information\nreflected by the inter-residue co-variation in the sequences. Instead of\nleveraging multiple sequence alignment as is usually done, we propose a novel\nmethod to capture this information directly by pre-training via a dedicated\nlanguage model, i.e., Pairwise Masked Language Model (PMLM). In a conventional\nmasked language model, the masked tokens are modeled by conditioning on the\nunmasked tokens only, but processed independently to each other. However, our\nproposed PMLM takes the dependency among masked tokens into consideration,\ni.e., the probability of a token pair is not equal to the product of the\nprobability of the two tokens. By applying this model, the pre-trained encoder\nis able to generate a better representation for protein sequences. Our result\nshows that the proposed method can effectively capture the inter-residue\ncorrelations and improves the performance of contact prediction by up to 9%\ncompared to the MLM baseline under the same setting. The proposed model also\nsignificantly outperforms the MSA baseline by more than 7% on the TAPE contact\nprediction benchmark when pre-trained on a subset of the sequence database\nwhich the MSA is generated from, revealing the potential of the sequence\npre-training method to surpass MSA based methods in general.",
    "descriptor": "",
    "authors": [
      "Liang He",
      "Shizhuo Zhang",
      "Lijun Wu",
      "Huanhuan Xia",
      "Fusong Ju",
      "He Zhang",
      "Siyuan Liu",
      "Yingce Xia",
      "Jianwei Zhu",
      "Pan Deng",
      "Bin Shao",
      "Tao Qin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15527"
  },
  {
    "id": "arXiv:2110.15528",
    "title": "Deconvolutional Networks on Graph Data",
    "abstract": "In this paper, we consider an inverse problem in graph learning domain --\n``given the graph representations smoothed by Graph Convolutional Network\n(GCN), how can we reconstruct the input graph signal?\" We propose Graph\nDeconvolutional Network (GDN) and motivate the design of GDN via a combination\nof inverse filters in spectral domain and de-noising layers in wavelet domain,\nas the inverse operation results in a high frequency amplifier and may amplify\nthe noise. We demonstrate the effectiveness of the proposed method on several\ntasks including graph feature imputation and graph structure generation.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2012.11898\n",
    "authors": [
      "Jia Li",
      "Jiajin Li",
      "Yang Liu",
      "Jianwei Yu",
      "Yueting Li",
      "Hong Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15528"
  },
  {
    "id": "arXiv:2110.15529",
    "title": "Topological Relational Learning on Graphs",
    "abstract": "Graph neural networks (GNNs) have emerged as a powerful tool for graph\nclassification and representation learning. However, GNNs tend to suffer from\nover-smoothing problems and are vulnerable to graph perturbations. To address\nthese challenges, we propose a novel topological neural framework of\ntopological relational inference (TRI) which allows for integrating\nhigher-order graph information to GNNs and for systematically learning a local\ngraph structure. The key idea is to rewire the original graph by using the\npersistent homology of the small neighborhoods of nodes and then to incorporate\nthe extracted topological summaries as the side information into the local\nalgorithm. As a result, the new framework enables us to harness both the\nconventional information on the graph structure and information on the graph\nhigher order topological properties. We derive theoretical stability guarantees\nfor the new local topological representation and discuss their implications on\nthe graph algebraic connectivity. The experimental results on node\nclassification tasks demonstrate that the new TRI-GNN outperforms all 14\nstate-of-the-art baselines on 6 out 7 graphs and exhibit higher robustness to\nperturbations, yielding up to 10\\% better performance under noisy scenarios.",
    "descriptor": "",
    "authors": [
      "Yuzhou Chen",
      "Baris Coskunuzer",
      "Yulia R. Gel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15529"
  },
  {
    "id": "arXiv:2110.15532",
    "title": "Contact Transfer: A Direct, User-Driven Method for Human to Robot  Transfer of Grasps and Manipulations",
    "abstract": "We present a novel method for the direct transfer of grasps and manipulations\nbetween objects and hands through utilization of contact areas. Our method\nfully preserves contact shapes, and in contrast to existing techniques, is not\ndependent on grasp families, requires no model training or grasp sampling,\nmakes no assumptions about manipulator morphology or kinematics, and allows\nuser control over both transfer parameters and solution optimization. Despite\nthese accommodations, we show that our method is capable of synthesizing\nkinematically feasible whole hand poses in seconds even for poor\ninitializations or hard to reach contacts. We additionally highlight the\nmethod's benefits in both response to design alterations as well as fast\napproximation over in-hand manipulation sequences. Finally, we demonstrate a\nsolution generated by our method on a physical, custom designed prosthetic\nhand.",
    "descriptor": "",
    "authors": [
      "Arjun Lakshmipathy",
      "Dominik Bauer",
      "Cornelia Bauer",
      "Nancy S. Pollard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.15532"
  },
  {
    "id": "arXiv:2110.15533",
    "title": "Improved Sliding Window Algorithms for Clustering and Coverage via  Bucketing-Based Sketches",
    "abstract": "Streaming computation plays an important role in large-scale data analysis.\nThe sliding window model is a model of streaming computation which also\ncaptures the recency of the data. In this model, data arrives one item at a\ntime, but only the latest $W$ data items are considered for a particular\nproblem. The goal is to output a good solution at the end of the stream by\nmaintaining a small summary during the stream.\nIn this work, we propose a new algorithmic framework for designing efficient\nsliding window algorithms via bucketing-based sketches. Based on this new\nframework, we develop space-efficient sliding window algorithms for $k$-cover,\n$k$-clustering and diversity maximization problems. For each of the above\nproblems, our algorithm achieves $(1\\pm \\varepsilon)$-approximation. Compared\nwith the previous work, it improves both the approximation ratio and the space.",
    "descriptor": "\nComments: SODA 2022\n",
    "authors": [
      "Alessandro Epasto",
      "Mohammad Mahdian",
      "Vahab Mirrokni",
      "Peilin Zhong"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15533"
  },
  {
    "id": "arXiv:2110.15534",
    "title": "Structure-aware Fine-tuning of Sequence-to-sequence Transformers for  Transition-based AMR Parsing",
    "abstract": "Predicting linearized Abstract Meaning Representation (AMR) graphs using\npre-trained sequence-to-sequence Transformer models has recently led to large\nimprovements on AMR parsing benchmarks. These parsers are simple and avoid\nexplicit modeling of structure but lack desirable properties such as graph\nwell-formedness guarantees or built-in graph-sentence alignments. In this work\nwe explore the integration of general pre-trained sequence-to-sequence language\nmodels and a structure-aware transition-based approach. We depart from a\npointer-based transition system and propose a simplified transition set,\ndesigned to better exploit pre-trained language models for structured\nfine-tuning. We also explore modeling the parser state within the pre-trained\nencoder-decoder architecture and different vocabulary strategies for the same\npurpose. We provide a detailed comparison with recent progress in AMR parsing\nand show that the proposed parser retains the desirable properties of previous\ntransition-based approaches, while being simpler and reaching the new parsing\nstate of the art for AMR 2.0, without the need for graph re-categorization.",
    "descriptor": "\nComments: EMNLP 2021 main conference\n",
    "authors": [
      "Jiawei Zhou",
      "Tahira Naseem",
      "Ram\u00f3n Fernandez Astudillo",
      "Young-Suk Lee",
      "Radu Florian",
      "Salim Roukos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15534"
  },
  {
    "id": "arXiv:2110.15535",
    "title": "An $O(k \\log{n})$ algorithm for prefix based ranked autocomplete",
    "abstract": "Many search engines such as Google, Bing & Yahoo! show search suggestions\nwhen users enter search phrases on their interfaces. These suggestions are\nmeant to assist the user in finding what she wants quickly and also suggesting\ncommon searches that may result in finding information that is more relevant.\nIt also serves the purpose of helping the user if she is not sure of what to\nsearch for, but has a vague idea of what it is that she wants. We present an\nalgorithm that takes time proportional to $O(k \\log{n})$, and $O(n)$ extra\nspace for providing the user with the top $k$ ranked suggestions out of a\ncorpus of $n$ possible suggestions based on the prefix of the query that she\nhas entered so far.",
    "descriptor": "",
    "authors": [
      "Dhruv Matani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15535"
  },
  {
    "id": "arXiv:2110.15538",
    "title": "Model Fusion of Heterogeneous Neural Networks via Cross-Layer Alignment",
    "abstract": "Layer-wise model fusion via optimal transport, named OTFusion, applies soft\nneuron association for unifying different pre-trained networks to save\ncomputational resources. While enjoying its success, OTFusion requires the\ninput networks to have the same number of layers. To address this issue, we\npropose a novel model fusion framework, named CLAFusion, to fuse neural\nnetworks with a different number of layers, which we refer to as heterogeneous\nneural networks, via cross-layer alignment. The cross-layer alignment problem,\nwhich is an unbalanced assignment problem, can be solved efficiently using\ndynamic programming. Based on the cross-layer alignment, our framework balances\nthe number of layers of neural networks before applying layer-wise model\nfusion. Our synthetic experiments indicate that the fused network from\nCLAFusion achieves a more favorable performance compared to the individual\nnetworks trained on heterogeneous data without the need for any retraining.\nWith an extra fine-tuning process, it improves the accuracy of residual\nnetworks on the CIFAR10 dataset. Finally, we explore its application for model\ncompression and knowledge distillation when applying to the teacher-student\nsetting.",
    "descriptor": "\nComments: 23 pages, 5 figures, 14 tables\n",
    "authors": [
      "Dang Nguyen",
      "Khai Nguyen",
      "Dinh Phung",
      "Hung Bui",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15538"
  },
  {
    "id": "arXiv:2110.15542",
    "title": "Automatic Hand Sign Recognition: Identify Unusuality through Latent  Cognizance",
    "abstract": "Sign language is a main communication channel among hearing disability\ncommunity. Automatic sign language transcription could facilitate better\ncommunication and understanding between hearing disability community and\nhearing majority. As a recent work in automatic sign language transcription has\ndiscussed, effectively handling or identifying a non-sign posture is one of the\nkey issues. A non-sign posture is a posture unintended for sign reading and\ndoes not belong to any valid sign. A non-sign posture may arise during sign\ntransition or simply from an unaware posture. Confidence ratio has been\nproposed to mitigate the issue. Confidence ratio is simple to compute and\nreadily available without extra training. However, confidence ratio is reported\nto only partially address the problem. In addition, confidence ratio\nformulation is susceptible to computational instability. This article proposes\nalternative formulations to confidence ratio, investigates an issue of non-sign\nidentification for Thai Finger Spelling recognition, explores potential\nsolutions and has found a promising direction. Not only does this finding\naddress the issue of non-sign identification, it also provide some insight\nbehind a well-learned inference machine, revealing hidden meaning and new\ninterpretation of the underlying mechanism. Our proposed methods are evaluated\nand shown to be effective for non-sign detection.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Pisit Nakjai",
      "Tatpong Katanyukul"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15542"
  },
  {
    "id": "arXiv:2110.15545",
    "title": "Improving Fairness via Federated Learning",
    "abstract": "Recently, lots of algorithms have been proposed for learning a fair\nclassifier from centralized data. However, how to privately train a fair\nclassifier on decentralized data has not been fully studied yet. In this work,\nwe first propose a new theoretical framework, with which we analyze the value\nof federated learning in improving fairness. Our analysis reveals that\nfederated learning can strictly boost model fairness compared with all\nnon-federated algorithms. We then theoretically and empirically show that the\nperformance tradeoff of FedAvg-based fair learning algorithms is strictly worse\nthan that of a fair classifier trained on centralized data. To resolve this, we\npropose FedFB, a private fair learning algorithm on decentralized data with a\nmodified FedAvg protocol. Our extensive experimental results show that FedFB\nsignificantly outperforms existing approaches, sometimes achieving a similar\ntradeoff as the one trained on centralized data.",
    "descriptor": "\nComments: 39 pages, 7 figures\n",
    "authors": [
      "Yuchen Zeng",
      "Hongxu Chen",
      "Kangwook Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15545"
  },
  {
    "id": "arXiv:2110.15547",
    "title": "Does Momentum Help? A Sample Complexity Analysis",
    "abstract": "Momentum methods are popularly used in accelerating stochastic iterative\nmethods. Although a fair amount of literature is dedicated to momentum in\nstochastic optimisation, there are limited results that quantify the benefits\nof using heavy ball momentum in the specific case of stochastic approximation\nalgorithms. We first show that the convergence rate with optimal step size does\nnot improve when momentum is used (under some assumptions). Secondly, to\nquantify the behaviour in the initial phase we analyse the sample complexity of\niterates with and without momentum. We show that the sample complexity bound\nfor SA without momentum is\n$\\tilde{\\mathcal{O}}(\\frac{1}{\\alpha\\lambda_{min}(A)})$ while for SA with\nmomentum is $\\tilde{\\mathcal{O}}(\\frac{1}{\\sqrt{\\alpha\\lambda_{min}(A)}})$,\nwhere $\\alpha$ is the step size and $\\lambda_{min}(A)$ is the smallest\neigenvalue of the driving matrix $A$. Although the sample complexity bound for\nSA with momentum is better for small enough $\\alpha$, it turns out that for\noptimal choice of $\\alpha$ in the two cases, the sample complexity bounds are\nof the same order.",
    "descriptor": "",
    "authors": [
      "Gugan Thoppe",
      "Rohan Deb",
      "Swetha Ganesh",
      "Amarjit Budhiraja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15547"
  },
  {
    "id": "arXiv:2110.15548",
    "title": "Latent Cognizance: What Machine Really Learns",
    "abstract": "Despite overwhelming achievements in recognition accuracy, extending an\nopen-set capability -- ability to identify when the question is out of scope --\nremains greatly challenging in a scalable machine learning inference. A recent\nresearch has discovered Latent Cognizance (LC) -- an insight on a recognition\nmechanism based on a new probabilistic interpretation, Bayesian theorem, and an\nanalysis of an internal structure of a commonly-used recognition inference\nstructure. The new interpretation emphasizes a latent assumption of an\noverlooked probabilistic condition on a learned inference model. Viability of\nLC has been shown on a task of sign language recognition, but its potential and\nimplication can reach far beyond a specific domain and can move object\nrecognition toward a scalable open-set recognition. However, LC new\nprobabilistic interpretation has not been directly investigated. This article\ninvestigates the new interpretation under a traceable context. Our findings\nsupport the rationale on which LC is based and reveal a hidden mechanism\nunderlying the learning classification inference. The ramification of these\nfindings could lead to a simple yet effective solution to an open-set\nrecognition.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Pisit Nakjai",
      "Jiradej Ponsawat",
      "Tatpong Katanyukul"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15548"
  },
  {
    "id": "arXiv:2110.15552",
    "title": "A Comprehensive Study on Learning-Based PE Malware Family Classification  Methods",
    "abstract": "Driven by the high profit, Portable Executable (PE) malware has been\nconsistently evolving in terms of both volume and sophistication. PE malware\nfamily classification has gained great attention and a large number of\napproaches have been proposed. With the rapid development of machine learning\ntechniques and the exciting results they achieved on various tasks, machine\nlearning algorithms have also gained popularity in the PE malware family\nclassification task. Three mainstream approaches that use learning based\nalgorithms, as categorized by the input format the methods take, are\nimage-based, binary-based and disassembly-based approaches. Although a large\nnumber of approaches are published, there is no consistent comparisons on those\napproaches, especially from the practical industry adoption perspective.\nMoreover, there is no comparison in the scenario of concept drift, which is a\nfact for the malware classification task due to the fast evolving nature of\nmalware. In this work, we conduct a thorough empirical study on learning-based\nPE malware classification approaches on 4 different datasets and consistent\nexperiment settings. Based on the experiment results and an interview with our\nindustry partners, we find that (1) there is no individual class of methods\nthat significantly outperforms the others; (2) All classes of methods show\nperformance degradation on concept drift (by an average F1-score of 32.23%);\nand (3) the prediction time and high memory consumption hinder existing\napproaches from being adopted for industry usage.",
    "descriptor": "\nComments: 12 pages, 3 figures, conference\n",
    "authors": [
      "Yixuan Ma",
      "Shuang Liu",
      "Jiajun Jiang",
      "Guanhong Chen",
      "Keqiu Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.15552"
  },
  {
    "id": "arXiv:2110.15554",
    "title": "Cubic upper and lower bounds for subtrajectory clustering under the  continuous Fr\u00e9chet distance",
    "abstract": "Detecting commuting patterns or migration patterns in movement data is an\nimportant problem in computational movement analysis. Given a trajectory, or\nset of trajectories, this corresponds to clustering similar subtrajectories.\nWe study subtrajectory clustering under the continuous and discrete Fr\\'echet\ndistances. The most relevant theoretical result is by Buchin et al. (2011).\nThey provide, in the continuous case, an $O(n^5)$ time algorithm and a\n3SUM-hardness lower bound, and in the discrete case, an $O(n^3)$ time\nalgorithm. We show, in the continuous case, an $O(n^3 \\log^2 n)$ time algorithm\nand a 3OV-hardness lower bound, and in the discrete case, an $O(n^2 \\log n)$\ntime algorithm and a quadratic lower bound. Our bounds are almost tight unless\nSETH fails.",
    "descriptor": "\nComments: To appear in SODA 2022\n",
    "authors": [
      "Joachim Gudmundsson",
      "Sampson Wong"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.15554"
  },
  {
    "id": "arXiv:2110.15557",
    "title": "Crowd-sensing Enhanced Parking Patrol using Sharing Bikes' Trajectories",
    "abstract": "Illegal vehicle parking is a common urban problem faced by major cities in\nthe world, as it incurs traffic jams, which lead to air pollution and traffic\naccidents. The government highly relies on active human efforts to detect\nillegal parking events. However, such an approach is extremely ineffective to\ncover a large city since the police have to patrol over the entire city roads.\nThe massive and high-quality sharing bike trajectories from Mobike offer us a\nunique opportunity to design a ubiquitous illegal parking detection approach,\nas most of the illegal parking events happen at curbsides and have significant\nimpact on the bike users. The detection result can guide the patrol schedule,\ni.e. send the patrol policemen to the region with higher illegal parking risks,\nand further improve the patrol efficiency. Inspired by this idea, three main\ncomponents are employed in the proposed framework: 1)~{\\em trajectory\npre-processing}, which filters outlier GPS points, performs map-matching, and\nbuilds trajectory indexes; 2)~{\\em illegal parking detection}, which models the\nnormal trajectories, extracts features from the evaluation trajectories, and\nutilizes a distribution test-based method to discover the illegal parking\nevents; and 3)~{\\em patrol scheduling}, which leverages the detection result as\nreference context, and models the scheduling task as a multi-agent\nreinforcement learning problem to guide the patrol police. Finally, extensive\nexperiments are presented to validate the effectiveness of illegal parking\ndetection, as well as the improvement of patrol efficiency.",
    "descriptor": "",
    "authors": [
      "Tianfu He",
      "Jie Bao",
      "Yexin Li",
      "Hui He",
      "Yu Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.15557"
  },
  {
    "id": "arXiv:2110.15559",
    "title": "Minimal Envy Matchings in the Hospitals/Residents Problem with Lower  Quotas",
    "abstract": "In the Hospitals/Residents problem, every hospital has an upper quota that\nlimits the number of residents assigned to it. While, in some applications,\neach hospital also has a lower quota for the number of residents it receives.\nIn this setting, a stable matching may not exist. Envy-freeness is introduced\nas a relaxation of stability that allows blocking pairs involving a resident\nand an empty position of a hospital. While, envy-free matching might not exist\neither when lower quotas are introduced. We consider the problem of finding a\nfeasible matching that satisfies lower quotas and upper quotas and minimizes\nenvy in terms of envy-pairs and envy-residents in the Hospitals/Resident\nproblem with Lower Quota. We show that the problem is NP-hard with both envy\nmeasurement. We also give a simple exponential-time algorithm for the\nMinimum-Envy-Pair HRLQ problem.",
    "descriptor": "",
    "authors": [
      "Changyong Hu",
      "Vijay K. Garg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.15559"
  },
  {
    "id": "arXiv:2110.15561",
    "title": "Exposing Deepfake with Pixel-wise AR and PPG Correlation from Faint  Signals",
    "abstract": "Deepfake poses a serious threat to the reliability of judicial evidence and\nintellectual property protection. In spite of an urgent need for Deepfake\nidentification, existing pixel-level detection methods are increasingly unable\nto resist the growing realism of fake videos and lack generalization. In this\npaper, we propose a scheme to expose Deepfake through faint signals hidden in\nface videos. This scheme extracts two types of minute information hidden\nbetween face pixels-photoplethysmography (PPG) features and auto-regressive\n(AR) features, which are used as the basis for forensics in the temporal and\nspatial domains, respectively. According to the principle of PPG, tracking the\nabsorption of light by blood cells allows remote estimation of the temporal\ndomains heart rate (HR) of face video, and irregular HR fluctuations can be\nseen as traces of tampering. On the other hand, AR coefficients are able to\nreflect the inter-pixel correlation, and can also reflect the traces of\nsmoothing caused by up-sampling in the process of generating fake faces.\nFurthermore, the scheme combines asymmetric convolution block (ACBlock)-based\nimproved densely connected networks (DenseNets) to achieve face video\nauthenticity forensics. Its asymmetric convolutional structure enhances the\nrobustness of network to the input feature image upside-down and left-right\nflipping, so that the sequence of feature stitching does not affect detection\nresults. Simulation results show that our proposed scheme provides more\naccurate authenticity detection results on multiple deep forgery datasets and\nhas better generalization compared to the benchmark strategy.",
    "descriptor": "",
    "authors": [
      "Maoyu Mao",
      "Jun Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.15561"
  },
  {
    "id": "arXiv:2110.15563",
    "title": "Computing Lewis Weights to High Precision",
    "abstract": "We present an algorithm for computing approximate $\\ell_p$ Lewis weights to\nhigh precision. Given a full-rank $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ with\n$m \\geq n$ and a scalar $p>2$, our algorithm computes $\\epsilon$-approximate\n$\\ell_p$ Lewis weights of $\\mathbf{A}$ in $\\widetilde{O}_p(\\log(1/\\epsilon))$\niterations; the cost of each iteration is linear in the input size plus the\ncost of computing the leverage scores of $\\mathbf{D}\\mathbf{A}$ for diagonal\n$\\mathbf{D} \\in \\mathbb{R}^{m \\times m}$. Prior to our work, such a\ncomputational complexity was known only for $p \\in (0, 4)$ [CohenPeng2015], and\ncombined with this result, our work yields the first polylogarithmic-depth\npolynomial-work algorithm for the problem of computing $\\ell_p$ Lewis weights\nto high precision for all constant $p > 0$. An important consequence of this\nresult is also the first polylogarithmic-depth polynomial-work algorithm for\ncomputing a nearly optimal self-concordant barrier for a polytope.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Maryam Fazel",
      "Yin Tat Lee",
      "Swati Padmanabhan",
      "Aaron Sidford"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.15563"
  },
  {
    "id": "arXiv:2110.15567",
    "title": "Assyrian merchants meet nuclear physicists: history of the early  contributions from social sciences to computer science. The case of automatic  pattern detection in graphs (1950s--1970s)",
    "abstract": "Community detection is a major issue in network analysis. This paper combines\na socio-historical approach with an experimental reconstruction of programs to\ninvestigate the early automation of clique detection algorithms, which remains\none of the unsolved NP-complete problems today. The research led by the\narchaeologist Jean-Claude Gardin from the 1950s on non-numerical information\nand graph analysis is retraced to demonstrate the early contributions of social\nsciences and humanities. The limited recognition and reception of Gardin's\ninnovative computer application to the humanities are addressed through two\nfactors, in addition to the effects of historiography and bibliographies on the\nrecording, discoverability, and reuse of scientific productions: 1) funding\npolicies, evidenced by the transfer of research effort on graph applications\nfrom temporary interdisciplinary spaces to disciplinary organizations related\nto the then-emerging field of computer science; and 2) the erratic careers of\nalgorithms, in which efficiency, flaws, corrections, and authors' status, were\ndetermining factors.",
    "descriptor": "",
    "authors": [
      "S\u00e9bastien Plutniak"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15567"
  },
  {
    "id": "arXiv:2110.15569",
    "title": "Novel View Synthesis from a Single Image via Unsupervised learning",
    "abstract": "View synthesis aims to generate novel views from one or more given source\nviews. Although existing methods have achieved promising performance, they\nusually require paired views of different poses to learn a pixel\ntransformation. This paper proposes an unsupervised network to learn such a\npixel transformation from a single source viewpoint. In particular, the network\nconsists of a token transformation module (TTM) that facilities the\ntransformation of the features extracted from a source viewpoint image into an\nintrinsic representation with respect to a pre-defined reference pose and a\nview generation module (VGM) that synthesizes an arbitrary view from the\nrepresentation. The learned transformation allows us to synthesize a novel view\nfrom any single source viewpoint image of unknown pose. Experiments on the\nwidely used view synthesis datasets have demonstrated that the proposed network\nis able to produce comparable results to the state-of-the-art methods despite\nthe fact that learning is unsupervised and only a single source viewpoint image\nis required for generating a novel view. The code will be available soon.",
    "descriptor": "\nComments: 9 pages, submitted to TCSVT\n",
    "authors": [
      "Bingzheng Liu",
      "Jianjun Lei",
      "Bo Peng",
      "Chuanbo Yu",
      "Wanqing Li",
      "Nam Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15569"
  },
  {
    "id": "arXiv:2110.15572",
    "title": "Understanding the Effect of Stochasticity in Policy Optimization",
    "abstract": "We study the effect of stochasticity in on-policy policy optimization, and\nmake the following four contributions. First, we show that the preferability of\noptimization methods depends critically on whether stochastic versus exact\ngradients are used. In particular, unlike the true gradient setting, geometric\ninformation cannot be easily exploited in the stochastic case for accelerating\npolicy optimization without detrimental consequences or impractical\nassumptions. Second, to explain these findings we introduce the concept of\ncommittal rate for stochastic policy optimization, and show that this can serve\nas a criterion for determining almost sure convergence to global optimality.\nThird, we show that in the absence of external oracle information, which allows\nan algorithm to determine the difference between optimal and sub-optimal\nactions given only on-policy samples, there is an inherent trade-off between\nexploiting geometry to accelerate convergence versus achieving optimality\nalmost surely. That is, an uninformed algorithm either converges to a globally\noptimal policy with probability $1$ but at a rate no better than $O(1/t)$, or\nit achieves faster than $O(1/t)$ convergence but then must fail to converge to\nthe globally optimal policy with some positive probability. Finally, we use the\ncommittal rate theory to explain why practical policy optimization methods are\nsensitive to random initialization, then develop an ensemble method that can be\nguaranteed to achieve near-optimal solutions with high probability.",
    "descriptor": "\nComments: 68 pages; Accepted at NeurIPS 2021\n",
    "authors": [
      "Jincheng Mei",
      "Bo Dai",
      "Chenjun Xiao",
      "Csaba Szepesvari",
      "Dale Schuurmans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15572"
  },
  {
    "id": "arXiv:2110.15574",
    "title": "ST-ABN: Visual Explanation Taking into Account Spatio-temporal  Information for Video Recognition",
    "abstract": "It is difficult for people to interpret the decision-making in the inference\nprocess of deep neural networks. Visual explanation is one method for\ninterpreting the decision-making of deep learning. It analyzes the\ndecision-making of 2D CNNs by visualizing an attention map that highlights\ndiscriminative regions. Visual explanation for interpreting the decision-making\nprocess in video recognition is more difficult because it is necessary to\nconsider not only spatial but also temporal information, which is different\nfrom the case of still images. In this paper, we propose a visual explanation\nmethod called spatio-temporal attention branch network (ST-ABN) for video\nrecognition. It enables visual explanation for both spatial and temporal\ninformation. ST-ABN acquires the importance of spatial and temporal information\nduring network inference and applies it to recognition processing to improve\nrecognition performance and visual explainability. Experimental results with\nSomething-Something datasets V1 \\& V2 demonstrated that ST-ABN enables visual\nexplanation that takes into account spatial and temporal information\nsimultaneously and improves recognition performance.",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Masahiro Mitsuhara",
      "Tsubasa Hirakawa",
      "Takayoshi Yamashita",
      "Hironobu Fujiyoshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15574"
  },
  {
    "id": "arXiv:2110.15579",
    "title": "A Hybrid-High Order Method for Quasilinear Elliptic Problems of  Nonmonotone Type",
    "abstract": "In this paper, we design and analyze a Hybrid-High Order (HHO) approximation\nfor a class of quasilinear elliptic problems of nonmonotone type. The proposed\nmethod has several advantages, for instance, it supports arbitrary order of\napproximation and general polytopal meshes. The key ingredients involve local\nreconstruction and high-order stabilization terms. Existence and uniqueness of\nthe discrete solution are shown by Brouwer's fixed point theorem and\ncontraction result. A priori error estimate is shown in discrete energy norm\nthat shows optimal order convergence rate. Numerical experiments are performed\nto substantiate the theoretical results.",
    "descriptor": "",
    "authors": [
      "Thirupathi Gudi",
      "Gouranga Mallik",
      "Tamal Pramanick"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15579"
  },
  {
    "id": "arXiv:2110.15582",
    "title": "Construction of APN permutations via Walsh zero spaces",
    "abstract": "A Walsh zero space (WZ space) for $f:F_{2^n}\\rightarrow F_{2^n}$ is an\n$n$-dimensional vector subspace of $F_{2^n}\\times F_{2^n}$ whose all nonzero\nelements are Walsh zeros of $f$. We provide several theoretical and\ncomputer-free constructions of WZ spaces for Gold APN functions\n$f(x)=x^{2^i+1}$ on $F_{2^n}$ where $n$ is odd and $\\gcd(i,n)=1$. We also\nprovide several constructions of trivially intersecting pairs of such spaces.\nWe illustrate applications of our constructions that include constructing APN\npermutations that are CCZ equivalent to $f$ but not extended affine equivalent\nto $f$ or its compositional inverse.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Benjamin Chase",
      "Petr Lisonek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.15582"
  },
  {
    "id": "arXiv:2110.15584",
    "title": "A two level finite element method for Stokes constrained Dirichlet  boundary control problem",
    "abstract": "In this paper we present a finite element analysis for a Dirichlet boundary\ncontrol problem governed by the Stokes equation. The Dirichlet control is\nconsidered in a convex closed subset of the energy space\n$\\mathbf{H}^1(\\Omega).$ Most of the previous works on the Stokes Dirichlet\nboundary control problem deals with either tangential control or the case where\nthe flux of the control is zero. This choice of the control is very particular\nand their choice of the formulation leads to the control with limited\nregularity. To overcome this difficulty, we introduce the Stokes problem with\noutflow condition and the control acts on the Dirichlet boundary only hence our\ncontrol is more general and it has both the tangential and normal components.\nWe prove well-posedness and discuss on the regularity of the control problem.\nThe first-order optimality condition for the control leads to a Signorini\nproblem. We develop a two-level finite element discretization by using\n$\\mathbf{P}_1$ elements(on the fine mesh) for the velocity and the control\nvariable and $P_0$ elements (on the coarse mesh) for the pressure variable. The\nstandard energy error analysis gives $\\frac{1}{2}+\\frac{\\delta}{2}$ order of\nconvergence when the control is in $\\mathbf{H}^{\\frac{3}{2}+\\delta}(\\Omega)$\nspace. Here we have improved it to $\\frac{1}{2}+\\delta,$ which is optimal.\nAlso, when the control lies in less regular space we derived optimal order of\nconvergence up to the regularity. The theoretical results are corroborated by a\nvariety of numerical tests.",
    "descriptor": "",
    "authors": [
      "Thirupathi Gudi",
      "Ramesh Ch. Sau"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.15584"
  },
  {
    "id": "arXiv:2110.15585",
    "title": "Non-existence results for vectorial bent functions with Dillon exponent",
    "abstract": "We prove new non-existence results for vectorial monomial Dillon type bent\nfunctions mapping the field of order $2^{2m}$ to the field of order $2^{m/3}$.\nWhen $m$ is odd and $m>3$ we show that there are no such functions. When $m$ is\neven we derive a condition for the bent coefficient. The latter result allows\nus to find examples of bent functions with $m=6$ in a simple way.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Lucien Lapierre",
      "Petr Lisonek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.15585"
  },
  {
    "id": "arXiv:2110.15586",
    "title": "A hybrid chaos map with two control parameters to secure image  encryption algorithms",
    "abstract": "In this paper, we introduce a hybrid chaos map for image encryption method\nwith high sensitivity. This new map is sensitive to small changes in the\nstarting point and also in control parameters which result in having more\ncomputational complexity. Also, it has uniform distribution that provides\nresisting of the new system against attacks in security applications. Various\ntests and plots are demonstrated to show more chaotic behavior of the proposed\nsystem. Finally, to show the ability of the generated chaotic map in the\nexistences image cryptography approaches, we further report some results in\nthis area.",
    "descriptor": "\nComments: 4pages, 7 figures\n",
    "authors": [
      "Roghayeh Hosseinzadeh",
      "Yavar Khedmati",
      "Reza Parvaz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.15586"
  },
  {
    "id": "arXiv:2110.15588",
    "title": "Nash equilibrium of multi-agent graphical game with a privacy  information encrypted learning algorithm",
    "abstract": "This paper studies the global Nash equilibrium problem of leader-follower\nmulti-agent dynamics, which yields consensus with a privacy information\nencrypted learning algorithm. With the secure hierarchical structure, the\nrelationship between the secure consensus problem and global Nash equilibrium\nis discussed under potential packet loss attacks, and the necessary and\nsufficient condition for the existence of global Nash equilibrium is provided\nregarding the soft-constrained graphical game. To achieve the optimal policies,\nthe convergence of decentralized learning algorithm is guaranteed with an\niteratively updated pair of decoupled gains. By using the developed\nquantization scheme and additive-multiplicative property, the\nencryption-decryption is successfully embedded in the data transmission and\ncomputation to overcome the potential privacy violation in unreliable networks.\nA simulation example is provided to verify the effectiveness of the designed\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Kun Zhang",
      "Ji-Feng Zhang",
      "Rong Su",
      "Huaguang Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.15588"
  },
  {
    "id": "arXiv:2110.15596",
    "title": "Training Integrable Parameterizations of Deep Neural Networks in the  Infinite-Width Limit",
    "abstract": "To theoretically understand the behavior of trained deep neural networks, it\nis necessary to study the dynamics induced by gradient methods from a random\ninitialization. However, the nonlinear and compositional structure of these\nmodels make these dynamics difficult to analyze. To overcome these challenges,\nlarge-width asymptotics have recently emerged as a fruitful viewpoint and led\nto practical insights on real-world deep networks. For two-layer neural\nnetworks, it has been understood via these asymptotics that the nature of the\ntrained model radically changes depending on the scale of the initial random\nweights, ranging from a kernel regime (for large initial variance) to a feature\nlearning regime (for small initial variance). For deeper networks more regimes\nare possible, and in this paper we study in detail a specific choice of \"small\"\ninitialization corresponding to ''mean-field'' limits of neural networks, which\nwe call integrable parameterizations (IPs). First, we show that under standard\ni.i.d. zero-mean initialization, integrable parameterizations of neural\nnetworks with more than four layers start at a stationary point in the\ninfinite-width limit and no learning occurs. We then propose various methods to\navoid this trivial behavior and analyze in detail the resulting dynamics. In\nparticular, one of these methods consists in using large initial learning\nrates, and we show that it is equivalent to a modification of the recently\nproposed maximal update parameterization $\\mu$P. We confirm our results with\nnumerical experiments on image classification tasks, which additionally show a\nstrong difference in behavior between various choices of activation functions\nthat is not yet captured by theory.",
    "descriptor": "",
    "authors": [
      "Karl Hajjar",
      "L\u00e9na\u00efc Chizat",
      "Christophe Giraud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15596"
  },
  {
    "id": "arXiv:2110.15599",
    "title": "Handshakes AI Research at CASE 2021 Task 1: Exploring different  approaches for multilingual tasks",
    "abstract": "The aim of the CASE 2021 Shared Task 1 (H\\\"urriyeto\\u{g}lu et al., 2021) was\nto detect and classify socio-political and crisis event information at\ndocument, sentence, cross-sentence, and token levels in a multilingual setting,\nwith each of these subtasks being evaluated separately in each test language.\nOur submission contained entries in all of the subtasks, and the scores\nobtained validated our research finding: That the multilingual aspect of the\ntasks should be embraced, so that modeling and training regimes use the\nmultilingual nature of the tasks to their mutual benefit, rather than trying to\ntackle the different languages separately. Our code is available at\nhttps://github.com/HandshakesByDC/case2021/",
    "descriptor": "\nComments: Accepted paper for CASE 2021 workshop at ACL-IJCNLP 2021. (6 pages including references)\n",
    "authors": [
      "Vivek Kalyan",
      "Paul Tan",
      "Shaun Tan",
      "Martin Andrews"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15599"
  },
  {
    "id": "arXiv:2110.15600",
    "title": "Data Driven based Dynamic Correction Prediction Model for NOx Emission  of Coal Fired Boiler",
    "abstract": "The real-time prediction of NOx emissions is of great significance for\npollutant emission control and unit operation of coal-fired power plants.\nAiming at dealing with the large time delay and strong nonlinear\ncharacteristics of the combustion process, a dynamic correction prediction\nmodel considering the time delay is proposed. First, the maximum information\ncoefficient (MIC) is used to calculate the delay time between related\nparameters and NOx emissions, and the modeling data set is reconstructed; then,\nan adaptive feature selection algorithm based on Lasso and ReliefF is\nconstructed to filter out the high correlation with NOx emissions. Parameters;\nFinally, an extreme learning machine (ELM) model combined with error correction\nwas established to achieve the purpose of dynamically predicting the\nconcentration of nitrogen oxides. Experimental results based on actual data\nshow that the same variable has different delay times under load conditions\nsuch as rising, falling, and steady; and there are differences in model\ncharacteristic variables under different load conditions; dynamic error\ncorrection strategies effectively improve modeling accuracy; proposed The\nprediction error of the algorithm under different working conditions is less\nthan 2%, which can accurately predict the NOx concentration at the combustion\noutlet, and provide guidance for NOx emission monitoring and combustion process\noptimization.",
    "descriptor": "\nComments: in Chinese language, Accepted by Proceedings of the CSEE\n",
    "authors": [
      "Zhenhao Tang",
      "Deyu Zhu",
      "Yang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15600"
  },
  {
    "id": "arXiv:2110.15603",
    "title": "An error analysis of discontinuous finite element methods for the  optimal control problems governed by Stokes equation",
    "abstract": "In this paper, an abstract framework for the error analysis of discontinuous\nfinite element method is developed for the distributed and Neumann boundary\ncontrol problems governed by the stationary Stokes equation with control\nconstraints. {\\it A~priori} error estimates of optimal order are derived for\nvelocity and pressure in the energy norm and the $L^2$-norm, respectively.\nMoreover, a reliable and efficient {\\it a~posteriori} error estimator is\nderived. The results are applicable to a variety of problems just under the\nminimal regularity possessed by the well-posedness of the problem. In\nparticular, we consider the abstract results with suitable stable pairs of\nvelocity and pressure spaces like as the lowest-order Crouzeix-Raviart finite\nelement and piecewise constant spaces, piecewise linear and constant finite\nelement spaces. The theoretical results are illustrated by the numerical\nexperiments.",
    "descriptor": "",
    "authors": [
      "Asha K Dond",
      "Thirupathi Gudi",
      "Ramesh Ch. Sau"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.15603"
  },
  {
    "id": "arXiv:2110.15606",
    "title": "Improving Camouflaged Object Detection with the Uncertainty of  Pseudo-edge Labels",
    "abstract": "This paper focuses on camouflaged object detection (COD), which is a task to\ndetect objects hidden in the background. Most of the current COD models aim to\nhighlight the target object directly while outputting ambiguous camouflaged\nboundaries. On the other hand, the performance of the models considering edge\ninformation is not yet satisfactory. To this end, we propose a new framework\nthat makes full use of multiple visual cues, i.e., saliency as well as edges,\nto refine the predicted camouflaged map. This framework consists of three key\ncomponents, i.e., a pseudo-edge generator, a pseudo-map generator, and an\nuncertainty-aware refinement module. In particular, the pseudo-edge generator\nestimates the boundary that outputs the pseudo-edge label, and the conventional\nCOD method serves as the pseudo-map generator that outputs the pseudo-map\nlabel. Then, we propose an uncertainty-based module to reduce the uncertainty\nand noise of such two pseudo labels, which takes both pseudo labels as input\nand outputs an edge-accurate camouflaged map. Experiments on various COD\ndatasets demonstrate the effectiveness of our method with superior performance\nto the existing state-of-the-art methods.",
    "descriptor": "\nComments: Accepted to ACM Multimedia Asia 2021\n",
    "authors": [
      "Nobukatsu Kajiura",
      "Hong Liu",
      "Shin'ichi Satoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15606"
  },
  {
    "id": "arXiv:2110.15608",
    "title": "Explicit Port-Hamiltonian FEM-Models for Linear Mechanical Systems with  Non-Uniform Boundary Conditions",
    "abstract": "In this contribution we present how to obtain explicit state space models in\nport-Hamiltonian form when a mixed finite element method is applied to a linear\nmechanical system with non-uniform boundary conditions. The key is to express\nthe variational problem based on the principle of virtual power, with both the\nDirichlet (velocity) and Neumann (stress) boundary conditions imposed in a weak\nsense. As a consequence, the formal skew-adjointness of the system operator\nbecomes directly visible after integration by parts, and, after compatible FE\ndiscretization, the boundary degrees of freedom of both causalities appear as\nexplicit inputs in the resulting state space model. The rationale behind our\nformulation is illustrated using a lumped parameter example, and numerical\nexperiments on a one-dimensional rod show the properties of the approach in\npractice.",
    "descriptor": "\nComments: 6 pages, 6 figures, submitted to the 10th Vienna International Conference on Mathematical Modelling\n",
    "authors": [
      "Tobias Thoma",
      "Paul Kotyczka"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15608"
  },
  {
    "id": "arXiv:2110.15609",
    "title": "Visual Spatio-temporal Relation-enhanced Network for Cross-modal  Text-Video Retrieval",
    "abstract": "The task of cross-modal retrieval between texts and videos aims to understand\nthe correspondence between vision and language. Existing studies follow a trend\nof measuring text-video similarity on the basis of textual and video\nembeddings. In common practice, video representation is constructed by feeding\nvideo frames into 2D/3D-CNN for global visual feature extraction or only\nlearning simple semantic relations by using local-level fine-grained frame\nregions via graph convolutional network. However, these video representations\ndo not fully exploit spatio-temporal relation among visual components in\nlearning video representations, resulting in their inability to distinguish\nvideos with the same visual components but with different relations. To solve\nthis problem, we propose a Visual Spatio-temporal Relation-enhanced Network\n(VSR-Net), a novel cross-modal retrieval framework that enhances visual\nrepresentation with spatio-temporal relations among components. Specifically,\nvisual spatio-temporal relations are encoded using a multi-layer\nspatio-temporal transformer to learn visual relational features. We combine\nfine-grained local relation and global features in bridging text-video\nmodalities. Extensive experimental are conducted on both MSR-VTT and MSVD\ndatasets. The results demonstrate the effectiveness of our proposed model.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Ning Han",
      "Jingjing Chen",
      "Guangyi Xiao",
      "Yawen Zeng",
      "Chuhao Shi",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.15609"
  },
  {
    "id": "arXiv:2110.15610",
    "title": "Unsupervised Person Re-Identification with Wireless Positioning under  Weak Scene Labeling",
    "abstract": "Existing unsupervised person re-identification methods only rely on visual\nclues to match pedestrians under different cameras. Since visual data is\nessentially susceptible to occlusion, blur, clothing changes, etc., a promising\nsolution is to introduce heterogeneous data to make up for the defect of visual\ndata. Some works based on full-scene labeling introduce wireless positioning to\nassist cross-domain person re-identification, but their GPS labeling of entire\nmonitoring scenes is laborious. To this end, we propose to explore unsupervised\nperson re-identification with both visual data and wireless positioning\ntrajectories under weak scene labeling, in which we only need to know the\nlocations of the cameras. Specifically, we propose a novel unsupervised\nmultimodal training framework (UMTF), which models the complementarity of\nvisual data and wireless information. Our UMTF contains a multimodal data\nassociation strategy (MMDA) and a multimodal graph neural network (MMGN). MMDA\nexplores potential data associations in unlabeled multimodal data, while MMGN\npropagates multimodal messages in the video graph based on the adjacency matrix\nlearned from histogram statistics of wireless data. Thanks to the robustness of\nthe wireless data to visual noise and the collaboration of various modules,\nUMTF is capable of learning a model free of the human label on data. Extensive\nexperimental results conducted on two challenging datasets, i.e., WP-ReID and\nDukeMTMC-VideoReID demonstrate the effectiveness of the proposed method.",
    "descriptor": "\nComments: Submitted to TPAMI for review\n",
    "authors": [
      "Yiheng Liu",
      "Wengang Zhou",
      "Qiaokang Xie",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15610"
  },
  {
    "id": "arXiv:2110.15611",
    "title": "Numerical and convergence analysis of the stochastic Lagrangian averaged  Navier-Stokes equations",
    "abstract": "The primary emphasis of this work is the development of a finite element\nbased space-time discretization for solving the stochastic Lagrangian averaged\nNavier-Stokes (LANS-$\\alpha$) equations of incompressible fluid turbulence with\nmultiplicative random forcing, under nonperiodic boundary conditions within a\nbounded polygonal (or polyhedral) domain of R^d , d $\\in$ {2, 3}. The\nconvergence analysis of a fully discretized numerical scheme is investigated\nand split into two cases according to the spacial scale $\\alpha$, namely we\nfirst assume $\\alpha$ to be controlled by the step size of the space\ndiscretization so that it vanishes when passing to the limit, then we provide\nan alternative study when $\\alpha$ is fixed. A preparatory analysis of uniform\nestimates in both $\\alpha$ and discretization parameters is carried out.\nStarting out from the stochastic LANS-$\\alpha$ model, we achieve convergence\ntoward the continuous strong solutions of the stochastic Navier-Stokes\nequations in 2D when $\\alpha$ vanishes at the limit. Additionally, convergence\ntoward the continuous strong solutions of the stochastic LANS-$\\alpha$ model is\naccomplished if $\\alpha$ is fixed.",
    "descriptor": "",
    "authors": [
      "Jad Doghman",
      "Ludovic Gouden\u00e8ge"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)",
      "Classical Physics (physics.class-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.15611"
  },
  {
    "id": "arXiv:2110.15621",
    "title": "MentalBERT: Publicly Available Pretrained Language Models for Mental  Healthcare",
    "abstract": "Mental health is a critical issue in modern society, and mental disorders\ncould sometimes turn to suicidal ideation without adequate treatment. Early\ndetection of mental disorders and suicidal ideation from social content\nprovides a potential way for effective social intervention. Recent advances in\npretrained contextualized language representations have promoted the\ndevelopment of several domain-specific pretrained models and facilitated\nseveral downstream applications. However, there are no existing pretrained\nlanguage models for mental healthcare. This paper trains and release two\npretrained masked language models, i.e., MentalBERT and MentalRoBERTa, to\nbenefit machine learning for the mental healthcare research community. Besides,\nwe evaluate our trained domain-specific models and several variants of\npretrained language models on several mental disorder detection benchmarks and\ndemonstrate that language representations pretrained in the target domain\nimprove the performance of mental health detection tasks.",
    "descriptor": "",
    "authors": [
      "Shaoxiong Ji",
      "Tianlin Zhang",
      "Luna Ansari",
      "Jie Fu",
      "Prayag Tiwari",
      "Erik Cambria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15621"
  },
  {
    "id": "arXiv:2110.15622",
    "title": "Path-Enhanced Multi-Relational Question Answering with Knowledge Graph  Embeddings",
    "abstract": "The multi-relational Knowledge Base Question Answering (KBQA) system performs\nmulti-hop reasoning over the knowledge graph (KG) to achieve the answer. Recent\napproaches attempt to introduce the knowledge graph embedding (KGE) technique\nto handle the KG incompleteness but only consider the triple facts and neglect\nthe significant semantic correlation between paths and multi-relational\nquestions. In this paper, we propose a Path and Knowledge Embedding-Enhanced\nmulti-relational Question Answering model (PKEEQA), which leverages multi-hop\npaths between entities in the KG to evaluate the ambipolar correlation between\na path embedding and a multi-relational question embedding via a customizable\npath representation mechanism, benefiting for achieving more accurate answers\nfrom the perspective of both the triple facts and the extra paths. Experimental\nresults illustrate that PKEEQA improves KBQA models' performance for\nmulti-relational question answering with explainability to some extent derived\nfrom paths.",
    "descriptor": "",
    "authors": [
      "Guanglin Niu",
      "Yang Li",
      "Chengguang Tang",
      "Zhongkai Hu",
      "Shibin Yang",
      "Peng Li",
      "Chengyu Wang",
      "Hao Wang",
      "Jian Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15622"
  },
  {
    "id": "arXiv:2110.15629",
    "title": "Attacking Video Recognition Models with Bullet-Screen Comments",
    "abstract": "Recent research has demonstrated that Deep Neural Networks (DNNs) are\nvulnerable to adversarial patches which introducing perceptible but localized\nchanges to the input. Nevertheless, existing approaches have focused on\ngenerating adversarial patches on images, their counterparts in videos have\nbeen less explored. Compared with images, attacking videos is much more\nchallenging as it needs to consider not only spatial cues but also temporal\ncues. To close this gap, we introduce a novel adversarial attack in this paper,\nthe bullet-screen comment (BSC) attack, which attacks video recognition models\nwith BSCs. Specifically, adversarial BSCs are generated with a Reinforcement\nLearning (RL) framework, where the environment is set as the target model and\nthe agent plays the role of selecting the position and transparency of each\nBSC. By continuously querying the target models and receiving feedback, the\nagent gradually adjusts its selection strategies in order to achieve a high\nfooling rate with non-overlapping BSCs. As BSCs can be regarded as a kind of\nmeaningful patch, adding it to a clean video will not affect people' s\nunderstanding of the video content, nor will arouse people' s suspicion. We\nconduct extensive experiments to verify the effectiveness of the proposed\nmethod. On both UCF-101 and HMDB-51 datasets, our BSC attack method can achieve\nabout 90\\% fooling rate when attack three mainstream video recognition models,\nwhile only occluding \\textless 8\\% areas in the video.",
    "descriptor": "",
    "authors": [
      "Kai Chen",
      "Zhipeng Wei",
      "Jingjing Chen",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15629"
  },
  {
    "id": "arXiv:2110.15632",
    "title": "Bayesian Optimal Experimental Design for Simulator Models of Cognition",
    "abstract": "Bayesian optimal experimental design (BOED) is a methodology to identify\nexperiments that are expected to yield informative data. Recent work in\ncognitive science considered BOED for computational models of human behavior\nwith tractable and known likelihood functions. However, tractability often\ncomes at the cost of realism; simulator models that can capture the richness of\nhuman behavior are often intractable. In this work, we combine recent advances\nin BOED and approximate inference for intractable models, using\nmachine-learning methods to find optimal experimental designs, approximate\nsufficient summary statistics and amortized posterior distributions. Our\nsimulation experiments on multi-armed bandit tasks show that our method results\nin improved model discrimination and parameter estimation, as compared to\nexperimental designs commonly used in the literature.",
    "descriptor": "\nComments: Accepted as a poster at the NeurIPS 2021 Workshop \"AI for Science\"\n",
    "authors": [
      "Simon Valentin",
      "Steven Kleinegesse",
      "Neil R. Bramley",
      "Michael U. Gutmann",
      "Christopher G. Lucas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15632"
  },
  {
    "id": "arXiv:2110.15639",
    "title": "Multi-Task and Multi-Modal Learning for RGB Dynamic Gesture Recognition",
    "abstract": "Gesture recognition is getting more and more popular due to various\napplication possibilities in human-machine interaction. Existing multi-modal\ngesture recognition systems take multi-modal data as input to improve accuracy,\nbut such methods require more modality sensors, which will greatly limit their\napplication scenarios. Therefore we propose an end-to-end multi-task learning\nframework in training 2D convolutional neural networks. The framework can use\nthe depth modality to improve accuracy during training and save costs by using\nonly RGB modality during inference. Our framework is trained to learn a\nrepresentation for multi-task learning: gesture segmentation and gesture\nrecognition. Depth modality contains the prior information for the location of\nthe gesture. Therefore it can be used as the supervision for gesture\nsegmentation. A plug-and-play module named Multi-Scale-Decoder is designed to\nrealize gesture segmentation, which contains two sub-decoder. It is used in the\nlower stage and higher stage respectively, and can help the network pay\nattention to key target areas, ignore irrelevant information, and extract more\ndiscriminant features. Additionally, the MSD module and depth modality are only\nused in the training stage to improve gesture recognition performance. Only RGB\nmodality and network without MSD are required during inference. Experimental\nresults on three public gesture recognition datasets show that our proposed\nmethod provides superior performance compared with existing gesture recognition\nframeworks. Moreover, using the proposed plug-and-play MSD in other 2D\nCNN-based frameworks also get an excellent accuracy improvement.",
    "descriptor": "",
    "authors": [
      "Dinghao Fan",
      "Hengjie Lu",
      "Shugong Xu",
      "Shan Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15639"
  },
  {
    "id": "arXiv:2110.15644",
    "title": "Gabor filter incorporated CNN for compression",
    "abstract": "Convolutional neural networks (CNNs) are remarkably successful in many\ncomputer vision tasks. However, the high cost of inference is problematic for\nembedded and real-time systems, so there are many studies on compressing the\nnetworks. On the other hand, recent advances in self-attention models showed\nthat convolution filters are preferable to self-attention in the earlier\nlayers, which indicates that stronger inductive biases are better in the\nearlier layers. As shown in convolutional filters, strong biases can train\nspecific filters and construct unnecessarily filters to zero. This is analogous\nto classical image processing tasks, where choosing the suitable filters makes\na compact dictionary to represent features. We follow this idea and incorporate\nGabor filters in the earlier layers of CNNs for compression. The parameters of\nGabor filters are learned through backpropagation, so the features are\nrestricted to Gabor filters. We show that the first layer of VGG-16 for\nCIFAR-10 has 192 kernels/features, but learning Gabor filters requires an\naverage of 29.4 kernels. Also, using Gabor filters, an average of 83% and 94%\nof kernels in the first and the second layer, respectively, can be removed on\nthe altered ResNet-20, where the first five layers are exchanged with two\nlayers of larger kernels for CIFAR-10.",
    "descriptor": "",
    "authors": [
      "Akihiro Imamura",
      "Nana Arizumi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15644"
  },
  {
    "id": "arXiv:2110.15649",
    "title": "New approach for solving stationary nonlinear Navier-Stokes equations in  non-convex domain",
    "abstract": "In the paper, an approach for the numerical solution of stationary nonlinear\nNavier-Stokes equations in rotation and convective forms in a polygonal domain\ncontaining one reentrant corner on its boundary, that is, a corner greater than\n${\\pi}$ is considered. The method allows us to obtain the 1st order of\nconvergence of the approximate solution to the exact one with respect to the\ngrid step h, regardless of the reentrant corner value.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Alexey V. Rukavishnikov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15649"
  },
  {
    "id": "arXiv:2110.15650",
    "title": "RedCASTLE: Practically Applicable $k_s$-Anonymity for IoT Streaming Data  at the Edge in Node-RED",
    "abstract": "In this paper, we present RedCASTLE, a practically applicable solution for\nEdge-based $k_s$-anonymization of IoT streaming data in Node-RED. RedCASTLE\nbuilds upon a pre-existing, rudimentary implementation of the CASTLE algorithm\nand significantly extends it with functionalities indispensable for real-world\nIoT scenarios. In addition, RedCASTLE provides an abstraction layer for\nsmoothly integrating $k_s$-anonymization into Node-RED, a visually programmable\nmiddleware for streaming dataflows widely used in Edge-based IoT scenarios.\nLast but not least, RedCASTLE also provides further capabilities for basic\ninformation reduction that complement $k_s$-anonymization in the\nprivacy-friendly implementation of usecases involving IoT streaming data. A\npreliminary performance assessment finds that RedCASTLE comes with reasonable\noverheads and demonstrates its practical viability.",
    "descriptor": "\nComments: Accepted for publication as regular research paper for the \"8th International Workshop on Middleware and Applications for the Internet of Things\". This is a preprint manuscript (authors' own version before final copy-editing)\n",
    "authors": [
      "Frank Pallas",
      "Julian Legler",
      "Niklas Amslgruber",
      "Elias Gr\u00fcnewald"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.15650"
  },
  {
    "id": "arXiv:2110.15655",
    "title": "Scale-Aware Dynamic Network for Continuous-Scale Super-Resolution",
    "abstract": "Single-image super-resolution (SR) with fixed and discrete scale factors has\nachieved great progress due to the development of deep learning technology.\nHowever, the continuous-scale SR, which aims to use a single model to process\narbitrary (integer or non-integer) scale factors, is still a challenging task.\nThe existing SR models generally adopt static convolution to extract features,\nand thus unable to effectively perceive the change of scale factor, resulting\nin limited generalization performance on multi-scale SR tasks. Moreover, the\nexisting continuous-scale upsampling modules do not make full use of\nmulti-scale features and face problems such as checkerboard artifacts in the SR\nresults and high computational complexity. To address the above problems, we\npropose a scale-aware dynamic network (SADN) for continuous-scale SR. First, we\npropose a scale-aware dynamic convolutional (SAD-Conv) layer for the feature\nlearning of multiple SR tasks with various scales. The SAD-Conv layer can\nadaptively adjust the attention weights of multiple convolution kernels based\non the scale factor, which enhances the expressive power of the model with a\nnegligible extra computational cost. Second, we devise a continuous-scale\nupsampling module (CSUM) with the multi-bilinear local implicit function\n(MBLIF) for any-scale upsampling. The CSUM constructs multiple feature spaces\nwith gradually increasing scales to approximate the continuous feature\nrepresentation of an image, and then the MBLIF makes full use of multi-scale\nfeatures to map arbitrary coordinates to RGB values in high-resolution space.\nWe evaluate our SADN using various benchmarks. The experimental results show\nthat the CSUM can replace the previous fixed-scale upsampling layers and obtain\na continuous-scale SR network while maintaining performance. Our SADN uses much\nfewer parameters and outperforms the state-of-the-art SR methods.",
    "descriptor": "",
    "authors": [
      "Hanlin Wu",
      "Ning Ni",
      "Libao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15655"
  },
  {
    "id": "arXiv:2110.15659",
    "title": "Amendable Generation for Dialogue State Tracking",
    "abstract": "In task-oriented dialogue systems, recent dialogue state tracking methods\ntend to perform one-pass generation of the dialogue state based on the previous\ndialogue state. The mistakes of these models made at the current turn are prone\nto be carried over to the next turn, causing error propagation. In this paper,\nwe propose a novel Amendable Generation for Dialogue State Tracking (AG-DST),\nwhich contains a two-pass generation process: (1) generating a primitive\ndialogue state based on the dialogue of the current turn and the previous\ndialogue state, and (2) amending the primitive dialogue state from the first\npass. With the additional amending generation pass, our model is tasked to\nlearn more robust dialogue state tracking by amending the errors that still\nexist in the primitive dialogue state, which plays the role of reviser in the\ndouble-checking process and alleviates unnecessary error propagation.\nExperimental results show that AG-DST significantly outperforms previous works\nin two active DST datasets (MultiWOZ 2.2 and WOZ 2.0), achieving new\nstate-of-the-art performances.",
    "descriptor": "\nComments: Presented at EMNLP 2021 NLP4ConvAI Workshop\n",
    "authors": [
      "Xin Tian",
      "Liankai Huang",
      "Yingzhan Lin",
      "Siqi Bao",
      "Huang He",
      "Yunyi Yang",
      "Hua Wu",
      "Fan Wang",
      "Shuqi Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15659"
  },
  {
    "id": "arXiv:2110.15660",
    "title": "Frame-Capture-Based CSI Recomposition Pertaining to Firmware-Agnostic  WiFi Sensing",
    "abstract": "With regard to the implementation of WiFi sensing agnostic according to the\navailability of channel state information (CSI), we investigate the possibility\nof estimating a CSI matrix based on its compressed version, which is known as\nbeamforming feedback matrix (BFM). Being different from the CSI matrix that is\nprocessed and discarded in physical layer components, the BFM can be captured\nusing a medium-access-layer frame-capturing technique because this is exchanged\namong an access point (AP) and stations (STAs) over the air. This indicates\nthat WiFi sensing that leverages the BFM matrix is more practical to implement\nusing the pre-installed APs. However, the ability of BFM-based sensing has been\nevaluated in a few tasks, and more general insights into its performance should\nbe provided. To fill this gap, we propose a CSI estimation method based on BFM,\napproximating the estimation function with a machine learning model. In\naddition, to improve the estimation accuracy, we leverage the inter-subcarrier\ndependency using the BFMs at multiple subcarriers in orthogonal frequency\ndivision multiplexing transmissions. Our simulation evaluation reveals that the\nestimated CSI matches the ground-truth amplitude. Moreover, compared to CSI\nestimation at each individual subcarrier, the effect of the BFMs at multiple\nsubcarriers on the CSI estimation accuracy is validated.",
    "descriptor": "",
    "authors": [
      "Ryosuke Hanahara",
      "Sohei Itahara",
      "Kota Yamashita",
      "Yusuke Koda",
      "Akihito Taya",
      "Takayuki Nishio",
      "Koji Yamamoto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15660"
  },
  {
    "id": "arXiv:2110.15669",
    "title": "SDP: Scalable Real-time Dynamic Graph Partitioner",
    "abstract": "Time-evolving large graph has received attention due to their participation\nin real-world applications such as social networks and PageRank calculation. It\nis necessary to partition a large-scale dynamic graph in a streaming manner to\novercome the memory bottleneck while partitioning the computational load.\nReducing network communication and balancing the load between the partitions\nare the criteria to achieve effective run-time performance in graph\npartitioning. Moreover, an optimal resource allocation is needed to utilise the\nresources while catering the graph streams into the partitions. A number of\nexisting partitioning algorithms (ADP, LogGP and LEOPARD) have been proposed to\naddress the above problem. However, these partitioning methods are incapable of\nscaling the resources and handling the stream of data in real-time.\nIn this study, we propose a dynamic graph partitioning method called Scalable\nDynamic Graph Partitioner (SDP) using the streaming partitioning technique. The\nSDP contributes a novel vertex assigning method, communication-aware balancing\nmethod, and a scaling technique to produce an efficient dynamic graph\npartitioner. Experiment results show that the proposed method achieves up to\n90% reduction of communication cost and 60%-70% balancing the load dynamically,\ncompared with previous algorithms. Moreover, the proposed algorithm\nsignificantly reduces the execution time during partitioning.",
    "descriptor": "",
    "authors": [
      "Md Anwarul Kaium Patwary",
      "Saurabh Garg",
      "Sudheer Kumar Battula",
      "Byeong Kang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.15669"
  },
  {
    "id": "arXiv:2110.15674",
    "title": "Multi-target tracking for video surveillance using deep affinity  network: a brief review",
    "abstract": "Deep learning models are known to function like the human brain. Due to their\nfunctional mechanism, they are frequently utilized to accomplish tasks that\nrequire human intelligence. Multi-target tracking (MTT) for video surveillance\nis one of the important and challenging tasks, which has attracted the\nresearcher's attention due to its potential applications in various domains.\nMulti-target tracking tasks require locating the objects individually in each\nframe, which remains a huge challenge as there are immediate changes in\nappearances and extreme occlusions of objects. In addition to that, the\nMultitarget tracking framework requires multiple tasks to perform i.e. target\ndetection, estimating trajectory, associations between frame, and\nre-identification. Various methods have been suggested, and some assumptions\nare made to constrain the problem in the context of a particular problem. In\nthis paper, the state-of-the-art MTT models, which leverage from deep learning\nrepresentational power are reviewed.",
    "descriptor": "",
    "authors": [
      "Sanam Nisar Mangi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15674"
  },
  {
    "id": "arXiv:2110.15676",
    "title": "An Assessment of Solvers for Algebraically Stabilized Discretizations of  Convection-Diffusion-Reaction Equations",
    "abstract": "We consider flux-corrected finite element discretizations of 3D\nconvection-dominated transport problems and assess the computational efficiency\nof algorithms based on such approximations. The methods under investigation\ninclude flux-corrected transport schemes and monolithic limiters. We discretize\nin space using a continuous Galerkin method and $\\mathbb{P}_1$ or\n$\\mathbb{Q}_1$ finite elements. Time integration is performed using the\nCrank-Nicolson method or an explicit strong stability preserving Runge-Kutta\nmethod. Nonlinear systems are solved using a fixed-point iteration method,\nwhich requires solution of large linear systems at each iteration or time step.\nThe great variety of options in the choice of discretization methods and solver\ncomponents calls for a dedicated comparative study of existing approaches. To\nperform such a study, we define new 3D test problems for time-dependent and\nstationary convection-diffusion-reaction equations. The results of our\nnumerical experiments illustrate how the limiting technique, time\ndiscretization and solver impact on the overall performance.",
    "descriptor": "",
    "authors": [
      "Abhinav Jha",
      "Ond\u0159ej P\u00e1rtl",
      "Naveed Ahmed",
      "Dmitri Kuzmin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15676"
  },
  {
    "id": "arXiv:2110.15678",
    "title": "A Shading-Guided Generative Implicit Model for Shape-Accurate 3D-Aware  Image Synthesis",
    "abstract": "The advancement of generative radiance fields has pushed the boundary of\n3D-aware image synthesis. Motivated by the observation that a 3D object should\nlook realistic from multiple viewpoints, these methods introduce a multi-view\nconstraint as regularization to learn valid 3D radiance fields from 2D images.\nDespite the progress, they often fall short of capturing accurate 3D shapes due\nto the shape-color ambiguity, limiting their applicability in downstream tasks.\nIn this work, we address this ambiguity by proposing a novel shading-guided\ngenerative implicit model that is able to learn a starkly improved shape\nrepresentation. Our key insight is that an accurate 3D shape should also yield\na realistic rendering under different lighting conditions. This multi-lighting\nconstraint is realized by modeling illumination explicitly and performing\nshading with various lighting conditions. Gradients are derived by feeding the\nsynthesized images to a discriminator. To compensate for the additional\ncomputational burden of calculating surface normals, we further devise an\nefficient volume rendering strategy via surface tracking, reducing the training\nand inference time by 24% and 48%, respectively. Our experiments on multiple\ndatasets show that the proposed approach achieves photorealistic 3D-aware image\nsynthesis while capturing accurate underlying 3D shapes. We demonstrate\nimproved performance of our approach on 3D shape reconstruction against\nexisting methods, and show its applicability on image relighting. Our code will\nbe released at https://github.com/XingangPan/ShadeGAN.",
    "descriptor": "\nComments: Accepted to NeurIPS2021. We proposed ShadeGAN, which could perform shape-accurate 3D-aware image synthesis by modeling shading in generative implicit models\n",
    "authors": [
      "Xingang Pan",
      "Xudong Xu",
      "Chen Change Loy",
      "Christian Theobalt",
      "Bo Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15678"
  },
  {
    "id": "arXiv:2110.15681",
    "title": "False Positive Detection and Prediction Quality Estimation for LiDAR  Point Cloud Segmentation",
    "abstract": "We present a novel post-processing tool for semantic segmentation of LiDAR\npoint cloud data, called LidarMetaSeg, which estimates the prediction quality\nsegmentwise. For this purpose we compute dispersion measures based on network\nprobability outputs as well as feature measures based on point cloud input\nfeatures and aggregate them on segment level. These aggregated measures are\nused to train a meta classification model to predict whether a predicted\nsegment is a false positive or not and a meta regression model to predict the\nsegmentwise intersection over union. Both models can then be applied to\nsemantic segmentation inferences without knowing the ground truth. In our\nexperiments we use different LiDAR segmentation models and datasets and analyze\nthe power of our method. We show that our results outperform other standard\napproaches.",
    "descriptor": "",
    "authors": [
      "Pascal Colling",
      "Matthias Rottmann",
      "Lutz Roese-Koerner",
      "Hanno Gottschalk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15681"
  },
  {
    "id": "arXiv:2110.15682",
    "title": "Overview of ADoBo 2021: Automatic Detection of Unassimilated Borrowings  in the Spanish Press",
    "abstract": "This paper summarizes the main findings of the ADoBo 2021 shared task,\nproposed in the context of IberLef 2021. In this task, we invited participants\nto detect lexical borrowings (coming mostly from English) in Spanish newswire\ntexts. This task was framed as a sequence classification problem using BIO\nencoding. We provided participants with an annotated corpus of lexical\nborrowings which we split into training, development and test splits. We\nreceived submissions from 4 teams with 9 different system runs overall. The\nresults, which range from F1 scores of 37 to 85, suggest that this is a\nchallenging task, especially when out-of-domain or OOV words are considered,\nand that traditional methods informed with lexicographic information would\nbenefit from taking advantage of current NLP trends.",
    "descriptor": "\nComments: Post-print. Original version at Procesamiento del Lenguaje Natural 67 (2021), p. 277-285\n",
    "authors": [
      "Elena \u00c1lvarez Mellado",
      "Luis Espinosa Anke",
      "Julio Gonzalo Arroyo",
      "Constantine Lignos",
      "Jordi Porta Zamorano"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15682"
  },
  {
    "id": "arXiv:2110.15683",
    "title": "Incentives for Item Duplication under Fair Ranking Policies",
    "abstract": "Ranking is a fundamental operation in information access systems, to filter\ninformation and direct user attention towards items deemed most relevant to\nthem. Due to position bias, items of similar relevance may receive\nsignificantly different exposure, raising fairness concerns for item providers\nand motivating recent research into fair ranking. While the area has progressed\ndramatically over recent years, no study to date has investigated the potential\nproblem posed by duplicated items. Duplicates and near-duplicates are common in\nseveral domains, including marketplaces and document collections available to\nsearch engines. In this work, we study the behaviour of different fair ranking\npolicies in the presence of duplicates, quantifying the extra-exposure gained\nby redundant items. We find that fairness-aware ranking policies may conflict\nwith diversity, due to their potential to incentivize duplication more than\npolicies solely focused on relevance. This fact poses a problem for system\nowners who, as a result of this incentive, may have to deal with increased\nredundancy, which is at odds with user satisfaction. Finally, we argue that\nthis aspect represents a blind spot in the normative reasoning underlying\ncommon fair ranking metrics, as rewarding providers who duplicate their items\nwith increased exposure seems unfair for the remaining providers.",
    "descriptor": "",
    "authors": [
      "Giorgio Maria Di Nunzio",
      "Alessandro Fabris",
      "Gianmaria Silvello",
      "Gian Antonio Susto"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.15683"
  },
  {
    "id": "arXiv:2110.15687",
    "title": "Reducing the Human Factor in Virtual Reality Research to Increase  Reproducibility and Replicability",
    "abstract": "The replication crisis is real, and awareness of its existence is growing\nacross disciplines. We argue that research in human-computer interaction (HCI),\nand especially virtual reality (VR), is vulnerable to similar challenges due to\nmany shared methodologies, theories, and incentive structures. For this reason,\nin this work, we transfer established solutions from other fields to address\nthe lack of replicability and reproducibility in HCI and VR. We focus on\nreducing errors resulting from the so-called human factor and adapt established\nsolutions to the specific needs of VR research. In addition, we present a\ntoolkit to support the setup, execution, and evaluation of VR research. Some of\nthe features aim to reduce human errors and thus improve replicability and\nreproducibility. Finally, the identified chances are applied to a typical\nscientific process in VR.",
    "descriptor": "\nComments: Daniel Hepperle: Original Draft, Conceptualization, Investigation, Methodology; Tobias Dienlin & Matthias W\\\"olfel: Review & Editing, Conceptualization, Supervision\n",
    "authors": [
      "Daniel Hepperle",
      "Tobias Dienlin",
      "Matthias W\u00f6lfel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.15687"
  },
  {
    "id": "arXiv:2110.15693",
    "title": "Shortest Beer Path Queries in Outerplanar Graphs",
    "abstract": "A \\emph{beer graph} is an undirected graph $G$, in which each edge has a\npositive weight and some vertices have a beer store. A \\emph{beer path} between\ntwo vertices $u$ and $v$ in $G$ is any path in $G$ between $u$ and $v$ that\nvisits at least one beer store.\nWe show that any outerplanar beer graph $G$ with $n$ vertices can be\npreprocessed in $O(n)$ time into a data structure of size $O(n)$, such that for\nany two query vertices $u$ and $v$, (i) the weight of the shortest beer path\nbetween $u$ and $v$ can be reported in $O(\\alpha(n))$ time (where $\\alpha(n)$\nis the inverse Ackermann function), and (ii) the shortest beer path between $u$\nand $v$ can be reported in $O(L)$ time, where $L$ is the number of vertices on\nthis path. Both results are optimal, even when $G$ is a beer tree (i.e., a beer\ngraph whose underlying graph is a tree).",
    "descriptor": "\nComments: ISAAC 2021\n",
    "authors": [
      "Joyce Bacic",
      "Saeed Mehrabi",
      "Michiel Smid"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15693"
  },
  {
    "id": "arXiv:2110.15695",
    "title": "A Protocol for Emotions",
    "abstract": "We tend to consider emotions a manifestation of our innermost nature of human\nbeings. Emotions characterize our lives in many ways and they chaperon every\nrational activity we carry out. Despite their pervasiveness, there are still\nmany things we ignore about emotions. Among them, our understanding of how\nliving beings transfer emotions is limited. In particular, there are highly\nsophisticated interactions between human beings that we would like to\ncomprehend. For instance, think of a movie director who knows in advance the\nstrong emotional impact that a certain scene will have on the spectators.\nAlthough many artists rely on some emotional devices, their talent and vision\nare still the key factors.\nIn this work we analyze high-level protocols for transferring emotions\nbetween two intelligent agents. To the best of our knowledge, this is the first\nattempt to use communication protocols for modeling the exchange of human\nemotions. By means of a number of examples, we show that our protocols\nadequately model the engagement of the two parties. Beyond the theoretical\ninterest, our proposal can provide a stepping stone for several applications\nthat we also discuss in this paper.",
    "descriptor": "",
    "authors": [
      "Gabriele Costa"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.15695"
  },
  {
    "id": "arXiv:2110.15700",
    "title": "Boosting Anomaly Detection Using Unsupervised Diverse Test-Time  Augmentation",
    "abstract": "Anomaly detection is a well-known task that involves the identification of\nabnormal events that occur relatively infrequently. Methods for improving\nanomaly detection performance have been widely studied. However, no studies\nutilizing test-time augmentation (TTA) for anomaly detection in tabular data\nhave been performed. TTA involves aggregating the predictions of several\nsynthetic versions of a given test sample; TTA produces different points of\nview for a specific test instance and might decrease its prediction bias. We\npropose the Test-Time Augmentation for anomaly Detection (TTAD) technique, a\nTTA-based method aimed at improving anomaly detection performance. TTAD\naugments a test instance based on its nearest neighbors; various methods,\nincluding the k-Means centroid and SMOTE methods, are used to produce the\naugmentations. Our technique utilizes a Siamese network to learn an advanced\ndistance metric when retrieving a test instance's neighbors. Our experiments\nshow that the anomaly detector that uses our TTA technique achieved\nsignificantly higher AUC results on all datasets evaluated.",
    "descriptor": "",
    "authors": [
      "Seffi Cohen",
      "Niv Goldshlager",
      "Lior Rokach",
      "Bracha Shapira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15700"
  },
  {
    "id": "arXiv:2110.15701",
    "title": "Xi-Learning: Successor Feature Transfer Learning for General Reward  Functions",
    "abstract": "Transfer in Reinforcement Learning aims to improve learning performance on\ntarget tasks using knowledge from experienced source tasks. Successor features\n(SF) are a prominent transfer mechanism in domains where the reward function\nchanges between tasks. They reevaluate the expected return of previously\nlearned policies in a new target task and to transfer their knowledge. A\nlimiting factor of the SF framework is its assumption that rewards linearly\ndecompose into successor features and a reward weight vector. We propose a\nnovel SF mechanism, $\\xi$-learning, based on learning the cumulative discounted\nprobability of successor features. Crucially, $\\xi$-learning allows to\nreevaluate the expected return of policies for general reward functions. We\nintroduce two $\\xi$-learning variations, prove its convergence, and provide a\nguarantee on its transfer performance. Experimental evaluations based on\n$\\xi$-learning with function approximation demonstrate the prominent advantage\nof $\\xi$-learning over available mechanisms not only for general reward\nfunctions, but also in the case of linearly decomposable reward functions.",
    "descriptor": "\nComments: source code available at this https URL\n",
    "authors": [
      "Chris Reinke",
      "Xavier Alameda-Pineda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15701"
  },
  {
    "id": "arXiv:2110.15702",
    "title": "DeF-DReL: Systematic Deployment of Serverless Functions in Fog and Cloud  environments using Deep Reinforcement Learning",
    "abstract": "Fog computing is introduced by shifting cloud resources towards the users'\nproximity to mitigate the limitations possessed by cloud computing. Fog\nenvironment made its limited resource available to a large number of users to\ndeploy their serverless applications, composed of several serverless functions.\nOne of the primary intentions behind introducing the fog environment is to\nfulfil the demand of latency and location-sensitive serverless applications\nthrough its limited resources. The recent research mainly focuses on assigning\nmaximum resources to such applications from the fog node and not taking full\nadvantage of the cloud environment. This introduces a negative impact in\nproviding the resources to a maximum number of connected users. To address this\nissue, in this paper, we investigated the optimum percentage of a user's\nrequest that should be fulfilled by fog and cloud. As a result, we proposed\nDeF-DReL, a Systematic Deployment of Serverless Functions in Fog and Cloud\nenvironments using Deep Reinforcement Learning, using several real-life\nparameters, such as distance and latency of the users from nearby fog node,\nuser's priority, the priority of the serverless applications and their resource\ndemand, etc. The performance of the DeF-DReL algorithm is further compared with\nrecent related algorithms. From the simulation and comparison results, its\nsuperiority over other algorithms and its applicability to the real-life\nscenario can be clearly observed.",
    "descriptor": "\nComments: This version is submitted to Elsevier JNCA and is under review process\n",
    "authors": [
      "Chinmaya Kumar Dehurya",
      "Shivananda Poojaraa",
      "Shridhar Domanalb",
      "Satish Narayana Srirama"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15702"
  },
  {
    "id": "arXiv:2110.15703",
    "title": "Navigating the Kaleidoscope of COVID-19 Misinformation Using Deep  Learning",
    "abstract": "Irrespective of the success of the deep learning-based mixed-domain transfer\nlearning approach for solving various Natural Language Processing tasks, it\ndoes not lend a generalizable solution for detecting misinformation from\nCOVID-19 social media data. Due to the inherent complexity of this type of\ndata, caused by its dynamic (context evolves rapidly), nuanced (misinformation\ntypes are often ambiguous), and diverse (skewed, fine-grained, and overlapping\ncategories) nature, it is imperative for an effective model to capture both the\nlocal and global context of the target domain. By conducting a systematic\ninvestigation, we show that: (i) the deep Transformer-based pre-trained models,\nutilized via the mixed-domain transfer learning, are only good at capturing the\nlocal context, thus exhibits poor generalization, and (ii) a combination of\nshallow network-based domain-specific models and convolutional neural networks\ncan efficiently extract local as well as global context directly from the\ntarget data in a hierarchical fashion, enabling it to offer a more\ngeneralizable solution.",
    "descriptor": "\nComments: The 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP)\n",
    "authors": [
      "Yuanzhi Chen",
      "Mohammad Rashedul Hasan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15703"
  },
  {
    "id": "arXiv:2110.15704",
    "title": "Influence of ASR and Language Model on Alzheimer's Disease Detection",
    "abstract": "Alzheimer's Disease is the most common form of dementia. Automatic detection\nfrom speech could help to identify symptoms at early stages, so that preventive\nactions can be carried out. This research is a contribution to the ADReSSo\nChallenge, we analyze the usage of a SotA ASR system to transcribe\nparticipant's spoken descriptions from a picture. We analyse the loss of\nperformance regarding the use of human transcriptions (measured using\ntranscriptions from the 2020 ADReSS Challenge). Furthermore, we study the\ninfluence of a language model -- which tends to correct non-standard sequences\nof words -- with the lack of language model to decode the hypothesis from the\nASR. This aims at studying the language bias and get more meaningful\ntranscriptions based only on the acoustic information from patients. The\nproposed system combines acoustic -- based on prosody and voice quality -- and\nlexical features based on the first occurrence of the most common words. The\nreported results show the effect of using automatic transcripts with or without\nlanguage model. The best fully automatic system achieves up to 76.06 % of\naccuracy (without language model), significantly higher, 3 % above, than a\nsystem employing word transcriptions decoded using general purpose language\nmodels.",
    "descriptor": "\nComments: 5 pages. Submitted to Interspeech 2021. arXiv admin note: text overlap with arXiv:2011.09272\n",
    "authors": [
      "Joan Codina-Filb\u00e0",
      "Guillermo C\u00e1mbara",
      "Jordi Luque",
      "Mireia Farr\u00fas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15704"
  },
  {
    "id": "arXiv:2110.15705",
    "title": "Distilling Relation Embeddings from Pre-trained Language Models",
    "abstract": "Pre-trained language models have been found to capture a surprisingly rich\namount of lexical knowledge, ranging from commonsense properties of everyday\nconcepts to detailed factual knowledge about named entities. Among others, this\nmakes it possible to distill high-quality word vectors from pre-trained\nlanguage models. However, it is currently unclear to what extent it is possible\nto distill relation embeddings, i.e. vectors that characterize the relationship\nbetween two words. Such relation embeddings are appealing because they can, in\nprinciple, encode relational knowledge in a more fine-grained way than is\npossible with knowledge graphs. To obtain relation embeddings from a\npre-trained language model, we encode word pairs using a (manually or\nautomatically generated) prompt, and we fine-tune the language model such that\nrelationally similar word pairs yield similar output vectors. We find that the\nresulting relation embeddings are highly competitive on analogy (unsupervised)\nand relation classification (supervised) benchmarks, even without any\ntask-specific fine-tuning. Source code to reproduce our experimental results\nand the model checkpoints are available in the following repository:\nhttps://github.com/asahi417/relbert",
    "descriptor": "\nComments: EMNLP 2021 main conference\n",
    "authors": [
      "Asahi Ushio",
      "Jose Camacho-Collados",
      "Steven Schockaert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15705"
  },
  {
    "id": "arXiv:2110.15706",
    "title": "Integrating Deep Event-Level and Script-Level Information for Script  Event Prediction",
    "abstract": "Scripts are structured sequences of events together with the participants,\nwhich are extracted from the texts.Script event prediction aims to predict the\nsubsequent event given the historical events in the script. Two kinds of\ninformation facilitate this task, namely, the event-level information and the\nscript-level information. At the event level, existing studies view an event as\na verb with its participants, while neglecting other useful properties, such as\nthe state of the participants. At the script level, most existing studies only\nconsider a single event sequence corresponding to one common protagonist. In\nthis paper, we propose a Transformer-based model, called MCPredictor, which\nintegrates deep event-level and script-level information for script event\nprediction. At the event level, MCPredictor utilizes the rich information in\nthe text to obtain more comprehensive event semantic representations. At the\nscript-level, it considers multiple event sequences corresponding to different\nparticipants of the subsequent event. The experimental results on the\nwidely-used New York Times corpus demonstrate the effectiveness and superiority\nof the proposed model.",
    "descriptor": "\nComments: EMNLP 2021 long paper (main conference)\n",
    "authors": [
      "Long Bai",
      "Saiping Guan",
      "Jiafeng Guo",
      "Zixuan Li",
      "Xiaolong Jin",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15706"
  },
  {
    "id": "arXiv:2110.15707",
    "title": "Hidden Markov Based Mathematical Model dedicated to Extract Ingredients  from Recipe Text",
    "abstract": "Natural Language Processing (NLP) is a branch of artificial intelligence that\ngives machines the ability to decode human languages. Partof-speech tagging\n(POS tagging) is a pre-processing task that requires an annotated corpus.\nRule-based and stochastic methods showed remarkable results for POS tag\nprediction. On this work, I performed a mathematical model based on Hidden\nMarkov structures and I obtained a high-level accuracy of ingredients extracted\nfrom text recipe with performances greater than what traditional methods could\nmake without unknown words consideration.",
    "descriptor": "",
    "authors": [
      "Zied Baklouti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15707"
  },
  {
    "id": "arXiv:2110.15708",
    "title": "Neural sentence embedding models for semantic similarity estimation in  the biomedical domain",
    "abstract": "BACKGROUND: In this study, we investigated the efficacy of current\nstate-of-the-art neural sentence embedding models for semantic similarity\nestimation of sentences from biomedical literature. We trained different neural\nembedding models on 1.7 million articles from the PubMed Open Access dataset,\nand evaluated them based on a biomedical benchmark set containing 100 sentence\npairs annotated by human experts and a smaller contradiction subset derived\nfrom the original benchmark set.\nRESULTS: With a Pearson correlation of 0.819, our best unsupervised model\nbased on the Paragraph Vector Distributed Memory algorithm outperforms previous\nstate-of-the-art results achieved on the BIOSSES biomedical benchmark set.\nMoreover, our proposed supervised model that combines different string-based\nsimilarity metrics with a neural embedding model surpasses previous\nontology-dependent supervised state-of-the-art approaches in terms of Pearson's\nr (r=0.871) on the biomedical benchmark set. In contrast to the promising\nresults for the original benchmark, we found our best models' performance on\nthe smaller contradiction subset to be poor.\nCONCLUSIONS: In this study we highlighted the value of neural network-based\nmodels for semantic similarity estimation in the biomedical domain by showing\nthat they can keep up with and even surpass previous state-of-the-art\napproaches for semantic similarity estimation that depend on the availability\nof laboriously curated ontologies when evaluated on a biomedical benchmark set.\nCapturing contradictions and negations in biomedical sentences, however,\nemerged as an essential area for further work.",
    "descriptor": "\nComments: Abstract shortened to comply with arXiv guidelines\n",
    "authors": [
      "Kathrin Blagec",
      "Hong Xu",
      "Asan Agibetov",
      "Matthias Samwald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15708"
  },
  {
    "id": "arXiv:2110.15709",
    "title": "LegalNLP -- Natural Language Processing methods for the Brazilian Legal  Language",
    "abstract": "We present and make available pre-trained language models (Phraser, Word2Vec,\nDoc2Vec, FastText, and BERT) for the Brazilian legal language, a Python package\nwith functions to facilitate their use, and a set of demonstrations/tutorials\ncontaining some applications involving them. Given that our material is built\nupon legal texts coming from several Brazilian courts, this initiative is\nextremely helpful for the Brazilian legal field, which lacks other open and\nspecific tools and language models. Our main objective is to catalyze the use\nof natural language processing tools for legal texts analysis by the Brazilian\nindustry, government, and academia, providing the necessary tools and\naccessible material.",
    "descriptor": "",
    "authors": [
      "Felipe Maia Polo",
      "Gabriel Caiaffa Floriano Mendon\u00e7a",
      "Kau\u00ea Capellato J. Parreira",
      "Lucka Gianvechio",
      "Peterson Cordeiro",
      "Jonathan Batista Ferreira",
      "Leticia Maria Paz de Lima",
      "Ant\u00f4nio Carlos do Amaral Maia",
      "Renato Vicente"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15709"
  },
  {
    "id": "arXiv:2110.15710",
    "title": "Classification of hierarchical text using geometric deep learning: the  case of clinical trials corpus",
    "abstract": "We consider the hierarchical representation of documents as graphs and use\ngeometric deep learning to classify them into different categories. While graph\nneural networks can efficiently handle the variable structure of hierarchical\ndocuments using the permutation invariant message passing operations, we show\nthat we can gain extra performance improvements using our proposed selective\ngraph pooling operation that arises from the fact that some parts of the\nhierarchy are invariable across different documents. We applied our model to\nclassify clinical trial (CT) protocols into completed and terminated\ncategories. We use bag-of-words based, as well as pre-trained transformer-based\nembeddings to featurize the graph nodes, achieving f1-scores around 0.85 on a\npublicly available large scale CT registry of around 360K protocols. We further\ndemonstrate how the selective pooling can add insights into the CT termination\nstatus prediction. We make the source code and dataset splits accessible.",
    "descriptor": "\nComments: Accepted as a long paper in EMNLP 2021 - Oral presentation to the Machine Learning track\n",
    "authors": [
      "Sohrab Ferdowsi",
      "Nikolay Borissov",
      "Julien Knafou",
      "Poorya Amini",
      "Douglas Teodoro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15710"
  },
  {
    "id": "arXiv:2110.15712",
    "title": "Analysing the Effect of Masking Length Distribution of MLM: An  Evaluation Framework and Case Study on Chinese MRC Datasets",
    "abstract": "Machine reading comprehension (MRC) is a challenging natural language\nprocessing (NLP) task. Recently, the emergence of pre-trained models (PTM) has\nbrought this research field into a new era, in which the training objective\nplays a key role. The masked language model (MLM) is a self-supervised training\nobjective that widely used in various PTMs. With the development of training\nobjectives, many variants of MLM have been proposed, such as whole word\nmasking, entity masking, phrase masking, span masking, and so on. In different\nMLM, the length of the masked tokens is different. Similarly, in different\nmachine reading comprehension tasks, the length of the answer is also\ndifferent, and the answer is often a word, phrase, or sentence. Thus, in MRC\ntasks with different answer lengths, whether the length of MLM is related to\nperformance is a question worth studying. If this hypothesis is true, it can\nguide us how to pre-train the MLM model with a relatively suitable mask length\ndistribution for MRC task. In this paper, we try to uncover how much of MLM's\nsuccess in the machine reading comprehension tasks comes from the correlation\nbetween masking length distribution and answer length in MRC dataset. In order\nto address this issue, herein, (1) we propose four MRC tasks with different\nanswer length distributions, namely short span extraction task, long span\nextraction task, short multiple-choice cloze task, long multiple-choice cloze\ntask; (2) four Chinese MRC datasets are created for these tasks; (3) we also\nhave pre-trained four masked language models according to the answer length\ndistributions of these datasets; (4) ablation experiments are conducted on the\ndatasets to verify our hypothesis. The experimental results demonstrate that\nour hypothesis is true.",
    "descriptor": "",
    "authors": [
      "Changchang. Zeng",
      "Shaobo. Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15712"
  },
  {
    "id": "arXiv:2110.15716",
    "title": "Building the Language Resource for a Cebuano-Filipino Neural Machine  Translation System",
    "abstract": "Parallel corpus is a critical resource in machine learning-based translation.\nThe task of collecting, extracting, and aligning texts in order to build an\nacceptable corpus for doing the translation is very tedious most especially for\nlow-resource languages. In this paper, we present the efforts made to build a\nparallel corpus for Cebuano and Filipino from two different domains: biblical\ntexts and the web. For the biblical resource, subword unit translation for\nverbs and copy-able approach for nouns were applied to correct inconsistencies\nin the translation. This correction mechanism was applied as a preprocessing\ntechnique. On the other hand, for Wikipedia being the main web resource,\ncommonly occurring topic segments were extracted from both the source and the\ntarget languages. These observed topic segments are unique in 4 different\ncategories. The identification of these topic segments may be used for the\nautomatic extraction of sentences. A Recurrent Neural Network was used to\nimplement the translation using OpenNMT sequence modeling tool in TensorFlow.\nThe two different corpora were then evaluated by using them as two separate\ninputs in the neural network. Results have shown a difference in BLEU scores in\nboth corpora.",
    "descriptor": "\nComments: Published in the Proceedings of the 2019 3rd International Conference on Natural Language Processing and Information Retrieval. arXiv admin note: substantial text overlap with arXiv:1902.07250\n",
    "authors": [
      "Kristine Mae Adlaon",
      "Nelson Marcos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15716"
  },
  {
    "id": "arXiv:2110.15717",
    "title": "LIDSNet: A Lightweight on-device Intent Detection model using Deep  Siamese Network",
    "abstract": "Intent detection is a crucial task in any Natural Language Understanding\n(NLU) system and forms the foundation of a task-oriented dialogue system. To\nbuild high-quality real-world conversational solutions for edge devices, there\nis a need for deploying intent detection model on device. This necessitates a\nlight-weight, fast, and accurate model that can perform efficiently in a\nresource-constrained environment. To this end, we propose LIDSNet, a novel\nlightweight on-device intent detection model, which accurately predicts the\nmessage intent by utilizing a Deep Siamese Network for learning better sentence\nrepresentations. We use character-level features to enrich the sentence-level\nrepresentations and empirically demonstrate the advantage of transfer learning\nby utilizing pre-trained embeddings. Furthermore, to investigate the efficacy\nof the modules in our architecture, we conduct an ablation study and arrive at\nour optimal model. Experimental results prove that LIDSNet achieves\nstate-of-the-art competitive accuracy of 98.00% and 95.97% on SNIPS and ATIS\npublic datasets respectively, with under 0.59M parameters. We further benchmark\nLIDSNet against fine-tuned BERTs and show that our model is at least 41x\nlighter and 30x faster during inference than MobileBERT on Samsung Galaxy S20\ndevice, justifying its efficiency on resource-constrained edge devices.",
    "descriptor": "\nComments: Accepted for publication in 2021 IEEE 20th International Conference on Machine Learning and Applications (ICMLA)\n",
    "authors": [
      "Vibhav Agarwal",
      "Sudeep Deepak Shivnikar",
      "Sourav Ghosh",
      "Himanshu Arora",
      "Yashwant Saini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15717"
  },
  {
    "id": "arXiv:2110.15718",
    "title": "Deep convolutional forest: a dynamic deep ensemble approach for spam  detection in text",
    "abstract": "The increase in people's use of mobile messaging services has led to the\nspread of social engineering attacks like phishing, considering that spam text\nis one of the main factors in the dissemination of phishing attacks to steal\nsensitive data such as credit cards and passwords. In addition, rumors and\nincorrect medical information regarding the COVID-19 pandemic are widely shared\non social media leading to people's fear and confusion. Thus, filtering spam\ncontent is vital to reduce risks and threats. Previous studies relied on\nmachine learning and deep learning approaches for spam classification, but\nthese approaches have two limitations. Machine learning models require manual\nfeature engineering, whereas deep neural networks require a high computational\ncost. This paper introduces a dynamic deep ensemble model for spam detection\nthat adjusts its complexity and extracts features automatically. The proposed\nmodel utilizes convolutional and pooling layers for feature extraction along\nwith base classifiers such as random forests and extremely randomized trees for\nclassifying texts into spam or legitimate ones. Moreover, the model employs\nensemble learning procedures like boosting and bagging. As a result, the model\nachieved high precision, recall, f1-score and accuracy of 98.38%.",
    "descriptor": "",
    "authors": [
      "Mai A. Shaaban",
      "Yasser F. Hassan",
      "Shawkat K. Guirguis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15718"
  },
  {
    "id": "arXiv:2110.15719",
    "title": "Generational Frameshifts in Technology: Computer Science and  Neurosurgery, The VR Use Case",
    "abstract": "We are at a unique moment in history where there is a confluence of\ntechnologies which will synergistically come together to transform the practice\nof neurosurgery. These technological transformations will be all-encompassing,\nincluding improved tools and methods for intraoperative performance of\nneurosurgery, scalable solutions for asynchronous neurosurgical training and\nsimulation, as well as broad aggregation of operative data allowing fundamental\nchanges in quality assessment, billing, outcome measures, and dissemination of\nsurgical best practices. The ability to perform surgery more safely and more\nefficiently while capturing the operative details and parsing each component of\nthe operation will open an entirely new epoch advancing our field and all\nsurgical specialties. The digitization of all components within the operating\nroom will allow us to leverage the various fields within computer and\ncomputational science to obtain new insights that will improve care and\ndelivery of the highest quality neurosurgery regardless of location. The\ndemocratization of neurosurgery is at hand and will be driven by our\ndevelopment, extraction, and adoption of these tools of the modern world.\nVirtual reality provides a good example of how consumer-facing technologies are\nfinding a clear role in industry and medicine and serves as a notable example\nof the confluence of various computer science technologies creating a novel\nparadigm for scaling human ability and interactions. The authors describe the\ntechnology ecosystem that has come and highlight a myriad of computational and\ndata sciences that will be necessary to enable the operating room of the near\nfuture.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Samuel R. Browd",
      "Maya Sharma",
      "Chetan Sharma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Other Quantitative Biology (q-bio.OT)"
    ],
    "url": "https://arxiv.org/abs/2110.15719"
  },
  {
    "id": "arXiv:2110.15720",
    "title": "Weakly Supervised Concept Map Generation through Task-Guided Graph  Translation",
    "abstract": "Recent years have witnessed the rapid development of concept map generation\ntechniques due to their advantages in providing well-structured summarization\nof knowledge from free texts. Traditional unsupervised methods do not generate\ntask-oriented concept maps, whereas deep generative models require large\namounts of training data. In this work, we present GT-D2G (Graph Translation\nbased Document-To-Graph), an automatic concept map generation framework that\nleverages generalized NLP pipelines to derive semantic-rich initial graphs, and\ntranslates them into more concise structures under the weak supervision of\ndocument labels. The quality and interpretability of such concept maps are\nvalidated through human evaluation on three real-world corpora, and their\nutility in the downstream task is further demonstrated in the controlled\nexperiments with scarce document labels.",
    "descriptor": "",
    "authors": [
      "Jiaying Lu",
      "Xiangjue Dong",
      "Carl J. Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15720"
  },
  {
    "id": "arXiv:2110.15721",
    "title": "Paperswithtopic: Topic Identification from Paper Title Only",
    "abstract": "The deep learning field is growing rapidly as witnessed by the exponential\ngrowth of papers submitted to journals, conferences, and pre-print servers. To\ncope with the sheer number of papers, several text mining tools from natural\nlanguage processing (NLP) have been proposed that enable researchers to keep\ntrack of recent findings. In this context, our paper makes two main\ncontributions: first, we collected and annotated a dataset of papers paired by\ntitle and sub-field from the field of artificial intelligence (AI), and,\nsecond, we present results on how to predict a paper's AI sub-field from a\ngiven paper title only. Importantly, for the latter, short-text classification\ntask we compare several algorithms from conventional machine learning all the\nway up to recent, larger transformer architectures. Finally, for the\ntransformer models, we also present gradient-based, attention visualizations to\nfurther explain the model's classification process. All code can be found at\n\\url{https://github.com/1pha/paperswithtopic}",
    "descriptor": "",
    "authors": [
      "Daehyun Cho",
      "Christian Wallraven"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15721"
  },
  {
    "id": "arXiv:2110.15722",
    "title": "A Novel Sequence Tagging Framework for Consumer Event-Cause Extraction",
    "abstract": "Consumer Event-Cause Extraction, the task aimed at extracting the potential\ncauses behind certain events in the text, has gained much attention in recent\nyears due to its wide applications. The ICDM 2020 conference sets up an\nevaluation competition that aims to extract events and the causes of the\nextracted events with a specified subject (a brand or product). In this task,\nwe mainly focus on how to construct an end-to-end model, and extract multiple\nevent types and event-causes simultaneously. To this end, we introduce a fresh\nperspective to revisit the relational event-cause extraction task and propose a\nnovel sequence tagging framework, instead of extracting event types and\nevents-causes separately. Experiments show our framework outperforms baseline\nmethods even when its encoder module uses an initialized pre-trained BERT\nencoder, showing the power of the new tagging framework. In this competition,\nour team achieved 1st place in the first stage leaderboard, and 3rd place in\nthe final stage leaderboard.",
    "descriptor": "",
    "authors": [
      "Congqing He",
      "Jie Zhang",
      "Xiangyu Zhu",
      "Huan Liu",
      "Yukun Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15722"
  },
  {
    "id": "arXiv:2110.15723",
    "title": "SP-GPT2: Semantics Improvement in Vietnamese Poetry Generation",
    "abstract": "Automatic text generation has garnered growing attention in recent years as\nan essential step towards computer creativity. Generative Pretraining\nTransformer 2 (GPT2) is one of the state of the art approaches that have\nexcellent successes. In this paper, we took the first step to investigate the\npower of GPT2 in traditional Vietnamese poetry generation. In the earlier time,\nour experiment with base GPT2 was quite good at generating the poem in the\nproper template. Though it can learn the patterns, including rhyme and tone\nrules, from the training data, like almost all other text generation\napproaches, the poems generated still has a topic drift and semantic\ninconsistency. To improve the cohesion within the poems, we proposed a new\nmodel SP-GPT2 (semantic poem GPT2) which was built on the top GPT2 model and an\nadditional loss to constrain context throughout the entire poem. For better\nevaluation, we examined the methods by both automatic quantitative evaluation\nand human evaluation. Both automatic and human evaluation demonstrated that our\napproach can generate poems that have better cohesion without losing the\nquality due to additional loss. At the same time, we are the pioneers of this\ntopic. We released the first computational scoring module for poems generated\nin the template containing the style rule dictionary. Additionally, we are the\nfirst to publish a Luc-Bat dataset, including 87609 Luc Bat poems, which is\nequivalent to about 2.6 million sentences, combined with about 83579 poems in\nother styles was also published for further exploration. The code is available\nat https://github.com/fsoft-ailab/Poem-Generator",
    "descriptor": "",
    "authors": [
      "Tuan Nguyen",
      "Hanh Pham",
      "Truong Bui",
      "Tan Nguyen",
      "Duc Luong",
      "Phong Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15723"
  },
  {
    "id": "arXiv:2110.15724",
    "title": "Learning to Learn End-to-End Goal-Oriented Dialog From Related Dialog  Tasks",
    "abstract": "For each goal-oriented dialog task of interest, large amounts of data need to\nbe collected for end-to-end learning of a neural dialog system. Collecting that\ndata is a costly and time-consuming process. Instead, we show that we can use\nonly a small amount of data, supplemented with data from a related dialog task.\nNaively learning from related data fails to improve performance as the related\ndata can be inconsistent with the target task. We describe a meta-learning\nbased method that selectively learns from the related dialog task data. Our\napproach leads to significant accuracy improvements in an example dialog task.",
    "descriptor": "\nComments: Workshop on NLP for Conversational AI, EMNLP 2021\n",
    "authors": [
      "Janarthanan Rajendran",
      "Jonathan K. Kummerfeld",
      "Satinder Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15724"
  },
  {
    "id": "arXiv:2110.15725",
    "title": "Batch-Softmax Contrastive Loss for Pairwise Sentence Scoring Tasks",
    "abstract": "The use of contrastive loss for representation learning has become prominent\nin computer vision, and it is now getting attention in Natural Language\nProcessing (NLP). Here, we explore the idea of using a batch-softmax\ncontrastive loss when fine-tuning large-scale pre-trained transformer models to\nlearn better task-specific sentence embeddings for pairwise sentence scoring\ntasks. We introduce and study a number of variations in the calculation of the\nloss as well as in the overall training procedure; in particular, we find that\ndata shuffling can be quite important. Our experimental results show sizable\nimprovements on a number of datasets and pairwise sentence scoring tasks\nincluding classification, ranking, and regression. Finally, we offer detailed\nanalysis and discussion, which should be useful for researchers aiming to\nexplore the utility of contrastive loss in NLP.",
    "descriptor": "\nComments: batch-softmax contrastive loss, pairwise sentence scoring, classification, ranking, and regression\n",
    "authors": [
      "Anton Chernyavskiy",
      "Dmitry Ilvovsky",
      "Pavel Kalinin",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.15725"
  },
  {
    "id": "arXiv:2110.15726",
    "title": "Social Media Reveals Urban-Rural Differences in Stress across China",
    "abstract": "Modeling differential stress expressions in urban and rural regions in China\ncan provide a better understanding of the effects of urbanization on\npsychological well-being in a country that has rapidly grown economically in\nthe last two decades. This paper studies linguistic differences in the\nexperiences and expressions of stress in urban-rural China from Weibo posts\nfrom over 65,000 users across 329 counties using hierarchical mixed-effects\nmodels. We analyzed phrases, topical themes, and psycho-linguistic word choices\nin Weibo posts mentioning stress to better understand appraisal differences\nsurrounding psychological stress in urban and rural communities in China; we\nthen compared them with large-scale polls from Gallup. After controlling for\nsocioeconomic and gender differences, we found that rural communities tend to\nexpress stress in emotional and personal themes such as relationships, health,\nand opportunity while users in urban areas express stress using relative,\ntemporal, and external themes such as work, politics, and economics. These\ndifferences exist beyond controlling for GDP and urbanization, indicating a\nfundamentally different lifestyle between rural and urban residents in very\nspecific environments, arguably having different sources of stress. We found\ncorroborative trends in physical, financial, and social wellness with\nurbanization in Gallup polls.",
    "descriptor": "\nComments: Accepted at AAAI Conference on Web and Social Media (ICWSM) 2022\n",
    "authors": [
      "Jesse Cui",
      "Tingdan Zhang",
      "Dandan Pang",
      "Kokil Jaidka",
      "Garrick Sherman",
      "Vinit Jakhetiya",
      "Lyle Ungar",
      "Sharath Chandra Guntuku"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.15726"
  },
  {
    "id": "arXiv:2110.15727",
    "title": "Calling to CNN-LSTM for Rumor Detection: A Deep Multi-channel Model for  Message Veracity Classification in Microblogs",
    "abstract": "Reputed by their low-cost, easy-access, real-time and valuable information,\nsocial media also wildly spread unverified or fake news. Rumors can notably\ncause severe damage on individuals and the society. Therefore, rumor detection\non social media has recently attracted tremendous attention. Most rumor\ndetection approaches focus on rumor feature analysis and social features, i.e.,\nmetadata in social media. Unfortunately, these features are data-specific and\nmay not always be available, e.g., when the rumor has just popped up and not\nyet propagated. In contrast, post contents (including images or videos) play an\nimportant role and can indicate the diffusion purpose of a rumor. Furthermore,\nrumor classification is also closely related to opinion mining and sentiment\nanalysis. Yet, to the best of our knowledge, exploiting images and sentiments\nis little investigated.Considering the available multimodal features from\nmicroblogs, notably, we propose in this paper an end-to-end model called\ndeepMONITOR that is based on deep neural networks and allows quite accurate\nautomated rumor verification, by utilizing all three characteristics: post\ntextual and image contents, as well as sentiment. deepMONITOR concatenates\nimage features with the joint text and sentiment features to produce a\nreliable, fused classification. We conduct extensive experiments on two\nlarge-scale, real-world datasets. The results show that deepMONITOR achieves a\nhigher accuracy than state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Abderrazek Azri",
      "C\u00e9cile Favre",
      "Nouria Harbi",
      "J\u00e9r\u00f4me Darmont",
      "Camille No\u00fbs"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15727"
  },
  {
    "id": "arXiv:2110.15728",
    "title": "Deep Learning for Bias Detection: From Inception to Deployment",
    "abstract": "To create a more inclusive workplace, enterprises are actively investing in\nidentifying and eliminating unconscious bias (e.g., gender, race, age,\ndisability, elitism and religion) across their various functions. We propose a\ndeep learning model with a transfer learning based language model to learn from\nmanually tagged documents for automatically identifying bias in enterprise\ncontent. We first pretrain a deep learning-based language-model using\nWikipedia, then fine tune the model with a large unlabelled data set related\nwith various types of enterprise content. Finally, a linear layer followed by\nsoftmax layer is added at the end of the language model and the model is\ntrained on a labelled bias dataset consisting of enterprise content. The\ntrained model is thoroughly evaluated on independent datasets to ensure a\ngeneral application. We present the proposed method and its deployment detail\nin a real-world application.",
    "descriptor": "",
    "authors": [
      "Md Abul Bashar",
      "Richi Nayak",
      "Anjor Kothare",
      "Vishal Sharma",
      "Kesavan Kandadai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.15728"
  },
  {
    "id": "arXiv:2110.15729",
    "title": "Decision Attentive Regularization to Improve Simultaneous Speech  Translation Systems",
    "abstract": "Simultaneous Speech-to-text Translation (SimulST) systems translate source\nspeech in tandem with the speaker using partial input. Recent works have tried\nto leverage the text translation task to improve the performance of Speech\nTranslation (ST) in the offline domain. Motivated by these improvements, we\npropose to add Decision Attentive Regularization (DAR) to Monotonic Multihead\nAttention (MMA) based SimulST systems. DAR improves the read/write decisions\nfor speech using the Simultaneous text Translation (SimulMT) task. We also\nextend several techniques from the offline domain to the SimulST task. Our\nproposed system achieves significant performance improvements for the MuST-C\nEnglish-German (EnDe) SimulST task, where we provide an average BLUE score\nimprovement of around 4.57 points or 34.17% across different latencies.\nFurther, the latency-quality tradeoffs establish that the proposed model\nachieves better results compared to the baseline.",
    "descriptor": "\nComments: 5 pages, 3 figures, 1 table\n",
    "authors": [
      "Mohd Abbas Zaidi",
      "Beomseok Lee",
      "Nikhil Kumar Lakumarapu",
      "Sangha Kim",
      "Chanwoo Kim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15729"
  },
  {
    "id": "arXiv:2110.15730",
    "title": "E-Commerce Dispute Resolution Prediction",
    "abstract": "E-Commerce marketplaces support millions of daily transactions, and some\ndisagreements between buyers and sellers are unavoidable. Resolving disputes in\nan accurate, fast, and fair manner is of great importance for maintaining a\ntrustworthy platform. Simple cases can be automated, but intricate cases are\nnot sufficiently addressed by hard-coded rules, and therefore most disputes are\ncurrently resolved by people. In this work we take a first step towards\nautomatically assisting human agents in dispute resolution at scale. We\nconstruct a large dataset of disputes from the eBay online marketplace, and\nidentify several interesting behavioral and linguistic patterns. We then train\nclassifiers to predict dispute outcomes with high accuracy. We explore the\nmodel and the dataset, reporting interesting correlations, important features,\nand insights.",
    "descriptor": "",
    "authors": [
      "David Tsurel",
      "Michael Doron",
      "Alexander Nus",
      "Arnon Dagan",
      "Ido Guy",
      "Dafna Shahaf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15730"
  },
  {
    "id": "arXiv:2110.15731",
    "title": "CORAA: a large corpus of spontaneous and prepared speech manually  validated for speech recognition in Brazilian Portuguese",
    "abstract": "Automatic Speech recognition (ASR) is a complex and challenging task. In\nrecent years, there have been significant advances in the area. In particular,\nfor the Brazilian Portuguese (BP) language, there were about 376 hours public\navailable for ASR task until the second half of 2020. With the release of new\ndatasets in early 2021, this number increased to 574 hours. The existing\nresources, however, are composed of audios containing only read and prepared\nspeech. There is a lack of datasets including spontaneous speech, which are\nessential in different ASR applications. This paper presents CORAA (Corpus of\nAnnotated Audios) v1. with 291 hours, a publicly available dataset for ASR in\nBP containing validated pairs (audio-transcription). CORAA also contains\nEuropean Portuguese audios (4.69 hours). We also present two public ASR models\nbased on Wav2Vec 2.0 XLSR-53 and fine-tuned over CORAA. Our best model achieved\na Word Error Rate of 27.35% on CORAA test set and 16.01% on Common Voice test\nset. When measuring the Character Error Rate, we obtained 14.26% and 5.45% for\nCORAA and Common Voice, respectively. CORAA corpora were assembled to both\nimprove ASR models in BP with phenomena from spontaneous speech and motivate\nyoung researchers to start their studies on ASR for Portuguese. All the corpora\nare publicly available at https://github.com/nilc-nlp/CORAA under the CC\nBY-NC-ND 4.0 license.",
    "descriptor": "\nComments: This paper is under consideration at Language Resources and Evaluation (LREV)\n",
    "authors": [
      "Arnaldo Candido Junior",
      "Edresson Casanova",
      "Anderson Soares",
      "Frederico Santos de Oliveira",
      "Lucas Oliveira",
      "Ricardo Corso Fernandes Junior",
      "Daniel Peixoto Pinto da Silva",
      "Fernando Gorgulho Fayet",
      "Bruno Baldissera Carlotto",
      "Lucas Rafael Stefanel Gris",
      "Sandra Maria Alu\u00edsio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15731"
  },
  {
    "id": "arXiv:2110.15732",
    "title": "Named Entity Recognition in Unstructured Medical Text Documents",
    "abstract": "Physicians provide expert opinion to legal courts on the medical state of\npatients, including determining if a patient is likely to have permanent or\nnon-permanent injuries or ailments. An independent medical examination (IME)\nreport summarizes a physicians medical opinion about a patients health status\nbased on the physicians expertise. IME reports contain private and sensitive\ninformation (Personally Identifiable Information or PII) that needs to be\nremoved or randomly encoded before further research work can be conducted. In\nour study the IME is an orthopedic surgeon from a private practice in the\nUnited States. The goal of this research is to perform named entity recognition\n(NER) to identify and subsequently remove/encode PII information from IME\nreports prepared by the physician. We apply the NER toolkits of OpenNLP and\nspaCy, two freely available natural language processing platforms, and compare\ntheir precision, recall, and f-measure performance at identifying five\ncategories of PII across trials of randomly selected IME reports using each\nmodels common default parameters. We find that both platforms achieve high\nperformance (f-measure > 0.9) at de-identification and that a spaCy model\ntrained with a 70-30 train-test data split is most performant.",
    "descriptor": "",
    "authors": [
      "Cole Pearson",
      "Naeem Seliya",
      "Rushit Dave"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15732"
  },
  {
    "id": "arXiv:2110.15733",
    "title": "Detecting Gender Bias in Transformer-based Models: A Case Study on BERT",
    "abstract": "In this paper, we propose a novel gender bias detection method by utilizing\nattention map for transformer-based models. We 1) give an intuitive gender bias\njudgement method by comparing the different relation degree between the genders\nand the occupation according to the attention scores, 2) design a gender bias\ndetector by modifying the attention module, 3) insert the gender bias detector\ninto different positions of the model to present the internal gender bias flow,\nand 4) draw the consistent gender bias conclusion by scanning the entire\nWikipedia, a BERT pretraining dataset. We observe that 1) the attention\nmatrices, Wq and Wk introduce much more gender bias than other modules\n(including the embedding layer) and 2) the bias degree changes periodically\ninside of the model (attention matrix Q, K, V, and the remaining part of the\nattention layer (including the fully-connected layer, the residual connection,\nand the layer normalization module) enhance the gender bias while the averaged\nattentions reduces the bias).",
    "descriptor": "",
    "authors": [
      "Bingbing Li",
      "Hongwu Peng",
      "Rajat Sainju",
      "Junhuan Yang",
      "Lei Yang",
      "Yueying Liang",
      "Weiwen Jiang",
      "Binghui Wang",
      "Hang Liu",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15733"
  },
  {
    "id": "arXiv:2110.15739",
    "title": "Scalable Inference in SDEs by Direct Matching of the  Fokker-Planck-Kolmogorov Equation",
    "abstract": "Simulation-based techniques such as variants of stochastic Runge-Kutta are\nthe de facto approach for inference with stochastic differential equations\n(SDEs) in machine learning. These methods are general-purpose and used with\nparametric and non-parametric models, and neural SDEs. Stochastic Runge-Kutta\nrelies on the use of sampling schemes that can be inefficient in high\ndimensions. We address this issue by revisiting the classical SDE literature\nand derive direct approximations to the (typically intractable)\nFokker-Planck-Kolmogorov equation by matching moments. We show how this\nworkflow is fast, scales to high-dimensional latent spaces, and is applicable\nto scarce-data applications, where a non-parametric SDE with a driving Gaussian\nprocess velocity field specifies the model.",
    "descriptor": "\nComments: To appear in Advances in Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Arno Solin",
      "Ella Tamir",
      "Prakhar Verma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15739"
  },
  {
    "id": "arXiv:2110.15742",
    "title": "Barlow Graph Auto-Encoder for Unsupervised Network Embedding",
    "abstract": "Network embedding has emerged as a promising research field for network\nanalysis. Recently, an approach, named Barlow Twins, has been proposed for\nself-supervised learning in computer vision by applying the\nredundancy-reduction principle to the embedding vectors corresponding to two\ndistorted versions of the image samples. Motivated by this, we propose Barlow\nGraph Auto-Encoder, a simple yet effective architecture for learning network\nembedding. It aims to maximize the similarity between the embedding vectors of\nimmediate and larger neighborhoods of a node, while minimizing the redundancy\nbetween the components of these projections. In addition, we also present the\nvariation counterpart named as Barlow Variational Graph Auto-Encoder. Our\napproach yields promising results for inductive link prediction and is also on\npar with state of the art for clustering and downstream node classification, as\ndemonstrated by extensive comparisons with several well-known techniques on\nthree benchmark citation datasets.",
    "descriptor": "",
    "authors": [
      "Rayyan Ahmad Khan",
      "Martin Kleinsteuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15742"
  },
  {
    "id": "arXiv:2110.15744",
    "title": "Media Modulation in Molecular Communications",
    "abstract": "In conventional molecular communication (MC) systems, the signaling molecules\nused for information transmission are stored, released, and then replenished by\na transmitter (TX). However, the replenishment of signaling molecules at the TX\nis challenging in practice. Furthermore, in most envisioned MC applications,\ne.g., in the medical field, it is not desirable to insert the TX into the MC\nsystem, as this might impair natural biological processes. In this paper, we\npropose the concept of media modulation based MC where the TX is placed outside\nthe channel and utilizes signaling molecules already existing inside the\nsystem. We consider signaling molecules that can be in different states which\ncan be switched by external stimuli. Hence, in media modulation based MC, for\ninformation transmission, the TX stimulates the signaling molecules to encode\ninformation into their state. In particular, we elaborate media modulation for\nthe group of photochromic molecules, which undergo light-induced reversible\ntransformations, and study the usage of these molecules for information\ntransmission in a three-dimensional duct system. We develop a statistical model\nfor the received signal which depends on the distribution of the signaling\nmolecules in the system, the reliability of the state control mechanism, and\nthe randomness of molecule propagation. Furthermore, we analyze the performance\nof media modulation based MC in terms of the bit error rate (BER). We show that\nmedia modulation enables reliable information transmission, which renders a TX\ninside the channel unnecessary.",
    "descriptor": "\nComments: 6 pages, 5 figures, 1 table, submitted to the 2022 IEEE International Conference on Communications (ICC) on October 29, 2021\n",
    "authors": [
      "Lukas Brand",
      "Moritz Garkisch",
      "Sebastian Lotter",
      "Maximilian Sch\u00e4fer",
      "Kathrin Castiglione",
      "Robert Schober"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.15744"
  },
  {
    "id": "arXiv:2110.15747",
    "title": "A Survey on Threat Situation Awareness Systems: Framework, Techniques,  and Insights",
    "abstract": "Cyberspace is full of uncertainty in terms of advanced and sophisticated\ncyber threats which are equipped with novel approaches to learn the system and\npropagate themselves, such as AI-powered threats. To debilitate these types of\nthreats, a modern and intelligent Cyber Situation Awareness (SA) system need to\nbe developed which has the ability of monitoring and capturing various types of\nthreats, analyzing and devising a plan to avoid further attacks. This paper\nprovides a comprehensive study on the current state-of-the-art in the cyber SA\nto discuss the following aspects of SA: key design principles, framework,\nclassifications, data collection, and analysis of the techniques, and\nevaluation methods. Lastly, we highlight misconceptions, insights and\nlimitations of this study and suggest some future work directions to address\nthe limitations.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Hooman Alavizadeh",
      "Julian Jang-Jaccard",
      "Simon Yusuf Enoch",
      "Harith Al-Sahaf",
      "Ian Welch",
      "Seyit A. Camtepe",
      "Dong Seong Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.15747"
  },
  {
    "id": "arXiv:2110.15749",
    "title": "A Riemannian Inexact Newton Dogleg Method for Constructing a Symmetric  Nonnegative Matrix with Prescribed Spectrum",
    "abstract": "This paper is concerned with the inverse problem of constructing a symmetric\nnonnegative matrix from realizable spectrum. We reformulate the inverse problem\nas an underdetermined nonlinear matrix equation over a Riemannian product\nmanifold. To solve it, we develop a Riemannian underdetermined inexact Newton\ndogleg method for solving a general underdetermined nonlinear equation defined\nbetween Riemannian manifolds and Euclidean spaces. The global and quadratic\nconvergence of the proposed method is established under some mild assumptions.\nThen we solve the inverse problem by applying the proposed method to its\nequivalent nonlinear matrix equation and a preconditioner for the perturbed\nnormal Riemannian Newton equation is also constructed. Numerical tests show the\nefficiency of the proposed method for solving the inverse problem.",
    "descriptor": "\nComments: 32 pages, 6 figures\n",
    "authors": [
      "Zhi Zhao",
      "Teng-Teng Yao",
      "Zheng-Jian Bai",
      "Xiao-Qing Jin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15749"
  },
  {
    "id": "arXiv:2110.15757",
    "title": "On Structural Parameterizations of the Offensive Alliance Problem",
    "abstract": "The Offensive Alliance problem has been studied extensively during the last\ntwenty years. A set $S\\subseteq V$ of vertices is an offensive alliance in an\nundirected graph $G=(V,E)$ if each $v\\in N(S)$ has at least as many neighbours\nin $S$ as it has neighbours (including itself) not in $S$. We study the\nparameterized complexity of the Offensive Alliance problem, where the aim is to\nfind a minimum size offensive alliance. Our focus here lies on parameters that\nmeasure the structural properties of the input instance. We enhance our\nunderstanding of the problem from the viewpoint of parameterized complexity by\nshowing that the problem is W[1]-hard parameterized by a wide range of fairly\nrestrictive structural parameters such as the feedback vertex set number,\ntreewidth, pathwidth, and treedepth of the input graph.",
    "descriptor": "",
    "authors": [
      "Ajinkya Gaikwad",
      "Soumen Maity"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.15757"
  },
  {
    "id": "arXiv:2110.15762",
    "title": "Mixed Cooperative-Competitive Communication Using Multi-Agent  Reinforcement Learning",
    "abstract": "By using communication between multiple agents in multi-agent environments,\none can reduce the effects of partial observability by combining one agent's\nobservation with that of others in the same dynamic environment. While a lot of\nsuccessful research has been done towards communication learning in cooperative\nsettings, communication learning in mixed cooperative-competitive settings is\nalso important and brings its own complexities such as the opposing team\noverhearing the communication. In this paper, we apply differentiable\ninter-agent learning (DIAL), designed for cooperative settings, to a mixed\ncooperative-competitive setting. We look at the difference in performance\nbetween communication that is private for a team and communication that can be\noverheard by the other team. Our research shows that communicating agents are\nable to achieve similar performance to fully observable agents after a given\ntraining period in our chosen environment. Overall, we find that sharing\ncommunication across teams results in decreased performance for the\ncommunicating team in comparison to results achieved with private\ncommunication.",
    "descriptor": "",
    "authors": [
      "Astrid Vanneste",
      "Wesley Van Wijnsberghe",
      "Simon Vanneste",
      "Kevin Mets",
      "Siegfried Mercelis",
      "Steven Latr\u00e9",
      "Peter Hellinckx"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.15762"
  },
  {
    "id": "arXiv:2110.15763",
    "title": "How to Leverage Multimodal EHR Data for Better Medical Predictions?",
    "abstract": "Healthcare is becoming a more and more important research topic recently.\nWith the growing data in the healthcare domain, it offers a great opportunity\nfor deep learning to improve the quality of medical service. However, the\ncomplexity of electronic health records (EHR) data is a challenge for the\napplication of deep learning. Specifically, the data produced in the hospital\nadmissions are monitored by the EHR system, which includes structured data like\ndaily body temperature, and unstructured data like free text and laboratory\nmeasurements. Although there are some preprocessing frameworks proposed for\nspecific EHR data, the clinical notes that contain significant clinical value\nare beyond the realm of their consideration. Besides, whether these different\ndata from various views are all beneficial to the medical tasks and how to best\nutilize these data remain unclear. Therefore, in this paper, we first extract\nthe accompanying clinical notes from EHR and propose a method to integrate\nthese data, we also comprehensively study the different models and the data\nleverage methods for better medical task prediction. The results on two medical\nprediction tasks show that our fused model with different data outperforms the\nstate-of-the-art method that without clinical notes, which illustrates the\nimportance of our fusion method and the value of clinical note features. Our\ncode is available at https: //github.com/emnlp-mimic/mimic.",
    "descriptor": "\nComments: Accepted by EMNLP 2021\n",
    "authors": [
      "Bo Yang",
      "Lijun Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15763"
  },
  {
    "id": "arXiv:2110.15764",
    "title": "\u03b5-weakened Robustness of Deep Neural Networks",
    "abstract": "This paper introduces a notation of $\\varepsilon$-weakened robustness for\nanalyzing the reliability and stability of deep neural networks (DNNs). Unlike\nthe conventional robustness, which focuses on the \"perfect\" safe region in the\nabsence of adversarial examples, $\\varepsilon$-weakened robustness focuses on\nthe region where the proportion of adversarial examples is bounded by\nuser-specified $\\varepsilon$. Smaller $\\varepsilon$ means a smaller chance of\nfailure. Under such robustness definition, we can give conclusive results for\nthe regions where conventional robustness ignores. We prove that the\n$\\varepsilon$-weakened robustness decision problem is PP-complete and give a\nstatistical decision algorithm with user-controllable error bound. Furthermore,\nwe derive an algorithm to find the maximum $\\varepsilon$-weakened robustness\nradius. The time complexity of our algorithms is polynomial in the dimension\nand size of the network. So, they are scalable to large real-world networks.\nBesides, We also show its potential application in analyzing quality issues.",
    "descriptor": "",
    "authors": [
      "Pei Huang",
      "Yuting Yang",
      "Minghao Liu",
      "Fuqi Jia",
      "Feifei Ma",
      "Jian Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15764"
  },
  {
    "id": "arXiv:2110.15766",
    "title": "NxMTransformer: Semi-Structured Sparsification for Natural Language  Understanding via ADMM",
    "abstract": "Natural Language Processing (NLP) has recently achieved success by using huge\npre-trained Transformer networks. However, these models often contain hundreds\nof millions or even billions of parameters, bringing challenges to online\ndeployment due to latency constraints. Recently, hardware manufacturers have\nintroduced dedicated hardware for NxM sparsity to provide the flexibility of\nunstructured pruning with the runtime efficiency of structured approaches. NxM\nsparsity permits arbitrarily selecting M parameters to retain from a contiguous\ngroup of N in the dense representation. However, due to the extremely high\ncomplexity of pre-trained models, the standard sparse fine-tuning techniques\noften fail to generalize well on downstream tasks, which have limited data\nresources. To address such an issue in a principled manner, we introduce a new\nlearning framework, called NxMTransformer, to induce NxM semi-structured\nsparsity on pretrained language models for natural language understanding to\nobtain better performance. In particular, we propose to formulate the NxM\nsparsity as a constrained optimization problem and use Alternating Direction\nMethod of Multipliers (ADMM) to optimize the downstream tasks while taking the\nunderlying hardware constraints into consideration. ADMM decomposes the NxM\nsparsification problem into two sub-problems that can be solved sequentially,\ngenerating sparsified Transformer networks that achieve high accuracy while\nbeing able to effectively execute on newly released hardware. We apply our\napproach to a wide range of NLP tasks, and our proposed method is able to\nachieve 1.7 points higher accuracy in GLUE score than current practices.\nMoreover, we perform detailed analysis on our approach and shed light on how\nADMM affects fine-tuning accuracy for downstream tasks. Finally, we illustrate\nhow NxMTransformer achieves performance improvement with knowledge\ndistillation.",
    "descriptor": "",
    "authors": [
      "Connor Holmes",
      "Minjia Zhang",
      "Yuxiong He",
      "Bo Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15766"
  },
  {
    "id": "arXiv:2110.15768",
    "title": "Intelligent Reflecting Surface-Aided Wideband THz Communications:  Modeling and Analysis",
    "abstract": "In this paper, we study the performance of wideband terahertz (THz)\ncommunications assisted by an intelligent reflecting surface (IRS).\nSpecifically, we first introduce a generalized channel model that is suitable\nfor electrically large THz IRSs operating in the near-field. Unlike prior\nworks, our channel model takes into account the spherical wavefront of the\nemitted electromagnetic waves and the spatial-wideband effect. We next show\nthat conventional frequency-flat beamfocusing significantly reduces the power\ngain due to beam squint, and hence is highly suboptimal. More importantly, we\nanalytically characterize this reduction when the spacing between adjacent\nreflecting elements is negligible, i.e., holographic reflecting surfaces.\nNumerical results corroborate our analysis and provide important insights into\nthe design of future IRS-aided THz systems.",
    "descriptor": "\nComments: To appear in the ITG Workshop on Smart Antennas (WSA), 2021\n",
    "authors": [
      "Konstantinos Dovelos",
      "Stylianos D. Assimonis",
      "Hien Quoc Ngo",
      "Boris Bellalta",
      "Michail Matthaiou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15768"
  },
  {
    "id": "arXiv:2110.15771",
    "title": "Collaborative Pure Exploration in Kernel Bandit",
    "abstract": "In this paper, we formulate a Collaborative Pure Exploration in Kernel Bandit\nproblem (CoPE-KB), which provides a novel model for multi-agent multi-task\ndecision making under limited communication and general reward functions, and\nis applicable to many online learning tasks, e.g., recommendation systems and\nnetwork scheduling. We consider two settings of CoPE-KB, i.e., Fixed-Confidence\n(FC) and Fixed-Budget (FB), and design two optimal algorithms CoopKernelFC (for\nFC) and CoopKernelFB (for FB). Our algorithms are equipped with innovative and\nefficient kernelized estimators to simultaneously achieve computation and\ncommunication efficiency. Matching upper and lower bounds under both the\nstatistical and communication metrics are established to demonstrate the\noptimality of our algorithms. The theoretical bounds successfully quantify the\ninfluences of task similarities on learning acceleration and only depend on the\neffective dimension of the kernelized feature space. Our analytical techniques,\nincluding data dimension decomposition, linear structured instance\ntransformation and (communication) round-speedup induction, are novel and\napplicable to other bandit problems. Empirical evaluations are provided to\nvalidate our theoretical results and demonstrate the performance superiority of\nour algorithms.",
    "descriptor": "",
    "authors": [
      "Yihan Du",
      "Wei Chen",
      "Yuko Yuroki",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15771"
  },
  {
    "id": "arXiv:2110.15772",
    "title": "Online Food Delivery to Minimize Maximum Flow Time",
    "abstract": "We study a common delivery problem encountered in nowadays online\nfood-ordering platforms: Customers order dishes online, and the restaurant\ndelivers the food after receiving the order. Specifically, we study a problem\nwhere $k$ vehicles of capacity $c$ are serving a set of requests ordering food\nfrom one restaurant. After a request arrives, it can be served by a vehicle\nmoving from the restaurant to its delivery location. We are interested in\nserving all requests while minimizing the maximum flow-time, i.e., the maximum\ntime length a customer waits to receive his/her food after submitting the\norder.\nWe show that the problem is hard in both offline and online settings: There\nis a hardness of approximation of $\\Omega(n)$ for the offline problem, and a\nlower bound of $\\Omega(n)$ on the competitive ratio of any online algorithm,\nwhere $n$ is number of points in the metric. Our main result is an\n$O(1)$-competitive online algorithm for the uncapaciated (i.e, $c = \\infty$)\nfood delivery problem on tree metrics. Then we consider the speed-augmentation\nmodel. We develop an exponential time $(1+\\epsilon)$-speeding\n$O(1/\\epsilon)$-competitive algorithm for any $\\epsilon > 0$. A polynomial time\nalgorithm can be obtained with a speeding factor of $\\alpha_{TSP}+ \\epsilon$ or\n$\\alpha_{CVRP}+ \\epsilon$, depending on whether the problem is uncapacitated.\nHere $\\alpha_{TSP}$ and $\\alpha_{CVRP}$ are the best approximation factors for\nthe traveling salesman (TSP) and capacitated vehicle routing (CVRP) problems\nrespectively. We complement the results with some negative ones.",
    "descriptor": "",
    "authors": [
      "Xiangyu Guo",
      "Shi Li",
      "Kelin Luo",
      "Yuhao Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15772"
  },
  {
    "id": "arXiv:2110.15777",
    "title": "GBK-GNN: Gated Bi-Kernel Graph Neural Networks for Modeling Both  Homophily and Heterophily",
    "abstract": "Graph Neural Networks (GNNs) are widely used on a variety of graph-based\nmachine learning tasks. For node-level tasks, GNNs have strong power to model\nthe homophily property of graphs (i.e., connected nodes are more similar) while\ntheir ability to capture heterophily property is often doubtful. This is\npartially caused by the design of the feature transformation with the same\nkernel for the nodes in the same hop and the followed aggregation operator. One\nkernel cannot model the similarity and the dissimilarity (i.e., the positive\nand negative correlation) between node features simultaneously even though we\nuse attention mechanisms like Graph Attention Network (GAT), since the weight\ncalculated by attention is always a positive value. In this paper, we propose a\nnovel GNN model based on a bi-kernel feature transformation and a selection\ngate. Two kernels capture homophily and heterophily information respectively,\nand the gate is introduced to select which kernel we should use for the given\nnode pairs. We conduct extensive experiments on various datasets with different\nhomophily-heterophily properties. The experimental results show consistent and\nsignificant improvements against state-of-the-art GNN methods.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Lun Du",
      "Xiaozhou Shi",
      "Qiang Fu",
      "Hengyu Liu",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15777"
  },
  {
    "id": "arXiv:2110.15778",
    "title": "Comparing Machine Learning-Centered Approaches for Forecasting Language  Patterns During Frustration in Early Childhood",
    "abstract": "When faced with self-regulation challenges, children have been known the use\ntheir language to inhibit their emotions and behaviors. Yet, to date, there has\nbeen a critical lack of evidence regarding what patterns in their speech\nchildren use during these moments of frustration. In this paper, eXtreme\nGradient Boosting, Random Forest, Long Short-Term Memory Recurrent Neural\nNetworks, and Elastic Net Regression, have all been used to forecast these\nlanguage patterns in children. Based on the results of a comparative analysis\nbetween these methods, the study reveals that when dealing with\nhigh-dimensional and dense data, with very irregular and abnormal\ndistributions, as is the case with self-regulation patterns in children,\ndecision tree-based algorithms are able to outperform traditional regression\nand neural network methods in their shortcomings.",
    "descriptor": "\nComments: 9 pages, 6 figures, UNDER REVIEW, UNPUBLISHED\n",
    "authors": [
      "Arnav Bhakta",
      "Yeunjoo Kim",
      "Pamela Cole"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15778"
  },
  {
    "id": "arXiv:2110.15779",
    "title": "Learning to Communicate with Reinforcement Learning for an Adaptive  Traffic Control System",
    "abstract": "Recent work in multi-agent reinforcement learning has investigated inter\nagent communication which is learned simultaneously with the action policy in\norder to improve the team reward. In this paper, we investigate independent\nQ-learning (IQL) without communication and differentiable inter-agent learning\n(DIAL) with learned communication on an adaptive traffic control system (ATCS).\nIn real world ATCS, it is impossible to present the full state of the\nenvironment to every agent so in our simulation, the individual agents will\nonly have a limited observation of the full state of the environment. The ATCS\nwill be simulated using the Simulation of Urban MObility (SUMO) traffic\nsimulator in which two connected intersections are simulated. Every\nintersection is controlled by an agent which has the ability to change the\ndirection of the traffic flow. Our results show that a DIAL agent outperforms\nan independent Q-learner on both training time and on maximum achieved reward\nas it is able to share relevant information with the other agents.",
    "descriptor": "",
    "authors": [
      "Simon Vanneste",
      "Gauthier de Borrekens",
      "Stig Bosmans",
      "Astrid Vanneste",
      "Kevin Mets",
      "Siegfried Mercelis",
      "Steven Latr\u00e9",
      "Peter Hellinckx"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.15779"
  },
  {
    "id": "arXiv:2110.15781",
    "title": "Two-sided fairness in rankings via Lorenz dominance",
    "abstract": "We consider the problem of generating rankings that are fair towards both\nusers and item producers in recommender systems. We address both usual\nrecommendation (e.g., of music or movies) and reciprocal recommendation (e.g.,\ndating). Following concepts of distributive justice in welfare economics, our\nnotion of fairness aims at increasing the utility of the worse-off individuals,\nwhich we formalize using the criterion of Lorenz efficiency. It guarantees that\nrankings are Pareto efficient, and that they maximally redistribute utility\nfrom better-off to worse-off, at a given level of overall utility. We propose\nto generate rankings by maximizing concave welfare functions, and develop an\nefficient inference procedure based on the Frank-Wolfe algorithm. We prove that\nunlike existing approaches based on fairness constraints, our approach always\nproduces fair rankings. Our experiments also show that it increases the utility\nof the worse-off at lower costs in terms of overall utility.",
    "descriptor": "",
    "authors": [
      "Virginie Do",
      "Sam Corbett-Davies",
      "Jamal Atif",
      "Nicolas Usunier"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15781"
  },
  {
    "id": "arXiv:2110.15783",
    "title": "Some Remarks on Bayesian Multiple Hypothesis Testing",
    "abstract": "We consider Bayesian multiple hypothesis problem with independent and\nidentically distributed observations. The classical, Sanov's theorem-based,\nanalysis of the error probability allows one to characterize the best\nachievable error exponent. However, this analysis does not generalize to the\ncase where the true distributions of the hypothesis are not exact or partially\nknown via some nominal distributions. This problem has practical significance,\nbecause the nominal distributions may be quantized versions of the true\ndistributions in a hardware implementation, or they may be estimates of the\ntrue distributions obtained from labeled training sequences as in statistical\nclassification. In this paper, we develop a type-based analysis to investigate\nBayesian multiple hypothesis testing problem. Our analysis allows one to\nexplicitly calculate the error exponent of a given type and extends the\nclassical analysis. As a generalization of the proposed method, we derive a\nrobust test and obtain its error exponent for the case where the hypothesis\ndistributions are not known but there exist nominal distribution that are close\nto true distributions in variational distance.",
    "descriptor": "\nComments: Accepted for publication in Hacettepe Journal of Mathematics and Statistics\n",
    "authors": [
      "H\u00fcseyin Af\u015fer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.15783"
  },
  {
    "id": "arXiv:2110.15784",
    "title": "Convergence of Uncertainty Sampling for Active Learning",
    "abstract": "Uncertainty sampling in active learning is heavily used in practice to reduce\nthe annotation cost. However, there has been no wide consensus on the function\nto be used for uncertainty estimation in binary classification tasks and\nconvergence guarantees of the corresponding active learning algorithms are not\nwell understood. The situation is even more challenging for multi-category\nclassification. In this work, we propose an efficient uncertainty estimator for\nbinary classification which we also extend to multiple classes, and provide a\nnon-asymptotic rate of convergence for our uncertainty sampling-based active\nlearning algorithm in both cases under no-noise conditions (i.e., linearly\nseparable data). We also extend our analysis to the noisy case and provide\ntheoretical guarantees for our algorithm under the influence of noise in the\ntask of binary and multi-class classification.",
    "descriptor": "",
    "authors": [
      "Anant Raj",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.15784"
  },
  {
    "id": "arXiv:2110.15788",
    "title": "Towards Intelligent Load Balancing in Data Centers",
    "abstract": "Network load balancers are important components in data centers to provide\nscalable services. Workload distribution algorithms are based on heuristics,\ne.g., Equal-Cost Multi-Path (ECMP), Weighted-Cost Multi-Path (WCMP) or naive\nmachine learning (ML) algorithms, e.g., ridge regression. Advanced ML-based\napproaches help achieve performance gain in different networking and system\nproblems. However, it is challenging to apply ML algorithms on networking\nproblems in real-life systems. It requires domain knowledge to collect features\nfrom low-latency, high-throughput, and scalable networking systems, which are\ndynamic and heterogenous. This paper proposes Aquarius to bridge the gap\nbetween ML and networking systems and demonstrates its usage in the context of\nnetwork load balancers. This paper demonstrates its ability of conducting both\noffline data analysis and online model deployment in realistic systems. The\nresults show that the ML model trained and deployed using Aquarius improves\nload balancing performance yet they also reveals more challenges to be resolved\nto apply ML for networking systems.",
    "descriptor": "",
    "authors": [
      "Zhiyuan Yao",
      "Yoann Desmouceaux",
      "Mark Townsley",
      "Thomas Heide Clausen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.15788"
  },
  {
    "id": "arXiv:2110.15789",
    "title": "On the Feasibility of Predicting Questions being Forgotten in Stack  Overflow",
    "abstract": "For their attractiveness, comprehensiveness and dynamic coverage of relevant\ntopics, community-based question answering sites such as Stack Overflow heavily\nrely on the engagement of their communities: Questions on new technologies,\ntechnology features as well as technology versions come up and have to be\nanswered as technology evolves (and as community members gather experience with\nit). At the same time, other questions cease in importance over time, finally\nbecoming irrelevant to users. Beyond filtering low-quality questions,\n\"forgetting\" questions, which have become redundant, is an important step for\nkeeping the Stack Overflow content concise and useful. In this work, we study\nthis managed forgetting task for Stack Overflow. Our work is based on data from\nmore than a decade (2008 - 2019) - covering 18.1M questions, that are made\npublicly available by the site itself. For establishing a deeper understanding,\nwe first analyze and characterize the set of questions about to be forgotten,\ni.e., questions that get a considerable number of views in the current period\nbut become unattractive in the near future. Subsequently, we examine the\ncapability of a wide range of features in predicting such forgotten questions\nin different categories. We find some categories in which those questions are\nmore predictable. We also discover that the text-based features are\nsurprisingly not helpful in this prediction task, while the meta information is\nmuch more predictive.",
    "descriptor": "",
    "authors": [
      "Thi Huyen Nguyen",
      "Tu Nguyen",
      "Tuan-Anh Hoang",
      "Claudia Nieder\u00e9e"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15789"
  },
  {
    "id": "arXiv:2110.15790",
    "title": "LSTM-RPA: A Simple but Effective Long Sequence Prediction Algorithm for  Music Popularity Prediction",
    "abstract": "The big data about music history contains information about time and users'\nbehavior. Researchers could predict the trend of popular songs accurately by\nanalyzing this data. The traditional trend prediction models can better predict\nthe short trend than the long trend. In this paper, we proposed the improved\nLSTM Rolling Prediction Algorithm (LSTM-RPA), which combines LSTM historical\ninput with current prediction results as model input for next time prediction.\nMeanwhile, this algorithm converts the long trend prediction task into multiple\nshort trend prediction tasks. The evaluation results show that the LSTM-RPA\nmodel increased F score by 13.03%, 16.74%, 11.91%, 18.52%, compared with LSTM,\nBiLSTM, GRU and RNN. And our method outperforms tradi-tional sequence models,\nwhich are ARIMA and SMA, by 10.67% and 3.43% improvement in F score.Code:\nhttps://github.com/maliaosaide/lstm-rpa",
    "descriptor": "",
    "authors": [
      "Kun Li",
      "Meng Li",
      "Yanling Li",
      "Min Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Social and Information Networks (cs.SI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15790"
  },
  {
    "id": "arXiv:2110.15792",
    "title": "VRAIN-UPV MLLP's system for the Blizzard Challenge 2021",
    "abstract": "This paper presents the VRAIN-UPV MLLP's speech synthesis system for the SH1\ntask of the Blizzard Challenge 2021. The SH1 task consisted in building a\nSpanish text-to-speech system trained on (but not limited to) the corpus\nreleased by the Blizzard Challenge 2021 organization. It included 5 hours of\nstudio-quality recordings from a native Spanish female speaker. In our case,\nthis dataset was solely used to build a two-stage neural text-to-speech\npipeline composed of a non-autoregressive acoustic model with explicit duration\nmodeling and a HiFi-GAN neural vocoder. Our team is identified as J in the\nevaluation results. Our system obtained very good results in the subjective\nevaluation tests. Only one system among other 11 participants achieved better\nnaturalness than ours. Concretely, it achieved a naturalness MOS of 3.61\ncompared to 4.21 for real samples.",
    "descriptor": "",
    "authors": [
      "Alejandro P\u00e9rez-Gonz\u00e1lez-de-Martos",
      "Albert Sanchis",
      "Alfons Juan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15792"
  },
  {
    "id": "arXiv:2110.15794",
    "title": "CLAUSEREC: A Clause Recommendation Framework for AI-aided Contract  Authoring",
    "abstract": "Contracts are a common type of legal document that frequent in several\nday-to-day business workflows. However, there has been very limited NLP\nresearch in processing such documents, and even lesser in generating them.\nThese contracts are made up of clauses, and the unique nature of these clauses\ncalls for specific methods to understand and generate such documents. In this\npaper, we introduce the task of clause recommendation, asa first step to aid\nand accelerate the author-ing of contract documents. We propose a two-staged\npipeline to first predict if a specific clause type is relevant to be added in\na contract, and then recommend the top clauses for the given type based on the\ncontract context. We pretrain BERT on an existing library of clauses with two\nadditional tasks and use it for our prediction and recommendation. We\nexperiment with classification methods and similarity-based heuristics for\nclause relevance prediction, and generation-based methods for clause\nrecommendation, and evaluate the results from various methods on several clause\ntypes. We provide analyses on the results, and further outline the advantages\nand limitations of the various methods for this line of research.",
    "descriptor": "",
    "authors": [
      "Vinay Aggarwal",
      "Aparna Garimella",
      "Balaji Vasan Srinivasan",
      "Anandhavelu N",
      "Rajiv Jain"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15794"
  },
  {
    "id": "arXiv:2110.15796",
    "title": "Properties from Mechanisms: An Equivariance Perspective on Identifiable  Representation Learning",
    "abstract": "A key goal of unsupervised representation learning is \"inverting\" a data\ngenerating process to recover its latent properties. Existing work that\nprovably achieves this goal relies on strong assumptions on relationships\nbetween the latent variables (e.g., independence conditional on auxiliary\ninformation). In this paper, we take a very different perspective on the\nproblem and ask, \"Can we instead identify latent properties by leveraging\nknowledge of the mechanisms that govern their evolution?\" We provide a complete\ncharacterization of the sources of non-identifiability as we vary knowledge\nabout a set of possible mechanisms. In particular, we prove that if we know the\nexact mechanisms under which the latent properties evolve, then identification\ncan be achieved up to any equivariances that are shared by the underlying\nmechanisms. We generalize this characterization to settings where we only know\nsome hypothesis class over possible mechanisms, as well as settings where the\nmechanisms are stochastic. We demonstrate the power of this mechanism-based\nperspective by showing that we can leverage our results to generalize existing\nidentifiable representation learning results. These results suggest that by\nexploiting inductive biases on mechanisms, it is possible to design a range of\nnew identifiable representation learning approaches.",
    "descriptor": "",
    "authors": [
      "Kartik Ahuja",
      "Jason Hartford",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15796"
  },
  {
    "id": "arXiv:2110.15797",
    "title": "Discovering Non-monotonic Autoregressive Orderings with Variational  Inference",
    "abstract": "The predominant approach for language modeling is to process sequences from\nleft to right, but this eliminates a source of information: the order by which\nthe sequence was generated. One strategy to recover this information is to\ndecode both the content and ordering of tokens. Existing approaches supervise\ncontent and ordering by designing problem-specific loss functions and\npre-training with an ordering pre-selected. Other recent works use iterative\nsearch to discover problem-specific orderings for training, but suffer from\nhigh time complexity and cannot be efficiently parallelized. We address these\nlimitations with an unsupervised parallelizable learner that discovers\nhigh-quality generation orders purely from training data -- no domain knowledge\nrequired. The learner contains an encoder network and decoder language model\nthat perform variational inference with autoregressive orders (represented as\npermutation matrices) as latent variables. The corresponding ELBO is not\ndifferentiable, so we develop a practical algorithm for end-to-end optimization\nusing policy gradients. We implement the encoder as a Transformer with\nnon-causal attention that outputs permutations in one forward pass.\nPermutations then serve as target generation orders for training an\ninsertion-based Transformer language model. Empirical results in language\nmodeling tasks demonstrate that our method is context-aware and discovers\norderings that are competitive with or even better than fixed orders.",
    "descriptor": "\nComments: updated from ICLR 2021, first two authors contributed equally\n",
    "authors": [
      "Xuanlin Li",
      "Brandon Trabucco",
      "Dong Huk Park",
      "Michael Luo",
      "Sheng Shen",
      "Trevor Darrell",
      "Yang Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15797"
  },
  {
    "id": "arXiv:2110.15799",
    "title": "Guided Policy Search for Parameterized Skills using Adverbs",
    "abstract": "We present a method for using adverb phrases to adjust skill parameters via\nlearned adverb-skill groundings. These groundings allow an agent to use adverb\nfeedback provided by a human to directly update a skill policy, in a manner\nsimilar to traditional local policy search methods. We show that our method can\nbe used as a drop-in replacement for these policy search methods when dense\nreward from the environment is not available but human language feedback is. We\ndemonstrate improved sample efficiency over modern policy search methods in two\nexperiments.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Benjamin A. Spiegel",
      "George Konidaris"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.15799"
  },
  {
    "id": "arXiv:2110.15801",
    "title": "Application of the Multi-label Residual Convolutional Neural Network  text classifier using Content-Based Routing process",
    "abstract": "In this article, we will present an NLP application in text classifying\nprocess using the content-based router. The ultimate goal throughout this\narticle is to predict the event described by a legal ad from the plain text of\nthe ad. This problem is purely a supervised problem that will involve the use\nof NLP techniques and conventional modeling methodologies through the use of\nthe Multi-label Residual Convolutional Neural Network for text classification.\nWe will explain the approach put in place to solve the problem of classified\nads, the difficulties encountered and the experimental results.",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Tounsi Achraf",
      "Elkefi Safa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15801"
  },
  {
    "id": "arXiv:2110.15802",
    "title": "BERMo: What can BERT learn from ELMo?",
    "abstract": "We propose BERMo, an architectural modification to BERT, which makes\npredictions based on a hierarchy of surface, syntactic and semantic language\nfeatures. We use linear combination scheme proposed in Embeddings from Language\nModels (ELMo) to combine the scaled internal representations from different\nnetwork depths. Our approach has two-fold benefits: (1) improved gradient flow\nfor the downstream task as every layer has a direct connection to the gradients\nof the loss function and (2) increased representative power as the model no\nlonger needs to copy the features learned in the shallower layer which are\nnecessary for the downstream task. Further, our model has a negligible\nparameter overhead as there is a single scalar parameter associated with each\nlayer in the network. Experiments on the probing task from SentEval dataset\nshow that our model performs up to $4.65\\%$ better in accuracy than the\nbaseline with an average improvement of $2.67\\%$ on the semantic tasks. When\nsubject to compression techniques, we find that our model enables stable\npruning for compressing small datasets like SST-2, where the BERT model\ncommonly diverges. We observe that our approach converges $1.67\\times$ and\n$1.15\\times$ faster than the baseline on MNLI and QQP tasks from GLUE dataset.\nMoreover, our results show that our approach can obtain better parameter\nefficiency for penalty based pruning approaches on QQP task.",
    "descriptor": "",
    "authors": [
      "Sangamesh Kodge",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15802"
  },
  {
    "id": "arXiv:2110.15803",
    "title": "Natural Language Processing for Smart Healthcare",
    "abstract": "Smart healthcare has achieved significant progress in recent years. Emerging\nartificial intelligence (AI) technologies enable various smart applications\nacross various healthcare scenarios. As an essential technology powered by AI,\nnatural language processing (NLP) plays a key role in smart healthcare due to\nits capability of analysing and understanding human language. In this work we\nreview existing studies that concern NLP for smart healthcare from the\nperspectives of technique and application. We focus on feature extraction and\nmodelling for various NLP tasks encountered in smart healthcare from a\ntechnical point of view. In the context of smart healthcare applications\nemploying NLP techniques, the elaboration largely attends to representative\nsmart healthcare scenarios, including clinical practice, hospital management,\npersonal care, public health, and drug development. We further discuss the\nlimitations of current works and identify the directions for future works.",
    "descriptor": "",
    "authors": [
      "Binggui Zhou",
      "Guanghua Yang",
      "Zheng Shi",
      "Shaodan Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15803"
  },
  {
    "id": "arXiv:2110.15804",
    "title": "Doubt and Redundancy Kill Soft Errors -- Towards Detection and  Correction of Silent Data Corruption in Task-based Numerical Software",
    "abstract": "Resilient algorithms in high-performance computing are subject to rigorous\nnon-functional constraints. Resiliency must not increase the runtime, memory\nfootprint or I/O demands too significantly. We propose a task-based soft error\ndetection scheme that relies on error criteria per task outcome. They formalise\nhow ``dubious'' an outcome is, i.e. how likely it contains an error. Our whole\nsimulation is replicated once, forming two teams of MPI ranks that share their\ntask results. Thus, ideally each team handles only around half of the workload.\nIf a task yields large error criteria values, i.e.~is dubious, we compute the\ntask redundantly and compare the outcomes. Whenever they disagree, the task\nresult with a lower error likeliness is accepted. We obtain a self-healing,\nresilient algorithm which can compensate silent floating-point errors without a\nsignificant performance, I/O or memory footprint penalty. Case studies however\nsuggest that a careful, domain-specific tailoring of the error criteria remains\nessential.",
    "descriptor": "",
    "authors": [
      "Philipp Samfass",
      "Tobias Weinzierl",
      "Anne Reinarz",
      "Michael Bader"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Hardware Architecture (cs.AR)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2110.15804"
  },
  {
    "id": "arXiv:2110.15809",
    "title": "Better Lower Bounds for Shortcut Sets and Additive Spanners via an  Improved Alternation Product",
    "abstract": "We obtain improved lower bounds for additive spanners, additive emulators,\nand diameter-reducing shortcut sets. Spanners and emulators are sparse graphs\nthat approximately preserve the distances of a given graph. A shortcut set is a\nset of edges that when added to a directed graph, decreases its diameter. The\nprevious best known lower bounds for these three structures are given by Huang\nand Pettie [SWAT 2018]. For $O(n)$-sized spanners, we improve the lower bound\non the additive stretch from $\\Omega(n^{1/11})$ to $\\Omega(n^{2/21})$. For\n$O(n)$-sized emulators, we improve the lower bound on the additive stretch from\n$\\Omega(n^{1/18})$ to $\\Omega(n^{2/29})$. For $O(m)$-sized shortcut sets, we\nimprove the lower bound on the graph diameter from $\\Omega(n^{1/11})$ to\n$\\Omega(n^{1/8})$. Our key technical contribution, which is the basis of all of\nour bounds, is an improvement of a graph product known as an alternation\nproduct.",
    "descriptor": "\nComments: To appear in SODA 2022\n",
    "authors": [
      "Kevin Lu",
      "Virginia Vassilevska Williams",
      "Nicole Wein",
      "Zixuan Xu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15809"
  },
  {
    "id": "arXiv:2110.15814",
    "title": "A GIS Data Realistic Road Generation Approach for Traffic Simulation",
    "abstract": "Road networks exist in the form of polylines with attributes within the GIS\ndatabases. Such a representation renders the geographic data impracticable for\n3D road traffic simulation. In this work, we propose a method to transform raw\nGIS data into a realistic, operational model for real-time road traffic\nsimulation. For instance, the proposed raw to simulation ready data\ntransformation is achieved through several curvature estimation,\ninterpolation/approximation, and clustering schemes. The obtained results show\nthe performance of our approach and prove its adequacy to real traffic\nsimulation scenario as can be seen in this video 1 .",
    "descriptor": "\nComments: Accepted in Federated Conference on Computer Science and Information Systems (FedCSIS)\n",
    "authors": [
      "Yacine Amara",
      "Abdenour Amamra",
      "Yasmine Daheur",
      "Lamia Saichi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.15814"
  },
  {
    "id": "arXiv:2110.15815",
    "title": "Real-time multiview data fusion for object tracking with RGBD sensors",
    "abstract": "This paper presents a new approach to accurately track a moving vehicle with\na multiview setup of red-green-blue depth (RGBD) cameras. We first propose a\ncorrection method to eliminate a shift, which occurs in depth sensors when they\nbecome worn. This issue could not be otherwise corrected with the ordinary\ncalibration procedure. Next, we present a sensor-wise filtering system to\ncorrect for an unknown vehicle motion. A data fusion algorithm is then used to\noptimally merge the sensor-wise estimated trajectories. We implement most parts\nof our solution in the graphic processor. Hence, the whole system is able to\noperate at up to 25 frames per second with a configuration of five cameras.\nTest results show the accuracy we achieved and the robustness of our solution\nto overcome uncertainties in the measurements and the modelling.",
    "descriptor": "\nComments: Accepted in Robotica\n",
    "authors": [
      "Abdenour Amamra",
      "Nabil Aouf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.15815"
  },
  {
    "id": "arXiv:2110.15824",
    "title": "Tractability from overparametrization: The example of the negative  perceptron",
    "abstract": "In the negative perceptron problem we are given $n$ data points\n$({\\boldsymbol x}_i,y_i)$, where ${\\boldsymbol x}_i$ is a $d$-dimensional\nvector and $y_i\\in\\{+1,-1\\}$ is a binary label. The data are not linearly\nseparable and hence we content ourselves to find a linear classifier with the\nlargest possible \\emph{negative} margin. In other words, we want to find a unit\nnorm vector ${\\boldsymbol \\theta}$ that maximizes $\\min_{i\\le n}y_i\\langle\n{\\boldsymbol \\theta},{\\boldsymbol x}_i\\rangle$. This is a non-convex\noptimization problem (it is equivalent to finding a maximum norm vector in a\npolytope), and we study its typical properties under two random models for the\ndata.\nWe consider the proportional asymptotics in which $n,d\\to \\infty$ with\n$n/d\\to\\delta$, and prove upper and lower bounds on the maximum margin\n$\\kappa_{\\text{s}}(\\delta)$ or -- equivalently -- on its inverse function\n$\\delta_{\\text{s}}(\\kappa)$. In other words, $\\delta_{\\text{s}}(\\kappa)$ is the\noverparametrization threshold: for $n/d\\le\n\\delta_{\\text{s}}(\\kappa)-\\varepsilon$ a classifier achieving vanishing\ntraining error exists with high probability, while for $n/d\\ge\n\\delta_{\\text{s}}(\\kappa)+\\varepsilon$ it does not. Our bounds on\n$\\delta_{\\text{s}}(\\kappa)$ match to the leading order as $\\kappa\\to -\\infty$.\nWe then analyze a linear programming algorithm to find a solution, and\ncharacterize the corresponding threshold $\\delta_{\\text{lin}}(\\kappa)$. We\nobserve a gap between the interpolation threshold $\\delta_{\\text{s}}(\\kappa)$\nand the linear programming threshold $\\delta_{\\text{lin}}(\\kappa)$, raising the\nquestion of the behavior of other algorithms.",
    "descriptor": "\nComments: 88 pages; 7 pdf figures\n",
    "authors": [
      "Andrea Montanari",
      "Yiqiao Zhong",
      "Kangjie Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.15824"
  },
  {
    "id": "arXiv:2110.15829",
    "title": "Holistic Deep Learning",
    "abstract": "There is much interest in deep learning to solve challenges that arise in\napplying neural network models in real-world environments. In particular, three\nareas have received considerable attention: adversarial robustness, parameter\nsparsity, and output stability. Despite numerous attempts on solving these\nproblems independently, there is very little work addressing the challenges\nsimultaneously. In this paper, we address this problem of constructing holistic\ndeep learning models by proposing a novel formulation that solves these issues\nin combination. Real-world experiments on both tabular and MNIST dataset show\nthat our formulation is able to simultaneously improve the accuracy,\nrobustness, stability, and sparsity over traditional deep learning models among\nmany others.",
    "descriptor": "\nComments: Under review at JMLR\n",
    "authors": [
      "Dimitris Bertsimas",
      "L\u00e9onard Boussioux",
      "Kimberly Villalobos Carballo",
      "Michael Lingzhi Li",
      "Alex Paskov",
      "Ivan Paskov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15829"
  },
  {
    "id": "arXiv:2110.15830",
    "title": "Characterising Linear Spatio-Temporal Dynamical Systems in the Frequency  Domain",
    "abstract": "A new concept, called the spatio-temporal transfer function (STTF), is\nintroduced to characterise a class of linear time-invariant (LTI)\nspatio-temporal dynamical systems. The spatio-temporal transfer function is a\nnatural extension of the ordinary transfer function for classical linear\ntime-invariant control systems. As in the case of the classical transfer\nfunction, the spatio-temporal transfer function can be used to characterise, in\nthe frequency domain, the inherent dynamics of linear time-invariant\nspatio-temporal systems. The introduction of the spatio-temporal transfer\nfunction should also facilitate the analysis of the dynamical stability of\ndiscrete-time spatio-temporal systems.",
    "descriptor": "\nComments: 11 pages, 1 figure\n",
    "authors": [
      "Hua-Liang Wei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Pattern Formation and Solitons (nlin.PS)"
    ],
    "url": "https://arxiv.org/abs/2110.15830"
  },
  {
    "id": "arXiv:2110.15832",
    "title": "CAN-PINN: A Fast Physics-Informed Neural Network Based on  Coupled-Automatic-Numerical Differentiation Method",
    "abstract": "In this study, novel physics-informed neural network (PINN) methods for\ncoupling neighboring support points and automatic differentiation (AD) through\nTaylor series expansion are proposed to allow efficient training with improved\naccuracy. The computation of differential operators required for PINNs loss\nevaluation at collocation points are conventionally obtained via AD. Although\nAD has the advantage of being able to compute the exact gradients at any point,\nsuch PINNs can only achieve high accuracies with large numbers of collocation\npoints, otherwise they are prone to optimizing towards unphysical solution. To\nmake PINN training fast, the dual ideas of using numerical differentiation\n(ND)-inspired method and coupling it with AD are employed to define the loss\nfunction. The ND-based formulation for training loss can strongly link\nneighboring collocation points to enable efficient training in sparse sample\nregimes, but its accuracy is restricted by the interpolation scheme. The\nproposed coupled-automatic-numerical differentiation framework, labeled as\ncan-PINN, unifies the advantages of AD and ND, providing more robust and\nefficient training than AD-based PINNs, while further improving accuracy by up\nto 1-2 orders of magnitude relative to ND-based PINNs. For a proof-of-concept\ndemonstration of this can-scheme to fluid dynamic problems, two\nnumerical-inspired instantiations of can-PINN schemes for the convection and\npressure gradient terms were derived to solve the incompressible Navier-Stokes\n(N-S) equations. The superior performance of can-PINNs is demonstrated on\nseveral challenging problems, including the flow mixing phenomena, lid driven\nflow in a cavity, and channel flow over a backward facing step. The results\nreveal that for challenging problems like these, can-PINNs can consistently\nachieve very good accuracy whereas conventional AD-based PINNs fail.",
    "descriptor": "\nComments: 24 pages, 18 figures\n",
    "authors": [
      "Pao-Hsiung Chiu",
      "Jian Cheng Wong",
      "Chinchun Ooi",
      "My Ha Dao",
      "Yew-Soon Ong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2110.15832"
  },
  {
    "id": "arXiv:2110.15836",
    "title": "Combining Unsupervised and Text Augmented Semi-Supervised Learning for  Low Resourced Autoregressive Speech Recognition",
    "abstract": "Recent advances in unsupervised representation learning have demonstrated the\nimpact of pretraining on large amounts of read speech. We adapt these\ntechniques for domain adaptation in low-resource -- both in terms of data and\ncompute -- conversational and broadcast domains. Moving beyond CTC, we pretrain\nstate-of-the-art Conformer models in an unsupervised manner. While the\nunsupervised approach outperforms traditional semi-supervised training, the\ntechniques are complementary. Combining the techniques is a 5% absolute\nimprovement in WER, averaged over all conditions, compared to semi-supervised\ntraining alone. Additional text data is incorporated through external language\nmodels. By using CTC-based decoding, we are better able to take advantage of\nthe additional text data. When used as a transcription model, it allows the\nConformer model to better incorporate the knowledge from the language model\nthrough semi-supervised training than shallow fusion. Final performance is an\nadditional 2% better absolute when using CTC-based decoding for semi-supervised\ntraining compared to shallow fusion.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Chak-Fai Li",
      "Francis Keith",
      "William Hartmann",
      "Matthew Snover"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15836"
  },
  {
    "id": "arXiv:2110.15860",
    "title": "Tree-Cotree Decomposition of Isogeometric Mortared Spaces in H(curl) on  Multi-Patch Domains",
    "abstract": "When applying isogeometric analysis to engineering problems, one often deals\nwith multi-patch spline spaces that have incompatible discretisations, e.g. in\nthe case of moving objects. In such cases mortaring has been shown to be\nadvantageous. This contribution discusses the appropriate B-spline spaces\nneeded for the solution of Maxwell's equations in the functions space H(curl)\nand the corresponding mortar spaces. The main contribution of this paper is to\nshow that in formulations requiring gauging, as in the vector potential\nformulation of magnetostatic equations, one can remove the discrete kernel\nsubspace from the mortared spaces by the graph-theoretical concept of a\ntree-cotree decomposition. The tree-cotree decomposition is done based on the\ncontrol mesh, it works for non-contractible domains, and it can be\nstraightforwardly applied independently of the degree of the B-spline bases.\nFinally, the simulation workflow is demonstrated using a realistic model of a\nrotating permanent magnet synchronous machine.",
    "descriptor": "",
    "authors": [
      "Bernard Kapidani",
      "Melina Merkel",
      "Sebastian Sch\u00f6ps",
      "Rafael V\u00e1zquez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.15860"
  },
  {
    "id": "arXiv:2110.15866",
    "title": "Towards Comparative Physical Interpretation of Spatial Variability Aware  Neural Networks: A Summary of Results",
    "abstract": "Given Spatial Variability Aware Neural Networks (SVANNs), the goal is to\ninvestigate mathematical (or computational) models for comparative physical\ninterpretation towards their transparency (e.g., simulatibility,\ndecomposability and algorithmic transparency). This problem is important due to\nimportant use-cases such as reusability, debugging, and explainability to a\njury in a court of law. Challenges include a large number of model parameters,\nvacuous bounds on generalization performance of neural networks, risk of\noverfitting, sensitivity to noise, etc., which all detract from the ability to\ninterpret the models. Related work on either model-specific or model-agnostic\npost-hoc interpretation is limited due to a lack of consideration of physical\nconstraints (e.g., mass balance) and properties (e.g., second law of\ngeography). This work investigates physical interpretation of SVANNs using\nnovel comparative approaches based on geographically heterogeneous features.\nThe proposed approach on feature-based physical interpretation is evaluated\nusing a case-study on wetland mapping. The proposed physical interpretation\nimproves the transparency of SVANN models and the analytical results highlight\nthe trade-off between model transparency and model performance (e.g.,\nF1-score). We also describe an interpretation based on geographically\nheterogeneous processes modeled as partial differential equations (PDEs).",
    "descriptor": "\nComments: Submission to SIGSPATIAL 2021 peer review process. The document contains 12 pages (including 2 pages of appendix)\n",
    "authors": [
      "Jayant Gupta",
      "Carl Molnar",
      "Gaoxiang Luo",
      "Joe Knight",
      "Shashi Shekhar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15866"
  },
  {
    "id": "arXiv:2110.15869",
    "title": "Trustworthy Pre-Processing of Sensor Data in Data On-chaining Workflows  for Blockchain-based IoT Applications",
    "abstract": "Prior to provisioning sensor data to smart contracts, a pre-processing of the\ndata on intermediate off-chain nodes is often necessary. When doing so,\noriginally constructed cryptographic signatures cannot be verified on-chain\nanymore. This exposes an opportunity for undetected manipulation and presents a\nproblem for applications in the Internet of Things where trustworthy sensor\ndata is required on-chain. In this paper, we propose trustworthy pre-processing\nas enabler for end-to-end sensor data integrity in data on-chaining workflows.\nWe define requirements for trustworthy pre-processing, present a model and\ncommon workflow for data on-chaining, select off-chain computation utilizing\nZero-knowledge Proofs (ZKPs) and Trusted Execution Environments (TEEs) as\npromising solution approaches, and discuss both our proof-of-concept\nimplementations and initial experimental, comparative evaluation results. The\nimportance of trustworthy pre-processing and principle solution approaches are\npresented, addressing the major problem of end-to-end sensor data integrity in\nblockchain-based IoT applications.",
    "descriptor": "\nComments: Preprint version of full paper at ICSCO21\n",
    "authors": [
      "Jonathan Heiss",
      "Anselm Busse",
      "Stefan Tai"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.15869"
  },
  {
    "id": "arXiv:2110.15871",
    "title": "From Theories on Styles to their Transfer in Text: Bridging the Gap with  a Hierarchical Survey",
    "abstract": "Humans are naturally endowed with the ability to write in a particular style.\nThey can, for instance, rephrase a formal letter in an informal way, convey a\nliteral message with the use of figures of speech, edit a novel mimicking the\nstyle of some well-known authors. Automating this form of creativity\nconstitutes the goal of style transfer. As a natural language generation task,\nstyle transfer aims at re-writing existing texts, and specifically, it creates\nparaphrases that exhibit some desired stylistic attributes. From a practical\nperspective, it envisions beneficial applications, like chat-bots that modulate\ntheir communicative style to appear empathetic, or systems that automatically\nsimplify technical articles for a non-expert audience.\nStyle transfer has been dedicated several style-aware paraphrasing methods. A\nhandful of surveys give a methodological overview of the field, but they do not\nsupport researchers to focus on specific styles. With this paper, we aim at\nproviding a comprehensive discussion of the styles that have received attention\nin the transfer task. We organize them into a hierarchy, highlighting the\nchallenges for the definition of each of them, and pointing out gaps in the\ncurrent research landscape. The hierarchy comprises two main groups. One\nencompasses styles that people modulate arbitrarily, along the lines of\nregisters and genres. The other group corresponds to unintentionally expressed\nstyles, due to an author's personal characteristics. Hence, our review shows\nhow the groups relate to one another, and where specific styles, including some\nthat have never been explored, belong in the hierarchy. Moreover, we summarize\nthe methods employed for different stylistic families, hinting researchers\ntowards those that would be the most fitting for future research.",
    "descriptor": "\nComments: 58 pages, 2 figures, 9 tables. Submitted for review to the Journal of Natural Language Engineering, Cambridge University Press\n",
    "authors": [
      "Enrica Troiano",
      "Aswathy Velutharambath",
      "and Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15871"
  },
  {
    "id": "arXiv:2110.15872",
    "title": "2D-2FA: A New Dimension in Two-Factor Authentication",
    "abstract": "We propose a two-factor authentication (2FA) mechanism called 2D-2FA to\naddress security and usability issues in existing methods. 2D-2FA has three\ndistinguishing features: First, after a user enters a username and password on\na login terminal, a unique $\\textit{identifier}$ is displayed to her. She\n$\\textit{inputs}$ the same identifier on her registered 2FA device, which\nensures appropriate engagement in the authentication process. Second, a\none-time PIN is computed on the device and $\\textit{automatically}$ transferred\nto the server. Thus, the PIN can have very high entropy, making guessing\nattacks infeasible. Third, the identifier is also incorporated into the PIN\ncomputation, which renders $\\textit{concurrent attacks}$ ineffective.\nThird-party services such as push-notification providers and 2FA service\nproviders, do not need to be trusted for the security of the system. The choice\nof identifiers depends on the device form factor and the context. Users could\nchoose to draw patterns, capture QR codes, etc.\nWe provide a proof of concept implementation, and evaluate performance,\naccuracy, and usability of the system. We show that the system offers a lower\nerror rate (about half) and better efficiency (2-3 times faster) compared to\nthe commonly used PIN-2FA. Our study indicates a high level of usability with a\nSUS of 75, and a high perception of efficiency, security, accuracy, and\nadoptability.",
    "descriptor": "\nComments: In the proceedings of Annual Computer Security Applications Conference (ACSAC) 2021\n",
    "authors": [
      "Maliheh Shirvanian",
      "Shashank Agrawal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.15872"
  },
  {
    "id": "arXiv:2110.15873",
    "title": "A comparison of Cahn-Hilliard and Navier-Stokes-Cahn-Hilliard models on  manifolds",
    "abstract": "We consider phase-field models with and without lateral flow for the\nnumerical simulation of lateral phase separation and coarsening in lipid\nmembranes. For the numerical solution of these models, we apply an unfitted\nfinite element method that is flexible in handling complex and possibly\nevolving shapes in the absence of an explicit surface parametrization. Through\nseveral numerical tests, we investigate the effect of the presence of lateral\nflow on the evolution of phases. In particular, we focus on understanding how\nvariable line tension, viscosity, membrane composition, and surface shape\naffect the pattern formation. Keywords: Lateral phase separation, surface\nCahn-Hilliard equation, lateral flow, surface Navier-Stokes-Cahn-Hilliard\nsystem, TraceFEM",
    "descriptor": "\nComments: 21 pages, 12 figures\n",
    "authors": [
      "Maxim Olshanskii",
      "Yerbol Palzhanov",
      "Annalisa Quaini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15873"
  },
  {
    "id": "arXiv:2110.15875",
    "title": "Elasto-acoustic modelling and simulation for the seismic response of  structures: The case of the Tahtal\u0131 dam in the 2020 \u0130zmir earthquake",
    "abstract": "As a mean to assess the risk dam structures are exposed to during\nearthquakes, we employ an abstract mathematical, three dimensional,\nelasto-acoustic coupled wave-propagation model taking into account (i) the dam\nstructure itself, embedded into (ii) its surrounding topography, (iii)\ndifferent material soil layers, (iv) the seismic source as well as (v) the\nreservoir lake filled with water treated as an acoustic medium. As a case study\nfor extensive numerical simulations we consider the magnitude 7 seismic event\nof the 30$^{\\rm th}$ of October 2020 taking place in the Icarian Sea (Greece)\nand the Tahtali dam around 30 km from there (Turkey). A challenging task is to\nresolve the multiple length scales that are present due to the huge differences\nin size between the dam building structure and the area of interest, considered\nfor the propagation of the earthquake. Interfaces between structures and highly\nnon-conforming meshes on different scales are resolved by means of a\ndiscontinuous Galerkin approach. The seismic source is modeled using inversion\ndata about the real fault plane. Ultimately, we perform a real data driven,\nmulti-scale, full source-to-site, physics based simulation based on the\ndiscontinuous Galerkin spectral element method, which allows to precisely\nvalidate the ground motion experienced along the Tahtali dam, comparing the\nsynthetic seismograms against actually observed ones. A comparison with a more\nclassical computational method, using a plane wave with data from a deconvolved\nseismogram reading as an input, is discussed.",
    "descriptor": "\nComments: 26 pages, 16 figures\n",
    "authors": [
      "Ilario Mazzieri",
      "Markus Muhr",
      "Marco Stupazzini",
      "Barbara Wohlmuth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.15875"
  },
  {
    "id": "arXiv:2110.15879",
    "title": "Upper and Lower Bounds for End-to-End Risks in Stochastic Robot  Navigation",
    "abstract": "We present novel upper and lower bounds to estimate the collision probability\nof motion plans for autonomous agents with discrete-time linear Gaussian\ndynamics. Motion plans generated by planning algorithms cannot be perfectly\nexecuted by autonomous agents in reality due to the inherent uncertainties in\nthe real world. Estimating collision probability is crucial to characterize the\nsafety of trajectories and plan risk optimal trajectories. Our approach is an\napplication of standard results in probability theory including the\ninequalities of Hunter, Kounias, Frechet, and Dawson. Using a ground robot\nnavigation example, we numerically demonstrate that our method is considerably\nfaster than the naive Monte Carlo sampling method and the proposed bounds are\nsignificantly less conservative than Boole's bound commonly used in the\nliterature.",
    "descriptor": "",
    "authors": [
      "Apurva Patil",
      "Takashi Tanaka"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.15879"
  },
  {
    "id": "arXiv:2110.15884",
    "title": "Distributing Deep Learning Hyperparameter Tuning for 3D Medical Image  Segmentation",
    "abstract": "Most research on novel techniques for 3D Medical Image Segmentation (MIS) is\ncurrently done using Deep Learning with GPU accelerators. The principal\nchallenge of such technique is that a single input can easily cope computing\nresources, and require prohibitive amounts of time to be processed.\nDistribution of deep learning and scalability over computing devices is an\nactual need for progressing on such research field. Conventional distribution\nof neural networks consist in data parallelism, where data is scattered over\nresources (e.g., GPUs) to parallelize the training of the model. However,\nexperiment parallelism is also an option, where different training processes\nare parallelized across resources. While the first option is much more common\non 3D image segmentation, the second provides a pipeline design with less\ndependence among parallelized processes, allowing overhead reduction and more\npotential scalability. In this work we present a design for distributed deep\nlearning training pipelines, focusing on multi-node and multi-GPU environments,\nwhere the two different distribution approaches are deployed and benchmarked.\nWe take as proof of concept the 3D U-Net architecture, using the MSD Brain\nTumor Segmentation dataset, a state-of-art problem in medical image\nsegmentation with high computing and space requirements. Using the BSC\nMareNostrum supercomputer as benchmarking environment, we use TensorFlow and\nRay as neural network training and experiment distribution platforms. We\nevaluate the experiment speed-up, showing the potential for scaling out on GPUs\nand nodes. Also comparing the different parallelism techniques, showing how\nexperiment distribution leverages better such resources through scaling.\nFinally, we provide the implementation of the design open to the community, and\nthe non-trivial steps and methodology for adapting and deploying a MIS case as\nthe here presented.",
    "descriptor": "\nComments: 7 pages, 4 figures, scientific report, official code: this https URL\n",
    "authors": [
      "Josep Lluis Berral",
      "Oriol Aranda",
      "Juan Luis Dominguez",
      "Jordi Torres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.15884"
  },
  {
    "id": "arXiv:2110.15885",
    "title": "Multiscale Finite Element Methods for an Elliptic Optimal Control  Problem with Rough Coefficients",
    "abstract": "We investigate multiscale finite element methods for an elliptic distributed\noptimal control problem with rough coefficients. They are based on the (local)\northogonal decomposition methodology of M\\aa lqvist and Peterseim.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Susanne C. Brenner",
      "Jos\u00e9 C. Garay",
      "Li-yeng Sung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15885"
  },
  {
    "id": "arXiv:2110.15891",
    "title": "Friendly Cut Sparsifiers and Faster Gomory-Hu Trees",
    "abstract": "We devise new cut sparsifiers that are related to the classical\nsparsification of Nagamochi and Ibaraki [Algorithmica, 1992], which is an\nalgorithm that, given an unweighted graph $G$ on $n$ nodes and a parameter $k$,\ncomputes a subgraph with $O(nk)$ edges that preserves all cuts of value up to\n$k$. We put forward the notion of a friendly cut sparsifier, which is a minor\nof $G$ that preserves all friendly cuts of value up to $k$, where a cut in $G$\nis called friendly if every node has more edges connecting it to its own side\nof the cut than to the other side. We present an algorithm that, given a simple\ngraph $G$, computes in almost-linear time a friendly cut sparsifier with\n$\\tilde{O}(n \\sqrt{k})$ edges. Using similar techniques, we also show how,\ngiven in addition a terminal set $T$, one can compute in almost-linear time a\nterminal sparsifier, which preserves the minimum $st$-cut between every pair of\nterminals, with $\\tilde{O}(n \\sqrt{k} + |T| k)$ edges.\nPlugging these sparsifiers into the recent $n^{2+o(1)}$-time algorithms for\nconstructing a Gomory-Hu tree of simple graphs, along with a relatively simple\nprocedure for handling the unfriendly minimum cuts, we improve the running time\nfor moderately dense graphs (e.g., with $m=n^{1.75}$ edges). In particular,\nassuming a linear-time Max-Flow algorithm, the new state-of-the-art for\nGomory-Hu tree is the minimum between our $(m+n^{1.75})^{1+o(1)}$ and the known\n$m n^{1/2+o(1)}$.\nWe further investigate the limits of this approach and the possibility of\nbetter sparsification. Under the hypothesis that an $\\tilde{O}(n)$-edge\nsparsifier that preserves all friendly minimum $st$-cuts can be computed\nefficiently, our upper bound improves to $\\tilde{O}(m+n^{1.5})$ which is the\nbest possible without breaking the cubic barrier for constructing Gomory-Hu\ntrees in non-simple graphs.",
    "descriptor": "",
    "authors": [
      "Amir Abboud",
      "Robert Krauthgamer",
      "Ohad Trabelsi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15891"
  },
  {
    "id": "arXiv:2110.15895",
    "title": "Application of 2-D Convolutional Neural Networks for Damage Detection in  Steel Frame Structures",
    "abstract": "In this paper, we present an application of 2-D convolutional neural networks\n(2-D CNNs) designed to perform both feature extraction and classification\nstages as a single organism to solve the highlighted problems. The method uses\na network of lighted CNNs instead of deep and takes raw acceleration signals as\ninput. Using lighted CNNs, in which every one of them is optimized for a\nspecific element, increases the accuracy and makes the network faster to\nperform. Also, a new framework is proposed for decreasing the data required in\nthe training phase. We verified our method on Qatar University Grandstand\nSimulator (QUGS) benchmark data provided by Structural Dynamics Team. The\nresults showed improved accuracy over other methods, and running time was\nadequate for real-time applications.",
    "descriptor": "\nComments: 17 pages, 5 Figures, 3 Tables\n",
    "authors": [
      "Shahin Ghazvineh",
      "Gholamreza Nouri",
      "Seyed Hossein Hosseini Lavassani",
      "Vahidreza Gharehbaghi",
      "Andy Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15895"
  },
  {
    "id": "arXiv:2110.15900",
    "title": "Hyperparameter Tuning is All You Need for LISTA",
    "abstract": "Learned Iterative Shrinkage-Thresholding Algorithm (LISTA) introduces the\nconcept of unrolling an iterative algorithm and training it like a neural\nnetwork. It has had great success on sparse recovery. In this paper, we show\nthat adding momentum to intermediate variables in the LISTA network achieves a\nbetter convergence rate and, in particular, the network with instance-optimal\nparameters is superlinearly convergent. Moreover, our new theoretical results\nlead to a practical approach of automatically and adaptively calculating the\nparameters of a LISTA network layer based on its previous layers. Perhaps most\nsurprisingly, such an adaptive-parameter procedure reduces the training of\nLISTA to tuning only three hyperparameters from data: a new record set in the\ncontext of the recent advances on trimming down LISTA complexity. We call this\nnew ultra-light weight network HyperLISTA. Compared to state-of-the-art LISTA\nmodels, HyperLISTA achieves almost the same performance on seen data\ndistributions and performs better when tested on unseen distributions\n(specifically, those with different sparsity levels and nonzero magnitudes).\nCode is available: https://github.com/VITA-Group/HyperLISTA.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Xiaohan Chen",
      "Jialin Liu",
      "Zhangyang Wang",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15900"
  },
  {
    "id": "arXiv:2110.15904",
    "title": "Learning Co-segmentation by Segment Swapping for Retrieval and Discovery",
    "abstract": "The goal of this work is to efficiently identify visually similar patterns\nfrom a pair of images, e.g. identifying an artwork detail copied between an\nengraving and an oil painting, or matching a night-time photograph with its\ndaytime counterpart. Lack of training data is a key challenge for this\nco-segmentation task. We present a simple yet surprisingly effective approach\nto overcome this difficulty: we generate synthetic training pairs by selecting\nobject segments in an image and copy-pasting them into another image. We then\nlearn to predict the repeated object masks. We find that it is crucial to\npredict the correspondences as an auxiliary task and to use Poisson blending\nand style transfer on the training pairs to generalize on real data. We analyse\nresults with two deep architectures relevant to our joint image analysis task:\na transformer-based architecture and Sparse Nc-Net, a recent network designed\nto predict coarse correspondences using 4D convolutions.\nWe show our approach provides clear improvements for artwork details\nretrieval on the Brueghel dataset and achieves competitive performance on two\nplace recognition benchmarks, Tokyo247 and Pitts30K. We then demonstrate the\npotential of our approach by performing object discovery on the Internet object\ndiscovery dataset and the Brueghel dataset. Our code and data are available at\nthis http URL",
    "descriptor": "",
    "authors": [
      "Xi Shen",
      "Alexei A. Efros",
      "Armand Joulin",
      "Mathieu Aubry"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15904"
  },
  {
    "id": "arXiv:2110.15905",
    "title": "Transformer Ensembles for Sexism Detection",
    "abstract": "This document presents in detail the work done for the sexism detection task\nat EXIST2021 workshop. Our methodology is built on ensembles of\nTransformer-based models which are trained on different background and corpora\nand fine-tuned on the provided dataset from the EXIST2021 workshop. We report\naccuracy of 0.767 for the binary classification task (task1), and f1 score\n0.766, and for the multi-class task (task2) accuracy 0.623 and f1-score 0.535.",
    "descriptor": "",
    "authors": [
      "Lily Davies",
      "Marta Baldracchi",
      "Carlo Alessandro Borella",
      "Konstantinos Perifanos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15905"
  },
  {
    "id": "arXiv:2110.15907",
    "title": "Learning to Be Cautious",
    "abstract": "A key challenge in the field of reinforcement learning is to develop agents\nthat behave cautiously in novel situations. It is generally impossible to\nanticipate all situations that an autonomous system may face or what behavior\nwould best avoid bad outcomes. An agent that could learn to be cautious would\novercome this challenge by discovering for itself when and how to behave\ncautiously. In contrast, current approaches typically embed task-specific\nsafety information or explicit cautious behaviors into the system, which is\nerror-prone and imposes extra burdens on practitioners. In this paper, we\npresent both a sequence of tasks where cautious behavior becomes increasingly\nnon-obvious, as well as an algorithm to demonstrate that it is possible for a\nsystem to \\emph{learn} to be cautious. The essential features of our algorithm\nare that it characterizes reward function uncertainty without task-specific\nsafety information and uses this uncertainty to construct a robust policy.\nSpecifically, we construct robust policies with a $k$-of-$N$ counterfactual\nregret minimization (CFR) subroutine given a learned reward function\nuncertainty represented by a neural network ensemble belief. These policies\nexhibit caution in each of our tasks without any task-specific safety tuning.",
    "descriptor": "",
    "authors": [
      "Montaser Mohammedalamen",
      "Dustin Morrill",
      "Alexander Sieusahai",
      "Yash Satsangi",
      "Michael Bowling"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15907"
  },
  {
    "id": "arXiv:2110.15909",
    "title": "Contrastive prediction strategies for unsupervised segmentation and  categorization of phonemes and words",
    "abstract": "We investigate the performance on phoneme categorization and phoneme and word\nsegmentation of several self-supervised learning (SSL) methods based on\nContrastive Predictive Coding (CPC). Our experiments show that with the\nexisting algorithms there is a trade off between categorization and\nsegmentation performance. We investigate the source of this conflict and\nconclude that the use of context building networks, albeit necessary for\nsuperior performance on categorization tasks, harms segmentation performance by\ncausing a temporal shift on the learned representations. Aiming to bridge this\ngap, we take inspiration from the leading approach on segmentation, which\nsimultaneously models the speech signal at the frame and phoneme level, and\nincorporate multi-level modelling into Aligned CPC (ACPC), a variation of CPC\nwhich exhibits the best performance on categorization tasks. Our multi-level\nACPC (mACPC) improves in all categorization metrics and achieves\nstate-of-the-art performance in word segmentation.",
    "descriptor": "",
    "authors": [
      "Santiago Cuervo",
      "Maciej Grabias",
      "Jan Chorowski",
      "Grzegorz Ciesielski",
      "Adrian \u0141a\u0144cucki",
      "Pawe\u0142 Rychlikowski",
      "Ricard Marxer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15909"
  },
  {
    "id": "arXiv:2110.15911",
    "title": "Physics-informed linear regression is a competitive approach compared to  Machine Learning methods in building MPC",
    "abstract": "Because physics-based building models are difficult to obtain as each\nbuilding is individual, there is an increasing interest in generating models\nsuitable for building MPC directly from measurement data. Machine learning\nmethods have been widely applied to this problem and validated mostly in\nsimulation; there are, however, few studies on a direct comparison of different\nmodels or validation in real buildings to be found in the literature. Methods\nthat are indeed validated in application often lead to computationally complex\nnon-convex optimization problems. Here we compare physics-informed\nAutoregressive-Moving-Average with Exogenous Inputs (ARMAX) models to Machine\nLearning models based on Random Forests and Input Convex Neural Networks and\nthe resulting convex MPC schemes in experiments on a practical building\napplication with the goal of minimizing energy consumption while maintaining\noccupant comfort, and in a numerical case study. We demonstrate that Predictive\nControl in general leads to savings between 26% and 49% of heating and cooling\nenergy, compared to the building's baseline hysteresis controller. Moreover, we\nshow that all model types lead to satisfactory control performance in terms of\nconstraint satisfaction and energy reduction. However, we also see that the\nphysics-informed ARMAX models have a lower computational burden, and a superior\nsample efficiency compared to the Machine Learning based models. Moreover, even\nif abundant training data is available, the ARMAX models have a significantly\nlower prediction error than the Machine Learning models, which indicates that\nthe encoded physics-based prior of the former cannot independently be found by\nthe latter.",
    "descriptor": "\nComments: 17 pages, 11 Figures, submitted to Applied Energy\n",
    "authors": [
      "Felix B\u00fcnning",
      "Benjamin Huber",
      "Adrian Schalbetter",
      "Ahmed Aboudonia",
      "Mathias Hudoba de Badyn",
      "Philipp Heer",
      "Roy S. Smith",
      "John Lygeros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.15911"
  },
  {
    "id": "arXiv:2110.15912",
    "title": "On the use of uncertainty in classifying Aedes Albopictus mosquitoes",
    "abstract": "The re-emergence of mosquito-borne diseases (MBDs), which kill hundreds of\nthousands of people each year, has been attributed to increased human\npopulation, migration, and environmental changes. Convolutional neural networks\n(CNNs) have been used by several studies to recognise mosquitoes in images\nprovided by projects such as Mosquito Alert to assist entomologists in\nidentifying, monitoring, and managing MBD. Nonetheless, utilising CNNs to\nautomatically label input samples could involve incorrect predictions, which\nmay mislead future epidemiological studies. Furthermore, CNNs require large\nnumbers of manually annotated data. In order to address the mentioned issues,\nthis paper proposes using the Monte Carlo Dropout method to estimate the\nuncertainty scores in order to rank the classified samples to reduce the need\nfor human supervision in recognising Aedes albopictus mosquitoes. The estimated\nuncertainty was also used in an active learning framework, where just a portion\nof the data from large training sets was manually labelled. The experimental\nresults show that the proposed classification method with rejection outperforms\nthe competing methods by improving overall performance and reducing\nentomologist annotation workload. We also provide explainable visualisations of\nthe different regions that contribute to a set of samples' uncertainty\nassessment.",
    "descriptor": "\nComments: This article has been accepted for publication in a future issue of IEEE Journal of Selected Topics in Signal Processing\n",
    "authors": [
      "Gereziher Adhane",
      "Mohammad Mahdi Dehshibi",
      "David Masip"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15912"
  },
  {
    "id": "arXiv:2110.15914",
    "title": "Improving the quality of generative models through Smirnov  transformation",
    "abstract": "Solving the convergence issues of Generative Adversarial Networks (GANs) is\none of the most outstanding problems in generative models. In this work, we\npropose a novel activation function to be used as output of the generator\nagent. This activation function is based on the Smirnov probabilistic\ntransformation and it is specifically designed to improve the quality of the\ngenerated data. In sharp contrast with previous works, our activation function\nprovides a more general approach that deals not only with the replication of\ncategorical variables but with any type of data distribution (continuous or\ndiscrete). Moreover, our activation function is derivable and therefore, it can\nbe seamlessly integrated in the backpropagation computations during the GAN\ntraining processes. To validate this approach, we evaluate our proposal against\ntwo different data sets: a) an artificially rendered data set containing a\nmixture of discrete and continuous variables, and b) a real data set of\nflow-based network traffic data containing both normal connections and\ncryptomining attacks. To evaluate the fidelity of the generated data, we\nanalyze both their results in terms of quality measures of statistical nature\nand also regarding the use of these synthetic data to feed a nested machine\nlearning-based classifier. The experimental results evince a clear\noutperformance of the GAN network tuned with this new activation function with\nrespect to both a na\\\"ive mean-based generator and a standard GAN. The quality\nof the data is so high that the generated data can fully substitute real data\nfor training the nested classifier without a fall in the obtained accuracy.\nThis result encourages the use of GANs to produce high-quality synthetic data\nthat are applicable in scenarios in which data privacy must be guaranteed.",
    "descriptor": "\nComments: 28 pages, 16 Figures, 4 Tables\n",
    "authors": [
      "\u00c1ngel Gonz\u00e1lez-Prieto",
      "Alberto Mozo",
      "Sandra G\u00f3mez-Canaval",
      "Edgar Talavera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15914"
  },
  {
    "id": "arXiv:2110.15918",
    "title": "Takagi factorization of matrices depending on parameters and locating  degeneracies of singular values",
    "abstract": "In this work we consider the Takagi factorization of a matrix valued function\ndepending on parameters. We give smoothness and genericity results and pay\nparticular attention to the concerns caused by having either a singular value\nequal to $0$ or multiple singular values. For these phenomena, we give\ntheoretical results showing that their co-dimension is $2$, and we further\ndevelop and test numerical methods to locate in parameter space values where\nthese occurrences take place. Numerical study of the density of these\noccurrences is performed.",
    "descriptor": "",
    "authors": [
      "Luca Dieci",
      "Alessandra Papini",
      "Alessandro Pugliese"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15918"
  },
  {
    "id": "arXiv:2110.15919",
    "title": "Performance Analysis of Dual-Hop THz Wireless Transmission for Backhaul  Applications",
    "abstract": "THz transmissions suffer from pointing errors due to antenna misalignment and\nincur higher path loss because of molecular absorption at such a high\nfrequency. In this paper, we employ an amplify-and-forward (AF) dual-hop relay\nto mitigate the effect of pointing errors and extend the range of a wireless\nbackhaul network. We provide statistical analysis on the performance of the\nconsidered system by deriving analytical expressions for the outage\nprobability, average bit-error-rate (BER), average signal-to-noise ratio (SNR),\nand a lower bound on the ergodic capacity over independent and identical\n(i.i.d) $\\alpha$-$\\mu$ fading model and statistical pointing errors. Using\ncomputer simulations, we validate the derived analysis of the relay-assisted\nsystem. We demonstrate the effect of the system parameters on outage\nprobability and average BER with the help of diversity order. We show that data\nrates up to several \\mbox{Gbps} can be achieved using THz transmissions, which\nis desirable for next-generation wireless systems, especially for backhaul\napplications.",
    "descriptor": "\nComments: This paper has been accepted for presentation in 2021 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS), Hyderabad, India\n",
    "authors": [
      "Vinay U. Pai",
      "Pranay Bhardwaj",
      "S. M. Zafaruddin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15919"
  },
  {
    "id": "arXiv:2110.15920",
    "title": "Entropy Stable Discontinuous Galerkin Methods for Balance Laws in  Non-Conservative Form: Applications to Euler with Gravity",
    "abstract": "In this work a non-conservative balance law formulation is considered that\nencompasses the rotating, compressible Euler equations for dry atmospheric\nflows. We develop a semi-discretely entropy stable discontinuous Galerkin\nmethod on curvilinear meshes using a generalization of flux differencing for\nnumerical fluxes in fluctuation form. The method uses the skew-hybridized\nformulation of the element operators to ensure that, even in the presence of\nunder-integration on curvilinear meshes, the resulting discretization is\nentropy stable. Several atmospheric flow test cases in one, two, and three\ndimensions confirm the theoretical entropy stability results as well as show\nthe high-order accuracy and robustness of the method.",
    "descriptor": "\nComments: 24 Pages, 10 figures\n",
    "authors": [
      "Maciej Waruszewski",
      "Jeremy E. Kozdon",
      "Lucas C. Wilcox",
      "Thomas H. Gibson",
      "Francis X. Giraldo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15920"
  },
  {
    "id": "arXiv:2110.15923",
    "title": "Efficient Representation of Interaction Patterns with Hyperbolic  Hierarchical Clustering for Classification of Users on Twitter",
    "abstract": "Social media platforms play an important role in democratic processes. During\nthe 2019 General Elections of India, political parties and politicians widely\nused Twitter to share their ideals, advocate their agenda and gain popularity.\nTwitter served as a ground for journalists, politicians and voters to interact.\nThe organic nature of these interactions can be upended by malicious accounts\non Twitter, which end up being suspended or deleted from the platform. Such\naccounts aim to modify the reach of content by inorganically interacting with\nparticular handles. This is a threat to the integrity of the platform, as such\nactivity has the potential to affect entire results of democratic processes. In\nthis work, we design a feature extraction framework which compactly captures\npotentially insidious interaction patterns. These features are designed to\nbring out communities amongst the users that work to boost the content of\nparticular accounts. We use Hyperbolic Hierarchical Clustering (HypHC) which\nrepresents the features in the hyperbolic manifold to further separate such\ncommunities. HypHC gives the added benefit of representing these features in a\nlower dimensional space -- thus serving as a dimensionality reduction\ntechnique. We use these features to distinguish between different classes of\nusers that emerged in the aftermath of the 2019 General Elections of India.\nAmongst the users active on Twitter during the elections, 2.8% of the users\nparticipating were suspended and 1% of the users were deleted from the\nplatform. We demonstrate the effectiveness of our proposed features in\ndifferentiating between regular users (users who were neither suspended nor\ndeleted), suspended users and deleted users. By leveraging HypHC in our\npipeline, we obtain F1 scores of upto 93%.",
    "descriptor": "",
    "authors": [
      "Tanvi Karandikar",
      "Avinash Prabhu",
      "Avinash Tulasi",
      "Arun Balaji Buduru",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.15923"
  },
  {
    "id": "arXiv:2110.15926",
    "title": "Delayed Propagation Transformer: A Universal Computation Engine towards  Practical Control in Cyber-Physical Systems",
    "abstract": "Multi-agent control is a central theme in the Cyber-Physical Systems (CPS).\nHowever, current control methods either receive non-Markovian states due to\ninsufficient sensing and decentralized design, or suffer from poor convergence.\nThis paper presents the Delayed Propagation Transformer (DePT), a new\ntransformer-based model that specializes in the global modeling of CPS while\ntaking into account the immutable constraints from the physical world. DePT\ninduces a cone-shaped spatial-temporal attention prior, which injects the\ninformation propagation and aggregation principles and enables a global view.\nWith physical constraint inductive bias baked into its design, our DePT is\nready to plug and play for a broad class of multi-agent systems. The\nexperimental results on one of the most challenging CPS -- network-scale\ntraffic signal control system in the open world -- show that our model\noutperformed the state-of-the-art expert methods on synthetic and real-world\ndatasets. Our codes are released at: https://github.com/VITA-Group/DePT.",
    "descriptor": "",
    "authors": [
      "Wenqing Zheng",
      "Qiangqiang Guo",
      "Hao Yang",
      "Peihao Wang",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.15926"
  },
  {
    "id": "arXiv:2110.15928",
    "title": "Joint Channel Estimation and Data Detection in Cell-Free Massive MU-MIMO  Systems",
    "abstract": "We propose a joint channel estimation and data detection (JED) algorithm for\ndensely-populated cell-free massive multiuser (MU) multiple-input\nmultiple-output (MIMO) systems, which reduces the channel training overhead\ncaused by the presence of hundreds of simultaneously transmitting user\nequipments (UEs). Our algorithm iteratively solves a relaxed version of a\nmaximum a-posteriori JED problem and simultaneously exploits the sparsity of\ncell-free massive MU-MIMO channels as well as the boundedness of QAM\nconstellations. In order to improve the performance and convergence of the\nalgorithm, we propose methods that permute the access point and UE indices to\nform so-called virtual cells, which leads to better initial solutions. We\nassess the performance of our algorithm in terms of root-mean-squared-symbol\nerror, bit error rate, and mutual information, and we demonstrate that JED\nsignificantly reduces the pilot overhead compared to orthogonal training, which\nenables reliable communication with short packets to a large number of UEs.",
    "descriptor": "\nComments: To appear in the IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Haochuan Song",
      "Tom Goldstein",
      "Xiaohu You",
      "Chuan Zhang",
      "Olav Tirkkonen",
      "Christoph Studer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15928"
  },
  {
    "id": "arXiv:2110.15931",
    "title": "Unsupervised Full Constituency Parsing with Neighboring Distribution  Divergence",
    "abstract": "Unsupervised constituency parsing has been explored much but is still far\nfrom being solved. Conventional unsupervised constituency parser is only able\nto capture the unlabeled structure of sentences. Towards unsupervised full\nconstituency parsing, we propose an unsupervised and training-free labeling\nprocedure by exploiting the property of a recently introduced metric,\nNeighboring Distribution Divergence (NDD), which evaluates semantic similarity\nbetween sentences before and after editions. For implementation, we develop NDD\ninto Dual POS-NDD (DP-NDD) and build \"molds\" to detect constituents and their\nlabels in sentences. We show that DP-NDD not only labels constituents precisely\nbut also inducts more accurate unlabeled constituency trees than all previous\nunsupervised methods with simpler rules. With two frameworks for labeled\nconstituency trees inference, we set both the new state-of-the-art for\nunlabeled F1 and strong baselines for labeled F1. In contrast with the\nconventional predicting-and-evaluating scenario, our method acts as an\nplausible example to inversely apply evaluating metrics for prediction.",
    "descriptor": "",
    "authors": [
      "Letian Peng",
      "Zuchao Li",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15931"
  },
  {
    "id": "arXiv:2110.15941",
    "title": "Personalized breath based biometric authentication with wearable  multimodality",
    "abstract": "Breath with nose sound features has been shown as a potential biometric in\npersonal identification and verification. In this paper, we show that\ninformation that comes from other modalities captured by motion sensors on the\nchest in addition to audio features could further improve the performance. Our\nwork is composed of three main contributions: hardware creation, dataset\npublication, and proposed multimodal models. To be more specific, we design new\nhardware which consists of an acoustic sensor to collect audio features from\nthe nose, as well as an accelerometer and gyroscope to collect movement on the\nchest as a result of an individual's breathing. Using this hardware, we publish\na collected dataset from a number of sessions from different volunteers, each\nsession includes three common gestures: normal, deep, and strong breathing.\nFinally, we experiment with two multimodal models based on Convolutional Long\nShort Term Memory (CNN-LSTM) and Temporal Convolutional Networks (TCN)\narchitectures. The results demonstrate the suitability of our new hardware for\nboth verification and identification tasks.",
    "descriptor": "\nComments: 7 pages (2 columns), 5 tables, 7 figures, submitted to ACM Multimedia 2020\n",
    "authors": [
      "Manh-Ha Bui",
      "Viet-Anh Tran",
      "Cuong Pham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15941"
  },
  {
    "id": "arXiv:2110.15943",
    "title": "MetaICL: Learning to Learn In Context",
    "abstract": "We introduce MetaICL (Meta-training for In-Context Learning), a new\nmeta-training framework for few-shot learning where a pretrained language model\nis tuned to do in-context learn-ing on a large set of training tasks. This\nmeta-training enables the model to more effectively learn a new task in context\nat test time, by simply conditioning on a few training examples with no\nparameter updates or task-specific templates. We experiment on a large, diverse\ncollection of tasks consisting of 142 NLP datasets including classification,\nquestion answering, natural language inference, paraphrase detection and more,\nacross seven different meta-training/target splits. MetaICL outperforms a range\nof baselines including in-context learning without meta-training and multi-task\nlearning followed by zero-shot transfer. We find that the gains are\nparticularly significant for target tasks that have domain shifts from the\nmeta-training tasks, and that using a diverse set of the meta-training tasks is\nkey to improvements. We also show that MetaICL approaches (and sometimes beats)\nthe performance of models fully finetuned on the target task training data, and\noutperforms much bigger models with nearly 8x parameters.",
    "descriptor": "\nComments: 18 pages (9 pages for the main paper, 9 pages for references and appendices). 1 figure. Code available at this https URL\n",
    "authors": [
      "Sewon Min",
      "Mike Lewis",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15943"
  },
  {
    "id": "arXiv:2110.15944",
    "title": "Universally-Optimal Distributed Shortest Paths and Transshipment via  Graph-Based L1-Oblivious Routing",
    "abstract": "We provide universally-optimal distributed graph algorithms for\n$(1+\\varepsilon)$-approximate shortest path problems including\nshortest-path-tree and transshipment.\nThe universal optimality of our algorithms guarantees that, on any $n$-node\nnetwork $G$, our algorithm completes in $T \\cdot n^{o(1)}$ rounds whenever a\n$T$-round algorithm exists for $G$. This includes $D \\cdot n^{o(1)}$-round\nalgorithms for any planar or excluded-minor network. Our algorithms never\nrequire more than $(\\sqrt{n} + D) \\cdot n^{o(1)}$ rounds, resulting in the\nfirst sub-linear-round distributed algorithm for transshipment.\nThe key technical contribution leading to these results is the first\nefficient $n^{o(1)}$-competitive linear $\\ell_1$-oblivious routing operator\nthat does not require the use of $\\ell_1$-embeddings. Our construction is\nsimple, solely based on low-diameter decompositions, and -- in contrast to all\nknown constructions -- directly produces an oblivious flow instead of just an\napproximation of the optimal flow cost. This also has the benefit of\nsimplifying the interaction with Sherman's multiplicative weight framework\n[SODA'17] in the distributed setting and its subsequent rounding procedures.",
    "descriptor": "\nComments: Accepted to SODA 2022. Author ordering was randomized using this https URL\n",
    "authors": [
      "Goran Zuzic",
      "Gramoz Goranci",
      "Mingquan Ye",
      "Bernhard Haeupler",
      "Xiaorui Sun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15944"
  },
  {
    "id": "arXiv:2110.15945",
    "title": "A spline-based spatial impulse response simulator",
    "abstract": "The spatial impulse response (SIR) method is a well-known approach to\ncalculate transient acoustic fields of arbitrary-shape transducers. It involves\nthe evaluation of a time-dependent surface integral. Although analytic\nexpressions of the SIR exist for some geometries, numerical methods based on\nthe discretization of transducer surfaces have become the standard. The\nproposed method consists of representing the transducer as a non-uniform\nrational B-spline (NURBS) surface, and decomposing it into smooth B\\'ezier\npatches onto which quadrature rules can be deployed. The evaluation of the SIR\ncan then be expressed in B-spline bases, resulting in a sum of\nshifted-and-weighted basis functions. Field signals are eventually obtained by\na convolution of the basis coefficients, derived from the excitation waveform,\nand the basis SIR. The use of NURBS enables exact representations of common\ntransducer elements. High-order Gaussian quadrature rules enable high accuracy\nwith few quadrature points. High-order B-spline bases are ideally suited to\nexploit efficiently the bandlimited property of excitation waveforms. Numerical\nexperiments demonstrate that the proposed approach enables sampling the SIR at\nlow sampling rates, as required by the excitation waveform, without introducing\nadditional errors on simulated field signals.",
    "descriptor": "\nComments: Main: 12 pages (5 figures). Supplement: 15 pages (21 figures)\n",
    "authors": [
      "Dimitris Perdios",
      "Florian Martinez",
      "Marcel Arditi",
      "Jean-Philippe Thiran"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2110.15945"
  },
  {
    "id": "arXiv:2110.15946",
    "title": "Estimating and Maximizing Mutual Information for Knowledge Distillation",
    "abstract": "Knowledge distillation is a widely used general technique to transfer\nknowledge from a teacher network to a student network. In this work, we propose\nMutual Information Maximization Knowledge Distillation (MIMKD). Our method uses\na contrastive objective to simultaneously estimate and maximize a lower bound\non the mutual information between intermediate and global feature\nrepresentations from the teacher and the student networks. Our method is\nflexible, as the proposed mutual information maximization does not impose\nsignificant constraints on the structure of the intermediate features of the\nnetworks. As such, we can distill knowledge from arbitrary teachers to\narbitrary students. Our empirical results show that our method outperforms\ncompeting approaches across a wide range of student-teacher pairs with\ndifferent capacities, with different architectures, and when student networks\nare with extremely low capacity. We are able to obtain 74.55% accuracy on\nCIFAR100 with a ShufflenetV2 from a baseline accuracy of 69.8% by distilling\nknowledge from ResNet50.",
    "descriptor": "",
    "authors": [
      "Aman Shrivastava",
      "Yanjun Qi",
      "Vicente Ordonez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.15946"
  },
  {
    "id": "arXiv:2110.15949",
    "title": "Sparsely Changing Latent States for Prediction and Planning in Partially  Observable Domains",
    "abstract": "A common approach to prediction and planning in partially observable domains\nis to use recurrent neural networks (RNNs), which ideally develop and maintain\na latent memory about hidden, task-relevant factors. We hypothesize that many\nof these hidden factors in the physical world are constant over time, changing\nonly sparsely. Accordingly, we propose Gated $L_0$ Regularized Dynamics\n(GateL0RD), a novel recurrent architecture that incorporates the inductive bias\nto maintain stable, sparsely changing latent states. The bias is implemented by\nmeans of a novel internal gating function and a penalty on the $L_0$ norm of\nlatent state changes. We demonstrate that GateL0RD can compete with or\noutperform state-of-the-art RNNs in a variety of partially observable\nprediction and control tasks. GateL0RD tends to encode the underlying\ngenerative factors of the environment, ignores spurious temporal dependencies,\nand generalizes better, improving sampling efficiency and prediction accuracy\nas well as behavior in model-based planning and reinforcement learning tasks.\nMoreover, we show that the developing latent states can be easily interpreted,\nwhich is a step towards better explainability in RNNs.",
    "descriptor": "",
    "authors": [
      "Christian Gumbsch",
      "Martin V. Butz",
      "Georg Martius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15949"
  },
  {
    "id": "arXiv:2110.15952",
    "title": "On the Performance of Multihop THz Wireless System Over Mixed Channel  Fading with Shadowing and Antenna Misalignment",
    "abstract": "The existing relay-assisted terahertz (THz) wireless system is limited to\ndual-hop transmission with pointing errors and short-term fading without\nconsidering the shadowing effect. This paper analyzes the performance of a\nmultihop-assisted backhaul communication mixed with an access link under the\nshadowed fading with antenna misalignment errors. We derive statistical results\nof the signal-to-noise ratio (SNR) of the multihop link by considering\nindependent but not identically distributed (i.ni.d) $\\alpha$-$\\mu$ fading\nchannel with pointing errors employing channel-assisted (CA) and fixed-gain\n(FG) amplify-and-forward (AF) relaying for each hop. We analyze the outage\nprobability, average BER, and ergodic capacity performance of the mixed system\nconsidering the generalized-$K$ shadowed fading model with AF and\ndecode-and-forward (DF) protocols employed for the access link. We derive exact\nexpressions of the performance metrics for the CA-multihop system with the DF\nrelaying for the last hop and upper bound of the performance for the\nFG-multihop system using FG and DF relaying at the last relay. We also develop\nasymptotic analysis in the high SNR to derive the diversity order of the system\nand use computer simulations to provide design and deployment aspects of\nmultiple relays in the backhaul link to extend the communication range for THz\nwireless transmissions.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Pranay Bhardwaj",
      "S. M. Zafaruddin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15952"
  },
  {
    "id": "arXiv:2110.15954",
    "title": "Limiting fluctuation and trajectorial stability of multilayer neural  networks with mean field training",
    "abstract": "The mean field (MF) theory of multilayer neural networks centers around a\nparticular infinite-width scaling, where the learning dynamics is closely\ntracked by the MF limit. A random fluctuation around this infinite-width limit\nis expected from a large-width expansion to the next order. This fluctuation\nhas been studied only in shallow networks, where previous works employ heavily\ntechnical notions or additional formulation ideas amenable only to that case.\nTreatment of the multilayer case has been missing, with the chief difficulty in\nfinding a formulation that captures the stochastic dependency across not only\ntime but also depth.\nIn this work, we initiate the study of the fluctuation in the case of\nmultilayer networks, at any network depth. Leveraging on the neuronal embedding\nframework recently introduced by Nguyen and Pham, we systematically derive a\nsystem of dynamical equations, called the second-order MF limit, that captures\nthe limiting fluctuation distribution. We demonstrate through the framework the\ncomplex interaction among neurons in this second-order MF limit, the\nstochasticity with cross-layer dependency and the nonlinear time evolution\ninherent in the limiting fluctuation. A limit theorem is proven to relate\nquantitatively this limit to the fluctuation of large-width networks.\nWe apply the result to show a stability property of gradient descent MF\ntraining: in the large-width regime, along the training trajectory, it\nprogressively biases towards a solution with \"minimal fluctuation\" (in fact,\nvanishing fluctuation) in the learned output function, even after the network\nhas been initialized at or has converged (sufficiently fast) to a global\noptimum. This extends a similar phenomenon previously shown only for shallow\nnetworks with a squared loss in the ERM setting, to multilayer networks with a\nloss function that is not necessarily convex in a more general setting.",
    "descriptor": "\nComments: 57 pages, 5 figures, NeurIPS 2021\n",
    "authors": [
      "Huy Tuan Pham",
      "Phan-Minh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15954"
  },
  {
    "id": "arXiv:2110.15956",
    "title": "A deep convolutional neural network for classification of Aedes  albopictus mosquitoes",
    "abstract": "Monitoring the spread of disease-carrying mosquitoes is a first and necessary\nstep to control severe diseases such as dengue, chikungunya, Zika or yellow\nfever. Previous citizen science projects have been able to obtain large image\ndatasets with linked geo-tracking information. As the number of international\ncollaborators grows, the manual annotation by expert entomologists of the large\namount of data gathered by these users becomes too time demanding and\nunscalable, posing a strong need for automated classification of mosquito\nspecies from images. We introduce the application of two Deep Convolutional\nNeural Networks in a comparative study to automate this classification task. We\nuse the transfer learning principle to train two state-of-the-art architectures\non the data provided by the Mosquito Alert project, obtaining testing accuracy\nof 94%. In addition, we applied explainable models based on the Grad-CAM\nalgorithm to visualise the most discriminant regions of the classified images,\nwhich coincide with the white band stripes located at the legs, abdomen, and\nthorax of mosquitoes of the Aedes albopictus species. The model allows us to\nfurther analyse the classification errors. Visual Grad-CAM models show that\nthey are linked to poor acquisition conditions and strong image occlusions.",
    "descriptor": "",
    "authors": [
      "Gereziher Adhane",
      "Mohammad Mahdi Dehshibi",
      "David Masip"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15956"
  },
  {
    "id": "arXiv:2110.15957",
    "title": "Visual Keyword Spotting with Attention",
    "abstract": "In this paper, we consider the task of spotting spoken keywords in silent\nvideo sequences -- also known as visual keyword spotting. To this end, we\ninvestigate Transformer-based models that ingest two streams, a visual encoding\nof the video and a phonetic encoding of the keyword, and output the temporal\nlocation of the keyword if present. Our contributions are as follows: (1) We\npropose a novel architecture, the Transpotter, that uses full cross-modal\nattention between the visual and phonetic streams; (2) We show through\nextensive evaluations that our model outperforms the prior state-of-the-art\nvisual keyword spotting and lip reading methods on the challenging LRW, LRS2,\nLRS3 datasets by a large margin; (3) We demonstrate the ability of our model to\nspot words under the extreme conditions of isolated mouthings in sign language\nvideos.",
    "descriptor": "\nComments: Appears in: British Machine Vision Conference 2021 (BMVC 2021)\n",
    "authors": [
      "K R Prajwal",
      "Liliane Momeni",
      "Triantafyllos Afouras",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15957"
  },
  {
    "id": "arXiv:2110.15363",
    "title": "Dual-band Harmonic and Subharmonic Frequency Generation Circuitry for  Joint Communication and Localization Applications Under Severe Multipath  Environment",
    "abstract": "The next generation of ultra-dense connected and automated wireless sensor\nnetworks (WSN) requires proximity intelligence for many of its applications,\nespecially for identification and localization. This work presents the first\nbidirectional circuitry for Internet of Things (IoT) transponder that\nreciprocally generates harmonics and subharmonics, dual-band frequencies. A\nmulti-band or wideband localization system is essential for future intelligent\nWSN to mitigate the influence of multipath signals for indoor dense\nenvironment. The proposed frequency generation circuitry is based on the novel\nnonlinear ring resonator (NRR) operating based on standing wave resonation. The\nproposed NRR generates two sustainable oscillation frequencies based on the\nperiodicity of the nonlinear circuit in the ring configuration. Due to the\nsymmetry and reciprocity of the ring layout, the two bidirectional ports can\nexcite the circuit at the two opposite nodes while maintaining the required\nboundary conditions for oscillation. The sustainable resonance conditions occur\nby creating zero, short impedance, or pole, infinite impedance, at subharmonic\nand harmonic excitation ports. The NRR circuit consumes zero DC power and\ncovers two communication frequency plans interchangeably, which makes it a\npremier technique compared to the conventional ultra-wideband (UWB)\nlocalization system and conventional single-band nonlinear passive circuitry.\nThe latter is narrowband due to the tunning limitation of the nonlinear\nvaractor while the former is power-hungry approach with complex hardware\nrequirements.",
    "descriptor": "",
    "authors": [
      "Payman Pahlavan",
      "Najme Ebrahimi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.15363"
  },
  {
    "id": "arXiv:2110.15412",
    "title": "Stochastic Mirror Descent: Convergence Analysis and Adaptive Variants  via the Mirror Stochastic Polyak Stepsize",
    "abstract": "We investigate the convergence of stochastic mirror descent (SMD) in\nrelatively smooth and smooth convex optimization. In relatively smooth convex\noptimization we provide new convergence guarantees for SMD with a constant\nstepsize. For smooth convex optimization we propose a new adaptive stepsize\nscheme -- the mirror stochastic Polyak stepsize (mSPS). Notably, our\nconvergence results in both settings do not make bounded gradient assumptions\nor bounded variance assumptions, and we show convergence to a neighborhood that\nvanishes under interpolation. mSPS generalizes the recently proposed stochastic\nPolyak stepsize (SPS) (Loizou et al., 2021) to mirror descent and remains both\npractical and efficient for modern machine learning applications while\ninheriting the benefits of mirror descent. We complement our results with\nexperiments across various supervised learning tasks and different instances of\nSMD, demonstrating the effectiveness of mSPS.",
    "descriptor": "",
    "authors": [
      "Ryan D'Orazio",
      "Nicolas Loizou",
      "Issam Laradji",
      "Ioannis Mitliagkas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15412"
  },
  {
    "id": "arXiv:2110.15424",
    "title": "Physics-Driven Learning of Wasserstein GAN for Density Reconstruction in  Dynamic Tomography",
    "abstract": "Object density reconstruction from projections containing scattered radiation\nand noise is of critical importance in many applications. Existing scatter\ncorrection and density reconstruction methods may not provide the high accuracy\nneeded in many applications and can break down in the presence of unmodeled or\nanomalous scatter and other experimental artifacts. Incorporating\nmachine-learned models could prove beneficial for accurate density\nreconstruction particularly in dynamic imaging, where the time-evolution of the\ndensity fields could be captured by partial differential equations or by\nlearning from hydrodynamics simulations. In this work, we demonstrate the\nability of learned deep neural networks to perform artifact removal in noisy\ndensity reconstructions, where the noise is imperfectly characterized. We use a\nWasserstein generative adversarial network (WGAN), where the generator serves\nas a denoiser that removes artifacts in densities obtained from traditional\nreconstruction algorithms. We train the networks from large density time-series\ndatasets, with noise simulated according to parametric random distributions\nthat may mimic noise in experiments. The WGAN is trained with noisy density\nframes as generator inputs, to match the generator outputs to the distribution\nof clean densities (time-series) from simulations. A supervised loss is also\nincluded in the training, which leads to improved density restoration\nperformance. In addition, we employ physics-based constraints such as mass\nconservation during network training and application to further enable highly\naccurate density reconstructions. Our preliminary numerical results show that\nthe models trained in our frameworks can remove significant portions of unknown\nnoise in density time-series data.",
    "descriptor": "",
    "authors": [
      "Zhishen Huang",
      "Marc Klasky",
      "Trevor Wilcox",
      "Saiprasad Ravishankar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15424"
  },
  {
    "id": "arXiv:2110.15449",
    "title": "Privacy Preserving Inference on the Ratio of Two Gaussians Using  (Weighted) Sums",
    "abstract": "The ratio of two Gaussians is useful in many contexts of statistical\ninference. We discuss statistically valid inference of the ratio estimator\nunder Differential Privacy (DP). We use the delta method to derive the\nasymptotic distribution of the ratio estimator and use the Gaussian mechanism\nto provide $(\\epsilon, \\delta)$ privacy guarantees. Like many statistics, the\nquantities needed here can be re-written as functions of sums, and sums are\neasy to work with for many reasons. In the DP case, the sensitivity of a sum\ncan be easily obtained. We focus on the coverage of 95\\% confidence intervals\n(CIs). Our simulations shows that the no correction method, which ignores the\nnoise mechanism, gives CIs that are too narrow to provide proper coverage for\nsmall samples. We propose two methods to mitigate the under-coverage issue, one\nbased on Monte Carlo simulations and the other based on analytical correction.\nWe show that the CIs of our methods have the right coverage with proper privacy\nbudget. In addition, our methods can handle weighted data, where the weights\nare fixed and bounded.",
    "descriptor": "",
    "authors": [
      "Jingang Miao",
      "Yiming Paul Li"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Cryptography and Security (cs.CR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.15449"
  },
  {
    "id": "arXiv:2110.15458",
    "title": "Open Problem: Tight Online Confidence Intervals for RKHS Elements",
    "abstract": "Confidence intervals are a crucial building block in the analysis of various\nonline learning problems. The analysis of kernel based bandit and reinforcement\nlearning problems utilize confidence intervals applicable to the elements of a\nreproducing kernel Hilbert space (RKHS). However, the existing confidence\nbounds do not appear to be tight, resulting in suboptimal regret bounds. In\nfact, the existing regret bounds for several kernelized bandit algorithms\n(e.g., GP-UCB, GP-TS, and their variants) may fail to even be sublinear. It is\nunclear whether the suboptimal regret bound is a fundamental shortcoming of\nthese algorithms or an artifact of the proof, and the main challenge seems to\nstem from the online (sequential) nature of the observation points. We\nformalize the question of online confidence intervals in the RKHS setting and\noverview the existing results.",
    "descriptor": "",
    "authors": [
      "Sattar Vakili",
      "Jonathan Scarlett",
      "Tara Javidi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.15458"
  },
  {
    "id": "arXiv:2110.15466",
    "title": "On the complexity of quantum partition functions",
    "abstract": "The partition function and free energy of a quantum many-body system\ndetermine its physical properties in thermal equilibrium. Here we study the\ncomputational complexity of approximating these quantities for $n$-qubit local\nHamiltonians. First, we report a classical algorithm with $\\mathrm{poly}(n)$\nruntime which approximates the free energy of a given $2$-local Hamiltonian\nprovided that it satisfies a certain denseness condition. Our algorithm\ncombines the variational characterization of the free energy and convex\nrelaxation methods. It contributes to a body of work on efficient approximation\nalgorithms for dense instances of optimization problems which are hard in the\ngeneral case, and can be viewed as simultaneously extending existing algorithms\nfor (a) the ground energy of dense $2$-local Hamiltonians, and (b) the free\nenergy of dense classical Ising models. Secondly, we establish polynomial-time\nequivalence between the problem of approximating the free energy of local\nHamiltonians and three other natural quantum approximate counting problems,\nincluding the problem of approximating the number of witness states accepted by\na QMA verifier. These results suggest that simulation of quantum many-body\nsystems in thermal equilibrium may precisely capture the complexity of a broad\nfamily of computational problems that has yet to be defined or characterized in\nterms of known complexity classes. Finally, we summarize state-of-the-art\nclassical and quantum algorithms for approximating the free energy and show how\nto improve their runtime and memory footprint.",
    "descriptor": "",
    "authors": [
      "Sergey Bravyi",
      "Anirban Chowdhury",
      "David Gosset",
      "Pawel Wocjan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.15466"
  },
  {
    "id": "arXiv:2110.15486",
    "title": "DOCKSTRING: easy molecular docking yields better benchmarks for ligand  design",
    "abstract": "The field of machine learning for drug discovery is witnessing an explosion\nof novel methods. These methods are often benchmarked on simple physicochemical\nproperties such as solubility or general druglikeness, which can be readily\ncomputed. However, these properties are poor representatives of objective\nfunctions in drug design, mainly because they do not depend on the candidate's\ninteraction with the target. By contrast, molecular docking is a widely\nsuccessful method in drug discovery to estimate binding affinities. However,\ndocking simulations require a significant amount of domain knowledge to set up\ncorrectly which hampers adoption. To this end, we present DOCKSTRING, a bundle\nfor meaningful and robust comparison of ML models consisting of three\ncomponents: (1) an open-source Python package for straightforward computation\nof docking scores; (2) an extensive dataset of docking scores and poses of more\nthan 260K ligands for 58 medically-relevant targets; and (3) a set of\npharmaceutically-relevant benchmark tasks including regression, virtual\nscreening, and de novo design. The Python package implements a robust ligand\nand target preparation protocol that allows non-experts to obtain meaningful\ndocking scores. Our dataset is the first to include docking poses, as well as\nthe first of its size that is a full matrix, thus facilitating experiments in\nmultiobjective optimization and transfer learning. Overall, our results\nindicate that docking scores are a more appropriate evaluation objective than\nsimple physicochemical properties, yielding more realistic benchmark tasks and\nmolecular candidates.",
    "descriptor": "",
    "authors": [
      "Miguel Garc\u00eda-Orteg\u00f3n",
      "Gregor N. C. Simm",
      "Austin J. Tripp",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
      "Andreas Bender",
      "Sergio Bacallado"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2110.15486"
  },
  {
    "id": "arXiv:2110.15493",
    "title": "Comment on \"Failure of the simultaneous block diagonalization technique  applied to complete and cluster synchronization of random networks\"",
    "abstract": "In their recent preprint [arXiv:2108.07893v1], S. Panahi, N. Amaya, I.\nKlickstein, G. Novello, and F. Sorrentino tested the simultaneous block\ndiagonalization (SBD) technique on synchronization in random networks and found\nthe dimensionality reduction to be limited. Based on this observation, they\nclaimed the SBD technique to be a failure in generic situations. Here, we show\nthat this is not a failure of the SBD technique. Rather, it is caused by\ninappropriate choices of network models. SBD provides a unified framework to\nanalyze the stability of synchronization patterns that are not encumbered by\nsymmetry considerations, and it always finds the optimal reduction for any\ngiven synchronization pattern and network structure [SIAM Rev. 62, 817-836\n(2020)]. The networks considered by Panahi et al. are poor benchmarks for the\nperformance of the SBD technique, as these systems are often intrinsically\nirreducible, regardless of the method used. Thus, although the results in\nPanahi et al. are technically valid, their interpretations are misleading and\nakin to claiming a community detection algorithm to be a failure because it\ndoes not find any meaningful communities in Erd\\H{o}s-R\\'enyi networks.",
    "descriptor": "",
    "authors": [
      "Yuanzhao Zhang"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2110.15493"
  },
  {
    "id": "arXiv:2110.15501",
    "title": "Doubly Robust Interval Estimation for Optimal Policy Evaluation in  Online Learning",
    "abstract": "Evaluating the performance of an ongoing policy plays a vital role in many\nareas such as medicine and economics, to provide crucial instruction on the\nearly-stop of the online experiment and timely feedback from the environment.\nPolicy evaluation in online learning thus attracts increasing attention by\ninferring the mean outcome of the optimal policy (i.e., the value) in\nreal-time. Yet, such a problem is particularly challenging due to the dependent\ndata generated in the online environment, the unknown optimal policy, and the\ncomplex exploration and exploitation trade-off in the adaptive experiment. In\nthis paper, we aim to overcome these difficulties in policy evaluation for\nonline learning. We explicitly derive the probability of exploration that\nquantifies the probability of exploring the non-optimal actions under commonly\nused bandit algorithms. We use this probability to conduct valid inference on\nthe online conditional mean estimator under each action and develop the doubly\nrobust interval estimation (DREAM) method to infer the value under the\nestimated optimal policy in online learning. The proposed value estimator\nprovides double protection on the consistency and is asymptotically normal with\na Wald-type confidence interval provided. Extensive simulations and real data\napplications are conducted to demonstrate the empirical validity of the\nproposed DREAM method.",
    "descriptor": "",
    "authors": [
      "Hengrui Cai",
      "Ye Shen",
      "Rui Song"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.15501"
  },
  {
    "id": "arXiv:2110.15504",
    "title": "A Remark on Random Vectors and Irreducible Representations",
    "abstract": "It was observed in [1] that the expectation of a squared scalar product of\ntwo random independent unit vectors that are uniformly distributed on the unit\nsphere in $R^n $ is equal to $1/n$. It is shown in this paper, that this is a\ncharacteristic property of random vectors defined on invariant probability\nsubspaces of unit spheres in irreducible real representations of compact Lie\ngroups.",
    "descriptor": "",
    "authors": [
      "Alexander Kushkuley"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2110.15504"
  },
  {
    "id": "arXiv:2110.15513",
    "title": "Generalization of bibliographic coupling and co-citation using the node  split network",
    "abstract": "Bibliographic coupling (BC) and co-citation (CC) are the two most common\ncitation-based coupling measures of similarity between scientific items. One\ncan interpret these measures as second-neighbor relations distinguished by the\ndirection of the citation: BC is a similarity between two citing items, whereas\nCC is that between two cited items. A previous study proposed a two-layer node\nsplit network that can emulate clusters of coupling measures in a\ncomputationally efficient manner; however, the lack of intralayer links makes\nit impossible to obtain exact similarities. Here, we propose novel methods to\nestimate intralayer similarity on a node split network using personalized\nPageRank and neural embedding. We demonstrate that the proposed measures are\nstrongly correlated with the coupling measures. Moreover, our proposed method\ncan yield precise similarities between items even if they are distant from each\nother. We also show that many links with high similarity are missing in the\noriginal BC/CC network, which suggests that it is essential to consider\nlong-range similarities. Comparative experiments on global and local edge\nsampling suggest that local sampling is stable for both similarities in node\nsplit networks. This analysis offers valuable insights into the process of\nsearching for significantly related items regarding each coupling measure.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Jinhyuk Yun"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2110.15513"
  },
  {
    "id": "arXiv:2110.15523",
    "title": "Sampling low-spectrum signals on graphs via cluster-concentrated modes:  examples",
    "abstract": "We establish frame inequalities for signals in Paley--Wiener spaces on two\nspecific families of graphs consisting of combinations of cubes and cycles. The\nframe elements are localizations to cubes, regarded as clusters in the graphs,\nof vertex functions that are eigenvectors of certain spatio--spectral limiting\noperators on graph signals.",
    "descriptor": "",
    "authors": [
      "Joseph D. Lakey",
      "Jeffrey A. Hogan"
    ],
    "subjectives": [
      "Spectral Theory (math.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.15523"
  },
  {
    "id": "arXiv:2110.15550",
    "title": "New Step-Size Criterion for the Steepest Descent based on Geometric  Numerical Integration",
    "abstract": "This paper deals with unconstrained optimization problems based on numerical\nanalysis of ordinary differential equations (ODEs). Although it has been known\nfor a long time that there is a relation between optimization methods and\ndiscretization of ODEs, research in this direction has recently been gaining\nattention. In recent studies, the dissipation laws of ODEs have often played an\nimportant role. By contrast, in the context of numerical analysis, a technique\ncalled geometric numerical integration, which explores discretization to\nmaintain geometrical properties such as the dissipation law, is actively\nstudied. However, in research investigating the relationship between\noptimization and ODEs, techniques of geometric numerical integration have not\nbeen sufficiently investigated. In this paper, we show that a recent geometric\nnumerical integration technique for gradient flow reads a new step-size\ncriterion for the steepest descent method. Consequently, owing to the discrete\ndissipation law, convergence rates can be proved in a form similar to the\ndiscussion in ODEs. Although the proposed method is a variant of the existing\nsteepest descent method, it is suggested that various analyses of the\noptimization methods via ODEs can be performed in the same way after\ndiscretization using geometric numerical integration.",
    "descriptor": "",
    "authors": [
      "Kenya Onuma",
      "Shun Sato"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15550"
  },
  {
    "id": "arXiv:2110.15558",
    "title": "AI-Powered Semantic Segmentation and Fluid Volume Calculation of Lung CT  images in Covid-19 Patients",
    "abstract": "COVID-19 pandemic is a deadly disease spreading very fast. People with the\nconfronted immune system are susceptible to many health conditions. A highly\nsignificant condition is pneumonia, which is found to be the cause of death in\nthe majority of patients. The main purpose of this study is to find the volume\nof GGO and consolidation of a covid-19 patient so that the physicians can\nprioritize the patients. Here we used transfer learning techniques for\nsegmentation of lung CTs with the latest libraries and techniques which reduces\ntraining time and increases the accuracy of the AI Model. This system is\ntrained with DeepLabV3+ network architecture and model Resnet50 with Imagenet\nweights. We used different augmentation techniques like Gaussian Noise,\nHorizontal shift, color variation, etc to get to the result. Intersection over\nUnion(IoU) is used as the performance metrics. The IoU of lung masks is\npredicted as 99.78% and that of infected masks is as 89.01%. Our work\neffectively measures the volume of infected region by calculating the volume of\ninfected and lung mask region of the patients.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Sabeerali K.P",
      "Saleena T.S",
      "Dr.Muhamed Ilyas P",
      "Dr. Neha Mohan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15558"
  },
  {
    "id": "arXiv:2110.15560",
    "title": "Low-Complexity Geometrical Shaping for 4D Modulation Formats via  Amplitude Coding",
    "abstract": "Signal shaping is vital to approach Shannon's capacity, yet it is challenging\nto implement at very high speeds. For example, probabilistic shaping often\nrequires arithmetic coding to realize the target distribution. Geometric\nshaping requires look-up tables to store the constellation points. In this\npaper, we propose a four-dimensional amplitude coding (4D-AC) geometrical\nshaper architecture. The proposed architecture can generate in real time\ngeometrically shaped 4D formats via simple logic circuit operations and two\nconventional quadrature amplitude modulation (QAM) modulators. This paper\ndescribes the 4D-AC used in generating approximated versions of two recently\nproposed 4D orthant symmetric modulation formats with spectral efficiencies of\n6 bit/4D-sym and 7 bit/4D-sym, respectively. Numerical results show losses\nbelow 0.05 dB when compared against the baseline formats.",
    "descriptor": "\nComments: 4 pages, 5 figures, Accepted by IEEE Photonics Technology Letter\n",
    "authors": [
      "Bin Chen",
      "Wei Ling",
      "Yunus Can G\u00fcltekin",
      "Yi Lei",
      "Chigo Okonkwo",
      "Alex Alvarado"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.15560"
  },
  {
    "id": "arXiv:2110.15568",
    "title": "Unsupervised PET Reconstruction from a Bayesian Perspective",
    "abstract": "Positron emission tomography (PET) reconstruction has become an ill-posed\ninverse problem due to low-count projection data, and a robust algorithm is\nurgently required to improve imaging quality. Recently, the deep image prior\n(DIP) has drawn much attention and has been successfully applied in several\nimage restoration tasks, such as denoising and inpainting, since it does not\nneed any labels (reference image). However, overfitting is a vital defect of\nthis framework. Hence, many methods have been proposed to mitigate this\nproblem, and DeepRED is a typical representation that combines DIP and\nregularization by denoising (RED). In this article, we leverage DeepRED from a\nBayesian perspective to reconstruct PET images from a single corrupted sinogram\nwithout any supervised or auxiliary information. In contrast to the\nconventional denoisers customarily used in RED, a DnCNN-like denoiser, which\ncan add an adaptive constraint to DIP and facilitate the computation of\nderivation, is employed. Moreover, to further enhance the regularization,\nGaussian noise is injected into the gradient updates, deriving a Markov chain\nMonte Carlo (MCMC) sampler. Experimental studies on brain and whole-body\ndatasets demonstrate that our proposed method can achieve better performance in\nterms of qualitative and quantitative results compared to several classic and\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Chenyu Shen",
      "Wenjun Xia",
      "Hongwei Ye",
      "Mingzheng Hou",
      "Hu Chen",
      "Yan Liu",
      "Jiliu Zhou",
      "Yi Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15568"
  },
  {
    "id": "arXiv:2110.15573",
    "title": "A/B/n Testing with Control in the Presence of Subpopulations",
    "abstract": "Motivated by A/B/n testing applications, we consider a finite set of\ndistributions (called \\emph{arms}), one of which is treated as a\n\\emph{control}. We assume that the population is stratified into homogeneous\nsubpopulations. At every time step, a subpopulation is sampled and an arm is\nchosen: the resulting observation is an independent draw from the arm\nconditioned on the subpopulation. The quality of each arm is assessed through a\nweighted combination of its subpopulation means. We propose a strategy for\nsequentially choosing one arm per time step so as to discover as fast as\npossible which arms, if any, have higher weighted expectation than the control.\nThis strategy is shown to be asymptotically optimal in the following sense: if\n$\\tau_\\delta$ is the first time when the strategy ensures that it is able to\noutput the correct answer with probability at least $1-\\delta$, then\n$\\mathbb{E}[\\tau_\\delta]$ grows linearly with $\\log(1/\\delta)$ at the exact\noptimal rate. This rate is identified in the paper in three different settings:\n(1) when the experimenter does not observe the subpopulation information, (2)\nwhen the subpopulation of each sample is observed but not chosen, and (3) when\nthe experimenter can select the subpopulation from which each response is\nsampled. We illustrate the efficiency of the proposed strategy with numerical\nsimulations on synthetic and real data collected from an A/B/n experiment.",
    "descriptor": "",
    "authors": [
      "Yoan Russac",
      "Christina Katsimerou",
      "Dennis Bohle",
      "Olivier Capp\u00e9",
      "Aur\u00e9lien Garivier",
      "Wouter Koolen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15573"
  },
  {
    "id": "arXiv:2110.15581",
    "title": "SA-SDR: A novel loss function for separation of meeting style data",
    "abstract": "Many state-of-the-art neural network-based source separation systems use the\naveraged Signal-to-Distortion Ratio (SDR) as a training objective function. The\nbasic SDR is, however, undefined if the network reconstructs the reference\nsignal perfectly or if the reference signal contains silence, e.g., when a\ntwo-output separator processes a single-speaker recording. Many modifications\nto the plain SDR have been proposed that trade-off between making the loss more\nrobust and distorting its value. We propose to switch from a mean over the SDRs\nof each individual output channel to a global SDR over all output channels at\nthe same time, which we call source-aggregated SDR (SA-SDR). This makes the\nloss robust against silence and perfect reconstruction as long as at least one\nreference signal is not silent. We experimentally show that our proposed SA-SDR\nis more stable and preferable over other well-known modifications when\nprocessing meeting-style data that typically contains many silent or\nsingle-speaker regions.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Thilo von Neumann",
      "Keisuke Kinoshita",
      "Christoph Boeddeker",
      "Marc Delcroix",
      "Reinhold Haeb-Umbach"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.15581"
  },
  {
    "id": "arXiv:2110.15587",
    "title": "A sublinear time quantum algorithm for s-t minimum cut on dense simple  graphs",
    "abstract": "An $s{\\operatorname{-}}t$ minimum cut in a graph corresponds to a minimum\nweight subset of edges whose removal disconnects vertices $s$ and $t$. Finding\nsuch a cut is a classic problem that is dual to that of finding a maximum flow\nfrom $s$ to $t$. In this work we describe a quantum algorithm for the minimum\n$s{\\operatorname{-}}t$ cut problem on undirected graphs. For an undirected\ngraph with $n$ vertices, $m$ edges, and integral edge weights bounded by $W$,\nthe algorithm computes with high probability the weight of a minimum\n$s{\\operatorname{-}}t$ cut in time $\\widetilde O(\\sqrt{m} n^{5/6} W^{1/3} +\nn^{5/3} W^{2/3})$, given adjacency list access to $G$. For simple graphs this\nbound is always $\\widetilde O(n^{11/6})$, even in the dense case when $m =\n\\Omega(n^2)$. In contrast, a randomized algorithm must make $\\Omega(m)$ queries\nto the adjacency list of a simple graph $G$ even to decide whether $s$ and $t$\nare connected.",
    "descriptor": "",
    "authors": [
      "Simon Apers",
      "Arinta Auza",
      "Troy Lee"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15587"
  },
  {
    "id": "arXiv:2110.15593",
    "title": "Towards automatic detection and classification of orca (Orcinus orca)  calls using cross-correlation methods",
    "abstract": "Orca (Orcinus orca) is known for complex vocalisation. Their social structure\nconsists of pods and clans sharing unique dialects due to geographic isolation.\nSound type repertoires are fundamental for monitoring orca populations and are\ntypically created visually and aurally. An orca pod occurring in the Ligurian\nSea (Pelagos Sanctuary) in December 2019 provided a unique occasion for\nlong-term recordings. The numerous data collected with the bottom recorder were\nanalysed with a traditional human-driven inspection to create a repertoire of\nthis pod and to compare it to catalogues from different orca populations\n(Icelandic and Antarctic) investigating its origins. Automatic signal detection\nand cross-correlation methods (R package warbleR) were used for the first time\nin orca studies. We found the Pearson cross-correlation method to be efficient\nfor most pairwise calculations (> 85%) but with false positives. One sound type\nfrom our repertoire presented a high positive match (range 0.62-0.67) with one\nfrom the Icelandic catalogue, which was confirmed visually and aurally. Our\nfirst attempt to automatically classify orca sound types presented limitations\ndue to background noise and sound complexity of orca communication. We show\ncross-correlation methods can be a powerful tool for sound type classification\nin combination with conventional methods.",
    "descriptor": "\nComments: 22 pages, 2 figures\n",
    "authors": [
      "Stefano Palmero",
      "Carlo Guidi",
      "Vladimir Kulikovskiy",
      "Matteo Sanguineti",
      "Michele Manghi",
      "Matteo Sommer",
      "Gaia Pesce"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15593"
  },
  {
    "id": "arXiv:2110.15601",
    "title": "Whole Brain Segmentation with Full Volume Neural Network",
    "abstract": "Whole brain segmentation is an important neuroimaging task that segments the\nwhole brain volume into anatomically labeled regions-of-interest. Convolutional\nneural networks have demonstrated good performance in this task. Existing\nsolutions, usually segment the brain image by classifying the voxels, or\nlabeling the slices or the sub-volumes separately. Their representation\nlearning is based on parts of the whole volume whereas their labeling result is\nproduced by aggregation of partial segmentation. Learning and inference with\nincomplete information could lead to sub-optimal final segmentation result. To\naddress these issues, we propose to adopt a full volume framework, which feeds\nthe full volume brain image into the segmentation network and directly outputs\nthe segmentation result for the whole brain volume. The framework makes use of\ncomplete information in each volume and can be implemented easily. An effective\ninstance in this framework is given subsequently. We adopt the $3$D\nhigh-resolution network (HRNet) for learning spatially fine-grained\nrepresentations and the mixed precision training scheme for memory-efficient\ntraining. Extensive experiment results on a publicly available $3$D MRI brain\ndataset show that our proposed model advances the state-of-the-art methods in\nterms of segmentation performance. Source code is publicly available at\nhttps://github.com/microsoft/VoxHRNet.",
    "descriptor": "\nComments: Accepted to CMIG\n",
    "authors": [
      "Yeshu Li",
      "Jonathan Cui",
      "Yilun Sheng",
      "Xiao Liang",
      "Jingdong Wang",
      "Eric I-Chao Chang",
      "Yan Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15601"
  },
  {
    "id": "arXiv:2110.15664",
    "title": "3D-OOCS: Learning Prostate Segmentation with Inductive Bias",
    "abstract": "Despite the great success of convolutional neural networks (CNN) in 3D\nmedical image segmentation tasks, the methods currently in use are still not\nrobust enough to the different protocols utilized by different scanners, and to\nthe variety of image properties or artefacts they produce. To this end, we\nintroduce OOCS-enhanced networks, a novel architecture inspired by the innate\nnature of visual processing in the vertebrates. With different 3D U-Net\nvariants as the base, we add two 3D residual components to the second encoder\nblocks: on and off center-surround (OOCS). They generalise the ganglion\npathways in the retina to a 3D setting. The use of 2D-OOCS in any standard CNN\nnetwork complements the feedforward framework with sharp edge-detection\ninductive biases. The use of 3D-OOCS also helps 3D U-Nets to scrutinise and\ndelineate anatomical structures present in 3D images with increased accuracy.We\ncompared the state-of-the-art 3D U-Nets with their 3D-OOCS extensions and\nshowed the superior accuracy and robustness of the latter in automatic prostate\nsegmentation from 3D Magnetic Resonance Images (MRIs). For a fair comparison,\nwe trained and tested all the investigated 3D U-Nets with the same pipeline,\nincluding automatic hyperparameter optimisation and data augmentation.",
    "descriptor": "",
    "authors": [
      "Shrajan Bhandary",
      "Zahra Babaiee",
      "Dejan Kostyszyn",
      "Tobias Fechter",
      "Constantinos Zamboglou",
      "Anca Grosu",
      "Radu Grosu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15664"
  },
  {
    "id": "arXiv:2110.15667",
    "title": "QDCNN: Quantum Dilated Convolutional Neural Network",
    "abstract": "In recent years, with rapid progress in the development of quantum\ntechnologies, quantum machine learning has attracted a lot of interest. In\nparticular, a family of hybrid quantum-classical neural networks, consisting of\nclassical and quantum elements, has been massively explored for the purpose of\nimproving the performance of classical neural networks. In this paper, we\npropose a novel hybrid quantum-classical algorithm called quantum dilated\nconvolutional neural networks (QDCNNs). Our method extends the concept of\ndilated convolution, which has been widely applied in modern deep learning\nalgorithms, to the context of hybrid neural networks. The proposed QDCNNs are\nable to capture larger context during the quantum convolution process while\nreducing the computational cost. We perform empirical experiments on MNIST and\nFashion-MNIST datasets for the task of image recognition and demonstrate that\nQDCNN models generally enjoy better performances in terms of both accuracy and\ncomputation efficiency compared to existing quantum convolutional neural\nnetworks (QCNNs).",
    "descriptor": "\nComments: 7 pages, 1 figure\n",
    "authors": [
      "Yixiong Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15667"
  },
  {
    "id": "arXiv:2110.15672",
    "title": "Improved FRQI on superconducting processors and its restrictions in the  NISQ era",
    "abstract": "In image processing, the amount of data to be processed grows rapidly, in\nparticular when imaging methods yield images of more than two dimensions or\ntime series of images. Thus, efficient processing is a challenge, as data sizes\nmay push even supercomputers to their limits. Quantum image processing promises\nto encode images with logarithmically less qubits than classical pixels in the\nimage. In theory, this is a huge progress, but so far not many experiments have\nbeen conducted in practice, in particular on real backends. Often, the precise\nconversion of classical data to quantum states, the exact implementation, and\nthe interpretation of the measurements in the classical context are\nchallenging. We investigate these practical questions in this paper. In\nparticular, we study the feasibility of the Flexible Representation of Quantum\nImages (FRQI). Furthermore, we check experimentally what is the limit in the\ncurrent noisy intermediate-scale quantum era, i.e. up to which image size an\nimage can be encoded, both on simulators and on real backends. Finally, we\npropose a method for simplifying the circuits needed for the FRQI. With our\nalteration, the number of gates needed, especially of the error-prone\ncontrolled-NOT gates, can be reduced. As a consequence, the size of manageable\nimages increases.",
    "descriptor": "\nComments: The paper is submitted in the journal Quantum Information Processing with manuscript number QINP-D-21-00710 (26.10.2021)\n",
    "authors": [
      "Alexander Geng",
      "Ali Moghiseh",
      "Claudia Redenbach",
      "Katja Schladitz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.15672"
  },
  {
    "id": "arXiv:2110.15684",
    "title": "Fusing ASR Outputs in Joint Training for Speech Emotion Recognition",
    "abstract": "Alongside acoustic information, linguistic features based on speech\ntranscripts have been proven useful in Speech Emotion Recognition (SER).\nHowever, due to the scarcity of emotion labelled data and the difficulty of\nrecognizing emotional speech, it is hard to obtain reliable linguistic features\nand models in this research area. In this paper, we propose to fuse Automatic\nSpeech Recognition (ASR) outputs into the pipeline for joint training SER. The\nrelationship between ASR and SER is understudied, and it is unclear what and\nhow ASR features benefit SER. By examining various ASR outputs and fusion\nmethods, our experiments show that in joint ASR-SER training, incorporating\nboth ASR hidden and text output using a hierarchical co-attention fusion\napproach improves the SER performance the most. On the IEMOCAP corpus, our\napproach achieves 63.4% weighted accuracy, which is close to the baseline\nresults achieved by combining ground-truth transcripts. In addition, we also\npresent novel word error rate analysis on IEMOCAP and layer-difference analysis\nof the Wav2vec 2.0 model to better understand the relationship between ASR and\nSER.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Yuanchao Li",
      "Peter Bell",
      "Catherine Lai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.15684"
  },
  {
    "id": "arXiv:2110.15688",
    "title": "Variational Bayesian Optimistic Sampling",
    "abstract": "We consider online sequential decision problems where an agent must balance\nexploration and exploitation. We derive a set of Bayesian `optimistic' policies\nwhich, in the stochastic multi-armed bandit case, includes the Thompson\nsampling policy. We provide a new analysis showing that any algorithm producing\npolicies in the optimistic set enjoys $\\tilde O(\\sqrt{AT})$ Bayesian regret for\na problem with $A$ actions after $T$ rounds. We extend the regret analysis for\noptimistic policies to bilinear saddle-point problems which include zero-sum\nmatrix games and constrained bandits as special cases. In this case we show\nthat Thompson sampling can produce policies outside of the optimistic set and\nsuffer linear regret in some instances. Finding a policy inside the optimistic\nset amounts to solving a convex optimization problem and we call the resulting\nalgorithm `variational Bayesian optimistic sampling' (VBOS). The procedure\nworks for any posteriors, \\ie, it does not require the posterior to have any\nspecial properties, such as log-concavity, unimodality, or smoothness. The\nvariational view of the problem has many useful properties, including the\nability to tune the exploration-exploitation tradeoff, add regularization,\nincorporate constraints, and linearly parameterize the policy.",
    "descriptor": "",
    "authors": [
      "Brendan O'Donoghue",
      "Tor Lattimore"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15688"
  },
  {
    "id": "arXiv:2110.15715",
    "title": "An Effective Image Restorer: Denoising and Luminance Adjustment for  Low-photon-count Imaging",
    "abstract": "Imaging under photon-scarce situations introduces challenges to many\napplications as the captured images are with low signal-to-noise ratio and poor\nluminance. In this paper, we investigate the raw image restoration under\nlow-photon-count conditions by simulating the imaging of quanta image sensor\n(QIS). We develop a lightweight framework, which consists of a multi-level\npyramid denoising network (MPDNet) and a luminance adjustment (LA) module to\nachieve separate denoising and luminance enhancement. The main component of our\nframework is the multi-skip attention residual block (MARB), which integrates\nmulti-scale feature fusion and attention mechanism for better feature\nrepresentation. Our MPDNet adopts the idea of Laplacian pyramid to learn the\nsmall-scale noise map and larger-scale high-frequency details at different\nlevels, and feature extractions are conducted on the multi-scale input images\nto encode richer contextual information. Our LA module enhances the luminance\nof the denoised image by estimating its illumination, which can better avoid\ncolor distortion. Extensive experimental results have demonstrated that our\nimage restorer can achieve superior performance on the degraded images with\nvarious photon levels by suppressing noise and recovering luminance and color\neffectively.",
    "descriptor": "",
    "authors": [
      "Shansi Zhang",
      "Edmund Y. Lam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15715"
  },
  {
    "id": "arXiv:2110.15761",
    "title": "Aligned Multi-Task Gaussian Process",
    "abstract": "Multi-task learning requires accurate identification of the correlations\nbetween tasks. In real-world time-series, tasks are rarely perfectly temporally\naligned; traditional multi-task models do not account for this and subsequent\nerrors in correlation estimation will result in poor predictive performance and\nuncertainty quantification. We introduce a method that automatically accounts\nfor temporal misalignment in a unified generative model that improves\npredictive performance. Our method uses Gaussian processes (GPs) to model the\ncorrelations both within and between the tasks. Building on the previous work\nby Kazlauskaiteet al. [2019], we include a separate monotonic warp of the input\ndata to model temporal misalignment. In contrast to previous work, we formulate\na lower bound that accounts for uncertainty in both the estimates of the\nwarping process and the underlying functions. Also, our new take on a monotonic\nstochastic process, with efficient path-wise sampling for the warp functions,\nallows us to perform full Bayesian inference in the model rather than MAP\nestimates. Missing data experiments, on synthetic and real time-series,\ndemonstrate the advantages of accounting for misalignments (vs standard\nunaligned method) as well as modelling the uncertainty in the warping\nprocess(vs baseline MAP alignment approach).",
    "descriptor": "",
    "authors": [
      "Olga Mikheeva",
      "Ieva Kazlauskaite",
      "Adam Hartshorne",
      "Hedvig Kjellstr\u00f6m",
      "Carl Henrik Ek",
      "Neill D. F. Campbell"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15761"
  },
  {
    "id": "arXiv:2110.15767",
    "title": "Adversarial Robustness with Semi-Infinite Constrained Learning",
    "abstract": "Despite strong performance in numerous applications, the fragility of deep\nlearning to input perturbations has raised serious questions about its use in\nsafety-critical domains. While adversarial training can mitigate this issue in\npractice, state-of-the-art methods are increasingly application-dependent,\nheuristic in nature, and suffer from fundamental trade-offs between nominal\nperformance and robustness. Moreover, the problem of finding worst-case\nperturbations is non-convex and underparameterized, both of which engender a\nnon-favorable optimization landscape. Thus, there is a gap between the theory\nand practice of adversarial training, particularly with respect to when and why\nadversarial training works. In this paper, we take a constrained learning\napproach to address these questions and to provide a theoretical foundation for\nrobust learning. In particular, we leverage semi-infinite optimization and\nnon-convex duality theory to show that adversarial training is equivalent to a\nstatistical problem over perturbation distributions, which we characterize\ncompletely. Notably, we show that a myriad of previous robust training\ntechniques can be recovered for particular, sub-optimal choices of these\ndistributions. Using these insights, we then propose a hybrid Langevin Monte\nCarlo approach of which several common algorithms (e.g., PGD) are special\ncases. Finally, we show that our approach can mitigate the trade-off between\nnominal and robust performance, yielding state-of-the-art results on MNIST and\nCIFAR-10. Our code is available at: https://github.com/arobey1/advbench.",
    "descriptor": "",
    "authors": [
      "Alexander Robey",
      "Luiz F. O. Chamon",
      "George J. Pappas",
      "Hamed Hassani",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15767"
  },
  {
    "id": "arXiv:2110.15811",
    "title": "CVAD: A generic medical anomaly detector based on Cascade VAE",
    "abstract": "Detecting out-of-distribution (OOD) samples in medical imaging plays an\nimportant role for downstream medical diagnosis. However, existing OOD\ndetectors are demonstrated on natural images composed of inter-classes and have\ndifficulty generalizing to medical images. The key issue is the granularity of\nOOD data in the medical domain, where intra-class OOD samples are predominant.\nWe focus on the generalizability of OOD detection for medical images and\npropose a self-supervised Cascade Variational autoencoder-based Anomaly\nDetector (CVAD). We use a variational autoencoders' cascade architecture, which\ncombines latent representation at multiple scales, before being fed to a\ndiscriminator to distinguish the OOD data from the in-distribution (ID) data.\nFinally, both the reconstruction error and the OOD probability predicted by the\nbinary discriminator are used to determine the anomalies. We compare the\nperformance with the state-of-the-art deep learning models to demonstrate our\nmodel's efficacy on various open-access medical imaging datasets for both\nintra- and inter-class OOD. Further extensive results on datasets including\ncommon natural datasets show our model's effectiveness and generalizability.\nThe code is available at https://github.com/XiaoyuanGuo/CVAD.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Xiaoyuan Guo",
      "Judy Wawira Gichoya",
      "Saptarshi Purkayastha",
      "Imon Banerjee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15811"
  },
  {
    "id": "arXiv:2110.15821",
    "title": "Landscape analysis of an improved power method for tensor decomposition",
    "abstract": "In this work, we consider the optimization formulation for symmetric tensor\ndecomposition recently introduced in the Subspace Power Method (SPM) of Kileel\nand Pereira. Unlike popular alternative functionals for tensor decomposition,\nthe SPM objective function has the desirable properties that its maximal value\nis known in advance, and its global optima are exactly the rank-1 components of\nthe tensor when the input is sufficiently low-rank. We analyze the non-convex\noptimization landscape associated with the SPM objective. Our analysis accounts\nfor working with noisy tensors. We derive quantitative bounds such that any\nsecond-order critical point with SPM objective value exceeding the bound must\nequal a tensor component in the noiseless case, and must approximate a tensor\ncomponent in the noisy case. For decomposing tensors of size $D^{\\times m}$, we\nobtain a near-global guarantee up to rank $\\widetilde{o}(D^{\\lfloor m/2\n\\rfloor})$ under a random tensor model, and a global guarantee up to rank\n$\\mathcal{O}(D)$ assuming deterministic frame conditions. This implies that SPM\nwith suitable initialization is a provable, efficient, robust algorithm for\nlow-rank symmetric tensor decomposition. We conclude with numerics that show a\npractical preferability for using the SPM functional over a more established\ncounterpart.",
    "descriptor": "\nComments: 45 pages, 4 figures, Matlab code included as ancillary files, to appear in NeurIPS 2021\n",
    "authors": [
      "Joe Kileel",
      "Timo Klock",
      "Jo\u00e3o M. Pereira"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15821"
  },
  {
    "id": "arXiv:2110.15823",
    "title": "C-MADA: Unsupervised Cross-Modality Adversarial Domain Adaptation  framework for medical Image Segmentation",
    "abstract": "Deep learning models have obtained state-of-the-art results for medical image\nanalysis. However, when these models are tested on an unseen domain there is a\nsignificant performance degradation. In this work, we present an unsupervised\nCross-Modality Adversarial Domain Adaptation (C-MADA) framework for medical\nimage segmentation. C-MADA implements an image- and feature-level adaptation\nmethod in a sequential manner. First, images from the source domain are\ntranslated to the target domain through an un-paired image-to-image adversarial\ntranslation with cycle-consistency loss. Then, a U-Net network is trained with\nthe mapped source domain images and target domain images in an adversarial\nmanner to learn domain-invariant feature representations. Furthermore, to\nimprove the networks segmentation performance, information about the shape,\ntexture, and con-tour of the predicted segmentation is included during the\nadversarial train-ing. C-MADA is tested on the task of brain MRI segmentation,\nobtaining competitive results.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Maria Baldeon-Calisto",
      "Susana K. Lai-Yuen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15823"
  },
  {
    "id": "arXiv:2110.15828",
    "title": "Resampling Base Distributions of Normalizing Flows",
    "abstract": "Normalizing flows are a popular class of models for approximating probability\ndistributions. However, their invertible nature limits their ability to model\ntarget distributions with a complex topological structure, such as Boltzmann\ndistributions. Several procedures have been proposed to solve this problem but\nmany of them sacrifice invertibility and, thereby, tractability of the\nlog-likelihood as well as other desirable properties. To address these\nlimitations, we introduce a base distribution for normalizing flows based on\nlearned rejection sampling, allowing the resulting normalizing flow to model\ncomplex topologies without giving up bijectivity. Furthermore, we develop\nsuitable learning algorithms using both maximizing the log-likelihood and the\noptimization of the reverse Kullback-Leibler divergence, and apply them to\nvarious sample problems, i.e.\\ approximating 2D densities, density estimation\nof tabular data, image generation, and modeling Boltzmann distributions. In\nthese experiments our method is competitive with or outperforms the baselines.",
    "descriptor": "",
    "authors": [
      "Vincent Stimper",
      "Bernhard Sch\u00f6lkopf",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15828"
  },
  {
    "id": "arXiv:2110.15841",
    "title": "Angle Diversity Trasmitter For High Speed Data Center Uplink  Communications",
    "abstract": "This paper proposes an uplink optical wireless communication (OWC) link\ndesign that can be used by data centers to support communication in spine and\nleaf architectures between the top of rack leaf switches and large spine\nswitches whose access points are mounted in the ceiling. The use of optical\nwireless links reduces cabling and allows easy reconfigurability for example\nwhen data centres expand. We consider three racks in a data center where each\nrack contains an Angle Diversity Transmitter (ADT) positioned on the top of the\nrack to realize the uplink function of a top-of-the-rack (ToR) or a leaf\nswitch. Four receivers are considered to be installed on the ceiling where each\nis connected to a spine switch. Two types of optical receivers are studied\nwhich are a Wide Field-of-View Receiver (WFOVR) and an Angle Diversity Receiver\n(ADR). The performance of the proposed system is evaluated when the links run\nat data rates higher than 19 Gbps. The results indicate that the proposed\napproach achieves excellent performance using simple On-Off Keying (OOK)",
    "descriptor": "",
    "authors": [
      "Abrar S. Alhazmi",
      "Sanaa H. Mohamed",
      "Osama Z. Alsulami",
      "T. E. H. El-Gorashi",
      "Jaafar M. H. Elmirghani"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.15841"
  },
  {
    "id": "arXiv:2110.15842",
    "title": "Equiangular lines and regular graphs",
    "abstract": "In 1973, Lemmens and Seidel posed the problem of determining $N_\\alpha(r)$,\nthe maximum number of equiangular lines in $\\mathbb{R}^r$ with common angle\n$\\arccos(\\alpha)$. Recently, this question has been almost completely settled\nin the case where $r$ is large relative to $1/\\alpha$, with the approach\nrelying on Ramsey's theorem. In this paper, we use orthogonal projections of\nmatrices with respect to the Frobenius inner product in order to overcome this\nlimitation, thereby obtaining upper bounds on $N_{\\alpha}(r)$ which\nsignificantly improve on the only previously known universal bound of Glazyrin\nand Yu, as well as taking an important step towards determining $N_\\alpha(r)$\nexactly for all $r, \\alpha$. In particular, our results imply that $N_\\alpha(r)\n= \\Theta(r)$ for $\\alpha \\geq \\Omega(1/r^{1/5})$.\nOur arguments rely on a new geometric inequality for equiangular lines in\n$\\mathbb{R}^r$ which is tight when the number of lines meets the absolute bound\n$\\binom{r+1}{2}$. Moreover, using the connection to graphs, we obtain lower\nbounds on the second eigenvalue of the adjacency matrix of a regular graph\nwhich are tight for strongly regular graphs corresponding to $\\binom{r+1}{2}$\nequiangular lines in $\\mathbb{R}^r$. Our results only require that the spectral\ngap is less than half the number of vertices and can therefore be seen as an\nextension of the Alon-Boppana theorem to dense graphs.\nGeneralizing to $\\mathbb{C}$, we also obtain the first universal bound on the\nmaximum number of complex equiangular lines in $\\mathbb{C}^r$ with common\nHermitian angle $\\arccos(\\alpha)$. In particular, we prove an inequality for\ncomplex equiangular lines in $\\mathbb{C}^r$ which is tight if the number of\nlines meets the absolute bound $r^2$ and may be of independent interest in\nquantum theory. Additionally, we use our projection method to obtain an\nimprovement to Welch's bound.",
    "descriptor": "",
    "authors": [
      "Igor Balla"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)",
      "Metric Geometry (math.MG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.15842"
  },
  {
    "id": "arXiv:2110.15843",
    "title": "Adaptive Discretization in Online Reinforcement Learning",
    "abstract": "Discretization based approaches to solving online reinforcement learning\nproblems have been studied extensively in practice on applications ranging from\nresource allocation to cache management. Two major questions in designing\ndiscretization-based algorithms are how to create the discretization and when\nto refine it. While there have been several experimental results investigating\nheuristic solutions to these questions, there has been little theoretical\ntreatment. In this paper we provide a unified theoretical analysis of\ntree-based hierarchical partitioning methods for online reinforcement learning,\nproviding model-free and model-based algorithms. We show how our algorithms are\nable to take advantage of inherent structure of the problem by providing\nguarantees that scale with respect to the 'zooming dimension' instead of the\nambient dimension, an instance-dependent quantity measuring the benignness of\nthe optimal $Q_h^\\star$ function.\nMany applications in computing systems and operations research requires\nalgorithms that compete on three facets: low sample complexity, mild storage\nrequirements, and low computational burden. Our algorithms are easily adapted\nto operating constraints, and our theory provides explicit bounds across each\nof the three facets. This motivates its use in practical applications as our\napproach automatically adapts to underlying problem structure even when very\nlittle is known a priori about the system.",
    "descriptor": "\nComments: 70 pages, 5 figures. arXiv admin note: text overlap with arXiv:2007.00717\n",
    "authors": [
      "Sean R. Sinclair",
      "Siddhartha Banerjee",
      "Christina Lee Yu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15843"
  },
  {
    "id": "arXiv:2110.15886",
    "title": "A probabilistic view of latent space graphs and phase transitions",
    "abstract": "We study random graphs with latent geometric structure, where the probability\nof each edge depends on the underlying random positions corresponding to the\ntwo endpoints. We focus on the setting where this conditional probability is a\ngeneral monotone increasing function of the inner product of two vectors; such\na function can naturally be viewed as the cumulative distribution function of\nsome independent random variable. We consider a one-parameter family of random\ngraphs, characterized by the variance of this random variable, that smoothly\ninterpolates between a random dot product graph and an Erd\\H{o}s--R\\'enyi\nrandom graph. We prove phase transitions of detecting geometry in these graphs,\nin terms of the dimension of the underlying geometric space and the variance\nparameter of the conditional probability. When the dimension is high or the\nvariance is large, the graph is similar to an Erd\\H{o}s--R\\'enyi graph with the\nsame edge density that does not possess geometry; in other parameter regimes,\nthere is a computationally efficient signed triangle statistic that\ndistinguishes them. The proofs make use of information-theoretic inequalities\nand concentration of measure phenomena.",
    "descriptor": "\nComments: 33 pages, 1 figure\n",
    "authors": [
      "Suqi Liu",
      "Miklos Z. Racz"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.15886"
  },
  {
    "id": "arXiv:2110.15893",
    "title": "Computing the Invariant Circle and the Foliation by Stable Manifolds for  a 2-D Map by the Parameterization Method: Numerical Implementation and  Results",
    "abstract": "We present and implement an algorithm for computing the invariant circle and\nthe corresponding stable manifolds for 2-dimensional maps. The algorithm is\nbased on the parameterization method, and it is backed up by an a-posteriori\ntheorem established in [YdlL21]. The algorithm works irrespective of whether\nthe internal dynamics in the invariant circle is a rotation or it is\nphase-locked. The algorithm converges quadratically and the number of\noperations and memory requirements for each step of the iteration is linear\nwith respect to the size of the discretization. We also report on the result of\nrunning the implementation in some standard models to uncover new phenomena. In\nparticular, we explored a bundle merging scenario in which the invariant circle\nloses hyperbolicity because the angle between the stable directions and the\ntangent becomes zero even if the rates of contraction are separated. We also\ndiscuss and implement a generalization of the algorithm to 3 dimensions, and\nimplement it on the 3-dimensional Fattened Arnold Family (3D-FAF) map with\nnon-resonant eigenvalues and present numerical results.",
    "descriptor": "",
    "authors": [
      "Yian Yao",
      "Rafael De La Llave"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15893"
  },
  {
    "id": "arXiv:2110.15950",
    "title": "Characterising and modeling the co-evolution of transportation networks  and territories",
    "abstract": "The identification of structuring effects of transportation infrastructure on\nterritorial dynamics remains an open research problem. This issue is one of the\naspects of approaches on complexity of territorial dynamics, within which\nterritories and networks would be co-evolving. The aim of this thesis is to\nchallenge this view on interactions between networks and territories, both at\nthe conceptual and empirical level, by integrating them in simulation models of\nterritorial systems.",
    "descriptor": "\nComments: Translated from French. Several papers compose this PhD thesis; overlap with: arXiv:1605.08888, arXiv:1608.00840, arXiv:1608.05266, arXiv:1612.08504, arXiv:1706.07467, arXiv:1706.09244, arXiv:1708.06743, arXiv:1709.08684, arXiv:1712.00805, arXiv:1803.11457, arXiv:1804.09416, arXiv:1804.09430, arXiv:1805.05195, arXiv:1808.07282, arXiv:1809.00861, arXiv:1811.04270, arXiv:1812.01473, arXiv:1812.06008, arXiv:1908.02034, arXiv:2012.13367, arXiv:2102.13501, arXiv:2106.11996\n",
    "authors": [
      "Juste Raimbault"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.15950"
  },
  {
    "id": "arXiv:2110.15960",
    "title": "Support Recovery with Stochastic Gates: Theory and Application for  Linear Models",
    "abstract": "We analyze the problem of simultaneous support recovery and estimation of the\ncoefficient vector ($\\beta^*$) in a linear model with independent and\nidentically distributed Normal errors. We apply the penalised least square\nestimator of $\\beta^*$ based on non-linear penalties of stochastic gates (STG)\n[YLNK20] to estimate the coefficients. Considering Gaussian design matrices we\nshow that under reasonable conditions on dimension and sparsity of $\\beta^*$\nthe STG based estimator converges to the true data generating coefficient\nvector and also detects its support set with high probability. We propose a new\nprojection based algorithm for the linear models setup to improve upon the\nexisting STG estimator that was originally designed for general non-linear\nmodels. Our new procedure outperforms many classical estimators for sparse\nsupport recovery in synthetic data analysis.",
    "descriptor": "",
    "authors": [
      "Soham Jana",
      "Henry Li",
      "Yutaro Yamada",
      "Ofir Lindenbaum"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15960"
  },
  {
    "id": "arXiv:1802.06021",
    "title": "Gray codes and symmetric chains",
    "abstract": "Gray codes and symmetric chains",
    "descriptor": "",
    "authors": [
      "Petr Gregor",
      "Sven J\u00e4ger",
      "Torsten M\u00fctze",
      "Joe Sawada",
      "Kaja Wille"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1802.06021"
  },
  {
    "id": "arXiv:1803.08836",
    "title": "Decentralized Pure Exchange Processes on Networks",
    "abstract": "Comments: 37 pages, 13 figures",
    "descriptor": "\nComments: 37 pages, 13 figures\n",
    "authors": [
      "Daniele Cassese",
      "Paolo Pin"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1803.08836"
  },
  {
    "id": "arXiv:1903.06119",
    "title": "Correct Approximation of IEEE 754 Floating-Point Arithmetic for Program  Verification",
    "abstract": "Comments: 64 pages, 19 figures, 2 tables",
    "descriptor": "\nComments: 64 pages, 19 figures, 2 tables\n",
    "authors": [
      "Roberto Bagnara",
      "Abramo Bagnara",
      "Fabio Biselli",
      "Michele Chiari",
      "Roberta Gori"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1903.06119"
  },
  {
    "id": "arXiv:1903.11991",
    "title": "Parabolic Approximation Line Search for DNNs",
    "abstract": "Parabolic Approximation Line Search for DNNs",
    "descriptor": "",
    "authors": [
      "Maximus Mutschler",
      "Andreas Zell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1903.11991"
  },
  {
    "id": "arXiv:1909.11528",
    "title": "Context-Aware Decentralized Invariant Signaling for Opportunistic  Communications",
    "abstract": "Comments: This paper was rejected. The authors decided to keep working and improving this work. Currently, a more sophisticated work based on the rejected paper is being written, which can be of major interest to anyone interested in this research topic. The authors will upload this new work as soon as possible",
    "descriptor": "\nComments: This paper was rejected. The authors decided to keep working and improving this work. Currently, a more sophisticated work based on the rejected paper is being written, which can be of major interest to anyone interested in this research topic. The authors will upload this new work as soon as possible\n",
    "authors": [
      "Jordi Borras",
      "Gregori Vazquez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1909.11528"
  },
  {
    "id": "arXiv:2002.03729",
    "title": "Renet: An improvement method for remote object detection based on  Darknet",
    "abstract": "Renet: An improvement method for remote object detection based on  Darknet",
    "descriptor": "",
    "authors": [
      "Shengquan Wang",
      "Ang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2002.03729"
  },
  {
    "id": "arXiv:2002.06770",
    "title": "Unsupervised Image-generation Enhanced Adaptation for Object Detection  in Thermal images",
    "abstract": "Comments: 5 pages, 4 figures",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Peng Liu",
      "Fuyu Li",
      "Wanyi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2002.06770"
  },
  {
    "id": "arXiv:2003.10166",
    "title": "Constrained Controller and Observer Design by Inverse Optimality",
    "abstract": "Constrained Controller and Observer Design by Inverse Optimality",
    "descriptor": "",
    "authors": [
      "Mario Zanon",
      "Alberto Bemporad"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2003.10166"
  },
  {
    "id": "arXiv:2005.10899",
    "title": "Extracting Daily Dosage from Medication Instructions in EHRs: An  Automated Approach and Lessons Learned",
    "abstract": "Comments: 10 pages, 4 figures, 9 tables",
    "descriptor": "\nComments: 10 pages, 4 figures, 9 tables\n",
    "authors": [
      "Diwakar Mahajan",
      "Jennifer J. Liang",
      "Ching-Huei Tsou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2005.10899"
  },
  {
    "id": "arXiv:2006.03684",
    "title": "Differentially private partition selection",
    "abstract": "Comments: Accepted for publication in Proceedings on Privacy Enhancing Technologies (PoPETs), issue 2022.1",
    "descriptor": "\nComments: Accepted for publication in Proceedings on Privacy Enhancing Technologies (PoPETs), issue 2022.1\n",
    "authors": [
      "Damien Desfontaines",
      "James Voss",
      "Bryant Gipson",
      "Chinmoy Mandayam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2006.03684"
  },
  {
    "id": "arXiv:2007.05861",
    "title": "On the complexity of binary polynomial optimization over acyclic  hypergraphs",
    "abstract": "On the complexity of binary polynomial optimization over acyclic  hypergraphs",
    "descriptor": "",
    "authors": [
      "Alberto Del Pia",
      "Silvia Di Gregorio"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2007.05861"
  },
  {
    "id": "arXiv:2007.15645",
    "title": "Approximation of Smoothness Classes by Deep Rectifier Networks",
    "abstract": "Comments: To appear in SIAM Journal on Numerical Analysis",
    "descriptor": "\nComments: To appear in SIAM Journal on Numerical Analysis\n",
    "authors": [
      "Mazen Ali",
      "Anthony Nouy"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2007.15645"
  },
  {
    "id": "arXiv:2008.03064",
    "title": "Evaluating Efficient Performance Estimators of Neural Architectures",
    "abstract": "Comments: accepted by NeurIPS 2021 (10 page main texts)",
    "descriptor": "\nComments: accepted by NeurIPS 2021 (10 page main texts)\n",
    "authors": [
      "Xuefei Ning",
      "Changcheng Tang",
      "Wenshuo Li",
      "Zixuan Zhou",
      "Shuang Liang",
      "Huazhong Yang",
      "Yu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.03064"
  },
  {
    "id": "arXiv:2008.08233",
    "title": "On condition numbers of the total least squares problem with linear  equality constraint",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Qiaohua Liu",
      "Zhigang Jia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.08233"
  },
  {
    "id": "arXiv:2009.01521",
    "title": "Smoke Testing for Machine Learning: Simple Tests to Discover Severe  Defects",
    "abstract": "Comments: Accepted at Empirical Software Engineering, Springer",
    "descriptor": "\nComments: Accepted at Empirical Software Engineering, Springer\n",
    "authors": [
      "Steffen Herbold",
      "Tobias Haar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.01521"
  },
  {
    "id": "arXiv:2009.13251",
    "title": "Deep Learning for Predictive Business Process Monitoring: Review and  Benchmark",
    "abstract": "Deep Learning for Predictive Business Process Monitoring: Review and  Benchmark",
    "descriptor": "",
    "authors": [
      "Efr\u00e9n Rama-Maneiro",
      "Juan C. Vidal",
      "Manuel Lama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.13251"
  },
  {
    "id": "arXiv:2010.02709",
    "title": "An Infinite-Feature Extension for Bayesian ReLU Nets That Fixes Their  Asymptotic Overconfidence",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Agustinus Kristiadi",
      "Matthias Hein",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.02709"
  },
  {
    "id": "arXiv:2010.11660",
    "title": "Detecting Rewards Deterioration in Episodic Reinforcement Learning",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Ido Greenberg",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.11660"
  },
  {
    "id": "arXiv:2010.12305",
    "title": "FAME: Feature-Based Adversarial Meta-Embeddings for Robust Input  Representations",
    "abstract": "Comments: Accepted at EMNLP 2021",
    "descriptor": "\nComments: Accepted at EMNLP 2021\n",
    "authors": [
      "Lukas Lange",
      "Heike Adel",
      "Jannik Str\u00f6tgen",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.12305"
  },
  {
    "id": "arXiv:2010.12527",
    "title": "Answering Open-Domain Questions of Varying Reasoning Steps from Text",
    "abstract": "Comments: EMNLP 2021. Peng Qi, Haejun Lee, and TG Sido contributed equally",
    "descriptor": "\nComments: EMNLP 2021. Peng Qi, Haejun Lee, and TG Sido contributed equally\n",
    "authors": [
      "Peng Qi",
      "Haejun Lee",
      "Oghenetegiri \"TG\" Sido",
      "Christopher D. Manning"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12527"
  },
  {
    "id": "arXiv:2010.13997",
    "title": "A Domain-Shrinking based Bayesian Optimization Algorithm with  Order-Optimal Regret Performance",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Sudeep Salgia",
      "Sattar Vakili",
      "Qing Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.13997"
  },
  {
    "id": "arXiv:2011.06733",
    "title": "One Explanation is Not Enough: Structured Attention Graphs for Image  Classification",
    "abstract": "Comments: 26 pages, 25 figures",
    "descriptor": "\nComments: 26 pages, 25 figures\n",
    "authors": [
      "Vivswan Shitole",
      "Li Fuxin",
      "Minsuk Kahng",
      "Prasad Tadepalli",
      "Alan Fern"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.06733"
  },
  {
    "id": "arXiv:2011.07682",
    "title": "A Large-Scale Database for Graph Representation Learning",
    "abstract": "Comments: Published in NeurIPS Datasets and Benchmarks Track, 2021",
    "descriptor": "\nComments: Published in NeurIPS Datasets and Benchmarks Track, 2021\n",
    "authors": [
      "Scott Freitas",
      "Yuxiao Dong",
      "Joshua Neil",
      "Duen Horng Chau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2011.07682"
  },
  {
    "id": "arXiv:2011.12413",
    "title": "Wide-band butterfly network: stable and efficient inversion via  multi-frequency neural networks",
    "abstract": "Wide-band butterfly network: stable and efficient inversion via  multi-frequency neural networks",
    "descriptor": "",
    "authors": [
      "Matthew Li",
      "Laurent Demanet",
      "Leonardo Zepeda-N\u00fa\u00f1ez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.12413"
  },
  {
    "id": "arXiv:2011.12719",
    "title": "RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem",
    "abstract": "Comments: NeurIPS 2021. The first two authors contributed equally to this work",
    "descriptor": "\nComments: NeurIPS 2021. The first two authors contributed equally to this work\n",
    "authors": [
      "Eric Liang",
      "Zhanghao Wu",
      "Michael Luo",
      "Sven Mika",
      "Joseph E. Gonzalez",
      "Ion Stoica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2011.12719"
  },
  {
    "id": "arXiv:2011.13000",
    "title": "Ax-BxP: Approximate Blocked Computation for Precision-Reconfigurable  Deep Neural Network Acceleration",
    "abstract": "Ax-BxP: Approximate Blocked Computation for Precision-Reconfigurable  Deep Neural Network Acceleration",
    "descriptor": "",
    "authors": [
      "Reena Elangovan",
      "Shubham Jain",
      "Anand Raghunathan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.13000"
  },
  {
    "id": "arXiv:2012.03612",
    "title": "LCS Graph Kernel Based on Wasserstein Distance in Longest Common  Subsequence Metric Space",
    "abstract": "LCS Graph Kernel Based on Wasserstein Distance in Longest Common  Subsequence Metric Space",
    "descriptor": "",
    "authors": [
      "Jianming Huang",
      "Zhongxi Fang",
      "Hiroyuki Kasai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.03612"
  },
  {
    "id": "arXiv:2012.06685",
    "title": "Coordinated Frequency and Voltage Regulation of Grid-Following and  Grid-Forming Inverters",
    "abstract": "Coordinated Frequency and Voltage Regulation of Grid-Following and  Grid-Forming Inverters",
    "descriptor": "",
    "authors": [
      "Ankit Singhal",
      "Thanh Long Vu",
      "Wei Du"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.06685"
  },
  {
    "id": "arXiv:2012.08730",
    "title": "Event-based Motion Segmentation with Spatio-Temporal Graph Cuts",
    "abstract": "Event-based Motion Segmentation with Spatio-Temporal Graph Cuts",
    "descriptor": "",
    "authors": [
      "Yi Zhou",
      "Guillermo Gallego",
      "Xiuyuan Lu",
      "Siqi Liu",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.08730"
  },
  {
    "id": "arXiv:2012.11368",
    "title": "Accurate Object Association and Pose Updating for Semantic SLAM",
    "abstract": "Comments: The paper needs to be revised, and it will be updated after the revision is completed",
    "descriptor": "\nComments: The paper needs to be revised, and it will be updated after the revision is completed\n",
    "authors": [
      "Kaiqi Chen",
      "Jialing Liu",
      "Jianhua Zhang",
      "Zhenhua Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.11368"
  },
  {
    "id": "arXiv:2012.11552",
    "title": "OBoW: Online Bag-of-Visual-Words Generation for Self-Supervised Learning",
    "abstract": "Comments: Accepted to CVPR2021. Code at this https URL",
    "descriptor": "\nComments: Accepted to CVPR2021. Code at this https URL\n",
    "authors": [
      "Spyros Gidaris",
      "Andrei Bursuc",
      "Gilles Puy",
      "Nikos Komodakis",
      "Matthieu Cord",
      "Patrick P\u00e9rez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.11552"
  },
  {
    "id": "arXiv:2012.11983",
    "title": "Approximation of functions with small mixed smoothness in the uniform  norm",
    "abstract": "Approximation of functions with small mixed smoothness in the uniform  norm",
    "descriptor": "",
    "authors": [
      "Vladimir Temlyakov",
      "Tino Ullrich"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.11983"
  },
  {
    "id": "arXiv:2012.14844",
    "title": "Inference for Low-rank Tensors -- No Need to Debias",
    "abstract": "Comments: to appear at the Annals of Statistics",
    "descriptor": "\nComments: to appear at the Annals of Statistics\n",
    "authors": [
      "Dong Xia",
      "Anru R. Zhang",
      "Yuchen Zhou"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.14844"
  },
  {
    "id": "arXiv:2012.14905",
    "title": "Meta Learning Backpropagation And Improving It",
    "abstract": "Comments: Updated to the NeurIPS 2021 camera ready",
    "descriptor": "\nComments: Updated to the NeurIPS 2021 camera ready\n",
    "authors": [
      "Louis Kirsch",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.14905"
  },
  {
    "id": "arXiv:2101.02994",
    "title": "Quotients, inductive types, and quotient inductive types",
    "abstract": "Quotients, inductive types, and quotient inductive types",
    "descriptor": "",
    "authors": [
      "Marcelo P. Fiore",
      "Andrew M. Pitts",
      "S. C. Steenkamp"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.02994"
  },
  {
    "id": "arXiv:2101.08248",
    "title": "Data-to-text Generation by Splicing Together Nearest Neighbors",
    "abstract": "Comments: EMNLP 2021; figures updated/improved",
    "descriptor": "\nComments: EMNLP 2021; figures updated/improved\n",
    "authors": [
      "Sam Wiseman",
      "Arturs Backurs",
      "Karl Stratos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.08248"
  },
  {
    "id": "arXiv:2101.12745",
    "title": "Improved Variance-Aware Confidence Sets for Linear Bandits and Linear  Mixture MDP",
    "abstract": "Comments: 31 pages",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Zihan Zhang",
      "Jiaqi Yang",
      "Xiangyang Ji",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.12745"
  },
  {
    "id": "arXiv:2102.06199",
    "title": "A-NeRF: Articulated Neural Radiance Fields for Learning Human Shape,  Appearance, and Pose",
    "abstract": "Comments: NeurIPS 2021. Project website: this https URL",
    "descriptor": "\nComments: NeurIPS 2021. Project website: this https URL\n",
    "authors": [
      "Shih-Yang Su",
      "Frank Yu",
      "Michael Zollhoefer",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2102.06199"
  },
  {
    "id": "arXiv:2102.06462",
    "title": "Two Sides of the Same Coin: Heterophily and Oversmoothing in Graph  Convolutional Neural Networks",
    "abstract": "Comments: Including 11 page supplement",
    "descriptor": "\nComments: Including 11 page supplement\n",
    "authors": [
      "Yujun Yan",
      "Milad Hashemi",
      "Kevin Swersky",
      "Yaoqing Yang",
      "Danai Koutra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06462"
  },
  {
    "id": "arXiv:2102.07927",
    "title": "Structured Dropout Variational Inference for Bayesian Neural Networks",
    "abstract": "Comments: 45 pages, 9 figures",
    "descriptor": "\nComments: 45 pages, 9 figures\n",
    "authors": [
      "Son Nguyen",
      "Duong Nguyen",
      "Khai Nguyen",
      "Khoat Than",
      "Hung Bui",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.07927"
  },
  {
    "id": "arXiv:2102.09884",
    "title": "Taxonomy of Assets for Development of Software-Intensive Products and  Services",
    "abstract": "Comments: Submitted to the Journal of Systems and Software (JSS)",
    "descriptor": "\nComments: Submitted to the Journal of Systems and Software (JSS)\n",
    "authors": [
      "Ehsan Zabardast",
      "Javier Gonzalez-Huerta",
      "Tony Gorschek",
      "Darja \u0160mite",
      "Emil Al\u00e9groth",
      "Fabian Fagerholm"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2102.09884"
  },
  {
    "id": "arXiv:2102.10172",
    "title": "Channel Estimation and Data Detection Analysis of Massive MIMO with  1-Bit ADCs",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Italo Atzeni",
      "Antti T\u00f6lli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2102.10172"
  },
  {
    "id": "arXiv:2102.10212",
    "title": "Hard-Attention for Scalable Image Classification",
    "abstract": "Hard-Attention for Scalable Image Classification",
    "descriptor": "",
    "authors": [
      "Athanasios Papadopoulos",
      "Pawe\u0142 Korus",
      "Nasir Memon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.10212"
  },
  {
    "id": "arXiv:2102.10557",
    "title": "Contrastive Self-supervised Neural Architecture Search",
    "abstract": "Contrastive Self-supervised Neural Architecture Search",
    "descriptor": "",
    "authors": [
      "Nam Nguyen",
      "J. Morris Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.10557"
  },
  {
    "id": "arXiv:2102.12002",
    "title": "Adversarial Robustness with Non-uniform Perturbations",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Ecenaz Erdemir",
      "Jeffrey Bickford",
      "Luca Melis",
      "Sergul Aydore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.12002"
  },
  {
    "id": "arXiv:2103.00064",
    "title": "Software-Supported Audits of Decision-Making Systems: Testing Google and  Facebook's Political Advertising Policies",
    "abstract": "Comments: To be presented at CSCW '22",
    "descriptor": "\nComments: To be presented at CSCW '22\n",
    "authors": [
      "J. Nathan Matias",
      "Austin Hounsel",
      "Nick Feamster"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2103.00064"
  },
  {
    "id": "arXiv:2103.03571",
    "title": "Cycle Self-Training for Domain Adaptation",
    "abstract": "Cycle Self-Training for Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Hong Liu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03571"
  },
  {
    "id": "arXiv:2103.08922",
    "title": "Combining Morphological and Histogram based Text Line Segmentation in  the OCR Context",
    "abstract": "Comments: Journal of Data Mining and Digital Humanities; Small adjustments",
    "descriptor": "\nComments: Journal of Data Mining and Digital Humanities; Small adjustments\n",
    "authors": [
      "Pit Schneider"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.08922"
  },
  {
    "id": "arXiv:2103.11849",
    "title": "Almost (Weighted) Proportional Allocations for Indivisible Chores",
    "abstract": "Almost (Weighted) Proportional Allocations for Indivisible Chores",
    "descriptor": "",
    "authors": [
      "Bo Li",
      "Yingkai Li",
      "Xiaowei Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2103.11849"
  },
  {
    "id": "arXiv:2103.12311",
    "title": "SuctionNet-1Billion: A Large-Scale Benchmark for Suction Grasping",
    "abstract": "SuctionNet-1Billion: A Large-Scale Benchmark for Suction Grasping",
    "descriptor": "",
    "authors": [
      "Hanwen Cao",
      "Hao-Shu Fang",
      "Wenhai Liu",
      "Cewu Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12311"
  },
  {
    "id": "arXiv:2103.12768",
    "title": "DA4Event: towards bridging the Sim-to-Real Gap for Event Cameras using  Domain Adaptation",
    "abstract": "Comments: Accepted at IROS21",
    "descriptor": "\nComments: Accepted at IROS21\n",
    "authors": [
      "Mirco Planamente",
      "Chiara Plizzari",
      "Marco Cannici",
      "Marco Ciccone",
      "Francesco Strada",
      "Andrea Bottino",
      "Matteo Matteucci",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12768"
  },
  {
    "id": "arXiv:2103.14431",
    "title": "Multimodal Knowledge Expansion",
    "abstract": "Comments: Accepted by ICCV 2021. Project website: this https URL",
    "descriptor": "\nComments: Accepted by ICCV 2021. Project website: this https URL\n",
    "authors": [
      "Zihui Xue",
      "Sucheng Ren",
      "Zhengqi Gao",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2103.14431"
  },
  {
    "id": "arXiv:2103.15233",
    "title": "Low-Fidelity End-to-End Video Encoder Pre-training for Temporal Action  Localization",
    "abstract": "Comments: To appear at NeurIPS 2021. 15 pages, 1 figure",
    "descriptor": "\nComments: To appear at NeurIPS 2021. 15 pages, 1 figure\n",
    "authors": [
      "Mengmeng Xu",
      "Juan-Manuel Perez-Rua",
      "Xiatian Zhu",
      "Bernard Ghanem",
      "Brais Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15233"
  },
  {
    "id": "arXiv:2103.15497",
    "title": "Postmortem memory of public figures in news and social media",
    "abstract": "Postmortem memory of public figures in news and social media",
    "descriptor": "",
    "authors": [
      "Robert West",
      "Jure Leskovec",
      "Christopher Potts"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2103.15497"
  },
  {
    "id": "arXiv:2104.06262",
    "title": "On Determinism of Game Engines used for Simulation-based Autonomous  Vehicle Verification",
    "abstract": "Comments: 17 pages, 9 figures, 1 table",
    "descriptor": "\nComments: 17 pages, 9 figures, 1 table\n",
    "authors": [
      "Greg Chance",
      "Abanoub Ghobrial",
      "Kevin McAreavey",
      "Severin Lemaignan",
      "Tony Pipe",
      "Kerstin Eder"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Performance (cs.PF)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.06262"
  },
  {
    "id": "arXiv:2104.07196",
    "title": "Graph-based Thermal-Inertial SLAM with Probabilistic Neural Networks",
    "abstract": "Comments: Accepted to IEEE Transactions on Robotics",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Robotics\n",
    "authors": [
      "Muhamad Risqi U. Saputra",
      "Chris Xiaoxuan Lu",
      "Pedro P. B. de Gusmao",
      "Bing Wang",
      "Andrew Markham",
      "Niki Trigoni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.07196"
  },
  {
    "id": "arXiv:2104.07923",
    "title": "Analytical Models of the Performance of IEEE 802.11p Vehicle to Vehicle  Communications",
    "abstract": "Analytical Models of the Performance of IEEE 802.11p Vehicle to Vehicle  Communications",
    "descriptor": "",
    "authors": [
      "Miguel Sepulcre",
      "Manuel Gonzalez-Martin",
      "Javier Gozalvez",
      "Rafael Molina-Masegosa",
      "Baldomero Coll-Perales"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.07923"
  },
  {
    "id": "arXiv:2104.08078",
    "title": "To Share or not to Share: Predicting Sets of Sources for Model Transfer  Learning",
    "abstract": "Comments: Accepted at EMNLP 2021",
    "descriptor": "\nComments: Accepted at EMNLP 2021\n",
    "authors": [
      "Lukas Lange",
      "Jannik Str\u00f6tgen",
      "Heike Adel",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08078"
  },
  {
    "id": "arXiv:2104.08308",
    "title": "Neural Transfer Learning for Repairing Security Vulnerabilities in C  Code",
    "abstract": "Neural Transfer Learning for Repairing Security Vulnerabilities in C  Code",
    "descriptor": "",
    "authors": [
      "Zimin Chen",
      "Steve Kommrusch",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08308"
  },
  {
    "id": "arXiv:2104.09330",
    "title": "Beyond tight deadlines: what are the business causes for technical debt?",
    "abstract": "Beyond tight deadlines: what are the business causes for technical debt?",
    "descriptor": "",
    "authors": [
      "Rodrigo Rebou\u00e7as de Almeida",
      "Christoph Treude",
      "Uir\u00e1 Kulesza"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2104.09330"
  },
  {
    "id": "arXiv:2104.10219",
    "title": "Scalable Synthesis of Verified Controllers in Deep Reinforcement  Learning",
    "abstract": "Scalable Synthesis of Verified Controllers in Deep Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "Zikang Xiong",
      "Suresh Jagannathan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.10219"
  },
  {
    "id": "arXiv:2104.13276",
    "title": "MULTIMODAL ANALYSIS: Informed content estimation and audio source  separation",
    "abstract": "Comments: Ph.D. dissertation. Thesis supervisor: Geoffroy Peeters. Jury:Laurent Girin, Ga\\\"el Richard, Rachel Bittner, Elena Cabrio, Bruno Gas, Perfecto Herrera Boyer, Antoine Liutkus",
    "descriptor": "\nComments: Ph.D. dissertation. Thesis supervisor: Geoffroy Peeters. Jury:Laurent Girin, Ga\\\"el Richard, Rachel Bittner, Elena Cabrio, Bruno Gas, Perfecto Herrera Boyer, Antoine Liutkus\n",
    "authors": [
      "Gabriel Meseguer-Brocal"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.13276"
  },
  {
    "id": "arXiv:2104.13675",
    "title": "Typability and Type Inference in Atomic Polymorphism",
    "abstract": "Typability and Type Inference in Atomic Polymorphism",
    "descriptor": "",
    "authors": [
      "M. Clarence Protin",
      "Gilda Ferreira"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.13675"
  },
  {
    "id": "arXiv:2104.14956",
    "title": "Methodological Foundation of a Numerical Taxonomy of Urban Form",
    "abstract": "Methodological Foundation of a Numerical Taxonomy of Urban Form",
    "descriptor": "",
    "authors": [
      "Martin Fleischmann",
      "Alessandra Feliciotti",
      "Ombretta Romice",
      "Sergio Porta"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.14956"
  },
  {
    "id": "arXiv:2105.03059",
    "title": "Self-paced Resistance Learning against Overfitting on Noisy Labels",
    "abstract": "Self-paced Resistance Learning against Overfitting on Noisy Labels",
    "descriptor": "",
    "authors": [
      "Xiaoshuang Shi",
      "Zhenhua Guo",
      "Kang Li",
      "Yun Liang",
      "Xiaofeng Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03059"
  },
  {
    "id": "arXiv:2105.04522",
    "title": "Generalized Jensen-Shannon Divergence Loss for Learning with Noisy  Labels",
    "abstract": "Comments: Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Erik Englesson",
      "Hossein Azizpour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04522"
  },
  {
    "id": "arXiv:2105.05308",
    "title": "Sequential Fair Allocation: Achieving the Optimal Envy-Efficiency  Tradeoff Curve",
    "abstract": "Comments: 41 pages, 4 figures, to appear in SIGMETRICS 2022",
    "descriptor": "\nComments: 41 pages, 4 figures, to appear in SIGMETRICS 2022\n",
    "authors": [
      "Sean R. Sinclair",
      "Siddhartha Banerjee",
      "Christina Lee Yu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.05308"
  },
  {
    "id": "arXiv:2105.05380",
    "title": "Fundamental Diagrams of Commercial Adaptive Cruise Control: Worldwide  Experimental Evidence",
    "abstract": "Fundamental Diagrams of Commercial Adaptive Cruise Control: Worldwide  Experimental Evidence",
    "descriptor": "",
    "authors": [
      "Tienan Li",
      "Danjue Chen",
      "Hao Zhou",
      "Yuanchang Xie",
      "Jorge Laval"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.05380"
  },
  {
    "id": "arXiv:2105.06369",
    "title": "Neighborhood-Aware Neural Architecture Search",
    "abstract": "Comments: BMVC 2021",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Xiaofang Wang",
      "Shengcao Cao",
      "Mengtian Li",
      "Kris M. Kitani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.06369"
  },
  {
    "id": "arXiv:2105.13396",
    "title": "Comparing Alternatives to the Fixed Degree Sequence Model for Extracting  the Backbone of Bipartite Projections",
    "abstract": "Comparing Alternatives to the Fixed Degree Sequence Model for Extracting  the Backbone of Bipartite Projections",
    "descriptor": "",
    "authors": [
      "Zachary P. Neal",
      "Rachel Domagalski",
      "Bruce Sagan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.13396"
  },
  {
    "id": "arXiv:2106.00099",
    "title": "Multi-Objective SPIBB: Seldonian Offline Policy Improvement with Safety  Constraints in Finite MDPs",
    "abstract": "Multi-Objective SPIBB: Seldonian Offline Policy Improvement with Safety  Constraints in Finite MDPs",
    "descriptor": "",
    "authors": [
      "Harsh Satija",
      "Philip S. Thomas",
      "Joelle Pineau",
      "Romain Laroche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00099"
  },
  {
    "id": "arXiv:2106.01202",
    "title": "Framing RNN as a kernel method: A neural ODE approach",
    "abstract": "Comments: 33 pages, 7 figures, accepted for an oral presentation at NeurIPS 2021",
    "descriptor": "\nComments: 33 pages, 7 figures, accepted for an oral presentation at NeurIPS 2021\n",
    "authors": [
      "Adeline Fermanian",
      "Pierre Marion",
      "Jean-Philippe Vert",
      "G\u00e9rard Biau"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01202"
  },
  {
    "id": "arXiv:2106.01413",
    "title": "Rectangular Flows for Manifold Learning",
    "abstract": "Comments: NeurIPS 2021 Camera Ready. Code available at this https URL",
    "descriptor": "\nComments: NeurIPS 2021 Camera Ready. Code available at this https URL\n",
    "authors": [
      "Anthony L. Caterini",
      "Gabriel Loaiza-Ganem",
      "Geoff Pleiss",
      "John P. Cunningham"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01413"
  },
  {
    "id": "arXiv:2106.02395",
    "title": "DOCTOR: A Simple Method for Detecting Misclassification Errors",
    "abstract": "Comments: This paper has been accepted to appear as a spotlight in the Proceedings of the 2021 Conference on Neural Information Processing Systems (NeurIPS 2021), December 6-14, 2021, Virtual Event",
    "descriptor": "\nComments: This paper has been accepted to appear as a spotlight in the Proceedings of the 2021 Conference on Neural Information Processing Systems (NeurIPS 2021), December 6-14, 2021, Virtual Event\n",
    "authors": [
      "Federica Granese",
      "Marco Romanelli",
      "Daniele Gorla",
      "Catuscia Palamidessi",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02395"
  },
  {
    "id": "arXiv:2106.03194",
    "title": "Robust Implicit Networks via Non-Euclidean Contractions",
    "abstract": "Robust Implicit Networks via Non-Euclidean Contractions",
    "descriptor": "",
    "authors": [
      "Saber Jafarpour",
      "Alexander Davydov",
      "Anton V. Proskurnikov",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03194"
  },
  {
    "id": "arXiv:2106.03880",
    "title": "Encoding-dependent generalization bounds for parametrized quantum  circuits",
    "abstract": "Comments: 34 pages, 3 figures",
    "descriptor": "\nComments: 34 pages, 3 figures\n",
    "authors": [
      "Matthias C. Caro",
      "Elies Gil-Fuster",
      "Johannes Jakob Meyer",
      "Jens Eisert",
      "Ryan Sweke"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03880"
  },
  {
    "id": "arXiv:2106.04024",
    "title": "Manifold Topology Divergence: a Framework for Comparing Data Manifolds",
    "abstract": "Manifold Topology Divergence: a Framework for Comparing Data Manifolds",
    "descriptor": "",
    "authors": [
      "Serguei Barannikov",
      "Ilya Trofimov",
      "Grigorii Sotnikov",
      "Ekaterina Trimbach",
      "Alexander Korotin",
      "Alexander Filippov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2106.04024"
  },
  {
    "id": "arXiv:2106.04089",
    "title": "Credit Assignment Through Broadcasting a Global Error Vector",
    "abstract": "Comments: 20 pages, 6 figures; expanded references and discussion",
    "descriptor": "\nComments: 20 pages, 6 figures; expanded references and discussion\n",
    "authors": [
      "David G. Clark",
      "L. F. Abbott",
      "SueYeon Chung"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.04089"
  },
  {
    "id": "arXiv:2106.04186",
    "title": "What training reveals about neural network complexity",
    "abstract": "Comments: Published at NeurIPS 2021",
    "descriptor": "\nComments: Published at NeurIPS 2021\n",
    "authors": [
      "Andreas Loukas",
      "Marinos Poiitis",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04186"
  },
  {
    "id": "arXiv:2106.04480",
    "title": "There Is No Turning Back: A Self-Supervised Approach for  Reversibility-Aware Reinforcement Learning",
    "abstract": "There Is No Turning Back: A Self-Supervised Approach for  Reversibility-Aware Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Nathan Grinsztajn",
      "Johan Ferret",
      "Olivier Pietquin",
      "Philippe Preux",
      "Matthieu Geist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.04480"
  },
  {
    "id": "arXiv:2106.04619",
    "title": "Self-Supervised Learning with Data Augmentations Provably Isolates  Content from Style",
    "abstract": "Comments: NeurIPS 2021 camera-ready version",
    "descriptor": "\nComments: NeurIPS 2021 camera-ready version\n",
    "authors": [
      "Julius von K\u00fcgelgen",
      "Yash Sharma",
      "Luigi Gresele",
      "Wieland Brendel",
      "Bernhard Sch\u00f6lkopf",
      "Michel Besserve",
      "Francesco Locatello"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04619"
  },
  {
    "id": "arXiv:2106.06839",
    "title": "Intelligent Vision Based Wear Forecasting on Surfaces of Machine Tool  Elements",
    "abstract": "Intelligent Vision Based Wear Forecasting on Surfaces of Machine Tool  Elements",
    "descriptor": "",
    "authors": [
      "Tobias Schlagenhauf",
      "Niklas Burghardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06839"
  },
  {
    "id": "arXiv:2106.07770",
    "title": "Potato Crop Stress Identification in Aerial Images using Deep  Learning-based Object Detection",
    "abstract": "Comments: 15 pages, 4 figures",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Sujata Butte",
      "Aleksandar Vakanski",
      "Kasia Duellman",
      "Haotian Wang",
      "Amin Mirkouei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07770"
  },
  {
    "id": "arXiv:2106.07887",
    "title": "Credit Assignment in Neural Networks through Deep Feedback Control",
    "abstract": "Comments: 14 pages and 4 figures in the main manuscript; 49 pages and 15 figures in the supplementary materials",
    "descriptor": "\nComments: 14 pages and 4 figures in the main manuscript; 49 pages and 15 figures in the supplementary materials\n",
    "authors": [
      "Alexander Meulemans",
      "Matilde Tristany Farinha",
      "Javier Garc\u00eda Ord\u00f3\u00f1ez",
      "Pau Vilimelis Aceituno",
      "Jo\u00e3o Sacramento",
      "Benjamin F. Grewe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07887"
  },
  {
    "id": "arXiv:2106.08929",
    "title": "KALE Flow: A Relaxed KL Gradient Flow for Probabilities with Disjoint  Support",
    "abstract": "KALE Flow: A Relaxed KL Gradient Flow for Probabilities with Disjoint  Support",
    "descriptor": "",
    "authors": [
      "Pierre Glaser",
      "Michael Arbel",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08929"
  },
  {
    "id": "arXiv:2106.09211",
    "title": "Square Root Principal Component Pursuit: Tuning-Free Noisy Robust Matrix  Recovery",
    "abstract": "Square Root Principal Component Pursuit: Tuning-Free Noisy Robust Matrix  Recovery",
    "descriptor": "",
    "authors": [
      "Junhui Zhang",
      "Jingkai Yan",
      "John Wright"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.09211"
  },
  {
    "id": "arXiv:2106.10052",
    "title": "On Contrastive Representations of Stochastic Processes",
    "abstract": "Comments: NeurIPS 2021 Camera ready",
    "descriptor": "\nComments: NeurIPS 2021 Camera ready\n",
    "authors": [
      "Emile Mathieu",
      "Adam Foster",
      "Yee Whye Teh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10052"
  },
  {
    "id": "arXiv:2106.11107",
    "title": "Electromagnetic Interference in RIS-Aided Communications",
    "abstract": "Comments: 5 pages, 5 figures, IEEE Wireless Communication Letters",
    "descriptor": "\nComments: 5 pages, 5 figures, IEEE Wireless Communication Letters\n",
    "authors": [
      "Andrea De Jesus Torres",
      "Luca Sanguinetti",
      "Emil Bj\u00f6rnson"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11107"
  },
  {
    "id": "arXiv:2106.12184",
    "title": "A note on concatenation of quasi-Monte Carlo and plain Monte Carlo rules  in high dimensions",
    "abstract": "Comments: major revision, 15 pages",
    "descriptor": "\nComments: major revision, 15 pages\n",
    "authors": [
      "Takashi Goda"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.12184"
  },
  {
    "id": "arXiv:2106.14448",
    "title": "R-Drop: Regularized Dropout for Neural Networks",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Xiaobo Liang",
      "Lijun Wu",
      "Juntao Li",
      "Yue Wang",
      "Qi Meng",
      "Tao Qin",
      "Wei Chen",
      "Min Zhang",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.14448"
  },
  {
    "id": "arXiv:2106.15191",
    "title": "Predictive Control based on Equivalent Dynamic Linearization Model",
    "abstract": "Predictive Control based on Equivalent Dynamic Linearization Model",
    "descriptor": "",
    "authors": [
      "Feilong Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15191"
  },
  {
    "id": "arXiv:2106.15845",
    "title": "Edge Representation Learning with Hypergraphs",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Jaehyeong Jo",
      "Jinheon Baek",
      "Seul Lee",
      "Dongki Kim",
      "Minki Kang",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15845"
  },
  {
    "id": "arXiv:2106.16204",
    "title": "Combinatorial generation via permutation languages. IV. Elimination  trees",
    "abstract": "Combinatorial generation via permutation languages. IV. Elimination  trees",
    "descriptor": "",
    "authors": [
      "Jean Cardinal",
      "Arturo Merino",
      "Torsten M\u00fctze"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.16204"
  },
  {
    "id": "arXiv:2107.01488",
    "title": "A fast algorithm for computing the Boys function",
    "abstract": "Comments: 9 pages, two figures and two tables",
    "descriptor": "\nComments: 9 pages, two figures and two tables\n",
    "authors": [
      "Gregory Beylkin",
      "Sandeep Sharma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01488"
  },
  {
    "id": "arXiv:2107.01837",
    "title": "Advanced turning maneuver of a multi-legged robot using pitchfork  bifurcation",
    "abstract": "Advanced turning maneuver of a multi-legged robot using pitchfork  bifurcation",
    "descriptor": "",
    "authors": [
      "Shinya Aoi",
      "Ryoe Tomatsu",
      "Yuki Yabuuchi",
      "Daiki Morozumi",
      "Kota Okamoto",
      "Soichiro Fujiki",
      "Kei Senda",
      "Kazuo Tsuchiya"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01837"
  },
  {
    "id": "arXiv:2107.02133",
    "title": "Test-Time Personalization with a Transformer for Human Pose Estimation",
    "abstract": "Comments: Project page: this http URL",
    "descriptor": "\nComments: Project page: this http URL\n",
    "authors": [
      "Yizhuo Li",
      "Miao Hao",
      "Zonglin Di",
      "Nitesh B. Gundavarapu",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02133"
  },
  {
    "id": "arXiv:2107.03377",
    "title": "Long Short-Term Transformer for Online Action Detection",
    "abstract": "Comments: NeurIPS 2021 Spotlight",
    "descriptor": "\nComments: NeurIPS 2021 Spotlight\n",
    "authors": [
      "Mingze Xu",
      "Yuanjun Xiong",
      "Hao Chen",
      "Xinyu Li",
      "Wei Xia",
      "Zhuowen Tu",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.03377"
  },
  {
    "id": "arXiv:2107.04827",
    "title": "Identifying Layers Susceptible to Adversarial Attacks",
    "abstract": "Identifying Layers Susceptible to Adversarial Attacks",
    "descriptor": "",
    "authors": [
      "Shoaib Ahmed Siddiqui",
      "Thomas Breuel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.04827"
  },
  {
    "id": "arXiv:2107.05624",
    "title": "End-to-end Multi-modal Video Temporal Grounding",
    "abstract": "Comments: Accepted in NeurIPS 2021. Project page at this https URL",
    "descriptor": "\nComments: Accepted in NeurIPS 2021. Project page at this https URL\n",
    "authors": [
      "Yi-Wen Chen",
      "Yi-Hsuan Tsai",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05624"
  },
  {
    "id": "arXiv:2107.06889",
    "title": "Counting list homomorphisms from graphs of bounded treewidth: tight  complexity bounds",
    "abstract": "Counting list homomorphisms from graphs of bounded treewidth: tight  complexity bounds",
    "descriptor": "",
    "authors": [
      "Jacob Focke",
      "D\u00e1niel Marx",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.06889"
  },
  {
    "id": "arXiv:2107.08353",
    "title": "Top-label calibration and multiclass-to-binary reductions",
    "abstract": "Comments: 41 pages, 12 figures, 5 tables",
    "descriptor": "\nComments: 41 pages, 12 figures, 5 tables\n",
    "authors": [
      "Chirag Gupta",
      "Aaditya K. Ramdas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.08353"
  },
  {
    "id": "arXiv:2107.12922",
    "title": "Griffin: Rethinking Sparse Optimization for Deep Learning Architectures",
    "abstract": "Griffin: Rethinking Sparse Optimization for Deep Learning Architectures",
    "descriptor": "",
    "authors": [
      "Jong Hoon Shin",
      "Ali Shafiee",
      "Ardavan Pedram",
      "Hamzah Abdel-Aziz",
      "Ling Li",
      "Joseph Hassoun"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.12922"
  },
  {
    "id": "arXiv:2107.14324",
    "title": "Deep Networks Provably Classify Data on Curves",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Tingran Wang",
      "Sam Buchanan",
      "Dar Gilboa",
      "John Wright"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.14324"
  },
  {
    "id": "arXiv:2108.06912",
    "title": "Blockchain-based Trustworthy Federated Learning Architecture",
    "abstract": "Blockchain-based Trustworthy Federated Learning Architecture",
    "descriptor": "",
    "authors": [
      "Sin Kit Lo",
      "Yue Liu",
      "Qinghua Lu",
      "Chen Wang",
      "Xiwei Xu",
      "Hye-Young Paik",
      "Liming Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.06912"
  },
  {
    "id": "arXiv:2108.09151",
    "title": "Group-based Distinctive Image Captioning with Memory Attention",
    "abstract": "Comments: Accepted at ACM MM 2021 (oral)",
    "descriptor": "\nComments: Accepted at ACM MM 2021 (oral)\n",
    "authors": [
      "Jiuniu Wang",
      "Wenjia Xu",
      "Qingzhong Wang",
      "Antoni B. Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.09151"
  },
  {
    "id": "arXiv:2108.09568",
    "title": "Heterogeneous Graph Attention Networks for Learning Diverse  Communication",
    "abstract": "Heterogeneous Graph Attention Networks for Learning Diverse  Communication",
    "descriptor": "",
    "authors": [
      "Esmaeil Seraj",
      "Zheyuan Wang",
      "Rohan Paleja",
      "Matthew Sklar",
      "Anirudh Patel",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2108.09568"
  },
  {
    "id": "arXiv:2108.10226",
    "title": "ECG-Based Heart Arrhythmia Diagnosis Through Attentional Convolutional  Neural Networks",
    "abstract": "Comments: 7 pages, accepted by The 2021 IEEE International Conference on Internet of Things and Intelligence Systems (IoTaIS 2021)",
    "descriptor": "\nComments: 7 pages, accepted by The 2021 IEEE International Conference on Internet of Things and Intelligence Systems (IoTaIS 2021)\n",
    "authors": [
      "Ziyu Liu",
      "Xiang Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.10226"
  },
  {
    "id": "arXiv:2108.10433",
    "title": "Computational multiphase periporomechanics for unguided cracking in  unsaturated porous media",
    "abstract": "Computational multiphase periporomechanics for unguided cracking in  unsaturated porous media",
    "descriptor": "",
    "authors": [
      "Shashank Menon",
      "Xiaoyu Song"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.10433"
  },
  {
    "id": "arXiv:2108.10511",
    "title": "CMML: Contextual Modulation Meta Learning for Cold-Start Recommendation",
    "abstract": "Comments: corresponding to &lt;xidong.feng.20@ucl.ac.uk&gt;; Accepted by CIKM 2021",
    "descriptor": "\nComments: corresponding to &lt;xidong.feng.20@ucl.ac.uk&gt;; Accepted by CIKM 2021\n",
    "authors": [
      "Xidong Feng",
      "Chen Chen",
      "Dong Li",
      "Mengchen Zhao",
      "Jianye Hao",
      "Jun Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.10511"
  },
  {
    "id": "arXiv:2108.11575",
    "title": "Shifted Chunk Transformer for Spatio-Temporal Representational Learning",
    "abstract": "Comments: 15 pages, 3 figures",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Xuefan Zha",
      "Wentao Zhu",
      "Tingxun Lv",
      "Sen Yang",
      "Ji Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11575"
  },
  {
    "id": "arXiv:2108.11695",
    "title": "PAENet: A Progressive Attention-Enhanced Network for 3D to 2D Retinal  Vessel Segmentation",
    "abstract": "Comments: IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM 2021)",
    "descriptor": "\nComments: IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM 2021)\n",
    "authors": [
      "Zhuojie Wu",
      "Muyi Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11695"
  },
  {
    "id": "arXiv:2108.12115",
    "title": "Recognition Awareness: An Application of Latent Cognizance to Open-Set  Recognition",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Tatpong Katanyukul",
      "Pisit Nakjai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.12115"
  },
  {
    "id": "arXiv:2109.04561",
    "title": "Supervising the Decoder of Variational Autoencoders to Improve  Scientific Utility",
    "abstract": "Supervising the Decoder of Variational Autoencoders to Improve  Scientific Utility",
    "descriptor": "",
    "authors": [
      "Liyun Tu",
      "Austin Talbot",
      "Neil Gallagher",
      "David Carlson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.04561"
  },
  {
    "id": "arXiv:2109.06992",
    "title": "ML-aided power allocation for Tactical MIMO",
    "abstract": "Comments: Accepted at MILCOM 2021",
    "descriptor": "\nComments: Accepted at MILCOM 2021\n",
    "authors": [
      "Arindam Chowdhury",
      "Gunjan Verma",
      "Chirag Rao",
      "Ananthram Swami",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.06992"
  },
  {
    "id": "arXiv:2109.08960",
    "title": "EVL: a typed functional language for event processing",
    "abstract": "Comments: Submitted to MSCS",
    "descriptor": "\nComments: Submitted to MSCS\n",
    "authors": [
      "Sandra Alves",
      "Maribel Fern\u00e1ndez",
      "Miguel Ramos"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.08960"
  },
  {
    "id": "arXiv:2109.09495",
    "title": "GhostShiftAddNet: More Features from Energy-Efficient Operations",
    "abstract": "GhostShiftAddNet: More Features from Energy-Efficient Operations",
    "descriptor": "",
    "authors": [
      "Jia Bi",
      "Jonathon Hare",
      "Geoff V. Merrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.09495"
  },
  {
    "id": "arXiv:2109.09628",
    "title": "Advancing Self-supervised Monocular Depth Learning with Sparse LiDAR",
    "abstract": "Comments: Accepted by CoRL2021",
    "descriptor": "\nComments: Accepted by CoRL2021\n",
    "authors": [
      "Ziyue Feng",
      "Longlong Jing",
      "Peng Yin",
      "Yingli Tian",
      "Bing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.09628"
  },
  {
    "id": "arXiv:2109.10255",
    "title": "Multi-Task Learning with Sentiment, Emotion, and Target Detection to  Recognize Hate Speech and Offensive Language",
    "abstract": "Comments: publication at FIRE 2021 as system description paper in the HASOC-FIRE shared task on hate speech and offensive language detection",
    "descriptor": "\nComments: publication at FIRE 2021 as system description paper in the HASOC-FIRE shared task on hate speech and offensive language detection\n",
    "authors": [
      "Flor Miriam Plaza-del-Arco",
      "Sercan Halat",
      "Sebastian Pad\u00f3",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.10255"
  },
  {
    "id": "arXiv:2109.10601",
    "title": "Efficient Context-Aware Network for Abdominal Multi-organ Segmentation",
    "abstract": "Efficient Context-Aware Network for Abdominal Multi-organ Segmentation",
    "descriptor": "",
    "authors": [
      "Fan Zhang",
      "Yu Wang",
      "Hua Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.10601"
  },
  {
    "id": "arXiv:2109.12907",
    "title": "Expressing High-Level Scientific Claims with Formal Semantics",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Cristina-Iulia Bucur",
      "Tobias Kuhn",
      "Davide Ceolin",
      "Jacco van Ossenbruggen"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.12907"
  },
  {
    "id": "arXiv:2110.00291",
    "title": "Discovering care pathways for multi-morbid patients using event graphs",
    "abstract": "Discovering care pathways for multi-morbid patients using event graphs",
    "descriptor": "",
    "authors": [
      "Milad Naeimaei Aali",
      "Felix Mannhardt",
      "Pieter Jelle Toussaint"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.00291"
  },
  {
    "id": "arXiv:2110.00392",
    "title": "Tree in Tree: from Decision Trees to Decision Graphs",
    "abstract": "Tree in Tree: from Decision Trees to Decision Graphs",
    "descriptor": "",
    "authors": [
      "Bingzhao Zhu",
      "Mahsa Shoaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00392"
  },
  {
    "id": "arXiv:2110.00685",
    "title": "Fast Multi-Resolution Transformer Fine-tuning for Extreme Multi-label  Text Classification",
    "abstract": "Fast Multi-Resolution Transformer Fine-tuning for Extreme Multi-label  Text Classification",
    "descriptor": "",
    "authors": [
      "Jiong Zhang",
      "Wei-cheng Chang",
      "Hsiang-fu Yu",
      "Inderjit S. Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.00685"
  },
  {
    "id": "arXiv:2110.01133",
    "title": "Lifetime Maximization for UAV-Enabled Cognitive-NOMA IoT Networks: Joint  Location, Power, and Decoding Order Optimization",
    "abstract": "Lifetime Maximization for UAV-Enabled Cognitive-NOMA IoT Networks: Joint  Location, Power, and Decoding Order Optimization",
    "descriptor": "",
    "authors": [
      "Na Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.01133"
  },
  {
    "id": "arXiv:2110.01325",
    "title": "Learning to Classify and Imitate Trading Agents in Continuous Double  Auction Markets",
    "abstract": "Learning to Classify and Imitate Trading Agents in Continuous Double  Auction Markets",
    "descriptor": "",
    "authors": [
      "Mahmoud Mahfouz",
      "Tucker Balch",
      "Manuela Veloso",
      "Danilo Mandic"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.01325"
  },
  {
    "id": "arXiv:2110.03395",
    "title": "SLASH: Embracing Probabilistic Circuits into Neural Answer Set  Programming",
    "abstract": "Comments: 16 pages, 7 figures and 5 tables",
    "descriptor": "\nComments: 16 pages, 7 figures and 5 tables\n",
    "authors": [
      "Arseny Skryagin",
      "Wolfgang Stammer",
      "Daniel Ochs",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03395"
  },
  {
    "id": "arXiv:2110.03513",
    "title": "Accelerated Componentwise Gradient Boosting using Efficient Data  Representation and Momentum-based Optimization",
    "abstract": "Accelerated Componentwise Gradient Boosting using Efficient Data  Representation and Momentum-based Optimization",
    "descriptor": "",
    "authors": [
      "Daniel Schalk",
      "Bernd Bischl",
      "David R\u00fcgamer"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03513"
  },
  {
    "id": "arXiv:2110.03611",
    "title": "Adversarial Retriever-Ranker for dense text retrieval",
    "abstract": "Adversarial Retriever-Ranker for dense text retrieval",
    "descriptor": "",
    "authors": [
      "Hang Zhang",
      "Yeyun Gong",
      "Yelong Shen",
      "Jiancheng Lv",
      "Nan Duan",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03611"
  },
  {
    "id": "arXiv:2110.04193",
    "title": "On Fast Johnson-Lindenstrauss Embeddings of Compact Submanifolds of  $\\mathbb{R}^N$ with Boundary",
    "abstract": "Comments: Fixed a typo",
    "descriptor": "\nComments: Fixed a typo\n",
    "authors": [
      "Mark A. Iwen",
      "Benjamin Schmidt",
      "Arman Tavakoli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04193"
  },
  {
    "id": "arXiv:2110.04591",
    "title": "Zig-Zag Modules: Cosheaves and K-Theory",
    "abstract": "Comments: v2: Fixed minor errors/ambiguities",
    "descriptor": "\nComments: v2: Fixed minor errors/ambiguities\n",
    "authors": [
      "Ryan E. Grady",
      "Anna Schenfisch"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2110.04591"
  },
  {
    "id": "arXiv:2110.04719",
    "title": "Structure learning in polynomial time: Greedy algorithms, Bregman  information, and exponential families",
    "abstract": "Comments: Accepted to NeurIPS 2021; 27 pages, 9 figures",
    "descriptor": "\nComments: Accepted to NeurIPS 2021; 27 pages, 9 figures\n",
    "authors": [
      "Goutham Rajendran",
      "Bohdan Kivva",
      "Ming Gao",
      "Bryon Aragam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04719"
  },
  {
    "id": "arXiv:2110.04908",
    "title": "Personalizing ASR with limited data using targeted subset selection",
    "abstract": "Comments: Under review (ICASSP 2022)",
    "descriptor": "\nComments: Under review (ICASSP 2022)\n",
    "authors": [
      "Mayank Kothyari",
      "Anmol Reddy Mekala",
      "Rishabh Iyer",
      "Ganesh Ramakrishnan",
      "Preethi Jyothi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04908"
  },
  {
    "id": "arXiv:2110.04995",
    "title": "The Skellam Mechanism for Differentially Private Federated Learning",
    "abstract": "Comments: Paper published in NeurIPS 2021",
    "descriptor": "\nComments: Paper published in NeurIPS 2021\n",
    "authors": [
      "Naman Agarwal",
      "Peter Kairouz",
      "Ziyu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04995"
  },
  {
    "id": "arXiv:2110.05069",
    "title": "Efficient Training of Audio Transformers with Patchout",
    "abstract": "Comments: Source code: this https URL",
    "descriptor": "\nComments: Source code: this https URL\n",
    "authors": [
      "Khaled Koutini",
      "Jan Schl\u00fcter",
      "Hamid Eghbal-zadeh",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05069"
  },
  {
    "id": "arXiv:2110.05580",
    "title": "vocadito: A dataset of solo vocals with $f_0$, note, and lyric  annotations",
    "abstract": "vocadito: A dataset of solo vocals with $f_0$, note, and lyric  annotations",
    "descriptor": "",
    "authors": [
      "Rachel M. Bittner",
      "Katherine Pasalo",
      "Juan Jos\u00e9 Bosch",
      "Gabriel Meseguer-Brocal",
      "David Rubinstein"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05580"
  },
  {
    "id": "arXiv:2110.06741",
    "title": "Dynamical Wasserstein Barycenters for Time-series Modeling",
    "abstract": "Comments: To appear at Neurips 2021",
    "descriptor": "\nComments: To appear at Neurips 2021\n",
    "authors": [
      "Kevin C. Cheng",
      "Shuchin Aeron",
      "Michael C. Hughes",
      "Eric L. Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06741"
  },
  {
    "id": "arXiv:2110.06910",
    "title": "On the Double Descent of Random Features Models Trained with SGD",
    "abstract": "Comments: 34 pages, 2 figures. This version gives a refined estimation on B2 (one term in Bias)",
    "descriptor": "\nComments: 34 pages, 2 figures. This version gives a refined estimation on B2 (one term in Bias)\n",
    "authors": [
      "Fanghui Liu",
      "Johan A.K. Suykens",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06910"
  },
  {
    "id": "arXiv:2110.07270",
    "title": "Spherical polar coordinate transformation for integration of singular  functions on tetrahedra",
    "abstract": "Spherical polar coordinate transformation for integration of singular  functions on tetrahedra",
    "descriptor": "",
    "authors": [
      "Michael J. Carley"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.07270"
  },
  {
    "id": "arXiv:2110.08558",
    "title": "Neural Network Pruning Through Constrained Reinforcement Learning",
    "abstract": "Comments: Submitted to ICASSP 2021",
    "descriptor": "\nComments: Submitted to ICASSP 2021\n",
    "authors": [
      "Shehryar Malik",
      "Muhammad Umair Haider",
      "Omer Iqbal",
      "Murtaza Taj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08558"
  },
  {
    "id": "arXiv:2110.09554",
    "title": "TransFusion: Cross-view Fusion with Transformer for 3D Human Pose  Estimation",
    "abstract": "Comments: BMVC 2021. Code is available at: this https URL",
    "descriptor": "\nComments: BMVC 2021. Code is available at: this https URL\n",
    "authors": [
      "Haoyu Ma",
      "Liangjian Chen",
      "Deying Kong",
      "Zhe Wang",
      "Xingwei Liu",
      "Hao Tang",
      "Xiangyi Yan",
      "Yusheng Xie",
      "Shih-Yao Lin",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09554"
  },
  {
    "id": "arXiv:2110.10221",
    "title": "The CoRa Tensor Compiler: Compilation for Ragged Tensors with Minimal  Padding",
    "abstract": "Comments: 23 pages, 25 figures and 10 tables",
    "descriptor": "\nComments: 23 pages, 25 figures and 10 tables\n",
    "authors": [
      "Pratik Fegade",
      "Tianqi Chen",
      "Phillip B. Gibbons",
      "Todd C. Mowry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10221"
  },
  {
    "id": "arXiv:2110.10436",
    "title": "A Survey on Deep-Learning Approaches for Vehicle Trajectory Prediction  in Autonomous Driving",
    "abstract": "Comments: Accepted by ROBIO2021",
    "descriptor": "\nComments: Accepted by ROBIO2021\n",
    "authors": [
      "Jianbang Liu",
      "Xinyu Mao",
      "Yuqi Fang",
      "Delong Zhu",
      "Max Q.-H. Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10436"
  },
  {
    "id": "arXiv:2110.11269",
    "title": "Modeling the AC Power Flow Equations with Optimally Compact Neural  Networks: Application to Unit Commitment",
    "abstract": "Comments: added acknowledgement, first two authors equally contributed, 8 pages, 3 figures, 1 table",
    "descriptor": "\nComments: added acknowledgement, first two authors equally contributed, 8 pages, 3 figures, 1 table\n",
    "authors": [
      "Alyssa Kody",
      "Samuel Chevalier",
      "Spyros Chatzivasileiadis",
      "Daniel Molzahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.11269"
  },
  {
    "id": "arXiv:2110.11430",
    "title": "How can classical multidimensional scaling go wrong?",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Rishi Sonthalia",
      "Gregory Van Buskirk",
      "Benjamin Raichel",
      "Anna C. Gilbert"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11430"
  },
  {
    "id": "arXiv:2110.11945",
    "title": "SOFT: Softmax-free Transformer with Linear Complexity",
    "abstract": "Comments: NeurIPS 2021 Spotlight. Project page at this https URL",
    "descriptor": "\nComments: NeurIPS 2021 Spotlight. Project page at this https URL\n",
    "authors": [
      "Jiachen Lu",
      "Jinghan Yao",
      "Junge Zhang",
      "Xiatian Zhu",
      "Hang Xu",
      "Weiguo Gao",
      "Chunjing Xu",
      "Tao Xiang",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11945"
  },
  {
    "id": "arXiv:2110.13047",
    "title": "Drug Similarity and Link Prediction Using Graph Embeddings on Medical  Knowledge Graphs",
    "abstract": "Drug Similarity and Link Prediction Using Graph Embeddings on Medical  Knowledge Graphs",
    "descriptor": "",
    "authors": [
      "Prakhar Gurawa",
      "Matthias Nickles"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13047"
  },
  {
    "id": "arXiv:2110.13323",
    "title": "Deep Learning Tools for Audacity: Helping Researchers Expand the  Artist's Toolkit",
    "abstract": "Deep Learning Tools for Audacity: Helping Researchers Expand the  Artist's Toolkit",
    "descriptor": "",
    "authors": [
      "Hugo Flores Garcia",
      "Aldo Aguilar",
      "Ethan Manilow",
      "Dmitry Vedenko",
      "Bryan Pardo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13323"
  },
  {
    "id": "arXiv:2110.13900",
    "title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech  Processing",
    "abstract": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech  Processing",
    "descriptor": "",
    "authors": [
      "Sanyuan Chen",
      "Chengyi Wang",
      "Zhengyang Chen",
      "Yu Wu",
      "Shujie Liu",
      "Zhuo Chen",
      "Jinyu Li",
      "Naoyuki Kanda",
      "Takuya Yoshioka",
      "Xiong Xiao",
      "Jian Wu",
      "Long Zhou",
      "Shuo Ren",
      "Yanmin Qian",
      "Yao Qian",
      "Jian Wu",
      "Michael Zeng",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13900"
  },
  {
    "id": "arXiv:2110.13957",
    "title": "Unbiased Graph Embedding with Biased Graph Observations",
    "abstract": "Unbiased Graph Embedding with Biased Graph Observations",
    "descriptor": "",
    "authors": [
      "Nan Wang",
      "Lu Lin",
      "Jundong Li",
      "Hongning Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13957"
  },
  {
    "id": "arXiv:2110.14010",
    "title": "MisConv: Convolutional Neural Networks for Missing Data",
    "abstract": "Comments: Accepted for publication at WACV 2022 Conference",
    "descriptor": "\nComments: Accepted for publication at WACV 2022 Conference\n",
    "authors": [
      "Marcin Przewi\u0119\u017alikowski",
      "Marek \u015amieja",
      "\u0141ukasz Struski",
      "Jacek Tabor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14010"
  },
  {
    "id": "arXiv:2110.14022",
    "title": "Intelligent Meta-Imagers: From Compressed to Learned Sensing",
    "abstract": "Comments: 59 pages including 8 figures",
    "descriptor": "\nComments: 59 pages including 8 figures\n",
    "authors": [
      "Chlo\u00e9 Saigre-Tardif",
      "Rashid Faqiri",
      "Hanting Zhao",
      "Lianlin Li",
      "Philipp del Hougne"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.14022"
  },
  {
    "id": "arXiv:2110.14115",
    "title": "Metrics of research impact in astronomy: Predicting later impact from  metrics measured 10-15 years after the PhD",
    "abstract": "Comments: 11 pages, 8 postscript figures, 5 tables accepted for publication in Proceedings of the National Academy of Sciences",
    "descriptor": "\nComments: 11 pages, 8 postscript figures, 5 tables accepted for publication in Proceedings of the National Academy of Sciences\n",
    "authors": [
      "John Kormendy"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2110.14115"
  },
  {
    "id": "arXiv:2110.14209",
    "title": "Distributionally Robust Day-ahead Scheduling for Power-traffic Network  Considering Multiple Uncertainties under a Potential Game Framework",
    "abstract": "Distributionally Robust Day-ahead Scheduling for Power-traffic Network  Considering Multiple Uncertainties under a Potential Game Framework",
    "descriptor": "",
    "authors": [
      "Haoran Deng",
      "Bo Yang",
      "Jiaxin Cao",
      "Chao Ning",
      "Cailian Chen",
      "Xinping Guan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14209"
  },
  {
    "id": "arXiv:2110.14461",
    "title": "Hand gesture detection in tests performed by older adults",
    "abstract": "Hand gesture detection in tests performed by older adults",
    "descriptor": "",
    "authors": [
      "Guan Huang",
      "Son N. Tran",
      "Quan Bai",
      "Jane Alty"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14461"
  },
  {
    "id": "arXiv:2110.14476",
    "title": "An Arbitrary Scale Super-Resolution Approach for 3-Dimensional Magnetic  Resonance Image using Implicit Neural Representation",
    "abstract": "Comments: 18 pages, 13 figures, 4 tables; submitted to Medical Image Analysis",
    "descriptor": "\nComments: 18 pages, 13 figures, 4 tables; submitted to Medical Image Analysis\n",
    "authors": [
      "Qing Wu",
      "Yuwei Li",
      "Yawen Sun",
      "Yan Zhou",
      "Hongjiang Wei",
      "Jingyi Yu",
      "Yuyao Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14476"
  },
  {
    "id": "arXiv:2110.14495",
    "title": "Convergence of Restricted Additive Schwarz with impedance transmission  conditions for discretised Helmholtz problems",
    "abstract": "Comments: 34 pages, 2 figures",
    "descriptor": "\nComments: 34 pages, 2 figures\n",
    "authors": [
      "Shihua Gong",
      "Ivan G. Graham",
      "Euan A. Spence"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.14495"
  },
  {
    "id": "arXiv:2110.14815",
    "title": "Deterministic enumeration of all minimum cut-sets and $k$-cut-sets in  hypergraphs for fixed $k$",
    "abstract": "Comments: Accepted to SODA'22",
    "descriptor": "\nComments: Accepted to SODA'22\n",
    "authors": [
      "Calvin Beideman",
      "Karthekeyan Chandrasekaran",
      "Weihang Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.14815"
  },
  {
    "id": "arXiv:2110.14888",
    "title": "Teaching an Active Learner with Contrastive Examples",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Chaoqi Wang",
      "Adish Singla",
      "Yuxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14888"
  },
  {
    "id": "arXiv:2110.14892",
    "title": "Analysis of COVID-19 in Japan with Extended SEIR model and ensemble  Kalman filter",
    "abstract": "Comments: 29 pages, 18 figures, 1 table",
    "descriptor": "\nComments: 29 pages, 18 figures, 1 table\n",
    "authors": [
      "Qiwen Sun",
      "Serge Richard",
      "Takemasa Miyoshi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2110.14892"
  },
  {
    "id": "arXiv:2110.14908",
    "title": "E-ffective: A Visual Analytic System for Exploring the Emotion and  Effectiveness of Inspirational Speeches",
    "abstract": "Comments: IEEE Transactions of Visualization and Computer Graphics (TVCG, Proc. VIS 2021), to appear",
    "descriptor": "\nComments: IEEE Transactions of Visualization and Computer Graphics (TVCG, Proc. VIS 2021), to appear\n",
    "authors": [
      "Kevin Maher",
      "Zeyuan Huang",
      "Jiancheng Song",
      "Xiaoming Deng",
      "Yu-Kun Lai",
      "Cuixia Ma",
      "Hao Wang",
      "Yong-Jin Liu",
      "Hongan Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.14908"
  },
  {
    "id": "arXiv:2110.14953",
    "title": "Multi-Task Processes",
    "abstract": "Comments: 33 pages, 13 figures",
    "descriptor": "\nComments: 33 pages, 13 figures\n",
    "authors": [
      "Donggyun Kim",
      "Seongwoong Cho",
      "Wonkwang Lee",
      "Seunghoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14953"
  },
  {
    "id": "arXiv:2110.15032",
    "title": "OneFlow: Redesign the Distributed Deep Learning Framework from Scratch",
    "abstract": "OneFlow: Redesign the Distributed Deep Learning Framework from Scratch",
    "descriptor": "",
    "authors": [
      "Jinhui Yuan",
      "Xinqi Li",
      "Cheng Cheng",
      "Juncheng Liu",
      "Ran Guo",
      "Shenghang Cai",
      "Chi Yao",
      "Fei Yang",
      "Xiaodong Yi",
      "Chuan Wu",
      "Haoran Zhang",
      "Jie Zhao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15032"
  },
  {
    "id": "arXiv:2110.15089",
    "title": "D2RLIR : an improved and diversified ranking function in interactive  recommendation systems based on deep reinforcement learning",
    "abstract": "D2RLIR : an improved and diversified ranking function in interactive  recommendation systems based on deep reinforcement learning",
    "descriptor": "",
    "authors": [
      "Vahid Baghi",
      "Seyed Mohammad Seyed Motehayeri",
      "Ali Moeini",
      "Rooholah Abedian"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15089"
  },
  {
    "id": "arXiv:2110.15105",
    "title": "A Game-Theoretic Approach for Improving Generalization Ability of TSP  Solvers",
    "abstract": "A Game-Theoretic Approach for Improving Generalization Ability of TSP  Solvers",
    "descriptor": "",
    "authors": [
      "Chenguang Wang",
      "Yaodong Yang",
      "Oliver Slumbers",
      "Congying Han",
      "Tiande Guo",
      "Haifeng Zhang",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15105"
  },
  {
    "id": "arXiv:2110.15137",
    "title": "Learning Aggregations of Binary Activated Neural Networks with  Probabilities over Representations",
    "abstract": "Learning Aggregations of Binary Activated Neural Networks with  Probabilities over Representations",
    "descriptor": "",
    "authors": [
      "Louis Fortier-Dubois",
      "Ga\u00ebl Letarte",
      "Benjamin Leblanc",
      "Fran\u00e7ois Laviolette",
      "Pascal Germain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15137"
  },
  {
    "id": "arXiv:2110.15255",
    "title": "Self-Supervised Learning Disentangled Group Representation as Feature",
    "abstract": "Comments: Accepted by NeurIPS 2021 (Spotlight)",
    "descriptor": "\nComments: Accepted by NeurIPS 2021 (Spotlight)\n",
    "authors": [
      "Tan Wang",
      "Zhongqi Yue",
      "Jianqiang Huang",
      "Qianru Sun",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15255"
  },
  {
    "id": "arXiv:2110.15269",
    "title": "Cognitive network science quantifies feelings expressed in suicide  letters and Reddit mental health communities",
    "abstract": "Cognitive network science quantifies feelings expressed in suicide  letters and Reddit mental health communities",
    "descriptor": "",
    "authors": [
      "Simmi Marina Joseph",
      "Salvatore Citraro",
      "Virginia Morini",
      "Giulio Rossetti",
      "Massimo Stella"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.15269"
  }
]
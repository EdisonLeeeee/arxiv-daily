[
  {
    "id": "arXiv:2111.00002",
    "title": "Earning Sans Learning: Noisy Decision-Making and Labor Supply on Gig  Economy Platforms",
    "abstract": "We study a gig economy platform's problem of finding optimal compensation\nschemes when faced with workers who myopically base their participation\ndecisions on limited information with respect to their earnings. The stylized\nmodel we consider captures two key, related features absent from prior work on\nthe operations of on-demand service platforms: (i) workers' lack of information\nregarding the distribution from which their earnings are drawn and (ii) worker\ndecisions that are sensitive to variability in earnings. Despite its stylized\nnature, our model induces a complex stochastic optimization problem whose\nnatural fluid relaxation is also a priori intractable. Nevertheless, we uncover\na surprising structural property of the relaxation that allows us to design a\ntractable, fast-converging heuristic policy that is asymptotically optimal\namongst the space of all policies that fulfill a fairness property. In doing\nso, via both theory and extensive simulations, we uncover phenomena that may\narise when earnings are volatile and hard to predict, as both the empirical\nliterature and our own data-driven observations suggest may be prevalent on gig\neconomy platforms.",
    "descriptor": "",
    "authors": [
      "Daniel Freund",
      "Chamsi Hssaine"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.00002"
  },
  {
    "id": "arXiv:2111.00003",
    "title": "A New Algorithm based on Extent Bit-array for Computing Formal Concepts",
    "abstract": "The emergence of Formal Concept Analysis (FCA) as a data analysis technique\nhas increased the need for developing algorithms which can compute formal\nconcepts quickly. The current efficient algorithms for FCA are variants of the\nClose-By-One (CbO) algorithm, such as In-Close2, In-Close3 and In-Close4, which\nare all based on horizontal storage of contexts. In this paper, based on\nalgorithm In-Close4, a new algorithm based on the vertical storage of contexts,\ncalled In-Close5, is proposed, which can significantly reduce both the time\ncomplexity and space complexity of algorithm In-Close4. Technically, the new\nalgorithm stores both context and extent of a concept as a vertical bit-array,\nwhile within In-Close4 algorithm the context is stored only as a horizontal\nbit-array, which is very slow in finding the intersection of two extent sets.\nExperimental results demonstrate that the proposed algorithm is much more\neffective than In-Close4 algorithm, and it also has a broader scope of\napplicability in computing formal concept in which one can solve the problems\nthat cannot be solved by the In-Close4 algorithm.",
    "descriptor": "",
    "authors": [
      "Jianqin Zhou",
      "Sichun Yang",
      "Xifeng Wang",
      "Wanquan Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.00003"
  },
  {
    "id": "arXiv:2111.00004",
    "title": "Granule Description based on Compound Concepts",
    "abstract": "Concise granule descriptions for describable granules and approaching\ndescription methods for indescribable granules are challenging and important\nissues in granular computing. The concept with only common attributes has been\nfrequently studied. To investigate the granules with some special needs, we\npropose two new types of compound concepts in this paper: bipolar concept and\ncommon-and-necessary concept. Based on the definitions of concept-forming\noperations, the logical formulas are derived for each of the following types of\nconcepts: formal concept, three-way concept, object oriented concept, bipolar\nconcept and common-and-necessary concept. Furthermore, by utilizing the logical\nrelationship among various concepts, we have derived concise and unified\nequivalent conditions for describable granules and approaching description\nmethods for indescribable granules for all five kinds of concepts.",
    "descriptor": "",
    "authors": [
      "Jianqin Zhou",
      "Sichun Yang",
      "Xifeng Wang",
      "Wanquan Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00004"
  },
  {
    "id": "arXiv:2111.00005",
    "title": "Concept and Attribute Reduction Based on Rectangle Theory of Formal  Concept",
    "abstract": "Based on rectangle theory of formal concept and set covering theory, the\nconcept reduction preserving binary relations is investigated in this paper. It\nis known that there are three types of formal concepts: core concepts, relative\nnecessary concepts and unnecessary concepts. First, we present the new judgment\nresults for relative necessary concepts and unnecessary concepts. Second, we\nderive the bounds for both the maximum number of relative necessary concepts\nand the maximum number of unnecessary concepts and it is a difficult problem as\neither in concept reduction preserving binary relations or attribute reduction\nof decision formal contexts, the computation of formal contexts from formal\nconcepts is a challenging problem. Third, based on rectangle theory of formal\nconcept, a fast algorithm for reducing attributes while preserving the\nextensions for a set of formal concepts is proposed using the extension\nbit-array technique, which allows multiple context cells to be processed by a\nsingle 32-bit or 64-bit operator. Technically, the new algorithm could store\nboth formal context and extent of a concept as bit-arrays, and we can use\nbit-operations to process set operations \"or\" as well as \"and\". One more merit\nis that the new algorithm does not need to consider other concepts in the\nconcept lattice, thus the algorithm is explicit to understand and fast.\nExperiments demonstrate that the new algorithm is effective in the computation\nof attribute reductions.",
    "descriptor": "",
    "authors": [
      "Jianqin Zhou",
      "Sichun Yang",
      "Xifeng Wang",
      "Wanquan Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00005"
  },
  {
    "id": "arXiv:2111.00006",
    "title": "Adaptive Hierarchical Similarity Metric Learning with Noisy Labels",
    "abstract": "Deep Metric Learning (DML) plays a critical role in various machine learning\ntasks. However, most existing deep metric learning methods with binary\nsimilarity are sensitive to noisy labels, which are widely present in\nreal-world data. Since these noisy labels often cause severe performance\ndegradation, it is crucial to enhance the robustness and generalization ability\nof DML. In this paper, we propose an Adaptive Hierarchical Similarity Metric\nLearning method. It considers two noise-insensitive information, \\textit{i.e.},\nclass-wise divergence and sample-wise consistency. Specifically, class-wise\ndivergence can effectively excavate richer similarity information beyond binary\nin modeling by taking advantage of Hyperbolic metric learning, while\nsample-wise consistency can further improve the generalization ability of the\nmodel using contrastive augmentation. More importantly, we design an adaptive\nstrategy to integrate this information in a unified view. It is noteworthy that\nthe new method can be extended to any pair-based metric loss. Extensive\nexperimental results on benchmark datasets demonstrate that our method achieves\nstate-of-the-art performance compared with current deep metric learning\napproaches.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Jiexi Yan",
      "Lei Luo",
      "Cheng Deng",
      "Heng Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00006"
  },
  {
    "id": "arXiv:2111.00007",
    "title": "Domain Agnostic Few-Shot Learning For Document Intelligence",
    "abstract": "Few-shot learning aims to generalize to novel classes with only a few samples\nwith class labels. Research in few-shot learning has borrowed techniques from\ntransfer learning, metric learning, meta-learning, and Bayesian methods. These\nmethods also aim to train models from limited training samples, and while\nencouraging performance has been achieved, they often fail to generalize to\nnovel domains. Many of the existing meta-learning methods rely on training data\nfor which the base classes are sampled from the same domain as the novel\nclasses used for meta-testing. However, in many applications in the industry,\nsuch as document classification, collecting large samples of data for\nmeta-learning is infeasible or impossible. While research in the field of the\ncross-domain few-shot learning exists, it is mostly limited to computer vision.\nTo our knowledge, no work yet exists that examines the use of few-shot learning\nfor classification of semi-structured documents (scans of paper documents)\ngenerated as part of a business workflow (forms, letters, bills, etc.). Here\nthe domain shift is significant, going from natural images to the\nsemi-structured documents of interest. In this work, we address the problem of\nfew-shot document image classification under domain shift. We evaluate our work\nby extensive comparisons with existing methods. Experimental results\ndemonstrate that the proposed method shows consistent improvements on the\nfew-shot classification performance under domain shift.",
    "descriptor": "",
    "authors": [
      "Jaya Krishna Mandivarapu",
      "Eric bunch",
      "Glenn fung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00007"
  },
  {
    "id": "arXiv:2111.00008",
    "title": "Reinforced Workload Distribution Fairness",
    "abstract": "Network load balancers are central components in data centers, that\ndistributes workloads across multiple servers and thereby contribute to\noffering scalable services. However, when load balancers operate in dynamic\nenvironments with limited monitoring of application server loads, they rely on\nheuristic algorithms that require manual configurations for fairness and\nperformance. To alleviate that, this paper proposes a distributed asynchronous\nreinforcement learning mechanism to-with no active load balancer state\nmonitoring and limited network observations-improve the fairness of the\nworkload distribution achieved by a load balancer. The performance of proposed\nmechanism is evaluated and compared with stateof-the-art load balancing\nalgorithms in a simulator, under configurations with progressively increasing\ncomplexities. Preliminary results show promise in RLbased load balancing\nalgorithms, and identify additional challenges and future research directions,\nincluding reward function design and model scalability.",
    "descriptor": "",
    "authors": [
      "Zhiyuan Yao",
      "Zihan Ding",
      "Thomas Heide Clausen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.00008"
  },
  {
    "id": "arXiv:2111.00010",
    "title": "Federated Semi-Supervised Learning with Class Distribution Mismatch",
    "abstract": "Many existing federated learning (FL) algorithms are designed for supervised\nlearning tasks, assuming that the local data owned by the clients are well\nlabeled. However, in many practical situations, it could be difficult and\nexpensive to acquire complete data labels. Federated semi-supervised learning\n(Fed-SSL) is an attractive solution for fully utilizing both labeled and\nunlabeled data. Similar to that encountered in federated supervised learning,\nclass distribution of labeled/unlabeled data could be non-i.i.d. among clients.\nBesides, in each client, the class distribution of labeled data may be distinct\nfrom that of unlabeled data. Unfortunately, both can severely jeopardize the FL\nperformance. To address such challenging issues, we introduce two proper\nregularization terms that can effectively alleviate the class distribution\nmismatch problem in Fed-SSL. In addition, to overcome the non-i.i.d. data, we\nleverage the variance reduction and normalized averaging techniques to develop\na novel Fed-SSL algorithm. Theoretically, we prove that the proposed method has\na convergence rate of $\\mathcal{O}(1/\\sqrt{T})$, where $T$ is the number of\ncommunication rounds, even when the data distribution are non-i.i.d. among\nclients. To the best of our knowledge, it is the first formal convergence\nresult for Fed-SSL problems. Numerical experiments based on MNIST data and\nCIFAR-10 data show that the proposed method can greatly improve the\nclassification accuracy compared to baselines.",
    "descriptor": "",
    "authors": [
      "Zhiguo Wang",
      "Xintong Wang",
      "Ruoyu Sun",
      "Tsung-Hui Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00010"
  },
  {
    "id": "arXiv:2111.00035",
    "title": "Skyformer: Remodel Self-Attention with Gaussian Kernel and Nystr\u00f6m  Method",
    "abstract": "Transformers are expensive to train due to the quadratic time and space\ncomplexity in the self-attention mechanism. On the other hand, although kernel\nmachines suffer from the same computation bottleneck in pairwise dot products,\nseveral approximation schemes have been successfully incorporated to\nconsiderably reduce their computational cost without sacrificing too much\naccuracy. In this work, we leverage the computation methods for kernel machines\nto alleviate the high computational cost and introduce Skyformer, which\nreplaces the softmax structure with a Gaussian kernel to stabilize the model\ntraining and adapts the Nystr\\\"om method to a non-positive semidefinite matrix\nto accelerate the computation. We further conduct theoretical analysis by\nshowing that the matrix approximation error of our proposed method is small in\nthe spectral norm. Experiments on Long Range Arena benchmark show that the\nproposed method is sufficient in getting comparable or even better performance\nthan the full self-attention while requiring fewer computation resources.",
    "descriptor": "\nComments: To appear in NeurIPS 2021\n",
    "authors": [
      "Yifan Chen",
      "Qi Zeng",
      "Heng Ji",
      "Yun Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00035"
  },
  {
    "id": "arXiv:2111.00038",
    "title": "On-device Real-time Hand Gesture Recognition",
    "abstract": "We present an on-device real-time hand gesture recognition (HGR) system,\nwhich detects a set of predefined static gestures from a single RGB camera. The\nsystem consists of two parts: a hand skeleton tracker and a gesture classifier.\nWe use MediaPipe Hands as the basis of the hand skeleton tracker, improve the\nkeypoint accuracy, and add the estimation of 3D keypoints in a world metric\nspace. We create two different gesture classifiers, one based on heuristics and\nthe other using neural networks (NN).",
    "descriptor": "\nComments: 5 pages, 6 figures; ICCV Workshop on Computer Vision for Augmented and Virtual Reality, Montreal, Canada, 2021\n",
    "authors": [
      "George Sung",
      "Kanstantsin Sokal",
      "Esha Uboweja",
      "Valentin Bazarevsky",
      "Jonathan Baccash",
      "Eduard Gabriel Bazavan",
      "Chuo-Ling Chang",
      "Matthias Grundmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00038"
  },
  {
    "id": "arXiv:2111.00042",
    "title": "CvS: Classification via Segmentation For Small Datasets",
    "abstract": "Deep learning models have shown promising results in a wide range of computer\nvision applications across various domains. The success of deep learning\nmethods relies heavily on the availability of a large amount of data. Deep\nneural networks are prone to overfitting when data is scarce. This problem\nbecomes even more severe for neural network with classification head with\naccess to only a few data points. However, acquiring large-scale datasets is\nvery challenging, laborious, or even infeasible in some domains. Hence,\ndeveloping classifiers that are able to perform well in small data regimes is\ncrucial for applications with limited data. This paper presents CvS, a\ncost-effective classifier for small datasets that derives the classification\nlabels from predicting the segmentation maps. We employ the label propagation\nmethod to achieve a fully segmented dataset with only a handful of manually\nsegmented data. We evaluate the effectiveness of our framework on diverse\nproblems showing that CvS is able to achieve much higher classification results\ncompared to previous methods when given only a handful of examples.",
    "descriptor": "",
    "authors": [
      "Nooshin Mojab",
      "Philip S. Yu",
      "Joelle A. Hallak",
      "Darvin Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00042"
  },
  {
    "id": "arXiv:2111.00048",
    "title": "On the Power of Edge Independent Graph Models",
    "abstract": "Why do many modern neural-network-based graph generative models fail to\nreproduce typical real-world network characteristics, such as high triangle\ndensity? In this work we study the limitations of edge independent random graph\nmodels, in which each edge is added to the graph independently with some\nprobability. Such models include both the classic Erd\\\"{o}s-R\\'{e}nyi and\nstochastic block models, as well as modern generative models such as NetGAN,\nvariational graph autoencoders, and CELL. We prove that subject to a bounded\noverlap condition, which ensures that the model does not simply memorize a\nsingle graph, edge independent models are inherently limited in their ability\nto generate graphs with high triangle and other subgraph densities. Notably,\nsuch high densities are known to appear in real-world social networks and other\ngraphs. We complement our negative results with a simple generative model that\nbalances overlap and accuracy, performing comparably to more complex models in\nreconstructing many graph statistics.",
    "descriptor": "",
    "authors": [
      "Sudhanshu Chanpuriya",
      "Cameron Musco",
      "Konstantinos Sotiropoulos",
      "Charalampos E. Tsourakakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.00048"
  },
  {
    "id": "arXiv:2111.00052",
    "title": "Diagnosing Web Data of ICTs to Provide Focused Assistance in  Agricultural Adoptions",
    "abstract": "The past decade has witnessed a rapid increase in technology ownership across\nrural areas of India, signifying the potential for ICT initiatives to empower\nrural households. In our work, we focus on the web infrastructure of one such\nICT - Digital Green that started in 2008. Following a participatory approach\nfor content production, Digital Green disseminates instructional agricultural\nvideos to smallholder farmers via human mediators to improve the adoption of\nfarming practices. Their web-based data tracker, CoCo, captures data related to\nthese processes, storing the attendance and adoption logs of over 2.3 million\nfarmers across three continents and twelve countries. Using this data, we model\nthe components of the Digital Green ecosystem involving the past\nattendance-adoption behaviours of farmers, the content of the videos screened\nto them and their demographic features across five states in India. We use\nstatistical tests to identify different factors which distinguish farmers with\nhigher adoption rates to understand why they adopt more than others. Our\nresearch finds that farmers with higher adoption rates adopt videos of shorter\nduration and belong to smaller villages. The co-attendance and co-adoption\nnetworks of farmers indicate that they greatly benefit from past adopters of a\nvideo from their village and group when it comes to adopting practices from the\nsame video. Following our analysis, we model the adoption of practices from a\nvideo as a prediction problem to identify and assist farmers who might face\nchallenges in adoption in each of the five states. We experiment with different\nmodel architectures and achieve macro-f1 scores ranging from 79% to 89% using a\nRandom Forest classifier. Finally, we measure the importance of different\nfeatures using SHAP values and provide implications for improving the adoption\nrates of nearly a million farmers across five states in India.",
    "descriptor": "",
    "authors": [
      "Ashwin Singh",
      "Mallika Subramanian",
      "Anmol Agarwal",
      "Pratyush Priyadarshi",
      "Shrey Gupta",
      "Kiran Garimella",
      "Sanjeev Kumar",
      "Ritesh Kumar",
      "Lokesh Garg",
      "Erica Arya",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.00052"
  },
  {
    "id": "arXiv:2111.00053",
    "title": "Symbolic Regression via Neural-Guided Genetic Programming Population  Seeding",
    "abstract": "Symbolic regression is the process of identifying mathematical expressions\nthat fit observed output from a black-box process. It is a discrete\noptimization problem generally believed to be NP-hard. Prior approaches to\nsolving the problem include neural-guided search (e.g. using reinforcement\nlearning) and genetic programming. In this work, we introduce a hybrid\nneural-guided/genetic programming approach to symbolic regression and other\ncombinatorial optimization problems. We propose a neural-guided component used\nto seed the starting population of a random restart genetic programming\ncomponent, gradually learning better starting populations. On a number of\ncommon benchmark tasks to recover underlying expressions from a dataset, our\nmethod recovers 65% more expressions than a recently published top-performing\nmodel using the same experimental setup. We demonstrate that running many\ngenetic programming generations without interdependence on the neural-guided\ncomponent performs better for symbolic regression than alternative formulations\nwhere the two are more strongly coupled. Finally, we introduce a new set of 22\nsymbolic regression benchmark problems with increased difficulty over existing\nbenchmarks. Source code is provided at\nwww.github.com/brendenpetersen/deep-symbolic-optimization.",
    "descriptor": "\nComments: Accepted at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "T. Nathan Mundhenk",
      "Mikel Landajuela",
      "Ruben Glatt",
      "Claudio P. Santiago",
      "Daniel M. Faissol",
      "Brenden K. Petersen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00053"
  },
  {
    "id": "arXiv:2111.00056",
    "title": "Generalized Data Weighting via Class-level Gradient Manipulation",
    "abstract": "Label noise and class imbalance are two major issues coexisting in real-world\ndatasets. To alleviate the two issues, state-of-the-art methods reweight each\ninstance by leveraging a small amount of clean and unbiased data. Yet, these\nmethods overlook class-level information within each instance, which can be\nfurther utilized to improve performance. To this end, in this paper, we propose\nGeneralized Data Weighting (GDW) to simultaneously mitigate label noise and\nclass imbalance by manipulating gradients at the class level. To be specific,\nGDW unrolls the loss gradient to class-level gradients by the chain rule and\nreweights the flow of each gradient separately. In this way, GDW achieves\nremarkable performance improvement on both issues. Aside from the performance\ngain, GDW efficiently obtains class-level weights without introducing any extra\ncomputational cost compared with instance weighting methods. Specifically, GDW\nperforms a gradient descent step on class-level weights, which only relies on\nintermediate gradients. Extensive experiments in various settings verify the\neffectiveness of GDW. For example, GDW outperforms state-of-the-art methods by\n$2.56\\%$ under the $60\\%$ uniform noise setting in CIFAR10. Our code is\navailable at https://github.com/GGchen1997/GDW-NIPS2021.",
    "descriptor": "\nComments: 17 pages, 8 figures, accepted by NeurIPS 2021 for a poster session, camera-ready version, initial submission to arXiv\n",
    "authors": [
      "Can Chen",
      "Shuhao Zheng",
      "Xi Chen",
      "Erqun Dong",
      "Xue Liu",
      "Hao Liu",
      "Dejing Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00056"
  },
  {
    "id": "arXiv:2111.00057",
    "title": "Word embeddings for topic modeling: an application to the estimation of  the economic policy uncertainty index",
    "abstract": "Quantification of economic uncertainty is a key concept for the prediction of\nmacro economic variables such as gross domestic product (GDP), and it becomes\nparticularly relevant on real-time or short-time predictions methodologies,\nsuch as nowcasting, where it is required a large amount of time series data,\ncommonly with different structures and frequencies. Most of the data comes from\nthe official agencies statistics and non-public institutions, however, relying\nour estimates in just the traditional data mentioned before, have some\ndisadvantages. One of them is that economic uncertainty could not be\nrepresented or measured in a proper way based solely in financial or\nmacroeconomic data, another one, is that they are susceptible to lack of\ninformation due to extraordinary events, such as the current COVID-19 pandemic.\nFor these reasons, it is very common nowadays to use some non-traditional data\nfrom different sources, such as social networks or digital newspapers, in\naddition to the traditional data from official sources. The economic policy\nuncertainty (EPU) index, is the most used newspaper-based indicator to quantify\nthe uncertainty, and is based on topic modeling of newspapers. In this paper,\nwe propose a methodology to estimate the EPU index, which incorporates a fast\nand efficient method for topic modeling of digital news based on semantic\nclustering with word embeddings, allowing to update the index in real-time,\nwhich is a drawback with another proposals that use computationally intensive\nmethods for topic modeling, such as Latent Dirichlet Allocation (LDA). We show\nthat our proposal allow us to update the index and significantly reduces the\ntime required for new document assignation into topics.",
    "descriptor": "\nComments: Preprint version\n",
    "authors": [
      "Hairo U. Miranda Belmonte",
      "Victor Mu\u00f1iz-S\u00e1nchez",
      "Francisco Corona"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.00057"
  },
  {
    "id": "arXiv:2111.00062",
    "title": "Improving Generalization Bounds for VC Classes Using the Hypergeometric  Tail Inversion",
    "abstract": "We significantly improve the generalization bounds for VC classes by using\ntwo main ideas. First, we consider the hypergeometric tail inversion to obtain\na very tight non-uniform distribution-independent risk upper bound for VC\nclasses. Second, we optimize the ghost sample trick to obtain a further\nnon-negligible gain. These improvements are then used to derive a relative\ndeviation bound, a multiclass margin bound, as well as a lower bound. Numerical\ncomparisons show that the new bound is nearly never vacuous, and is tighter\nthan other VC bounds for all reasonable data set sizes.",
    "descriptor": "\nComments: 15 pages (body), 36 pages (appendices), 54 pages (total), 13 figures\n",
    "authors": [
      "Jean-Samuel Leboeuf",
      "Fr\u00e9d\u00e9ric LeBlanc",
      "Mario Marchand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00062"
  },
  {
    "id": "arXiv:2111.00063",
    "title": "Polyline Based Generative Navigable Space Segmentation for Autonomous  Visual Navigation",
    "abstract": "Detecting navigable space is a fundamental capability for mobile robots\nnavigating in unknown or unmapped environments. In this work, we treat the\nvisual navigable space segmentation as a scene decomposition problem and\npropose Polyline Segmentation Variational AutoEncoder Networks (PSV-Nets), a\nrepresentation-learning-based framework to enable robots to learn the navigable\nspace segmentation in an unsupervised manner. Current segmentation techniques\nheavily rely on supervised learning strategies which demand a large amount of\npixel-level annotated images. In contrast, the proposed framework leverages a\ngenerative model - Variational AutoEncoder (VAE) and an AutoEncoder (AE) to\nlearn a polyline representation that compactly outlines the desired navigable\nspace boundary in an unsupervised way. We also propose a visual receding\nhorizon planning method that uses the learned navigable space and a Scaled\nEuclidean Distance Field (SEDF) to achieve autonomous navigation without an\nexplicit map. Through extensive experiments, we have validated that the\nproposed PSV-Nets can learn the visual navigable space with high accuracy, even\nwithout any single label. We also show that the prediction of the PSV-Nets can\nbe further improved with a small number of labels (if available) and can\nsignificantly outperform the state-of-the-art fully supervised-learning-based\nsegmentation methods.",
    "descriptor": "",
    "authors": [
      "Zheng Chen",
      "Zhengming Ding",
      "David Crandall",
      "Lantao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00063"
  },
  {
    "id": "arXiv:2111.00064",
    "title": "Node Feature Extraction by Self-Supervised Multi-scale Neighborhood  Prediction",
    "abstract": "Learning on graphs has attracted significant attention in the learning\ncommunity due to numerous real-world applications. In particular, graph neural\nnetworks (GNNs), which take numerical node features and graph structure as\ninputs, have been shown to achieve state-of-the-art performance on various\ngraph-related learning tasks. Recent works exploring the correlation between\nnumerical node features and graph structure via self-supervised learning have\npaved the way for further performance improvements of GNNs. However, methods\nused for extracting numerical node features from raw data are still\ngraph-agnostic within standard GNN pipelines. This practice is sub-optimal as\nit prevents one from fully utilizing potential correlations between graph\ntopology and node attributes. To mitigate this issue, we propose a new\nself-supervised learning framework, Graph Information Aided Node feature\nexTraction (GIANT). GIANT makes use of the eXtreme Multi-label Classification\n(XMC) formalism, which is crucial for fine-tuning the language model based on\ngraph information, and scales to large datasets. We also provide a theoretical\nanalysis that justifies the use of XMC over link prediction and motivates\nintegrating XR-Transformers, a powerful method for solving XMC problems, into\nthe GIANT framework. We demonstrate the superior performance of GIANT over the\nstandard GNN pipeline on Open Graph Benchmark datasets: For example, we improve\nthe accuracy of the top-ranked method GAMLP from $68.25\\%$ to $69.67\\%$, SGC\nfrom $63.29\\%$ to $66.10\\%$ and MLP from $47.24\\%$ to $61.10\\%$ on the\nogbn-papers100M dataset by leveraging GIANT.",
    "descriptor": "",
    "authors": [
      "Eli Chien",
      "Wei-Cheng Chang",
      "Cho-Jui Hsieh",
      "Hsiang-Fu Yu",
      "Jiong Zhang",
      "Olgica Milenkovic",
      "Inderjit S Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00064"
  },
  {
    "id": "arXiv:2111.00067",
    "title": "Multi-Objective Autonomous Exploration on Real-Time Continuous Occupancy  Maps",
    "abstract": "Autonomous exploration in unknown environments using mobile robots is the\npillar of many robotic applications. Existing exploration frameworks either\nselect the nearest geometric frontier or the nearest information-theoretic\nfrontier. However, just because a frontier itself is informative does not\nnecessarily mean that the robot will be in an informative area after reaching\nthat frontier. To fill this gap, we propose to use a multi-objective variant of\nMonte-Carlo tree search that provides a non-myopic Pareto optimal action\nsequence leading the robot to a frontier with the greatest extent of unknown\narea uncovering. We also adopted Bayesian Hilbert Map (BHM) for continuous\noccupancy mapping and made it more applicable to real-time tasks.",
    "descriptor": "",
    "authors": [
      "Zheng Chen",
      "Weizhe Chen",
      "Shi Bai",
      "Lantao Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00067"
  },
  {
    "id": "arXiv:2111.00070",
    "title": "Deep inference of latent dynamics with spatio-temporal super-resolution  using selective backpropagation through time",
    "abstract": "Modern neural interfaces allow access to the activity of up to a million\nneurons within brain circuits. However, bandwidth limits often create a\ntrade-off between greater spatial sampling (more channels or pixels) and the\ntemporal frequency of sampling. Here we demonstrate that it is possible to\nobtain spatio-temporal super-resolution in neuronal time series by exploiting\nrelationships among neurons, embedded in latent low-dimensional population\ndynamics. Our novel neural network training strategy, selective backpropagation\nthrough time (SBTT), enables learning of deep generative models of latent\ndynamics from data in which the set of observed variables changes at each time\nstep. The resulting models are able to infer activity for missing samples by\ncombining observations with learned latent dynamics. We test SBTT applied to\nsequential autoencoders and demonstrate more efficient and higher-fidelity\ncharacterization of neural population dynamics in electrophysiological and\ncalcium imaging data. In electrophysiology, SBTT enables accurate inference of\nneuronal population dynamics with lower interface bandwidths, providing an\navenue to significant power savings for implanted neuroelectronic interfaces.\nIn applications to two-photon calcium imaging, SBTT accurately uncovers\nhigh-frequency temporal structure underlying neural population activity,\nsubstantially outperforming the current state-of-the-art. Finally, we\ndemonstrate that performance could be further improved by using limited,\nhigh-bandwidth sampling to pretrain dynamics models, and then using SBTT to\nadapt these models for sparsely-sampled data.",
    "descriptor": "",
    "authors": [
      "Feng Zhu",
      "Andrew R. Sedler",
      "Harrison A. Grier",
      "Nauman Ahad",
      "Mark A. Davenport",
      "Matthew T. Kaufman",
      "Andrea Giovannucci",
      "Chethan Pandarinath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2111.00070"
  },
  {
    "id": "arXiv:2111.00071",
    "title": "ReSkin: versatile, replaceable, lasting tactile skins",
    "abstract": "Soft sensors have continued growing interest in robotics, due to their\nability to enable both passive conformal contact from the material properties\nand active contact data from the sensor properties. However, the same\nproperties of conformal contact result in faster deterioration of soft sensors\nand larger variations in their response characteristics over time and across\nsamples, inhibiting their ability to be long-lasting and replaceable. ReSkin is\na tactile soft sensor that leverages machine learning and magnetic sensing to\noffer a low-cost, diverse and compact solution for long-term use. Magnetic\nsensing separates the electronic circuitry from the passive interface, making\nit easier to replace interfaces as they wear out while allowing for a wide\nvariety of form factors. Machine learning allows us to learn sensor response\nmodels that are robust to variations across fabrication and time, and our\nself-supervised learning algorithm enables finer performance enhancement with\nsmall, inexpensive data collection procedures. We believe that ReSkin opens the\ndoor to more versatile, scalable and inexpensive tactile sensation modules than\nexisting alternatives.",
    "descriptor": "\nComments: CoRL 2021. Project Website: this https URL . First two authors contributed equally\n",
    "authors": [
      "Raunaq Bhirangi",
      "Tess Hellebrekers",
      "Carmel Majidi",
      "Abhinav Gupta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00071"
  },
  {
    "id": "arXiv:2111.00072",
    "title": "Generalized Proximal Policy Optimization with Sample Reuse",
    "abstract": "In real-world decision making tasks, it is critical for data-driven\nreinforcement learning methods to be both stable and sample efficient.\nOn-policy methods typically generate reliable policy improvement throughout\ntraining, while off-policy methods make more efficient use of data through\nsample reuse. In this work, we combine the theoretically supported stability\nbenefits of on-policy algorithms with the sample efficiency of off-policy\nalgorithms. We develop policy improvement guarantees that are suitable for the\noff-policy setting, and connect these bounds to the clipping mechanism used in\nProximal Policy Optimization. This motivates an off-policy version of the\npopular algorithm that we call Generalized Proximal Policy Optimization with\nSample Reuse. We demonstrate both theoretically and empirically that our\nalgorithm delivers improved performance by effectively balancing the competing\ngoals of stability and sample efficiency.",
    "descriptor": "\nComments: To appear in 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "James Queeney",
      "Ioannis Ch. Paschalidis",
      "Christos G. Cassandras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00072"
  },
  {
    "id": "arXiv:2111.00075",
    "title": "Efficient Map Prediction via Low-Rank Matrix Completion",
    "abstract": "In many autonomous mapping tasks, the maps cannot be accurately constructed\ndue to various reasons such as sparse, noisy, and partial sensor measurements.\nWe propose a novel map prediction method built upon the recent success of\nLow-Rank Matrix Completion. The proposed map prediction is able to achieve both\nmap interpolation and extrapolation on raw poor-quality maps with missing or\nnoisy observations. We validate with extensive simulated experiments that the\napproach can achieve real-time computation for large maps, and the performance\nis superior to the state-of-the-art map prediction approach - Bayesian Hilbert\nMapping in terms of mapping accuracy and computation time. Then we demonstrate\nthat with the proposed real-time map prediction framework, the coverage\nconvergence rate (per action step) for a set of representative coverage\nplanning methods commonly used for environmental modeling and monitoring tasks\ncan be significantly improved.",
    "descriptor": "",
    "authors": [
      "Zheng Chen",
      "Shi Bai",
      "Lantao Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00075"
  },
  {
    "id": "arXiv:2111.00076",
    "title": "Game Transformations that preserve Nash Equilibrium sets and/or Best  Response sets",
    "abstract": "In the literature on simultaneous non-cooperative games, it is well-known\nthat a positive affine (linear) transformation (PAT) of the utility payoffs do\nnot change the best response sets and the Nash equilibrium set. PATs have been\nsuccessfully used to expand the classes of 2-player games for which we can\ncompute a Nash equilibrium in polynomial time.\nWe investigate which game transformations other than PATs also possess one of\nthe following properties: (i) The game transformation shall not change the Nash\nequilibrium set when being applied on an arbitrary game. (ii) The game\ntransformation shall not change the best response sets when being applied on an\narbitrary game.\nFirst, we prove that property (i) implies property (ii). Over a series of\nfurther results, we derive that game transformations with property (ii) must be\npositive affine. Therefore, we obtained two new and equivalent\ncharacterisations with game theoretic meaning for what it means to be a\npositive affine transformation.\nAll our results in particular hold for the 2-player case of bimatrix games.",
    "descriptor": "\nComments: 18 pages, 0 figures\n",
    "authors": [
      "Emanuel Tewolde"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2111.00076"
  },
  {
    "id": "arXiv:2111.00079",
    "title": "Deep Deterministic Uncertainty for Semantic Segmentation",
    "abstract": "We extend Deep Deterministic Uncertainty (DDU), a method for uncertainty\nestimation using feature space densities, to semantic segmentation. DDU enables\nquantifying and disentangling epistemic and aleatoric uncertainty in a single\nforward pass through the model. We study the similarity of feature\nrepresentations of pixels at different locations for the same class and\nconclude that it is feasible to apply DDU location independently, which leads\nto a significant reduction in memory consumption compared to pixel dependent\nDDU. Using the DeepLab-v3+ architecture on Pascal VOC 2012, we show that DDU\nimproves upon MC Dropout and Deep Ensembles while being significantly faster to\ncompute.",
    "descriptor": "",
    "authors": [
      "Jishnu Mukhoti",
      "Joost van Amersfoort",
      "Philip H.S. Torr",
      "Yarin Gal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00079"
  },
  {
    "id": "arXiv:2111.00080",
    "title": "Targeted Hardening of Electric Distribution System Components for  Enhanced Resilience against Earthquakes",
    "abstract": "Securing the power system from catastrophic natural disasters is a rising\nproblem in power system operation and planning. This paper particularly\nconsiders earthquake and aims to evaluate and improve the resilience of power\ndistribution networks by developing a novel hardware hardening framework. In\nthe proposed framework, fragility curves of the network equipment are used to\nrepresent equipment failure probabilities when facing an earthquake, and\nfailure scenarios of the distribution network are obtained via the Monte Carlo\nmethod. Based on the distribution network topology and the locations of\nessential loads, various hardware hardening strategies are determined within\nthe proposed framework. Through a series of resilience and economic analyses,\nthe optimal hardening strategy is determined to improve the resilience and\nsupply the essential loads during and after the earthquake. The efficacy of the\nproposed approach is examined through simulations on an IEEE 33-bus test\nfeeder.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Mahan Fakouri Fard",
      "Mostafa Sahraei-Ardakani",
      "Ge Ou",
      "Mingxi Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00080"
  },
  {
    "id": "arXiv:2111.00082",
    "title": "PiDRAM: A Holistic End-to-end FPGA-based Framework for  Processing-in-DRAM",
    "abstract": "Processing-using-memory (PuM) techniques leverage the analog operation of\nmemory cells to perform computation. Several recent works have demonstrated PuM\ntechniques in off-the-shelf DRAM devices. Since DRAM is the dominant memory\ntechnology as main memory in current computing systems, these PuM techniques\nrepresent an opportunity for alleviating the data movement bottleneck at very\nlow cost. However, system integration of PuM techniques imposes non-trivial\nchallenges that are yet to be solved. Design space exploration of potential\nsolutions to the PuM integration challenges requires appropriate tools to\ndevelop necessary hardware and software components. Unfortunately, current\nspecialized DRAM-testing platforms, or system simulators do not provide the\nflexibility and/or the holistic system view that is necessary to deal with PuM\nintegration challenges.\nWe design and develop PiDRAM, the first flexible end-to-end framework that\nenables system integration studies and evaluation of real PuM techniques.\nPiDRAM provides software and hardware components to rapidly integrate PuM\ntechniques across the whole system software and hardware stack (e.g., necessary\nmodifications in the operating system, memory controller). We implement PiDRAM\non an FPGA-based platform along with an open-source RISC-V system. Using\nPiDRAM, we implement and evaluate two state-of-the-art PuM techniques: in-DRAM\n(i) copy and initialization, (ii) true random number generation. Our results\nshow that the in-memory copy and initialization techniques can improve the\nperformance of bulk copy operations by 12.6x and bulk initialization operations\nby 14.6x on a real system. Implementing the true random number generator\nrequires only 190 lines of Verilog and 74 lines of C code using PiDRAM's\nsoftware and hardware components.",
    "descriptor": "\nComments: 15 pages, 11 figures\n",
    "authors": [
      "Ataberk Olgun",
      "Juan G\u00f3mez Luna",
      "Konstantinos Kanellopoulos",
      "Behzad Salami",
      "Hasan Hassan",
      "O\u011fuz Ergin",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.00082"
  },
  {
    "id": "arXiv:2111.00083",
    "title": "A Scalable AutoML Approach Based on Graph Neural Networks",
    "abstract": "AutoML systems build machine learning models automatically by performing a\nsearch over valid data transformations and learners, along with hyper-parameter\noptimization for each learner. We present a system called KGpip for the\nselection of transformations and learners, which (1) builds a database of\ndatasets and corresponding historically used pipelines using effective static\nanalysis instead of the typical use of actual runtime information, (2) uses\ndataset embeddings to find similar datasets in the database based on its\ncontent instead of metadata-based features, (3) models AutoML pipeline creation\nas a graph generation problem, to succinctly characterize the diverse pipelines\nseen for a single dataset. KGpip is designed as a sub-component for AutoML\nsystems. We demonstrate this ability via integrating KGpip with two AutoML\nsystems and show that it does significantly enhance the performance of existing\nstate-of-the-art systems.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Mossad Helali",
      "Essam Mansour",
      "Ibrahim Abdelaziz",
      "Julian Dolby",
      "Kavitha Srinivas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00083"
  },
  {
    "id": "arXiv:2111.00084",
    "title": "Reddit and the Fourth Estate: Exploring the magnitude and effects of  media influence on community level moderation on Reddit",
    "abstract": "Most platforms, including Reddit, face a dilemma when applying interventions\nsuch as subreddit bans to toxic communities -- do they risk angering their user\nbase by proactively enforcing stricter controls on discourse or do they defer\ninterventions at the risk of eventually triggering negative media reactions\nwhich might impact their advertising revenue? In this paper, we analyze\nReddit's previous administrative interventions to understand one aspect of this\ndilemma: the relationship between the media and administrative interventions.\nMore specifically, we make two primary contributions. First, using a mediation\nanalysis framework, we find evidence that Reddit's interventions for violating\ntheir content policy for toxic content occur because of media pressure. Second,\nusing interrupted time series analysis, we show that media attention on\ncommunities with toxic content only increases the problematic behavior\nassociated with that community (both within the community itself and across the\nplatform). However, we find no significant difference in the impact of\nadministrative interventions on subreddits with and without media pressure.\nTaken all together, this study provides evidence of a media-driven moderation\nstrategy at Reddit and also suggests that such a strategy may not have a\nsignificantly different impact than a more proactive strategy.",
    "descriptor": "",
    "authors": [
      "Hussam Habib",
      "Rishab Nithyanand"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.00084"
  },
  {
    "id": "arXiv:2111.00086",
    "title": "Measuring a Texts Fairness Dimensions Using Machine Learning Based on  Social Psychological Factors",
    "abstract": "Fairness is a principal social value that can be observed in civilisations\naround the world. A manifestations of this is in social agreements, often\ndescribed in texts, such as contracts. Yet, despite the prevalence of such, a\nfairness metric for texts describing a social act remains wanting. To address\nthis, we take a step back to consider the problem based on first principals.\nInstead of using rules or templates, we utilise social psychology literature to\ndetermine the principal factors that humans use when making a fairness\nassessment. We then attempt to digitise these using word embeddings into a\nmulti-dimensioned sentence level fairness perceptions vector to serve as an\napproximation for these fairness perceptions. The method leverages a pro-social\nbias within word embeddings, for which we obtain an F1= 81.0. A second\napproach, using PCA and ML based on the said fairness approximation vector\nproduces an F1 score of 86.2. We details improvements that can be made in the\nmethodology to incorporate the projection of sentence embedding on to a\nsubspace representation of fairness.",
    "descriptor": "\nComments: 38 pages, 9 figures\n",
    "authors": [
      "A. Izzidien",
      "J. Watson",
      "B. Loe",
      "P. Romero",
      "S. Fitz",
      "D. Stillwell"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.00086"
  },
  {
    "id": "arXiv:2111.00087",
    "title": "Improving Driver Situation Awareness Prediction using Human Visual  Sensory and Memory Mechanism",
    "abstract": "Situation awareness (SA) is generally considered as the perception,\nunderstanding, and projection of objects' properties and positions. We believe\nif the system can sense drivers' SA, it can appropriately provide warnings for\nobjects that drivers are not aware of. To investigate drivers' awareness, in\nthis study, a human-subject experiment of driving simulation was conducted for\ndata collection. While a previous predictive model for drivers' situation\nawareness utilized drivers' gaze movement only, this work utilizes object\nproperties, characteristics of human visual sensory and memory mechanism. As a\nresult, the proposed driver SA prediction model achieves over 70% accuracy and\noutperforms the baselines.",
    "descriptor": "\nComments: 7 pages, 4 figures, The IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2021\n",
    "authors": [
      "Haibei Zhu",
      "Teruhisa Misu",
      "Sujitha Martin",
      "Xingwei Wu",
      "Kumar Akash"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.00087"
  },
  {
    "id": "arXiv:2111.00088",
    "title": "Stitching Dynamic Movement Primitives and Image-based Visual Servo  Control",
    "abstract": "Utilizing perception for feedback control in combination with Dynamic\nMovement Primitive (DMP)-based motion generation for a robot's end-effector\ncontrol is a useful solution for many robotic manufacturing tasks. For\ninstance, while performing an insertion task when the hole or the recipient\npart is not visible in the eye-in-hand camera, a learning-based movement\nprimitive method can be used to generate the end-effector path. Once the\nrecipient part is in the field of view (FOV), Image-based Visual Servo (IBVS)\ncan be used to control the motion of the robot. Inspired by such applications,\nthis paper presents a generalized control scheme that switches between motion\ngeneration using DMPs and IBVS control. To facilitate the design, a common\nstate space representation for the DMP and the IBVS systems is first\nestablished. Stability analysis of the switched system using multiple Lyapunov\nfunctions shows that the state trajectories converge to a bound asymptotically.\nThe developed method is validated by two real world experiments using the\neye-in-hand configuration on a Baxter research robot.",
    "descriptor": "",
    "authors": [
      "Ghananeel Rotithor",
      "Iman Salehi",
      "Edward Tunstel",
      "Ashwin P. Dani"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00088"
  },
  {
    "id": "arXiv:2111.00092",
    "title": "Optimal Compression of Locally Differentially Private Mechanisms",
    "abstract": "Compressing the output of \\epsilon-locally differentially private (LDP)\nrandomizers naively leads to suboptimal utility. In this work, we demonstrate\nthe benefits of using schemes that jointly compress and privatize the data\nusing shared randomness. In particular, we investigate a family of schemes\nbased on Minimal Random Coding (Havasi et al., 2019) and prove that they offer\noptimal privacy-accuracy-communication tradeoffs. Our theoretical and empirical\nfindings show that our approach can compress PrivUnit (Bhowmick et al., 2018)\nand Subset Selection (Ye et al., 2018), the best known LDP algorithms for mean\nand frequency estimation, to to the order of \\epsilon-bits of communication\nwhile preserving their privacy and accuracy guarantees.",
    "descriptor": "",
    "authors": [
      "Abhin Shah",
      "Wei-Ning Chen",
      "Johannes Balle",
      "Peter Kairouz",
      "Lucas Theis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00092"
  },
  {
    "id": "arXiv:2111.00094",
    "title": "Profit equitably: An investigation of market maker's impact on equitable  outcomes",
    "abstract": "We look at discovering the impact of market microstructure on equitability\nfor market participants at public exchanges such as the New York Stock Exchange\nor NASDAQ. Are these environments equitable venues for low-frequency\nparticipants (such as retail investors)? In particular, can market makers\ncontribute to equitability for these agents? We use a simulator to assess the\neffect a market marker can have on equality of outcomes for consumer or retail\ntraders by adjusting its parameters. Upon numerically quantifying market\nequitability by the entropy of the price returns distribution of consumer\nagents, we demonstrate that market makers indeed support equitability and that\na negative correlation is observed between the profits of the market maker and\nequitability. We then use multi objective reinforcement learning to\nconcurrently optimize for the two objectives of consumer agent equitability and\nmarket maker profitability, which leads us to learn policies that facilitate\nlower market volatility and tighter spreads for comparable profit levels.",
    "descriptor": "",
    "authors": [
      "Kshama Dwarakanath",
      "Svitlana S Vyetrenko",
      "Tucker Balch"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.00094"
  },
  {
    "id": "arXiv:2111.00095",
    "title": "Online Optimization with Feedback Delay and Nonlinear Switching Cost",
    "abstract": "We study a variant of online optimization in which the learner receives\n$k$-round $\\textit{delayed feedback}$ about hitting cost and there is a\nmulti-step nonlinear switching cost, i.e., costs depend on multiple previous\nactions in a nonlinear manner. Our main result shows that a novel Iterative\nRegularized Online Balanced Descent (iROBD) algorithm has a constant,\ndimension-free competitive ratio that is $O(L^{2k})$, where $L$ is the\nLipschitz constant of the switching cost. Additionally, we provide lower bounds\nthat illustrate the Lipschitz condition is required and the dependencies on $k$\nand $L$ are tight. Finally, via reductions, we show that this setting is\nclosely related to online control problems with delay, nonlinear dynamics, and\nadversarial disturbances, where iROBD directly offers constant-competitive\nonline policies.",
    "descriptor": "",
    "authors": [
      "Weici Pan",
      "Guanya Shi",
      "Yiheng Lin",
      "Adam Wierman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00095"
  },
  {
    "id": "arXiv:2111.00097",
    "title": "Evaluation of an Anomaly Detector for Routers using Parameterizable  Malware in an IoT Ecosystem",
    "abstract": "This work explores the evaluation of a machine learning anomaly detector\nusing custom-made parameterizable malware in an Internet of Things (IoT)\nEcosystem. It is assumed that the malware has infected, and resides on, the\nLinux router that serves other devices on the network, as depicted in Figure 1.\nThis IoT Ecosystem was developed as a testbed to evaluate the efficacy of a\nbehavior-based anomaly detector. The malware consists of three types of\ncustom-made malware: ransomware, cryptominer, and keylogger, which all have\nexfiltration capabilities to the network. The parameterization of the malware\ngives the malware samples multiple degrees of freedom, specifically relating to\nthe rate and size of data exfiltration. The anomaly detector uses feature sets\ncrafted from system calls and network traffic, and uses a Support Vector\nMachine (SVM) for behavioral-based anomaly detection. The custom-made malware\nis used to evaluate the situations where the SVM is effective, as well as the\nsituations where it is not effective.",
    "descriptor": "\nComments: To appear in Proceedings of the 17th International Conference on Ubiquitous Security (UbiSec 2021)\n",
    "authors": [
      "John Carter",
      "Spiros Mancoridis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00097"
  },
  {
    "id": "arXiv:2111.00099",
    "title": "Autoencoder-based Anomaly Detection in Smart Farming Ecosystem",
    "abstract": "The inclusion of Internet of Things (IoT) devices is growing rapidly in all\napplication domains. Smart Farming supports devices connected, and with the\nsupport of Internet, cloud or edge computing infrastructure provide remote\ncontrol of watering and fertilization, real time monitoring of farm conditions,\nand provide solutions to more sustainable practices. This could involve using\nirrigation systems only when the detected soil moisture level is low or stop\nwhen the plant reaches a sufficient level of soil moisture content. These\nimprovements to efficiency and ease of use come with added risks to security\nand privacy. Cyber attacks in large coordinated manner can disrupt economy of\nagriculture-dependent nations. To the sensors in the system, an attack may\nappear as anomalous behaviour. In this context, there are possibilities of\nanomalies generated due to faulty hardware, issues in network connectivity (if\npresent), or simply abrupt changes to the environment due to weather, human\naccident, or other unforeseen circumstances. To make such systems more secure,\nit is imperative to detect such data discrepancies, and trigger appropriate\nmitigation mechanisms. In this paper, we propose an anomaly detection model for\nSmart Farming using an unsupervised Autoencoder machine learning model. We\nchose to use an Autoencoder because it encodes and decodes data and attempts to\nignore outliers. When it encounters anomalous data the result will be a high\nreconstruction loss value, signaling that this data was not like the rest. Our\nmodel was trained and tested on data collected from our designed greenhouse\ntest-bed. Proposed Autoencoder model based anomaly detection achieved 98.98%\nand took 262 seconds to train and has a detection time of .0585 seconds.",
    "descriptor": "",
    "authors": [
      "Mary Adkisson",
      "Jeffrey C Kimmel",
      "Maanak Gupta",
      "Mahmoud Abdelsalam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00099"
  },
  {
    "id": "arXiv:2111.00103",
    "title": "MINRES for second-order PDEs with singular data",
    "abstract": "Minimum residual methods such as the least-squares finite element method\n(FEM) or the discontinuous Petrov--Galerkin method with optimal test functions\n(DPG) usually exclude singular data, e.g., non square-integrable loads. We\nconsider a DPG method and a least-squares FEM for the Poisson problem. For both\nmethods we analyze regularization approaches that allow the use of $H^{-1}$\nloads, and also study the case of point loads. For all cases we prove\nappropriate convergence orders. We present various numerical experiments that\nconfirm our theoretical results. Our approach extends to general well-posed\nsecond-order problems.",
    "descriptor": "",
    "authors": [
      "Thomas F\u00fchrer",
      "Norbert Heuer",
      "Michael Karkulik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00103"
  },
  {
    "id": "arXiv:2111.00107",
    "title": "The Golden Rule as a Heuristic to Measure the Fairness of Texts Using  Machine Learning",
    "abstract": "To treat others as one would wish to be treated is a common formulation of\nthe Golden Rule (GR). Yet, despite its prevalence as an axiom throughout\nhistory, no digitisation of the moral philosophy exists. In this paper we\nconsider how to digitise it so that it may be used to measure sentences such\nas: the boy harmed the girl, and categorise them as fair or unfair. A review\nand reply to criticisms of the GR is made. We share the code for the\ndigitisation of the GR, and test it with a list of sentences. Implementing two\napproaches, one using the USE, and a second using ALBERT. We find F1 scores of\n78.0, 85.0, respectively. A suggestion of how the technology may be implemented\nto avoid unfair biases in word embeddings is made - given that individuals\nwould typically not wish to be on the receiving end of an unfair act, such as\nracism, irrespective of whether the corpus being used deems such discrimination\nas praiseworthy.",
    "descriptor": "\nComments: 32 pages, 4 figures\n",
    "authors": [
      "A. Izzidien",
      "J. Watson",
      "B. Loe",
      "P. Romero",
      "S. Fitz",
      "D. Stillwell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00107"
  },
  {
    "id": "arXiv:2111.00110",
    "title": "FC2T2: The Fast Continuous Convolutional Taylor Transform with  Applications in Vision and Graphics",
    "abstract": "Series expansions have been a cornerstone of applied mathematics and\nengineering for centuries. In this paper, we revisit the Taylor series\nexpansion from a modern Machine Learning perspective. Specifically, we\nintroduce the Fast Continuous Convolutional Taylor Transform (FC2T2), a variant\nof the Fast Multipole Method (FMM), that allows for the efficient approximation\nof low dimensional convolutional operators in continuous space. We build upon\nthe FMM which is an approximate algorithm that reduces the computational\ncomplexity of N-body problems from O(NM) to O(N+M) and finds application in\ne.g. particle simulations. As an intermediary step, the FMM produces a series\nexpansion for every cell on a grid and we introduce algorithms that act\ndirectly upon this representation. These algorithms analytically but\napproximately compute the quantities required for the forward and backward pass\nof the backpropagation algorithm and can therefore be employed as (implicit)\nlayers in Neural Networks. Specifically, we introduce a root-implicit layer\nthat outputs surface normals and object distances as well as an\nintegral-implicit layer that outputs a rendering of a radiance field given a 3D\npose. In the context of Machine Learning, $N$ and $M$ can be understood as the\nnumber of model parameters and model evaluations respectively which entails\nthat, for applications that require repeated function evaluations which are\nprevalent in Computer Vision and Graphics, unlike regular Neural Networks, the\ntechniques introduce in this paper scale gracefully with parameters. For some\napplications, this results in a 200x reduction in FLOPs compared to\nstate-of-the-art approaches at a reasonable or non-existent loss in accuracy.",
    "descriptor": "",
    "authors": [
      "Henning Lange",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00110"
  },
  {
    "id": "arXiv:2111.00112",
    "title": "Classification of jujube fruit based on several pricing factors using  machine learning methods",
    "abstract": "Jujube is a fruit mainly cultivated in India, China and Iran and has many\nhealth benefits. It is sold both fresh and dried. There are several factors in\njujube pricing such as weight, wrinkles and defections. Some jujube farmers\nsell their product all at once, without any proper sorting or classification,\nfor an average price. Our studies and experiences show that their profit can\nincrease significantly if their product is sold after the sorting process.\nThere are some traditional sorting methods for dried jujube fruit but they are\ncostly, time consuming and can be inaccurate due to human error. Nowadays,\ncomputer vision combined with machine learning methods, is used increasingly in\nfood industry for sorting and classification purposes and solve many of the\ntraditional sorting methods' problems. In this paper we are proposing a\ncomputer vision-based method for grading jujube fruits using machine learning\ntechniques which will take most of the important pricing factors into account\nand can be used to increase the profit of farmers. In this method we first\nacquire several images from different samples and then extract their visual\nfeatures such as color features, shape and size features, texture features,\ndefection and wrinkle features and then we select the most useful features\nusing feature selection algorithms like PCA and CFS. A feature vector is\nobtained for each sample and we use these vectors to train our classifiers to\nbe able to specify the corresponding pre-defined group for each of the samples.\nWe used different classifiers and training methods in order to obtain the best\nresult and by using decision tree we could reach 98.8% accuracy of the\nclassification.",
    "descriptor": "",
    "authors": [
      "Abdollah Zakeri",
      "Ruhollah Hedayati",
      "Mohammad Khedmati",
      "Mehran Taghipour-Gorjikolaie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00112"
  },
  {
    "id": "arXiv:2111.00113",
    "title": "Fast & Accurate Randomized Algorithms for Linear Systems and Eigenvalue  Problems",
    "abstract": "This paper develops a new class of algorithms for general linear systems and\neigenvalue problems. These algorithms apply fast randomized sketching to\naccelerate subspace projection methods, such as GMRES and Rayleigh--Ritz. This\napproach offers great flexibility in designing the basis for the approximation\nsubspace, which can improve scalability in many computational environments. The\nresulting algorithms outperform the classic methods with minimal loss of\naccuracy. For model problems, numerical experiments show large advantages over\nMATLAB's optimized routines, including a $100 \\times$ speedup over gmres and a\n$10 \\times$ speedup over eigs.",
    "descriptor": "\nComments: 29 pages, 6 figures\n",
    "authors": [
      "Yuji Nakatsukasa",
      "Joel A. Tropp"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00113"
  },
  {
    "id": "arXiv:2111.00115",
    "title": "Combining Public and Private Data",
    "abstract": "Differential privacy is widely adopted to provide provable privacy guarantees\nin data analysis. We consider the problem of combining public and private data\n(and, more generally, data with heterogeneous privacy needs) for estimating\naggregate statistics. We introduce a mixed estimator of the mean optimized to\nminimize the variance. We argue that our mechanism is preferable to techniques\nthat preserve the privacy of individuals by subsampling data proportionally to\nthe privacy needs of users. Similarly, we present a mixed median estimator\nbased on the exponential mechanism. We compare our mechanisms to the methods\nproposed in Jorgensen et al. [2015]. Our experiments provide empirical evidence\nthat our mechanisms often outperform the baseline methods.",
    "descriptor": "",
    "authors": [
      "Cecilia Ferrando",
      "Jennifer Gillenwater",
      "Alex Kulesza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00115"
  },
  {
    "id": "arXiv:2111.00116",
    "title": "Visual Explanations for Convolutional Neural Networks via Latent  Traversal",
    "abstract": "Lack of explainability in artificial intelligence, specifically deep neural\nnetworks, remains a bottleneck for implementing models in practice. Popular\ntechniques such as Gradient-weighted Class Activation Mapping (Grad-CAM)\nprovide a coarse map of salient features in an image, which rarely tells the\nwhole story of what a convolutional neural network (CNN) learned. Using\nCOVID-19 chest X-rays, we present a method for interpreting what a CNN has\nlearned by utilizing Generative Adversarial Networks (GANs). Our GAN framework\ndisentangles lung structure from COVID-19 features. Using this GAN, we can\nvisualize the transition of a pair of COVID negative lungs in a chest\nradiograph to a COVID positive pair by interpolating in the latent space of the\nGAN, which provides fine-grained visualization of how the CNN responds to\nvarying features within the lungs.",
    "descriptor": "\nComments: 2 pages, 2 figures, to appear as extended abstract at AAAI-22\n",
    "authors": [
      "Amil Dravid",
      "Aggelos K. Katsaggelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.00116"
  },
  {
    "id": "arXiv:2111.00120",
    "title": "How to Find New Characteristic-Dependent Linear Rank Inequalities using  Secret Sharing",
    "abstract": "Determining information ratios of access structures is an important problem\nin secret sharing. Information inequalities and linear rank inequalities play\nan important role for proving bounds. Characteristic-dependent linear rank\ninequalities are rank inequalities which are true over vector spaces with\nspecific field characteristic. In this paper, using ideas of secret sharing, we\nshow a theorem that produces characteristic-dependent linear rank inequalities.\nThese inequalities can be used for getting lower bounds on information ratios\nin linear secret sharing.",
    "descriptor": "",
    "authors": [
      "Victor Pe\u00f1a-Macias"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.00120"
  },
  {
    "id": "arXiv:2111.00121",
    "title": "Longitudinal Analysis of Mask and No-Mask on Child Face Recognition",
    "abstract": "Face is one of the most widely employed traits for person recognition, even\nin many large-scale applications. Despite technological advancements in face\nrecognition systems, they still face obstacles caused by pose, expression,\nocclusion, and aging variations. Owing to the COVID-19 pandemic, contactless\nidentity verification has become exceedingly vital. To constrain the pandemic,\npeople have started using face mask. Recently, few studies have been conducted\non the effect of face mask on adult face recognition systems. However, the\nimpact of aging with face mask on child subject recognition has not been\nadequately explored. Thus, the main objective of this study is analyzing the\nchild longitudinal impact together with face mask and other covariates on face\nrecognition systems. Specifically, we performed a comparative investigation of\nthree top performing publicly available face matchers and a post-COVID-19\ncommercial-off-the-shelf (COTS) system under child cross-age verification and\nidentification settings using our generated synthetic mask and no-mask samples.\nFurthermore, we investigated the longitudinal consequence of eyeglasses with\nmask and no-mask. The study exploited no-mask longitudinal child face dataset\n(i.e., extended Indian Child Longitudinal Face Dataset) that contains $26,258$\nface images of $7,473$ subjects in the age group of $[2, 18]$ over an average\ntime span of $3.35$ years. Experimental results showed that problem of face\nmask on automated face recognition is compounded by aging variate.",
    "descriptor": "\nComments: 6 Pages, 3 Figure\n",
    "authors": [
      "Praveen Kumar Chandaliya",
      "Zahid Akhtar",
      "Neeta Nain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00121"
  },
  {
    "id": "arXiv:2111.00122",
    "title": "AIoT-Bench: A Demonstration of Benchmarking Time Series Management  Systems in the Cloud",
    "abstract": "Time Series Management Systems (TSMS) are Database Management Systems that\nhave been configured with the primary objective of processing and storing time\nseries data. With the IoT expanding at exponential rates and there becoming\nincreasingly more time series data to process and analyze, several TSMS have\nbeen proposed and are used in practice. Each system has its own architecture\nand storage mechanisms and factors such as the dimensionality of the dataset or\nthe nature of the operators a user wishes to execute can cause differences in\nsystem performance. This makes it highly challenging for practitioners to\ndetermine the most optimal TSMS for their use case. To remedy this several TSMS\nbenchmarks have been proposed, yet these benchmarks focus primary on simple and\nsupported operators, largely disregarding the advanced analytical operators\n(ie. Normalization, Clustering, etc) that constitute a large part of the use\ncases in practice. In this demo, we introduce a new benchmark that enables\nusers to evaluate the performance of four prominent TSMS (TimescaleDB, MonetDB,\nExtremeDB, Kairos-H2) in their handling of over 13 advanced analytical\noperators. In a simple and interactive manner, users can specify the TSMS(s) to\ncompare, the advanced analytical operator(s) to execute, and the dataset(s) to\nutilize for the comparison. Users can choose from over eight real-world\ndatasets with varying dimensions or upload their own dataset. The tool then\nprovides a report and recommendation of the most optimal TSMS for the\nparameters chosen.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Prabhav Arora",
      "Djellel Difallah",
      "Gabriela-Carmen Voroneanu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.00122"
  },
  {
    "id": "arXiv:2111.00123",
    "title": "Learning Representations for Zero-Shot Retrieval over Structured Data",
    "abstract": "Large Scale Question-Answering systems today are widely used in downstream\napplications such as chatbots and conversational dialogue agents. Typically,\nsuch systems consist of an Answer Passage retrieval layer coupled with Machine\nComprehension models trained on natural language query-passage pairs. Recent\nstudies have explored Question Answering over structured data sources such as\nweb-tables and relational databases. However, architectures such as Seq2SQL\nassume the correct table a priori which is input to the model along with the\nfree text question. Our proposed method, analogues to a passage retrieval model\nin traditional Question-Answering systems, describes an architecture to discern\nthe correct table pertaining to a given query from amongst a large pool of\ncandidate tables.",
    "descriptor": "\nComments: 11 pages, 3 figures, 2 tables\n",
    "authors": [
      "Harsh Kohli"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.00123"
  },
  {
    "id": "arXiv:2111.00124",
    "title": "Predicting Atlantic Multidecadal Variability",
    "abstract": "Atlantic Multidecadal Variability (AMV) describes variations of North\nAtlantic sea surface temperature with a typical cycle of between 60 and 70\nyears. AMV strongly impacts local climate over North America and Europe,\ntherefore prediction of AMV, especially the extreme values, is of great\nsocietal utility for understanding and responding to regional climate change.\nThis work tests multiple machine learning models to improve the state of AMV\nprediction from maps of sea surface temperature, salinity, and sea level\npressure in the North Atlantic region. We use data from the Community Earth\nSystem Model 1 Large Ensemble Project, a state-of-the-art climate model with\n3,440 years of data. Our results demonstrate that all of the models we use\noutperform the traditional persistence forecast baseline. Predicting the AMV is\nimportant for identifying future extreme temperatures and precipitation, as\nwell as hurricane activity, in Europe and North America up to 25 years in\nadvance.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Glenn Liu",
      "Peidong Wang",
      "Matthew Beveridge",
      "Young-Oh Kwon",
      "Iddo Drori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.00124"
  },
  {
    "id": "arXiv:2111.00126",
    "title": "Predicting Critical Biogeochemistry of the Southern Ocean for Climate  Monitoring",
    "abstract": "The Biogeochemical-Argo (BGC-Argo) program is building a network of globally\ndistributed, sensor-equipped robotic profiling floats, improving our\nunderstanding of the climate system and how it is changing. These floats,\nhowever, are limited in the number of variables measured. In this study, we\ntrain neural networks to predict silicate and phosphate values in the Southern\nOcean from temperature, pressure, salinity, oxygen, nitrate, and location and\napply these models to earth system model (ESM) and BGC-Argo data to expand the\nutility of this ocean observation network. We trained our neural networks on\nobservations from the Global Ocean Ship-Based Hydrographic Investigations\nProgram (GO-SHIP) and use dropout regularization to provide uncertainty bounds\naround our predicted values. Our neural network significantly improves upon\nlinear regression but shows variable levels of uncertainty across the ranges of\npredicted variables. We explore the generalization of our estimators to test\ndata outside our training distribution from both ESM and BGC-Argo data. Our use\nof out-of-distribution test data to examine shifts in biogeochemical parameters\nand calculate uncertainty bounds around estimates advance the state-of-the-art\nin oceanographic data and climate monitoring. We make our data and code\npublicly available.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Ellen Park",
      "Jae Deok Kim",
      "Nadege Aoki",
      "Yumeng Melody Cao",
      "Yamin Arefeen",
      "Matthew Beveridge",
      "David Nicholson",
      "Iddo Drori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.00126"
  },
  {
    "id": "arXiv:2111.00129",
    "title": "Distributed model order reduction of a model for microtubule-based cell  polarization using HAPOD",
    "abstract": "In this contribution we investigate in mathematical modeling and efficient\nsimulation of biological cells with a particular emphasis on effective modeling\nof structural properties that originate from active forces generated from\npolymerization and depolymerization of cytoskeletal components. In detail, we\npropose a nonlinear continuum approach to model microtubule-based forces which\nhave recently been established as central components of cell mechanics during\nearly fruit fly wing development. The model is discretized in space using the\nfinite-element method. Although the individual equations are decoupled by a\nsemi-implicit time discretization, the discrete model is still computationally\ndemanding. In addition, the parameters needed for the effective model equations\nare not easily available and have to be estimated or determined by repeatedly\nsolving the model and fitting the results to measurements. This drastically\nincreases the computational cost. Reduced basis methods have been used\nsuccessfully to speed up such repeated solves, often by several orders of\nmagnitude. However, for the complex nonlinear models regarded here, the\napplication of these model order reduction methods is not always\nstraight-forward and comes with its own set of challenges. In particular,\nsubspace construction using the Proper Orthogonal Decomposition (POD) becomes\nprohibitively expensive for reasonably fine grids. We thus propose to combine\nthe Hierarchical Approximate POD, which is a general, easy-to-implement\napproach to compute an approximate POD, with an Empirical Interpolation Method\nto efficiently generate a fast to evaluate reduced order model. Numerical\nexperiments are given to demonstrate the applicability and efficiency of the\nproposed modeling and simulation approach.",
    "descriptor": "",
    "authors": [
      "Tobias Leibner",
      "Maja Matis",
      "Mario Ohlberger",
      "Stephan Rave"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00129"
  },
  {
    "id": "arXiv:2111.00131",
    "title": "Three approaches to facilitate DNN generalization to objects in  out-of-distribution orientations and illuminations: late-stopping, tuning  batch normalization and invariance loss",
    "abstract": "The training data distribution is often biased towards objects in certain\norientations and illumination conditions. While humans have a remarkable\ncapability of recognizing objects in out-of-distribution (OoD) orientations and\nilluminations, Deep Neural Networks (DNNs) severely suffer in this case, even\nwhen large amounts of training examples are available. In this paper, we\ninvestigate three different approaches to improve DNNs in recognizing objects\nin OoD orientations and illuminations. Namely, these are (i) training much\nlonger after convergence of the in-distribution (InD) validation accuracy,\ni.e., late-stopping, (ii) tuning the momentum parameter of the batch\nnormalization layers, and (iii) enforcing invariance of the neural activity in\nan intermediate layer to orientation and illumination conditions. Each of these\napproaches substantially improves the DNN's OoD accuracy (more than 20% in some\ncases). We report results in four datasets: two datasets are modified from the\nMNIST and iLab datasets, and the other two are novel (one of 3D rendered cars\nand another of objects taken from various controlled orientations and\nillumination conditions). These datasets allow to study the effects of\ndifferent amounts of bias and are challenging as DNNs perform poorly in OoD\nconditions. Finally, we demonstrate that even though the three approaches focus\non different aspects of DNNs, they all tend to lead to the same underlying\nneural mechanism to enable OoD accuracy gains -- individual neurons in the\nintermediate layers become more selective to a category and also invariant to\nOoD orientations and illuminations.",
    "descriptor": "",
    "authors": [
      "Akira Sakai",
      "Taro Sunagawa",
      "Spandan Madan",
      "Kanata Suzuki",
      "Takashi Katoh",
      "Hiromichi Kobashi",
      "Hanspeter Pfister",
      "Pawan Sinha",
      "Xavier Boix",
      "Tomotake Sasaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00131"
  },
  {
    "id": "arXiv:2111.00134",
    "title": "Context Meta-Reinforcement Learning via Neuromodulation",
    "abstract": "Meta-reinforcement learning (meta-RL) algorithms enable agents to adapt\nquickly to tasks from few samples in dynamic environments. Such a feat is\nachieved through dynamic representations in an agent's policy network (obtained\nvia reasoning about task context, model parameter updates, or both). However,\nobtaining rich dynamic representations for fast adaptation beyond simple\nbenchmark problems is challenging due to the burden placed on the policy\nnetwork to accommodate different policies. This paper addresses the challenge\nby introducing neuromodulation as a modular component to augment a standard\npolicy network that regulates neuronal activities in order to produce efficient\ndynamic representations for task adaptation. The proposed extension to the\npolicy network is evaluated across multiple discrete and continuous control\nenvironments of increasing complexity. To prove the generality and benefits of\nthe extension in meta-RL, the neuromodulated network was applied to two\nstate-of-the-art meta-RL algorithms (CAVIA and PEARL). The result demonstrates\nthat meta-RL augmented with neuromodulation produces significantly better\nresult and richer dynamic representations in comparison to the baselines.",
    "descriptor": "",
    "authors": [
      "Eseoghene Ben-Iwhiwhu",
      "Jeffery Dick",
      "Nicholas A. Ketz",
      "Praveen K. Pilly",
      "Andrea Soltoggio"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00134"
  },
  {
    "id": "arXiv:2111.00140",
    "title": "DIB-R++: Learning to Predict Lighting and Material with a Hybrid  Differentiable Renderer",
    "abstract": "We consider the challenging problem of predicting intrinsic object properties\nfrom a single image by exploiting differentiable renderers. Many previous\nlearning-based approaches for inverse graphics adopt rasterization-based\nrenderers and assume naive lighting and material models, which often fail to\naccount for non-Lambertian, specular reflections commonly observed in the wild.\nIn this work, we propose DIBR++, a hybrid differentiable renderer which\nsupports these photorealistic effects by combining rasterization and\nray-tracing, taking the advantage of their respective strengths -- speed and\nrealism. Our renderer incorporates environmental lighting and spatially-varying\nmaterial models to efficiently approximate light transport, either through\ndirect estimation or via spherical basis functions. Compared to more advanced\nphysics-based differentiable renderers leveraging path tracing, DIBR++ is\nhighly performant due to its compact and expressive shading model, which\nenables easy integration with learning frameworks for geometry, reflectance and\nlighting prediction from a single image without requiring any ground-truth. We\nexperimentally demonstrate that our approach achieves superior material and\nlighting disentanglement on synthetic and real data compared to existing\nrasterization-based approaches and showcase several artistic applications\nincluding material editing and relighting.",
    "descriptor": "",
    "authors": [
      "Wenzheng Chen",
      "Joey Litalien",
      "Jun Gao",
      "Zian Wang",
      "Clement Fuji Tsang",
      "Sameh Khamis",
      "Or Litany",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.00140"
  },
  {
    "id": "arXiv:2111.00142",
    "title": "Uncovering IP Address Hosting Types Behind Malicious Websites",
    "abstract": "Hundreds of thousands of malicious domains are created everyday. These\nmalicious domains are hosted on a wide variety of network infrastructures.\nTraditionally, attackers utilize bullet proof hosting services (e.g. MaxiDed,\nCyber Bunker) to take advantage of relatively lenient policies on what content\nthey can host. However, these IP ranges are increasingly being blocked or the\nservices are taken down by law enforcement. Hence, attackers are moving towards\nutilizing IPs from regular hosting providers while staying under the radar of\nthese hosting providers. There are several practical advantages of accurately\nknowing the type of IP used to host malicious domains. If the IP is a dedicated\nIP (i.e. it is leased to a single entity), one may blacklist the IP to block\ndomains hosted on those IPs as welll as use as a way to identify other\nmalicious domains hosted the same IP. If the IP is a shared hosting IP, hosting\nproviders may take measures to clean up such domains and maintain a high\nreputation for their users.",
    "descriptor": "",
    "authors": [
      "Nimesha Wickramasinghe",
      "Mohamed Nabeel",
      "Kenneth Thilakaratne",
      "Chamath Keppitiyagama",
      "Kasun De Zoysa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00142"
  },
  {
    "id": "arXiv:2111.00148",
    "title": "On Small-Depth Tree Augmentations",
    "abstract": "We study the Weighted Tree Augmentation Problem for general link costs. We\nshow that the integrality gap of the ODD-LP relaxation for the (weighted) Tree\nAugmentation Problem for a $k$-level tree instance is at most $2 -\n\\frac{1}{2^{k-1}}$. For 2- and 3-level trees, these ratios are $\\frac32$ and\n$\\frac74$ respectively. Our proofs are constructive and yield polynomial-time\napproximation algorithms with matching guarantees.",
    "descriptor": "",
    "authors": [
      "Ojas Parekh",
      "R. Ravi",
      "Michael Zlatin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.00148"
  },
  {
    "id": "arXiv:2111.00149",
    "title": "Temporal-Spatial Feature Extraction Based on Convolutional Neural  Networks for Travel Time Prediction",
    "abstract": "In recent years, some traffic information prediction methods have been\nproposed to provide the precise information of travel time, vehicle speed, and\ntraffic flow for highways. However, big errors may be obtained by these methods\nfor urban roads or the alternative roads of highways. Therefore, this study\nproposes a travel time prediction method based on convolutional neural networks\nto extract important factors for the improvement of traffic information\nprediction. In practical experimental environments, the travel time records of\nNo. 5 Highway and the alternative roads of its were collected and used to\nevaluate the proposed method. The results showed that the mean absolute\npercentage error of the proposed method was about 5.69%. Therefore, the\nproposed method based on deep learning techniques can improve the accuracy of\ntravel time prediction.",
    "descriptor": "\nComments: 22 pages, 15 figures, and 3 tables\n",
    "authors": [
      "Chi-Hua Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00149"
  },
  {
    "id": "arXiv:2111.00153",
    "title": "RMSMP: A Novel Deep Neural Network Quantization Framework with Row-wise  Mixed Schemes and Multiple Precisions",
    "abstract": "This work proposes a novel Deep Neural Network (DNN) quantization framework,\nnamely RMSMP, with a Row-wise Mixed-Scheme and Multi-Precision approach.\nSpecifically, this is the first effort to assign mixed quantization schemes and\nmultiple precisions within layers -- among rows of the DNN weight matrix, for\nsimplified operations in hardware inference, while preserving accuracy.\nFurthermore, this paper makes a different observation from the prior work that\nthe quantization error does not necessarily exhibit the layer-wise sensitivity,\nand actually can be mitigated as long as a certain portion of the weights in\nevery layer are in higher precisions. This observation enables layer-wise\nuniformality in the hardware implementation towards guaranteed inference\nacceleration, while still enjoying row-wise flexibility of mixed schemes and\nmultiple precisions to boost accuracy. The candidates of schemes and precisions\nare derived practically and effectively with a highly hardware-informative\nstrategy to reduce the problem search space. With the offline determined ratio\nof different quantization schemes and precisions for all the layers, the RMSMP\nquantization algorithm uses the Hessian and variance-based method to\neffectively assign schemes and precisions for each row. The proposed RMSMP is\ntested for the image classification and natural language processing (BERT)\napplications and achieves the best accuracy performance among state-of-the-arts\nunder the same equivalent precisions. The RMSMP is implemented on FPGA devices,\nachieving 3.65x speedup in the end-to-end inference time for ResNet-18 on\nImageNet, compared with the 4-bit Fixed-point baseline.",
    "descriptor": "\nComments: Accepted by International Conference on Computer Vision 2021 (ICCV 2021)\n",
    "authors": [
      "Sung-En Chang",
      "Yanyu Li",
      "Mengshu Sun",
      "Weiwen Jiang",
      "Sijia Liu",
      "Yanzhi Wang",
      "Xue Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00153"
  },
  {
    "id": "arXiv:2111.00154",
    "title": "Characterization of the Imbalance Problem on Complete Bipartite Graphs",
    "abstract": "We study the imbalance problem on complete bipartite graphs. The imbalance\nproblem is a graph layout problem and is known to be NP-complete. Graph layout\nproblems find their applications in the optimization of networks for parallel\ncomputer architectures, VLSI circuit design, information retrieval, numerical\nanalysis, computational biology, graph theory, scheduling and archaeology. In\nthis paper, we give characterizations for the optimal solutions of the\nimbalance problem on complete bipartite graphs. Using the characterizations, we\ncan solve the imbalance problem in $\\mathcal{O}(\\log(|V|) \\cdot\n\\log(\\log(|V|)))$ time, when given the cardinalities of the parts of the graph,\nand verify whether a given solution is optimal in $O(|V|)$ time on complete\nbipartite graphs. We also introduce a restricted form of proper interval\nbipartite graphs on which the imbalance problem is solvable in $\\mathcal{O}(c\n\\cdot \\log(|V|) \\cdot \\log(\\log(|V|)))$ time, where $c = \\mathcal{O}(|V|)$, by\nusing the aforementioned characterizations.",
    "descriptor": "\nComments: 25 pages, 23 figures in the appendix\n",
    "authors": [
      "Steven Ge",
      "Toshiya Itoh"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.00154"
  },
  {
    "id": "arXiv:2111.00155",
    "title": "ILMPQ : An Intra-Layer Multi-Precision Deep Neural Network Quantization  framework for FPGA",
    "abstract": "This work targets the commonly used FPGA (field-programmable gate array)\ndevices as the hardware platform for DNN edge computing. We focus on DNN\nquantization as the main model compression technique. The novelty of this work\nis: We use a quantization method that supports multiple precisions along the\nintra-layer dimension, while the existing quantization methods apply\nmulti-precision quantization along the inter-layer dimension. The intra-layer\nmulti-precision method can uniform the hardware configurations for different\nlayers to reduce computation overhead and at the same time preserve the model\naccuracy as the inter-layer approach. Our proposed ILMPQ DNN quantization\nframework achieves 70.73 Top1 accuracy in ResNet-18 on the ImageNet dataset. We\nalso validate the proposed MSP framework on two FPGA devices i.e., Xilinx\nXC7Z020 and XC7Z045. We achieve 3.65x speedup in end-to-end inference time on\nthe ImageNet, compared with the fixed-point quantization method.",
    "descriptor": "\nComments: Accepted by CogArch 2021: 5th Workshop on Cognitive Architectures\n",
    "authors": [
      "Sung-En Chang",
      "Yanyu Li",
      "Mengshu Sun",
      "Yanzhi Wang",
      "Xue Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00155"
  },
  {
    "id": "arXiv:2111.00157",
    "title": "TransAug: Translate as Augmentation for Sentence Embeddings",
    "abstract": "While contrastive learning greatly advances the representation of sentence\nembeddings, it is still limited by the size of the existing sentence datasets.\nIn this paper, we present TransAug (Translate as Augmentation), which provide\nthe first exploration of utilizing translated sentence pairs as data\naugmentation for text, and introduce a two-stage paradigm to advances the\nstate-of-the-art sentence embeddings. Instead of adopting an encoder trained in\nother languages setting, we first distill a Chinese encoder from a SimCSE\nencoder (pretrained in English), so that their embeddings are close in semantic\nspace, which can be regraded as implicit data augmentation. Then, we only\nupdate the English encoder via cross-lingual contrastive learning and frozen\nthe distilled Chinese encoder. Our approach achieves a new state-of-art on\nstandard semantic textual similarity (STS), outperforming both SimCSE and\nSentence-T5, and the best performance in corresponding tracks on transfer tasks\nevaluated by SentEval.",
    "descriptor": "",
    "authors": [
      "Jue Wang",
      "Haofan Wang",
      "Xing Wu",
      "Chaochen Gao",
      "Debing Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00157"
  },
  {
    "id": "arXiv:2111.00160",
    "title": "DSEE: Dually Sparsity-embedded Efficient Tuning of Pre-trained Language  Models",
    "abstract": "Gigantic pre-trained models have become central to natural language\nprocessing (NLP), serving as the starting point for fine-tuning towards a range\nof downstream tasks. However, two pain points persist for this paradigm: (a) as\nthe pre-trained models grow bigger (e.g., 175B parameters for GPT-3), even the\nfine-tuning process can be time-consuming and computationally expensive; (b)\nthe fine-tuned model has the same size as its starting point by default, which\nis neither sensible due to its more specialized functionality, nor practical\nsince many fine-tuned models will be deployed in resource-constrained\nenvironments. To address these pain points, we propose a framework for\nresource- and parameter-efficient fine-tuning by leveraging the sparsity prior\nin both weight updates and the final model weights. Our proposed framework,\ndubbed Dually Sparsity-Embedded Efficient Tuning (DSEE), aims to achieve two\nkey objectives: (i) parameter efficient fine-tuning - by enforcing\nsparsity-aware weight updates on top of the pre-trained weights; and (ii)\nresource-efficient inference - by encouraging a sparse weight structure towards\nthe final fine-tuned model. We leverage sparsity in these two directions by\nexploiting both unstructured and structured sparse patterns in pre-trained\nlanguage models via magnitude-based pruning and $\\ell_1$ sparse regularization.\nExtensive experiments and in-depth investigations, with diverse network\nbackbones (i.e., BERT, GPT-2, and DeBERTa) on dozens of datasets, consistently\ndemonstrate highly impressive parameter-/training-/inference-efficiency, while\nmaintaining competitive downstream transfer performance. For instance, our\nDSEE-BERT obtains about $35\\%$ inference FLOPs savings with <1% trainable\nparameters and comparable performance to conventional fine-tuning. Codes are\navailable in https://github.com/VITA-Group/DSEE.",
    "descriptor": "",
    "authors": [
      "Xuxi Chen",
      "Tianlong Chen",
      "Yu Cheng",
      "Weizhu Chen",
      "Zhangyang Wang",
      "Ahmed Hassan Awadallah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00160"
  },
  {
    "id": "arXiv:2111.00161",
    "title": "Pseudo-Labeling for Massively Multilingual Speech Recognition",
    "abstract": "Semi-supervised learning through pseudo-labeling has become a staple of\nstate-of-the-art monolingual speech recognition systems. In this work, we\nextend pseudo-labeling to massively multilingual speech recognition with 60\nlanguages. We propose a simple pseudo-labeling recipe that works well even with\nlow-resource languages: train a supervised multilingual model, fine-tune it\nwith semi-supervised learning on a target language, generate pseudo-labels for\nthat language, and train a final model using pseudo-labels for all languages,\neither from scratch or by fine-tuning. Experiments on the labeled Common Voice\nand unlabeled VoxPopuli datasets show that our recipe can yield a model with\nbetter performance for many languages that also transfers well to LibriSpeech.",
    "descriptor": "",
    "authors": [
      "Loren Lugosch",
      "Tatiana Likhomanenko",
      "Gabriel Synnaeve",
      "Ronan Collobert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.00161"
  },
  {
    "id": "arXiv:2111.00162",
    "title": "You are caught stealing my winning lottery ticket! Making a lottery  ticket claim its ownership",
    "abstract": "Despite tremendous success in many application scenarios, the training and\ninference costs of using deep learning are also rapidly increasing over time.\nThe lottery ticket hypothesis (LTH) emerges as a promising framework to\nleverage a special sparse subnetwork (i.e., winning ticket) instead of a full\nmodel for both training and inference, that can lower both costs without\nsacrificing the performance. The main resource bottleneck of LTH is however the\nextraordinary cost to find the sparse mask of the winning ticket. That makes\nthe found winning ticket become a valuable asset to the owners, highlighting\nthe necessity of protecting its copyright. Our setting adds a new dimension to\nthe recently soaring interest in protecting against the intellectual property\n(IP) infringement of deep models and verifying their ownerships, since they\ntake owners' massive/unique resources to develop or train. While existing\nmethods explored encrypted weights or predictions, we investigate a unique way\nto leverage sparse topological information to perform lottery verification, by\ndeveloping several graph-based signatures that can be embedded as credentials.\nBy further combining trigger set-based methods, our proposal can work in both\nwhite-box and black-box verification scenarios. Through extensive experiments,\nwe demonstrate the effectiveness of lottery verification in diverse models\n(ResNet-20, ResNet-18, ResNet-50) on CIFAR-10 and CIFAR-100. Specifically, our\nverification is shown to be robust to removal attacks such as model fine-tuning\nand pruning, as well as several ambiguity attacks. Our codes are available at\nhttps://github.com/VITA-Group/NO-stealing-LTH.",
    "descriptor": "",
    "authors": [
      "Xuxi Chen",
      "Tianlong Chen",
      "Zhenyu Zhang",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00162"
  },
  {
    "id": "arXiv:2111.00163",
    "title": "Simpli-Squared: A Very Simple Yet Unexpectedly Powerful Join Ordering  Algorithm Without Cardinality Estimates",
    "abstract": "The Join Order Benchmark (JOB) has become the de facto standard to assess the\nperformance of relational database query optimizers due to its complexity and\ncompleteness. In order to compute the optimal execution plan -- join order --\nexisting solutions employ extensive data synopses and correlations --\nfunctional dependencies -- between table attributes. These structures incur\nsignificant overhead to design, build, and maintain. In this paper, we present\n\\textit{Simpli}city \\textit{Simpli}fied (\\textit{Simpli-Squared}), a very\nsimple join ordering algorithm that achieves unexpectedly good results.\nSimpli-Squared computes the join order without using any statistics or\ncardinality estimates. It takes as input only the referential integrity\nconstraints declared at schema definition and the number of tuples (size) in\nthe base tables. The join order of a given query is computed by splitting the\njoin graph along the many-to-many joins and sorting the tables based on their\nsize. The tables involved in one-to-many joins are greedily included based on\nsize and the query join graph. The resulting plan can be efficiently generated\nby a lightweight query rewriting procedure. Experiments on the JOB benchmark in\nPostgreSQL show that Simpli-Squared achieves runtimes having an increase of\nonly up to 16\\% -- and sometimes even a reduction -- compared to four\nstate-of-the-art solutions that are considerably more intricate. Based on these\nresults, we question whether JOB adequately tests query optimizers or if\naccurate cardinality estimation is such a fundamental requirement for\nperforming well on the JOB benchmark.",
    "descriptor": "",
    "authors": [
      "Asoke Datta",
      "Yesdaulet Izenov",
      "Brian Tsan",
      "Florin Rusu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.00163"
  },
  {
    "id": "arXiv:2111.00164",
    "title": "HIERMATCH: Leveraging Label Hierarchies for Improving Semi-Supervised  Learning",
    "abstract": "Semi-supervised learning approaches have emerged as an active area of\nresearch to combat the challenge of obtaining large amounts of annotated data.\nTowards the goal of improving the performance of semi-supervised learning\nmethods, we propose a novel framework, HIERMATCH, a semi-supervised approach\nthat leverages hierarchical information to reduce labeling costs and performs\nas well as a vanilla semi-supervised learning method. Hierarchical information\nis often available as prior knowledge in the form of coarse labels (e.g.,\nwoodpeckers) for images with fine-grained labels (e.g., downy woodpeckers or\ngolden-fronted woodpeckers). However, the use of supervision using coarse\ncategory labels to improve semi-supervised techniques has not been explored. In\nthe absence of fine-grained labels, HIERMATCH exploits the label hierarchy and\nuses coarse class labels as a weak supervisory signal. Additionally, HIERMATCH\nis a generic-approach to improve any semisupervised learning framework, we\ndemonstrate this using our results on recent state-of-the-art techniques\nMixMatch and FixMatch. We evaluate the efficacy of HIERMATCH on two benchmark\ndatasets, namely CIFAR-100 and NABirds. HIERMATCH can reduce the usage of\nfine-grained labels by 50% on CIFAR-100 with only a marginal drop of 0.59% in\ntop-1 accuracy as compared to MixMatch.",
    "descriptor": "\nComments: 10 pages, 1 figure, Accepted in WACV 2022\n",
    "authors": [
      "Ashima Garg",
      "Shaurya Bagga",
      "Yashvardhan Singh",
      "Saket Anand"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00164"
  },
  {
    "id": "arXiv:2111.00166",
    "title": "Advanced Algorithms of Collision Free Navigation and Flocking for  Autonomous UAVs",
    "abstract": "Unmanned aerial vehicles (UAVs) have become very popular for many military\nand civilian applications including in agriculture, construction, mining,\nenvironmental monitoring, etc. A desirable feature for UAVs is the ability to\nnavigate and perform tasks autonomously with least human interaction. This is a\nvery challenging problem due to several factors such as the high complexity of\nUAV applications, operation in harsh environments, limited payload and onboard\ncomputing power and highly nonlinear dynamics. The work presented in this\nreport contributes towards the state-of-the-art in UAV control for safe\nautonomous navigation and motion coordination of multi-UAV systems. The first\npart of this report deals with single-UAV systems. The complex problem of\nthree-dimensional (3D) collision-free navigation in unknown/dynamic\nenvironments is addressed. To that end, advanced 3D reactive control strategies\nare developed adopting the sense-and-avoid paradigm to produce quick reactions\naround obstacles. A special case of navigation in 3D unknown confined\nenvironments (i.e. tunnel-like) is also addressed. General 3D kinematic models\nare considered in the design which makes these methods applicable to different\nUAV types in addition to underwater vehicles. Moreover, different\nimplementation methods for these strategies with quadrotor-type UAVs are also\ninvestigated considering UAV dynamics in the control design. Practical\nexperiments and simulations were carried out to analyze the performance of the\ndeveloped methods. The second part of this report addresses safe navigation for\nmulti-UAV systems. Distributed motion coordination methods of multi-UAV systems\nfor flocking and 3D area coverage are developed. These methods offer good\ncomputational cost for large-scale systems. Simulations were performed to\nverify the performance of these methods considering systems with different\nsizes.",
    "descriptor": "",
    "authors": [
      "Taha Elmokadem"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00166"
  },
  {
    "id": "arXiv:2111.00169",
    "title": "Trojan Source: Invisible Vulnerabilities",
    "abstract": "We present a new type of attack in which source code is maliciously encoded\nso that it appears different to a compiler and to the human eye. This attack\nexploits subtleties in text-encoding standards such as Unicode to produce\nsource code whose tokens are logically encoded in a different order from the\none in which they are displayed, leading to vulnerabilities that cannot be\nperceived directly by human code reviewers. 'Trojan Source' attacks, as we call\nthem, pose an immediate threat both to first-party software and of supply-chain\ncompromise across the industry. We present working examples of Trojan-Source\nattacks in C, C++, C#, JavaScript, Java, Rust, Go, and Python. We propose\ndefinitive compiler-level defenses, and describe other mitigating controls that\ncan be deployed in editors, repositories, and build pipelines while compilers\nare upgraded to block this attack.",
    "descriptor": "",
    "authors": [
      "Nicholas Boucher",
      "Ross Anderson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.00169"
  },
  {
    "id": "arXiv:2111.00172",
    "title": "Finding citations for PubMed: A large-scale comparison between five  freely available bibliographic data sources",
    "abstract": "As an important biomedical database, PubMed provides users with free access\nto abstracts of its documents. However, citations between these documents need\nto be collected from external data sources. Although previous studies have\ninvestigated the coverage of various data sources, the quality of citations is\nunderexplored. In response, this study compares the coverage and citation\nquality of five freely available data sources on 30 million PubMed documents,\nincluding OpenCitations Index of CrossRef open DOI-to-DOI citations (COCI),\nDimensions, Microsoft Academic Graph (MAG), National Institutes of Health Open\nCitation Collection (NIH-OCC), and Semantic Scholar Open Research Corpus\n(S2ORC). Three gold standards and five metrics are introduced to evaluate the\ncorrectness and completeness of citations. Our results indicate that Dimensions\nis the most comprehensive data source that provides references for 62.4% of\nPubMed documents, outperforming the official NIH-OCC dataset (56.7%). Over 90%\nof citation links in other data sources can also be found in Dimensions. The\ncoverage of MAG, COCI, and S2ORC is 59.6%, 34.7%, and 23.5%, respectively.\nRegarding the citation quality, Dimensions and NIH-OCC achieve the best overall\nresults. Almost all data sources have a precision higher than 90%, but their\nrecall is much lower. All databases have better performances on recent\npublications than earlier ones. Meanwhile, the gaps between different data\nsources have diminished for the documents published in recent years. This study\nprovides evidence for researchers to choose suitable PubMed citation sources,\nwhich is also helpful for evaluating the citation quality of free bibliographic\ndatabases.",
    "descriptor": "\nComments: Scientometrics (2021)\n",
    "authors": [
      "Zhentao Liang",
      "Jin Mao",
      "Kun Lu",
      "Gang Li"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2111.00172"
  },
  {
    "id": "arXiv:2111.00173",
    "title": "Dynamic Differential-Privacy Preserving SGD",
    "abstract": "Differentially-Private Stochastic Gradient Descent (DP-SGD) prevents\ntraining-data privacy breaches by adding noise to the clipped gradient during\nSGD training to satisfy the differential privacy (DP) definition. On the other\nhand, the same clipping operation and additive noise across training steps\nresults in unstable updates and even a ramp-up period, which significantly\nreduces the model's accuracy. In this paper, we extend the Gaussian DP central\nlimit theorem to calibrate the clipping value and the noise power for each\nindividual step separately. We, therefore, are able to propose the dynamic\nDP-SGD, which has a lower privacy cost than the DP-SGD during updates until\nthey achieve the same target privacy budget at a target number of updates.\nDynamic DP-SGD, in particular, improves model accuracy without sacrificing\nprivacy by gradually lowering both clipping value and noise power while\nadhering to a total privacy budget constraint. Extensive experiments on a\nvariety of deep learning tasks, including image classification, natural\nlanguage processing, and federated learning, show that the proposed dynamic\nDP-SGD algorithm stabilizes updates and, as a result, significantly improves\nmodel accuracy in the strong privacy protection region when compared to DP-SGD.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Jian Du",
      "Song Li",
      "Moran Feng",
      "Siheng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00173"
  },
  {
    "id": "arXiv:2111.00174",
    "title": "Multi-User Augmented Reality with Infrastructure-free Collaborative  Localization",
    "abstract": "Multi-user augmented reality (AR) could someday empower first responders with\nthe ability to see team members around corners and through walls. For this\nvision of people tracking in dynamic environments to be practical, we need a\nrelative localization system that is nearly instantly available across\nwide-areas without any existing infrastructure or manual setup. In this paper,\nwe present LocAR, an infrastructure-free 6-degrees-of-freedom (6DoF)\nlocalization system for AR applications that uses motion estimates and range\nmeasurements between users to establish an accurate relative coordinate system.\nWe show that not only is it possible to perform collaborative localization\nwithout infrastructure or global coordinates, but that our approach provides\nnearly the same level of accuracy as fixed infrastructure approaches for AR\nteaming applications. LocAR uses visual-inertial odometry (VIO) in conjunction\nwith ultra-wideband (UWB) ranging radios to estimate the relative position of\neach device in an ad-hoc manner. The system leverages a collaborative 6DoF\nparticle filtering formulation that operates on sporadic messages exchanged\nbetween nearby users. Unlike map or landmark sharing approaches, this allows\nfor collaborative AR sessions even if users do not overlap the same spaces.\nLocAR consists of an open-source UWB firmware and reference mobile phone\napplication that can display the location of team members in real-time using\nmobile AR. We evaluate LocAR across multiple buildings under a wide-variety of\nconditions including a contiguous 30,000 square foot region spanning multiple\nfloors and find that it achieves median geometric error in 3D of less than 1\nmeter between five users freely walking across 3 floors.",
    "descriptor": "",
    "authors": [
      "John Miller",
      "Elahe Soltanaghai",
      "Raewyn Duvall",
      "Jeff Chen",
      "Vikram Bhat",
      "Nuno Pereira",
      "Anthony Rowe"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00174"
  },
  {
    "id": "arXiv:2111.00175",
    "title": "Phone Sharing and Cash Transfers in Togo: Quantitative Evidence from  Mobile Phone Data",
    "abstract": "Phone sharing is pervasive in many low- and middle-income countries,\naffecting how millions of people interact with technology and each other. Yet\nthere is very little quantitative evidence available on the extent or nature of\nphone sharing in resource-constrained contexts. This paper provides a\ncomprehensive quantitative analysis of phone sharing in Togo, and documents how\na large cash transfer program during the COVID-19 pandemic impacted sharing\npatterns. We analyze mobile phone records from the entire Togolese mobile\nnetwork to measure the movement of SIM cards between SIM card slots (often on\ndifferent mobile devices). First, we document the prevalence of sharing in\nTogo, with 22% of SIMs and 7% of SIM slots shared. Second, using administrative\ndata from a government-run cash transfer program, we find that phone sharing is\nmost common among women, young people, and people in rural areas. Finally, we\nfind that the delivery of cash aid via mobile money significantly increases\nphone sharing among beneficiaries. We discuss the limitations of measuring\nphone sharing with mobile network data and the implications of our results for\nfuture aid programs delivered via mobile money.",
    "descriptor": "\nComments: 23 pages, 2 figures, 6 tables\n",
    "authors": [
      "Emily L. Aiken",
      "Viraj Thakur",
      "Joshua E. Blumenstock"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.00175"
  },
  {
    "id": "arXiv:2111.00176",
    "title": "Iris Recognition Based on SIFT Features",
    "abstract": "Biometric methods based on iris images are believed to allow very high\naccuracy, and there has been an explosion of interest in iris biometrics in\nrecent years. In this paper, we use the Scale Invariant Feature Transformation\n(SIFT) for recognition using iris images. Contrarily to traditional iris\nrecognition systems, the SIFT approach does not rely on the transformation of\nthe iris pattern to polar coordinates or on highly accurate segmentation,\nallowing less constrained image acquisition conditions. We extract\ncharacteristic SIFT feature points in scale space and perform matching based on\nthe texture information around the feature points using the SIFT operator.\nExperiments are done using the BioSec multimodal database, which includes 3,200\niris images from 200 individuals acquired in two different sessions. We\ncontribute with the analysis of the influence of different SIFT parameters on\nthe recognition performance. We also show the complementarity between the SIFT\napproach and a popular matching approach based on transformation to polar\ncoordinates and Log-Gabor wavelets. The combination of the two approaches\nachieves significantly better performance than either of the individual\nschemes, with a performance improvement of 24% in the Equal Error Rate.",
    "descriptor": "\nComments: Published at IEEE International Conference on Biometrics, Identity and Security (BIdS)\n",
    "authors": [
      "Fernando Alonso-Fernandez",
      "Pedro Tome-Gonzalez",
      "Virginia Ruiz-Albacete",
      "Javier Ortega-Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00176"
  },
  {
    "id": "arXiv:2111.00177",
    "title": "On Quantitative Evaluations of Counterfactuals",
    "abstract": "As counterfactual examples become increasingly popular for explaining\ndecisions of deep learning models, it is essential to understand what\nproperties quantitative evaluation metrics do capture and equally important\nwhat they do not capture. Currently, such understanding is lacking, potentially\nslowing down scientific progress. In this paper, we consolidate the work on\nevaluating visual counterfactual examples through an analysis and experiments.\nWe find that while most metrics behave as intended for sufficiently simple\ndatasets, some fail to tell the difference between good and bad counterfactuals\nwhen the complexity increases. We observe experimentally that metrics give good\nscores to tiny adversarial-like changes, wrongly identifying such changes as\nsuperior counterfactual examples. To mitigate this issue, we propose two new\nmetrics, the Label Variation Score and the Oracle score, which are both less\nvulnerable to such tiny changes. We conclude that a proper quantitative\nevaluation of visual counterfactual examples should combine metrics to ensure\nthat all aspects of good counterfactuals are quantified.",
    "descriptor": "",
    "authors": [
      "Frederik Hvilsh\u00f8j",
      "Alexandros Iosifidis",
      "Ira Assent"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00177"
  },
  {
    "id": "arXiv:2111.00178",
    "title": "Direct attacks using fake images in iris verification",
    "abstract": "In this contribution, the vulnerabilities of iris-based recognition systems\nto direct attacks are studied. A database of fake iris images has been created\nfrom real iris of the BioSec baseline database. Iris images are printed using a\ncommercial printer and then, presented at the iris sensor. We use for our\nexperiments a publicly available iris recognition system, which some\nmodifications to improve the iris segmentation step. Based on results achieved\non different operational scenarios, we show that the system is vulnerable to\ndirect attacks, pointing out the importance of having countermeasures against\nthis type of fraudulent actions.",
    "descriptor": "\nComments: Published at European Workshop on Biometrics and Identity Management (BIOID)\n",
    "authors": [
      "Virginia Ruiz-Albacete",
      "Pedro Tome-Gonzalez",
      "Fernando Alonso-Fernandez",
      "Javier Galbally",
      "Julian Fierrez",
      "Javier Ortega-Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00178"
  },
  {
    "id": "arXiv:2111.00180",
    "title": "Hierarchical Heterogeneous Graph Representation Learning for Short Text  Classification",
    "abstract": "Short text classification is a fundamental task in natural language\nprocessing. It is hard due to the lack of context information and labeled data\nin practice. In this paper, we propose a new method called SHINE, which is\nbased on graph neural network (GNN), for short text classification. First, we\nmodel the short text dataset as a hierarchical heterogeneous graph consisting\nof word-level component graphs which introduce more semantic and syntactic\ninformation. Then, we dynamically learn a short document graph that facilitates\neffective label propagation among similar short texts. Thus, compared with\nexisting GNN-based methods, SHINE can better exploit interactions between nodes\nof the same types and capture similarities between short texts. Extensive\nexperiments on various benchmark short text datasets show that SHINE\nconsistently outperforms state-of-the-art methods, especially with fewer\nlabels.",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Yaqing Wang",
      "Song Wang",
      "Quanming Yao",
      "Dejing Dou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00180"
  },
  {
    "id": "arXiv:2111.00184",
    "title": "Geometry-Aware Hierarchical Bayesian Learning on Manifolds",
    "abstract": "Bayesian learning with Gaussian processes demonstrates encouraging regression\nand classification performances in solving computer vision tasks. However,\nBayesian methods on 3D manifold-valued vision data, such as meshes and point\nclouds, are seldom studied. One of the primary challenges is how to effectively\nand efficiently aggregate geometric features from the irregular inputs. In this\npaper, we propose a hierarchical Bayesian learning model to address this\nchallenge. We initially introduce a kernel with the properties of\ngeometry-awareness and intra-kernel convolution. This enables geometrically\nreasonable inferences on manifolds without using any specific hand-crafted\nfeature descriptors. Then, we use a Gaussian process regression to organize the\ninputs and finally implement a hierarchical Bayesian network for the feature\naggregation. Furthermore, we incorporate the feature learning of neural\nnetworks with the feature aggregation of Bayesian models to investigate the\nfeasibility of jointly learning on manifolds. Experimental results not only\nshow that our method outperforms existing Bayesian methods on manifolds but\nalso demonstrate the prospect of coupling neural networks with Bayesian\nnetworks.",
    "descriptor": "\nComments: Published in WACV 2022\n",
    "authors": [
      "Yonghui Fan",
      "Yalin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00184"
  },
  {
    "id": "arXiv:2111.00185",
    "title": "Convergence and Optimality of Policy Gradient Methods in Weakly Smooth  Settings",
    "abstract": "Policy gradient methods have been frequently applied to problems in control\nand reinforcement learning with great success, yet existing convergence\nanalysis still relies on non-intuitive, impractical and often opaque\nconditions. In particular, existing rates are achieved in limited settings,\nunder strict smoothness and bounded conditions. In this work, we establish\nexplicit convergence rates of policy gradient methods without relying on these\nconditions, instead extending the convergence regime to weakly smooth policy\nclasses with $L_2$ integrable gradient. We provide intuitive examples to\nillustrate the insight behind these new conditions. We also characterize the\nsufficiency conditions for the ergodicity of near-linear MDPs, which represent\nan important class of problems. Notably, our analysis also shows that fast\nconvergence rates are achievable for both the standard policy gradient and the\nnatural policy gradient algorithms under these assumptions. Lastly we provide\nconditions and analysis for optimality of the converged policies.",
    "descriptor": "",
    "authors": [
      "Matthew Shunshi Zhang",
      "Murat Erdogdu",
      "Animesh Garg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00185"
  },
  {
    "id": "arXiv:2111.00190",
    "title": "Leveraging SE(3) Equivariance for Self-Supervised Category-Level Object  Pose Estimation",
    "abstract": "Category-level object pose estimation aims to find 6D object poses of\npreviously unseen object instances from known categories without access to\nobject CAD models. To reduce the huge amount of pose annotations needed for\ncategory-level learning, we propose for the first time a self-supervised\nlearning framework to estimate category-level 6D object pose from single 3D\npoint clouds.During training, our method assumes no ground-truth pose\nannotations, no CAD models, and no multi-view supervision. The key to our\nmethod is to disentangle shape and pose through an invariant shape\nreconstruction module and an equivariant pose estimation module, empowered by\nSE(3) equivariant point cloud networks.The invariant shape reconstruction\nmodule learns to perform aligned reconstructions, yielding a category-level\nreference frame without using any annotations. In addition, the equivariant\npose estimation module achieves category-level pose estimation accuracy that is\ncomparable to some fully supervised methods. Extensive experiments demonstrate\nthe effectiveness of our approach on both complete and partial depth point\nclouds from the ModelNet40 benchmark, and on real depth point clouds from the\nNOCS-REAL 275 dataset. The project page with code and visualizations can be\nfound at: https://dragonlong.github.io/equi-pose.",
    "descriptor": "\nComments: 20 pages, 11 figures\n",
    "authors": [
      "Xiaolong Li",
      "Yijia Weng",
      "Li Yi",
      "Leonidas Guibas",
      "A. Lynn Abbott",
      "Shuran Song",
      "He Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00190"
  },
  {
    "id": "arXiv:2111.00191",
    "title": "How should human translation coexist with NMT? Efficient tool for  building high quality parallel corpus",
    "abstract": "This paper proposes a tool for efficiently constructing high-quality parallel\ncorpora with minimizing human labor and making this tool publicly available.\nOur proposed construction process is based on neural machine translation (NMT)\nto allow for it to not only coexist with human translation, but also improve\nits efficiency by combining data quality control with human translation in a\ndata-centric approach.",
    "descriptor": "\nComments: Accepted for Data-centric AI workshop at NeurIPS 2021\n",
    "authors": [
      "Chanjun Park",
      "Seolhwa Lee",
      "Hyeonseok Moon",
      "Sugyeong Eo",
      "Jaehyung Seo",
      "Heuiseok Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00191"
  },
  {
    "id": "arXiv:2111.00192",
    "title": "Automatic Knowledge Augmentation for Generative Commonsense Reasoning",
    "abstract": "Generative commonsense reasoning is the capability of a language model to\ngenerate a sentence with a given concept-set that is based on commonsense\nknowledge. However, generative language models still struggle to provide\noutputs, and the training set does not contain patterns that are sufficient for\ngenerative commonsense reasoning. In this paper, we propose a data-centric\nmethod that uses automatic knowledge augmentation to extend commonsense\nknowledge using a machine knowledge generator. This method can generate\nsemi-golden sentences that improve the generative commonsense reasoning of a\nlanguage model without architecture modifications. Furthermore, this approach\nis a model-agnostic method and does not require human effort for data\nconstruction.",
    "descriptor": "\nComments: Accepted for Data-centric AI workshop at NeurIPS 2021\n",
    "authors": [
      "Jaehyung Seo",
      "Chanjun Park",
      "Sugyeong Eo",
      "Hyeonseok Moon",
      "Heuiseok Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00192"
  },
  {
    "id": "arXiv:2111.00195",
    "title": "Learning Continuous Representation of Audio for Arbitrary Scale Super  Resolution",
    "abstract": "Audio super resolution aims to predict the missing high resolution components\nof the low resolution audio signals. While audio in nature is continuous\nsignal, current approaches treat it as discrete data (i.e., input is defined on\ndiscrete time domain), and consider the super resolution over fixed scale\nfactor (i.e., it is required to train a new neural network to change output\nresolution). To obtain a continuous representation of audio and enable super\nresolution for arbitrary scale factor, we propose a method of neural implicit\nrepresentation, coined Local Implicit representation for Super resolution of\nArbitrary scale (LISA). Our method locally parameterizes a chunk of audio as a\nfunction of continuous time, and represents each chunk with the local latent\ncodes of neighboring chunks so that the function can extrapolate the signal at\nany time coordinate, i.e., infinite resolution. To learn a continuous\nrepresentation for audio, we design a self-supervised learning strategy to\npractice super resolution tasks up to the original resolution by stochastic\nselection. Our numerical evaluation shows that LISA outperforms the previous\nfixed-scale methods with a fraction of parameters, but also is capable of\narbitrary scale super resolution even beyond the resolution of training data.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Jaechang Kim",
      "Yunjoo Lee",
      "Seunghoon Hong",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.00195"
  },
  {
    "id": "arXiv:2111.00197",
    "title": "Backdoor Pre-trained Models Can Transfer to All",
    "abstract": "Pre-trained general-purpose language models have been a dominating component\nin enabling real-world natural language processing (NLP) applications. However,\na pre-trained model with backdoor can be a severe threat to the applications.\nMost existing backdoor attacks in NLP are conducted in the fine-tuning phase by\nintroducing malicious triggers in the targeted class, thus relying greatly on\nthe prior knowledge of the fine-tuning task. In this paper, we propose a new\napproach to map the inputs containing triggers directly to a predefined output\nrepresentation of the pre-trained NLP models, e.g., a predefined output\nrepresentation for the classification token in BERT, instead of a target label.\nIt can thus introduce backdoor to a wide range of downstream tasks without any\nprior knowledge. Additionally, in light of the unique properties of triggers in\nNLP, we propose two new metrics to measure the performance of backdoor attacks\nin terms of both effectiveness and stealthiness. Our experiments with various\ntypes of triggers show that our method is widely applicable to different\nfine-tuning tasks (classification and named entity recognition) and to\ndifferent models (such as BERT, XLNet, BART), which poses a severe threat.\nFurthermore, by collaborating with the popular online model repository Hugging\nFace, the threat brought by our method has been confirmed. Finally, we analyze\nthe factors that may affect the attack performance and share insights on the\ncauses of the success of our backdoor attack.",
    "descriptor": "",
    "authors": [
      "Lujia Shen",
      "Shouling Ji",
      "Xuhong Zhang",
      "Jinfeng Li",
      "Jing Chen",
      "Jie Shi",
      "Chengfang Fang",
      "Jianwei Yin",
      "Ting Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00197"
  },
  {
    "id": "arXiv:2111.00199",
    "title": "Personal thermal comfort models using digital twins: Preference  prediction with BIM-extracted spatial-temporal proximity data from Build2Vec",
    "abstract": "Conventional thermal preference prediction in buildings has limitations due\nto the difficulty in capturing all environmental and personal factors. New\nmodel features can improve the ability of a machine learning model to classify\na person's thermal preference. The spatial context of a building can provide\ninformation to models about the windows, walls, heating and cooling sources,\nair diffusers, and other factors that create micro-environments that influence\nthermal comfort. Due to spatial heterogeneity, it is impractical to position\nsensors at a high enough resolution to capture all conditions. This research\naims to build upon an existing vector-based spatial model, called Build2Vec,\nfor predicting spatial-temporal occupants' indoor environmental preferences.\nBuild2Vec utilizes the spatial data from the Building Information Model (BIM)\nand indoor localization in a real-world setting. This framework uses\nlongitudinal intensive thermal comfort subjective feedback from smart\nwatch-based ecological momentary assessments (EMA). The aggregation of these\ndata is combined into a graph network structure (i.e., objects and relations)\nand used as input for a classification model to predict occupant thermal\npreference. The results of a test implementation show 14-28% accuracy\nimprovement over a set of baselines that use conventional thermal preference\nprediction input variables.",
    "descriptor": "",
    "authors": [
      "Mahmoud Abdelrahman",
      "Adrian Chong",
      "Clayton Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00199"
  },
  {
    "id": "arXiv:2111.00200",
    "title": "AutoDrone: Shortest Optimized Obstacle-Free Path Planning for Autonomous  Drones",
    "abstract": "With technological advancement, drone has emerged as unmanned aerial vehicle\nthat can be controlled by humans to fly or reach a destination. This may be\nautonomous as well, where the drone itself is intelligent enough to find a\nshortest obstacle-free path to reach the destination from a designated source.\nBe it a planned smart city or even a wreckage site affected by natural\ncalamity, we may imagine the buildings, any surface-erected structure or other\nblockage as obstacles for the drone to fly in a direct line-of-sight path. So,\nthe whole bird's eye-view of the landscape can be transformed to a graph of\ngrid-cells, where some are occupied to indicate the obstacles and some are free\nto indicate the free path. The autonomous drone (AutoDrone) will be able to\nfind out the shortest hindrance-free path while travelling in two-dimensional\nspace and move from one place to another. In this paper, we propose a method to\nfind out an obstacle-free shortest path in the coordinate system guided by GPS.\nThis can be especially beneficial in rescue operations and fast delivery or\npick-up in an energy-efficient way, where our algorithm will help in finding\nout the shortest path and angle along which it should fly. Our work shows\ndifferent scenarios to path-tracing, through the shortest feasible path\ncomputed by the autonomous drone.",
    "descriptor": "",
    "authors": [
      "Prithwish Jana",
      "Debasish Jana"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00200"
  },
  {
    "id": "arXiv:2111.00201",
    "title": "A Comparative Review of Recent Few-Shot Object Detection Algorithms",
    "abstract": "Few-shot object detection, learning to adapt to the novel classes with a few\nlabeled data, is an imperative and long-lasting problem due to the inherent\nlong-tail distribution of real-world data and the urgent demands to cut costs\nof data collection and annotation. Recently, some studies have explored how to\nuse implicit cues in extra datasets without target-domain supervision to help\nfew-shot detectors refine robust task notions. This survey provides a\ncomprehensive overview from current classic and latest achievements for\nfew-shot object detection to future research expectations from manifold\nperspectives. In particular, we first propose a data-based taxonomy of the\ntraining data and the form of corresponding supervision which are accessed\nduring the training stage. Following this taxonomy, we present a significant\nreview of the formal definition, main challenges, benchmark datasets,\nevaluation metrics, and learning strategies. In addition, we present a detailed\ninvestigation of how to interplay the object detection methods to develop this\nissue systematically. Finally, we conclude with the current status of few-shot\nobject detection, along with potential research directions for this field.",
    "descriptor": "",
    "authors": [
      "Leng Jiaxu",
      "Chen Taiyue",
      "Gao Xinbo",
      "Yu Yongtao",
      "Wang Ye",
      "Gao Feng",
      "Wang Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00201"
  },
  {
    "id": "arXiv:2111.00202",
    "title": "Articulations and Products of Transition Systems and their Applications  to Petri Net Synthesis",
    "abstract": "In order to speed up the synthesis of Petri nets from labelled transition\nsystems, a divide and conquer strategy consists in defining decompositions of\nlabelled transition systems, such that each component is synthesisable iff so\nis the original system. Then corresponding Petri Net composition operators are\nsearched to combine the solutions of the various components\ninto a solution of the original system. The paper presents two such\ntechniques, which may be combined: products and articulations. They may also be\nused to structure transition systems, and to analyse the performance of\nsynthesis techniques when applied to such structures.",
    "descriptor": "",
    "authors": [
      "Raymond Devillers"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.00202"
  },
  {
    "id": "arXiv:2111.00203",
    "title": "Imitating Arbitrary Talking Style for Realistic Audio-DrivenTalking Face  Synthesis",
    "abstract": "People talk with diversified styles. For one piece of speech, different\ntalking styles exhibit significant differences in the facial and head pose\nmovements. For example, the \"excited\" style usually talks with the mouth wide\nopen, while the \"solemn\" style is more standardized and seldomly exhibits\nexaggerated motions. Due to such huge differences between different styles, it\nis necessary to incorporate the talking style into audio-driven talking face\nsynthesis framework. In this paper, we propose to inject style into the talking\nface synthesis framework through imitating arbitrary talking style of the\nparticular reference video. Specifically, we systematically investigate talking\nstyles with our collected \\textit{Ted-HD} dataset and construct style codes as\nseveral statistics of 3D morphable model~(3DMM) parameters. Afterwards, we\ndevise a latent-style-fusion~(LSF) model to synthesize stylized talking faces\nby imitating talking styles from the style codes. We emphasize the following\nnovel characteristics of our framework: (1) It doesn't require any annotation\nof the style, the talking style is learned in an unsupervised manner from\ntalking videos in the wild. (2) It can imitate arbitrary styles from arbitrary\nvideos, and the style codes can also be interpolated to generate new styles.\nExtensive experiments demonstrate that the proposed framework has the ability\nto synthesize more natural and expressive talking styles compared with baseline\nmethods.",
    "descriptor": "\nComments: Accepted by MM2021, code available at this https URL\n",
    "authors": [
      "Haozhe Wu",
      "Jia Jia",
      "Haoyu Wang",
      "Yishun Dou",
      "Chao Duan",
      "Qingshan Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.00203"
  },
  {
    "id": "arXiv:2111.00206",
    "title": "One Step at a Time: Pros and Cons of Multi-Step Meta-Gradient  Reinforcement Learning",
    "abstract": "Self-tuning algorithms that adapt the learning process online encourage more\neffective and robust learning. Among all the methods available, meta-gradients\nhave emerged as a promising approach. They leverage the differentiability of\nthe learning rule with respect to some hyper-parameters to adapt them in an\nonline fashion. Although meta-gradients can be accumulated over multiple\nlearning steps to avoid myopic updates, this is rarely used in practice. In\nthis work, we demonstrate that whilst multi-step meta-gradients do provide a\nbetter learning signal in expectation, this comes at the cost of a significant\nincrease in variance, hindering performance. In the light of this analysis, we\nintroduce a novel method mixing multiple inner steps that enjoys a more\naccurate and robust meta-gradient signal, essentially trading off bias and\nvariance in meta-gradient estimation. When applied to the Snake game, the\nmixing meta-gradient algorithm can cut the variance by a factor of 3 while\nachieving similar or higher performance.",
    "descriptor": "\nComments: 14 pages, 6 figures, 2 tables\n",
    "authors": [
      "Cl\u00e9ment Bonnet",
      "Paul Caron",
      "Thomas Barrett",
      "Ian Davies",
      "Alexandre Laterre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00206"
  },
  {
    "id": "arXiv:2111.00207",
    "title": "PatchFormer: A Versatile 3D Transformer Based on Patch Attention",
    "abstract": "The 3D vision community is witnesses a modeling shift from CNNs to\nTransformers, where pure Transformer architectures have attained top accuracy\non the major 3D learning benchmarks. However, existing 3D Transformers need to\ngenerate a large attention map, which has quadratic complexity (both in space\nand time) with respect to input size. To solve this shortcoming, we introduce\npatch-attention to adaptively learn a much smaller set of bases upon which the\nattention maps are computed. By a weighted summation upon these bases,\npatch-attention not only captures the global shape context but also achieves\nlinear complexity to input size. In addition, we propose a lightweight\nMulti-scale Attention (MSA) block to build attentions among features of\ndifferent scales, providing the model with multi-scale features. Based on these\nproposed modules, we construct our neural architecture called PatchFormer.\nExtensive experiments demonstrate that our network achieves strong accuracy on\ngeneral 3D recognition tasks with 7.3x speed-up than previous 3D Transformers.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Zhang Cheng",
      "Haocheng Wan",
      "Xinyi Shen",
      "Zizhao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00207"
  },
  {
    "id": "arXiv:2111.00210",
    "title": "Mastering Atari Games with Limited Data",
    "abstract": "Reinforcement learning has achieved great success in many applications.\nHowever, sample efficiency remains a key challenge, with prominent methods\nrequiring millions (or even billions) of environment steps to train. Recently,\nthere has been significant progress in sample efficient image-based RL\nalgorithms; however, consistent human-level performance on the Atari game\nbenchmark remains an elusive goal. We propose a sample efficient model-based\nvisual RL algorithm built on MuZero, which we name EfficientZero. Our method\nachieves 190.4% mean human performance and 116.0% median performance on the\nAtari 100k benchmark with only two hours of real-time game experience and\noutperforms the state SAC in some tasks on the DMControl 100k benchmark. This\nis the first time an algorithm achieves super-human performance on Atari games\nwith such little data. EfficientZero's performance is also close to DQN's\nperformance at 200 million frames while we consume 500 times less data.\nEfficientZero's low sample complexity and high performance can bring RL closer\nto real-world applicability. We implement our algorithm in an\neasy-to-understand manner and it is available at\nhttps://github.com/YeWR/EfficientZero. We hope it will accelerate the research\nof MCTS-based RL algorithms in the wider community.",
    "descriptor": "\nComments: Published at NeurIPS 2021\n",
    "authors": [
      "Weirui Ye",
      "Shaohuai Liu",
      "Thanard Kurutach",
      "Pieter Abbeel",
      "Yang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00210"
  },
  {
    "id": "arXiv:2111.00213",
    "title": "Adjacency constraint for efficient hierarchical reinforcement learning",
    "abstract": "Goal-conditioned Hierarchical Reinforcement Learning (HRL) is a promising\napproach for scaling up reinforcement learning (RL) techniques. However, it\noften suffers from training inefficiency as the action space of the high-level,\ni.e., the goal space, is large. Searching in a large goal space poses\ndifficulty for both high-level subgoal generation and low-level policy\nlearning. In this paper, we show that this problem can be effectively\nalleviated by restricting the high-level action space from the whole goal space\nto a $k$-step adjacent region of the current state using an adjacency\nconstraint. We theoretically prove that in a deterministic Markov Decision\nProcess (MDP), the proposed adjacency constraint preserves the optimal\nhierarchical policy, while in a stochastic MDP the adjacency constraint induces\na bounded state-value suboptimality determined by the MDP's transition\nstructure. We further show that this constraint can be practically implemented\nby training an adjacency network that can discriminate between adjacent and\nnon-adjacent subgoals. Experimental results on discrete and continuous control\ntasks including challenging simulated robot locomotion and manipulation tasks\nshow that incorporating the adjacency constraint significantly boosts the\nperformance of state-of-the-art goal-conditioned HRL approaches.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2006.11485\n",
    "authors": [
      "Tianren Zhang",
      "Shangqi Guo",
      "Tian Tan",
      "Xiaolin Hu",
      "Feng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00213"
  },
  {
    "id": "arXiv:2111.00215",
    "title": "Approximation properties of Residual Neural Networks for Kolmogorov PDEs",
    "abstract": "In recent years residual neural networks (ResNets) as introduced by [He, K.,\nZhang, X., Ren, S., and Sun, J., Proceedings of the IEEE conference on computer\nvision and pattern recognition (2016), 770-778] have become very popular in a\nlarge number of applications, including in image classification and\nsegmentation. They provide a new perspective in training very deep neural\nnetworks without suffering the vanishing gradient problem. In this article we\nshow that ResNets are able to approximate solutions of Kolmogorov partial\ndifferential equations (PDEs) with constant diffusion and possibly nonlinear\ndrift coefficients without suffering the curse of dimensionality, which is to\nsay the number of parameters of the approximating ResNets grows at most\npolynomially in the reciprocal of the approximation accuracy $\\varepsilon > 0$\nand the dimension of the considered PDE $d\\in\\mathbb{N}$. We adapt a proof in\n[Jentzen, A., Salimova, D., and Welti, T., Commun. Math. Sci. 19, 5 (2021),\n1167-1205] - who showed a similar result for feedforward neural networks (FNNs)\n- to ResNets. In contrast to FNNs, the Euler-Maruyama approximation structure\nof ResNets simplifies the construction of the approximating ResNets\nsubstantially. Moreover, contrary to the above work, in our proof using ResNets\ndoes not require the existence of an FNN (or a ResNet) representing the\nidentity map, which enlarges the set of applicable activation functions.",
    "descriptor": "\nComments: 24 pages, 2 figures\n",
    "authors": [
      "Jonas Baggenstos",
      "Diyora Salimova"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.00215"
  },
  {
    "id": "arXiv:2111.00217",
    "title": "On quadrature rules for solving Partial Differential Equations using  Neural Networks",
    "abstract": "Neural Networks have been widely used to solve Partial Differential\nEquations. These methods require to approximate definite integrals using\nquadrature rules. Here, we illustrate via 1D numerical examples the quadrature\nproblems that may arise in these applications and propose different\nalternatives to overcome them, namely: Monte Carlo methods, adaptive\nintegration, polynomial approximations of the Neural Network output, and the\ninclusion of regularization terms in the loss. We also discuss the advantages\nand limitations of each proposed alternative. We advocate the use of Monte\nCarlo methods for high dimensions (above 3 or 4), and adaptive integration or\npolynomial approximations for low dimensions (3 or below). The use of\nregularization terms is a mathematically elegant alternative that is valid for\nany spacial dimension, however, it requires certain regularity assumptions on\nthe solution and complex mathematical analysis when dealing with sophisticated\nNeural Networks.",
    "descriptor": "",
    "authors": [
      "Jon A. Rivera",
      "Jamie M. Taylor",
      "\u00c1ngel J. Omella",
      "David Pardo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00217"
  },
  {
    "id": "arXiv:2111.00218",
    "title": "A Non-Deterministic Multiset Query Language",
    "abstract": "We develop a multiset query and update language executable in a term\nrewriting system. Its most remarkable feature, besides non-standard approach to\nquantification and introduction of fresh values, is non-determinism - a query\nresult is not uniquely determined by the database. We argue that this feature\nis very useful, e.g., in modelling user choices during simulation or\nreachability analysis of a data-centric business process - the intended\napplication of our work. Query evaluation is implemented by converting the\nquery into a terminating term rewriting system and normalizing the initial term\nwhich encapsulates the current database. A normal form encapsulates a query\nresult. We prove that our language can express any relational algebra query.\nFinally, we present a simple business process specification framework (and an\nexample specification). Both syntax and semantics of our query language is\nimplemented in Maude.",
    "descriptor": "\nComments: 40 pages, accepted for publication in Fundamenta Informaticae\n",
    "authors": [
      "Bartosz Zielinski"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.00218"
  },
  {
    "id": "arXiv:2111.00221",
    "title": "Chaos Engineering of Ethereum Blockchain Clients",
    "abstract": "The Ethereum blockchain is the operational backbone of major decentralized\nfinance platforms. As such, it is expected to be exceptionally reliable. In\nthis paper, we present ChaosETH, a chaos engineering tool for resilience\nassessment of Ethereum clients. ChaosETH operates in the following manner:\nFirst, it monitors Ethereum clients to determine their normal behavior. Then,\nit injects system call invocation errors into the Ethereum clients and observes\nthe resulting behavior under perturbation. Finally, ChaosETH compares the\nbehavior recorded before, during, and after perturbation to assess the impact\nof the injected system call invocation errors. The experiments are performed on\nthe two most popular Ethereum client implementations: GoEthereum and\nOpenEthereum. We experiment with 22 different types of system call invocation\nerrors. We assess their impact on the Ethereum clients with respect to 15\napplication-level metrics. Our results reveal a broad spectrum of resilience\ncharacteristics of Ethereum clients in the presence of system call invocation\nerrors, ranging from direct crashes to full resilience. The experiments clearly\ndemonstrate the feasibility of applying chaos engineering principles to\nblockchains.",
    "descriptor": "",
    "authors": [
      "Long Zhang",
      "Javier Ron",
      "Benoit Baudry",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00221"
  },
  {
    "id": "arXiv:2111.00222",
    "title": "A Hybrid Software Test Automation for Educational Portals",
    "abstract": "Educational portal (EP) is a multi-function website that allows access to\nactivities such as public and private sections, data retrieval and submission,\npersonalized content and so on for the educational system. This study\ninvestigated the specific requirement for the enhancement of quality and\nbehavior of EP with regards to time and cost using Obafemi Awolowo University\n(OAU), Ile-Ife, Nigeria as a case study. A test automation framework was\ndesigned using unified modelling language and implemented in Java programming\nlanguage. MySQL and Excel database were used to store test data. The framework\ndeveloped was evaluated using Test Time Performance (TTP), Performance Test\nEfficiency (PTE) and Automation Scripting Productivity (ASP) metrics. The\nresults from the evaluation of the sample data provided showed that ASP\nproduced a tested outcome of 360 operations per hour, PTE yielded 80% and TTP\nwas just 4%. Based on the recorded performance, it is evident that the research\ncan provide quick and firsthand information to quality assurance analyst and\nsoftware testers, thereby reducing maintenance cost during software\ndevelopment.",
    "descriptor": "",
    "authors": [
      "A. T. Aniwange",
      "P. T. Nyishar",
      "B. S. Afolabi",
      "A. O. Ejidokun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.00222"
  },
  {
    "id": "arXiv:2111.00228",
    "title": "A Spatio-Temporal Identity Verification Method for Person-Action  Instance Search in Movies",
    "abstract": "As one of the challenging problems in video search, Person-Action Instance\nSearch (INS) aims to retrieve shots with specific person carrying out specific\naction from massive video shots. Existing methods mainly include two steps:\nFirst, two individual INS branches, i.e., person INS and action INS, are\nseparately conducted to compute the initial person and action ranking scores;\nSecond, both scores are directly fused to generate the final ranking list.\nHowever, direct aggregation of two individual INS scores cannot guarantee the\nidentity consistency between person and action. For example, a shot with \"Pat\nis standing\" and \"Ian is sitting on couch\" may be erroneously understood as\n\"Pat is sitting on couch\" or \"Ian is standing\". To address the above identity\ninconsistency problem (IIP), we study a spatio-temporal identity verification\nmethod. Specifically, in the spatial dimension, we propose an identity\nconsistency verification scheme to optimize the direct fusion score of person\nINS and action INS. The motivation originates from an observation that face\ndetection results usually locate in the identity-consistent action bounding\nboxes. Moreover, in the temporal dimension, considering the complex filming\ncondition, we propose an inter-frame detection extension operation to\ninterpolate missing face/action detection results in successive video frames.\nThe proposed method is evaluated on the large scale TRECVID INS dataset, and\nthe experimental results show that our method can effectively mitigate the IIP\nand surpass the existing second places in both TRECVID 2019 and 2020 INS tasks.",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Jingyao Yang",
      "Chao Liang",
      "Yanrui Niu",
      "Baojin Huang",
      "Zhongyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.00228"
  },
  {
    "id": "arXiv:2111.00229",
    "title": "Fuzzy Conceptual Graphs: a comparative discussion",
    "abstract": "Conceptual Graphs (CG) are a graph-based knowledge representation and\nreasoning formalism; fuzzy Conceptual Graphs (fCG) constitute an extension that\nenriches their expressiveness, exploiting the fuzzy set theory so as to relax\ntheir constraints at various levels. This paper proposes a comparative study of\nexisting approaches over their respective advantages and possible limitations.\nThe discussion revolves around three axes: (a) Critical view of each approach\nand comparison with previous propositions from the state of the art; (b)\nPresentation of the many possible interpretations of each definition to\nillustrate its potential and its limits; (c) Clarification of the part of CG\nimpacted by the definition as well as the relaxed constraint.",
    "descriptor": "",
    "authors": [
      "Adam Faci",
      "Marie-Jeanne Lesot",
      "Claire Laudy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.00229"
  },
  {
    "id": "arXiv:2111.00230",
    "title": "Magic Pyramid: Accelerating Inference with Early Exiting and Token  Pruning",
    "abstract": "Pre-training and then fine-tuning large language models is commonly used to\nachieve state-of-the-art performance in natural language processing (NLP)\ntasks. However, most pre-trained models suffer from low inference speed.\nDeploying such large models to applications with latency constraints is\nchallenging. In this work, we focus on accelerating the inference via\nconditional computations. To achieve this, we propose a novel idea, Magic\nPyramid (MP), to reduce both width-wise and depth-wise computation via token\npruning and early exiting for Transformer-based models, particularly BERT. The\nformer manages to save the computation via removing non-salient tokens, while\nthe latter can fulfill the computation reduction by terminating the inference\nearly before reaching the final layer, if the exiting condition is met. Our\nempirical studies demonstrate that compared to previous state of arts, MP is\nnot only able to achieve a speed-adjustable inference but also to surpass token\npruning and early exiting by reducing up to 70% giga floating point operations\n(GFLOPs) with less than 0.5% accuracy drop. Token pruning and early exiting\nexpress distinctive preferences to sequences with different lengths. However,\nMP is capable of achieving an average of 8.06x speedup on two popular text\nclassification tasks, regardless of the sizes of the inputs.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Xuanli He",
      "Iman Keivanloo",
      "Yi Xu",
      "Xiang He",
      "Belinda Zeng",
      "Santosh Rajagopalan",
      "Trishul Chilimbi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00230"
  },
  {
    "id": "arXiv:2111.00231",
    "title": "Two Heads are Better than One: Geometric-Latent Attention for Point  Cloud Classification and Segmentation",
    "abstract": "We present an innovative two-headed attention layer that combines geometric\nand latent features to segment a 3D scene into semantically meaningful subsets.\nEach head combines local and global information, using either the geometric or\nlatent features, of a neighborhood of points and uses this information to learn\nbetter local relationships. This Geometric-Latent attention layer (Ge-Latto) is\ncombined with a sub-sampling strategy to capture global features. Our method is\ninvariant to permutation thanks to the use of shared-MLP layers, and it can\nalso be used with point clouds with varying densities because the local\nattention layer does not depend on the neighbor order. Our proposal is simple\nyet robust, which allows it to achieve competitive results in the ShapeNetPart\nand ModelNet40 datasets, and the state-of-the-art when segmenting the complex\ndataset S3DIS, with 69.2% IoU on Area 5, and 89.7% overall accuracy using\nK-fold cross-validation on the 6 areas.",
    "descriptor": "\nComments: Accepted in BMVC 2021\n",
    "authors": [
      "Hanz Cuevas-Velasquez",
      "Antonio Javier Gallego",
      "Robert B. Fisher"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00231"
  },
  {
    "id": "arXiv:2111.00232",
    "title": "MFNet: Multi-class Few-shot Segmentation Network with Pixel-wise Metric  Learning",
    "abstract": "In visual recognition tasks, few-shot learning requires the ability to learn\nobject categories with few support examples. Its recent resurgence in light of\nthe deep learning development is mainly in image classification. This work\nfocuses on few-shot semantic segmentation, which is still a largely unexplored\nfield. A few recent advances are often restricted to single-class few-shot\nsegmentation. In this paper, we first present a novel multi-way encoding and\ndecoding architecture which effectively fuses multi-scale query information and\nmulti-class support information into one query-support embedding; multi-class\nsegmentation is directly decoded upon this embedding. In order for better\nfeature fusion, a multi-level attention mechanism is proposed within the\narchitecture, which includes the attention for support feature modulation and\nattention for multi-scale combination. Last, to enhance the embedding space\nlearning, an additional pixel-wise metric learning module is devised with\ntriplet loss formulated on the pixel-level embedding of the input image.\nExtensive experiments on standard benchmarks PASCAL-5^i and COCO-20^i show\nclear benefits of our method over the state of the art in few-shot\nsegmentation.",
    "descriptor": "",
    "authors": [
      "Miao Zhang",
      "Miaojing Shi",
      "Li Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00232"
  },
  {
    "id": "arXiv:2111.00234",
    "title": "On Joint Learning for Solving Placement and Routing in Chip Design",
    "abstract": "For its advantage in GPU acceleration and less dependency on human experts,\nmachine learning has been an emerging tool for solving the placement and\nrouting problems, as two critical steps in modern chip design flow. Being still\nin its early stage, there are fundamental issues: scalability, reward design,\nand end-to-end learning paradigm etc. To achieve end-to-end placement learning,\nwe first propose a joint learning method termed by DeepPlace for the placement\nof macros and standard cells, by the integration of reinforcement learning with\na gradient based optimization scheme. To further bridge the placement with the\nsubsequent routing task, we also develop a joint learning approach via\nreinforcement learning to fulfill both macro placement and routing, which is\ncalled DeepPR. One key design in our (reinforcement) learning paradigm involves\na multi-view embedding model to encode both global graph level and local node\nlevel information of the input macros. Moreover, the random network\ndistillation is devised to encourage exploration. Experiments on public chip\ndesign benchmarks show that our method can effectively learn from experience\nand also provides intermediate placement for the post standard cell placement,\nwithin few hours for training.",
    "descriptor": "\nComments: accepted for 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Ruoyu Cheng",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00234"
  },
  {
    "id": "arXiv:2111.00235",
    "title": "Multi-weight Matrix Completion with Arbitrary Subspace Prior Information",
    "abstract": "Matrix completion refers to completing a low-rank matrix from a few observed\nelements of its entries and has been known as one of the significant and\nwidely-used problems in recent years. The required number of observations for\nexact completion is directly proportional to rank and the coherency parameter\nof the matrix. In many applications, there might exist additional information\nabout the low-rank matrix of interest. For example, in collaborative filtering,\nNetflix and dynamic channel estimation in communications, extra subspace\ninformation is available. More precisely in these applications, there are prior\nsubspaces forming multiple angles with the ground-truth subspaces. In this\npaper, we propose a novel strategy to incorporate this information into the\ncompletion task. To this end, we designed a multi-weight nuclear norm\nminimization where the weights are such chosen to penalize each angle within\nthe matrix subspace independently. We propose a new scheme for optimally\nchoosing the weights. Specifically, we first calculate an upper-bound\nexpression describing the coherency of the interested matrix. Then, we obtain\nthe optimal weights by minimizing this expression. Simulation results certify\nthe advantages of allowing multiple weights in the completion procedure.\nExplicitly, they indicate that our proposed multi-weight problem needs fewer\nobservations compared to state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Hamideh.Sadat Fazael Ardakani",
      "Niloufar Rahmani",
      "Sajad Daei"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00235"
  },
  {
    "id": "arXiv:2111.00240",
    "title": "Heuristic and Reinforcement Learning Algorithms for Dynamic Service  Placement on Mobile Edge Cloud",
    "abstract": "Edge computing hosts applications close to the end users and enables\nlow-latency real-time applications. Modern applications inturn have adopted the\nmicroservices architecture which composes applications as loosely coupled\nsmaller components, or services. This complements edge computing infrastructure\nthat are often resource constrained and may not handle monolithic applications.\nInstead, edge servers can independently deploy application service components,\nalthough at the cost of communication overheads. Consistently meeting\napplication service level objectives while also optimizing application\ndeployment (placement and migration of services) cost and communication\noverheads in mobile edge cloud environment is non-trivial. In this paper we\npropose and evaluate three dynamic placement strategies, two heuristic (greedy\napproximation based on set cover, and integer programming based optimization)\nand one learning-based algorithm. Their goal is to satisfy the application\nconstraints, minimize infrastructure deployment cost, while ensuring\navailability of services to all clients and User Equipment (UE) in the network\ncoverage area. The algorithms can be extended to any network topology and\nmicroservice based edge computing applications. For the experiments, we use the\ndrone swarm navigation as a representative application for edge computing use\ncases. Since access to real-world physical testbed for such application is\ndifficult, we demonstrate the efficacy of our algorithms as a simulation. We\nalso contrast these algorithms with respect to placement quality, utilization\nof clusters, and level of determinism. Our evaluation not only shows that the\nlearning-based algorithm provides solutions of better quality; it also provides\ninteresting conclusions regarding when the (more traditional) heuristic\nalgorithms are actually better suited.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Dhruv Garg",
      "Nanjangud C. Narendra",
      "Selome Tesfatsion"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.00240"
  },
  {
    "id": "arXiv:2111.00243",
    "title": "The CAT SET on the MAT: Cross Attention for Set Matching in Bipartite  Hypergraphs",
    "abstract": "Usual relations between entities could be captured using graphs; but those of\na higher-order -- more so between two different types of entities (which we\nterm \"left\" and \"right\") -- calls for a \"bipartite hypergraph\". For example,\ngiven a left set of symptoms and right set of diseases, the relation between a\nset subset of symptoms (that a patient experiences at a given point of time)\nand a subset of diseases (that he/she might be diagnosed with) could be\nwell-represented using a bipartite hyperedge. The state-of-the-art in embedding\nnodes of a hypergraph is based on learning the self-attention structure between\nnode-pairs from a hyperedge. In the present work, given a bipartite hypergraph,\nwe aim at capturing relations between node pairs from the cross-product between\nthe left and right hyperedges, and term it a \"cross-attention\" (CAT) based\nmodel. More precisely, we pose \"bipartite hyperedge link prediction\" as a\nset-matching (SETMAT) problem and propose a novel neural network architecture\ncalled CATSETMAT for the same. We perform extensive experiments on multiple\nbipartite hypergraph datasets to show the superior performance of CATSETMAT,\nwhich we compare with multiple techniques from the state-of-the-art. Our\nresults also elucidate information flow in self- and cross-attention scenarios.",
    "descriptor": "\nComments: 18 pages, 9 figures, under review\n",
    "authors": [
      "Govind Sharma",
      "Swyam Prakash Singh",
      "V. Susheela Devi",
      "M. Narasimha Murty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.00243"
  },
  {
    "id": "arXiv:2111.00247",
    "title": "Utility-driven Mining of Contiguous Sequences",
    "abstract": "Recently, contiguous sequential pattern mining (CSPM) gained interest as a\nresearch topic, due to its varied potential real-world applications, such as\nweb log and biological sequence analysis. To date, studies on the CSPM problem\nremain in preliminary stages. Existing CSPM algorithms lack the efficiency to\nsatisfy users' needs and can still be improved in terms of runtime and memory\nconsumption. In addition, existing algorithms were developed to deal with\nsimple sequence data, working with only one event at a time. Complex sequence\ndata, which represent multiple events occurring simultaneously, are also\ncommonly observed in real life. In this paper, we propose a novel algorithm,\nfast utility-driven contiguous sequential pattern mining (FUCPM), to address\nthe CSPM problem. FUCPM adopts a compact sequence information list and instance\nchain structures to store the necessary information of the database and\ncandidate patterns. For further efficiency, we develop the global unpromising\nitems pruning and local unpromising items pruning strategies, based on\nsequence-weighted utilization and item-extension utilization, to reduce the\nsearch space. Extensive experiments on real-world and synthetic datasets\ndemonstrate that FUCPM outperforms the state-of-the-art algorithms and is\nscalable enough to handle complex sequence data.",
    "descriptor": "\nComments: Preprint. 8 figures, 6 tables\n",
    "authors": [
      "Chunkai Zhang",
      "Quanjian Dai",
      "Zilin Du",
      "Wensheng Gan",
      "Jian Weng",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.00247"
  },
  {
    "id": "arXiv:2111.00254",
    "title": "Equinox: neural networks in JAX via callable PyTrees and filtered  transformations",
    "abstract": "JAX and PyTorch are two popular Python autodifferentiation frameworks. JAX is\nbased around pure functions and functional programming. PyTorch has popularised\nthe use of an object-oriented (OO) class-based syntax for defining\nparameterised functions, such as neural networks. That this seems like a\nfundamental difference means current libraries for building parameterised\nfunctions in JAX have either rejected the OO approach entirely (Stax) or have\nintroduced OO-to-functional transformations, multiple new abstractions, and\nbeen limited in the extent to which they integrate with JAX (Flax, Haiku,\nObjax). Either way this OO/functional difference has been a source of tension.\nHere, we introduce `Equinox', a small neural network library showing how a\nPyTorch-like class-based approach may be admitted without sacrificing JAX-like\nfunctional programming. We provide two main ideas. One: parameterised functions\nare themselves represented as `PyTrees', which means that the parameterisation\nof a function is transparent to the JAX framework. Two: we filter a PyTree to\nisolate just those components that should be treated when transforming (`jit',\n`grad' or `vmap'-ing) a higher-order function of a parameterised function --\nsuch as a loss function applied to a model. Overall Equinox resolves the above\ntension without introducing any new programmatic abstractions: only PyTrees and\ntransformations, just as with regular JAX. Equinox is available at\n\\url{https://github.com/patrick-kidger/equinox}.",
    "descriptor": "\nComments: Accepted at the Differentiable Programming workshop at NeurIPS 2021\n",
    "authors": [
      "Patrick Kidger",
      "Cristian Garcia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.00254"
  },
  {
    "id": "arXiv:2111.00256",
    "title": "Love tHy Neighbour: Remeasuring Local Structural Node Similarity in  Hypergraph-Derived Networks",
    "abstract": "The problem of node-similarity in networks has motivated a plethora of such\nmeasures between node-pairs, which make use of the underlying graph structure.\nHowever, higher-order relations cannot be losslessly captured by mere graphs\nand hence, extensions thereof viz. hypergraphs are used instead. Measuring\nproximity between node pairs in such a setting calls for a revision in the\ntopological measures of similarity, lest the hypergraph structure remains\nunder-exploited. We, in this work, propose a multitude of hypergraph-oriented\nsimilarity scores between node-pairs, thereby providing novel solutions to the\nlink prediction problem. As a part of our proposition, we provide theoretical\nformulations to extend graph-topology based scores to hypergraphs. We compare\nour scores with graph-based scores (over clique-expansions of hypergraphs into\ngraphs) from the state-of-the-art. Using a combination of the existing\ngraph-based and the proposed hypergraph-based similarity scores as features for\na classifier predicts links much better than using the former solely.\nExperiments on several real-world datasets and both quantitative as well as\nqualitative analyses on the same exhibit the superiority of the proposed\nsimilarity scores over the existing ones.",
    "descriptor": "\nComments: 15 pages, 2 figures, 9 tables, under review\n",
    "authors": [
      "Govind Sharma",
      "Paarth Gupta",
      "M. Narasihma Murty"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00256"
  },
  {
    "id": "arXiv:2111.00259",
    "title": "Counting and Verifying Abelian Border Arrays of Binary Words",
    "abstract": "In this note, we consider the problem of counting and verifying abelian\nborder arrays of binary words. We show that the number of valid abelian border\narrays of length \\(n\\) is \\(2^{n-1}\\). We also show that verifying whether a\ngiven array is the abelian border array of some binary word reduces to\ncomputing the abelian border array of a specific binary word. Thus, assuming\nthe word-RAM model, we present an \\(O\\left(\\frac{n^2}{\\log^2n}\\right)\\) time\nalgorithm for the abelian border array verification problem.",
    "descriptor": "",
    "authors": [
      "Mursalin Habib",
      "Md. Salman Shamil",
      "M. Sohel Rahman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.00259"
  },
  {
    "id": "arXiv:2111.00260",
    "title": "A Machine Learning approach to enhance the SUPG stabilization method for  advection-dominated differential problems",
    "abstract": "We propose using Machine Learning and Artificial Neural Networks (ANN) to\nenhance residual-based stabilization methods for advection-dominated\ndifferential problems. Specifically, in the context of the Finite Element\nmethod, we consider the Streamline Upwind Petrov-Galerkin (SUPG) stabilization\nmethod and we employ ANN to optimally choose the stabilization parameter on\nwhich the method relies. We generate our dataset by solving optimization\nproblems to find the optimal stabilization parameters that minimize the\ndistances among the numerical and the exact solutions for different data of\ndifferential problem and the numerical settings of the Finite Element method,\ne.g. mesh size and polynomial degree. The dataset generated is used to train\nthe ANN, and we used the latter \"online\" to predict the optimal stabilization\nparameter to be used in the SUPG method for any given numerical setting and\nproblem data. We show, by means of 1D and 2D numerical tests for the\nadvection-dominated differential problem, that our ANN approach yields more\naccurate solution than using the conventional stabilization parameter for the\nSUPG method.",
    "descriptor": "",
    "authors": [
      "Tommaso Tassi",
      "Alberto Zingaro",
      "Luca Dede'"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00260"
  },
  {
    "id": "arXiv:2111.00261",
    "title": "Explicit and Efficient Construction of (nearly) Optimal Rate Codes for  Binary Deletion Channel and the Poisson Repeat Channel",
    "abstract": "Two of the most common models for channels with synchronisation errors are\nthe Binary Deletion Channel with parameter $p$ ($\\text{BDC}_p$) -- a channel\nwhere every bit of the codeword is deleted i.i.d with probability $p$, and the\nPoisson Repeat Channel with parameter $\\lambda$ ($\\text{PRC}_\\lambda$) -- a\nchannel where every bit of the codeword is repeated $\\text{Poisson}(\\lambda)$\ntimes. Previous codes for these channels can be split into two main categories:\ninefficient constructions that prove the capacities of these channels are\ngreater than $\\frac{1-p}{9}$, $\\frac{\\lambda}{9}$ respectively, and more\nrecently, codes with efficient encoding and decoding algorithms that have lower\nrates $\\frac{1-p}{16}$, $\\frac{\\lambda}{17}$. In this work, we present a new\nmethod for concatenating synchronisation codes. This method can be used to\ntransform lower bounds on the capacities of these channels into efficient\nconstructions, at a negligible cost to the rate of the code. This yields a\nfamily of codes with quasi-linear encoding and decoding algorithms that achieve\nrates of $\\frac{1-p}{9}, \\frac{\\lambda}{9}$ respectively for these channels.",
    "descriptor": "",
    "authors": [
      "Ittai Rubinstein"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00261"
  },
  {
    "id": "arXiv:2111.00262",
    "title": "Learning Coordinated Terrain-Adaptive Locomotion by Imitating a  Centroidal Dynamics Planner",
    "abstract": "Dynamic quadruped locomotion over challenging terrains with precise foot\nplacements is a hard problem for both optimal control methods and Reinforcement\nLearning (RL). Non-linear solvers can produce coordinated constraint satisfying\nmotions, but often take too long to converge for online application. RL methods\ncan learn dynamic reactive controllers but require carefully tuned shaping\nrewards to produce good gaits and can have trouble discovering precise\ncoordinated movements. Imitation learning circumvents this problem and has been\nused with motion capture data to extract quadruped gaits for flat terrains.\nHowever, it would be costly to acquire motion capture data for a very large\nvariety of terrains with height differences. In this work, we combine the\nadvantages of trajectory optimization and learning methods and show that\nterrain adaptive controllers can be obtained by training policies to imitate\ntrajectories that have been planned over procedural terrains by a non-linear\nsolver. We show that the learned policies transfer to unseen terrains and can\nbe fine-tuned to dynamically traverse challenging terrains that require precise\nfoot placements and are very hard to solve with standard RL.",
    "descriptor": "\nComments: A shorter version without appendix was submitted to ICRA 2022\n",
    "authors": [
      "Philemon Brakel",
      "Steven Bohez",
      "Leonard Hasenclever",
      "Nicolas Heess",
      "Konstantinos Bousmalis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00262"
  },
  {
    "id": "arXiv:2111.00264",
    "title": "A Quasi-Newton method for physically-admissible simulation of Poiseuille  flow under fracture propagation",
    "abstract": "Coupled hydro-mechanical processes are of great importance to numerous\nengineering systems, e.g., hydraulic fracturing, geothermal energy, and carbon\nsequestration. Fluid flow in fractures is modeled after a Poiseuille law that\nrelates the conductivity to the aperture by a cubic relation. Newton's method\nis commonly employed to solve the resulting discrete, nonlinear algebraic\nsystems. It is demonstrated, however, that Newton's method will likely converge\nto nonphysical numerical solutions, resulting in estimates with a negative\nfracture aperture. A Quasi-Newton approach is developed to ensure global\nconvergence to the physical solution. A fixed-point stability analysis\ndemonstrates that both physical and nonphysical solutions are stable for\nNewton's method, whereas only physical solutions are stable for the proposed\nQuasi-Newton method. Additionally, it is also demonstrated that the\nQuasi-Newton method offers a contraction mapping along the iteration path.\nNumerical examples of fluid-driven fracture propagation demonstrate that the\nproposed solution method results in robust and computationally efficient\nperformance.",
    "descriptor": "",
    "authors": [
      "Guotong Ren",
      "Rami M. Younis"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.00264"
  },
  {
    "id": "arXiv:2111.00271",
    "title": "Higher-Order Relations Skew Link Prediction in Graphs",
    "abstract": "The problem of link prediction is of active interest. The main approach to\nsolving the link prediction problem is based on heuristics such as Common\nNeighbors (CN) -- more number of common neighbors of a pair of nodes implies a\nhigher chance of them getting linked. In this article, we investigate this\nproblem in the presence of higher-order relations. Surprisingly, it is found\nthat CN works very well, and even better in the presence of higher-order\nrelations. However, as we prove in the current work, this is due to the\nCN-heuristic overestimating its prediction abilities in the presence of\nhigher-order relations. This statement is proved by considering a theoretical\nmodel for higher-order relations and by showing that AUC scores of CN are\nhigher than can be achieved from the model. Theoretical justification in simple\ncases is also provided. Further, we extend our observations to other similar\nlink prediction algorithms such as Adamic Adar. Finally, these insights are\nused to propose an adjustment factor by taking into conscience that a random\ngraph would only have a best AUC score of 0.5. This adjustment factor allows\nfor a better estimation of generalization scores.",
    "descriptor": "\nComments: 12 pages, 1 table, 5 figures, under review\n",
    "authors": [
      "Govind Sharma",
      "Aditya Challa",
      "Paarth Gupta",
      "M. Narasimha Murty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.00271"
  },
  {
    "id": "arXiv:2111.00272",
    "title": "A Framework for Transforming Specifications in Reinforcement Learning",
    "abstract": "Reactive synthesis algorithms allow automatic construction of policies to\ncontrol an environment modeled as a Markov Decision Process (MDP) that are\noptimal with respect to high-level temporal logic specifications assuming the\nMDP model is known a priori. Reinforcement learning algorithms, in contrast,\nare designed to learn an optimal policy when the transition probabilities of\nthe MDP are unknown, but require the user to associate local rewards with\ntransitions. The appeal of high-level temporal logic specifications has\nmotivated research to develop RL algorithms for synthesis of policies from\nspecifications. To understand the techniques, and nuanced variations in their\ntheoretical guarantees, in the growing body of resulting literature, we develop\na formal framework for defining transformations among RL tasks with different\nforms of objectives. We define the notion of sampling-based reduction to relate\ntwo MDPs whose transition probabilities can be learnt by sampling, followed by\nformalization of preservation of optimal policies, convergence, and robustness.\nWe then use our framework to restate known results, establish new results to\nfill in some gaps, and identify open problems.",
    "descriptor": "",
    "authors": [
      "Rajeev Alur",
      "Suguman Bansal",
      "Osbert Bastani",
      "Kishor Jothimurugan"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.00272"
  },
  {
    "id": "arXiv:2111.00276",
    "title": "EventNarrative: A large-scale Event-centric Dataset for Knowledge  Graph-to-Text Generation",
    "abstract": "We introduce EventNarrative, a knowledge graph-to-text dataset from publicly\navailable open-world knowledge graphs. Given the recent advances in\nevent-driven Information Extraction (IE), and that prior research on\ngraph-to-text only focused on entity-driven KGs, this paper focuses on\nevent-centric data. However, our data generation system can still be adapted to\nother other types of KG data. Existing large-scale datasets in the\ngraph-to-text area are non-parallel, meaning there is a large disconnect\nbetween the KGs and text. The datasets that have a paired KG and text, are\nsmall scale and manually generated or generated without a rich ontology, making\nthe corresponding graphs sparse. Furthermore, these datasets contain many\nunlinked entities between their KG and text pairs. EventNarrative consists of\napproximately 230,000 graphs and their corresponding natural language text, 6\ntimes larger than the current largest parallel dataset. It makes use of a rich\nontology, all of the KGs entities are linked to the text, and our manual\nannotations confirm a high data quality. Our aim is two-fold: help break new\nground in event-centric research where data is lacking, and to give researchers\na well-defined, large-scale dataset in order to better evaluate existing and\nfuture knowledge graph-to-text models. We also evaluate two types of baseline\non EventNarrative: a graph-to-text specific model and two state-of-the-art\nlanguage models, which previous work has shown to be adaptable to the knowledge\ngraph-to-text domain.",
    "descriptor": "",
    "authors": [
      "Anthony Colas",
      "Ali Sadeghian",
      "Yue Wang",
      "Daisy Zhe Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00276"
  },
  {
    "id": "arXiv:2111.00278",
    "title": "A Decentralized Reinforcement Learning Framework for Efficient Passage  of Emergency Vehicles",
    "abstract": "Emergency vehicles (EMVs) play a critical role in a city's response to\ntime-critical events such as medical emergencies and fire outbreaks. The\nexisting approaches to reduce EMV travel time employ route optimization and\ntraffic signal pre-emption without accounting for the coupling between route\nthese two subproblems. As a result, the planned route often becomes suboptimal.\nIn addition, these approaches also do not focus on minimizing disruption to the\noverall traffic flow. To address these issues, we introduce EMVLight in this\npaper. This is a decentralized reinforcement learning (RL) framework for\nsimultaneous dynamic routing and traffic signal control. EMVLight extends\nDijkstra's algorithm to efficiently update the optimal route for an EMV in\nreal-time as it travels through the traffic network. Consequently, the\ndecentralized RL agents learn network-level cooperative traffic signal phase\nstrategies that reduce EMV travel time and the average travel time of non-EMVs\nin the network. We have carried out comprehensive experiments with synthetic\nand real-world maps to demonstrate this benefit. Our results show that EMVLight\noutperforms benchmark transportation engineering techniques as well as existing\nRL-based traffic signal control methods.",
    "descriptor": "\nComments: Artificial Intelligence and Humanitarian Assistance and Disaster Recovery (AI + HADR) workshop, NeurIPS 2021. arXiv admin note: substantial text overlap with arXiv:2109.05429\n",
    "authors": [
      "Haoran Su",
      "Yaofeng Desmond Zhong",
      "Dey Biswadip",
      "Amit Chakraborty"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00278"
  },
  {
    "id": "arXiv:2111.00282",
    "title": "Twin-width VI: the lens of contraction sequences",
    "abstract": "A contraction sequence of a graph consists of iteratively merging two of its\nvertices until only one vertex remains. The recently introduced twin-width\ngraph invariant is based on contraction sequences. More precisely, if one puts\nred edges between two vertices representing non-homogeneous subsets, the\ntwin-width is the minimum integer $d$ such that a contraction sequence keeps\nred degree at most $d$. By changing the condition imposed on the trigraphs\n(i.e., graphs with some edges being red) and possibly slightly tweaking the\nnotion of contractions, we show how to characterize the well-established\nbounded rank-width, tree-width, linear rank-width, path-width, and proper\nminor-closed classes by means of contraction sequences. As an application we\ngive a transparent alternative proof of the celebrated Courcelle's theorem\n(actually of its generalization by Courcelle, Makowsky, and Rotics), that\nMSO$_2$ (resp. MSO$_1$) model checking on graphs with bounded tree-width (resp.\nbounded rank-width) is fixed-parameter tractable in the size of the input\nsentence.\nWe then explore new avenues along the general theme of contraction sequences\nboth in order to refine the landscape between bounded tree-width and bounded\ntwin-width (via spanning twin-width) and to capture more general classes than\nbounded twin-width. To this end, we define an oriented version of twin-width,\nwhere appearing red edges are oriented away from the newly contracted vertex,\nand the mere red out-degree should remain bounded. Surprisingly, classes of\nbounded oriented twin-width coincide with those of bounded twin-width. Finally\nwe examine, from an algorithmic standpoint, the concept of partial contraction\nsequences, where, instead of terminating on a single-vertex graph, the sequence\nends when reaching a particular target class.",
    "descriptor": "\nComments: 27 pages, 2 figures\n",
    "authors": [
      "\u00c9douard Bonnet",
      "Eun Jung Kim",
      "Amadeus Reinald",
      "St\u00e9phan Thomass\u00e9"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.00282"
  },
  {
    "id": "arXiv:2111.00289",
    "title": "Intrusion Prevention through Optimal Stopping",
    "abstract": "We study automated intrusion prevention using reinforcement learning.\nFollowing a novel approach, we formulate the problem of intrusion prevention as\nan (optimal) multiple stopping problem. This formulation gives us insight into\nthe structure of optimal policies, which we show to have threshold properties.\nFor most practical cases, it is not feasible to obtain an optimal defender\npolicy using dynamic programming. We therefore develop a reinforcement learning\napproach to approximate an optimal policy. Our method for learning and\nvalidating policies includes two systems: a simulation system where defender\npolicies are incrementally learned and an emulation system where statistics are\nproduced that drive simulation runs and where learned policies are evaluated.\nWe show that our approach can produce effective defender policies for a\npractical IT infrastructure of limited size. Inspection of the learned policies\nconfirms that they exhibit threshold properties.",
    "descriptor": "\nComments: Preprint; Submitted to IEEE for review. arXiv admin note: substantial text overlap with arXiv:2106.07160\n",
    "authors": [
      "Kim Hammar",
      "Rolf Stadler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.00289"
  },
  {
    "id": "arXiv:2111.00293",
    "title": "Long-Range Route-planning for Autonomous Vehicles in the Polar Oceans",
    "abstract": "There is an increasing demand for piloted autonomous underwater vehicles\n(AUVs) to operate in polar ice conditions. At present, AUVs are deployed from\nships and directly human-piloted in these regions, entailing a high carbon cost\nand limiting the scope of operations. A key requirement for long-term\nautonomous missions is a long-range route planning capability that is aware of\nthe changing ice conditions. In this paper we address the problem of automating\nlong-range route-planning for AUVs operating in the Southern Ocean. We present\nthe route-planning method and results showing that efficient, ice-avoiding,\nlong-distance traverses can be planned.",
    "descriptor": "\nComments: Submitted to the AMS Journal of Atmospheric and Oceanic Technology\n",
    "authors": [
      "Maria Fox",
      "Michael Meredith",
      "J. Alexander Brearley",
      "Dan Jones",
      "Derek Long"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00293"
  },
  {
    "id": "arXiv:2111.00295",
    "title": "Get Fooled for the Right Reason: Improving Adversarial Robustness  through a Teacher-guided Curriculum Learning Approach",
    "abstract": "Current SOTA adversarially robust models are mostly based on adversarial\ntraining (AT) and differ only by some regularizers either at inner maximization\nor outer minimization steps. Being repetitive in nature during the inner\nmaximization step, they take a huge time to train. We propose a non-iterative\nmethod that enforces the following ideas during training. Attribution maps are\nmore aligned to the actual object in the image for adversarially robust models\ncompared to naturally trained models. Also, the allowed set of pixels to\nperturb an image (that changes model decision) should be restricted to the\nobject pixels only, which reduces the attack strength by limiting the attack\nspace. Our method achieves significant performance gains with a little extra\neffort (10-20%) over existing AT models and outperforms all other methods in\nterms of adversarial as well as natural accuracy. We have performed extensive\nexperimentation with CIFAR-10, CIFAR-100, and TinyImageNet datasets and\nreported results against many popular strong adversarial attacks to prove the\neffectiveness of our method.",
    "descriptor": "\nComments: 16 pages, 9 figures, Accepted at NeurIPS 2021, Code at this https URL\n",
    "authors": [
      "Anindya Sarkar",
      "Anirban Sarkar",
      "Sowrya Gali",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00295"
  },
  {
    "id": "arXiv:2111.00298",
    "title": "A fast accurate fine-grain object detection model based on YOLOv4 deep  neural network",
    "abstract": "Early identification and prevention of various plant diseases in commercial\nfarms and orchards is a key feature of precision agriculture technology. This\npaper presents a high-performance real-time fine-grain object detection\nframework that addresses several obstacles in plant disease detection that\nhinder the performance of traditional methods, such as, dense distribution,\nirregular morphology, multi-scale object classes, textural similarity, etc. The\nproposed model is built on an improved version of the You Only Look Once\n(YOLOv4) algorithm. The modified network architecture maximizes both detection\naccuracy and speed by including the DenseNet in the back-bone to optimize\nfeature transfer and reuse, two new residual blocks in the backbone and neck\nenhance feature extraction and reduce computing cost; the Spatial Pyramid\nPooling (SPP) enhances receptive field, and a modified Path Aggregation Network\n(PANet) preserves fine-grain localized information and improve feature fusion.\nAdditionally, the use of the Hard-Swish function as the primary activation\nimproved the model's accuracy due to better nonlinear feature extraction. The\nproposed model is tested in detecting four different diseases in tomato plants\nunder various challenging environments. The model outperforms the existing\nstate-of-the-art detection models in detection accuracy and speed. At a\ndetection rate of 70.19 FPS, the proposed model obtained a precision value of\n$90.33 \\%$, F1-score of $93.64 \\%$, and a mean average precision ($mAP$) value\nof $96.29 \\%$. Current work provides an effective and efficient method for\ndetecting different plant diseases in complex scenarios that can be extended to\ndifferent fruit and crop detection, generic disease detection, and various\nautomated agricultural detection processes.",
    "descriptor": "",
    "authors": [
      "Arunabha M. Roy",
      "Rikhi Bose",
      "Jayabrata Bhaduri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00298"
  },
  {
    "id": "arXiv:2111.00299",
    "title": "Throughput and Latency in the Distributed Q-Learning Random Access mMTC  Networks",
    "abstract": "In mMTC mode, with thousands of devices trying to access network resources\nsporadically, the problem of random access (RA) and collisions between devices\nthat select the same resources becomes crucial. A promising approach to solve\nsuch an RA problem is to use learning mechanisms, especially the Q-learning\nalgorithm, where the devices learn about the best time-slot periods to transmit\nthrough rewards sent by the central node. In this work, we propose a\ndistributed packet-based learning method by varying the reward from the central\nnode that favors devices having a larger number of remaining packets to\ntransmit. Our numerical results indicated that the proposed distributed\npacket-based Q-learning method attains a much better throughput-latency\ntrade-off than the alternative independent and collaborative techniques in\npractical scenarios of interest. In contrast, the number of payload bits of the\npacket-based technique is reduced regarding the collaborative Q-learning RA\ntechnique for achieving the same normalized throughput.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Giovanni Maciel Ferreira Silva",
      "Taufik Abrao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00299"
  },
  {
    "id": "arXiv:2111.00303",
    "title": "Optimizing Binary Symptom Checkers via Approximate Message Passing",
    "abstract": "Symptom checkers have been widely adopted as an intelligent e-healthcare\napplication during the ongoing pandemic crisis. Their performance have been\nlimited by the fine-grained quality of the collected medical knowledge between\nsymptom and diseases. While the binarization of the relationships between\nsymptoms and diseases simplifies the data collection process, it also leads to\nnon-convex optimization problems during the inference step. In this paper, we\nformulate the symptom checking problem as an underdertermined non-convex\noptimization problem, thereby justifying the use of the compressive sensing\nframework to solve it. We show that the generalized vector approximate message\npassing (G-VAMP) algorithm provides the best performance for binary symptom\ncheckers.",
    "descriptor": "",
    "authors": [
      "Mohamed Akrout",
      "Faouzi Bellili",
      "Amine Mezghani",
      "Hayet Amdouni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00303"
  },
  {
    "id": "arXiv:2111.00307",
    "title": "FUIM: Fuzzy Utility Itemset Mining",
    "abstract": "Because of usefulness and comprehensibility, fuzzy data mining has been\nextensively studied and is an emerging topic in recent years. Compared with\nutility-driven itemset mining technologies, fuzzy utility mining not only takes\nutilities (e.g., profits) into account, but also considers quantities of items\nin each transaction for discovering high fuzzy utility itemsets (HFUIs). Thus,\nfuzziness can be regard as a key criterion to select high-utility itemsets,\nwhile the exiting algorithms are not efficient enough. In this paper, an\nefficient one-phase algorithm named Fuzzy-driven Utility Itemset Miner (FUIM)\nis proposed to find out a complete set of HFUIs effectively. In addition, a\nnovel compact data structure named fuzzy-list keeps the key information from\nquantitative transaction databases. Using fuzzy-list, FUIM can discover HFUIs\nfrom transaction databases efficiently and effectively. Both completeness and\ncorrectness of the FUIM algorithm are proved by five theorems. At last,\nsubstantial experiments test three terms (runtime cost, memory consumption, and\nscalability) to confirm that FUIM considerably outperforms the state-of-the-art\nalgorithms.",
    "descriptor": "\nComments: Preprint. 10 figures, 6 tables\n",
    "authors": [
      "Shicheng Wan",
      "Wensheng Gan",
      "Xu Guo",
      "Jiahui Chen",
      "Unil Yun"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.00307"
  },
  {
    "id": "arXiv:2111.00308",
    "title": "Mobile Technologies in Education",
    "abstract": "The growth of smartphone users globally is a factor that educational\ntechnologists should not ignore. This ever-growing market will eventually lead\nto ubiquitous learning (u-learning). The development of specific content should\nbe replaced by the design of content in languages that are compatible with\nscalable technologies and that will reach the hands of students in the future\nin an attractive way.",
    "descriptor": "\nComments: in Spanish. II International Congress of Emergen Technologies in Education 2014. Universidad Da Vinci\n",
    "authors": [
      "Daniel Serna-Poot"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.00308"
  },
  {
    "id": "arXiv:2111.00309",
    "title": "TargetUM: Targeted High-Utility Itemset Querying",
    "abstract": "Traditional high-utility itemset mining (HUIM) aims to determine all\nhigh-utility itemsets (HUIs) that satisfy the minimum utility threshold\n(\\textit{minUtil}) in transaction databases. However, in most applications, not\nall HUIs are interesting because only specific parts are required. Thus,\ntargeted mining based on user preferences is more important than traditional\nmining tasks. This paper is the first to propose a target-based HUIM problem\nand to provide a clear formulation of the targeted utility mining task in a\nquantitative transaction database. A tree-based algorithm known as Target-based\nhigh-Utility iteMset querying using (TargetUM) is proposed. The algorithm uses\na lexicographic querying tree and three effective pruning strategies to improve\nthe mining efficiency. We implemented experimental validation on several real\nand synthetic databases, and the results demonstrate that the performance of\n\\textbf{TargetUM} is satisfactory, complete, and correct. Finally, owing to the\nlexicographic querying tree, the database no longer needs to be scanned\nrepeatedly for multiple queries.",
    "descriptor": "\nComments: Preprint. 7 figures, 9 tables\n",
    "authors": [
      "Jinbao Miao",
      "Shicheng Wan",
      "Wensheng Gan",
      "Jiayi Sun",
      "Jiahui Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00309"
  },
  {
    "id": "arXiv:2111.00310",
    "title": "EmpBot: A T5-based Empathetic Chatbot focusing on Sentiments",
    "abstract": "In this paper, we introduce EmpBot: an end-to-end empathetic chatbot.\nEmpathetic conversational agents should not only understand what is being\ndiscussed, but also acknowledge the implied feelings of the conversation\npartner and respond appropriately. To this end, we propose a method based on a\ntransformer pretrained language model (T5). Specifically, during finetuning we\npropose to use three objectives: response language modeling, sentiment\nunderstanding, and empathy forcing. The first objective is crucial for\ngenerating relevant and coherent responses, while the next ones are significant\nfor acknowledging the sentimental state of the conversational partner and for\nfavoring empathetic responses. We evaluate our model on the EmpatheticDialogues\ndataset using both automated metrics and human evaluation. The inclusion of the\nsentiment understanding and empathy forcing auxiliary losses favor empathetic\nresponses, as human evaluation results indicate, comparing with the current\nstate-of-the-art.",
    "descriptor": "",
    "authors": [
      "Emmanouil Zaranis",
      "Georgios Paraskevopoulos",
      "Athanasios Katsamanis",
      "Alexandros Potamianos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00310"
  },
  {
    "id": "arXiv:2111.00312",
    "title": "3DP3: 3D Scene Perception via Probabilistic Programming",
    "abstract": "We present 3DP3, a framework for inverse graphics that uses inference in a\nstructured generative model of objects, scenes, and images. 3DP3 uses (i) voxel\nmodels to represent the 3D shape of objects, (ii) hierarchical scene graphs to\ndecompose scenes into objects and the contacts between them, and (iii) depth\nimage likelihoods based on real-time graphics. Given an observed RGB-D image,\n3DP3's inference algorithm infers the underlying latent 3D scene, including the\nobject poses and a parsimonious joint parametrization of these poses, using\nfast bottom-up pose proposals, novel involutive MCMC updates of the scene graph\nstructure, and, optionally, neural object detectors and pose estimators. We\nshow that 3DP3 enables scene understanding that is aware of 3D shape,\nocclusion, and contact structure. Our results demonstrate that 3DP3 is more\naccurate at 6DoF object pose estimation from real images than deep learning\nbaselines and shows better generalization to challenging scenes with novel\nviewpoints, contact, and partial observability.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Nishad Gothoskar",
      "Marco Cusumano-Towner",
      "Ben Zinberg",
      "Matin Ghavamizadeh",
      "Falk Pollok",
      "Austin Garrett",
      "Joshua B. Tenenbaum",
      "Dan Gutfreund",
      "Vikash K. Mansinghka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00312"
  },
  {
    "id": "arXiv:2111.00314",
    "title": "ECG synthesis with Neural ODE and GAN models",
    "abstract": "Continuous medical time series data such as ECG is one of the most complex\ntime series due to its dynamic and high dimensional characteristics. In\naddition, due to its sensitive nature, privacy concerns and legal restrictions,\nit is often even complex to use actual data for different medical research. As\na result, generating continuous medical time series is a very critical research\narea. Several research works already showed that the ability of generative\nadversarial networks (GANs) in the case of continuous medical time series\ngeneration is promising. Most medical data generation works, such as ECG\nsynthesis, are mainly driven by the GAN model and its variation. On the other\nhand, Some recent work on Neural Ordinary Differential Equation (Neural ODE)\ndemonstrates its strength against informative missingness, high dimension as\nwell as dynamic nature of continuous time series. Instead of considering\ncontinuous-time series as a discrete-time sequence, Neural ODE can train\ncontinuous time series in real-time continuously. In this work, we used Neural\nODE based model to generate synthetic sine waves and synthetic ECG. We\nintroduced a new technique to design the generative adversarial network with\nNeural ODE based Generator and Discriminator. We developed three new models to\nsynthesise continuous medical data. Different evaluation metrics are then used\nto quantitatively assess the quality of generated synthetic data for real-world\napplications and data analysis. Another goal of this work is to combine the\nstrength of GAN and Neural ODE to generate synthetic continuous medical time\nseries data such as ECG. We also evaluated both the GAN model and the Neural\nODE model to understand the comparative efficiency of models from the GAN and\nNeural ODE family in medical data synthesis.",
    "descriptor": "\nComments: Proc. of the International Conference on Electrical, Computer and Energy Technologies (ICECET), 9-10 December 2021, Cape Town-South Africa\n",
    "authors": [
      "Mansura Habiba",
      "Eoin Borphy",
      "Barak A. Pearlmutter",
      "Tomas Ward"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00314"
  },
  {
    "id": "arXiv:2111.00324",
    "title": "Property-Directed Reachability as Abstract Interpretation in the  Monotone Theory",
    "abstract": "Inferring inductive invariants is one of the main challenges of formal\nverification. The theory of abstract interpretation provides a rich framework\nto devise invariant inference algorithms. One of the latest breakthroughs in\ninvariant inference is property-directed reachability (PDR), but the research\ncommunity views PDR and abstract interpretation as mostly unrelated techniques.\nThis paper shows that, surprisingly, propositional PDR can be formulated as\nan abstract interpretation algorithm in a logical domain. More precisely, we\ndefine a version of PDR, called $\\Lambda$-PDR, in which all generalizations of\ncounterexamples are used to strengthen a frame. In this way, there is no need\nto refine frames after their creation, because all the possible supporting\nfacts are included in advance. We analyze this algorithm using notions from\nBshouty's monotone theory, originally developed in the context of exact\nlearning. We show that there is an inherent overapproximation between the\nalgorithm's frames that is related to the monotone theory. We then define a new\nabstract domain in which the best abstract transformer performs this\noverapproximation, and show that it captures the invariant inference process,\ni.e., $\\Lambda$-PDR corresponds to Kleene iterations with the best transformer\nin this abstract domain. We provide some sufficient conditions for when this\nprocess converges in a small number of iterations, with sometimes an\nexponential gap from the number of iterations required for naive exact forward\nreachability. These results provide a firm theoretical foundation for the\nbenefits of how PDR tackles forward reachability.",
    "descriptor": "\nComments: Extended version of a POPL'22 paper\n",
    "authors": [
      "Yotam M. Y. Feldman",
      "Mooly Sagiv",
      "Sharon Shoham",
      "James R. Wilcox"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.00324"
  },
  {
    "id": "arXiv:2111.00326",
    "title": "Neural Network based on Automatic Differentiation Transformation of  Numeric Iterate-to-Fixedpoint",
    "abstract": "This work proposes a Neural Network model that can control its depth using an\niterate-to-fixed-point operator. The architecture starts with a standard\nlayered Network but with added connections from current later to earlier\nlayers, along with a gate to make them inactive under most circumstances. These\n``temporal wormhole'' connections create a shortcut that allows the Neural\nNetwork to use the information available at deeper layers and re-do earlier\ncomputations with modulated inputs. End-to-end training is accomplished by\nusing appropriate calculations for a numeric iterate-to-fixed-point operator.\nIn a typical case, where the ``wormhole'' connections are inactive, this is\ninexpensive; but when they are active, the network takes a longer time to\nsettle down, and the gradient calculation is also more laborious, with an\neffect similar to making the network deeper. In contrast to the existing\nskip-connection concept, this proposed technique enables information to flow up\nand down in the network. Furthermore, the flow of information follows a fashion\nthat seems analogous to the afferent and efferent flow of information through\nlayers of processing in the brain. We evaluate models that use this novel\nmechanism on different long-term dependency tasks. The results are competitive\nwith other studies, showing that the proposed model contributes significantly\nto overcoming traditional deep learning models' vanishing gradient descent\nproblem. At the same time, the training time is significantly reduced, as the\n``easy'' input cases are processed more quickly than ``difficult'' ones.",
    "descriptor": "\nComments: Proc. of the International Conference on Electrical, Computer and Energy Technologies (ICECET)\n",
    "authors": [
      "Mansura Habiba",
      "Barak A. Pearlmutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00326"
  },
  {
    "id": "arXiv:2111.00327",
    "title": "Beyond Independent Measurements: General Compressed Sensing with GNN  Application",
    "abstract": "We consider the problem of recovering a structured signal $\\mathbf{x} \\in\n\\mathbb{R}^{n}$ from noisy linear observations $\\mathbf{y} =\\mathbf{M}\n\\mathbf{x}+\\mathbf{w}$. The measurement matrix is modeled as $\\mathbf{M} =\n\\mathbf{B}\\mathbf{A}$, where $\\mathbf{B} \\in \\mathbb{R}^{l \\times m}$ is\narbitrary and $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ has independent\nsub-gaussian rows. By varying $\\mathbf{B}$, and the sub-gaussian distribution\nof $\\mathbf{A}$, this gives a family of measurement matrices which may have\nheavy tails, dependent rows and columns, and singular values with a large\ndynamic range. When the structure is given as a possibly non-convex cone $T\n\\subset \\mathbb{R}^{n}$, an approximate empirical risk minimizer is proven to\nbe a robust estimator if the effective number of measurements is sufficient,\neven in the presence of a model mismatch. In classical compressed sensing with\nindependent (sub-)gaussian measurements, one asks how many measurements are\nneeded to recover $\\mathbf{x}$? In our setting, however, the effective number\nof measurements depends on the properties of $\\mathbf{B}$. We show that the\neffective rank of $\\mathbf{B}$ may be used as a surrogate for the number of\nmeasurements, and if this exceeds the squared Gaussian mean width of $(T-T)\n\\cap \\mathbb{S}^{n-1}$, then accurate recovery is guaranteed. Furthermore, we\nexamine the special case of generative priors in detail, that is when\n$\\mathbf{x}$ lies close to $T = \\mathrm{ran}(G)$ and $G: \\mathbb{R}^k\n\\rightarrow \\mathbb{R}^n$ is a Generative Neural Network (GNN) with ReLU\nactivation functions. Our work relies on a recent result in random matrix\ntheory by Jeong, Li, Plan, and Yilmaz arXiv:2001.10631. .",
    "descriptor": "",
    "authors": [
      "Alireza Naderi",
      "Yaniv Plan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00327"
  },
  {
    "id": "arXiv:2111.00339",
    "title": "Constraint-Aware Trajectory for Drone Delivery Services",
    "abstract": "Drones are becoming a novel means for delivery services. We present a\ndemonstration of drone delivery services in a skyway network that uses the\nservice paradigm. A set of experiments is conducted using Crazyflie drones to\ncollect the data on various positions of drones, wind speed, wind direction,\nand battery consumption. We run the experiments for a range of flight patterns\nincluding linear, rectangular, and triangular shapes.",
    "descriptor": "\nComments: 4 pages, 13 figures. This is an accepted paper and it is going to be published in the Proceedings of 19th International Conference on Service Oriented Computing (ICSOC 2021)\n",
    "authors": [
      "Jermaine Janszen",
      "Babar Shahzaad",
      "Balsam Alkouz",
      "Athman Bouguettaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00339"
  },
  {
    "id": "arXiv:2111.00340",
    "title": "Identifying and mitigating bias in algorithms used to manage patients in  a pandemic",
    "abstract": "Numerous COVID-19 clinical decision support systems have been developed.\nHowever many of these systems do not have the merit for validity due to\nmethodological shortcomings including algorithmic bias. Methods Logistic\nregression models were created to predict COVID-19 mortality, ventilator status\nand inpatient status using a real-world dataset consisting of four hospitals in\nNew York City and analyzed for biases against race, gender and age. Simple\nthresholding adjustments were applied in the training process to establish more\nequitable models. Results Compared to the naively trained models, the\ncalibrated models showed a 57% decrease in the number of biased trials, while\npredictive performance, measured by area under the receiver/operating curve\n(AUC), remained unchanged. After calibration, the average sensitivity of the\npredictive models increased from 0.527 to 0.955. Conclusion We demonstrate that\nnaively training and deploying machine learning models on real world data for\npredictive analytics of COVID-19 has a high risk of bias. Simple implemented\nadjustments or calibrations during model training can lead to substantial and\nsustained gains in fairness on subsequent deployment.",
    "descriptor": "\nComments: 4 pages, 1 tables\n",
    "authors": [
      "Yifan Li",
      "Garrett Yoon",
      "Mustafa Nasir-Moin",
      "David Rosenberg",
      "Sean Neifert",
      "Douglas Kondziolka",
      "Eric Karl Oermann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.00340"
  },
  {
    "id": "arXiv:2111.00341",
    "title": "Causal Discovery in Linear Structural Causal Models with Deterministic  Relations",
    "abstract": "Linear structural causal models (SCMs) -- in which each observed variable is\ngenerated by a subset of the other observed variables as well as a subset of\nthe exogenous sources -- are pervasive in causal inference and casual\ndiscovery. However, for the task of causal discovery, existing work almost\nexclusively focus on the submodel where each observed variable is associated\nwith a distinct source with non-zero variance. This results in the restriction\nthat no observed variable can deterministically depend on other observed\nvariables or latent confounders. In this paper, we extend the results on\nstructure learning by focusing on a subclass of linear SCMs which do not have\nthis property, i.e., models in which observed variables can be causally\naffected by any subset of the sources, and are allowed to be a deterministic\nfunction of other observed variables or latent confounders. This allows for a\nmore realistic modeling of influence or information propagation in systems. We\nfocus on the task of causal discovery form observational data generated from a\nmember of this subclass. We derive a set of necessary and sufficient conditions\nfor unique identifiability of the causal structure. To the best of our\nknowledge, this is the first work that gives identifiability results for causal\ndiscovery under both latent confounding and deterministic relationships.\nFurther, we propose an algorithm for recovering the underlying causal structure\nwhen the aforementioned conditions are satisfied. We validate our theoretical\nresults both on synthetic and real datasets.",
    "descriptor": "",
    "authors": [
      "Yuqin Yang",
      "Mohamed Nafea",
      "AmirEmad Ghassami",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00341"
  },
  {
    "id": "arXiv:2111.00343",
    "title": "Continuous Convolutional Neural Networks: Coupled Neural PDE and ODE",
    "abstract": "Recent work in deep learning focuses on solving physical systems in the\nOrdinary Differential Equation or Partial Differential Equation. This current\nwork proposed a variant of Convolutional Neural Networks (CNNs) that can learn\nthe hidden dynamics of a physical system using ordinary differential equation\n(ODEs) systems (ODEs) and Partial Differential Equation systems (PDEs). Instead\nof considering the physical system such as image, time -series as a system of\nmultiple layers, this new technique can model a system in the form of\nDifferential Equation (DEs). The proposed method has been assessed by solving\nseveral steady-state PDEs on irregular domains, including heat equations,\nNavier-Stokes equations.",
    "descriptor": "\nComments: Proc. of the International Conference on Electrical, Computer and Energy Technologies (ICECET)\n",
    "authors": [
      "Mansura Habiba",
      "Barak A. Pearlmutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00343"
  },
  {
    "id": "arXiv:2111.00344",
    "title": "Convergence and Semi-convergence of a class of constrained block  iterative methods",
    "abstract": "In this paper, we analyze the convergence %semi-convergence properties of\nprojected non-stationary block iterative methods (P-BIM) aiming to find a\nconstrained solution to large linear, usually both noisy and ill-conditioned,\nsystems of equations. We split the error of the $k$th iterate into noise error\nand iteration error, and consider each error separately. The iteration error is\ntreated for a more general algorithm, also suited for solving split feasibility\nproblems in Hilbert space. The results for P-BIM come out as a special case.\nThe algorithmic step involves projecting onto closed convex sets. When these\nsets are polyhedral, and of finite dimension, it is shown that the algorithm\nconverges linearly. We further derive an upper bound for the noise error of\nP-BIM. Based on this bound, we suggest a new strategy for choosing relaxation\nparameters, which assist in speeding up the reconstruction process and\nimproving the quality of obtained images. The relaxation parameters may depend\non the noise. The performance of the suggested strategy is shown by examples\ntaken from the field of image reconstruction from projections.",
    "descriptor": "",
    "authors": [
      "Mahdi Mirzapour",
      "Andrzej Cegielski",
      "Tommy Elfving"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00344"
  },
  {
    "id": "arXiv:2111.00345",
    "title": "Multi-Agent Advisor Q-Learning",
    "abstract": "In the last decade, there have been significant advances in multi-agent\nreinforcement learning (MARL) but there are still numerous challenges, such as\nhigh sample complexity and slow convergence to stable policies, that need to be\novercome before wide-spread deployment is possible. However, many real-world\nenvironments already, in practice, deploy sub-optimal or heuristic approaches\nfor generating policies. An interesting question which arises is how to best\nuse such approaches as advisors to help improve reinforcement learning in\nmulti-agent domains. In this paper, we provide a principled framework for\nincorporating action recommendations from online sub-optimal advisors in\nmulti-agent settings. We describe the problem of ADvising Multiple Intelligent\nReinforcement Agents (ADMIRAL) in nonrestrictive general-sum stochastic game\nenvironments and present two novel Q-learning based algorithms: ADMIRAL -\nDecision Making (ADMIRAL-DM) and ADMIRAL - Advisor Evaluation (ADMIRAL-AE),\nwhich allow us to improve learning by appropriately incorporating advice from\nan advisor (ADMIRAL-DM), and evaluate the effectiveness of an advisor\n(ADMIRAL-AE). We analyze the algorithms theoretically and provide fixed-point\nguarantees regarding their learning in general-sum stochastic games.\nFurthermore, extensive experiments illustrate that these algorithms: can be\nused in a variety of environments, have performances that compare favourably to\nother related baselines, can scale to large state-action spaces, and are robust\nto poor advice from advisors.",
    "descriptor": "",
    "authors": [
      "Sriram Ganapathi Subramanian",
      "Matthew E. Taylor",
      "Kate Larson",
      "Mark Crowley"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.00345"
  },
  {
    "id": "arXiv:2111.00350",
    "title": "AdvCodeMix: Adversarial Attack on Code-Mixed Data",
    "abstract": "Research on adversarial attacks are becoming widely popular in the recent\nyears. One of the unexplored areas where prior research is lacking is the\neffect of adversarial attacks on code-mixed data. Therefore, in the present\nwork, we have explained the first generalized framework on text perturbation to\nattack code-mixed classification models in a black-box setting. We rely on\nvarious perturbation techniques that preserve the semantic structures of the\nsentences and also obscure the attacks from the perception of a human user. The\npresent methodology leverages the importance of a token to decide where to\nattack by employing various perturbation strategies. We test our strategies on\nvarious sentiment classification models trained on Bengali-English and\nHindi-English code-mixed datasets, and reduce their F1-scores by nearly 51 %\nand 53 % respectively, which can be further reduced if a larger number of\ntokens are perturbed in a given sentence.",
    "descriptor": "\nComments: Accepted to CODS-COMAD 2022\n",
    "authors": [
      "Sourya Dipta Das",
      "Ayan Basak",
      "Soumil Mandal",
      "Dipankar Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00350"
  },
  {
    "id": "arXiv:2111.00352",
    "title": "Optimizing Sparse Matrix Multiplications for Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) are emerging as a powerful technique for\nmodeling graph structures. Due to the sparsity of real-world graph data, GNN\nperformance is limited by extensive sparse matrix multiplication (SpMM)\noperations involved in computation. While the right sparse matrix storage\nformat varies across input data, existing deep learning frameworks employ a\nsingle, static storage format, leaving much room for improvement. This paper\ninvestigates how the choice of sparse matrix storage formats affect the GNN\nperformance. We observe that choosing a suitable sparse matrix storage format\ncan significantly improve the GNN training performance, but the right format\ndepends on the input workloads and can change as the GNN iterates over the\ninput graph. We then develop a predictive model to dynamically choose a sparse\nmatrix storage format to be used by a GNN layer based on the input matrices.\nOur model is first trained offline using training matrix samples, and the\ntrained model can be applied to any input matrix and GNN kernels with SpMM\ncomputation. We implement our approach on top of PyTorch and apply it to 5\nrepresentative GNN models running on a multi-core CPU using real-life and\nsynthetic datasets. Experimental results show that our approach gives an\naverage speedup of 1.17x (up to 3x) for GNN running time.",
    "descriptor": "",
    "authors": [
      "Shenghao Qiu",
      "You Liang",
      "Zheng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00352"
  },
  {
    "id": "arXiv:2111.00358",
    "title": "A Survey on the Robustness of Feature Importance and Counterfactual  Explanations",
    "abstract": "There exist several methods that aim to address the crucial task of\nunderstanding the behaviour of AI/ML models. Arguably, the most popular among\nthem are local explanations that focus on investigating model behaviour for\nindividual instances. Several methods have been proposed for local analysis,\nbut relatively lesser effort has gone into understanding if the explanations\nare robust and accurately reflect the behaviour of underlying models. In this\nwork, we present a survey of the works that analysed the robustness of two\nclasses of local explanations (feature importance and counterfactual\nexplanations) that are popularly used in analysing AI/ML models in finance. The\nsurvey aims to unify existing definitions of robustness, introduces a taxonomy\nto classify different robustness approaches, and discusses some interesting\nresults. Finally, the survey introduces some pointers about extending current\nrobustness analysis approaches so as to identify reliable explainability\nmethods.",
    "descriptor": "\nComments: 4 pages plus references. Accepted at the workshop on Explainable AI in Finance (XAI-FIN21). Camera-ready version\n",
    "authors": [
      "Saumitra Mishra",
      "Sanghamitra Dutta",
      "Jason Long",
      "Daniele Magazzeni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00358"
  },
  {
    "id": "arXiv:2111.00360",
    "title": "Identifying Functions and Behaviours of Social Robots during Learning  Activities: Teachers' Perspective",
    "abstract": "With advances in artificial intelligence, research is increasingly exploring\nthe potential functions that social robots can play in education. As teachers\nare a critical stakeholder in the use and application of educational\ntechnologies, we conducted a study to understand teachers' perspectives on how\na social robot could support a variety of learning activities in the classroom.\nThrough interviews, robot puppeteering, and group brainstorming sessions with\nfive elementary and middle school teachers from a local school in Canada, we\ntake a socio-technical perspective to conceptualize possible robot functions\nand behaviours, and the effects they may have on the current way learning\nactivities are designed, planned, and executed. Overall, the teachers responded\npositively to the idea of introducing a social robot as a technological tool\nfor learning activities, envisioning differences in usage for teacher-robot and\nstudent-robot interactions. Further, Engestr\\\"om's Activity System Model -- a\nframework for analyzing human needs, tasks, and outcomes -- illustrated a\nnumber of tensions associated with learning activities in the classroom. We\ndiscuss the fine-grained robot functions and behaviours conceived by teachers,\nand how they address the current tensions -- providing suggestions for\nimproving the design of social robots for learning activities.",
    "descriptor": "\nComments: This is a preprint of an article published in The International Journal of Social Robotics. The final authenticated version is available online at: this https URL\n",
    "authors": [
      "Jessy Ceha",
      "Edith Law",
      "Dana Kuli\u0107",
      "Pierre-Yves Oudeyer",
      "Didier Roy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.00360"
  },
  {
    "id": "arXiv:2111.00364",
    "title": "Sustainable AI: Environmental Implications, Challenges and Opportunities",
    "abstract": "This paper explores the environmental impact of the super-linear growth\ntrends for AI from a holistic perspective, spanning Data, Algorithms, and\nSystem Hardware. We characterize the carbon footprint of AI computing by\nexamining the model development cycle across industry-scale machine learning\nuse cases and, at the same time, considering the life cycle of system hardware.\nTaking a step further, we capture the operational and manufacturing carbon\nfootprint of AI computing and present an end-to-end analysis for what and how\nhardware-software design and at-scale optimization can help reduce the overall\ncarbon footprint of AI. Based on the industry experience and lessons learned,\nwe share the key challenges and chart out important development directions\nacross the many dimensions of AI. We hope the key messages and insights\npresented in this paper can inspire the community to advance the field of AI in\nan environmentally-responsible manner.",
    "descriptor": "",
    "authors": [
      "Carole-Jean Wu",
      "Ramya Raghavendra",
      "Udit Gupta",
      "Bilge Acun",
      "Newsha Ardalani",
      "Kiwan Maeng",
      "Gloria Chang",
      "Fiona Aga Behram",
      "James Huang",
      "Charles Bai",
      "Michael Gschwind",
      "Anurag Gupta",
      "Myle Ott",
      "Anastasia Melnikov",
      "Salvatore Candido",
      "David Brooks",
      "Geeta Chauhan",
      "Benjamin Lee",
      "Hsien-Hsin S. Lee",
      "Bugra Akyildiz",
      "Maximilian Balandat",
      "Joe Spisak",
      "Ravi Jain",
      "Mike Rabbat",
      "Kim Hazelwood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.00364"
  },
  {
    "id": "arXiv:2111.00375",
    "title": "Conical Classification For Computationally Efficient One-Class Topic  Determination",
    "abstract": "As the Internet grows in size, so does the amount of text based information\nthat exists. For many application spaces it is paramount to isolate and\nidentify texts that relate to a particular topic. While one-class\nclassification would be ideal for such analysis, there is a relative lack of\nresearch regarding efficient approaches with high predictive power. By noting\nthat the range of documents we wish to identify can be represented as positive\nlinear combinations of the Vector Space Model representing our text, we propose\nConical classification, an approach that allows us to identify if a document is\nof a particular topic in a computationally efficient manner. We also propose\nNormal Exclusion, a modified version of Bi-Normal Separation that makes it more\nsuitable within the one-class classification context. We show in our analysis\nthat our approach not only has higher predictive power on our datasets, but is\nalso faster to compute.",
    "descriptor": "\nComments: Findings in Empirical Methods in Natural Language Processing 2021\n",
    "authors": [
      "Sameer Khanna"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00375"
  },
  {
    "id": "arXiv:2111.00376",
    "title": "Computing Matching Statistics on Repetitive Texts",
    "abstract": "Computing the {\\em matching statistics} of a string $P[1..m]$ with respect to\na text $T[1..n]$ is a fundamental problem which has application to genome\nsequence comparison. In this paper, we study the problem of computing the\nmatching statistics upon highly repetitive texts. We design three different\ndata structures that are similar to LZ-compressed indexes. The space costs of\nall of them can be measured by $\\gamma$, the size of the smallest string\nattractor [STOC'2018] and $\\delta$, a better measure of repetitiveness\n[LATIN'2020].",
    "descriptor": "",
    "authors": [
      "Younan Gao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.00376"
  },
  {
    "id": "arXiv:2111.00379",
    "title": "EfficientWord-Net: An Open Source Hotword Detection Engine based on  One-shot Learning",
    "abstract": "Voice assistants like Siri, Google Assistant, Alexa etc. are used widely\nacross the globe for home automation, these require the use of special phrases\nalso known as hotwords to wake it up and perform an action like \"Hey Alexa!\",\n\"Ok Google!\" and \"Hey Siri!\" etc. These hotwords are detected with lightweight\nreal-time engines whose purpose is to detect the hotwords uttered by the user.\nThis paper presents the design and implementation of a hotword detection engine\nbased on one-shot learning which detects the hotword uttered by the user in\nreal-time with just one or few training samples of the hotword. This approach\nis efficient when compared to existing implementations because the process of\nadding a new hotword in the existing systems requires enormous amounts of\npositive and negative training samples and the model needs to retrain for every\nhotword. This makes the existing implementations inefficient in terms of\ncomputation and cost. The architecture proposed in this paper has achieved an\naccuracy of 94.51%.",
    "descriptor": "",
    "authors": [
      "Chidhambararajan R",
      "Aman Rangaur",
      "Sibi Chakkaravarthy Sethuraman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.00379"
  },
  {
    "id": "arXiv:2111.00382",
    "title": "A Novel Linear Power Flow Model",
    "abstract": "Linear power flow (LPF) models are important for the solution of large-scale\nproblems in power system analysis. This paper proposes a novel LPF method named\ndata-based LPF (DB-LPF). The DB-LPF is distinct from the data-driven LPF\n(DD-LPF) model because the DB-LPF formulates the definition set first and then\ndiscretizes the set into representative data samples, while the DD-LPF directly\nmines the variable mappings from historical or measurement data. In this paper,\nthe concept of LPF definition set (i.e., the set where the LPF performs well)\nis proposed and an analytical algorithm is provided to get the set. Meanwhile,\na novel form of AC-PF models is provided, which is helpful in deriving the\nanalytical algorithm and directing the formulations of LPF models. The\ndefinition set is discretized by a grid sampling approach and the obtained\nsamples are processed by the least-squares method to formulate the DB-LPF\nmodel. Moreover, the model for obtaining the error bound of the DB-LPF is\nproposed, and the network losses of the DB-LPF is also analyzed. Finally, the\nDB-LPF model is tested on enormous cases, whose branch parameters are also\nanal-yzed. The test results verify the effectiveness and superiority of the\nproposed method.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Zhentong Shao",
      "Qiaozhu Zhai",
      "Xiaohong Guan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00382"
  },
  {
    "id": "arXiv:2111.00383",
    "title": "Relevant Region Sampling Strategy with Adaptive Heuristic Estimation for  Asymptotically Optimal Motion Planning",
    "abstract": "The sampling-based motion planning algorithms can solve the motion planning\nproblem in high-dimensional state space efficiently. This article presents a\nnovel approach to sample in the promising region and reduce planning time\nremarkably. The RRT# defines the Relevant Region according to the cost-to-come\nprovided by the optimal forward-searching tree; however, it takes the\ncumulative cost of a direct connection between the current state and the goal\nstate as the cost-to-go. We propose a batch sampling method that samples in the\nrefined Relevant Region, which is defined according to the optimal cost-to-come\nand the adaptive cost-to-go. In our method, the cost-to-come and the cost-to-go\nof a specific vertex are estimated by the valid optimal forward-searching tree\nand the lazy reverse-searching tree, respectively. New samples are generated\nwith a direct sampling method, which can take advantage of the heuristic\nestimation result. We carry on several simulations in both SE(2) and SE(3)\nstate spaces to validate the effectiveness of our method. Simulation results\ndemonstrate that the proposed algorithm can find a better initial solution and\nconsumes less planning time than related work.",
    "descriptor": "",
    "authors": [
      "Chenming Li",
      "Fei Meng",
      "Han Ma",
      "Jiankun Wang",
      "Max Q.-H. Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00383"
  },
  {
    "id": "arXiv:2111.00384",
    "title": "A Design and an Implementation of an Inverse Kinematics Computation in  Robotics Using Real Quantifier Elimination based on Comprehensive Gr\u00f6bner  Systems",
    "abstract": "The solution and implementation of the inverse kinematics computation of a\nthree degree-of-freedom (DOF) robot manipulator using an algorithm for real\nquantifier elimination with Comprehensive Gr\\\"obner Systems (CGS) are\npresented. The method enables us to verify if the given parameters are feasible\nbefore solving the inverse kinematics problem. Furthermore, pre-computation of\nCGS and substituting parameters in the CGS with the given values avoids the\nrepetitive computation of Gr\\\"obner basis. Experimental results compared with\nour previous implementation are shown.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Shuto Otaki",
      "Akira Terui",
      "Masahiko Mikawa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Symbolic Computation (cs.SC)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2111.00384"
  },
  {
    "id": "arXiv:2111.00396",
    "title": "Efficiently Modeling Long Sequences with Structured State Spaces",
    "abstract": "A central goal of sequence modeling is designing a single principled model\nthat can address sequence data across a range of modalities and tasks,\nparticularly on long-range dependencies. Although conventional models including\nRNNs, CNNs, and Transformers have specialized variants for capturing long\ndependencies, they still struggle to scale to very long sequences of $10000$ or\nmore steps. A promising recent approach proposed modeling sequences by\nsimulating the fundamental state space model (SSM) \\( x'(t) = Ax(t) + Bu(t),\ny(t) = Cx(t) + Du(t) \\), and showed that for appropriate choices of the state\nmatrix \\( A \\), this system could handle long-range dependencies mathematically\nand empirically. However, this method has prohibitive computation and memory\nrequirements, rendering it infeasible as a general sequence modeling solution.\nWe propose the Structured State Space (S4) sequence model based on a new\nparameterization for the SSM, and show that it can be computed much more\nefficiently than prior approaches while preserving their theoretical strengths.\nOur technique involves conditioning \\( A \\) with a low-rank correction,\nallowing it to be diagonalized stably and reducing the SSM to the well-studied\ncomputation of a Cauchy kernel. S4 achieves strong empirical results across a\ndiverse range of established benchmarks, including (i) 91\\% accuracy on\nsequential CIFAR-10 with no data augmentation or auxiliary losses, on par with\na larger 2-D ResNet, (ii) substantially closing the gap to Transformers on\nimage and language modeling tasks, while performing generation $60\\times$\nfaster (iii) SoTA on every task from the Long Range Arena benchmark, including\nsolving the challenging Path-X task of length 16k that all prior work fails on,\nwhile being as efficient as all competitors.",
    "descriptor": "",
    "authors": [
      "Albert Gu",
      "Karan Goel",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00396"
  },
  {
    "id": "arXiv:2111.00397",
    "title": "Optimizing Secure Decision Tree Inference Outsourcing",
    "abstract": "Outsourcing decision tree inference services to the cloud is highly\nbeneficial, yet raises critical privacy concerns on the proprietary decision\ntree of the model provider and the private input data of the client. In this\npaper, we design, implement, and evaluate a new system that allows highly\nefficient outsourcing of decision tree inference. Our system significantly\nimproves upon the state-of-the-art in the overall online end-to-end secure\ninference service latency at the cloud as well as the local-side performance of\nthe model provider. We first presents a new scheme which securely shifts most\nof the processing of the model provider to the cloud, resulting in a\nsubstantial reduction on the model provider's performance complexities. We\nfurther devise a scheme which substantially optimizes the performance for\nencrypted decision tree inference at the cloud, particularly the communication\nround complexities. The synergy of these techniques allows our new system to\nachieve up to $8 \\times$ better overall online end-to-end secure inference\nlatency at the cloud side over realistic WAN environment, as well as bring the\nmodel provider up to $19 \\times$ savings in communication and $18 \\times$\nsavings in computation.",
    "descriptor": "\nComments: under review by a journal\n",
    "authors": [
      "Yifeng Zheng",
      "Cong Wang",
      "Ruochen Wang",
      "Huayi Duan",
      "Surya Nepal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00397"
  },
  {
    "id": "arXiv:2111.00398",
    "title": "A Simple Approach to Image Tilt Correction with Self-Attention MobileNet  for Smartphones",
    "abstract": "The main contributions of our work are two-fold. First, we present a\nSelf-Attention MobileNet, called SA-MobileNet Network that can model long-range\ndependencies between the image features instead of processing the local region\nas done by standard convolutional kernels. SA-MobileNet contains self-attention\nmodules integrated with the inverted bottleneck blocks of the MobileNetV3 model\nwhich results in modeling of both channel-wise attention and spatial attention\nof the image features and at the same time introduce a novel self-attention\narchitecture for low-resource devices. Secondly, we propose a novel training\npipeline for the task of image tilt detection. We treat this problem in a\nmulti-label scenario where we predict multiple angles for a tilted input image\nin a narrow interval of range 1-2 degrees, depending on the dataset used. This\nprocess induces an implicit correlation between labels without any\ncomputational overhead of the second or higher-order methods in multi-label\nlearning. With the combination of our novel approach and the architecture, we\npresent state-of-the-art results on detecting the image tilt angle on mobile\ndevices as compared to the MobileNetV3 model. Finally, we establish that\nSA-MobileNet is more accurate than MobileNetV3 on SUN397, NYU-V1, and ADE20K\ndatasets by 6.42%, 10.51%, and 9.09% points respectively, and faster by at\nleast 4 milliseconds on Snapdragon 750 Octa-core.",
    "descriptor": "\nComments: Accepted - British Machine vision Conference 2021\n",
    "authors": [
      "Siddhant Garg",
      "Debi Prasanna Mohanty",
      "Siva Prasad Thota",
      "Sukumar Moharana"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00398"
  },
  {
    "id": "arXiv:2111.00400",
    "title": "FANS: Fusing ASR and NLU for on-device SLU",
    "abstract": "Spoken language understanding (SLU) systems translate voice input commands to\nsemantics which are encoded as an intent and pairs of slot tags and values.\nMost current SLU systems deploy a cascade of two neural models where the first\none maps the input audio to a transcript (ASR) and the second predicts the\nintent and slots from the transcript (NLU). In this paper, we introduce FANS, a\nnew end-to-end SLU model that fuses an ASR audio encoder to a multi-task NLU\ndecoder to infer the intent, slot tags, and slot values directly from a given\ninput audio, obviating the need for transcription. FANS consists of a shared\naudio encoder and three decoders, two of which are seq-to-seq decoders that\npredict non null slot tags and slot values in parallel and in an\nauto-regressive manner. FANS neural encoder and decoders architectures are\nflexible which allows us to leverage different combinations of LSTM,\nself-attention, and attenders. Our experiments show compared to the\nstate-of-the-art end-to-end SLU models, FANS reduces ICER and IRER errors\nrelatively by 30 % and 7 %, respectively, when tested on an in-house SLU\ndataset and by 0.86 % and 2 % absolute when tested on a public SLU dataset.",
    "descriptor": "\nComments: Published in Interspeech 2021\n",
    "authors": [
      "Martin Radfar",
      "Athanasios Mouchtaris",
      "Siegfried Kunzmann",
      "Ariya Rastrow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.00400"
  },
  {
    "id": "arXiv:2111.00401",
    "title": "On multiple IoT data streams processing using LoRaWAN",
    "abstract": "LoraWAN has turned out to be one of the most successful frameworks in IoT\ndevices. Real world scenarios demand the use of such networks along with a\nrobust stream processing application layer. To maintain the exactly once\nprocessing semantics one must ensure that we have proper ways to proactively\ndetect message drops and handle the same. An important use case where stream\nprocessing plays a crucial role is joining various data streams that are\ntransmitted via gateways connected to edge devices which are related to each\nother as part of some common business requirement. LoraWAN supports\nconnectivity to multiple gateways for edge devices and by virtue of its\ndifferent device classes, the network can send and receive messages in an\neffective way that conserves battery power as well as network bandwidth. Rather\nthan relying on explicit acknowledgements for the transmitted messages we take\nthe advantage of these characteristics of the devices to detect , handle\nmissing messages and finally process them.",
    "descriptor": "",
    "authors": [
      "Kunal Chowdhury"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.00401"
  },
  {
    "id": "arXiv:2111.00404",
    "title": "Speech Emotion Recognition Using Quaternion Convolutional Neural  Networks",
    "abstract": "Although speech recognition has become a widespread technology, inferring\nemotion from speech signals still remains a challenge. To address this problem,\nthis paper proposes a quaternion convolutional neural network (QCNN) based\nspeech emotion recognition (SER) model in which Mel-spectrogram features of\nspeech signals are encoded in an RGB quaternion domain. We show that our QCNN\nbased SER model outperforms other real-valued methods in the Ryerson\nAudio-Visual Database of Emotional Speech and Song (RAVDESS, 8-classes)\ndataset, achieving, to the best of our knowledge, state-of-the-art results. The\nQCNN also achieves comparable results with the state-of-the-art methods in the\nInteractive Emotional Dyadic Motion Capture (IEMOCAP 4-classes) and Berlin\nEMO-DB (7-classes) datasets. Specifically, the model achieves an accuracy of\n77.87\\%, 70.46\\%, and 88.78\\% for the RAVDESS, IEMOCAP, and EMO-DB datasets,\nrespectively. In addition, our results show that the quaternion unit structure\nis better able to encode internal dependencies to reduce its model size\nsignificantly compared to other methods.",
    "descriptor": "\nComments: Published in ICASSP 2021\n",
    "authors": [
      "Aneesh Muppidi",
      "Martin Radfar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.00404"
  },
  {
    "id": "arXiv:2111.00406",
    "title": "PANet: Perspective-Aware Network with Dynamic Receptive Fields and  Self-Distilling Supervision for Crowd Counting",
    "abstract": "Crowd counting aims to learn the crowd density distributions and estimate the\nnumber of objects (e.g. persons) in images. The perspective effect, which\nsignificantly influences the distribution of data points, plays an important\nrole in crowd counting. In this paper, we propose a novel perspective-aware\napproach called PANet to address the perspective problem. Based on the\nobservation that the size of the objects varies greatly in one image due to the\nperspective effect, we propose the dynamic receptive fields (DRF) framework.\nThe framework is able to adjust the receptive field by the dilated convolution\nparameters according to the input image, which helps the model to extract more\ndiscriminative features for each local region. Different from most previous\nworks which use Gaussian kernels to generate the density map as the supervised\ninformation, we propose the self-distilling supervision (SDS) training method.\nThe ground-truth density maps are refined from the first training stage and the\nperspective information is distilled to the model in the second stage. The\nexperimental results on ShanghaiTech Part_A and Part_B, UCF_QNRF, and UCF_CC_50\ndatasets demonstrate that our proposed PANet outperforms the state-of-the-art\nmethods by a large margin.",
    "descriptor": "",
    "authors": [
      "Xiaoshuang Chen",
      "Yiru Zhao",
      "Yu Qin",
      "Fei Jiang",
      "Mingyuan Tao",
      "Xiansheng Hua",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00406"
  },
  {
    "id": "arXiv:2111.00407",
    "title": "Regularized Identification with Internal Positivity Side-Information",
    "abstract": "In this paper, we present an impulse response identification scheme that\nincorporates the internal positivity side-information of the system. The\nrealization theory of positive systems establishes specific criteria for the\nexistence of a positive realization for a given transfer function. These\ntransfer function criteria are translated to a set of suitable conditions on\nthe shape and structure of the impulse responses of positive systems. Utilizing\nthese conditions, the impulse response estimation problem is formulated as a\nconstrained optimization in a reproducing kernel Hilbert space equipped with a\nstable kernel, and suitable constraints are imposed to encode the internal\npositivity side-information. The optimization problem is infinite-dimensional\nwith an infinite number of constraints. An equivalent finite-dimensional convex\noptimization in the form of a convex quadratic program is derived. The\nresulting equivalent reformulation makes the proposed approach suitable for\nnumerical simulation and practical implementation. A Monte Carlo numerical\nexperiment evaluates the impact of incorporating the internal positivity\nside-information in the proposed identification scheme. The effectiveness of\nthe proposed method is demonstrated using data from a heating system\nexperiment.",
    "descriptor": "",
    "authors": [
      "Mohammad Khosravi",
      "Roy S. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00407"
  },
  {
    "id": "arXiv:2111.00409",
    "title": "Kernel-based Impulse Response Identification with Side-Information on  Steady-State Gain",
    "abstract": "In this paper, we consider the problem of system identification when\nside-information is available on the steady-state (or DC) gain of the system.\nWe formulate a general nonparametric identification method as an\ninfinite-dimensional constrained convex program over the reproducing kernel\nHilbert space (RKHS) of stable impulse responses. The objective function of\nthis optimization problem is the empirical loss regularized with the norm of\nRKHS, and the constraint is considered for enforcing the integration of the\nsteady-state gain side-information. The proposed formulation addresses both the\ndiscrete-time and continuous-time cases. We show that this program has a unique\nsolution obtained by solving an equivalent finite-dimensional convex\noptimization. This solution has a closed-form when the empirical loss and\nregularization functions are quadratic and exact side-information is\nconsidered. We perform extensive numerical comparisons to verify the efficiency\nof the proposed identification methodology.",
    "descriptor": "",
    "authors": [
      "Mohammad Khosravi",
      "Roy S. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00409"
  },
  {
    "id": "arXiv:2111.00411",
    "title": "Safe Adaptive Learning-based Control for Constrained Linear Quadratic  Regulators with Regret Guarantees",
    "abstract": "We study the adaptive control of an unknown linear system with a quadratic\ncost function subject to safety constraints on both the states and actions. The\nchallenges of this problem arise from the tension among safety, exploration,\nperformance, and computation. To address these challenges, we propose a\npolynomial-time algorithm that guarantees feasibility and constraint\nsatisfaction with high probability under proper conditions. Our algorithm is\nimplemented on a single trajectory and does not require system restarts.\nFurther, we analyze the regret of our learning algorithm compared to the\noptimal safe linear controller with known model information. The proposed\nalgorithm can achieve a $\\tilde O(T^{2/3})$ regret, where $T$ is the number of\nstages and $\\tilde O(\\cdot)$ absorbs some logarithmic terms of $T$.",
    "descriptor": "",
    "authors": [
      "Yingying Li",
      "Subhro Das",
      "Jeff Shamma",
      "Na Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00411"
  },
  {
    "id": "arXiv:2111.00416",
    "title": "How BlockChain Can Help Enhance The Security And Privacy in Edge  Computing?",
    "abstract": "In order to solve security and privacy issues of centralized cloud services,\nthe edge computing network is introduced, where computing and storage resources\nare distributed to the edge of the network. However, native edge computing is\nsubject to the limited performance of edge devices, which causes challenges in\ndata authorization, data encryption, user privacy, and other fields. Blockchain\nis currently the hottest technology for distributed networks. It solves the\nconsistent issue of distributed data and is used in many areas, such as\ncryptocurrency, smart grid, and the Internet of Things.\nOur work discussed the security and privacy challenges of edge computing\nnetworks. From the perspectives of data authorization, encryption, and user\nprivacy, we analyze the solutions brought by blockchain technology to edge\ncomputing networks. In this work, we deeply present the benefits from the\nintegration of the edge computing network and blockchain technology, which\neffectively controls the data authorization and data encryption of the edge\nnetwork and enhances the architecture's scalability under the premise of\nensuring security and privacy. Finally, we investigate challenges on storage,\nworkload, and latency for future research in this field.",
    "descriptor": "",
    "authors": [
      "Jinyue Song",
      "Tianbo Gu",
      "Prasant Mohapatra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.00416"
  },
  {
    "id": "arXiv:2111.00417",
    "title": "Hierarchical Deep Residual Reasoning for Temporal Moment Localization",
    "abstract": "Temporal Moment Localization (TML) in untrimmed videos is a challenging task\nin the field of multimedia, which aims at localizing the start and end points\nof the activity in the video, described by a sentence query. Existing methods\nmainly focus on mining the correlation between video and sentence\nrepresentations or investigating the fusion manner of the two modalities. These\nworks mainly understand the video and sentence coarsely, ignoring the fact that\na sentence can be understood from various semantics, and the dominant words\naffecting the moment localization in the semantics are the action and object\nreference. Toward this end, we propose a Hierarchical Deep Residual Reasoning\n(HDRR) model, which decomposes the video and sentence into multi-level\nrepresentations with different semantics to achieve a finer-grained\nlocalization. Furthermore, considering that videos with different resolution\nand sentences with different length have different difficulty in understanding,\nwe design the simple yet effective Res-BiGRUs for feature fusion, which is able\nto grasp the useful information in a self-adapting manner. Extensive\nexperiments conducted on Charades-STA and ActivityNet-Captions datasets\ndemonstrate the superiority of our HDRR model compared with other\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Ziyang Ma",
      "Xianjing Han",
      "Xuemeng Song",
      "Yiran Cui",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.00417"
  },
  {
    "id": "arXiv:2111.00418",
    "title": "Deep Learning in Human Activity Recognition with Wearable Sensors: A  Review on Advances",
    "abstract": "Mobile and wearable devices have enabled numerous applications, including\nactivity tracking, wellness monitoring, and human-computer interaction, that\nmeasure and improve our daily lives. Many of these applications are made\npossible by leveraging the rich collection of low-power sensors found in many\nmobile and wearable devices to perform human activity recognition (HAR).\nRecently, deep learning has greatly pushed the boundaries of HAR on mobile and\nwearable devices. This paper systematically categorizes and summarizes existing\nwork that introduces deep learning methods for wearables-based HAR and provides\na comprehensive analysis of the current advancements, developing trends, and\nmajor challenges. We also present cutting-edge frontiers and future directions\nfor deep learning--based HAR.",
    "descriptor": "",
    "authors": [
      "Shibo Zhang",
      "Yaxuan Li",
      "Shen Zhang",
      "Farzad Shahabi",
      "Stephen Xia",
      "Yu Deng",
      "Nabil Alshurafa"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.00418"
  },
  {
    "id": "arXiv:2111.00419",
    "title": "Interpreting Deep Knowledge Tracing Model on EdNet Dataset",
    "abstract": "With more deep learning techniques being introduced into the knowledge\ntracing domain, the interpretability issue of the knowledge tracing models has\naroused researchers' attention. Our previous study(Lu et al. 2020) on building\nand interpreting the KT model mainly adopts the ASSISTment dataset(Feng,\nHeffernan, and Koedinger 2009),, whose size is relatively small. In this work,\nwe perform the similar tasks but on a large and newly available dataset, called\nEdNet(Choi et al. 2020). The preliminary experiment results show the\neffectiveness of the interpreting techniques, while more questions and tasks\nare worthy to be further explored and accomplished.",
    "descriptor": "\nComments: This paper has been accepted and presented in AAAI 2021 Workshop on AI Education\n",
    "authors": [
      "Deliang Wang",
      "Yu Lu",
      "Qinggang Meng",
      "Penghe Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00419"
  },
  {
    "id": "arXiv:2111.00422",
    "title": "Shape Programmable Magnetic Pixel Soft Robot",
    "abstract": "Magnetic response soft robot realizes programmable shape regulation with the\nhelp of magnetic field and produces various actions. The shape control of\nmagnetic soft robot is based on the magnetic anisotropy caused by the orderly\ndistribution of magnetic particles in the elastic matrix. In the previous\ntechnologies, magnetic programming is coupled with the manufacturing process,\nand the orientation of magnetic particles cannot be modified, which brings\nrestrictions to the design and use of magnetic soft robot. This paper presents\na magnetic pixel robot with shape programmable function. By encapsulating\nNdFeB/gallium composites into silicone shell, a thermo-magnetic response\nfunctional film with lattice structure are fabricated. Basing on\nthermal-assisted magnetization technique, we realized the discrete\nmagnetization region distribution on the film. Therefore, we proposed a\nmagnetic coding technique to realize the mathematical response action design of\nsoftware robot. Using these methods, we prepared several magnetic soft robots\nbased on origami structure. The experiments show that the behavior mode of\nrobot can be flexibly and repeatedly regulated by magnetic encoding technique.\nThis work provides a basis for the programmed shape regulation and motion\ndesign of soft robot.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Ran Zhao",
      "Hanchen Yao",
      "Houde Dai"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2111.00422"
  },
  {
    "id": "arXiv:2111.00424",
    "title": "Graph Tree Neural Networks",
    "abstract": "Graph neural networks (GNNs) have recently shown good performance in various\nfields. In this paper, we propose graph tree neural networks (GTNNs) designed\nto solve the problems of existing networks by analyzing the structure of human\nneural networks. In GTNNs, information units are related to the form of a graph\nand then they become a bigger unit of information again and have a relationship\nwith other information units. At this point, the unit of information is a set\nof neurons, and we can express it as a vector with GTNN. Defining the starting\nand ending points in a single graph is difficult, and a tree cannot express the\nrelationship among sibling nodes. However, a graph tree can be expressed using\nleaf and root nodes as its starting and ending points and the relationship\namong sibling nodes. Depth-first convolution (DFC) encodes the interaction\nresult from leaf nodes to the root node in a bottom-up approach, and\ndepth-first deconvolution (DFD) decodes the interaction result from the root\nnode to the leaf nodes in a top-down approach. GTNN is data-driven learning in\nwhich the number of convolutions varies according to the depth of the tree.\nMoreover, learning features of different types together is possible.\nSupervised, unsupervised, and semi-supervised learning using graph tree\nrecursive neural network (GTR) , graph tree recursive attention networks\n(GTRAs), and graph tree recursive autoencoders (GTRAEs) are introduced in this\npaper. We experimented with a simple toy test with source code dataset.",
    "descriptor": "\nComments: This paper was submitted as a simple experiment. It has been slightly modified from the original\n",
    "authors": [
      "Seokjun Kim",
      "Jaeeun Jang",
      "Hee-seok Jung",
      "Hyeoncheol Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00424"
  },
  {
    "id": "arXiv:2111.00426",
    "title": "Using Google Trends as a proxy for occupant behavior to predict building  energy consumption",
    "abstract": "In recent years, the availability of larger amounts of energy data and\nadvanced machine learning algorithms has created a surge in building energy\nprediction research. However, one of the variables in energy prediction models,\noccupant behavior, is crucial for prediction performance but hard-to-measure or\ntime-consuming to collect from each building. This study proposes an approach\nthat utilizes the search volume of topics (e.g., education} or Microsoft Excel)\non the Google Trends platform as a proxy of occupant behavior and use of\nbuildings. Linear correlations were first examined to explore the relationship\nbetween energy meter data and Google Trends search terms to infer building\noccupancy. Prediction errors before and after the inclusion of the trends of\nthese terms were compared and analyzed based on the ASHRAE Great Energy\nPredictor III (GEPIII) competition dataset. The results show that highly\ncorrelated Google Trends data can effectively reduce the overall RMSLE error\nfor a subset of the buildings to the level of the GEPIII competition's top five\nwinning teams' performance. In particular, the RMSLE error reduction during\npublic holidays and days with site-specific schedules are respectively reduced\nby 20-30% and 2-5%. These results show the potential of using Google Trends to\nimprove energy prediction for a portion of the building stock by automatically\nidentifying site-specific and holiday schedules.",
    "descriptor": "",
    "authors": [
      "Chun Fu",
      "Clayton Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.00426"
  },
  {
    "id": "arXiv:2111.00429",
    "title": "Enhancing Top-N Item Recommendations by Peer Collaboration",
    "abstract": "Deep neural networks (DNN) have achieved great success in the recommender\nsystems (RS) domain. However, to achieve remarkable performance, DNN-based\nrecommender models often require numerous parameters, which inevitably bring\nredundant neurons and weights, a phenomenon referred to as\nover-parameterization. In this paper, we plan to exploit such redundancy\nphenomena to improve the performance of RS. Specifically, we propose PCRec, a\ntop-N item \\underline{rec}ommendation framework that leverages collaborative\ntraining of two DNN-based recommender models with the same network structure,\ntermed \\underline{p}eer \\underline{c}ollaboration. PCRec can reactivate and\nstrengthen the unimportant (redundant) weights during training, which achieves\nhigher prediction accuracy but maintains its original inference efficiency. To\nrealize this, we first introduce two criteria to identify the importance of\nweights of a given recommender model. Then, we rejuvenate the unimportant\nweights by transplanting outside information (i.e., weights) from its peer\nnetwork. After such an operation and retraining, the original recommender model\nis endowed with more representation capacity by possessing more functional\nmodel parameters. To show its generality, we instantiate PCRec by using three\nwell-known recommender models. We conduct extensive experiments on three\nreal-world datasets, and show that PCRec yields significantly better\nrecommendations than its counterpart with the same model (parameter) size.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Yang Sun",
      "Fajie Yuan",
      "Min Yang",
      "Alexandros Karatzoglou",
      "Shen Li",
      "Xiaoyan Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.00429"
  },
  {
    "id": "arXiv:2111.00430",
    "title": "Efficient passive membership inference attack in federated learning",
    "abstract": "In cross-device federated learning (FL) setting, clients such as mobiles\ncooperate with the server to train a global machine learning model, while\nmaintaining their data locally. However, recent work shows that client's\nprivate information can still be disclosed to an adversary who just eavesdrops\nthe messages exchanged between the client and the server. For example, the\nadversary can infer whether the client owns a specific data instance, which is\ncalled a passive membership inference attack. In this paper, we propose a new\npassive inference attack that requires much less computation power and memory\nthan existing methods. Our empirical results show that our attack achieves a\nhigher accuracy on CIFAR100 dataset (more than $4$ percentage points) with\nthree orders of magnitude less memory space and five orders of magnitude less\ncalculations.",
    "descriptor": "\nComments: Accepted as a poster in NeurIPS 2021 PriML workshop\n",
    "authors": [
      "Oualid Zari",
      "Chuan Xu",
      "Giovanni Neglia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.00430"
  },
  {
    "id": "arXiv:2111.00431",
    "title": "A Dynamic Resource Allocation Framework for Synchronizing Metaverse with  IoT Service and Data",
    "abstract": "Spurred by the severe restrictions on mobility due to the COVID-19 pandemic,\nthere is currently intense interest in developing the Metaverse, to offer\nvirtual services/business online. A key enabler of such virtual service is the\ndigital twin, i.e., a digital replication of real-world entities in the\nMetaverse, e.g., city twin, avatars, etc. The real-world data collected by IoT\ndevices and sensors are key for synchronizing the two worlds. In this paper, we\nconsider the scenario in which a group of IoT devices are employed by the\nMetaverse platform to collect such data on behalf of virtual service providers\n(VSPs). Device owners, who are self-interested, dynamically select a VSP to\nmaximize rewards. We adopt hybrid evolutionary dynamics, in which heterogeneous\ndevice owner populations can employ different revision protocols to update\ntheir strategies. Extensive simulations demonstrate that a hybrid protocol can\nlead to evolutionary stable states.",
    "descriptor": "",
    "authors": [
      "Yue Han",
      "Dusit Niyato",
      "Cyril Leung",
      "Chunyan Miao",
      "Dong In Kim"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.00431"
  },
  {
    "id": "arXiv:2111.00435",
    "title": "An Actor-Critic Method for Simulation-Based Optimization",
    "abstract": "We focus on a simulation-based optimization problem of choosing the best\ndesign from the feasible space. Although the simulation model can be queried\nwith finite samples, its internal processing rule cannot be utilized in the\noptimization process. We formulate the sampling process as a policy searching\nproblem and give a solution from the perspective of Reinforcement Learning\n(RL). Concretely, Actor-Critic (AC) framework is applied, where the Actor\nserves as a surrogate model to predict the performance on unknown designs,\nwhereas the actor encodes the sampling policy to be optimized. We design the\nupdating rule and propose two algorithms for the cases where the feasible\nspaces are continuous and discrete respectively. Some experiments are designed\nto validate the effectiveness of proposed algorithms, including two toy\nexamples, which intuitively explain the algorithms, and two more complex tasks,\ni.e., adversarial attack task and RL task, which validate the effectiveness in\nlarge-scale problems. The results show that the proposed algorithms can\nsuccessfully deal with these problems. Especially note that in the RL task, our\nmethods give a new perspective to robot control by treating the task as a\nsimulation model and solving it by optimizing the policy generating process,\nwhile existing works commonly optimize the policy itself directly.",
    "descriptor": "",
    "authors": [
      "Kuo Li",
      "Qing-Shan Jia",
      "Jiaqi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00435"
  },
  {
    "id": "arXiv:2111.00436",
    "title": "Analysis of North Indian Classical Ragas Using Tonnetz",
    "abstract": "In North Indian Classical music, each raga has been traditionally associated\nwith a performance time, which supposedly maximizes its aesthetic and emotional\neffects on the listener. The objective of this work was to investigate the\nstructural basis, if any, for the association of ragas with different times of\nthe 24-hour span. The tonnetz framework has been used to analyze the pitch sets\nof 65 North Indian Classical ragas, and structural similarities have been\nobserved between ragas associated with (1) times of transition between day and\nnight, i.e., dawn and dusk, and (2) times between these transitions. These\nfindings could provide some insight into the scientific basis of the age-old\nraga-time relation, and their effects on the perception of the listener.",
    "descriptor": "",
    "authors": [
      "Ananya Giri"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.00436"
  },
  {
    "id": "arXiv:2111.00438",
    "title": "Decentralized Multi-Agent Reinforcement Learning: An Off-Policy Method",
    "abstract": "We discuss the problem of decentralized multi-agent reinforcement learning\n(MARL) in this work. In our setting, the global state, action, and reward are\nassumed to be fully observable, while the local policy is protected as privacy\nby each agent, and thus cannot be shared with others. There is a communication\ngraph, among which the agents can exchange information with their neighbors.\nThe agents make individual decisions and cooperate to reach a higher\naccumulated reward.\nTowards this end, we first propose a decentralized actor-critic (AC) setting.\nThen, the policy evaluation and policy improvement algorithms are designed for\ndiscrete and continuous state-action-space Markov Decision Process (MDP)\nrespectively. Furthermore, convergence analysis is given under the\ndiscrete-space case, which guarantees that the policy will be reinforced by\nalternating between the processes of policy evaluation and policy improvement.\nIn order to validate the effectiveness of algorithms, we design experiments and\ncompare them with previous algorithms, e.g., Q-learning \\cite{watkins1992q} and\nMADDPG \\cite{lowe2017multi}. The results show that our algorithms perform\nbetter from the aspects of both learning speed and final performance. Moreover,\nthe algorithms can be executed in an off-policy manner, which greatly improves\nthe data efficiency compared with on-policy algorithms.",
    "descriptor": "",
    "authors": [
      "Kuo Li",
      "Qing-Shan Jia"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00438"
  },
  {
    "id": "arXiv:2111.00440",
    "title": "Loop closure detection using local 3D deep descriptors",
    "abstract": "We present a simple yet effective method to address loop closure detection in\nsimultaneous localisation and mapping using local 3D deep descriptors (L3Ds).\nL3Ds are emerging compact representations of patches extracted from point\nclouds that are learned from data using a deep learning algorithm. We propose a\nnovel overlap measure for loop detection by computing the metric error between\npoints that correspond to mutually-nearest-neighbour descriptors after\nregistering the loop candidate point cloud by its estimated relative pose. This\nnovel approach enables us to accurately detect loops and estimate six\ndegrees-of-freedom poses in the case of small overlaps. We compare our\nL3D-based loop closure approach with recent approaches on LiDAR data and\nachieve state-of-the-art loop closure detection accuracy. Additionally, we\nembed our loop closure approach in RESLAM, a recent edge-based SLAM system, and\nperform the evaluation on real-world RGBD-TUM and synthetic ICL datasets. Our\napproach enables RESLAM to achieve a better localisation accuracy compared to\nits original loop closure strategy.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Youjie Zhou",
      "Yiming Wang",
      "Fabio Poiesi",
      "Qi Qin",
      "Yi Wan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00440"
  },
  {
    "id": "arXiv:2111.00444",
    "title": "Finite-Time Capacity: Making Exceed-Shannon Possible?",
    "abstract": "Shannon-Hartley theorem can accurately calculate the channel capacity when\nthe signal observation time is infinite. However, the calculation of\nfinite-time capacity, which remains unknown, is essential for guiding the\ndesign of practical communication systems. In this paper, we investigate the\ncapacity between two correlated Gaussian processes within a finite-time\nobservation window. We first derive the finite-time capacity by providing a\nlimit expression. Then we numerically compute the maximum transmission rate\nwithin a single finite-time window. We reveal that the number of bits\ntransmitted per second within the finite-time window can exceed the classical\nShannon capacity, which is called as the Exceed-Shannon phenomenon.\nFurthermore, we derive a finite-time capacity formula under a typical signal\nautocorrelation case by utilizing the Mercer expansion of trace class\noperators, and reveal the connection between the finite-time capacity problem\nand the operator theory. Finally, we analytically prove the existence of the\nExceed-Shannon phenomenon in this typical case, and demonstrate the\nachievability of the finite-time capacity and its compatibility with the\nclassical Shannon capacity.",
    "descriptor": "",
    "authors": [
      "Jieao Zhu",
      "Zijian Zhang",
      "Zhongzhichao Wan",
      "Linglong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00444"
  },
  {
    "id": "arXiv:2111.00452",
    "title": "Experimental Study on the Imitation of the Human Neck-and-Eye Pose Using  the 3-DOF Agile Eye Parallel Robot Based on a Deep Neural Network Approach",
    "abstract": "In this paper, a method to mimic a human face and eyes is proposed which can\nbe regarded as a combination of computer vision techniques and neural network\nconcepts. From a mechanical standpoint, a 3-DOF spherical parallel robot is\nused which imitates the human face movement. In what concerns eye movement, a\n2-DOF mechanism is attached to the end-effector of the 3-DOF spherical parallel\nmechanism. In order to have robust and reliable results for the imitation,\nmeaningful information should be extracted from the face mesh for obtaining the\npose of a face, i.e., the roll, yaw, and pitch angles. To this end, two methods\nare proposed where each of them has its own pros and cons. The first method\nconsists in resorting to the so-called Mediapipe library which is a machine\nlearning solution for high-fidelity body pose tracking, introduced by Google.\nAs the second method, a model is trained by a linear regression model for a\ngathered dataset of face pictures in different poses. In addition, a 3-DOF\nAgile Eye parallel robot is utilized to show the ability of this robot to be\nused as a system which is similar to a human neck for performing a 3-DOF\nrotational motion pattern. Furthermore, a 3D printed face and a 2-DOF eye\nmechanism are fabricated to display the whole system more stylish way.\nExperiments on this platform demonstrate the effectiveness of the proposed\nmethods for tracking the human neck and eye movement.",
    "descriptor": "",
    "authors": [
      "Amirmohammad Radmehr",
      "Milad Asgari",
      "Mehdi Tale Masouleh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00452"
  },
  {
    "id": "arXiv:2111.00454",
    "title": "Gaussian Kernel Mixture Network for Single Image Defocus Deblurring",
    "abstract": "Defocus blur is one kind of blur effects often seen in images, which is\nchallenging to remove due to its spatially variant amount. This paper presents\nan end-to-end deep learning approach for removing defocus blur from a single\nimage, so as to have an all-in-focus image for consequent vision tasks. First,\na pixel-wise Gaussian kernel mixture (GKM) model is proposed for representing\nspatially variant defocus blur kernels in an efficient linear parametric form,\nwith higher accuracy than existing models. Then, a deep neural network called\nGKMNet is developed by unrolling a fixed-point iteration of the GKM-based\ndeblurring. The GKMNet is built on a lightweight scale-recurrent architecture,\nwith a scale-recurrent attention module for estimating the mixing coefficients\nin GKM for defocus deblurring. Extensive experiments show that the GKMNet not\nonly noticeably outperforms existing defocus deblurring methods, but also has\nits advantages in terms of model complexity and computational efficiency.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Yuhui Quan",
      "Zicong Wu",
      "Hui Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00454"
  },
  {
    "id": "arXiv:2111.00459",
    "title": "Graph Neural Network based scheduling : Improved throughput under a  generalized interference model",
    "abstract": "In this work, we propose a Graph Convolutional Neural Networks (GCN) based\nscheduling algorithm for adhoc networks. In particular, we consider a\ngeneralized interference model called the $k$-tolerant conflict graph model and\ndesign an efficient approximation for the well-known Max-Weight scheduling\nalgorithm. A notable feature of this work is that the proposed method do not\nrequire labelled data set (NP-hard to compute) for training the neural network.\nInstead, we design a loss function that utilises the existing greedy approaches\nand trains a GCN that improves the performance of greedy approaches. Our\nextensive numerical experiments illustrate that using our GCN approach, we can\nsignificantly ($4$-$20$ percent) improve the performance of the conventional\ngreedy approach.",
    "descriptor": "\nComments: 10 pages, Accepted at EAI VALUETOOLS 2021 - 14th EAI International Conference on Performance Evaluation Methodologies and Tools\n",
    "authors": [
      "S. Ramakrishnan",
      "Jaswanthi Mandalapu",
      "Subrahmanya Swamy Peruru",
      "Bhavesh Jain",
      "Eitan Altman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00459"
  },
  {
    "id": "arXiv:2111.00460",
    "title": "The Impact of Knowledge of the Issue of Identification and  Authentication on the Information Security of Adolescents in the Virtual  Space",
    "abstract": "Information security in the context of digital literacy is a digital skill\nthat enables safe and purposeful movement through virtual space. The age limit\nand frequency of use of the Internet by young generations has been moved back a\nyear due to the COVID-19 pandemic, and the concern for information security of\nyoung people is increasingly emphasized. If, and to what extent, knowledge of\nthe issue of identification and authentication affects the information security\nof high school students aged 16 to 19 in the virtual space, the research\nquestion addressed by the authors of this paper was to determine which student\nbehaviors pose a potential danger compromising their information security by\nestablishing a correlation between the variables that determine student\nbehavior and the variables used to examine their level of security in a virtual\nenvironment. The research was conducted using a questionnaire on a sample of\nhigh school students in the Republic of Croatia, the results of which showed\nthat some students practice behaviors that are potentially dangerous, make them\nvulnerable and easy targets of cyber predators and attackers, which is why\nthere is cause for concern and a need for a additional education of children of\nprimary and secondary school age in the field of information security in the\nform of the introduction of the subject Digital Literacy. Based on the results,\na model for assessing the level of digital literacy of adolescents that affect\ninformation literacy can be designed, but also further related research in the\nfield of information literacy of children and youth can be conducted.",
    "descriptor": "",
    "authors": [
      "Ljerka Luic",
      "Drazenka Svelec-Juricic",
      "Petar Misevic"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.00460"
  },
  {
    "id": "arXiv:2111.00463",
    "title": "FastCover: An Unsupervised Learning Framework for Multi-Hop Influence  Maximization in Social Networks",
    "abstract": "Finding influential users in social networks is a fundamental problem with\nmany possible useful applications. Viewing the social network as a graph, the\ninfluence of a set of users can be measured by the number of neighbors located\nwithin a given number of hops in the network, where each hop marks a step of\ninfluence diffusion. In this paper, we reduce the problem of IM to a\nbudget-constrained d-hop dominating set problem (kdDSP). We propose a unified\nmachine learning (ML) framework, FastCover, to solve kdDSP by learning an\nefficient greedy strategy in an unsupervised way. As one critical component of\nthe framework, we devise a novel graph neural network (GNN) architecture, graph\nreversed attention network (GRAT), that captures the diffusion process among\nneighbors. Unlike most heuristic algorithms and concurrent ML frameworks for\ncombinatorial optimization problems, FastCover determines the entire seed set\nfrom the nodes' scores computed with only one forward propagation of the GNN\nand has a time complexity quasi-linear in the graph size. Experiments on\nsynthetic graphs and real-world social networks demonstrate that FastCover\nfinds solutions with better or comparable quality rendered by the concurrent\nalgorithms while achieving a speedup of over 1000x.",
    "descriptor": "",
    "authors": [
      "Runbo Ni",
      "Xueyan Li",
      "Fangqi Li",
      "Xiaofeng Gao",
      "Guihai Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00463"
  },
  {
    "id": "arXiv:2111.00465",
    "title": "DAdaQuant: Doubly-adaptive quantization for communication-efficient  Federated Learning",
    "abstract": "Federated Learning (FL) is a powerful technique for training a model on a\nserver with data from several clients in a privacy-preserving manner. In FL, a\nserver sends the model to every client, who then train the model locally and\nsend it back to the server. The server aggregates the updated models and\nrepeats the process for several rounds. FL incurs significant communication\ncosts, in particular when transmitting the updated local models from the\nclients back to the server. Recently proposed algorithms quantize the model\nparameters to efficiently compress FL communication. These algorithms typically\nhave a quantization level that controls the compression factor. We find that\ndynamic adaptations of the quantization level can boost compression without\nsacrificing model quality. First, we introduce a time-adaptive quantization\nalgorithm that increases the quantization level as training progresses. Second,\nwe introduce a client-adaptive quantization algorithm that assigns each\nindividual client the optimal quantization level at every round. Finally, we\ncombine both algorithms into DAdaQuant, the doubly-adaptive quantization\nalgorithm. Our experiments show that DAdaQuant consistently improves\nclient$\\rightarrow$server compression, outperforming the strongest non-adaptive\nbaselines by up to $2.8\\times$.",
    "descriptor": "\nComments: 10 pages, 5 figures, submitted to ICLR 2022\n",
    "authors": [
      "Robert H\u00f6nig",
      "Yiren Zhao",
      "Robert Mullins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00465"
  },
  {
    "id": "arXiv:2111.00467",
    "title": "Multi-User Blind Symmetric Private Information Retrieval from Coded  Servers",
    "abstract": "The problem of Multi-user Blind $X$-secure $T$-colluding Symmetric Private\nInformation Retrieval from Maximum Distance Separable (MDS) coded storage\nsystem with $B$ Byzantine and $U$ unresponsive servers (U-B-MDS-MB-XTSPIR) is\nstudied in this paper. Specifically, a database consisting of multiple files,\neach labeled by $M$ indices, is stored at the distributed system with $N$\nservers according to $(N,K+X)$ MDS codes over $\\mathbb{F}_q$ such that any\ngroup of up to $X$ colluding servers learn nothing about the data files. There\nare $M$ users, in which each user $m,m=1,\\ldots,M$ privately selects an index\n$\\theta_m$ and wishes to jointly retrieve the file specified by the $M$ users'\nindices $(\\theta_1,\\ldots,\\theta_M)$ from the storage system, while keeping its\nindex $\\theta_m$ private from any $T_m$ colluding servers, where there exists\n$B$ Byzantine servers that can send arbitrary responses maliciously to confuse\nthe users retrieving the desired file and $U$ unresponsive servers that will\nnot respond any message at all. In addition, each user must not learn\ninformation about the other users' indices and the database more than the\ndesired file. An U-B-MDS-MB-XTSPIR scheme is constructed based on Lagrange\nencoding. The scheme achieves a retrieval rate of\n$1-\\frac{K+X+T_1+\\ldots+T_M+2B-1}{N-U}$ with secrecy rate\n$\\frac{K+X+T_1+\\ldots+T_M-1}{ N-(K+X+T_1+\\ldots+T_M+2B+U-1)}$ on the finite\nfield of size $q\\geq N+\\max\\{K, N-(K+X+T_1+\\ldots+T_M+2B+U-1)\\}$ for any number\nof files.",
    "descriptor": "",
    "authors": [
      "Jinbao Zhu",
      "Qifa Yan",
      "Xiaohu Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00467"
  },
  {
    "id": "arXiv:2111.00468",
    "title": "Efficient, Anytime Algorithms for Calibration with Isotonic Regression  under Strictly Convex Losses",
    "abstract": "We investigate the calibration of estimations to increase performance with an\noptimal monotone transform on the estimator outputs. We start by studying the\ntraditional square error setting with its weighted variant and show that the\noptimal monotone transform is in the form of a unique staircase function. We\nfurther show that this staircase behavior is preserved for general strictly\nconvex loss functions. Their optimal monotone transforms are also unique, i.e.,\nthere exist a single staircase transform that achieves the minimum loss. We\npropose a linear time and space algorithm that can find such optimal transforms\nfor specific loss settings. Our algorithm has an online implementation where\nthe optimal transform for the samples observed so far are found in linear space\nand amortized time when the samples arrive in an ordered fashion. We also\nextend our results to cases where the functions are not trivial to individually\noptimize and propose an anytime algorithm, which has linear space and\npseudo-linearithmic time complexity.",
    "descriptor": "",
    "authors": [
      "Kaan Gokcesu",
      "Hakan Gokcesu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00468"
  },
  {
    "id": "arXiv:2111.00479",
    "title": "Adapting paths against zero-determinant strategies in repeated  prisoner's dilemma games",
    "abstract": "Long-term cooperation, competition, or exploitation among individuals can be\nmodeled through repeated games. In repeated games, Press and Dyson discovered\nzero-determinant (ZD) strategies that enforce a special relationship between\ntwo players. This special relationship implies that a ZD player can\nunilaterally impose a linear payoff relationship to the opponent regardless of\nthe opponent's strategies. A ZD player also has a property that can lead the\nopponent to an unconditional cooperation if the opponent tries to improve its\npayoff. This property has been mathematically confirmed by Chen and Zinger.\nHumans often underestimate a payoff obtained in the future. However, such\ndiscounting was not considered in their analysis. Here, we mathematically\nexplored whether a ZD player can lead the opponent to an unconditional\ncooperation even if a discount factor is incorporated. Specifically, we\nrepresented the expected payoff with a discount factor as the form of\ndeterminants and calculated whether the values obtained by partially\ndifferentiating each factor in the strategy vector become positive. As a\nresult, we proved that the strategy vector ends up as an unconditional\ncooperation even when starting from any initial strategy. This result was\nconfirmed through numerical calculations. We extended the applicability of ZD\nstrategies to real world problems.",
    "descriptor": "\nComments: 23 pages, 6 figures, and 6 tables\n",
    "authors": [
      "Daiki Miyagawa",
      "Azumi Mamiya",
      "Genki Ichinose"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.00479"
  },
  {
    "id": "arXiv:2111.00480",
    "title": "Alexa, Play Fetch! A Review of Alexa Skills for Pets",
    "abstract": "Alexa Skills are used for a variety of daily routines and purposes, but\nlittle research has focused on a key part of many people's daily lives: their\npets. We present a systematic review categorizing the purposes of 88 Alexa\nSkills aimed at pets and pet owners and introduce a veterinary perspective to\nassess their benefits and risks. We present 8 themes of the purposes for Skills\naimed at pets and their owners: Calming, Animal Audience, Smart Device,\nTracking, Training and Health, Translator, Entertainment/Trivia, and Other -\nHuman Audience. Broadly, we find that these purposes mirror the purposes people\nhave for using Alexa overall, and they largely are supported by veterinary\nevidence, though caution must be used when Skills relate to animal health. More\ncollaboration between Conversational Agent researchers and animal scientists is\ncalled for to better understand the efficacy of using Alexa with pets.",
    "descriptor": "\nComments: Accepted, Animal Computer Interaction 2021 (ACI '21)\n",
    "authors": [
      "Justin Edwards",
      "Orla Cooney",
      "Rachel Edwards"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.00480"
  },
  {
    "id": "arXiv:2111.00482",
    "title": "Size Matters in Univalent Foundations",
    "abstract": "We investigate predicative aspects of constructive univalent foundations. By\npredicative and constructive, we respectively mean that we do not assume\nVoevodsky's propositional resizing axioms or excluded middle. Our work\ncomplements existing work on predicative mathematics by exploring what cannot\nbe done predicatively in univalent foundations. Our first main result is that\nnontrivial (directed or bounded) complete posets are necessarily large. That\nis, if such a nontrivial poset is small, then weak propositional resizing\nholds. It is possible to derive full propositional resizing if we strengthen\nnontriviality to positivity. The distinction between nontriviality and\npositivity is analogous to the distinction between nonemptiness and\ninhabitedness. Moreover, we prove that locally small, nontrivial (directed or\nbounded) complete posets necessarily lack decidable equality. We prove our\nresults for a general class of posets, which includes directed complete posets,\nbounded complete posets and sup-lattices. Secondly, we show that each of Zorn's\nlemma, Tarski's greatest fixed point theorem and Pataraia's lemma implies\npropositional resizing. Hence, these principles are inherently impredicative\nand a predicative development of order theory must therefore do without them.\nThirdly, we clarify, in our predicative setting, the relation between the\ntraditional definition of sup-lattice that requires suprema for all subsets and\nour definition that asks for suprema of all small families. Finally, we\ninvestigate the inter-definability and interaction of type universes of\npropositional truncations and set quotients in the absence of propositional\nresizing axioms.",
    "descriptor": "\nComments: Extended version of arXiv:2102.08812\n",
    "authors": [
      "Tom de Jong",
      "Mart\u00edn H\u00f6tzel Escard\u00f3"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.00482"
  },
  {
    "id": "arXiv:2111.00485",
    "title": "Learned Image Compression with Separate Hyperprior Decoders",
    "abstract": "Learned image compression techniques have achieved considerable development\nin recent years. In this paper, we find that the performance bottleneck lies in\nthe use of a single hyperprior decoder, in which case the ternary Gaussian\nmodel collapses to a binary one. To solve this, we propose to use three\nhyperprior decoders to separate the decoding process of the mixed parameters in\ndiscrete Gaussian mixture likelihoods, achieving more accurate parameters\nestimation. Experimental results demonstrate the proposed method optimized by\nMS-SSIM achieves on average 3.36% BD-rate reduction compared with\nstate-of-the-art approach. The contribution of the proposed method to the\ncoding time and FLOPs is negligible.",
    "descriptor": "\nComments: This paper has been accepted by IEEE Open Journal of Circuits and Systems\n",
    "authors": [
      "Zhao Zan",
      "Chao Liu",
      "Heming Sun",
      "Xiaoyang Zeng",
      "Yibo Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.00485"
  },
  {
    "id": "arXiv:2111.00486",
    "title": "Fine-Grained Cryptanalysis: Tight Conditional Bounds for Dense k-SUM and  k-XOR",
    "abstract": "An average-case variant of the $k$-SUM conjecture asserts that finding $k$\nnumbers that sum to 0 in a list of $r$ random numbers, each of the order $r^k$,\ncannot be done in much less than $r^{\\lceil k/2 \\rceil}$ time. On the other\nhand, in the dense regime of parameters, where the list contains more numbers\nand many solutions exist, the complexity of finding one of them can be\nsignificantly improved by Wagner's $k$-tree algorithm. Such algorithms for\n$k$-SUM in the dense regime have many applications, notably in cryptanalysis.\nIn this paper, assuming the average-case $k$-SUM conjecture, we prove that\nknown algorithms are essentially optimal for $k= 3,4,5$. For $k>5$, we prove\nthe optimality of the $k$-tree algorithm for a limited range of parameters. We\nalso prove similar results for $k$-XOR, where the sum is replaced with\nexclusive or.\nOur results are obtained by a self-reduction that, given an instance of\n$k$-SUM which has a few solutions, produces from it many instances in the dense\nregime. We solve each of these instances using the dense $k$-SUM oracle, and\nhope that a solution to a dense instance also solves the original problem. We\ndeal with potentially malicious oracles (that repeatedly output correlated\nuseless solutions) by an obfuscation process that adds noise to the dense\ninstances. Using discrete Fourier analysis, we show that the obfuscation\neliminates correlations among the oracle's solutions, even though its inputs\nare highly correlated.",
    "descriptor": "\nComments: 42 pages, abridged version accepted to FOCS'2021\n",
    "authors": [
      "Itai Dinur",
      "Nathan Keller",
      "Ohad Klein"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.00486"
  },
  {
    "id": "arXiv:2111.00487",
    "title": "Smart(Sampling)Augment: Optimal and Efficient Data Augmentation for  Semantic Segmentation",
    "abstract": "Data augmentation methods enrich datasets with augmented data to improve the\nperformance of neural networks. Recently, automated data augmentation methods\nhave emerged, which automatically design augmentation strategies. Existing work\nfocuses on image classification and object detection, whereas we provide the\nfirst study on semantic image segmentation and introduce two new approaches:\n\\textit{SmartAugment} and \\textit{SmartSamplingAugment}. SmartAugment uses\nBayesian Optimization to search over a rich space of augmentation strategies\nand achieves a new state-of-the-art performance in all semantic segmentation\ntasks we consider. SmartSamplingAugment, a simple parameter-free approach with\na fixed augmentation strategy competes in performance with the existing\nresource-intensive approaches and outperforms cheap state-of-the-art data\naugmentation methods. Further, we analyze the impact, interaction, and\nimportance of data augmentation hyperparameters and perform ablation studies,\nwhich confirm our design choices behind SmartAugment and SmartSamplingAugment.\nLastly, we will provide our source code for reproducibility and to facilitate\nfurther research.",
    "descriptor": "\nComments: Negassi and Wagner provided an equal contribution\n",
    "authors": [
      "Misgana Negassi",
      "Diane Wagner",
      "Alexander Reiterer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00487"
  },
  {
    "id": "arXiv:2111.00488",
    "title": "Beyond Bufferbloat: End-to-End Congestion Control Cannot Avoid Latency  Spikes",
    "abstract": "End-to-end congestion control is the main method of congestion control in the\nInternet, and achieving consistent low queuing latency with end-to-end methods\nis a very active area of research. Even so, achieving consistent low queuing\nlatency in the Internet still remains an unsolved problem. Therefore, we ask\n\"What are the fundamental limits of end-to-end congestion control?\" We find\nthat the unavoidable queuing latency for best-case end-to-end congestion\ncontrol is on the order of hundreds of milliseconds under conditions that are\ncommon in the Internet. Our argument depends on two things: The latency of\ncongestion signaling -- at minimum the speed of light -- and the fact that link\ncapacity may change rapidly for an end-to-end path in the Internet.",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Bj\u00f8rn Ivar Teigen",
      "Neil Davies",
      "Kai Olav Ellefsen",
      "Tor Skeie",
      "Jim Torresen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.00488"
  },
  {
    "id": "arXiv:2111.00489",
    "title": "Integrated Modular Solution for Task Oriented Manipulator Configuration  Design",
    "abstract": "Modular and reconfigurable robotic systems have been designed to provide a\ncustomized solution for the non-repetitive tasks to be performed in a\nconstrained environment. Customized solutions are normally extracted from\ntask-based optimization of the possible manipulator configurations but the\nsolution are not integrated, for providing the modular compositions directly.\nIn this work, in the first phase, a strategy of finding unconventional optimal\nconfigurations with minimal number of degrees-of-freedom are discussed based\nupon the prescribed working locations and the cluttered environment. Then, in\nthe second phase, design of the modular and reconfigurable architecture is\npresented which can adapt these unconventional robotic parameters. Rather than\ngenerating and evolving the modular compositions, a strategy is presented\nthrough which the unconventional optimal configurations can be mapped directly\nto the modular compositions. The generated modular composition is validated\nusing Robot Operating System for the motion planning between the prescribed\nworking locations in a given cluttered environment.",
    "descriptor": "\nComments: Paper presented at the 5th IEEE/IFToMM International Conference on Reconfigurable Mechanisms and Robots\n",
    "authors": [
      "Anubhav Dogra",
      "Sakshay Mahna",
      "Srikant Sekhar Padhee",
      "Ekta Singla"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00489"
  },
  {
    "id": "arXiv:2111.00490",
    "title": "DSC-IITISM at FinCausal 2021: Combining POS tagging with Attention-based  Contextual Representations for Identifying Causal Relationships in Financial  Documents",
    "abstract": "Causality detection draws plenty of attention in the field of Natural\nLanguage Processing and linguistics research. It has essential applications in\ninformation retrieval, event prediction, question answering, financial\nanalysis, and market research. In this study, we explore several methods to\nidentify and extract cause-effect pairs in financial documents using\ntransformers. For this purpose, we propose an approach that combines POS\ntagging with the BIO scheme, which can be integrated with modern transformer\nmodels to address this challenge of identifying causality in a given text. Our\nbest methodology achieves an F1-Score of 0.9551, and an Exact Match Score of\n0.8777 on the blind test in the FinCausal-2021 Shared Task at the FinCausal\n2021 Workshop.",
    "descriptor": "\nComments: 5 pages, 5 tables\n",
    "authors": [
      "Gunjan Haldar",
      "Aman Mittal",
      "Pradyumna Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00490"
  },
  {
    "id": "arXiv:2111.00495",
    "title": "Local Trajectory Planning For UAV Autonomous Landing",
    "abstract": "An important capability of autonomous Unmanned Aerial Vehicles (UAVs) is\nautonomous landing while avoiding collision with obstacles in the process. Such\ncapability requires real-time local trajectory planning. Although\ntrajectory-planning methods have been introduced for cases such as emergency\nlanding, they have not been evaluated in real-life scenarios where only the\nsurface of obstacles can be sensed and detected. We propose a novel\noptimization framework using a pre-planned global path and a priority map of\nthe landing area. Several trajectory planning algorithms were implemented and\nevaluated in a simulator that includes a 3D urban environment, LiDAR-based\nobstacle-surface sensing and UAV guidance and dynamics. We show that using our\nproposed optimization criterion can successfully improve the landing-mission\nsuccess probability while avoiding collisions with obstacles in real-time.",
    "descriptor": "",
    "authors": [
      "Yossi Magrisso",
      "Ehud Rivlin",
      "Hector Rotstein",
      "Oren Salzman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00495"
  },
  {
    "id": "arXiv:2111.00496",
    "title": "Capacity for Electromagnetic Information Theory",
    "abstract": "Traditional channel capacity based on one-dimensional time domain mismatches\nthe four-dimensional electromagnetic fields, thus it cannot fully exploit the\ninformation in the spatial dimensions. Therefore, electromagnetic information\ntheory based on the four-dimensional electromagnetic fields becomes necessary\nto reveal the fundamental theoretical capacity bound of the communication\nsystems. Existing works on electromagnetic information theory focused on\ndeterministic signals and degrees of freedom, which were unable to derive the\ncapacity due to the lack of entropy definition. In this paper, we first model\nthe communication between two continuous regions by random field. Then, we\nanalyze a special case with parallel linear source and destination to derive\nthe capacity bound. Specifically, for parallel infinite-length source and\ndestination, we analyze the mutual information by spatial spectral density and\nderive the best current distribution on the source to achieve the maximum\nmutual information, i.e., the capacity. Then, we analyze the scenario with\ninfinite-length source and finite-length destination. We use Mercer expansion\nto derive the mutual information between the source and the destination.\nFinally, for a practical model with finite-length source and destination, we\nanalyze its Mercer expansion and reveal its connection with the infinite-length\ncase.",
    "descriptor": "\nComments: This paper analyzes the capacity based on spatial correlation analysis for electromagnetic information theory. The source code will be provided after the publication of the paper\n",
    "authors": [
      "Zhongzhichao Wan",
      "Jieao Zhu",
      "Zijian Zhang",
      "Linglong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00496"
  },
  {
    "id": "arXiv:2111.00500",
    "title": "DPNET: Dual-Path Network for Efficient Object Detectioj with Lightweight  Self-Attention",
    "abstract": "Object detection often costs a considerable amount of computation to get\nsatisfied performance, which is unfriendly to be deployed in edge devices. To\naddress the trade-off between computational cost and detection accuracy, this\npaper presents a dual path network, named DPNet, for efficient object detection\nwith lightweight self-attention. In backbone, a single input/output lightweight\nself-attention module (LSAM) is designed to encode global interactions between\ndifferent positions. LSAM is also extended into a multiple-inputs version in\nfeature pyramid network (FPN), which is employed to capture cross-resolution\ndependencies in two paths. Extensive experiments on the COCO dataset\ndemonstrate that our method achieves state-of-the-art detection results. More\nspecifically, DPNet obtains 29.0% AP on COCO test-dev, with only 1.14 GFLOPs\nand 2.27M model size for a 320x320 image.",
    "descriptor": "",
    "authors": [
      "Huimin Shi",
      "Quan Zhou",
      "Yinghao Ni",
      "Xiaofu Wu",
      "Longin Jan Latecki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00500"
  },
  {
    "id": "arXiv:2111.00506",
    "title": "PnPOOD : Out-Of-Distribution Detection for Text Classification via Plug  andPlay Data Augmentation",
    "abstract": "While Out-of-distribution (OOD) detection has been well explored in computer\nvision, there have been relatively few prior attempts in OOD detection for NLP\nclassification. In this paper we argue that these prior attempts do not fully\naddress the OOD problem and may suffer from data leakage and poor calibration\nof the resulting models. We present PnPOOD, a data augmentation technique to\nperform OOD detection via out-of-domain sample generation using the recently\nproposed Plug and Play Language Model (Dathathri et al., 2020). Our method\ngenerates high quality discriminative samples close to the class boundaries,\nresulting in accurate OOD detection at test time. We demonstrate that our model\noutperforms prior models on OOD sample detection, and exhibits lower\ncalibration error on the 20 newsgroup text and Stanford Sentiment Treebank\ndataset (Lang, 1995; Socheret al., 2013). We further highlight an important\ndata leakage issue with datasets used in prior attempts at OOD detection, and\nshare results on a new dataset for OOD detection that does not suffer from the\nsame problem.",
    "descriptor": "",
    "authors": [
      "Mrinal Rawat",
      "Ramya Hebbalaguppe",
      "Lovekesh Vig"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00506"
  },
  {
    "id": "arXiv:2111.00507",
    "title": "Introduction to probabilistic concurrent systems",
    "abstract": "The first part of the paper is an introduction to the theory of probabilistic\nconcurrent systems under a partial order semantics. Key definitions and results\nare given and illustrated on examples. The second part includes contributions.\nWe introduce deterministic concurrent systems as a subclass of concurrent\nsystems. Deterministic concurrent system are \"locally commutative'\" concurrent\nsystems. We prove that irreducible and deterministic concurrent systems have a\nunique probabilistic dynamics, and we characterize these systems by means of\ntheir combinatorial properties.",
    "descriptor": "\nComments: Extended version of the Petri Net 2021 conference paper arXiv:2008.07233 \"Deterministic concurrent systems\" by the same author. 30 pages, 8 figures, 17 references\n",
    "authors": [
      "Samy Abbes"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.00507"
  },
  {
    "id": "arXiv:2111.00508",
    "title": "Fully convolutional Siamese neural networks for buildings damage  assessment from satellite images",
    "abstract": "Damage assessment after natural disasters is needed to distribute aid and\nforces to recovery from damage dealt optimally. This process involves acquiring\nsatellite imagery for the region of interest, localization of buildings, and\nclassification of the amount of damage caused by nature or urban factors to\nbuildings. In case of natural disasters, this means processing many square\nkilometers of the area to judge whether a particular building had suffered from\nthe damaging factors.\nIn this work, we develop a computational approach for an automated comparison\nof the same region's satellite images before and after the disaster, and\nclassify different levels of damage in buildings. Our solution is based on\nSiamese neural networks with encoder-decoder architecture. We include an\nextensive ablation study and compare different encoders, decoders, loss\nfunctions, augmentations, and several methods to combine two images. The\nsolution achieved one of the best results in the Computer Vision for Building\nDamage Assessment competition.",
    "descriptor": "",
    "authors": [
      "Eugene Khvedchenya",
      "Tatiana Gabruseva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.00508"
  },
  {
    "id": "arXiv:2111.00509",
    "title": "DRBANET: A Lightweight Dual-Resolution Network for Semantic Segmentation  with Boundary Auxiliary",
    "abstract": "Due to the powerful ability to encode image details and semantics, many\nlightweight dual-resolution networks have been proposed in recent years.\nHowever, most of them ignore the benefit of boundary information. This paper\nintroduces a lightweight dual-resolution network, called DRBANet, aiming to\nrefine semantic segmentation results with the aid of boundary information.\nDRBANet adopts dual parallel architecture, including: high resolution branch\n(HRB) and low resolution branch (LRB). Specifically, HRB mainly consists of a\nset of Efficient Inverted Bottleneck Modules (EIBMs), which learn feature\nrepresentations with larger receptive fields. LRB is composed of a series of\nEIBMs and an Extremely Lightweight Pyramid Pooling Module (ELPPM), where ELPPM\nis utilized to capture multi-scale context through hierarchical residual\nconnections. Finally, a boundary supervision head is designed to capture object\nboundaries in HRB. Extensive experiments on Cityscapes and CamVid datasets\ndemonstrate that our method achieves promising trade-off between segmentation\naccuracy and running efficiency.",
    "descriptor": "",
    "authors": [
      "Linjie Wang",
      "Quan Zhou",
      "Chenfeng Jiang",
      "Xiaofu Wu",
      "Longin Jan Latecki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00509"
  },
  {
    "id": "arXiv:2111.00511",
    "title": "Optimal Targeted Advertising Strategy For Secure Wireless Edge Metaverse",
    "abstract": "Recently, Metaverse has attracted increasing attention from both industry and\nacademia, because of the significant potential to integrate real and digital\nworlds ever more seamlessly. By combining advanced wireless communications,\nedge computing and virtual reality (VR) technologies into Metaverse, a\nmultidimensional, intelligent and powerful wireless edge Metaverse is created\nfor future human society. In this paper, we design a privacy preserving\ntargeted advertising strategy for the wireless edge Metaverse. Specifically, a\nMetaverse service provider (MSP) allocates bandwidth to the VR users so that\nthe users can access Metaverse from edge access points. To protect users'\nprivacy, the covert communication technique is used in the downlink. Then, the\nMSP can offer high-quality access services to earn more profits. Motivated by\nthe concept of \"covert\", targeted advertising is used to promote the sale of\nbandwidth and ensure that the advertising strategy cannot be detected by\ncompetitors who may make counter-offer and by attackers who want to disrupt the\nservices. We derive the best advertising strategy in terms of budget input,\nwith the help of the Vidale-Wolfe model and Hamiltonian function. Furthermore,\nwe propose a novel metric named Meta-Immersion to represent the user's\nexperience feelings. The performance evaluation shows that the MSP can boost\nits revenue with an optimal targeted advertising strategy, especially compared\nwith that without the advertising.",
    "descriptor": "",
    "authors": [
      "Hongyang Du",
      "Dusit Niyato",
      "Jiawen Kang",
      "Dong In Kim",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00511"
  },
  {
    "id": "arXiv:2111.00513",
    "title": "Automated Hyperparameter Optimization Challenge at CIKM 2021 AnalyticCup",
    "abstract": "In this paper, we describe our method for tackling the automated\nhyperparameter optimization challenge in QQ Browser 2021 AI Algorithm\nCompetiton (ACM CIKM 2021 AnalyticCup Track 2). The competition organizers\nprovide anonymized realistic industrial tasks and datasets for black-box\noptimization. Based on our open-sourced package OpenBox, we adopt the Bayesian\noptimization framework for configuration sampling and a heuristic early\nstopping strategy. We won first place in both the preliminary and final\ncontests with the results of 0.938291 and 0.918753, respectively.",
    "descriptor": "",
    "authors": [
      "Huaijun Jiang",
      "Yu Shen",
      "Yang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00513"
  },
  {
    "id": "arXiv:2111.00514",
    "title": "Visualization: the missing factor in Simultaneous Speech Translation",
    "abstract": "Simultaneous speech translation (SimulST) is the task in which output\ngeneration has to be performed on partial, incremental speech input. In recent\nyears, SimulST has become popular due to the spread of cross-lingual\napplication scenarios, like international live conferences and streaming\nlectures, in which on-the-fly speech translation can facilitate users' access\nto audio-visual content. In this paper, we analyze the characteristics of the\nSimulST systems developed so far, discussing their strengths and weaknesses. We\nthen concentrate on the evaluation framework required to properly assess\nsystems' effectiveness. To this end, we raise the need for a broader\nperformance analysis, also including the user experience standpoint. SimulST\nsystems, indeed, should be evaluated not only in terms of quality/latency\nmeasures, but also via task-oriented metrics accounting, for instance, for the\nvisualization strategy adopted. In light of this, we highlight which are the\ngoals achieved by the community and what is still missing.",
    "descriptor": "\nComments: Accepted at CLIC-it 2021\n",
    "authors": [
      "Sara Papi",
      "Matteo Negri",
      "Marco Turchi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00514"
  },
  {
    "id": "arXiv:2111.00517",
    "title": "Classification of fetal compromise during labour: signal processing and  feature engineering of the cardiotocograph",
    "abstract": "Cardiotocography (CTG) is the main tool used for fetal monitoring during\nlabour. Interpretation of CTG requires dynamic pattern recognition in real\ntime. It is recognised as a difficult task with high inter- and intra-observer\ndisagreement. Machine learning has provided a viable path towards objective and\nreliable CTG assessment. In this study, novel CTG features are developed based\non clinical expertise and system control theory using an autoregressive\nmoving-average (ARMA) model to characterise the response of the fetal heart\nrate to contractions. The features are evaluated in a machine learning model to\nassess their efficacy in identifying fetal compromise. ARMA features ranked\namongst the top features for detecting fetal compromise. Additionally,\nincluding clinical factors in the machine learning model and pruning data based\non a signal quality measure improved the performance of the classifier.",
    "descriptor": "",
    "authors": [
      "M. O'Sullivan",
      "T. Gabruseva",
      "G. Boylan",
      "M. O'Riordan",
      "G. Lightbody",
      "W. Marnane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.00517"
  },
  {
    "id": "arXiv:2111.00524",
    "title": "Intermodulation Interference Detection in 6G Networks: A Machine  Learning Approach",
    "abstract": "This letter demonstrates the use of machine learning to detect the presence\nof intermodulation interference across several wireless carriers. We propose an\nalgorithm that detects presence of intermodulation interference through the use\nof linear regression as a supervised machine learning technique. Furthermore,\nwe show that our proposed algorithm can additionally detect narrow-band\ninterference. Our proposed algorithm can run in near-constant time complexity,\nmaking it a suitable real-time radio resource management application for the\nsixth generation of wireless communication and beyond.",
    "descriptor": "\nComments: 5 pages, 5 figures. Submitted to IEEE Communication Letters\n",
    "authors": [
      "Faris B. Mismar",
      "Carlos A. Cabrera"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.00524"
  },
  {
    "id": "arXiv:2111.00526",
    "title": "FinEAS: Financial Embedding Analysis of Sentiment",
    "abstract": "We introduce a new language representation model in finance called Financial\nEmbedding Analysis of Sentiment (FinEAS). In financial markets, news and\ninvestor sentiment are significant drivers of security prices. Thus, leveraging\nthe capabilities of modern NLP approaches for financial sentiment analysis is a\ncrucial component in identifying patterns and trends that are useful for market\nparticipants and regulators. In recent years, methods that use transfer\nlearning from large Transformer-based language models like BERT, have achieved\nstate-of-the-art results in text classification tasks, including sentiment\nanalysis using labelled datasets. Researchers have quickly adopted these\napproaches to financial texts, but best practices in this domain are not\nwell-established. In this work, we propose a new model for financial sentiment\nanalysis based on supervised fine-tuned sentence embeddings from a standard\nBERT model. We demonstrate our approach achieves significant improvements in\ncomparison to vanilla BERT, LSTM, and FinBERT, a financial domain specific\nBERT.",
    "descriptor": "",
    "authors": [
      "Asier Guti\u00e9rrez-Fandi\u00f1o",
      "Miquel Noguer i Alonso",
      "Petter Kolm",
      "Jordi Armengol-Estap\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Finance (q-fin.CP)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2111.00526"
  },
  {
    "id": "arXiv:2111.00531",
    "title": "Learning Debiased and Disentangled Representations for Semantic  Segmentation",
    "abstract": "Deep neural networks are susceptible to learn biased models with entangled\nfeature representations, which may lead to subpar performances on various\ndownstream tasks. This is particularly true for under-represented classes,\nwhere a lack of diversity in the data exacerbates the tendency. This limitation\nhas been addressed mostly in classification tasks, but there is little study on\nadditional challenges that may appear in more complex dense prediction problems\nincluding semantic segmentation. To this end, we propose a model-agnostic and\nstochastic training scheme for semantic segmentation, which facilitates the\nlearning of debiased and disentangled representations. For each class, we first\nextract class-specific information from the highly entangled feature map. Then,\ninformation related to a randomly sampled class is suppressed by a feature\nselection process in the feature space. By randomly eliminating certain class\ninformation in each training iteration, we effectively reduce feature\ndependencies among classes, and the model is able to learn more debiased and\ndisentangled feature representations. Models trained with our approach\ndemonstrate strong results on multiple semantic segmentation benchmarks, with\nespecially notable performance gains on under-represented classes.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Sanghyeok Chu",
      "Dongwan Kim",
      "Bohyung Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00531"
  },
  {
    "id": "arXiv:2111.00537",
    "title": "A network-based approach to QAnon user dynamics during COVID-19  infodemic",
    "abstract": "QAnon is an umbrella conspiracy theory that encompasses a wide spectrum of\npeople. The COVID-19 pandemic has helped raise QAnon conspiracy theory to a\nwide-spreading movement, especially in the US. Here, we study users' dynamics\non Twitter related to the QAnon movement (i.e., pro-/anti-QAnon and swing\nusers) in the context of the COVID-19 infodemic and the topics involved using a\nnetwork-based approach. We find that it is not easy for swing users to convert\ntheir attitudes, although Twitter is suspending malicious pro-QAnon users as\nmuch as possible. We also find that QAnon clusters include many bot users.\nFurthermore, our results suggest that QAnon continues to evolve amid the\ninfodemic and does not limit itself to its original idea, but instead, extends\nits reach to create a much larger umbrella conspiracy theory. A network-based\napproach in this study is important for both nowcasting and forecasting the\nevolution of the QAnon movement.",
    "descriptor": "",
    "authors": [
      "Wentao Xu",
      "Kazutoshi Sasahara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.00537"
  },
  {
    "id": "arXiv:2111.00538",
    "title": "From Face to Gait: Weakly-Supervised Learning of Gender Information from  Walking Patterns",
    "abstract": "Obtaining demographics information from video is valuable for a range of\nreal-world applications. While approaches that leverage facial features for\ngender inference are very successful in restrained environments, they do not\nwork in most real-world scenarios when the subject is not facing the camera,\nhas the face obstructed or the face is not clear due to distance from the\ncamera or poor resolution. We propose a weakly-supervised method for learning\ngender information of people based on their manner of walking. We make use of\nstate-of-the art facial analysis models to automatically annotate front-view\nwalking sequences and generalise to unseen angles by leveraging gait-based\nlabel propagation. Our results show on par or higher performance with facial\nanalysis models with an F1 score of 91% and the ability to successfully\ngeneralise to scenarios in which facial analysis is unfeasible due to subjects\nnot facing the camera or having the face obstructed.",
    "descriptor": "\nComments: Accepted at Face & Gesture Recognition 2021\n",
    "authors": [
      "Andy Catruna",
      "Adrian Cosma",
      "Ion Emilian Radoi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00538"
  },
  {
    "id": "arXiv:2111.00539",
    "title": "Cross-Domain Reasoning via Template Filling",
    "abstract": "In this paper, we explore the ability of sequence to sequence models to\nperform cross-domain reasoning. Towards this, we present a\nprompt-template-filling approach to enable sequence to sequence models to\nperform cross-domain reasoning. We also present a case-study with commonsense\nand health and well-being domains, where we study how prompt-template-filling\nenables pretrained sequence to sequence models across domains. Our experiments\nacross several pretrained encoder-decoder models show that cross-domain\nreasoning is challenging for current models. We also show an in-depth error\nanalysis and avenues for future research for reasoning across domains",
    "descriptor": "",
    "authors": [
      "Dheeraj Rajagopal",
      "Vivek Khetan",
      "Bogdan Sacaleanu",
      "Anatole Gershman",
      "Andrew Fano",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00539"
  },
  {
    "id": "arXiv:2111.00543",
    "title": "Some axioms for mathematics",
    "abstract": "The lambda-Pi-calculus modulo theory is a logical framework in which many\nlogical systems can be expressed as theories. We present such a theory, the\ntheory U, where proofs of several logical systems can be expressed. Moreover,\nwe identify a sub-theory of U corresponding to each of these systems, and prove\nthat, when a proof in U uses only symbols of a sub-theory, then it is a proof\nin that sub-theory.",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Blanqui",
      "Gilles Dowek",
      "Emilie Grienenberger",
      "Gabriel Hondet",
      "Fran\u00e7ois Thir\u00e9"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.00543"
  },
  {
    "id": "arXiv:2111.00552",
    "title": "Fast Global Convergence of Policy Optimization for Constrained MDPs",
    "abstract": "We address the issue of safety in reinforcement learning. We pose the problem\nin a discounted infinite-horizon constrained Markov decision process framework.\nExisting results have shown that gradient-based methods are able to achieve an\n$\\mathcal{O}(1/\\sqrt{T})$ global convergence rate both for the optimality gap\nand the constraint violation. We exhibit a natural policy gradient-based\nalgorithm that has a faster convergence rate $\\mathcal{O}(\\log(T)/T)$ for both\nthe optimality gap and the constraint violation. When Slater's condition is\nsatisfied and known a priori, zero constraint violation can be further\nguaranteed for a sufficiently large $T$ while maintaining the same convergence\nrate.",
    "descriptor": "",
    "authors": [
      "Tao Liu",
      "Ruida Zhou",
      "Dileep Kalathil",
      "P. R. Kumar",
      "Chao Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00552"
  },
  {
    "id": "arXiv:2111.00554",
    "title": "Quality Estimation Using Round-trip Translation with Sentence Embeddings",
    "abstract": "Estimating the quality of machine translation systems has been an ongoing\nchallenge for researchers in this field. Many previous attempts at using\nround-trip translation as a measure of quality have failed, and there is much\ndisagreement as to whether it can be a viable method of quality estimation. In\nthis paper, we revisit round-trip translation, proposing a system which aims to\nsolve the previous pitfalls found with the approach. Our method makes use of\nrecent advances in language representation learning to more accurately gauge\nthe similarity between the original and round-trip translated sentences.\nExperiments show that while our approach does not reach the performance of\ncurrent state of the art methods, it may still be an effective approach for\nsome language pairs.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Nathan Crone",
      "Adam Power",
      "John Weldon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00554"
  },
  {
    "id": "arXiv:2111.00556",
    "title": "Revealing and Protecting Labels in Distributed Training",
    "abstract": "Distributed learning paradigms such as federated learning often involve\ntransmission of model updates, or gradients, over a network, thereby avoiding\ntransmission of private data. However, it is possible for sensitive information\nabout the training data to be revealed from such gradients. Prior works have\ndemonstrated that labels can be revealed analytically from the last layer of\ncertain models (e.g., ResNet), or they can be reconstructed jointly with model\ninputs by using Gradients Matching [Zhu et al'19] with additional knowledge\nabout the current state of the model. In this work, we propose a method to\ndiscover the set of labels of training samples from only the gradient of the\nlast layer and the id to label mapping. Our method is applicable to a wide\nvariety of model architectures across multiple domains. We demonstrate the\neffectiveness of our method for model training in two domains - image\nclassification, and automatic speech recognition. Furthermore, we show that\nexisting reconstruction techniques improve their efficacy when used in\nconjunction with our method. Conversely, we demonstrate that gradient\nquantization and sparsification can significantly reduce the success of the\nattack.",
    "descriptor": "",
    "authors": [
      "Trung Dang",
      "Om Thakkar",
      "Swaroop Ramaswamy",
      "Rajiv Mathews",
      "Peter Chin",
      "Fran\u00e7oise Beaufays"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00556"
  },
  {
    "id": "arXiv:2111.00559",
    "title": "Capacity of Noisy Permutation Channels",
    "abstract": "We establish the capacity of a class of communication channels introduced in\n[1]. The $n$-letter input from a finite alphabet is passed through a discrete\nmemoryless channel $P_{Z|X}$ and then the output $n$-letter sequence is\nuniformly permuted. We show that the maximal communication rate (normalized by\n$\\log n$) equals $1/2 (rank(P_{Z|X})-1)$ whenever $P_{Z|X}$ is strictly\npositive. This is done by establishing a converse bound matching the\nachievability of [1]. The two main ingredients of our proof are (1) a sharp\nbound on the entropy of a uniformly sampled vector from a type class and\nobserved through a DMC; and (2) the covering $\\epsilon$-net of a probability\nsimplex with Kullback-Leibler divergence as a metric. In addition to strictly\npositive DMC we also find the noisy permutation capacity for $q$-ary erasure\nchannels, the Z-channel and others.",
    "descriptor": "",
    "authors": [
      "Jennifer Tang",
      "Yury Polyanskiy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00559"
  },
  {
    "id": "arXiv:2111.00562",
    "title": "My friends also prefer diverse music: homophily and link prediction with  user preferences for mainstream, novelty, and diversity in music",
    "abstract": "Homophily describes the phenomenon that similarity breeds connection, i.e.,\nindividuals tend to form ties with other people who are similar to themselves\nin some aspect(s). The similarity in music taste can undoubtedly influence who\nwe make friends with and shape our social circles. In this paper, we study\nhomophily in an online music platform Last.fm regarding user preferences\ntowards listening to mainstream (M), novel (N), or diverse (D) content.\nFurthermore, we draw comparisons with homophily based on listening profiles\nderived from artists users have listened to in the past, i.e., artist profiles.\nFinally, we explore the utility of users' artist profiles as well as features\ndescribing M, N, and D for the task of link prediction. Our study reveals that:\n(i) users with a friendship connection share similar music taste based on their\nartist profiles; (ii) on average, a measure of how diverse is the music two\nusers listen to is a stronger predictor of friendship than measures of their\npreferences towards mainstream or novel content, i.e., homophily is stronger\nfor D than for M and N; (iii) some user groups such as high-novelty-seekers\n(explorers) exhibit strong homophily, but lower than average artist profile\nsimilarity; (iv) using M, N and D achieves comparable results on link\nprediction accuracy compared with using artist profiles, but the combination of\nfeatures yields the best accuracy results, and (v) using combined features does\nnot add value if graph-based features such as common neighbors are available,\nmaking M, N, and D features primarily useful in a cold-start user\nrecommendation setting for users with few friendship connections. The insights\nfrom this study will inform future work on social context-aware music\nrecommendation, user modeling, and link prediction.",
    "descriptor": "\nComments: 8 page full paper accepted at the 12th International Workshop on Mining and Analyzing Social Networks for Decision Support (MSNDS 2021). Included in the Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2021)\n",
    "authors": [
      "Tomislav Duricic",
      "Dominik Kowald",
      "Markus Schedl",
      "Elisabeth Lex"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.00562"
  },
  {
    "id": "arXiv:2111.00565",
    "title": "Can we learn gradients by Hamiltonian Neural Networks?",
    "abstract": "In this work, we propose a meta-learner based on ODE neural networks that\nlearns gradients. This approach makes the optimizer is more flexible inducing\nan automatic inductive bias to the given task. Using the simplest Hamiltonian\nNeural Network we demonstrate that our method outperforms a meta-learner based\non LSTM for an artificial task and the MNIST dataset with ReLU activations in\nthe optimizee. Furthermore, it also surpasses the classic optimization methods\nfor the artificial task and achieves comparable results for MNIST.",
    "descriptor": "",
    "authors": [
      "Aleksandr Timofeev",
      "Andrei Afonin",
      "Yehao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00565"
  },
  {
    "id": "arXiv:2111.00570",
    "title": "An Approach to Inference-Driven Dialogue Management within a Social  Chatbot",
    "abstract": "We present a chatbot implementing a novel dialogue management approach based\non logical inference. Instead of framing conversation a sequence of response\ngeneration tasks, we model conversation as a collaborative inference process in\nwhich speakers share information to synthesize new knowledge in real time. Our\nchatbot pipeline accomplishes this modelling in three broad stages. The first\nstage translates user utterances into a symbolic predicate representation. The\nsecond stage then uses this structured representation in conjunction with a\nlarger knowledge base to synthesize new predicates using efficient graph\nmatching. In the third and final stage, our bot selects a small subset of\npredicates and translates them into an English response. This approach lends\nitself to understanding latent semantics of user inputs, flexible initiative\ntaking, and responses that are novel and coherent with the dialogue context.",
    "descriptor": "\nComments: Published in 4th Proceedings of Alexa Prize (Alexa Prize 2020)\n",
    "authors": [
      "Sarah E. Finch",
      "James D. Finch",
      "Daniil Huryn",
      "William Hutsell",
      "Xiaoyuan Huang",
      "Han He",
      "Jinho D. Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00570"
  },
  {
    "id": "arXiv:2111.00572",
    "title": "What Went Wrong? Explaining Overall Dialogue Quality through  Utterance-Level Impacts",
    "abstract": "Improving user experience of a dialogue system often requires intensive\ndeveloper effort to read conversation logs, run statistical analyses, and\nintuit the relative importance of system shortcomings. This paper presents a\nnovel approach to automated analysis of conversation logs that learns the\nrelationship between user-system interactions and overall dialogue quality.\nUnlike prior work on utterance-level quality prediction, our approach learns\nthe impact of each interaction from the overall user rating without\nutterance-level annotation, allowing resultant model conclusions to be derived\non the basis of empirical evidence and at low cost. Our model identifies\ninteractions that have a strong correlation with the overall dialogue quality\nin a chatbot setting. Experiments show that the automated analysis from our\nmodel agrees with expert judgments, making this work the first to show that\nsuch weakly-supervised learning of utterance-level quality prediction is highly\nachievable.",
    "descriptor": "\nComments: Accepted at the 3rd Workshop on NLP for ConvAI\n",
    "authors": [
      "James D. Finch",
      "Sarah E. Finch",
      "Jinho D. Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00572"
  },
  {
    "id": "arXiv:2111.00579",
    "title": "RRFT: A Rank-Based Resource Aware Fault Tolerant Strategy for Cloud  Platforms",
    "abstract": "The applications that are deployed in the cloud to provide services to the\nusers encompass a large number of interconnected dependent cloud components.\nMultiple identical components are scheduled to run concurrently in order to\nhandle unexpected failures and provide uninterrupted service to the end user,\nwhich introduces resource overhead problem for the cloud service provider.\nFurthermore such resource-intensive fault tolerant strategies bring extra\nmonetary overhead to the cloud service provider and eventually to the cloud\nusers. In order to address these issues, a novel fault tolerant strategy based\non the significance level of each component is developed. The communication\ntopology among the application components, their historical performance,\nfailure rate, failure impact on other components, dependencies among them,\netc., are used to rank those application components to further decide on the\nimportance of one component over others. Based on the rank, a Markov Decision\nProcess (MDP) model is presented to determine the number of replicas that\nvaries from one component to another. A rigorous performance evaluation is\ncarried out using some of the most common practically useful metrics such as,\nrecovery time upon a fault, average number of components needed, number of\nparallel components successfully executed, etc., to quote a few, with similar\ncomponent ranking and fault tolerant strategies. Simulation results demonstrate\nthat the proposed algorithm reduces the required number of virtual and physical\nmachines by approximately 10% and 4.2%, respectively, compared to other similar\nalgorithms.",
    "descriptor": "\nComments: This is accepted in IEEE TCC. The preprint version will be uploaded soon\n",
    "authors": [
      "Chinmaya Kumar Dehury",
      "Prasan Kumar Sahoo",
      "Bharadwaj Veeravalli"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.00579"
  },
  {
    "id": "arXiv:2111.00580",
    "title": "Text Classification for Task-based Source Code Related Questions",
    "abstract": "There is a key demand to automatically generate code for small tasks for\ndevelopers. Websites such as StackOverflow provide a simplistic way by offering\nsolutions in small snippets which provide a complete answer to whatever task\nquestion the developer wants to code. Natural Language Processing and\nparticularly Question-Answering Systems are very helpful in resolving and\nworking on these tasks. In this paper, we develop a two-fold deep learning\nmodel: Seq2Seq and a binary classifier that takes in the intent (which is in\nnatural language) and code snippets in Python. We train both the intent and the\ncode utterances in the Seq2Seq model, where we decided to compare the effect of\nthe hidden layer embedding from the encoder for representing the intent and\nsimilarly, using the decoder's hidden layer embeddings for the code sequence.\nThen we combine both these embeddings and then train a simple binary neural\nnetwork classifier model for predicting if the intent is correctly answered by\nthe predicted code sequence from the seq2seq model. We find that the hidden\nstate layer's embeddings perform slightly better than regular standard\nembeddings from a constructed vocabulary. We experimented with our tests on the\nCoNaLa dataset in addition to the StaQC database consisting of simple task-code\nsnippet-based pairs. We empirically establish that using additional pre-trained\nembeddings for code snippets in Python is less context-based in comparison to\nusing hidden state context vectors from seq2seq models.",
    "descriptor": "",
    "authors": [
      "Sairamvinay Vijayaraghavan",
      "Jinxiao Song",
      "David Tomassi",
      "Siddhartha Punj",
      "Jailan Sabet"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00580"
  },
  {
    "id": "arXiv:2111.00582",
    "title": "Data Breaches in Healthcare Security Systems",
    "abstract": "Providing security to Health Information is considered to be the topmost\npriority when compared to any other field. After the digitalization of the\npatient's records in the medical field, the healthcare/medical field has become\na victim of several internal and external cyberattacks. Data breaches in the\nhealthcare industry have been increasing rapidly. Despite having security\nstandards such as HIPAA (Health Insurance Portability and Accountability Act),\ndata breaches still happen on a daily basis. All various types of data breaches\nhave the same harmful impact on healthcare data, especially on patients'\nprivacy. The main objective of this paper is to analyze why healthcare data\nbreaches occur and what is the impact of these breaches. The paper also\npresents the possible improvements that can be made in the current standards,\nsuch as HIPAA, to increase security in the healthcare field.",
    "descriptor": "\nComments: 7 pages, 4 figures, under reviewing process\n",
    "authors": [
      "Jahnavi Reddy",
      "Nelly Elsayed",
      "Zag ElSayed",
      "Murat Ozer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00582"
  },
  {
    "id": "arXiv:2111.00585",
    "title": "JEDAI Explains Decision-Making AI",
    "abstract": "This paper presents JEDAI, an AI system designed for outreach and educational\nefforts aimed at non-AI experts. JEDAI features a novel synthesis of research\nideas from integrated task and motion planning and explainable AI. JEDAI helps\nusers create high-level, intuitive plans while ensuring that they will be\nexecutable by the robot. It also provides users customized explanations about\nerrors and helps improve their understanding of AI planning as well as the\nlimits and capabilities of the underlying robot system.",
    "descriptor": "",
    "authors": [
      "Trevor Angle",
      "Naman Shah",
      "Pulkit Verma",
      "Siddharth Srivastava"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00585"
  },
  {
    "id": "arXiv:2111.00587",
    "title": "A Tensor SVD-based Classification Algorithm Applied to fMRI Data",
    "abstract": "To analyze the abundance of multidimensional data, tensor-based frameworks\nhave been developed. Traditionally, the matrix singular value decomposition\n(SVD) is used to extract the most dominant features from a matrix containing\nthe vectorized data. While the SVD is highly useful for data that can be\nappropriately represented as a matrix, this step of vectorization causes us to\nlose the high-dimensional relationships intrinsic to the data. To facilitate\nefficient multidimensional feature extraction, we utilize a projection-based\nclassification algorithm using the t-SVDM, a tensor analog of the matrix SVD.\nOur work extends the t-SVDM framework and the classification algorithm, both\ninitially proposed for tensors of order 3, to any number of dimensions. We then\napply this algorithm to a classification task using the StarPlus fMRI dataset.\nOur numerical experiments demonstrate that there exists a superior tensor-based\napproach to fMRI classification than the best possible equivalent matrix-based\napproach. Our results illustrate the advantages of our chosen tensor framework,\nprovide insight into beneficial choices of parameters, and could be further\ndeveloped for classification of more complex imaging data. We provide our\nPython implementation at https://github.com/elizabethnewman/tensor-fmri.",
    "descriptor": "",
    "authors": [
      "Katherine Keegan",
      "Tanvi Vishwanath",
      "Yihua Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00587"
  },
  {
    "id": "arXiv:2111.00588",
    "title": "A Graphical Framework for the Category-Based Metamodel for Access  Control and Obligations",
    "abstract": "We design a graph-based framework for the visualisation and analysis of\nobligations in access control policies. We consider obligation policies in\nCBACO, the category-based access control model, which has been shown to subsume\nmany of the most well known access control such as MAC, DAC, RBAC. CBACO is an\nextension of the CBAC metamodel that deals with obligations. We describe the\nimplementation of the proposed model in PORGY, a strategy driven\ngraph-rewriting tool, based on the theory of port-graphs. CBACO policies allow\nfor dynamic behavior in the modelled systems, which is implemented using the\nstrategy language of PORGY.",
    "descriptor": "\nComments: 19 pages, 6 figures\n",
    "authors": [
      "Sandra Alves",
      "Jorge Igl\u00e9sias"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00588"
  },
  {
    "id": "arXiv:2111.00591",
    "title": "Stochastic behaviour of an interface-based memristive device",
    "abstract": "A large number of simulation models have been proposed over the years to\nmimic the electrical behaviour of memristive devices. The models are based\neither on sophisticated mathematical formulations that do not account for\nphysical and chemical processes responsible for the actual switching dynamics\nor on multi-physical spatially resolved approaches that include the inherent\nstochastic behaviour of real-world memristive devices but are computationally\nvery expensive. In contrast to the available models, we present a\ncomputationally inexpensive and robust spatially 1D model for simulating\ninterface-type memristive devices. The model efficiently incorporates the\nstochastic behaviour observed in experiments and can be easily transferred to\ncircuit simulation frameworks. The ion transport, responsible for the resistive\nswitching behaviour, is modelled using the kinetic Cloud-In-a-Cell scheme. The\ncalculated current-voltage characteristics obtained using the proposed model\nshow excellent agreement with the experimental findings.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Sahitya Yarragolla",
      "Torben Hemke",
      "Jan Trieschmann",
      "Finn Zahari",
      "Hermann Kohlstedt",
      "Thomas Mussenbrock"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2111.00591"
  },
  {
    "id": "arXiv:2111.00592",
    "title": "Unsupervised Learning to Subphenotype Delirium Patients from Electronic  Health Records",
    "abstract": "Delirium is a common acute onset brain dysfunction in the emergency setting\nand is associated with higher mortality. It is difficult to detect and monitor\nsince its presentations and risk factors can be different depending on the\nunderlying medical condition of patients. In our study, we aimed to identify\nsubtypes within the delirium population and build subgroup-specific predictive\nmodels to detect delirium using Medical Information Mart for Intensive Care IV\n(MIMIC-IV) data. We showed that clusters exist within the delirium population.\nDifferences in feature importance were also observed for subgroup-specific\npredictive models. Our work could recalibrate existing delirium prediction\nmodels for each delirium subgroup and improve the precision of delirium\ndetection and monitoring for ICU or emergency department patients who had\nhighly heterogeneous medical conditions.",
    "descriptor": "",
    "authors": [
      "Yiqing Zhao",
      "Yuan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00592"
  },
  {
    "id": "arXiv:2111.00593",
    "title": "Approximate Solutions to Second-Order Parabolic Equations: evolution  systems and discretization",
    "abstract": "We study the discretization of a linear evolution partial differential\nequation when its Green function is known. We provide error estimates both for\nthe spatial approximation and for the time stepping approximation. We show\nthat, in fact, an approximation of the Green function is almost as good as the\nGreen function itself. For suitable time-dependent parabolic equations, we\nexplain how to obtain good, explicit approximations of the Green function using\nthe Dyson-Taylor commutator method (DTCM) that we developed in J. Math. Phys.\n(2010). This approximation for short time, when combined with a bootstrap\nargument, gives an approximate solution on any fixed time interval within any\nprescribed tolerance.",
    "descriptor": "\nComments: In part based on IMA Preprint 2372, available at: this https URL\n",
    "authors": [
      "Wen Cheng",
      "Anna L. Mazzucato",
      "Victor Nistor"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.00593"
  },
  {
    "id": "arXiv:2111.00598",
    "title": "Recognizing Families In the Wild (RFIW): The 5th Edition",
    "abstract": "Recognizing Families In the Wild (RFIW), held as a data challenge in\nconjunction with the 16th IEEE International Conference on Automatic Face and\nGesture Recognition (FG), is a large-scale, multi-track visual kinship\nrecognition evaluation. This is our fifth edition of RFIW, for which we\ncontinue the effort to attract scholars, bring together professionals, publish\nnew work, and discuss prospects. In this paper, we summarize submissions for\nthe three tasks of this year's RFIW: specifically, we review the results for\nkinship verification, tri-subject verification, and family member search and\nretrieval. We take a look at the RFIW problem, as well as share current efforts\nand make recommendations for promising future directions.",
    "descriptor": "\nComments: 2021 Conference on Automatic Face and Gesture Recognition\n",
    "authors": [
      "Joseph P. Robinson",
      "Can Qin",
      "Ming Shao",
      "Matthew A. Turk",
      "Rama Chellappa",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00598"
  },
  {
    "id": "arXiv:2111.00599",
    "title": "Bayesian optimization of distributed neurodynamical controller models  for spatial navigation",
    "abstract": "Dynamical systems models for controlling multi-agent swarms have demonstrated\nadvances toward resilient, decentralized navigation algorithms. We previously\nintroduced the NeuroSwarms controller, in which agent-based interactions were\nmodeled by analogy to neuronal network interactions, including attractor\ndynamics and phase synchrony, that have been theorized to operate within\nhippocampal place-cell circuits in navigating rodents. This complexity\nprecludes linear analyses of stability, controllability, and performance\ntypically used to study conventional swarm models. Further, tuning dynamical\ncontrollers by hand or grid search is often inadequate due to the complexity of\nobjectives, dimensionality of model parameters, and computational costs of\nsimulation-based sampling. Here, we present a framework for tuning dynamical\ncontroller models of autonomous multi-agent systems based on Bayesian\nOptimization (BayesOpt). Our approach utilizes a task-dependent objective\nfunction to train Gaussian Processes (GPs) as surrogate models to achieve\nadaptive and efficient exploration of a dynamical controller model's parameter\nspace. We demonstrate this approach by studying an objective function selecting\nfor NeuroSwarms behaviors that cooperatively localize and capture spatially\ndistributed rewards under time pressure. We generalized task performance across\nenvironments by combining scores for simulations in distinct geometries. To\nvalidate search performance, we compared high-dimensional clustering for high-\nvs. low-likelihood parameter points by visualizing sample trajectories in\nUniform Manifold Approximation and Projection (UMAP) embeddings. Our findings\nshow that adaptive, sample-efficient evaluation of the self-organizing\nbehavioral capacities of complex systems, including dynamical swarm\ncontrollers, can accelerate the translation of neuroscientific theory to\napplied domains.",
    "descriptor": "\nComments: 29 pages, 10 figures\n",
    "authors": [
      "Armin Hadzic",
      "Grace M. Hwang",
      "Kechen Zhang",
      "Kevin M. Schultz",
      "Joseph D. Monaco"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.00599"
  },
  {
    "id": "arXiv:2111.00600",
    "title": "Minimum Description Length Recurrent Neural Networks",
    "abstract": "We train neural networks to optimize a Minimum Description Length score,\ni.e., to balance between the complexity of the network and its accuracy at a\ntask. We show that networks trained with this objective function master tasks\ninvolving memory challenges such as counting, including cases that go beyond\ncontext-free languages. These learners master grammars for, e.g., $a^nb^n$,\n$a^nb^nc^n$, $a^nb^{2n}$, and $a^nb^mc^{n+m}$, and they perform addition. They\ndo so with 100% accuracy, sometimes also with 100% confidence. The networks are\nalso small and their inner workings are transparent. We thus provide formal\nproofs that their perfect accuracy holds not only on a given test set, but for\nany input sequence.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Nur Lan",
      "Michal Geyer",
      "Emmanuel Chemla",
      "Roni Katzir"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00600"
  },
  {
    "id": "arXiv:2111.00601",
    "title": "Explainable Artificial Intelligence for Smart City Application: A Secure  and Trusted Platform",
    "abstract": "Artificial Intelligence (AI) is one of the disruptive technologies that is\nshaping the future. It has growing applications for data-driven decisions in\nmajor smart city solutions, including transportation, education, healthcare,\npublic governance, and power systems. At the same time, it is gaining\npopularity in protecting critical cyber infrastructure from cyber threats,\nattacks, damages, or unauthorized access. However, one of the significant\nissues of those traditional AI technologies (e.g., deep learning) is that the\nrapid progress in complexity and sophistication propelled and turned out to be\nuninterpretable black boxes. On many occasions, it is very challenging to\nunderstand the decision and bias to control and trust systems' unexpected or\nseemingly unpredictable outputs. It is acknowledged that the loss of control\nover interpretability of decision-making becomes a critical issue for many\ndata-driven automated applications. But how may it affect the system's security\nand trustworthiness? This chapter conducts a comprehensive study of machine\nlearning applications in cybersecurity to indicate the need for explainability\nto address this question. While doing that, this chapter first discusses the\nblack-box problems of AI technologies for Cybersecurity applications in smart\ncity-based solutions. Later, considering the new technological paradigm,\nExplainable Artificial Intelligence (XAI), this chapter discusses the\ntransition from black-box to white-box. This chapter also discusses the\ntransition requirements concerning the interpretability, transparency,\nunderstandability, and Explainability of AI-based technologies in applying\ndifferent autonomous systems in smart cities. Finally, it has presented some\ncommercial XAI platforms that offer explainability over traditional AI\ntechnologies before presenting future challenges and opportunities.",
    "descriptor": "\nComments: Book_Chapter, Springer Nature\n",
    "authors": [
      "M. Humayn Kabir",
      "Khondokar Fida Hasan",
      "Mohammad Kamrul Hasan",
      "Keyvan Ansari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.00601"
  },
  {
    "id": "arXiv:2111.00602",
    "title": "On the Optimal Time/Space Tradeoff for Hash Tables",
    "abstract": "For nearly six decades, the central open question in the study of hash tables\nhas been to determine the optimal achievable tradeoff curve between time and\nspace. State-of-the-art hash tables offer the following guarantee: If\nkeys/values are Theta(log n) bits each, then it is possible to achieve\nconstant-time insertions/deletions/queries while wasting only O(loglog n) bits\nof space per key when compared to the information-theoretic optimum. Even prior\nto this bound being achieved, the target of O(loglog n) wasted bits per key was\nknown to be a natural end goal, and was proven to be optimal for a number of\nclosely related problems (e.g., stable hashing, dynamic retrieval, and\ndynamically-resized filters).\nThis paper shows that O(loglog n) wasted bits per key is not the end of the\nline for hashing. In fact, for any k \\in [log* n], it is possible to achieve\nO(k)-time insertions/deletions, O(1)-time queries, and O(\\log^{(k)} n) wasted\nbits per key (all with high probability in n). This means that, each time we\nincrease insertion/deletion time by an \\emph{additive constant}, we reduce the\nwasted bits per key \\emph{exponentially}. We further show that this tradeoff\ncurve is the best achievable by any of a large class of hash tables, including\nany hash table designed using the current framework for making constant-time\nhash tables succinct.",
    "descriptor": "\nComments: 48 pages\n",
    "authors": [
      "Michael A. Bender",
      "Mart\u00edn Farach-Colton",
      "John Kuszmaul",
      "William Kuszmaul"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.00602"
  },
  {
    "id": "arXiv:2111.00603",
    "title": "Optimization of a Millimeter-Wave UAV-to-Ground Network in Urban  Deployments",
    "abstract": "An urban tactical wireless network is considered wherein the base stations\nare situated on unmanned aerial vehicles (UAVs) that provide connectivity to\nground assets such as vehicles located on city streets. The UAVs are assumed to\nbe randomly deployed at a fixed height according to a two-dimensional point\nprocess. Millimeter-wave (mmWave) frequencies are used to avail of large\navailable bandwidths and spatial isolation due to beamforming. In urban\nenvironments, mmWave signals are prone to blocking of the line-of-sight (LoS)\nby buildings. While reflections are possible, the desire for consistent\nconnectivity places a strong preference on the existence of an unblocked LoS\npath. As such, the key performance metric considered in this paper is the\nconnectivity probability, which is the probability of an unblocked LoS path to\nat least one UAV within some maximum transmission distance. By leveraging tools\nfrom stochastic geometry, the connectivity probability is characterized as a\nfunction of the city type (e.g., urban, dense urban, suburban), density of UAVs\n(average number of UAVs per square km), and height of the UAVs. The city\nstreets are modeled as a Manhattan Poisson Line Process (MPLP) and the building\nheights are randomly distributed. The analysis first finds the connectivity\nprobability conditioned on a particular network realization (location of the\nUAVs) and then removes the conditioning to uncover the distribution of the\nconnectivity; i.e., the fraction of network realizations that will fail to meet\nan outage threshold. While related work has applied an MPLP to networks with a\nsingle UAV, the contributions of this paper are that it (1) considers networks\nof multiple UAVs, (2) characterizes the performance by a connectivity\ndistribution, and (3) identifies the optimal altitude for the UAVs.",
    "descriptor": "",
    "authors": [
      "Enass Hriba",
      "Matthew C. Valenti",
      "Robert W. Heath Jr"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00603"
  },
  {
    "id": "arXiv:2111.00604",
    "title": "Graph Embedding with Hierarchical Attentive Membership",
    "abstract": "The exploitation of graph structures is the key to effectively learning\nrepresentations of nodes that preserve useful information in graphs. A\nremarkable property of graph is that a latent hierarchical grouping of nodes\nexists in a global perspective, where each node manifests its membership to a\nspecific group based on the context composed by its neighboring nodes. Most\nprior works ignore such latent groups and nodes' membership to different\ngroups, not to mention the hierarchy, when modeling the neighborhood structure.\nThus, they fall short of delivering a comprehensive understanding of the nodes\nunder different contexts in a graph. In this paper, we propose a novel\nhierarchical attentive membership model for graph embedding, where the latent\nmemberships for each node are dynamically discovered based on its neighboring\ncontext. Both group-level and individual-level attentions are performed when\naggregating neighboring states to generate node embeddings. We introduce\nstructural constraints to explicitly regularize the inferred memberships of\neach node, such that a well-defined hierarchical grouping structure is\ncaptured. The proposed model outperformed a set of state-of-the-art graph\nembedding solutions on node classification and link prediction tasks in a\nvariety of graphs including citation networks and social networks. Qualitative\nevaluations visualize the learned node embeddings along with the inferred\nmemberships, which proved the concept of membership hierarchy and enables\nexplainable embedding learning in graphs.",
    "descriptor": "\nComments: to be published in WSDM 2022\n",
    "authors": [
      "Lu Lin",
      "Ethan Blaser",
      "Hongning Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.00604"
  },
  {
    "id": "arXiv:2111.00606",
    "title": "A posteriori error analysis for a space-time parallel discretization of  parabolic partial differential equations",
    "abstract": "We construct a space-time parallel method for solving parabolic partial\ndifferential equations by coupling the Parareal algorithm in time with\noverlapping domain decomposition in space. Reformulating the original Parareal\nalgorithm as a variational method and implementing a finite element\ndiscretization in space enables an adjoint-based a posteriori error analysis to\nbe performed. Through an appropriate choice of adjoint problems and residuals\nthe error analysis distinguishes between errors arising due to the temporal and\nspatial discretizations, as well as between the errors arising due to\nincomplete Parareal iterations and incomplete iterations of the domain\ndecomposition solver. We first develop an error analysis for the Parareal\nmethod applied to parabolic partial differential equations, and then refine\nthis analysis to the case where the associated spatial problems are solved\nusing overlapping domain decomposition. These constitute our Time Parallel\nAlgorithm (TPA) and Space-Time Parallel Algorithm (STPA) respectively.\nNumerical experiments demonstrate the accuracy of the estimator for both\nalgorithms and the iterations between distinct components of the error.",
    "descriptor": "",
    "authors": [
      "Jehanzeb Chaudhry",
      "Donald Estep",
      "Simon Tavener"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00606"
  },
  {
    "id": "arXiv:2111.00607",
    "title": "A Systematic Investigation of Commonsense Understanding in Large  Language Models",
    "abstract": "Large language models have shown impressive performance on many natural\nlanguage processing (NLP) tasks in a zero-shot setting. We ask whether these\nmodels exhibit commonsense understanding -- a critical component of NLP\napplications -- by evaluating models against four commonsense benchmarks. We\nfind that the impressive zero-shot performance of large language models is\nmostly due to existence of dataset bias in our benchmarks. We also show that\nthe zero-shot performance is sensitive to the choice of hyper-parameters and\nsimilarity of the benchmark to the pre-training datasets. Moreover, we did not\nobserve substantial improvements when evaluating models in a few-shot setting.\nFinally, in contrast to previous work, we find that leveraging explicit\ncommonsense knowledge does not yield substantial improvement.",
    "descriptor": "",
    "authors": [
      "Xiang Lorraine Li",
      "Adhi Kuncoro",
      "Cyprien de Masson d'Autume",
      "Phil Blunsom",
      "Aida Nematzadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00607"
  },
  {
    "id": "arXiv:2111.00609",
    "title": "Computational Aspects of Problems on Visibility and Disk Graph  Representations",
    "abstract": "This thesis focuses on two concepts which are widely studied in the field of\ncomputational geometry. Namely, visibility and unit disk graphs. In the field\nof visibility, we have studied the conflict-free chromatic guarding of\npolygons, for which we have described a polynomial-time algorithm that uses\n$O(n \\log^2 n)$ colors to guard a polygon in a conflict-free setting, and\nproper coloring of polygon visibility graphs, for which we have described an\nalgorithm that returns a proper 4-coloring for a simple polygon. Besides, we\nhave shown that the 5-colorability problem is NP-complete on visibility graphs\nof simple polygons, and 4-colorability is NP-complete on visibility graphs of\npolygons with holes.\nThen, we move further with the notion of visibility, and define a graph class\nwhich considers the real-world limitations for the applications of visibility\ngraphs. That is, no physical object has infinite range, and two objects might\nnot be mutually visible from a certain distance although there are no obstacles\nin-between. To model this property, we introduce unit disk visibility graphs,\nand show that the 3-colorability problem is NP-complete for unit disk\nvisibility graphs of a set of line segments, and a polygon with holes.\nAfter bridging the gap between the visibility and the unit disk graphs, we\nthen present our results on the recognition of unit disk graphs in a restricted\nsetting -- axes-parallel unit disk graphs. We show that the recognition of unit\ndisk graphs is NP-complete when the disks are centered on pre-given parallel\nlines. If, on the other hand, the lines are not parallel to one another, the\nrecognition problem is NP-hard even though the pre-given lines are\naxes-parallel (i.e. any pair is either parallel or perpendicular).",
    "descriptor": "\nComments: PhD thesis, 166 pages\n",
    "authors": [
      "Onur \u00c7a\u011f\u0131r\u0131c\u0131"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.00609"
  },
  {
    "id": "arXiv:2111.00610",
    "title": "Towards Language Modelling in the Speech Domain Using Sub-word  Linguistic Units",
    "abstract": "Language models (LMs) for text data have been studied extensively for their\nusefulness in language generation and other downstream tasks. However, language\nmodelling purely in the speech domain is still a relatively unexplored topic,\nwith traditional speech LMs often depending on auxiliary text LMs for learning\ndistributional aspects of the language. For the English language, these LMs\ntreat words as atomic units, which presents inherent challenges to language\nmodelling in the speech domain. In this paper, we propose a novel LSTM-based\ngenerative speech LM that is inspired by the CBOW model and built on linguistic\nunits including syllables and phonemes. This offers better acoustic consistency\nacross utterances in the dataset, as opposed to single melspectrogram frames,\nor whole words. With a limited dataset, orders of magnitude smaller than that\nrequired by contemporary generative models, our model closely approximates\nbabbling speech. We show the effect of training with auxiliary text LMs,\nmultitask learning objectives, and auxiliary articulatory features. Through our\nexperiments, we also highlight some well known, but poorly documented\nchallenges in training generative speech LMs, including the mismatch between\nthe supervised learning objective with which these models are trained such as\nMean Squared Error (MSE), and the true objective, which is speech quality. Our\nexperiments provide an early indication that while validation loss and Mel\nCepstral Distortion (MCD) are not strongly correlated with generated speech\nquality, traditional text language modelling metrics like perplexity and\nnext-token-prediction accuracy might be.",
    "descriptor": "",
    "authors": [
      "Anurag Katakkar",
      "Alan W Black"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.00610"
  },
  {
    "id": "arXiv:2111.00611",
    "title": "R-BERT-CNN: Drug-target interactions extraction from biomedical  literature",
    "abstract": "In this research, we present our work participation for the DrugProt task of\nBioCreative VII challenge. Drug-target interactions (DTIs) are critical for\ndrug discovery and repurposing, which are often manually extracted from the\nexperimental articles. There are >32M biomedical articles on PubMed and\nmanually extracting DTIs from such a huge knowledge base is challenging. To\nsolve this issue, we provide a solution for Track 1, which aims to extract 10\ntypes of interactions between drug and protein entities. We applied an Ensemble\nClassifier model that combines BioMed-RoBERTa, a state of art language model,\nwith Convolutional Neural Networks (CNN) to extract these relations. Despite\nthe class imbalances in the BioCreative VII DrugProt test corpus, our model\nachieves a good performance compared to the average of other submissions in the\nchallenge, with the micro F1 score of 55.67% (and 63% on BioCreative VI\nChemProt test corpus). The results show the potential of deep learning in\nextracting various types of DTIs.",
    "descriptor": "",
    "authors": [
      "Jehad Aldahdooh",
      "Ziaurrehman Tanoli",
      "Jing Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.00611"
  },
  {
    "id": "arXiv:2111.00612",
    "title": "An accurate, robust, and efficient finite element framework for  anisotropic, nearly and fully incompressible elasticity",
    "abstract": "Fiber-reinforced soft biological tissues are typically modeled as\nhyperelastic, anisotropic, and nearly incompressible materials. To enforce\nincompressibility a multiplicative split of the deformation gradient into a\nvolumetric and an isochoric part is a very common approach. However, due to the\nhigh stiffness of anisotropic materials in the preferred directions, the finite\nelement analysis of such problems often suffers from severe locking effects and\nnumerical instabilities. In this paper, we present novel methods to overcome\nlocking phenomena for anisotropic materials using stabilized P1-P1 elements. We\nintroduce different stabilization techniques and demonstrate the high\nrobustness and computational efficiency of the chosen methods. In several\nbenchmark problems we compare the approach to standard linear elements and show\nthe accuracy and versatility of the methods to simulate anisotropic, nearly and\nfully incompressible materials. We are convinced that this numerical framework\noffers the possibility to accelerate accurate simulations of biological\ntissues, enabling patient-specfic parameterization studies, which require\nnumerous forward simulations.",
    "descriptor": "\nComments: This research has received funding from the European Union's Horizon 2020 research and innovation programme under the ERA-NET co-fund action No. 680969 (ERA-CVD SICVALVES) funded by the Austrian Science Fund (FWF), Grant I 4652-B\n",
    "authors": [
      "Elias Karabelas",
      "Matthias A. F. Gsell",
      "Gundolf Haase",
      "Gernot Plank",
      "Christoph M. Augustin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.00612"
  },
  {
    "id": "arXiv:2111.00619",
    "title": "PIE: Pseudo-Invertible Encoder",
    "abstract": "We consider the problem of information compression from high dimensional\ndata. Where many studies consider the problem of compression by non-invertible\ntransformations, we emphasize the importance of invertible compression. We\nintroduce new class of likelihood-based autoencoders with pseudo bijective\narchitecture, which we call Pseudo Invertible Encoders. We provide the\ntheoretical explanation of their principles. We evaluate Gaussian Pseudo\nInvertible Encoder on MNIST, where our model outperforms WAE and VAE in\nsharpness of the generated images.",
    "descriptor": "",
    "authors": [
      "Jan Jetze Beitler",
      "Ivan Sosnovik",
      "Arnold Smeulders"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00619"
  },
  {
    "id": "arXiv:2111.00621",
    "title": "Clinical Evidence Engine: Proof-of-Concept For A  Clinical-Domain-Agnostic Decision Support Infrastructure",
    "abstract": "Abstruse learning algorithms and complex datasets increasingly characterize\nmodern clinical decision support systems (CDSS). As a result, clinicians cannot\neasily or rapidly scrutinize the CDSS recommendation when facing a difficult\ndiagnosis or treatment decision in practice. Over-trust or under-trust are\nfrequent. Prior research has explored supporting such assessments by explaining\nDST data inputs and algorithmic mechanisms. This paper explores a different\napproach: Providing precisely relevant, scientific evidence from biomedical\nliterature. We present a proof-of-concept system, Clinical Evidence Engine, to\ndemonstrate the technical and design feasibility of this approach across three\ndomains (cardiovascular diseases, autism, cancer). Leveraging Clinical BioBERT,\nthe system can effectively identify clinical trial reports based on lengthy\nclinical questions (e.g., \"risks of catheter infection among adult patients in\nintensive care unit who require arterial catheters, if treated with povidone\niodine-alcohol\"). This capability enables the system to identify clinical\ntrials relevant to diagnostic/treatment hypotheses -- a clinician's or a\nCDSS's. Further, Clinical Evidence Engine can identify key parts of a clinical\ntrial abstract, including patient population (e.g., adult patients in intensive\ncare unit who require arterial catheters), intervention (povidone\niodine-alcohol), and outcome (risks of catheter infection). This capability\nopens up the possibility of enabling clinicians to 1) rapidly determine the\nmatch between a clinical trial and a clinical question, and 2) understand the\nresult and contexts of the trial without extensive reading. We demonstrate this\npotential by illustrating two example use scenarios of the system. We discuss\nthe idea of designing DST explanations not as specific to a DST or an\nalgorithm, but as a domain-agnostic decision support infrastructure.",
    "descriptor": "",
    "authors": [
      "Bojian Hou",
      "Hao Zhang",
      "Gur Ladizhinsky",
      "Gur Ladizhinsky",
      "Stephen Yang",
      "Volodymyr Kuleshov",
      "Fei Wang",
      "Qian Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.00621"
  },
  {
    "id": "arXiv:2111.00622",
    "title": "Deep Recursive Embedding for High-Dimensional Data",
    "abstract": "Embedding high-dimensional data onto a low-dimensional manifold is of both\ntheoretical and practical value. In this paper, we propose to combine deep\nneural networks (DNN) with mathematics-guided embedding rules for\nhigh-dimensional data embedding. We introduce a generic deep embedding network\n(DEN) framework, which is able to learn a parametric mapping from\nhigh-dimensional space to low-dimensional space, guided by well-established\nobjectives such as Kullback-Leibler (KL) divergence minimization. We further\npropose a recursive strategy, called deep recursive embedding (DRE), to make\nuse of the latent data representations for boosted embedding performance. We\nexemplify the flexibility of DRE by different architectures and loss functions,\nand benchmarked our method against the two most popular embedding methods,\nnamely, t-distributed stochastic neighbor embedding (t-SNE) and uniform\nmanifold approximation and projection (UMAP). The proposed DRE method can map\nout-of-sample data and scale to extremely large datasets. Experiments on a\nrange of public datasets demonstrated improved embedding performance in terms\nof local and global structure preservation, compared with other\nstate-of-the-art embedding methods.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2104.05171\n",
    "authors": [
      "Zixia Zhou",
      "Xinrui Zu",
      "Yuanyuan Wang",
      "Boudewijn P.F. Lelieveldt",
      "Qian Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.00622"
  },
  {
    "id": "arXiv:2111.00626",
    "title": "Intrusion Detection using Spatial-Temporal features based on Riemannian  Manifold",
    "abstract": "Network traffic data is a combination of different data bytes packets under\ndifferent network protocols. These traffic packets have complex time-varying\nnon-linear relationships. Existing state-of-the-art methods rise up to this\nchallenge by fusing features into multiple subsets based on correlations and\nusing hybrid classification techniques that extract spatial and temporal\ncharacteristics. This often requires high computational cost and manual support\nthat limit them for real-time processing of network traffic. To address this,\nwe propose a new novel feature extraction method based on covariance matrices\nthat extract spatial-temporal characteristics of network traffic data for\ndetecting malicious network traffic behavior. The covariance matrices in our\nproposed method not just naturally encode the mutual relationships between\ndifferent network traffic values but also have well-defined geometry that falls\nin the Riemannian manifold. Riemannian manifold is embedded with distance\nmetrics that facilitate extracting discriminative features for detecting\nmalicious network traffic. We evaluated our model on NSL-KDD and UNSW-NB15\ndatasets and showed our proposed method significantly outperforms the\nconventional method and other existing studies on the dataset.",
    "descriptor": "",
    "authors": [
      "Amardeep Singh",
      "Julian Jang-Jaccard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00626"
  },
  {
    "id": "arXiv:2111.00629",
    "title": "Distantly Supervised Semantic Text Detection and Recognition for  Broadcast Sports Videos Understanding",
    "abstract": "Comprehensive understanding of key players and actions in multiplayer sports\nbroadcast videos is a challenging problem. Unlike in news or finance videos,\nsports videos have limited text. While both action recognition for multiplayer\nsports and detection of players has seen robust research, understanding\ncontextual text in video frames still remains one of the most impactful avenues\nof sports video understanding. In this work we study extremely accurate\nsemantic text detection and recognition in sports clocks, and challenges\ntherein. We observe unique properties of sports clocks, which makes it hard to\nutilize general-purpose pre-trained detectors and recognizers, so that text can\nbe accurately understood to the degree of being used to align to external\nknowledge. We propose a novel distant supervision technique to automatically\nbuild sports clock datasets. Along with suitable data augmentations, combined\nwith any state-of-the-art text detection and recognition model architectures,\nwe extract extremely accurate semantic text. Finally, we share our\ncomputational architecture pipeline to scale this system in industrial setting\nand proposed a robust dataset for the same to validate our results.",
    "descriptor": "\nComments: 9 pages, 7 figures and 6 tables. To be published in the proceedings of ACM Multimedia 21, Industrial Track, held from October 20-24 in China\n",
    "authors": [
      "Avijit Shah",
      "Topojoy Biswas",
      "Sathish Ramadoss",
      "Deven Santosh Shah"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00629"
  },
  {
    "id": "arXiv:2111.00631",
    "title": "Safe Learning of Linear Time-Invariant Systems",
    "abstract": "We consider safety in simultaneous learning and control of discrete-time\nlinear time-invariant systems. We provide rigorous confidence bounds on the\nlearned model of the system based on the number of utilized state measurements.\nThese bounds are used to modify control inputs to the system via an\noptimization problem with potentially time-varying safety constraints. We prove\nthat the state can only exit the safe set with small probability, provided a\nfeasible solution to the safety-constrained optimization exists. This\noptimization problem is then reformulated in a more computationally-friendly\nformat by tightening the safety constraints to account for model uncertainty\nduring learning. The tightening decreases as the confidence in the learned\nmodel improves. We finally prove that, under persistence of excitation, the\ntightening becomes negligible as more measurements are gathered.",
    "descriptor": "\nComments: Accepted in NeurIPS 2021 Workshop on Safe and Robust Control of Uncertain Systems\n",
    "authors": [
      "Farhad Farokhi",
      "Alex S. Leong",
      "Mohammad Zamani",
      "Iman Shames"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00631"
  },
  {
    "id": "arXiv:2111.00633",
    "title": "Settling the Horizon-Dependence of Sample Complexity in Reinforcement  Learning",
    "abstract": "Recently there is a surge of interest in understanding the horizon-dependence\nof the sample complexity in reinforcement learning (RL). Notably, for an RL\nenvironment with horizon length $H$, previous work have shown that there is a\nprobably approximately correct (PAC) algorithm that learns an $O(1)$-optimal\npolicy using $\\mathrm{polylog}(H)$ episodes of environment interactions when\nthe number of states and actions is fixed. It is yet unknown whether the\n$\\mathrm{polylog}(H)$ dependence is necessary or not. In this work, we resolve\nthis question by developing an algorithm that achieves the same PAC guarantee\nwhile using only $O(1)$ episodes of environment interactions, completely\nsettling the horizon-dependence of the sample complexity in RL. We achieve this\nbound by (i) establishing a connection between value functions in discounted\nand finite-horizon Markov decision processes (MDPs) and (ii) a novel\nperturbation analysis in MDPs. We believe our new techniques are of independent\ninterest and could be applied in related questions in RL.",
    "descriptor": "",
    "authors": [
      "Yuanzhi Li",
      "Ruosong Wang",
      "Lin F. Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00633"
  },
  {
    "id": "arXiv:2111.00637",
    "title": "To Talk or to Work: Delay Efficient Federated Learning over Mobile Edge  Devices",
    "abstract": "Federated learning (FL), an emerging distributed machine learning paradigm,\nin conflux with edge computing is a promising area with novel applications over\nmobile edge devices. In FL, since mobile devices collaborate to train a model\nbased on their own data under the coordination of a central server by sharing\njust the model updates, training data is maintained private. However, without\nthe central availability of data, computing nodes need to communicate the model\nupdates often to attain convergence. Hence, the local computation time to\ncreate local model updates along with the time taken for transmitting them to\nand from the server result in a delay in the overall time. Furthermore,\nunreliable network connections may obstruct an efficient communication of these\nupdates. To address these, in this paper, we propose a delay-efficient FL\nmechanism that reduces the overall time (consisting of both the computation and\ncommunication latencies) and communication rounds required for the model to\nconverge. Exploring the impact of various parameters contributing to delay, we\nseek to balance the trade-off between wireless communication (to talk) and\nlocal computation (to work). We formulate a relation with overall time as an\noptimization problem and demonstrate the efficacy of our approach through\nextensive simulations.",
    "descriptor": "\nComments: Accepted for publication in Globecom'21\n",
    "authors": [
      "Pavana Prakash",
      "Jiahao Ding",
      "Maoqiang Wu",
      "Minglei Shu",
      "Rong Yu",
      "Miao Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.00637"
  },
  {
    "id": "arXiv:2111.00640",
    "title": "VSEC: Transformer-based Model for Vietnamese Spelling Correction",
    "abstract": "Spelling error correction is one of topics which have a long history in\nnatural language processing. Although previous studies have achieved remarkable\nresults, challenges still exist. In the Vietnamese language, a state-of-the-art\nmethod for the task infers a syllable's context from its adjacent syllables.\nThe method's accuracy can be unsatisfactory, however, because the model may\nlose the context if two (or more) spelling mistakes stand near each other. In\nthis paper, we propose a novel method to correct Vietnamese spelling errors. We\ntackle the problems of mistyped errors and misspelled errors by using a deep\nlearning model. The embedding layer, in particular, is powered by the byte pair\nencoding technique. The sequence to sequence model based on the Transformer\narchitecture makes our approach different from the previous works on the same\nproblem. In the experiment, we train the model with a large synthetic dataset,\nwhich is randomly introduced spelling errors. We test the performance of the\nproposed method using a realistic dataset. This dataset contains 11,202\nhuman-made misspellings in 9,341 different Vietnamese sentences. The\nexperimental results show that our method achieves encouraging performance with\n86.8% errors detected and 81.5% errors corrected, which improves the\nstate-of-the-art approach 5.6% and 2.2%, respectively.",
    "descriptor": "",
    "authors": [
      "Dinh-Truong Do",
      "Ha Thanh Nguyen",
      "Thang Ngoc Bui",
      "Dinh Hieu Vo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00640"
  },
  {
    "id": "arXiv:2111.00643",
    "title": "Learning Distilled Collaboration Graph for Multi-Agent Perception",
    "abstract": "To promote better performance-bandwidth trade-off for multi-agent perception,\nwe propose a novel distilled collaboration graph (DiscoGraph) to model\ntrainable, pose-aware, and adaptive collaboration among agents. Our key\nnovelties lie in two aspects. First, we propose a teacher-student framework to\ntrain DiscoGraph via knowledge distillation. The teacher model employs an early\ncollaboration with holistic-view inputs; the student model is based on\nintermediate collaboration with single-view inputs. Our framework trains\nDiscoGraph by constraining post-collaboration feature maps in the student model\nto match the correspondences in the teacher model. Second, we propose a\nmatrix-valued edge weight in DiscoGraph. In such a matrix, each element\nreflects the inter-agent attention at a specific spatial region, allowing an\nagent to adaptively highlight the informative regions. During inference, we\nonly need to use the student model named as the distilled collaboration network\n(DiscoNet). Attributed to the teacher-student framework, multiple agents with\nthe shared DiscoNet could collaboratively approach the performance of a\nhypothetical teacher model with a holistic view. Our approach is validated on\nV2X-Sim 1.0, a large-scale multi-agent perception dataset that we synthesized\nusing CARLA and SUMO co-simulation. Our quantitative and qualitative\nexperiments in multi-agent 3D object detection show that DiscoNet could not\nonly achieve a better performance-bandwidth trade-off than the state-of-the-art\ncollaborative perception methods, but also bring more straightforward design\nrationale. Our code is available on https://github.com/ai4ce/DiscoNet.",
    "descriptor": "\nComments: Accepted to 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Yiming Li",
      "Shunli Ren",
      "Pengxiang Wu",
      "Siheng Chen",
      "Chen Feng",
      "Wenjun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00643"
  },
  {
    "id": "arXiv:2111.00648",
    "title": "Accurate Point Cloud Registration with Robust Optimal Transport",
    "abstract": "This work investigates the use of robust optimal transport (OT) for shape\nmatching. Specifically, we show that recent OT solvers improve both\noptimization-based and deep learning methods for point cloud registration,\nboosting accuracy at an affordable computational cost. This manuscript starts\nwith a practical overview of modern OT theory. We then provide solutions to the\nmain difficulties in using this framework for shape matching. Finally, we\nshowcase the performance of transport-enhanced registration models on a wide\nrange of challenging tasks: rigid registration for partial shapes; scene flow\nestimation on the Kitti dataset; and nonparametric registration of lung\nvascular trees between inspiration and expiration. Our OT-based methods achieve\nstate-of-the-art results on Kitti and for the challenging lung registration\ntask, both in terms of accuracy and scalability. We also release PVT1010, a new\npublic dataset of 1,010 pairs of lung vascular trees with densely sampled\npoints. This dataset provides a challenging use case for point cloud\nregistration algorithms with highly complex shapes and deformations. Our work\ndemonstrates that robust OT enables fast pre-alignment and fine-tuning for a\nwide range of registration models, thereby providing a new key method for the\ncomputer vision toolbox. Our code and dataset are available online at:\nhttps://github.com/uncbiag/robot.",
    "descriptor": "\nComments: Accepted in NeurIPS 2021\n",
    "authors": [
      "Zhengyang Shen",
      "Jean Feydy",
      "Peirong Liu",
      "Ariel Hern\u00e1n Curiale",
      "Ruben San Jose Estepar",
      "Raul San Jose Estepar",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2111.00648"
  },
  {
    "id": "arXiv:2111.00649",
    "title": "Interpolatory tensorial reduced order models for parametric dynamical  systems",
    "abstract": "The paper introduces a reduced order model (ROM) for numerical integration of\na dynamical system which depends on multiple parameters. The ROM is a\nprojection of the dynamical system on a low dimensional space that is both\nproblem-dependent and parameter-specific. The ROM exploits compressed tensor\nformats to find a low rank representation for a sample of high-fidelity\nsnapshots of the system state. This tensorial representation provides ROM with\nan orthogonal basis in a universal space of all snapshots and encodes\ninformation about the state variation in parameter domain. During the online\nphase and for any incoming parameter, this information is used to find a\nreduced basis that spans a parameter-specific subspace in the universal space.\nThe computational cost of the online phase then depends only on tensor\ncompression ranks, but not on space or time resolution of high-fidelity\ncomputations. Moreover, certain compressed tensor formats enable to avoid the\nadverse effect of parameter space dimension on the online costs (known as the\ncurse of dimension). The analysis of the approach includes an estimate for the\nrepresentation power of the acquired ROM basis. We illustrate the performance\nand prediction properties of the ROM with several numerical experiments, where\ntensorial ROM's complexity and accuracy is compared to those of conventional\nPOD-ROM.",
    "descriptor": "",
    "authors": [
      "Alexander V. Mamonov",
      "Maxim A. Olshanskii"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.00649"
  },
  {
    "id": "arXiv:2111.00653",
    "title": "SADGA: Structure-Aware Dual Graph Aggregation Network for Text-to-SQL",
    "abstract": "The Text-to-SQL task, aiming to translate the natural language of the\nquestions into SQL queries, has drawn much attention recently. One of the most\nchallenging problems of Text-to-SQL is how to generalize the trained model to\nthe unseen database schemas, also known as the cross-domain Text-to-SQL task.\nThe key lies in the generalizability of (i) the encoding method to model the\nquestion and the database schema and (ii) the question-schema linking method to\nlearn the mapping between words in the question and tables/columns in the\ndatabase schema. Focusing on the above two key issues, we propose a\nStructure-Aware Dual Graph Aggregation Network (SADGA) for cross-domain\nText-to-SQL. In SADGA, we adopt the graph structure to provide a unified\nencoding model for both the natural language question and database schema.\nBased on the proposed unified modeling, we further devise a structure-aware\naggregation method to learn the mapping between the question-graph and\nschema-graph. The structure-aware aggregation method is featured with Global\nGraph Linking, Local Graph Linking, and Dual-Graph Aggregation Mechanism. We\nnot only study the performance of our proposal empirically but also achieved\n3rd place on the challenging Text-to-SQL benchmark Spider at the time of\nwriting.",
    "descriptor": "\nComments: Paper accepted at the 35th Conference on Neural Information Processing Systems(NeurIPS 2021)\n",
    "authors": [
      "Ruichu Cai",
      "Jinjie Yuan",
      "Boyan Xu",
      "Zhifeng Hao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00653"
  },
  {
    "id": "arXiv:2111.00655",
    "title": "Collage: Automated Integration of Deep Learning Backends",
    "abstract": "Strong demands for efficient deployment of Deep Learning (DL) applications\nprompt the rapid development of a rich DL ecosystem. To keep up with its fast\nadvancement, it is crucial for DL frameworks to efficiently integrate a variety\nof optimized libraries and runtimes as their backends and generate the fastest\npossible executable by using them properly. However, current DL frameworks\nrequire significant manual effort to integrate diverse backends and often fail\nto deliver high performance. In this paper, we propose Collage, an automatic\nframework for integrating DL backends. Collage provides a backend registration\ninterface that allows users to precisely specify the capability of various\nbackends. By leveraging the specifications of available backends, Collage\nsearches for an optimized backend placement for a given workload and execution\nenvironment. Our evaluation shows that Collage automatically integrates\nmultiple backends together without manual intervention, and outperforms\nexisting frameworks by 1.21x, 1.39x, 1.40x on two different NVIDIA GPUs and an\nIntel CPU respectively.",
    "descriptor": "",
    "authors": [
      "Byungsoo Jeon",
      "Sunghyun Park",
      "Peiyuan Liao",
      "Sheng Xu",
      "Tianqi Chen",
      "Zhihao Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00655"
  },
  {
    "id": "arXiv:2111.00657",
    "title": "TriVoC: Efficient Voting-based Consensus Maximization for Robust Point  Cloud Registration with Extreme Outlier Ratios",
    "abstract": "Correspondence-based point cloud registration is a cornerstone in robotics\nperception and computer vision, which seeks to estimate the best rigid\ntransformation aligning two point clouds from the putative correspondences.\nHowever, due to the limited robustness of 3D keypoint matching approaches,\noutliers, probably in large numbers, are prone to exist among the\ncorrespondences, which makes robust registration methods imperative.\nUnfortunately, existing robust methods have their own limitations (e.g. high\ncomputational cost or limited robustness) when facing high or extreme outlier\nratios, probably unsuitable for practical use. In this paper, we present a\nnovel, fast, deterministic and guaranteed robust solver, named TriVoC\n(Triple-layered Voting with Consensus maximization), for the robust\nregistration problem. We decompose the selecting of the minimal 3-point sets\ninto 3 consecutive layers, and in each layer we design an efficient voting and\ncorrespondence sorting framework on the basis of the pairwise equal-length\nconstraint. In this manner, the 3-point sets can be selected independently from\nthe reduced correspondence sets according to the sorted sequence, which can\nsignificantly lower the computational cost and meanwhile provide a strong\nguarantee to achieve the largest consensus set (as the final inlier set) as\nlong as a probabilistic termination condition is fulfilled. Varied experiments\nshow that our solver TriVoC is robust against up to 99% outliers, highly\naccurate, time-efficient even with extreme outlier ratios, and also practical\nfor real-world applications, showing performance superior to other\nstate-of-the-art competitors.",
    "descriptor": "",
    "authors": [
      "Lei Sun",
      "Lu Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00657"
  },
  {
    "id": "arXiv:2111.00658",
    "title": "RMNA: A Neighbor Aggregation-Based Knowledge Graph Representation  Learning Model Using Rule Mining",
    "abstract": "Although the state-of-the-art traditional representation learning (TRL)\nmodels show competitive performance on knowledge graph completion, there is no\nparameter sharing between the embeddings of entities, and the connections\nbetween entities are weak. Therefore, neighbor aggregation-based representation\nlearning (NARL) models are proposed, which encode the information in the\nneighbors of an entity into its embeddings. However, existing NARL models\neither only utilize one-hop neighbors, ignoring the information in multi-hop\nneighbors, or utilize multi-hop neighbors by hierarchical neighbor aggregation,\ndestroying the completeness of multi-hop neighbors. In this paper, we propose a\nNARL model named RMNA, which obtains and filters horn rules through a rule\nmining algorithm, and uses selected horn rules to transform valuable multi-hop\nneighbors into one-hop neighbors, therefore, the information in valuable\nmulti-hop neighbors can be completely utilized by aggregating these one-hop\nneighbors. In experiments, we compare RMNA with the state-of-the-art TRL models\nand NARL models. The results show that RMNA has a competitive performance.",
    "descriptor": "\nComments: 22 pages, 2 figures\n",
    "authors": [
      "Ling Chen",
      "Jun Cui",
      "Xing Tang",
      "Chaodu Song",
      "Yuntao Qian",
      "Yansheng Li",
      "Yongjun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00658"
  },
  {
    "id": "arXiv:2111.00659",
    "title": "Feature Aggregation and Refinement Network for 2D AnatomicalLandmark  Detection",
    "abstract": "Localization of anatomical landmarks is essential for clinical diagnosis,\ntreatment planning, and research. In this paper, we propose a novel deep\nnetwork, named feature aggregation and refinement network (FARNet), for the\nautomatic detection of anatomical landmarks. To alleviate the problem of\nlimited training data in the medical domain, our network adopts a deep network\npre-trained on natural images as the backbone network and several popular\nnetworks have been compared. Our FARNet also includes a multi-scale feature\naggregation module for multi-scale feature fusion and a feature refinement\nmodule for high-resolution heatmap regression. Coarse-to-fine supervisions are\napplied to the two modules to facilitate the end-to-end training. We further\npropose a novel loss function named Exponential Weighted Center loss for\naccurate heatmap regression, which focuses on the losses from the pixels near\nlandmarks and suppresses the ones from far away. Our network has been evaluated\non three publicly available anatomical landmark detection datasets, including\ncephalometric radiographs, hand radiographs, and spine radiographs, and\nachieves state-of-art performances on all three datasets. Code is available at:\n\\url{https://github.com/JuvenileInWind/FARNet}",
    "descriptor": "",
    "authors": [
      "Yueyuan Ao",
      "Hong Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00659"
  },
  {
    "id": "arXiv:2111.00660",
    "title": "Evaluation of Human and Machine Face Detection using a Novel Distinctive  Human Appearance Dataset",
    "abstract": "Face detection is a long-standing challenge in the field of computer vision,\nwith the ultimate goal being to accurately localize human faces in an\nunconstrained environment. There are significant technical hurdles in making\nthese systems accurate due to confounding factors related to pose, image\nresolution, illumination, occlusion, and viewpoint \\cite{merler2019diversity}.\nThat being said, with recent developments in machine learning, face-detection\nsystems have achieved extraordinary accuracy, largely built on data-driven\ndeep-learning models \\cite{wang2017detecting}. Though encouraging, a critical\naspect that limits face-detection performance and social responsibility of\ndeployed systems is the inherent diversity of human appearance. Every human\nappearance reflects something unique about a person, including their heritage,\nidentity, experiences, and visible manifestations of self-expression. However,\nthere are questions about how well face-detection systems perform when faced\nwith varying face size and shape, skin color, body modification, and body\nornamentation. Towards this goal, we collected the Distinctive Human Appearance\ndataset, an image set that represents appearances with low frequency and that\ntend to be undersampled in face datasets. Then, we evaluated current\nstate-of-the-art face-detection models in their ability to detect faces in\nthese images. The evaluation results show that face-detection algorithms do not\ngeneralize well to these diverse appearances. Evaluating and characterizing the\nstate of current face-detection models will accelerate research and development\ntowards creating fairer and more accurate face-detection systems.",
    "descriptor": "",
    "authors": [
      "Necdet Gurkan",
      "Jordan W. Suchow"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00660"
  },
  {
    "id": "arXiv:2111.00664",
    "title": "Optimal Sketching for Trace Estimation",
    "abstract": "Matrix trace estimation is ubiquitous in machine learning applications and\nhas traditionally relied on Hutchinson's method, which requires\n$O(\\log(1/\\delta)/\\epsilon^2)$ matrix-vector product queries to achieve a $(1\n\\pm \\epsilon)$-multiplicative approximation to $\\text{tr}(A)$ with failure\nprobability $\\delta$ on positive-semidefinite input matrices $A$. Recently, the\nHutch++ algorithm was proposed, which reduces the number of matrix-vector\nqueries from $O(1/\\epsilon^2)$ to the optimal $O(1/\\epsilon)$, and the\nalgorithm succeeds with constant probability. However, in the high probability\nsetting, the non-adaptive Hutch++ algorithm suffers an extra\n$O(\\sqrt{\\log(1/\\delta)})$ multiplicative factor in its query complexity.\nNon-adaptive methods are important, as they correspond to sketching algorithms,\nwhich are mergeable, highly parallelizable, and provide low-memory streaming\nalgorithms as well as low-communication distributed protocols. In this work, we\nclose the gap between non-adaptive and adaptive algorithms, showing that even\nnon-adaptive algorithms can achieve $O(\\sqrt{\\log(1/\\delta)}/\\epsilon +\n\\log(1/\\delta))$ matrix-vector products. In addition, we prove matching lower\nbounds demonstrating that, up to a $\\log \\log(1/\\delta)$ factor, no further\nimprovement in the dependence on $\\delta$ or $\\epsilon$ is possible by any\nnon-adaptive algorithm. Finally, our experiments demonstrate the superior\nperformance of our sketch over the adaptive Hutch++ algorithm, which is less\nparallelizable, as well as over the non-adaptive Hutchinson's method.",
    "descriptor": "\nComments: 31 pages, 5 figures. Proceedings of the 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia\n",
    "authors": [
      "Shuli Jiang",
      "Hai Pham",
      "David P. Woodruff",
      "Qiuyi",
      "Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00664"
  },
  {
    "id": "arXiv:2111.00667",
    "title": "Unsupervised Domain Adaptation with Adapter",
    "abstract": "Unsupervised domain adaptation (UDA) with pre-trained language models (PrLM)\nhas achieved promising results since these pre-trained models embed generic\nknowledge learned from various domains. However, fine-tuning all the parameters\nof the PrLM on a small domain-specific corpus distort the learned generic\nknowledge, and it is also expensive to deployment a whole fine-tuned PrLM for\neach domain. This paper explores an adapter-based fine-tuning approach for\nunsupervised domain adaptation. Specifically, several trainable adapter modules\nare inserted in a PrLM, and the embedded generic knowledge is preserved by\nfixing the parameters of the original PrLM at fine-tuning. A domain-fusion\nscheme is introduced to train these adapters using a mix-domain corpus to\nbetter capture transferable features. Elaborated experiments on two benchmark\ndatasets are carried out, and the results demonstrate that our approach is\neffective with different tasks, dataset sizes, and domain similarities.",
    "descriptor": "\nComments: Accepted by NeurIPS2021 workshop\n",
    "authors": [
      "Rongsheng Zhang",
      "Yinhe Zheng",
      "Xiaoxi Mao",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00667"
  },
  {
    "id": "arXiv:2111.00668",
    "title": "Improved Algorithms for Low Rank Approximation from Sparsity",
    "abstract": "We overcome two major bottlenecks in the study of low rank approximation by\nassuming the low rank factors themselves are sparse. Specifically, (1) for low\nrank approximation with spectral norm error, we show how to improve the best\nknown $\\mathsf{nnz}(\\mathbf A) k / \\sqrt{\\varepsilon}$ running time to\n$\\mathsf{nnz}(\\mathbf A)/\\sqrt{\\varepsilon}$ running time plus low order terms\ndepending on the sparsity of the low rank factors, and (2) for streaming\nalgorithms for Frobenius norm error, we show how to bypass the known\n$\\Omega(nk/\\varepsilon)$ memory lower bound and obtain an $s k (\\log n)/\n\\mathrm{poly}(\\varepsilon)$ memory bound, where $s$ is the number of non-zeros\nof each low rank factor. Although this algorithm is inefficient, as it must be\nunder standard complexity theoretic assumptions, we also present polynomial\ntime algorithms using $\\mathrm{poly}(s,k,\\log n,\\varepsilon^{-1})$ memory that\noutput rank $k$ approximations supported on a $O(sk/\\varepsilon)\\times\nO(sk/\\varepsilon)$ submatrix.\nBoth the prior $\\mathsf{nnz}(\\mathbf A) k / \\sqrt{\\varepsilon}$ running time\nand the $nk/\\varepsilon$ memory for these problems were long-standing barriers;\nour results give a natural way of overcoming them assuming sparsity of the low\nrank factors.",
    "descriptor": "\nComments: To appear in SODA 2022\n",
    "authors": [
      "David P. Woodruff",
      "Taisuke Yasuda"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00668"
  },
  {
    "id": "arXiv:2111.00670",
    "title": "Comparative Explanations of Recommendations",
    "abstract": "As recommendation is essentially a comparative (or ranking) process, a good\nexplanation should illustrate to users why an item is believed to be better\nthan another, i.e., comparative explanations about the recommended items.\nIdeally, after reading the explanations, a user should reach the same ranking\nof items as the system's. Unfortunately, little research attention has yet been\npaid on such comparative explanations.\nIn this work, we develop an extract-and-refine architecture to explain the\nrelative comparisons among a set of ranked items from a recommender system. For\neach recommended item, we first extract one sentence from its associated\nreviews that best suits the desired comparison against a set of reference\nitems. Then this extracted sentence is further articulated with respect to the\ntarget user through a generative model to better explain why the item is\nrecommended. We design a new explanation quality metric based on BLEU to guide\nthe end-to-end training of the extraction and refinement components, which\navoids generation of generic content. Extensive offline evaluations on two\nlarge recommendation benchmark datasets and serious user studies against an\narray of state-of-the-art explainable recommendation algorithms demonstrate the\nnecessity of comparative explanations and the effectiveness of our solution.",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "Aobo Yang",
      "Nan Wang",
      "Renqin Cai",
      "Hongbo Deng",
      "Hongning Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00670"
  },
  {
    "id": "arXiv:2111.00673",
    "title": "Decoding of Polar Codes Based on Q-Learning-Driven Belief Propagation",
    "abstract": "This paper presents an enhanced belief propagation (BP) decoding algorithm\nand a reinforcement learning-based BP decoding algorithm for polar codes. The\nenhanced BP algorithm weighs each Processing Element (PE) input based on their\nsignals and Euclidean distances using a heuristic metric. The proposed\nreinforcement learning-based BP decoding strategy relies on reweighting the\nmessages and consists of two steps: we first weight each PE input based on\ntheir signals and Euclidean distances using a heuristic metric, then a\nQ-learning algorithm (QLBP) is employed to figure out the best correction\nfactor for successful decoding. Simulations show that the proposed enhanced BP\nand QLBP decoders outperform the successive cancellation (SC) and belief\npropagation (BP) decoders, and approach the SCL decoders.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "L. M. Oliveira",
      "R. M. Oliveira",
      "R. C. de Lamare"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00673"
  },
  {
    "id": "arXiv:2111.00674",
    "title": "Distilling Object Detectors with Feature Richness",
    "abstract": "In recent years, large-scale deep models have achieved great success, but the\nhuge computational complexity and massive storage requirements make it a great\nchallenge to deploy them in resource-limited devices. As a model compression\nand acceleration method, knowledge distillation effectively improves the\nperformance of small models by transferring the dark knowledge from the teacher\ndetector. However, most of the existing distillation-based detection methods\nmainly imitating features near bounding boxes, which suffer from two\nlimitations. First, they ignore the beneficial features outside the bounding\nboxes. Second, these methods imitate some features which are mistakenly\nregarded as the background by the teacher detector. To address the above\nissues, we propose a novel Feature-Richness Score (FRS) method to choose\nimportant features that improve generalized detectability during distilling.\nThe proposed method effectively retrieves the important features outside the\nbounding boxes and removes the detrimental features within the bounding boxes.\nExtensive experiments show that our methods achieve excellent performance on\nboth anchor-based and anchor-free detectors. For example, RetinaNet with\nResNet-50 achieves 39.7% in mAP on the COCO2017 dataset, which even surpasses\nthe ResNet-101 based teacher detector 38.9% by 0.8%.",
    "descriptor": "\nComments: 9 pages, 5 figures, 4 tables\n",
    "authors": [
      "Zhixing Du",
      "Rui Zhang",
      "Ming Chang",
      "Xishan Zhang",
      "Shaoli Liu",
      "Tianshi Chen",
      "Tianshi Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00674"
  },
  {
    "id": "arXiv:2111.00677",
    "title": "Domain-adaptation of spherical embeddings",
    "abstract": "Domain adaptation of embedding models, updating a generic embedding to the\nlanguage of a specific domain, is a proven technique for domains that have\ninsufficient data to train an effective model from scratch. Chemistry\npublications is one such domain, where scientific jargon and overloaded\nterminology inhibit the performance of a general language model. The recent\nspherical embedding model (JoSE) proposed in arXiv:1911.01196 jointly learns\nword and document embeddings during training on the multi-dimensional unit\nsphere, which performs well for document classification and word correlation\ntasks. But, we show a non-convergence caused by global rotations during its\ntraining prevents it from domain adaptation. In this work, we develop methods\nto counter the global rotation of the embedding space and propose strategies to\nupdate words and documents during domain specific training. Two new document\nclassification data-sets are collated from general and chemistry scientific\njournals to compare the proposed update training strategies with benchmark\nmodels. We show that our strategies are able to reduce the performance cost of\ndomain adaptation to a level similar to Word2Vec.",
    "descriptor": "\nComments: SciNLP 2021 poster abstract\n",
    "authors": [
      "Mihalis Gongolidis",
      "Jeremy Minton",
      "Ronin Wu",
      "Valentin Stauber",
      "Jason Hoelscher-Obermaier",
      "Viktor Botev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00677"
  },
  {
    "id": "arXiv:2111.00678",
    "title": "Latent Structures Mining with Contrastive Modality Fusion for Multimedia  Recommendation",
    "abstract": "Recent years have witnessed growing interests in multimedia recommendation,\nwhich aims to predict whether a user will interact with an item with multimodal\ncontents. Previous studies focus on modeling user-item interactions with\nmultimodal features included as side information. However, this scheme is not\nwell-designed for multimedia recommendation. Firstly, only collaborative\nitem-item relationships are implicitly modeled through high-order\nitem-user-item co-occurrences. We argue that the latent semantic item-item\nstructures underlying these multimodal contents could be beneficial for\nlearning better item representations and assist the recommender models to\ncomprehensively discover candidate items. Secondly, previous studies disregard\nthe fine-grained multimodal fusion. Although having access to multiple\nmodalities might allow us to capture rich information, we argue that the simple\ncoarse-grained fusion by linear combination or concatenation in previous work\nis insufficient to fully understand content information and item\nrelationships.To this end, we propose a latent structure MIning with\nContRastive mOdality fusion method (MICRO for brevity). To be specific, we\ndevise a novel modality-aware structure learning module, which learns item-item\nrelationships for each modality. Based on the learned modality-aware latent\nitem relationships, we perform graph convolutions that explicitly inject item\naffinities to modality-aware item representations. Then, we design a novel\ncontrastive method to fuse multimodal features. These enriched item\nrepresentations can be plugged into existing collaborative filtering methods to\nmake more accurate recommendations. Extensive experiments on real-world\ndatasets demonstrate the superiority of our method over state-of-the-art\nbaselines.",
    "descriptor": "\nComments: 12 pages; in submission to IEEE TKDE. arXiv admin note: substantial text overlap with arXiv:2104.09036\n",
    "authors": [
      "Jinghao Zhang",
      "Yanqiao Zhu",
      "Qiang Liu",
      "Mengqi Zhang",
      "Shu Wu",
      "Liang Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.00678"
  },
  {
    "id": "arXiv:2111.00680",
    "title": "GCNear: A Hybrid Architecture for Efficient GCN Training with  Near-Memory Processing",
    "abstract": "Recently, Graph Convolutional Networks (GCNs) have become state-of-the-art\nalgorithms for analyzing non-euclidean graph data. However, it is challenging\nto realize efficient GCN training, especially on large graphs. The reasons are\nmany-folded: 1) GCN training incurs a substantial memory footprint. Full-batch\ntraining on large graphs even requires hundreds to thousands of gigabytes of\nmemory to buffer the intermediate data for back-propagation. 2) GCN training\ninvolves both memory-intensive data reduction and computation-intensive\nfeatures/gradients update operations. Such a heterogeneous nature challenges\ncurrent CPU/GPU platforms. 3) The irregularity of graphs and the complex\ntraining dataflow jointly increase the difficulty of improving a GCN training\nsystem's efficiency.\nThis paper presents GCNear, a hybrid architecture to tackle these challenges.\nSpecifically, GCNear adopts a DIMM-based memory system to provide easy-to-scale\nmemory capacity. To match the heterogeneous nature, we categorize GCN training\noperations as memory-intensive Reduce and computation-intensive Update\noperations. We then offload Reduce operations to on-DIMM NMEs, making full use\nof the high aggregated local bandwidth. We adopt a CAE with sufficient\ncomputation capacity to process Update operations. We further propose several\noptimization strategies to deal with the irregularity of GCN tasks and improve\nGCNear's performance. We also propose a Multi-GCNear system to evaluate the\nscalability of GCNear.",
    "descriptor": "",
    "authors": [
      "Zhe Zhou",
      "Cong Li",
      "Xuechao Wei",
      "Guangyu Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.00680"
  },
  {
    "id": "arXiv:2111.00684",
    "title": "Graph Structural Attack by Spectral Distanc",
    "abstract": "Graph Convolutional Networks (GCNs) have fueled a surge of interest due to\ntheir superior performance on graph learning tasks, but are also shown\nvulnerability to adversarial attacks. In this paper, an effective graph\nstructural attack is investigated to disrupt graph spectral filters in the\nFourier domain. We define the spectral distance based on the eigenvalues of\ngraph Laplacian to measure the disruption of spectral filters. We then generate\nedge perturbations by simultaneously maximizing a task-specific attack\nobjective and the proposed spectral distance. The experiments demonstrate\nremarkable effectiveness of the proposed attack in the white-box setting at\nboth training and test time. Our qualitative analysis shows the connection\nbetween the attack behavior and the imposed changes on the spectral\ndistribution, which provides empirical evidence that maximizing spectral\ndistance is an effective manner to change the structural property of graphs in\nthe spatial domain and perturb the frequency components in the Fourier domain.",
    "descriptor": "",
    "authors": [
      "Lu Lin",
      "Ethan Blaser",
      "Hongning Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.00684"
  },
  {
    "id": "arXiv:2111.00687",
    "title": "RMNet: Equivalently Removing Residual Connection from Networks",
    "abstract": "Although residual connection enables training very deep neural networks, it\nis not friendly for online inference due to its multi-branch topology. This\nencourages many researchers to work on designing DNNs without residual\nconnections at inference. For example, RepVGG re-parameterizes multi-branch\ntopology to a VGG-like (single-branch) model when deploying, showing great\nperformance when the network is relatively shallow. However, RepVGG can not\ntransform ResNet to VGG equivalently because re-parameterizing methods can only\nbe applied to linear blocks and the non-linear layers (ReLU) have to be put\noutside of the residual connection which results in limited representation\nability, especially for deeper networks. In this paper, we aim to remedy this\nproblem and propose to remove the residual connection in a vanilla ResNet\nequivalently by a reserving and merging (RM) operation on ResBlock.\nSpecifically, the RM operation allows input feature maps to pass through the\nblock while reserving their information and merges all the information at the\nend of each block, which can remove residual connections without changing the\noriginal output. As a plug-in method, RM Operation basically has three\nadvantages: 1) its implementation makes it naturally friendly for high ratio\nnetwork pruning. 2) it helps break the depth limitation of RepVGG. 3) it leads\nto better accuracy-speed trade-off network (RMNet) compared to ResNet and\nRepVGG. We believe the ideology of RM Operation can inspire many insights on\nmodel design for the community in the future. Code is available at:\nhttps://github.com/fxmeng/RMNet.",
    "descriptor": "\nComments: Equivalently removing residual connection from ResBlock with non-linear layer inside it, towards an efficient plain model\n",
    "authors": [
      "Fanxu Meng",
      "Hao Cheng",
      "Jiaxin Zhuang",
      "Ke Li",
      "Xing Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00687"
  },
  {
    "id": "arXiv:2111.00695",
    "title": "Noise Error Pattern Generation Based on Successive Addition-Subtraction  for Guessing Decoding",
    "abstract": "Guessing random additive noise decoding (GRAND) algorithm has emerged as an\nexcellent decoding strategy that can meet both the high reliability and low\nlatency constraints. This paper proposes a successive addition-subtraction\nalgorithm to generate noise error permutations. A noise error patterns\ngeneration scheme is presented by embedding the \"1\" and \"0\" bursts alternately.\nThen detailed procedures of the proposed algorithm are presented, and its\ncorrectness is also demonstrated through theoretical derivations. The aim of\nthis work is to provide a preliminary paradigm and reference for future\nresearch on GRAND algorithm and hardware implementation.",
    "descriptor": "\nComments: 6 pages, 7 figures, submitted to IEEE Communications Letters\n",
    "authors": [
      "Ming Zhan",
      "Zhibo Pang",
      "Kan Yu",
      "Jing Xu",
      "Fang Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00695"
  },
  {
    "id": "arXiv:2111.00699",
    "title": "Principles towards Real-Time Simulation of Material Point Method on  Modern GPUs",
    "abstract": "Physics-based simulation has been actively employed in generating offline\nvisual effects in the film and animation industry. However, the computations\nrequired for high-quality scenarios are generally immense, deterring its\nadoption in real-time applications, e.g., virtual production, avatar\nlive-streaming, and cloud gaming. We summarize the principles that can\naccelerate the computation pipeline on single-GPU and multi-GPU platforms\nthrough extensive investigation and comprehension of modern GPU architecture.\nWe further demonstrate the effectiveness of these principles by applying them\nto the material point method to build up our framework, which achieves\n$1.7\\times$--$8.6\\times$ speedup on a single GPU and $2.5\\times$--$14.8\\times$\non four GPUs compared to the state-of-the-art. Our pipeline is specifically\ndesigned for real-time applications (i.e., scenarios with small to medium\nparticles) and achieves significant multi-GPU efficiency. We demonstrate our\npipeline by simulating a snow scenario with 1.33M particles and a fountain\nscenario with 143K particles in real-time (on average, 68.5 and 55.9\nframe-per-second, respectively) on four NVIDIA Tesla V100 GPUs interconnected\nwith NVLinks.",
    "descriptor": "",
    "authors": [
      "Yun Fei",
      "Yuhan Huang",
      "Ming Gao"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.00699"
  },
  {
    "id": "arXiv:2111.00700",
    "title": "Analyzing Behavioral Changes of Twitter Users After Exposure to  Misinformation",
    "abstract": "Social media platforms have been exploited to disseminate misinformation in\nrecent years. The widespread online misinformation has been shown to affect\nusers' beliefs and is connected to social impact such as polarization. In this\nwork, we focus on misinformation's impact on specific user behavior and aim to\nunderstand whether general Twitter users changed their behavior after being\nexposed to misinformation. We compare the before and after behavior of exposed\nusers to determine whether the frequency of the tweets they posted, or the\nsentiment of their tweets underwent any significant change. Our results\nindicate that users overall exhibited statistically significant changes in\nbehavior across some of these metrics. Through language distance analysis, we\nshow that exposed users were already different from baseline users before the\nexposure. We also study the characteristics of two specific user groups,\nmulti-exposure and extreme change groups, which were potentially highly\nimpacted. Finally, we study if the changes in the behavior of the users after\nexposure to misinformation tweets vary based on the number of their followers\nor the number of followers of the tweet authors, and find that their behavioral\nchanges are all similar.",
    "descriptor": "\nComments: Accepted to FOSINT-SI, co-located with ASONAM 2021\n",
    "authors": [
      "Yichen Wang",
      "Richard Han",
      "Tamara Lehman",
      "Qin Lv",
      "Shivakant Mishra"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.00700"
  },
  {
    "id": "arXiv:2111.00701",
    "title": "Discourse Comprehension: A Question Answering Framework to Represent  Sentence Connections",
    "abstract": "While there has been substantial progress in text comprehension through\nsimple factoid question answering, more holistic comprehension of a discourse\nstill presents a major challenge. Someone critically reflecting on a text as\nthey read it will pose curiosity-driven, often open-ended questions, which\nreflect deep understanding of the content and require complex reasoning to\nanswer. A key challenge in building and evaluating models for this type of\ndiscourse comprehension is the lack of annotated data, especially since finding\nanswers to such questions (which may not be answered at all) requires high\ncognitive load for annotators over long documents. This paper presents a novel\nparadigm that enables scalable data collection targeting the comprehension of\nnews documents, viewing these questions through the lens of discourse. The\nresulting corpus, DCQA (Discourse Comprehension by Question Answering),\nconsists of 22,430 question-answer pairs across 607 English documents. DCQA\ncaptures both discourse and semantic links between sentences in the form of\nfree-form, open-ended questions. On an evaluation set that we annotated on\nquestions from the INQUISITIVE dataset, we show that DCQA provides valuable\nsupervision for answering open-ended questions. We additionally design\npre-training methods utilizing existing question-answering resources, and use\nsynthetic data to accommodate unanswerable questions.",
    "descriptor": "",
    "authors": [
      "Wei-Jen Ko",
      "Cutter Dalton",
      "Mark Simmons",
      "Eliza Fisher",
      "Greg Durrett",
      "Junyi Jessy Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00701"
  },
  {
    "id": "arXiv:2111.00702",
    "title": "Comparative Study of Long Document Classification",
    "abstract": "The amount of information stored in the form of documents on the internet has\nbeen increasing rapidly. Thus it has become a necessity to organize and\nmaintain these documents in an optimum manner. Text classification algorithms\nstudy the complex relationships between words in a text and try to interpret\nthe semantics of the document. These algorithms have evolved significantly in\nthe past few years. There has been a lot of progress from simple machine\nlearning algorithms to transformer-based architectures. However, existing\nliterature has analyzed different approaches on different data sets thus making\nit difficult to compare the performance of machine learning algorithms. In this\nwork, we revisit long document classification using standard machine learning\napproaches. We benchmark approaches ranging from simple Naive Bayes to complex\nBERT on six standard text classification datasets. We present an exhaustive\ncomparison of different algorithms on a range of long document datasets. We\nre-iterate that long document classification is a simpler task and even basic\nalgorithms perform competitively with BERT-based approaches on most of the\ndatasets. The BERT-based models perform consistently well on all the datasets\nand can be blindly used for the document classification task when the\ncomputations cost is not a concern. In the shallow model's category, we suggest\nthe usage of raw BiLSTM + Max architecture which performs decently across all\nthe datasets. Even simpler Glove + Attention bag of words model can be utilized\nfor simpler use cases. The importance of using sophisticated models is clearly\nvisible in the IMDB sentiment dataset which is a comparatively harder task.",
    "descriptor": "",
    "authors": [
      "Vedangi Wagh",
      "Snehal Khandve",
      "Isha Joshi",
      "Apurva Wani",
      "Geetanjali Kale",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00702"
  },
  {
    "id": "arXiv:2111.00703",
    "title": "An Empirical Analysis of HTTPS Configuration Security",
    "abstract": "It is notoriously difficult to securely configure HTTPS, and poor server\nconfigurations have contributed to several attacks including the FREAK, Logjam,\nand POODLE attacks. In this work, we empirically evaluate the TLS security\nposture of popular websites and endeavor to understand the configuration\ndecisions that operators make. We correlate several sources of influence on\nsites' security postures, including software defaults, cloud providers, and\nonline recommendations. We find a fragmented web ecosystem: while most websites\nhave secure configurations, this is largely due to major cloud providers that\noffer secure defaults. Individually configured servers are more often insecure\nthan not. This may be in part because common resources available to individual\noperators -- server software defaults and online configuration guides -- are\nfrequently insecure. Our findings highlight the importance of considering SaaS\nservices separately from individually-configured sites in measurement studies,\nand the need for server software to ship with secure defaults.",
    "descriptor": "",
    "authors": [
      "Camelia Simoiu",
      "Wilson Nguyen",
      "Zakir Durumeric"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00703"
  },
  {
    "id": "arXiv:2111.00704",
    "title": "A Novel 1D State Space for Efficient Music Rhythmic Analysis",
    "abstract": "Inferring music time structures has a broad range of applications in music\nproduction, processing and analysis. Scholars have proposed various methods to\nanalyze different aspects of time structures, including beat, downbeat, tempo\nand meter. Many of the state-of-the-art methods, however, are computationally\nexpensive. This makes them inapplicable in real-world industrial settings where\nthe scale of the music collections can be millions. This paper proposes a new\nstate space approach for music time structure analysis. The proposed approach\ncollapses the commonly used 2D state spaces into 1D through a jump-back reward\nstrategy. This reduces the state space size drastically. We then utilize the\nproposed method for casual, joint beat, downbeat, tempo, and meter tracking,\nand compare it against several previous beat and downbeat tracking methods. The\nproposed method delivers comparable performance with the state-of-the-art joint\ncasual models with a much smaller state space and a more than 30 times speedup.",
    "descriptor": "\nComments: Submitted to International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2022. The source code, video demos, and user package are available in the following GitHub repository: this https URL\n",
    "authors": [
      "Mojtaba Heydari",
      "Matthew McCallum",
      "Andreas Ehmann",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.00704"
  },
  {
    "id": "arXiv:2111.00705",
    "title": "Communication-Compressed Adaptive Gradient Method for Distributed  Nonconvex Optimization",
    "abstract": "Due to the explosion in the size of the training datasets, distributed\nlearning has received growing interest in recent years. One of the major\nbottlenecks is the large communication cost between the central server and the\nlocal workers. While error feedback compression has been proven to be\nsuccessful in reducing communication costs with stochastic gradient descent\n(SGD), there are much fewer attempts in building communication-efficient\nadaptive gradient methods with provable guarantees, which are widely used in\ntraining large-scale machine learning models. In this paper, we propose a new\ncommunication-compressed AMSGrad for distributed nonconvex optimization\nproblem, which is provably efficient. Our proposed distributed learning\nframework features an effective gradient compression strategy and a worker-side\nmodel update design. We prove that the proposed communication-efficient\ndistributed adaptive gradient method converges to the first-order stationary\npoint with the same iteration complexity as uncompressed vanilla AMSGrad in the\nstochastic nonconvex optimization setting. Experiments on various benchmarks\nback up our theory.",
    "descriptor": "\nComments: 34 pages, 10 figures\n",
    "authors": [
      "Yujia Wang",
      "Lu Lin",
      "Jinghui Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00705"
  },
  {
    "id": "arXiv:2111.00707",
    "title": "B-DAC: A Decentralized Access Control Framework on Northbound Interface  for Securing SDN Using Blockchain",
    "abstract": "Software-Defined Network (SDN) is a new arising terminology of network\narchitecture with outstanding features of orchestration by decoupling the\ncontrol plane and the data plane in each network element. Even though it brings\nseveral benefits, SDN is vulnerable to a diversity of attacks. Abusing the\nsingle point of failure in the SDN controller component, hackers can shut down\nall network operations. More specifics, a malicious OpenFlow application can\naccess to SDN controller to carry out harmful actions without any limitation\nowing to the lack of the access control mechanism as a standard in the\nNorthbound. The sensitive information about the whole network such as network\ntopology, flow information, and statistics can be gathered and leaked out. Even\nworse, the entire network can be taken over by the compromised controller.\nHence, it is vital to build a scheme of access control for SDN's Northbound.\nFurthermore, it must also protect the data integrity and availability during\ndata exchange between application and controller. To address such limitations,\nwe introduce B-DAC, a blockchain-based framework for decentralized\nauthentication and fine-grained access control for the Northbound interface to\nassist administrators in managing and protecting critical resources. With\nstrict policy enforcement, B-DAC can perform decentralized access control for\neach request to keep network applications under surveillance for preventing\nover-privileged activities or security policy conflicts. To demonstrate the\nfeasibility of our approach, we also implement a prototype of this framework to\nevaluate the security impact, effectiveness, and performance through typical\nuse cases.",
    "descriptor": "\nComments: 23 pages, 14 figures, 14 tables\n",
    "authors": [
      "Phan The Duy",
      "Hien Do Hoang",
      "Do Thi Thu Hien",
      "Anh Gia-Tuan Nguyen",
      "Van-Hau Pham"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.00707"
  },
  {
    "id": "arXiv:2111.00714",
    "title": "Bridging Action Frames: Instagram Infographics in U.S.Ethnic Movements",
    "abstract": "Instagram infographics are a digital activism tool that have redefined action\nframes for technology-facilitated social movements. From the 1960s through the\n1980s, United States ethnic movements practiced collective action:\nideologically unified, resource-intensive traditional activism. Today,\ntechnologically enabled movements have been categorized as practicing\nconnective action: individualized, low-resource online activism. Yet, we argue\nthat Instagram infographics are both connective and collective. This paper\njuxtaposes the insights of past and present U.S. ethnic movement activists and\nanalyzes Black Lives Matter Instagram data over the course of 7 years\n(2014-2020). We find that Instagram infographic activism bridges connective and\ncollective action in three ways: (1) Scope for Education: Visually enticing and\ndigestible infographics reduce the friction of information dissemination,\nfacilitating collective movement education while preserving customizability.\n(2) Reconciliation for Credibility: Activists use connective features to combat\ninfographic misinformation and resolve internal differences, creating a trusted\ncollective movement front. (3) High-Resource Efforts for Transformative Change:\nInstagram infographic activism has been paired with boots on the ground and\naction-oriented content, curating a connective-to-collective pipeline that\nexpends movement resources. Our work unveils the vitality of evaluating digital\nactivism action frames at the movement integration level, exemplifies the\npowerful coexistence of connective and collective action, and offers meaningful\ndesign implications for activists seeking to leverage this novel tool.",
    "descriptor": "\nComments: 43 pages, 12 figures, Conference On Computer-Supported Cooperative Work And Social Computing\n",
    "authors": [
      "Darya Kaviani",
      "Niloufar Salehi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.00714"
  },
  {
    "id": "arXiv:2111.00717",
    "title": "SFOL DME Pulse Shaping Through Digital Predistortion for High-Accuracy  DME",
    "abstract": "The Stretched-FrOnt-Leg (SFOL) pulse is a high-accuracy distance measuring\nequipment (DME) pulse developed to support alternative positioning and\nnavigation for aircraft during global navigation satellite system outages. To\nfacilitate the use of the SFOL pulse, it is best to use legacy DMEs that are\nalready deployed to transmit the SFOL pulse, rather than the current Gaussian\npulse, through software changes only. When attempting to transmit the SFOL\npulse in legacy DMEs, the greatest challenge is the pulse shape distortion\ncaused by the pulse-shaping circuits and power amplifiers in the transmission\nunit such that the original SFOL pulse shape is no longer preserved. This\nletter proposes an inverse-learning-based DME digital predistortion method and\npresents successfully transmitted SFOL pulses from a testbed based on a\ncommercial legacy DME that was designed to transmit Gaussian pulses.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Aerospace and Electronic Systems\n",
    "authors": [
      "Sunghwa Lee",
      "Euiho Kim",
      "Jiwon Seo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.00717"
  },
  {
    "id": "arXiv:2111.00721",
    "title": "Online Edge Coloring via Tree Recurrences and Correlation Decay",
    "abstract": "We give an online algorithm that with high probability computes a\n$\\left(\\frac{e}{e-1} + o(1)\\right)\\Delta$ edge coloring on a graph $G$ with\nmaximum degree $\\Delta = \\omega(\\log n)$ under online edge arrivals against\noblivious adversaries, making first progress on the conjecture of Bar-Noy,\nMotwani, and Naor in this general setting. Our algorithm is based on reducing\nto a matching problem on locally treelike graphs, and then applying a tree\nrecurrences based approach for arguing correlation decay.",
    "descriptor": "\nComments: 22 pages, 1 figure\n",
    "authors": [
      "Janardhan Kulkarni",
      "Yang P. Liu",
      "Ashwin Sah",
      "Mehtaab Sawhney",
      "Jakub Tarnawski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.00721"
  },
  {
    "id": "arXiv:2111.00722",
    "title": "Edge-Level Explanations for Graph Neural Networks by Extending  Explainability Methods for Convolutional Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) are deep learning models that take graph data as\ninputs, and they are applied to various tasks such as traffic prediction and\nmolecular property prediction. However, owing to the complexity of the GNNs, it\nhas been difficult to analyze which parts of inputs affect the GNN model's\noutputs. In this study, we extend explainability methods for Convolutional\nNeural Networks (CNNs), such as Local Interpretable Model-Agnostic Explanations\n(LIME), Gradient-Based Saliency Maps, and Gradient-Weighted Class Activation\nMapping (Grad-CAM) to GNNs, and predict which edges in the input graphs are\nimportant for GNN decisions. The experimental results indicate that the\nLIME-based approach is the most efficient explainability method for multiple\ntasks in the real-world situation, outperforming even the state-of-the-art\nmethod in GNN explainability.",
    "descriptor": "\nComments: 4 pages, accepted at 23rd IEEE International Symposium on Multimedia (ISM), short paper, 2021\n",
    "authors": [
      "Tetsu Kasanishi",
      "Xueting Wang",
      "Toshihiko Yamasaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00722"
  },
  {
    "id": "arXiv:2111.00724",
    "title": "Adaptive Multi-receptive Field Spatial-Temporal Graph Convolutional  Network for Traffic Forecasting",
    "abstract": "Mobile network traffic forecasting is one of the key functions in daily\nnetwork operation. A commercial mobile network is large, heterogeneous, complex\nand dynamic. These intrinsic features make mobile network traffic forecasting\nfar from being solved even with recent advanced algorithms such as graph\nconvolutional network-based prediction approaches and various attention\nmechanisms, which have been proved successful in vehicle traffic forecasting.\nIn this paper, we cast the problem as a spatial-temporal sequence prediction\ntask. We propose a novel deep learning network architecture, Adaptive\nMulti-receptive Field Spatial-Temporal Graph Convolutional Networks\n(AMF-STGCN), to model the traffic dynamics of mobile base stations. AMF-STGCN\nextends GCN by (1) jointly modeling the complex spatial-temporal dependencies\nin mobile networks, (2) applying attention mechanisms to capture various\nReceptive Fields of heterogeneous base stations, and (3) introducing an extra\ndecoder based on a fully connected deep network to conquer the error\npropagation challenge with multi-step forecasting. Experiments on four\nreal-world datasets from two different domains consistently show AMF-STGCN\noutperforms the state-of-the-art methods.",
    "descriptor": "\nComments: To be published in IEEE GLOBECOM\n",
    "authors": [
      "Xing Wang",
      "Juan Zhao",
      "Lin Zhu",
      "Xu Zhou",
      "Zhao Li",
      "Junlan Feng",
      "Chao Deng",
      "Yong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00724"
  },
  {
    "id": "arXiv:2111.00728",
    "title": "Learning Iterative Robust Transformation Synchronization",
    "abstract": "Transformation Synchronization is the problem of recovering absolute\ntransformations from a given set of pairwise relative motions. Despite its\nusefulness, the problem remains challenging due to the influences from noisy\nand outlier relative motions, and the difficulty to model analytically and\nsuppress them with high fidelity. In this work, we avoid handcrafting robust\nloss functions, and propose to use graph neural networks (GNNs) to learn\ntransformation synchronization. Unlike previous works which use complicated\nmulti-stage pipelines, we use an iterative approach where each step consists of\na single weight-shared message passing layer that refines the absolute poses\nfrom the previous iteration by predicting an incremental update in the tangent\nspace. To reduce the influence of outliers, the messages are weighted before\naggregation. Our iterative approach alleviates the need for an explicit\ninitialization step and performs well with identity initial poses. Although our\napproach is simple, we show that it performs favorably against existing\nhandcrafted and learned synchronization methods through experiments on both\nSO(3) and SE(3) synchronization.",
    "descriptor": "\nComments: To appear in 3DV2021\n",
    "authors": [
      "Zi Jian Yew",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00728"
  },
  {
    "id": "arXiv:2111.00732",
    "title": "Outlining and Filling: Hierarchical Query Graph Generation for Answering  Complex Questions over Knowledge Graph",
    "abstract": "Query graph building aims to build correct executable SPARQL over the\nknowledge graph for answering natural language questions. Although recent\napproaches perform well by NN-based query graph ranking, more complex questions\nbring three new challenges: complicated SPARQL syntax, huge search space for\nranking, and noisy query graphs with local ambiguity. This paper handles these\nchallenges. Initially, we regard common complicated SPARQL syntax as the\nsub-graphs comprising of vertices and edges and propose a new unified query\ngraph grammar to adapt them. Subsequently, we propose a new two-stage approach\nto build query graphs. In the first stage, the top-$k$ related instances\n(entities, relations, etc.) are collected by simple strategies, as the\ncandidate instances. In the second stage, a graph generation model performs\nhierarchical generation. It first outlines a graph structure whose vertices and\nedges are empty slots, and then fills the appropriate instances into the slots,\nthereby completing the query graph. Our approach decomposes the unbearable\nsearch space of entire query graphs into affordable sub-spaces of operations,\nmeanwhile, leverages the global structural information to eliminate local\nambiguity. The experimental results demonstrate that our approach greatly\nimproves state-of-the-art on the hardest KGQA benchmarks and has an excellent\nperformance on complex questions.",
    "descriptor": "",
    "authors": [
      "Yongrui Chen",
      "Huiying Li",
      "Guilin Qi",
      "Tianxing Wu",
      "Tenggou Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00732"
  },
  {
    "id": "arXiv:2111.00734",
    "title": "Robust Deep Learning from Crowds with Belief Propagation",
    "abstract": "Crowdsourcing systems enable us to collect noisy labels from crowd workers. A\ngraphical model representing local dependencies between workers and tasks\nprovides a principled way of reasoning over the true labels from the noisy\nanswers. However, one needs a predictive model working on unseen data directly\nfrom crowdsourced datasets instead of the true labels in many cases. To infer\ntrue labels and learn a predictive model simultaneously, we propose a new\ndata-generating process, where a neural network generates the true labels from\ntask features. We devise an EM framework alternating variational inference and\ndeep learning to infer the true labels and to update the neural network,\nrespectively. Experimental results with synthetic and real datasets show a\nbelief-propagation-based EM algorithm is robust to i) corruption in task\nfeatures, ii) multi-modal or mismatched worker prior, and iii) few spammers\nsubmitting noises to many tasks.",
    "descriptor": "",
    "authors": [
      "Hoyoung Kim",
      "Seunghyuk Cho",
      "Dongwoo Kim",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00734"
  },
  {
    "id": "arXiv:2111.00735",
    "title": "Calibrating Explore-Exploit Trade-off for Fair Online Learning to Rank",
    "abstract": "Online learning to rank (OL2R) has attracted great research interests in\nrecent years, thanks to its advantages in avoiding expensive relevance labeling\nas required in offline supervised ranking model learning. Such a solution\nexplores the unknowns (e.g., intentionally present selected results on top\npositions) to improve its relevance estimation. This however triggers concerns\non its ranking fairness: different groups of items might receive differential\ntreatments during the course of OL2R. But existing fair ranking solutions\nusually require the knowledge of result relevance or a performing ranker\nbeforehand, which contradicts with the setting of OL2R and thus cannot be\ndirectly applied to guarantee fairness.\nIn this work, we propose a general framework to achieve fairness defined by\ngroup exposure in OL2R. The key idea is to calibrate exploration and\nexploitation for fairness control, relevance learning and online ranking\nquality. In particular, when the model is exploring a set of results for\nrelevance feedback, we confine the exploration within a subset of random\npermutations, where fairness across groups is maintained while the feedback is\nstill unbiased. Theoretically we prove such a strategy introduces minimum\ndistortion in OL2R's regret to obtain fairness. Extensive empirical analysis is\nperformed on two public learning to rank benchmark datasets to demonstrate the\neffectiveness of the proposed solution compared to existing fair OL2R\nsolutions.",
    "descriptor": "",
    "authors": [
      "Yiling Jia",
      "Hongning Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00735"
  },
  {
    "id": "arXiv:2111.00739",
    "title": "URIR: Recommendation algorithm of user RNN encoder and item encoder  based on knowledge graph",
    "abstract": "Due to a large amount of information, it is difficult for users to find what\nthey are interested in among the many choices. In order to improve users'\nexperience, recommendation systems have been widely used in music\nrecommendations, movie recommendations, online shopping, and other scenarios.\nRecently, Knowledge Graph (KG) has been proven to be an effective tool to\nimprove the performance of recommendation systems. However, a huge challenge in\napplying knowledge graphs for recommendation is how to use knowledge graphs to\nobtain better user codes and item codes. In response to this problem, this\nresearch proposes a user Recurrent Neural Network (RNN) encoder and item\nencoder recommendation algorithm based on Knowledge Graph (URIR). This study\nencodes items by capturing high-level neighbor information to generate items'\nrepresentation vectors and applies an RNN and items' representation vectors to\nencode users to generate users' representation vectors, and then perform inner\nproduct operation on users' representation vectors and items' representation\nvectors to get probabilities of users interaction with items. Numerical\nexperiments on three real-world datasets demonstrate that URIR is superior\nperformance to state-of-the-art algorithms in indicators such as AUC,\nPrecision, Recall, and MRR. This implies that URIR can effectively use\nknowledge graph to obtain better user codes and item codes, thereby obtaining\nbetter recommendation results.",
    "descriptor": "",
    "authors": [
      "Na zhao",
      "Zhen Long",
      "Zhi-Dan Zhao",
      "Jian Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00739"
  },
  {
    "id": "arXiv:2111.00743",
    "title": "Towards the Generalization of Contrastive Self-Supervised Learning",
    "abstract": "Recently, self-supervised learning has attracted great attention since it\nonly requires unlabeled data for training. Contrastive learning is a popular\napproach for self-supervised learning and empirically performs well in\npractice. However, the theoretical understanding of its generalization ability\non downstream tasks is not well studied. To this end, we present a theoretical\nexplanation of how contrastive self-supervised pre-trained models generalize to\ndownstream tasks. Concretely, we quantitatively show that the self-supervised\nmodel has generalization ability on downstream classification tasks if it\nembeds input data into a feature space with distinguishing centers of classes\nand closely clustered intra-class samples. With the above conclusion, we\nfurther explore SimCLR and Barlow Twins, which are two canonical contrastive\nself-supervised methods. We prove that the aforementioned feature space can be\nobtained via any of the methods, and thus explain their success on the\ngeneralization on downstream classification tasks. Finally, various experiments\nare also conducted to verify our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Weiran Huang",
      "Mingyang Yi",
      "Xuyang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00743"
  },
  {
    "id": "arXiv:2111.00746",
    "title": "Decentralized On-Ramp Merging Control of Connected and Automated  Vehicles in the Mixed Traffic Using Control Barrier Functions",
    "abstract": "The cooperative control of the connected and automated vehicle (CAV) is\nrecognized as an effective approach to alleviate traffic congestion and improve\ntraffic safety, especially for on-ramp bottlenecks. However, in the mixed\ntraffic, the uncertainty of human-driven vehicles (HDVs) makes the on-ramp\nmerging control for CAVs more challenging. This paper proposes a decentralized\noptimal control method to address the merging control problem of CAVs at\nhighway on-ramps in the mixed traffic. We first formulate the optimal merging\ncontrol problem, which includes the constraints of safety and vehicle dynamics,\nwith the objectives of minimizing travel time and energy consumption. Then, a\ncontrol framework, combining control barrier functions (CBFs) and control\nLyapunov functions (CLFs) is proposed. CBFs render the system subject to\nsafety-critical constraints, while CLFs stabilize the system to the objectives.\nIn addition, to enable effective control of CAVs in the mixed traffic, a\nrecursive merging control framework is proposed, where HDVs are regarded as\ndisturbances, and CAVs collect surrounding vehicles' states repeatedly and\nupdate their trajectories recursively to satisfy strict merging requirements.\nFinally, the merging problem is reformulated as a quadratic programming\nproblem, which allows for real-time application. Simulation results show that\nthe proposed on-ramp merging control method is robust in resisting disturbance\nfrom the HDV with traffic efficiency and energy economy improvement.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Haoji Liu",
      "Weichao Zhuang",
      "Guodong Yin",
      "Rongcan Li",
      "Chang Liu",
      "Shanxing Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00746"
  },
  {
    "id": "arXiv:2111.00748",
    "title": "Quasi-Linear Transfer Function: A New Method for Frequency Domain  Analysis of Nonlinear Systems",
    "abstract": "A new concept, called quasi-linear transfer functions (QLTF), which can be\nused to characterize the output frequency behaviour of nonlinear systems, is\nintroduced based on the well-known Volterra series representation. By using the\nnew concept of QLTF, it can be proved that the input and output frequency\nbehaviour of a given system can be expressed using a number of one-dimensional\nfunctions with a form similar to that of the traditional frequency response\nfunction for linear systems. Two algorithms, which can be used to determine the\nvalid range of the associated output frequencies of arbitrary order nonlinear\nsubsystems with both a multitone and general inputs, are provided. The results\nobtained provide a new important insight into the output frequency\ncharacteristics of nonlinear systems and have many potential applications in\nnonlinear systems analysis and nonlinear structure detection",
    "descriptor": "\nComments: 26 pages, 9 figures, 3 tables\n",
    "authors": [
      "Hua-Liang Wei",
      "S. A. Billings"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00748"
  },
  {
    "id": "arXiv:2111.00754",
    "title": "Few-shot learning with improved local representations via bias rectify  module",
    "abstract": "Recent approaches based on metric learning have achieved great progress in\nfew-shot learning. However, most of them are limited to image-level\nrepresentation manners, which fail to properly deal with the intra-class\nvariations and spatial knowledge and thus produce undesirable performance. In\nthis paper we propose a Deep Bias Rectify Network (DBRN) to fully exploit the\nspatial information that exists in the structure of the feature\nrepresentations. We first employ a bias rectify module to alleviate the adverse\nimpact caused by the intra-class variations. bias rectify module is able to\nfocus on the features that are more discriminative for classification by given\ndifferent weights. To make full use of the training data, we design a prototype\naugment mechanism that can make the prototypes generated from the support set\nto be more representative. To validate the effectiveness of our method, we\nconducted extensive experiments on various popular few-shot classification\nbenchmarks and our methods can outperform state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Chao Dong",
      "Qi Ye",
      "Wenchao Meng",
      "Kaixiang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00754"
  },
  {
    "id": "arXiv:2111.00757",
    "title": "Toward an improved BCI for damaged CNS-tissue patient using EEG-signal  processing approach",
    "abstract": "This article examined brain signals of people with disabilities using various\nsignal processing methods to achieve the desired accuracy for utilizing\nbrain-computer interfaces (BCI). EEG signals resulted from 5 mental tasks of\nword association (WORD), Mental subtraction (SUB), spatial navigation (NAV),\nright-hand motor imagery (HAND), and feet motor imagery (FEET) of 9 people with\ncentral nervous system (CNS) tissue damage were used as input. In processing\nthis data, Butterworth band-pass filter (8-30 Hz) was used in the\npreprocessing, and CSP, TRCSP, FBCSP methods were used in feature extraction,\nand LDA, KNN, linear and nonlinear SVM were used in classification stages. The\ntraining and testing process was repeated up to 100 times, and the random\nsubsampling method was used to select the training and test data. Mean accuracy\nin 100 replications was reported as final accuracy. The classification results\nof two classes of 5 mental tasks on the data of 9 people with central nerve\ndamage showed that the combination of FBCSP with KNN classifier has the highest\naccuracy of 69+-1.1 which belongs to the two classes of word association and\nfeet motor imagery. The study of different feature extraction methods and\nclassification indicates that the proper feature selection method and\nespecially classifier is crucial in accuracy rate. Furthermore, it is necessary\nto pay attention to successful signal processing methods in designing a\nbrain-computer interface to use in people with central nervous system.",
    "descriptor": "",
    "authors": [
      "Fateme Dehrouye-Semnani",
      "Nasrollah Moghada Charkari",
      "Seyed Mohammad Mehdi Mirbagheri"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.00757"
  },
  {
    "id": "arXiv:2111.00758",
    "title": "Single-Item Fashion Recommender: Towards Cross-Domain Recommendations",
    "abstract": "Nowadays, recommender systems and search engines play an integral role in\nfashion e-commerce. Still, many challenges lie ahead, and this study tries to\ntackle some. This article first suggests a content-based fashion recommender\nsystem that uses a parallel neural network to take a single fashion item shop\nimage as input and make in-shop recommendations by listing similar items\navailable in the store. Next, the same structure is enhanced to personalize the\nresults based on user preferences. This work then introduces a background\naugmentation technique that makes the system more robust to out-of-domain\nqueries, enabling it to make street-to-shop recommendations using only a\ntraining set of catalog shop images. Moreover, the last contribution of this\npaper is a new evaluation metric for recommendation tasks called\nobjective-guided human score. This method is an entirely customizable framework\nthat produces interpretable, comparable scores from subjective evaluations of\nhuman scorers.",
    "descriptor": "\nComments: 16 Pages, 14 Figures, 2 Tables\n",
    "authors": [
      "Seyed Omid Mohammadi",
      "Hossein Bodaghi",
      "Ahmad Kalhor"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00758"
  },
  {
    "id": "arXiv:2111.00762",
    "title": "MetroLoc: Metro Vehicle Mapping and Localization with  LiDAR-Camera-Inertial Integration",
    "abstract": "We propose an accurate and robust multi-modal sensor fusion framework,\nMetroLoc, towards one of the most extreme scenarios, the large-scale metro\nvehicle localization and mapping. MetroLoc is built atop an IMU-centric state\nestimator that tightly couples light detection and ranging (LiDAR), visual, and\ninertial information with the convenience of loosely coupled methods. The\nproposed framework is composed of three submodules: IMU odometry,\nLiDAR-inertial odometry (LIO), and Visual-inertial odometry (VIO). The IMU is\ntreated as the primary sensor, which achieves the observations from LIO and VIO\nto constrain the accelerometer and gyroscope biases. Compared to previous\npoint-only LIO methods, our approach leverages more geometry information by\nintroducing both line and plane features into motion estimation. The VIO also\nutilizes the environmental structure information by employing both lines and\npoints. Our proposed method has been extensively tested in the long-during\nmetro environments with a maintenance vehicle. Experimental results show the\nsystem more accurate and robust than the state-of-the-art approaches with\nreal-time performance. Besides, we develop a series of Virtual Reality (VR)\napplications towards efficient, economical, and interactive rail vehicle state\nand trackside infrastructure monitoring, which has already been deployed to an\noutdoor testing railroad.",
    "descriptor": "",
    "authors": [
      "Yusheng Wang",
      "Weiwei Song",
      "Yi Zhang",
      "Fei Huang",
      "Zhiyong Tu",
      "Yidong Lou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00762"
  },
  {
    "id": "arXiv:2111.00763",
    "title": "Monocular 3D Reconstruction of Interacting Hands via Collision-Aware  Factorized Refinements",
    "abstract": "3D interacting hand reconstruction is essential to facilitate human-machine\ninteraction and human behaviors understanding. Previous works in this field\neither rely on auxiliary inputs such as depth images or they can only handle a\nsingle hand if monocular single RGB images are used. Single-hand methods tend\nto generate collided hand meshes, when applied to closely interacting hands,\nsince they cannot model the interactions between two hands explicitly. In this\npaper, we make the first attempt to reconstruct 3D interacting hands from\nmonocular single RGB images. Our method can generate 3D hand meshes with both\nprecise 3D poses and minimal collisions. This is made possible via a two-stage\nframework. Specifically, the first stage adopts a convolutional neural network\nto generate coarse predictions that tolerate collisions but encourage\npose-accurate hand meshes. The second stage progressively ameliorates the\ncollisions through a series of factorized refinements while retaining the\npreciseness of 3D poses. We carefully investigate potential implementations for\nthe factorized refinement, considering the trade-off between efficiency and\naccuracy. Extensive quantitative and qualitative results on large-scale\ndatasets such as InterHand2.6M demonstrate the effectiveness of the proposed\napproach.",
    "descriptor": "\nComments: Accepted to 3DV 2021. Code and demo is available at this https URL\n",
    "authors": [
      "Yu Rong",
      "Jingbo Wang",
      "Ziwei Liu",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00763"
  },
  {
    "id": "arXiv:2111.00765",
    "title": "Validate on Sim, Detect on Real -- Model Selection for Domain  Randomization",
    "abstract": "A practical approach to learning robot skills, often termed sim2real, is to\ntrain control policies in simulation and then deploy them on a real robot.\nPopular techniques to improve the sim2real transfer build on domain\nrandomization (DR): Training the policy on a diverse set of randomly generated\ndomains with the hope of better generalization to the real world. Due to the\nlarge number of hyper-parameters in both the policy learning and DR algorithms,\none often ends up with a large number of trained models, where choosing the\nbest model among them demands costly evaluation on the real robot. In this work\nwe ask: Can we rank the policies without running them in the real world? Our\nmain idea is that a predefined set of real world data can be used to evaluate\nall policies, using out-of-distribution detection (OOD) techniques. In a sense,\nthis approach can be seen as a \"unit test\" to evaluate policies before any real\nworld execution. However, we find that by itself, the OOD score can be\ninaccurate and very sensitive to the particular OOD method. Our main\ncontribution is a simple-yet-effective policy score that combines OOD with an\nevaluation in simulation. We show that our score - VSDR - can significantly\nimprove the accuracy of policy ranking without requiring additional real world\ndata. We evaluate the effectiveness of VSDR on sim2real transfer in a robotic\ngrasping task with image inputs. We extensively evaluate different DR\nparameters and OOD methods, and show that VSDR improves policy selection across\nthe board. More importantly, our method achieves significantly better ranking,\nand uses significantly less data compared to baselines.",
    "descriptor": "",
    "authors": [
      "Gal Leibovich",
      "Guy Jacob",
      "Shadi Endrawis",
      "Gal Novik",
      "Aviv Tamar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00765"
  },
  {
    "id": "arXiv:2111.00767",
    "title": "A New Tool for Efficiently Generating Quality Estimation Datasets",
    "abstract": "Building of data for quality estimation (QE) training is expensive and\nrequires significant human labor. In this study, we focus on a data-centric\napproach while performing QE, and subsequently propose a fully automatic\npseudo-QE dataset generation tool that generates QE datasets by receiving only\nmonolingual or parallel corpus as the input. Consequently, the QE performance\nis enhanced either by data augmentation or by encouraging multiple language\npairs to exploit the applicability of QE. Further, we intend to publicly\nrelease this user friendly QE dataset generation tool as we believe this tool\nprovides a new, inexpensive method to the community for developing QE datasets.",
    "descriptor": "\nComments: Accepted for Data-centric AI workshop at NeurIPS 2021\n",
    "authors": [
      "Sugyeong Eo",
      "Chanjun Park",
      "Jaehyung Seo",
      "Hyeonseok Moon",
      "Heuiseok Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00767"
  },
  {
    "id": "arXiv:2111.00770",
    "title": "Dense Prediction with Attentive Feature Aggregation",
    "abstract": "Aggregating information from features across different layers is an essential\noperation for dense prediction models. Despite its limited expressiveness,\nfeature concatenation dominates the choice of aggregation operations. In this\npaper, we introduce Attentive Feature Aggregation (AFA) to fuse different\nnetwork layers with more expressive non-linear operations. AFA exploits both\nspatial and channel attention to compute weighted average of the layer\nactivations. Inspired by neural volume rendering, we extend AFA with\nScale-Space Rendering (SSR) to perform late fusion of multi-scale predictions.\nAFA is applicable to a wide range of existing network designs. Our experiments\nshow consistent and significant improvements on challenging semantic\nsegmentation benchmarks, including Cityscapes, BDD100K, and Mapillary Vistas,\nat negligible computational and parameter overhead. In particular, AFA improves\nthe performance of the Deep Layer Aggregation (DLA) model by nearly 6% mIoU on\nCityscapes. Our experimental analyses show that AFA learns to progressively\nrefine segmentation maps and to improve boundary details, leading to new\nstate-of-the-art results on boundary detection benchmarks on BSDS500 and\nNYUDv2. Code and video resources are available at this http URL",
    "descriptor": "\nComments: 18 pages, 16 figures\n",
    "authors": [
      "Yung-Hsu Yang",
      "Thomas E. Huang",
      "Samuel Rota Bul\u00f2",
      "Peter Kontschieder",
      "Fisher Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00770"
  },
  {
    "id": "arXiv:2111.00771",
    "title": "First order strong convergence and extinction of positivity preserving  logarithmic truncated Euler-Maruyama method for the stochastic SIS epidemic  model",
    "abstract": "The well-known stochastic SIS model characterized by highly nonlinear in\nepidemiology has a unique positive solution taking values in a bounded domain\nwith a series of dynamical behaviors. However, the approximation methods to\nmaintain the positivity and long-time behaviors for the stochastic SIS model,\nwhile very important, are also lacking. In this paper, based on a logarithmic\ntransformation, we propose a novel explicit numerical method for a stochastic\nSIS epidemic model whose coefficients violate the global monotonicity\ncondition, which can preserve the positivity of the original stochastic SIS\nmodel. And we show the strong convergence of the numerical method and derive\nthat the rate of convergence is of order one. Moreover, the extinction of the\nexact solution of stochastic SIS model is reproduced. Some numerical\nexperiments are given to illustrate the theoretical results and testify the\nefficiency of our algorithm.",
    "descriptor": "\nComments: 20 pages, 6figures\n",
    "authors": [
      "Hongfu Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00771"
  },
  {
    "id": "arXiv:2111.00772",
    "title": "AdaPool: Exponential Adaptive Pooling for Information-Retaining  Downsampling",
    "abstract": "Pooling layers are essential building blocks of Convolutional Neural Networks\n(CNNs) that reduce computational overhead and increase the receptive fields of\nproceeding convolutional operations. They aim to produce downsampled volumes\nthat closely resemble the input volume while, ideally, also being\ncomputationally and memory efficient. It is a challenge to meet both\nrequirements jointly. To this end, we propose an adaptive and exponentially\nweighted pooling method named $\\textit{adaPool}$. Our proposed method uses a\nparameterized fusion of two sets of pooling kernels that are based on the\nexponent of the Dice-Sorensen coefficient and the exponential maximum,\nrespectively. A key property of adaPool is its bidirectional nature. In\ncontrast to common pooling methods, weights can be used to upsample a\ndownsampled activation map. We term this method $\\textit{adaUnPool}$. We\ndemonstrate how adaPool improves the preservation of detail through a range of\ntasks including image and video classification and object detection. We then\nevaluate adaUnPool on image and video frame super-resolution and frame\ninterpolation tasks. For benchmarking, we introduce $\\textit{Inter4K}$, a novel\nhigh-quality, high frame-rate video dataset. Our combined experiments\ndemonstrate that adaPool systematically achieves better results across tasks\nand backbone architectures, while introducing a minor additional computational\nand memory overhead.",
    "descriptor": "",
    "authors": [
      "Alexandros Stergiou",
      "Ronald Poppe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00772"
  },
  {
    "id": "arXiv:2111.00774",
    "title": "On the number of $q$-ary quasi-perfect codes with covering radius 2",
    "abstract": "In this paper we present a family of $q$-ary nonlinear quasi-perfect codes\nwith covering radius 2. The codes have length $n = q^m$ and size $ M = q^{n - m\n- 1}$ where $q$ is a prime power, $q \\geq 3$, $m$ is an integer, $m \\geq 2$. We\nprove that there are more than $q^{q^{cn}}$ nonequivalent such codes of length\n$n$, for all sufficiently large $n$ and a constant $c = \\frac{1}{q} -\n\\varepsilon$.",
    "descriptor": "",
    "authors": [
      "Alexander M. Romanov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00774"
  },
  {
    "id": "arXiv:2111.00775",
    "title": "PP-ShiTu: A Practical Lightweight Image Recognition System",
    "abstract": "In recent years, image recognition applications have developed rapidly. A\nlarge number of studies and techniques have emerged in different fields, such\nas face recognition, pedestrian and vehicle re-identification, landmark\nretrieval, and product recognition. In this paper, we propose a practical\nlightweight image recognition system, named PP-ShiTu, consisting of the\nfollowing 3 modules, mainbody detection, feature extraction and vector search.\nWe introduce popular strategies including metric learning, deep hash, knowledge\ndistillation and model quantization to improve accuracy and inference speed.\nWith strategies above, PP-ShiTu works well in different scenarios with a set of\nmodels trained on a mixed dataset. Experiments on different datasets and\nbenchmarks show that the system is widely effective in different domains of\nimage recognition. All the above mentioned models are open-sourced and the code\nis available in the GitHub repository PaddleClas on PaddlePaddle.",
    "descriptor": "\nComments: 9 pages, 5 figures, 8 tables. arXiv admin note: text overlap with arXiv:2109.03144\n",
    "authors": [
      "Shengyu Wei",
      "Ruoyu Guo",
      "Cheng Cui",
      "Bin Lu",
      "Shuilong Dong",
      "Tingquan Gao",
      "Yuning Du",
      "Ying Zhou",
      "Xueying Lyu",
      "Qiwen Liu",
      "Xiaoguang Hu",
      "Dianhai Yu",
      "Yanjun Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00775"
  },
  {
    "id": "arXiv:2111.00780",
    "title": "Pseudo-Spherical Contrastive Divergence",
    "abstract": "Energy-based models (EBMs) offer flexible distribution parametrization.\nHowever, due to the intractable partition function, they are typically trained\nvia contrastive divergence for maximum likelihood estimation. In this paper, we\npropose pseudo-spherical contrastive divergence (PS-CD) to generalize maximum\nlikelihood learning of EBMs. PS-CD is derived from the maximization of a family\nof strictly proper homogeneous scoring rules, which avoids the computation of\nthe intractable partition function and provides a generalized family of\nlearning objectives that include contrastive divergence as a special case.\nMoreover, PS-CD allows us to flexibly choose various learning objectives to\ntrain EBMs without additional computational cost or variational minimax\noptimization. Theoretical analysis on the proposed method and extensive\nexperiments on both synthetic data and commonly used image datasets demonstrate\nthe effectiveness and modeling flexibility of PS-CD, as well as its robustness\nto data contamination, thus showing its superiority over maximum likelihood and\n$f$-EBMs.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Lantao Yu",
      "Jiaming Song",
      "Yang Song",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00780"
  },
  {
    "id": "arXiv:2111.00781",
    "title": "Decentralized Cooperative Reinforcement Learning with Hierarchical  Information Structure",
    "abstract": "Multi-agent reinforcement learning (MARL) problems are challenging due to\ninformation asymmetry. To overcome this challenge, existing methods often\nrequire high level of coordination or communication between the agents. We\nconsider two-agent multi-armed bandits (MABs) and Markov decision processes\n(MDPs) with a hierarchical information structure arising in applications, which\nwe exploit to propose simpler and more efficient algorithms that require no\ncoordination or communication. In the structure, in each step the ``leader\"\nchooses her action first, and then the ``follower\" decides his action after\nobserving the leader's action. The two agents observe the same reward (and the\nsame state transition in the MDP setting) that depends on their joint action.\nFor the bandit setting, we propose a hierarchical bandit algorithm that\nachieves a near-optimal gap-independent regret of\n$\\widetilde{\\mathcal{O}}(\\sqrt{ABT})$ and a near-optimal gap-dependent regret\nof $\\mathcal{O}(\\log(T))$, where $A$ and $B$ are the numbers of actions of the\nleader and the follower, respectively, and $T$ is the number of steps. We\nfurther extend to the case of multiple followers and the case with a deep\nhierarchy, where we both obtain near-optimal regret bounds. For the MDP\nsetting, we obtain $\\widetilde{\\mathcal{O}}(\\sqrt{H^7S^2ABT})$ regret, where\n$H$ is the number of steps per episode, $S$ is the number of states, $T$ is the\nnumber of episodes. This matches the existing lower bound in terms of $A, B$,\nand $T$.",
    "descriptor": "",
    "authors": [
      "Hsu Kao",
      "Chen-Yu Wei",
      "Vijay Subramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00781"
  },
  {
    "id": "arXiv:2111.00783",
    "title": "An AI-powered Smart Routing Solution for Payment Systems",
    "abstract": "In the current era of digitization, online payment systems are attracting\nconsiderable interest. Improving the efficiency of a payment system is\nimportant since it has a substantial impact on revenues for businesses. A\ngateway is an integral component of a payment system through which every\ntransaction is routed. In an online payment system, payment processors\nintegrate with these gateways by means of various configurations such as\npricing, methods, risk checks, etc. These configurations are called terminals.\nEach gateway can have multiple terminals associated with it. Routing a payment\ntransaction through the best terminal is crucial to increase the probability of\na payment transaction being successful. Machine learning (ML) and artificial\nintelligence (AI) techniques can be used to accurately predict the best\nterminals based on their previous performance and various payment-related\nattributes. We have devised a pipeline consisting of static and dynamic\nmodules. The static module does the initial filtering of the terminals using\nstatic rules and a logistic regression model that predicts gateway downtimes.\nSubsequently, the dynamic module computes a lot of novel features based on\nsuccess rate, payment attributes, time lag, etc. to model the terminal\nbehaviour accurately. These features are updated using an adaptive time decay\nrate algorithm in real-time using a feedback loop and passed to a random forest\nclassifier to predict the success probabilities for every terminal. This\npipeline is currently in production at Razorpay routing millions of\ntransactions through it in real-time and has given a 4-6\\% improvement in\nsuccess rate across all payment methods (credit card, debit card, UPI, net\nbanking). This has made our payment system more resilient to performance drops,\nwhich has improved the user experience, instilled more trust in the merchants,\nand boosted the revenue of the business.",
    "descriptor": "\nComments: 9 pages, 10 figures, Accepted at IEEE Big Data Conference - this https URL\n",
    "authors": [
      "Ramya Bygari",
      "Aayush Gupta",
      "Shashwat Raghuvanshi",
      "Aakanksha Bapna",
      "Birendra Sahu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00783"
  },
  {
    "id": "arXiv:2111.00787",
    "title": "Knowledge-driven Site Selection via Urban Knowledge Graph",
    "abstract": "Site selection determines optimal locations for new stores, which is of\ncrucial importance to business success. Especially, the wide application of\nartificial intelligence with multi-source urban data makes intelligent site\nselection promising. However, existing data-driven methods heavily rely on\nfeature engineering, facing the issues of business generalization and complex\nrelationship modeling. To get rid of the dilemma, in this work, we borrow ideas\nfrom knowledge graph (KG), and propose a knowledge-driven model for site\nselection, short for KnowSite. Specifically, motivated by distilled knowledge\nand rich semantics in KG, we firstly construct an urban KG (UrbanKG) with\ncities' key elements and semantic relationships captured. Based on UrbanKG, we\nemploy pre-training techniques for semantic representations, which are fed into\nan encoder-decoder structure for site decisions. With multi-relational message\npassing and relation path-based attention mechanism developed, KnowSite\nsuccessfully reveals the relationship between various businesses and site\nselection criteria. Extensive experiments on two datasets demonstrate that\nKnowSite outperforms representative baselines with both effectiveness and\nexplainability achieved.",
    "descriptor": "",
    "authors": [
      "Yu Liu",
      "Jingtao Ding",
      "Yong Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00787"
  },
  {
    "id": "arXiv:2111.00788",
    "title": "Hierarchical Adaptable and Transferable Networks (HATN) for Driving  Behavior Prediction",
    "abstract": "When autonomous vehicles still struggle to solve challenging situations\nduring on-road driving, humans have long mastered the essence of driving with\nefficient transferable and adaptable driving capability. By mimicking humans'\ncognition model and semantic understanding during driving, we present HATN, a\nhierarchical framework to generate high-quality driving behaviors in\nmulti-agent dense-traffic environments. Our method hierarchically consists of a\nhigh-level intention identification and low-level action generation policy.\nWith the semantic sub-task definition and generic state representation, the\nhierarchical framework is transferable across different driving scenarios.\nBesides, our model is also able to capture variations of driving behaviors\namong individuals and scenarios by an online adaptation module. We demonstrate\nour algorithms in the task of trajectory prediction for real traffic data at\nintersections and roundabouts, where we conducted extensive studies of the\nproposed method and demonstrated how our method outperformed other methods in\nterms of prediction accuracy and transferability.",
    "descriptor": "\nComments: 8 pages, 6 figures. Accepted by Advances in Neural Information Processing Systems Machine Learning for Autonomous Driving Workshop (NeurIPS ML4AD). October 2021\n",
    "authors": [
      "Letian Wang",
      "Yeping Hu",
      "Liting Sun",
      "Wei Zhan",
      "Masayoshi Tomizuka",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00788"
  },
  {
    "id": "arXiv:2111.00789",
    "title": "Learning Inertial Odometry for Dynamic Legged Robot State Estimation",
    "abstract": "This paper introduces a novel proprioceptive state estimator for legged\nrobots based on a learned displacement measurement from IMU data. Recent\nresearch in pedestrian tracking has shown that motion can be inferred from\ninertial data using convolutional neural networks. A learned inertial\ndisplacement measurement can improve state estimation in challenging scenarios\nwhere leg odometry is unreliable, such as slipping and compressible terrains.\nOur work learns to estimate a displacement measurement from IMU data which is\nthen fused with traditional leg odometry. Our approach greatly reduces the\ndrift of proprioceptive state estimation, which is critical for legged robots\ndeployed in vision and lidar denied environments such as foggy sewers or dusty\nmines. We compared results from an EKF and an incremental fixed-lag factor\ngraph estimator using data from several real robot experiments crossing\nchallenging terrains. Our results show a reduction of relative pose error by\n37% in challenging scenarios when compared to a traditional kinematic-inertial\nestimator without learned measurement. We also demonstrate a 22% reduction in\nerror when used with vision systems in visually degraded environments such as\nan underground mine.",
    "descriptor": "\nComments: To be presented at 5th Annual Conference on Robot Learning (CoRL), 2021\n",
    "authors": [
      "Russell Buchanan",
      "Marco Camurri",
      "Frank Dellaert",
      "Maurice Fallon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00789"
  },
  {
    "id": "arXiv:2111.00791",
    "title": "Learning Event-based Spatio-Temporal Feature Descriptors via Local  Synaptic Plasticity: A Biologically-realistic Perspective of Computer Vision",
    "abstract": "We present an optimization-based theory describing spiking cortical ensembles\nequipped with Spike-Timing-Dependent Plasticity (STDP) learning, as empirically\nobserved in the visual cortex. Using our methods, we build a class of\nfully-connected, convolutional and action-based feature descriptors for\nevent-based camera that we respectively assess on N-MNIST, challenging\nCIFAR10-DVS and on the IBM DVS128 gesture dataset. We report significant\naccuracy improvements compared to conventional state-of-the-art event-based\nfeature descriptors (+8% on CIFAR10-DVS). We report large improvements in\naccuracy compared to state-of-the-art STDP-based systems (+10% on N-MNIST,\n+7.74% on IBM DVS128 Gesture). In addition to ultra-low-power learning in\nneuromorphic edge devices, our work helps paving the way towards a\nbiologically-realistic, optimization-based theory of cortical vision.",
    "descriptor": "",
    "authors": [
      "Ali Safa",
      "Hichem Sahli",
      "Andr\u00e9 Bourdoux",
      "Ilja Ocket",
      "Francky Catthoor",
      "Georges Gielen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.00791"
  },
  {
    "id": "arXiv:2111.00794",
    "title": "Geodesic Models with Convexity Shape Prior",
    "abstract": "The minimal geodesic models based on the Eikonal equations are capable of\nfinding suitable solutions in various image segmentation scenarios. Existing\ngeodesic-based segmentation approaches usually exploit image features in\nconjunction with geometric regularization terms, such as Euclidean curve length\nor curvature-penalized length, for computing geodesic curves. In this paper, we\ntake into account a more complicated problem: finding curvature-penalized\ngeodesic paths with a convexity shape prior. We establish new geodesic models\nrelying on the strategy of orientation-lifting, by which a planar curve can be\nmapped to an high-dimensional orientation-dependent space. The convexity shape\nprior serves as a constraint for the construction of local geodesic metrics\nencoding a particular curvature constraint. Then the geodesic distances and the\ncorresponding closed geodesic paths in the orientation-lifted space can be\nefficiently computed through state-of-the-art Hamiltonian fast marching method.\nIn addition, we apply the proposed geodesic models to the active contours,\nleading to efficient interactive image segmentation algorithms that preserve\nthe advantages of convexity shape prior and curvature penalization.",
    "descriptor": "",
    "authors": [
      "Da Chen",
      "Jean-Marie Mirebeau",
      "Minglei Shu",
      "Xuecheng Tai",
      "Laurent D. Cohen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00794"
  },
  {
    "id": "arXiv:2111.00799",
    "title": "Challenging but Full of Opportunities: Teachers' Perspectives on  Programming in Primary Schools",
    "abstract": "The widespread establishment of computational thinking in school curricula\nrequires teachers to introduce children to programming already at primary\nschool level. As this is a recent development, primary school teachers may\nneither be adequately prepared for how to best teach programming, nor may they\nbe fully aware why they have to do so. In order to gain a better understanding\nof these questions, we contrast insights taken from practical experiences with\nthe anticipations of teachers in training. By surveying 200 teachers who have\ntaught programming at primary schools and 97 teachers in training, we identify\nrelevant challenges when teaching programming, opportunities that arise when\nchildren learn programming, and strategies how to address both of these in\npractice. While many challenges and opportunities are correctly anticipated, we\nfind several disagreements that can inform revisions of the curricula in\nteaching studies to better prepare primary school teachers for teaching\nprogramming at primary schools.",
    "descriptor": "\nComments: To be published in the Proceedings of the 21st Koli Calling International Conference on Computing Education Research (Koli Calling 2021)\n",
    "authors": [
      "Luisa Greifenstein",
      "Isabella Gra\u00dfl",
      "Gordon Fraser"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.00799"
  },
  {
    "id": "arXiv:2111.00801",
    "title": "Livestock Monitoring with Transformer",
    "abstract": "Tracking the behaviour of livestock enables early detection and thus\nprevention of contagious diseases in modern animal farms. Apart from economic\ngains, this would reduce the amount of antibiotics used in livestock farming\nwhich otherwise enters the human diet exasperating the epidemic of antibiotic\nresistance - a leading cause of death. We could use standard video cameras,\navailable in most modern farms, to monitor livestock. However, most computer\nvision algorithms perform poorly on this task, primarily because, (i) animals\nbred in farms look identical, lacking any obvious spatial signature, (ii) none\nof the existing trackers are robust for long duration, and (iii) real-world\nconditions such as changing illumination, frequent occlusion, varying camera\nangles, and sizes of the animals make it hard for models to generalize. Given\nthese challenges, we develop an end-to-end behaviour monitoring system for\ngroup-housed pigs to perform simultaneous instance level segmentation,\ntracking, action recognition and re-identification (STAR) tasks. We present\nstarformer, the first end-to-end multiple-object livestock monitoring framework\nthat learns instance-level embeddings for grouped pigs through the use of\ntransformer architecture. For benchmarking, we present Pigtrace, a carefully\ncurated dataset comprising video sequences with instance level bounding box,\nsegmentation, tracking and activity classification of pigs in real indoor\nfarming environment. Using simultaneous optimization on STAR tasks we show that\nstarformer outperforms popular baseline models trained for individual tasks.",
    "descriptor": "",
    "authors": [
      "Bhavesh Tangirala",
      "Ishan Bhandari",
      "Daniel Laszlo",
      "Deepak K. Gupta",
      "Rajat M. Thomas",
      "Devanshu Arya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00801"
  },
  {
    "id": "arXiv:2111.00805",
    "title": "FuCE: Fuzzing+Concolic Execution guided Trojan Detection in  Synthesizable Hardware Designs",
    "abstract": "High-level synthesis (HLS) is the next emerging trend for designing complex\ncustomized architectures for applications such as Machine Learning, Video\nProcessing. It provides a higher level of abstraction and freedom to hardware\nengineers to perform hardware software co-design. However, it opens up a new\ngateway to attackers to insert hardware trojans. Such trojans are semantically\nmore meaningful and stealthy, compared to gate-level trojans and therefore are\nhard-to-detect using state-of-the-art gate-level trojan detection techniques.\nAlthough recent works have proposed detection mechanisms to uncover such\nstealthy trojans in high-level synthesis (HLS) designs, these techniques are\neither specially curated for existing trojan benchmarks or may run into\nscalability issues for large designs. In this work, we leverage the power of\ngreybox fuzzing combined with concolic execution to explore deeper segments of\ndesign and uncover stealthy trojans. Experimental results show that our\nproposed framework is able to automatically detect trojans faster with fewer\ntest cases, while attaining notable branch coverage, without any manual\npre-processing analysis.",
    "descriptor": "\nComments: 23 pages, 4 figures, 6 tables, 4 listings\n",
    "authors": [
      "Mukta Debnath",
      "Animesh Basak Chowdhury",
      "Debasri Saha",
      "Susmita Sur-Kolay"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00805"
  },
  {
    "id": "arXiv:2111.00808",
    "title": "Unsupervised Discovery of Unaccusative and Unergative Verbs",
    "abstract": "We present an unsupervised method to detect English unergative and\nunaccusative verbs. These categories allow us to identify verbs participating\nin the causative-inchoative alternation without knowing the semantic roles of\nthe verb. The method is based on the generation of intransitive sentence\nvariants of candidate verbs and probing a language model. We obtained results\non par with similar approaches, with the added benefit of not relying on\nannotated resources.",
    "descriptor": "",
    "authors": [
      "Sharid Lo\u00e1iciga",
      "Luca Bevacqua",
      "Christian Hardmeier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00808"
  },
  {
    "id": "arXiv:2111.00814",
    "title": "Statistical quantification of confounding bias in predictive modelling",
    "abstract": "The lack of non-parametric statistical tests for confounding bias\nsignificantly hampers the development of robust, valid and generalizable\npredictive models in many fields of research. Here I propose the partial and\nfull confounder tests, which, for a given confounder variable, probe the null\nhypotheses of unconfounded and fully confounded models, respectively. The tests\nprovide a strict control for Type I errors and high statistical power, even for\nnon-normally and non-linearly dependent predictions, often seen in machine\nlearning. Applying the proposed tests on models trained on functional brain\nconnectivity data from the Human Connectome Project and the Autism Brain\nImaging Data Exchange dataset reveals confounders that were previously\nunreported or found to be hard to correct for with state-of-the-art confound\nmitigation approaches. The tests, implemented in the package mlconfound\n(https://mlconfound.readthedocs.io), can aid the assessment and improvement of\nthe generalizability and neurobiological validity of predictive models and,\nthereby, foster the development of clinically useful machine learning\nbiomarkers.",
    "descriptor": "\nComments: 20 pages, 7 figures. The manuscript is associated with the the python package `mlconfound`: this https URL See manuscript repository, including fully reproducible analysis code, here: this https URL\n",
    "authors": [
      "Tamas Spisak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00814"
  },
  {
    "id": "arXiv:2111.00821",
    "title": "Towards Reformulating Essence Specifications for Robustness",
    "abstract": "The Essence language allows a user to specify a constraint problem at a level\nof abstraction above that at which constraint modelling decisions are made.\nEssence specifications are refined into constraint models using the Conjure\nautomated modelling tool, which employs a suite of refinement rules. However,\nEssence is a rich language in which there are many equivalent ways to specify a\ngiven problem. A user may therefore omit the use of domain attributes or\nabstract types, resulting in fewer refinement rules being applicable and\ntherefore a reduced set of output models from which to select. This paper\naddresses the problem of recovering this information automatically to increase\nthe robustness of the quality of the output constraint models in the face of\nvariation in the input Essence specification. We present reformulation rules\nthat can change the type of a decision variable or add attributes that shrink\nits domain. We demonstrate the efficacy of this approach in terms of the\nquantity and quality of models Conjure can produce from the transformed\nspecification compared with the original.",
    "descriptor": "\nComments: 12 pages, 6 figures, presented at ModRef 2021\n",
    "authors": [
      "\u00d6zg\u00fcr Akg\u00fcn",
      "Alan M. Frisch",
      "Ian P. Gent",
      "Christopher Jefferson",
      "Ian Miguel",
      "Peter Nightingale",
      "Andr\u00e1s Z. Salamon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.00821"
  },
  {
    "id": "arXiv:2111.00823",
    "title": "LSTA-Net: Long short-term Spatio-Temporal Aggregation Network for  Skeleton-based Action Recognition",
    "abstract": "Modelling various spatio-temporal dependencies is the key to recognising\nhuman actions in skeleton sequences. Most existing methods excessively relied\non the design of traversal rules or graph topologies to draw the dependencies\nof the dynamic joints, which is inadequate to reflect the relationships of the\ndistant yet important joints. Furthermore, due to the locally adopted\noperations, the important long-range temporal information is therefore not well\nexplored in existing works. To address this issue, in this work we propose\nLSTA-Net: a novel Long short-term Spatio-Temporal Aggregation Network, which\ncan effectively capture the long/short-range dependencies in a spatio-temporal\nmanner. We devise our model into a pure factorised architecture which can\nalternately perform spatial feature aggregation and temporal feature\naggregation. To improve the feature aggregation effect, a channel-wise\nattention mechanism is also designed and employed. Extensive experiments were\nconducted on three public benchmark datasets, and the results suggest that our\napproach can capture both long-and-short range dependencies in the space and\ntime domain, yielding higher results than other state-of-the-art methods. Code\navailable at https://github.com/tailin1009/LSTA-Net.",
    "descriptor": "\nComments: Accepted by BMVC 2021\n",
    "authors": [
      "Tailin Chen",
      "Shidong Wang",
      "Desen Zhou",
      "Yu Guan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00823"
  },
  {
    "id": "arXiv:2111.00824",
    "title": "Living Literature Reviews",
    "abstract": "Literature reviews have long played a fundamental role in synthesizing the\ncurrent state of a research field. However, in recent years, certain fields\nhave evolved at such a rapid rate that literature reviews quickly lose their\nrelevance as new work is published that renders them outdated. We should\ntherefore rethink how to structure and publish such literature reviews with\ntheir highly valuable synthesized content. Here, we aim to determine if\nexisting Linked Data technologies can be harnessed to prolong the relevance of\nliterature reviews and whether researchers are comfortable with working with\nsuch a solution. We present here our approach of ``living literature reviews''\nwhere the core information is represented as Linked Data which can be amended\nwith new findings after the publication of the literature review. We present a\nprototype implementation, which we use for a case study where we expose\npotential users to a concrete literature review modeled with our approach. We\nobserve that our model is technically feasible and is received well by\nresearchers, with our ``living'' versions scoring higher than their traditional\ncounterparts in our user study. In conclusion, we find that there are strong\nbenefits to using a Linked Data solution to extend the effective lifetime of a\nliterature review.",
    "descriptor": "",
    "authors": [
      "Michel Wijkstra",
      "Timo Lek",
      "Tobias Kuhn",
      "Kasper Welbers",
      "Mickey Steijaert"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2111.00824"
  },
  {
    "id": "arXiv:2111.00826",
    "title": "Teaching Fairness, Accountability, Confidentiality, and Transparency in  Artificial Intelligence through the Lens of Reproducibility",
    "abstract": "In this work we explain the setup for a technical, graduate-level course on\nFairness, Accountability, Confidentiality and Transparency in Artificial\nIntelligence (FACT-AI) at the University of Amsterdam, which teaches FACT-AI\nconcepts through the lens of reproducibility. The focal point of the course is\na group project based on reproducing existing FACT-AI algorithms from top AI\nconferences, and writing a report about their experiences. In the first\niteration of the course, we created an open source repository with the code\nimplementations from the group projects. In the second iteration, we encouraged\nstudents to submit their group projects to the Machine Learning Reproducibility\nChallenge, which resulted in 9 reports from our course being accepted to the\nchallenge. We reflect on our experience teaching the course over two academic\nyears, where one year coincided with a global pandemic, and propose guidelines\nfor teaching FACT-AI through reproducibility in graduate-level AI programs. We\nhope this can be a useful resource for instructors to set up similar courses at\ntheir universities in the future.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Ana Lucic",
      "Maurits Bleeker",
      "Sami Jullien",
      "Samarth Bhargav",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00826"
  },
  {
    "id": "arXiv:2111.00830",
    "title": "Deep Learning Transformer Architecture for Named Entity Recognition on  Low Resourced Languages: State of the art results",
    "abstract": "This paper reports on the evaluation of Deep Learning (DL) transformer\narchitecture models for Named-Entity Recognition (NER) on ten low-resourced\nSouth African (SA) languages. In addition, these DL transformer models were\ncompared to other Neural Network and Machine Learning (ML) NER models. The\nfindings show that transformer models significantly improve performance when\napplying discrete fine-tuning parameters per language. Furthermore, fine-tuned\ntransformer models outperform other neural network and machine learning models\nwith NER on the low-resourced SA languages. For example, the transformer models\ngenerated the highest F-scores for six of the ten SA languages, including the\nhighest average F-score surpassing the Conditional Random Fields ML model.\nAdditional research could evaluate the more recent transformer architecture\nmodels on other Natural Language Processing tasks and applications, such as\nPhrase chunking, Machine Translation, and Part-of-Speech tagging.",
    "descriptor": "\nComments: 8 pages, 6 tables, and 3 figures\n",
    "authors": [
      "Ridewaan Hanslo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00830"
  },
  {
    "id": "arXiv:2111.00831",
    "title": "User-friendly Composition of FAIR Workflows in a Notebook Environment",
    "abstract": "There has been a large focus in recent years on making assets in scientific\nresearch findable, accessible, interoperable and reusable, collectively known\nas the FAIR principles. A particular area of focus lies in applying these\nprinciples to scientific computational workflows. Jupyter notebooks are a very\npopular medium by which to program and communicate computational scientific\nanalyses. However, they present unique challenges when it comes to reuse of\nonly particular steps of an analysis without disrupting the usual flow and\nbenefits of the notebook approach, making it difficult to fully comply with the\nFAIR principles. Here we present an approach and toolset for adding the power\nof semantic technologies to Python-encoded scientific workflows in a simple,\nautomated and minimally intrusive manner. The semantic descriptions are\npublished as a series of nanopublications that can be searched and used in\nother notebooks by means of a Jupyter Lab plugin. We describe the\nimplementation of the proposed approach and toolset, and provide the results of\na user study with 15 participants, designed around image processing workflows,\nto evaluate the usability of the system and its perceived effect on FAIRness.\nOur results show that our approach is feasible and perceived as user-friendly.\nOur system received an overall score of 78.75 on the System Usability Scale,\nwhich is above the average score reported in the literature.",
    "descriptor": "",
    "authors": [
      "Robin A Richardson",
      "Remzi Celebi",
      "Sven van der Burg",
      "Djura Smits",
      "Lars Ridder",
      "Michel Dumontier",
      "Tobias Kuhn"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.00831"
  },
  {
    "id": "arXiv:2111.00834",
    "title": "Fast Newton Iterative Method for Local Steric Poisson--Boltzmann  Theories in Biomolecular Solvation",
    "abstract": "This work proposes a fast iterative method for local steric\nPoisson--Boltzmann (PB) theories, in which the electrostatic potential is\ngoverned by the Poisson's equation and ionic concentrations satisfy equilibrium\nconditions. To present the method, we focus on a local steric PB theory derived\nfrom a lattice-gas model, as an example. The advantages of the proposed method\nin efficiency lies on a key idea that ionic concentrations as scalar implicit\nfunctions of the electrostatic potential, i.e, generalized Boltzmann\ndistributions, are numerically available. The existence, uniqueness, boundness,\nand smoothness of such distributions are rigorously established. A Newton\niteration method with truncation is proposed to solve a nonlinear system\ndiscretized from the generalized PB equations. The existence and uniqueness of\nthe solution to the discretized nonlinear system are established by showing\nthat it is a unique minimizer of a constructed convex energy. Thanks to the\nboundness of ionic concentrations, truncation bounds for the potential are\nobtained by using the extremum principle. The truncation step in iterations is\nshown to be energy, residual, and error decreasing. To further speed-up\ncomputations, we propose a novel precomputing-interpolation strategy, which is\napplicable to other local steric PB theories and makes the proposed methods for\nsolving steric PB theories as efficient as for solving the classical PB theory.\nAnalysis on the Newton iteration method with truncation shows local quadratic\nconvergence for the proposed numerical methods. Applications to realistic\nbiomolecular solvation systems reveal that counterions with steric hindrance\nstratify in an order prescribed by the parameter of ionic valence-to-volume\nratio. Finally, we remark that the proposed iterative methods for local steric\nPB theories can be readily incorporated in well-known classical PB solvers.",
    "descriptor": "",
    "authors": [
      "Minhong Chen",
      "Wei Dou",
      "Shenggao Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.00834"
  },
  {
    "id": "arXiv:2111.00843",
    "title": "Back to Basics: Efficient Network Compression via IMP",
    "abstract": "Network pruning is a widely used technique for effectively compressing Deep\nNeural Networks with little to no degradation in performance during inference.\nIterative Magnitude Pruning (IMP) is one of the most established approaches for\nnetwork pruning, consisting of several iterative training and pruning steps,\nwhere a significant amount of the network's performance is lost after pruning\nand then recovered in the subsequent retraining phase. While commonly used as a\nbenchmark reference, it is often argued that a) it reaches suboptimal states by\nnot incorporating sparsification into the training phase, b) its global\nselection criterion fails to properly determine optimal layer-wise pruning\nrates and c) its iterative nature makes it slow and non-competitive. In light\nof recently proposed retraining techniques, we investigate these claims through\nrigorous and consistent experiments where we compare IMP to\npruning-during-training algorithms, evaluate proposed modifications of its\nselection criterion and study the number of iterations and total training time\nactually required. We find that IMP with SLR for retraining can outperform\nstate-of-the-art pruning-during-training approaches without or with only little\ncomputational overhead, that the global magnitude selection criterion is\nlargely competitive with more complex approaches and that only few retraining\nepochs are needed in practice to achieve most of the sparsity-vs.-performance\ntradeoff of IMP. Our goals are both to demonstrate that basic IMP can already\nprovide state-of-the-art pruning results on par with or even outperforming more\ncomplex or heavily parameterized approaches and also to establish a more\nrealistic yet easily realisable baseline for future research.",
    "descriptor": "\nComments: 10 pages main text, 11 pages appendix, 4 tables, 12 figures\n",
    "authors": [
      "Max Zimmer",
      "Christoph Spiegel",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00843"
  },
  {
    "id": "arXiv:2111.00844",
    "title": "Exploring Non-Autoregressive End-To-End Neural Modeling For English  Mispronunciation Detection And Diagnosis",
    "abstract": "End-to-end (E2E) neural modeling has emerged as one predominant school of\nthought to develop computer-assisted language training (CAPT) systems, showing\ncompetitive performance to conventional pronunciation-scoring based methods.\nHowever, current E2E neural methods for CAPT are faced with at least two\npivotal challenges. On one hand, most of the E2E methods operate in an\nautoregressive manner with left-to-right beam search to dictate the\npronunciations of an L2 learners. This however leads to very slow inference\nspeed, which inevitably hinders their practical use. On the other hand, E2E\nneural methods are normally data greedy and meanwhile an insufficient amount of\nnonnative training data would often reduce their efficacy on mispronunciation\ndetection and diagnosis (MD&D). In response, we put forward a novel MD&D method\nthat leverages non-autoregressive (NAR) E2E neural modeling to dramatically\nspeed up the inference time while maintaining performance in line with the\nconventional E2E neural methods. In addition, we design and develop a\npronunciation modeling network stacked on top of the NAR E2E models of our\nmethod to further boost the effectiveness of MD&D. Empirical experiments\nconducted on the L2-ARCTIC English dataset seems to validate the feasibility of\nour method, in comparison to some top-of-the-line E2E models and an iconic\npronunciation-scoring based method built on a DNN-HMM acoustic model.",
    "descriptor": "\nComments: Preprint. Under review 5 pages, 2 figures\n",
    "authors": [
      "Hsin-Wei Wang",
      "Bi-Cheng Yan",
      "Hsuan-Sheng Chiu",
      "Yung-Chang Hsu",
      "Berlin Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.00844"
  },
  {
    "id": "arXiv:2111.00856",
    "title": "Large-Scale Deep Learning Optimizations: A Comprehensive Survey",
    "abstract": "Deep learning have achieved promising results on a wide spectrum of AI\napplications. Larger datasets and models consistently yield better performance.\nHowever, we generally spend longer training time on more computation and\ncommunication. In this survey, we aim to provide a clear sketch about the\noptimizations for large-scale deep learning with regard to the model accuracy\nand model efficiency. We investigate algorithms that are most commonly used for\noptimizing, elaborate the debatable topic of generalization gap arises in\nlarge-batch training, and review the SOTA strategies in addressing the\ncommunication overhead and reducing the memory footprints.",
    "descriptor": "",
    "authors": [
      "Xiaoxin He",
      "Fuzhao Xue",
      "Xiaozhe Ren",
      "Yang You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00856"
  },
  {
    "id": "arXiv:2111.00857",
    "title": "Individual codewords",
    "abstract": "Algorithmic information theory translates statements about classes of objects\ninto statements about individual objects; it defines individual random\nsequences, effective Hausdorff dimension of individual points, amount of\ninformation in individual strings, etc. We observe that a similar translation\nis possible for list-decodable codes.",
    "descriptor": "",
    "authors": [
      "Alexander Shen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.00857"
  },
  {
    "id": "arXiv:2111.00861",
    "title": "A Frequency Perspective of Adversarial Robustness",
    "abstract": "Adversarial examples pose a unique challenge for deep learning systems.\nDespite recent advances in both attacks and defenses, there is still a lack of\nclarity and consensus in the community about the true nature and underlying\nproperties of adversarial examples. A deep understanding of these examples can\nprovide new insights towards the development of more effective attacks and\ndefenses. Driven by the common misconception that adversarial examples are\nhigh-frequency noise, we present a frequency-based understanding of adversarial\nexamples, supported by theoretical and empirical findings. Our analysis shows\nthat adversarial examples are neither in high-frequency nor in low-frequency\ncomponents, but are simply dataset dependent. Particularly, we highlight the\nglaring disparities between models trained on CIFAR-10 and ImageNet-derived\ndatasets. Utilizing this framework, we analyze many intriguing properties of\ntraining robust models with frequency constraints, and propose a\nfrequency-based explanation for the commonly observed accuracy vs. robustness\ntrade-off.",
    "descriptor": "",
    "authors": [
      "Shishira R Maiya",
      "Max Ehrlich",
      "Vatsal Agarwal",
      "Ser-Nam Lim",
      "Tom Goldstein",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00861"
  },
  {
    "id": "arXiv:2111.00862",
    "title": "Surreal Decisions",
    "abstract": "Although expected utility theory has proven a fruitful and elegant theory in\nthe finite realm, attempts to generalize it to infinite values have resulted in\nmany paradoxes. In this paper, we argue that the use of John Conway's surreal\nnumbers shall provide a firm mathematical foundation for transfinite decision\ntheory. To that end, we prove a surreal representation theorem and show that\nour surreal decision theory respects dominance reasoning even in the case of\ninfinite values. We then bring our theory to bear on one of the more venerable\ndecision problems in the literature: Pascal's Wager. Analyzing the wager\nshowcases our theory's virtues and advantages. To that end, we analyze two\nobjections against the wager: Mixed Strategies and Many Gods. After formulating\nthe two objections in the framework of surreal utilities and probabilities, our\ntheory correctly predicts that (1) the pure Pascalian strategy beats all mixed\nstrategies, and (2) what one should do in a Pascalian decision problem depends\non what one's credence function is like. Our analysis therefore suggests that\nalthough Pascal's Wager is mathematically coherent, it does not deliver what it\npurports to, a rationally compelling argument that people should lead a\nreligious life regardless of how confident they are in theism and its\nalternatives.",
    "descriptor": "\nComments: First published online: 05 June 2018\n",
    "authors": [
      "Eddy Keming Chen",
      "Daniel Rubio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2111.00862"
  },
  {
    "id": "arXiv:2111.00865",
    "title": "MEmoBERT: Pre-training Model with Prompt-based Learning for Multimodal  Emotion Recognition",
    "abstract": "Multimodal emotion recognition study is hindered by the lack of labelled\ncorpora in terms of scale and diversity, due to the high annotation cost and\nlabel ambiguity. In this paper, we propose a pre-training model\n\\textbf{MEmoBERT} for multimodal emotion recognition, which learns multimodal\njoint representations through self-supervised learning from large-scale\nunlabeled video data that come in sheer volume. Furthermore, unlike the\nconventional \"pre-train, finetune\" paradigm, we propose a prompt-based method\nthat reformulates the downstream emotion classification task as a masked text\nprediction one, bringing the downstream task closer to the pre-training.\nExtensive experiments on two benchmark datasets, IEMOCAP and MSP-IMPROV, show\nthat our proposed MEmoBERT significantly enhances emotion recognition\nperformance.",
    "descriptor": "\nComments: 4 papges, 2 figures\n",
    "authors": [
      "Jinming Zhao",
      "Ruichen Li",
      "Qin Jin",
      "Xinchao Wang",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.00865"
  },
  {
    "id": "arXiv:2111.00867",
    "title": "Interpretive Blindness",
    "abstract": "We model here an epistemic bias we call \\textit{interpretive blindness} (IB).\nIB is a special problem for learning from testimony, in which one acquires\ninformation only from text or conversation. We show that IB follows from a\nco-dependence between background beliefs and interpretation in a Bayesian\nsetting and the nature of contemporary testimony. We argue that a particular\ncharacteristic contemporary testimony, \\textit{argumentative completeness}, can\npreclude learning in hierarchical Bayesian settings, even in the presence of\nconstraints that are designed to promote good epistemic practices.",
    "descriptor": "",
    "authors": [
      "Nicholas Asher",
      "Julie Hunter"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00867"
  },
  {
    "id": "arXiv:2111.00868",
    "title": "A mathematical model of the vowel space",
    "abstract": "The articulatory-acoustic relationship is many-to-one and non linear and this\nis a great limitation for studying speech production. A simplification is\nproposed to set a bijection between the vowel space (f1, f2) and the parametric\nspace of different vocal tract models. The generic area function model is based\non mixtures of cosines allowing the generation of main vowels with two\nformulas. Then the mixture function is transformed into a coordination function\nable to deal with articulatory parameters. This is shown that the coordination\nfunction acts similarly with the Fant's model and with the 4-Tube DRM derived\nfrom the generic model.",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Berthommier"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2111.00868"
  },
  {
    "id": "arXiv:2111.00869",
    "title": "DetectorNet: Transformer-enhanced Spatial Temporal Graph Neural Network  for Traffic Prediction",
    "abstract": "Detectors with high coverage have direct and far-reaching benefits for road\nusers in route planning and avoiding traffic congestion, but utilizing these\ndata presents unique challenges including: the dynamic temporal correlation,\nand the dynamic spatial correlation caused by changes in road conditions.\nAlthough the existing work considers the significance of modeling with\nspatial-temporal correlation, what it has learned is still a static road\nnetwork structure, which cannot reflect the dynamic changes of roads, and\neventually loses much valuable potential information. To address these\nchallenges, we propose DetectorNet enhanced by Transformer. Differs from\nprevious studies, our model contains a Multi-view Temporal Attention module and\na Dynamic Attention module, which focus on the long-distance and short-distance\ntemporal correlation, and dynamic spatial correlation by dynamically updating\nthe learned knowledge respectively, so as to make accurate prediction. In\naddition, the experimental results on two public datasets and the comparison\nresults of four ablation experiments proves that the performance of DetectorNet\nis better than the eleven advanced baselines.",
    "descriptor": "\nComments: The 29th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2021)\n",
    "authors": [
      "He Li",
      "Shiyu Zhang",
      "Xuejiao Li",
      "Liangcai Su",
      "Hongjie Huang",
      "Duo Jin",
      "Linghao Chen",
      "Jianbing Huang",
      "Jaesoo Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00869"
  },
  {
    "id": "arXiv:2111.00870",
    "title": "Statistical Consequences of Dueling Bandits",
    "abstract": "Multi-Armed-Bandit frameworks have often been used by researchers to assess\neducational interventions, however, recent work has shown that it is more\nbeneficial for a student to provide qualitative feedback through preference\nelicitation between different alternatives, making a dueling bandits framework\nmore appropriate. In this paper, we explore the statistical quality of data\nunder this framework by comparing traditional uniform sampling to a dueling\nbandit algorithm and find that dueling bandit algorithms perform well at\ncumulative regret minimisation, but lead to inflated Type-I error rates and\nreduced power under certain circumstances. Through these results we provide\ninsight into the challenges and opportunities in using dueling bandit\nalgorithms to run adaptive experiments.",
    "descriptor": "\nComments: In Workshop on Reinforcement Learning for Education, 14th International Conference on Educational Data Mining , Paris, France, 2021\n",
    "authors": [
      "Nayan Saxena",
      "Pan Chen",
      "Emmy Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.00870"
  },
  {
    "id": "arXiv:2111.00873",
    "title": "Probabilistic prediction of the heave motions of a semi-submersible by a  deep learning problem model",
    "abstract": "The real-time motion prediction of a floating offshore platform refers to\nforecasting its motions in the following one- or two-wave cycles, which helps\nimprove the performance of a motion compensation system and provides useful\nearly warning information. In this study, we extend a deep learning (DL) model,\nwhich could predict the heave and surge motions of a floating semi-submersible\n20 to 50 seconds ahead with good accuracy, to quantify its uncertainty of the\npredictive time series with the help of the dropout technique. By repeating the\ninference several times, it is found that the collection of the predictive time\nseries is a Gaussian process (GP). The DL model with dropout learned a kernel\ninside, and the learning procedure was similar to GP regression. Adding noise\ninto training data could help the model to learn more robust features from the\ntraining data, thereby leading to a better performance on test data with a wide\nnoise level range. This study extends the understanding of the DL model to\npredict the wave excited motions of an offshore platform.",
    "descriptor": "",
    "authors": [
      "Xiaoxian Guo",
      "Xiantao Zhang",
      "Xinliang Tian",
      "Wenyue Lu",
      "Xin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00873"
  },
  {
    "id": "arXiv:2111.00874",
    "title": "An Uncertainty-Informed Framework for Trustworthy Fault Diagnosis in  Safety-Critical Applications",
    "abstract": "There has been a growing interest in deep learning-based prognostic and\nhealth management (PHM) for building end-to-end maintenance decision support\nsystems, especially due to the rapid development of autonomous systems.\nHowever, the low trustworthiness of PHM hinders its applications in\nsafety-critical assets when handling data from an unknown distribution that\ndiffers from the training dataset, referred to as the out-of-distribution (OOD)\ndataset. To bridge this gap, we propose an uncertainty-informed framework to\ndiagnose faults and meanwhile detect the OOD dataset, enabling the capability\nof learning unknowns and achieving trustworthy fault diagnosis. Particularly,\nwe develop a probabilistic Bayesian convolutional neural network (CNN) to\nquantify both epistemic and aleatory uncertainties in fault diagnosis. The\nfault diagnosis model flags the OOD dataset with large predictive uncertainty\nfor expert intervention and is confident in providing predictions for the data\nwithin tolerable uncertainty. This results in trustworthy fault diagnosis and\nreduces the risk of erroneous decision-making, thus potentially avoiding\nundesirable consequences. The proposed framework is demonstrated by the fault\ndiagnosis of bearings with three OOD datasets attributed to random number\ngeneration, an unknown fault mode, and four common sensor faults, respectively.\nThe results show that the proposed framework is of particular advantage in\ntackling unknowns and enhancing the trustworthiness of fault diagnosis in\nsafety-critical applications.",
    "descriptor": "\nComments: 49 pages\n",
    "authors": [
      "Taotao Zhou",
      "Enrique Lopez Droguett",
      "Ali Mosleh",
      "Felix T.S. Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00874"
  },
  {
    "id": "arXiv:2111.00875",
    "title": "A moment-matching metric for latent variable generative models",
    "abstract": "It can be difficult to assess the quality of a fitted model when facing\nunsupervised learning problems. Latent variable models, such as variation\nautoencoders and Gaussian mixture models, are often trained with\nlikelihood-based approaches. In scope of Goodhart's law, when a metric becomes\na target it ceases to be a good metric and therefore we should not use\nlikelihood to assess the quality of the fit of these models. The solution we\npropose is a new metric for model comparison or regularization that relies on\nmoments. The concept is to study the difference between the data moments and\nthe model moments using a matrix norm, such as the Frobenius norm. We show how\nto use this new metric for model comparison and then for regularization. It is\ncommon to draw samples from the fitted distribution when evaluating latent\nvariable models and we show that our proposed metric is faster to compute and\nhas a smaller variance that this alternative. We conclude this article with a\nproof of concept of both applications and we discuss future work.",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Beaulac"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00875"
  },
  {
    "id": "arXiv:2111.00876",
    "title": "On the Expressivity of Markov Reward",
    "abstract": "Reward is the driving force for reinforcement-learning agents. This paper is\ndedicated to understanding the expressivity of reward as a way to capture tasks\nthat we would want an agent to perform. We frame this study around three new\nabstract notions of \"task\" that might be desirable: (1) a set of acceptable\nbehaviors, (2) a partial ordering over behaviors, or (3) a partial ordering\nover trajectories. Our main results prove that while reward can express many of\nthese tasks, there exist instances of each task type that no Markov reward\nfunction can capture. We then provide a set of polynomial-time algorithms that\nconstruct a Markov reward function that allows an agent to optimize tasks of\neach of these three types, and correctly determine when no such reward function\nexists. We conclude with an empirical study that corroborates and illustrates\nour theoretical findings.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "David Abel",
      "Will Dabney",
      "Anna Harutyunyan",
      "Mark K. Ho",
      "Michael L. Littman",
      "Doina Precup",
      "Satinder Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00876"
  },
  {
    "id": "arXiv:2111.00880",
    "title": "Benchmarks for Corruption Invariant Person Re-identification",
    "abstract": "When deploying person re-identification (ReID) model in safety-critical\napplications, it is pivotal to understanding the robustness of the model\nagainst a diverse array of image corruptions. However, current evaluations of\nperson ReID only consider the performance on clean datasets and ignore images\nin various corrupted scenarios. In this work, we comprehensively establish six\nReID benchmarks for learning corruption invariant representation. In the field\nof ReID, we are the first to conduct an exhaustive study on corruption\ninvariant learning in single- and cross-modality datasets, including\nMarket-1501, CUHK03, MSMT17, RegDB, SYSU-MM01. After reproducing and examining\nthe robustness performance of 21 recent ReID methods, we have some\nobservations: 1) transformer-based models are more robust towards corrupted\nimages, compared with CNN-based models, 2) increasing the probability of random\nerasing (a commonly used augmentation method) hurts model corruption\nrobustness, 3) cross-dataset generalization improves with corruption robustness\nincreases. By analyzing the above observations, we propose a strong baseline on\nboth single- and cross-modality ReID datasets which achieves improved\nrobustness against diverse corruptions. Our codes are available on\nhttps://github.com/MinghuiChen43/CIL-ReID.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021 Track on Datasets and Benchmarks. Project page: this https URL\n",
    "authors": [
      "Minghui Chen",
      "Zhiqiang Wang",
      "Feng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00880"
  },
  {
    "id": "arXiv:2111.00881",
    "title": "Artificial Intelligence in the Low-Level Realm -- A Survey",
    "abstract": "Resource-aware machine learning has been a trending topic in recent years,\nfocusing on making ML computational aspects more exploitable by the edge\ndevices in the Internet of Things. This paper attempts to review a conceptually\nand practically related area concentrated on efforts and challenges for\napplying ML in the operating systems' main tasks in a low-resource environment.\nArtificial Intelligence has been integrated into the operating system with\napplications such as voice or image recognition. However, this integration is\nonly in user space. Here, we seek methods and efforts that exploit AI\napproaches, specifically machine learning, in the OSes' primary\nresponsibilities. We provide the improvements that ML can bring to OS to make\nthem more trustworthy. In other words, the main question to be answered is how\nAI has played/can play a role directly in improving the traditional OS kernel\nmain tasks. Also, the challenges and limitations in the way of this combination\nare provided.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Vahid Mohammadi Safarzadeh",
      "Hamed Ghasr Loghmani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00881"
  },
  {
    "id": "arXiv:2111.00884",
    "title": "Enhanced Language Representation with Label Knowledge for Span  Extraction",
    "abstract": "Span extraction, aiming to extract text spans (such as words or phrases) from\nplain texts, is a fundamental process in Information Extraction. Recent works\nintroduce the label knowledge to enhance the text representation by formalizing\nthe span extraction task into a question answering problem (QA Formalization),\nwhich achieves state-of-the-art performance. However, QA Formalization does not\nfully exploit the label knowledge and suffers from low efficiency in\ntraining/inference. To address those problems, we introduce a new paradigm to\nintegrate label knowledge and further propose a novel model to explicitly and\nefficiently integrate label knowledge into text representations. Specifically,\nit encodes texts and label annotations independently and then integrates label\nknowledge into text representation with an elaborate-designed semantics fusion\nmodule. We conduct extensive experiments on three typical span extraction\ntasks: flat NER, nested NER, and event detection. The empirical results show\nthat 1) our method achieves state-of-the-art performance on four benchmarks,\nand 2) reduces training time and inference time by 76% and 77% on average,\nrespectively, compared with the QA Formalization paradigm. Our code and data\nare available at https://github.com/Akeepers/LEAR.",
    "descriptor": "\nComments: Accepted to the main conference of EMNLP 2021 (long paper)\n",
    "authors": [
      "Pan Yang",
      "Xin Cong",
      "Zhenyun Sun",
      "Xingwu Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00884"
  },
  {
    "id": "arXiv:2111.00885",
    "title": "Algorithms for Interference Minimization in Future Wireless Network  Decomposition",
    "abstract": "We propose a simple and fast method for providing a high quality solution for\nthe sum-interference minimization problem. As future networks are deployed in\nhigh density urban areas, improved clustering methods are needed to provide low\ninterference network connectivity. The proposed algorithm applies\nstraightforward similarity based clustering and optionally stable matchings to\noutperform state of the art algorithms. The running times of our algorithms are\ndominated by one matrix multiplication.",
    "descriptor": "",
    "authors": [
      "P\u00e9ter L. Erd\u0151s",
      "Tam\u00e1s R\u00f3bert Mezei",
      "Yiding Yu",
      "Xiang Chen",
      "Wei Han",
      "Bo Bai"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.00885"
  },
  {
    "id": "arXiv:2111.00886",
    "title": "Intervention Efficient Algorithm for Two-Stage Causal MDPs",
    "abstract": "We study Markov Decision Processes (MDP) wherein states correspond to causal\ngraphs that stochastically generate rewards. In this setup, the learner's goal\nis to identify atomic interventions that lead to high rewards by intervening on\nvariables at each state. Generalizing the recent causal-bandit framework, the\ncurrent work develops (simple) regret minimization guarantees for two-stage\ncausal MDPs, with parallel causal graph at each state. We propose an algorithm\nthat achieves an instance dependent regret bound. A key feature of our\nalgorithm is that it utilizes convex optimization to address the exploration\nproblem. We identify classes of instances wherein our regret guarantee is\nessentially tight, and experimentally validate our theoretical results.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Rahul Madhavan",
      "Aurghya Maiti",
      "Gaurav Sinha",
      "Siddharth Barman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00886"
  },
  {
    "id": "arXiv:2111.00890",
    "title": "In-layer Thermal Control of a Multi-layer Selective Laser Melting  Process",
    "abstract": "Selective Laser Melting (SLM) is an additive manufacturing technology that\nbuilds three dimensional parts by melting layers of metal powder together with\na laser that traces out a desired geometry. SLM is popular in industry, however\nthe inherent melting and re-solidification of the metal during the process can,\nif left uncontrolled, cause excessive residual stress, porosity, and other\ndefects in the final printed parts. This paper presents a control-oriented\nthermal model of a multi-layer SLM process and proposes a structured model\nreduction methodology with an associated reduced order model based in-layer\ncontroller to track temperature references. Simulation studies demonstrate that\nthe controller is able to prevent layer-to-layer heat buildup and that good\nclosed-loop performance is possible using relatively low-order models.",
    "descriptor": "",
    "authors": [
      "Dominic Liao-McPherson",
      "Efe C. Balta",
      "Ryan W\u00fcest",
      "Alisa Rupenyan",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00890"
  },
  {
    "id": "arXiv:2111.00892",
    "title": "Hierarchical Image Classification with A Literally Toy Dataset",
    "abstract": "Unsupervised domain adaptation (UDA) in image classification remains a big\nchallenge. In existing UDA image dataset, classes are usually organized in a\nflattened way, where a plain classifier can be trained. Yet in some scenarios,\nthe flat categories originate from some base classes. For example, buggies\nbelong to the class bird. We define the classification task where classes have\ncharacteristics above and the flat classes and the base classes are organized\nhierarchically as hierarchical image classification. Intuitively, leveraging\nsuch hierarchical structure will benefit hierarchical image classification,\ne.g., two easily confusing classes may belong to entirely different base\nclasses. In this paper, we improve the performance of classification by fusing\nfeatures learned from a hierarchy of labels. Specifically, we train feature\nextractors supervised by hierarchical labels and with UDA technology, which\nwill output multiple features for an input image. The features are subsequently\nconcatenated to predict the finest-grained class. This study is conducted with\na new dataset named Lego-15. Consisting of synthetic images and real images of\nthe Lego bricks, the Lego-15 dataset contains 15 classes of bricks. Each class\noriginates from a coarse-level label and a middle-level label. For example,\nclass \"85080\" is associated with bricks (coarse) and bricks round (middle). In\nthis dataset, we demonstrate that our method brings about consistent\nimprovement over the baseline in UDA in hierarchical image classification.\nExtensive ablation and variant studies provide insights into the new dataset\nand the investigated algorithm.",
    "descriptor": "",
    "authors": [
      "Long He",
      "Dandan Song",
      "Liang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00892"
  },
  {
    "id": "arXiv:2111.00898",
    "title": "Indiscriminate Poisoning Attacks Are Shortcuts",
    "abstract": "Indiscriminate data poisoning attacks, which add imperceptible perturbations\nto training data to maximize the test error of trained models, have become a\ntrendy topic because they are thought to be capable of preventing unauthorized\nuse of data. In this work, we investigate why these perturbations work in\nprinciple. We find that the perturbations of advanced poisoning attacks are\nalmost \\textbf{linear separable} when assigned with the target labels of the\ncorresponding samples, which hence can work as \\emph{shortcuts} for the\nlearning objective. This important population property has not been unveiled\nbefore. Moreover, we further verify that linear separability is indeed the\nworkhorse for poisoning attacks. We synthesize linear separable data as\nperturbations and show that such synthetic perturbations are as powerful as the\ndeliberately crafted attacks. Our finding suggests that the \\emph{shortcut\nlearning} problem is more serious than previously believed as deep learning\nheavily relies on shortcuts even if they are of an imperceptible scale and\nmixed together with the normal features. This finding also suggests that\npre-trained feature extractors would disable these poisoning attacks\neffectively.",
    "descriptor": "",
    "authors": [
      "Da Yu",
      "Huishuai Zhang",
      "Wei Chen",
      "Jian Yin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00898"
  },
  {
    "id": "arXiv:2111.00899",
    "title": "Equivariant Contrastive Learning",
    "abstract": "In state-of-the-art self-supervised learning (SSL) pre-training produces\nsemantically good representations by encouraging them to be invariant under\nmeaningful transformations prescribed from human knowledge. In fact, the\nproperty of invariance is a trivial instance of a broader class called\nequivariance, which can be intuitively understood as the property that\nrepresentations transform according to the way the inputs transform. Here, we\nshow that rather than using only invariance, pre-training that encourages\nnon-trivial equivariance to some transformations, while maintaining invariance\nto other transformations, can be used to improve the semantic quality of\nrepresentations. Specifically, we extend popular SSL methods to a more general\nframework which we name Equivariant Self-Supervised Learning (E-SSL). In E-SSL,\na simple additional pre-training objective encourages equivariance by\npredicting the transformations applied to the input. We demonstrate E-SSL's\neffectiveness empirically on several popular computer vision benchmarks.\nFurthermore, we demonstrate usefulness of E-SSL for applications beyond\ncomputer vision; in particular, we show its utility on regression problems in\nphotonics science. We will release our code.",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Rumen Dangovski",
      "Li Jing",
      "Charlotte Loh",
      "Seungwook Han",
      "Akash Srivastava",
      "Brian Cheung",
      "Pulkit Agrawal",
      "Marin Solja\u010di\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.00899"
  },
  {
    "id": "arXiv:2111.00900",
    "title": "On the Usage of Networked Tethered Flying Platforms for Massive Events  -- Case Study: Hajj Pilgrimage",
    "abstract": "The Hajj is a religious Muslim pilgrimage undertaken annually by 2-3 million\npeople in Makkah. Consequently, several problems arise due to the sheer number\nof pilgrims, and therefore negatively impact their stay and the conduct of the\nrituals. During the Hajj, several problems occur related to mobility, security,\nand connectivity. The current solutions used to deal with these problems have\nlimitations and they usually require a lot of resources with suboptimal\nresults. In this paper, we proposed an aerial-based solution that rely on\nNetworked Tethered Flying Platforms (NTFPs). NTFPs are flying vehicles such as\ndrones, Helikites, and blimps, that are tethered to the ground via a cable that\nsupplies them with constant data and power. NTFPs can fly at high altitude with\na great backhaul capacity and large coverage. We show in this paper how\nNTFP-based solution solve mobility, security, and connectivity problems during\nthe Hajj and the main advantages and benefits as well as the cost-efficiency of\nsuch solution. For the sake of completeness, we also present other similar case\nstudies in which NTFPs can be used.",
    "descriptor": "",
    "authors": [
      "Baha Eddine Youcef Belmekki",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00900"
  },
  {
    "id": "arXiv:2111.00901",
    "title": "Click-Based Student Performance Prediction: A Clustering Guided  Meta-Learning Approach",
    "abstract": "We study the problem of predicting student knowledge acquisition in online\ncourses from clickstream behavior. Motivated by the proliferation of eLearning\nlecture delivery, we specifically focus on student in-video activity in\nlectures videos, which consist of content and in-video quizzes. Our methodology\nfor predicting in-video quiz performance is based on three key ideas we\ndevelop. First, we model students' clicking behavior via time-series learning\narchitectures operating on raw event data, rather than defining hand-crafted\nfeatures as in existing approaches that may lose important information embedded\nwithin the click sequences. Second, we develop a self-supervised clickstream\npre-training to learn informative representations of clickstream events that\ncan initialize the prediction model effectively. Third, we propose a clustering\nguided meta-learning-based training that optimizes the prediction model to\nexploit clusters of frequent patterns in student clickstream sequences. Through\nexperiments on three real-world datasets, we demonstrate that our method\nobtains substantial improvements over two baseline models in predicting\nstudents' in-video quiz performance. Further, we validate the importance of the\npre-training and meta-learning components of our framework through ablation\nstudies. Finally, we show how our methodology reveals insights on\nvideo-watching behavior associated with knowledge acquisition for useful\nlearning analytics.",
    "descriptor": "\nComments: 10 pages, IEEE BigData 2021\n",
    "authors": [
      "Yun-Wei Chu",
      "Elizabeth Tenorio",
      "Laura Cruz",
      "Kerrie Douglas",
      "Andrew S. Lan",
      "Christopher G. Brinton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00901"
  },
  {
    "id": "arXiv:2111.00902",
    "title": "PP-PicoDet: A Better Real-Time Object Detector on Mobile Devices",
    "abstract": "The better accuracy and efficiency trade-off has been a challenging problem\nin object detection. In this work, we are dedicated to studying key\noptimizations and neural network architecture choices for object detection to\nimprove accuracy and efficiency. We investigate the applicability of the\nanchor-free strategy on lightweight object detection models. We enhance the\nbackbone structure and design the lightweight structure of the neck, which\nimproves the feature extraction ability of the network. We improve label\nassignment strategy and loss function to make training more stable and\nefficient. Through these optimizations, we create a new family of real-time\nobject detectors, named PP-PicoDet, which achieves superior performance on\nobject detection for mobile devices. Our models achieve better trade-offs\nbetween accuracy and latency compared to other popular models. PicoDet-S with\nonly 0.99M parameters achieves 30.6% mAP, which is an absolute 4.8% improvement\nin mAP while reducing mobile CPU inference latency by 55% compared to\nYOLOX-Nano, and is an absolute 7.1% improvement in mAP compared to NanoDet. It\nreaches 123 FPS (150 FPS using Paddle Lite) on mobile ARM CPU when the input\nsize is 320. PicoDet-L with only 3.3M parameters achieves 40.9% mAP, which is\nan absolute 3.7% improvement in mAP and 44% faster than YOLOv5s. As shown in\nFigure 1, our models far outperform the state-of-the-art results for\nlightweight object detection. Code and pre-trained models are available at\nhttps://github.com/PaddlePaddle/PaddleDetection.",
    "descriptor": "\nComments: 9 pages, 3 figures, 5 tables\n",
    "authors": [
      "Guanghua Yu",
      "Qinyao Chang",
      "Wenyu Lv",
      "Chang Xu",
      "Cheng Cui",
      "Wei Ji",
      "Qingqing Dang",
      "Kaipeng Deng",
      "Guanzhong Wang",
      "Yuning Du",
      "Baohua Lai",
      "Qiwen Liu",
      "Xiaoguang Hu",
      "Dianhai Yu",
      "Yanjun Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00902"
  },
  {
    "id": "arXiv:2111.00903",
    "title": "Towards a theory of quantum gravity from neural networks",
    "abstract": "Neural network is a dynamical system described by two different types of\ndegrees of freedom: fast-changing non-trainable variables (e.g. state of\nneurons) and slow-changing trainable variables (e.g. weights and biases). We\nshow that the non-equilibrium dynamics of trainable variables can be described\nby the Madelung equations, if the number of neurons is fixed, and by the\nSchrodinger equation, if the learning system is capable of adjusting its own\nparameters such as the number of neurons, step size and mini-batch size. We\nargue that the Lorentz symmetries and curved space-time can emerge from the\ninterplay between stochastic entropy production and entropy destruction due to\nlearning. We show that the non-equilibrium dynamics of non-trainable variables\ncan be described by the geodesic equation (in the emergent space-time) for\nlocalized states of neurons, and by the Einstein equations (with cosmological\nconstant) for the entire network. We conclude that the quantum description of\ntrainable variables and the gravitational description of non-trainable\nvariables are dual in the sense that they provide alternative macroscopic\ndescriptions of the same learning system, defined microscopically as a neural\nnetwork.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Vitaly Vanchurin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)",
      "High Energy Physics - Theory (hep-th)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.00903"
  },
  {
    "id": "arXiv:2111.00905",
    "title": "Smart Fashion: A Review of AI Applications in the Fashion & Apparel  Industry",
    "abstract": "The fashion industry is on the verge of an unprecedented change. The\nimplementation of machine learning, computer vision, and artificial\nintelligence (AI) in fashion applications is opening lots of new opportunities\nfor this industry. This paper provides a comprehensive survey on this matter,\ncategorizing more than 580 related articles into 22 well-defined\nfashion-related tasks. Such structured task-based multi-label classification of\nfashion research articles provides researchers with explicit research\ndirections and facilitates their access to the related studies, improving the\nvisibility of studies simultaneously. For each task, a time chart is provided\nto analyze the progress through the years. Furthermore, we provide a list of 86\npublic fashion datasets accompanied by a list of suggested applications and\nadditional information for each.",
    "descriptor": "\nComments: 99 Pages, 79 Figures, 24 Tables, Full length manuscript\n",
    "authors": [
      "Seyed Omid Mohammadi",
      "Ahmad Kalhor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00905"
  },
  {
    "id": "arXiv:2111.00909",
    "title": "Multi-Attribute Balanced Sampling for Disentangled GAN Controls",
    "abstract": "Various controls over the generated data can be extracted from the latent\nspace of a pre-trained GAN, as it implicitly encodes the semantics of the\ntraining data. The discovered controls allow to vary semantic attributes in the\ngenerated images but usually lead to entangled edits that affect multiple\nattributes at the same time. Supervised approaches typically sample and\nannotate a collection of latent codes, then train classifiers in the latent\nspace to identify the controls. Since the data generated by GANs reflects the\nbiases of the original dataset, so do the resulting semantic controls. We\npropose to address disentanglement by subsampling the generated data to remove\nover-represented co-occuring attributes thus balancing the semantics of the\ndataset before training the classifiers. We demonstrate the effectiveness of\nthis approach by extracting disentangled linear directions for face\nmanipulation on two popular GAN architectures, PGGAN and StyleGAN, and two\ndatasets, CelebAHQ and FFHQ. We show that this approach outperforms\nstate-of-the-art classifier-based methods while avoiding the need for\ndisentanglement-enforcing post-processing.",
    "descriptor": "",
    "authors": [
      "Perla Doubinsky",
      "Nicolas Audebert",
      "Michel Crucianu",
      "Herv\u00e9 Le Borgne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00909"
  },
  {
    "id": "arXiv:2111.00910",
    "title": "Distance and Bounds for Flag Codes",
    "abstract": "Given $\\mathbb{F}_q$ the finite field with $q$ elements and an integer $n\\geq\n2$, a flag is a sequence of nested subspaces of $\\mathbb{F}_q^n$ and a flag\ncode is a nonempty set of flags. In this context, the distance between flags is\nthe sum of the corresponding subspace distances. Hence, a given flag distance\nvalue might be obtained by many different combinations. To capture such a\nvariability, in the paper at hand, we introduce the notion of distance vector\nas an algebraic object intrinsically associated to a flag code that encloses\nmuch more information than the distance parameter itself. Our study of the flag\ndistance by using this new tool allows us to provide a fine description of the\nstructure of flag codes as well as to derive bounds for their maximum possible\nsize once the minimum distance and dimensions are fixed.",
    "descriptor": "",
    "authors": [
      "Clementa Alonso-Gonz\u00e1lez",
      "Miguel \u00c1ngel Navarro-P\u00e9rez",
      "Xaro Soler-Escriv\u00e0"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.00910"
  },
  {
    "id": "arXiv:2111.00917",
    "title": "Adaptive Modeling Powers Fast Multi-parameter Fitting of CARS Spectra",
    "abstract": "Coherent anti-Stokes Raman Spectroscopy (CARS) is a laser-based measurement\ntechnique widely applied across many science and engineering disciplines to\nperform non-intrusive gas diagnostics. CARS is often used to study combustion,\nwhere the measured spectra can be used to simultaneously recover multiple flow\nparameters from the reacting gas such as temperature and relative species mole\nfractions. This is typically done by using numerical optimization to find the\nflow parameters for which a theoretical model of the CARS spectra best matches\nthe actual measurements. The most commonly used theoretical model is the CARSFT\nspectrum calculator. Unfortunately, this CARSFT spectrum generator is\ncomputationally expensive and using it to recover multiple flow parameters can\nbe prohibitively time-consuming, especially when experiments have hundreds or\nthousands of measurements distributed over time or space. To overcome these\nissues, several methods have been developed to approximate CARSFT using a\nlibrary of pre-computed theoretical spectra. In this work we present a new\napproach that leverages ideas from the machine learning literature to build an\nadaptively smoothed kernel-based approximator. In application on a simulated\ndual-pump CARS experiment probing a $H_2/$air flame, we show that the approach\ncan use a small number library spectra to quickly and accurately recover\ntemperature and four gas species' mole fractions. The method's flexibility\nallows fine-tuned navigation of the trade-off between speed and accuracy, and\nmakes the approach suitable for a wide range of problems and flow regimes.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Gregory J. Hunt",
      "Cody R. Ground",
      "Andrew D. Cutler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2111.00917"
  },
  {
    "id": "arXiv:2111.00918",
    "title": "Combining expert knowledge and neural networks to model environmental  stresses in agriculture",
    "abstract": "In this work we combine representation learning capabilities of neural\nnetwork with agricultural knowledge from experts to model environmental heat\nand drought stresses. We first design deterministic expert models which serve\nas a benchmark and inform the design of flexible neural-network architectures.\nFinally, a sensitivity analysis of the latter allows a clustering of hybrids\ninto susceptible and resistant ones.",
    "descriptor": "\nComments: 19 pages, Winners of the 2019 Syngenta Crop Challenge\n",
    "authors": [
      "Kostadin Cvejoski",
      "Jannis Schuecker",
      "Anne-Katrin Mahlein",
      "Bogdan Georgiev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.00918"
  },
  {
    "id": "arXiv:2111.00919",
    "title": "DFCANet: Dense Feature Calibration-Attention Guided Network for Cross  Domain Iris Presentation Attack Detection",
    "abstract": "An iris presentation attack detection (IPAD) is essential for securing\npersonal identity is widely used iris recognition systems. However, the\nexisting IPAD algorithms do not generalize well to unseen and cross-domain\nscenarios because of capture in unconstrained environments and high visual\ncorrelation amongst bonafide and attack samples. These similarities in\nintricate textural and morphological patterns of iris ocular images contribute\nfurther to performance degradation. To alleviate these shortcomings, this paper\nproposes DFCANet: Dense Feature Calibration and Attention Guided Network which\ncalibrates the locally spread iris patterns with the globally located ones.\nUplifting advantages from feature calibration convolution and residual\nlearning, DFCANet generates domain-specific iris feature representations. Since\nsome channels in the calibrated feature maps contain more prominent\ninformation, we capitalize discriminative feature learning across the channels\nthrough the channel attention mechanism. In order to intensify the challenge\nfor our proposed model, we make DFCANet operate over nonsegmented and\nnon-normalized ocular iris images. Extensive experimentation conducted over\nchallenging cross-domain and intra-domain scenarios highlights consistent\noutperforming results. Compared to state-of-the-art methods, DFCANet achieves\nsignificant gains in performance for the benchmark IIITD CLI, IIIT CSD and\nNDCLD13 databases respectively. Further, a novel incremental learning-based\nmethodology has been introduced so as to overcome disentangled iris-data\ncharacteristics and data scarcity. This paper also pursues the challenging\nscenario that considers soft-lens under the attack category with evaluation\nperformed under various cross-domain protocols. The code will be made publicly\navailable.",
    "descriptor": "",
    "authors": [
      "Gaurav Jaswal",
      "Aman Verma",
      "Sumantra Dutta Roy",
      "Raghavendra Ramachandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00919"
  },
  {
    "id": "arXiv:2111.00926",
    "title": "Heterogeneous Graph Neural Networks for Large-Scale Bid Keyword Matching",
    "abstract": "Digital advertising is a critical part of many e-commerce platforms such as\nTaobao and Amazon. While in recent years a lot of attention has been drawn to\nthe consumer side including canonical problems like ctr/cvr prediction, the\nadvertiser side, which directly serves advertisers by providing them with\nmarketing tools, is now playing a more and more important role. When speaking\nof sponsored search, bid keyword recommendation is the fundamental service.\nThis paper addresses the problem of keyword matching, the primary step of\nkeyword recommendation. Existing methods for keyword matching merely consider\nmodeling relevance based on a single type of relation among ads and keywords,\nsuch as query clicks or text similarity, which neglects rich heterogeneous\ninteractions hidden behind them. To fill this gap, the keyword matching problem\nfaces several challenges including: 1) how to learn enriched and robust\nembeddings from complex interactions among various types of objects; 2) how to\nconduct high-quality matching for new ads that usually lack sufficient data.\nTo address these challenges, we develop a\nheterogeneous-graph-neural-network-based model for keyword matching named\nHetMatch, which has been deployed both online and offline at the core sponsored\nsearch platform of Alibaba Group. To extract enriched and robust embeddings\namong rich relations, we design a hierarchical structure to fuse and enhance\nthe relevant neighborhood patterns both on the micro and the macro level.\nMoreover, by proposing a multi-view framework, the model is able to involve\nmore positive samples for cold-start ads. Experimental results on a large-scale\nindustrial dataset as well as online AB tests exhibit the effectiveness of\nHetMatch.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Zongtao Liu",
      "Bin Ma",
      "Quan Liu",
      "Jian Xu",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.00926"
  },
  {
    "id": "arXiv:2111.00928",
    "title": "Combating Noise: Semi-supervised Learning by Region Uncertainty  Quantification",
    "abstract": "Semi-supervised learning aims to leverage a large amount of unlabeled data\nfor performance boosting. Existing works primarily focus on image\nclassification. In this paper, we delve into semi-supervised learning for\nobject detection, where labeled data are more labor-intensive to collect.\nCurrent methods are easily distracted by noisy regions generated by pseudo\nlabels. To combat the noisy labeling, we propose noise-resistant\nsemi-supervised learning by quantifying the region uncertainty. We first\ninvestigate the adverse effects brought by different forms of noise associated\nwith pseudo labels. Then we propose to quantify the uncertainty of regions by\nidentifying the noise-resistant properties of regions over different strengths.\nBy importing the region uncertainty quantification and promoting multipeak\nprobability distribution output, we introduce uncertainty into training and\nfurther achieve noise-resistant learning. Experiments on both PASCAL VOC and MS\nCOCO demonstrate the extraordinary performance of our method.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Zhenyu Wang",
      "Yali Li",
      "Ye Guo",
      "Shengjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00928"
  },
  {
    "id": "arXiv:2111.00929",
    "title": "Bounds all around: training energy-based models with bidirectional  bounds",
    "abstract": "Energy-based models (EBMs) provide an elegant framework for density\nestimation, but they are notoriously difficult to train. Recent work has\nestablished links to generative adversarial networks, where the EBM is trained\nthrough a minimax game with a variational value function. We propose a\nbidirectional bound on the EBM log-likelihood, such that we maximize a lower\nbound and minimize an upper bound when solving the minimax game. We link one\nbound to a gradient penalty that stabilizes training, thereby providing\ngrounding for best engineering practice. To evaluate the bounds we develop a\nnew and efficient estimator of the Jacobi-determinant of the EBM generator. We\ndemonstrate that these developments significantly stabilize training and yield\nhigh-quality density estimation and sample generation.",
    "descriptor": "\nComments: This paper has been accepted by NeurIPS 2021\n",
    "authors": [
      "Cong Geng",
      "Jia Wang",
      "Zhiyong Gao",
      "Jes Frellsen",
      "S\u00f8ren Hauberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00929"
  },
  {
    "id": "arXiv:2111.00931",
    "title": "Structure Information is the Key: Self-Attention RoI Feature Extractor  in 3D Object Detection",
    "abstract": "Unlike 2D object detection where all RoI features come from grid pixels, the\nRoI feature extraction of 3D point cloud object detection is more diverse. In\nthis paper, we first compare and analyze the differences in structure and\nperformance between the two state-of-the-art models PV-RCNN and Voxel-RCNN.\nThen, we find that the performance gap between the two models does not come\nfrom point information, but structural information. The voxel features contain\nmore structural information because they do quantization instead of\ndownsampling to point cloud so that they can contain basically the complete\ninformation of the whole point cloud. The stronger structural information in\nvoxel features makes the detector have higher performance in our experiments\neven if the voxel features don't have accurate location information. Then, we\npropose that structural information is the key to 3D object detection. Based on\nthe above conclusion, we propose a Self-Attention RoI Feature Extractor (SARFE)\nto enhance structural information of the feature extracted from 3D proposals.\nSARFE is a plug-and-play module that can be easily used on existing 3D\ndetectors. Our SARFE is evaluated on both KITTI dataset and Waymo Open dataset.\nWith the newly introduced SARFE, we improve the performance of the\nstate-of-the-art 3D detectors by a large margin in cyclist on KITTI dataset\nwhile keeping real-time capability.",
    "descriptor": "",
    "authors": [
      "Diankun Zhang",
      "Zhijie Zheng",
      "Xueting Bi",
      "Xiaojun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00931"
  },
  {
    "id": "arXiv:2111.00933",
    "title": "Application-Platform Co-Design for Serverless Data Processing",
    "abstract": "\"Application-platform co-design\" refers to the phenomenon of new platforms\nbeing created in response to changing application needs, followed by\napplication design and development changing due to the emergence (and the\nspecifics, limitations) of the new platforms, therefore creating, again, new\napplication and platform requirements. This continuous process of application\nand platform (re-)design describes an engineering and management responsibility\nto constantly evaluate any given platform for application fit and\nplatform-specific application design, and to consider a new or evolutionary\nplatform development project due to evolving and changing application needs.\nIn this paper, we study this phenomenon in the context of serverless\ncomputing and (big) data processing needs, and thus, for application-platform\nco-design for serverless data processing (SDP). We present an analysis of the\nstate-of-the-art of function-as-a-service (FaaS) platforms, which reveals\nseveral configuration, deployment, execution, and measurement differences\nbetween popular platforms happening at-speed. These differences indicate\nalready ongoing platform (re-)design processes resulting in more specialized\nserverless platforms and new, platform-specific challenges for application\ndesign. We discuss data processing needs of applications using the serverless\nmodel and present common initial (and undesirable) workaround solutions on the\napplication level, giving additional argument to the creation of new SDP\nplatforms. We present critical SDP requirements and possible new platform\naugmentations, but identify the need for engineering methods and tooling to\nbetter guide application-platform co-design. We argue to pay appropriate\nattention to the phenomenon of continuous application-platform co-design to\nbetter anticipate and to control future platform and application developments.",
    "descriptor": "\nComments: Preprint version to be published Proceedings of the 19th International Conference on Service-Oriented Computing\n",
    "authors": [
      "Sebastian Werner",
      "Stefan Tai"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.00933"
  },
  {
    "id": "arXiv:2111.00941",
    "title": "Turning Traffic Monitoring Cameras into Intelligent Sensors for Traffic  Density Estimation",
    "abstract": "Accurate traffic state information plays a pivotal role in the Intelligent\nTransportation Systems (ITS), and it is an essential input to various smart\nmobility applications such as signal coordination and traffic flow prediction.\nThe current practice to obtain the traffic state information is through\nspecialized sensors such as loop detectors and speed cameras. In most\nmetropolitan areas, traffic monitoring cameras have been installed to monitor\nthe traffic conditions on arterial roads and expressways, and the collected\nvideos or images are mainly used for visual inspection by traffic engineers.\nUnfortunately, the data collected from traffic monitoring cameras are affected\nby the 4L characteristics: Low frame rate, Low resolution, Lack of annotated\ndata, and Located in complex road environments. Therefore, despite the great\npotentials of the traffic monitoring cameras, the 4L characteristics hinder\nthem from providing useful traffic state information (e.g., speed, flow,\ndensity). This paper focuses on the traffic density estimation problem as it is\nwidely applicable to various traffic surveillance systems. To the best of our\nknowledge, there is a lack of the holistic framework for addressing the 4L\ncharacteristics and extracting the traffic density information from traffic\nmonitoring camera data. In view of this, this paper proposes a framework for\nestimating traffic density using uncalibrated traffic monitoring cameras with\n4L characteristics. The proposed framework consists of two major components:\ncamera calibration and vehicle detection. The camera calibration method\nestimates the actual length between pixels in the images and videos, and the\nvehicle counts are extracted from the deep-learning-based vehicle detection\nmethod. Combining the two components, high-granular traffic density can be\nestimated. To validate the proposed framework, two case studies were conducted\nin Hong Kong and Sacramento. The results show that the Mean Absolute Error\n(MAE) in camera calibration is less than 0.2 meters out of 6 meters, and the\naccuracy of vehicle detection under various conditions is approximately 90%.\nOverall, the MAE for the estimated density is 9.04 veh/km/lane in Hong Kong and\n1.30 veh/km/lane in Sacramento. The research outcomes can be used to calibrate\nthe speed-density fundamental diagrams, and the proposed framework can provide\naccurate and real-time traffic information without installing additional\nsensors.",
    "descriptor": "",
    "authors": [
      "Zijian Hu",
      "William H.K. Lam",
      "S.C. Wong",
      "Andy H.F. Chow",
      "Wei Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00941"
  },
  {
    "id": "arXiv:2111.00943",
    "title": "SVBRDF Recovery From a Single Image With Highlights using a Pretrained  Generative Adversarial Network",
    "abstract": "Spatially-varying bi-directional reflectance distribution functions (SVBRDFs)\nare crucial for designers to incorporate new materials in virtual scenes,\nmaking them look more realistic. Reconstruction of SVBRDFs is a long-standing\nproblem. Existing methods either rely on extensive acquisition system or\nrequire huge datasets which are nontrivial to acquire. We aim to recover\nSVBRDFs from a single image, without any datasets. A single image contains\nincomplete information about the SVBRDF, making the reconstruction task highly\nill-posed. It is also difficult to separate between the changes in color that\nare caused by the material and those caused by the illumination, without the\nprior knowledge learned from the dataset. In this paper, we use an unsupervised\ngenerative adversarial neural network (GAN) to recover SVBRDFs maps with a\nsingle image as input. To better separate the effects due to illumination from\nthe effects due to the material, we add the hypothesis that the material is\nstationary and introduce a new loss function based on Fourier coefficients to\nenforce this stationarity. For efficiency, we train the network in two stages:\nreusing a trained model to initialize the SVBRDFs and fine-tune it based on the\ninput image. Our method generates high-quality SVBRDFs maps from a single input\nphotograph, and provides more vivid rendering results compared to previous\nwork. The two-stage training boosts runtime performance, making it 8 times\nfaster than previous work.",
    "descriptor": "",
    "authors": [
      "Tao Wen",
      "Beibei Wang",
      "Lei Zhang",
      "Jie Guo",
      "Nicolas Holzschuch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.00943"
  },
  {
    "id": "arXiv:2111.00944",
    "title": "Piezoelectric Soft Robot Inchworm Motion by Controlling Ground Friction  through Robot Shape",
    "abstract": "Electrically driven soft robots enable small and light bodies, as well as\nenvironmental compatibility, various locomotion, and safe operation. In\nparticular, electrostatic actuators (for example, piezoelectric actuators) are\nfast responded. However, scalable ways for seamless integration and untethered\noperation remain unclear. In addition, soft body nature modeling, including\nenvironmental interactions, is a long-standing challenge. Furthermore, more\nlocomotion mechanisms need to be explored. In this paper, we have designed,\nmodeled, and demonstrated a soft robot that, for the first time, starts to\naddress all these questions. It has a linear array of five actuators in a\nplanar structure, opening doors for integration and free operation. A new\ninchworm-inspired crawling motion mechanism was designed and validated by\nrelying on posture self-adjustment. The first analytical soft body model\nincluding piezoelectricity, gravity, and ground interactions that well explain\nrobot locomotion was developed and validated by experiments. We demonstrated\nthe robot's forward and backward motion and explored the effects of payload and\ndriving speed: 1.2 mm movement per cycle and up to 200 g payload (16x body\nweight) can be carried while moving. This work paves the way for\nfast-responding robots in complicated unknown environments.",
    "descriptor": "\nComments: 14 pages, 27 figures\n",
    "authors": [
      "Zhiwu Zheng",
      "Prakhar Kumar",
      "Yenan Chen",
      "Hsin Cheng",
      "Sigurd Wagner",
      "Minjie Chen",
      "Naveen Verma",
      "James C. Sturm"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00944"
  },
  {
    "id": "arXiv:2111.00945",
    "title": "Escaping the abstraction: a foreign function interface for the Unified  Form Language [UFL]",
    "abstract": "High level domain specific languages for the finite element method underpin\nhigh productivity programming environments for simulations based on partial\ndifferential equations (PDE) while employing automatic code generation to\nachieve high performance. However, a limitation of this approach is that it\ndoes not support operators that are not directly expressible in the vector\ncalculus. This is critical in applications where PDEs are not enough to\naccurately describe the physical problem of interest. The use of deep learning\ntechniques have become increasingly popular in filling this knowledge gap, for\nexample to include features not represented in the differential equations, or\nclosures for unresolved spatiotemporal scales. We introduce an interface within\nthe Firedrake finite element system that enables a seamless interface with deep\nlearning models. This new feature composes with the automatic differentiation\ncapabilities of Firedrake, enabling the automated solution of inverse problems.\nOur implementation interfaces with PyTorch and can be extended to other machine\nlearning libraries. The resulting framework supports complex models coupling\nPDEs and deep learning whilst maintaining separation of concerns between\napplication scientists and software experts.",
    "descriptor": "\nComments: First Workshop on Differentiable Programming (NeurIPS 2021)\n",
    "authors": [
      "Nacime Bouziani",
      "David A. Ham"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00945"
  },
  {
    "id": "arXiv:2111.00946",
    "title": "Methods for the Numerical Analysis of Boundary Value Problem of Partial  Differential Equations Based on Kolmogorov Superposition Theorem",
    "abstract": "This research introduces a new method for the transition from partial to\nordinary differential equations that is based on the Kolmogorov superposition\ntheorem. In this paper, we discuss the numerical implementation of the\nKolmogorov theorem and propose an approach that allows us to apply the theorem\nto represent partial derivatives of multivariate function as a combination of\nordinary derivatives of univariate functions. We tested the method by running a\nnumerical experiment with the Poisson equation. As a result, we managed to get\na system of ordinary differential equations whose solution coincides with a\nsolution of the initial partial differential equation.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Korney Tomashchuk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.00946"
  },
  {
    "id": "arXiv:2111.00947",
    "title": "Nested Multiple Instance Learning with Attention Mechanisms",
    "abstract": "Multiple instance learning (MIL) is a type of weakly supervised learning\nwhere multiple instances of data with unknown labels are sorted into bags.\nSince knowledge about the individual instances is incomplete, labels are\nassigned to the bags containing the instances. While this method fits diverse\napplications were labelled data is scarce, it lacks depth for solving more\ncomplex scenarios where associations between sets of instances have to be made,\nlike finding relevant regions of interest in an image or detecting events in a\nset of time-series signals. Nested MIL considers labelled bags within bags,\nwhere only the outermost bag is labelled and inner-bags and instances are\nrepresented as latent labels. In addition, we propose using an attention\nmechanism to add interpretability, providing awareness into the impact of each\ninstance to the weak bag label. Experiments in classical image datasets show\nthat our proposed model provides high accuracy performance as well as spotting\nrelevant instances on image regions.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Saul Fuster",
      "Trygve Eftest\u00f8l",
      "Kjersti Engan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00947"
  },
  {
    "id": "arXiv:2111.00950",
    "title": "Higher-Order Implicit Fairing Networks for 3D Human Pose Estimation",
    "abstract": "Estimating a 3D human pose has proven to be a challenging task, primarily\nbecause of the complexity of the human body joints, occlusions, and variability\nin lighting conditions. In this paper, we introduce a higher-order graph\nconvolutional framework with initial residual connections for 2D-to-3D pose\nestimation. Using multi-hop neighborhoods for node feature aggregation, our\nmodel is able to capture the long-range dependencies between body joints.\nMoreover, our approach leverages residual connections, which are integrated by\ndesign in our network architecture, ensuring that the learned feature\nrepresentations retain important information from the initial features of the\ninput layer as the network depth increases. Experiments and ablations studies\nconducted on two standard benchmarks demonstrate the effectiveness of our\nmodel, achieving superior performance over strong baseline methods for 3D human\npose estimation.",
    "descriptor": "",
    "authors": [
      "Jianning Quan",
      "A. Ben Hamza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00950"
  },
  {
    "id": "arXiv:2111.00956",
    "title": "Robot Learning from Randomized Simulations: A Review",
    "abstract": "The rise of deep learning has caused a paradigm shift in robotics research,\nfavoring methods that require large amounts of data. It is prohibitively\nexpensive to generate such data sets on a physical platform. Therefore,\nstate-of-the-art approaches learn in simulation where data generation is fast\nas well as inexpensive and subsequently transfer the knowledge to the real\nrobot (sim-to-real). Despite becoming increasingly realistic, all simulators\nare by construction based on models, hence inevitably imperfect. This raises\nthe question of how simulators can be modified to facilitate learning robot\ncontrol policies and overcome the mismatch between simulation and reality,\noften called the 'reality gap'. We provide a comprehensive review of\nsim-to-real research for robotics, focusing on a technique named 'domain\nrandomization' which is a method for learning from randomized simulations.",
    "descriptor": "\nComments: submitted to Frontiers in Robotics and AI\n",
    "authors": [
      "Fabio Muratore",
      "Fabio Ramos",
      "Greg Turk",
      "Wenhao Yu",
      "Michael Gienger",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00956"
  },
  {
    "id": "arXiv:2111.00960",
    "title": "gtfs2vec -- Learning GTFS Embeddings for comparing Public Transport  Offer in Microregions",
    "abstract": "We selected 48 European cities and gathered their public transport timetables\nin the GTFS format. We utilized Uber's H3 spatial index to divide each city\ninto hexagonal micro-regions. Based on the timetables data we created certain\nfeatures describing the quantity and variety of public transport availability\nin each region. Next, we trained an auto-associative deep neural network to\nembed each of the regions. Having such prepared representations, we then used a\nhierarchical clustering approach to identify similar regions. To do so, we\nutilized an agglomerative clustering algorithm with a euclidean distance\nbetween regions and Ward's method to minimize in-cluster variance. Finally, we\nanalyzed the obtained clusters at different levels to identify some number of\nclusters that qualitatively describe public transport availability. We showed\nthat our typology matches the characteristics of analyzed cities and allows\nsuccesful searching for areas with similar public transport schedule\ncharacteristics.",
    "descriptor": "\nComments: Accepted at 4th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery GEOAI'21\n",
    "authors": [
      "Piotr Gramacki",
      "Szymon Wo\u017aniak",
      "Piotr Szyma\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00960"
  },
  {
    "id": "arXiv:2111.00962",
    "title": "RefineGAN: Universally Generating Waveform Better than Ground Truth with  Highly Accurate Pitch and Intensity Responses",
    "abstract": "Most GAN(Generative Adversarial Network)-based approaches towards\nhigh-fidelity waveform generation heavily rely on discriminators to improve\ntheir performance. However, the over-use of this GAN method introduces much\nuncertainty into the generation process and often result in mismatches of pitch\nand intensity, which is fatal when it comes to sensitive using cases such as\nsinging voice synthesis(SVS). To address this problem, we propose RefineGAN, a\nhigh-fidelity neural vocoder with faster-than-real-time generation capability,\nand focused on the robustness, pitch and intensity accuracy, and full-band\naudio generation. We employed a pitch-guided refine architecture with a\nmulti-scale spectrogram-based loss function to help stabilize the training\nprocess and maintain the robustness of the neural vocoder while using the\nGAN-based training method. Audio generated using this method shows a better\nperformance in subjective tests when compared with the ground-truth audio. This\nresult shows that the fidelity is even improved during the waveform\nreconstruction by eliminating defects produced by the speaker and the recording\nprocedure. Moreover, a further study shows that models trained on a specified\ntype of data can perform on totally unseen language and unseen speaker\nidentically well. Generated sample pairs are provided on\nhttps://timedomain-tech.github.io/refinegan/.",
    "descriptor": "",
    "authors": [
      "Shengyuan Xu",
      "Wenxiao Zhao",
      "Jing Guo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.00962"
  },
  {
    "id": "arXiv:2111.00963",
    "title": "Machine Learning aided Crop Yield Optimization",
    "abstract": "We present a crop simulation environment with an OpenAI Gym interface, and\napply modern deep reinforcement learning (DRL) algorithms to optimize yield. We\nempirically show that DRL algorithms may be useful in discovering new policies\nand approaches to help optimize crop yield, while simultaneously minimizing\nconstraining factors such as water and fertilizer usage. We propose that this\nhybrid plant modeling and data-driven approach for discovering new strategies\nto optimize crop yield may help address upcoming global food demands due to\npopulation expansion and climate change.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Chace Ashcraft",
      "Kiran Karra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00963"
  },
  {
    "id": "arXiv:2111.00965",
    "title": "iFlow: Numerically Invertible Flows for Efficient Lossless Compression  via a Uniform Coder",
    "abstract": "It was estimated that the world produced $59 ZB$ ($5.9 \\times 10^{13} GB$) of\ndata in 2020, resulting in the enormous costs of both data storage and\ntransmission. Fortunately, recent advances in deep generative models have\nspearheaded a new class of so-called \"neural compression\" algorithms, which\nsignificantly outperform traditional codecs in terms of compression ratio.\nUnfortunately, the application of neural compression garners little commercial\ninterest due to its limited bandwidth; therefore, developing highly efficient\nframeworks is of critical practical importance. In this paper, we discuss\nlossless compression using normalizing flows which have demonstrated a great\ncapacity for achieving high compression ratios. As such, we introduce iFlow, a\nnew method for achieving efficient lossless compression. We first propose\nModular Scale Transform (MST) and a novel family of numerically invertible flow\ntransformations based on MST. Then we introduce the Uniform Base Conversion\nSystem (UBCS), a fast uniform-distribution codec incorporated into iFlow,\nenabling efficient compression. iFlow achieves state-of-the-art compression\nratios and is $5\\times$ quicker than other high-performance schemes.\nFurthermore, the techniques presented in this paper can be used to accelerate\ncoding time for a broad class of flow-based algorithms.",
    "descriptor": "\nComments: Accepted for NeurIPS 2021 Spotlight\n",
    "authors": [
      "Shifeng Zhang",
      "Ning Kang",
      "Tom Ryder",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00965"
  },
  {
    "id": "arXiv:2111.00966",
    "title": "VPFNet: Voxel-Pixel Fusion Network for Multi-class 3D Object Detection",
    "abstract": "Many LiDAR-based methods for detecting large objects, single-class object\ndetection, or under easy situations were claimed to perform quite well.\nHowever, their performances of detecting small objects or under hard situations\ndid not surpass those of the fusion-based ones due to failure to leverage the\nimage semantics. In order to elevate the detection performance in a complicated\nenvironment, this paper proposes a deep learning (DL)-embedded fusion-based\nmulti-class 3D object detection network which admits both LiDAR and camera\nsensor data streams, named Voxel-Pixel Fusion Network (VPFNet). Inside this\nnetwork, a key novel component is called Voxel-Pixel Fusion (VPF) layer, which\ntakes advantage of the geometric relation of a voxel-pixel pair and fuses the\nvoxel features and the pixel features with proper mechanisms. Moreover, several\nparameters are particularly designed to guide and enhance the fusion effect\nafter considering the characteristics of a voxel-pixel pair. Finally, the\nproposed method is evaluated on the KITTI benchmark for multi-class 3D object\ndetection task under multilevel difficulty, and is shown to outperform all\nstate-of-the-art methods in mean average precision (mAP). It is also noteworthy\nthat our approach here ranks the first on the KITTI leaderboard for the\nchallenging pedestrian class.",
    "descriptor": "",
    "authors": [
      "Chia-Hung Wang",
      "Hsueh-Wei Chen",
      "Li-Chen Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.00966"
  },
  {
    "id": "arXiv:2111.00968",
    "title": "Achieving increased Phasor POD performance by introducing a  Control-Input Model",
    "abstract": "In this paper, an enhancement to the well known Phasor Power Oscillation\nDamper is proposed, aiming to increase its performance. Fundamental to the\nfunctioning of this controller is the estimation of a phasor representing\noscillatory behaviour at a particular frequency in a measured signal. The\nphasor is transformed to time domain and applied as a setpoint signal to a\ncontrollable device. The contribution in this paper specifically targets the\nestimation algorithm of the controller: It is found that increased estimation\naccuracy and thereby enhanced damping performance can be achieved by\nintroducing a prediction-correction scheme for the estimator, in the form of a\nKalman Filter. The prediction of the phasor at the next step is performed based\non the control signal that is applied at the current step. This enables more\nprecise damping of the targeted mode.\nThe presented results, which are obtained from simulations on a\nSingle-Machine Infinite Bus system and the IEEE 39-Bus system, indicate that\nthe proposed enhancement improves the performance of this type of controller.",
    "descriptor": "",
    "authors": [
      "Hallvar Haugdal",
      "Kjetil Uhlen",
      "Hj\u00f6rtur J\u00f3hannsson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00968"
  },
  {
    "id": "arXiv:2111.00969",
    "title": "Generative Occupancy Fields for 3D Surface-Aware Image Synthesis",
    "abstract": "The advent of generative radiance fields has significantly promoted the\ndevelopment of 3D-aware image synthesis. The cumulative rendering process in\nradiance fields makes training these generative models much easier since\ngradients are distributed over the entire volume, but leads to diffused object\nsurfaces. In the meantime, compared to radiance fields occupancy\nrepresentations could inherently ensure deterministic surfaces. However, if we\ndirectly apply occupancy representations to generative models, during training\nthey will only receive sparse gradients located on object surfaces and\neventually suffer from the convergence problem. In this paper, we propose\nGenerative Occupancy Fields (GOF), a novel model based on generative radiance\nfields that can learn compact object surfaces without impeding its training\nconvergence. The key insight of GOF is a dedicated transition from the\ncumulative rendering in radiance fields to rendering with only the surface\npoints as the learned surface gets more and more accurate. In this way, GOF\ncombines the merits of two representations in a unified framework. In practice,\nthe training-time transition of start from radiance fields and march to\noccupancy representations is achieved in GOF by gradually shrinking the\nsampling region in its rendering process from the entire volume to a minimal\nneighboring region around the surface. Through comprehensive experiments on\nmultiple datasets, we demonstrate that GOF can synthesize high-quality images\nwith 3D consistency and simultaneously learn compact and smooth object\nsurfaces. Code, models, and demo videos are available at\nhttps://sheldontsui.github.io/projects/GOF",
    "descriptor": "\nComments: Accepted to NeurIPS2021. We propose Generative Occupancy Fields(GOF), a 3D-aware generative model which could synthesize realistic images with 3D consistency and simultaneously learn compact object surfaces\n",
    "authors": [
      "Xudong Xu",
      "Xingang Pan",
      "Dahua Lin",
      "Bo Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00969"
  },
  {
    "id": "arXiv:2111.00970",
    "title": "Hex2vec -- Context-Aware Embedding H3 Hexagons with OpenStreetMap Tags",
    "abstract": "Representation learning of spatial and geographic data is a rapidly\ndeveloping field which allows for similarity detection between areas and\nhigh-quality inference using deep neural networks. Past approaches however\nconcentrated on embedding raster imagery (maps, street or satellite photos),\nmobility data or road networks. In this paper we propose the first approach to\nlearning vector representations of OpenStreetMap regions with respect to urban\nfunctions and land-use in a micro-region grid. We identify a subset of OSM tags\nrelated to major characteristics of land-use, building and urban region\nfunctions, types of water, green or other natural areas. Through manual\nverification of tagging quality, we selected 36 cities were for training region\nrepresentations. Uber's H3 index was used to divide the cities into hexagons,\nand OSM tags were aggregated for each hexagon. We propose the hex2vec method\nbased on the Skip-gram model with negative sampling. The resulting vector\nrepresentations showcase semantic structures of the map characteristics,\nsimilar to ones found in vector-based language models. We also present insights\nfrom region similarity detection in six Polish cities and propose a region\ntypology obtained through agglomerative clustering.",
    "descriptor": "\nComments: Accepted at 4th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery (GEOAI '21)\n",
    "authors": [
      "Szymon Wo\u017aniak",
      "Piotr Szyma\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00970"
  },
  {
    "id": "arXiv:2111.00974",
    "title": "Transductive Data Augmentation with Relational Path Rule Mining for  Knowledge Graph Embedding",
    "abstract": "For knowledge graph completion, two major types of prediction models exist:\none based on graph embeddings, and the other based on relation path rule\ninduction. They have different advantages and disadvantages. To take advantage\nof both types, hybrid models have been proposed recently. One of the hybrid\nmodels, UniKER, alternately augments training data by relation path rules and\ntrains an embedding model. Despite its high prediction accuracy, it does not\ntake full advantage of relation path rules, as it disregards low-confidence\nrules in order to maintain the quality of augmented data. To mitigate this\nlimitation, we propose transductive data augmentation by relation path rules\nand confidence-based weighting of augmented data. The results and analysis show\nthat our proposed method effectively improves the performance of the embedding\nmodel by augmenting data that include true answers or entities similar to them.",
    "descriptor": "\nComments: 8 pages, 0 figures, accepted by 2021 IEEE International Conference on Big Knowledge. The copyright of this paper has been transferred to the IEEE, please comply with the copyright of the IEEE\n",
    "authors": [
      "Yushi Hirose",
      "Masashi Shimbo",
      "Taro Watanabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.00974"
  },
  {
    "id": "arXiv:2111.00976",
    "title": "A transfer learning based approach for pronunciation scoring",
    "abstract": "Phone-level pronunciation scoring is a challenging task, with performance far\nfrom that of human annotators. Standard systems generate a score for each phone\nin a phrase using models trained for automatic speech recognition (ASR) with\nnative data only. Better performance has been shown when using systems that are\ntrained specifically for the task using non-native data. Yet, such systems face\nthe challenge that datasets labelled for this task are scarce and usually\nsmall. In this paper, we present a transfer learning-based approach that\nleverages a model trained for ASR, adapting it for the task of pronunciation\nscoring. We analyze the effect of several design choices and compare the\nperformance with a state-of-the-art goodness of pronunciation (GOP) system. Our\nfinal system is 20% better than the GOP system on EpaDB, a database for\npronunciation scoring research, for a cost function that prioritizes low rates\nof unnecessary corrections.",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Marcelo Sancinetti",
      "Jazmin Vidal",
      "Cyntia Bonomi",
      "Luciana Ferrer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.00976"
  },
  {
    "id": "arXiv:2111.00977",
    "title": "Fast Convolution based on Winograd Minimum Filtering: Introduction and  Development",
    "abstract": "Convolutional Neural Network (CNN) has been widely used in various fields and\nplayed an important role. Convolution operators are the fundamental component\nof convolutional neural networks, and it is also the most time-consuming part\nof network training and inference. In recent years, researchers have proposed\nseveral fast convolution algorithms including FFT and Winograd. Among them,\nWinograd convolution significantly reduces the multiplication operations in\nconvolution, and it also takes up less memory space than FFT convolution.\nTherefore, Winograd convolution has quickly become the first choice for fast\nconvolution implementation within a few years. At present, there is no\nsystematic summary of the convolution algorithm. This article aims to fill this\ngap and provide detailed references for follow-up researchers. This article\nsummarizes the development of Winograd convolution from the three aspects of\nalgorithm expansion, algorithm optimization, implementation, and application,\nand finally makes a simple outlook on the possible future directions.",
    "descriptor": "\nComments: 15 pages, 1 figure\n",
    "authors": [
      "Gan Tong",
      "Libo Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.00977"
  },
  {
    "id": "arXiv:2111.00978",
    "title": "A critical review of data-driven transient stability assessment of power  systems: principles, prospects and challenges",
    "abstract": "Transient stability assessment (TSA) has always been a fundamental means for\nensuring the secure and stable operation of power systems. Due to the\nintegration of new elements such as power electronics, electric vehicles and\nrenewable power generations, dynamic characteristics of power systems are\nbecoming more and more complex, which makes TSA an increasingly urgent task.\nSince traditional time-domain simulations and direct method cannot meet the\nactual operation requirements of power systems, data-driven TSA has attracted\ngrowing attention from both academia and industry. This paper makes a\ncomprehensive review from the following four aspects: feature extraction and\nselection, model construction, online learning and rule extraction; and then,\nsummarizes the challenges and prospects for future research; finally, draws the\nconclusions of this review. This review will be beneficial for relevant\nresearchers to better understand the research status, key technologies and\nexisting challenges in the field.",
    "descriptor": "\nComments: Accepted by Energies\n",
    "authors": [
      "Shitu Zhang",
      "Zhixun Zhu",
      "Yang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.00978"
  },
  {
    "id": "arXiv:2111.00980",
    "title": "Mixture Proportion Estimation and PU Learning: A Modern Approach",
    "abstract": "Given only positive examples and unlabeled examples (from both positive and\nnegative classes), we might hope nevertheless to estimate an accurate\npositive-versus-negative classifier. Formally, this task is broken down into\ntwo subtasks: (i) Mixture Proportion Estimation (MPE) -- determining the\nfraction of positive examples in the unlabeled data; and (ii) PU-learning --\ngiven such an estimate, learning the desired positive-versus-negative\nclassifier. Unfortunately, classical methods for both problems break down in\nhigh-dimensional settings. Meanwhile, recently proposed heuristics lack\ntheoretical coherence and depend precariously on hyperparameter tuning. In this\npaper, we propose two simple techniques: Best Bin Estimation (BBE) (for MPE);\nand Conditional Value Ignoring Risk (CVIR), a simple objective for PU-learning.\nBoth methods dominate previous approaches empirically, and for BBE, we\nestablish formal guarantees that hold whenever we can train a model to cleanly\nseparate out a small subset of positive examples. Our final algorithm\n(TED)$^n$, alternates between the two procedures, significantly improving both\nour mixture proportion estimator and classifier",
    "descriptor": "\nComments: Spotlight at NeurIPS 2021\n",
    "authors": [
      "Saurabh Garg",
      "Yifan Wu",
      "Alex Smola",
      "Sivaraman Balakrishnan",
      "Zachary C. Lipton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00980"
  },
  {
    "id": "arXiv:2111.00981",
    "title": "Cross-lingual Hate Speech Detection using Transformer Models",
    "abstract": "Hate speech detection within a cross-lingual setting represents a paramount\narea of interest for all medium and large-scale online platforms. Failing to\nproperly address this issue on a global scale has already led over time to\nmorally questionable real-life events, human deaths, and the perpetuation of\nhate itself. This paper illustrates the capabilities of fine-tuned altered\nmulti-lingual Transformer models (mBERT, XLM-RoBERTa) regarding this crucial\nsocial data science task with cross-lingual training from English to French,\nvice-versa and each language on its own, including sections about iterative\nimprovement and comparative error analysis.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Teodor Ti\u0163a",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00981"
  },
  {
    "id": "arXiv:2111.00986",
    "title": "Partial-Adaptive Submodular Maximization",
    "abstract": "The goal of a typical adaptive sequential decision making problem is to\ndesign an interactive policy that selects a group of items sequentially, based\non some partial observations, to maximize the expected utility. It has been\nshown that the utility functions of many real-world applications, including\npooled-based active learning and adaptive influence maximization, satisfy the\nproperty of adaptive submodularity. However, most of existing studies on\nadaptive submodular maximization focus on the fully adaptive setting, i.e., one\nmust wait for the feedback from \\emph{all} past selections before making the\nnext selection. Although this approach can take full advantage of feedback from\nthe past to make informed decisions, it may take a longer time to complete the\nselection process as compared with the non-adaptive solution where all\nselections are made in advance before any observations take place. In this\npaper, we explore the problem of partial-adaptive submodular maximization where\none is allowed to make multiple selections in a batch simultaneously and\nobserve their realizations together. Our approach enjoys the benefits of\nadaptivity while reducing the time spent on waiting for the observations from\npast selections. To the best of our knowledge, no results are known for\npartial-adaptive policies for the non-monotone adaptive submodular maximization\nproblem. We study this problem under both cardinality constraint and knapsack\nconstraints, and develop effective and efficient solutions for both cases. We\nalso analyze the batch query complexity, i.e., the number of batches a policy\ntakes to complete the selection process, of our policy under some additional\nassumptions.",
    "descriptor": "",
    "authors": [
      "Shaojie Tang",
      "Jing Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00986"
  },
  {
    "id": "arXiv:2111.00990",
    "title": "Transfer Learning Approach to Bicycle-sharing Systems' Station Location  Planning using OpenStreetMap Data",
    "abstract": "Bicycle-sharing systems (BSS) have become a daily reality for many citizens\nof larger, wealthier cities in developed regions. However, planning the layout\nof bicycle-sharing stations usually requires expensive data gathering,\nsurveying travel behavior and trip modelling followed by station layout\noptimization. Many smaller cities and towns, especially in developing areas,\nmay have difficulty financing such projects. Planning a BSS also takes a\nconsiderable amount of time. Yet as the pandemic has shown us, municipalities\nwill face the need to adapt rapidly to mobility shifts, which include citizens\nleaving public transport for bicycles. Laying out a bike sharing system quickly\nwill become critical in addressing the increase in bike demand. This paper\naddresses the problem of cost and time in BSS layout design and proposes a new\nsolution to streamline and facilitate the process of such planning by using\nspatial embedding methods. Based only on publicly available data from\nOpenStreetMap, and station layouts from 34 cities in Europe, a method has been\ndeveloped to divide cities into micro-regions using the Uber H3 discrete global\ngrid system and to indicate regions where it is worth placing a station based\non existing systems in different cities using transfer learning. The result of\nthe work is a mechanism to support planners in their decision making when\nplanning a station layout with a choice of reference cities.",
    "descriptor": "\nComments: Accepted to 4th ACM SIGSPATIAL International Workshop on Advances in Resilient and Intelligent Cities\n",
    "authors": [
      "Kamil Raczycki",
      "Piotr Szyma\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00990"
  },
  {
    "id": "arXiv:2111.00993",
    "title": "Egocentric Human Trajectory Forecasting with a Wearable Camera and  Multi-Modal Fusion",
    "abstract": "In this paper, we address the problem of forecasting the trajectory of an\negocentric camera wearer (ego-person) in crowded spaces. The trajectory\nforecasting ability learned from the data of different camera wearers walking\naround in the real world can be transferred to assist visually impaired people\nin navigation, as well as to instill human navigation behaviours in mobile\nrobots, enabling better human-robot interactions. To this end, a novel\negocentric human trajectory forecasting dataset was constructed, containing\nreal trajectories of people navigating in crowded spaces wearing a camera, as\nwell as extracted rich contextual data. We extract and utilize three different\nmodalities to forecast the trajectory of the camera wearer, i.e., his/her past\ntrajectory, the past trajectories of nearby people, and the environment such as\nthe scene semantics or the depth of the scene. A Transformer-based\nencoder-decoder neural network model, integrated with a novel cascaded\ncross-attention mechanism that fuses multiple modalities, has been designed to\npredict the future trajectory of the camera wearer. Extensive experiments have\nbeen conducted, and the results have shown that our model outperforms the\nstate-of-the-art methods in egocentric human trajectory forecasting.",
    "descriptor": "",
    "authors": [
      "Jianing Qiu",
      "Lipeng Chen",
      "Xiao Gu",
      "Frank P.-W. Lo",
      "Ya-Yen Tsai",
      "Jiankai Sun",
      "Jiaqi Liu",
      "Benny Lo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00993"
  },
  {
    "id": "arXiv:2111.00995",
    "title": "Sign-to-Speech Model for Sign Language Understanding: A Case Study of  Nigerian Sign Language",
    "abstract": "Through this paper, we seek to reduce the communication barrier between the\nhearing-impaired community and the larger society who are usually not familiar\nwith sign language in the sub-Saharan region of Africa with the largest\noccurrences of hearing disability cases, while using Nigeria as a case study.\nThe dataset is a pioneer dataset for the Nigerian Sign Language and was created\nin collaboration with relevant stakeholders. We pre-processed the data in\nreadiness for two different object detection models and a classification model\nand employed diverse evaluation metrics to gauge model performance on\nsign-language to text conversion tasks. Finally, we convert the predicted sign\ntexts to speech and deploy the best performing model in a lightweight\napplication that works in real-time and achieves impressive results converting\nsign words/phrases to text and subsequently, into speech.",
    "descriptor": "",
    "authors": [
      "Steven Kolawole",
      "Opeyemi Osakuade",
      "Nayan Saxena",
      "Babatunde Kazeem Olorisade"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00995"
  },
  {
    "id": "arXiv:2111.00998",
    "title": "PDE-READ: Human-readable Partial Differential Equation Discovery using  Deep Learning",
    "abstract": "PDE discovery shows promise for uncovering predictive models for complex\nphysical systems but has difficulty when measurements are sparse and noisy. We\nintroduce a new approach for PDE discovery that uses two Rational Neural\nNetworks and a principled sparse regression algorithm to identify the hidden\ndynamics that govern a system's response. The first network learns the system\nresponse function, while the second learns a hidden PDE which drives the\nsystem's evolution. We then use a parameter-free sparse regression algorithm to\nextract a human-readable form of the hidden PDE from the second network. We\nimplement our approach in an open-source library called PDE-READ. Our approach\nsuccessfully identifies the Heat, Burgers, and Korteweg-De Vries equations with\nremarkable consistency. We demonstrate that our approach is unprecedentedly\nrobust to both sparsity and noise and is, therefore, applicable to real-world\nobservational data.",
    "descriptor": "\nComments: 32 pages, 14 figures\n",
    "authors": [
      "Robert Stephany",
      "Christopher Earls"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00998"
  },
  {
    "id": "arXiv:2111.01004",
    "title": "Improving Contrastive Learning on Imbalanced Seed Data via Open-World  Sampling",
    "abstract": "Contrastive learning approaches have achieved great success in learning\nvisual representations with few labels of the target classes. That implies a\ntantalizing possibility of scaling them up beyond a curated \"seed\" benchmark,\nto incorporating more unlabeled images from the internet-scale external sources\nto enhance its performance. However, in practice, larger amount of unlabeled\ndata will require more computing resources due to the bigger model size and\nlonger training needed. Moreover, open-world unlabeled data usually follows an\nimplicit long-tail class or attribute distribution, many of which also do not\nbelong to the target classes. Blindly leveraging all unlabeled data hence can\nlead to the data imbalance as well as distraction issues. This motivates us to\nseek a principled approach to strategically select unlabeled data from an\nexternal source, in order to learn generalizable, balanced and diverse\nrepresentations for relevant classes. In this work, we present an open-world\nunlabeled data sampling framework called Model-Aware K-center (MAK), which\nfollows three simple principles: (1) tailness, which encourages sampling of\nexamples from tail classes, by sorting the empirical contrastive loss\nexpectation (ECLE) of samples over random data augmentations; (2) proximity,\nwhich rejects the out-of-distribution outliers that may distract training; and\n(3) diversity, which ensures diversity in the set of sampled examples.\nEmpirically, using ImageNet-100-LT (without labels) as the seed dataset and two\n\"noisy\" external data sources, we demonstrate that MAK can consistently improve\nboth the overall representation quality and the class balancedness of the\nlearned features, as evaluated via linear classifier evaluation on full-shot\nand few-shot settings. The code is available at:\n\\url{https://github.com/VITA-Group/MAK",
    "descriptor": "\nComments: Neurips 2021\n",
    "authors": [
      "Ziyu Jiang",
      "Tianlong Chen",
      "Ting Chen",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01004"
  },
  {
    "id": "arXiv:2111.01007",
    "title": "Projected GANs Converge Faster",
    "abstract": "Generative Adversarial Networks (GANs) produce high-quality images but are\nchallenging to train. They need careful regularization, vast amounts of\ncompute, and expensive hyper-parameter sweeps. We make significant headway on\nthese issues by projecting generated and real samples into a fixed, pretrained\nfeature space. Motivated by the finding that the discriminator cannot fully\nexploit features from deeper layers of the pretrained model, we propose a more\neffective strategy that mixes features across channels and resolutions. Our\nProjected GAN improves image quality, sample efficiency, and convergence speed.\nIt is further compatible with resolutions of up to one Megapixel and advances\nthe state-of-the-art Fr\\'echet Inception Distance (FID) on twenty-two benchmark\ndatasets. Importantly, Projected GANs match the previously lowest FIDs up to 40\ntimes faster, cutting the wall-clock time from 5 days to less than 3 hours\ngiven the same computational resources.",
    "descriptor": "\nComments: To appear in NeurIPS 2021. Project Page: this https URL\n",
    "authors": [
      "Axel Sauer",
      "Kashyap Chitta",
      "Jens M\u00fcller",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01007"
  },
  {
    "id": "arXiv:2111.01008",
    "title": "HyperPINN: Learning parameterized differential equations with  physics-informed hypernetworks",
    "abstract": "Many types of physics-informed neural network models have been proposed in\nrecent years as approaches for learning solutions to differential equations.\nWhen a particular task requires solving a differential equation at multiple\nparameterizations, this requires either re-training the model, or expanding its\nrepresentation capacity to include the parameterization -- both solution that\nincrease its computational cost. We propose the HyperPINN, which uses\nhypernetworks to learn to generate neural networks that can solve a\ndifferential equation from a given parameterization. We demonstrate with\nexperiments on both a PDE and an ODE that this type of model can lead to neural\nnetwork solutions to differential equations that maintain a small size, even\nwhen learning a family of solutions over a parameter space.",
    "descriptor": "",
    "authors": [
      "Filipe de Avila Belbute-Peres",
      "Yi-fan Chen",
      "Fei Sha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.01008"
  },
  {
    "id": "arXiv:2111.01013",
    "title": "Improving Location Recommendation with Urban Knowledge Graph",
    "abstract": "Location recommendation is defined as to recommend locations (POIs) to users\nin location-based services. The existing data-driving approaches of location\nrecommendation suffer from the limitation of the implicit modeling of the\ngeographical factor, which may lead to sub-optimal recommendation results. In\nthis work, we address this problem by introducing knowledge-driven solutions.\nSpecifically, we first construct the Urban Knowledge Graph (UrbanKG) with\ngeographical information and functional information of POIs. On the other side,\nthere exist a fact that the geographical factor not only characterizes POIs but\nalso affects user-POI interactions. To address it, we propose a novel method\nnamed UKGC. We first conduct information propagation on two sub-graphs to learn\nthe representations of POIs and users. We then fuse two parts of\nrepresentations by counterfactual learning for the final prediction. Extensive\nexperiments on two real-world datasets verify that our method can outperform\nthe state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Chang Liu",
      "Chen Gao",
      "Depeng Jin",
      "Yong Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.01013"
  },
  {
    "id": "arXiv:2111.01016",
    "title": "Gomoku: analysis of the game and of the player Wine",
    "abstract": "Gomoku, also known as five in a row, is a classical board game, ideally\nsuited for quickly testing novel Artificial Intelligence (AI) techniques. With\nthe aim of facilitating a developer willing to write a new Gomoku player, in\nthis report we present an analysis of the main game concepts and strategies,\nwhich is wider and deeper than existing ones. Moreover, after discussing the\ngeneral structure of an artificial player, we present and analyse a strong\nGomoku player, named Wine, the code of which is freely available on the\nInternet and which is an excelent example of how a modern player is organised.",
    "descriptor": "\nComments: 32 pages, 1 figure\n",
    "authors": [
      "Lorenzo Piazzo",
      "Michele Scarpiniti",
      "Enzo Baccarelli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01016"
  },
  {
    "id": "arXiv:2111.01019",
    "title": "Dynamic Distances in Hyperbolic Graphs",
    "abstract": "We consider the following dynamic problem: given a fixed (small) template\ngraph with colored vertices C and a large graph with colored vertices G (whose\ncolors can be changed dynamically), how many mappings m are there from the\nvertices of C to vertices of G in such a way that the colors agree, and the\ndistances between m(v) and m(w) have given values for every edge? We show that\nthis problem can be solved efficiently on triangulations of the hyperbolic\nplane, as well as other Gromov hyperbolic graphs. For various template graphs\nC, this result lets us efficiently solve various computational problems which\nare relevant in applications, such as visualization of hierarchical data and\nsocial network analysis.",
    "descriptor": "",
    "authors": [
      "Eryk Kopczy\u0144ski",
      "Dorota Celi\u0144ska-Kopczy\u0144ska"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.01019"
  },
  {
    "id": "arXiv:2111.01022",
    "title": "A variance principle explains why dropout finds flatter minima",
    "abstract": "Although dropout has achieved great success in deep learning, little is known\nabout how it helps the training find a good generalization solution in the\nhigh-dimensional parameter space. In this work, we show that the training with\ndropout finds the neural network with a flatter minimum compared with standard\ngradient descent training. We further study the underlying mechanism of why\ndropout finds flatter minima through experiments. We propose a {\\it Variance\nPrinciple} that the variance of a noise is larger at the sharper direction of\nthe loss landscape. Existing works show that SGD satisfies the variance\nprinciple, which leads the training to flatter minima. Our work show that the\nnoise induced by the dropout also satisfies the variance principle that\nexplains why dropout finds flatter minima. In general, our work points out that\nthe variance principle is an important similarity between dropout and SGD that\nlead the training to find flatter minima and obtain good generalization.",
    "descriptor": "",
    "authors": [
      "Zhongwang Zhang",
      "Hanxu Zhou",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01022"
  },
  {
    "id": "arXiv:2111.01023",
    "title": "Interpretable contrastive word mover's embedding",
    "abstract": "This paper shows that a popular approach to the supervised embedding of\ndocuments for classification, namely, contrastive Word Mover's Embedding, can\nbe significantly enhanced by adding interpretability. This interpretability is\nachieved by incorporating a clustering promoting mechanism into the contrastive\nloss. On several public datasets, we show that our method improves\nsignificantly upon existing baselines while providing interpretation to the\nclusters via identifying a set of keywords that are the most representative of\na particular class. Our approach was motivated in part by the need to develop\nNatural Language Processing (NLP) methods for the \\textit{novel problem of\nassessing student work for scientific writing and thinking} - a problem that is\ncentral to the area of (educational) Learning Sciences (LS). In this context,\nwe show that our approach leads to a meaningful assessment of the student work\nrelated to lab reports from a biology class and can help LS researchers gain\ninsights into student understanding and assess evidence of scientific thought\nprocesses.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Ruijie Jiang",
      "Julia Gouvea",
      "Eric Miller",
      "David Hammer",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01023"
  },
  {
    "id": "arXiv:2111.01024",
    "title": "With a Little Help from my Temporal Context: Multimodal Egocentric  Action Recognition",
    "abstract": "In egocentric videos, actions occur in quick succession. We capitalise on the\naction's temporal context and propose a method that learns to attend to\nsurrounding actions in order to improve recognition performance. To incorporate\nthe temporal context, we propose a transformer-based multimodal model that\ningests video and audio as input modalities, with an explicit language model\nproviding action sequence context to enhance the predictions. We test our\napproach on EPIC-KITCHENS and EGTEA datasets reporting state-of-the-art\nperformance. Our ablations showcase the advantage of utilising temporal context\nas well as incorporating audio input modality and language model to rescore\npredictions. Code and models at: https://github.com/ekazakos/MTCN.",
    "descriptor": "\nComments: Accepted at BMVC 2021\n",
    "authors": [
      "Evangelos Kazakos",
      "Jaesung Huh",
      "Arsha Nagrani",
      "Andrew Zisserman",
      "Dima Damen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.01024"
  },
  {
    "id": "arXiv:2111.01026",
    "title": "Introspective Distillation for Robust Question Answering",
    "abstract": "Question answering (QA) models are well-known to exploit data bias, e.g., the\nlanguage prior in visual QA and the position bias in reading comprehension.\nRecent debiasing methods achieve good out-of-distribution (OOD)\ngeneralizability with a considerable sacrifice of the in-distribution (ID)\nperformance. Therefore, they are only applicable in domains where the test\ndistribution is known in advance. In this paper, we present a novel debiasing\nmethod called Introspective Distillation (IntroD) to make the best of both\nworlds for QA. Our key technical contribution is to blend the inductive bias of\nOOD and ID by introspecting whether a training sample fits in the factual ID\nworld or the counterfactual OOD one. Experiments on visual QA datasets VQA v2,\nVQA-CP, and reading comprehension dataset SQuAD demonstrate that our proposed\nIntroD maintains the competitive OOD performance compared to other debiasing\nmethods, while sacrificing little or even achieving better ID performance\ncompared to the non-debiasing ones.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Yulei Niu",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.01026"
  },
  {
    "id": "arXiv:2111.01028",
    "title": "Identification of Stability Regions in Inverter-Based Microgrids",
    "abstract": "A new method for the stability assessment of inverter-based microgrids is\npresented in this paper. Directly determining stability boundaries by searching\nthe multidimensional space of inverters' droop gains is a computationally\nprohibitive task. Instead, we build a certified stability region by utilizing a\ngeneralized Laplacian matrix eigenvalues, which are a measure of proximity to\nstability boundary. We establish an upper threshold for the eigenvalues that\ndetermines the stability boundary of the entire system and demonstrate that\nthis value depends only on the network's R/X ratio but does not depend on the\ngrid topology. We also provide a conservative upper threshold of the\neigenvalues that are universal for any systems within a reasonable range of R/X\nratios. We then construct approximate certified stability regions representing\nconvex sets in the multidimensional space of droop gains that could be utilized\nfor gains optimization. We show how the certified stability region can be\nmaximized by properly choosing droop gains, and we provide closed-form analytic\nexpressions for the certified stability regions. The computational complexity\nof our method is almost independent of the number of inverters. The proposed\nmethodology has been tested using IEEE 123 node test system with 10 inverters.",
    "descriptor": "\nComments: 11 pages, 10 figures, submitted to IEEE Trans. Power Systems. arXiv admin note: text overlap with arXiv:2007.09347\n",
    "authors": [
      "Andrey Gorbunov",
      "Jimmy Chih-Hsien Peng",
      "Janusz W. Bialek",
      "Petr Vorobev"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01028"
  },
  {
    "id": "arXiv:2111.01029",
    "title": "Render In-between: Motion Guided Video Synthesis for Action  Interpolation",
    "abstract": "Upsampling videos of human activity is an interesting yet challenging task\nwith many potential applications ranging from gaming to entertainment and\nsports broadcasting. The main difficulty in synthesizing video frames in this\nsetting stems from the highly complex and non-linear nature of human motion and\nthe complex appearance and texture of the body. We propose to address these\nissues in a motion-guided frame-upsampling framework that is capable of\nproducing realistic human motion and appearance. A novel motion model is\ntrained to inference the non-linear skeletal motion between frames by\nleveraging a large-scale motion-capture dataset (AMASS). The high-frame-rate\npose predictions are then used by a neural rendering pipeline to produce the\nfull-frame output, taking the pose and background consistency into\nconsideration. Our pipeline only requires low-frame-rate videos and unpaired\nhuman motion data but does not require high-frame-rate videos for training.\nFurthermore, we contribute the first evaluation dataset that consists of\nhigh-quality and high-frame-rate videos of human activities for this task.\nCompared with state-of-the-art video interpolation techniques, our method\nproduces in-between frames with better quality and accuracy, which is evident\nby state-of-the-art results on pixel-level, distributional metrics and\ncomparative user evaluations. Our code and the collected dataset are available\nat https://git.io/Render-In-Between.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Hsuan-I Ho",
      "Xu Chen",
      "Jie Song",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01029"
  },
  {
    "id": "arXiv:2111.01035",
    "title": "A Unified View of cGANs with and without Classifiers",
    "abstract": "Conditional Generative Adversarial Networks (cGANs) are implicit generative\nmodels which allow to sample from class-conditional distributions. Existing\ncGANs are based on a wide range of different discriminator designs and training\nobjectives. One popular design in earlier works is to include a classifier\nduring training with the assumption that good classifiers can help eliminate\nsamples generated with wrong classes. Nevertheless, including classifiers in\ncGANs often comes with a side effect of only generating easy-to-classify\nsamples. Recently, some representative cGANs avoid the shortcoming and reach\nstate-of-the-art performance without having classifiers. Somehow it remains\nunanswered whether the classifiers can be resurrected to design better cGANs.\nIn this work, we demonstrate that classifiers can be properly leveraged to\nimprove cGANs. We start by using the decomposition of the joint probability\ndistribution to connect the goals of cGANs and classification as a unified\nframework. The framework, along with a classic energy model to parameterize\ndistributions, justifies the use of classifiers for cGANs in a principled\nmanner. It explains several popular cGAN variants, such as ACGAN, ProjGAN, and\nContraGAN, as special cases with different levels of approximations, which\nprovides a unified view and brings new insights to understanding cGANs.\nExperimental results demonstrate that the design inspired by the proposed\nframework outperforms state-of-the-art cGANs on multiple benchmark datasets,\nespecially on the most challenging ImageNet. The code is available at\nhttps://github.com/sian-chen/PyTorch-ECGAN.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Si-An Chen",
      "Chun-Liang Li",
      "Hsuan-Tien Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01035"
  },
  {
    "id": "arXiv:2111.01036",
    "title": "The degree of ill-posedness of composite linear ill-posed problems with  focus on the impact of the non-compact Hausdorff moment operator",
    "abstract": "We consider compact composite linear operators in Hilbert space, where the\ncomposition is given by some compact operator followed by some non-compact one\npossessing a non-closed range.\nFocus is on the impact of the non-compact factor on the overall behaviour of\nthe decay rates of the singular values of the composition. Specifically, the\ncomposition of the compact integration operator with the non-compact Hausdorff\nmoment operator is considered. We show that the singular values of the\ncomposition decay faster than the ones of the integration operator, providing a\nfirst example of this kind. However, there is a gap between available lower\nbounds for the decay rate and the obtained result. Therefore we conclude with a\ndiscussion.",
    "descriptor": "\nComments: 2 figures\n",
    "authors": [
      "Bernd Hofmann",
      "Peter Math\u00e9"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.01036"
  },
  {
    "id": "arXiv:2111.01042",
    "title": "Logic Rules Meet Deep Learning: A Novel Approach for Ship Type  Classification",
    "abstract": "The shipping industry is an important component of the global trade and\neconomy, however in order to ensure law compliance and safety it needs to be\nmonitored. In this paper, we present a novel Ship Type classification model\nthat combines vessel transmitted data from the Automatic Identification System,\nwith vessel imagery. The main components of our approach are the Faster R-CNN\nDeep Neural Network and a Neuro-Fuzzy system with IF-THEN rules. We evaluate\nour model using real world data and showcase the advantages of this combination\nwhile also compare it with other methods. Results show that our model can\nincrease prediction scores by up to 15.4\\% when compared with the next best\nmodel we considered, while also maintaining a level of explainability as\nopposed to common black box approaches.",
    "descriptor": "\nComments: Accepted and presented in RuleML+RR 2021\n",
    "authors": [
      "Manolis Pitsikalis",
      "Thanh-Toan Do",
      "Alexei Lisitsa",
      "Shan Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01042"
  },
  {
    "id": "arXiv:2111.01048",
    "title": "MOST-GAN: 3D Morphable StyleGAN for Disentangled Face Image Manipulation",
    "abstract": "Recent advances in generative adversarial networks (GANs) have led to\nremarkable achievements in face image synthesis. While methods that use\nstyle-based GANs can generate strikingly photorealistic face images, it is\noften difficult to control the characteristics of the generated faces in a\nmeaningful and disentangled way. Prior approaches aim to achieve such semantic\ncontrol and disentanglement within the latent space of a previously trained\nGAN. In contrast, we propose a framework that a priori models physical\nattributes of the face such as 3D shape, albedo, pose, and lighting explicitly,\nthus providing disentanglement by design. Our method, MOST-GAN, integrates the\nexpressive power and photorealism of style-based GANs with the physical\ndisentanglement and flexibility of nonlinear 3D morphable models, which we\ncouple with a state-of-the-art 2D hair manipulation network. MOST-GAN achieves\nphotorealistic manipulation of portrait images with fully disentangled 3D\ncontrol over their physical attributes, enabling extreme manipulation of\nlighting, facial expression, and pose variations up to full profile view.",
    "descriptor": "",
    "authors": [
      "Safa C. Medin",
      "Bernhard Egger",
      "Anoop Cherian",
      "Ye Wang",
      "Joshua B. Tenenbaum",
      "Xiaoming Liu",
      "Tim K. Marks"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01048"
  },
  {
    "id": "arXiv:2111.01058",
    "title": "Learning to Assimilate in Chaotic Dynamical Systems",
    "abstract": "The accuracy of simulation-based forecasting in chaotic systems is heavily\ndependent on high-quality estimates of the system state at the time the\nforecast is initialized. Data assimilation methods are used to infer these\ninitial conditions by systematically combining noisy, incomplete observations\nand numerical models of system dynamics to produce effective estimation\nschemes. We introduce amortized assimilation, a framework for learning to\nassimilate in dynamical systems from sequences of noisy observations with no\nneed for ground truth data. We motivate the framework by extending powerful\nresults from self-supervised denoising to the dynamical systems setting through\nthe use of differentiable simulation. Experimental results across several\nbenchmark systems highlight the improved effectiveness of our approach over\nwidely-used data assimilation methods.",
    "descriptor": "",
    "authors": [
      "Michael McCabe",
      "Jed Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2111.01058"
  },
  {
    "id": "arXiv:2111.01060",
    "title": "Exponential Lower Bounds for Locally Decodable and Correctable Codes for  Insertions and Deletions",
    "abstract": "Locally Decodable Codes (LDCs) are error-correcting codes for which\nindividual message symbols can be quickly recovered despite errors in the\ncodeword. LDCs for Hamming errors have been studied extensively in the past few\ndecades, where a major goal is to understand the amount of redundancy that is\nnecessary and sufficient to decode from large amounts of error, with small\nquery complexity.\nIn this work, we study LDCs for insertion and deletion errors, called Insdel\nLDCs. Their study was initiated by Ostrovsky and Paskin-Cherniavsky\n(Information Theoretic Security, 2015), who gave a reduction from Hamming LDCs\nto Insdel LDCs with a small blowup in the code parameters. On the other hand,\nthe only known lower bounds for Insdel LDCs come from those for Hamming LDCs,\nthus there is no separation between them. Here we prove new, strong lower\nbounds for the existence of Insdel LDCs. In particular, we show that $2$-query\nlinear Insdel LDCs do not exist, and give an exponential lower bound for the\nlength of all $q$-query Insdel LDCs with constant $q$. For $q \\ge 3$ our bounds\nare exponential in the existing lower bounds for Hamming LDCs. Furthermore, our\nexponential lower bounds continue to hold for adaptive decoders, and even in\nprivate-key settings where the encoder and decoder share secret randomness.\nThis exhibits a strict separation between Hamming LDCs and Insdel LDCs.\nOur strong lower bounds also hold for the related notion of Insdel LCCs\n(except in the private-key setting), due to an analogue to the Insdel notions\nof a reduction from Hamming LCCs to LDCs.\nOur techniques are based on a delicate design and analysis of hard\ndistributions of insertion and deletion errors, which depart significantly from\ntypical techniques used in analyzing Hamming LDCs.",
    "descriptor": "\nComments: Accepted to the 62nd Annual Symposium on Foundations of Computer Science (FOCS)\n",
    "authors": [
      "Jeremiah Blocki",
      "Kuan Cheng",
      "Elena Grigorescu",
      "Xin Li",
      "Yu Zheng",
      "Minshen Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.01060"
  },
  {
    "id": "arXiv:2111.01067",
    "title": "OctField: Hierarchical Implicit Functions for 3D Modeling",
    "abstract": "Recent advances in localized implicit functions have enabled neural implicit\nrepresentation to be scalable to large scenes. However, the regular subdivision\nof 3D space employed by these approaches fails to take into account the\nsparsity of the surface occupancy and the varying granularities of geometric\ndetails. As a result, its memory footprint grows cubically with the input\nvolume, leading to a prohibitive computational cost even at a moderately dense\ndecomposition. In this work, we present a learnable hierarchical implicit\nrepresentation for 3D surfaces, coded OctField, that allows high-precision\nencoding of intricate surfaces with low memory and computational budget. The\nkey to our approach is an adaptive decomposition of 3D scenes that only\ndistributes local implicit functions around the surface of interest. We achieve\nthis goal by introducing a hierarchical octree structure to adaptively\nsubdivide the 3D space according to the surface occupancy and the richness of\npart geometry. As octree is discrete and non-differentiable, we further propose\na novel hierarchical network that models the subdivision of octree cells as a\nprobabilistic process and recursively encodes and decodes both octree structure\nand surface geometry in a differentiable manner. We demonstrate the value of\nOctField for a range of shape modeling and reconstruction tasks, showing\nsuperiority over alternative approaches.",
    "descriptor": "\nComments: 13 pages, 9 figures, NeurIPS 2021\n",
    "authors": [
      "Jia-Heng Tang",
      "Weikai Chen",
      "Jie Yang",
      "Bo Wang",
      "Songrun Liu",
      "Bo Yang",
      "Lin Gao"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01067"
  },
  {
    "id": "arXiv:2111.01072",
    "title": "A generalized algorithm and framework for online 3-dimensional bin  packing in an automated sorting center",
    "abstract": "Online 3-dimensional bin packing problem (O3D-BPP) is getting renewed\nprominence due to the industrial automation brought by Industry 4.0. However,\ndue to limited attention in the past and its challenging nature, a good\napproximate algorithm is in scarcity as compared to 1D or 2D problems. This\npaper considers real-time O$3$D-BPP of cuboidal boxes with partial information\n(look-ahead) in an automated robotic sorting center. We present two\nrolling-horizon mixed-integer linear programming (MILP) cum-heuristic based\nalgorithms: MPack (for bench-marking) and MPackLite (for real-time deployment).\nAdditionally, we present a framework OPack that adapts and improves the\nperformance of BP heuristics by utilizing information in an online setting with\na look-ahead. We then perform a comparative analysis of BP heuristics (with and\nwithout OPack), MPack, and MPackLite on synthetic and industry provided data\nwith increasing look-ahead. MPackLite and the baseline heuristics perform\nwithin bounds of robot operations and thus, can be used in real-time.",
    "descriptor": "\nComments: Accepted in The Seventh Indian Control Conference (ICC-7) 2021\n",
    "authors": [
      "Ankush Ojha",
      "Marichi Agarwal",
      "Aniruddha Singhal",
      "Chayan Sarkar",
      "Supratim Ghosh",
      "Rajesh Sinha"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.01072"
  },
  {
    "id": "arXiv:2111.01073",
    "title": "Third-order accurate initialization of VOF volume fractions on  unstructured grids with arbitrary polyhedral cells",
    "abstract": "This paper introduces a novel method for the efficient and accurate\ncomputation of volume fractions on unstructured polyhedral meshes, where the\nphase boundary is an orientable hypersurface, implicitly given as the\niso-contour of a sufficiently smooth level-set function. Locally, i.e.~in each\nmesh cell, we compute a principal coordinate system in which the hypersurface\ncan be approximated as the graph of an osculating paraboloid. A recursive\napplication of the \\textsc{Gaussian} divergence theorem then allows to\nanalytically transform the volume integrals to curve integrals associated to\nthe polyhedron faces, which can be easily approximated numerically by means of\nstandard \\textsc{Gauss-Legendre} quadrature. This face-based formulation\nenables the applicability to unstructured meshes and considerably simplifies\nthe numerical procedure for applications in three spatial dimensions. We\ndiscuss the theoretical foundations and provide details of the numerical\nalgorithm. Finally, we present numerical results for convex and non-convex\nhypersurfaces embedded in cuboidal and tetrahedral meshes, showing both high\naccuracy and third- to fourth-order convergence with spatial resolution.",
    "descriptor": "",
    "authors": [
      "Johannes Kromer",
      "Dieter Bothe"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2111.01073"
  },
  {
    "id": "arXiv:2111.01074",
    "title": "FedFm: Towards a Robust Federated Learning Approach For Fault Mitigation  at the Edge Nodes",
    "abstract": "Federated Learning deviates from the norm of \"send data to model\" to \"send\nmodel to data\". When used in an edge ecosystem, numerous heterogeneous edge\ndevices collecting data through different means and connected through different\nnetwork channels get involved in the training process. Failure of edge devices\nin such an ecosystem due to device fault or network issues is highly likely. In\nthis paper, we first analyse the impact of the number of edge devices on an FL\nmodel and provide a strategy to select an optimal number of devices that would\ncontribute to the model. We observe how the edge ecosystem behaves when the\nselected devices fail and provide a mitigation strategy to ensure a robust\nFederated Learning technique.",
    "descriptor": "",
    "authors": [
      "Manupriya Gupta",
      "Pavas Goyal",
      "Rohit Verma",
      "Rajeev Shorey",
      "Huzur Saran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01074"
  },
  {
    "id": "arXiv:2111.01077",
    "title": "SmartSplit: Latency-Energy-Memory Optimisation for CNN Splitting on  Smartphone Environment",
    "abstract": "Artificial Intelligence has now taken centre stage in the smartphone industry\nowing to the need of bringing all processing close to the user and addressing\nprivacy concerns. Convolution Neural Networks (CNNs), which are used by several\nAI applications, are highly resource and computation intensive. Although new\ngeneration smartphones come with AI-enabled chips, minimal memory and energy\nutilisation is essential as many applications are run concurrently on a\nsmartphone. In light of this, optimising the workload on the smartphone by\noffloading a part of the processing to a cloud server is an important direction\nof research. In this paper, we analyse the feasibility of splitting CNNs\nbetween smartphones and cloud server by formulating a multi-objective\noptimisation problem that optimises the end-to-end latency, memory utilisation,\nand energy consumption. We design SmartSplit, a Genetic Algorithm with decision\nanalysis based approach to solve the optimisation problem. Our experiments run\nwith multiple CNN models show that splitting a CNN between a smartphone and a\ncloud server is feasible. The proposed approach, SmartSplit fares better when\ncompared to other state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Ishan Prakash",
      "Aniruddh Bansal",
      "Rohit Verma",
      "Rajeev Shorey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01077"
  },
  {
    "id": "arXiv:2111.01080",
    "title": "ZeBRA: Precisely Destroying Neural Networks with Zero-Data Based  Repeated Bit Flip Attack",
    "abstract": "In this paper, we present Zero-data Based Repeated bit flip Attack (ZeBRA)\nthat precisely destroys deep neural networks (DNNs) by synthesizing its own\nattack datasets. Many prior works on adversarial weight attack require not only\nthe weight parameters, but also the training or test dataset in searching\nvulnerable bits to be attacked. We propose to synthesize the attack dataset,\nnamed distilled target data, by utilizing the statistics of batch normalization\nlayers in the victim DNN model. Equipped with the distilled target data, our\nZeBRA algorithm can search vulnerable bits in the model without accessing\ntraining or test dataset. Thus, our approach makes the adversarial weight\nattack more fatal to the security of DNNs. Our experimental results show that\n2.0x (CIFAR-10) and 1.6x (ImageNet) less number of bit flips are required on\naverage to destroy DNNs compared to the previous attack method. Our code is\navailable at https://github. com/pdh930105/ZeBRA.",
    "descriptor": "\nComments: 14 pages, 3 figures, 5 tables, Accepted at British Machine Vision Conference (BMVC) 2021\n",
    "authors": [
      "Dahoon Park",
      "Kon-Woo Kwon",
      "Sunghoon Im",
      "Jaeha Kung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.01080"
  },
  {
    "id": "arXiv:2111.01082",
    "title": "FaceScape: 3D Facial Dataset and Benchmark for Single-View 3D Face  Reconstruction",
    "abstract": "In this paper, we present a large-scale detailed 3D face dataset, FaceScape,\nand the corresponding benchmark to evaluate single-view facial 3D\nreconstruction. By training on FaceScape data, a novel algorithm is proposed to\npredict elaborate riggable 3D face models from a single image input. FaceScape\ndataset provides 18,760 textured 3D faces, captured from 938 subjects and each\nwith 20 specific expressions. The 3D models contain the pore-level facial\ngeometry that is also processed to be topologically uniformed. These fine 3D\nfacial models can be represented as a 3D morphable model for rough shapes and\ndisplacement maps for detailed geometry. Taking advantage of the large-scale\nand high-accuracy dataset, a novel algorithm is further proposed to learn the\nexpression-specific dynamic details using a deep neural network. The learned\nrelationship serves as the foundation of our 3D face prediction system from a\nsingle image input. Different than the previous methods, our predicted 3D\nmodels are riggable with highly detailed geometry under different expressions.\nWe also use FaceScape data to generate the in-the-wild and in-the-lab benchmark\nto evaluate recent methods of single-view face reconstruction. The accuracy is\nreported and analyzed on the dimensions of camera pose and focal length, which\nprovides a faithful and comprehensive evaluation and reveals new challenges.\nThe unprecedented dataset, benchmark, and code have been released to the public\nfor research purpose.",
    "descriptor": "\nComments: 14 pages, 13 figures, journal extension of FaceScape(CVPR 2020). arXiv admin note: substantial text overlap with arXiv:2003.13989\n",
    "authors": [
      "Hao Zhu",
      "Haotian Yang",
      "Longwei Guo",
      "Yidi Zhang",
      "Yanru Wang",
      "Mingkai Huang",
      "Qiu Shen",
      "Ruigang Yang",
      "Xun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.01082"
  },
  {
    "id": "arXiv:2111.01083",
    "title": "Periodic Fast Multipole Method",
    "abstract": "A new scheme is presented for imposing periodic boundary conditions on unit\ncells with arbitrary source distributions. We restrict our attention here to\nthe Poisson, modified Helmholtz, Stokes and modified Stokes equations. The\napproach extends to the oscillatory equations of mathematical physics,\nincluding the Helmholtz and Maxwell equations, but we will address these in a\ncompanion paper, since the nature of the problem is somewhat different and\nincludes the consideration of quasiperiodic boundary conditions and resonances.\nUnlike lattice sum-based methods, the scheme is insensitive to the unit cell's\naspect ratio and is easily coupled to adaptive fast multipole methods (FMMs).\nOur analysis relies on classical \"plane-wave\" representations of the\nfundamental solution, and yields an explicit low-rank representation of the\nfield due to all image sources beyond the first layer of neighboring unit\ncells. When the aspect ratio of the unit cell is large, our scheme can be\ncoupled with the nonuniform fast Fourier transform (NUFFT) to accelerate the\nevaluation of the induced field. Its performance is illustrated with several\nnumerial examples.",
    "descriptor": "\nComments: 46 pages, 5 figures\n",
    "authors": [
      "Ruqi Pei",
      "Travis Askham",
      "Leslie Greengard",
      "Shidong Jiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.01083"
  },
  {
    "id": "arXiv:2111.01086",
    "title": "AutoShard -- Declaratively Managing Hot Spot Data Objects in NoSQL  Document Stores",
    "abstract": "NoSQL document stores are becoming increasingly popular as backends in web\ndevelopment. Not only do they scale out to large volumes of data, many systems\nare even custom-tailored for this domain: NoSQL document stores like Google\nCloud Datastore have been designed to support massively parallel reads, and\neven guarantee strong consistency in updating single data objects. However,\nstrongly consistent updates cannot be implemented arbitrarily fast in\nlarge-scale distributed systems. Consequently, data objects that experience\nhigh-frequent writes can turn into severe performance bottlenecks. In this\npaper, we present AutoShard, a ready-to-use object mapper for Java applications\nrunning against NoSQL document stores. AutoShard's unique feature is its\ncapability to gracefully shard hot spot data objects to avoid write contention.\nUsing AutoShard, developers can easily handle hot spot data objects by adding\nminimally intrusive annotations to their application code. Our experiments show\nthe significant impact of sharding on both the write throughput and the\nexecution time.",
    "descriptor": "\nComments: Published at WebDB 2014\n",
    "authors": [
      "Stefanie Scherzinger",
      "Andreas Thor"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.01086"
  },
  {
    "id": "arXiv:2111.01092",
    "title": "Fault-Tolerant Performance Enhancement of DC-DC Converters with  High-Speed Fault Clearing-unit based Redundant Power Switch Configurations",
    "abstract": "Fault detection and reconfiguration in fault-tolerant converters may\ncomplicated and necessitate using all-purpose microprocessors and high-speed\nsensors to guarantee the satisfactory performance of power converters.\nTherefore, providing fault-clearing feature without increasing the processing\nand sensing burdens and reducing the transition time between faulty to normal\nstate are of great importance. This research proposes a new redundant-switch\nconfiguration to address the mentioned challenges. The proposed configuration\nuses one diode and two fuses to eliminate the faulty switch and replace the\nreserve one, spontaneously. Open-circuit fault in the proposed configuration is\nclarified instantly. Moreover, the short-circuit fault is dealt as an\nopen-circuit fault by using a fuse. Thus, the fault-tolerant feature of the\nproposed switch configuration is achieved without using a complex, versatile\nand multifaceted fault managing unit. Resultant behaviors of the case studies\nare derived using MATLAB/SIMULINK. Also, steady-state thermal distribution of\npower switches which are implemented on a monolith heat sink, analyzed in\nCOMSOL Multi-physics environment. Finally, the viability of the proposed\nconfiguration is demonstrated by a laboratory-scaled prototype.",
    "descriptor": "",
    "authors": [
      "Tohid Rahimi",
      "Hossein Khoun Jahan",
      "Armin Abadifard",
      "Mohsen Akbari",
      "Pedram Ghavidel",
      "Masoud Farhadi",
      "Seyed Hossein Hosseini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01092"
  },
  {
    "id": "arXiv:2111.01094",
    "title": "On the Markov extremal problem in the $L^2$-norm with the classical  weight functions",
    "abstract": "This paper is devoted to Markov's extremal problems of the form\n$M_{n,k}=\\sup_{p\\in\\PP_n\\setminus\\{0\\}}{{\\|p^{(k)}\\|}_X}/{{\\|p\\|}_X}$ $(1\\le\nk\\le n)$, where $\\PP_n$ is the set of all algebraic polynomials of degree at\nmost $n$ and $X$ is a normed space, starting with original Markov's result in\nuniform norm on $X=C[-1,1]$ from the end of the 19th century. The central part\nis devoted to extremal problems on the space $X=L^2[(a,b);w]$ for the classical\nweights $w$ on $(-1,1)$, $(0,+\\infty)$ and $(-\\infty,+\\infty)$. Beside a short\naccount on basic properties of the (classical) orthogonal polynomials on the\nreal line, the explicit formulas for expressing $k$-th derivative of the\nclassical orthonormal polynomials in terms of the same polynomials are\npresented, which are important in our study of this kind of extremal problems,\nusing methods of linear algebra. Several results for all cases of the classical\nweights, including algorithms for numerical computation of the best constants\n$M_{n,k}$, as well as their lower and upper bounds, asymptotic behaviour, etc.,\nare also given. Finally, some results on Markov's extremal problems on certain\nrestricted classes of polynomials are also mentioned.",
    "descriptor": "",
    "authors": [
      "Gradimir V. Milovanovi\u0107"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.01094"
  },
  {
    "id": "arXiv:2111.01097",
    "title": "Encoding Program as Image: Evaluating Visual Representation of Source  Code",
    "abstract": "There are several approaches to encode source code in the input vectors of\nneural models. These approaches attempt to include various syntactic and\nsemantic features of input programs in their encoding. In this paper, we\ninvestigate Code2Snapshot, a novel representation of the source code that is\nbased on the snapshots of input programs. We evaluate several variations of\nthis representation and compare its performance with state-of-the-art\nrepresentations that utilize the rich syntactic and semantic features of input\nprograms. Our preliminary study on the utility of Code2Snapshot in the code\nsummarization task suggests that simple snapshots of input programs have\ncomparable performance to the state-of-the-art representations. Interestingly,\nobscuring the input programs have insignificant impacts on the Code2Snapshot\nperformance, suggesting that, for some tasks, neural models may provide high\nperformance by relying merely on the structure of input programs.",
    "descriptor": "\nComments: 8 pages, 2 figures, 1 table\n",
    "authors": [
      "Md Rafiqul Islam Rabin",
      "Mohammad Amin Alipour"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.01097"
  },
  {
    "id": "arXiv:2111.01100",
    "title": "Investigation of Independent Reinforcement Learning Algorithms in  Multi-Agent Environments",
    "abstract": "Independent reinforcement learning algorithms have no theoretical guarantees\nfor finding the best policy in multi-agent settings. However, in practice,\nprior works have reported good performance with independent algorithms in some\ndomains and bad performance in others. Moreover, a comprehensive study of the\nstrengths and weaknesses of independent algorithms is lacking in the\nliterature. In this paper, we carry out an empirical comparison of the\nperformance of independent algorithms on four PettingZoo environments that span\nthe three main categories of multi-agent environments, i.e., cooperative,\ncompetitive, and mixed. We show that in fully-observable environments,\nindependent algorithms can perform on par with multi-agent algorithms in\ncooperative and competitive settings. For the mixed environments, we show that\nagents trained via independent algorithms learn to perform well individually,\nbut fail to learn to cooperate with allies and compete with enemies. We also\nshow that adding recurrence improves the learning of independent algorithms in\ncooperative partially observable environments.",
    "descriptor": "\nComments: 15 pages, 7 figures, Accepted for NeurIPS 2021 Deep Reinforcement Learning Workshop\n",
    "authors": [
      "Ken Ming Lee",
      "Sriram Ganapathi Subramanian",
      "Mark Crowley"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01100"
  },
  {
    "id": "arXiv:2111.01103",
    "title": "Predicting Power System Dynamics and Transients: A Frequency Domain  Approach",
    "abstract": "The dynamics of a power grid are governed by a large number of nonlinear\nordinary differential equations (ODEs). To safely operate the system, operators\nneed to check that the states described by this set of ODEs stay within\nprescribed limits after various faults. Limited by the size and stiffness of\nthe ODEs, current numerical integration techniques are often too slow to be\nuseful for real-time or large-scale resource allocation problems. In addition,\nthe detailed system parameters are often not exactly known. Machine learning\napproaches have been proposed to reduce the computational efforts, but current\nmethods generally suffer from overfitting and failures to predict unstable\nbehaviors.\nThis paper proposes a novel framework for power system dynamic predictions by\nlearning in the frequency domain. The intuition is that although the system\nbehavior is complex in the time domain, there are relatively few dominant modes\nin the frequency domain. Therefore, we learn to predict by constructing neural\nnetworks with Fourier transform and filtering layers. System topology and fault\ninformation are encoded by taking a multi-dimensional Fourier transform,\nallowing us to leverage the fact that the trajectories are sparse both in time\nand spatial (across different buses) frequencies. We show that the proposed\napproach does not need detailed system parameters, speeds up prediction\ncomputations by orders of magnitude and is highly accurate for different fault\ntypes.",
    "descriptor": "",
    "authors": [
      "Wenqi Cui",
      "Weiwei Yang",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01103"
  },
  {
    "id": "arXiv:2111.01105",
    "title": "FREGAN : an application of generative adversarial networks in enhancing  the frame rate of videos",
    "abstract": "A digital video is a collection of individual frames, while streaming the\nvideo the scene utilized the time slice for each frame. High refresh rate and\nhigh frame rate is the demand of all high technology applications. The action\ntracking in videos becomes easier and motion becomes smoother in gaming\napplications due to the high refresh rate. It provides a faster response\nbecause of less time in between each frame that is displayed on the screen.\nFREGAN (Frame Rate Enhancement Generative Adversarial Network) model has been\nproposed, which predicts future frames of a video sequence based on a sequence\nof past frames. In this paper, we investigated the GAN model and proposed\nFREGAN for the enhancement of frame rate in videos. We have utilized Huber loss\nas a loss function in the proposed FREGAN. It provided excellent results in\nsuper-resolution and we have tried to reciprocate that performance in the\napplication of frame rate enhancement. We have validated the effectiveness of\nthe proposed model on the standard datasets (UCF101 and RFree500). The\nexperimental outcomes illustrate that the proposed model has a Peak\nsignal-to-noise ratio (PSNR) of 34.94 and a Structural Similarity Index (SSIM)\nof 0.95.",
    "descriptor": "",
    "authors": [
      "Rishik Mishra",
      "Neeraj Gupta",
      "Nitya Shukla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.01105"
  },
  {
    "id": "arXiv:2111.01108",
    "title": "Resource-Efficient Federated Learning",
    "abstract": "Federated Learning (FL) enables distributed training by learners using local\ndata, thereby enhancing privacy and reducing communication. However, it\npresents numerous challenges relating to the heterogeneity of the data\ndistribution, device capabilities, and participant availability as deployments\nscale, which can impact both model convergence and bias. Existing FL schemes\nuse random participant selection to improve fairness; however, this can result\nin inefficient use of resources and lower quality training. In this work, we\nsystematically address the question of resource efficiency in FL, showing the\nbenefits of intelligent participant selection, and incorporation of updates\nfrom straggling participants. We demonstrate how these factors enable resource\nefficiency while also improving trained model quality.",
    "descriptor": "",
    "authors": [
      "Ahmed M. Abdelmoniem",
      "Atal Narayan Sahu",
      "Marco Canini",
      "Suhaib A. Fahmy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.01108"
  },
  {
    "id": "arXiv:2111.01118",
    "title": "Rebooting ACGAN: Auxiliary Classifier GANs with Stable Training",
    "abstract": "Conditional Generative Adversarial Networks (cGAN) generate realistic images\nby incorporating class information into GAN. While one of the most popular\ncGANs is an auxiliary classifier GAN with softmax cross-entropy loss (ACGAN),\nit is widely known that training ACGAN is challenging as the number of classes\nin the dataset increases. ACGAN also tends to generate easily classifiable\nsamples with a lack of diversity. In this paper, we introduce two cures for\nACGAN. First, we identify that gradient exploding in the classifier can cause\nan undesirable collapse in early training, and projecting input vectors onto a\nunit hypersphere can resolve the problem. Second, we propose the Data-to-Data\nCross-Entropy loss (D2D-CE) to exploit relational information in the\nclass-labeled dataset. On this foundation, we propose the Rebooted Auxiliary\nClassifier Generative Adversarial Network (ReACGAN). The experimental results\nshow that ReACGAN achieves state-of-the-art generation results on CIFAR10,\nTiny-ImageNet, CUB200, and ImageNet datasets. We also verify that ReACGAN\nbenefits from differentiable augmentations and that D2D-CE harmonizes with\nStyleGAN2 architecture. Model weights and a software package that provides\nimplementations of representative cGANs and all experiments in our paper are\navailable at https://github.com/POSTECH-CVLab/PyTorch-StudioGAN.",
    "descriptor": "\nComments: 34 pages, 26 figures, 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Minguk Kang",
      "Woohyeon Shim",
      "Minsu Cho",
      "Jaesik Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01118"
  },
  {
    "id": "arXiv:2111.01122",
    "title": "Stakeholder Participation in AI: Beyond \"Add Diverse Stakeholders and  Stir\"",
    "abstract": "There is a growing consensus in HCI and AI research that the design of AI\nsystems needs to engage and empower stakeholders who will be affected by AI.\nHowever, the manner in which stakeholders should participate in AI design is\nunclear. This workshop paper aims to ground what we dub a 'participatory turn'\nin AI design by synthesizing existing literature on participation and through\nempirical analysis of its current practices via a survey of recent published\nresearch and a dozen semi-structured interviews with AI researchers and\npractitioners. Based on our literature synthesis and empirical research, this\npaper presents a conceptual framework for analyzing participatory approaches to\nAI design and articulates a set of empirical findings that in ensemble detail\nout the contemporary landscape of participatory practice in AI design. These\nfindings can help bootstrap a more principled discussion on how PD of AI should\nmove forward across AI, HCI, and other research communities.",
    "descriptor": "\nComments: Pre-print of an accepted paper at the Human-Centered AI workshop at NeurIPS 2021\n",
    "authors": [
      "Fernando Delgado",
      "Stephen Yang",
      "Michael Madaio",
      "Qian Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.01122"
  },
  {
    "id": "arXiv:2111.01124",
    "title": "When Does Contrastive Learning Preserve Adversarial Robustness from  Pretraining to Finetuning?",
    "abstract": "Contrastive learning (CL) can learn generalizable feature representations and\nachieve the state-of-the-art performance of downstream tasks by finetuning a\nlinear classifier on top of it. However, as adversarial robustness becomes\nvital in image classification, it remains unclear whether or not CL is able to\npreserve robustness to downstream tasks. The main challenge is that in the\nself-supervised pretraining + supervised finetuning paradigm, adversarial\nrobustness is easily forgotten due to a learning task mismatch from pretraining\nto finetuning. We call such a challenge 'cross-task robustness\ntransferability'. To address the above problem, in this paper we revisit and\nadvance CL principles through the lens of robustness enhancement. We show that\n(1) the design of contrastive views matters: High-frequency components of\nimages are beneficial to improving model robustness; (2) Augmenting CL with\npseudo-supervision stimulus (e.g., resorting to feature clustering) helps\npreserve robustness without forgetting. Equipped with our new designs, we\npropose AdvCL, a novel adversarial contrastive pretraining framework. We show\nthat AdvCL is able to enhance cross-task robustness transferability without\nloss of model accuracy and finetuning efficiency. With a thorough experimental\nstudy, we demonstrate that AdvCL outperforms the state-of-the-art\nself-supervised robust learning methods across multiple datasets (CIFAR-10,\nCIFAR-100, and STL-10) and finetuning schemes (linear evaluation and full model\nfinetuning).",
    "descriptor": "\nComments: NeurIPS 2021. Code is available at this https URL\n",
    "authors": [
      "Lijie Fan",
      "Sijia Liu",
      "Pin-Yu Chen",
      "Gaoyuan Zhang",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01124"
  },
  {
    "id": "arXiv:2108.11791",
    "title": "Multiple Sclerosis Lesions Identification/Segmentation in Magnetic  Resonance Imaging using Ensemble CNN and Uncertainty Classification",
    "abstract": "To date, several automated strategies for identification/segmentation of\nMultiple Sclerosis (MS) lesions with the use of Magnetic Resonance Imaging\n(MRI) have been presented but they are either outperformed by human experts or\nperform differently from them. This is mainly due to the ambiguity originated\nby MRI instabilities, peculiar variability of MS and unspecific nature of MRI\nwith respect to MS. Physicians partially manage the uncertainty generated by\nambiguity relying on their personal radiological/clinical/anatomical background\nand experience. We present an automated framework based on three pivotal\nconcepts to better emulate human reasoning: 1. the modelling of uncertainty; 2.\nthe proposal of two, separately trained, CNN, one optimized with respect to\nlesions themselves and the other to the environment surrounding lesions,\nrespectively repeated for axial, coronal and sagittal directions; 3. the\ndefinition of an ensemble classifier to merge the information collected by all\nCNN. The proposed framework is trained, validated and tested on the 2016 MSSEG\nbenchmark public data set from a single imaging modality, the FLuid-Attenuated\nInversion Recovery (FLAIR). The comparison, made with the consensus (the\nground-truth) between 7 human raters and with each of the 7 human raters,\nproves that there is no significant difference between the automated and the\nhuman raters. The results of our framework concerning the uncertainty are also\nreported, even if a comparison with the raters is impossible because they don't\nrecognize this class.",
    "descriptor": "",
    "authors": [
      "Giuseppe Placidi",
      "Luigi Cinque",
      "Filippo Mignosi",
      "Matteo Polsinelli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11791"
  },
  {
    "id": "arXiv:2110.12662",
    "title": "Sampling-Based Robust Control of Autonomous Systems with Non-Gaussian  Noise",
    "abstract": "Controllers for autonomous systems that operate in safety-critical settings\nmust account for stochastic disturbances. Such disturbances are often modelled\nas process noise, and common assumptions are that the underlying distributions\nare known and/or Gaussian. In practice, however, these assumptions may be\nunrealistic and can lead to poor approximations of the true noise distribution.\nWe present a novel planning method that does not rely on any explicit\nrepresentation of the noise distributions. In particular, we address the\nproblem of computing a controller that provides probabilistic guarantees on\nsafely reaching a target. First, we abstract the continuous system into a\ndiscrete-state model that captures noise by probabilistic transitions between\nstates. As a key contribution, we adapt tools from the scenario approach to\ncompute probably approximately correct (PAC) bounds on these transition\nprobabilities, based on a finite number of samples of the noise. We capture\nthese bounds in the transition probability intervals of a so-called interval\nMarkov decision process (iMDP). This iMDP is robust against uncertainty in the\ntransition probabilities, and the tightness of the probability intervals can be\ncontrolled through the number of samples. We use state-of-the-art verification\ntechniques to provide guarantees on the iMDP, and compute a controller for\nwhich these guarantees carry over to the autonomous system. Realistic\nbenchmarks show the practical applicability of our method, even when the iMDP\nhas millions of states or transitions.",
    "descriptor": "",
    "authors": [
      "Thom S. Badings",
      "Alessandro Abate",
      "Nils Jansen",
      "David Parker",
      "Hasan A. Poonawala",
      "Marielle Stoelinga"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.12662"
  },
  {
    "id": "arXiv:2111.00009",
    "title": "Revisiting joint decoding based multi-talker speech recognition with DNN  acoustic model",
    "abstract": "In typical multi-talker speech recognition systems, a neural network-based\nacoustic model predicts senone state posteriors for each speaker. These are\nlater used by a single-talker decoder which is applied on each speaker-specific\noutput stream separately. In this work, we argue that such a scheme is\nsub-optimal and propose a principled solution that decodes all speakers\njointly. We modify the acoustic model to predict joint state posteriors for all\nspeakers, enabling the network to express uncertainty about the attribution of\nparts of the speech signal to the speakers. We employ a joint decoder that can\nmake use of this uncertainty together with higher-level language information.\nFor this, we revisit decoding algorithms used in factorial generative models in\nearly multi-talker speech recognition systems. In contrast with these early\nworks, we replace the GMM acoustic model with DNN, which provides greater\nmodeling power and simplifies part of the inference. We demonstrate the\nadvantage of joint decoding in proof of concept experiments on a mixed-TIDIGITS\ndataset.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Martin Kocour",
      "Kate\u0159ina \u017dmol\u00edkov\u00e1",
      "Lucas Ondel",
      "J\u00e1n \u0160vec",
      "Marc Delcroix",
      "Tsubasa Ochiai",
      "Luk\u00e1\u0161 Burget",
      "Jan \u010cernock\u00fd"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.00009"
  },
  {
    "id": "arXiv:2111.00030",
    "title": "Differentiable Tracking-Based Training of Deep Learning Sound Source  Localizers",
    "abstract": "Data-based and learning-based sound source localization (SSL) has shown\npromising results in challenging conditions, and is commonly set as a\nclassification or a regression problem. Regression-based approaches have\ncertain advantages over classification-based, such as continuous\ndirection-of-arrival estimation of static and moving sources. However,\nmulti-source scenarios require multiple regressors without a clear training\nstrategy up-to-date, that does not rely on auxiliary information such as\nsimultaneous sound classification. We investigate end-to-end training of such\nmethods with a technique recently proposed for video object detectors, adapted\nto the SSL setting. A differentiable network is constructed that can be plugged\nto the output of the localizer to solve the optimal assignment between\npredictions and references, optimizing directly the popular CLEAR-MOT tracking\nmetrics. Results indicate large improvements over directly optimizing mean\nsquared errors, in terms of localization error, detection metrics, and tracking\ncapabilities.",
    "descriptor": "\nComments: Submitted to IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA2021)\n",
    "authors": [
      "Sharath Adavanne",
      "Archontis Politis",
      "Tuomas Virtanen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.00030"
  },
  {
    "id": "arXiv:2111.00034",
    "title": "Neural Networks as Kernel Learners: The Silent Alignment Effect",
    "abstract": "Neural networks in the lazy training regime converge to kernel machines. Can\nneural networks in the rich feature learning regime learn a kernel machine with\na data-dependent kernel? We demonstrate that this can indeed happen due to a\nphenomenon we term silent alignment, which requires that the tangent kernel of\na network evolves in eigenstructure while small and before the loss appreciably\ndecreases, and grows only in overall scale afterwards. We show that such an\neffect takes place in homogenous neural networks with small initialization and\nwhitened data. We provide an analytical treatment of this effect in the linear\nnetwork case. In general, we find that the kernel develops a low-rank\ncontribution in the early phase of training, and then evolves in overall scale,\nyielding a function equivalent to a kernel regression solution with the final\nnetwork's tangent kernel. The early spectral learning of the kernel depends on\nboth depth and on relative learning rates in each layer. We also demonstrate\nthat non-whitened data can weaken the silent alignment effect.",
    "descriptor": "\nComments: 24 pages, 13 figures\n",
    "authors": [
      "Alexander Atanasov",
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00034"
  },
  {
    "id": "arXiv:2111.00036",
    "title": "Real-time detection of anomalies in large-scale transient surveys",
    "abstract": "New time-domain surveys, such as the Rubin Observatory Legacy Survey of Space\nand Time (LSST), will observe millions of transient alerts each night, making\nstandard approaches of visually identifying new and interesting transients\ninfeasible. We present two novel methods of automatically detecting anomalous\ntransient light curves in real-time. Both methods are based on the simple idea\nthat if the light curves from a known population of transients can be\naccurately modelled, any deviations from model predictions are likely\nanomalies. The first modelling approach is a probabilistic neural network built\nusing Temporal Convolutional Networks (TCNs) and the second is an interpretable\nBayesian parametric model of a transient. We demonstrate our methods' ability\nto provide anomaly scores as a function of time on light curves from the Zwicky\nTransient Facility. We show that the flexibility of neural networks, the\nattribute that makes them such a powerful tool for many regression tasks, is\nwhat makes them less suitable for anomaly detection when compared with our\nparametric model. The parametric model is able to identify anomalies with\nrespect to common supernova classes with low false anomaly rates and high true\nanomaly rates achieving Area Under the Receive Operating Characteristic (ROC)\nCurve (AUC) scores above 0.8 for most rare classes such as kilonovae, tidal\ndisruption events, intermediate luminosity transients, and pair-instability\nsupernovae. Our ability to identify anomalies improves over the lifetime of the\nlight curves. Our framework, used in conjunction with transient classifiers,\nwill enable fast and prioritised follow-up of unusual transients from new\nlarge-scale surveys.",
    "descriptor": "\nComments: 25 pages, 21 figures, submitted to MNRAS\n",
    "authors": [
      "Daniel Muthukrishna",
      "Kaisey S. Mandel",
      "Michelle Lochner",
      "Sara Webb",
      "Gautham Narayan"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00036"
  },
  {
    "id": "arXiv:2111.00043",
    "title": "Learning generative models for valid knockoffs using novel  multivariate-rank based statistics",
    "abstract": "We consider the problem of generating valid knockoffs for knockoff filtering\nwhich is a statistical method that provides provable false discovery rate\nguarantees for any model selection procedure. To this end, we are motivated by\nrecent advances in multivariate distribution-free goodness-of-fit tests namely,\nthe rank energy (RE), that is derived using theoretical results characterizing\nthe optimal maps in the Monge's Optimal Transport (OT) problem. However, direct\nuse of use RE for learning generative models is not feasible because of its\nhigh computational and sample complexity, saturation under large support\ndiscrepancy between distributions, and non-differentiability in generative\nparameters. To alleviate these, we begin by proposing a variant of the RE,\ndubbed as soft rank energy (sRE), and its kernel variant called as soft rank\nmaximum mean discrepancy (sRMMD) using entropic regularization of Monge's OT\nproblem. We then use sRMMD to generate deep knockoffs and show via extensive\nevaluation that it is a novel and effective method to produce valid knockoffs,\nachieving comparable, or in some cases improved tradeoffs between detection\npower Vs false discoveries.",
    "descriptor": "\nComments: 23 pages, 9 figures\n",
    "authors": [
      "Shoaib Bin Masud",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00043"
  },
  {
    "id": "arXiv:2111.00047",
    "title": "Robust and efficient change point detection using novel multivariate  rank-energy GoF test",
    "abstract": "In this paper, we use and further develop upon a recently proposed\nmultivariate, distribution-free Goodness-of-Fit (GoF) test based on the theory\nof Optimal Transport (OT) called the Rank Energy (RE) [1], for non-parametric\nand unsupervised Change Point Detection (CPD) in multivariate time series data.\nWe show that directly using RE leads to high sensitivity to very small changes\nin distributions (causing high false alarms) and it requires large sample\ncomplexity and huge computational cost. To alleviate these drawbacks, we\npropose a new GoF test statistic called as soft-Rank Energy (sRE) that is based\non entropy regularized OT and employ it towards CPD. We discuss the advantages\nof using sRE over RE and demonstrate that the proposed sRE based CPD\noutperforms all the existing methods in terms of Area Under the Curve (AUC) and\nF1-score on real and synthetic data sets.",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "Shoaib Bin Masud"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.00047"
  },
  {
    "id": "arXiv:2111.00077",
    "title": "DeepDoseNet: A Deep Learning model for 3D Dose Prediction in Radiation  Therapy",
    "abstract": "The DeepDoseNet 3D dose prediction model based on ResNet and Dilated DenseNet\nis proposed. The 340 head-and-neck datasets from the 2020 AAPM OpenKBP\nchallenge were utilized, with 200 for training, 40 for validation, and 100 for\ntesting. Structures include 56Gy, 63Gy, 70Gy PTVs, and brainstem, spinal cord,\nright parotid, left parotid, larynx, esophagus, and mandible OARs. Mean squared\nerror (MSE) loss, mean absolute error (MAE) loss, and MAE plus dose-volume\nhistogram (DVH) based loss functions were investigated. Each model's\nperformance was compared using a 3D dose score, $\\bar{S_{D}}$, (mean absolute\ndifference between ground truth and predicted 3D dose distributions) and a DVH\nscore, $\\bar{S_{DVH}}$ (mean absolute difference between ground truth and\npredicted dose-volume metrics).Furthermore, DVH metrics Mean[Gy] and D0.1cc\n[Gy] for OARs and D99%, D95%, D1% for PTVs were computed. DeepDoseNet with the\nMAE plus DVH-based loss function had the best dose score performance of the\nOpenKBP entries. MAE+DVH model had the lowest prediction error (P<0.0001,\nWilcoxon test) on validation and test datasets (validation:\n$\\bar{S_{D}}$=2.3Gy, $\\bar{S_{DVH}}$=1.9Gy; test: $\\bar{S_{D}}$=2.0Gy,\n$\\bar{S_{DVH}}$=1.6Gy) followed by the MAE model (validation:\n$\\bar{S_{D}}$=3.6Gy, $\\bar{S_{DVH}}$=2.4Gy; test: $\\bar{S_{D}}$=3.5Gy,\n$\\bar{S_{DVH}}$=2.3Gy). The MSE model had the highest prediction error\n(validation: $\\bar{S_{D}}$=3.7Gy, $\\bar{S_{DVH}}$=3.2Gy; test:\n$\\bar{S_{D}}$=3.6Gy, $\\bar{S_{DVH}}$=3.0Gy). No significant difference was\nfound among models in terms of Mean [Gy], but the MAE+DVH model significantly\noutperformed the MAE and MSE models in terms of D0.1cc[Gy], particularly for\nmandible and parotids on both validation (P<0.01) and test (P<0.0001) datasets.\nMAE+DVH outperformed (P<0.0001) in terms of D99%, D95%, D1% for targets.\nMAE+DVH reduced $\\bar{S_{D}}$ by ~60% and $\\bar{S_{DVH}}$ by ~70%.",
    "descriptor": "",
    "authors": [
      "Mumtaz Hussain Soomro",
      "Victor Gabriel Leandro Alves",
      "Hamidreza Nourzadeh",
      "Jeffrey V. Siebers"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.00077"
  },
  {
    "id": "arXiv:2111.00102",
    "title": "Fetal MRI by robust deep generative prior reconstruction and  diffeomorphic registration: application to gestational age prediction",
    "abstract": "Magnetic resonance imaging of whole fetal body and placenta is limited by\ndifferent sources of motion affecting the womb. Usual scanning techniques\nemploy single-shot multi-slice sequences where anatomical information in\ndifferent slices may be subject to different deformations, contrast variations\nor artifacts. Volumetric reconstruction formulations have been proposed to\ncorrect for these factors, but they must accommodate a non-homogeneous and\nnon-isotropic sampling, so regularization becomes necessary. Thus, in this\npaper we propose a deep generative prior for robust volumetric reconstructions\nintegrated with a diffeomorphic volume to slice registration method.\nExperiments are performed to validate our contributions and compare with a\nstate of the art method in a cohort of $72$ fetal datasets in the range of\n$20-36$ weeks gestational age. Results suggest improved image resolution and\nmore accurate prediction of gestational age at scan when comparing to a state\nof the art reconstruction method. In addition, gestational age prediction\nresults from our volumetric reconstructions compare favourably with existing\nbrain-based approaches, with boosted accuracy when integrating information of\norgans other than the brain. Namely, a mean absolute error of $0.618$ weeks\n($R^2=0.958$) is achieved when combining fetal brain and trunk information.",
    "descriptor": "\nComments: 23 pages, 15 figures, 1 table\n",
    "authors": [
      "Lucilio Cordero-Grande",
      "Juan Enrique Ortu\u00f1o-Fisac",
      "Alena Uus",
      "Maria Deprez",
      "Andr\u00e9s Santos",
      "Joseph V. Hajnal",
      "Mar\u00eda Jes\u00fas Ledesma-Carbayo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.00102"
  },
  {
    "id": "arXiv:2111.00108",
    "title": "High-dimensional multi-trait GWAS by reverse prediction of genotypes",
    "abstract": "Multi-trait genome-wide association studies (GWAS) use multi-variate\nstatistical methods to identify associations between genetic variants and\nmultiple correlated traits simultaneously, and have higher statistical power\nthan independent univariate analysis of traits. Reverse regression, where\ngenotypes of genetic variants are regressed on multiple traits simultaneously,\nhas emerged as a promising approach to perform multi-trait GWAS in\nhigh-dimensional settings where the number of traits exceeds the number of\nsamples. We extended this approach and analyzed different machine learning\nmethods (ridge regression, random forests and support vector machines)for\nreverse regression in multi-trait GWAS, using genotypes, gene expression data\nand ground-truth transcriptional regulatory networks from the DREAM5 SysGen\nChallenge and from a cross between two yeast strains to evaluate methods. We\nfound that genotype prediction performance, in terms of root mean squared error\n(RMSE), allowed to distinguish between genomic regions with high and low\ntranscriptional activity. Moreover, model feature coefficients correlated with\nthe strength of association between variants and individual traits, and were\npredictive of true trans-eQTL target genes, with complementary findings across\nmethods.",
    "descriptor": "",
    "authors": [
      "Muhammad Ammar Malik",
      "Adriaan-Alexander Ludl",
      "Tom Michoel"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.00108"
  },
  {
    "id": "arXiv:2111.00127",
    "title": "Cross-attention conformer for context modeling in speech enhancement for  ASR",
    "abstract": "This work introduces \\emph{cross-attention conformer}, an attention-based\narchitecture for context modeling in speech enhancement. Given that the context\ninformation can often be sequential, and of different length as the audio that\nis to be enhanced, we make use of cross-attention to summarize and merge\ncontextual information with input features. Building upon the recently proposed\nconformer model that uses self attention layers as building blocks, the\nproposed cross-attention conformer can be used to build deep contextual models.\nAs a concrete example, we show how noise context, i.e., short noise-only audio\nsegment preceding an utterance, can be used to build a speech enhancement\nfeature frontend using cross-attention conformer layers for improving noise\nrobustness of automatic speech recognition.",
    "descriptor": "\nComments: Will appear in IEEE-ASRU 2021\n",
    "authors": [
      "Arun Narayanan",
      "Chung-Cheng Chiu",
      "Tom O'Malley",
      "Quan Wang",
      "Yanzhang He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.00127"
  },
  {
    "id": "arXiv:2111.00137",
    "title": "Efficient Inference Without Trading-off Regret in Bandits: An Allocation  Probability Test for Thompson Sampling",
    "abstract": "Using bandit algorithms to conduct adaptive randomised experiments can\nminimise regret, but it poses major challenges for statistical inference (e.g.,\nbiased estimators, inflated type-I error and reduced power). Recent attempts to\naddress these challenges typically impose restrictions on the exploitative\nnature of the bandit algorithm$-$trading off regret$-$and require large sample\nsizes to ensure asymptotic guarantees. However, large experiments generally\nfollow a successful pilot study, which is tightly constrained in its size or\nduration. Increasing power in such small pilot experiments, without limiting\nthe adaptive nature of the algorithm, can allow promising interventions to\nreach a larger experimental phase. In this work we introduce a novel hypothesis\ntest, uniquely based on the allocation probabilities of the bandit algorithm,\nand without constraining its exploitative nature or requiring a minimum\nexperimental size. We characterise our $Allocation\\ Probability\\ Test$ when\napplied to $Thompson\\ Sampling$, presenting its asymptotic theoretical\nproperties, and illustrating its finite-sample performances compared to\nstate-of-the-art approaches. We demonstrate the regret and inferential\nadvantages of our approach, particularly in small samples, in both extensive\nsimulations and in a real-world experiment on mental health aspects.",
    "descriptor": "\nComments: 32 pages including supplementary material\n",
    "authors": [
      "Nina Deliu",
      "Joseph J. Williams",
      "Sofia S. Villar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.00137"
  },
  {
    "id": "arXiv:2111.00143",
    "title": "On the Control of Flying Qubits",
    "abstract": "The control of flying quantum bits (qubits) carried by traveling quantum\nfields is crucial for coherent information transmission in quantum networks. In\nthis paper, we develop a general framework for modeling the generation,\ncatching and transformation processes of flying qubits. We introduce the\nquantum stochastic differential equation (QSDE) to describe the flying-qubit\ninput-output relations actuated by a standing quantum system. Under the\ncontinuous time-ordered photon-number basis, the infinite-dimensional QSDE is\nreduced to a low-dimensional deterministic non-unitary differential equation\nfor the state evolution of the standing system, and the outgoing flying-qubit\nstates can be calculated via randomly occurring quantum jumps. This makes it\npossible, as demonstrated by examples of flying-qubit generation and\ntransformation, to analyze general cases when the number of excitations is not\nreserved. The proposed framework lays the foundation for the design of\nflying-qubit control systems from a control theoretic point of view, within\nwhich advanced control techniques can be incorporated for practical\napplications.",
    "descriptor": "\nComments: 18 pages, 4 figures. Comments are welcome!\n",
    "authors": [
      "Wen-Long Li ang Guofeng Zhang",
      "Re-Bing Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00143"
  },
  {
    "id": "arXiv:2111.00193",
    "title": "M2MRF: Many-to-Many Reassembly of Features for Tiny Lesion Segmentation  in Fundus Images",
    "abstract": "Feature reassembly is an essential component in modern CNNs-based\nsegmentation approaches, which includes feature downsampling and upsampling\noperators. Existing feature reassembly operators reassemble multiple features\nfrom a small predefined region into one for each target location independently.\nThis may result in loss of spatial information, which could vanish activations\nof tiny lesions particularly when they cluster together. In this paper, we\npropose a many-to-many reassembly of features (M2MRF). It reassembles features\nin a dimension-reduced feature space and simultaneously aggregates multiple\nfeatures inside a large predefined region into multiple target features. In\nthis way, long range spatial dependencies are captured to maintain activations\non tiny lesions, particularly when multiple lesions coexist. Experimental\nresults on two lesion segmentation benchmarks, i.e. DDR and IDRiD, show that\nour M2MRF outperforms existing feature reassembly operators.",
    "descriptor": "",
    "authors": [
      "Qing Liu",
      "Haotian Liu",
      "Yixiong Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00193"
  },
  {
    "id": "arXiv:2111.00219",
    "title": "Unpaired Learning for High Dynamic Range Image Tone Mapping",
    "abstract": "High dynamic range (HDR) photography is becoming increasingly popular and\navailable by DSLR and mobile-phone cameras. While deep neural networks (DNN)\nhave greatly impacted other domains of image manipulation, their use for HDR\ntone-mapping is limited due to the lack of a definite notion of ground-truth\nsolution, which is needed for producing training data.\nIn this paper we describe a new tone-mapping approach guided by the distinct\ngoal of producing low dynamic range (LDR) renditions that best reproduce the\nvisual characteristics of native LDR images. This goal enables the use of an\nunpaired adversarial training based on unrelated sets of HDR and LDR images,\nboth of which are widely available and easy to acquire.\nIn order to achieve an effective training under this minimal requirements, we\nintroduce the following new steps and components: (i) a range-normalizing\npre-process which estimates and applies a different level of curve-based\ncompression, (ii) a loss that preserves the input content while allowing the\nnetwork to achieve its goal, and (iii) the use of a more concise discriminator\nnetwork, designed to promote the reproduction of low-level attributes native\nLDR possess.\nEvaluation of the resulting network demonstrates its ability to produce\nphoto-realistic artifact-free tone-mapped images, and state-of-the-art\nperformance on different image fidelity indices and visual distances.",
    "descriptor": "",
    "authors": [
      "Yael Vinker",
      "Inbar Huberman-Spiegelglas",
      "Raanan Fattal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00219"
  },
  {
    "id": "arXiv:2111.00226",
    "title": "Quantum simulation of perfect state transfer on weighted cubelike graphs",
    "abstract": "A continuous-time quantum walk on a graph evolves according to the unitary\noperator $e^{-iAt}$, where $A$ is the adjacency matrix of the graph. Perfect\nstate transfer (PST) in a quantum walk is the transfer of a quantum state from\none node of a graph to another node with $100\\%$ fidelity. It can be shown that\nthe adjacency matrix of a cubelike graph is a finite sum of tensor products of\nPauli $X$ operators. We use this fact to construct an efficient quantum circuit\nfor the quantum walk on cubelike graphs. In \\cite{Cao2021, rishi2021(2)}, a\ncharacterization of integer weighted cubelike graphs is given that exhibit\nperiodicity or PST at time $t=\\pi/2$. We use our circuits to demonstrate PST or\nperiodicity in these graphs on IBM's quantum computing platform~\\cite{Qiskit,\nIBM2021}.",
    "descriptor": "",
    "authors": [
      "Jaideep Mulherkar",
      "Rishikant Rajdeepak",
      "V. Sunitha"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.00226"
  },
  {
    "id": "arXiv:2111.00242",
    "title": "Speech Denoising Using Only Single Noisy Audio Samples",
    "abstract": "In this paper, we propose a novel Single Noisy Audio De-noising Framework\n(SNA-DF) for speech denoising using only single noisy audio samples, which\novercomes the limi-tation of constructing either noisy-clean training pairs or\nmultiple independent noisy audio samples. The proposed SNA-DF contains two\nmodules: training audio pairs gener-ated module and audio denoising module. The\nfirst module adopts a random audio sub-sampler on single noisy audio samples\nfor the generation of training audio pairs. The sub-sampled training audio\npairs are then fed into the audio denoising module, which employs a deep\ncomplex U-Net incorporating a complex two-stage transformer (cTSTM) to extract\nboth magnitude and phase information for taking full advantage of the complex\nfeatures of single noisy au-dios. Experimental results show that the proposed\nSNA-DF not only eliminates the high dependence on clean targets of traditional\naudio denoising methods, but also outperforms the methods using multiple noisy\naudio samples.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Qingchun Li",
      "Jiasong Wu",
      "Yilun Kong",
      "Chunfeng Yang",
      "Youyong Kong",
      "Guanyu Yang",
      "Lotfi Senhadji",
      "Huazhong Shu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.00242"
  },
  {
    "id": "arXiv:2111.00273",
    "title": "Cross-Modality Fusion Transformer for Multispectral Object Detection",
    "abstract": "Multispectral image pairs can provide the combined information, making object\ndetection applications more reliable and robust in the open world. To fully\nexploit the different modalities, we present a simple yet effective\ncross-modality feature fusion approach, named Cross-Modality Fusion Transformer\n(CFT) in this paper. Unlike prior CNNs-based works, guided by the transformer\nscheme, our network learns long-range dependencies and integrates global\ncontextual information in the feature extraction stage. More importantly, by\nleveraging the self attention of the transformer, the network can naturally\ncarry out simultaneous intra-modality and inter-modality fusion, and robustly\ncapture the latent interactions between RGB and Thermal domains, thereby\nsignificantly improving the performance of multispectral object detection.\nExtensive experiments and ablation studies on multiple datasets demonstrate\nthat our approach is effective and achieves state-of-the-art detection\nperformance. Our code and models will be released soon at\nhttps://github.com/DocF/multispectral-object-detection.",
    "descriptor": "\nComments: 5 pages,3 figures, 4 tables\n",
    "authors": [
      "Fang Qingyun",
      "Han Dapeng",
      "Wang Zhaokui"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00273"
  },
  {
    "id": "arXiv:2111.00316",
    "title": "Real-time Speaker counting in a cocktail party scenario using  Attention-guided Convolutional Neural Network",
    "abstract": "Most current speech technology systems are designed to operate well even in\nthe presence of multiple active speakers. However, most solutions assume that\nthe number of co-current speakers is known. Unfortunately, this information\nmight not always be available in real-world applications. In this study, we\npropose a real-time, single-channel attention-guided Convolutional Neural\nNetwork (CNN) to estimate the number of active speakers in overlapping speech.\nThe proposed system extracts higher-level information from the speech spectral\ncontent using a CNN model. Next, the attention mechanism summarizes the\nextracted information into a compact feature vector without losing critical\ninformation. Finally, the active speakers are classified using a fully\nconnected network. Experiments on simulated overlapping speech using WSJ corpus\nshow that the attention solution is shown to improve the performance by almost\n3% absolute over conventional temporal average pooling. The proposed\nAttention-guided CNN achieves 76.15% for both Weighted Accuracy and average\nRecall, and 75.80% Precision on speech segments as short as 20 frames (i.e.,\n200 ms). All the classification metrics exceed 92% for the attention-guided\nmodel in offline scenarios where the input signal is more than 100 frames long\n(i.e., 1s).",
    "descriptor": "",
    "authors": [
      "Midia Yousefi",
      "John H.L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.00316"
  },
  {
    "id": "arXiv:2111.00320",
    "title": "Speaker conditioning of acoustic models using affine transformation for  multi-speaker speech recognition",
    "abstract": "This study addresses the problem of single-channel Automatic Speech\nRecognition of a target speaker within an overlap speech scenario. In the\nproposed method, the hidden representations in the acoustic model are modulated\nby speaker auxiliary information to recognize only the desired speaker. Affine\ntransformation layers are inserted into the acoustic model network to integrate\nspeaker information with the acoustic features. The speaker conditioning\nprocess allows the acoustic model to perform computation in the context of\ntarget-speaker auxiliary information. The proposed speaker conditioning method\nis a general approach and can be applied to any acoustic model architecture.\nHere, we employ speaker conditioning on a ResNet acoustic model. Experiments on\nthe WSJ corpus show that the proposed speaker conditioning method is an\neffective solution to fuse speaker auxiliary information with acoustic features\nfor multi-speaker speech recognition, achieving +9% and +20% relative WER\nreduction for clean and overlap speech scenarios, respectively, compared to the\noriginal ResNet acoustic model baseline.",
    "descriptor": "",
    "authors": [
      "Midia Yousefi",
      "John H.L. Hanse"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.00320"
  },
  {
    "id": "arXiv:2111.00328",
    "title": "Multi-Task Learning based Convolutional Models with Curriculum Learning  for the Anisotropic Reynolds Stress Tensor in Turbulent Duct Flow",
    "abstract": "The Reynolds-averaged Navier-Stokes (RANS) equations require accurate\nmodeling of the anisotropic Reynolds stress tensor, for which traditional\nclosure models only give good results in certain flow configurations.\nResearchers have started using machine learning approaches to address this\nproblem. In this work we build upon recent convolutional neural network\narchitectures used for turbulence modeling and propose a multi-task learning\nbased fully convolutional neural network that is able to accurately predict the\nnormalized anisotropic Reynolds stress tensor for turbulent duct flow.\nFurthermore, we also explore the application of curriculum learning to\ndata-driven turbulence modeling.",
    "descriptor": "",
    "authors": [
      "Haitz S\u00e1ez de Oc\u00e1riz Borde",
      "David Sondak",
      "Pavlos Protopapas"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00328"
  },
  {
    "id": "arXiv:2111.00361",
    "title": "Functional Neural Networks for Parametric Image Restoration Problems",
    "abstract": "Almost every single image restoration problem has a closely related\nparameter, such as the scale factor in super-resolution, the noise level in\nimage denoising, and the quality factor in JPEG deblocking. Although recent\nstudies on image restoration problems have achieved great success due to the\ndevelopment of deep neural networks, they handle the parameter involved in an\nunsophisticated way. Most previous researchers either treat problems with\ndifferent parameter levels as independent tasks, and train a specific model for\neach parameter level; or simply ignore the parameter, and train a single model\nfor all parameter levels. The two popular approaches have their own\nshortcomings. The former is inefficient in computing and the latter is\nineffective in performance. In this work, we propose a novel system called\nfunctional neural network (FuncNet) to solve a parametric image restoration\nproblem with a single model. Unlike a plain neural network, the smallest\nconceptual element of our FuncNet is no longer a floating-point variable, but a\nfunction of the parameter of the problem. This feature makes it both efficient\nand effective for a parametric problem. We apply FuncNet to super-resolution,\nimage denoising, and JPEG deblocking. The experimental results show the\nsuperiority of our FuncNet on all three parametric image restoration tasks over\nthe state of the arts.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Fangzhou Luo",
      "Xiaolin Wu",
      "Yanhui Guo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00361"
  },
  {
    "id": "arXiv:2111.00390",
    "title": "Dual Attention Network for Heart Rate and Respiratory Rate Estimation",
    "abstract": "Heart rate and respiratory rate measurement is a vital step for diagnosing\nmany diseases. Non-contact camera based physiological measurement is more\naccessible and convenient in Telehealth nowadays than contact instruments such\nas fingertip oximeters since non-contact methods reduce risk of infection.\nHowever, remote physiological signal measurement is challenging due to\nenvironment illumination variations, head motion, facial expression, etc. It's\nalso desirable to have a unified network which could estimate both heart rate\nand respiratory rate to reduce system complexity and latency. We propose a\nconvolutional neural network which leverages spatial attention and channel\nattention, which we call it dual attention network (DAN) to jointly estimate\nheart rate and respiratory rate with camera video as input. Extensive\nexperiments demonstrate that our proposed system significantly improves heart\nrate and respiratory rate measurement accuracy.",
    "descriptor": "",
    "authors": [
      "Yuzhuo Ren",
      "Braeden Syrnyk",
      "Niranjan Avadhanam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.00390"
  },
  {
    "id": "arXiv:2111.00395",
    "title": "A robust single-pixel particle image velocimetry based on fully  convolutional networks with cross-correlation embedded",
    "abstract": "Particle image velocimetry (PIV) is essential in experimental fluid dynamics.\nIn the current work, we propose a new velocity field estimation paradigm, which\nachieves a synergetic combination of the deep learning method and the\ntraditional cross-correlation method. Specifically, the deep learning method is\nused to optimize and correct a coarse velocity guess to achieve a\nsuper-resolution calculation. And the cross-correlation method provides the\ninitial velocity field based on a coarse correlation with a large interrogation\nwindow. As a reference, the coarse velocity guess helps with improving the\nrobustness of the proposed algorithm. This fully convolutional network with\nembedded cross-correlation is named as CC-FCN. CC-FCN has two types of input\nlayers, one is for the particle images, and the other is for the initial\nvelocity field calculated using cross-correlation with a coarse resolution.\nFirstly, two pyramidal modules extract features of particle images and initial\nvelocity field respectively. Then the fusion module appropriately fuses these\nfeatures. Finally, CC-FCN achieves the super-resolution calculation through a\nseries of deconvolution layers to obtain the single-pixel velocity field. As\nthe supervised learning strategy is considered, synthetic data sets including\nground-truth fluid motions are generated to train the network parameters.\nSynthetic and real experimental PIV data sets are used to test the trained\nneural network in terms of accuracy, precision, spatial resolution and\nrobustness. The test results show that these attributes of CC-FCN are further\nimproved compared with those of other tested PIV algorithms. The proposed model\ncould therefore provide competitive and robust estimations for PIV experiments.",
    "descriptor": "",
    "authors": [
      "Qi Gao",
      "Hongtao Lin",
      "Han Tu",
      "Haoran Zhu",
      "Runjie Wei",
      "Guoping Zhang",
      "Xueming Shao"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00395"
  },
  {
    "id": "arXiv:2111.00405",
    "title": "Limitations of the Macaulay matrix approach for using the HHL algorithm  to solve multivariate polynomial systems",
    "abstract": "Recently Chen and Gao~\\cite{ChenGao2017} proposed a new quantum algorithm for\nBoolean polynomial system solving, motivated by the cryptanalysis of some\npost-quantum cryptosystems. The key idea of their approach is to apply a\nQuantum Linear System (QLS) algorithm to a Macaulay linear system over $\\CC$,\nwhich is derived from the Boolean polynomial system. The efficiency of their\nalgorithm depends on the condition number of the Macaulay matrix. In this\npaper, we give a strong lower bound on the condition number as a function of\nthe Hamming weight of the Boolean solution, and show that in many (if not all)\ncases a Grover-based exhaustive search algorithm outperforms their algorithm.\nThen, we improve upon Chen and Gao's algorithm by introducing the Boolean\nMacaulay linear system over $\\CC$ by reducing the original Macaulay linear\nsystem. This improved algorithm could potentially significantly outperform the\nbrute-force algorithm, when the Hamming weight of the solution is logarithmic\nin the number of Boolean variables.\nFurthermore, we provide a simple and more elementary proof of correctness for\nour improved algorithm using a reduction employing the Valiant-Vazirani affine\nhashing method, and also extend the result to polynomial systems over $\\FF_q$\nimproving on subsequent work by Chen, Gao and Yuan \\cite{ChenGao2018}. We also\nsuggest a new approach for extracting the solution of the Boolean polynomial\nsystem via a generalization of the quantum coupon collector problem\n\\cite{arunachalam2020QuantumCouponCollector}.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Jintai Ding",
      "Vlad Gheorghiu",
      "Andr\u00e1s Gily\u00e9n",
      "Sean Hallgren",
      "Jianqiang Li"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.00405"
  },
  {
    "id": "arXiv:2111.00410",
    "title": "Kernel-Based Identification with Frequency Domain Side-Information",
    "abstract": "This paper discusses the problem of system identification when frequency\ndomain side-information is available. Initially, we consider the case where the\nside-information is provided as the $\\mathcal{H}_{\\infty}$-norm of the system\nbeing bounded by a given scalar. This framework allows considering different\nforms of frequency domain side-information, such as the dissipativity of the\nsystem. We propose a nonparametric identification approach for estimating the\nimpulse response of the system under the given side-information. The estimation\nproblem is formulated as a constrained optimization in a stable reproducing\nkernel Hilbert space, where suitable constraints are considered for\nincorporating the desired frequency domain features. The resulting optimization\nhas an infinite-dimensional feasible set with an infinite number of\nconstraints. We show that this problem is a well-defined convex program with a\nunique solution. We propose a heuristic that tightly approximates this unique\nsolution. The proposed approach is equivalent to solving a finite-dimensional\nconvex quadratically constrained quadratic program. The efficiency of the\ndiscussed method is verified by several numerical examples.",
    "descriptor": "",
    "authors": [
      "Mohammad Khosravi",
      "Roy S. Smith"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00410"
  },
  {
    "id": "arXiv:2111.00484",
    "title": "IGCN: Image-to-graph Convolutional Network for 2D/3D Deformable  Registration",
    "abstract": "Organ shape reconstruction based on a single-projection image during\ntreatment has wide clinical scope, e.g., in image-guided radiotherapy and\nsurgical guidance. We propose an image-to-graph convolutional network that\nachieves deformable registration of a 3D organ mesh for a single-viewpoint 2D\nprojection image. This framework enables simultaneous training of two types of\ntransformation: from the 2D projection image to a displacement map, and from\nthe sampled per-vertex feature to a 3D displacement that satisfies the\ngeometrical constraint of the mesh structure. Assuming application to radiation\ntherapy, the 2D/3D deformable registration performance is verified for multiple\nabdominal organs that have not been targeted to date, i.e., the liver, stomach,\nduodenum, and kidney, and for pancreatic cancer. The experimental results show\nshape prediction considering relationships among multiple organs can be used to\npredict respiratory motion and deformation from digitally reconstructed\nradiographs with clinically acceptable accuracy.",
    "descriptor": "",
    "authors": [
      "Megumi Nakao",
      "Mitsuhiro Nakamura",
      "Tetsuya Matsuda"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00484"
  },
  {
    "id": "arXiv:2111.00510",
    "title": "Vertex Lattice Models Simulated with Quantum Circuits",
    "abstract": "Classical planar vertex models afford transfer matrices with real and\npositive entries, which makes this class of models suitable for quantum\nsimulations. In this work, we support this statement by building explicit\nquantum circuits that implement the actions of the transfer matrices on\narbitrary many-qubit states. The number of qubits and the depth of the circuits\ngrow linearly with the size of the system. Furthermore, we present tests using\nquantum simulators and demonstrate that important physical quantities can be\nextracted, such as the eigen-vector corresponding to the largest eigenvalue of\nthe transfer matrix and the ratio of the second to first largest eigenvalue.\nChallenges steaming from the non-unitarity of the transfer matrix are\ndiscussed.",
    "descriptor": "",
    "authors": [
      "Jechiel Van Dijk",
      "Emil Prodan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.00510"
  },
  {
    "id": "arXiv:2111.00516",
    "title": "G\u00e1cs-Ku\u010dera's Theorem Revisited by Levin",
    "abstract": "Leonid Levin (arxiv.org/abs/cs/0503039v14, p.7) published a new (and very\nnice) proof of G\\'acs-Ku\\v{c}era's theorem that occupies only a few lines when\npresented in his style. We try to explain more details and discuss the\nconnection of this proof with image randomness theorems, making explicit some\nresult (see Proposition 4) that is implicit in Levin's exposition.",
    "descriptor": "",
    "authors": [
      "Alexander Shen"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00516"
  },
  {
    "id": "arXiv:2111.00528",
    "title": "Calibrating the Dice loss to handle neural network overconfidence for  biomedical image segmentation",
    "abstract": "The Dice similarity coefficient (DSC) is both a widely used metric and loss\nfunction for biomedical image segmentation due to its robustness to class\nimbalance. However, it is well known that the DSC loss is poorly calibrated,\nresulting in overconfident predictions that cannot be usefully interpreted in\nbiomedical and clinical practice. Performance is often the only metric used to\nevaluate segmentations produced by deep neural networks, and calibration is\noften neglected. However, calibration is important for translation into\nbiomedical and clinical practice, providing crucial contextual information to\nmodel predictions for interpretation by scientists and clinicians. In this\nstudy, we identify poor calibration as an emerging challenge of deep learning\nbased biomedical image segmentation. We provide a simple yet effective\nextension of the DSC loss, named the DSC++ loss, that selectively modulates the\npenalty associated with overconfident, incorrect predictions. As a standalone\nloss function, the DSC++ loss achieves significantly improved calibration over\nthe conventional DSC loss across five well-validated open-source biomedical\nimaging datasets. Similarly, we observe significantly improved when integrating\nthe DSC++ loss into four DSC-based loss functions. Finally, we use softmax\nthresholding to illustrate that well calibrated outputs enable tailoring of\nprecision-recall bias, an important post-processing technique to adapt the\nmodel predictions to suit the biomedical or clinical task. The DSC++ loss\novercomes the major limitation of the DSC, providing a suitable loss function\nfor training deep learning segmentation models for use in biomedical and\nclinical practice.",
    "descriptor": "",
    "authors": [
      "Michael Yeung",
      "Leonardo Rundo",
      "Yang Nan",
      "Evis Sala",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00528"
  },
  {
    "id": "arXiv:2111.00533",
    "title": "Incorporating Boundary Uncertainty into loss functions for biomedical  image segmentation",
    "abstract": "Manual segmentation is used as the gold-standard for evaluating neural\nnetworks on automated image segmentation tasks. Due to considerable\nheterogeneity in shapes, colours and textures, demarcating object boundaries is\nparticularly difficult in biomedical images, resulting in significant inter and\nintra-rater variability. Approaches, such as soft labelling and distance\npenalty term, apply a global transformation to the ground truth, redefining the\nloss function with respect to uncertainty. However, global operations are\ncomputationally expensive, and neither approach accurately reflects the\nuncertainty underlying manual annotation. In this paper, we propose the\nBoundary Uncertainty, which uses morphological operations to restrict soft\nlabelling to object boundaries, providing an appropriate representation of\nuncertainty in ground truth labels, and may be adapted to enable robust model\ntraining where systematic manual segmentation errors are present. We\nincorporate Boundary Uncertainty with the Dice loss, achieving consistently\nimproved performance across three well-validated biomedical imaging datasets\ncompared to soft labelling and distance-weighted penalty. Boundary Uncertainty\nnot only more accurately reflects the segmentation process, but it is also\nefficient, robust to segmentation errors and exhibits better generalisation.",
    "descriptor": "",
    "authors": [
      "Michael Yeung",
      "Guang Yang",
      "Evis Sala",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Leonardo Rundo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00533"
  },
  {
    "id": "arXiv:2111.00534",
    "title": "Focal Attention Networks: optimising attention for biomedical image  segmentation",
    "abstract": "In recent years, there has been increasing interest to incorporate attention\ninto deep learning architectures for biomedical image segmentation. The modular\ndesign of attention mechanisms enables flexible integration into convolutional\nneural network architectures, such as the U-Net. Whether attention is\nappropriate to use, what type of attention to use, and where in the network to\nincorporate attention modules, are all important considerations that are\ncurrently overlooked. In this paper, we investigate the role of the Focal\nparameter in modulating attention, revealing a link between attention in loss\nfunctions and networks. By incorporating a Focal distance penalty term, we\nextend the Unified Focal loss framework to include boundary-based losses.\nFurthermore, we develop a simple and interpretable, dataset and model-specific\nheuristic to integrate the Focal parameter into the Squeeze-and-Excitation\nblock and Attention Gate, achieving optimal performance with fewer number of\nattention modules on three well-validated biomedical imaging datasets,\nsuggesting judicious use of attention modules results in better performance and\nefficiency.",
    "descriptor": "",
    "authors": [
      "Michael Yeung",
      "Leonardo Rundo",
      "Evis Sala",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00534"
  },
  {
    "id": "arXiv:2111.00551",
    "title": "Learning to Detect Open Carry and Concealed Object with 77GHz Radar",
    "abstract": "Detecting harmful carried objects plays a key role in intelligent\nsurveillance systems and has widespread applications, for example, in airport\nsecurity. In this paper, we focus on the relatively unexplored area of using\nlow-cost 77GHz mmWave radar for the carried objects detection problem. The\nproposed system is capable of real-time detecting three classes of objects -\nlaptop, phone, and knife - under open carry and concealed cases where objects\nare hidden with clothes or bags. This capability is achieved by initial signal\nprocessing for localization and generating range-azimuth-elevation image cubes,\nfollowed by a deep learning-based prediction network and a multi-shot\npost-processing module for detecting objects. Extensive experiments for\nvalidating the system performance on detecting open carry and concealed objects\nhave been presented with a self-built radar-camera testbed and dataset.\nAdditionally, the influence of different input, factors, and parameters on\nsystem performance is analyzed, providing an intuitive understanding of the\nsystem. This system would be the very first baseline for other future works\naiming to detect carried objects using 77GHz radar.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Xiangyu Gao",
      "Hui Liu",
      "Sumit Roy",
      "Guanbin Xing",
      "Ali Alansari",
      "Youchen Luo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00551"
  },
  {
    "id": "arXiv:2111.00557",
    "title": "On The Absolute Constant in Hanson-Wright Inequality",
    "abstract": "We revisit and slightly modify the proof of the Gaussian Hanson-Wright\ninequality where we keep track of the absolute constant in its formulation.",
    "descriptor": "",
    "authors": [
      "Kamyar Moshksar"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00557"
  },
  {
    "id": "arXiv:2111.00590",
    "title": "Laplacian Constrained Precision Matrix Estimation: Existence and High  Dimensional Consistency",
    "abstract": "This paper considers the problem of estimating high dimensional Laplacian\nconstrained precision matrices by minimizing Stein's loss. We obtain a\nnecessary and sufficient condition for existence of this estimator, that boils\ndown to checking whether a certain data dependent graph is connected. We also\nprove consistency in the high dimensional setting under the symmetryzed Stein\nloss. We show that the error rate does not depend on the graph sparsity, or\nother type of structure, and that Laplacian constraints are sufficient for high\ndimensional consistency. Our proofs exploit properties of graph Laplacians, and\na characterization of the proposed estimator based on effective graph\nresistances. We validate our theoretical claims with numerical experiments.",
    "descriptor": "",
    "authors": [
      "Eduardo Pavez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.00590"
  },
  {
    "id": "arXiv:2111.00595",
    "title": "TorchXRayVision: A library of chest X-ray datasets and models",
    "abstract": "TorchXRayVision is an open source software library for working with chest\nX-ray datasets and deep learning models. It provides a common interface and\ncommon pre-processing chain for a wide set of publicly available chest X-ray\ndatasets. In addition, a number of classification and representation learning\nmodels with different architectures, trained on different data combinations,\nare available through the library to serve as baselines or feature extractors.",
    "descriptor": "\nComments: Library source code: this https URL\n",
    "authors": [
      "Joseph Paul Cohen",
      "Joseph D. Viviano",
      "Paul Bertin",
      "Paul Morrison",
      "Parsa Torabian",
      "Matteo Guarrera",
      "Matthew P Lungren",
      "Akshay Chaudhari",
      "Rupert Brooks",
      "Mohammad Hashir",
      "Hadrien Bertrand"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00595"
  },
  {
    "id": "arXiv:2111.00597",
    "title": "Reduced Order Model Predictive Control for Parametrized Parabolic  Partial Differential Equations",
    "abstract": "Model Predictive Control (MPC) is a well-established approach to solve\ninfinite horizon optimal control problems. Since optimization over an infinite\ntime horizon is generally infeasible, MPC determines a suboptimal feedback\ncontrol by repeatedly solving finite time optimal control problems. Although\nMPC has been successfully used in many applications, applying MPC to\nlarge-scale systems -- arising, e.g., through discretization of partial\ndifferential equations -- requires the solution of high-dimensional optimal\ncontrol problems and thus poses immense computational effort.\nWe consider systems governed by parametrized parabolic partial differential\nequations and employ the reduced basis (RB) method as a low-dimensional\nsurrogate model for the finite time optimal control problem. The reduced order\noptimal control serves as feedback control for the original large-scale system.\nWe analyze the proposed RB-MPC approach by first developing a posteriori error\nbounds for the errors in the optimal control and associated cost functional.\nThese bounds can be evaluated efficiently in an offline-online computational\nprocedure and allow us to guarantee asymptotic stability of the closed-loop\nsystem using the RB-MPC approach. We also propose an adaptive strategy to\nchoose the prediction horizon of the finite time optimal control problem.\nNumerical results are presented to illustrate the theoretical properties of our\napproach.",
    "descriptor": "",
    "authors": [
      "Saskia Dietze",
      "Martin A. Grepl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00597"
  },
  {
    "id": "arXiv:2111.00639",
    "title": "End-to-End Learning of Deep Kernel Acquisition Functions for Bayesian  Optimization",
    "abstract": "For Bayesian optimization (BO) on high-dimensional data with complex\nstructure, neural network-based kernels for Gaussian processes (GPs) have been\nused to learn flexible surrogate functions by the high representation power of\ndeep learning. However, existing methods train neural networks by maximizing\nthe marginal likelihood, which do not directly improve the BO performance. In\nthis paper, we propose a meta-learning method for BO with neural network-based\nkernels that minimizes the expected gap between the true optimum value and the\nbest value found by BO. We model a policy, which takes the current evaluated\ndata points as input and outputs the next data point to be evaluated, by a\nneural network, where neural network-based kernels, GPs, and mutual\ninformation-based acquisition functions are used as its layers. With our model,\nthe neural network-based kernel is trained to be appropriate for the\nacquisition function by backpropagating the gap through the acquisition\nfunction and GP. Our model is trained by a reinforcement learning framework\nfrom multiple tasks. Since the neural network is shared across different tasks,\nwe can gather knowledge on BO from multiple training tasks, and use the\nknowledge for unseen test tasks. In experiments using three text document\ndatasets, we demonstrate that the proposed method achieves better BO\nperformance than the existing methods.",
    "descriptor": "",
    "authors": [
      "Tomoharu Iwata"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00639"
  },
  {
    "id": "arXiv:2111.00666",
    "title": "Self-Verification in Image Denoising",
    "abstract": "We devise a new regularization, called self-verification, for image\ndenoising. This regularization is formulated using a deep image prior learned\nby the network, rather than a traditional predefined prior. Specifically, we\ntreat the output of the network as a ``prior'' that we denoise again after\n``re-noising''. The comparison between the again denoised image and its prior\ncan be interpreted as a self-verification of the network's denoising ability.\nWe demonstrate that self-verification encourages the network to capture\nlow-level image statistics needed to restore the image. Based on this\nself-verification regularization, we further show that the network can learn to\ndenoise even if it has not seen any clean images. This learning strategy is\nself-supervised, and we refer to it as Self-Verification Image Denoising\n(SVID). SVID can be seen as a mixture of learning-based methods and traditional\nmodel-based denoising methods, in which regularization is adaptively formulated\nusing the output of the network. We show the application of SVID to various\ndenoising tasks using only observed corrupted data. It can achieve the\ndenoising performance close to supervised CNNs.",
    "descriptor": "",
    "authors": [
      "Huangxing Lin",
      "Yihong Zhuang",
      "Delu Zeng",
      "Yue Huang",
      "Xinghao Ding",
      "John Paisley"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00666"
  },
  {
    "id": "arXiv:2111.00698",
    "title": "Influential Prototypical Networks for Few Shot Learning: A  Dermatological Case Study",
    "abstract": "Prototypical network (PN) is a simple yet effective few shot learning\nstrategy. It is a metric-based meta-learning technique where classification is\nperformed by computing Euclidean distances to prototypical representations of\neach class. Conventional PN attributes equal importance to all samples and\ngenerates prototypes by simply averaging the support sample embeddings\nbelonging to each class. In this work, we propose a novel version of PN that\nattributes weights to support samples corresponding to their influence on the\nsupport sample distribution. Influence weights of samples are calculated based\non maximum mean discrepancy (MMD) between the mean embeddings of sample\ndistributions including and excluding the sample. Comprehensive evaluation of\nour proposed influential PN (IPNet) is performed by comparing its performance\nwith other baseline PNs on three different benchmark dermatological datasets.\nIPNet outperforms all baseline models with compelling results across all three\ndatasets and various N-way, K-shot classification tasks. Findings from\ncross-domain adaptation experiments further establish the robustness and\ngeneralizability of IPNet.",
    "descriptor": "",
    "authors": [
      "Ranjana Roy Chowdhury",
      "Deepti R. Bathula"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00698"
  },
  {
    "id": "arXiv:2111.00740",
    "title": "Learning linear non-Gaussian directed acyclic graph with diverging  number of nodes",
    "abstract": "Acyclic model, often depicted as a directed acyclic graph (DAG), has been\nwidely employed to represent directional causal relations among collected\nnodes. In this article, we propose an efficient method to learn linear\nnon-Gaussian DAG in high dimensional cases, where the noises can be of any\ncontinuous non-Gaussian distribution. This is in sharp contrast to most\nexisting DAG learning methods assuming Gaussian noise with additional variance\nassumptions to attain exact DAG recovery. The proposed method leverages a novel\nconcept of topological layer to facilitate the DAG learning. Particularly, we\nshow that the topological layers can be exactly reconstructed in a bottom-up\nfashion, and the parent-child relations among nodes in each layer can also be\nconsistently established. More importantly, the proposed method does not\nrequire the faithfulness or parental faithfulness assumption which has been\nwidely assumed in the literature of DAG learning. Its advantage is also\nsupported by the numerical comparison against some popular competitors in\nvarious simulated examples as well as a real application on the global spread\nof COVID-19.",
    "descriptor": "",
    "authors": [
      "Ruixuan Zhao",
      "Xin He",
      "Junhui Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00740"
  },
  {
    "id": "arXiv:2111.00742",
    "title": "Redundancy Reduction in Semantic Segmentation of 3D Brain Tumor MRIs",
    "abstract": "Another year of the multimodal brain tumor segmentation challenge (BraTS)\n2021 provides an even larger dataset to facilitate collaboration and research\nof brain tumor segmentation methods, which are necessary for disease analysis\nand treatment planning. A large dataset size of BraTS 2021 and the advent of\nmodern GPUs provide a better opportunity for deep-learning based approaches to\nlearn tumor representation from the data. In this work, we maintained an\nencoder-decoder based segmentation network, but focused on a modification of\nnetwork training process that minimizes redundancy under perturbations. Given a\nset trained networks, we further introduce a confidence based ensembling\ntechniques to further improve the performance. We evaluated the method on BraTS\n2021 validation board, and achieved 0.8600, 0.8868 and 0.9265 average dice for\nenhanced tumor core, tumor core and whole tumor, respectively. Our team\n(NVAUTO) submission was the top performing in terms of ET and TC scores and\nwithin top 10 performing teams in terms of WT scores.",
    "descriptor": "\nComments: BraTS 2021, BrainLes, MICCAI 2021\n",
    "authors": [
      "Md Mahfuzur Rahman Siddiquee",
      "Andriy Myronenko"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00742"
  },
  {
    "id": "arXiv:2111.00745",
    "title": "Uncertainty quantification for ptychography using normalizing flows",
    "abstract": "Ptychography, as an essential tool for high-resolution and nondestructive\nmaterial characterization, presents a challenging large-scale nonlinear and\nnon-convex inverse problem; however, its intrinsic photon statistics create\nclear opportunities for statistical-based deep learning approaches to tackle\nthese challenges, which has been underexplored. In this work, we explore\nnormalizing flows to obtain a surrogate for the high-dimensional posterior,\nwhich also enables the characterization of the uncertainty associated with the\nreconstruction: an extremely desirable capability when judging the\nreconstruction quality in the absence of ground truth, spotting spurious\nartifacts and guiding future experiments using the returned uncertainty\npatterns. We demonstrate the performance of the proposed method on a synthetic\nsample with added noise and in various physical experimental settings.",
    "descriptor": "\nComments: Accepted at the Fourth Workshop on Machine Learning for Physical Sciences, NeurIPS 2021\n",
    "authors": [
      "Agnimitra Dasgupta",
      "Zichao Wendy Di"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00745"
  },
  {
    "id": "arXiv:2111.00764",
    "title": "SNRi Target Training for Joint Speech Enhancement and Recognition",
    "abstract": "This study aims to improve the performance of automatic speech recognition\n(ASR) under noisy conditions. The use of a speech enhancement (SE) frontend has\nbeen widely studied for noise robust ASR. However, most single-channel SE\nmodels introduce processing artifacts in the enhanced speech resulting in\ndegraded ASR performance. To overcome this problem, we propose Signal-to-Noise\nRatio improvement (SNRi) target training; the SE frontend automatically\ncontrols its noise reduction level to avoid degrading the ASR performance due\nto artifacts. The SE frontend uses an auxiliary scalar input which represents\nthe target SNRi of the output signal. The target SNRi value is estimated by the\nSNRi prediction network, which is trained to minimize the ASR loss. Experiments\nusing 55,027 hours of noisy speech training data show that SNRi target training\nenables control of the SNRi of the output signal, and the joint training\nreduces word error rate by 12% compared to a state-of-the-art Conformer-based\nASR model.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Yuma Koizumi",
      "Shigeki Karita",
      "Arun Narayanan",
      "Sankaran Panchapagesan",
      "Michiel Bacchiani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.00764"
  },
  {
    "id": "arXiv:2111.00777",
    "title": "Geometric Control for Load Transportation with Quadrotor UAVs by Elastic  Cables",
    "abstract": "Groups of unmanned aerial vehicles (UAVs) are increasingly utilized in\ntransportation task as the combined strength allows to increase the maximum\npayload. However, the resulting mechanical coupling of the UAVs impose new\nchallenges in terms of the tracking control. Thus, we design a geometric\ntrajectory tracking controller for the cooperative task of four quadrotor UAVs\ncarrying and transporting a rigid body, which is attached to the quadrotors via\ninflexible elastic cables. The elasticity of the cables together with\ntechniques of singular perturbation allows a reduction in the model to that of\na similar model with inelastic cables. In this reduced model, we design a\ncontroller such that the position and attitude of the load exponentially\nconverges to a given desired trajectory. We then show that this result leads to\nan uniformly converging tracking error for the original elastic model under\nsome assumptions. Furthermore, under the presence of unstructured disturbances\non the system, we show that the error is ultimately bounded with an arbitrarily\nsmall bound. Finally, a simulation illustrates the theoretical results.",
    "descriptor": "\nComments: 14 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2104.06155\n",
    "authors": [
      "Jacob R. Goodman",
      "Juan S. Cely",
      "Thomas Beckers",
      "Leonardo J. Colombo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00777"
  },
  {
    "id": "arXiv:2111.00790",
    "title": "Dynamic Pricing and Demand Learning on a Large Network of Products: A  PAC-Bayesian Approach",
    "abstract": "We consider a seller offering a large network of $N$ products over a time\nhorizon of $T$ periods. The seller does not know the parameters of the\nproducts' linear demand model, and can dynamically adjust product prices to\nlearn the demand model based on sales observations. The seller aims to minimize\nits pseudo-regret, i.e., the expected revenue loss relative to a clairvoyant\nwho knows the underlying demand model. We consider a sparse set of demand\nrelationships between products to characterize various connectivity properties\nof the product network. In particular, we study three different sparsity\nframeworks: (1) $L_0$ sparsity, which constrains the number of connections in\nthe network, and (2) off-diagonal sparsity, which constrains the magnitude of\ncross-product price sensitivities, and (3) a new notion of spectral sparsity,\nwhich constrains the asymptotic decay of a similarity metric on network nodes.\nWe propose a dynamic pricing-and-learning policy that combines the\noptimism-in-the-face-of-uncertainty and PAC-Bayesian approaches, and show that\nthis policy achieves asymptotically optimal performance in terms of $N$ and\n$T$. We also show that in the case of spectral and off-diagonal sparsity, the\nseller can have a pseudo-regret linear in $N$, even when the network is dense.",
    "descriptor": "",
    "authors": [
      "Bora Keskin",
      "David Simchi-Levi",
      "Prem Talwai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00790"
  },
  {
    "id": "arXiv:2111.00812",
    "title": "Topology identification of autonomous quantum dynamical networks",
    "abstract": "Topology identification comprises reconstructing the interaction Hamiltonian\nof a quantum network by properly processing measurements of its density\noperator within a fixed time interval. It finds application in several quantum\ntechnology contexts, ranging from quantum communication to quantum computing or\nsensing. In this paper, we provide analytical conditions for the solvability of\nthe topology identification problem of autonomous quantum dynamical networks.\nThe analytical results are then converted in an algorithm for quantum network\nreconstruction that is able to efficiently determine the topology of\nlarge-scale networks and is easily implementable on standard computer\nfacilities. The obtained algorithm is tested on numerical examples based on the\nquantum walks formalism.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Stefano Gherardini",
      "Henk J. van Waarde",
      "Pietro Tesi",
      "Filippo Caruso"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00812"
  },
  {
    "id": "arXiv:2111.00833",
    "title": "Swift sky localization of gravitational waves using deep learning seeded  importance sampling",
    "abstract": "Fast, highly accurate, and reliable inference of the sky origin of\ngravitational waves would enable real-time multi-messenger astronomy. Current\nBayesian inference methodologies, although highly accurate and reliable, are\nslow. Deep learning models have shown themselves to be accurate and extremely\nfast for inference tasks on gravitational waves, but their output is inherently\nquestionable due to the blackbox nature of neural networks. In this work, we\njoin Bayesian inference and deep learning by applying importance sampling on an\napproximate posterior generated by a multi-headed convolutional neural network.\nThe neural network parametrizes Von Mises-Fisher and Gaussian distributions for\nthe sky coordinates and two masses for given simulated gravitational wave\ninjections in the LIGO and Virgo detectors. We generate skymaps for unseen\ngravitational-wave events that highly resemble predictions generated using\nBayesian inference in a few minutes. Furthermore, we can detect poor\npredictions from the neural network, and quickly flag them.",
    "descriptor": "\nComments: 12 pages, 9 figures, 1 table\n",
    "authors": [
      "Alex Kolmus",
      "Gr\u00e9gory Baltus",
      "Justin Janquart",
      "Twan van Laarhoven",
      "Sarah Caudill",
      "Tom Heskes"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00833"
  },
  {
    "id": "arXiv:2111.00837",
    "title": "Simulating Realistic MRI variations to Improve Deep Learning model and  visual explanations using GradCAM",
    "abstract": "In the medical field, landmark detection in MRI plays an important role in\nreducing medical technician efforts in tasks like scan planning, image\nregistration, etc. First, 88 landmarks spread across the brain anatomy in the\nthree respective views -- sagittal, coronal, and axial are manually annotated,\nlater guidelines from the expert clinical technicians are taken\nsub-anatomy-wise, for better localization of the existing landmarks, in order\nto identify and locate the important atlas landmarks even in oblique scans. To\novercome limited data availability, we implement realistic data augmentation to\ngenerate synthetic 3D volumetric data. We use a modified HighRes3DNet model for\nsolving brain MRI volumetric landmark detection problem. In order to visually\nexplain our trained model on unseen data, and discern a stronger model from a\nweaker model, we implement Gradient-weighted Class Activation Mapping\n(Grad-CAM) which produces a coarse localization map highlighting the regions\nthe model is focusing. Our experiments show that the proposed method shows\nfavorable results, and the overall pipeline can be extended to a variable\nnumber of landmarks and other anatomies.",
    "descriptor": "\nComments: 8 pages, 9 figures, IEEE-CCEM 2021 conference\n",
    "authors": [
      "Muhammad Ilyas Patel",
      "Shrey Singla",
      "Razeem Ahmad Ali Mattathodi",
      "Sumit Sharma",
      "Deepam Gautam",
      "Srinivasa Rao Kundeti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00837"
  },
  {
    "id": "arXiv:2111.00841",
    "title": "Free Probability, Newton lilypads and Jacobians of neural networks",
    "abstract": "Gradient descent during the learning process of a neural network can be\nsubject to many instabilities. The spectral density of the Jacobian is a key\ncomponent for analyzing robustness. Following the works of Pennington et al.,\nsuch Jacobians are modeled using free multiplicative convolutions from Free\nProbability Theory. We present a reliable and very fast method for computing\nthe associated spectral densities. This method has a controlled and proven\nconvergence.\nOur technique is based on an adaptative Newton-Raphson scheme, by finding and\nchaining basins of attraction: the Newton algorithm finds contiguous\nlilypad-like basins and steps from one to the next, heading towards the\nobjective.\nWe demonstrate the applicability of our method by using it to assess how the\nlearning process is affected by network depth, layer widths and initialization\nchoices: empirically, final test losses are very correlated to our Free\nProbability metrics.",
    "descriptor": "\nComments: 22 pages, 4 figures\n",
    "authors": [
      "Reda Chhaibi",
      "Tariq Daouda",
      "Ezechiel Kahn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.00841"
  },
  {
    "id": "arXiv:2111.00863",
    "title": "Finite and infinite closed-rich words",
    "abstract": "A word is called closed if it has a prefix which is also its suffix and there\nis no internal occurrences of this prefix in the word. In this paper we study\nwords that are rich in closed factors, i.e., which contain the maximal possible\nnumber of distinct closed factors. As the main result, we show that for finite\nwords the asymptotics of the maximal number of distinct closed factors in a\nword of length $n$ is $\\frac{n^2}{6}$. For infinite words, we show there exist\nwords such that each their factor of length $n$ contains a quadratic number of\ndistinct closed factors, with uniformly bounded constant; we call such words\ninfinite closed-rich. We provide several necessary and some sufficient\nconditions for a word to be infinite closed rich. For example, we show that all\nlinearly recurrent words are closed-rich. We provide a characterization of rich\nwords among Sturmian words. Certain examples we provide involve\nnon-constructive methods.",
    "descriptor": "",
    "authors": [
      "Olga Parshina",
      "Svetlana Puzynina"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.00863"
  },
  {
    "id": "arXiv:2111.00916",
    "title": "A multi-task learning-based optimization approach for finding diverse  sets of material microstructures with desired properties and its application  to texture optimization",
    "abstract": "The optimization along the chain processing-structure-properties-performance\nis one of the core objectives in data-driven materials science. In this sense,\nprocesses are supposed to manufacture workpieces with targeted material\nmicrostructures. These microstructures are defined by the material properties\nof interest and identifying them is a question of materials design. In the\npresent paper, we addresse this issue and introduce a generic multi-task\nlearning-based optimization approach. The approach enables the identification\nof sets of highly diverse microstructures for given desired properties and\ncorresponding tolerances. Basically, the approach consists of an optimization\nalgorithm that interacts with a machine learning model that combines multi-task\nlearning with siamese neural networks. The resulting model (1) relates\nmicrostructures and properties, (2) estimates the likelihood of a\nmicrostructure of being producible, and (3) performs a distance preserving\nmicrostructure feature extraction in order to generate a lower dimensional\nlatent feature space to enable efficient optimization. The proposed approach is\napplied on a crystallographic texture optimization problem for rolled steel\nsheets given desired properties.",
    "descriptor": "",
    "authors": [
      "Tarek Iraki",
      "Lukas Morand",
      "Johannes Dornheim",
      "Norbert Link",
      "Dirk Helm"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00916"
  },
  {
    "id": "arXiv:2111.00924",
    "title": "PCA-based Multi Task Learning: a Random Matrix Approach",
    "abstract": "The article proposes and theoretically analyses a \\emph{computationally\nefficient} multi-task learning (MTL) extension of popular principal component\nanalysis (PCA)-based supervised learning schemes\n\\cite{barshan2011supervised,bair2006prediction}. The analysis reveals that (i)\nby default learning may dramatically fail by suffering from \\emph{negative\ntransfer}, but that (ii) simple counter-measures on data labels avert negative\ntransfer and necessarily result in improved performances.\nSupporting experiments on synthetic and real data benchmarks show that the\nproposed method achieves comparable performance with state-of-the-art MTL\nmethods but at a \\emph{significantly reduced computational cost}.",
    "descriptor": "",
    "authors": [
      "Malik Tiomoko",
      "Romain Couillet",
      "Fr\u00e9d\u00e9ric Pascal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.00924"
  },
  {
    "id": "arXiv:2111.00939",
    "title": "IRA: A shape matching approach for recognition and comparison of generic  atomic patterns",
    "abstract": "We propose a versatile, parameter-less approach for solving the shape\nmatching problem, specifically in the context of atomic structures when atomic\nassignments are not known a priori. The algorithm Iteratively suggests Rotated\natom-centered reference frames and Assignments (Iterative Rotations and\nAssignments, IRA). The frame for which a permutationally invariant set-set\ndistance, namely the Hausdorff distance, returns minimal value is chosen as the\nsolution of the matching problem. IRA is able to find rigid rotations,\nreflections, translations, and permutations between structures with different\nnumbers of atoms, for any atomic arrangement and pattern, periodic or not. When\ndistortions are present between the structures, optimal rotation and\ntranslation are found by further applying a standard Singular Value\nDecomposition-based method. To compute the atomic assignments under the\none-to-one assignment constraint, we develop our own algorithm, Constrained\nShortest Distance Assignments (CShDA). The overall approach is extensively\ntested on several structures, including distorted structural fragments.\nEfficiency of the proposed algorithm is shown as a benchmark comparison against\ntwo other shape matching algorithms. We discuss the use of our approach for the\nidentification and comparison of structures and structural fragments through\ntwo examples: a replica exchange trajectory of a cyanine molecule, in which we\nshow how our approach could aid the exploration of relevant collective\ncoordinates for clustering the data; and an SiO$_2$ amorphous model, in which\nwe compute distortion scores and compare them with a classical strain-based\npotential. The source code and benchmark data are available at\n\\url{https://github.com/mammasmias/IterativeRotationsAssignments}.",
    "descriptor": "\nComments: 18 pages, 19 figures\n",
    "authors": [
      "Miha Gunde",
      "Nicolas Salles",
      "Anne H\u00e9meryck",
      "Layla Martin-Samos"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00939"
  },
  {
    "id": "arXiv:2111.00961",
    "title": "Robustness of deep learning algorithms in astronomy -- galaxy morphology  studies",
    "abstract": "Deep learning models are being increasingly adopted in wide array of\nscientific domains, especially to handle high-dimensionality and volume of the\nscientific data. However, these models tend to be brittle due to their\ncomplexity and overparametrization, especially to the inadvertent adversarial\nperturbations that can appear due to common image processing such as\ncompression or blurring that are often seen with real scientific data. It is\ncrucial to understand this brittleness and develop models robust to these\nadversarial perturbations. To this end, we study the effect of observational\nnoise from the exposure time, as well as the worst case scenario of a one-pixel\nattack as a proxy for compression or telescope errors on performance of\nResNet18 trained to distinguish between galaxies of different morphologies in\nLSST mock data. We also explore how domain adaptation techniques can help\nimprove model robustness in case of this type of naturally occurring attacks\nand help scientists build more trustworthy and stable models.",
    "descriptor": "\nComments: Accepted in: Fourth Workshop on Machine Learning and the Physical Sciences (35th Conference on Neural Information Processing Systems; NeurIPS2021); final version\n",
    "authors": [
      "A. \u0106iprijanovi\u0107",
      "D. Kafkes",
      "G. N. Perdue",
      "K. Pedro",
      "G. Snyder",
      "F. J. S\u00e1nchez",
      "S. Madireddy",
      "S. Wild",
      "B. Nord"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00961"
  },
  {
    "id": "arXiv:2111.00979",
    "title": "Properties of Parabola-Inscribed Poncelet Polygons",
    "abstract": "We investigate properties of Poncelet $N$-gon families inscribed in a\nparabola and circumscribing a focus-centered circle. These can be regarded as\nthe polar images of a bicentric family with respect to the circumcircle, such\nthat the bicentric incircle contains the circumcenter. We derive closure\nconditions for several $N$ and describe curious Euclidean properties such as\nstraight line, circular, and point, loci, as well as a (perhaps new) conserved\nquantity.",
    "descriptor": "\nComments: 20 pages, 17 figures\n",
    "authors": [
      "Filipe Bellio",
      "Ronaldo Garcia",
      "Dan Reznik"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.00979"
  },
  {
    "id": "arXiv:2111.00987",
    "title": "Modelling the transition to a low-carbon energy supply",
    "abstract": "A transition to a low-carbon electricity supply is crucial to limit the\nimpacts of climate change. Reducing carbon emissions could help prevent the\nworld from reaching a tipping point, where runaway emissions are likely.\nRunaway emissions could lead to extremes in weather conditions around the world\n-- especially in problematic regions unable to cope with these conditions.\nHowever, the movement to a low-carbon energy supply can not happen\ninstantaneously due to the existing fossil-fuel infrastructure and the\nrequirement to maintain a reliable energy supply. Therefore, a low-carbon\ntransition is required, however, the decisions various stakeholders should make\nover the coming decades to reduce these carbon emissions are not obvious. This\nis due to many long-term uncertainties, such as electricity, fuel and\ngeneration costs, human behaviour and the size of electricity demand. A well\nchoreographed low-carbon transition is, therefore, required between all of the\nheterogenous actors in the system, as opposed to changing the behaviour of a\nsingle, centralised actor. The objective of this thesis is to create a novel,\nopen-source agent-based model to better understand the manner in which the\nwhole electricity market reacts to different factors using state-of-the-art\nmachine learning and artificial intelligence methods. In contrast to other\nworks, this thesis looks at both the long-term and short-term impact that\ndifferent behaviours have on the electricity market by using these\nstate-of-the-art methods.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Alexander Kell"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.00987"
  },
  {
    "id": "arXiv:2111.00991",
    "title": "Computing input-output projections of dynamical models with applications  to structural identifiability",
    "abstract": "Elimination of unknowns in a system of differential equations is often\nrequired when analysing (possibly nonlinear) dynamical systems models, where\nonly a subset of variables are observable. One such analysis, identifiability,\noften relies on computing input-output relations via differential algebraic\nelimination. Determining identifiability, a natural prerequisite for meaningful\nparameter estimation, is often prohibitively expensive for medium to large\nsystems due to the computationally expensive task of elimination.\nWe propose an algorithm that computes a description of the set of\ndifferential-algebraic relations between the input and output variables of a\ndynamical system model. The resulting algorithm outperforms general-purpose\nsoftware for differential elimination on a set of benchmark models from\nliterature.\nWe use the designed elimination algorithm to build a new randomized algorithm\nfor assessing structural identifiability of a parameter in a parametric model.\nA parameter is said to be identifiable if its value can be uniquely determined\nfrom input-output data assuming the absence of noise and sufficiently exciting\ninputs. Our new algorithm allows the identification of models that could not be\ntackled before.\nOur implementation is publicly available as a Julia package at\nhttps://github.com/SciML/StructuralIdentifiability.jl.",
    "descriptor": "",
    "authors": [
      "Ruiwen Dong",
      "Christian Goodbrake",
      "Heather A Harrington",
      "Gleb Pogudin"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Computational Geometry (cs.CG)",
      "Symbolic Computation (cs.SC)",
      "Systems and Control (eess.SY)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.00991"
  },
  {
    "id": "arXiv:2111.01009",
    "title": "Fragment-based Sequential Translation for Molecular Optimization",
    "abstract": "Searching for novel molecular compounds with desired properties is an\nimportant problem in drug discovery. Many existing frameworks generate\nmolecules one atom at a time. We instead propose a flexible editing paradigm\nthat generates molecules using learned molecular fragments--meaningful\nsubstructures of molecules. To do so, we train a variational autoencoder (VAE)\nto encode molecular fragments in a coherent latent space, which we then utilize\nas a vocabulary for editing molecules to explore the complex chemical property\nspace. Equipped with the learned fragment vocabulary, we propose Fragment-based\nSequential Translation (FaST), which learns a reinforcement learning (RL)\npolicy to iteratively translate model-discovered molecules into increasingly\nnovel molecules while satisfying desired properties. Empirical evaluation shows\nthat FaST significantly improves over state-of-the-art methods on benchmark\nsingle/multi-objective molecular optimization tasks.",
    "descriptor": "",
    "authors": [
      "Benson Chen",
      "Xiang Fu",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01009"
  },
  {
    "id": "arXiv:2111.01033",
    "title": "Linking theory and empirics: a general framework to model opinion  formation processes",
    "abstract": "We introduce a minimal opinion formation model, which is quite flexible and\ncan reproduce a broad variety of the existing micro-influence assumptions and\nmodels. At the same time, the model can be easily calibrated on real data, upon\nwhich it imposes only a few requirements. From this perspective, our model can\nbe considered as a bridge, connecting theoretical studies on opinion formation\nmodels and empirical research on social dynamics. We investigate the model\nanalytically by using mean-field approximation and numerically. Our analysis is\nexemplified by recently reported empirical data drawn from an online social\nnetwork. Employing these data for the model calibration, we demonstrate that\nthe model may reproduce fragmented and polarizing social systems. Furthermore,\nwe manage to generate an artificial society that features properties\nquantitatively and qualitatively similar to those observed empirically at the\nmacro scale. This ability became possible after we had advanced the model with\ntwo important communication features: selectivity and personalization\nalgorithms.",
    "descriptor": "\nComments: 59 pages, 8 figures, 6 tables\n",
    "authors": [
      "Ivan V. Kozitsin"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.01033"
  },
  {
    "id": "arXiv:2111.01037",
    "title": "Interpretable and Explainable Machine Learning for Materials Science and  Chemistry",
    "abstract": "While the uptake of data-driven approaches for materials science is at an\nexciting, early stage, to realise the true potential of machine learning models\nfor successful scientific discovery, they must have qualities beyond purely\npredictive power. The predictions and inner workings of models should provide a\ncertain degree of explainability by human experts, permitting the\nidentification of potential model issues or limitations, building trust on\nmodel predictions and unveiling unexpected correlations that may lead to\nscientific insights. In this work, we summarize applications of\ninterpretability and explainability techniques for materials science and\nchemistry and discuss how these techniques can improve the outcome of\nscientific studies.",
    "descriptor": "\nComments: Under review Accounts of Material Research\n",
    "authors": [
      "Felipe Oviedo",
      "Juan Lavista Ferres",
      "Tonio Buonassisi",
      "Keith Butler"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01037"
  },
  {
    "id": "arXiv:2111.01040",
    "title": "STORM+: Fully Adaptive SGD with Momentum for Nonconvex Optimization",
    "abstract": "In this work we investigate stochastic non-convex optimization problems where\nthe objective is an expectation over smooth loss functions, and the goal is to\nfind an approximate stationary point. The most popular approach to handling\nsuch problems is variance reduction techniques, which are also known to obtain\ntight convergence rates, matching the lower bounds in this case. Nevertheless,\nthese techniques require a careful maintenance of anchor points in conjunction\nwith appropriately selected \"mega-batchsizes\". This leads to a challenging\nhyperparameter tuning problem, that weakens their practicality. Recently,\n[Cutkosky and Orabona, 2019] have shown that one can employ recursive momentum\nin order to avoid the use of anchor points and large batchsizes, and still\nobtain the optimal rate for this setting. Yet, their method called STORM\ncrucially relies on the knowledge of the smoothness, as well a bound on the\ngradient norms. In this work we propose STORM+, a new method that is completely\nparameter-free, does not require large batch-sizes, and obtains the optimal\n$O(1/T^{1/3})$ rate for finding an approximate stationary point. Our work\nbuilds on the STORM algorithm, in conjunction with a novel approach to\nadaptively set the learning rate and momentum parameters.",
    "descriptor": "\nComments: 25 pages, 1 figure, accepted to NeurIPS 2021\n",
    "authors": [
      "Kfir Y. Levy",
      "Ali Kavis",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01040"
  },
  {
    "id": "arXiv:2111.01047",
    "title": "Mixed-Integer Programming for the ROADEF/EURO 2020 challenge",
    "abstract": "The ROADEF 2020 challenge presents a maintenance scheduling problem from the\nFrench electricity grid company RTE. The modeling of uncertainty makes the\nproblem highly nonconvex and apparently out of the reach of mathematical\nsolvers. We present our approach for the challenge problem. It is based on a\nnew family of cutting planes, coupled with a constraint generation approach. We\npresent mathematical proofs and separation algorithms for the cutting planes.\nWe then study the practical impact of our additions on the challenge instances,\nshowing that our approach significantly reduces the optimality gap obtained by\nthe solver.",
    "descriptor": "",
    "authors": [
      "Gabriel Gouvine"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.01047"
  },
  {
    "id": "arXiv:2111.01075",
    "title": "Exponent in Smoothing the Max-Relative Entropy and Its Application to  Quantum Privacy Amplification",
    "abstract": "The max-relative entropy together with its smoothed version is a basic tool\nin quantum information theory. In this paper, we derive the exact exponent for\nthe decay of the small modification of the quantum state in smoothing the\nmax-relative entropy. We then apply this result to the problem of privacy\namplification against quantum side information, and we obtain an upper bound\nfor the exponent of the decreasing of the insecurity, measured using either\npurified distance or relative entropy. Our upper bound complements the earlier\nlower bound established by Hayashi, and the two bounds match when the rate of\nrandomness extraction is above a critical value. Thus, for the case of high\nrate, we have determined the exact security exponent. Following this, we give\nexamples and show that in the low-rate case, neither the upper bound nor the\nlower bound is tight in general. This exhibits a picture similar to that of the\nerror exponent in channel coding.",
    "descriptor": "",
    "authors": [
      "Ke Li",
      "Yongsheng Yao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.01075"
  },
  {
    "id": "arXiv:2111.01093",
    "title": "Correlation between image quality metrics of magnetic resonance images  and the neural network segmentation accuracy",
    "abstract": "Deep neural networks with multilevel connections process input data in\ncomplex ways to learn the information.A networks learning efficiency depends\nnot only on the complex neural network architecture but also on the input\ntraining images.Medical image segmentation with deep neural networks for skull\nstripping or tumor segmentation from magnetic resonance images enables learning\nboth global and local features of the images.Though medical images are\ncollected in a controlled environment,there may be artifacts or equipment based\nvariance that cause inherent bias in the input set.In this study, we\ninvestigated the correlation between the image quality metrics of MR images\nwith the neural network segmentation accuracy.For that we have used the 3D\nDenseNet architecture and let the network trained on the same input but\napplying different methodologies to select the training data set based on the\nIQM values.The difference in the segmentation accuracy between models based on\nthe random training inputs with IQM based training inputs shed light on the\nrole of image quality metrics on segmentation accuracy.By running the image\nquality metrics to choose the training inputs,further we may tune the learning\nefficiency of the network and the segmentation accuracy.",
    "descriptor": "",
    "authors": [
      "Rajarajeswari Muthusivarajan",
      "Adrian Celaya",
      "Joshua P. Yung",
      "Satish Viswanath",
      "Daniel S. Marcus",
      "Caroline Chung",
      "David Fuentes"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01093"
  },
  {
    "id": "arXiv:2111.01104",
    "title": "NOTMAD: Estimating Bayesian Networks with Sample-Specific Structures and  Parameters",
    "abstract": "Context-specific Bayesian networks (i.e. directed acyclic graphs, DAGs)\nidentify context-dependent relationships between variables, but the\nnon-convexity induced by the acyclicity requirement makes it difficult to share\ninformation between context-specific estimators (e.g. with graph generator\nfunctions). For this reason, existing methods for inferring context-specific\nBayesian networks have favored breaking datasets into subsamples, limiting\nstatistical power and resolution, and preventing the use of multidimensional\nand latent contexts. To overcome this challenge, we propose NOTEARS-optimized\nMixtures of Archetypal DAGs (NOTMAD). NOTMAD models context-specific Bayesian\nnetworks as the output of a function which learns to mix archetypal networks\naccording to sample context. The archetypal networks are estimated jointly with\nthe context-specific networks and do not require any prior knowledge. We encode\nthe acyclicity constraint as a smooth regularization loss which is\nback-propagated to the mixing function; in this way, NOTMAD shares information\nbetween context-specific acyclic graphs, enabling the estimation of Bayesian\nnetwork structures and parameters at even single-sample resolution. We\ndemonstrate the utility of NOTMAD and sample-specific network inference through\nanalysis and experiments, including patient-specific gene expression networks\nwhich correspond to morphological variation in cancer.",
    "descriptor": "",
    "authors": [
      "Ben Lengerich",
      "Caleb Ellington",
      "Bryon Aragam",
      "Eric P. Xing",
      "Manolis Kellis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01104"
  },
  {
    "id": "arXiv:1707.05368",
    "title": "A robotic vision system to measure tree traits",
    "abstract": "Comments: 9 pages, IEEE/RSJ IROS 2017 conference paper, added Erratum 11/1/2021",
    "descriptor": "\nComments: 9 pages, IEEE/RSJ IROS 2017 conference paper, added Erratum 11/1/2021\n",
    "authors": [
      "Amy Tabb",
      "Henry Medeiros"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1707.05368"
  },
  {
    "id": "arXiv:1806.01331",
    "title": "Precise Runtime Analysis for Plateau Functions",
    "abstract": "Precise Runtime Analysis for Plateau Functions",
    "descriptor": "",
    "authors": [
      "Denis Antipov",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1806.01331"
  },
  {
    "id": "arXiv:1810.03793",
    "title": "Collective Strategies with a Master-slave Mechanism Dominate in Spatial  Iterated Prisoner's Dilemma",
    "abstract": "Comments: 11 pages, 31 figures",
    "descriptor": "\nComments: 11 pages, 31 figures\n",
    "authors": [
      "Jiawei Li"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1810.03793"
  },
  {
    "id": "arXiv:1901.07418",
    "title": "CAMR: Coded Aggregated MapReduce",
    "abstract": "Comments: 6 pages, 2 figures, full paper for ISIT 2019 paper",
    "descriptor": "\nComments: 6 pages, 2 figures, full paper for ISIT 2019 paper\n",
    "authors": [
      "Konstantinos Konstantinidis",
      "Aditya Ramamoorthy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1901.07418"
  },
  {
    "id": "arXiv:1902.02698",
    "title": "Ranked Enumeration of Conjunctive Query Results",
    "abstract": "Comments: LMCS journal submission",
    "descriptor": "\nComments: LMCS journal submission\n",
    "authors": [
      "Shaleen Deep",
      "Paraschos Koutris"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/1902.02698"
  },
  {
    "id": "arXiv:1904.00326",
    "title": "Medication Recommendation and Lab Test Imputation via Graph  Convolutional Networks",
    "abstract": "Medication Recommendation and Lab Test Imputation via Graph  Convolutional Networks",
    "descriptor": "",
    "authors": [
      "Chengsheng Mao",
      "Liang Yao",
      "Yuan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1904.00326"
  },
  {
    "id": "arXiv:1906.00066",
    "title": "Optimized Score Transformation for Consistent Fair Classification",
    "abstract": "Comments: 78 pages, 16 figures. Published in Journal of Machine Learning Research. Earlier version published at the 2020 International Conference on Artificial Intelligence and Statistics (AISTATS)",
    "descriptor": "\nComments: 78 pages, 16 figures. Published in Journal of Machine Learning Research. Earlier version published at the 2020 International Conference on Artificial Intelligence and Statistics (AISTATS)\n",
    "authors": [
      "Dennis Wei",
      "Karthikeyan Natesan Ramamurthy",
      "Flavio du Pin Calmon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.00066"
  },
  {
    "id": "arXiv:1906.03563",
    "title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Jingkang Wang",
      "Tianyun Zhang",
      "Sijia Liu",
      "Pin-Yu Chen",
      "Jiacen Xu",
      "Makan Fardad",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.03563"
  },
  {
    "id": "arXiv:1907.08410",
    "title": "Geometric Rates of Convergence for Kernel-based Sampling Algorithms",
    "abstract": "Comments: Accepted to UAI 2021 (Oral)",
    "descriptor": "\nComments: Accepted to UAI 2021 (Oral)\n",
    "authors": [
      "Rajiv Khanna",
      "Liam Hodgkinson",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1907.08410"
  },
  {
    "id": "arXiv:1908.03903",
    "title": "Quantum algorithm for estimating volumes of convex bodies",
    "abstract": "Comments: 61 pages, 8 figures. v2: Quantum query complexity improved to $\\tilde{O}(n^{3}+n^{2.5}/\\epsilon)$ and number of additional arithmetic operations improved to $\\tilde{O}(n^{5}+n^{4.5}/\\epsilon)$. v3: Improved Section 4.3.3 on nondestructive mean estimation and Section 6 on quantum lower bounds; various minor changes",
    "descriptor": "\nComments: 61 pages, 8 figures. v2: Quantum query complexity improved to $\\tilde{O}(n^{3}+n^{2.5}/\\epsilon)$ and number of additional arithmetic operations improved to $\\tilde{O}(n^{5}+n^{4.5}/\\epsilon)$. v3: Improved Section 4.3.3 on nondestructive mean estimation and Section 6 on quantum lower bounds; various minor changes\n",
    "authors": [
      "Shouvanik Chakrabarti",
      "Andrew M. Childs",
      "Shih-Han Hung",
      "Tongyang Li",
      "Chunhao Wang",
      "Xiaodi Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1908.03903"
  },
  {
    "id": "arXiv:1909.05244",
    "title": "Automatic Kappa Weighting for Instrumental Variable Models of Complier  Treatment Effects",
    "abstract": "Comments: 68 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: 68 pages, 5 figures, 2 tables\n",
    "authors": [
      "Rahul Singh",
      "Liyang Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/1909.05244"
  },
  {
    "id": "arXiv:1910.00149",
    "title": "Fame and Ultrafame: Measuring and comparing daily levels of `being  talked about' for United States' presidents, their rivals, God, countries,  and K-pop",
    "abstract": "Comments: 31 pages (21 pages main text, 10 pages appendix), 8 figures (7 in main text, 1 in appendix), 10 tables (1 in main text, 9 in appendix)",
    "descriptor": "\nComments: 31 pages (21 pages main text, 10 pages appendix), 8 figures (7 in main text, 1 in appendix), 10 tables (1 in main text, 9 in appendix)\n",
    "authors": [
      "Peter Sheridan Dodds",
      "Joshua R. Minot",
      "Michael V. Arnold",
      "Thayer Alshaabi",
      "Jane Lydia Adams",
      "David Rushing Dewhurst",
      "Andrew J. Reagan",
      "Christopher M. Danforth"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1910.00149"
  },
  {
    "id": "arXiv:1911.11855",
    "title": "Asymmetric Correntropy for Robust Adaptive Filtering",
    "abstract": "Asymmetric Correntropy for Robust Adaptive Filtering",
    "descriptor": "",
    "authors": [
      "Badong Chen",
      "Yuqing Xie",
      "Zhuang Li",
      "Yingsong Li",
      "Pengju Ren"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.11855"
  },
  {
    "id": "arXiv:1912.02906",
    "title": "Scalable Reinforcement Learning for Multi-Agent Networked Systems",
    "abstract": "Comments: Accepted to Operations Research. Conference version appeared in 2nd Learning for Dynamics and Control Conference with title \"Scalable Reinforcement Learning of Localized Policies for Multi-Agent Networked Systems\". This journal version includes more examples, discussions and simulations",
    "descriptor": "\nComments: Accepted to Operations Research. Conference version appeared in 2nd Learning for Dynamics and Control Conference with title \"Scalable Reinforcement Learning of Localized Policies for Multi-Agent Networked Systems\". This journal version includes more examples, discussions and simulations\n",
    "authors": [
      "Guannan Qu",
      "Adam Wierman",
      "Na Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1912.02906"
  },
  {
    "id": "arXiv:1912.08927",
    "title": "Hyperbolic Multiplex Network Embedding with Maps of Random Walk",
    "abstract": "Hyperbolic Multiplex Network Embedding with Maps of Random Walk",
    "descriptor": "",
    "authors": [
      "Peiyuan Sun"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.08927"
  },
  {
    "id": "arXiv:2002.02430",
    "title": "Asymptotically Optimal Competitive Ratio for Online Allocation of  Reusable Resources",
    "abstract": "Comments: 1-pg abstract in WINE 2021. This version combines results from previous iteration (arXiv:2002.02430v3) and the short note arXiv:2010.03983",
    "descriptor": "\nComments: 1-pg abstract in WINE 2021. This version combines results from previous iteration (arXiv:2002.02430v3) and the short note arXiv:2010.03983\n",
    "authors": [
      "Vineet Goyal",
      "Garud Iyengar",
      "Rajan Udwani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2002.02430"
  },
  {
    "id": "arXiv:2002.05226",
    "title": "Factorization of the Partial Covariance in Singly-Connected Path  Diagrams",
    "abstract": "Factorization of the Partial Covariance in Singly-Connected Path  Diagrams",
    "descriptor": "",
    "authors": [
      "Jose M. Pe\u00f1a"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.05226"
  },
  {
    "id": "arXiv:2002.06770",
    "title": "Unsupervised Image-generation Enhanced Adaptation for Object Detection  in Thermal images",
    "abstract": "Comments: 5 pages, 4 figures",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Peng Liu",
      "Fuyu Li",
      "Wanyi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2002.06770"
  },
  {
    "id": "arXiv:2002.09565",
    "title": "Adversarial Attacks on Machine Learning Systems for High-Frequency  Trading",
    "abstract": "Comments: ACM International Conference on AI in Finance (ICAIF) 2021",
    "descriptor": "\nComments: ACM International Conference on AI in Finance (ICAIF) 2021\n",
    "authors": [
      "Micah Goldblum",
      "Avi Schwarzschild",
      "Ankit B. Patel",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2002.09565"
  },
  {
    "id": "arXiv:2002.10316",
    "title": "Bandit Learning with Delayed Impact of Actions",
    "abstract": "Bandit Learning with Delayed Impact of Actions",
    "descriptor": "",
    "authors": [
      "Wei Tang",
      "Chien-Ju Ho",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.10316"
  },
  {
    "id": "arXiv:2003.01247",
    "title": "Iterative Averaging in the Quest for Best Test Error",
    "abstract": "Iterative Averaging in the Quest for Best Test Error",
    "descriptor": "",
    "authors": [
      "Diego Granziol",
      "Xingchen Wan",
      "Samuel Albanie",
      "Stephen Roberts"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.01247"
  },
  {
    "id": "arXiv:2003.02455",
    "title": "PAC-Bayes meta-learning with implicit task-specific posteriors",
    "abstract": "Comments: Add background and directly specify meta-learning as a bi-level optimisation",
    "descriptor": "\nComments: Add background and directly specify meta-learning as a bi-level optimisation\n",
    "authors": [
      "Cuong Nguyen",
      "Thanh-Toan Do",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.02455"
  },
  {
    "id": "arXiv:2003.05328",
    "title": "ENSEI: Efficient Secure Inference via Frequency-Domain Homomorphic  Convolution for Privacy-Preserving Visual Recognition",
    "abstract": "Comments: 10 pages, 3 figures, in Proceedings of Conference on Computer Vision and Pattern Recognition (CVPR 2020)",
    "descriptor": "\nComments: 10 pages, 3 figures, in Proceedings of Conference on Computer Vision and Pattern Recognition (CVPR 2020)\n",
    "authors": [
      "Song Bian",
      "Tianchen Wang",
      "Masayuki Hiromoto",
      "Yiyu Shi",
      "Takashi Sato"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.05328"
  },
  {
    "id": "arXiv:2004.03281",
    "title": "Teacher-Class Network: A Neural Network Compression Mechanism",
    "abstract": "Comments: Published in BMVC 2021",
    "descriptor": "\nComments: Published in BMVC 2021\n",
    "authors": [
      "Shaiq Munir Malik",
      "Muhammad Umair Haider",
      "Mohbat Tharani",
      "Musab Rasheed",
      "Murtaza Taj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.03281"
  },
  {
    "id": "arXiv:2004.07049",
    "title": "Boosting algorithms in energy research: A systematic review",
    "abstract": "Boosting algorithms in energy research: A systematic review",
    "descriptor": "",
    "authors": [
      "Hristos Tyralis",
      "Georgia Papacharalampous"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2004.07049"
  },
  {
    "id": "arXiv:2005.04162",
    "title": "Graph Consistency as a Graduated Property: Consistency-Sustaining and  -Improving Graph Transformations",
    "abstract": "Comments: 23 pages, accepted for publication at the International Conference on Graph Transformation 2020 Typos corrected, heading for Table 2 clarified, wrong statement in Theorem 2 omitted",
    "descriptor": "\nComments: 23 pages, accepted for publication at the International Conference on Graph Transformation 2020 Typos corrected, heading for Table 2 clarified, wrong statement in Theorem 2 omitted\n",
    "authors": [
      "Jens Kosiol",
      "Daniel Str\u00fcber",
      "Gabriele Taentzer",
      "Steffen Zschaler"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2005.04162"
  },
  {
    "id": "arXiv:2005.04176",
    "title": "In Pursuit of Interpretable, Fair and Accurate Machine Learning for  Criminal Recidivism Prediction",
    "abstract": "In Pursuit of Interpretable, Fair and Accurate Machine Learning for  Criminal Recidivism Prediction",
    "descriptor": "",
    "authors": [
      "Caroline Wang",
      "Bin Han",
      "Bhrij Patel",
      "Cynthia Rudin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2005.04176"
  },
  {
    "id": "arXiv:2005.04692",
    "title": "Topological regularization with information filtering networks",
    "abstract": "Comments: 17 pages , 4 figures, 1 table",
    "descriptor": "\nComments: 17 pages , 4 figures, 1 table\n",
    "authors": [
      "Tomaso Aste"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.04692"
  },
  {
    "id": "arXiv:2005.06034",
    "title": "An adaptive Euler-Maruyama scheme for McKean-Vlasov SDEs with  super-linear growth and application to the mean-field FitzHugh-Nagumo model",
    "abstract": "Comments: 29 pages, 12 figures",
    "descriptor": "\nComments: 29 pages, 12 figures\n",
    "authors": [
      "Christoph Reisinger",
      "Wolfgang Stockinger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2005.06034"
  },
  {
    "id": "arXiv:2006.00587",
    "title": "Towards Understanding Cooperative Multi-Agent Q-Learning with Value  Factorization",
    "abstract": "Comments: Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Jianhao Wang",
      "Zhizhou Ren",
      "Beining Han",
      "Jianing Ye",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.00587"
  },
  {
    "id": "arXiv:2006.09092",
    "title": "Learning Rates as a Function of Batch Size: A Random Matrix Theory  Approach to Neural Network Training",
    "abstract": "Learning Rates as a Function of Batch Size: A Random Matrix Theory  Approach to Neural Network Training",
    "descriptor": "",
    "authors": [
      "Diego Granziol",
      "Stefan Zohren",
      "Stephen Roberts"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.09092"
  },
  {
    "id": "arXiv:2006.12469",
    "title": "Attention-based Quantum Tomography",
    "abstract": "Attention-based Quantum Tomography",
    "descriptor": "",
    "authors": [
      "Peter Cha",
      "Paul Ginsparg",
      "Felix Wu",
      "Juan Carrasquilla",
      "Peter L. McMahon",
      "Eun-Ah Kim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.12469"
  },
  {
    "id": "arXiv:2006.12837",
    "title": "SWAG: A Wrapper Method for Sparse Learning",
    "abstract": "SWAG: A Wrapper Method for Sparse Learning",
    "descriptor": "",
    "authors": [
      "Roberto Molinari",
      "Gaetan Bakalli",
      "St\u00e9phane Guerrier",
      "Cesare Miglioli",
      "Samuel Orso",
      "Mucyo Karemera",
      "Olivier Scaillet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.12837"
  },
  {
    "id": "arXiv:2006.13365",
    "title": "Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge  Graph Embedding Models Under a Unified Framework",
    "abstract": "Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge  Graph Embedding Models Under a Unified Framework",
    "descriptor": "",
    "authors": [
      "Mehdi Ali",
      "Max Berrendorf",
      "Charles Tapley Hoyt",
      "Laurent Vermue",
      "Mikhail Galkin",
      "Sahand Sharifzadeh",
      "Asja Fischer",
      "Volker Tresp",
      "Jens Lehmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.13365"
  },
  {
    "id": "arXiv:2006.14061",
    "title": "Pareto Active Learning with Gaussian Processes and Adaptive  Discretization",
    "abstract": "Pareto Active Learning with Gaussian Processes and Adaptive  Discretization",
    "descriptor": "",
    "authors": [
      "Andi Nika",
      "Kerem Bozgan",
      "Sepehr Elahi",
      "\u00c7a\u011f\u0131n Ararat",
      "Cem Tekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.14061"
  },
  {
    "id": "arXiv:2007.01285",
    "title": "Deep Learning for Neuroimaging-based Diagnosis and Rehabilitation of  Autism Spectrum Disorder: A Review",
    "abstract": "Deep Learning for Neuroimaging-based Diagnosis and Rehabilitation of  Autism Spectrum Disorder: A Review",
    "descriptor": "",
    "authors": [
      "Marjane Khodatars",
      "Afshin Shoeibi",
      "Delaram Sadeghi",
      "Navid Ghassemi",
      "Mahboobeh Jafari",
      "Parisa Moridian",
      "Ali Khadem",
      "Roohallah Alizadehsani",
      "Assef Zare",
      "Yinan Kong",
      "Abbas Khosravi",
      "Saeid Nahavandi",
      "Sadiq Hussain",
      "U. Rajendra Acharya",
      "Michael Berk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.01285"
  },
  {
    "id": "arXiv:2007.04210",
    "title": "Epidemic Spreading and Equilibrium Social Distancing in Heterogeneous  Networks",
    "abstract": "Comments: 31 pages, 2 figures",
    "descriptor": "\nComments: 31 pages, 2 figures\n",
    "authors": [
      "Hamed Amini",
      "Andreea Minca"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2007.04210"
  },
  {
    "id": "arXiv:2007.08128",
    "title": "Detecting Out-of-distribution Samples via Variational Auto-encoder with  Reliable Uncertainty Estimation",
    "abstract": "Detecting Out-of-distribution Samples via Variational Auto-encoder with  Reliable Uncertainty Estimation",
    "descriptor": "",
    "authors": [
      "Xuming Ran",
      "Mingkun Xu",
      "Lingrui Mei",
      "Qi Xu",
      "Quanying Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.08128"
  },
  {
    "id": "arXiv:2007.08792",
    "title": "Uncertainty Quantification and Deep Ensembles",
    "abstract": "Uncertainty Quantification and Deep Ensembles",
    "descriptor": "",
    "authors": [
      "Rahul Rahaman",
      "Alexandre H. Thiery"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.08792"
  },
  {
    "id": "arXiv:2007.15700",
    "title": "The Unreasonable Effectiveness of Machine Learning in Moldavian versus  Romanian Dialect Identification",
    "abstract": "Comments: Accepted in International Journal of Intelligent Systems",
    "descriptor": "\nComments: Accepted in International Journal of Intelligent Systems\n",
    "authors": [
      "Mihaela G\u0103man",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2007.15700"
  },
  {
    "id": "arXiv:2008.00076",
    "title": "Possibility conditions for Open Access",
    "abstract": "Comments: 13 pages, 2 figures, 6 tables and accompanying prolog source code",
    "descriptor": "\nComments: 13 pages, 2 figures, 6 tables and accompanying prolog source code\n",
    "authors": [
      "Jacinto Davila"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2008.00076"
  },
  {
    "id": "arXiv:2008.00511",
    "title": "Curriculum Learning with a Progression Function",
    "abstract": "Curriculum Learning with a Progression Function",
    "descriptor": "",
    "authors": [
      "Andrea Bassich",
      "Francesco Foglino",
      "Matteo Leonetti",
      "Daniel Kudenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.00511"
  },
  {
    "id": "arXiv:2008.03128",
    "title": "Revisiting Mid-Level Patterns for Cross-Domain Few-Shot Recognition",
    "abstract": "Revisiting Mid-Level Patterns for Cross-Domain Few-Shot Recognition",
    "descriptor": "",
    "authors": [
      "Yixiong Zou",
      "Shanghang Zhang",
      "JianPeng Yu",
      "Yonghong Tian",
      "Jos\u00e9 M. F. Moura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.03128"
  },
  {
    "id": "arXiv:2008.03793",
    "title": "A family of finite element Stokes complexes in three dimensions",
    "abstract": "Comments: 27 pages, 1 figure",
    "descriptor": "\nComments: 27 pages, 1 figure\n",
    "authors": [
      "Kaibo Hu",
      "Qian Zhang",
      "Zhimin Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.03793"
  },
  {
    "id": "arXiv:2008.05648",
    "title": "Cut Sparsification of the Clique Beyond the Ramanujan Bound: A  Separation of Cut Versus Spectral Sparsification",
    "abstract": "Comments: To appear in SODA 2022",
    "descriptor": "\nComments: To appear in SODA 2022\n",
    "authors": [
      "Antares Chen",
      "Jonathan Shi",
      "Luca Trevisan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2008.05648"
  },
  {
    "id": "arXiv:2008.05911",
    "title": "On the Bipartiteness Constant and Expansion of Cayley Graphs",
    "abstract": "Comments: 14 pages, 2 figures",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Nina Moorman",
      "Peter Ralli",
      "Prasad Tetali"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2008.05911"
  },
  {
    "id": "arXiv:2009.07398",
    "title": "A Sensitivity-based Data Augmentation Framework for Model Predictive  Control Policy Approximation",
    "abstract": "Comments: Accepted for publication at IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: Accepted for publication at IEEE Transactions on Automatic Control\n",
    "authors": [
      "Dinesh Krishnamoorthy"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.07398"
  },
  {
    "id": "arXiv:2009.08327",
    "title": "Berrut Approximated Coded Computing: Straggler Resistance Beyond  Polynomial Computing",
    "abstract": "Berrut Approximated Coded Computing: Straggler Resistance Beyond  Polynomial Computing",
    "descriptor": "",
    "authors": [
      "Tayyebeh Jahani-Nezhad",
      "Mohammad Ali Maddah-Ali"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.08327"
  },
  {
    "id": "arXiv:2009.08965",
    "title": "Encoding Robustness to Image Style via Adversarial Feature Perturbations",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Manli Shu",
      "Zuxuan Wu",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.08965"
  },
  {
    "id": "arXiv:2010.02745",
    "title": "Image Translation for Medical Image Generation -- Ischemic Stroke  Lesions",
    "abstract": "Comments: 15 pages; 9 figures; 2 tables; content matches published version",
    "descriptor": "\nComments: 15 pages; 9 figures; 2 tables; content matches published version\n",
    "authors": [
      "Moritz Platscher",
      "Jonathan Zopes",
      "Christian Federau"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.02745"
  },
  {
    "id": "arXiv:2010.02917",
    "title": "NCP-VAE: Variational Autoencoders with Noise Contrastive Priors",
    "abstract": "Comments: Accepted to NeurIPS 2021; 22 pages including appendix",
    "descriptor": "\nComments: Accepted to NeurIPS 2021; 22 pages including appendix\n",
    "authors": [
      "Jyoti Aneja",
      "Alexander Schwing",
      "Jan Kautz",
      "Arash Vahdat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.02917"
  },
  {
    "id": "arXiv:2010.03603",
    "title": "Solving stochastic inverse problems for property-structure linkages  using data-consistent inversion and machine learning",
    "abstract": "Solving stochastic inverse problems for property-structure linkages  using data-consistent inversion and machine learning",
    "descriptor": "",
    "authors": [
      "Anh Tran",
      "Tim Wildey"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2010.03603"
  },
  {
    "id": "arXiv:2010.06100",
    "title": "Invariant Representation Learning for Infant Pose Estimation with Small  Data",
    "abstract": "Invariant Representation Learning for Infant Pose Estimation with Small  Data",
    "descriptor": "",
    "authors": [
      "Xiaofei Huang",
      "Nihang Fu",
      "Shuangjun Liu",
      "Sarah Ostadabbas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.06100"
  },
  {
    "id": "arXiv:2010.06581",
    "title": "Geomechanical simulation of energy storage in salt formations",
    "abstract": "Geomechanical simulation of energy storage in salt formations",
    "descriptor": "",
    "authors": [
      "Kishan Ramesh Kumar",
      "Artur A. Makhmutov",
      "Christopher J. Spiers",
      "Hadi Hajibeygi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2010.06581"
  },
  {
    "id": "arXiv:2010.08164",
    "title": "Pose And Joint-Aware Action Recognition",
    "abstract": "Comments: Accepted to WACV 2022",
    "descriptor": "\nComments: Accepted to WACV 2022\n",
    "authors": [
      "Anshul Shah",
      "Shlok Mishra",
      "Ankan Bansal",
      "Jun-Cheng Chen",
      "Rama Chellappa",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.08164"
  },
  {
    "id": "arXiv:2010.09670",
    "title": "RobustBench: a standardized adversarial robustness benchmark",
    "abstract": "Comments: The camera-ready version accepted at the NeurIPS'21 Datasets and Benchmarks Track: 120+ evaluations, 80+ models, 7 leaderboards (Linf, L2, common corruptions; CIFAR-10, CIFAR-100, ImageNet), significantly expanded analysis part (calibration, fairness, privacy leakage, smoothness, transferability)",
    "descriptor": "\nComments: The camera-ready version accepted at the NeurIPS'21 Datasets and Benchmarks Track: 120+ evaluations, 80+ models, 7 leaderboards (Linf, L2, common corruptions; CIFAR-10, CIFAR-100, ImageNet), significantly expanded analysis part (calibration, fairness, privacy leakage, smoothness, transferability)\n",
    "authors": [
      "Francesco Croce",
      "Maksym Andriushchenko",
      "Vikash Sehwag",
      "Edoardo Debenedetti",
      "Nicolas Flammarion",
      "Mung Chiang",
      "Prateek Mittal",
      "Matthias Hein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.09670"
  },
  {
    "id": "arXiv:2010.10041",
    "title": "Looking for Clues of Language in Multilingual BERT to Improve  Cross-lingual Generalization",
    "abstract": "Comments: preprint",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Chi-Liang Liu",
      "Tsung-Yuan Hsu",
      "Yung-Sung Chuang",
      "Chung-Yi Li",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.10041"
  },
  {
    "id": "arXiv:2010.10314",
    "title": "The complexity of finding optimal subgraphs to represent spatial  correlation",
    "abstract": "Comments: Numerous new results added",
    "descriptor": "\nComments: Numerous new results added\n",
    "authors": [
      "Jessica Enright",
      "Duncan Lee",
      "Kitty Meeks",
      "William Pettersson",
      "John Sylvester"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2010.10314"
  },
  {
    "id": "arXiv:2010.11003",
    "title": "Unsupervised Multiple Choices Question Answering: Start Learning from  Basic Knowledge",
    "abstract": "Comments: Accepted by EMNLP 2021 MRQA workshop",
    "descriptor": "\nComments: Accepted by EMNLP 2021 MRQA workshop\n",
    "authors": [
      "Chi-Liang Liu",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.11003"
  },
  {
    "id": "arXiv:2010.11375",
    "title": "Deep Learning for Distinguishing Normal versus Abnormal Chest  Radiographs and Generalization to Unseen Diseases",
    "abstract": "Deep Learning for Distinguishing Normal versus Abnormal Chest  Radiographs and Generalization to Unseen Diseases",
    "descriptor": "",
    "authors": [
      "Zaid Nabulsi",
      "Andrew Sellergren",
      "Shahar Jamshy",
      "Charles Lau",
      "Edward Santos",
      "Atilla P. Kiraly",
      "Wenxing Ye",
      "Jie Yang",
      "Rory Pilgrim",
      "Sahar Kazemzadeh",
      "Jin Yu",
      "Sreenivasa Raju Kalidindi",
      "Mozziyar Etemadi",
      "Florencia Garcia-Vicente",
      "David Melnick",
      "Greg S. Corrado",
      "Lily Peng",
      "Krish Eswaran",
      "Daniel Tse",
      "Neeral Beladia",
      "Yun Liu",
      "Po-Hsuan Cameron Chen",
      "Shravya Shetty"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.11375"
  },
  {
    "id": "arXiv:2010.12249",
    "title": "Multi Scale Identity-Preserving Image-to-Image Translation Network for  Low-Resolution Face Recognition",
    "abstract": "Multi Scale Identity-Preserving Image-to-Image Translation Network for  Low-Resolution Face Recognition",
    "descriptor": "",
    "authors": [
      "Vahid Reza Khazaie",
      "Nicky Bayat",
      "Yalda Mohsenzadeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.12249"
  },
  {
    "id": "arXiv:2010.12427",
    "title": "Casting a BAIT for Offline and Online Source-free Domain Adaptation",
    "abstract": "Casting a BAIT for Offline and Online Source-free Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Shiqi Yang",
      "Yaxing Wang",
      "Joost van de Weijer",
      "Luis Herranz",
      "Shangling Jui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.12427"
  },
  {
    "id": "arXiv:2010.14746",
    "title": "Continuous Lyapunov Controller and Chaotic Non-linear System  Optimization using Deep Machine Learning",
    "abstract": "Comments: 7 pages, 12 figures",
    "descriptor": "\nComments: 7 pages, 12 figures\n",
    "authors": [
      "Amr Mahmoud",
      "Youmna Ismaeil",
      "Mohamed Zohdy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.14746"
  },
  {
    "id": "arXiv:2011.00416",
    "title": "Deep Learning for Text Style Transfer: A Survey",
    "abstract": "Comments: Computational Linguistics Journal 2021",
    "descriptor": "\nComments: Computational Linguistics Journal 2021\n",
    "authors": [
      "Di Jin",
      "Zhijing Jin",
      "Zhiting Hu",
      "Olga Vechtomova",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.00416"
  },
  {
    "id": "arXiv:2011.00448",
    "title": "Mitigating Write Disturbance Errors of Phase-Change Memory as In-Module  Approach",
    "abstract": "Mitigating Write Disturbance Errors of Phase-Change Memory as In-Module  Approach",
    "descriptor": "",
    "authors": [
      "Hyokeun Lee",
      "Seungyong Lee",
      "Byeongki Song",
      "Moonsoo Kim",
      "Seokbo Shim",
      "Hyun Kim",
      "Hyuk-Jae Lee"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2011.00448"
  },
  {
    "id": "arXiv:2011.01681",
    "title": "Learning Causal Semantic Representation for Out-of-Distribution  Prediction",
    "abstract": "Comments: NeurIPS'21 camera-ready version",
    "descriptor": "\nComments: NeurIPS'21 camera-ready version\n",
    "authors": [
      "Chang Liu",
      "Xinwei Sun",
      "Jindong Wang",
      "Haoyue Tang",
      "Tao Li",
      "Tao Qin",
      "Wei Chen",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.01681"
  },
  {
    "id": "arXiv:2011.02966",
    "title": "Absence of Barren Plateaus in Quantum Convolutional Neural Networks",
    "abstract": "Comments: 9 + 20 pages, 7 + 8 figures, 3 tables. Updated to published version",
    "descriptor": "\nComments: 9 + 20 pages, 7 + 8 figures, 3 tables. Updated to published version\n",
    "authors": [
      "Arthur Pesah",
      "M. Cerezo",
      "Samson Wang",
      "Tyler Volkoff",
      "Andrew T. Sornborger",
      "Patrick J. Coles"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.02966"
  },
  {
    "id": "arXiv:2011.06247",
    "title": "Optimal Collaterals in Multi-Enterprise Investment Networks",
    "abstract": "Optimal Collaterals in Multi-Enterprise Investment Networks",
    "descriptor": "",
    "authors": [
      "Moshe Babaioff",
      "Yoav Kolumbus",
      "Eyal Winter"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2011.06247"
  },
  {
    "id": "arXiv:2011.09704",
    "title": "Causal Contextual Prediction for Learned Image Compression",
    "abstract": "Comments: We add some descriptions for the improved quantization in the latest arxiv version",
    "descriptor": "\nComments: We add some descriptions for the improved quantization in the latest arxiv version\n",
    "authors": [
      "Zongyu Guo",
      "Zhizheng Zhang",
      "Runsen Feng",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2011.09704"
  },
  {
    "id": "arXiv:2011.09719",
    "title": "Adversarial Examples for $k$-Nearest Neighbor Classifiers Based on  Higher-Order Voronoi Diagrams",
    "abstract": "Comments: Appears at NeurIPS 2021. Code is available at this https URL",
    "descriptor": "\nComments: Appears at NeurIPS 2021. Code is available at this https URL\n",
    "authors": [
      "Chawin Sitawarin",
      "Evgenios M. Kornaropoulos",
      "Dawn Song",
      "David Wagner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.09719"
  },
  {
    "id": "arXiv:2011.13311",
    "title": "Data-Efficient Classification of Radio Galaxies",
    "abstract": "Comments: 11 pages, 8 figures, Accepted for publication in MNRAS",
    "descriptor": "\nComments: 11 pages, 8 figures, Accepted for publication in MNRAS\n",
    "authors": [
      "Ashwin Samudre",
      "Lijo George",
      "Mahak Bansal",
      "Yogesh Wadadekar"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.13311"
  },
  {
    "id": "arXiv:2011.14478",
    "title": "Annotation-Efficient Untrimmed Video Action Recognition",
    "abstract": "Annotation-Efficient Untrimmed Video Action Recognition",
    "descriptor": "",
    "authors": [
      "Yixiong Zou",
      "Shanghang Zhang",
      "Guangyao Chen",
      "Yonghong Tian",
      "Kurt Keutzer",
      "Jos\u00e9 M. F. Moura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.14478"
  },
  {
    "id": "arXiv:2012.06613",
    "title": "Beyond Scaling: Calculable Error Bounds of the Power-of-Two-Choices  Mean-Field Model in Heavy-Traffic",
    "abstract": "Beyond Scaling: Calculable Error Bounds of the Power-of-Two-Choices  Mean-Field Model in Heavy-Traffic",
    "descriptor": "",
    "authors": [
      "Fnu Hairi",
      "Xin Liu",
      "Lei Ying"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2012.06613"
  },
  {
    "id": "arXiv:2012.06646",
    "title": "A fine-grained parallelization of the immersed boundary method",
    "abstract": "Comments: 14 pages, 5 figures",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Andrew Kassen",
      "Varun Shankar",
      "Aaron L Fogelson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.06646"
  },
  {
    "id": "arXiv:2012.07962",
    "title": "Iterative label cleaning for transductive and semi-supervised few-shot  learning",
    "abstract": "Comments: published in ICCV 2021",
    "descriptor": "\nComments: published in ICCV 2021\n",
    "authors": [
      "Michalis Lazarou",
      "Tania Stathaki",
      "Yannis Avrithis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.07962"
  },
  {
    "id": "arXiv:2012.08073",
    "title": "Chernoff Sampling for Active Testing and Extension to Active Regression",
    "abstract": "Comments: 46 pages, 9 figures",
    "descriptor": "\nComments: 46 pages, 9 figures\n",
    "authors": [
      "Subhojyoti Mukherjee",
      "Ardhendu Tripathy",
      "Robert Nowak"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.08073"
  },
  {
    "id": "arXiv:2012.08868",
    "title": "Using Spatio-temporal Deep Learning for Forecasting Demand and  Supply-demand Gap in Ride-hailing System with Anonymized Spatial Adjacency  Information",
    "abstract": "Using Spatio-temporal Deep Learning for Forecasting Demand and  Supply-demand Gap in Ride-hailing System with Anonymized Spatial Adjacency  Information",
    "descriptor": "",
    "authors": [
      "M. H. Rahman",
      "S. M. Rifaat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.08868"
  },
  {
    "id": "arXiv:2012.11867",
    "title": "Intelligent Resource Allocation in Dense LoRa Networks using Deep  Reinforcement Learning",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Inaam Ilahi",
      "Muhammad Usama",
      "Muhammad Omer Farooq",
      "Muhammad Umar Janjua",
      "Junaid Qadir"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.11867"
  },
  {
    "id": "arXiv:2012.13154",
    "title": "Adversarial Momentum-Contrastive Pre-Training for Robust Feature  Extraction",
    "abstract": "Comments: 16 pages;6 figures; preprint",
    "descriptor": "\nComments: 16 pages;6 figures; preprint\n",
    "authors": [
      "Cong Xu",
      "Dan Li",
      "Min Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.13154"
  },
  {
    "id": "arXiv:2101.00536",
    "title": "Computing Cliques and Cavities in Networks",
    "abstract": "Comments: 20 pages, 4+2 figures, 3+3 tables",
    "descriptor": "\nComments: 20 pages, 4+2 figures, 3+3 tables\n",
    "authors": [
      "Dinghua Shi",
      "Zhifeng Chen",
      "Xiang Sun",
      "Qinghua Chen",
      "Chuang Ma",
      "Yang Lou",
      "Guanrong Chen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2101.00536"
  },
  {
    "id": "arXiv:2101.01213",
    "title": "Improving Portuguese Semantic Role Labeling with Transformers and  Transfer Learning",
    "abstract": "Comments: 30 pages, 3 figures; Fixed broken links in References",
    "descriptor": "\nComments: 30 pages, 3 figures; Fixed broken links in References\n",
    "authors": [
      "Sofia Oliveira",
      "Daniel Loureiro",
      "Al\u00edpio Jorge"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.01213"
  },
  {
    "id": "arXiv:2101.01484",
    "title": "QoE-driven Secure Video Transmission in Cloud-edge Collaborative  Networks",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Tantan Zhao",
      "Lijun He",
      "Xinyu Huang",
      "Fan Li"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2101.01484"
  },
  {
    "id": "arXiv:2101.02307",
    "title": "Directed mixed membership stochastic blockmodel",
    "abstract": "Comments: 35 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 35 pages, 6 figures, 2 tables\n",
    "authors": [
      "Huan Qing",
      "Jingli Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2101.02307"
  },
  {
    "id": "arXiv:2101.03712",
    "title": "Enumeration Algorithms for Conjunctive Queries with Projection",
    "abstract": "Comments: journal version for LMCS",
    "descriptor": "\nComments: journal version for LMCS\n",
    "authors": [
      "Shaleen Deep",
      "Xiao Hu",
      "Paraschos Koutris"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2101.03712"
  },
  {
    "id": "arXiv:2101.05244",
    "title": "Computing Touch-Point Ambiguity on Mobile Touchscreens for Modeling  Target Selection Times",
    "abstract": "Comments: Accepted to PACM IMWUT (oral presentation at UbiComp 2022)",
    "descriptor": "\nComments: Accepted to PACM IMWUT (oral presentation at UbiComp 2022)\n",
    "authors": [
      "Shota Yamanaka",
      "Hiroki Usuba"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2101.05244"
  },
  {
    "id": "arXiv:2101.06426",
    "title": "A Survey on Extraction of Causal Relations from Natural Language Text",
    "abstract": "A Survey on Extraction of Causal Relations from Natural Language Text",
    "descriptor": "",
    "authors": [
      "Jie Yang",
      "Soyeon Caren Han",
      "Josiah Poon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.06426"
  },
  {
    "id": "arXiv:2102.00104",
    "title": "Performance of the low-rank tensor-train SVD (TT-SVD) for large dense  tensors on modern multi-core CPUs",
    "abstract": "Comments: 26 pages, 16 figures, submitted to SISC",
    "descriptor": "\nComments: 26 pages, 16 figures, submitted to SISC\n",
    "authors": [
      "Melven R\u00f6hrig-Z\u00f6llner",
      "Jonas Thies",
      "Achim Basermann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2102.00104"
  },
  {
    "id": "arXiv:2102.02118",
    "title": "Group Consensus of Linear Multi-agent Systems under Nonnegative Directed  Graphs",
    "abstract": "Comments: to be published in IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: to be published in IEEE Transactions on Automatic Control\n",
    "authors": [
      "Zhongchang Liu",
      "Wing Shing Wong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.02118"
  },
  {
    "id": "arXiv:2102.02976",
    "title": "Analyzing the Generalization Capability of SGLD Using Properties of  Gaussian Channels",
    "abstract": "Analyzing the Generalization Capability of SGLD Using Properties of  Gaussian Channels",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Yizhe Huang",
      "Rui Gao",
      "Flavio P. Calmon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02976"
  },
  {
    "id": "arXiv:2102.03782",
    "title": "Using Gaussian Processes to Design Dynamic Experiments for Black-Box  Model Discrimination under Uncertainty",
    "abstract": "Using Gaussian Processes to Design Dynamic Experiments for Black-Box  Model Discrimination under Uncertainty",
    "descriptor": "",
    "authors": [
      "Simon Olofsson",
      "Eduardo S. Schultz",
      "Adel Mhamdi",
      "Alexander Mitsos",
      "Marc Peter Deisenroth",
      "Ruth Misener"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2102.03782"
  },
  {
    "id": "arXiv:2102.04200",
    "title": "Variations on a Theme by Massey",
    "abstract": "Variations on a Theme by Massey",
    "descriptor": "",
    "authors": [
      "Olivier Rioul"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.04200"
  },
  {
    "id": "arXiv:2102.04279",
    "title": "Constrained Ensemble Langevin Monte Carlo",
    "abstract": "Constrained Ensemble Langevin Monte Carlo",
    "descriptor": "",
    "authors": [
      "Zhiyan Ding",
      "Qin Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.04279"
  },
  {
    "id": "arXiv:2102.05034",
    "title": "SLAPS: Self-Supervision Improves Structure Learning for Graph Neural  Networks",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Bahare Fatemi",
      "Layla El Asri",
      "Seyed Mehran Kazemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.05034"
  },
  {
    "id": "arXiv:2102.05306",
    "title": "Differential Entropy Rate Characterisations of Long Range Dependent  Processes",
    "abstract": "Differential Entropy Rate Characterisations of Long Range Dependent  Processes",
    "descriptor": "",
    "authors": [
      "Andrew Feutrill",
      "Matthew Roughan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2102.05306"
  },
  {
    "id": "arXiv:2102.08549",
    "title": "First Target and Opinion then Polarity: Enhancing Target-opinion  Correlation for Aspect Sentiment Triplet Extraction",
    "abstract": "First Target and Opinion then Polarity: Enhancing Target-opinion  Correlation for Aspect Sentiment Triplet Extraction",
    "descriptor": "",
    "authors": [
      "Lianzhe Huang",
      "Peiyi Wang",
      "Sujian Li",
      "Tianyu Liu",
      "Xiaodong Zhang",
      "Zhicong Cheng",
      "Dawei Yin",
      "Houfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.08549"
  },
  {
    "id": "arXiv:2102.09526",
    "title": "Convex regularization in statistical inverse learning problems",
    "abstract": "Comments: 35 pages, 4 figures",
    "descriptor": "\nComments: 35 pages, 4 figures\n",
    "authors": [
      "Tatiana A. Bubba",
      "Martin Burger",
      "Tapio Helin",
      "Luca Ratti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2102.09526"
  },
  {
    "id": "arXiv:2102.10509",
    "title": "Partition Rank and Analytic Rank are Uniformly Equivalent",
    "abstract": "Comments: Added two corollaries: Corollary 1 shows that improving the field cardinality assumption from double exponential to single exponential would nearly settle the question even for tiny fields; Corollary 2 proves a special case of the Polynomial Gowers Inverse Conjecture",
    "descriptor": "\nComments: Added two corollaries: Corollary 1 shows that improving the field cardinality assumption from double exponential to single exponential would nearly settle the question even for tiny fields; Corollary 2 proves a special case of the Polynomial Gowers Inverse Conjecture\n",
    "authors": [
      "Alex Cohen",
      "Guy Moshkovitz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2102.10509"
  },
  {
    "id": "arXiv:2102.11764",
    "title": "Quantum Entropic Causal Inference",
    "abstract": "Quantum Entropic Causal Inference",
    "descriptor": "",
    "authors": [
      "Mohammad Ali Javidian",
      "Vaneet Aggarwal",
      "Fanglin Bao",
      "Zubin Jacob"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.11764"
  },
  {
    "id": "arXiv:2102.12086",
    "title": "Modern Koopman Theory for Dynamical Systems",
    "abstract": "Comments: 110 pages, 27 figures",
    "descriptor": "\nComments: 110 pages, 27 figures\n",
    "authors": [
      "Steven L. Brunton",
      "Marko Budi\u0161i\u0107",
      "Eurika Kaiser",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.12086"
  },
  {
    "id": "arXiv:2102.12209",
    "title": "Designing zonal-based flexible bus services under stochastic demand",
    "abstract": "Comments: 42 pages, 12 figures, manuscript accepted by Transportation Science",
    "descriptor": "\nComments: 42 pages, 12 figures, manuscript accepted by Transportation Science\n",
    "authors": [
      "Enoch Lee",
      "Xuekai Cen",
      "Hong K. Lo",
      "Ka Fai Ng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.12209"
  },
  {
    "id": "arXiv:2102.12770",
    "title": "BeFaaS: An Application-Centric Benchmarking Framework for FaaS Platforms",
    "abstract": "Comments: Accepted for publication in Proc. of IEEE International Conference on Cloud Engineering 2021 (IC2E'21)",
    "descriptor": "\nComments: Accepted for publication in Proc. of IEEE International Conference on Cloud Engineering 2021 (IC2E'21)\n",
    "authors": [
      "Martin Grambow",
      "Tobias Pfandzelter",
      "Luk Burchard",
      "Carsten Schubert",
      "Max Zhao",
      "David Bermbach"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.12770"
  },
  {
    "id": "arXiv:2103.00223",
    "title": "Generalized Universe Hierarchies and First-Class Universe Levels",
    "abstract": "Generalized Universe Hierarchies and First-Class Universe Levels",
    "descriptor": "",
    "authors": [
      "Andr\u00e1s Kov\u00e1cs"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.00223"
  },
  {
    "id": "arXiv:2103.01488",
    "title": "Multi-Level Attention Pooling for Graph Neural Networks: Unifying Graph  Representations with Multiple Localities",
    "abstract": "Comments: 17 pages + 5 appendix pages, 16 figures + 2 appendix figures, 2 tables + 5 appendix tables",
    "descriptor": "\nComments: 17 pages + 5 appendix pages, 16 figures + 2 appendix figures, 2 tables + 5 appendix tables\n",
    "authors": [
      "Takeshi D. Itoh",
      "Takatomi Kubo",
      "Kazushi Ikeda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01488"
  },
  {
    "id": "arXiv:2103.01546",
    "title": "Real Masks and Spoof Faces: On the Masked Face Presentation Attack  Detection",
    "abstract": "Comments: Accepted at Pattern Recognition",
    "descriptor": "\nComments: Accepted at Pattern Recognition\n",
    "authors": [
      "Meiling Fang",
      "Naser Damer",
      "Florian Kirchbuchner",
      "Arjan Kuijper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.01546"
  },
  {
    "id": "arXiv:2103.02167",
    "title": "Touchless Palmprint Recognition based on 3D Gabor Template and Block  Feature Refinement",
    "abstract": "Comments: There are some theoretical errors",
    "descriptor": "\nComments: There are some theoretical errors\n",
    "authors": [
      "Zhaoqun Li",
      "Xu Liang",
      "Dandan Fan",
      "Jinxing Li",
      "Wei Jia",
      "David Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.02167"
  },
  {
    "id": "arXiv:2103.02696",
    "title": "On the Importance of Sampling in Training GCNs: Tighter Analysis and  Variance Reduction",
    "abstract": "On the Importance of Sampling in Training GCNs: Tighter Analysis and  Variance Reduction",
    "descriptor": "",
    "authors": [
      "Weilin Cong",
      "Morteza Ramezani",
      "Mehrdad Mahdavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.02696"
  },
  {
    "id": "arXiv:2103.03319",
    "title": "Self-supervised 3D Representation Learning of Dressed Humans from Social  Media Videos",
    "abstract": "Self-supervised 3D Representation Learning of Dressed Humans from Social  Media Videos",
    "descriptor": "",
    "authors": [
      "Yasamin Jafarian",
      "Hyun Soo Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03319"
  },
  {
    "id": "arXiv:2103.04629",
    "title": "Jordan-Wigner transformation and qubits with nontrivial exchange rule",
    "abstract": "Comments: LaTeX, 12pt, 16 pages. Comments are welcome. v3: Conclusion added. Conference Quantum Informatics, Moscow, 2021",
    "descriptor": "\nComments: LaTeX, 12pt, 16 pages. Comments are welcome. v3: Conclusion added. Conference Quantum Informatics, Moscow, 2021\n",
    "authors": [
      "Alexander Yu. Vlasov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2103.04629"
  },
  {
    "id": "arXiv:2103.05825",
    "title": "ELLA: Exploration through Learned Language Abstraction",
    "abstract": "Comments: 19 pages, 9 figures. Published in Conference on Neural Information Processing Systems (NeurIPS) 2021. Appendix includes supplementary experiments",
    "descriptor": "\nComments: 19 pages, 9 figures. Published in Conference on Neural Information Processing Systems (NeurIPS) 2021. Appendix includes supplementary experiments\n",
    "authors": [
      "Suvir Mirchandani",
      "Siddharth Karamcheti",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.05825"
  },
  {
    "id": "arXiv:2103.06624",
    "title": "Beta-CROWN: Efficient Bound Propagation with Per-neuron Split  Constraints for Complete and Incomplete Neural Network Robustness  Verification",
    "abstract": "Comments: Shiqi Wang, Huan Zhang and Kaidi Xu contributed equally. Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Shiqi Wang, Huan Zhang and Kaidi Xu contributed equally. Accepted by NeurIPS 2021\n",
    "authors": [
      "Shiqi Wang",
      "Huan Zhang",
      "Kaidi Xu",
      "Xue Lin",
      "Suman Jana",
      "Cho-Jui Hsieh",
      "J. Zico Kolter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.06624"
  },
  {
    "id": "arXiv:2103.06647",
    "title": "Compiler-Guided Throughput Scheduling for Many-core Machines",
    "abstract": "Compiler-Guided Throughput Scheduling for Many-core Machines",
    "descriptor": "",
    "authors": [
      "Girish Mururu",
      "Sharjeel Khan",
      "Bodhisatwa Chatterjee",
      "Chao Chen",
      "Chris Porter",
      "Ada Gavrilovska",
      "Santosh Pande"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2103.06647"
  },
  {
    "id": "arXiv:2103.08922",
    "title": "Combining Morphological and Histogram based Text Line Segmentation in  the OCR Context",
    "abstract": "Comments: Journal of Data Mining and Digital Humanities; Small adjustments",
    "descriptor": "\nComments: Journal of Data Mining and Digital Humanities; Small adjustments\n",
    "authors": [
      "Pit Schneider"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.08922"
  },
  {
    "id": "arXiv:2103.09323",
    "title": "Intelligent Reflecting Surface-aided URLLC in a Factory Automation  Scenario",
    "abstract": "Comments: Accepted by IEEE TCOM",
    "descriptor": "\nComments: Accepted by IEEE TCOM\n",
    "authors": [
      "Hong Ren",
      "Kezhi Wang",
      "Cunhua Pan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2103.09323"
  },
  {
    "id": "arXiv:2103.09333",
    "title": "Combinatorial generation via permutation languages. III. Rectangulations",
    "abstract": "Combinatorial generation via permutation languages. III. Rectangulations",
    "descriptor": "",
    "authors": [
      "Arturo Merino",
      "Torsten M\u00fctze"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2103.09333"
  },
  {
    "id": "arXiv:2103.11747",
    "title": "Handling Missing Observations with an RNN-based Prediction-Update Cycle",
    "abstract": "Comments: Accepted at the International Conference on Computer Analysis of Images and Patterns (CAIP) 2021",
    "descriptor": "\nComments: Accepted at the International Conference on Computer Analysis of Images and Patterns (CAIP) 2021\n",
    "authors": [
      "Stefan Becker",
      "Ronny Hug",
      "Wolfgang H\u00fcbner",
      "Michael Arens",
      "Brendan T. Morris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11747"
  },
  {
    "id": "arXiv:2103.11870",
    "title": "A Federated Learning Framework for Smart Grids: Securing Power Traces in  Collaborative Learning",
    "abstract": "A Federated Learning Framework for Smart Grids: Securing Power Traces in  Collaborative Learning",
    "descriptor": "",
    "authors": [
      "Haizhou Liu",
      "Xuan Zhang",
      "Xinwei Shen",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.11870"
  },
  {
    "id": "arXiv:2103.13767",
    "title": "Patch Craft: Video Denoising by Deep Modeling and Patch Matching",
    "abstract": "Patch Craft: Video Denoising by Deep Modeling and Patch Matching",
    "descriptor": "",
    "authors": [
      "Gregory Vaksman",
      "Michael Elad",
      "Peyman Milanfar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.13767"
  },
  {
    "id": "arXiv:2103.14344",
    "title": "Second order semi-smooth Proximal Newton methods in Hilbert spaces",
    "abstract": "Comments: 31 pages, 4 figures",
    "descriptor": "\nComments: 31 pages, 4 figures\n",
    "authors": [
      "Bastian P\u00f6tzl",
      "Anton Schiela",
      "Patrick Jaap"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.14344"
  },
  {
    "id": "arXiv:2103.14510",
    "title": "Limitations on Uncloneable Encryption and Simultaneous One-Way-to-Hiding",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Christian Majenz",
      "Christian Schaffner",
      "Mehrdad Tahmasbi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.14510"
  },
  {
    "id": "arXiv:2103.15691",
    "title": "ViViT: A Video Vision Transformer",
    "abstract": "Comments: ICCV 2021. Code at this https URL",
    "descriptor": "\nComments: ICCV 2021. Code at this https URL\n",
    "authors": [
      "Anurag Arnab",
      "Mostafa Dehghani",
      "Georg Heigold",
      "Chen Sun",
      "Mario Lu\u010di\u0107",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15691"
  },
  {
    "id": "arXiv:2103.16211",
    "title": "iVPF: Numerical Invertible Volume Preserving Flow for Efficient Lossless  Compression",
    "abstract": "Comments: Accepted for CVPR 2021",
    "descriptor": "\nComments: Accepted for CVPR 2021\n",
    "authors": [
      "Shifeng Zhang",
      "Chen Zhang",
      "Ning Kang",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.16211"
  },
  {
    "id": "arXiv:2104.00793",
    "title": "Effect of Radiology Report Labeler Quality on Deep Learning Models for  Chest X-Ray Interpretation",
    "abstract": "Comments: In Neural Information Processing Systems (NeurIPS) Workshop on Data-Centric AI (DCAI)",
    "descriptor": "\nComments: In Neural Information Processing Systems (NeurIPS) Workshop on Data-Centric AI (DCAI)\n",
    "authors": [
      "Saahil Jain",
      "Akshay Smit",
      "Andrew Y. Ng",
      "Pranav Rajpurkar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.00793"
  },
  {
    "id": "arXiv:2104.02234",
    "title": "DeepEverest: Accelerating Declarative Top-K Queries for Deep Neural  Network Interpretation [Technical Report]",
    "abstract": "DeepEverest: Accelerating Declarative Top-K Queries for Deep Neural  Network Interpretation [Technical Report]",
    "descriptor": "",
    "authors": [
      "Dong He",
      "Maureen Daum",
      "Walter Cai",
      "Magdalena Balazinska"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2104.02234"
  },
  {
    "id": "arXiv:2104.02242",
    "title": "HBert + BiasCorp -- Fighting Racism on the Web",
    "abstract": "HBert + BiasCorp -- Fighting Racism on the Web",
    "descriptor": "",
    "authors": [
      "Olawale Onabola",
      "Zhuang Ma",
      "Yang Xie",
      "Benjamin Akera",
      "Abdulrahman Ibraheem",
      "Jia Xue",
      "Dianbo Liu",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.02242"
  },
  {
    "id": "arXiv:2104.02818",
    "title": "Why? Why not? When? Visual Explanations of Agent Behavior in  Reinforcement Learning",
    "abstract": "Why? Why not? When? Visual Explanations of Agent Behavior in  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Aditi Mishra",
      "Utkarsh Soni",
      "Jinbin Huang",
      "Chris Bryan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2104.02818"
  },
  {
    "id": "arXiv:2104.03066",
    "title": "Distributional Robustness Loss for Long-tail Learning",
    "abstract": "Comments: Accepted to ICCV 2021",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Dvir Samuel",
      "Gal Chechik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03066"
  },
  {
    "id": "arXiv:2104.05062",
    "title": "Achieving Model Robustness through Discrete Adversarial Training",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Maor Ivgi",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.05062"
  },
  {
    "id": "arXiv:2104.05154",
    "title": "Machine Learning Approach to Uncovering Residential Energy Consumption  Patterns Based on Socioeconomic and Smart Meter Data",
    "abstract": "Machine Learning Approach to Uncovering Residential Energy Consumption  Patterns Based on Socioeconomic and Smart Meter Data",
    "descriptor": "",
    "authors": [
      "Wenjun Tang",
      "Hao Wang",
      "Xian-Long Lee",
      "Hong-Tzer Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.05154"
  },
  {
    "id": "arXiv:2104.05859",
    "title": "Rapid Exploration for Open-World Navigation with Latent Goal Models",
    "abstract": "Comments: Accepted for presentation at 5th Annual Conference on Robot Learning (CoRL 2021), London, UK as an Oral Talk. Project page and dataset release at this https URL",
    "descriptor": "\nComments: Accepted for presentation at 5th Annual Conference on Robot Learning (CoRL 2021), London, UK as an Oral Talk. Project page and dataset release at this https URL\n",
    "authors": [
      "Dhruv Shah",
      "Benjamin Eysenbach",
      "Nicholas Rhinehart",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.05859"
  },
  {
    "id": "arXiv:2104.06714",
    "title": "Lazy Parameter Tuning and Control: Choosing All Parameters Randomly From  a Power-Law Distribution",
    "abstract": "Comments: Extended version of the paper accepted to GECCO 2021, including all the proofs omitted in the conference version",
    "descriptor": "\nComments: Extended version of the paper accepted to GECCO 2021, including all the proofs omitted in the conference version\n",
    "authors": [
      "Denis Antipov",
      "Maxim Buzdalov",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2104.06714"
  },
  {
    "id": "arXiv:2104.07085",
    "title": "Fast Walsh-Hadamard Transform and Smooth-Thresholding Based Binary  Layers in Deep Neural Networks",
    "abstract": "Comments: The paper (v1) has been accepted to CVPR 2021 BiVision Workshop. We notice the final Conv2D is also a 1x1 convolution layer so we update the result with changing the layer in v2. In v3, we update citation 37 because its authorship changes. In v4, we propose the improved version of smooth thresholding called \"weighted smooth thresholding\"",
    "descriptor": "\nComments: The paper (v1) has been accepted to CVPR 2021 BiVision Workshop. We notice the final Conv2D is also a 1x1 convolution layer so we update the result with changing the layer in v2. In v3, we update citation 37 because its authorship changes. In v4, we propose the improved version of smooth thresholding called \"weighted smooth thresholding\"\n",
    "authors": [
      "Hongyi Pan",
      "Diaa Dabawi",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.07085"
  },
  {
    "id": "arXiv:2104.10763",
    "title": "Development of Aircraft Spoiler Demonstrators for Cost-Efficient  Investigations of SHM Technologies under Quasi-Realistic Loading Conditions",
    "abstract": "Comments: 19 pages, 12 figures, published in Aerospace (ISSN 2226-4310)",
    "descriptor": "\nComments: 19 pages, 12 figures, published in Aerospace (ISSN 2226-4310)\n",
    "authors": [
      "Markus Winklberger",
      "Christoph Kralovec",
      "Martin Schagerl"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.10763"
  },
  {
    "id": "arXiv:2104.11268",
    "title": "Hyperbolicity-Preserving and Well-Balanced Stochastic Galerkin Method  for Two-Dimensional Shallow Water Equations",
    "abstract": "Hyperbolicity-Preserving and Well-Balanced Stochastic Galerkin Method  for Two-Dimensional Shallow Water Equations",
    "descriptor": "",
    "authors": [
      "Dihan Dai",
      "Yekaterina Epshteyn",
      "Akil Narayan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.11268"
  },
  {
    "id": "arXiv:2104.11470",
    "title": "Random Noise Defense Against Query-Based Black-Box Attacks",
    "abstract": "Comments: NeurIPS 2021 poster paper",
    "descriptor": "\nComments: NeurIPS 2021 poster paper\n",
    "authors": [
      "Zeyu Qin",
      "Yanbo Fan",
      "Hongyuan Zha",
      "Baoyuan Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.11470"
  },
  {
    "id": "arXiv:2104.11510",
    "title": "Time Series Forecasting via Learning Convolutionally Low-Rank Models",
    "abstract": "Time Series Forecasting via Learning Convolutionally Low-Rank Models",
    "descriptor": "",
    "authors": [
      "Guangcan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.11510"
  },
  {
    "id": "arXiv:2104.11559",
    "title": "Optimizing small BERTs trained for German NER",
    "abstract": "Optimizing small BERTs trained for German NER",
    "descriptor": "",
    "authors": [
      "Jochen Z\u00f6llner",
      "Konrad Sperfeld",
      "Christoph Wick",
      "Roger Labahn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.11559"
  },
  {
    "id": "arXiv:2104.12615",
    "title": "Evaluating Query Languages and Systems for High-Energy Physics Data  [Extended Version]",
    "abstract": "Comments: This is the extended version of a full paper to appear in PVLDB 15.2 (VLDB 2022)",
    "descriptor": "\nComments: This is the extended version of a full paper to appear in PVLDB 15.2 (VLDB 2022)\n",
    "authors": [
      "Dan Graur",
      "Ingo M\u00fcller",
      "Mason Proffitt",
      "Ghislain Fourny",
      "Gordon T. Watts",
      "Gustavo Alonso"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2104.12615"
  },
  {
    "id": "arXiv:2104.14657",
    "title": "Revisiting the dynamics of Bose-Einstein condensates in a double well by  deep learning with a hybrid network",
    "abstract": "Comments: 11 pages, 8 figures",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Shurui Li",
      "Jianqin Xu",
      "Jing Qian",
      "Weiping Zhang"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.14657"
  },
  {
    "id": "arXiv:2105.00309",
    "title": "PREDICT: Persian Reverse Dictionary",
    "abstract": "PREDICT: Persian Reverse Dictionary",
    "descriptor": "",
    "authors": [
      "Arman Malekzadeh",
      "Amin Gheibi",
      "Ali Mohades"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.00309"
  },
  {
    "id": "arXiv:2105.06791",
    "title": "Agree to Disagree: When Deep Learning Models With Identical  Architectures Produce Distinct Explanations",
    "abstract": "Comments: 9 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 9 pages, 5 figures, 3 tables\n",
    "authors": [
      "Matthew Watson",
      "Bashar Awwad Shiekh Hasan",
      "Noura Al Moubayed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.06791"
  },
  {
    "id": "arXiv:2105.07540",
    "title": "Deep learning for detecting pulmonary tuberculosis via chest  radiography: an international study across 10 countries",
    "abstract": "Deep learning for detecting pulmonary tuberculosis via chest  radiography: an international study across 10 countries",
    "descriptor": "",
    "authors": [
      "Sahar Kazemzadeh",
      "Jin Yu",
      "Shahar Jamshy",
      "Rory Pilgrim",
      "Zaid Nabulsi",
      "Christina Chen",
      "Neeral Beladia",
      "Charles Lau",
      "Scott Mayer McKinney",
      "Thad Hughes",
      "Atilla Kiraly",
      "Sreenivasa Raju Kalidindi",
      "Monde Muyoyeta",
      "Jameson Malemela",
      "Ting Shih",
      "Greg S. Corrado",
      "Lily Peng",
      "Katherine Chou",
      "Po-Hsuan Cameron Chen",
      "Yun Liu",
      "Krish Eswaran",
      "Daniel Tse",
      "Shravya Shetty",
      "Shruthi Prabhakara"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07540"
  },
  {
    "id": "arXiv:2105.08847",
    "title": "Beyond \"Fairness:\" Structural (In)justice Lenses on AI for Education",
    "abstract": "Comments: To be published in: The Ethics of Artificial Intelligence in Education: Current Challenges, Practices and Debates, W. Holmesand K. Porayska-Pomsta (Eds.), Routledge. This revision incorporates reviewer feedback and updates the title to reflect the current book chapter title",
    "descriptor": "\nComments: To be published in: The Ethics of Artificial Intelligence in Education: Current Challenges, Practices and Debates, W. Holmesand K. Porayska-Pomsta (Eds.), Routledge. This revision incorporates reviewer feedback and updates the title to reflect the current book chapter title\n",
    "authors": [
      "Michael Madaio",
      "Su Lin Blodgett",
      "Elijah Mayfield",
      "Ezekiel Dixon-Rom\u00e1n"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.08847"
  },
  {
    "id": "arXiv:2105.08886",
    "title": "Towards Trusted and Intelligent Cyber-Physical Systems: A  Security-by-Design Approach",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Sabah Suhail",
      "Raja Jurdak",
      "Raimundas Matulevi\u010dius"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.08886"
  },
  {
    "id": "arXiv:2105.09536",
    "title": "On the $\u03b1$-lazy version of Markov chains in estimation and testing  problems",
    "abstract": "On the $\u03b1$-lazy version of Markov chains in estimation and testing  problems",
    "descriptor": "",
    "authors": [
      "Sela Fried",
      "Geoffrey Wolfer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09536"
  },
  {
    "id": "arXiv:2105.09666",
    "title": "On the Optimization of Behavioral Logic Locking for High-Level Synthesis",
    "abstract": "Comments: Submitted to IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems\n",
    "authors": [
      "Christian Pilato",
      "Luca Collini",
      "Luca Cassano",
      "Donatella Sciuto",
      "Siddharth Garg",
      "Ramesh Karri"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.09666"
  },
  {
    "id": "arXiv:2105.10591",
    "title": "Detecting Treatment Effect Modifiers in Social Networks",
    "abstract": "Detecting Treatment Effect Modifiers in Social Networks",
    "descriptor": "",
    "authors": [
      "Amir Gilad",
      "Harsh Parikh",
      "Sudeepa Roy",
      "Babak Salimi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.10591"
  },
  {
    "id": "arXiv:2105.13937",
    "title": "Polygonal Unadjusted Langevin Algorithms: Creating stable and efficient  adaptive algorithms for neural networks",
    "abstract": "Polygonal Unadjusted Langevin Algorithms: Creating stable and efficient  adaptive algorithms for neural networks",
    "descriptor": "",
    "authors": [
      "Dong-Young Lim",
      "Sotirios Sabanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13937"
  },
  {
    "id": "arXiv:2105.13980",
    "title": "Coloring Trees in Massively Parallel Computation",
    "abstract": "Coloring Trees in Massively Parallel Computation",
    "descriptor": "",
    "authors": [
      "Rustam Latypov",
      "Jara Uitto"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.13980"
  },
  {
    "id": "arXiv:2105.14260",
    "title": "Understanding Bandits with Graph Feedback",
    "abstract": "Comments: To be published in NeurIPS'21",
    "descriptor": "\nComments: To be published in NeurIPS'21\n",
    "authors": [
      "Houshuang Chen",
      "Zengfeng Huang",
      "Shuai Li",
      "Chihao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14260"
  },
  {
    "id": "arXiv:2105.14995",
    "title": "Choose a Transformer: Fourier or Galerkin",
    "abstract": "Comments: 35 pages, 13 figures. Published as a conference paper at NeurIPS 2021",
    "descriptor": "\nComments: 35 pages, 13 figures. Published as a conference paper at NeurIPS 2021\n",
    "authors": [
      "Shuhao Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14995"
  },
  {
    "id": "arXiv:2106.00072",
    "title": "Early Detection of COVID-19 Hotspots Using Spatio-Temporal Data",
    "abstract": "Early Detection of COVID-19 Hotspots Using Spatio-Temporal Data",
    "descriptor": "",
    "authors": [
      "Shixiang Zhu",
      "Alexander Bukharin",
      "Liyan Xie",
      "Khurram Yamin",
      "Shihao Yang",
      "Pinar Keskinocak",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.00072"
  },
  {
    "id": "arXiv:2106.00463",
    "title": "Instance-optimal Mean Estimation Under Differential Privacy",
    "abstract": "Instance-optimal Mean Estimation Under Differential Privacy",
    "descriptor": "",
    "authors": [
      "Ziyue Huang",
      "Yuting Liang",
      "Ke Yi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.00463"
  },
  {
    "id": "arXiv:2106.00908",
    "title": "TransMIL: Transformer based Correlated Multiple Instance Learning for  Whole Slide Image Classification",
    "abstract": "TransMIL: Transformer based Correlated Multiple Instance Learning for  Whole Slide Image Classification",
    "descriptor": "",
    "authors": [
      "Zhuchen Shao",
      "Hao Bian",
      "Yang Chen",
      "Yifeng Wang",
      "Jian Zhang",
      "Xiangyang Ji",
      "Yongbing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00908"
  },
  {
    "id": "arXiv:2106.02129",
    "title": "The Algorithmic Phase Transition of Random $k$-SAT for Low Degree  Polynomials",
    "abstract": "Comments: 59 pages, 1 table. Added hardness result against local algorithms and stronger achievability guarantees. To appear in FOCS 2021",
    "descriptor": "\nComments: 59 pages, 1 table. Added hardness result against local algorithms and stronger achievability guarantees. To appear in FOCS 2021\n",
    "authors": [
      "Guy Bresler",
      "Brice Huang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02129"
  },
  {
    "id": "arXiv:2106.02195",
    "title": "Celebrating Diversity in Shared Multi-Agent Reinforcement Learning",
    "abstract": "Celebrating Diversity in Shared Multi-Agent Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Chenghao Li",
      "Tonghan Wang",
      "Chengjie Wu",
      "Qianchuan Zhao",
      "Jun Yang",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02195"
  },
  {
    "id": "arXiv:2106.02261",
    "title": "Out-of-Distribution Generalization in Kernel Regression",
    "abstract": "Out-of-Distribution Generalization in Kernel Regression",
    "descriptor": "",
    "authors": [
      "Abdulkadir Canatar",
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02261"
  },
  {
    "id": "arXiv:2106.02522",
    "title": "Price graphs: Utilizing the structural information of financial time  series for stock prediction",
    "abstract": "Comments: Code and data can be accessed through this https URL",
    "descriptor": "\nComments: Code and data can be accessed through this https URL\n",
    "authors": [
      "Junran Wu",
      "Ke Xu",
      "Xueyuan Chen",
      "Shangzhe Li",
      "Jichang Zhao"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02522"
  },
  {
    "id": "arXiv:2106.02638",
    "title": "Associating Objects with Transformers for Video Object Segmentation",
    "abstract": "Comments: NeurIPS 2021. 20 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: NeurIPS 2021. 20 pages, 9 figures, 5 tables\n",
    "authors": [
      "Zongxin Yang",
      "Yunchao Wei",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02638"
  },
  {
    "id": "arXiv:2106.02733",
    "title": "DISCO: accurate Discrete Scale Convolutions",
    "abstract": "DISCO: accurate Discrete Scale Convolutions",
    "descriptor": "",
    "authors": [
      "Ivan Sosnovik",
      "Artem Moskalev",
      "Arnold Smeulders"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02733"
  },
  {
    "id": "arXiv:2106.02745",
    "title": "Neural Auto-Curricula",
    "abstract": "Comments: corresponding to &lt;yaodong.yang@outlook.com&gt;",
    "descriptor": "\nComments: corresponding to &lt;yaodong.yang@outlook.com&gt;\n",
    "authors": [
      "Xidong Feng",
      "Oliver Slumbers",
      "Ziyu Wan",
      "Bo Liu",
      "Stephen McAleer",
      "Ying Wen",
      "Jun Wang",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.02745"
  },
  {
    "id": "arXiv:2106.02925",
    "title": "Tensor Normal Training for Deep Learning Models",
    "abstract": "Tensor Normal Training for Deep Learning Models",
    "descriptor": "",
    "authors": [
      "Yi Ren",
      "Donald Goldfarb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02925"
  },
  {
    "id": "arXiv:2106.03114",
    "title": "Leveraging spectral analysis to elucidate membrane locking and unlocking  in isogeometric finite element formulations of the curved Euler-Bernoulli  beam",
    "abstract": "Leveraging spectral analysis to elucidate membrane locking and unlocking  in isogeometric finite element formulations of the curved Euler-Bernoulli  beam",
    "descriptor": "",
    "authors": [
      "Thi-Hoa Nguyen",
      "Ren\u00e9 R. Hiemstra",
      "Dominik Schillinger"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.03114"
  },
  {
    "id": "arXiv:2106.03408",
    "title": "Antipodes of Label Differential Privacy: PATE and ALIBI",
    "abstract": "Comments: 2021 Conference on Neural Information Processing Systems (NeurIPS)",
    "descriptor": "\nComments: 2021 Conference on Neural Information Processing Systems (NeurIPS)\n",
    "authors": [
      "Mani Malek",
      "Ilya Mironov",
      "Karthik Prasad",
      "Igor Shilov",
      "Florian Tram\u00e8r"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.03408"
  },
  {
    "id": "arXiv:2106.03442",
    "title": "Average-Reward Reinforcement Learning with Trust Region Methods",
    "abstract": "Comments: Accepted by IJCAI2021",
    "descriptor": "\nComments: Accepted by IJCAI2021\n",
    "authors": [
      "Xiaoteng Ma",
      "Xiaohang Tang",
      "Li Xia",
      "Jun Yang",
      "Qianchuan Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.03442"
  },
  {
    "id": "arXiv:2106.03579",
    "title": "Forward Looking Best-Response Multiplicative Weights Update Methods for  Bilinear Zero-sum Games",
    "abstract": "Forward Looking Best-Response Multiplicative Weights Update Methods for  Bilinear Zero-sum Games",
    "descriptor": "",
    "authors": [
      "Michail Fasoulakis",
      "Evangelos Markakis",
      "Yannis Pantazis",
      "Constantinos Varsos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03579"
  },
  {
    "id": "arXiv:2106.03609",
    "title": "High-Dimensional Bayesian Optimisation with Variational Autoencoders and  Deep Metric Learning",
    "abstract": "High-Dimensional Bayesian Optimisation with Variational Autoencoders and  Deep Metric Learning",
    "descriptor": "",
    "authors": [
      "Antoine Grosnit",
      "Rasul Tutunov",
      "Alexandre Max Maraval",
      "Ryan-Rhys Griffiths",
      "Alexander I. Cowen-Rivers",
      "Lin Yang",
      "Lin Zhu",
      "Wenlong Lyu",
      "Zhitang Chen",
      "Jun Wang",
      "Jan Peters",
      "Haitham Bou-Ammar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03609"
  },
  {
    "id": "arXiv:2106.03743",
    "title": "Proxy-Normalizing Activations to Match Batch Normalization while  Removing Batch Dependence",
    "abstract": "Comments: NeurIPS 2021 camera-ready",
    "descriptor": "\nComments: NeurIPS 2021 camera-ready\n",
    "authors": [
      "Antoine Labatie",
      "Dominic Masters",
      "Zach Eaton-Rosen",
      "Carlo Luschi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03743"
  },
  {
    "id": "arXiv:2106.03783",
    "title": "An Information-theoretic Approach to Distribution Shifts",
    "abstract": "An Information-theoretic Approach to Distribution Shifts",
    "descriptor": "",
    "authors": [
      "Marco Federici",
      "Ryota Tomioka",
      "Patrick Forr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.03783"
  },
  {
    "id": "arXiv:2106.04911",
    "title": "Memory-based Optimization Methods for Model-Agnostic Meta-Learning",
    "abstract": "Memory-based Optimization Methods for Model-Agnostic Meta-Learning",
    "descriptor": "",
    "authors": [
      "Bokun Wang",
      "Zhuoning Yuan",
      "Yiming Ying",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04911"
  },
  {
    "id": "arXiv:2106.05152",
    "title": "Rethink Transfer Learning in Medical Image Classification",
    "abstract": "Rethink Transfer Learning in Medical Image Classification",
    "descriptor": "",
    "authors": [
      "Le Peng",
      "Hengyue Liang",
      "Gaoxiang Luo",
      "Taihui Li",
      "Ju Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05152"
  },
  {
    "id": "arXiv:2106.05241",
    "title": "Multi-Facet Clustering Variational Autoencoders",
    "abstract": "Comments: Advances in Neural Information Processing Systems 34 (NeurIPS 2021)",
    "descriptor": "\nComments: Advances in Neural Information Processing Systems 34 (NeurIPS 2021)\n",
    "authors": [
      "Fabian Falck",
      "Haoting Zhang",
      "Matthew Willetts",
      "George Nicholson",
      "Christopher Yau",
      "Chris Holmes"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.05241"
  },
  {
    "id": "arXiv:2106.05739",
    "title": "Separation Results between Fixed-Kernel and Feature-Learning Probability  Metrics",
    "abstract": "Separation Results between Fixed-Kernel and Feature-Learning Probability  Metrics",
    "descriptor": "",
    "authors": [
      "Carles Domingo-Enrich",
      "Youssef Mroueh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.05739"
  },
  {
    "id": "arXiv:2106.06610",
    "title": "Scalars are universal: Equivariant machine learning, structured like  classical physics",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Soledad Villar",
      "David W.Hogg",
      "Kate Storey-Fisher",
      "Weichi Yao",
      "Ben Blum-Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06610"
  },
  {
    "id": "arXiv:2106.07175",
    "title": "Learning to Combine Per-Example Solutions for Neural Program Synthesis",
    "abstract": "Comments: NeurIPS 2021 (camera-ready version)",
    "descriptor": "\nComments: NeurIPS 2021 (camera-ready version)\n",
    "authors": [
      "Disha Shrivastava",
      "Hugo Larochelle",
      "Daniel Tarlow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.07175"
  },
  {
    "id": "arXiv:2106.07218",
    "title": "Physics-Aware Downsampling with Deep Learning for Scalable Flood  Modeling",
    "abstract": "Physics-Aware Downsampling with Deep Learning for Scalable Flood  Modeling",
    "descriptor": "",
    "authors": [
      "Niv Giladi",
      "Zvika Ben-Haim",
      "Sella Nevo",
      "Yossi Matias",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07218"
  },
  {
    "id": "arXiv:2106.07233",
    "title": "Minimality Notions via Factorization Systems",
    "abstract": "Minimality Notions via Factorization Systems",
    "descriptor": "",
    "authors": [
      "Thorsten Wi\u00dfmann"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2106.07233"
  },
  {
    "id": "arXiv:2106.07289",
    "title": "Decentralized Personalized Federated Min-Max Problems",
    "abstract": "Decentralized Personalized Federated Min-Max Problems",
    "descriptor": "",
    "authors": [
      "Ekaterina Borodich",
      "Aleksandr Beznosikov",
      "Abdurakhmon Sadiev",
      "Vadim Sushko",
      "Nikolay Savelyev",
      "Martin Tak\u00e1\u010d",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07289"
  },
  {
    "id": "arXiv:2106.07736",
    "title": "Unique sparse decomposition of low rank matrices",
    "abstract": "Comments: Accepted by 2021 Neurips",
    "descriptor": "\nComments: Accepted by 2021 Neurips\n",
    "authors": [
      "Dian Jin",
      "Xin Bing",
      "Yuqian Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07736"
  },
  {
    "id": "arXiv:2106.07807",
    "title": "Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with  Unlabeled Data",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Ashraful Islam",
      "Chun-Fu Chen",
      "Rameswar Panda",
      "Leonid Karlinsky",
      "Rogerio Feris",
      "Richard J. Radke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07807"
  },
  {
    "id": "arXiv:2106.07876",
    "title": "Vision-Language Navigation with Random Environmental Mixup",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Chong Liu",
      "Fengda Zhu",
      "Xiaojun Chang",
      "Xiaodan Liang",
      "Zongyuan Ge",
      "Yi-Dong Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07876"
  },
  {
    "id": "arXiv:2106.08208",
    "title": "SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients",
    "abstract": "Comments: To appear in NeurIPS 2021",
    "descriptor": "\nComments: To appear in NeurIPS 2021\n",
    "authors": [
      "Feihu Huang",
      "Junyi Li",
      "Heng Huang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08208"
  },
  {
    "id": "arXiv:2106.08567",
    "title": "Optimal Accounting of Differential Privacy via Characteristic Function",
    "abstract": "Optimal Accounting of Differential Privacy via Characteristic Function",
    "descriptor": "",
    "authors": [
      "Yuqing Zhu",
      "Jinshuo Dong",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08567"
  },
  {
    "id": "arXiv:2106.08619",
    "title": "Locality defeats the curse of dimensionality in convolutional  teacher-student scenarios",
    "abstract": "Comments: 32 pages, 7 figures",
    "descriptor": "\nComments: 32 pages, 7 figures\n",
    "authors": [
      "Alessandro Favero",
      "Francesco Cagnetta",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08619"
  },
  {
    "id": "arXiv:2106.08796",
    "title": "Tactile Sim-to-Real Policy Transfer via Real-to-Sim Image Translation",
    "abstract": "Tactile Sim-to-Real Policy Transfer via Real-to-Sim Image Translation",
    "descriptor": "",
    "authors": [
      "Alex Church",
      "John Lloyd",
      "Raia Hadsell",
      "Nathan F. Lepora"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08796"
  },
  {
    "id": "arXiv:2106.09012",
    "title": "A learning agent that acquires social norms from public sanctions in  decentralized multi-agent settings",
    "abstract": "A learning agent that acquires social norms from public sanctions in  decentralized multi-agent settings",
    "descriptor": "",
    "authors": [
      "Eugene Vinitsky",
      "Raphael K\u00f6ster",
      "John P. Agapiou",
      "Edgar Du\u00e9\u00f1ez-Guzm\u00e1n",
      "Alexander Sasha Vezhnevets",
      "Joel Z. Leibo"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.09012"
  },
  {
    "id": "arXiv:2106.09330",
    "title": "A Simple Generative Network",
    "abstract": "Comments: To be published at ISVC 2021",
    "descriptor": "\nComments: To be published at ISVC 2021\n",
    "authors": [
      "Daniel N. Nissani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.09330"
  },
  {
    "id": "arXiv:2106.12253",
    "title": "Harmonic Power-Flow Study of Polyphase Grids with Converter-Interfaced  Distributed Energy Resources, Part I: Modelling Framework and Algorithm",
    "abstract": "Harmonic Power-Flow Study of Polyphase Grids with Converter-Interfaced  Distributed Energy Resources, Part I: Modelling Framework and Algorithm",
    "descriptor": "",
    "authors": [
      "Andreas Martin Kettner",
      "Lorenzo Reyes-Chamorro",
      "Johanna Kristin Maria Becker",
      "Zhixiang Zou",
      "Marco Liserre",
      "Mario Paolone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.12253"
  },
  {
    "id": "arXiv:2106.12255",
    "title": "Harmonic Power-Flow Study of Polyphase Grids with Converter-Interfaced  Distributed Energy Resources, Part II: Model Library and Validation",
    "abstract": "Harmonic Power-Flow Study of Polyphase Grids with Converter-Interfaced  Distributed Energy Resources, Part II: Model Library and Validation",
    "descriptor": "",
    "authors": [
      "Johanna Kristin Maria Becker",
      "Andreas Martin Kettner",
      "Lorenzo Reyes-Chamorro",
      "Zhixiang Zou",
      "Marco Liserre",
      "Mario Paolone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.12255"
  },
  {
    "id": "arXiv:2106.12753",
    "title": "DeepAuditor: Distributed Online Intrusion Detection System for IoT  devices via Power Side-channel Auditing",
    "abstract": "DeepAuditor: Distributed Online Intrusion Detection System for IoT  devices via Power Side-channel Auditing",
    "descriptor": "",
    "authors": [
      "Woosub Jung",
      "Yizhou Feng",
      "Sabbir Ahmed Khan",
      "Chunsheng Xin",
      "Danella Zhao",
      "Gang Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12753"
  },
  {
    "id": "arXiv:2106.13897",
    "title": "Implicit Gradient Alignment in Distributed and Federated Learning",
    "abstract": "Comments: Accepted at FL-ICML 2021: International Workshop on Federated Learning for User Privacy and Data Confidentiality in Conjunction with ICML 2021",
    "descriptor": "\nComments: Accepted at FL-ICML 2021: International Workshop on Federated Learning for User Privacy and Data Confidentiality in Conjunction with ICML 2021\n",
    "authors": [
      "Yatin Dandi",
      "Luis Barba",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13897"
  },
  {
    "id": "arXiv:2106.14054",
    "title": "Evaluation of Cache Attacks on Arm Processors and Secure Caches",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Shuwen Deng",
      "Nikolay Matyunin",
      "Wenjie Xiong",
      "Stefan Katzenbeisser",
      "Jakub Szefer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.14054"
  },
  {
    "id": "arXiv:2106.14806",
    "title": "Laplace Redux -- Effortless Bayesian Deep Learning",
    "abstract": "Comments: NeurIPS 2021 camera-ready version; source code: this https URL",
    "descriptor": "\nComments: NeurIPS 2021 camera-ready version; source code: this https URL\n",
    "authors": [
      "Erik Daxberger",
      "Agustinus Kristiadi",
      "Alexander Immer",
      "Runa Eschenhagen",
      "Matthias Bauer",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.14806"
  },
  {
    "id": "arXiv:2106.14855",
    "title": "K-Net: Towards Unified Image Segmentation",
    "abstract": "Comments: Camera ready for NeurIPS2021",
    "descriptor": "\nComments: Camera ready for NeurIPS2021\n",
    "authors": [
      "Wenwei Zhang",
      "Jiangmiao Pang",
      "Kai Chen",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.14855"
  },
  {
    "id": "arXiv:2106.15054",
    "title": "Time-Domain Doppler Biomotion Detections Immune to Unavoidable DC  Offsets",
    "abstract": "Comments: Accepted by IEEE Transactions on Instrumentation & Measurement",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Instrumentation & Measurement\n",
    "authors": [
      "Qinyi Lv",
      "Lingtong Min",
      "Congqi Cao",
      "Shigang Zhou",
      "Deyun Zhou",
      "Chengkai Zhu",
      "Yun Li",
      "Zhongbo Zhu",
      "Xiaojun Li",
      "Lixin Ran"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15054"
  },
  {
    "id": "arXiv:2107.00422",
    "title": "Generating Synthetic Training Data for Deep Learning-Based UAV  Trajectory Prediction",
    "abstract": "Comments: Accepted at the International Conference on Robotics, Computer Vision and Intelligent Systems (ROBOVIS) 2021",
    "descriptor": "\nComments: Accepted at the International Conference on Robotics, Computer Vision and Intelligent Systems (ROBOVIS) 2021\n",
    "authors": [
      "Stefan Becker",
      "Ronny Hug",
      "Wolfgang H\u00fcbner",
      "Michael Arens",
      "Brendan T. Morris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00422"
  },
  {
    "id": "arXiv:2107.00591",
    "title": "Offline-to-Online Reinforcement Learning via Balanced Replay and  Pessimistic Q-Ensemble",
    "abstract": "Comments: CoRL 2021. First two authors contributed equally",
    "descriptor": "\nComments: CoRL 2021. First two authors contributed equally\n",
    "authors": [
      "Seunghyun Lee",
      "Younggyo Seo",
      "Kimin Lee",
      "Pieter Abbeel",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00591"
  },
  {
    "id": "arXiv:2107.01510",
    "title": "Directed Percolation in Temporal Networks",
    "abstract": "Comments: Implementation available at this https URL",
    "descriptor": "\nComments: Implementation available at this https URL\n",
    "authors": [
      "Arash Badie-Modiri",
      "Abbas K. Rizi",
      "M\u00e1rton Karsai",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.01510"
  },
  {
    "id": "arXiv:2107.01729",
    "title": "Hebbian learning with gradients: Hebbian convolutional neural networks  with modern deep learning frameworks",
    "abstract": "Comments: All code available at this https URL",
    "descriptor": "\nComments: All code available at this https URL\n",
    "authors": [
      "Thomas Miconi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.01729"
  },
  {
    "id": "arXiv:2107.02071",
    "title": "Unsupervised Ensemble Selection for Multilayer Bootstrap Networks",
    "abstract": "Unsupervised Ensemble Selection for Multilayer Bootstrap Networks",
    "descriptor": "",
    "authors": [
      "Xiao-Lei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02071"
  },
  {
    "id": "arXiv:2107.02233",
    "title": "End-to-End Weak Supervision",
    "abstract": "End-to-End Weak Supervision",
    "descriptor": "",
    "authors": [
      "Salva R\u00fchling Cachay",
      "Benedikt Boecking",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.02233"
  },
  {
    "id": "arXiv:2107.03022",
    "title": "Reconstructing Test Labels from Noisy Loss Functions",
    "abstract": "Comments: Accepted at NeurIPS 2021 Workshop on Privacy in Machine Learning (PriML)",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 Workshop on Privacy in Machine Learning (PriML)\n",
    "authors": [
      "Abhinav Aggarwal",
      "Shiva Prasad Kasiviswanathan",
      "Zekun Xu",
      "Oluwaseyi Feyisetan",
      "Nathanael Teissier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.03022"
  },
  {
    "id": "arXiv:2107.03919",
    "title": "Understanding the Limits of Unsupervised Domain Adaptation via Data  Poisoning",
    "abstract": "Comments: Neurips 2021",
    "descriptor": "\nComments: Neurips 2021\n",
    "authors": [
      "Akshay Mehra",
      "Bhavya Kailkhura",
      "Pin-Yu Chen",
      "Jihun Hamm"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.03919"
  },
  {
    "id": "arXiv:2107.04150",
    "title": "MCMC Variational Inference via Uncorrected Hamiltonian Annealing",
    "abstract": "Comments: Published at NeurIPS (2021)",
    "descriptor": "\nComments: Published at NeurIPS (2021)\n",
    "authors": [
      "Tomas Geffner",
      "Justin Domke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.04150"
  },
  {
    "id": "arXiv:2107.05038",
    "title": "Multilingual and crosslingual speech recognition using  phonological-vector based phone embeddings",
    "abstract": "Comments: ASRU2021",
    "descriptor": "\nComments: ASRU2021\n",
    "authors": [
      "Chengrui Zhu",
      "Keyu An",
      "Huahuan Zheng",
      "Zhijian Ou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.05038"
  },
  {
    "id": "arXiv:2107.05434",
    "title": "Polynomial-time algorithm for Maximum Independent Set in bounded-degree  graphs with no long induced claws",
    "abstract": "Polynomial-time algorithm for Maximum Independent Set in bounded-degree  graphs with no long induced claws",
    "descriptor": "",
    "authors": [
      "Tara Abrishami",
      "Maria Chudnovsky",
      "Cemil Dibek",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.05434"
  },
  {
    "id": "arXiv:2107.05822",
    "title": "Multi-token Markov Game with Switching Costs",
    "abstract": "Comments: Accepted by SODA2022",
    "descriptor": "\nComments: Accepted by SODA2022\n",
    "authors": [
      "Jian Li",
      "Daogao Liu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.05822"
  },
  {
    "id": "arXiv:2107.06278",
    "title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation",
    "abstract": "Comments: NeurIPS 2021, Spotlight. Project page: this https URL",
    "descriptor": "\nComments: NeurIPS 2021, Spotlight. Project page: this https URL\n",
    "authors": [
      "Bowen Cheng",
      "Alexander G. Schwing",
      "Alexander Kirillov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06278"
  },
  {
    "id": "arXiv:2107.07013",
    "title": "Passive Attention in Artificial Neural Networks Predicts Human Visual  Selectivity",
    "abstract": "Passive Attention in Artificial Neural Networks Predicts Human Visual  Selectivity",
    "descriptor": "",
    "authors": [
      "Thomas A. Langlois",
      "H. Charles Zhao",
      "Erin Grant",
      "Ishita Dasgupta",
      "Thomas L. Griffiths",
      "Nori Jacoby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07013"
  },
  {
    "id": "arXiv:2107.07171",
    "title": "DeceFL: A Principled Decentralized Federated Learning Framework",
    "abstract": "DeceFL: A Principled Decentralized Federated Learning Framework",
    "descriptor": "",
    "authors": [
      "Ye Yuan",
      "Jun Liu",
      "Dou Jin",
      "Zuogong Yue",
      "Ruijuan Chen",
      "Maolin Wang",
      "Chuan Sun",
      "Lei Xu",
      "Feng Hua",
      "Xin He",
      "Xinlei Yi",
      "Tao Yang",
      "Hai-Tao Zhang",
      "Shaochun Sui",
      "Han Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07171"
  },
  {
    "id": "arXiv:2107.07746",
    "title": "Rectifying the Shortcut Learning of Background for Few-Shot Learning",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Xu Luo",
      "Longhui Wei",
      "Liangjian Wen",
      "Jinrong Yang",
      "Lingxi Xie",
      "Zenglin Xu",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07746"
  },
  {
    "id": "arXiv:2107.08310",
    "title": "FairBalance: Improving Machine Learning Fairness on MultipleSensitive  Attributes With Data Balancing",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Zhe Yu",
      "Joymallya Chakraborty",
      "Tim Menzies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.08310"
  },
  {
    "id": "arXiv:2107.08921",
    "title": "Dormancy-aware timed branching bisimilarity for timed analysis of  communication protocols",
    "abstract": "Comments: 38 pages, revision of v2, presentation improved at several places",
    "descriptor": "\nComments: 38 pages, revision of v2, presentation improved at several places\n",
    "authors": [
      "C.A. Middelburg"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.08921"
  },
  {
    "id": "arXiv:2107.09286",
    "title": "ByPE-VAE: Bayesian Pseudocoresets Exemplar VAE",
    "abstract": "Comments: NeurIPS21",
    "descriptor": "\nComments: NeurIPS21\n",
    "authors": [
      "Qingzhong Ai",
      "Lirong He",
      "Shiyu Liu",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.09286"
  },
  {
    "id": "arXiv:2107.09833",
    "title": "Leaking Secrets through Modern Branch Predictor in the Speculative World",
    "abstract": "Comments: Camera ready version will appear in a future issue of IEEE Transactions on Computers (TC). DOI: this https URL",
    "descriptor": "\nComments: Camera ready version will appear in a future issue of IEEE Transactions on Computers (TC). DOI: this https URL\n",
    "authors": [
      "Md Hafizul Islam Chowdhuryy",
      "Fan Yao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.09833"
  },
  {
    "id": "arXiv:2107.11080",
    "title": "Comments on lumping the Google matrix",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Yongxin Dong",
      "Yuehua Feng",
      "Jianxin You",
      "Jinrui Guan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.11080"
  },
  {
    "id": "arXiv:2107.14702",
    "title": "Towards General Function Approximation in Zero-Sum Markov Games",
    "abstract": "Towards General Function Approximation in Zero-Sum Markov Games",
    "descriptor": "",
    "authors": [
      "Baihe Huang",
      "Jason D. Lee",
      "Zhaoran Wang",
      "Zhuoran Yang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.14702"
  },
  {
    "id": "arXiv:2108.00225",
    "title": "Solving Constrained Horn Clauses over ADTs by Finite Model Finding",
    "abstract": "Comments: The paper is a shrinked version of our paper arXiv:2104.04463",
    "descriptor": "\nComments: The paper is a shrinked version of our paper arXiv:2104.04463\n",
    "authors": [
      "Yurii Kostyukov",
      "Dmitry Mordvinov",
      "Grigory Fedyukovich"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2108.00225"
  },
  {
    "id": "arXiv:2108.00542",
    "title": "Stable Voting",
    "abstract": "Comments: Updated Section 2, fixed typos in the proof of Proposition 4.1, added Proposition 4.4, and added a link to this https URL",
    "descriptor": "\nComments: Updated Section 2, fixed typos in the proof of Proposition 4.1, added Proposition 4.4, and added a link to this https URL\n",
    "authors": [
      "Wesley H. Holliday",
      "Eric Pacuit"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2108.00542"
  },
  {
    "id": "arXiv:2108.00889",
    "title": "Resilience of Well-structured Graph Transformation Systems",
    "abstract": "Comments: 20 pages, 9 figures, GCM 2021",
    "descriptor": "\nComments: 20 pages, 9 figures, GCM 2021\n",
    "authors": [
      "Okan \u00d6zkan",
      "Nick W\u00fcrdemann"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2108.00889"
  },
  {
    "id": "arXiv:2108.01598",
    "title": "Secure and Efficient Blockchain based Knowledge Sharing for Intelligent  Connected Vehicles",
    "abstract": "Comments: 12 pages, 11 figures",
    "descriptor": "\nComments: 12 pages, 11 figures\n",
    "authors": [
      "Haoye Chai",
      "Supeng Leng",
      "Fan Wu",
      "Jianhua He"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.01598"
  },
  {
    "id": "arXiv:2108.04063",
    "title": "Co-learning: Learning from Noisy Labels with Self-supervision",
    "abstract": "Comments: ACM Multimedia 2021",
    "descriptor": "\nComments: ACM Multimedia 2021\n",
    "authors": [
      "Cheng Tan",
      "Jun Xia",
      "Lirong Wu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04063"
  },
  {
    "id": "arXiv:2108.04728",
    "title": "Box-Aware Feature Enhancement for Single Object Tracking on Point Clouds",
    "abstract": "Comments: Accepted by ICCV 2021",
    "descriptor": "\nComments: Accepted by ICCV 2021\n",
    "authors": [
      "Chaoda Zheng",
      "Xu Yan",
      "Jiantao Gao",
      "Weibing Zhao",
      "Wei Zhang",
      "Zhen Li",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.04728"
  },
  {
    "id": "arXiv:2108.07313",
    "title": "Fine-tuning in Federated Learning: a simple but tough-to-beat baseline",
    "abstract": "Comments: 43 pages (11 main pages, 2 reference pages, 30 appendix pages), 13 figures",
    "descriptor": "\nComments: 43 pages (11 main pages, 2 reference pages, 30 appendix pages), 13 figures\n",
    "authors": [
      "Gary Cheng",
      "Karan Chadha",
      "John Duchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.07313"
  },
  {
    "id": "arXiv:2108.09147",
    "title": "Convolutional Neural Network (CNN) vs Vision Transformer (ViT) for  Digital Holography",
    "abstract": "Comments: 6 pages, 11 figures, ICCCR 2022 Conference",
    "descriptor": "\nComments: 6 pages, 11 figures, ICCCR 2022 Conference\n",
    "authors": [
      "St\u00e9phane Cuenat",
      "Rapha\u00ebl Couturier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2108.09147"
  },
  {
    "id": "arXiv:2108.09265",
    "title": "Efficient Online Estimation of Causal Effects by Deciding What to  Observe",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Shantanu Gupta",
      "Zachary C. Lipton",
      "David Childers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.09265"
  },
  {
    "id": "arXiv:2108.10390",
    "title": "Reachability of weakly nonlinear systems using Carleman linearization",
    "abstract": "Reachability of weakly nonlinear systems using Carleman linearization",
    "descriptor": "",
    "authors": [
      "Marcelo Forets",
      "Christian Schilling"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Mathematical Software (cs.MS)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.10390"
  },
  {
    "id": "arXiv:2108.11791",
    "title": "Multiple Sclerosis Lesions Identification/Segmentation in Magnetic  Resonance Imaging using Ensemble CNN and Uncertainty Classification",
    "abstract": "Multiple Sclerosis Lesions Identification/Segmentation in Magnetic  Resonance Imaging using Ensemble CNN and Uncertainty Classification",
    "descriptor": "",
    "authors": [
      "Giuseppe Placidi",
      "Luigi Cinque",
      "Filippo Mignosi",
      "Matteo Polsinelli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11791"
  },
  {
    "id": "arXiv:2108.12617",
    "title": "AP-10K: A Benchmark for Animal Pose Estimation in the Wild",
    "abstract": "Comments: Accepted to NeurIPS 2021 Datasets and Benchmarks Track",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 Datasets and Benchmarks Track\n",
    "authors": [
      "Hang Yu",
      "Yufei Xu",
      "Jing Zhang",
      "Wei Zhao",
      "Ziyu Guan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.12617"
  },
  {
    "id": "arXiv:2108.12883",
    "title": "A closed loop gradient descent algorithm applied to Rosenbrock's  function",
    "abstract": "Comments: This paper has been accepted for the 2021 Australia and New Zealand Control Conference, to be held in November 2021",
    "descriptor": "\nComments: This paper has been accepted for the 2021 Australia and New Zealand Control Conference, to be held in November 2021\n",
    "authors": [
      "Subhransu Bhattacharjee",
      "Ian Petersen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.12883"
  },
  {
    "id": "arXiv:2108.13941",
    "title": "Bubblewrap: Online tiling and real-time flow prediction on neural  manifolds",
    "abstract": "Comments: Version of the work appearing in NeurIPS 2021",
    "descriptor": "\nComments: Version of the work appearing in NeurIPS 2021\n",
    "authors": [
      "Anne Draelos",
      "Pranjal Gupta",
      "Na Young Jun",
      "Chaichontat Sriworarat",
      "John Pearson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.13941"
  },
  {
    "id": "arXiv:2109.00637",
    "title": "Properly learning decision trees in almost polynomial time",
    "abstract": "Comments: 21 pages, to appear in FOCS 2021",
    "descriptor": "\nComments: 21 pages, to appear in FOCS 2021\n",
    "authors": [
      "Guy Blanc",
      "Jane Lange",
      "Mingda Qiao",
      "Li-Yang Tan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.00637"
  },
  {
    "id": "arXiv:2109.01115",
    "title": "Learning Language-Conditioned Robot Behavior from Offline Data and  Crowd-Sourced Annotation",
    "abstract": "Comments: Conference on Robot Learning (CoRL) 2021. 24 Pages, 18 Figures",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL) 2021. 24 Pages, 18 Figures\n",
    "authors": [
      "Suraj Nair",
      "Eric Mitchell",
      "Kevin Chen",
      "Brian Ichter",
      "Silvio Savarese",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01115"
  },
  {
    "id": "arXiv:2109.01135",
    "title": "Sequence-to-Sequence Learning with Latent Neural Grammars",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Yoon Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01135"
  },
  {
    "id": "arXiv:2109.01483",
    "title": "A Survey of the Proof-Theoretic Foundations of Logic Programming",
    "abstract": "Comments: To appear in Theory and Practice of Logic Programming (TPLP)",
    "descriptor": "\nComments: To appear in Theory and Practice of Logic Programming (TPLP)\n",
    "authors": [
      "Dale Miller"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2109.01483"
  },
  {
    "id": "arXiv:2109.01900",
    "title": "Uncovering the Limits of Text-based Emotion Detection",
    "abstract": "Comments: Accepted for publication in Findings of EMNLP 2021",
    "descriptor": "\nComments: Accepted for publication in Findings of EMNLP 2021\n",
    "authors": [
      "Nurudin Alvarez-Gonzalez",
      "Andreas Kaltenbrunner",
      "Vicen\u00e7 G\u00f3mez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01900"
  },
  {
    "id": "arXiv:2109.03150",
    "title": "Recommendation Fairness: From Static to Dynamic",
    "abstract": "Comments: A position paper for the FAccTRec-2021 workshop. Revised based on the reviewers' feedback. 6 pages",
    "descriptor": "\nComments: A position paper for the FAccTRec-2021 workshop. Revised based on the reviewers' feedback. 6 pages\n",
    "authors": [
      "Dell Zhang",
      "Jun Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03150"
  },
  {
    "id": "arXiv:2109.04797",
    "title": "Mesh convolutional neural networks for wall shear stress estimation in  3D artery models",
    "abstract": "Comments: (MICCAI 2021) Workshop on Statistical Atlases and Computational Modelling of the Heart (STACOM)",
    "descriptor": "\nComments: (MICCAI 2021) Workshop on Statistical Atlases and Computational Modelling of the Heart (STACOM)\n",
    "authors": [
      "Julian Suk",
      "Pim de Haan",
      "Phillip Lippe",
      "Christoph Brune",
      "Jelmer M. Wolterink"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2109.04797"
  },
  {
    "id": "arXiv:2109.05182",
    "title": "Speaker-Oriented Latent Structures for Dialogue-Based Relation  Extraction",
    "abstract": "Comments: The experiment part is insufficient, while we are not planning to improve it for now. To avoid potential confusion and to ensure the quality of arxiv papers, we would like to withdraw this submission",
    "descriptor": "\nComments: The experiment part is insufficient, while we are not planning to improve it for now. To avoid potential confusion and to ensure the quality of arxiv papers, we would like to withdraw this submission\n",
    "authors": [
      "Guoshun Nan",
      "Guoqing Luo",
      "Sicong Leng",
      "Yao Xiao",
      "Wei Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05182"
  },
  {
    "id": "arXiv:2109.05532",
    "title": "SDG Target Interactions: The Philippine Analysis of Indivisible and  Cancelling Targets",
    "abstract": "SDG Target Interactions: The Philippine Analysis of Indivisible and  Cancelling Targets",
    "descriptor": "",
    "authors": [
      "Vena Pearl Bongolan",
      "Arian Allenson M. Valdez",
      "Roselle Leah K. Rivera"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.05532"
  },
  {
    "id": "arXiv:2109.05599",
    "title": "DELP: Dynamic Epistemic Logic for Security Protocols",
    "abstract": "DELP: Dynamic Epistemic Logic for Security Protocols",
    "descriptor": "",
    "authors": [
      "Ioana Leustean",
      "Bogdan Macovei"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.05599"
  },
  {
    "id": "arXiv:2109.06485",
    "title": "Coo: Rethink Data Anomalies In Databases",
    "abstract": "Coo: Rethink Data Anomalies In Databases",
    "descriptor": "",
    "authors": [
      "Haixiang Li",
      "Xiaoyan Li",
      "Yuxing Chen",
      "Yuean Zhu",
      "Xiaoyong Du",
      "Wei Lu",
      "Chang Liu",
      "Anqun Pan"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2109.06485"
  },
  {
    "id": "arXiv:2109.07078",
    "title": "DSOR: A Scalable Statistical Filter for Removing Falling Snow from LiDAR  Point Clouds in Severe Winter Weather",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Akhil Kurup",
      "Jeremy Bos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07078"
  },
  {
    "id": "arXiv:2109.07883",
    "title": "Channel Estimation for Extremely Large-Scale Massive MIMO: Far-Field,  Near-Field, or Hybrid-Field?",
    "abstract": "Comments: This paper has been accepted by IEEE Communications Letters",
    "descriptor": "\nComments: This paper has been accepted by IEEE Communications Letters\n",
    "authors": [
      "Xiuhong Wei",
      "Linglong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.07883"
  },
  {
    "id": "arXiv:2109.07950",
    "title": "Learnable Multi-level Frequency Decomposition and Hierarchical Attention  Mechanism for Generalized Face Presentation Attack Detection",
    "abstract": "Comments: Accepted at IEEE Winter Conference on Applications of Computer Vision (WACV 2022)",
    "descriptor": "\nComments: Accepted at IEEE Winter Conference on Applications of Computer Vision (WACV 2022)\n",
    "authors": [
      "Meiling Fang",
      "Naser Damer",
      "Florian Kirchbuchner",
      "Arjan Kuijper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07950"
  },
  {
    "id": "arXiv:2109.08367",
    "title": "On Overcoming the Transverse Boundary Error of the SU/PG Scheme for  Moving Conductor Problems",
    "abstract": "Comments: 8 pages, 15 figures",
    "descriptor": "\nComments: 8 pages, 15 figures\n",
    "authors": [
      "Sethupathy Subramanian",
      "Udaya Kumar",
      "Sujata Bhowmick"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.08367"
  },
  {
    "id": "arXiv:2109.08722",
    "title": "Efficient Variational Graph Autoencoders for Unsupervised Cross-domain  Prerequisite Chains",
    "abstract": "Comments: Accepted by the Efficient Natural Language and Speech Processing (ENLSP) Workshop, NeurIPS 2021",
    "descriptor": "\nComments: Accepted by the Efficient Natural Language and Speech Processing (ENLSP) Workshop, NeurIPS 2021\n",
    "authors": [
      "Irene Li",
      "Vanessa Yan",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.08722"
  },
  {
    "id": "arXiv:2109.10021",
    "title": "Stabilizing Elastic Weight Consolidation method in practical ML tasks  and using weight importances for neural network pruning",
    "abstract": "Comments: 16 pages, 7 figures",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Alexey Kutalev",
      "Alisa Lapina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.10021"
  },
  {
    "id": "arXiv:2109.10780",
    "title": "Stability Assessment for Multi-Infeed Grid-Connected VSCs Modeled in the  Admittance Matrix Form",
    "abstract": "Stability Assessment for Multi-Infeed Grid-Connected VSCs Modeled in the  Admittance Matrix Form",
    "descriptor": "",
    "authors": [
      "Luis Orellana",
      "Luis Sainz",
      "Eduardo Prieto-Araujo",
      "Oriol Gomis-Bellmunt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.10780"
  },
  {
    "id": "arXiv:2109.11978",
    "title": "Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement  Learning",
    "abstract": "Comments: CoRL 2021 Project website: : this https URL Video: this https URL",
    "descriptor": "\nComments: CoRL 2021 Project website: : this https URL Video: this https URL\n",
    "authors": [
      "Nikita Rudin",
      "David Hoeller",
      "Philipp Reist",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.11978"
  },
  {
    "id": "arXiv:2109.12456",
    "title": "Auditing AI models for Verified Deployment under Semantic Specifications",
    "abstract": "Comments: Preprint; Under review",
    "descriptor": "\nComments: Preprint; Under review\n",
    "authors": [
      "Homanga Bharadhwaj",
      "De-An Huang",
      "Chaowei Xiao",
      "Anima Anandkumar",
      "Animesh Garg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12456"
  },
  {
    "id": "arXiv:2109.13916",
    "title": "Unsolved Problems in ML Safety",
    "abstract": "Comments: Position Paper",
    "descriptor": "\nComments: Position Paper\n",
    "authors": [
      "Dan Hendrycks",
      "Nicholas Carlini",
      "John Schulman",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.13916"
  },
  {
    "id": "arXiv:2109.14700",
    "title": "Safety Assurances for Human-Robot Interaction via Confidence-aware  Game-theoretic Human Models",
    "abstract": "Safety Assurances for Human-Robot Interaction via Confidence-aware  Game-theoretic Human Models",
    "descriptor": "",
    "authors": [
      "Ran Tian",
      "Liting Sun",
      "Andrea Bajcsy",
      "Masayoshi Tomizuka",
      "Anca D. Dragan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.14700"
  },
  {
    "id": "arXiv:2109.14851",
    "title": "The Deep Minimizing Movement Scheme",
    "abstract": "Comments: 27 pages, 12 figures",
    "descriptor": "\nComments: 27 pages, 12 figures\n",
    "authors": [
      "Hyung Ju Hwang",
      "Cheolhyeong Kim",
      "Min Sue Park",
      "Hwijae Son"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.14851"
  },
  {
    "id": "arXiv:2109.15062",
    "title": "Towards Principled Causal Effect Estimation by Deep Identifiable Models",
    "abstract": "Comments: Fully updated. Largely improve clarity, add identification under unconfoundedness (Sec. 4.2), and more",
    "descriptor": "\nComments: Fully updated. Largely improve clarity, add identification under unconfoundedness (Sec. 4.2), and more\n",
    "authors": [
      "Pengzhou Wu",
      "Kenji Fukumizu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.15062"
  },
  {
    "id": "arXiv:2110.00091",
    "title": "Strengthening Probabilistic Graphical Models: The Purge-and-merge  Algorithm",
    "abstract": "Strengthening Probabilistic Graphical Models: The Purge-and-merge  Algorithm",
    "descriptor": "",
    "authors": [
      "Simon Streicher",
      "Johan du Preez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00091"
  },
  {
    "id": "arXiv:2110.00841",
    "title": "Transfer Learning Approaches for Knowledge Discovery in Grid-based  Geo-Spatiotemporal Data",
    "abstract": "Transfer Learning Approaches for Knowledge Discovery in Grid-based  Geo-Spatiotemporal Data",
    "descriptor": "",
    "authors": [
      "Aishwarya Sarkar",
      "Jien Zhang",
      "Chaoqun Lu",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00841"
  },
  {
    "id": "arXiv:2110.01304",
    "title": "Synthetic Velocity Mapping Cardiac MRI Coupled with Automated Left  Ventricle Segmentation",
    "abstract": "Synthetic Velocity Mapping Cardiac MRI Coupled with Automated Left  Ventricle Segmentation",
    "descriptor": "",
    "authors": [
      "Xiaodan Xing",
      "Yinzhe Wu",
      "David Firmin",
      "Peter Gatehouse",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01304"
  },
  {
    "id": "arXiv:2110.01387",
    "title": "Machine Learning with Knowledge Constraints for Process Optimization of  Open-Air Perovskite Solar Cell Manufacturing",
    "abstract": "Machine Learning with Knowledge Constraints for Process Optimization of  Open-Air Perovskite Solar Cell Manufacturing",
    "descriptor": "",
    "authors": [
      "Zhe Liu",
      "Nicholas Rolston",
      "Austin C. Flick",
      "Thomas Colburn",
      "Zekun Ren",
      "Reinhold H. Dauskardt",
      "Tonio Buonassisi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.01387"
  },
  {
    "id": "arXiv:2110.01607",
    "title": "Using Out-of-the-Box Frameworks for Contrastive Unpaired Image  Translation for Vestibular Schwannoma and Cochlea Segmentation: An approach  for the crossMoDA Challenge",
    "abstract": "Comments: 5 pages, 1 figure, MICCAI 2021 Cross-Modality Domain Adaptation for Medical Image Segmentation Challenge; an edit to the title, extended results, and added references",
    "descriptor": "\nComments: 5 pages, 1 figure, MICCAI 2021 Cross-Modality Domain Adaptation for Medical Image Segmentation Challenge; an edit to the title, extended results, and added references\n",
    "authors": [
      "Jae Won Choi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01607"
  },
  {
    "id": "arXiv:2110.01684",
    "title": "Irreversibility of Structure Tensors of Modules",
    "abstract": "Comments: Minor fixes",
    "descriptor": "\nComments: Minor fixes\n",
    "authors": [
      "Maciej Wojtala"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2110.01684"
  },
  {
    "id": "arXiv:2110.01810",
    "title": "Deep Synoptic Monte Carlo Planning in Reconnaissance Blind Chess",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Gregory Clark"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01810"
  },
  {
    "id": "arXiv:2110.02403",
    "title": "Tradeoffs in Streaming Binary Classification under Limited Inspection  Resources",
    "abstract": "Comments: To appear in Proceedings of the ACM International Conference on AI in Finance (ICAIF '21)",
    "descriptor": "\nComments: To appear in Proceedings of the ACM International Conference on AI in Finance (ICAIF '21)\n",
    "authors": [
      "Parisa Hassanzadeh",
      "Danial Dervovic",
      "Samuel Assefa",
      "Prashant Reddy",
      "Manuela Veloso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02403"
  },
  {
    "id": "arXiv:2110.03189",
    "title": "Pointwise Bounds for Distribution Estimation under Communication  Constraints",
    "abstract": "Pointwise Bounds for Distribution Estimation under Communication  Constraints",
    "descriptor": "",
    "authors": [
      "Wei-Ning Chen",
      "Peter Kairouz",
      "Ayfer \u00d6zg\u00fcr"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.03189"
  },
  {
    "id": "arXiv:2110.03374",
    "title": "Model Adaptation: Historical Contrastive Learning for Unsupervised  Domain Adaptation without Source Data",
    "abstract": "Comments: Preliminary version release",
    "descriptor": "\nComments: Preliminary version release\n",
    "authors": [
      "Jiaxing Huang",
      "Dayan Guan",
      "Aoran Xiao",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03374"
  },
  {
    "id": "arXiv:2110.03395",
    "title": "SLASH: Embracing Probabilistic Circuits into Neural Answer Set  Programming",
    "abstract": "Comments: 16 pages, 7 figures and 5 tables",
    "descriptor": "\nComments: 16 pages, 7 figures and 5 tables\n",
    "authors": [
      "Arseny Skryagin",
      "Wolfgang Stammer",
      "Daniel Ochs",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03395"
  },
  {
    "id": "arXiv:2110.03613",
    "title": "A Data-Centric Approach for Training Deep Neural Networks with Less Data",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Mohammad Motamedi",
      "Nikolay Sakharnykh",
      "Tim Kaldewey"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03613"
  },
  {
    "id": "arXiv:2110.03761",
    "title": "A simple equivariant machine learning method for dynamics based on  scalars",
    "abstract": "A simple equivariant machine learning method for dynamics based on  scalars",
    "descriptor": "",
    "authors": [
      "Weichi Yao",
      "Kate Storey-Fisher",
      "David W. Hogg",
      "Soledad Villar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03761"
  },
  {
    "id": "arXiv:2110.03898",
    "title": "Differentiable Programming of Isometric Tensor Networks",
    "abstract": "Comments: 17 pages, 22 figures",
    "descriptor": "\nComments: 17 pages, 22 figures\n",
    "authors": [
      "Chenhua Geng",
      "Hong-Ye Hu",
      "Yijian Zou"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03898"
  },
  {
    "id": "arXiv:2110.04399",
    "title": "Global Explainability of BERT-Based Evaluation Metrics by Disentangling  along Linguistic Factors",
    "abstract": "Comments: EMNLP2021 Camera Ready",
    "descriptor": "\nComments: EMNLP2021 Camera Ready\n",
    "authors": [
      "Marvin Kaster",
      "Wei Zhao",
      "Steffen Eger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04399"
  },
  {
    "id": "arXiv:2110.04792",
    "title": "6D-ViT: Category-Level 6D Object Pose Estimation via Transformer-based  Instance Representation Learning",
    "abstract": "Comments: 13 pages, 12 figures",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Lu Zou",
      "Zhangjin Huang",
      "Naijie Gu",
      "Guoping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04792"
  },
  {
    "id": "arXiv:2110.06416",
    "title": "MMIU: Dataset for Visual Intent Understanding in Multimodal Assistants",
    "abstract": "Comments: Extended abstract accepted for WeCNLP 2021",
    "descriptor": "\nComments: Extended abstract accepted for WeCNLP 2021\n",
    "authors": [
      "Alkesh Patel",
      "Joel Ruben Antony Moniz",
      "Roman Nguyen",
      "Nick Tzou",
      "Hadas Kotek",
      "Vincent Renkens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06416"
  },
  {
    "id": "arXiv:2110.06831",
    "title": "Safe Driving via Expert Guided Policy Optimization",
    "abstract": "Safe Driving via Expert Guided Policy Optimization",
    "descriptor": "",
    "authors": [
      "Zhenghao Peng",
      "Quanyi Li",
      "Chunxiao Liu",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06831"
  },
  {
    "id": "arXiv:2110.08146",
    "title": "ACOA -- Chronological Analysis of the Exhibition of Artistic Works",
    "abstract": "ACOA -- Chronological Analysis of the Exhibition of Artistic Works",
    "descriptor": "",
    "authors": [
      "Daniela Prado",
      "Armanda Rodrigues",
      "Nuno Correia",
      "Rita Macedo",
      "Sofia Gomes"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.08146"
  },
  {
    "id": "arXiv:2110.08271",
    "title": "Training Deep Neural Networks with Joint Quantization and Pruning of  Weights and Activations",
    "abstract": "Training Deep Neural Networks with Joint Quantization and Pruning of  Weights and Activations",
    "descriptor": "",
    "authors": [
      "Xinyu Zhang",
      "Ian Colbert",
      "Ken Kreutz-Delgado",
      "Srinjoy Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08271"
  },
  {
    "id": "arXiv:2110.08964",
    "title": "Affine Hermitian Grassmann Codes",
    "abstract": "Affine Hermitian Grassmann Codes",
    "descriptor": "",
    "authors": [
      "Fernando Pi\u00f1ero Gonz\u00e1lez",
      "Doel Rivera Laboy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2110.08964"
  },
  {
    "id": "arXiv:2110.09113",
    "title": "Salt and pepper noise removal method based on stationary Framelet  transform with non-convex sparsity regularization",
    "abstract": "Salt and pepper noise removal method based on stationary Framelet  transform with non-convex sparsity regularization",
    "descriptor": "",
    "authors": [
      "Yingpin Chen",
      "Yuming Huang",
      "Lingzhi Wang",
      "Huiying Huang",
      "Jianhua Song",
      "Chaoqun Yu",
      "Yanping Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09113"
  },
  {
    "id": "arXiv:2110.09338",
    "title": "Contextual Hate Speech Detection in Code Mixed Text using Transformer  Based Approaches",
    "abstract": "Comments: Accepted at HASOC @Forum for Information Retrieval Evaluation(FIRE) 2021",
    "descriptor": "\nComments: Accepted at HASOC @Forum for Information Retrieval Evaluation(FIRE) 2021\n",
    "authors": [
      "Ravindra Nayak",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09338"
  },
  {
    "id": "arXiv:2110.09456",
    "title": "NormFormer: Improved Transformer Pretraining with Extra Normalization",
    "abstract": "NormFormer: Improved Transformer Pretraining with Extra Normalization",
    "descriptor": "",
    "authors": [
      "Sam Shleifer",
      "Jason Weston",
      "Myle Ott"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09456"
  },
  {
    "id": "arXiv:2110.09485",
    "title": "Learning in High Dimension Always Amounts to Extrapolation",
    "abstract": "Learning in High Dimension Always Amounts to Extrapolation",
    "descriptor": "",
    "authors": [
      "Randall Balestriero",
      "Jerome Pesenti",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09485"
  },
  {
    "id": "arXiv:2110.09769",
    "title": "Digital transformation of droplet/aerosol infection risk assessment  realized on \"Fugaku\" for the fight against COVID-19",
    "abstract": "Comments: 24 pages, 12 figures",
    "descriptor": "\nComments: 24 pages, 12 figures\n",
    "authors": [
      "Kazuto Ando",
      "Rahul Bale",
      "ChungGang Li",
      "Satoshi Matsuoka",
      "Keiji Onishi",
      "Makoto Tsubokura"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2110.09769"
  },
  {
    "id": "arXiv:2110.10225",
    "title": "What Averages Do Not Tell -- Predicting Real Life Processes with  Sequential Deep Learning",
    "abstract": "What Averages Do Not Tell -- Predicting Real Life Processes with  Sequential Deep Learning",
    "descriptor": "",
    "authors": [
      "Istv\u00e1n Ketyk\u00f3",
      "Felix Mannhardt",
      "Marwan Hassani",
      "Boudewijn van Dongen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10225"
  },
  {
    "id": "arXiv:2110.10953",
    "title": "MOS: A Low Latency and Lightweight Framework for Face Detection,  Landmark Localization, and Head Pose Estimation",
    "abstract": "Comments: Accepted at BMVC 2021",
    "descriptor": "\nComments: Accepted at BMVC 2021\n",
    "authors": [
      "Yepeng Liu",
      "Zaiwang Gu",
      "Shenghua Gao",
      "Dong Wang",
      "Yusheng Zeng",
      "Jun Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10953"
  },
  {
    "id": "arXiv:2110.11091",
    "title": "E-DPNCT: An Enhanced Attack Resilient Differential Privacy Model For  Smart Grids Using Split Noise Cancellation",
    "abstract": "Comments: 10 pages, 12 figues, 4 tables",
    "descriptor": "\nComments: 10 pages, 12 figues, 4 tables\n",
    "authors": [
      "Khadija Hafeez",
      "Donna OShea",
      "Mubashir Husain Rehmani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11091"
  },
  {
    "id": "arXiv:2110.11245",
    "title": "Evolutionary Foundation for Heterogeneity in Risk Aversion",
    "abstract": "Evolutionary Foundation for Heterogeneity in Risk Aversion",
    "descriptor": "",
    "authors": [
      "Yuval Heller",
      "Ilan Nehama"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.11245"
  },
  {
    "id": "arXiv:2110.11283",
    "title": "The Effect of Wearing a Face Mask on Face Image Quality",
    "abstract": "Comments: Accepted at the 16th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2021",
    "descriptor": "\nComments: Accepted at the 16th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2021\n",
    "authors": [
      "Biying Fu",
      "Florian Kirchbuchner",
      "Naser Damer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.11283"
  },
  {
    "id": "arXiv:2110.11725",
    "title": "DC-Microgrid Voltage Stabilization Using ANFIS Controller Considering  Permanent and Transient Storages",
    "abstract": "Comments: 18 pages, 27 figures, don't submitted",
    "descriptor": "\nComments: 18 pages, 27 figures, don't submitted\n",
    "authors": [
      "Hussein Zolfaghari",
      "Hossein Karimi",
      "Hamidreza Momeni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11725"
  },
  {
    "id": "arXiv:2110.12200",
    "title": "Hate and Offensive Speech Detection in Hindi and Marathi",
    "abstract": "Comments: Accepted at HASOC @Forum for Information Retrieval Evaluation(FIRE) 2021",
    "descriptor": "\nComments: Accepted at HASOC @Forum for Information Retrieval Evaluation(FIRE) 2021\n",
    "authors": [
      "Abhishek Velankar",
      "Hrushikesh Patil",
      "Amol Gore",
      "Shubham Salunke",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12200"
  },
  {
    "id": "arXiv:2110.12246",
    "title": "Parametric Variational Linear Units (PVLUs) in Deep Convolutional  Networks",
    "abstract": "Comments: Both authors contributed equally to this research",
    "descriptor": "\nComments: Both authors contributed equally to this research\n",
    "authors": [
      "Aarush Gupta",
      "Shikhar Ahuja"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12246"
  },
  {
    "id": "arXiv:2110.12541",
    "title": "Partially Intervenable Causal Models",
    "abstract": "Comments: The authors received communication that convincingly argued this draft in its current state does not engage sufficiently with prior work on partially intervenable causal models. Thus, it is not yet ready to be publicly shown in its current state",
    "descriptor": "\nComments: The authors received communication that convincingly argued this draft in its current state does not engage sufficiently with prior work on partially intervenable causal models. Thus, it is not yet ready to be publicly shown in its current state\n",
    "authors": [
      "AmirEmad Ghassami",
      "Ilya Shpitser"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.12541"
  },
  {
    "id": "arXiv:2110.12654",
    "title": "Facilitating Database Tuning with Hyper-Parameter Optimization: A  Comprehensive Experimental Evaluation",
    "abstract": "Facilitating Database Tuning with Hyper-Parameter Optimization: A  Comprehensive Experimental Evaluation",
    "descriptor": "",
    "authors": [
      "Xinyi Zhang",
      "Zhuo Chang",
      "Yang Li",
      "Hong Wu",
      "Jian Tan",
      "Feifei Li",
      "Bin Cui"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.12654"
  },
  {
    "id": "arXiv:2110.13008",
    "title": "Logsig-RNN: a novel network for robust and efficient skeleton-based  action recognition",
    "abstract": "Comments: This paper is accepted by British Machine Vision Conference 2021",
    "descriptor": "\nComments: This paper is accepted by British Machine Vision Conference 2021\n",
    "authors": [
      "Shujian Liao",
      "Terry Lyons",
      "Weixin Yang",
      "Kevin Schlegel",
      "Hao Ni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13008"
  },
  {
    "id": "arXiv:2110.13179",
    "title": "Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures",
    "abstract": "Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures",
    "descriptor": "",
    "authors": [
      "Kin G. Olivares",
      "Nganba Meetei",
      "Ruijun Ma",
      "Rohan Reddy",
      "Mengfei Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13179"
  },
  {
    "id": "arXiv:2110.13500",
    "title": "Exploring Content Moderation in the Decentralised Web: The Pleroma Case",
    "abstract": "Exploring Content Moderation in the Decentralised Web: The Pleroma Case",
    "descriptor": "",
    "authors": [
      "Anaobi Ishaku Hassan",
      "Aravindh Raman",
      "Ignacio Castro",
      "Haris Bin Zia",
      "Emiliano De Cristofaro",
      "Nishanth Sastry",
      "Gareth Tyson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.13500"
  },
  {
    "id": "arXiv:2110.13522",
    "title": "Probabilistic Entity Representation Model for Reasoning over Knowledge  Graphs",
    "abstract": "Comments: Accepted at Thirty-fifth Conference on Neural Information Processing Systems 2021 (NeurIPS '21)",
    "descriptor": "\nComments: Accepted at Thirty-fifth Conference on Neural Information Processing Systems 2021 (NeurIPS '21)\n",
    "authors": [
      "Nurendra Choudhary",
      "Nikhil Rao",
      "Sumeet Katariya",
      "Karthik Subbian",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.13522"
  },
  {
    "id": "arXiv:2110.13537",
    "title": "Overlapping Schwarz methods with GenEO coarse spaces for indefinite and  non-self-adjoint problems",
    "abstract": "Overlapping Schwarz methods with GenEO coarse spaces for indefinite and  non-self-adjoint problems",
    "descriptor": "",
    "authors": [
      "Niall Bootland",
      "Victorita Dolean",
      "Ivan G. Graham",
      "Chupeng Ma",
      "Robert Scheichl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13537"
  },
  {
    "id": "arXiv:2110.13623",
    "title": "Contrastive Neural Processes for Self-Supervised Learning",
    "abstract": "Comments: 16 pages, 6 figures, ACML 2021",
    "descriptor": "\nComments: 16 pages, 6 figures, ACML 2021\n",
    "authors": [
      "Konstantinos Kallidromitis",
      "Denis Gudovskiy",
      "Kazuki Kozuka",
      "Ohama Iku",
      "Luca Rigazio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.13623"
  },
  {
    "id": "arXiv:2110.13661",
    "title": "Hybrid physics-based and data-driven modeling with calibrated  uncertainty for lithium-ion battery degradation diagnosis and prognosis",
    "abstract": "Comments: 6 pages, 3 figures, accepted for poster presentation at Tackling Climate Change with Machine Learning workshop at NeurIPS 2021",
    "descriptor": "\nComments: 6 pages, 3 figures, accepted for poster presentation at Tackling Climate Change with Machine Learning workshop at NeurIPS 2021\n",
    "authors": [
      "Jing Lin",
      "Yu Zhang",
      "Edwin Khoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.13661"
  },
  {
    "id": "arXiv:2110.13729",
    "title": "Improving Robustness of Deep Neural Networks for Aerial Navigation by  Incorporating Input Uncertainty",
    "abstract": "Comments: Accepted at the Fourth International Workshop on Artificial Intelligence Safety Engineering, WAISE 2021",
    "descriptor": "\nComments: Accepted at the Fourth International Workshop on Artificial Intelligence Safety Engineering, WAISE 2021\n",
    "authors": [
      "Fabio Arnez",
      "Huascar Espinoza",
      "Ansgar Radermacher",
      "Fran\u00e7ois Terrier"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.13729"
  },
  {
    "id": "arXiv:2110.13817",
    "title": "Real time Simulation of Gird-connected Photovoltaic Multilevel Inverter  using Hybrid GA/PSO Optimization Algorithm",
    "abstract": "Real time Simulation of Gird-connected Photovoltaic Multilevel Inverter  using Hybrid GA/PSO Optimization Algorithm",
    "descriptor": "",
    "authors": [
      "Hussein Zolfaghari",
      "Hamidreza Momeni",
      "Hossein Karimi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13817"
  },
  {
    "id": "arXiv:2110.14038",
    "title": "Robustness of Graph Neural Networks at Scale",
    "abstract": "Comments: 39 pages, 22 figures, 17 tables NeurIPS 2021",
    "descriptor": "\nComments: 39 pages, 22 figures, 17 tables NeurIPS 2021\n",
    "authors": [
      "Simon Geisler",
      "Tobias Schmidt",
      "Hakan \u015eirin",
      "Daniel Z\u00fcgner",
      "Aleksandar Bojchevski",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14038"
  },
  {
    "id": "arXiv:2110.14124",
    "title": "A novel decompostion-based multiobjective evolutionary algorithm with an  application to engineering optimal design problems",
    "abstract": "A novel decompostion-based multiobjective evolutionary algorithm with an  application to engineering optimal design problems",
    "descriptor": "",
    "authors": [
      "Wang Chen",
      "Jian Chen",
      "Weitian Wu",
      "Xinmin Yang",
      "Hui Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.14124"
  },
  {
    "id": "arXiv:2110.14137",
    "title": "Relationship Oriented Affordance Learning through Manipulation Graph  Construction",
    "abstract": "Relationship Oriented Affordance Learning through Manipulation Graph  Construction",
    "descriptor": "",
    "authors": [
      "Chao Tang",
      "Jingwen Yu",
      "Weinan Chen",
      "Hong Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.14137"
  },
  {
    "id": "arXiv:2110.14300",
    "title": "Multi-Agent Reinforcement Learning for Active Voltage Control on Power  Distribution Networks",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Jianhong Wang",
      "Wangkun Xu",
      "Yunjie Gu",
      "Wenbin Song",
      "Tim C. Green"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.14300"
  },
  {
    "id": "arXiv:2110.14621",
    "title": "Fairer LP-based Online Allocation",
    "abstract": "Comments: 46 pages. arXiv admin note: text overlap with arXiv:2101.11092",
    "descriptor": "\nComments: 46 pages. arXiv admin note: text overlap with arXiv:2101.11092\n",
    "authors": [
      "Guanting Chen",
      "Xiaocheng Li",
      "Yinyu Ye"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.14621"
  },
  {
    "id": "arXiv:2110.14622",
    "title": "Heterogeneous Multi-player Multi-armed Bandits: Closing the Gap and  Generalization",
    "abstract": "Comments: Accepted to NeurIPS 2021, camera-ready version",
    "descriptor": "\nComments: Accepted to NeurIPS 2021, camera-ready version\n",
    "authors": [
      "Chengshuai Shi",
      "Wei Xiong",
      "Cong Shen",
      "Jing Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14622"
  },
  {
    "id": "arXiv:2110.14693",
    "title": "Towards Robust Reasoning over Knowledge Graphs",
    "abstract": "Towards Robust Reasoning over Knowledge Graphs",
    "descriptor": "",
    "authors": [
      "Zhaohan Xi",
      "Ren Pang",
      "Changjiang Li",
      "Shouling Ji",
      "Xiapu Luo",
      "Xusheng Xiao",
      "Ting Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.14693"
  },
  {
    "id": "arXiv:2110.14768",
    "title": "Distributed Asynchronous Games With Causal Memory are Undecidable",
    "abstract": "Distributed Asynchronous Games With Causal Memory are Undecidable",
    "descriptor": "",
    "authors": [
      "Hugo Gimbert"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14768"
  },
  {
    "id": "arXiv:2110.14775",
    "title": "BI-GCN: Boundary-Aware Input-Dependent Graph Convolution Network for  Biomedical Image Segmentation",
    "abstract": "Comments: Accepted in BMVC2021 as Oral",
    "descriptor": "\nComments: Accepted in BMVC2021 as Oral\n",
    "authors": [
      "Yanda Meng",
      "Hongrun Zhang",
      "Dongxu Gao",
      "Yitian Zhao",
      "Xiaoyun Yang",
      "Xuesheng Qian",
      "Xiaowei Huang",
      "Yalin Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14775"
  },
  {
    "id": "arXiv:2110.14780",
    "title": "Combining Vagueness Detection with Deep Learning to Identify Fake News",
    "abstract": "Comments: Paper to appear in the Proceedings of the 24th International Conference on Information Fusion. Johannesburg. (2nd version: Typo corrected in metadata in one of the authors' names)",
    "descriptor": "\nComments: Paper to appear in the Proceedings of the 24th International Conference on Information Fusion. Johannesburg. (2nd version: Typo corrected in metadata in one of the authors' names)\n",
    "authors": [
      "Paul Gu\u00e9lorget",
      "Benjamin Icard",
      "Guillaume Gadek",
      "Souhir Gahbiche",
      "Sylvain Gatepaille",
      "Ghislain Atemezing",
      "Paul \u00c9gr\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14780"
  },
  {
    "id": "arXiv:2110.14880",
    "title": "AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value  Analysis",
    "abstract": "AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value  Analysis",
    "descriptor": "",
    "authors": [
      "Junfeng Guo",
      "Ang Li",
      "Cong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14880"
  },
  {
    "id": "arXiv:2110.14914",
    "title": "Trading via Selective Classification",
    "abstract": "Comments: (8 pages, 6 figures, 4 tables, ICAIF'21)",
    "descriptor": "\nComments: (8 pages, 6 figures, 4 tables, ICAIF'21)\n",
    "authors": [
      "Nestoras Chalkidis",
      "Rahul Savani"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14914"
  },
  {
    "id": "arXiv:2110.14923",
    "title": "Modeling Heterogeneous Hierarchies with Relation-specific Hyperbolic  Cones",
    "abstract": "Comments: To be published in NeurIPS 2021, full version including appendix",
    "descriptor": "\nComments: To be published in NeurIPS 2021, full version including appendix\n",
    "authors": [
      "Yushi Bai",
      "Rex Ying",
      "Hongyu Ren",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.14923"
  },
  {
    "id": "arXiv:2110.15678",
    "title": "A Shading-Guided Generative Implicit Model for Shape-Accurate 3D-Aware  Image Synthesis",
    "abstract": "Comments: Accepted to NeurIPS2021. We proposed ShadeGAN, which could perform shape-accurate 3D-aware image synthesis by modeling shading in generative implicit models",
    "descriptor": "\nComments: Accepted to NeurIPS2021. We proposed ShadeGAN, which could perform shape-accurate 3D-aware image synthesis by modeling shading in generative implicit models\n",
    "authors": [
      "Xingang Pan",
      "Xudong Xu",
      "Chen Change Loy",
      "Christian Theobalt",
      "Bo Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15678"
  },
  {
    "id": "arXiv:2110.15719",
    "title": "Generational Frameshifts in Technology: Computer Science and  Neurosurgery, The VR Use Case",
    "abstract": "Comments: 9 pages, 3 figures",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Samuel R. Browd",
      "Maya Sharma",
      "Chetan Sharma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Other Quantitative Biology (q-bio.OT)"
    ],
    "url": "https://arxiv.org/abs/2110.15719"
  },
  {
    "id": "arXiv:2110.15923",
    "title": "Efficient Representation of Interaction Patterns with Hyperbolic  Hierarchical Clustering for Classification of Users on Twitter",
    "abstract": "Efficient Representation of Interaction Patterns with Hyperbolic  Hierarchical Clustering for Classification of Users on Twitter",
    "descriptor": "",
    "authors": [
      "Tanvi Karandikar",
      "Avinash Prabhu",
      "Avinash Tulasi",
      "Arun Balaji Buduru",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.15923"
  },
  {
    "id": "arXiv:2110.15960",
    "title": "Support Recovery with Stochastic Gates: Theory and Application for  Linear Models",
    "abstract": "Comments: 12 pages, 3 figures, Corrected typos in this revision",
    "descriptor": "\nComments: 12 pages, 3 figures, Corrected typos in this revision\n",
    "authors": [
      "Soham Jana",
      "Henry Li",
      "Yutaro Yamada",
      "Ofir Lindenbaum"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15960"
  }
]
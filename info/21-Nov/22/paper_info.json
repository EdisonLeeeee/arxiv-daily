[
  {
    "id": "arXiv:2111.09908",
    "title": "Visual Goal-Directed Meta-Learning with Contextual Planning Networks",
    "abstract": "The goal of meta-learning is to generalize to new tasks and goals as quickly\nas possible. Ideally, we would like approaches that generalize to new goals and\ntasks on the first attempt. Toward that end, we introduce contextual planning\nnetworks (CPN). Tasks are represented as goal images and used to condition the\napproach. We evaluate CPN along with several other approaches adapted for\nzero-shot goal-directed meta-learning. We evaluate these approaches across 24\ndistinct manipulation tasks using Metaworld benchmark tasks. We found that CPN\noutperformed several approaches and baselines on one task and was competitive\nwith existing approaches on others. We demonstrate the approach on a physical\nplatform on Jenga tasks using a Kinova Jaco robotic arm.",
    "descriptor": "",
    "authors": [
      "Corban G. Rivera",
      "David A Handelman"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.09908"
  },
  {
    "id": "arXiv:2111.09912",
    "title": "Efficiently Transforming Tables for Joinability",
    "abstract": "Data from different sources rarely conform to a single formatting even if\nthey describe the same set of entities, and this raises concerns when data from\nmultiple sources must be joined or cross-referenced. Such a formatting mismatch\nis unavoidable when data is gathered from various public and third-party\nsources. Commercial database systems are not able to perform the join when\nthere exist differences in data representation or formatting, and manual\nreformatting is both time consuming and error-prone. We study the problem of\nefficiently joining textual data under the condition that the join columns are\nnot formatted the same and cannot be equi-joined, but they become joinable\nunder some transformations. The problem is challenging simply because the\nnumber of possible transformations explodes with both the length of the input\nand the number of rows, even if each transformation is formed using very few\nbasic units. We show that an efficient algorithm can be developed based on the\ncommon characteristics of the joined columns, and develop one such algorithm\nover a rich set of basic operations that can be composed to form\ntransformations. We compare both the coverage and the running time of our\nalgorithm to a state-of-the-art approach, and show that our algorithm covers\nevery transformation that is covered in the state-of-the-art approach but is a\nfew orders of magnitude faster, as evaluated on various real and synthetic\ndata.",
    "descriptor": "",
    "authors": [
      "Arash Dargahi Nobari",
      "Davood Rafiei"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.09912"
  },
  {
    "id": "arXiv:2111.09917",
    "title": "Interactive Set Discovery",
    "abstract": "We study the problem of set discovery where given a few example tuples of a\ndesired set, we want to find the set in a collection of sets. A challenge is\nthat the example tuples may not uniquely identify a set, and a large number of\ncandidate sets may be returned. Our focus is on interactive exploration to set\ndiscovery where additional example tuples from the candidate sets are shown and\nthe user either accepts or rejects them as members of the target set. The goal\nis to find the target set with the least number of user interactions. The\nproblem can be cast as an optimization problem where we want to find a decision\ntree that can guide the search to the target set with the least number of\nquestions to be answered by the user. We propose a general algorithm that is\ncapable of reaching an optimal solution and two variations of it that strike a\nbalance between the quality of a solution and the running time. We also propose\na novel pruning strategy that safely reduces the search space without\nintroducing false negatives. We evaluate the efficiency and the effectiveness\nof our algorithms through an extensive experimental study using both real and\nsynthetic datasets and comparing them to previous approaches in the literature.\nWe show that our pruning strategy reduces the running time of the search\nalgorithms by 2-5 orders of magnitude.",
    "descriptor": "",
    "authors": [
      "Arif Hasnat",
      "Davood Rafiei"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.09917"
  },
  {
    "id": "arXiv:2111.09920",
    "title": "BLUE: A 3D Dynamic Bipedal Robot",
    "abstract": "The objective of this work is to design a mechatronic bipedal robot with\nmobility in 3D environments. The designed robot has a total of six actuated\ndegrees of freedom (DoF), each leg has two DoF located at the hip: one for\nabduction/adduction and another for thigh flexion/extension, and a third DoF at\nthe knee for the shin flexion/extension. This robot is designed with point-feet\nlegs to achieve a dynamic underactuated walking. Each actuator in the robot\nincludes a DC gear motor, an encoder for position measurement, a flexible joint\nto form a series flexible actuator, and a feedback controller to ensure\ntrajectory tracking. In order to reduce the total mass of the robot, the shin\nis designed using topology optimization. The resulting design is fabricated\nusing 3D printed parts, which allows to get a robot's prototype to validate the\nselection of actuators. The preliminary experiments confirm the robot's ability\nto maintain a stand-up position and let us drawn future works in dynamic\ncontrol and trajectory generation for periodic stable walking.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "German Vargas",
      "Margarita Berrio",
      "Jaime Arcos-Legarda"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.09920"
  },
  {
    "id": "arXiv:2111.09922",
    "title": "A cut finite element method for the Darcy problem",
    "abstract": "We present and analyze a cut finite element method for the weak imposition of\nthe Neumann boundary conditions of the Darcy problem. The Raviart-Thomas mixed\nelement on both triangular and quadrilateral meshes is considered. Our method\nis based on the Nitsche formulation studied in [10.1515/jnma-2021-0042] and can\nbe considered as a first attempt at extension in the unfitted case. The key\nfeature is to add two ghost penalty operators to stabilize both the velocity\nand pressure fields. We rigorously prove our stabilized formulation to be\nwell-posed and derive a priori error estimates for the velocity and pressure\nfields. We show that an upper bound for the condition number of the stiffness\nmatrix holds as well. Numerical examples corroborating the theory are included.",
    "descriptor": "",
    "authors": [
      "Riccardo Puppi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.09922"
  },
  {
    "id": "arXiv:2111.09927",
    "title": "Quality and Cost Trade-offs in Passage Re-ranking Task",
    "abstract": "Deep learning models named transformers achieved state-of-the-art results in\na vast majority of NLP tasks at the cost of increased computational complexity\nand high memory consumption. Using the transformer model in real-time inference\nbecomes a major challenge when implemented in production, because it requires\nexpensive computational resources. The more executions of a transformer are\nneeded the lower the overall throughput is, and switching to the smaller\nencoders leads to the decrease of accuracy. Our paper is devoted to the problem\nof how to choose the right architecture for the ranking step of the information\nretrieval pipeline, so that the number of required calls of transformer encoder\nis minimal with the maximum achievable quality of ranking. We investigated\nseveral late-interaction models such as Colbert and Poly-encoder architectures\nalong with their modifications. Also, we took care of the memory footprint of\nthe search index and tried to apply the learning-to-hash method to binarize the\noutput vectors from the transformer encoders. The results of the evaluation are\nprovided using TREC 2019-2021 and MS Marco dev datasets.",
    "descriptor": "\nComments: The Thirtieth Text REtrieval Conference (TREC 2021) Proceedings\n",
    "authors": [
      "Pavel Podberezko",
      "Vsevolod Mitskevich",
      "Raman Makouski",
      "Pavel Goncharov",
      "Andrei Khobnia",
      "Nikolay Bushkov",
      "Marina Chernyshevich"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.09927"
  },
  {
    "id": "arXiv:2111.09930",
    "title": "Learning To Estimate Regions Of Attraction Of Autonomous Dynamical  Systems Using Physics-Informed Neural Networks",
    "abstract": "When learning to perform motor tasks in a simulated environment, neural\nnetworks must be allowed to explore their action space to discover new\npotentially viable solutions. However, in an online learning scenario with\nphysical hardware, this exploration must be constrained by relevant safety\nconsiderations in order to avoid damage to the agent's hardware and\nenvironment. We aim to address this problem by training a neural network, which\nwe will refer to as a \"safety network\", to estimate the region of attraction\n(ROA) of a controlled autonomous dynamical system. This safety network can\nthereby be used to quantify the relative safety of proposed control actions and\nprevent the selection of damaging actions. Here we present our development of\nthe safety network by training an artificial neural network (ANN) to represent\nthe ROA of several autonomous dynamical system benchmark problems. The training\nof this network is predicated upon both Lyapunov theory and neural solutions to\npartial differential equations (PDEs). By learning to approximate the viscosity\nsolution to a specially chosen PDE that contains the dynamics of the system of\ninterest, the safety network learns to approximate a particular function,\nsimilar to a Lyapunov function, whose zero level set is boundary of the ROA. We\ntrain our safety network to solve these PDEs in a semi-supervised manner\nfollowing a modified version of the Physics Informed Neural Network (PINN)\napproach, utilizing a loss function that penalizes disagreement with the PDE's\ninitial and boundary conditions, as well as non-zero residual and variational\nterms. In future work we intend to apply this technique to reinforcement\nlearning agents during motor learning tasks.",
    "descriptor": "\nComments: 31 pages, 17 figures\n",
    "authors": [
      "Cody Scharzenberger",
      "Joe Hays"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09930"
  },
  {
    "id": "arXiv:2111.09931",
    "title": "DawDreamer: Bridging the Gap Between Digital Audio Workstations and  Python Interfaces",
    "abstract": "Audio production techniques which previously only existed in GUI-constrained\ndigital audio workstations, livecoding environments, or C++ APIs are now\naccessible with our new Python module called DawDreamer. DawDreamer therefore\nbridges the gap between real sound engineers and coders imitating them with\noffline batch-processing. Like contemporary modules in this domain, DawDreamer\ncan create directed acyclic graphs of audio processors such as VSTs which\ngenerate or manipulate audio streams. DawDreamer can also dynamically compile\nand execute code from Faust, a powerful signal processing language which can be\ndeployed to many platforms and microcontrollers. We discuss DawDreamer's unique\nfeatures in detail and potential applications across music information\nretrieval including source separation, transcription, and audio effect\nparameter inference. We provide fully cross-platform PyPI installers, a Linux\nDockerfile, and an example Jupyter notebook.",
    "descriptor": "\nComments: 3 pages with 0 figures. Included in the Late-Breaking Demo Session of the 22nd International Society for Music Information Retrieval Conference\n",
    "authors": [
      "David Braun"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.09931"
  },
  {
    "id": "arXiv:2111.09933",
    "title": "Loss Functions for Discrete Contextual Pricing with Observational Data",
    "abstract": "We study a pricing setting where each customer is offered a contextualized\nprice based on customer and/or product features that are predictive of the\ncustomer's valuation for that product. Often only historical sales records are\navailable, where we observe whether each customer purchased a product at the\nprice prescribed rather than the customer's true valuation. As such, the data\nis influenced by the historical sales policy which introduces difficulties in\na) estimating future loss/regret for pricing policies without the possibility\nof conducting real experiments and b) optimizing new policies for downstream\ntasks such as revenue management. We study how to formulate loss functions\nwhich can be used for optimizing pricing policies directly, rather than going\nthrough an intermediate demand estimation stage, which can be biased in\npractice due to model misspecification, regularization or poor calibration.\nWhile existing approaches have been proposed when valuation data is available,\nwe propose loss functions for the observational data setting. To achieve this,\nwe adapt ideas from machine learning with corrupted labels, where we can\nconsider each observed customer's outcome (purchased or not for a prescribed\nprice), as a (known) probabilistic transformation of the customer's valuation.\nFrom this transformation we derive a class of suitable unbiased loss functions.\nWithin this class we identify minimum variance estimators, those which are\nrobust to poor demand function estimation, and provide guidance on when the\nestimated demand function is useful. Furthermore, we also show that when\napplied to our contextual pricing setting, estimators popular in the off-policy\nevaluation literature fall within this class of loss functions, and also offer\nmanagerial insights on when each estimator is likely to perform well in\npractice.",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Max Biggs",
      "Ruijiang Gao",
      "Wei Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.09933"
  },
  {
    "id": "arXiv:2111.09934",
    "title": "Constraint-based Diversification of JOP Gadgets",
    "abstract": "Modern software deployment process produces software that is uniform and\nhence vulnerable to large-scale code-reuse attacks, such as Jump-Oriented\nProgramming (JOP) attacks. Compiler-based diversification improves the\nresilience of software systems by automatically generating different assembly\ncode versions of a given program. Existing techniques are efficient but do not\nhave a precise control over the quality of the generated variants. This paper\nintroduces Diversity by Construction (DivCon), a constraint-based approach to\nsoftware diversification. Unlike previous approaches, DivCon allows users to\ncontrol and adjust the conflicting goals of diversity and code quality. A key\nenabler is the use of Large Neighborhood Search (LNS) to generate highly\ndiverse code efficiently. For larger problems, we propose a combination of LNS\nwith a structural decomposition of the problem. To further improve the\ndiversification efficiency of DivCon against JOP attacks, we propose an\napplication-specific distance measure tailored to the characteristics of JOP\nattacks. We evaluate DivCon with 20 functions from a popular benchmark suite\nfor embedded systems. These experiments show that the combination of LNS and\nour application-specific distance measure generates binary programs that are\nhighly resilient against JOP attacks. Our results confirm that there is a\ntrade-off between the quality of each assembly code version and the diversity\nof the entire pool of versions. In particular, the experiments show that DivCon\ngenerates near-optimal binary programs that share a small number of gadgets.\nFor constraint programming researchers and practitioners, this paper\ndemonstrates that LNS is a valuable technique for finding diverse solutions.\nFor security researchers and software engineers, DivCon extends the scope of\ncompiler-based diversification to performance-critical and resource-constrained\napplications.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2007.08955\n",
    "authors": [
      "Rodothea Myrsini Tsoupidi",
      "Roberto Casta\u00f1eda Lozano",
      "Benoit Baudry"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.09934"
  },
  {
    "id": "arXiv:2111.09939",
    "title": "Explainable predictions of different machine learning algorithms used to  predict Early Stage diabetes",
    "abstract": "Machine Learning and Artificial Intelligence can be widely used to diagnose\nchronic diseases so that necessary precautionary treatment can be done in\ncritical time. Diabetes Mellitus which is one of the major diseases can be\neasily diagnosed by several Machine Learning algorithms. Early stage diagnosis\nis crucial to prevent dangerous consequences. In this paper we have made a\ncomparative analysis of several machine learning algorithms viz. Random Forest,\nDecision Tree, Artificial Neural Networks, K Nearest Neighbor, Support Vector\nMachine, and XGBoost along with feature attribution using SHAP to identify the\nmost important feature in predicting the diabetes on a dataset collected from\nSylhet Hospital. As per the experimental results obtained, the Random Forest\nalgorithm has outperformed all the other algorithms with an accuracy of 99\npercent on this particular dataset.",
    "descriptor": "\nComments: Under review at another conference\n",
    "authors": [
      "V. Vakil",
      "S. Pachchigar",
      "C. Chavda",
      "S. Soni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.09939"
  },
  {
    "id": "arXiv:2111.09947",
    "title": "Parallel Algorithms for Masked Sparse Matrix-Matrix Products",
    "abstract": "Computing the product of two sparse matrices (SpGEMM) is a fundamental\noperation in various combinatorial and graph algorithms as well as various\nbioinformatics and data analytics applications for computing inner-product\nsimilarities. For an important class of algorithms, only a subset of the output\nentries are needed, and the resulting operation is known as Masked SpGEMM since\na subset of the output entries is considered to be \"masked out\". Existing\nalgorithms for Masked SpGEMM usually do not consider mask as part of\nmultiplication and either first compute a regular SpGEMM followed by masking,\nor perform a sparse inner product only for output elements that are not masked\nout. In this work, we investigate various novel algorithms and data structures\nfor this rather challenging and important computation, and provide guidelines\non how to design a fast Masked-SpGEMM for shared-memory architectures. Our\nevaluations show that factors such as matrix and mask density, mask structure\nand cache behavior play a vital role in attaining high performance for Masked\nSpGEMM. We evaluate our algorithms on a large number of matrices using several\nreal-world benchmarks and show that our algorithms in most cases significantly\noutperform the state of the art for Masked SpGEMM implementations.",
    "descriptor": "",
    "authors": [
      "Sr\u0111an Milakovi\u0107",
      "Oguz Selvitopi",
      "Israt Nisa",
      "Zoran Budimli\u0107",
      "Aydin Buluc"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2111.09947"
  },
  {
    "id": "arXiv:2111.09949",
    "title": "A fast algorithm for computing the Smith normal form with multipliers  for a nonsingular integer matrix",
    "abstract": "A Las Vegas randomized algorithm is given to compute the Smith multipliers\nfor a nonsingular integer matrix $A$, that is, unimodular matrices $U$ and $V$\nsuch that $AV=US$, with $S$ the Smith normal form of $A$. The expected running\ntime of the algorithm is about the same as required to multiply together two\nmatrices of the same dimension and size of entries as $A$. Explicit bounds are\ngiven for the size of the entries in both unimodular multipliers. The main tool\nused by the algorithm is the Smith massager, a relaxed version of $V$, the\nunimodular matrix specifying the column operations of the Smith computation.\nFrom the perspective of efficiency, the main tools used are fast linear solving\nand partial linearization of integer matrices. As an application of the Smith\nwith multipliers algorithm, a fast algorithm is given to find the fractional\npart of the inverse of the input matrix.",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Stavros Birmpilis",
      "George Labahn",
      "Arne Storjohann"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2111.09949"
  },
  {
    "id": "arXiv:2111.09950",
    "title": "Correcting Face Distortion in Wide-Angle Videos",
    "abstract": "Video blogs and selfies are popular social media formats, which are often\ncaptured by wide-angle cameras to show human subjects and expanded background.\nUnfortunately, due to perspective projection, faces near corners and edges\nexhibit apparent distortions that stretch and squish the facial features,\nresulting in poor video quality. In this work, we present a video warping\nalgorithm to correct these distortions. Our key idea is to apply stereographic\nprojection locally on the facial regions. We formulate a mesh warp problem\nusing spatial-temporal energy minimization and minimize background deformation\nusing a line-preservation term to maintain the straight edges in the\nbackground. To address temporal coherency, we constrain the temporal smoothness\non the warping meshes and facial trajectories through the latent variables. For\nperformance evaluation, we develop a wide-angle video dataset with a wide range\nof focal lengths. The user study shows that 83.9% of users prefer our algorithm\nover other alternatives based on perspective projection.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Wei-Sheng Lai",
      "YiChang Shih",
      "Chia-Kai Liang",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.09950"
  },
  {
    "id": "arXiv:2111.09954",
    "title": "MS-nowcasting: Operational Precipitation Nowcasting with Convolutional  LSTMs at Microsoft Weather",
    "abstract": "We present the encoder-forecaster convolutional long short-term memory (LSTM)\ndeep-learning model that powers Microsoft Weather's operational precipitation\nnowcasting product. This model takes as input a sequence of weather radar\nmosaics and deterministically predicts future radar reflectivity at lead times\nup to 6 hours. By stacking a large input receptive field along the feature\ndimension and conditioning the model's forecaster with predictions from the\nphysics-based High Resolution Rapid Refresh (HRRR) model, we are able to\noutperform optical flow and HRRR baselines by 20-25% on multiple metrics\naveraged over all lead times.",
    "descriptor": "",
    "authors": [
      "Sylwester Klocek",
      "Haiyu Dong",
      "Matthew Dixon",
      "Panashe Kanengoni",
      "Najeeb Kazmi",
      "Pete Luferenko",
      "Zhongjian Lv",
      "Shikhar Sharma",
      "Jonathan Weyn",
      "Siqi Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.09954"
  },
  {
    "id": "arXiv:2111.09955",
    "title": "SmartSlice: Dynamic, self-optimization of applications QoS requests to  5G networks",
    "abstract": "Applications can tailor a network slice by specifying a variety of QoS\nattributes related to application-specific performance, function or operation.\nHowever, some QoS attributes like guaranteed bandwidth required by the\napplication do vary over time. For example, network bandwidth needs of video\nstreams from surveillance cameras can vary a lot depending on the environmental\nconditions and the content in the video streams. In this paper, we propose a\nnovel, dynamic QoS attribute prediction technique that assists any application\nto make optimal resource reservation requests at all times. Standard\nforecasting using traditional cost functions like MAE, MSE, RMSE, MDA, etc.\ndon't work well because they do not take into account the direction (whether\nthe forecasting of resources is more or less than needed), magnitude (by how\nmuch the forecast deviates, and in which direction), or frequency (how many\ntimes the forecast deviates from actual needs, and in which direction). The\ndirection, magnitude and frequency have a direct impact on the application's\naccuracy of insights, and the operational costs. We propose a new,\nparameterized cost function that takes into account all three of them, and\nguides the design of a new prediction technique. To the best of our knowledge,\nthis is the first work that considers time-varying application requirements and\ndynamically adjusts slice QoS requests to 5G networks in order to ensure a\nbalance between application's accuracy and operational costs. In a real-world\ndeployment of a surveillance video analytics application over 17 cameras, we\nshow that our technique outperforms other traditional forecasting methods, and\nit saves 34% of network bandwidth (over a ~24 hour period) when compared to a\nstatic, one-time reservation.",
    "descriptor": "",
    "authors": [
      "Kunal Rao",
      "Murugan Sankaradas",
      "Vivek Aswal",
      "Srimat Chakradhar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.09955"
  },
  {
    "id": "arXiv:2111.09957",
    "title": "Rethink Dilated Convolution for Real-time Semantic Segmentation",
    "abstract": "Recent advances in semantic segmentation generally adapt an ImageNet\npretrained backbone with a special context module after it to quickly increase\nthe field-of-view. Although successful, the backbone, in which most of the\ncomputation lies, does not have a large enough field-of-view to make the best\ndecisions. Some recent advances tackle this problem by rapidly downsampling the\nresolution in the backbone while also having one or more parallel branches with\nhigher resolutions. We take a different approach by designing a ResNeXt\ninspired block structure that uses two parallel 3x3 convolutional layers with\ndifferent dilation rates to increase the field-of-view while also preserving\nthe local details. By repeating this block structure in the backbone, we do not\nneed to append any special context module after it. In addition, we propose a\nlightweight decoder that restores local information better than common\nalternatives. To demonstrate the effectiveness of our approach, our model\nRegSeg achieves state-of-the-art results on real-time Cityscapes and CamVid\ndatasets. Using a T4 GPU with mixed precision, RegSeg achieves 78.3 mIOU on\nCityscapes test set at 30 FPS, and 80.9 mIOU on CamVid test set at 70 FPS, both\nwithout ImageNet pretraining.",
    "descriptor": "",
    "authors": [
      "Roland Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.09957"
  },
  {
    "id": "arXiv:2111.09958",
    "title": "A Nodal Immersed Finite Element-Finite Difference Method",
    "abstract": "The immersed finite element-finite difference (IFED) method is a\ncomputational approach to modeling interactions between a fluid and an immersed\nstructure. This method uses a finite element (FE) method to approximate the\nstresses and forces on a structural mesh and a finite difference (FD) method to\napproximate the momentum of the entire fluid-structure system on a Cartesian\ngrid. The fundamental approach used by this method follows the immersed\nboundary framework for modeling fluid-structure interaction (FSI), in which a\nforce spreading operator prolongs structural forces to a Cartesian grid, and a\nvelocity interpolation operator restricts a velocity field defined on that grid\nback onto the structural mesh. Force spreading and velocity interpolation both\nrequire projecting data onto the finite element space. Consequently, evaluating\neither coupling operator requires solving a matrix equation at every time step.\nMass lumping, in which the projection matrices are replaced by diagonal\napproximations, has the potential to accelerate this method considerably.\nConstructing the coupling operators also requires determining the locations on\nthe structure mesh where the forces and velocities are sampled. Here we show\nthat sampling the forces and velocities at the nodes of the structural mesh is\nequivalent to using lumped mass matrices in the coupling operators. A key\ntheoretical result of our analysis is that if both of these approaches are used\ntogether, the IFED method permits the use of lumped mass matrices derived from\nnodal quadrature rules for any standard interpolatory element. This is\ndifferent from standard FE methods, which require specialized treatments to\naccommodate mass lumping with higher-order shape functions. Our theoretical\nresults are confirmed by numerical benchmarks, including standard solid\nmechanics tests and examination of a dynamic model of a bioprosthetic heart\nvalve.",
    "descriptor": "",
    "authors": [
      "David Wells",
      "Ben Vadala-Roth",
      "Jae H. Lee",
      "Boyce E. Griffith"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.09958"
  },
  {
    "id": "arXiv:2111.09959",
    "title": "Predictive Scheduling of Collaborative Mobile Robots for Improved  Crop-transport Logistics of Manually Harvested Crops",
    "abstract": "Mechanizing the manual harvesting of fresh market fruits constitutes one of\nthe biggest challenges to the sustainability of the fruit industry. During\nmanual harvesting of some fresh-market crops like strawberries and table\ngrapes, pickers spend significant amounts of time walking to carry full trays\nto a collection station at the edge of the field. A step toward increasing\nharvest automation for such crops is to deploy harvest-aid collaborative robots\n(co-bots) that transport the empty and full trays, thus increasing harvest\nefficiency by reducing pickers' non-productive walking times. This work\npresents the development of a co-robotic harvest-aid system and its evaluation\nduring commercial strawberry harvesting. At the heart of the system lies a\npredictive stochastic scheduling algorithm that minimizes the expected\nnon-picking time, thus maximizing the harvest efficiency. During the evaluation\nexperiments, the co-robots improved the mean harvesting efficiency by around\n10% and reduced the mean non-productive time by 60%, when the robot-to-picker\nratio was 1:3. The concepts developed in this work can be applied to robotic\nharvest-aids for other manually harvested crops that involve walking for crop\ntransportation.",
    "descriptor": "\nComments: PhD Dissertation\n",
    "authors": [
      "Chen Peng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.09959"
  },
  {
    "id": "arXiv:2111.09960",
    "title": "Reining in Mobile Web Performance with Document and Permission Policies",
    "abstract": "The quality of experience with the mobile web remains poor, partially as a\nresult of complex websites and design choices that worsen performance,\nparticularly for users in suboptimal networks or devices. Prior proposed\nsolutions have seen limited adoption due in part to the demand they place on\ndevelopers and content providers, and the performing infrastructure needed to\nsupport them. We argue that Document and Permissions Policies -- an ongoing\neffort to enforce good practices on web design -- may offer the basis for a\nreadily-available and easily-adoptable solution. In this paper, we evaluate the\npotential performance cost of violating well-understood policies and how common\nsuch violations are in today's web. Our analysis show, for example, that\ncontrolling for unsized-media policy, something applicable to 70% of the\ntop-1million websites, can indeed reduce Cumulative Layout Shift metric.",
    "descriptor": "\nComments: 6 pages, 5 figures, submitted to HotMobile 2021\n",
    "authors": [
      "Byungjin Jun",
      "Fabian E. Bustamante",
      "Ben Greenstein",
      "Ian Clelland"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.09960"
  },
  {
    "id": "arXiv:2111.09961",
    "title": "A Review of Adversarial Attack and Defense for Classification Methods",
    "abstract": "Despite the efficiency and scalability of machine learning systems, recent\nstudies have demonstrated that many classification methods, especially deep\nneural networks (DNNs), are vulnerable to adversarial examples; i.e., examples\nthat are carefully crafted to fool a well-trained classification model while\nbeing indistinguishable from natural data to human. This makes it potentially\nunsafe to apply DNNs or related methods in security-critical areas. Since this\nissue was first identified by Biggio et al. (2013) and Szegedy et al.(2014),\nmuch work has been done in this field, including the development of attack\nmethods to generate adversarial examples and the construction of defense\ntechniques to guard against such examples. This paper aims to introduce this\ntopic and its latest developments to the statistical community, primarily\nfocusing on the generation and guarding of adversarial examples. Computing\ncodes (in python and R) used in the numerical experiments are publicly\navailable for readers to explore the surveyed methods. It is the hope of the\nauthors that this paper will encourage more statisticians to work on this\nimportant and exciting field of generating and defending against adversarial\nexamples.",
    "descriptor": "",
    "authors": [
      "Yao Li",
      "Minhao Cheng",
      "Cho-Jui Hsieh",
      "Thomas C. M. Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09961"
  },
  {
    "id": "arXiv:2111.09963",
    "title": "Beyond NDCG: behavioral testing of recommender systems with RecList",
    "abstract": "As with most Machine Learning systems, recommender systems are typically\nevaluated through performance metrics computed over held-out data points.\nHowever, real-world behavior is undoubtedly nuanced: ad hoc error analysis and\ndeployment-specific tests must be employed to ensure the desired quality in\nactual deployments. In this paper, we propose RecList, a behavioral-based\ntesting methodology. RecList organizes recommender systems by use case and\nintroduces a general plug-and-play procedure to scale up behavioral testing. We\ndemonstrate its capabilities by analyzing known algorithms and black-box\ncommercial systems, and we release RecList as an open source, extensible\npackage for the community.",
    "descriptor": "\nComments: Alpha draft\n",
    "authors": [
      "Patrick John Chia",
      "Jacopo Tagliabue",
      "Federico Bianchi",
      "Chloe He",
      "Brian Ko"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09963"
  },
  {
    "id": "arXiv:2111.09971",
    "title": "Learning Robust Output Control Barrier Functions from Safe Expert  Demonstrations",
    "abstract": "This paper addresses learning safe control laws from expert demonstrations.\nWe assume that appropriate models of the system dynamics and the output\nmeasurement map are available, along with corresponding error bounds. We first\npropose robust output control barrier functions (ROCBFs) as a means to\nguarantee safety, as defined through controlled forward invariance of a safe\nset. We then present an optimization problem to learn ROCBFs from expert\ndemonstrations that exhibit safe system behavior, e.g., data collected from a\nhuman operator. Along with the optimization problem, we provide verifiable\nconditions that guarantee validity of the obtained ROCBF. These conditions are\nstated in terms of the density of the data and on Lipschitz and boundedness\nconstants of the learned function and the models of the system dynamics and the\noutput measurement map. When the parametrization of the ROCBF is linear, then,\nunder mild assumptions, the optimization problem is convex. We validate our\nfindings in the autonomous driving simulator CARLA and show how to learn safe\ncontrol laws from RGB camera images.",
    "descriptor": "\nComments: 30 pages, submitted to the IEEE Transactions on Automatic Control\n",
    "authors": [
      "Lars Lindemann",
      "Alexander Robey",
      "Lejun Jiang",
      "Stephen Tu",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09971"
  },
  {
    "id": "arXiv:2111.09975",
    "title": "Malfustection: Obfuscated Malware Detection and Malware Classification  with Data Shortage by Combining Semi-Supervised and Contrastive Learning",
    "abstract": "With the advent of new technologies, using various formats of digital gadgets\nis becoming widespread. In today's world, where everyday tasks are inevitable\nwithout technology, this extensive use of computers paves the way for malicious\nactivity. As a result, it is important to provide solutions to defend against\nthese threats. Malware is one of the well-known and widely used means utilized\nfor doing destructive activities by malicious attackers. Producing malware from\nscratch is somewhat difficult, so attackers tend to obfuscate existing malware\nand prepare it to become an unrecognizable program. Since creating new malware\nfrom an old one using obfuscation is a creative task, there are some drawbacks\nto identifying obfuscated malwares. In this research, we propose a solution to\novercome this problem by converting the code to an image in the first step and\nthen using a semi-supervised approach combined with contrastive learning. In\nthis case, an obfuscation in the malware bytecode corresponds to an\naugmentation in the image. Hence, by utilizing meaningful augmentations, which\nsimulate some obfuscation changes and combine them to generate complex\nambiguity procedures, our proposed solution is able to construct, learn, and\ndetect a wide range of obfuscations. This work addresses two issues: 1) malware\nclassification despite the data deficiency and 2) obfuscated malware detection\nby training on non-obfuscated malwares. According to the results, the proposed\nmethod overcomes the data shortage problem in malware classification, as its\naccuracy is 90.1% when just 10% of data is used for training the model.\nMoreover, training on basic malwares without obfuscation achieved 96.21 percent\naccuracy in detecting obfuscated malware.",
    "descriptor": "",
    "authors": [
      "Mohammad Mahdi Maghouli",
      "Mohamadreza Fereydooni",
      "Monireh Abdoos",
      "Mojtaba Vahidi-Asl"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.09975"
  },
  {
    "id": "arXiv:2111.09976",
    "title": "M2A: Motion Aware Attention for Accurate Video Action Recognition",
    "abstract": "Advancements in attention mechanisms have led to significant performance\nimprovements in a variety of areas in machine learning due to its ability to\nenable the dynamic modeling of temporal sequences. A particular area in\ncomputer vision that is likely to benefit greatly from the incorporation of\nattention mechanisms in video action recognition. However, much of the current\nresearch's focus on attention mechanisms have been on spatial and temporal\nattention, which are unable to take advantage of the inherent motion found in\nvideos. Motivated by this, we develop a new attention mechanism called Motion\nAware Attention (M2A) that explicitly incorporates motion characteristics. More\nspecifically, M2A extracts motion information between consecutive frames and\nutilizes attention to focus on the motion patterns found across frames to\naccurately recognize actions in videos. The proposed M2A mechanism is simple to\nimplement and can be easily incorporated into any neural network backbone\narchitecture. We show that incorporating motion mechanisms with attention\nmechanisms using the proposed M2A mechanism can lead to a +15% to +26%\nimprovement in top-1 accuracy across different backbone architectures, with\nonly a small increase in computational complexity. We further compared the\nperformance of M2A with other state-of-the-art motion and attention mechanisms\non the Something-Something V1 video action recognition benchmark. Experimental\nresults showed that M2A can lead to further improvements when combined with\nother temporal mechanisms and that it outperforms other motion-only or\nattention-only mechanisms by as much as +60% in top-1 accuracy for specific\nclasses in the benchmark.",
    "descriptor": "",
    "authors": [
      "Brennan Gebotys",
      "Alexander Wong",
      "David A. Clausi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09976"
  },
  {
    "id": "arXiv:2111.09985",
    "title": "DeMFI: Deep Joint Deblurring and Multi-Frame Interpolation with  Flow-Guided Attentive Correlation and Recursive Boosting",
    "abstract": "In this paper, we propose a novel joint deblurring and multi-frame\ninterpolation (DeMFI) framework, called DeMFI-Net, which accurately converts\nblurry videos of lower-frame-rate to sharp videos at higher-frame-rate based on\nflow-guided attentive-correlation-based feature bolstering (FAC-FB) module and\nrecursive boosting (RB), in terms of multi-frame interpolation (MFI). The\nDeMFI-Net jointly performs deblurring and MFI where its baseline version\nperforms feature-flow-based warping with FAC-FB module to obtain a\nsharp-interpolated frame as well to deblur two center-input frames. Moreover,\nits extended version further improves the joint task performance based on\npixel-flow-based warping with GRU-based RB. Our FAC-FB module effectively\ngathers the distributed blurry pixel information over blurry input frames in\nfeature-domain to improve the overall joint performances, which is\ncomputationally efficient since its attentive correlation is only focused\npointwise. As a result, our DeMFI-Net achieves state-of-the-art (SOTA)\nperformances for diverse datasets with significant margins compared to the\nrecent SOTA methods, for both deblurring and MFI. All source codes including\npretrained DeMFI-Net are publicly available at\nhttps://github.com/JihyongOh/DeMFI.",
    "descriptor": "\nComments: 18 pages, 16 figures, 4 tables, GitHub page: this https URL\n",
    "authors": [
      "Jihyong Oh",
      "Munchurl Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09985"
  },
  {
    "id": "arXiv:2111.09986",
    "title": "Boost Distribution System Restoration with Emergency Communication  Vehicles Considering Cyber-Physical Interdependence",
    "abstract": "Enhancing restoration capabilities of distribution systems is one of the main\nstrategies for resilient power systems to cope with extreme events. However,\nmost of the existing studies assume the communication infrastructures are\nintact for distribution automation, which is unrealistic. Motivated by the\napplications of the emergency communication vehicles (ECVs) in quickly setting\nup wireless communication networks after disasters, in this paper, we propose\nan integrated distribution system restoration (DSR) framework and optimization\nmodels, which can coordinate the repair crews, the distribution system\n(physical sectors), and the emergency communication (cyber sectors) to pick up\nunserved customers as quickly as possible. Case studies validated the\neffectiveness of the proposed models and proved the benefit of considering ECVs\nand cyber-physical interdependencies in DSR.",
    "descriptor": "",
    "authors": [
      "Zhigang Ye",
      "Chen Chen",
      "Ruihuan Liu",
      "Kai Wu",
      "Zhaohong Bie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.09986"
  },
  {
    "id": "arXiv:2111.09991",
    "title": "Sketch-based Creativity Support Tools using Deep Learning",
    "abstract": "Sketching is a natural and effective visual communication medium commonly\nused in creative processes. Recent developments in deep-learning models\ndrastically improved machines' ability in understanding and generating visual\ncontent. An exciting area of development explores deep-learning approaches used\nto model human sketches, opening opportunities for creative applications. This\nchapter describes three fundamental steps in developing deep-learning-driven\ncreativity support tools that consumes and generates sketches: 1) a data\ncollection effort that generated a new paired dataset between sketches and\nmobile user interfaces; 2) a sketch-based user interface retrieval system\nadapted from state-of-the-art computer vision techniques; and, 3) a\nconversational sketching system that supports the novel interaction of a\nnatural-language-based sketch/critique authoring process. In this chapter, we\nsurvey relevant prior work in both the deep-learning and\nhuman-computer-interaction communities, document the data collection process\nand the systems' architectures in detail, present qualitative and quantitative\nresults, and paint the landscape of several future research directions in this\nexciting area.",
    "descriptor": "\nComments: Preprint of chapter in published in \"Artificial Intelligence for Human Computer Interaction: A Modern Approach\". arXiv admin note: substantial text overlap with arXiv:2005.07781\n",
    "authors": [
      "Forrest Huang",
      "Eldon Schoop",
      "David Ha",
      "Jeffrey Nichols",
      "John Canny"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09991"
  },
  {
    "id": "arXiv:2111.09993",
    "title": "Esophageal virtual disease landscape using mechanics-informed machine  learning",
    "abstract": "The pathogenesis of esophageal disorders is related to the esophageal wall\nmechanics. Therefore, to understand the underlying fundamental mechanisms\nbehind various esophageal disorders, it is crucial to map the esophageal wall\nmechanics-based parameters onto physiological and pathophysiological conditions\ncorresponding to altered bolus transit and supraphysiologic IBP. In this work,\nwe present a hybrid framework that combines fluid mechanics and machine\nlearning to identify the underlying physics of the various esophageal disorders\nand maps them onto a parameter space which we call the virtual disease\nlandscape (VDL). A one-dimensional inverse model processes the output from an\nesophageal diagnostic device called endoscopic functional lumen imaging probe\n(EndoFLIP) to estimate the mechanical \"health\" of the esophagus by predicting a\nset of mechanics-based parameters such as esophageal wall stiffness, muscle\ncontraction pattern and active relaxation of esophageal walls. The\nmechanics-based parameters were then used to train a neural network that\nconsists of a variational autoencoder (VAE) that generates a latent space and a\nside network that predicts mechanical work metrics for estimating\nesophagogastric junction motility. The latent vectors along with a set of\ndiscrete mechanics-based parameters define the VDL and form clusters\ncorresponding to the various esophageal disorders. The VDL not only\ndistinguishes different disorders but can also be used to predict disease\nprogression in time. Finally, we also demonstrate the clinical applicability of\nthis framework for estimating the effectiveness of a treatment and track\npatient condition after a treatment.",
    "descriptor": "\nComments: 26 pages, 17 figures\n",
    "authors": [
      "Sourav Halder",
      "Jun Yamasaki",
      "Shashank Acharya",
      "Wenjun Kou",
      "Guy Elisha",
      "Dustin A. Carlson",
      "Peter J. Kahrilas",
      "John E. Pandolfino",
      "Neelesh A. Patankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.09993"
  },
  {
    "id": "arXiv:2111.09996",
    "title": "LOLNeRF: Learn from One Look",
    "abstract": "We present a method for learning a generative 3D model based on neural\nradiance fields, trained solely from data with only single views of each\nobject. While generating realistic images is no longer a difficult task,\nproducing the corresponding 3D structure such that they can be rendered from\ndifferent views is non-trivial. We show that, unlike existing methods, one does\nnot need multi-view data to achieve this goal. Specifically, we show that by\nreconstructing many images aligned to an approximate canonical pose with a\nsingle network conditioned on a shared latent space, you can learn a space of\nradiance fields that models shape and appearance for a class of objects. We\ndemonstrate this by training models to reconstruct object categories using\ndatasets that contain only one view of each subject without depth or geometry\ninformation. Our experiments show that we achieve state-of-the-art results in\nnovel view synthesis and competitive results for monocular depth prediction.",
    "descriptor": "",
    "authors": [
      "Daniel Rebain",
      "Mark Matthews",
      "Kwang Moo Yi",
      "Dmitry Lagun",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09996"
  },
  {
    "id": "arXiv:2111.09999",
    "title": "TnT Attacks! Universal Naturalistic Adversarial Patches Against Deep  Neural Network Systems",
    "abstract": "Deep neural networks are vulnerable to attacks from adversarial inputs and,\nmore recently, Trojans to misguide or hijack the decision of the model. We\nexpose the existence of an intriguing class of bounded adversarial examples --\nUniversal NaTuralistic adversarial paTches -- we call TnTs, by exploring the\nsuperset of the bounded adversarial example space and the natural input space\nwithin generative adversarial networks. Now, an adversary can arm themselves\nwith a patch that is naturalistic, less malicious-looking, physically\nrealizable, highly effective -- achieving high attack success rates, and\nuniversal. A TnT is universal because any input image captured with a TnT in\nthe scene will: i) misguide a network (untargeted attack); or ii) force the\nnetwork to make a malicious decision (targeted attack). Interestingly, now, an\nadversarial patch attacker has the potential to exert a greater level of\ncontrol -- the ability to choose a location independent, natural-looking patch\nas a trigger in contrast to being constrained to noisy perturbations -- an\nability is thus far shown to be only possible with Trojan attack methods\nneeding to interfere with the model building processes to embed a backdoor at\nthe risk discovery; but, still realize a patch deployable in the physical\nworld. Through extensive experiments on the large-scale visual classification\ntask, ImageNet with evaluations across its entire validation set of 50,000\nimages, we demonstrate the realistic threat from TnTs and the robustness of the\nattack. We show a generalization of the attack to create patches achieving\nhigher attack success rates than existing state-of-the-art methods. Our results\nshow the generalizability of the attack to different visual classification\ntasks (CIFAR-10, GTSRB, PubFig) and multiple state-of-the-art deep neural\nnetworks such as WideResnet50, Inception-V3 and VGG-16.",
    "descriptor": "\nComments: We demonstrate physical deployments in multiple videos at this https URL\n",
    "authors": [
      "Bao Gia Doan",
      "Minhui Xue",
      "Shiqing Ma",
      "Ehsan Abbasnejad",
      "Damith C. Ranasinghe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.09999"
  },
  {
    "id": "arXiv:2111.10003",
    "title": "Differentiable Wavetable Synthesis",
    "abstract": "Differentiable Wavetable Synthesis (DWTS) is a technique for neural audio\nsynthesis which learns a dictionary of one-period waveforms i.e. wavetables,\nthrough end-to-end training. We achieve high-fidelity audio synthesis with as\nlittle as 10 to 20 wavetables and demonstrate how a data-driven dictionary of\nwaveforms opens up unprecedented one-shot learning paradigms on short audio\nclips. Notably, we show audio manipulations, such as high quality\npitch-shifting, using only a few seconds of input audio. Lastly, we investigate\nperformance gains from using learned wavetables for realtime and interactive\naudio synthesis.",
    "descriptor": "\nComments: Demo: this https URL\n",
    "authors": [
      "Siyuan Shan",
      "Lamtharn Hantrakul",
      "Jitong Chen",
      "Matt Avent",
      "David Trevelyan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.10003"
  },
  {
    "id": "arXiv:2111.10005",
    "title": "Reinforcement Learning with Adaptive Curriculum Dynamics Randomization  for Fault-Tolerant Robot Control",
    "abstract": "This study is aimed at addressing the problem of fault tolerance of quadruped\nrobots to actuator failure, which is critical for robots operating in remote or\nextreme environments. In particular, an adaptive curriculum reinforcement\nlearning algorithm with dynamics randomization (ACDR) is established. The ACDR\nalgorithm can adaptively train a quadruped robot in random actuator failure\nconditions and formulate a single robust policy for fault-tolerant robot\ncontrol. It is noted that the hard2easy curriculum is more effective than the\neasy2hard curriculum for quadruped robot locomotion. The ACDR algorithm can be\nused to build a robot system that does not require additional modules for\ndetecting actuator failures and switching policies. Experimental results show\nthat the ACDR algorithm outperforms conventional algorithms in terms of the\naverage reward and walking distance.",
    "descriptor": "\nComments: 8 pages, 9 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Wataru Okamoto",
      "Hiroshi Kera",
      "Kazuhiko Kawamoto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10005"
  },
  {
    "id": "arXiv:2111.10007",
    "title": "FBNetV5: Neural Architecture Search for Multiple Tasks in One Run",
    "abstract": "Neural Architecture Search (NAS) has been widely adopted to design accurate\nand efficient image classification models. However, applying NAS to a new\ncomputer vision task still requires a huge amount of effort. This is because 1)\nprevious NAS research has been over-prioritized on image classification while\nlargely ignoring other tasks; 2) many NAS works focus on optimizing\ntask-specific components that cannot be favorably transferred to other tasks;\nand 3) existing NAS methods are typically designed to be \"proxyless\" and\nrequire significant effort to be integrated with each new task's training\npipelines. To tackle these challenges, we propose FBNetV5, a NAS framework that\ncan search for neural architectures for a variety of vision tasks with much\nreduced computational cost and human effort. Specifically, we design 1) a\nsearch space that is simple yet inclusive and transferable; 2) a multitask\nsearch process that is disentangled with target tasks' training pipeline; and\n3) an algorithm to simultaneously search for architectures for multiple tasks\nwith a computational cost agnostic to the number of tasks. We evaluate the\nproposed FBNetV5 targeting three fundamental vision tasks -- image\nclassification, object detection, and semantic segmentation. Models searched by\nFBNetV5 in a single run of search have outperformed the previous\nstateof-the-art in all the three tasks: image classification (e.g., +1.3%\nImageNet top-1 accuracy under the same FLOPs as compared to FBNetV3), semantic\nsegmentation (e.g., +1.8% higher ADE20K val. mIoU than SegFormer with 3.6x\nfewer FLOPs), and object detection (e.g., +1.1% COCO val. mAP with 1.2x fewer\nFLOPs as compared to YOLOX).",
    "descriptor": "",
    "authors": [
      "Bichen Wu",
      "Chaojian Li",
      "Hang Zhang",
      "Xiaoliang Dai",
      "Peizhao Zhang",
      "Matthew Yu",
      "Jialiang Wang",
      "Yingyan Lin",
      "Peter Vajda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10007"
  },
  {
    "id": "arXiv:2111.10010",
    "title": "UN-AVOIDS: Unsupervised and Nonparametric Approach for Visualizing  Outliers and Invariant Detection Scoring",
    "abstract": "The visualization and detection of anomalies (outliers) are of crucial\nimportance to many fields, particularly cybersecurity. Several approaches have\nbeen proposed in these fields, yet to the best of our knowledge, none of them\nhas fulfilled both objectives, simultaneously or cooperatively, in one coherent\nframework. The visualization methods of these approaches were introduced for\nexplaining the output of a detection algorithm, not for data exploration that\nfacilitates a standalone visual detection. This is our point of departure:\nUN-AVOIDS, an unsupervised and nonparametric approach for both visualization (a\nhuman process) and detection (an algorithmic process) of outliers, that assigns\ninvariant anomalous scores (normalized to $[0,1]$), rather than hard\nbinary-decision. The main aspect of novelty of UN-AVOIDS is that it transforms\ndata into a new space, which is introduced in this paper as neighborhood\ncumulative density function (NCDF), in which both visualization and detection\nare carried out. In this space, outliers are remarkably visually\ndistinguishable, and therefore the anomaly scores assigned by the detection\nalgorithm achieved a high area under the ROC curve (AUC). We assessed UN-AVOIDS\non both simulated and two recently published cybersecurity datasets, and\ncompared it to three of the most successful anomaly detection methods: LOF, IF,\nand FABOD. In terms of AUC, UN-AVOIDS was almost an overall winner. The article\nconcludes by providing a preview of new theoretical and practical avenues for\nUN-AVOIDS. Among them is designing a visualization aided anomaly detection\n(VAAD), a type of software that aids analysts by providing UN-AVOIDS' detection\nalgorithm (running in a back engine), NCDF visualization space (rendered to\nplots), along with other conventional methods of visualization in the original\nfeature space, all of which are linked in one interactive environment.",
    "descriptor": "",
    "authors": [
      "Waleed A.Yousef",
      "Issa Traore",
      "William Briguglio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.10010"
  },
  {
    "id": "arXiv:2111.10014",
    "title": "CoCAtt: A Cognitive-Conditioned Driver Attention Dataset",
    "abstract": "The task of driver attention prediction has drawn considerable interest among\nresearchers in robotics and the autonomous vehicle industry. Driver attention\nprediction can play an instrumental role in mitigating and preventing high-risk\nevents, like collisions and casualties. However, existing driver attention\nprediction models neglect the distraction state and intention of the driver,\nwhich can significantly influence how they observe their surroundings. To\naddress these issues, we present a new driver attention dataset, CoCAtt\n(Cognitive-Conditioned Attention). Unlike previous driver attention datasets,\nCoCAtt includes per-frame annotations that describe the distraction state and\nintention of the driver. In addition, the attention data in our dataset is\ncaptured in both manual and autopilot modes using eye-tracking devices of\ndifferent resolutions. Our results demonstrate that incorporating the above two\ndriver states into attention modeling can improve the performance of driver\nattention prediction. To the best of our knowledge, this work is the first to\nprovide autopilot attention data. Furthermore, CoCAtt is currently the largest\nand the most diverse driver attention dataset in terms of autonomy levels, eye\ntracker resolutions, and driving scenarios.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Yuan Shen",
      "Niviru Wijayaratne",
      "Pranav Sriram",
      "Aamir Hasan",
      "Peter Du",
      "Katie Driggs-Campbell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10014"
  },
  {
    "id": "arXiv:2111.10017",
    "title": "Rethinking Query, Key, and Value Embedding in Vision Transformer under  Tiny Model Constraints",
    "abstract": "A vision transformer (ViT) is the dominant model in the computer vision\nfield. Despite numerous studies that mainly focus on dealing with inductive\nbias and complexity, there remains the problem of finding better transformer\nnetworks. For example, conventional transformer-based models usually use a\nprojection layer for each query (Q), key (K), and value (V) embedding before\nmulti-head self-attention. Insufficient consideration of semantic $Q, K$, and\n$V$ embedding may lead to a performance drop. In this paper, we propose three\ntypes of structures for $Q$, $K$, and $V$ embedding. The first structure\nutilizes two layers with ReLU, which is a non-linear embedding for $Q, K$, and\n$V$. The second involves sharing one of the non-linear layers to share\nknowledge among $Q, K$, and $V$. The third proposed structure shares all\nnon-linear layers with code parameters. The codes are trainable, and the values\ndetermine the embedding process to be performed among $Q$, $K$, and $V$. Hence,\nwe demonstrate the superior image classification performance of the proposed\napproaches in experiments compared to several state-of-the-art approaches. The\nproposed method achieved $71.4\\%$ with a few parameters (of $3.1M$) on the\nImageNet-1k dataset compared to that required by the original transformer model\nof XCiT-N12 ($69.9\\%$). Additionally, the method achieved $93.3\\%$ with only\n$2.9M$ parameters in transfer learning on average for the CIFAR-10, CIFAR-100,\nStanford Cars datasets, and STL-10 datasets, which is better than the accuracy\nof $92.2\\%$ obtained via the original XCiT-N12 model.",
    "descriptor": "",
    "authors": [
      "Jaesin Ahn",
      "Jiuk Hong",
      "Jeongwoo Ju",
      "Heechul Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10017"
  },
  {
    "id": "arXiv:2111.10023",
    "title": "UFO: A UniFied TransfOrmer for Vision-Language Representation Learning",
    "abstract": "In this paper, we propose a single UniFied transfOrmer (UFO), which is\ncapable of processing either unimodal inputs (e.g., image or language) or\nmultimodal inputs (e.g., the concatenation of the image and the question), for\nvision-language (VL) representation learning. Existing approaches typically\ndesign an individual network for each modality and/or a specific fusion network\nfor multimodal tasks. To simplify the network architecture, we use a single\ntransformer network and enforce multi-task learning during VL pre-training,\nwhich includes the image-text contrastive loss, image-text matching loss, and\nmasked language modeling loss based on the bidirectional and the seq2seq\nattention mask. The same transformer network is used as the image encoder, the\ntext encoder, or the fusion network in different pre-training tasks.\nEmpirically, we observe less conflict among different tasks and achieve new\nstate of the arts on visual question answering, COCO image captioning\n(cross-entropy optimization) and nocaps (in SPICE). On other downstream tasks,\ne.g., image-text retrieval, we also achieve competitive performance.",
    "descriptor": "",
    "authors": [
      "Jianfeng Wang",
      "Xiaowei Hu",
      "Zhe Gan",
      "Zhengyuan Yang",
      "Xiyang Dai",
      "Zicheng Liu",
      "Yumao Lu",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10023"
  },
  {
    "id": "arXiv:2111.10027",
    "title": "E3NE: An End-to-End Framework for Accelerating Spiking Neural Networks  with Emerging Neural Encoding on FPGAs",
    "abstract": "Compiler frameworks are crucial for the widespread use of FPGA-based deep\nlearning accelerators. They allow researchers and developers, who are not\nfamiliar with hardware engineering, to harness the performance attained by\ndomain-specific logic. There exists a variety of frameworks for conventional\nartificial neural networks. However, not much research effort has been put into\nthe creation of frameworks optimized for spiking neural networks (SNNs). This\nnew generation of neural networks becomes increasingly interesting for the\ndeployment of AI on edge devices, which have tight power and resource\nconstraints. Our end-to-end framework E3NE automates the generation of\nefficient SNN inference logic for FPGAs. Based on a PyTorch model and user\nparameters, it applies various optimizations and assesses trade-offs inherent\nto spike-based accelerators. Multiple levels of parallelism and the use of an\nemerging neural encoding scheme result in an efficiency superior to previous\nSNN hardware implementations. For a similar model, E3NE uses less than 50% of\nhardware resources and 20% less power, while reducing the latency by an order\nof magnitude. Furthermore, scalability and generality allowed the deployment of\nthe large-scale SNN models AlexNet and VGG.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Parallel and Distributed Systems\n",
    "authors": [
      "Daniel Gerlinghoff",
      "Zhehui Wang",
      "Xiaozhe Gu",
      "Rick Siow Mong Goh",
      "Tao Luo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.10027"
  },
  {
    "id": "arXiv:2111.10031",
    "title": "Novel Real-Time EMT-TS Modeling Architecture for Feeder Blackstart  Simulations",
    "abstract": "This paper presents the development and benchmarking of a novel real-time\nelectromagnetic-transient and transient-stability (EMT-TS) modeling\narchitecture for distribution feeder restoration studies. The work presents for\nthe first time in the literature a real-time EMT-TS testbed in which the\ngrid-forming unit is simulated in EMT domain, operating as the slack bus of the\nphasor domain while including unbalanced voltage conditions. To evaluate the\nperformance and limitations of the proposed model, an equivalent EMT testbed is\ndeveloped to serve as a benchmark. First, the co-simulation framework and the\ndomain coupling methodology are introduced. Next, the steady-state operation of\nthe EMT-TS and EMT models are matched. Then, tests are conducted to analyze the\ntransient performance of the proposed EMT-TS model when compared to its EMT\nbenchmark. Results reveal that when utilizing a battery energy storage system\n(BESS) as the grid-forming unit, the EMT-TS testbed can maintain high accuracy\nfor typical load steps.",
    "descriptor": "\nComments: Submitted to 2022 PESGM\n",
    "authors": [
      "Victor Paduani",
      "Bei Xu",
      "David Lubkeman",
      "Ning Lu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10031"
  },
  {
    "id": "arXiv:2111.10032",
    "title": "Meta Clustering Learning for Large-scale Unsupervised Person  Re-identification",
    "abstract": "Unsupervised Person Re-identification (U-ReID) with pseudo labeling recently\nreaches a competitive performance compared to fully-supervised ReID methods\nbased on modern clustering algorithms. However, such clustering-based scheme\nbecomes computationally prohibitive for large-scale datasets. How to\nefficiently leverage endless unlabeled data with limited computing resources\nfor better U-ReID is under-explored. In this paper, we make the first attempt\nto the large-scale U-ReID and propose a \"small data for big task\" paradigm\ndubbed Meta Clustering Learning (MCL). MCL only pseudo-labels a subset of the\nentire unlabeled data via clustering to save computing for the first-phase\ntraining. After that, the learned cluster centroids, termed as meta-prototypes\nin our MCL, are regarded as a proxy annotator to softly annotate the rest\nunlabeled data for further polishing the model. To alleviate the potential\nnoisy labeling issue in the polishment phase, we enforce two well-designed loss\nconstraints to promise intra-identity consistency and inter-identity strong\ncorrelation. For multiple widely-used U-ReID benchmarks, our method\nsignificantly saves computational cost while achieving a comparable or even\nbetter performance compared to prior works.",
    "descriptor": "",
    "authors": [
      "Xin Jin",
      "Tianyu He",
      "Zhiheng Yin",
      "Xu Shen",
      "Tongliang Liu",
      "Xinchao Wang",
      "Jianqiang Huang",
      "Xian-Sheng Hua",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10032"
  },
  {
    "id": "arXiv:2111.10037",
    "title": "Explaining GNN over Evolving Graphs using Information Flow",
    "abstract": "Graphs are ubiquitous in many applications, such as social networks,\nknowledge graphs, smart grids, etc.. Graph neural networks (GNN) are the\ncurrent state-of-the-art for these applications, and yet remain obscure to\nhumans. Explaining the GNN predictions can add transparency. However, as many\ngraphs are not static but continuously evolving, explaining changes in\npredictions between two graph snapshots is different but equally important.\nPrior methods only explain static predictions or generate coarse or irrelevant\nexplanations for dynamic predictions. We define the problem of explaining\nevolving GNN predictions and propose an axiomatic attribution method to\nuniquely decompose the change in a prediction to paths on computation graphs.\nThe attribution to many paths involving high-degree nodes is still not\ninterpretable, while simply selecting the top important paths can be suboptimal\nin approximating the change. We formulate a novel convex optimization problem\nto optimally select the paths that explain the prediction evolution.\nTheoretically, we prove that the existing method based on\nLayer-Relevance-Propagation (LRP) is a special case of the proposed algorithm\nwhen an empty graph is compared with. Empirically, on seven graph datasets,\nwith a novel metric designed for evaluating explanations of prediction change,\nwe demonstrate the superiority of the proposed approach over existing methods,\nincluding LRP, DeepLIFT, and other path selection methods.",
    "descriptor": "",
    "authors": [
      "Yazheng Liu",
      "Xi Zhang",
      "Sihong Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.10037"
  },
  {
    "id": "arXiv:2111.10039",
    "title": "Modeling Flash Memory Channels Using Conditional Generative Nets",
    "abstract": "Understanding the NAND flash memory channel has become more and more\nchallenging due to the continually increasing density and the complex\ndistortions arising from the write and read mechanisms. In this work, we\npropose a data-driven generative modeling method to characterize the flash\nmemory channel. The learned model can reconstruct the read voltage from an\nindividual memory cell based on the program levels of the cell and its\nsurrounding array of cells. Experimental results show that the statistical\ndistribution of the reconstructed read voltages accurately reflects the\nmeasured distribution on a commercial flash memory chip, both qualitatively and\nas quantified by the total variation distance. Moreover, we observe that the\nlearned model can capture precise inter-cell interference (ICI) effects, as\nverified by comparison of the error probabilities of specific patterns in\nwordlines and bitlines.",
    "descriptor": "",
    "authors": [
      "Simeng Zheng",
      "Chih-Hui Ho",
      "Paul H. Siegel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10039"
  },
  {
    "id": "arXiv:2111.10041",
    "title": "Embeddings and labeling schemes for A*",
    "abstract": "A* is a classic and popular method for graphs search and path finding. It\nassumes the existence of a heuristic function $h(u,t)$ that estimates the\nshortest distance from any input node $u$ to the destination $t$.\nTraditionally, heuristics have been handcrafted by domain experts. However,\nover the last few years, there has been a growing interest in learning\nheuristic functions. Such learned heuristics estimate the distance between\ngiven nodes based on \"features\" of those nodes.\nIn this paper we formalize and initiate the study of such feature-based\nheuristics. In particular, we consider heuristics induced by norm embeddings\nand distance labeling schemes, and provide lower bounds for the tradeoffs\nbetween the number of dimensions or bits used to represent each graph node, and\nthe running time of the A* algorithm. We also show that, under natural\nassumptions, our lower bounds are almost optimal.",
    "descriptor": "\nComments: ITCS 2022\n",
    "authors": [
      "Talya Eden",
      "Piotr Indyk",
      "Haike Xu"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10041"
  },
  {
    "id": "arXiv:2111.10042",
    "title": "Functional equivariance and conservation laws in numerical integration",
    "abstract": "Preservation of linear and quadratic invariants by numerical integrators has\nbeen well studied. However, many systems have linear or quadratic observables\nthat are not invariant, but which satisfy evolution equations expressing\nimportant properties of the system. For example, a time-evolution PDE may have\nan observable that satisfies a local conservation law, such as the\nmultisymplectic conservation law for Hamiltonian PDEs.\nWe introduce the concept of functional equivariance, a natural sense in which\na numerical integrator may preserve the dynamics satisfied by certain classes\nof observables, whether or not they are invariant. After developing the general\nframework, we use it to obtain results on methods preserving local conservation\nlaws in PDEs. In particular, integrators preserving quadratic invariants also\npreserve local conservation laws for quadratic observables, and symplectic\nintegrators are multisymplectic.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Robert I. McLachlan",
      "Ari Stern"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.10042"
  },
  {
    "id": "arXiv:2111.10044",
    "title": "Building a Question Answering System for the Manufacturing Domain",
    "abstract": "The design or simulation analysis of special equipment products must follow\nthe national standards, and hence it may be necessary to repeatedly consult the\ncontents of the standards in the design process. However, it is difficult for\nthe traditional question answering system based on keyword retrieval to give\naccurate answers to technical questions. Therefore, we use natural language\nprocessing techniques to design a question answering system for the\ndecision-making process in pressure vessel design. To solve the problem of\ninsufficient training data for the technology question answering system, we\npropose a method to generate questions according to a declarative sentence from\nseveral different dimensions so that multiple question-answer pairs can be\nobtained from a declarative sentence. In addition, we designed an interactive\nattention model based on a bidirectional long short-term memory (BiLSTM)\nnetwork to improve the performance of the similarity comparison of two question\nsentences. Finally, the performance of the question answering system was tested\non public and technical domain datasets.",
    "descriptor": "",
    "authors": [
      "Liu Xingguang",
      "Cheng Zhenbo",
      "Shen Zhengyuan",
      "Zhang Haoxin",
      "Meng Hangcheng",
      "Xu Xuesong",
      "Xiao Gang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10044"
  },
  {
    "id": "arXiv:2111.10046",
    "title": "YMIR: A Rapid Data-centric Development Platform for Vision Applications",
    "abstract": "This paper introduces an open source platform for rapid development of\ncomputer vision applications. The platform puts the efficient data development\nat the center of the machine learning development process, integrates active\nlearning methods, data and model version control, and uses concepts such as\nprojects to enable fast iteration of multiple task specific datasets in\nparallel. We make it an open platform by abstracting the development process\ninto core states and operations, and design open APIs to integrate third party\ntools as implementations of the operations. This open design reduces the\ndevelopment cost and adoption cost for ML teams with existing tools. At the\nsame time, the platform supports recording project development history, through\nwhich successful projects can be shared to further boost model production\nefficiency on similar tasks. The platform is open source and is already used\ninternally to meet the increasing demand from custom real world computer vision\napplications.",
    "descriptor": "",
    "authors": [
      "Phoenix X. Huang",
      "Wenze Hu",
      "William Brendel",
      "Manmohan Chandraker",
      "Li-Jia Li",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10046"
  },
  {
    "id": "arXiv:2111.10048",
    "title": "Uniform Brackets, Containers, and Combinatorial Macbeath Regions",
    "abstract": "We study the connections between three seemingly different combinatorial\nstructures - \"uniform\" brackets in statistics and probability theory,\n\"containers\" in online and distributed learning theory, and \"combinatorial\nMacbeath regions\", or Mnets in discrete and computational geometry. We show\nthat these three concepts are manifestations of a single combinatorial property\nthat can be expressed under a unified framework along the lines of\nVapnik-Chervonenkis type theory for uniform convergence. These new connections\nhelp us to bring tools from discrete and computational geometry to prove\nimproved bounds for these objects. Our improved bounds help to get an optimal\nalgorithm for distributed learning of halfspaces, an improved algorithm for the\ndistributed convex set disjointness problem, and improved regret bounds for\nonline algorithms against a smoothed adversary for a large class of\nsemi-algebraic threshold functions.",
    "descriptor": "\nComments: 21 pages. Full version of the ITCS'22 paper with the same title\n",
    "authors": [
      "Kunal Dutta",
      "Arijit Ghosh",
      "Shay Moran"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10048"
  },
  {
    "id": "arXiv:2111.10049",
    "title": "Formalization of Transform Methods in Higher-order Logic: A Survey",
    "abstract": "Most of the engineering and physical systems are generally characterized by\ndifferential and difference equations based on their continuous-time and\ndiscrete-time dynamics, respectively. Moreover, these dynamical models are\nanalyzed using transform methods to prove various properties of these systems,\nsuch as, transfer function, frequency response and stability, and to find out\nsolutions of the differential/difference equations. The conventional techniques\nfor performing the transform methods based analysis have been unable to provide\nan accurate analysis of these systems. Therefore, higher-order-logic theorem\nproving, a formal method, has been used for accurately analyzing systems based\non transform methods. In this paper, we survey developments for transform\nmethods based analysis in various higher-order-logic theorem provers and\noverview the corresponding real world case studies from the avionics, medicine\nand transportation domains that have been analyzed based on these developments.",
    "descriptor": "\nComments: Formal Verification of Physical Systems (FVPS-2021), co-located with Conference on Intelligent Computer Mathematics (CICM-2021)\n",
    "authors": [
      "Muhammad Ahmed",
      "Adnan Rashid"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.10049"
  },
  {
    "id": "arXiv:2111.10050",
    "title": "Combined Scaling for Zero-shot Transfer Learning",
    "abstract": "We present a combined scaling method called BASIC that achieves 85.7% top-1\nzero-shot accuracy on the ImageNet ILSVRC-2012 validation set, surpassing the\nbest-published zero-shot models - CLIP and ALIGN - by 9.3%. Our BASIC model\nalso shows significant improvements in robustness benchmarks. For instance, on\n5 test sets with natural distribution shifts such as ImageNet-{A,R,V2,Sketch}\nand ObjectNet, our model achieves 83.7% top-1 average accuracy, only a small\ndrop from the its original ImageNet accuracy.\nTo achieve these results, we scale up the contrastive learning framework of\nCLIP and ALIGN in three dimensions: data size, model size, and batch size. Our\ndataset has 6.6B noisy image-text pairs, which is 4x larger than ALIGN, and 16x\nlarger than CLIP. Our largest model has 3B weights, which is 3.75x larger in\nparameters and 8x larger in FLOPs than ALIGN and CLIP. Our batch size is 65536\nwhich is 2x more than CLIP and 4x more than ALIGN. The main challenge with\nscaling is the limited memory of our accelerators such as GPUs and TPUs. We\nhence propose a simple method of online gradient caching to overcome this\nlimit.",
    "descriptor": "",
    "authors": [
      "Hieu Pham",
      "Zihang Dai",
      "Golnaz Ghiasi",
      "Hanxiao Liu",
      "Adams Wei Yu",
      "Minh-Thang Luong",
      "Mingxing Tan",
      "Quoc V. Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10050"
  },
  {
    "id": "arXiv:2111.10055",
    "title": "Towards Efficiently Evaluating the Robustness of Deep Neural Networks in  IoT Systems: A GAN-based Method",
    "abstract": "Intelligent Internet of Things (IoT) systems based on deep neural networks\n(DNNs) have been widely deployed in the real world. However, DNNs are found to\nbe vulnerable to adversarial examples, which raises people's concerns about\nintelligent IoT systems' reliability and security. Testing and evaluating the\nrobustness of IoT systems becomes necessary and essential. Recently various\nattacks and strategies have been proposed, but the efficiency problem remains\nunsolved properly. Existing methods are either computationally extensive or\ntime-consuming, which is not applicable in practice. In this paper, we propose\na novel framework called Attack-Inspired GAN (AI-GAN) to generate adversarial\nexamples conditionally. Once trained, it can generate adversarial perturbations\nefficiently given input images and target classes. We apply AI-GAN on different\ndatasets in white-box settings, black-box settings and targeted models\nprotected by state-of-the-art defenses. Through extensive experiments, AI-GAN\nachieves high attack success rates, outperforming existing methods, and reduces\ngeneration time significantly. Moreover, for the first time, AI-GAN\nsuccessfully scales to complex datasets e.g. CIFAR-100 and ImageNet, with about\n$90\\%$ success rates among all classes.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2002.02196\n",
    "authors": [
      "Tao Bai",
      "Jun Zhao",
      "Jinlin Zhu",
      "Shoudong Han",
      "Jiefeng Chen",
      "Bo Li",
      "Alex Kot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10055"
  },
  {
    "id": "arXiv:2111.10056",
    "title": "Medical Visual Question Answering: A Survey",
    "abstract": "Medical Visual Question Answering (VQA) is a combination of medical\nartificial intelligence and popular VQA challenges. Given a medical image and a\nclinically relevant question in natural language, the medical VQA system is\nexpected to predict a plausible and convincing answer. Although the\ngeneral-domain VQA has been extensively studied, the medical VQA still needs\nspecific investigation and exploration due to its task features. In the first\npart of this survey, we cover and discuss the publicly available medical VQA\ndatasets up to date about the data source, data quantity, and task feature. In\nthe second part, we review the approaches used in medical VQA tasks. In the\nlast part, we analyze some medical-specific challenges for the field and\ndiscuss future research directions.",
    "descriptor": "",
    "authors": [
      "Zhihong Lin",
      "Donghao Zhang",
      "Qingyi Tac",
      "Danli Shi",
      "Gholamreza Haffari",
      "Qi Wu",
      "Mingguang He",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10056"
  },
  {
    "id": "arXiv:2111.10058",
    "title": "DeepQR: Neural-based Quality Ratings for Learnersourced Multiple-Choice  Questions",
    "abstract": "Automated question quality rating (AQQR) aims to evaluate question quality\nthrough computational means, thereby addressing emerging challenges in online\nlearnersourced question repositories. Existing methods for AQQR rely solely on\nexplicitly-defined criteria such as readability and word count, while not fully\nutilising the power of state-of-the-art deep-learning techniques. We propose\nDeepQR, a novel neural-network model for AQQR that is trained using\nmultiple-choice-question (MCQ) datasets collected from PeerWise, a widely-used\nlearnersourcing platform. Along with designing DeepQR, we investigate models\nbased on explicitly-defined features, or semantic features, or both. We also\nintroduce a self-attention mechanism to capture semantic correlations between\nMCQ components, and a contrastive-learning approach to acquire question\nrepresentations using quality ratings. Extensive experiments on datasets\ncollected from eight university-level courses illustrate that DeepQR has\nsuperior performance over six comparative models.",
    "descriptor": "\nComments: EAAI 22\n",
    "authors": [
      "Lin Ni",
      "Qiming Bao",
      "Xiaoxuan Li",
      "Qianqian Qi",
      "Paul Denny",
      "Jim Warren",
      "Michael Witbrock",
      "Jiamou Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10058"
  },
  {
    "id": "arXiv:2111.10061",
    "title": "An Activity-Based Model of Transport Demand for Greater Melbourne",
    "abstract": "In this paper, we present an algorithm for creating a synthetic population\nfor the Greater Melbourne area using a combination of machine learning,\nprobabilistic, and gravity-based approaches. We combine these techniques in a\nhybrid model with three primary innovations: 1. when assigning activity\npatterns, we generate individual activity chains for every agent, tailored to\ntheir cohort; 2. when selecting destinations, we aim to strike a balance\nbetween the distance-decay of trip lengths and the activity-based attraction of\ndestination locations; and 3. we take into account the number of trips\nremaining for an agent so as to ensure they do not select a destination that\nwould be unreasonable to return home from. Our method is completely open and\nreplicable, requiring only publicly available data to generate a synthetic\npopulation of agents compatible with commonly used agent-based modeling\nsoftware such as MATSim. The synthetic population was found to be accurate in\nterms of distance distribution, mode choice, and destination choice for a\nvariety of population sizes.",
    "descriptor": "\nComments: 35 pages, 10 figures\n",
    "authors": [
      "Alan Both",
      "Dhirendra Singh",
      "Afshin Jafari",
      "Billie Giles-Corti",
      "Lucy Gunn"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10061"
  },
  {
    "id": "arXiv:2111.10070",
    "title": "Sum Capacity Loss Quantification With Optimal and Sub-Optimal Precoding  in Heterogeneous Multiuser Channels",
    "abstract": "We analytically approximate the expected sum capacity loss between the\noptimal downlink precoding technique of dirty paper coding (DPC), and the\nsub-optimal technique of zero-forcing precoding, for multiuser channels. We\nalso consider the most general case of multi-stream transmission to multiple\nusers, where we evaluate the expected sum capacity loss between DPC and block\ndiagonalization precoding. Unlike previously, assuming heterogeneous Ricean\nfading, we utilize the well known affine approximation to predict the expected\nsum capacity difference between both precoder types (optimal and sub-optimal)\nover a wide range of system and propagation parameters. Furthermore, for\nsingle-stream transmission, we consider the problem of weighted sum capacity\nmaximization, where a similar quantification of the sum capacity difference\nbetween the two precoder types is presented. In doing so, we disclose that\npower allocation to different users proportional to their individual weights\nasymptotically maximizes the weighted sum capacity. Numerical simulations are\npresented to demonstrate the tightness of the developed expressions relative to\ntheir simulated counterparts.",
    "descriptor": "\nComments: IEEE WCNC 2022, 6 pages, 4 figures\n",
    "authors": [
      "Harsh Tataria",
      "Mansoor Shafi",
      "Dino Pjani\u0107"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.10070"
  },
  {
    "id": "arXiv:2111.10073",
    "title": "An Asynchronous Multi-Beam MAC Protocol for Multi-Hop Wireless Networks",
    "abstract": "A node equipped with a multi-beam antenna can achieve a throughput of up to m\ntimes as compared to a single-beam antenna, by simultaneously communicating on\nits m non-interfering beams. However, the existing multi-beam medium access\ncontrol (MAC) schemes can achieve concurrent data communication only when the\ntransmitter nodes are locally synchronized. Asynchronous packet arrival at a\nmulti-beam receiver node would increase the node deafness and MAC layer capture\nproblems, and thereby limit the data throughput. This paper presents an\nasynchronous multi-beam MAC protocol for multi-hop wireless networks, which\nmakes the following enhancements to the existing multi-beam MAC schemes (i) A\nwindowing mechanism to achieve concurrent communication when the packet arrival\nis asynchronous, (ii) A smart packet processing mechanism which reduces the\nnode deafness, hidden terminals and MAC-layer capture problems, and (iii) A\nchannel access mechanism which decreases resource wastage and node starvation.\nOur proposed protocol also works in heterogeneous networks that deploy the\nnodes equipped with single-beam as well as multi-beam antennas. Simulation\nresults demonstrate a superior performance of our proposed protocol.",
    "descriptor": "\nComments: Medium access control (MAC), directional communication, wireless network, multi-beam antenna\n",
    "authors": [
      "Shivam Garg",
      "Nandini Venkatraman",
      "Elizabeth Serena Bentley",
      "Sunil Kumar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.10073"
  },
  {
    "id": "arXiv:2111.10075",
    "title": "Enhanced countering adversarial attacks via input denoising and feature  restoring",
    "abstract": "Despite the fact that deep neural networks (DNNs) have achieved prominent\nperformance in various applications, it is well known that DNNs are vulnerable\nto adversarial examples/samples (AEs) with imperceptible perturbations in\nclean/original samples. To overcome the weakness of the existing defense\nmethods against adversarial attacks, which damages the information on the\noriginal samples, leading to the decrease of the target classifier accuracy,\nthis paper presents an enhanced countering adversarial attack method IDFR (via\nInput Denoising and Feature Restoring). The proposed IDFR is made up of an\nenhanced input denoiser (ID) and a hidden lossy feature restorer (FR) based on\nthe convex hull optimization. Extensive experiments conducted on benchmark\ndatasets show that the proposed IDFR outperforms the various state-of-the-art\ndefense methods, and is highly effective for protecting target models against\nvarious adversarial black-box or white-box attacks. \\footnote{Souce code is\nreleased at:\n\\href{https://github.com/ID-FR/IDFR}{https://github.com/ID-FR/IDFR}}",
    "descriptor": "",
    "authors": [
      "Yanni Li",
      "Wenhui Zhang",
      "Jiawei Liu",
      "Xiaoli Kou",
      "Hui Li",
      "Jiangtao Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10075"
  },
  {
    "id": "arXiv:2111.10076",
    "title": "Edge Computing vs Centralized Cloud: Impact of Communication Latency on  the Energy Consumption of LTE Terminal Nodes",
    "abstract": "Edge computing brings several advantages, such as reduced latency, increased\nbandwidth, and improved locality of traffic. One aspect that is not\nsufficiently understood is the impact of the different communication latency\nexperienced in the edge-cloud continuum on the energy consumption of clients.\nWe studied how a request-response communication scheme is influenced by\ndifferent placements of the server, when communication is based on LTE. Results\nshow that by accurately selecting the operational parameters a significant\namount of energy can be saved.",
    "descriptor": "",
    "authors": [
      "Chiara Caiazza",
      "Silvia Giordano",
      "Valerio Luconi",
      "Alessio Vecchio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.10076"
  },
  {
    "id": "arXiv:2111.10078",
    "title": "Defeating Catastrophic Forgetting via Enhanced Orthogonal Weights  Modification",
    "abstract": "The ability of neural networks (NNs) to learn and remember multiple tasks\nsequentially is facing tough challenges in achieving general artificial\nintelligence due to their catastrophic forgetting (CF) issues. Fortunately, the\nlatest OWM Orthogonal Weights Modification) and other several continual\nlearning (CL) methods suggest some promising ways to overcome the CF issue.\nHowever, none of existing CL methods explores the following three crucial\nquestions for effectively overcoming the CF issue: that is, what knowledge does\nit contribute to the effective weights modification of the NN during its\nsequential tasks learning? When the data distribution of a new learning task\nchanges corresponding to the previous learned tasks, should a uniform/specific\nweight modification strategy be adopted or not? what is the upper bound of the\nlearningable tasks sequentially for a given CL method? ect. To achieve this, in\nthis paper, we first reveals the fact that of the weight gradient of a new\nlearning task is determined by both the input space of the new task and the\nweight space of the previous learned tasks sequentially. On this observation\nand the recursive least square optimal method, we propose a new efficient and\neffective continual learning method EOWM via enhanced OWM. And we have\ntheoretically and definitively given the upper bound of the learningable tasks\nsequentially of our EOWM. Extensive experiments conducted on the benchmarks\ndemonstrate that our EOWM is effectiveness and outperform all of the\nstate-of-the-art CL baselines.",
    "descriptor": "",
    "authors": [
      "Yanni Li",
      "Bing Liu",
      "Kaicheng Yao",
      "Xiaoli Kou",
      "Pengfan Lv",
      "Yueshen Xu",
      "Jiangtao Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10078"
  },
  {
    "id": "arXiv:2111.10079",
    "title": "Evaluating Self and Semi-Supervised Methods for Remote Sensing  Segmentation Tasks",
    "abstract": "We perform a rigorous evaluation of recent self and semi-supervised ML\ntechniques that leverage unlabeled data for improving downstream task\nperformance, on three remote sensing tasks of riverbed segmentation, land cover\nmapping and flood mapping. These methods are especially valuable for remote\nsensing tasks since there is easy access to unlabeled imagery and getting\nground truth labels can often be expensive. We quantify performance\nimprovements one can expect on these remote sensing segmentation tasks when\nunlabeled imagery (outside of the labeled dataset) is made available for\ntraining. We also design experiments to test the effectiveness of these\ntechniques when the test set has a domain shift relative to the training and\nvalidation sets.",
    "descriptor": "",
    "authors": [
      "Chaitanya Patel",
      "Shashank Sharma",
      "Varun Gulshan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10079"
  },
  {
    "id": "arXiv:2111.10083",
    "title": "Autoencoder-based Semantic Communication Systems with Relay Channels",
    "abstract": "In this letter, we propose a semantic communication scheme for wireless relay\nchannels based on Autoencoder, named AESC, which encodes and decodes sentences\nfrom the semantic dimension. The Autoencoder module provides anti-noise\nperformance for the system. Meanwhile, a novel semantic forward (SF) mode is\ndesigned for the relay node to forward the semantic information at the semantic\nlevel, especially for the scenarios that there is no common knowledge shared\nbetween the source and destination nodes. Numerical results show that the AESC\nachieves better stability performance than the traditional communication\nschemes, and the proposed SF mode provides a significant performance gain\ncompared to the traditional forward protocols.",
    "descriptor": "\nComments: submitted to IEEE Communication Letters\n",
    "authors": [
      "Xinlai Luo",
      "Zhiyong Chen",
      "Bin Xia",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.10083"
  },
  {
    "id": "arXiv:2111.10085",
    "title": "Exposing Weaknesses of Malware Detectors with Explainability-Guided  Evasion Attacks",
    "abstract": "Numerous open-source and commercial malware detectors are available. However,\nthe efficacy of these tools has been threatened by new adversarial attacks,\nwhereby malware attempts to evade detection using, for example, machine\nlearning techniques. In this work, we design an adversarial evasion attack that\nrelies on both feature-space and problem-space manipulation. It uses\nexplainability-guided feature selection to maximize evasion by identifying the\nmost critical features that impact detection. We then use this attack as a\nbenchmark to evaluate several state-of-the-art malware detectors. We find that\n(i) state-of-the-art malware detectors are vulnerable to even simple evasion\nstrategies, and they can easily be tricked using off-the-shelf techniques; (ii)\nfeature-space manipulation and problem-space obfuscation can be combined to\nenable evasion without needing white-box understanding of the detector; (iii)\nwe can use explainability approaches (e.g., SHAP) to guide the feature\nmanipulation and explain how attacks can transfer across multiple detectors.\nOur findings shed light on the weaknesses of current malware detectors, as well\nas how they can be improved.",
    "descriptor": "",
    "authors": [
      "Wei Wang",
      "Ruoxi Sun",
      "Tian Dong",
      "Shaofeng Li",
      "Minhui Xue",
      "Gareth Tyson",
      "Haojin Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10085"
  },
  {
    "id": "arXiv:2111.10086",
    "title": "An Improved Analysis of Greedy for Online Steiner Forest",
    "abstract": "This paper considers the classic Online Steiner Forest problem where one is\ngiven a (weighted) graph $G$ and an arbitrary set of $k$ terminal pairs\n$\\{\\{s_1,t_1\\},\\ldots ,\\{s_k,t_k\\}\\}$ that are required to be connected. The\ngoal is to maintain a minimum-weight sub-graph that satisfies all the\nconnectivity requirements as the pairs are revealed one by one. It has been\nknown for a long time that no algorithm (even randomized) can be better than\n$\\Omega(\\log(k))$-competitive for this problem. Interestingly, a simple greedy\nalgorithm is already very efficient for this problem. This algorithm can be\ninformally described as follows: Upon arrival of a new pair $\\{s_i,t_i\\}$,\nconnect $s_i$ and $t_i$ with the shortest path in the current metric, contract\nthe metric along the chosen path and wait for the next pair.\nAlthough simple and intuitive, greedy proved itself challenging to analyze\nand its competitive ratio is a long-standing open problem in the area of online\nalgorithms. The last progress on this question is due to an elegant analysis by\nAwerbuch, Azar, and Bartal [SODA~1996], who showed that greedy is\n$O(\\log^2(k))$-competitive. Our main result is to show that greedy is in fact\n$O(\\log(k)\\log\\log(k))$-competitive on a wide class of instances. In\nparticular, this wide class of instances contains all the instances that were\nexhibited in the literature until now.",
    "descriptor": "\nComments: To appear in ACM-SIAM Symposium on Discrete Algorithms (SODA22). Abstract abridged for arXiv submission\n",
    "authors": [
      "\u00c9tienne Bamas",
      "Marina Drygala",
      "Andreas Maggiori"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.10086"
  },
  {
    "id": "arXiv:2111.10088",
    "title": "Data imputation and comparison of custom ensemble models with existing  libraries like XGBoost, Scikit learn, etc. for Predictive Equipment failure",
    "abstract": "This paper presents comparison of custom ensemble models with the models\ntrained using existing libraries Like Xgboost, Scikit Learn, etc. in case of\npredictive equipment failure for the case of oil extracting equipment setup.\nThe dataset that is used contains many missing values and the paper proposes\ndifferent model-based data imputation strategies to impute the missing values.\nThe architecture and the training and testing process of the custom ensemble\nmodels are explained in detail.",
    "descriptor": "\nComments: 16 pages, 19 figures\n",
    "authors": [
      "Tejas Y. Deo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10088"
  },
  {
    "id": "arXiv:2111.10090",
    "title": "Quantifying Cybersecurity Effectiveness of Software Diversity",
    "abstract": "The deployment of monoculture software stacks can cause a devastating damage\neven by a single exploit against a single vulnerability. Inspired by the\nresilience benefit of biological diversity, the concept of software diversity\nhas been proposed in the security domain. Although it is intuitive that\nsoftware diversity may enhance security, its effectiveness has not been\nquantitatively investigated. Currently, no theoretical or empirical study has\nbeen explored to measure the security effectiveness of network diversity. In\nthis paper, we take a first step towards ultimately tackling the problem. We\npropose a systematic framework that can model and quantify the security\neffectiveness of network diversity. We conduct simulations to demonstrate the\nusefulness of the framework. In contrast to the intuitive belief, we show that\ndiversity does not necessarily improve security from a whole-network\nperspective. The root cause of this phenomenon is that the degree of\nvulnerability in diversified software implementations plays a critical role in\ndetermining the security effectiveness of software diversity.",
    "descriptor": "",
    "authors": [
      "Huashan Chen",
      "Richard B. Garcia-Lebron",
      "Zheyuan Sun",
      "Jin-Hee Cho",
      "Shouhuai Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.10090"
  },
  {
    "id": "arXiv:2111.10091",
    "title": "A Voting-Based Blockchain Interoperability Oracle",
    "abstract": "Today's blockchain landscape is severely fragmented as more and more\nheterogeneous blockchain platforms have been developed in recent years. These\nblockchain platforms are not able to interact with each other or with the\noutside world since only little emphasis is placed on the interoperability\nbetween them. Already proposed solutions for blockchain interoperability such\nas naive relay or oracle solutions are usually not broadly applicable since\nthey are either too expensive to operate or very resource-intensive.\nFor that reason, we propose a blockchain interoperability oracle that follows\na voting-based approach based on threshold signatures. The oracle nodes\ngenerate a distributed private key to execute an off-chain aggregation\nmechanism to collectively respond to requests. Compared to state-of-the-art\nrelay schemes, our approach does not incur any ongoing costs and since the\non-chain component only needs to verify a single signature, we can achieve\nremarkable cost savings compared to conventional oracle solutions.",
    "descriptor": "",
    "authors": [
      "Michael Sober",
      "Giulia Scaffino",
      "Christof Spanring",
      "Stefan Schulte"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.10091"
  },
  {
    "id": "arXiv:2111.10092",
    "title": "Non-NP-Hardness of Translationally-Invariant Spin-Model Problems",
    "abstract": "Finding the ground state energy of the Heisenberg Hamiltonian is an important\nproblem in the field of condensed matter physics. In some configurations, such\nas the antiferromagnetic translationally-invariant case on the 2D square\nlattice, its exact ground state energy is still unknown. We show that finding\nthe ground state energy of the Heisenberg model cannot be an NP-Hard problem\nunless P=NP. We prove this result using a reduction to a sparse set and certain\ntheorems from computational complexity theory. The result hints at the\npotential tractability of the problem and encourages further research towards a\npositive complexity result. In addition, we prove similar results for many\nsimilarly structured Hamiltonian problems, including certain forms of the\nIsing, t-J, and Fermi-Hubbard models.",
    "descriptor": "",
    "authors": [
      "Rotem Liss",
      "Tal Mor",
      "Roman Shapira"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.10092"
  },
  {
    "id": "arXiv:2111.10093",
    "title": "RecGURU: Adversarial Learning of Generalized User Representations for  Cross-Domain Recommendation",
    "abstract": "Cross-domain recommendation can help alleviate the data sparsity issue in\ntraditional sequential recommender systems. In this paper, we propose the\nRecGURU algorithm framework to generate a Generalized User Representation (GUR)\nincorporating user information across domains in sequential recommendation,\neven when there is minimum or no common users in the two domains. We propose a\nself-attentive autoencoder to derive latent user representations, and a domain\ndiscriminator, which aims to predict the origin domain of a generated latent\nrepresentation. We propose a novel adversarial learning method to train the two\nmodules to unify user embeddings generated from different domains into a single\nglobal GUR for each user. The learned GUR captures the overall preferences and\ncharacteristics of a user and thus can be used to augment the behavior data and\nimprove recommendations in any single domain in which the user is involved.\nExtensive experiments have been conducted on two public cross-domain\nrecommendation datasets as well as a large dataset collected from real-world\napplications. The results demonstrate that RecGURU boosts performance and\noutperforms various state-of-the-art sequential recommendation and cross-domain\nrecommendation methods. The collected data will be released to facilitate\nfuture research.",
    "descriptor": "\nComments: 11 pages, 2 figures, 4 tables, Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining\n",
    "authors": [
      "Chenglin Li",
      "Mingjun Zhao",
      "Huanming Zhang",
      "Chenyun Yu",
      "Lei Cheng",
      "Guoqiang Shu",
      "Beibei Kong",
      "Di Niu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10093"
  },
  {
    "id": "arXiv:2111.10095",
    "title": "An Index for Single Source All Destinations Distance Queries in Temporal  Graphs",
    "abstract": "Typical tasks in analyzing temporal graphs are single-source-all-destination\n(SSAD) temporal distance queries, which are, e.g., common during the\ncomputation of centrality measures in temporal social networks. An SSAD query\nstarting at a vertex $v$ asks for the temporal distances, e.g., durations,\nearliest arrival times, or the number of hops, between $v$ and all other\nreachable vertices. We introduce a new index to speed up SSAD temporal distance\nqueries. The indexing is based on the construction of $k$ subgraphs and a\nmapping from the vertices to the subgraphs. Each subgraph contains the temporal\nedges sufficient to answer queries starting from any vertex mapped to the\nsubgraph. We answer a query starting at a vertex $v$ with a single pass over\nthe edges of the subgraph. The new index supports dynamic updates, i.e.,\nefficient insertion and deletion of temporal edges. We call our index Substream\nindex and show that deciding if there exists a Substream index of a given size\nis NP-complete. We provide a greedy approximation that constructs an index at\nmost $k/\\delta$ times larger than an optimal index where $\\delta$, with\n$1\\leq\\delta\\leq k$, depends on the temporal and spatial structure of the\ngraph. Moreover, we improve the running time of the approximation in three\nways. First, we use a secondary index called Time Skip index. It speeds up the\nconstruction and queries by skipping edges that do not need to be considered.\nNext, we apply min-hashing to avoid costly union operations. Finally, we use\nparallelization to take the parallel processing capabilities of modern\nprocessors into account. Our extensive evaluation using real-world temporal\nnetworks shows the efficiency and effectiveness of our indices.",
    "descriptor": "",
    "authors": [
      "Lutz Oettershagen",
      "Petra Mutzel"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.10095"
  },
  {
    "id": "arXiv:2111.10097",
    "title": "Lexicon-based Methods vs. BERT for Text Sentiment Analysis",
    "abstract": "The performance of sentiment analysis methods has greatly increased in recent\nyears. This is due to the use of various models based on the Transformer\narchitecture, in particular BERT. However, deep neural network models are\ndifficult to train and poorly interpretable. An alternative approach is\nrule-based methods using sentiment lexicons. They are fast, require no\ntraining, and are well interpreted. But recently, due to the widespread use of\ndeep learning, lexicon-based methods have receded into the background. The\npurpose of the article is to study the performance of the SO-CAL and\nSentiStrength lexicon-based methods, adapted for the Russian language. We have\ntested these methods, as well as the RuBERT neural network model, on 16 text\ncorpora and have analyzed their results. RuBERT outperforms both lexicon-based\nmethods on average, but SO-CAL surpasses RuBERT for four corpora out of 16.",
    "descriptor": "\nComments: 14 pages, 4 tables, 3 figures. Accepted to AIST-2021 conference\n",
    "authors": [
      "Anastasia Kotelnikova",
      "Danil Paschenko",
      "Klavdiya Bochenina",
      "Evgeny Kotelnikov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.10097"
  },
  {
    "id": "arXiv:2111.10100",
    "title": "Does BERT look at sentiment lexicon?",
    "abstract": "The main approaches to sentiment analysis are rule-based methods and ma-chine\nlearning, in particular, deep neural network models with the Trans-former\narchitecture, including BERT. The performance of neural network models in the\ntasks of sentiment analysis is superior to the performance of rule-based\nmethods. The reasons for this situation remain unclear due to the poor\ninterpretability of deep neural network models. One of the main keys to\nunderstanding the fundamental differences between the two approaches is the\nanalysis of how sentiment lexicon is taken into account in neural network\nmodels. To this end, we study the attention weights matrices of the\nRussian-language RuBERT model. We fine-tune RuBERT on sentiment text corpora\nand compare the distributions of attention weights for sentiment and neutral\nlexicons. It turns out that, on average, 3/4 of the heads of various model\nvar-iants statistically pay more attention to the sentiment lexicon compared to\nthe neutral one.",
    "descriptor": "\nComments: 14 pages, 3 tables, 3 figures. Accepted to AIST-2021 conference\n",
    "authors": [
      "Elena Razova",
      "Sergey Vychegzhanin",
      "Evgeny Kotelnikov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.10100"
  },
  {
    "id": "arXiv:2111.10101",
    "title": "Deep Domain Adaptation for Pavement Crack Detection",
    "abstract": "Deep learning-based pavement cracks detection methods often require\nlarge-scale labels with detailed crack location information to learn accurate\npredictions. In practice, however, crack locations are very difficult to be\nmanually annotated due to various visual patterns of pavement crack. In this\npaper, we propose a Deep Domain Adaptation-based Crack Detection Network\n(DDACDN), which learns to take advantage of the source domain knowledge to\npredict the multi-category crack location information in the target domain,\nwhere only image-level labels are available. Specifically, DDACDN first\nextracts crack features from both the source and target domain by a two-branch\nweights-shared backbone network. And in an effort to achieve the cross-domain\nadaptation, an intermediate domain is constructed by aggregating the\nthree-scale features from the feature space of each domain to adapt the crack\nfeatures from the source domain to the target domain. Finally, the network\ninvolves the knowledge of both domains and is trained to recognize and localize\npavement cracks. To facilitate accurate training and validation for domain\nadaptation, we use two challenging pavement crack datasets CQU-BPDD and\nRDD2020. Furthermore, we construct a new large-scale Bituminous Pavement\nMulti-label Disease Dataset named CQU-BPMDD, which contains 38994\nhigh-resolution pavement disease images to further evaluate the robustness of\nour model. Extensive experiments demonstrate that DDACDN outperforms\nstate-of-the-art pavement crack detection methods in predicting the crack\nlocation on the target domain.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Huijun Liu",
      "Chunhua Yang",
      "Ao Li",
      "Yongxin Ge",
      "Sheng Huang",
      "Xin Feng",
      "Zhimin Ruan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10101"
  },
  {
    "id": "arXiv:2111.10102",
    "title": "Graph Neural Networks with Feature and Structure Aware Random Walk",
    "abstract": "Graph Neural Networks (GNNs) have received increasing attention for\nrepresentation learning in various machine learning tasks. However, most\nexisting GNNs applying neighborhood aggregation usually perform poorly on the\ngraph with heterophily where adjacent nodes belong to different classes. In\nthis paper, we show that in typical heterphilous graphs, the edges may be\ndirected, and whether to treat the edges as is or simply make them undirected\ngreatly affects the performance of the GNN models. Furthermore, due to the\nlimitation of heterophily, it is highly beneficial for the nodes to aggregate\nmessages from similar nodes beyond local neighborhood.These motivate us to\ndevelop a model that adaptively learns the directionality of the graph, and\nexploits the underlying long-distance correlations between nodes. We first\ngeneralize the graph Laplacian to digraph based on the proposed Feature-Aware\nPageRank algorithm, which simultaneously considers the graph directionality and\nlong-distance feature similarity between nodes. Then digraph Laplacian defines\na graph propagation matrix that leads to a model called {\\em DiglacianGCN}.\nBased on this, we further leverage the node proximity measured by commute times\nbetween nodes, in order to preserve the nodes' long-distance correlation on the\ntopology level. Extensive experiments on ten datasets with different levels of\nhomophily demonstrate the effectiveness of our method over existing solutions\nin the task of node classification.",
    "descriptor": "",
    "authors": [
      "Wei Zhuo",
      "Chenyun Yu",
      "Guang Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10102"
  },
  {
    "id": "arXiv:2111.10103",
    "title": "Uncertainty-aware Low-Rank Q-Matrix Estimation for Deep Reinforcement  Learning",
    "abstract": "Value estimation is one key problem in Reinforcement Learning. Albeit many\nsuccesses have been achieved by Deep Reinforcement Learning (DRL) in different\nfields, the underlying structure and learning dynamics of value function,\nespecially with complex function approximation, are not fully understood. In\nthis paper, we report that decreasing rank of $Q$-matrix widely exists during\nlearning process across a series of continuous control tasks for different\npopular algorithms. We hypothesize that the low-rank phenomenon indicates the\ncommon learning dynamics of $Q$-matrix from stochastic high dimensional space\nto smooth low dimensional space. Moreover, we reveal a positive correlation\nbetween value matrix rank and value estimation uncertainty. Inspired by above\nevidence, we propose a novel Uncertainty-Aware Low-rank Q-matrix Estimation\n(UA-LQE) algorithm as a general framework to facilitate the learning of value\nfunction. Through quantifying the uncertainty of state-action value estimation,\nwe selectively erase the entries of highly uncertain values in state-action\nvalue matrix and conduct low-rank matrix reconstruction for them to recover\ntheir values. Such a reconstruction exploits the underlying structure of value\nmatrix to improve the value approximation, thus leading to a more efficient\nlearning process of value function. In the experiments, we evaluate the\nefficacy of UA-LQE in several representative OpenAI MuJoCo continuous control\ntasks.",
    "descriptor": "\nComments: This paper is accepted by The 3rd International Conference on Distributed Artificial Intelligence (DAI 2021, Shanghai, China)\n",
    "authors": [
      "Tong Sang",
      "Hongyao Tang",
      "Jianye Hao",
      "Yan Zheng",
      "Zhaopeng Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.10103"
  },
  {
    "id": "arXiv:2111.10115",
    "title": "IRONWAN: Increasing Reliability of Overlapping Networks in LoRaWAN",
    "abstract": "LoRaWAN deployments follow an ad-hoc deployment model that has organically\nled to overlapping communication networks, sharing the wireless spectrum, and\ncompletely unaware of each other. LoRaWAN uses ALOHA-style communication where\nit is almost impossible to schedule transmission between networks belonging to\ndifferent owners properly. The inability to schedule overlapping networks will\ncause inter-network interference, which will increase node-to-gateway message\nlosses and gateway-to-node acknowledgement failures. This problem is likely to\nget worse as the number of LoRaWAN networks increase. In response to this\nproblem, we propose IRONWAN, a wireless overlay network that shares\ncommunication resources without modifications to underlying protocols. It\nutilises the broadcast nature of radio communication and enables\ngateway-to-gateway communication to facilitate the search for failed messages\nand transmit failed acknowledgements already received and cached in overlapping\nnetwork's gateways. IRONWAN uses two novel algorithms, a Real-time Message\nInter-arrival Predictor, to highlight when a server has not received an\nexpected uplink message. The Interference Predictor ensures that extra\ngateway-to-gateway communication does not negatively impact communication\nbandwidth. We evaluate IRONWAN on a 1000-node simulator with up to ten gateways\nand a 10-node testbed with 2-gateways. Results show that IRONWAN can achieve up\nto 12\\% higher packet delivery ratio (PDR) and total messages received per node\nwhile increasing the minimum PDR by up to 28\\%. These improvements save up to\n50\\% node's energy. Finally, we demonstrate that IRONWAN has comparable\nperformance to an optimal solution (wired, centralised) but with 2-32 times\nlower communication costs. IRONWAN also has up to 14\\% better PDR when compared\nto FLIP, a wired-distributed gateway-to-gateway protocol in certain scenarios.",
    "descriptor": "\nComments: Accepted for publication at IEEE Internet of Things Journal\n",
    "authors": [
      "Laksh Bhatia",
      "Po-Yu Chen",
      "Michael Breza",
      "Cong Zhao",
      "Julie A. McCann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10115"
  },
  {
    "id": "arXiv:2111.10125",
    "title": "A Semi-Distributed Interior Point Algorithm for Optimal Coordination of  Automated Vehicles at Intersections",
    "abstract": "In this paper, we consider the optimal coordination of automated vehicles at\nintersections under fixed crossing orders. We formulate the problem using\ndirect optimal control and exploit the structure to construct a\nsemi-distributed primal-dual interior-point algorithm to solve it by\nparallelizing most of the computations. Differently from standard distributed\noptimization algorithms, where the optimization problem is split, in our\napproach we split the linear algebra steps, such that the algorithm takes the\nsame steps as a fully centralized one, while still performing computations in a\ndistributed fashion. We analyze the communication requirements of the\nalgorithm, and propose an approximation scheme which can significantly reduce\nthe data exchange. We demonstrate the effectiveness of the algorithm in hard\nbut realistic scenarios, which show that the approximation leads to reductions\nin communicated data of almost 99\\% of the exact formulation, at the expense of\nless than 1\\% suboptimality.",
    "descriptor": "",
    "authors": [
      "Robert Hult",
      "Mario Zanon",
      "Sebastien Gros",
      "Paolo Falcone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.10125"
  },
  {
    "id": "arXiv:2111.10126",
    "title": "On the Download Rate of Homomorphic Secret Sharing",
    "abstract": "A homomorphic secret sharing (HSS) scheme is a secret sharing scheme that\nsupports evaluating functions on shared secrets by means of a local mapping\nfrom input shares to output shares. We initiate the study of the download rate\nof HSS, namely, the achievable ratio between the length of the output shares\nand the output length when amortized over $\\ell$ function evaluations. We\nobtain the following results.\n* In the case of linear information-theoretic HSS schemes for degree-$d$\nmultivariate polynomials, we characterize the optimal download rate in terms of\nthe optimal minimal distance of a linear code with related parameters. We\nfurther show that for sufficiently large $\\ell$ (polynomial in all problem\nparameters), the optimal rate can be realized using Shamir's scheme, even with\nsecrets over $\\mathbb{F}_2$.\n* We present a general rate-amplification technique for HSS that improves the\ndownload rate at the cost of requiring more shares. As a corollary, we get\nhigh-rate variants of computationally secure HSS schemes and efficient private\ninformation retrieval protocols from the literature.\n* We show that, in some cases, one can beat the best download rate of linear\nHSS by allowing nonlinear output reconstruction and $2^{-\\Omega(\\ell)}$ error\nprobability.",
    "descriptor": "",
    "authors": [
      "Ingerid Fosli",
      "Yuval Ishai",
      "Victor I. Kolobov",
      "Mary Wootters"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.10126"
  },
  {
    "id": "arXiv:2111.10127",
    "title": "Neural Image Beauty Predictor Based on Bradley-Terry Model",
    "abstract": "Image beauty assessment is an important subject of computer vision.\nTherefore, building a model to mimic the image beauty assessment becomes an\nimportant task. To better imitate the behaviours of the human visual system\n(HVS), a complete survey about images of different categories should be\nimplemented. This work focuses on image beauty assessment. In this study, the\npairwise evaluation method was used, which is based on the Bradley-Terry model.\nWe believe that this method is more accurate than other image rating methods\nwithin an image group. Additionally, Convolution neural network (CNN), which is\nfit for image quality assessment, is used in this work. The first part of this\nstudy is a survey about the image beauty comparison of different images. The\nBradley-Terry model is used for the calculated scores, which are the target of\nCNN model. The second part of this work focuses on the results of the image\nbeauty prediction, including landscape images, architecture images and portrait\nimages. The models are pretrained by the AVA dataset to improve the performance\nlater. Then, the CNN model is trained with the surveyed images and\ncorresponding scores. Furthermore, this work compares the results of four CNN\nbase networks, i.e., Alex net, VGG net, Squeeze net and LSiM net, as discussed\nin literature. In the end, the model is evaluated by the accuracy in pairs,\ncorrelation coefficient and relative error calculated by survey results.\nSatisfactory results are achieved by our proposed methods with about 70 percent\naccuracy in pairs. Our work sheds more light on the novel image beauty\nassessment method. While more studies should be conducted, this method is a\npromising step.",
    "descriptor": "\nComments: 16 pages 18 fiugures\n",
    "authors": [
      "Shiyu Li",
      "Hao Ma",
      "Xiangyu Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10127"
  },
  {
    "id": "arXiv:2111.10130",
    "title": "Fooling Adversarial Training with Inducing Noise",
    "abstract": "Adversarial training is widely believed to be a reliable approach to improve\nmodel robustness against adversarial attack. However, in this paper, we show\nthat when trained on one type of poisoned data, adversarial training can also\nbe fooled to have catastrophic behavior, e.g., $<1\\%$ robust test accuracy with\n$>90\\%$ robust training accuracy on CIFAR-10 dataset. Previously, there are\nother types of noise poisoned in the training data that have successfully\nfooled standard training ($15.8\\%$ standard test accuracy with $99.9\\%$\nstandard training accuracy on CIFAR-10 dataset), but their poisonings can be\neasily removed when adopting adversarial training. Therefore, we aim to design\na new type of inducing noise, named ADVIN, which is an irremovable poisoning of\ntraining data. ADVIN can not only degrade the robustness of adversarial\ntraining by a large margin, for example, from $51.7\\%$ to $0.57\\%$ on CIFAR-10\ndataset, but also be effective for fooling standard training ($13.1\\%$ standard\ntest accuracy with $100\\%$ standard training accuracy). Additionally, ADVIN can\nbe applied to preventing personal data (like selfies) from being exploited\nwithout authorization under whether standard or adversarial training.",
    "descriptor": "",
    "authors": [
      "Zhirui Wang",
      "Yifei Wang",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.10130"
  },
  {
    "id": "arXiv:2111.10132",
    "title": "Formal verification of space systems designed with TASTE",
    "abstract": "Model-Based Systems Engineering (MBSE) is a development approach aiming to\nbuild correct-by-construction systems, provided the use of clear, unambiguous\nand complete models to describe them along the design process. The approach is\nsupported by several engineering tools that automate the development steps, for\nexample the production of code, documentation, test cases and more. TASTE [1]\nis pragmatic MBSE toolset supported by ESA that encapsulates several\ntechnologies to design a system (data modelling, architecture modelling,\nbehaviour modelling/implementation), to automatically generate the binary\napplication(s), and to validate it. One topic left open in TASTE is the formal\nverification of a system design with respect to specified properties. In this\npaper we describe our approach based on the IF model-checker [4] to enable the\nformal verification of properties on TASTE designs. The approach is currently\nunder development in the ESA MoC4Space project.",
    "descriptor": "",
    "authors": [
      "I Dragomir",
      "M Bozga",
      "Iulian Ober",
      "D Silveira",
      "T Jorge",
      "E Ala\u00f1a",
      "M Perrotin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.10132"
  },
  {
    "id": "arXiv:2111.10135",
    "title": "Grounded Situation Recognition with Transformers",
    "abstract": "Grounded Situation Recognition (GSR) is the task that not only classifies a\nsalient action (verb), but also predicts entities (nouns) associated with\nsemantic roles and their locations in the given image. Inspired by the\nremarkable success of Transformers in vision tasks, we propose a GSR model\nbased on a Transformer encoder-decoder architecture. The attention mechanism of\nour model enables accurate verb classification by capturing high-level semantic\nfeature of an image effectively, and allows the model to flexibly deal with the\ncomplicated and image-dependent relations between entities for improved noun\nclassification and localization. Our model is the first Transformer\narchitecture for GSR, and achieves the state of the art in every evaluation\nmetric on the SWiG benchmark. Our code is available at\nhttps://github.com/jhcho99/gsrtr .",
    "descriptor": "\nComments: Accepted to BMVC 2021, Code: this https URL\n",
    "authors": [
      "Junhyeong Cho",
      "Youngseok Yoon",
      "Hyeonjun Lee",
      "Suha Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10135"
  },
  {
    "id": "arXiv:2111.10137",
    "title": "Learning to Detect Instance-level Salient Objects Using Complementary  Image Labels",
    "abstract": "Existing salient instance detection (SID) methods typically learn from\npixel-level annotated datasets. In this paper, we present the first\nweakly-supervised approach to the SID problem. Although weak supervision has\nbeen considered in general saliency detection, it is mainly based on using\nclass labels for object localization. However, it is non-trivial to use only\nclass labels to learn instance-aware saliency information, as salient instances\nwith high semantic affinities may not be easily separated by the labels. As the\nsubitizing information provides an instant judgement on the number of salient\nitems, it is naturally related to detecting salient instances and may help\nseparate instances of the same class while grouping different parts of the same\ninstance. Inspired by this observation, we propose to use class and subitizing\nlabels as weak supervision for the SID problem. We propose a novel\nweakly-supervised network with three branches: a Saliency Detection Branch\nleveraging class consistency information to locate candidate objects; a\nBoundary Detection Branch exploiting class discrepancy information to delineate\nobject boundaries; and a Centroid Detection Branch using subitizing information\nto detect salient instance centroids. This complementary information is then\nfused to produce a salient instance map. To facilitate the learning process, we\nfurther propose a progressive training scheme to reduce label noise and the\ncorresponding noise learned by the model, via reciprocating the model with\nprogressive salient instance prediction and model refreshing. Our extensive\nevaluations show that the proposed method plays favorably against carefully\ndesigned baseline methods adapted from related tasks.",
    "descriptor": "\nComments: to appear IJCV. arXiv admin note: text overlap with arXiv:2009.13898\n",
    "authors": [
      "Xin Tian",
      "Ke Xu",
      "Xin Yang",
      "Baocai Yin",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10137"
  },
  {
    "id": "arXiv:2111.10139",
    "title": "More than Words: In-the-Wild Visually-Driven Prosody for Text-to-Speech",
    "abstract": "In this paper we present VDTTS, a Visually-Driven Text-to-Speech model.\nMotivated by dubbing, VDTTS takes advantage of video frames as an additional\ninput alongside text, and generates speech that matches the video signal. We\ndemonstrate how this allows VDTTS to, unlike plain TTS models, generate speech\nthat not only has prosodic variations like natural pauses and pitch, but is\nalso synchronized to the input video. Experimentally, we show our model\nproduces well synchronized outputs, approaching the video-speech\nsynchronization quality of the ground-truth, on several challenging benchmarks\nincluding \"in-the-wild\" content from VoxCeleb2. We encourage the reader to view\nthe demo videos demonstrating video-speech synchronization, robustness to\nspeaker ID swapping, and prosody.",
    "descriptor": "",
    "authors": [
      "Michael Hassid",
      "Michelle Tadmor Ramanovich",
      "Brendan Shillingford",
      "Miaosen Wang",
      "Ye Jia",
      "Tal Remez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.10139"
  },
  {
    "id": "arXiv:2111.10140",
    "title": "Learning in High-Dimensional Feature Spaces Using ANOVA-Based Fast  Matrix-Vector Multiplication",
    "abstract": "Kernel matrices are crucial in many learning tasks such as support vector\nmachines or kernel ridge regression. The kernel matrix is typically dense and\nlarge-scale. Depending on the dimension of the feature space even the\ncomputation of all of its entries in reasonable time becomes a challenging\ntask. For such dense matrices the cost of a matrix-vector product scales\nquadratically in the number of entries, if no customized methods are applied.\nWe propose the use of an ANOVA kernel, where we construct several kernels based\non lower-dimensional feature spaces for which we provide fast algorithms\nrealizing the matrix-vector products. We employ the non-equispaced fast Fourier\ntransform (NFFT), which is of linear complexity for fixed accuracy. Based on a\nfeature grouping approach, we then show how the fast matrix-vector products can\nbe embedded into a learning method choosing kernel ridge regression and the\npreconditioned conjugate gradient solver. We illustrate the performance of our\napproach on several data sets.",
    "descriptor": "\nComments: Official Code this https URL\n",
    "authors": [
      "Franziska Nestler",
      "Martin Stoll",
      "Theresa Wagner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10140"
  },
  {
    "id": "arXiv:2111.10142",
    "title": "Between welcome culture and border fence. A dataset on the European  refugee crisis in German newspaper reports",
    "abstract": "Newspaper reports provide a rich source of information on the unfolding of\npublic debate on specific policy fields that can serve as basis for inquiry in\npolitical science. Such debates are often triggered by critical events, which\nattract public attention and incite the reactions of political actors: crisis\nsparks the debate. However, due to the challenges of reliable annotation and\nmodeling, few large-scale datasets with high-quality annotation are available.\nThis paper introduces DebateNet2.0, which traces the political discourse on the\nEuropean refugee crisis in the German quality newspaper taz during the year\n2015. The core units of our annotation are political claims (requests for\nspecific actions to be taken within the policy field) and the actors who make\nthem (politicians, parties, etc.). The contribution of this paper is twofold.\nFirst, we document and release DebateNet2.0 along with its companion R package,\nmardyR, guiding the reader through the practical and conceptual issues related\nto the annotation of policy debates in newspapers. Second, we outline and apply\na Discourse Network Analysis (DNA) to DebateNet2.0, comparing two crucial\nmoments of the policy debate on the 'refugee crisis': the migration flux\nthrough the Mediterranean in April/May and the one along the Balkan route in\nSeptember/October. Besides the released resources and the case-study, our\ncontribution is also methodological: we talk the reader through the steps from\na newspaper article to a discourse network, demonstrating that there is not\njust one discourse network for the German migration debate, but multiple ones,\ndepending on the topic of interest (political actors, policy fields, time\nspans).",
    "descriptor": "\nComments: Submitted to Language Resources and Evaluation. This manuscript is an extended version of this https URL\n",
    "authors": [
      "Nico Blokker",
      "Andr\u00e9 Blessing",
      "Erenay Dayanik",
      "Jonas Kuhn",
      "Sebastian Pad\u00f3",
      "Gabriella Lapesa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.10142"
  },
  {
    "id": "arXiv:2111.10144",
    "title": "Positional Encoder Graph Neural Networks for Geographic Data",
    "abstract": "Graph neural networks (GNNs) provide a powerful and scalable solution for\nmodeling continuous spatial data. However, in the absence of further context on\nthe geometric structure of the data, they often rely on Euclidean distances to\nconstruct the input graphs. This assumption can be improbable in many\nreal-world settings, where the spatial structure is more complex and explicitly\nnon-Euclidean (e.g., road networks). In this paper, we propose PE-GNN, a new\nframework that incorporates spatial context and correlation explicitly into the\nmodels. Building on recent advances in geospatial auxiliary task learning and\nsemantic spatial embeddings, our proposed method (1) learns a context-aware\nvector encoding of the geographic coordinates and (2) predicts spatial\nautocorrelation in the data in parallel with the main task. On spatial\nregression tasks, we show the effectiveness of our approach, improving\nperformance over different state-of-the-art GNN approaches. We also test our\napproach for spatial interpolation, i.e., spatial regression without node\nfeatures, a task that GNNs are currently not competitive at. We observe that\nour approach not only vastly improves over the GNN baselines, but can match\nGaussian processes, the most commonly utilized method for spatial interpolation\nproblems.",
    "descriptor": "",
    "authors": [
      "Konstantin Klemmer",
      "Nathan Safir",
      "Daniel B Neill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10144"
  },
  {
    "id": "arXiv:2111.10146",
    "title": "DVCFlow: Modeling Information Flow Towards Human-like Video Captioning",
    "abstract": "Dense video captioning (DVC) aims to generate multi-sentence descriptions to\nelucidate the multiple events in the video, which is challenging and demands\nvisual consistency, discoursal coherence, and linguistic diversity. Existing\nmethods mainly generate captions from individual video segments, lacking\nadaptation to the global visual context and progressive alignment between the\nfast-evolved visual content and textual descriptions, which results in\nredundant and spliced descriptions. In this paper, we introduce the concept of\ninformation flow to model the progressive information changing across video\nsequence and captions. By designing a Cross-modal Information Flow Alignment\nmechanism, the visual and textual information flows are captured and aligned,\nwhich endows the captioning process with richer context and dynamics on\nevent/topic evolution. Based on the Cross-modal Information Flow Alignment\nmodule, we further put forward DVCFlow framework, which consists of a\nGlobal-local Visual Encoder to capture both global features and local features\nfor each video segment, and a pre-trained Caption Generator to produce\ncaptions. Extensive experiments on the popular ActivityNet Captions and\nYouCookII datasets demonstrate that our method significantly outperforms\ncompetitive baselines, and generates more human-like text according to subject\nand objective tests.",
    "descriptor": "",
    "authors": [
      "Xu Yan",
      "Zhengcong Fei",
      "Shuhui Wang",
      "Qingming Huang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10146"
  },
  {
    "id": "arXiv:2111.10153",
    "title": "Blockchain for Genomics: A Systematic Literature Review",
    "abstract": "Human genomic data carry unique information about an individual and offer\nunprecedented opportunities for healthcare. The clinical interpretations\nderived from large genomic datasets can greatly improve healthcare and pave the\nway for personalized medicine. Sharing genomic datasets, however, pose major\nchallenges, as genomic data is different from traditional medical data,\nindirectly revealing information about descendants and relatives of the data\nowner and carrying valid information even after the owner passes away.\nTherefore, stringent data ownership and control measures are required when\ndealing with genomic data. In order to provide secure and accountable\ninfrastructure, blockchain technologies offer a promising alternative to\ntraditional distributed systems. Indeed, the research on blockchain-based\ninfrastructures tailored to genomics is on the rise. However, there is a lack\nof a comprehensive literature review that summarizes the current\nstate-of-the-art methods in the applications of blockchain in genomics. In this\npaper, we systematically look at the existing work both commercial and\nacademic, and discuss the major opportunities and challenges. Our study is\ndriven by five research questions that we aim to answer in our review. We also\npresent our projections of future research directions which we hope the\nresearchers interested in the area can benefit from.",
    "descriptor": "",
    "authors": [
      "Mohammed Alghazwi",
      "Fatih Turkmen",
      "Joeri van der Velde",
      "Dimka Karastoyanova"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.10153"
  },
  {
    "id": "arXiv:2111.10154",
    "title": "Small Changes Make Big Differences: Improving Multi-turn Response  Selection \\\\in Dialogue Systems via Fine-Grained Contrastive Learning",
    "abstract": "Retrieve-based dialogue response selection aims to find a proper response\nfrom a candidate set given a multi-turn context. Pre-trained language models\n(PLMs) based methods have yielded significant improvements on this task. The\nsequence representation plays a key role in the learning of matching degree\nbetween the dialogue context and the response. However, we observe that\ndifferent context-response pairs sharing the same context always have a greater\nsimilarity in the sequence representations calculated by PLMs, which makes it\nhard to distinguish positive responses from negative ones. Motivated by this,\nwe propose a novel \\textbf{F}ine-\\textbf{G}rained \\textbf{C}ontrastive (FGC)\nlearning method for the response selection task based on PLMs. This FGC\nlearning strategy helps PLMs to generate more distinguishable matching\nrepresentations of each dialogue at fine grains, and further make better\npredictions on choosing positive responses. Empirical studies on two benchmark\ndatasets demonstrate that the proposed FGC learning method can generally and\nsignificantly improve the model performance of existing PLM-based matching\nmodels.",
    "descriptor": "",
    "authors": [
      "Yuntao Li",
      "Can Xu",
      "Huang Hu",
      "Lei Sha",
      "Yan Zhang",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.10154"
  },
  {
    "id": "arXiv:2111.10157",
    "title": "Lattention: Lattice-attention in ASR rescoring",
    "abstract": "Lattices form a compact representation of multiple hypotheses generated from\nan automatic speech recognition system and have been shown to improve\nperformance of downstream tasks like spoken language understanding and speech\ntranslation, compared to using one-best hypothesis. In this work, we look into\nthe effectiveness of lattice cues for rescoring n-best lists in second-pass. We\nencode lattices with a recurrent network and train an attention encoder-decoder\nmodel for n-best rescoring. The rescoring model with attention to lattices\nachieves 4-5% relative word error rate reduction over first-pass and 6-8% with\nattention to both lattices and acoustic features. We show that rescoring models\nwith attention to lattices outperform models with attention to n-best\nhypotheses. We also study different ways to incorporate lattice weights in the\nlattice encoder and demonstrate their importance for n-best rescoring.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Prabhat Pandey",
      "Sergio Duarte Torres",
      "Ali Orkan Bayer",
      "Ankur Gandhe",
      "Volker Leutnant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.10157"
  },
  {
    "id": "arXiv:2111.10167",
    "title": "UEFI virtual machine firmware hardening through snapshots and attack  surface reduction",
    "abstract": "The Unified Extensible Firmware Interface (UEFI) is a standardised interface\nbetween the firmware and the operating system used in all x86-based platforms\nover the past ten years. A side effect of the transition from conventional BIOS\nimplementations to more complex and flexible implementations based on the UEFI\nwas that it became easier for the malware to target BIOS in a widespread\nfashion, as these BIOS implementations are based on a common specification.\nThis paper introduces Amaranth project - a solution to some of the contemporary\nsecurity issues related to UEFI firmware. In this work we focused our attention\non virtual machines as it allowed us to simplify the development of secure UEFI\nfirmware. Security hardening of our firmware is achieved through several\ntechniques, the most important of which are an operating system integrity\nchecking mechanism (through snapshots) and overall firmware size reduction.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Mikhail Krichanov",
      "Vitaly Cheptsov"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.10167"
  },
  {
    "id": "arXiv:2111.10168",
    "title": "Improved Prosodic Clustering for Multispeaker and Speaker-independent  Phoneme-level Prosody Control",
    "abstract": "This paper presents a method for phoneme-level prosody control of F0 and\nduration on a multispeaker text-to-speech setup, which is based on prosodic\nclustering. An autoregressive attention-based model is used, incorporating\nmultispeaker architecture modules in parallel to a prosody encoder. Several\nimprovements over the basic single-speaker method are proposed that increase\nthe prosodic control range and coverage. More specifically we employ data\naugmentation, F0 normalization, balanced clustering for duration, and\nspeaker-independent prosodic clustering. These modifications enable\nfine-grained phoneme-level prosody control for all speakers contained in the\ntraining set, while maintaining the speaker identity. The model is also\nfine-tuned to unseen speakers with limited amounts of data and it is shown to\nmaintain its prosody control capabilities, verifying that the\nspeaker-independent prosodic clustering is effective. Experimental results\nverify that the model maintains high output speech quality and that the\nproposed method allows efficient prosody control within each speaker's range\ndespite the variability that a multispeaker setting introduces.",
    "descriptor": "\nComments: Proceedings of SPECOM 2021\n",
    "authors": [
      "Myrsini Christidou",
      "Alexandra Vioni",
      "Nikolaos Ellinas",
      "Georgios Vamvoukakis",
      "Konstantinos Markopoulos",
      "Panos Kakoulidis",
      "June Sig Sung",
      "Hyoungmin Park",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.10168"
  },
  {
    "id": "arXiv:2111.10173",
    "title": "Word-Level Style Control for Expressive, Non-attentive Speech Synthesis",
    "abstract": "This paper presents an expressive speech synthesis architecture for modeling\nand controlling the speaking style at a word level. It attempts to learn\nword-level stylistic and prosodic representations of the speech data, with the\naid of two encoders. The first one models style by finding a combination of\nstyle tokens for each word given the acoustic features, and the second outputs\na word-level sequence conditioned only on the phonetic information in order to\ndisentangle it from the style information. The two encoder outputs are aligned\nand concatenated with the phoneme encoder outputs and then decoded with a\nNon-Attentive Tacotron model. An extra prior encoder is used to predict the\nstyle tokens autoregressively, in order for the model to be able to run without\na reference utterance. We find that the resulting model gives both word-level\nand global control over the style, as well as prosody transfer capabilities.",
    "descriptor": "\nComments: Proceedings of SPECOM 2021\n",
    "authors": [
      "Konstantinos Klapsas",
      "Nikolaos Ellinas",
      "June Sig Sung",
      "Hyoungmin Park",
      "Spyros Raptis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.10173"
  },
  {
    "id": "arXiv:2111.10175",
    "title": "Randomized Algorithms for Monotone Submodular Function Maximization on  the Integer Lattice",
    "abstract": "Optimization problems with set submodular objective functions have many\nreal-world applications. In discrete scenarios, where the same item can be\nselected more than once, the domain is generalized from a 2-element set to a\nbounded integer lattice. In this work, we consider the problem of maximizing a\nmonotone submodular function on the bounded integer lattice subject to a\ncardinality constraint. In particular, we focus on maximizing DR-submodular\nfunctions, i.e., functions defined on the integer lattice that exhibit the\ndiminishing returns property. Given any epsilon > 0, we present a randomized\nalgorithm with probabilistic guarantees of O(1 - 1/e - epsilon) approximation,\nusing a framework inspired by a Stochastic Greedy algorithm developed for set\nsubmodular functions by Mirzasoleiman et al. We then show that, on synthetic\nDR-submodular functions, applying our proposed algorithm on the integer lattice\nis faster than the alternatives, including reducing a target problem to the set\ndomain and then applying the fastest known set submodular maximization\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Alberto Schiabel",
      "Vyacheslav Kungurtsev",
      "Jakub Marecek"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.10175"
  },
  {
    "id": "arXiv:2111.10177",
    "title": "Prosodic Clustering for Phoneme-level Prosody Control in End-to-End  Speech Synthesis",
    "abstract": "This paper presents a method for controlling the prosody at the phoneme level\nin an autoregressive attention-based text-to-speech system. Instead of learning\nlatent prosodic features with a variational framework as is commonly done, we\ndirectly extract phoneme-level F0 and duration features from the speech data in\nthe training set. Each prosodic feature is discretized using unsupervised\nclustering in order to produce a sequence of prosodic labels for each\nutterance. This sequence is used in parallel to the phoneme sequence in order\nto condition the decoder with the utilization of a prosodic encoder and a\ncorresponding attention module. Experimental results show that the proposed\nmethod retains the high quality of generated speech, while allowing\nphoneme-level control of F0 and duration. By replacing the F0 cluster centroids\nwith musical notes, the model can also provide control over the note and octave\nwithin the range of the speaker.",
    "descriptor": "\nComments: Proceedings of ICASSP 2021\n",
    "authors": [
      "Alexandra Vioni",
      "Myrsini Christidou",
      "Nikolaos Ellinas",
      "Georgios Vamvoukakis",
      "Panos Kakoulidis",
      "Taehoon Kim",
      "June Sig Sung",
      "Hyoungmin Park",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.10177"
  },
  {
    "id": "arXiv:2111.10179",
    "title": "Backstepping-based Integral Sliding Mode Control with Time Delay  Estimation for Autonomous Underwater Vehicles",
    "abstract": "The aim of this paper is to propose a high performance control approach for\ntrajectory tracking of Autonomous Underwater Vehicles (AUVs). However, the\ncontroller performance can be affected by the unknown perturbations including\nmodel uncertainties and external time-varying disturbances in an undersea\nenvironment. To address this problem, a Backstepping-based Integral Sliding\nMode Control with Time Delay Estimation (BS-ISMC-TDE) is designed. To improve\nthe performance of a conventional backstepping control algorithm, an Integral\nSliding Mode Control (ISMC) approach is adopted in the backstepping design to\nattenuate the steady-state error. Moreover, an adaptive Time Delay Estimation\n(TDE) strategy is proposed to provide an estimation of perturbations by\nobserving the inputs and the states of the AUV one step into the past without\nan exact knowledge of the dynamics and the upper bound of uncertainties. From\nthe simulation results, it is shown that the proposed control approach using\nboth adaptive and conventional TDE parts outperforms a Backstepping-based\nIntegral Sliding Mode Control (BS-ISMC).",
    "descriptor": "\nComments: This paper was accepted to 20th International Conference on ADVANCED ROBOTICS 2021\n",
    "authors": [
      "Hossein Nejatbakhsh Esfahani",
      "Behdad Aminian",
      "Esten Ingar Gr\u00f8tli",
      "Sebastien Gros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10179"
  },
  {
    "id": "arXiv:2111.10184",
    "title": "Streaming Deletion Problems Parameterized by Vertex Cover",
    "abstract": "Streaming is a model where an input graph is provided one edge at a time,\ninstead of being able to inspect it at will. In this work, we take a\nparameterized approach by assuming a vertex cover of the graph is given,\nbuilding on work of Bishnu et al. [COCOON 2020]. We show the further potency of\ncombining this parameter with the Adjacency List streaming model to obtain\nresults for vertex deletion problems. This includes kernels, parameterized\nalgorithms, and lower bounds for the problems of Pi-free Deletion, H-free\nDeletion, and the more specific forms of Cluster Vertex Deletion and Odd Cycle\nTransversal. We focus on the complexity in terms of the number of passes over\nthe input stream, and the memory used. This leads to a pass/memory trade-off,\nwhere a different algorithm might be favourable depending on the context and\ninstance. We also discuss implications for parameterized complexity in the\nnon-streaming setting.",
    "descriptor": "\nComments: 31 pages, 2 figures, an extended abstract appeared in the proceedings of FCT 2021, see this http URL\n",
    "authors": [
      "Jelle J. Oostveen",
      "Erik Jan van Leeuwen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.10184"
  },
  {
    "id": "arXiv:2111.10188",
    "title": "HMS-OS: Improving the Human Mental Search Optimisation Algorithm by  Grouping in both Search and Objective Space",
    "abstract": "The human mental search (HMS) algorithm is a relatively recent\npopulation-based metaheuristic algorithm, which has shown competitive\nperformance in solving complex optimisation problems. It is based on three main\noperators: mental search, grouping, and movement. In the original HMS\nalgorithm, a clustering algorithm is used to group the current population in\norder to identify a promising region in search space, while candidate solutions\nthen move towards the best candidate solution in the promising region. In this\npaper, we propose a novel HMS algorithm, HMS-OS, which is based on clustering\nin both objective and search space, where clustering in objective space finds a\nset of best candidate solutions whose centroid is then also used in updating\nthe population. For further improvement, HMSOS benefits from an adaptive\nselection of the number of mental processes in the mental search operator.\nExperimental results on CEC-2017 benchmark functions with dimensionalities of\n50 and 100, and in comparison to other optimisation algorithms, indicate that\nHMS-OS yields excellent performance, superior to those of other methods.",
    "descriptor": "\nComments: 7 pages, IEEE Symposium Series on Computational Intelligence (IEEE SSCI 2021), Orlando, USA\n",
    "authors": [
      "Seyed Jalaleddin Mousavirad",
      "Gerald Schaefer",
      "Iakov Korovin",
      "Iakov Korovin",
      "Iakov Korovin",
      "Mehrdad Saadatmand"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.10188"
  },
  {
    "id": "arXiv:2111.10192",
    "title": "An Expectation-Maximization Perspective on Federated Learning",
    "abstract": "Federated learning describes the distributed training of models across\nmultiple clients while keeping the data private on-device. In this work, we\nview the server-orchestrated federated learning process as a hierarchical\nlatent variable model where the server provides the parameters of a prior\ndistribution over the client-specific model parameters. We show that with\nsimple Gaussian priors and a hard version of the well known\nExpectation-Maximization (EM) algorithm, learning in such a model corresponds\nto FedAvg, the most popular algorithm for the federated learning setting. This\nperspective on FedAvg unifies several recent works in the field and opens up\nthe possibility for extensions through different choices for the hierarchical\nmodel. Based on this view, we further propose a variant of the hierarchical\nmodel that employs prior distributions to promote sparsity. By similarly using\nthe hard-EM algorithm for learning, we obtain FedSparse, a procedure that can\nlearn sparse neural networks in the federated learning setting. FedSparse\nreduces communication costs from client to server and vice-versa, as well as\nthe computational costs for inference with the sparsified network - both of\nwhich are of great practical importance in federated learning.",
    "descriptor": "",
    "authors": [
      "Christos Louizos",
      "Matthias Reisser",
      "Joseph Soriaga",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.10192"
  },
  {
    "id": "arXiv:2111.10196",
    "title": "Towards Traffic Scene Description: The Semantic Scene Graph",
    "abstract": "For the classification of traffic scenes, a description model is necessary\nthat can describe the scene in a uniform way, independent of its domain. A\nmodel to describe a traffic scene in a semantic way is described in this paper.\nThe description model allows to describe a traffic scene independently of the\nroad geometry and road topology. Here, the traffic participants are projected\nonto the road network and represented as nodes in a graph. Depending on the\nrelative location between two traffic participants with respect to the road\ntopology, semantic classified edges are created between the corresponding\nnodes. For concretization, the edge attributes are extended by relative\ndistances and velocities between both traffic participants with regard to the\ncourse of the lane. An important aspect of the description is that it can be\nconverted easily into a machine-readable format. The current description\nfocuses on dynamic objects of a traffic scene and considers traffic\nparticipants, such as pedestrians or vehicles.",
    "descriptor": "",
    "authors": [
      "Maximilian Zipfl",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10196"
  },
  {
    "id": "arXiv:2111.10200",
    "title": "Optimisation of job scheduling for supercomputers with burst buffers",
    "abstract": "The ever-increasing gap between compute and I/O performance in HPC platforms,\ntogether with the development of novel NVMe storage devices (NVRAM), led to the\nemergence of the burst buffer concept - an intermediate persistent storage\nlayer logically positioned between random-access main memory and a parallel\nfile system. Since the appearance of this technology, numerous supercomputers\nhave been equipped with burst buffers exploring various architectures. Despite\nthe development of real-world architectures as well as research concepts,\nResource and Job Management Systems, such as Slurm, provide only marginal\nsupport for scheduling jobs with burst buffer requirements. This research is\nprimarily motivated by the alerting observation that burst buffers are omitted\nfrom reservations in the procedure of backfilling in existing job schedulers.\nIn this dissertation, we forge a detailed supercomputer simulator based on\nBatsim and SimGrid, which is capable of simulating I/O contention and I/O\ncongestion effects. Due to the lack of publicly available workloads with burst\nbuffer requests, we create a burst buffer request distribution model derived\nfrom Parallel Workload Archive logs. We investigate the impact of burst buffer\nreservations on the overall efficiency of online job scheduling for canonical\nalgorithms: First-Come-First-Served (FCFS) and Shortest-Job-First (SJF)\nEASY-backfilling. Our results indicate that the lack of burst buffer\nreservations in backfilling may significantly deteriorate the performance of\nscheduling. [...] Furthermore, this lack of reservations may cause the\nstarvation of medium-size and wide jobs. Finally, we propose a\nburst-buffer-aware plan-based scheduling algorithm with simulated annealing\noptimisation, which improves the mean waiting time by over 20% and mean bounded\nslowdown by 27% compared to the SJF EASY-backfilling.",
    "descriptor": "\nComments: Master's thesis in computer science supervised by Krzysztof Rzadca; Base work to Euro-Par 2021 publication: Plan-based Job Scheduling for Supercomputers with Shared Burst Buffers (arXiv:2109.00082); Source code: this https URL\n",
    "authors": [
      "Jan Kopanski"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.10200"
  },
  {
    "id": "arXiv:2111.10204",
    "title": "Augmentation of base classifier performance via HMMs on a handwritten  character data set",
    "abstract": "This paper presents results of a study of the performance of several base\nclassifiers for recognition of handwritten characters of the modern Latin\nalphabet. Base classification performance is further enhanced by utilizing\nViterbi error correction by determining the Viterbi sequence. Hidden Markov\nModels (HMMs) models exploit relationships between letters within a word to\ndetermine the most likely sequence of characters. Four base classifiers are\nstudied along with eight feature sets extracted from the handwritten dataset.\nThe best classification performance after correction was 89.8%, and the average\nwas 68.1%",
    "descriptor": "",
    "authors": [
      "H\u00e9lder Campos",
      "Nuno Paulino"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10204"
  },
  {
    "id": "arXiv:2111.10206",
    "title": "Subspace Graph Physics: Real-Time Rigid Body-Driven Granular Flow  Simulation",
    "abstract": "An important challenge in robotics is understanding the interactions between\nrobots and deformable terrains that consist of granular material. Granular\nflows and their interactions with rigid bodies still pose several open\nquestions. A promising direction for accurate, yet efficient, modeling is using\ncontinuum methods. Also, a new direction for real-time physics modeling is the\nuse of deep learning. This research advances machine learning methods for\nmodeling rigid body-driven granular flows, for application to terrestrial\nindustrial machines as well as space robotics (where the effect of gravity is\nan important factor). In particular, this research considers the development of\na subspace machine learning simulation approach. To generate training datasets,\nwe utilize our high-fidelity continuum method, material point method (MPM).\nPrincipal component analysis (PCA) is used to reduce the dimensionality of\ndata. We show that the first few principal components of our high-dimensional\ndata keep almost the entire variance in data. A graph network simulator (GNS)\nis trained to learn the underlying subspace dynamics. The learned GNS is then\nable to predict particle positions and interaction forces with good accuracy.\nMore importantly, PCA significantly enhances the time and memory efficiency of\nGNS in both training and rollout. This enables GNS to be trained using a single\ndesktop GPU with moderate VRAM. This also makes the GNS real-time on\nlarge-scale 3D physics configurations (700x faster than our continuum method).",
    "descriptor": "",
    "authors": [
      "Amin Haeri",
      "Krzysztof Skonieczny"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.10206"
  },
  {
    "id": "arXiv:2111.10214",
    "title": "Homomorphisms on graph-walking automata",
    "abstract": "Graph-walking automata (GWA) are a model for graph traversal using\nfinite-state control: these automata move between the nodes of an input graph,\nfollowing its edges. This paper investigates the effect of node-replacement\ngraph homomorphisms on recognizability by these automata. It is not difficult\nto see that the family of graph languages recognized by GWA is closed under\ninverse homomorphisms. The main result of this paper is that, for $n$-state\nautomata operating on graphs with $k$ labels of edge end-points, the inverse\nhomomorphic images require GWA with $kn+O(1)$ states in the worst case. The\nsecond result is that already for tree-walking automata, the family they\nrecognize is not closed under injective homomorphisms. Here the proof is based\non an easy homomorphic characterization of regular tree languages.",
    "descriptor": "",
    "authors": [
      "Olga Martynova",
      "Alexander Okhotin"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.10214"
  },
  {
    "id": "arXiv:2111.10218",
    "title": "Benchmarks of Extended Basis Reachability Graphs",
    "abstract": "In this note, we want to provide a comparison among the efficiency of\ndifferent approaches for the verification of K-step and infinite-step opacity\nbased on three different graphs: the Extended Basis Reachability Graph (EBRG),\nthe Basis Reachability Graph (BRG) when applicable, and the Reachability Graph\n(RG).",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Yin Tong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10218"
  },
  {
    "id": "arXiv:2111.10219",
    "title": "A Survey on Rural Internet Connectivity in India",
    "abstract": "Rural connectivity is widely research topic for several years. In India,\naround 70% of the population have poor or no connectivity to access digital\nservices. Different solutions are being tested and trialled around the world,\nespecially in India. They key driving factor for reducing digital divide is\nexploring different solutions both technologically and economically to lower\nthe cost for the network deployments and improving service adoption rate. In\nthis survey, we aim to study the rural connectivity use-cases, state of art\nprojects and initiatives, challenges, and technologies to improve digital\nconnectivity in rural parts of India. The strengths and weakness of different\ntechnologies which are being tested for rural connectivity is analyzed. We also\nexplore the rural use-case of 6G communication system which would be suitable\nfor rural Indian scenario.",
    "descriptor": "\nComments: 9 pages, 2 figures, conference paper, 2 tables\n",
    "authors": [
      "Shruthi K A",
      "Ihita G V",
      "Sachin Chaudhari"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.10219"
  },
  {
    "id": "arXiv:2111.10221",
    "title": "Semi-Supervised Domain Generalization in Real World:New Benchmark and  Strong Baseline",
    "abstract": "Conventional domain generalization aims to learn domain invariant\nrepresentation from multiple domains, which requires accurate annotations. In\nrealistic application scenarios, however, it is too cumbersome or even\ninfeasible to collect and annotate the large mass of data. Yet, web data\nprovides a free lunch to access a huge amount of unlabeled data with rich style\ninformation that can be harnessed to augment domain generalization ability. In\nthis paper, we introduce a novel task, termed as semi-supervised domain\ngeneralization, to study how to interact the labeled and unlabeled domains, and\nestablish two benchmarks including a web-crawled dataset, which poses a novel\nyet realistic challenge to push the limits of existing technologies. To tackle\nthis task, a straightforward solution is to propagate the class information\nfrom the labeled to the unlabeled domains via pseudo labeling in conjunction\nwith domain confusion training. Considering narrowing domain gap can improve\nthe quality of pseudo labels and further advance domain invariant feature\nlearning for generalization, we propose a cycle learning framework to encourage\nthe positive feedback between label propagation and domain generalization, in\nfavor of an evolving intermediate domain bridging the labeled and unlabeled\ndomains in a curriculum learning manner. Experiments are conducted to validate\nthe effectiveness of our framework. It is worth highlighting that web-crawled\ndata benefits domain generalization as demonstrated in our results. Our code\nwill be available later.",
    "descriptor": "\nComments: 10pages, 7 figures\n",
    "authors": [
      "Luojun Lin",
      "Han Xie",
      "Zhifeng Yang",
      "Zhishu Sun",
      "Wenxi Liu",
      "Yuanlong Yu",
      "Weijie Chen",
      "Shicai Yang",
      "Di Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10221"
  },
  {
    "id": "arXiv:2111.10223",
    "title": "Toxicity Detection can be Sensitive to the Conversational Context",
    "abstract": "User posts whose perceived toxicity depends on the conversational context are\nrare in current toxicity detection datasets. Hence, toxicity detectors trained\non existing datasets will also tend to disregard context, making the detection\nof context-sensitive toxicity harder when it does occur. We construct and\npublicly release a dataset of 10,000 posts with two kinds of toxicity labels:\n(i) annotators considered each post with the previous one as context; and (ii)\nannotators had no additional context. Based on this, we introduce a new task,\ncontext sensitivity estimation, which aims to identify posts whose perceived\ntoxicity changes if the context (previous post) is also considered. We then\nevaluate machine learning systems on this task, showing that classifiers of\npractical quality can be developed, and we show that data augmentation with\nknowledge distillation can improve the performance further. Such systems could\nbe used to enhance toxicity detection datasets with more context-dependent\nposts, or to suggest when moderators should consider the parent posts, which\noften may be unnecessary and may otherwise introduce significant additional\ncost.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Alexandros Xenos",
      "John Pavlopoulos",
      "Ion Androutsopoulos",
      "Lucas Dixon",
      "Jeffrey Sorensen",
      "Leo Laugier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.10223"
  },
  {
    "id": "arXiv:2111.10226",
    "title": "An Alternative Approach for Computing Discrete Logarithms in Compressed  SIDH",
    "abstract": "Currently, public-key compression of supersingular isogeny Diffie-Hellman\n(SIDH) and its variant, supersingular isogeny key encapsulation (SIKE) involve\npairing computation and discrete logarithm computation. For efficiency,\nrelatively large storage of precomputed values is required for discrete\nlogarithm computation. In this paper, we propose novel algorithms to compute\ndiscrete logarithms, allowing us to make a trade-off between memory and\nefficiency. Our implementation shows that the efficiency of our algorithms is\nclose to that of the previous work, and our algorithms perform better in some\nspecial cases.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Kaizhan Lin",
      "Weize Wang",
      "Lin Wang",
      "Chang-An Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.10226"
  },
  {
    "id": "arXiv:2111.10228",
    "title": "Impact of spatial coarsening on Parareal convergence",
    "abstract": "We study the impact of spatial coarsening on the convergence of the Parareal\nalgorithm, both theoretically and numerically. For initial value problems with\na normal system matrix, we prove a lower bound for the Euclidean norm of the\niteration matrix. When there is no physical or numerical diffusion, an\nimmediate consequence is that the norm of the iteration matrix cannot be\nsmaller than unoty as soon as the coarse problem has fewer degrees-of-freedom\nthan the fine. This prevents a theoretical guarantee for monotonic convergence,\nwhich is necessary to obtain meaningful speedups. For diffusive problems, in\nthe worst-case where the iteration error contracts only as fast as the powers\nof the iteration matrix norm, making Parareal as accurate as the fine method\nwill take about as many iterations as there are processors, making meaningful\nspeedup impossible. Numerical examples with a non-normal system matrix show\nthat for diffusive problems good speedup is possible, but that for\nnon-diffusive problems the negative impact of spatial coarsening on convergence\nis big.",
    "descriptor": "",
    "authors": [
      "Judith Angel",
      "Sebastian G\u00f6tschel",
      "Daniel Ruprecht"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.10228"
  },
  {
    "id": "arXiv:2111.10233",
    "title": "Xp-GAN: Unsupervised Multi-object Controllable Video Generation",
    "abstract": "Video Generation is a relatively new and yet popular subject in machine\nlearning due to its vast variety of potential applications and its numerous\nchallenges. Current methods in Video Generation provide the user with little or\nno control over the exact specification of how the objects in the generate\nvideo are to be moved and located at each frame, that is, the user can't\nexplicitly control how each object in the video should move. In this paper we\npropose a novel method that allows the user to move any number of objects of a\nsingle initial frame just by drawing bounding boxes over those objects and then\nmoving those boxes in the desired path. Our model utilizes two Autoencoders to\nfully decompose the motion and content information in a video and achieves\nresults comparable to well-known baseline and state of the art methods.",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Bahman Rouhani",
      "Mohammad Rahmati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.10233"
  },
  {
    "id": "arXiv:2111.10235",
    "title": "Interpreting deep urban sound classification using Layer-wise Relevance  Propagation",
    "abstract": "After constructing a deep neural network for urban sound classification, this\nwork focuses on the sensitive application of assisting drivers suffering from\nhearing loss. As such, clear etiology justifying and interpreting model\npredictions comprise a strong requirement. To this end, we used two different\nrepresentations of audio signals, i.e. Mel and constant-Q spectrograms, while\nthe decisions made by the deep neural network are explained via layer-wise\nrelevance propagation. At the same time, frequency content assigned with high\nrelevance in both feature sets, indicates extremely discriminative information\ncharacterizing the present classification task. Overall, we present an\nexplainable AI framework for understanding deep urban sound classification.",
    "descriptor": "",
    "authors": [
      "Marco Colussi",
      "Stavros Ntalampiras"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.10235"
  },
  {
    "id": "arXiv:2111.10241",
    "title": "START: Straggler Prediction and Mitigation for Cloud Computing  Environments using Encoder LSTM Networks",
    "abstract": "Modern large-scale computing systems distribute jobs into multiple smaller\ntasks which execute in parallel to accelerate job completion rates and reduce\nenergy consumption. However, a common performance problem in such systems is\ndealing with straggler tasks that are slow running instances that increase the\noverall response time. Such tasks can significantly impact the system's Quality\nof Service (QoS) and the Service Level Agreements (SLA). To combat this issue,\nthere is a need for automatic straggler detection and mitigation mechanisms\nthat execute jobs without violating the SLA. Prior work typically builds\nreactive models that focus first on detection and then mitigation of straggler\ntasks, which leads to delays. Other works use prediction based proactive\nmechanisms, but ignore heterogeneous host or volatile task characteristics. In\nthis paper, we propose a Straggler Prediction and Mitigation Technique (START)\nthat is able to predict which tasks might be stragglers and dynamically adapt\nscheduling to achieve lower response times. Our technique analyzes all tasks\nand hosts based on compute and network resource consumption using an Encoder\nLong-Short-Term-Memory (LSTM) network. The output of this network is then used\nto predict and mitigate expected straggler tasks. This reduces the SLA\nviolation rate and execution time without compromising QoS. Specifically, we\nuse the CloudSim toolkit to simulate START in a cloud environment and compare\nit with state-of-the-art techniques (IGRU-SD, SGC, Dolly, GRASS, NearestFit and\nWrangler) in terms of QoS parameters such as energy consumption, execution\ntime, resource contention, CPU utilization and SLA violation rate. Experiments\nshow that START reduces execution time, resource contention, energy and SLA\nviolations by 13%, 11%, 16% and 19%, respectively, compared to the\nstate-of-the-art approaches.",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Services Computing, 2021\n",
    "authors": [
      "Shreshth Tuli",
      "Sukhpal Singh Gill",
      "Peter Garraghan",
      "Rajkumar Buyya",
      "Giuliano Casale",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2111.10241"
  },
  {
    "id": "arXiv:2111.10245",
    "title": "Ubi-SleepNet: Advanced Multimodal Fusion Techniques for Three-stage  Sleep Classification Using Ubiquitous Sensing",
    "abstract": "Sleep is a fundamental physiological process that is essential for sustaining\na healthy body and mind. The gold standard for clinical sleep monitoring is\npolysomnography(PSG), based on which sleep can be categorized into five stages,\nincluding wake/rapid eye movement sleep (REM sleep)/Non-REM sleep 1\n(N1)/Non-REM sleep 2 (N2)/Non-REM sleep 3 (N3). However, PSG is expensive,\nburdensome, and not suitable for daily use. For long-term sleep monitoring,\nubiquitous sensing may be a solution. Most recently, cardiac and movement\nsensing has become popular in classifying three-stage sleep, since both\nmodalities can be easily acquired from research-grade or consumer-grade devices\n(e.g., Apple Watch). However, how best to fuse the data for the greatest\naccuracy remains an open question. In this work, we comprehensively studied\ndeep learning (DL)-based advanced fusion techniques consisting of three fusion\nstrategies alongside three fusion methods for three-stage sleep classification\nbased on two publicly available datasets. Experimental results demonstrate\nimportant evidence that three-stage sleep can be reliably classified by fusing\ncardiac/movement sensing modalities, which may potentially become a practical\ntool to conduct large-scale sleep stage assessment studies or long-term\nself-tracking on sleep. To accelerate the progression of sleep research in the\nubiquitous/wearable computing community, we made this project open source, and\nthe code can be found at: https://github.com/bzhai/Ubi-SleepNet.",
    "descriptor": "\nComments: Accepted in IMWUT for 2021 Dec issue\n",
    "authors": [
      "Bing Zhai",
      "Yu Guan",
      "Michael Catt",
      "Thomas Ploetz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10245"
  },
  {
    "id": "arXiv:2111.10246",
    "title": "Learning-Based Repetitive Precision Motion Control with Mismatch  Compensation",
    "abstract": "Learning-based control methods utilize run-time data from the underlying\nprocess to improve the controller performance under model mismatch and\nunmodeled disturbances. This is beneficial for optimizing industrial processes,\nwhere the dynamics are difficult to model, and the repetitive nature of the\nprocess can be exploited. In this work, we develop an iterative approach for\nrepetitive precision motion control problems where the objective is to follow a\nreference geometry with minimal tracking error. Our method utilizes a nominal\nmodel of the process and learns the mismatch using Gaussian Process Regression\n(GPR). The control input and the GPR data are updated after each iteration to\nimprove the performance in a run-to-run fashion. We provide a preliminary\nconvergence analysis, implementation details of the proposed controller for\nminimizing different error types, and a case study where we demonstrate\nimproved tracking performance with simulation and experimental results.",
    "descriptor": "",
    "authors": [
      "Efe C. Balta",
      "Kira Barton",
      "Dawn M. Tilbury",
      "Alisa Rupenyan",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10246"
  },
  {
    "id": "arXiv:2111.10247",
    "title": "Fast and Data-Efficient Training of Rainbow: an Experimental Study on  Atari",
    "abstract": "Across the Arcade Learning Environment, Rainbow achieves a level of\nperformance competitive with humans and modern RL algorithms. However,\nattaining this level of performance requires large amounts of data and hardware\nresources, making research in this area computationally expensive and use in\npractical applications often infeasible. This paper's contribution is\nthreefold: We (1) propose an improved version of Rainbow, seeking to\ndrastically reduce Rainbow's data, training time, and compute requirements\nwhile maintaining its competitive performance; (2) we empirically demonstrate\nthe effectiveness of our approach through experiments on the Arcade Learning\nEnvironment, and (3) we conduct a number of ablation studies to investigate the\neffect of the individual proposed modifications. Our improved version of\nRainbow reaches a median human normalized score close to classic Rainbow's,\nwhile using 20 times less data and requiring only 7.5 hours of training time on\na single GPU. We also provide our full implementation including pre-trained\nmodels.",
    "descriptor": "\nComments: NeurIPS 2021, Deep Reinforcement Learning Workshop. Code at this https URL\n",
    "authors": [
      "Dominik Schmidt",
      "Thomas Schmied"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10247"
  },
  {
    "id": "arXiv:2111.10250",
    "title": "Panoptic Segmentation: A Review",
    "abstract": "Image segmentation for video analysis plays an essential role in different\nresearch fields such as smart city, healthcare, computer vision and geoscience,\nand remote sensing applications. In this regard, a significant effort has been\ndevoted recently to developing novel segmentation strategies; one of the latest\noutstanding achievements is panoptic segmentation. The latter has resulted from\nthe fusion of semantic and instance segmentation. Explicitly, panoptic\nsegmentation is currently under study to help gain a more nuanced knowledge of\nthe image scenes for video surveillance, crowd counting, self-autonomous\ndriving, medical image analysis, and a deeper understanding of the scenes in\ngeneral. To that end, we present in this paper the first comprehensive review\nof existing panoptic segmentation methods to the best of the authors'\nknowledge. Accordingly, a well-defined taxonomy of existing panoptic techniques\nis performed based on the nature of the adopted algorithms, application\nscenarios, and primary objectives. Moreover, the use of panoptic segmentation\nfor annotating new datasets by pseudo-labeling is discussed. Moving on,\nablation studies are carried out to understand the panoptic methods from\ndifferent perspectives. Moreover, evaluation metrics suitable for panoptic\nsegmentation are discussed, and a comparison of the performance of existing\nsolutions is provided to inform the state-of-the-art and identify their\nlimitations and strengths. Lastly, the current challenges the subject\ntechnology faces and the future trends attracting considerable interest in the\nnear future are elaborated, which can be a starting point for the upcoming\nresearch studies. The papers provided with code are available at:\nhttps://github.com/elharroussomar/Awesome-Panoptic-Segmentation",
    "descriptor": "",
    "authors": [
      "Omar Elharrouss",
      "Somaya Al-Maadeed",
      "Nandhini Subramanian",
      "Najmath Ottakath",
      "Noor Almaadeed",
      "Yassine Himeur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10250"
  },
  {
    "id": "arXiv:2111.10257",
    "title": "Sparsified Block Elimination for Directed Laplacians",
    "abstract": "We show that the sparsified block elimination algorithm for solving\nundirected Laplacian linear systems from [Kyng-Lee-Peng-Sachdeva-Spielman\nSTOC'16] directly works for directed Laplacians. Given access to a\nsparsification algorithm that, on graphs with $n$ vertices and $m$ edges, takes\ntime $\\mathcal{T}_{\\rm S}(m)$ to output a sparsifier with $\\mathcal{N}_{\\rm\nS}(n)$ edges, our algorithm solves a directed Eulerian system on $n$ vertices\nand $m$ edges to $\\epsilon$ relative accuracy in time $$ O(\\mathcal{T}_{\\rm\nS}(m) + {\\mathcal{N}_{\\rm S}(n)\\log {n}\\log(n/\\epsilon)}) +\n\\tilde{O}(\\mathcal{T}_{\\rm S}(\\mathcal{N}_{\\rm S}(n)) \\log n), $$ where the\n$\\tilde{O}(\\cdot)$ notation hides $\\log\\log(n)$ factors. By previous results,\nthis implies improved runtimes for linear systems in strongly connected\ndirected graphs, PageRank matrices, and asymmetric M-matrices. When combined\nwith slower constructions of smaller Eulerian sparsifiers based on short cycle\ndecompositions, it also gives a solver that runs in $O(n \\log^{5}n \\log(n /\n\\epsilon))$ time after $O(n^2 \\log^{O(1)} n)$ pre-processing. At the core of\nour analyses are constructions of augmented matrices whose Schur complements\nencode error matrices.",
    "descriptor": "",
    "authors": [
      "Richard Peng",
      "Zhuoqing Song"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.10257"
  },
  {
    "id": "arXiv:2111.10261",
    "title": "Optimal Association Strategy of Multi-gateway Wireless Sensor Networks  Against Smart Jammers",
    "abstract": "Engineers have numerous low-power wireless sensor devices in the current\nnetwork setup for the Internet of Things, such as ZigBee, LoRaWAN, ANT, or\nBluetooth. These low-power wireless sensors are the best candidates to transfer\nand collect data. But they are all vulnerable to the physical jamming attack\nsince it is not costly for the attackers to run low power jammer sources in\nthese networks. Having multiple gateways and providing alternative connections\nto sensors would help these networks to mitigate successful jamming. In this\npaper, we propose an analytical model to solve the problem of gateway selection\nand association based on a Stackelberg game, where the jammer is the follower.\nWe first formulate the payoffs of both sensor network and attacker and then\nestablish and prove the conditions leading to NASH equilibrium. With numerical\ninvestigation, we also present how our model can capture the performance of\nsensor networks under jamming with a varying number of gateways. Our results\nshow that compared to the single gateway scenario, the network's throughput\nwill improve by 26% and 60% when we deploy two and four gateways in the\npresence of a single jammer.",
    "descriptor": "",
    "authors": [
      "Mohammad Reza Heidarpour",
      "Mohammad Hossein Manshaei"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.10261"
  },
  {
    "id": "arXiv:2111.10265",
    "title": "ClevrTex: A Texture-Rich Benchmark for Unsupervised Multi-Object  Segmentation",
    "abstract": "There has been a recent surge in methods that aim to decompose and segment\nscenes into multiple objects in an unsupervised manner, i.e., unsupervised\nmulti-object segmentation. Performing such a task is a long-standing goal of\ncomputer vision, offering to unlock object-level reasoning without requiring\ndense annotations to train segmentation models. Despite significant progress,\ncurrent models are developed and trained on visually simple scenes depicting\nmono-colored objects on plain backgrounds. The natural world, however, is\nvisually complex with confounding aspects such as diverse textures and\ncomplicated lighting effects. In this study, we present a new benchmark called\nClevrTex, designed as the next challenge to compare, evaluate and analyze\nalgorithms. ClevrTex features synthetic scenes with diverse shapes, textures\nand photo-mapped materials, created using physically based rendering\ntechniques. It includes 50k examples depicting 3-10 objects arranged on a\nbackground, created using a catalog of 60 materials, and a further test set\nfeaturing 10k images created using 25 different materials. We benchmark a large\nset of recent unsupervised multi-object segmentation models on ClevrTex and\nfind all state-of-the-art approaches fail to learn good representations in the\ntextured setting, despite impressive performance on simpler data. We also\ncreate variants of the ClevrTex dataset, controlling for different aspects of\nscene complexity, and probe current approaches for individual shortcomings.\nDataset and code are available at\nhttps://www.robots.ox.ac.uk/~vgg/research/clevrtex.",
    "descriptor": "\nComments: NeurIPS 2021 Datasets and Benchmarks\n",
    "authors": [
      "Laurynas Karazija",
      "Iro Laina",
      "Christian Rupprecht"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10265"
  },
  {
    "id": "arXiv:2111.10268",
    "title": "SpeedyIBL: A Solution to the Curse of Exponential Growth in  Instance-Based Learning Models of Decisions from Experience",
    "abstract": "Computational cognitive modeling is a useful methodology to explore and\nvalidate theories of human cognitive processes. Often cognitive models are used\nto simulate the process by which humans perform a task or solve a problem and\nto make predictions about human behavior. Cognitive models based on\nInstance-Based Learning (IBL) Theory rely on a formal computational algorithm\nfor dynamic decision making and on a memory mechanism from a well-known\ncognitive architecture, ACT-R. To advance the computational theory of human\ndecision making and to demonstrate the usefulness of cognitive models in\ndiverse domains, we must address a practical computational problem, the curse\nof exponential growth, that emerges from memory-based tabular computations.\nWhen more observations accumulate, there is an exponential growth of the memory\nof instances that leads directly to an exponential slow down of the\ncomputational time. In this paper, we propose a new Speedy IBL implementation\nthat innovates the mathematics of vectorization and parallel computation over\nthe traditional loop-based approach. Through the implementation of IBL models\nin many decision games of increasing complexity, we demonstrate the\napplicability of the regular IBL models and the advantages of their Speedy\nimplementation. Decision games vary in their complexity of decision features\nand in the number of agents involved in the decision process. The results\nclearly illustrate that Speedy IBL addresses the curse of exponential growth of\nmemory, reducing the computational time significantly, while maintaining the\nsame level of performance than the traditional implementation of IBL models.",
    "descriptor": "",
    "authors": [
      "Thuy Ngoc Nguyen",
      "Duy Nhat Phan",
      "Cleotilde Gonzalez"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.10268"
  },
  {
    "id": "arXiv:2111.10269",
    "title": "Pointer over Attention: An Improved Bangla Text Summarization Approach  Using Hybrid Pointer Generator Network",
    "abstract": "Despite the success of the neural sequence-to-sequence model for abstractive\ntext summarization, it has a few shortcomings, such as repeating inaccurate\nfactual details and tending to repeat themselves. We propose a hybrid pointer\ngenerator network to solve the shortcomings of reproducing factual details\ninadequately and phrase repetition. We augment the attention-based\nsequence-to-sequence using a hybrid pointer generator network that can generate\nOut-of-Vocabulary words and enhance accuracy in reproducing authentic details\nand a coverage mechanism that discourages repetition. It produces a\nreasonable-sized output text that preserves the conceptual integrity and\nfactual information of the input article. For evaluation, we primarily employed\n\"BANSData\" - a highly adopted publicly available Bengali dataset. Additionally,\nwe prepared a large-scale dataset called \"BANS-133\" which consists of 133k\nBangla news articles associated with human-generated summaries. Experimenting\nwith the proposed model, we achieved ROUGE-1 and ROUGE-2 scores of 0.66, 0.41\nfor the \"BANSData\" dataset and 0.67, 0.42 for the BANS-133k\" dataset,\nrespectively. We demonstrated that the proposed system surpasses previous\nstate-of-the-art Bengali abstractive summarization techniques and its stability\non a larger dataset. \"BANS-133\" datasets and code-base will be publicly\navailable for research.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Nobel Dhar",
      "Gaurob Saha",
      "Prithwiraj Bhattacharjee",
      "Avi Mallick",
      "Md Saiful Islam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10269"
  },
  {
    "id": "arXiv:2111.10272",
    "title": "Resilience from Diversity: Population-based approach to harden models  against adversarial attacks",
    "abstract": "Traditional deep learning models exhibit intriguing vulnerabilities that\nallow an attacker to force them to fail at their task. Notorious attacks such\nas the Fast Gradient Sign Method (FGSM) and the more powerful Projected\nGradient Descent (PGD) generate adversarial examples by adding a magnitude of\nperturbation $\\epsilon$ to the input's computed gradient, resulting in a\ndeterioration of the effectiveness of the model's classification. This work\nintroduces a model that is resilient to adversarial attacks. Our model\nleverages a well established principle from biological sciences: population\ndiversity produces resilience against environmental changes. More precisely,\nour model consists of a population of $n$ diverse submodels, each one of them\ntrained to individually obtain a high accuracy for the task at hand, while\nforced to maintain meaningful differences in their weight tensors. Each time\nour model receives a classification query, it selects a submodel from its\npopulation at random to answer the query. To introduce and maintain diversity\nin population of submodels, we introduce the concept of counter linking\nweights. A Counter-Linked Model (CLM) consists of submodels of the same\narchitecture where a periodic random similarity examination is conducted during\nthe simultaneous training to guarantee diversity while maintaining accuracy. In\nour testing, CLM robustness got enhanced by around 20% when tested on the MNIST\ndataset and at least 15% when tested on the CIFAR-10 dataset. When implemented\nwith adversarially trained submodels, this methodology achieves\nstate-of-the-art robustness. On the MNIST dataset with $\\epsilon=0.3$, it\nachieved 94.34% against FGSM and 91% against PGD. On the CIFAR-10 dataset with\n$\\epsilon=8/255$, it achieved 62.97% against FGSM and 59.16% against PGD.",
    "descriptor": "\nComments: 10 pages, 6 figures, 5 tables\n",
    "authors": [
      "Jasser Jasser",
      "Ivan Garibay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10272"
  },
  {
    "id": "arXiv:2111.10280",
    "title": "A Hybrid Approach for an Interpretable and Explainable Intrusion  Detection System",
    "abstract": "Cybersecurity has been a concern for quite a while now. In the latest years,\ncyberattacks have been increasing in size and complexity, fueled by significant\nadvances in technology. Nowadays, there is an unavoidable necessity of\nprotecting systems and data crucial for business continuity. Hence, many\nintrusion detection systems have been created in an attempt to mitigate these\nthreats and contribute to a timelier detection. This work proposes an\ninterpretable and explainable hybrid intrusion detection system, which makes\nuse of artificial intelligence methods to achieve better and more long-lasting\nsecurity. The system combines experts' written rules and dynamic knowledge\ncontinuously generated by a decision tree algorithm as new shreds of evidence\nemerge from network activity.",
    "descriptor": "\nComments: 11 pages, 5 figures, 1 table, ISDA conference\n",
    "authors": [
      "Tiago Dias",
      "Nuno Oliveira",
      "Norberto Sousa",
      "Isabel Pra\u00e7a",
      "Orlando Sousa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10280"
  },
  {
    "id": "arXiv:2111.10281",
    "title": "A new class of MDS symbol-pair codes",
    "abstract": "The symbol-pair code is a new coding framework proposed to guard against\npair-errors in symbol-pair read channels. Especially, a symbol-pair code with\nthe parameters achieving the Singleton-type bound is called an MDS symbol-pair\ncode. In this paper, inspiring by the classical construction for Reed-Solomon\ncodes, for any $3\\le k<m\\le q-2$ and\n$m_1=\\Big\\lfloor{\\tiny\\frac{m}{\\lfloor\\frac{k-1}{2}\\rfloor}}\\Big\\rfloor$, we\nconstruct a class of $q$-ary MDS symbol-pair codes with dimension $k$ and\nlength $n$ $(n=m+m_1, m+m_1-1)$, where $q$ is a prime power. Furthermore, for\n$k\\in\\{3,4\\}$, the symbol-pair weight distributions for these codes are\ndetermined by enumerating the number of polynomials with given roots.",
    "descriptor": "",
    "authors": [
      "Canze Zhu",
      "Qunying Liao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.10281"
  },
  {
    "id": "arXiv:2111.10283",
    "title": "The Joy of Neural Painting",
    "abstract": "Neural Painters is a class of models that follows a GAN framework to generate\nbrushstrokes, which are then composed to create paintings. GANs are great\ngenerative models for AI Art but they are known to be notoriously difficult to\ntrain. To overcome GAN's limitations and to speed up the Neural Painter\ntraining, we applied Transfer Learning to the process reducing it from days to\nonly hours, while achieving the same level of visual aesthetics in the final\npaintings generated. We report our approach and results in this work.",
    "descriptor": "",
    "authors": [
      "Ernesto Diaz-Aviles",
      "Claudia Orellana-Rodriguez",
      "Beth Jochim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.10283"
  },
  {
    "id": "arXiv:2111.10285",
    "title": "Adversarial Deep Learning for Online Resource Allocation",
    "abstract": "Online algorithm is an important branch in algorithm design. Designing online\nalgorithms with a bounded competitive ratio (in terms of worst-case\nperformance) can be hard and usually relies on problem-specific assumptions.\nInspired by adversarial training from Generative Adversarial Net (GAN) and the\nfact that competitive ratio of an online algorithm is based on worst-case\ninput, we adopt deep neural networks to learn an online algorithm for a\nresource allocation and pricing problem from scratch, with the goal that the\nperformance gap between offline optimum and the learned online algorithm can be\nminimized for worst-case input.\nSpecifically, we leverage two neural networks as algorithm and adversary\nrespectively and let them play a zero sum game, with the adversary being\nresponsible for generating worst-case input while the algorithm learns the best\nstrategy based on the input provided by the adversary. To ensure better\nconvergence of the algorithm network (to the desired online algorithm), we\npropose a novel per-round update method to handle sequential decision making to\nbreak complex dependency among different rounds so that update can be done for\nevery possible action, instead of only sampled actions. To the best of our\nknowledge, our work is the first using deep neural networks to design an online\nalgorithm from the perspective of worst-case performance guarantee. Empirical\nstudies show that our updating methods ensure convergence to Nash equilibrium\nand the learned algorithm outperforms state-of-the-art online algorithms under\nvarious settings.",
    "descriptor": "",
    "authors": [
      "Bingqian Du",
      "Zhiyi Huang",
      "Chuan Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10285"
  },
  {
    "id": "arXiv:2111.10290",
    "title": "A Risk-Managed Steady-State Analysis to Assess The Impact of Power Grid  Uncertainties",
    "abstract": "Increased levels of randomness and variability are introducing new\nuncertainties into power systems that can impact system operability and\nreliability. Existing planning and operational methods for assessing\noperability and reliability are primarily deterministic, therefore, ill-suited\nto capture randomness and variability. This work proposes an approach to model,\npropagate, and measure the impact of uncertainties in power flow caused by\nstochastic grid resources. Using system sensitivities, statistical circuit\nanalysis methods, and convex optimization, we demonstrate that we can\naccurately estimate the worst-case impact of stochastic resources on the health\nof a grid. We compare our method's performance to Monte Carlo analyses, and our\nresults demonstrate an increase in efficiency of more than 2 to 3 orders of\nmagnitude for the same probabilistic accuracy.",
    "descriptor": "\nComments: Under review: Submitted for consideration for the 22nd Power Systems Computation Conference\n",
    "authors": [
      "Naeem Turner-Bandele",
      "Amritanshu Pandey",
      "Larry Pileggi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10290"
  },
  {
    "id": "arXiv:2111.10291",
    "title": "Meta Adversarial Perturbations",
    "abstract": "A plethora of attack methods have been proposed to generate adversarial\nexamples, among which the iterative methods have been demonstrated the ability\nto find a strong attack. However, the computation of an adversarial\nperturbation for a new data point requires solving a time-consuming\noptimization problem from scratch. To generate a stronger attack, it normally\nrequires updating a data point with more iterations. In this paper, we show the\nexistence of a meta adversarial perturbation (MAP), a better initialization\nthat causes natural images to be misclassified with high probability after\nbeing updated through only a one-step gradient ascent update, and propose an\nalgorithm for computing such perturbations. We conduct extensive experiments,\nand the empirical results demonstrate that state-of-the-art deep neural\nnetworks are vulnerable to meta perturbations. We further show that these\nperturbations are not only image-agnostic, but also model-agnostic, as a single\nperturbation generalizes well across unseen data points and different neural\nnetwork architectures.",
    "descriptor": "",
    "authors": [
      "Chia-Hung Yuan",
      "Pin-Yu Chen",
      "Chia-Mu Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10291"
  },
  {
    "id": "arXiv:2111.10293",
    "title": "A 3D 2D convolutional Neural Network Model for Hyperspectral Image  Classification",
    "abstract": "In the proposed SEHybridSN model, a dense block was used to reuse shallow\nfeature and aimed at better exploiting hierarchical spatial spectral feature.\nSubsequent depth separable convolutional layers were used to discriminate the\nspatial information. Further refinement of spatial spectral features was\nrealized by the channel attention method, which were performed behind every 3D\nconvolutional layer and every 2D convolutional layer. Experiment results\nindicate that our proposed model learn more discriminative spatial spectral\nfeatures using very few training data. SEHybridSN using only 0.05 and 0.01\nlabeled data for training, a very satisfactory performance is obtained.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1902.06701 by other authors\n",
    "authors": [
      "Jiaxin Cao",
      "Xiaoyan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.10293"
  },
  {
    "id": "arXiv:2111.10295",
    "title": "Hex Me If You Can",
    "abstract": "HEXME consists of tetrahedral meshes with tagged features, and of a workflow\nto generate them. The main purpose of HEXME meshes is to enable consistent and\nfair evaluation of hexahedral meshing algorithms and related techniques. The\ntetrahedral meshes have been generated with Gmsh, starting from 63\ncomputer-aided design (CAD) models coming from various databases. To highlight\nand label the various and challenging aspects of hexahedral mesh generation,\nthe CAD models are classified into three categories: simple, nasty and\nindustrial. For each CAD model, we provide three kinds of tetrahedral meshes.\nThe mesh generation yielding those 189 tetrahedral meshes is defined thanks to\nSnakemake, a modern workflow management system, which allows us to define a\nfully automated, extensible and sustainable workflow. It is possible to\ndownload the whole dataset or to pick some meshes by browsing the online\ncatalog. Since there is no doubt that the hexahedral meshing techniques are\ngoing to progress, the HEXME dataset is also built with evolution in mind. A\npublic GitHub repository hosts the HEXME workflow, in which external\ncontributions and future releases are possible and encouraged.",
    "descriptor": "\nComments: Initial draft about HEXME\n",
    "authors": [
      "Pierre-Alexandre Beaufort",
      "Maxence Reberol",
      "Heng Liu",
      "Franck Ledoux",
      "David Bommes"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2111.10295"
  },
  {
    "id": "arXiv:2111.10296",
    "title": "Probabilistic Regression with Huber Distributions",
    "abstract": "In this paper we describe a probabilistic method for estimating the position\nof an object along with its covariance matrix using neural networks. Our method\nis designed to be robust to outliers, have bounded gradients with respect to\nthe network outputs, among other desirable properties. To achieve this we\nintroduce a novel probability distribution inspired by the Huber loss. We also\nintroduce a new way to parameterize positive definite matrices to ensure\ninvariance to the choice of orientation for the coordinate system we regress\nover. We evaluate our method on popular body pose and facial landmark datasets\nand get performance on par or exceeding the performance of non-heatmap methods.\nOur code is available at\ngithub.com/Davmo049/Public_prob_regression_with_huber_distributions",
    "descriptor": "\nComments: to be published at BMVC, 10 pages\n",
    "authors": [
      "David Mohlin",
      "Gerald Bianchi",
      "Josephine Sullivan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10296"
  },
  {
    "id": "arXiv:2111.10297",
    "title": "Expert-Guided Symmetry Detection in Markov Decision Processes",
    "abstract": "Learning a Markov Decision Process (MDP) from a fixed batch of trajectories\nis a non-trivial task whose outcome's quality depends on both the amount and\nthe diversity of the sampled regions of the state-action space. Yet, many MDPs\nare endowed with invariant reward and transition functions with respect to some\ntransformations of the current state and action. Being able to detect and\nexploit these structures could benefit not only the learning of the MDP but\nalso the computation of its subsequent optimal control policy. In this work we\npropose a paradigm, based on Density Estimation methods, that aims to detect\nthe presence of some already supposed transformations of the state-action space\nfor which the MDP dynamics is invariant. We tested the proposed approach in a\ndiscrete toroidal grid environment and in two notorious environments of\nOpenAI's Gym Learning Suite. The results demonstrate that the model\ndistributional shift is reduced when the dataset is augmented with the data\nobtained by using the detected symmetries, allowing for a more thorough and\ndata-efficient learning of the transition functions.",
    "descriptor": "\nComments: Accepted to the 14th International Conference on Agents and Artificial Intelligence - ICAART 2022\n",
    "authors": [
      "Giorgio Angelotti",
      "Nicolas Drougard",
      "Caroline P. C. Chanel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10297"
  },
  {
    "id": "arXiv:2111.10307",
    "title": "A privacy-aware zero interaction smart mobility system",
    "abstract": "Smart cities often rely on technological innovation to improve citizens'\nsafety and quality of life. This paper presents a novel smart mobility system\nthat aims to facilitate people accessing public mobility while preserving their\nprivacy. The system is based on a zero interaction approach whereby a person\ncan use public transport services without any need to perform explicit actions.\nOperations related to ticket purchase and validation have been fully automated.\nThe system is also designed with the privacy-by-design paradigm in mind, to\npreserve user privacy as much as possible. Throughout the paper several\ntechnical details are discussed as well to describe a prototype version of the\nsystem that was implemented. The prototype has been successfully tested in the\ncity of Imola (Emilia Romagna, Italy) in order to prove the system validity on\nthe field.",
    "descriptor": "",
    "authors": [
      "Stefano Righini",
      "Luca Calderoni",
      "Dario Maio"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.10307"
  },
  {
    "id": "arXiv:2111.10309",
    "title": "Unsupervised Visual Time-Series Representation Learning and Clustering",
    "abstract": "Time-series data is generated ubiquitously from Internet-of-Things (IoT)\ninfrastructure, connected and wearable devices, remote sensing, autonomous\ndriving research and, audio-video communications, in enormous volumes. This\npaper investigates the potential of unsupervised representation learning for\nthese time-series. In this paper, we use a novel data transformation along with\nnovel unsupervised learning regime to transfer the learning from other domains\nto time-series where the former have extensive models heavily trained on very\nlarge labelled datasets. We conduct extensive experiments to demonstrate the\npotential of the proposed approach through time-series clustering.",
    "descriptor": "\nComments: 9 pages, 4 figures, International Conference on Neural Information Processing. Springer, Cham, (2020) submitted version\n",
    "authors": [
      "Gaurangi Anand",
      "Richi Nayak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10309"
  },
  {
    "id": "arXiv:2111.10318",
    "title": "Max-algebraic hybrid automata: Modelling and equivalences",
    "abstract": "This article introduces the novel framework of max-algebraic hybrid automata\nas a hybrid modelling language in the max-plus algebra. We show that the\nmodelling framework unifies and extends the switching max-plus linear systems\nframework and is analogous to the discrete hybrid automata framework in\nconventional algebra. In addition, we show that the framework serves as a\nbridge between automata-theoretic models in max-plus algebra and switching\nmax-plus linear systems. In doing so, we formalise the relationship between\nmax-plus automata and switching max-plus linear systems in a behavioural sense.\nThis also serves as another step towards importing tools for analysis and\noptimal control from conventional time-driven hybrid systems to discrete-event\nsystems in max-plus algebra.",
    "descriptor": "\nComments: 13 pages, 6 figures, submitted to Automatica\n",
    "authors": [
      "A. Gupta",
      "B. De Schutter",
      "J. van der Woude",
      "T. van den Boom"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10318"
  },
  {
    "id": "arXiv:2111.10320",
    "title": "Toward Compact Parameter Representations for Architecture-Agnostic  Neural Network Compression",
    "abstract": "This paper investigates deep neural network (DNN) compression from the\nperspective of compactly representing and storing trained parameters. We\nexplore the previously overlooked opportunity of cross-layer\narchitecture-agnostic representation sharing for DNN parameters. To do this, we\ndecouple feedforward parameters from DNN architectures and leverage additive\nquantization, an extreme lossy compression method invented for image\ndescriptors, to compactly represent the parameters. The representations are\nthen finetuned on task objectives to improve task accuracy. We conduct\nextensive experiments on MobileNet-v2, VGG-11, ResNet-50, Feature Pyramid\nNetworks, and pruned DNNs trained for classification, detection, and\nsegmentation tasks. The conceptually simple scheme consistently outperforms\niterative unstructured pruning. Applied to ResNet-50 with 76.1% top-1 accuracy\non the ILSVRC12 classification challenge, it achieves a $7.2\\times$ compression\nratio with no accuracy loss and a $15.3\\times$ compression ratio at 74.79%\naccuracy. Further analyses suggest that representation sharing can frequently\nhappen across network layers and that learning shared representations for an\nentire DNN can achieve better accuracy at the same compression ratio than\ncompressing the model as multiple separate parts. We release PyTorch code to\nfacilitate DNN deployment on resource-constrained devices and spur future\nresearch on efficient representations and storage of DNN parameters.",
    "descriptor": "",
    "authors": [
      "Yuezhou Sun",
      "Wenlong Zhao",
      "Lijun Zhang",
      "Xiao Liu",
      "Hui Guan",
      "Matei Zaharia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10320"
  },
  {
    "id": "arXiv:2111.10326",
    "title": "Factorisation-based Image Labelling",
    "abstract": "Segmentation of brain magnetic resonance images (MRI) into anatomical regions\nis a useful task in neuroimaging. Manual annotation is time consuming and\nexpensive, so having a fully automated and general purpose brain segmentation\nalgorithm is highly desirable. To this end, we propose a patched-based label\npropagation approach based on a generative model with latent variables. Once\ntrained, our Factorisation-based Image Labelling (FIL) model is able to label\ntarget images with a variety of image contrasts. We compare the effectiveness\nof our proposed model against the state-of-the-art using data from the MICCAI\n2012 Grand Challenge and Workshop on Multi-Atlas Labeling. As our approach is\nintended to be general purpose, we also assess how well it can handle domain\nshift by labelling images of the same subjects acquired with different MR\ncontrasts.",
    "descriptor": "",
    "authors": [
      "Yu Yan",
      "Yael Balbastre",
      "Mikael Brudfors",
      "John Ashburner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10326"
  },
  {
    "id": "arXiv:2111.10330",
    "title": "Data-driven verification and synthesis of stochastic systems through  barrier certificates",
    "abstract": "In this work, we study verification and synthesis problems for safety\nspecifications over unknown discrete-time stochastic systems. When a model of\nthe system is available, barrier certificates have been successfully applied\nfor ensuring the satisfaction of safety specifications. In this work, we\nformulate the computation of barrier certificates as a robust convex program\n(RCP). Solving the acquired RCP is hard in general because the model of the\nsystem that appears in one of the constraints of the RCP is unknown. We propose\na data-driven approach that replaces the uncountable number of constraints in\nthe RCP with a finite number of constraints by taking finitely many random\nsamples from the trajectories of the system. We thus replace the original RCP\nwith a scenario convex program (SCP) and show how to relate their optimizers.\nWe guarantee that the solution of the SCP is a solution of the RCP with a\npriori guaranteed confidence when the number of samples is larger than a\npre-computed value. This provides a lower bound on the safety probability of\nthe original unknown system together with a controller in the case of\nsynthesis. We also discuss an extension of our verification approach to a case\nwhere the associated robust program is non-convex and show how a similar\nmethodology can be applied. Finally, the applicability of our proposed approach\nis illustrated through three case studies.",
    "descriptor": "",
    "authors": [
      "Ali Salamati",
      "Abolfazl Lavaei",
      "Sadegh Soudjani",
      "Majid Zamani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10330"
  },
  {
    "id": "arXiv:2111.10332",
    "title": "DSPoint: Dual-scale Point Cloud Recognition with High-frequency Fusion",
    "abstract": "Point cloud processing is a challenging task due to its sparsity and\nirregularity. Prior works introduce delicate designs on either local feature\naggregator or global geometric architecture, but few combine both advantages.\nWe propose Dual-Scale Point Cloud Recognition with High-frequency Fusion\n(DSPoint) to extract local-global features by concurrently operating on voxels\nand points. We reverse the conventional design of applying convolution on\nvoxels and attention to points. Specifically, we disentangle point features\nthrough channel dimension for dual-scale processing: one by point-wise\nconvolution for fine-grained geometry parsing, the other by voxel-wise global\nattention for long-range structural exploration. We design a co-attention\nfusion module for feature alignment to blend local-global modalities, which\nconducts inter-scale cross-modality interaction by communicating high-frequency\ncoordinates information. Experiments and ablations on widely-adopted\nModelNet40, ShapeNet, and S3DIS demonstrate the state-of-the-art performance of\nour DSPoint.",
    "descriptor": "",
    "authors": [
      "Renrui Zhang",
      "Ziyao Zeng",
      "Ziyu Guo",
      "Xinben Gao",
      "Kexue Fu",
      "Jianbo Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10332"
  },
  {
    "id": "arXiv:2111.10333",
    "title": "Improving a High Productivity Data Analytics Chapel Framework",
    "abstract": "Most state of the art exploratory data analysis frameworks fall into one of\nthe two extremes: they either focus on the high-performance computational, or\non the interactive and open-ended aspects of the analysis. Arkouda is a\nframework that attempts to integrate the interactive approach with the high\nperformance computation by using a novel client-server architecture, with a\nPython interpreter on the client side for the interactions with the scientist\nand a Chapel server for performing the demanding high-performance computations.\nThe Arkouda Python interpreter overloads the Python operators and transforms\nthem into messages to the Chapel server that performs the actual computation.\nIn this paper, we are proposing several client-side optimization techniques\nfor the Arkouda framework that maintain the interactive nature of the Arkouda\nframework, but at the same time significantly improve the performance of the\nprograms that perform operations running on the high-performance Chapel server.\nWe do this by intercepting the Python operations in the interpreter, and\ndelaying their execution until the user requires the data, or we fill out the\ninstruction buffer. We implement caching and reuse of the Arkouda arrays on the\nChapel server side (thus saving on the allocation, initialization and\ndeallocation of the Chapel arrays), tracking and caching the results of\nfunction calls on the Arkouda arrays (thus avoiding repeated computation) and\nreusing the results of array operations by performing common subexpression\nelimination.\nWe evaluate our approach on several Arkouda benchmarks and a large collection\nof real-world and synthetic data inputs and show significant performance\nimprovements between 20% and 120% across the board, while fully maintaining the\ninteractive nature of the Arkouda framework.",
    "descriptor": "",
    "authors": [
      "Prashanth Pai",
      "Andrej Jakovljevi\u0107",
      "Zoran Budimli\u0107",
      "Costin Iancu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.10333"
  },
  {
    "id": "arXiv:2111.10337",
    "title": "Advancing High-Resolution Video-Language Representation with Large-Scale  Video Transcriptions",
    "abstract": "We study joint video and language (VL) pre-training to enable cross-modality\nlearning and benefit plentiful downstream VL tasks. Existing works either\nextract low-quality video features or learn limited text embedding, while\nneglecting that high-resolution videos and diversified semantics can\nsignificantly improve cross-modality learning. In this paper, we propose a\nnovel High-resolution and Diversified VIdeo-LAnguage pre-training model\n(HD-VILA) for many visual tasks. In particular, we collect a large dataset with\ntwo distinct properties: 1) the first high-resolution dataset including 371.5k\nhours of 720p videos, and 2) the most diversified dataset covering 15 popular\nYouTube categories. To enable VL pre-training, we jointly optimize the HD-VILA\nmodel by a hybrid Transformer that learns rich spatiotemporal features, and a\nmultimodal Transformer that enforces interactions of the learned video features\nwith diversified texts. Our pre-training model achieves new state-of-the-art\nresults in 10 VL understanding tasks and 2 more novel text-to-visual generation\ntasks. For example, we outperform SOTA models with relative increases of 38.5%\nR@1 in zero-shot MSR-VTT text-to-video retrieval task, and 53.6% in\nhigh-resolution dataset LSMDC. The learned VL embedding is also effective in\ngenerating visually pleasing and semantically relevant results in\ntext-to-visual manipulation and super-resolution tasks.",
    "descriptor": "",
    "authors": [
      "Hongwei Xue",
      "Tiankai Hang",
      "Yanhong Zeng",
      "Yuchong Sun",
      "Bei Liu",
      "Huan Yang",
      "Jianlong Fu",
      "Baining Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10337"
  },
  {
    "id": "arXiv:2111.10338",
    "title": "Towards intrinsic force sensing and control in parallel soft robots",
    "abstract": "With soft robotics being increasingly employed in settings demanding high and\ncontrolled contact forces, recent research has demonstrated the use of soft\nrobots to estimate or intrinsically sense forces without requiring external\nsensing mechanisms. Whilst this has mainly been shown in tendon-based continuum\nmanipulators or deformable robots comprising of push-pull rod actuation, fluid\ndrives still pose great challenges due to high actuation variability and\nnonlinear mechanical system responses. In this work we investigate the\ncapabilities of a hydraulic, parallel soft robot to intrinsically sense and\nsubsequently control contact forces. A comprehensive algorithm is derived for\nstatic, quasi-static and dynamic force sensing which relies on fluid volume and\npressure information of the system. The algorithm is validated for a single\ndegree-of-freedom soft fluidic actuator. Results indicate that axial forces\nacting on a single actuator can be estimated with an accuracy of 0.56 +- 0.66N\nwithin the validated range of 0 to 6N in a quasi-static configuration. The\nforce sensing methodology is applied to force control in a single actuator as\nwell as the coupled parallel robot. It can be seen that forces are accurately\ncontrollable for both systems, with the capability of controlling directional\ncontact forces in case of the multi degree-of-freedom parallel soft robot.",
    "descriptor": "",
    "authors": [
      "Lukas Lindenroth",
      "Danail Stoyanov",
      "Kawal Rhode",
      "Hongbin Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.10338"
  },
  {
    "id": "arXiv:2111.10339",
    "title": "Bi-Mix: Bidirectional Mixing for Domain Adaptive Nighttime Semantic  Segmentation",
    "abstract": "In autonomous driving, learning a segmentation model that can adapt to\nvarious environmental conditions is crucial. In particular, copying with severe\nillumination changes is an impelling need, as models trained on daylight data\nwill perform poorly at nighttime. In this paper, we study the problem of Domain\nAdaptive Nighttime Semantic Segmentation (DANSS), which aims to learn a\ndiscriminative nighttime model with a labeled daytime dataset and an unlabeled\ndataset, including coarsely aligned day-night image pairs. To this end, we\npropose a novel Bidirectional Mixing (Bi-Mix) framework for DANSS, which can\ncontribute to both image translation and segmentation adaptation processes.\nSpecifically, in the image translation stage, Bi-Mix leverages the knowledge of\nday-night image pairs to improve the quality of nighttime image relighting. On\nthe other hand, in the segmentation adaptation stage, Bi-Mix effectively\nbridges the distribution gap between day and night domains for adapting the\nmodel to the night domain. In both processes, Bi-Mix simply operates by mixing\ntwo samples without extra hyper-parameters, thus it is easy to implement.\nExtensive experiments on Dark Zurich and Nighttime Driving datasets demonstrate\nthe advantage of the proposed Bi-Mix and show that our approach obtains\nstate-of-the-art performance in DANSS. Our code is available at\nhttps://github.com/ygjwd12345/BiMix.",
    "descriptor": "",
    "authors": [
      "Guanglei Yang",
      "Zhun Zhong",
      "Hao Tang",
      "Mingli Ding",
      "Nicu Sebe",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10339"
  },
  {
    "id": "arXiv:2111.10342",
    "title": "GRecX: An Efficient and Unified Benchmark for GNN-based Recommendation",
    "abstract": "In this paper, we present GRecX, an open-source TensorFlow framework for\nbenchmarking GNN-based recommendation models in an efficient and unified way.\nGRecX consists of core libraries for building GNN-based recommendation\nbenchmarks, as well as the implementations of popular GNN-based recommendation\nmodels. The core libraries provide essential components for building efficient\nand unified benchmarks, including FastMetrics (efficient metrics computation\nlibraries), VectorSearch (efficient similarity search libraries for dense\nvectors), BatchEval (efficient mini-batch evaluation libraries), and\nDataManager (unified dataset management libraries). Especially, to provide a\nunified benchmark for the fair comparison of different complex GNN-based\nrecommendation models, we design a new metric GRMF-X and integrate it into the\nFastMetrics component. Based on a TensorFlow GNN library tf_geometric, GRecX\ncarefully implements a variety of popular GNN-based recommendation models. We\ncarefully implement these baseline models to reproduce the performance reported\nin the literature, and our implementations are usually more efficient and\nfriendly. In conclusion, GRecX enables uses to train and benchmark GNN-based\nrecommendation baselines in an efficient and unified way. We conduct\nexperiments with GRecX, and the experimental results show that GRecX allows us\nto train and benchmark GNN-based recommendation baselines in an efficient and\nunified way. The source code of GRecX is available at\nhttps://github.com/maenzhier/GRecX.",
    "descriptor": "",
    "authors": [
      "Desheng Cai",
      "Jun Hu",
      "Shengsheng Qian",
      "Quan Fang",
      "Quan Zhao",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10342"
  },
  {
    "id": "arXiv:2111.10344",
    "title": "Maximum Mean Discrepancy for Generalization in the Presence of  Distribution and Missingness Shift",
    "abstract": "Covariate shifts are a common problem in predictive modeling on real-world\nproblems. This paper proposes addressing the covariate shift problem by\nminimizing Maximum Mean Discrepancy (MMD) statistics between the training and\ntest sets in either feature input space, feature representation space, or both.\nWe designed three techniques that we call MMD Representation, MMD Mask, and MMD\nHybrid to deal with the scenarios where only a distribution shift exists, only\na missingness shift exists, or both types of shift exist, respectively. We find\nthat integrating an MMD loss component helps models use the best features for\ngeneralization and avoid dangerous extrapolation as much as possible for each\ntest sample. Models treated with this MMD approach show better performance,\ncalibration, and extrapolation on the test set.",
    "descriptor": "\nComments: a short version accepted by NeurIPS DistShift Workshop 2021\n",
    "authors": [
      "Liwn Ouyang",
      "Aaron Key"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10344"
  },
  {
    "id": "arXiv:2111.10346",
    "title": "Global and Local Alignment Networks for Unpaired Image-to-Image  Translation",
    "abstract": "The goal of unpaired image-to-image translation is to produce an output image\nreflecting the target domain's style while keeping unrelated contents of the\ninput source image unchanged. However, due to the lack of attention to the\ncontent change in existing methods, the semantic information from source images\nsuffers from degradation during translation. In the paper, to address this\nissue, we introduce a novel approach, Global and Local Alignment Networks\n(GLA-Net). The global alignment network aims to transfer the input image from\nthe source domain to the target domain. To effectively do so, we learn the\nparameters (mean and standard deviation) of multivariate Gaussian distributions\nas style features by using an MLP-Mixer based style encoder. To transfer the\nstyle more accurately, we employ an adaptive instance normalization layer in\nthe encoder, with the parameters of the target multivariate Gaussian\ndistribution as input. We also adopt regularization and likelihood losses to\nfurther reduce the domain gap and produce high-quality outputs. Additionally,\nwe introduce a local alignment network, which employs a pretrained\nself-supervised model to produce an attention map via a novel local alignment\nloss, ensuring that the translation network focuses on relevant pixels.\nExtensive experiments conducted on five public datasets demonstrate that our\nmethod effectively generates sharper and more realistic images than existing\napproaches. Our code is available at https://github.com/ygjwd12345/GLANet.",
    "descriptor": "",
    "authors": [
      "Guanglei Yang",
      "Hao Tang",
      "Humphrey Shi",
      "Mingli Ding",
      "Nicu Sebe",
      "Radu Timofte",
      "Luc Van Gool",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10346"
  },
  {
    "id": "arXiv:2111.10349",
    "title": "Understanding Developers Well-Being and Productivity: A Longitudinal  Analysis of the COVID-19 Pandemic",
    "abstract": "COVID-19 has likely been the most disruptive event at a global scale the\nworld experienced since WWII. Our discipline never experienced such a\nphenomenon, whereby software engineers were forced to abruptly work from home.\nNearly every developer started new working habits and organizational routines,\nwhile trying to stay mentally healthy and productive during the lockdowns. We\nare now starting to realize that some of these new habits and routines may\nstick with us in the future. Therefore, it is of importance to understand how\nwe have worked from home so far. We investigated whether 15 psychological,\nsocial, and situational variables such as quality of social contacts or\nloneliness predict software engineers' well-being and productivity across a\nfour wave longitudinal study of over 14 months. Additionally, we tested whether\nthere were changes in any of these variables across time. We found that\ndevelopers' well-being and quality of social contacts improved between April\n2020 and July 2021, while their emotional loneliness went down. Other\nvariables, such as productivity and boredom have not changed. We further found\nthat developers' stress measured in May 2020 negatively predicted their\nwell-being 14 months later, even after controlling for many other variables.\nFinally, comparisons of women and men, as well as between developers residing\nin the UK and USA, were not statistically different but revealed substantial\nsimilarities.",
    "descriptor": "",
    "authors": [
      "Daniel Russo",
      "Paul H.P. Hanel",
      "Niels van Berkel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.10349"
  },
  {
    "id": "arXiv:2111.10352",
    "title": "On the power of adaptivity in statistical adversaries",
    "abstract": "We study a fundamental question concerning adversarial noise models in\nstatistical problems where the algorithm receives i.i.d. draws from a\ndistribution $\\mathcal{D}$. The definitions of these adversaries specify the\ntype of allowable corruptions (noise model) as well as when these corruptions\ncan be made (adaptivity); the latter differentiates between oblivious\nadversaries that can only corrupt the distribution $\\mathcal{D}$ and adaptive\nadversaries that can have their corruptions depend on the specific sample $S$\nthat is drawn from $\\mathcal{D}$.\nIn this work, we investigate whether oblivious adversaries are effectively\nequivalent to adaptive adversaries, across all noise models studied in the\nliterature. Specifically, can the behavior of an algorithm $\\mathcal{A}$ in the\npresence of oblivious adversaries always be well-approximated by that of an\nalgorithm $\\mathcal{A}'$ in the presence of adaptive adversaries? Our first\nresult shows that this is indeed the case for the broad class of statistical\nquery algorithms, under all reasonable noise models. We then show that in the\nspecific case of additive noise, this equivalence holds for all algorithms.\nFinally, we map out an approach towards proving this statement in its fullest\ngenerality, for all algorithms and under all reasonable noise models.",
    "descriptor": "",
    "authors": [
      "Guy Blanc",
      "Jane Lange",
      "Ali Malik",
      "Li-Yang Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.10352"
  },
  {
    "id": "arXiv:2111.10361",
    "title": "Solving Visual Analogies Using Neural Algorithmic Reasoning",
    "abstract": "We consider a class of visual analogical reasoning problems that involve\ndiscovering the sequence of transformations by which pairs of input/output\nimages are related, so as to analogously transform future inputs. This program\nsynthesis task can be easily solved via symbolic search. Using a variation of\nthe `neural analogical reasoning' approach of (Velickovic and Blundell 2021),\nwe instead search for a sequence of elementary neural network transformations\nthat manipulate distributed representations derived from a symbolic space, to\nwhich input images are directly encoded. We evaluate the extent to which our\n`neural reasoning' approach generalizes for images with unseen shapes and\npositions.",
    "descriptor": "\nComments: 20 pages. Contains extended abstract accepted at the AAAI-22 Student Abstract and Poster Program along with relevent supplementary material\n",
    "authors": [
      "Atharv Sonwane",
      "Gautam Shroff",
      "Lovekesh Vig",
      "Ashwin Srinivasan",
      "Tirtharaj Dash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10361"
  },
  {
    "id": "arXiv:2111.10364",
    "title": "Generalized Decision Transformer for Offline Hindsight Information  Matching",
    "abstract": "How to extract as much learning signal from each trajectory data has been a\nkey problem in reinforcement learning (RL), where sample inefficiency has posed\nserious challenges for practical applications. Recent works have shown that\nusing expressive policy function approximators and conditioning on future\ntrajectory information -- such as future states in hindsight experience replay\nor returns-to-go in Decision Transformer (DT) -- enables efficient learning of\nmulti-task policies, where at times online RL is fully replaced by offline\nbehavioral cloning, e.g. sequence modeling. We demonstrate that all these\napproaches are doing hindsight information matching (HIM) -- training policies\nthat can output the rest of trajectory that matches some statistics of future\nstate information. We present Generalized Decision Transformer (GDT) for\nsolving any HIM problem, and show how different choices for the feature\nfunction and the anti-causal aggregator not only recover DT as a special case,\nbut also lead to novel Categorical DT (CDT) and Bi-directional DT (BDT) for\nmatching different statistics of the future. For evaluating CDT and BDT, we\ndefine offline multi-task state-marginal matching (SMM) and imitation learning\n(IL) as two generic HIM problems, propose a Wasserstein distance loss as a\nmetric for both, and empirically study them on MuJoCo continuous control\nbenchmarks. CDT, which simply replaces anti-causal summation with anti-causal\nbinning in DT, enables the first effective offline multi-task SMM algorithm\nthat generalizes well to unseen and even synthetic multi-modal state-feature\ndistributions. BDT, which uses an anti-causal second transformer as the\naggregator, can learn to model any statistics of the future and outperforms DT\nvariants in offline multi-task IL. Our generalized formulations from HIM and\nGDT greatly expand the role of powerful sequence modeling architectures in\nmodern RL.",
    "descriptor": "\nComments: Website: this https URL\n",
    "authors": [
      "Hiroki Furuta",
      "Yutaka Matsuo",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.10364"
  },
  {
    "id": "arXiv:2111.10365",
    "title": "Joint Delay and Phase Precoding Under True-Time Delay Constraint for THz  Massive MIMO",
    "abstract": "A new approach is presented to the problem of compensating the beam squint\neffect arising in wideband terahertz (THz) hybrid massive multiple-input\nmultiple-output (MIMO) systems, based on the joint optimization of the phase\nshifter (PS) and true-time delay (TTD) values under per-TTD device time delay\nconstraints. Unlike the prior approaches, the new approach does not require the\nunbounded time delay assumption; the range of time delay values that a TTD\ndevice can produce is strictly limited in our approach. Instead of focusing on\nthe design of TTD values, we jointly optimize both the TTD and PS values to\neffectively cope with the practical time delay constraint. Simulation results\nthat illustrate the performance benefits of the new method for the beam squint\ncompensation are presented. Through simulations and analysis, we show that our\napproach is a generalization of the prior TTD-based precoding approaches.",
    "descriptor": "",
    "authors": [
      "Dang Qua Nguyen",
      "Taejoon Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.10365"
  },
  {
    "id": "arXiv:2111.10367",
    "title": "SLUE: New Benchmark Tasks for Spoken Language Understanding Evaluation  on Natural Speech",
    "abstract": "Progress in speech processing has been facilitated by shared datasets and\nbenchmarks. Historically these have focused on automatic speech recognition\n(ASR), speaker identification, or other lower-level tasks. Interest has been\ngrowing in higher-level spoken language understanding tasks, including using\nend-to-end models, but there are fewer annotated datasets for such tasks. At\nthe same time, recent work shows the possibility of pre-training generic\nrepresentations and then fine-tuning for several tasks using relatively little\nlabeled data. We propose to create a suite of benchmark tasks for Spoken\nLanguage Understanding Evaluation (SLUE) consisting of limited-size labeled\ntraining sets and corresponding evaluation sets. This resource would allow the\nresearch community to track progress, evaluate pre-trained representations for\nhigher-level tasks, and study open questions such as the utility of pipeline\nversus end-to-end approaches. We present the first phase of the SLUE benchmark\nsuite, consisting of named entity recognition, sentiment analysis, and ASR on\nthe corresponding datasets. We focus on naturally produced (not read or\nsynthesized) speech, and freely available datasets. We provide new\ntranscriptions and annotations on subsets of the VoxCeleb and VoxPopuli\ndatasets, evaluation metrics and results for baseline models, and an\nopen-source toolkit to reproduce the baselines and evaluate new models.",
    "descriptor": "\nComments: Toolkit link this https URL\n",
    "authors": [
      "Suwon Shon",
      "Ankita Pasad",
      "Felix Wu",
      "Pablo Brusco",
      "Yoav Artzi",
      "Karen Livescu",
      "Kyu J. Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.10367"
  },
  {
    "id": "arXiv:2111.10368",
    "title": "Faster Sparse Minimum Cost Flow by Electrical Flow Localization",
    "abstract": "We give an $\\widetilde{O}({m^{3/2 - 1/762} \\log (U+W))}$ time algorithm for\nminimum cost flow with capacities bounded by $U$ and costs bounded by $W$. For\nsparse graphs with general capacities, this is the first algorithm to improve\nover the $\\widetilde{O}({m^{3/2} \\log^{O(1)} (U+W)})$ running time obtained by\nan appropriate instantiation of an interior point method [Daitch-Spielman,\n2008].\nOur approach is extending the framework put forth in [Gao-Liu-Peng, 2021] for\ncomputing the maximum flow in graphs with large capacities and, in particular,\ndemonstrates how to reduce the problem of computing an electrical flow with\ngeneral demands to the same problem on a sublinear-sized set of vertices --\neven if the demand is supported on the entire graph. Along the way, we develop\nnew machinery to assess the importance of the graph's edges at each phase of\nthe interior point method optimization process. This capability relies on\nestablishing a new connections between the electrical flows arising inside that\noptimization process and vertex distances in the corresponding effective\nresistance metric.",
    "descriptor": "",
    "authors": [
      "Kyriakos Axiotis",
      "Aleksander M\u0105dry",
      "Adrian Vladu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.10368"
  },
  {
    "id": "arXiv:2111.09459",
    "title": "Gradient flows on graphons: existence, convergence, continuity equations",
    "abstract": "Wasserstein gradient flows on probability measures have found a host of\napplications in various optimization problems. They typically arise as the\ncontinuum limit of exchangeable particle systems evolving by some mean-field\ninteraction involving a gradient-type potential. However, in many problems,\nsuch as in multi-layer neural networks, the so-called particles are edge\nweights on large graphs whose nodes are exchangeable. Such large graphs are\nknown to converge to continuum limits called graphons as their size grow to\ninfinity. We show that the Euclidean gradient flow of a suitable function of\nthe edge-weights converges to a novel continuum limit given by a curve on the\nspace of graphons that can be appropriately described as a gradient flow or,\nmore technically, a curve of maximal slope. Several natural functions on\ngraphons, such as homomorphism functions and the scalar entropy, are covered by\nour set-up, and the examples have been worked out in detail.",
    "descriptor": "\nComments: 40 pages, 2 figures\n",
    "authors": [
      "Sewoong Oh",
      "Soumik Pal",
      "Raghav Somani",
      "Raghav Tripathi"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09459"
  },
  {
    "id": "arXiv:2111.09631",
    "title": "Neural Network Kalman filtering for 3D object tracking from linear array  ultrasound data",
    "abstract": "Many interventional surgical procedures rely on medical imaging to visualise\nand track instruments. Such imaging methods not only need to be real-time\ncapable, but also provide accurate and robust positional information. In\nultrasound applications, typically only two-dimensional data from a linear\narray are available, and as such obtaining accurate positional estimation in\nthree dimensions is non-trivial. In this work, we first train a neural network,\nusing realistic synthetic training data, to estimate the out-of-plane offset of\nan object with the associated axial aberration in the reconstructed ultrasound\nimage. The obtained estimate is then combined with a Kalman filtering approach\nthat utilises positioning estimates obtained in previous time-frames to improve\nlocalisation robustness and reduce the impact of measurement noise. The\naccuracy of the proposed method is evaluated using simulations, and its\npractical applicability is demonstrated on experimental data obtained using a\nnovel optical ultrasound imaging setup. Accurate and robust positional\ninformation is provided in real-time. Axial and lateral coordinates for\nout-of-plane objects are estimated with a mean error of 0.1mm for simulated\ndata and a mean error of 0.2mm for experimental data. Three-dimensional\nlocalisation is most accurate for elevational distances larger than 1mm, with a\nmaximum distance of 5mm considered for a 25mm aperture.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Arttu Arjas",
      "Erwin J. Alles",
      "Efthymios Maneas",
      "Simon Arridge",
      "Adrien Desjardins",
      "Mikko J. Sillanp\u00e4\u00e4",
      "Andreas Hauptmann"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.09631"
  },
  {
    "id": "arXiv:2111.09902",
    "title": "A transformer-based model for default prediction in mid-cap corporate  markets",
    "abstract": "In this paper, we study mid-cap companies, i.e. publicly traded companies\nwith less than US $10 billion in market capitalisation. Using a large dataset\nof US mid-cap companies observed over 30 years, we look to predict the default\nprobability term structure over the medium term and understand which data\nsources (i.e. fundamental, market or pricing data) contribute most to the\ndefault risk. Whereas existing methods typically require that data from\ndifferent time periods are first aggregated and turned into cross-sectional\nfeatures, we frame the problem as a multi-label time-series classification\nproblem. We adapt transformer models, a state-of-the-art deep learning model\nemanating from the natural language processing domain, to the credit risk\nmodelling setting. We also interpret the predictions of these models using\nattention heat maps. To optimise the model further, we present a custom loss\nfunction for multi-label classification and a novel multi-channel architecture\nwith differential training that gives the model the ability to use all input\ndata efficiently. Our results show the proposed deep learning architecture's\nsuperior performance, resulting in a 13% improvement in AUC (Area Under the\nreceiver operating characteristic Curve) over traditional models. We also\ndemonstrate how to produce an importance ranking for the different data sources\nand the temporal relationships using a Shapley approach specific to these\nmodels.",
    "descriptor": "",
    "authors": [
      "Kamesh Korangi",
      "Christophe Mues",
      "Cristi\u00e1n Bravo"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09902"
  },
  {
    "id": "arXiv:2111.09935",
    "title": "A Conformer-based ASR Frontend for Joint Acoustic Echo Cancellation,  Speech Enhancement and Speech Separation",
    "abstract": "We present a frontend for improving robustness of automatic speech\nrecognition (ASR), that jointly implements three modules within a single model:\nacoustic echo cancellation, speech enhancement, and speech separation. This is\nachieved by using a contextual enhancement neural network that can optionally\nmake use of different types of side inputs: (1) a reference signal of the\nplayback audio, which is necessary for echo cancellation; (2) a noise context,\nwhich is useful for speech enhancement; and (3) an embedding vector\nrepresenting the voice characteristic of the target speaker of interest, which\nis not only critical in speech separation, but also helpful for echo\ncancellation and speech enhancement. We present detailed evaluations to show\nthat the joint model performs almost as well as the task-specific models, and\nsignificantly reduces word error rate in noisy conditions even when using a\nlarge-scale state-of-the-art ASR model. Compared to the noisy baseline, the\njoint model reduces the word error rate in low signal-to-noise ratio conditions\nby at least 71% on our echo cancellation dataset, 10% on our noisy dataset, and\n26% on our multi-speaker dataset. Compared to task-specific models, the joint\nmodel performs within 10% on our echo cancellation dataset, 2% on the noisy\ndataset, and 3% on the multi-speaker dataset.",
    "descriptor": "\nComments: Will appear in IEEE-ASRU 2021\n",
    "authors": [
      "Tom O'Malley",
      "Arun Narayanan",
      "Quan Wang",
      "Alex Park",
      "James Walker",
      "Nathan Howard"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.09935"
  },
  {
    "id": "arXiv:2111.09964",
    "title": "Deep IDA: A Deep Learning Method for Integrative Discriminant Analysis  of Multi-View Data with Feature Ranking -- An Application to COVID-19  severity",
    "abstract": "COVID-19 severity is due to complications from SARS-Cov-2 but the clinical\ncourse of the infection varies for individuals, emphasizing the need to better\nunderstand the disease at the molecular level. We use clinical and multiple\nmolecular data (or views) obtained from patients with and without COVID-19 who\nwere (or not) admitted to the intensive care unit to shed light on COVID-19\nseverity. Methods for jointly associating the views and separating the COVID-19\ngroups (i.e., one-step methods) have focused on linear relationships. The\nrelationships between the views and COVID-19 patient groups, however, are too\ncomplex to be understood solely by linear methods. Existing nonlinear one-step\nmethods cannot be used to identify signatures to aid in our understanding of\nthe complexity of the disease. We propose Deep IDA (Integrative Discriminant\nAnalysis) to address analytical challenges in our problem of interest. Deep IDA\nlearns nonlinear projections of two or more views that maximally associate the\nviews and separate the classes in each view, and permits feature ranking for\ninterpretable findings. Our applications demonstrate that Deep IDA has\ncompetitive classification rates compared to other state-of-the-art methods and\nis able to identify molecular signatures that facilitate an understanding of\nCOVID-19 severity.",
    "descriptor": "",
    "authors": [
      "Jiuzhou Wang",
      "Sandra E. Safo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.09964"
  },
  {
    "id": "arXiv:2111.09972",
    "title": "COVID-19 Detection on Chest X-Ray Images: A comparison of CNN  architectures and ensembles",
    "abstract": "COVID-19 quickly became a global pandemic after only four months of its first\ndetection. It is crucial to detect this disease as soon as possible to decrease\nits spread. The use of chest X-ray (CXR) images became an effective screening\nstrategy, complementary to the reverse transcription-polymerase chain reaction\n(RT-PCR). Convolutional neural networks (CNNs) are often used for automatic\nimage classification and they can be very useful in CXR diagnostics. In this\npaper, 21 different CNN architectures are tested and compared in the task of\nidentifying COVID-19 in CXR images. They were applied to the COVIDx8B dataset,\nwhich is the largest and more diverse COVID-19 dataset available. Ensembles of\nCNNs were also employed and they showed better efficacy than individual\ninstances. The best individual CNN instance results were achieved by\nDenseNet169, with an accuracy of 98.15% and an F1 score of 98.12%. These were\nfurther increased to 99.25% and 99.24%, respectively, through an ensemble with\nfive instances of DenseNet169. These results are higher than those obtained in\nrecent works using the same dataset.",
    "descriptor": "\nComments: 15 pages, 2 figures\n",
    "authors": [
      "Fabricio Breve"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09972"
  },
  {
    "id": "arXiv:2111.09982",
    "title": "Second-Order Mirror Descent: Convergence in Games Beyond Averaging and  Discounting",
    "abstract": "In this paper, we propose a second-order extension of the continuous-time\ngame-theoretic mirror descent (MD) dynamics, referred to as MD2, which\nconverges to mere (but not necessarily strict) variationally stable states\n(VSS) without using common auxiliary techniques such as averaging or\ndiscounting. We show that MD2 enjoys no-regret as well as exponential rate of\nconvergence towards a strong VSS upon a slight modification. Furthermore, MD2\ncan be used to derive many novel primal-space dynamics. Lastly, using\nstochastic approximation techniques, we provide a convergence guarantee of\ndiscrete-time MD2 with noisy observations towards interior mere VSS. Selected\nsimulations are provided to illustrate our results.",
    "descriptor": "\nComments: 16 pages, 12 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Bolin Gao",
      "Lacra Pavel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.09982"
  },
  {
    "id": "arXiv:2111.09983",
    "title": "Towards Measuring Fairness in Speech Recognition: Casual Conversations  Dataset Transcriptions",
    "abstract": "It is well known that many machine learning systems demonstrate bias towards\nspecific groups of individuals. This problem has been studied extensively in\nthe Facial Recognition area, but much less so in Automatic Speech Recognition\n(ASR). This paper presents initial Speech Recognition results on \"Casual\nConversations\" -- a publicly released 846 hour corpus designed to help\nresearchers evaluate their computer vision and audio models for accuracy across\na diverse set of metadata, including age, gender, and skin tone. The entire\ncorpus has been manually transcribed, allowing for detailed ASR evaluations\nacross these metadata. Multiple ASR models are evaluated, including models\ntrained on LibriSpeech, 14,000 hour transcribed, and over 2 million hour\nuntranscribed social media videos. Significant differences in word error rate\nacross gender and skin tone are observed at times for all models. We are\nreleasing human transcripts from the Casual Conversations dataset to encourage\nthe community to develop a variety of techniques to reduce these statistical\nbiases.",
    "descriptor": "\nComments: Submitted to ICASSP 2022. Our dataset will be publicly available at (this https URL) for general use. We also would like to note that considering the limitations of our dataset, we limit the use of it for only evaluation purposes (see license agreement)\n",
    "authors": [
      "Chunxi Liu",
      "Michael Picheny",
      "Leda Sar\u0131",
      "Pooja Chitkara",
      "Alex Xiao",
      "Xiaohui Zhang",
      "Mark Chou",
      "Andres Alvarado",
      "Caner Hazirbas",
      "Yatharth Saraf"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.09983"
  },
  {
    "id": "arXiv:2111.09990",
    "title": "Gaussian Determinantal Processes: a new model for directionality in data",
    "abstract": "Determinantal point processes (a.k.a. DPPs) have recently become popular\ntools for modeling the phenomenon of negative dependence, or repulsion, in\ndata. However, our understanding of an analogue of a classical parametric\nstatistical theory is rather limited for this class of models. In this work, we\ninvestigate a parametric family of Gaussian DPPs with a clearly interpretable\neffect of parametric modulation on the observed points. We show that parameter\nmodulation impacts the observed points by introducing directionality in their\nrepulsion structure, and the principal directions correspond to the directions\nof maximal (i.e. the most long ranged) dependency.\nThis model readily yields a novel and viable alternative to Principal\nComponent Analysis (PCA) as a dimension reduction tool that favors directions\nalong which the data is most spread out. This methodological contribution is\ncomplemented by a statistical analysis of a spiked model similar to that\nemployed for covariance matrices as a framework to study PCA. These theoretical\ninvestigations unveil intriguing questions for further examination in random\nmatrix theory, stochastic geometry and related topics.",
    "descriptor": "\nComments: Published in the Proceedings of the National Academy of Sciences (Direct Submission)\n",
    "authors": [
      "Subhro Ghosh",
      "Philippe Rigollet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.09990"
  },
  {
    "id": "arXiv:2111.10009",
    "title": "ExoMiner: A Highly Accurate and Explainable Deep Learning Classifier to  Mine Exoplanets",
    "abstract": "The kepler and TESS missions have generated over 100,000 potential transit\nsignals that must be processed in order to create a catalog of planet\ncandidates. During the last few years, there has been a growing interest in\nusing machine learning to analyze these data in search of new exoplanets.\nDifferent from the existing machine learning works, ExoMiner, the proposed deep\nlearning classifier in this work, mimics how domain experts examine diagnostic\ntests to vet a transit signal. ExoMiner is a highly accurate, explainable, and\nrobust classifier that 1) allows us to validate 301 new exoplanets from the\nMAST Kepler Archive and 2) is general enough to be applied across missions such\nas the on-going TESS mission. We perform an extensive experimental study to\nverify that ExoMiner is more reliable and accurate than the existing transit\nsignal classifiers in terms of different classification and ranking metrics.\nFor example, for a fixed precision value of 99%, ExoMiner retrieves 93.6% of\nall exoplanets in the test set (i.e., recall=0.936) while this rate is 76.3%\nfor the best existing classifier. Furthermore, the modular design of ExoMiner\nfavors its explainability. We introduce a simple explainability framework that\nprovides experts with feedback on why ExoMiner classifies a transit signal into\na specific class label (e.g., planet candidate or not planet candidate).",
    "descriptor": "\nComments: Accepted for Publication in Astrophysical Journals, November 20201\n",
    "authors": [
      "Hamed Valizadegan",
      "Miguel Martinho",
      "Laurent S. Wilkens",
      "Jon M. Jenkins",
      "Jeffrey Smith",
      "Douglas A. Caldwell",
      "Joseph D. Twicken",
      "Pedro C. Gerum",
      "Nikash Walia",
      "Kaylie Hausknecht",
      "Noa Y. Lubin",
      "Stephen T. Bryson",
      "Nikunj C. Oza"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10009"
  },
  {
    "id": "arXiv:2111.10021",
    "title": "Achievability and Impossibility of Exact Pairwise Ranking",
    "abstract": "We consider the problem of recovering the rank of a set of $n$ items based on\nnoisy pairwise comparisons. We assume the SST class as the family of generative\nmodels. Our analysis gave sharp information theoretic upper and lower bound for\nthe exact requirement, which matches exactly in the parametric limit. Our tight\nanalysis on the algorithm induced by the moment method gave better constant in\nMinimax optimal rate than ~\\citet{shah2017simple} and contribute to their open\nproblem. The strategy we used in this work to obtain information theoretic\nbounds is based on combinatorial arguments and is of independent interest.",
    "descriptor": "",
    "authors": [
      "Yihan He"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10021"
  },
  {
    "id": "arXiv:2111.10022",
    "title": "Concurrent Transmission and Multiuser Detection of LoRa Signals",
    "abstract": "This paper investigates a new model to improve the scalability of low-power\nlong-range (LoRa) networks by allowing multiple end devices (EDs) to\nsimultaneously communicate with multiple multi-antenna gateways on the same\nfrequency band and using the same spreading factor. The maximum likelihood (ML)\ndecision rule is first derived for non-coherent detection of information bits\ntransmitted by multiple devices. To overcome the high complexity of the ML\ndetection, we propose a sub-optimal two-stage detection algorithm to balance\nthe computational complexity and error performance. In the first stage, we\nidentify transmit chirps (without knowing which EDs transmit them). In the\nsecond stage, we determine the EDs that transmit the specific chirps identified\nfrom the first stage. To improve the detection performance in the second stage,\nwe also optimize the transmit powers of EDs to minimize the similarity,\nmeasured by the Jaccard coefficient, between the received powers of any pair of\nEDs. As the power control optimization problem is non-convex, we use concepts\nfrom successive convex approximation to transform it to an approximate convex\noptimization problem that can be solved iteratively and guaranteed to reach a\nsub-optimal solution. Simulation results demonstrate and justify the tradeoff\nbetween transmit power penalties and network scalability of the proposed LoRa\nnetwork model. In particular, by allowing concurrent transmission of 2 or 3\nEDs, the uplink capacity of the proposed network can be doubled or tripled over\nthat of a conventional LoRa network, albeit at the expense of additional 3.0 or\n4.7 dB transmit power.",
    "descriptor": "\nComments: 11 pages, 7 figures, submitted to IEEE for possible publication\n",
    "authors": [
      "Khai Nguyen",
      "Ha H. Nguyen",
      "Ebrahim Bedeer"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.10022"
  },
  {
    "id": "arXiv:2111.10026",
    "title": "IC-U-Net: A U-Net-based Denoising Autoencoder Using Mixtures of  Independent Components for Automatic EEG Artifact Removal",
    "abstract": "Electroencephalography (EEG) signals are often contaminated with artifacts.\nIt is imperative to develop a practical and reliable artifact removal method to\nprevent misinterpretations of neural signals and underperformance of\nbrain-computer interfaces. This study developed a new artifact removal method,\nIC-U-Net, which is based on the U-Net architecture for removing pervasive EEG\nartifacts and reconstructing brain sources. The IC-U-Net was trained using\nmixtures of brain and non-brain sources decomposed by independent component\nanalysis and employed an ensemble of loss functions to model complex signal\nfluctuations in EEG recordings. The effectiveness of the proposed method in\nrecovering brain sources and removing various artifacts (e.g., eye\nblinks/movements, muscle activities, and line/channel noises) was demonstrated\nin a simulation study and three real-world EEG datasets collected at rest and\nwhile driving and walking. IC-U-Net is user-friendly and publicly available,\ndoes not require parameter tuning or artifact type designations, and has no\nlimitations on channel numbers. Given the increasing need to image natural\nbrain dynamics in a mobile setting, IC-U-Net offers a promising end-to-end\nsolution for automatically removing artifacts from EEG recordings.",
    "descriptor": "",
    "authors": [
      "Chun-Hsiang Chuang",
      "Kong-Yi Chang",
      "Chi-Sheng Huang",
      "Tzyy-Ping Jung"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10026"
  },
  {
    "id": "arXiv:2111.10038",
    "title": "From word-representable graphs to altered Tverberg-type theorems",
    "abstract": "Tverberg's theorem says that a set with sufficiently many points in\n$\\mathbb{R}^d$ can always be partitioned into $m$ parts so that the\n$(m-1)$-simplex is the (nerve) intersection pattern of the convex hulls of the\nparts. In arXiv:1808.00551v1 [math.MG] the authors investigate how other\nsimplicial complexes arise as nerve complexes once we have a set with\nsufficiently many points. In this paper we relate the theory of\nword-representable graphs as a way of codifying $1$-skeletons of simplicial\ncomplexes to generate nerves. In particular, we show that every\n$2$-word-representable triangle-free graph, every circle graph, every\nouterplanar graph, and every bipartite graph could be induced as a nerve\ncomplex once we have a set with sufficiently many points in $\\mathbb{R}^d$ for\nsome $d$.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Deborah Oliveros",
      "Antonio Torres"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2111.10038"
  },
  {
    "id": "arXiv:2111.10043",
    "title": "A comparison of streaming models and data augmentation methods for  robust speech recognition",
    "abstract": "In this paper, we present a comparative study on the robustness of two\ndifferent online streaming speech recognition models: Monotonic Chunkwise\nAttention (MoChA) and Recurrent Neural Network-Transducer (RNN-T). We explore\nthree recently proposed data augmentation techniques, namely, multi-conditioned\ntraining using an acoustic simulator, Vocal Tract Length Perturbation (VTLP)\nfor speaker variability, and SpecAugment. Experimental results show that\nunidirectional models are in general more sensitive to noisy examples in the\ntraining set. It is observed that the final performance of the model depends on\nthe proportion of training examples processed by data augmentation techniques.\nMoChA models generally perform better than RNN-T models. However, we observe\nthat training of MoChA models seems to be more sensitive to various factors\nsuch as the characteristics of training sets and the incorporation of\nadditional augmentations techniques. On the other hand, RNN-T models perform\nbetter than MoChA models in terms of latency, inference time, and the stability\nof training. Additionally, RNN-T models are generally more robust against noise\nand reverberation. All these advantages make RNN-T models a better choice for\nstreaming on-device speech recognition compared to MoChA models.",
    "descriptor": "\nComments: Accepted as a conference paper at ASRU 2021\n",
    "authors": [
      "Jiyeon Kim",
      "Mehul Kumar",
      "Dhananjaya Gowda",
      "Abhinav Garg",
      "Chanwoo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.10043"
  },
  {
    "id": "arXiv:2111.10047",
    "title": "Semi-supervised transfer learning for language expansion of end-to-end  speech recognition models to low-resource languages",
    "abstract": "In this paper, we propose a three-stage training methodology to improve the\nspeech recognition accuracy of low-resource languages. We explore and propose\nan effective combination of techniques such as transfer learning, encoder\nfreezing, data augmentation using Text-To-Speech (TTS), and Semi-Supervised\nLearning (SSL). To improve the accuracy of a low-resource Italian ASR, we\nleverage a well-trained English model, unlabeled text corpus, and unlabeled\naudio corpus using transfer learning, TTS augmentation, and SSL respectively.\nIn the first stage, we use transfer learning from a well-trained English model.\nThis primarily helps in learning the acoustic information from a resource-rich\nlanguage. This stage achieves around 24% relative Word Error Rate (WER)\nreduction over the baseline. In stage two, We utilize unlabeled text data via\nTTS data-augmentation to incorporate language information into the model. We\nalso explore freezing the acoustic encoder at this stage. TTS data augmentation\nhelps us further reduce the WER by ~ 21% relatively. Finally, In stage three we\nreduce the WER by another 4% relative by using SSL from unlabeled audio data.\nOverall, our two-pass speech recognition system with a Monotonic Chunkwise\nAttention (MoChA) in the first pass and a full-attention in the second pass\nachieves a WER reduction of ~ 42% relative to the baseline.",
    "descriptor": "\nComments: Accepted as a conference paper at ASRU 2021\n",
    "authors": [
      "Jiyeon Kim",
      "Mehul Kumar",
      "Dhananjaya Gowda",
      "Abhinav Garg",
      "Chanwoo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.10047"
  },
  {
    "id": "arXiv:2111.10066",
    "title": "Assessment of Fetal and Maternal Well-Being During Pregnancy Using  Passive Wearable Inertial Sensor",
    "abstract": "Assessing the health of both the fetus and mother is vital in preventing and\nidentifying possible complications in pregnancy. This paper focuses on a device\nthat can be used effectively by the mother herself with minimal supervision and\nprovide a reasonable estimation of fetal and maternal health while being safe,\ncomfortable, and easy to use. The device proposed uses a belt with a single\naccelerometer over the mother's uterus to record the required information. The\ndevice is expected to monitor both the mother and the fetus constantly over a\nlong period and provide medical professionals with useful information, which\nthey would otherwise overlook due to the low frequency that health monitoring\nis carried out at the present. The paper shows that simultaneous measurement of\nrespiratory information of the mother and fetal movement is in fact possible\neven in the presence of mild interferences, which needs to be accounted for if\nthe device is expected to be worn for extended times.",
    "descriptor": "\nComments: 9 pages, 16 figures, 1 table\n",
    "authors": [
      "Eranda Somathilake",
      "Upekha Delay",
      "Janith Bandara Senanayaka",
      "Samitha Gunarathne",
      "Roshan Godaliyadda",
      "Parakrama Ekanayake",
      "Janaka Wijayakulasooriya",
      "Chathura Rathnayake"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.10066"
  },
  {
    "id": "arXiv:2111.10106",
    "title": "A Large Scale Benchmark for Individual Treatment Effect Prediction and  Uplift Modeling",
    "abstract": "Individual Treatment Effect (ITE) prediction is an important area of research\nin machine learning which aims at explaining and estimating the causal impact\nof an action at the granular level. It represents a problem of growing interest\nin multiple sectors of application such as healthcare, online advertising or\nsocioeconomics. To foster research on this topic we release a publicly\navailable collection of 13.9 million samples collected from several randomized\ncontrol trials, scaling up previously available datasets by a healthy 210x\nfactor. We provide details on the data collection and perform sanity checks to\nvalidate the use of this data for causal inference tasks. First, we formalize\nthe task of uplift modeling (UM) that can be performed with this data, along\nwith the relevant evaluation metrics. Then, we propose synthetic response\nsurfaces and heterogeneous treatment assignment providing a general set-up for\nITE prediction. Finally, we report experiments to validate key characteristics\nof the dataset leveraging its size to evaluate and compare - with high\nstatistical significance - a selection of baseline UM and ITE prediction\nmethods.",
    "descriptor": "",
    "authors": [
      "Eustache Diemert",
      "Artem Betlei",
      "Christophe Renaudin",
      "Massih-Reza Amini",
      "Th\u00e9ophane Gregoir",
      "Thibaud Rahier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.10106"
  },
  {
    "id": "arXiv:2111.10178",
    "title": "Understanding Training-Data Leakage from Gradients in Neural Networks  for Image Classification",
    "abstract": "Federated learning of deep learning models for supervised tasks, e.g. image\nclassification and segmentation, has found many applications: for example in\nhuman-in-the-loop tasks such as film post-production where it enables sharing\nof domain expertise of human artists in an efficient and effective fashion. In\nmany such applications, we need to protect the training data from being leaked\nwhen gradients are shared in the training process due to IP or privacy\nconcerns. Recent works have demonstrated that it is possible to reconstruct the\ntraining data from gradients for an image-classification model when its\narchitecture is known. However, there is still an incomplete theoretical\nunderstanding of the efficacy and failure of such attacks. In this paper, we\nanalyse the source of training-data leakage from gradients. We formulate the\nproblem of training data reconstruction as solving an optimisation problem\niteratively for each layer. The layer-wise objective function is primarily\ndefined by weights and gradients from the current layer as well as the output\nfrom the reconstruction of the subsequent layer, but it might also involve a\n'pull-back' constraint from the preceding layer. Training data can be\nreconstructed when we solve the problem backward from the output of the network\nthrough each layer. Based on this formulation, we are able to attribute the\npotential leakage of the training data in a deep network to its architecture.\nWe also propose a metric to measure the level of security of a deep learning\nmodel against gradient-based attacks on the training data.",
    "descriptor": "",
    "authors": [
      "Cangxiong Chen",
      "Neill D.F. Campbell"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10178"
  },
  {
    "id": "arXiv:2111.10183",
    "title": "Benchmarking Small-Scale Quantum Devices on Computing Graph Edit  Distance",
    "abstract": "Distance measures provide the foundation for many popular algorithms in\nMachine Learning and Pattern Recognition. Different notions of distance can be\nused depending on the types of the data the algorithm is working on. For\ngraph-shaped data, an important notion is the Graph Edit Distance (GED) that\nmeasures the degree of (dis)similarity between two graphs in terms of the\noperations needed to make them identical. As the complexity of computing GED is\nthe same as NP-hard problems, it is reasonable to consider approximate\nsolutions. In this paper we present a comparative study of two quantum\napproaches to computing GED: quantum annealing and variational quantum\nalgorithms, which refer to the two types of quantum hardware currently\navailable, namely quantum annealer and gate-based quantum computer,\nrespectively. Considering the current state of noisy intermediate-scale quantum\ncomputers, we base our study on proof-of-principle tests of the performance of\nthese quantum algorithms.",
    "descriptor": "\nComments: 12 pages, 8 figures. Comments are welcome\n",
    "authors": [
      "Massimiliano Incudini",
      "Fabio Tarocco",
      "Riccardo Mengoni",
      "Alessandra Di Pierro",
      "Antonio Mandarino"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10183"
  },
  {
    "id": "arXiv:2111.10189",
    "title": "Analysis of autocorrelation times in Neural Markov Chain Monte Carlo  simulations",
    "abstract": "We provide a deepened study of autocorrelations in Neural Markov Chain Monte\nCarlo simulations, a version of the traditional Metropolis algorithm which\nemploys neural networks to provide independent proposals. We illustrate our\nideas using the two-dimensional Ising model. We propose several estimates of\nautocorrelation times, some inspired by analytical results derived for the\nMetropolized Independent Sampler, which we compare and study as a function of\ninverse temperature $\\beta$. Based on that we propose an alternative loss\nfunction and study its impact on the autocorelation times. Furthermore, we\ninvestigate the impact of imposing system symmetries ($Z_2$ and/or\ntranslational) in the neural network training process on the autocorrelation\ntimes. Eventually, we propose a scheme which incorporates partial heat-bath\nupdates. The impact of the above enhancements is discussed for a $16 \\times 16$\nspin system. The summary of our findings may serve as a guide to the\nimplementation of Neural Markov Chain Monte Carlo simulations of more\ncomplicated models.",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Piotr Bia\u0142as",
      "Piotr Korcyl",
      "Tomasz Stebel"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.10189"
  },
  {
    "id": "arXiv:2111.10195",
    "title": "Real-time Coherency Identification using a Window-Size-Based Recursive  Typicality Data Analysis",
    "abstract": "This work presents a data-driven analysis of minimal length necessary for\ncoherency detection considering a recursive form of the typicality-based Data\nanalysis (TDA). It proposes a methodology that encloses the observation of the\nvariance of the typicality ({\\tau} ) to asses the minimal window length\nnecessary to determine the coherent buses, where the properties of the TDA\napproach and the groups of buses are iteratively calculated at every new data\npoint sampled. Once the variance of each group reaches a certain value, the\nminimal window length is determined. Besides, this method preserves the TDA\ncharacteristics of using exclusively measurements, not requiring\npre-determination of number of groups, group centers or cut-off constants. The\nmethod is applied to the well know 2-area Kundur test system, allowing to\ncorroborate its effectiveness and draw conclusions regarding minimal window\nlength dependence on the slowest inter-area mode.",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "Lucas Lugnani",
      "Daniel Dotta",
      "Mario R. A. Paternina",
      "Joe Chow"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10195"
  },
  {
    "id": "arXiv:2111.10198",
    "title": "Datasets for Online Controlled Experiments",
    "abstract": "Online Controlled Experiments (OCE) are the gold standard to measure impact\nand guide decisions for digital products and services. Despite many\nmethodological advances in this area, the scarcity of public datasets and the\nlack of a systematic review and categorization hinder its development. We\npresent the first survey and taxonomy for OCE datasets, which highlight the\nlack of a public dataset to support the design and running of experiments with\nadaptive stopping, an increasingly popular approach to enable quickly deploying\nimprovements or rolling back degrading changes. We release the first such\ndataset, containing daily checkpoints of decision metrics from multiple, real\nexperiments run on a global e-commerce platform. The dataset design is guided\nby a broader discussion on data requirements for common statistical tests used\nin digital experimentation. We demonstrate how to use the dataset in the\nadaptive stopping scenario using sequential and Bayesian hypothesis tests and\nlearn the relevant parameters for each approach.",
    "descriptor": "\nComments: To appear in 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks. 16 pages, 2 figures, 2 tables. Dataset available on Open Science Framework: this https URL\n",
    "authors": [
      "C. H. Bryan Liu",
      "\u00c2ngelo Cardoso",
      "Paul Couturier",
      "Emma J. McCoy"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Databases (cs.DB)",
      "General Literature (cs.GL)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.10198"
  },
  {
    "id": "arXiv:2111.10202",
    "title": "Multimodal Emotion Recognition with High-level Speech and Text Features",
    "abstract": "Automatic emotion recognition is one of the central concerns of the\nHuman-Computer Interaction field as it can bridge the gap between humans and\nmachines. Current works train deep learning models on low-level data\nrepresentations to solve the emotion recognition task. Since emotion datasets\noften have a limited amount of data, these approaches may suffer from\noverfitting, and they may learn based on superficial cues. To address these\nissues, we propose a novel cross-representation speech model, inspired by\ndisentanglement representation learning, to perform emotion recognition on\nwav2vec 2.0 speech features. We also train a CNN-based model to recognize\nemotions from text features extracted with Transformer-based models. We further\ncombine the speech-based and text-based results with a score fusion approach.\nOur method is evaluated on the IEMOCAP dataset in a 4-class classification\nproblem, and it surpasses current works on speech-only, text-only, and\nmultimodal emotion recognition.",
    "descriptor": "\nComments: Accepted at ASRU 2021. Code available at this https URL\n",
    "authors": [
      "Mariana Rodrigues Makiuchi",
      "Kuniaki Uto",
      "Koichi Shinoda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.10202"
  },
  {
    "id": "arXiv:2111.10205",
    "title": "Control-sharing Control Barrier Functions for Intersection Automation  under Input Constraints",
    "abstract": "This contribution introduces a centralized input constrained optimal control\nframework based on multiple control barrier functions (CBFs) to coordinate\nconnected and automated agents at intersections. For collision avoidance, we\npropose a novel CBF which is safe by construction. The given control scheme\nprovides provable guarantees that collision avoidance CBFs and CBFs to\nconstrain the agents' velocity are jointly feasible (referred to as\ncontrol-sharing property) subject to input constraints. A simulation study\nfinally provides evidence that the proposed control scheme is safe.",
    "descriptor": "\nComments: Submitted to European Control Conference 2022\n",
    "authors": [
      "Alexander Katriniok"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10205"
  },
  {
    "id": "arXiv:2111.10207",
    "title": "Comparative Study of Speech Analysis Methods to Predict Parkinson's  Disease",
    "abstract": "One of the symptoms observed in the early stages of Parkinson's Disease (PD)\nis speech impairment. Speech disorders can be used to detect this disease\nbefore it degenerates. This work analyzes speech features and machine learning\napproaches to predict PD. Acoustic features such as shimmer and jitter\nvariants, and Mel Frequency Cepstral Coefficients (MFCC) are extracted from\nspeech signals. We use two datasets in this work: the MDVR-KCL and the Italian\nParkinson's Voice and Speech database. To separate PD and non-PD speech\nsignals, seven classification models were implemented: K-Nearest Neighbor,\nDecision Trees, Support Vector Machines, Naive Bayes, Logistic Regression,\nGradient Boosting, Random Forests. Three feature sets were used for each of the\nmodels: (a) Acoustic features only, (b) All the acoustic features and MFCC, (c)\nSelected subset of features from acoustic features and MFCC. Using all the\nacoustic features and MFCC, together with SVM produced the highest performance\nwith an accuracy of 98% and F1-Score of 99%. When compared with prior art, this\nshows a better performance. Our code and related documentation is available in\na public domain repository.",
    "descriptor": "\nComments: Machine Learning for Health (ML4H) - Extended Abstract\n",
    "authors": [
      "Adedolapo Aishat Toye",
      "Suryaprakash Kompalli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.10207"
  },
  {
    "id": "arXiv:2111.10208",
    "title": "Attention based end to end Speech Recognition for Voice Search in Hindi  and English",
    "abstract": "We describe here our work with automatic speech recognition (ASR) in the\ncontext of voice search functionality on the Flipkart e-Commerce platform.\nStarting with the deep learning architecture of Listen-Attend-Spell (LAS), we\nbuild upon and expand the model design and attention mechanisms to incorporate\ninnovative approaches including multi-objective training, multi-pass training,\nand external rescoring using language models and phoneme based losses. We\nreport a relative WER improvement of 15.7% on top of state-of-the-art LAS\nmodels using these modifications. Overall, we report an improvement of 36.9%\nover the phoneme-CTC system. The paper also provides an overview of different\ncomponents that can be tuned in a LAS-based system.",
    "descriptor": "\nComments: Accepted at Forum for Information Retrieval Evaluation (FIRE) 2021\n",
    "authors": [
      "Raviraj Joshi",
      "Venkateshan Kannan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.10208"
  },
  {
    "id": "arXiv:2111.10210",
    "title": "The Application of Zig-Zag Sampler in Sequential Markov Chain Monte  Carlo",
    "abstract": "Particle filtering methods are widely applied in sequential state estimation\nwithin nonlinear non-Gaussian state space model. However, the traditional\nparticle filtering methods suffer the weight degeneracy in the high-dimensional\nstate space model. Currently, there are many methods to improve the performance\nof particle filtering in high-dimensional state space model. Among these, the\nmore advanced method is to construct the Sequential Makov chian Monte Carlo\n(SMCMC) framework by implementing the Composite Metropolis-Hasting (MH) Kernel.\nIn this paper, we proposed to discrete the Zig-Zag Sampler and apply the\nZig-Zag Sampler in the refinement stage of the Composite MH Kernel within the\nSMCMC framework which is implemented the invertible particle flow in the joint\ndraw stage. We evaluate the performance of proposed method through numerical\nexperiments of the challenging complex high-dimensional filtering examples.\nNemurical experiments show that in high-dimensional state estimation examples,\nthe proposed method improves estimation accuracy and increases the acceptance\nratio compared with state-of-the-art filtering methods.",
    "descriptor": "",
    "authors": [
      "Yu Han",
      "Kazuyuki Nakamura"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.10210"
  },
  {
    "id": "arXiv:2111.10227",
    "title": "Policy Gradient Approach to Compilation of Variational Quantum Circuits",
    "abstract": "We propose a method for finding approximate compilations of quantum circuits,\nbased on techniques from policy gradient reinforcement learning. The choice of\na stochastic policy allows us to rephrase the optimization problem in terms of\nprobability distributions, rather than variational parameters. This implies\nthat searching for the optimal configuration is done by optimizing over the\ndistribution parameters, rather than over the circuit free angles. The upshot\nof this is that we can always compute a gradient, provided that the policy is\ndifferentiable. We show numerically that this approach is more competitive than\nthose using gradient-free methods, even in the presence of depolarizing noise,\nand argue analytically why this is the case. Another interesting feature of\nthis approach to variational compilation is that it does not need a separate\nregister and long-range interactions to estimate the end-point fidelity. We\nexpect these techniques to be relevant for training variational circuit in\nother contexts",
    "descriptor": "",
    "authors": [
      "David A. Herrera-Mart\u00ed"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10227"
  },
  {
    "id": "arXiv:2111.10243",
    "title": "Posterior concentration and fast convergence rates for generalized  Bayesian learning",
    "abstract": "In this paper, we study the learning rate of generalized Bayes estimators in\na general setting where the hypothesis class can be uncountable and have an\nirregular shape, the loss function can have heavy tails, and the optimal\nhypothesis may not be unique. We prove that under the multi-scale Bernstein's\ncondition, the generalized posterior distribution concentrates around the set\nof optimal hypotheses and the generalized Bayes estimator can achieve fast\nlearning rate. Our results are applied to show that the standard Bayesian\nlinear regression is robust to heavy-tailed distributions.",
    "descriptor": "",
    "authors": [
      "Lam Si Tung Ho",
      "Binh T. Nguyen",
      "Vu Dinh",
      "Duy Nguyen"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10243"
  },
  {
    "id": "arXiv:2111.10248",
    "title": "Non asymptotic bounds in asynchronous sum-weight gossip protocols",
    "abstract": "This paper focuses on non-asymptotic diffusion time in asynchronous gossip\nprotocols. Asynchronous gossip protocols are designed to perform distributed\ncomputation in a network of nodes by randomly exchanging messages on the\nassociated graph. To achieve consensus among nodes, a minimal number of\nmessages has to be exchanged. We provides a probabilistic bound to such number\nfor the general case. We provide a explicit formula for fully connected graphs\ndepending only on the number of nodes and an approximation for any graph\ndepending on the spectrum of the graph.",
    "descriptor": "\nComments: Unpublished work done circa 2016\n",
    "authors": [
      "David Picard",
      "J\u00e9r\u00f4me Fellus",
      "St\u00e9phane Garnier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.10248"
  },
  {
    "id": "arXiv:2111.10255",
    "title": "An Analysis of the Influence of Transfer Learning When Measuring the  Tortuosity of Blood Vessels",
    "abstract": "Characterizing blood vessels in digital images is important for the diagnosis\nof many types of diseases as well as for assisting current researches regarding\nvascular systems. The automated analysis of blood vessels typically requires\nthe identification, or segmentation, of the blood vessels in an image or a set\nof images, which is usually a challenging task. Convolutional Neural Networks\n(CNNs) have been shown to provide excellent results regarding the segmentation\nof blood vessels. One important aspect of CNNs is that they can be trained on\nlarge amounts of data and then be made available, for instance, in image\nprocessing software for wide use. The pre-trained CNNs can then be easily\napplied in downstream blood vessel characterization tasks such as the\ncalculation of the length, tortuosity, or caliber of the blood vessels. Yet, it\nis still unclear if pre-trained CNNs can provide robust, unbiased, results on\ndownstream tasks when applied to datasets that they were not trained on. Here,\nwe focus on measuring the tortuosity of blood vessels and investigate to which\nextent CNNs may provide biased tortuosity values even after fine-tuning the\nnetwork to the new dataset under study. We show that the tortuosity values\nobtained by a CNN trained from scratch on a dataset may not agree with those\nobtained by a fine-tuned network that was pre-trained on a dataset having\ndifferent tortuosity statistics. In addition, we show that the improvement in\nsegmentation performance when fine-tuning the network does not necessarily lead\nto a respective improvement on the estimation of the tortuosity. To mitigate\nthe aforementioned issues, we propose the application of specific data\naugmentation techniques even in situations where they do not improve\nsegmentation performance.",
    "descriptor": "",
    "authors": [
      "Matheus V. da Silva",
      "Julie Ouellette",
      "Baptiste Lacoste",
      "Cesar H. Comin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10255"
  },
  {
    "id": "arXiv:2111.10262",
    "title": "Residual fourier neural operator for thermochemical curing of composites",
    "abstract": "During the curing process of composites, the temperature history heavily\ndetermines the evolutions of the field of degree of cure as well as the\nresidual stress, which will further influence the mechanical properties of\ncomposite, thus it is important to simulate the real temperature history to\noptimize the curing process of composites. Since thermochemical analysis using\nFinite Element (FE) simulations requires heavy computational loads and\ndata-driven approaches suffer from the complexity of highdimensional mapping.\nThis paper proposes a Residual Fourier Neural Operator (ResFNO) to establish\nthe direct high-dimensional mapping from any given cure cycle to the\ncorresponding temperature histories. By integrating domain knowledge into a\ntime-resolution independent parameterized neural network, the mapping between\ncure cycles to temperature histories can be learned using limited number of\nlabelled data. Besides, a novel Fourier residual mapping is designed based on\nmode decomposition to accelerate the training and boost the performance\nsignificantly. Several cases are carried out to evaluate the superior\nperformance and generalizability of the proposed method comprehensively.",
    "descriptor": "\nComments: 15 pages, 16 figures\n",
    "authors": [
      "Gengxiang Chen",
      "Yingguang Li",
      "Xu liu",
      "Qinglu Meng",
      "Jing Zhou",
      "Xiaozhong Hao"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10262"
  },
  {
    "id": "arXiv:2111.10267",
    "title": "Over-the-Air Federated Learning with Retransmissions (Extended Version)",
    "abstract": "Motivated by increasing computational capabilities of wireless devices, as\nwell as unprecedented levels of user- and device-generated data, new\ndistributed machine learning (ML) methods have emerged. In the wireless\ncommunity, Federated Learning (FL) is of particular interest due to its\ncommunication efficiency and its ability to deal with the problem of non-IID\ndata. FL training can be accelerated by a wireless communication method called\nOver-the-Air Computation (AirComp) which harnesses the interference of\nsimultaneous uplink transmissions to efficiently aggregate model updates.\nHowever, since AirComp utilizes analog communication, it introduces inevitable\nestimation errors. In this paper, we study the impact of such estimation errors\non the convergence of FL and propose retransmissions as a method to improve FL\nconvergence over resource-constrained wireless networks. First, we derive the\noptimal AirComp power control scheme with retransmissions over static channels.\nThen, we investigate the performance of Over-the-Air FL with retransmissions\nand find two upper bounds on the FL loss function. Finally, we propose a\nheuristic for selecting the optimal number of retransmissions, which can be\ncalculated before training the ML model. Numerical results demonstrate that the\nintroduction of retransmissions can lead to improved ML performance, without\nincurring extra costs in terms of communication or computation. Additionally,\nwe provide simulation results on our heuristic which indicate that it can\ncorrectly identify the optimal number of retransmissions for different wireless\nnetwork setups and machine learning problems.",
    "descriptor": "\nComments: 14 pages, 8 figure, journal paper\n",
    "authors": [
      "Henrik Hellstr\u00f6m",
      "Viktoria Fodor",
      "Carlo Fischione"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10267"
  },
  {
    "id": "arXiv:2111.10270",
    "title": "FastDOG: Fast Discrete Optimization on GPU",
    "abstract": "We present a massively parallel Lagrange decomposition method for solving 0-1\ninteger linear programs occurring in structured prediction. We propose a new\niterative update scheme for solving the Lagrangean dual and a perturbation\ntechnique for decoding primal solutions. For representing subproblems we follow\nLange et al. (2021) and use binary decision diagrams (BDDs). Our primal and\ndual algorithms require little synchronization between subproblems and\noptimization over BDDs needs only elementary operations without complicated\ncontrol flow. This allows us to exploit the parallelism offered by GPUs for all\ncomponents of our method. We present experimental results on combinatorial\nproblems from MAP inference for Markov Random Fields, quadratic assignment and\ncell tracking for developmental biology. Our highly parallel GPU implementation\nimproves upon the running times of the algorithms from Lange et al. (2021) by\nup to an order of magnitude. In particular, we come close to or outperform some\nstate-of-the-art specialized heuristics while being problem agnostic.",
    "descriptor": "\nComments: Alert before printing: last 10 pages just contains detailed results can possibly be skipped\n",
    "authors": [
      "Ahmed Abbas",
      "Paul Swoboda"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.10270"
  },
  {
    "id": "arXiv:2111.10275",
    "title": "Composite Goodness-of-fit Tests with Kernels",
    "abstract": "Model misspecification can create significant challenges for the\nimplementation of probabilistic models, and this has led to development of a\nrange of inference methods which directly account for this issue. However,\nwhether these more involved methods are required will depend on whether the\nmodel is really misspecified, and there is a lack of generally applicable\nmethods to answer this question. One set of tools which can help are\ngoodness-of-fit tests, where we test whether a dataset could have been\ngenerated by a fixed distribution. Kernel-based tests have been developed to\nfor this problem, and these are popular due to their flexibility, strong\ntheoretical guarantees and ease of implementation in a wide range of scenarios.\nIn this paper, we extend this line of work to the more challenging composite\ngoodness-of-fit problem, where we are instead interested in whether the data\ncomes from any distribution in some parametric family. This is equivalent to\ntesting whether a parametric model is well-specified for the data.",
    "descriptor": "",
    "authors": [
      "Oscar Key",
      "Tamara Fernandez",
      "Arthur Gretton",
      "Fran\u00e7ois-Xavier Briol"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.10275"
  },
  {
    "id": "arXiv:2111.10298",
    "title": "An Asymptotic Equivalence between the Mean-Shift Algorithm and the  Cluster Tree",
    "abstract": "Two important nonparametric approaches to clustering emerged in the 1970's:\nclustering by level sets or cluster tree as proposed by Hartigan, and\nclustering by gradient lines or gradient flow as proposed by Fukunaga and\nHosteler. In a recent paper, we argue the thesis that these two approaches are\nfundamentally the same by showing that the gradient flow provides a way to move\nalong the cluster tree. In making a stronger case, we are confronted with the\nfact the cluster tree does not define a partition of the entire support of the\nunderlying density, while the gradient flow does. In the present paper, we\nresolve this conundrum by proposing two ways of obtaining a partition from the\ncluster tree -- each one of them very natural in its own right -- and showing\nthat both of them reduce to the partition given by the gradient flow under\nstandard assumptions on the sampling density.",
    "descriptor": "",
    "authors": [
      "Ery Arias-Castro",
      "Wanli Qiao"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10298"
  },
  {
    "id": "arXiv:2111.10302",
    "title": "Instance-Adaptive Video Compression: Improving Neural Codecs by Training  on the Test Set",
    "abstract": "We introduce a video compression algorithm based on instance-adaptive\nlearning. On each video sequence to be transmitted, we finetune a pretrained\ncompression model. The optimal parameters are transmitted to the receiver along\nwith the latent code. By entropy-coding the parameter updates under a suitable\nmixture model prior, we ensure that the network parameters can be encoded\nefficiently. This instance-adaptive compression algorithm is agnostic about the\nchoice of base model and has the potential to improve any neural video codec.\nOn UVG, HEVC, and Xiph datasets, our codec improves the performance of a\nlow-latency scale-space flow model by between 21% and 26% BD-rate savings, and\nthat of a state-of-the-art B-frame model by 17 to 20% BD-rate savings. We also\ndemonstrate that instance-adaptive finetuning improves the robustness to domain\nshift. Finally, our approach reduces the capacity requirements on compression\nmodels. We show that it enables a state-of-the-art performance even after\nreducing the network size by 72%.",
    "descriptor": "",
    "authors": [
      "Ties van Rozendaal",
      "Johann Brehmer",
      "Yunfan Zhang",
      "Reza Pourreza",
      "Taco S. Cohen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10302"
  },
  {
    "id": "arXiv:2111.10303",
    "title": "Asymptotic Improvements on the Exact Matching Distance for 2-parameter  Persistence",
    "abstract": "In the field of topological data analysis, persistence modules are used to\nexpress geometrical features of data sets. The matching distance\n$d_\\mathcal{M}$ measures the difference between $2$-parameter persistence\nmodules by taking the maximum bottleneck distance between $1$-parameter slices\nof the modules. The previous fastest algorithm to compute $d_\\mathcal{M}$\nexactly runs in $O(n^{8+\\omega})$, where $\\omega$ is the matrix multiplication\nconstant. We improve significantly on this by describing an algorithm with\nexpected running time $O(n^5 \\log^3 n)$. We first solve the decision problem\n$d_\\mathcal{M}\\leq \\lambda$ for a constant $\\lambda$ in $O(n^5\\log n)$ by\ntraversing a line arrangement in the dual plane, where each point represents a\nslice. Then we lift the line arrangement to a plane arrangement in\n$\\mathbb{R}^3$ whose vertices represent possible values for $d_\\mathcal{M}$,\nand use a randomized incremental method to search through the vertices and find\n$d_\\mathcal{M}$. The expected running time of this algorithm is\n$O((n^4+T(n))\\log^2 n)$, where $T(n)$ is an upper bound for the complexity of\ndeciding if $d_\\mathcal{M}\\leq \\lambda$.",
    "descriptor": "",
    "authors": [
      "H\u00e5vard Bakke Bjerkevik",
      "Michael Kerber"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2111.10303"
  },
  {
    "id": "arXiv:2111.10329",
    "title": "Physics-enhanced Neural Networks in the Small Data Regime",
    "abstract": "Identifying the dynamics of physical systems requires a machine learning\nmodel that can assimilate observational data, but also incorporate the laws of\nphysics. Neural Networks based on physical principles such as the Hamiltonian\nor Lagrangian NNs have recently shown promising results in generating\nextrapolative predictions and accurately representing the system's dynamics. We\nshow that by additionally considering the actual energy level as a\nregularization term during training and thus using physical information as\ninductive bias, the results can be further improved. Especially in the case\nwhere only small amounts of data are available, these improvements can\nsignificantly enhance the predictive capability. We apply the proposed\nregularization term to a Hamiltonian Neural Network (HNN) and Constrained\nHamiltonian Neural Network (CHHN) for a single and double pendulum, generate\npredictions under unseen initial conditions and report significant gains in\npredictive accuracy.",
    "descriptor": "",
    "authors": [
      "Jonas Eichelsd\u00f6rfer",
      "Sebastian Kaltenbach",
      "Phaedon-Stelios Koutsourelakis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.10329"
  },
  {
    "id": "arXiv:1706.09387",
    "title": "Asynchronous Massive Access and Neighbor Discovery Using OFDMA",
    "abstract": "Asynchronous Massive Access and Neighbor Discovery Using OFDMA",
    "descriptor": "",
    "authors": [
      "Xu Chen",
      "Lina Liu",
      "Dongning Guo",
      "Gregory W. Wornell"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1706.09387"
  },
  {
    "id": "arXiv:1805.08969",
    "title": "Semantic Network Interpretation",
    "abstract": "Semantic Network Interpretation",
    "descriptor": "",
    "authors": [
      "Pei Guo",
      "Ryan Farrell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1805.08969"
  },
  {
    "id": "arXiv:1806.07740",
    "title": "Effective Divergence Analysis for Linear Recurrence Sequences",
    "abstract": "Comments: Published in CONCUR 2018",
    "descriptor": "\nComments: Published in CONCUR 2018\n",
    "authors": [
      "Shaull Almagor",
      "Brynmor Chapman",
      "Mehran Hosseini",
      "Jo\u00ebl Ouaknine",
      "James Worrell"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1806.07740"
  },
  {
    "id": "arXiv:1909.00204",
    "title": "NEZHA: Neural Contextualized Representation for Chinese Language  Understanding",
    "abstract": "NEZHA: Neural Contextualized Representation for Chinese Language  Understanding",
    "descriptor": "",
    "authors": [
      "Junqiu Wei",
      "Xiaozhe Ren",
      "Xiaoguang Li",
      "Wenyong Huang",
      "Yi Liao",
      "Yasheng Wang",
      "Jiashu Lin",
      "Xin Jiang",
      "Xiao Chen",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1909.00204"
  },
  {
    "id": "arXiv:1910.05862",
    "title": "Constrained Non-Affine Alignment of Embeddings",
    "abstract": "Constrained Non-Affine Alignment of Embeddings",
    "descriptor": "",
    "authors": [
      "Yuwei Wang",
      "Yan Zheng",
      "Yanqing Peng",
      "Chin-Chia Michael Yeh",
      "Zhongfang Zhuang",
      "Das Mahashweta",
      "Bendre Mangesh",
      "Feifei Li",
      "Wei Zhang",
      "Jeff M. Phillips"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.05862"
  },
  {
    "id": "arXiv:1910.07567",
    "title": "Active Learning for Graph Neural Networks via Node Feature Propagation",
    "abstract": "Comments: 15 pages, 5 figures",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Yuexin Wu",
      "Yichong Xu",
      "Aarti Singh",
      "Yiming Yang",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.07567"
  },
  {
    "id": "arXiv:1911.03387",
    "title": "Combining subspace codes",
    "abstract": "Comments: 17 pages; construction for A_(10,4;5) was flawed",
    "descriptor": "\nComments: 17 pages; construction for A_(10,4;5) was flawed\n",
    "authors": [
      "Antonio Cossidente",
      "Sascha Kurz",
      "Giuseppe Marino",
      "Francesco Pavese"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1911.03387"
  },
  {
    "id": "arXiv:1912.09323",
    "title": "NFAD: Fixing anomaly detection using normalizing flows",
    "abstract": "NFAD: Fixing anomaly detection using normalizing flows",
    "descriptor": "",
    "authors": [
      "Artem Ryzhikov",
      "Maxim Borisyak",
      "Andrey Ustyuzhanin",
      "Denis Derkach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.09323"
  },
  {
    "id": "arXiv:2001.04194",
    "title": "Cascaded Coded Distributed Computing Schemes Based on Placement Delivery  Arrays",
    "abstract": "Cascaded Coded Distributed Computing Schemes Based on Placement Delivery  Arrays",
    "descriptor": "",
    "authors": [
      "Jing Jiang",
      "Lingxiao Qu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2001.04194"
  },
  {
    "id": "arXiv:2003.03229",
    "title": "Non-linear Neurons with Human-like Apical Dendrite Activations",
    "abstract": "Comments: Submitted for review",
    "descriptor": "\nComments: Submitted for review\n",
    "authors": [
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu",
      "Nicolae-Catalin Ristea",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.03229"
  },
  {
    "id": "arXiv:2003.05425",
    "title": "Gauge Equivariant Mesh CNNs: Anisotropic convolutions on geometric  graphs",
    "abstract": "Comments: Published at ICLR 2021",
    "descriptor": "\nComments: Published at ICLR 2021\n",
    "authors": [
      "Pim de Haan",
      "Maurice Weiler",
      "Taco Cohen",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.05425"
  },
  {
    "id": "arXiv:2003.07407",
    "title": "Nonlinear Stochastic Estimators on the Special Euclidean Group SE(3)  using Uncertain IMU and Vision Measurements",
    "abstract": "Nonlinear Stochastic Estimators on the Special Euclidean Group SE(3)  using Uncertain IMU and Vision Measurements",
    "descriptor": "",
    "authors": [
      "Hashim A Hashim",
      "Frank L Lewis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2003.07407"
  },
  {
    "id": "arXiv:2004.01625",
    "title": "Forward-looking persistent excitation in model predictive control",
    "abstract": "Comments: 11 pages plus references. Extension of IFAC World Congress conference paper through replacement of limiting assumptions and new simulation example",
    "descriptor": "\nComments: 11 pages plus references. Extension of IFAC World Congress conference paper through replacement of limiting assumptions and new simulation example\n",
    "authors": [
      "Sven Br\u00fcggemann",
      "Robert R. Bitmead"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2004.01625"
  },
  {
    "id": "arXiv:2004.12859",
    "title": "Static Race Detection and Mutex Safety and Liveness for Go Programs  (extended version)",
    "abstract": "Comments: Short version of this paper published in: ECOOP 2020; 26 pages + references and appendix; Main body: 17 figures + 1 table; Appendix: 1 figure",
    "descriptor": "\nComments: Short version of this paper published in: ECOOP 2020; 26 pages + references and appendix; Main body: 17 figures + 1 table; Appendix: 1 figure\n",
    "authors": [
      "Julia Gabet",
      "Nobuko Yoshida"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2004.12859"
  },
  {
    "id": "arXiv:2005.01097",
    "title": "Adaptive Learning of the Optimal Batch Size of SGD",
    "abstract": "Comments: Accepted to the 12th Annual Workshop on Optimization for Machine Learning (OPT2020)",
    "descriptor": "\nComments: Accepted to the 12th Annual Workshop on Optimization for Machine Learning (OPT2020)\n",
    "authors": [
      "Motasem Alfarra",
      "Slavomir Hanzely",
      "Alyazeed Albasyoni",
      "Bernard Ghanem",
      "Peter Richtarik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.01097"
  },
  {
    "id": "arXiv:2005.10058",
    "title": "On embedding Lambek calculus into commutative categorial grammars",
    "abstract": "Comments: Some computational errors corrected. The final version of this draft was published in Jpurnal of Logic and Computation, Oxford University press",
    "descriptor": "\nComments: Some computational errors corrected. The final version of this draft was published in Jpurnal of Logic and Computation, Oxford University press\n",
    "authors": [
      "Sergey Slavnov"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2005.10058"
  },
  {
    "id": "arXiv:2006.07682",
    "title": "Rethinking Clustering for Robustness",
    "abstract": "Comments: Accepted to the 32nd British Machine Vision Conference (BMVC'21)",
    "descriptor": "\nComments: Accepted to the 32nd British Machine Vision Conference (BMVC'21)\n",
    "authors": [
      "Motasem Alfarra",
      "Juan C. P\u00e9rez",
      "Adel Bibi",
      "Ali Thabet",
      "Pablo Arbel\u00e1ez",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07682"
  },
  {
    "id": "arXiv:2007.00714",
    "title": "Quantifying intrinsic causal contributions via structure preserving  interventions",
    "abstract": "Quantifying intrinsic causal contributions via structure preserving  interventions",
    "descriptor": "",
    "authors": [
      "Dominik Janzing",
      "Patrick Bl\u00f6baum",
      "Lenon Minorics",
      "Philipp Faller",
      "Atalanti Mastakouri"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.00714"
  },
  {
    "id": "arXiv:2008.10797",
    "title": "The Fairness-Accuracy Pareto Front",
    "abstract": "Comments: added toy figs to illustrate pareto optimality, some re-organization for clarity following reviewer comments",
    "descriptor": "\nComments: added toy figs to illustrate pareto optimality, some re-organization for clarity following reviewer comments\n",
    "authors": [
      "Susan Wei",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.10797"
  },
  {
    "id": "arXiv:2009.03979",
    "title": "A Distance-preserving Matrix Sketch",
    "abstract": "Comments: 38 pages, 13 figures",
    "descriptor": "\nComments: 38 pages, 13 figures\n",
    "authors": [
      "Leland Wilkinson",
      "Hengrui Luo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.03979"
  },
  {
    "id": "arXiv:2009.10317",
    "title": "iWash: A Smartwatch Handwashing Quality Assessment and Reminder System  with Real-time Feedback in the Context of Infectious Disease",
    "abstract": "Comments: Published in Elsevier Smart Health Journal, 2021",
    "descriptor": "\nComments: Published in Elsevier Smart Health Journal, 2021\n",
    "authors": [
      "Sirat Samyoun",
      "Sudipta Saha Shubha",
      "Md Abu Sayeed Mondol",
      "John A. Stankovic"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2009.10317"
  },
  {
    "id": "arXiv:2010.03001",
    "title": "A Review on Fact Extraction and Verification",
    "abstract": "Comments: Preprint - Accepted for publication in ACM Computing Surveys",
    "descriptor": "\nComments: Preprint - Accepted for publication in ACM Computing Surveys\n",
    "authors": [
      "Giannis Bekoulis",
      "Christina Papagiannopoulou",
      "Nikos Deligiannis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.03001"
  },
  {
    "id": "arXiv:2010.03324",
    "title": "Automated Human Activity Recognition by Colliding Bodies  Optimization-based Optimal Feature Selection with Recurrent Neural Network",
    "abstract": "Automated Human Activity Recognition by Colliding Bodies  Optimization-based Optimal Feature Selection with Recurrent Neural Network",
    "descriptor": "",
    "authors": [
      "Pankaj Khatiwada",
      "Ayan Chatterjee",
      "Matrika Subedi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2010.03324"
  },
  {
    "id": "arXiv:2010.16344",
    "title": "Marginalised Gaussian Processes with Nested Sampling",
    "abstract": "Comments: To appear in Neural Information Processing Systems (NeurIPS) 2021",
    "descriptor": "\nComments: To appear in Neural Information Processing Systems (NeurIPS) 2021\n",
    "authors": [
      "Fergus Simpson",
      "Vidhi Lalchand",
      "Carl Edward Rasmussen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.16344"
  },
  {
    "id": "arXiv:2011.06089",
    "title": "Continuous Perception for Classifying Shapes and Weights of Garmentsfor  Robotic Vision Applications",
    "abstract": "Comments: Accepted by the 17th International Conference on Computer Vision Theory and Applications",
    "descriptor": "\nComments: Accepted by the 17th International Conference on Computer Vision Theory and Applications\n",
    "authors": [
      "Li Duan",
      "Gerardo Aragon-Camarasa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.06089"
  },
  {
    "id": "arXiv:2011.06795",
    "title": "Similarity network fusion for scholarly journals",
    "abstract": "Comments: 21 pages, 4 figures",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Federica Baccini",
      "Lucio Barabesi",
      "Alberto Baccini",
      "Mahdi Khelfaoui",
      "Yves Gingras"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2011.06795"
  },
  {
    "id": "arXiv:2011.07126",
    "title": "Zero-shot Relation Classification from Side Information",
    "abstract": "Comments: 10 pages, 8 figures, published in CIKM 2021",
    "descriptor": "\nComments: 10 pages, 8 figures, published in CIKM 2021\n",
    "authors": [
      "Jiaying Gong",
      "Hoda Eldardiry"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.07126"
  },
  {
    "id": "arXiv:2011.10231",
    "title": "Efficient Conditional Pre-training for Transfer Learning",
    "abstract": "Efficient Conditional Pre-training for Transfer Learning",
    "descriptor": "",
    "authors": [
      "Shuvam Chakraborty",
      "Burak Uzkent",
      "Kumar Ayush",
      "Kumar Tanmay",
      "Evan Sheehan",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.10231"
  },
  {
    "id": "arXiv:2011.12454",
    "title": "Supercharging Imbalanced Data Learning With Energy-based Contrastive  Representation Transfer",
    "abstract": "Supercharging Imbalanced Data Learning With Energy-based Contrastive  Representation Transfer",
    "descriptor": "",
    "authors": [
      "Zidi Xiu",
      "Junya Chen",
      "Ricardo Henao",
      "Benjamin Goldstein",
      "Lawrence Carin",
      "Chenyang Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.12454"
  },
  {
    "id": "arXiv:2011.14165",
    "title": "Verifying liquidity of recursive Bitcoin contracts",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2003.00296",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2003.00296\n",
    "authors": [
      "Massimo Bartoletti",
      "Stefano Lande",
      "Maurizio Murgia",
      "Roberto Zunino"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.14165"
  },
  {
    "id": "arXiv:2012.03596",
    "title": "The hardest language for grammars with context operators",
    "abstract": "The hardest language for grammars with context operators",
    "descriptor": "",
    "authors": [
      "Mikhail Mrykhin",
      "Alexander Okhotin"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2012.03596"
  },
  {
    "id": "arXiv:2012.04207",
    "title": "Efficient Estimation of Influence of a Training Instance",
    "abstract": "Comments: This is an extended version of the paper presented at SustaiNLP 2020",
    "descriptor": "\nComments: This is an extended version of the paper presented at SustaiNLP 2020\n",
    "authors": [
      "Sosuke Kobayashi",
      "Sho Yokoi",
      "Jun Suzuki",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04207"
  },
  {
    "id": "arXiv:2012.06047",
    "title": "KNN Classification with One-step Computation",
    "abstract": "Comments: 13 pages. in IEEE Transactions on Knowledge and Data Engineering",
    "descriptor": "\nComments: 13 pages. in IEEE Transactions on Knowledge and Data Engineering\n",
    "authors": [
      "Shichao Zhang",
      "Jiaye Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.06047"
  },
  {
    "id": "arXiv:2012.12130",
    "title": "A Computational Framework for Solving Nonlinear Binary  OptimizationProblems in Robust Causal Inference",
    "abstract": "A Computational Framework for Solving Nonlinear Binary  OptimizationProblems in Robust Causal Inference",
    "descriptor": "",
    "authors": [
      "Md Saiful Islam",
      "Md Sarowar Morshed",
      "Md. Noor-E-Alam"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2012.12130"
  },
  {
    "id": "arXiv:2101.07217",
    "title": "Is it a great Autonomous FX Trading Strategy or you are just fooling  yourself",
    "abstract": "Comments: An Implementation of the proposed method: STSE is available at github. The paper includes the link in the reference section",
    "descriptor": "\nComments: An Implementation of the proposed method: STSE is available at github. The paper includes the link in the reference section\n",
    "authors": [
      "Murilo Sibrao Bernardini",
      "Paulo Andre Lima de Castro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2101.07217"
  },
  {
    "id": "arXiv:2101.08208",
    "title": "Solving SDP Faster: A Robust IPM Framework and Efficient Implementation",
    "abstract": "Solving SDP Faster: A Robust IPM Framework and Efficient Implementation",
    "descriptor": "",
    "authors": [
      "Baihe Huang",
      "Shunhua Jiang",
      "Zhao Song",
      "Runzhou Tao",
      "Ruizhe Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2101.08208"
  },
  {
    "id": "arXiv:2102.00968",
    "title": "CRPS Learning",
    "abstract": "Comments: Accepted for publication in Journal of Econometrics",
    "descriptor": "\nComments: Accepted for publication in Journal of Econometrics\n",
    "authors": [
      "Jonathan Berrisch",
      "Florian Ziel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2102.00968"
  },
  {
    "id": "arXiv:2102.09798",
    "title": "Training Neural Networks is $\\exists\\mathbb R$-complete",
    "abstract": "Comments: 12 pages, 4 figures, accepted at NeurIPS 2021",
    "descriptor": "\nComments: 12 pages, 4 figures, accepted at NeurIPS 2021\n",
    "authors": [
      "Mikkel Abrahamsen",
      "Linda Kleist",
      "Tillmann Miltzow"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2102.09798"
  },
  {
    "id": "arXiv:2102.10773",
    "title": "Slowly Varying Regression under Sparsity",
    "abstract": "Comments: Submitted to Operations Research. First submission: 02/2021",
    "descriptor": "\nComments: Submitted to Operations Research. First submission: 02/2021\n",
    "authors": [
      "Dimitris Bertsimas",
      "Vassilis Digalakis Jr",
      "Michael Linghzi Li",
      "Omar Skali Lami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.10773"
  },
  {
    "id": "arXiv:2102.11273",
    "title": "On Interaction Between Augmentations and Corruptions in Natural  Corruption Robustness",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Eric Mintun",
      "Alexander Kirillov",
      "Saining Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.11273"
  },
  {
    "id": "arXiv:2102.12722",
    "title": "Combinatorial Bandits under Strategic Manipulations",
    "abstract": "Combinatorial Bandits under Strategic Manipulations",
    "descriptor": "",
    "authors": [
      "Jing Dong",
      "Ke Li",
      "Shuai Li",
      "Baoxiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.12722"
  },
  {
    "id": "arXiv:2102.12827",
    "title": "Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints",
    "abstract": "Comments: Accepted at NeurIPS'21",
    "descriptor": "\nComments: Accepted at NeurIPS'21\n",
    "authors": [
      "Maura Pintor",
      "Fabio Roli",
      "Wieland Brendel",
      "Battista Biggio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.12827"
  },
  {
    "id": "arXiv:2102.13343",
    "title": "Are Gross Substitutes a Substitute for Submodular Valuations?",
    "abstract": "Are Gross Substitutes a Substitute for Submodular Valuations?",
    "descriptor": "",
    "authors": [
      "Shahar Dozinski",
      "Uriel Feige",
      "Michal Feldman",
      "Renato Paes Leme"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2102.13343"
  },
  {
    "id": "arXiv:2103.01434",
    "title": "Learning Robotic Manipulation Tasks via Task Progress based Gaussian  Reward and Loss Adjusted Exploration",
    "abstract": "Comments: Accepted for publication in IEEE Robotics and Automation Letters (RA-L)",
    "descriptor": "\nComments: Accepted for publication in IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Sulabh Kumra",
      "Shirin Josh",
      "Ferat Sahin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.01434"
  },
  {
    "id": "arXiv:2103.02700",
    "title": "Decoding supercodes of Gabidulin codes and applications to cryptanalysis",
    "abstract": "Comments: PQCrypto 2021. The Sage code is available on Github: this https URL",
    "descriptor": "\nComments: PQCrypto 2021. The Sage code is available on Github: this https URL\n",
    "authors": [
      "Maxime Bombar",
      "Alain Couvreur"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.02700"
  },
  {
    "id": "arXiv:2103.03136",
    "title": "Optimization-based parametric model order reduction via  $\\mathcal{H}_2\\otimes\\mathcal{L}_2$ first-order necessary conditions",
    "abstract": "Comments: 24 pages, 6 figures",
    "descriptor": "\nComments: 24 pages, 6 figures\n",
    "authors": [
      "Manuela Hund",
      "Tim Mitchell",
      "Petar Mlinari\u0107",
      "Jens Saak"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.03136"
  },
  {
    "id": "arXiv:2103.05222",
    "title": "Data augmentation by morphological mixup for solving Raven's Progressive  Matrices",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Wentao He",
      "Jianfeng Ren",
      "Ruibin Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.05222"
  },
  {
    "id": "arXiv:2103.06248",
    "title": "Bounded Invariant Checking for Stateflow Programs",
    "abstract": "Comments: 35 pages, 2 figures, 1 table",
    "descriptor": "\nComments: 35 pages, 2 figures, 1 table\n",
    "authors": [
      "Predrag Filipovikj",
      "Dilian Gurov",
      "Mattias Nyberg"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2103.06248"
  },
  {
    "id": "arXiv:2103.06854",
    "title": "A conditional, a fuzzy and a probabilistic interpretation of  self-organising maps",
    "abstract": "Comments: 31 pages, 1 figure. arXiv admin note: text overlap with arXiv:2008.13278",
    "descriptor": "\nComments: 31 pages, 1 figure. arXiv admin note: text overlap with arXiv:2008.13278\n",
    "authors": [
      "Laura Giordano",
      "Valentina Gliozzi",
      "Daniele Theseider Dupr\u00e9"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.06854"
  },
  {
    "id": "arXiv:2103.10334",
    "title": "Structure Inducing Pre-Training",
    "abstract": "Structure Inducing Pre-Training",
    "descriptor": "",
    "authors": [
      "Matthew B. A. McDermott",
      "Brendan Yap",
      "Peter Szolovits",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10334"
  },
  {
    "id": "arXiv:2103.11568",
    "title": "Cluster Contrast for Unsupervised Person Re-Identification",
    "abstract": "Cluster Contrast for Unsupervised Person Re-Identification",
    "descriptor": "",
    "authors": [
      "Zuozhuo Dai",
      "Guangyuan Wang",
      "Weihao Yuan",
      "Xiaoli Liu",
      "Siyu Zhu",
      "Ping Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11568"
  },
  {
    "id": "arXiv:2103.13278",
    "title": "Safe Linear-Quadratic Dual Control with Almost Sure Performance  Guarantee",
    "abstract": "Safe Linear-Quadratic Dual Control with Almost Sure Performance  Guarantee",
    "descriptor": "",
    "authors": [
      "Yiwen Lu",
      "Yilin Mo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.13278"
  },
  {
    "id": "arXiv:2103.14675",
    "title": "Synthesis of Compositional Animations from Textual Descriptions",
    "abstract": "Comments: 13 pages, 6 figures, 3 tables. Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021, pp. 1396-1406",
    "descriptor": "\nComments: 13 pages, 6 figures, 3 tables. Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021, pp. 1396-1406\n",
    "authors": [
      "Anindita Ghosh",
      "Noshaba Cheema",
      "Cennet Oguz",
      "Christian Theobalt",
      "Philipp Slusallek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.14675"
  },
  {
    "id": "arXiv:2103.14886",
    "title": "Generalization over different cellular automata rules learned by a deep  feed-forward neural network",
    "abstract": "Comments: Accepted at 23rd International Conference on Artificial Intelligence (July 2021, Las Vegas, USA) To appear in: Springer Transactions on Computational Science & Computational Intelligence",
    "descriptor": "\nComments: Accepted at 23rd International Conference on Artificial Intelligence (July 2021, Las Vegas, USA) To appear in: Springer Transactions on Computational Science & Computational Intelligence\n",
    "authors": [
      "Marcel Aach",
      "Jens Henrik Goebbert",
      "Jenia Jitsev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2103.14886"
  },
  {
    "id": "arXiv:2104.01263",
    "title": "A Semantic Segmentation Network for Urban-Scale Building Footprint  Extraction Using RGB Satellite Imagery",
    "abstract": "Comments: 11 pages, 5 figures. Code available at this https URL",
    "descriptor": "\nComments: 11 pages, 5 figures. Code available at this https URL\n",
    "authors": [
      "Aatif Jiwani",
      "Shubhrakanti Ganguly",
      "Chao Ding",
      "Nan Zhou",
      "David M. Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.01263"
  },
  {
    "id": "arXiv:2104.05596",
    "title": "Samanantar: The Largest Publicly Available Parallel Corpora Collection  for 11 Indic Languages",
    "abstract": "Comments: Accepted to the Transactions of the Association for Computational Linguistics (TACL)",
    "descriptor": "\nComments: Accepted to the Transactions of the Association for Computational Linguistics (TACL)\n",
    "authors": [
      "Gowtham Ramesh",
      "Sumanth Doddapaneni",
      "Aravinth Bheemaraj",
      "Mayank Jobanputra",
      "Raghavan AK",
      "Ajitesh Sharma",
      "Sujit Sahoo",
      "Harshita Diddee",
      "Mahalakshmi J",
      "Divyanshu Kakwani",
      "Navneet Kumar",
      "Aswin Pradeep",
      "Srihari Nagaraj",
      "Kumar Deepak",
      "Vivek Raghavan",
      "Anoop Kunchukuttan",
      "Pratyush Kumar",
      "Mitesh Shantadevi Khapra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.05596"
  },
  {
    "id": "arXiv:2104.09002",
    "title": "On the Complexity of Inverse Mixed Integer Linear Optimization",
    "abstract": "On the Complexity of Inverse Mixed Integer Linear Optimization",
    "descriptor": "",
    "authors": [
      "Aykut Bulut",
      "Ted K. Ralphs"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.09002"
  },
  {
    "id": "arXiv:2104.09392",
    "title": "Coresets for $(k, \\ell)$-Median Clustering under the Fr\u00e9chet Distance",
    "abstract": "Coresets for $(k, \\ell)$-Median Clustering under the Fr\u00e9chet Distance",
    "descriptor": "",
    "authors": [
      "Maike Buchin",
      "Dennis Rohde"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2104.09392"
  },
  {
    "id": "arXiv:2104.09994",
    "title": "Federated Learning for Malware Detection in IoT Devices",
    "abstract": "Federated Learning for Malware Detection in IoT Devices",
    "descriptor": "",
    "authors": [
      "Valerian Rey",
      "Pedro Miguel S\u00e1nchez S\u00e1nchez",
      "Alberto Huertas Celdr\u00e1n",
      "G\u00e9r\u00f4me Bovet",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09994"
  },
  {
    "id": "arXiv:2105.07782",
    "title": "A fast vectorized sorting implementation based on the ARM scalable  vector extension (SVE)",
    "abstract": "Comments: this https URL this https URL",
    "descriptor": "\nComments: this https URL this https URL\n",
    "authors": [
      "B\u00e9renger Bramas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.07782"
  },
  {
    "id": "arXiv:2105.11748",
    "title": "Dense Regression Activation Maps For Lesion Segmentation in CT scans of  COVID-19 patients",
    "abstract": "Dense Regression Activation Maps For Lesion Segmentation in CT scans of  COVID-19 patients",
    "descriptor": "",
    "authors": [
      "Weiyi Xie",
      "Colin Jacobs",
      "Jean-Paul Charbonnier",
      "Bram van Ginneken"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11748"
  },
  {
    "id": "arXiv:2105.14183",
    "title": "Verified Quadratic Virtual Substitution for Real Arithmetic",
    "abstract": "Comments: FM 2021",
    "descriptor": "\nComments: FM 2021\n",
    "authors": [
      "Matias Scharager",
      "Katherine Cordwell",
      "Stefan Mitsch",
      "Andr\u00e9 Platzer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14183"
  },
  {
    "id": "arXiv:2105.15005",
    "title": "Rapid mixing of Glauber dynamics via spectral independence for all  degrees",
    "abstract": "Comments: Resolve formatting issues in v2",
    "descriptor": "\nComments: Resolve formatting issues in v2\n",
    "authors": [
      "Xiaoyu Chen",
      "Weiming Feng",
      "Yitong Yin",
      "Xinyuan Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.15005"
  },
  {
    "id": "arXiv:2106.00591",
    "title": "Comparing Multi-Index Stochastic Collocation and Multi-Fidelity  Stochastic Radial Basis Functions for Forward Uncertainty Quantification of  Ship Resistance",
    "abstract": "Comments: This article supersedes arXiv:2005.07405",
    "descriptor": "\nComments: This article supersedes arXiv:2005.07405\n",
    "authors": [
      "Chiara Piazzola",
      "Lorenzo Tamellini",
      "Riccardo Pellegrini",
      "Riccardo Broglia",
      "Andrea Serani",
      "Matteo Diez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00591"
  },
  {
    "id": "arXiv:2106.04399",
    "title": "Flow Network based Generative Models for Non-Iterative Diverse Candidate  Generation",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Emmanuel Bengio",
      "Moksh Jain",
      "Maksym Korablyov",
      "Doina Precup",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04399"
  },
  {
    "id": "arXiv:2106.05407",
    "title": "OVRseen: Auditing Network Traffic and Privacy Policies in Oculus VR",
    "abstract": "Comments: This is the extended version of the paper with the same title published at USENIX Security Symposium 2022",
    "descriptor": "\nComments: This is the extended version of the paper with the same title published at USENIX Security Symposium 2022\n",
    "authors": [
      "Rahmadi Trimananda",
      "Hieu Le",
      "Hao Cui",
      "Janice Tran Ho",
      "Anastasia Shuba",
      "Athina Markopoulou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.05407"
  },
  {
    "id": "arXiv:2106.08185",
    "title": "Kernel Identification Through Transformers",
    "abstract": "Comments: To appear in Neural Information Processing Systems (NeurIPS) 2021",
    "descriptor": "\nComments: To appear in Neural Information Processing Systems (NeurIPS) 2021\n",
    "authors": [
      "Fergus Simpson",
      "Ian Davies",
      "Vidhi Lalchand",
      "Alessandro Vullo",
      "Nicolas Durrande",
      "Carl Rasmussen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08185"
  },
  {
    "id": "arXiv:2106.10891",
    "title": "Open-set Label Noise Can Improve Robustness Against Inherent Label Noise",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Hongxin Wei",
      "Lue Tao",
      "Renchunzi Xie",
      "Bo An"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10891"
  },
  {
    "id": "arXiv:2106.12718",
    "title": "Sparse Flows: Pruning Continuous-depth Models",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Lucas Liebenwein",
      "Ramin Hasani",
      "Alexander Amini",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.12718"
  },
  {
    "id": "arXiv:2106.13239",
    "title": "Federated Noisy Client Learning",
    "abstract": "Federated Noisy Client Learning",
    "descriptor": "",
    "authors": [
      "Li Li",
      "Liang Gao",
      "Huazhu Fu",
      "Bo Han",
      "Cheng-Zhong Xu",
      "Ling Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.13239"
  },
  {
    "id": "arXiv:2106.14233",
    "title": "KGRefiner: Knowledge Graph Refinement for Improving Accuracy of  Translational Link Prediction Methods",
    "abstract": "Comments: 8 pages, 1 figure",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Mohammad Javad Saeedizade",
      "Najmeh Torabian",
      "Behrouz Minaei-Bidgoli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.14233"
  },
  {
    "id": "arXiv:2106.14827",
    "title": "Analysis and Control of Autonomous Mobility-on-Demand Systems",
    "abstract": "Comments: To appear in Annual Review of Control, Robotics, and Autonomous Systems",
    "descriptor": "\nComments: To appear in Annual Review of Control, Robotics, and Autonomous Systems\n",
    "authors": [
      "Gioele Zardini",
      "Nicolas Lanzetti",
      "Marco Pavone",
      "Emilio Frazzoli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.14827"
  },
  {
    "id": "arXiv:2107.00156",
    "title": "A Study of the Quality of Wikidata",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Kartik Shenoy",
      "Filip Ilievski",
      "Daniel Garijo",
      "Daniel Schwabe",
      "Pedro Szekely"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00156"
  },
  {
    "id": "arXiv:2107.00328",
    "title": "End-to-end Compression Towards Machine Vision: Network Architecture  Design and Optimization",
    "abstract": "End-to-end Compression Towards Machine Vision: Network Architecture  Design and Optimization",
    "descriptor": "",
    "authors": [
      "Shurun Wang",
      "Zhao Wang",
      "Shiqi Wang",
      "Yan Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.00328"
  },
  {
    "id": "arXiv:2107.00719",
    "title": "Toward Drug-Target Interaction Prediction via Ensemble Modeling and  Transfer Learning",
    "abstract": "Comments: 8 pages, 1 figure, 10 tables",
    "descriptor": "\nComments: 8 pages, 1 figure, 10 tables\n",
    "authors": [
      "Po-Yu Kao",
      "Shu-Min Kao",
      "Nan-Lan Huang",
      "Yen-Chu Lin"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2107.00719"
  },
  {
    "id": "arXiv:2107.02446",
    "title": "Two new classes of projective two-weight linear codes",
    "abstract": "Two new classes of projective two-weight linear codes",
    "descriptor": "",
    "authors": [
      "Canze Zhu",
      "Qunying Liao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.02446"
  },
  {
    "id": "arXiv:2107.03251",
    "title": "IRS-Aided WPCNs: A New Optimization Framework for Dynamic IRS  Beamforming",
    "abstract": "Comments: Submitted to IEEE TWC",
    "descriptor": "\nComments: Submitted to IEEE TWC\n",
    "authors": [
      "Qingqing Wu",
      "Xiaobo Zhou",
      "Wen Chen",
      "Jun Li",
      "Xiuyin Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.03251"
  },
  {
    "id": "arXiv:2107.05577",
    "title": "On Divergence- and Gradient-Preserving Coarse-Graining for Finite Volume  Primitive Equation Ocean Models",
    "abstract": "Comments: 34 pages, 14 figures",
    "descriptor": "\nComments: 34 pages, 14 figures\n",
    "authors": [
      "Stuart Patching"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2107.05577"
  },
  {
    "id": "arXiv:2107.06721",
    "title": "Resonant tunnelling diode nano-optoelectronic spiking nodes for  neuromorphic information processing",
    "abstract": "Comments: Updated with feedback from first round of reviews. Updated figure with 3D model",
    "descriptor": "\nComments: Updated with feedback from first round of reviews. Updated figure with 3D model\n",
    "authors": [
      "Mat\u011bj Hejda",
      "Juan Arturo Alanis",
      "Ignacio Ortega-Piwonka",
      "Jo\u00e3o Louren\u00e7o",
      "Jos\u00e9 Figueiredo",
      "Julien Javaloyes",
      "Bruno Romeira",
      "Antonio Hurtado"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2107.06721"
  },
  {
    "id": "arXiv:2107.07233",
    "title": "Genetic CFL: Optimization of Hyper-Parameters in Clustered Federated  Learning",
    "abstract": "Comments: 7 pages, 4 figures, 4 tables",
    "descriptor": "\nComments: 7 pages, 4 figures, 4 tables\n",
    "authors": [
      "Shaashwat Agrawal",
      "Sagnik Sarkar",
      "Mamoun Alazab",
      "Praveen Kumar Reddy Maddikunta",
      "Thippa Reddy Gadekallu",
      "Quoc-Viet Pham"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07233"
  },
  {
    "id": "arXiv:2107.11442",
    "title": "Compressing Neural Networks: Towards Determining the Optimal Layer-wise  Decomposition",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Lucas Liebenwein",
      "Alaa Maalouf",
      "Oren Gal",
      "Dan Feldman",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.11442"
  },
  {
    "id": "arXiv:2107.11637",
    "title": "Group-based Motion Prediction for Navigation in Crowded Environments",
    "abstract": "Group-based Motion Prediction for Navigation in Crowded Environments",
    "descriptor": "",
    "authors": [
      "Allan Wang",
      "Christoforos Mavrogiannis",
      "Aaron Steinfeld"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.11637"
  },
  {
    "id": "arXiv:2107.12518",
    "title": "Segmentation in Style: Unsupervised Semantic Image Segmentation with  Stylegan and CLIP",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Daniil Pakhomov",
      "Sanchit Hira",
      "Narayani Wagle",
      "Kemar E. Green",
      "Nassir Navab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.12518"
  },
  {
    "id": "arXiv:2108.01595",
    "title": "Extending a Physics-Based Constitutive Model using Genetic Programming",
    "abstract": "Comments: Preprint submitted to Applications in Engineering Sciences",
    "descriptor": "\nComments: Preprint submitted to Applications in Engineering Sciences\n",
    "authors": [
      "Gabriel Kronberger",
      "Evgeniya Kabliman",
      "Johannes Kronsteiner",
      "Michael Kommenda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2108.01595"
  },
  {
    "id": "arXiv:2108.07347",
    "title": "Issues with Positivity-Preserving Patankar-type Schemes",
    "abstract": "Issues with Positivity-Preserving Patankar-type Schemes",
    "descriptor": "",
    "authors": [
      "Davide Torlo",
      "Philipp \u00d6ffner",
      "Hendrik Ranocha"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.07347"
  },
  {
    "id": "arXiv:2108.08418",
    "title": "Optimised Multithreaded CV-QKD Reconciliation for Global Quantum  Networks",
    "abstract": "Comments: Updated References",
    "descriptor": "\nComments: Updated References\n",
    "authors": [
      "Xiaoyu Ai",
      "Robert Malaney"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.08418"
  },
  {
    "id": "arXiv:2108.10461",
    "title": "Deterministic Dynamic Matching In Worst-Case Update Time",
    "abstract": "Deterministic Dynamic Matching In Worst-Case Update Time",
    "descriptor": "",
    "authors": [
      "Peter Kiss"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.10461"
  },
  {
    "id": "arXiv:2108.13987",
    "title": "OARnet: Automated organs-at-risk delineation in Head and Neck CT images",
    "abstract": "Comments: need more work!",
    "descriptor": "\nComments: need more work!\n",
    "authors": [
      "Mumtaz Hussain Soomro",
      "Hamidreza Nourzadeh",
      "Victor Gabriel Leandro Alves",
      "Wookjin Choi",
      "Jeffrey V. Siebers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.13987"
  },
  {
    "id": "arXiv:2109.04822",
    "title": "1st-Order Dynamics on Nonlinear Agents for Resource Allocation over  Uniformly-Connected Networks",
    "abstract": "1st-Order Dynamics on Nonlinear Agents for Resource Allocation over  Uniformly-Connected Networks",
    "descriptor": "",
    "authors": [
      "Mohammadreza Doostmohammadian",
      "Alireza Aghasi",
      "Maria Vrakopoulou",
      "Themistoklis Charalambous"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.04822"
  },
  {
    "id": "arXiv:2109.05115",
    "title": "Partially-Supervised Novel Object Captioning Leveraging Context from  Paired Data",
    "abstract": "Partially-Supervised Novel Object Captioning Leveraging Context from  Paired Data",
    "descriptor": "",
    "authors": [
      "Shashank Bujimalla",
      "Mahesh Subedar",
      "Omesh Tickoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05115"
  },
  {
    "id": "arXiv:2109.08042",
    "title": "Vertex Fault-Tolerant Emulators",
    "abstract": "Comments: To appear in ITCS 2022",
    "descriptor": "\nComments: To appear in ITCS 2022\n",
    "authors": [
      "Greg Bodwin",
      "Michael Dinitz",
      "Yasamin Nazari"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.08042"
  },
  {
    "id": "arXiv:2109.08784",
    "title": "Unbiased Bregman-Risk Estimators: Application to Regularization  Parameter Selection in Tomographic Image Reconstruction",
    "abstract": "Unbiased Bregman-Risk Estimators: Application to Regularization  Parameter Selection in Tomographic Image Reconstruction",
    "descriptor": "",
    "authors": [
      "Elias S. Helou",
      "Sandra A. Santos",
      "Lucas E. A. Sim\u00f5es"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.08784"
  },
  {
    "id": "arXiv:2109.09092",
    "title": "Wellbeing supportive design -- Research-based guidelines for supporting  psychological wellbeing in user experience",
    "abstract": "Comments: ArXiv pre-print last updated 19 Nov 21",
    "descriptor": "\nComments: ArXiv pre-print last updated 19 Nov 21\n",
    "authors": [
      "Dorian Peters"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.09092"
  },
  {
    "id": "arXiv:2109.10498",
    "title": "Less is More: Learning from Synthetic Data with Fine-grained Attributes  for Person Re-Identification",
    "abstract": "Less is More: Learning from Synthetic Data with Fine-grained Attributes  for Person Re-Identification",
    "descriptor": "",
    "authors": [
      "Suncheng Xiang",
      "Guanjie You",
      "Mengyuan Guan",
      "Hao Chen",
      "Binjie Yan",
      "Ting Liu",
      "Yuzhuo Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.10498"
  },
  {
    "id": "arXiv:2109.11537",
    "title": "Faster $p$-Norm Regression Using Sparsity",
    "abstract": "Comments: Includes new results. The first input sparsity algorithm for p-norm via efficient row-sampling",
    "descriptor": "\nComments: Includes new results. The first input sparsity algorithm for p-norm via efficient row-sampling\n",
    "authors": [
      "Mehrdad Ghadiri",
      "Richard Peng",
      "Santosh S. Vempala"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.11537"
  },
  {
    "id": "arXiv:2109.12473",
    "title": "Statically Bounded-Memory Delayed Sampling for Probabilistic Streams",
    "abstract": "Statically Bounded-Memory Delayed Sampling for Probabilistic Streams",
    "descriptor": "",
    "authors": [
      "Eric Atkinson",
      "Guillaume Baudart",
      "Louis Mandel",
      "Charles Yuan",
      "Michael Carbin"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2109.12473"
  },
  {
    "id": "arXiv:2109.14478",
    "title": "Quadratic-Curve-Lifted Reed-Solomon Codes",
    "abstract": "Comments: 16 pager, 2 figures. A short version is submitted to WCC 2022 (12th International Workshop on Coding and Cryptography)",
    "descriptor": "\nComments: 16 pager, 2 figures. A short version is submitted to WCC 2022 (12th International Workshop on Coding and Cryptography)\n",
    "authors": [
      "Hedongliang Liu",
      "Lukas Holzbaur",
      "Nikita Polyanskii",
      "Sven Puchinger",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2109.14478"
  },
  {
    "id": "arXiv:2109.14851",
    "title": "The Deep Minimizing Movement Scheme",
    "abstract": "Comments: 27 pages, 12 figures",
    "descriptor": "\nComments: 27 pages, 12 figures\n",
    "authors": [
      "Hyung Ju Hwang",
      "Cheolhyeong Kim",
      "Min Sue Park",
      "Hwijae Son"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.14851"
  },
  {
    "id": "arXiv:2109.15035",
    "title": "Focus! Rating XAI Methods and Finding Biases with Mosaics",
    "abstract": "Focus! Rating XAI Methods and Finding Biases with Mosaics",
    "descriptor": "",
    "authors": [
      "Anna Arias-Duart",
      "Ferran Par\u00e9s",
      "Dario Garcia-Gasulla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.15035"
  },
  {
    "id": "arXiv:2110.00061",
    "title": "PubTables-1M: Towards comprehensive table extraction from unstructured  documents",
    "abstract": "PubTables-1M: Towards comprehensive table extraction from unstructured  documents",
    "descriptor": "",
    "authors": [
      "Brandon Smock",
      "Rohith Pesala",
      "Robin Abraham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00061"
  },
  {
    "id": "arXiv:2110.01648",
    "title": "Robust Linear Classification from Limited Training Data",
    "abstract": "Comments: 31 pages, published in the Machine Learning Journal",
    "descriptor": "\nComments: 31 pages, published in the Machine Learning Journal\n",
    "authors": [
      "Deepayan Chakrabarti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01648"
  },
  {
    "id": "arXiv:2110.05313",
    "title": "Unsupervised Source Separation via Bayesian Inference in the Latent  Domain",
    "abstract": "Comments: 5 pages, 1 figure, submitted to ICASSP 2022",
    "descriptor": "\nComments: 5 pages, 1 figure, submitted to ICASSP 2022\n",
    "authors": [
      "Michele Mancusi",
      "Emilian Postolache",
      "Marco Fumero",
      "Andrea Santilli",
      "Luca Cosmo",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05313"
  },
  {
    "id": "arXiv:2110.05428",
    "title": "Learning Temporally Causal Latent Processes from General Temporal Data",
    "abstract": "Learning Temporally Causal Latent Processes from General Temporal Data",
    "descriptor": "",
    "authors": [
      "Weiran Yao",
      "Yuewen Sun",
      "Alex Ho",
      "Changyin Sun",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05428"
  },
  {
    "id": "arXiv:2110.06568",
    "title": "One to Multiple Mapping Dual Learning: Learning Multiple Sources from  One Mixed Signal",
    "abstract": "One to Multiple Mapping Dual Learning: Learning Multiple Sources from  One Mixed Signal",
    "descriptor": "",
    "authors": [
      "Ting Liu",
      "Wenwu Wang",
      "Xiaofei Zhang",
      "Zhenyin Gong",
      "Yina Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06568"
  },
  {
    "id": "arXiv:2110.09482",
    "title": "Self-Supervised Monocular Depth Estimation with Internal Feature Fusion",
    "abstract": "Comments: Accepted at BMVC2021",
    "descriptor": "\nComments: Accepted at BMVC2021\n",
    "authors": [
      "Hang Zhou",
      "David Greenwood",
      "Sarah Taylor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09482"
  },
  {
    "id": "arXiv:2110.10093",
    "title": "Stochastic Primal-Dual Deep Unrolling Networks for Imaging Inverse  Problems",
    "abstract": "Stochastic Primal-Dual Deep Unrolling Networks for Imaging Inverse  Problems",
    "descriptor": "",
    "authors": [
      "Junqi Tang",
      "Subhadip Mukherjee",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.10093"
  },
  {
    "id": "arXiv:2110.12612",
    "title": "DelightfulTTS: The Microsoft Speech Synthesis System for Blizzard  Challenge 2021",
    "abstract": "DelightfulTTS: The Microsoft Speech Synthesis System for Blizzard  Challenge 2021",
    "descriptor": "",
    "authors": [
      "Yanqing Liu",
      "Zhihang Xu",
      "Gang Wang",
      "Kuan Chen",
      "Bohan Li",
      "Xu Tan",
      "Jinzhu Li",
      "Lei He",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.12612"
  },
  {
    "id": "arXiv:2110.14199",
    "title": "Arbitrarily Fast Switched Distributed Stabilization of Partially Unknown  Interconnected Multiagent Systems: A Proactive Cyber Defense Perspective",
    "abstract": "Arbitrarily Fast Switched Distributed Stabilization of Partially Unknown  Interconnected Multiagent Systems: A Proactive Cyber Defense Perspective",
    "descriptor": "",
    "authors": [
      "Vahid Rezaei",
      "Jafar Haadi Jafarian",
      "Douglas C. Sicker"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.14199"
  },
  {
    "id": "arXiv:2110.15426",
    "title": "RadBERT-CL: Factually-Aware Contrastive Learning For Radiology Report  Classification",
    "abstract": "RadBERT-CL: Factually-Aware Contrastive Learning For Radiology Report  Classification",
    "descriptor": "",
    "authors": [
      "Ajay Jaiswal",
      "Liyan Tang",
      "Meheli Ghosh",
      "Justin Rousseau",
      "Yifan Peng",
      "Ying Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15426"
  },
  {
    "id": "arXiv:2111.00086",
    "title": "Measuring a Texts Fairness Dimensions Using Machine Learning Based on  Social Psychological Factors",
    "abstract": "Comments: 38 pages, 9 figures Change in Author details Added acknowledgment section on page 29",
    "descriptor": "\nComments: 38 pages, 9 figures Change in Author details Added acknowledgment section on page 29\n",
    "authors": [
      "A. Izzidien",
      "P. Romero",
      "S. Fitz",
      "D. Stillwell"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.00086"
  },
  {
    "id": "arXiv:2111.00107",
    "title": "The Golden Rule as a Heuristic to Measure the Fairness of Texts Using  Machine Learning",
    "abstract": "Comments: 32 pages, 4 figures Author details changed Added acknowledgments on page 18",
    "descriptor": "\nComments: 32 pages, 4 figures Author details changed Added acknowledgments on page 18\n",
    "authors": [
      "A. Izzidien",
      "P. Romero",
      "S. Fitz",
      "D. Stillwell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00107"
  },
  {
    "id": "arXiv:2111.00121",
    "title": "Longitudinal Analysis of Mask and No-Mask on Child Face Recognition",
    "abstract": "Comments: 6 Pages, 3 Figure, Paper is under consideration at Pattern Recognition Letters",
    "descriptor": "\nComments: 6 Pages, 3 Figure, Paper is under consideration at Pattern Recognition Letters\n",
    "authors": [
      "Praveen Kumar Chandaliya",
      "Zahid Akhtar",
      "Neeta Nain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00121"
  },
  {
    "id": "arXiv:2111.00526",
    "title": "FinEAS: Financial Embedding Analysis of Sentiment",
    "abstract": "FinEAS: Financial Embedding Analysis of Sentiment",
    "descriptor": "",
    "authors": [
      "Asier Guti\u00e9rrez-Fandi\u00f1o",
      "Miquel Noguer i Alonso",
      "Petter Kolm",
      "Jordi Armengol-Estap\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Finance (q-fin.CP)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2111.00526"
  },
  {
    "id": "arXiv:2111.00863",
    "title": "Finite and infinite closed-rich words",
    "abstract": "Finite and infinite closed-rich words",
    "descriptor": "",
    "authors": [
      "Olga Parshina",
      "Svetlana Puzynina"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.00863"
  },
  {
    "id": "arXiv:2111.01717",
    "title": "MixFace: Improving Face Verification Focusing on Fine-grained Conditions",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Junuk Jung",
      "Sungbin Son",
      "Joochan Park",
      "Yongjun Park",
      "Seonhoon Lee",
      "Heung-Seon Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01717"
  },
  {
    "id": "arXiv:2111.02061",
    "title": "Deep-Learning-Based Single-Image Height Reconstruction from  Very-High-Resolution SAR Intensity Data",
    "abstract": "Comments: 19 pages, 14 figures",
    "descriptor": "\nComments: 19 pages, 14 figures\n",
    "authors": [
      "Michael Recla",
      "Michael Schmitt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02061"
  },
  {
    "id": "arXiv:2111.02353",
    "title": "Associational Memory Networks",
    "abstract": "Comments: This study is part of a series and is a memory device in artificial association neural networks",
    "descriptor": "\nComments: This study is part of a series and is a memory device in artificial association neural networks\n",
    "authors": [
      "Seokjun Kim",
      "Jaeeun Jang",
      "Yeonju Jang",
      "Seongyune Choi",
      "Hyeoncheol Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02353"
  },
  {
    "id": "arXiv:2111.05842",
    "title": "Reply to Comment on \"TVOR: Finding Discrete Total Variation Outliers  among Histograms\"",
    "abstract": "Comments: 62 pages, 7 figures",
    "descriptor": "\nComments: 62 pages, 7 figures\n",
    "authors": [
      "Nikola Bani\u0107",
      "Neven Elezovi\u0107"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.05842"
  },
  {
    "id": "arXiv:2111.05959",
    "title": "Advancing Brain Metastases Detection in T1-Weighted Contrast-Enhanced 3D  MRI using Noisy Student-based Training",
    "abstract": "Advancing Brain Metastases Detection in T1-Weighted Contrast-Enhanced 3D  MRI using Noisy Student-based Training",
    "descriptor": "",
    "authors": [
      "Engin Dikici",
      "Xuan V. Nguyen",
      "Matthew Bigelow",
      "John. L. Ryu",
      "Luciano M. Prevedello"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.05959"
  },
  {
    "id": "arXiv:2111.06119",
    "title": "Fine-Grained Image Analysis with Deep Learning: A Survey",
    "abstract": "Comments: Accepted by IEEE TPAMI",
    "descriptor": "\nComments: Accepted by IEEE TPAMI\n",
    "authors": [
      "Xiu-Shen Wei",
      "Yi-Zhe Song",
      "Oisin Mac Aodha",
      "Jianxin Wu",
      "Yuxin Peng",
      "Jinhui Tang",
      "Jian Yang",
      "Serge Belongie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.06119"
  },
  {
    "id": "arXiv:2111.06733",
    "title": "A Constant-Factor Approximation for Generalized Malleable Scheduling  under $M^\\natural$-Concave Processing Speeds",
    "abstract": "A Constant-Factor Approximation for Generalized Malleable Scheduling  under $M^\\natural$-Concave Processing Speeds",
    "descriptor": "",
    "authors": [
      "Dimitris Fotakis",
      "Jannik Matuschke",
      "Orestis Papadigenopoulos"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.06733"
  },
  {
    "id": "arXiv:2111.07680",
    "title": "Quadratic speedup of global search using a biased crossover of two good  solutions",
    "abstract": "Comments: 52 pages, 4 figures, 1 table",
    "descriptor": "\nComments: 52 pages, 4 figures, 1 table\n",
    "authors": [
      "Takuya Isomura"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.07680"
  },
  {
    "id": "arXiv:2111.08793",
    "title": "The Stochastic Boolean Function Evaluation Problem for Symmetric Boolean  Functions",
    "abstract": "Comments: Preliminary versions of these results appeared on Arxiv in arXiv:1806.10660. That paper contains results for both arbitrary costs and unit costs. This paper considers only arbitrary costs",
    "descriptor": "\nComments: Preliminary versions of these results appeared on Arxiv in arXiv:1806.10660. That paper contains results for both arbitrary costs and unit costs. This paper considers only arbitrary costs\n",
    "authors": [
      "Dimitrios Gkenosis",
      "Nathaniel Grammel",
      "Lisa Hellerstein",
      "Devorah Kletenik"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.08793"
  },
  {
    "id": "arXiv:2111.08843",
    "title": "Error Coefficient-reduced Polar/PAC Codes",
    "abstract": "Comments: 19 pages, 10 figures, 4 tables, 2 listings",
    "descriptor": "\nComments: 19 pages, 10 figures, 4 tables, 2 listings\n",
    "authors": [
      "Mohammad Rowshan",
      "Son Hoang Dau",
      "Emanuele Viterbo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.08843"
  },
  {
    "id": "arXiv:2111.08867",
    "title": "TYolov5: A Temporal Yolov5 Detector Based on Quasi-Recurrent Neural  Networks for Real-Time Handgun Detection in Video",
    "abstract": "TYolov5: A Temporal Yolov5 Detector Based on Quasi-Recurrent Neural  Networks for Real-Time Handgun Detection in Video",
    "descriptor": "",
    "authors": [
      "Mario Alberto Duran-Vega",
      "Miguel Gonzalez-Mendoza",
      "Leonardo Chang",
      "Cuauhtemoc Daniel Suarez-Ramirez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08867"
  },
  {
    "id": "arXiv:2111.08896",
    "title": "Achieving Human Parity on Visual Question Answering",
    "abstract": "Achieving Human Parity on Visual Question Answering",
    "descriptor": "",
    "authors": [
      "Ming Yan",
      "Haiyang Xu",
      "Chenliang Li",
      "Junfeng Tian",
      "Bin Bi",
      "Wei Wang",
      "Weihua Chen",
      "Xianzhe Xu",
      "Fan Wang",
      "Zheng Cao",
      "Zhicheng Zhang",
      "Qiyu Zhang",
      "Ji Zhang",
      "Songfang Huang",
      "Fei Huang",
      "Luo Si",
      "Rong Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08896"
  },
  {
    "id": "arXiv:2111.08973",
    "title": "Generating Unrestricted 3D Adversarial Point Clouds",
    "abstract": "Generating Unrestricted 3D Adversarial Point Clouds",
    "descriptor": "",
    "authors": [
      "Xuelong Dai",
      "Yanjie Li",
      "Hua Dai",
      "Bin Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.08973"
  },
  {
    "id": "arXiv:2111.09098",
    "title": "Unifying Heterogenous Electronic Health Records Systems via Text-Based  Code Embedding",
    "abstract": "Comments: v1: Main paper + supplementary material (14 pages, 5 figures, 9 tables) This is a condensed version of arXiv:2108.03625",
    "descriptor": "\nComments: v1: Main paper + supplementary material (14 pages, 5 figures, 9 tables) This is a condensed version of arXiv:2108.03625\n",
    "authors": [
      "Kyunghoon Hur",
      "Jiyoung Lee",
      "Jungwoo Oh",
      "Wesley Price",
      "Young-Hak Kim",
      "Edward Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09098"
  },
  {
    "id": "arXiv:2111.09099",
    "title": "Self-Supervised Predictive Convolutional Attentive Block for Anomaly  Detection",
    "abstract": "Self-Supervised Predictive Convolutional Attentive Block for Anomaly  Detection",
    "descriptor": "",
    "authors": [
      "Nicolae-Catalin Ristea",
      "Neelu Madan",
      "Radu Tudor Ionescu",
      "Kamal Nasrollahi",
      "Fahad Shahbaz Khan",
      "Thomas B. Moeslund",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09099"
  },
  {
    "id": "arXiv:2111.09190",
    "title": "Understanding and Testing Generalization of Deep Networks on  Out-of-Distribution Data",
    "abstract": "Understanding and Testing Generalization of Deep Networks on  Out-of-Distribution Data",
    "descriptor": "",
    "authors": [
      "Rui Hu",
      "Jitao Sang",
      "Jinqiang Wang",
      "Rui Hu",
      "Chaoquan Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.09190"
  },
  {
    "id": "arXiv:2111.09296",
    "title": "XLS-R: Self-supervised Cross-lingual Speech Representation Learning at  Scale",
    "abstract": "XLS-R: Self-supervised Cross-lingual Speech Representation Learning at  Scale",
    "descriptor": "",
    "authors": [
      "Arun Babu",
      "Changhan Wang",
      "Andros Tjandra",
      "Kushal Lakhotia",
      "Qiantong Xu",
      "Naman Goyal",
      "Kritika Singh",
      "Patrick von Platen",
      "Yatharth Saraf",
      "Juan Pino",
      "Alexei Baevski",
      "Alexis Conneau",
      "Michael Auli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.09296"
  },
  {
    "id": "arXiv:2111.09376",
    "title": "Optimal Decremental Connectivity in Non-Sparse Graphs",
    "abstract": "Optimal Decremental Connectivity in Non-Sparse Graphs",
    "descriptor": "",
    "authors": [
      "Anders Aaman",
      "Adam Karczmarz",
      "Jakub \u0141\u0105cki",
      "Nikos Parotsidis",
      "Peter M. R. Rasmussen",
      "Mikkel Thorup"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.09376"
  },
  {
    "id": "arXiv:2111.09442",
    "title": "Monitoring COVID-19-induced gender differences in teleworking rates  using Mobile Network Data",
    "abstract": "Comments: added figures",
    "descriptor": "\nComments: added figures\n",
    "authors": [
      "Sara Grubanov-Boskovic",
      "Spyridon Spyratos",
      "Stefano Maria Iacus",
      "Umberto Minora",
      "Francesco Sermi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2111.09442"
  },
  {
    "id": "arXiv:2111.09464",
    "title": "A Novel Grid-forming Voltage Control Strategy for Supplying Unbalanced  Microgrid Loads Using Inverter-based Resources",
    "abstract": "Comments: 5 pages, 6 figures, 2022 PESGM conference",
    "descriptor": "\nComments: 5 pages, 6 figures, 2022 PESGM conference\n",
    "authors": [
      "Bei Xu",
      "Victor Paduani",
      "Hui Yu",
      "David Lubkeman",
      "Ning Lu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.09464"
  },
  {
    "id": "arXiv:2111.09547",
    "title": "QGTC: Accelerating Quantized GNN via GPU Tensor Core",
    "abstract": "QGTC: Accelerating Quantized GNN via GPU Tensor Core",
    "descriptor": "",
    "authors": [
      "Yuke Wang",
      "Boyuan Feng",
      "Yufei Ding"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.09547"
  },
  {
    "id": "arXiv:2111.09692",
    "title": "SUB-Depth: Self-distillation and Uncertainty Boosting Self-supervised  Monocular Depth Estimation",
    "abstract": "SUB-Depth: Self-distillation and Uncertainty Boosting Self-supervised  Monocular Depth Estimation",
    "descriptor": "",
    "authors": [
      "Hang Zhou",
      "Sarah Taylor",
      "David Greenwood"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09692"
  },
  {
    "id": "arXiv:2111.09793",
    "title": "Unsupervised Online Learning for Robotic Interestingness with Visual  Memory",
    "abstract": "Comments: Accepted to The IEEE Transactions on Robotics (T-RO). A substantial extension of the ECCV 2020 paper arXiv:2005.08829",
    "descriptor": "\nComments: Accepted to The IEEE Transactions on Robotics (T-RO). A substantial extension of the ECCV 2020 paper arXiv:2005.08829\n",
    "authors": [
      "Chen Wang",
      "Yuheng Qiu",
      "Wenshan Wang",
      "Yafei Hu",
      "Seungchan Kim",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09793"
  },
  {
    "id": "arXiv:2111.09799",
    "title": "LiDAR Cluster First and Camera Inference Later: A New Perspective  Towards Autonomous Driving",
    "abstract": "Comments: 6 pages",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Jiyang Chen",
      "Simon Yu",
      "Rohan Tabish",
      "Ayoosh Bansal",
      "Shengzhong Liu",
      "Tarek Abdelzaher",
      "Lui Sha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09799"
  }
]
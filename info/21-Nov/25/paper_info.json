[
  {
    "id": "arXiv:2111.12111",
    "title": "Context-based navigation for ground mobile robot in a semi-structured  indoor environment",
    "abstract": "There is a growing demand for mobile robots to operate in more variable\nenvironments, where guaranteeing safe robot navigation is a priority, in\naddition to time performance. To achieve this, current solutions for local\nplanning use a specific configuration tuned to the characteristics of the\napplication environment. In this paper, we present an approach for developing\nquality models that can be used by a self-adaptation framework to adapt the\nlocal planner configuration at run-time based on the perceived environment. We\ncontribute a definition of a safety model that predicts the safety of a\nnavigation configuration given the perceived environment. Experiments have been\nperformed in a realistic navigation scenario for a retail application to\nvalidate the obtained models and demonstrate their integration in a\nself-adaptation framework.",
    "descriptor": "",
    "authors": [
      "Darko Bozhinoski",
      "Jasper Wijkhuizen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.12111"
  },
  {
    "id": "arXiv:2111.12115",
    "title": "Algorithmic Fairness in Face Morphing Attack Detection",
    "abstract": "Face morphing attacks can compromise Face Recognition System (FRS) by\nexploiting their vulnerability. Face Morphing Attack Detection (MAD) techniques\nhave been developed in recent past to deter such attacks and mitigate risks\nfrom morphing attacks. MAD algorithms, as any other algorithms should treat the\nimages of subjects from different ethnic origins in an equal manner and provide\nnon-discriminatory results. While the promising MAD algorithms are tested for\nrobustness, there is no study comprehensively bench-marking their behaviour\nagainst various ethnicities. In this paper, we study and present a\ncomprehensive analysis of algorithmic fairness of the existing Single\nimage-based Morph Attack Detection (S-MAD) algorithms. We attempt to better\nunderstand the influence of ethnic bias on MAD algorithms and to this extent,\nwe study the performance of MAD algorithms on a newly created dataset\nconsisting of four different ethnic groups. With Extensive experiments using\nsix different S-MAD techniques, we first present benchmark of detection\nperformance and then measure the quantitative value of the algorithmic fairness\nfor each of them using Fairness Discrepancy Rate (FDR). The results indicate\nthe lack of fairness on all six different S-MAD methods when trained and tested\non different ethnic groups suggesting the need for reliable MAD approaches to\nmitigate the algorithmic bias.",
    "descriptor": "\nComments: Accepted to WACVW2022\n",
    "authors": [
      "Raghavendra Ramachandra",
      "Kiran Raja",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12115"
  },
  {
    "id": "arXiv:2111.12116",
    "title": "Caviar: An E-graph Based TRS for Automatic Code Optimization",
    "abstract": "Term Rewriting Systems (TRS) are used in compilers to simplify and prove\nexpressions. State-of-the-art TRSs in compilers use a greedy algorithm that\napplies a set of rewriting rules in a predefined order (where some of the rules\nare not axiomatic). This leads to a loss in the ability to simplify certain\nexpressions. E-graphs and equality saturation sidestep this issue by\nrepresenting the different equivalent expressions in a compact manner from\nwhich the optimal expression can be extracted. While an e-graph-based TRS can\nbe more powerful than a TRS that uses a greedy algorithm, it is slower because\nexpressions may have a large or sometimes infinite number of equivalent\nexpressions. Accelerating e-graph construction is crucial for making the use of\ne-graphs practical in compilers. In this paper, we present Caviar, an\ne-graph-based TRS for proving expressions within compilers. Caviar is a fast\n(20x faster than base e-graph TRS) and flexible (completely parameterized) TRS\nthat that relies on three novel techniques: 1) a technique that stops e-graphs\nfrom growing when the goal is reached, called Iteration Level Check; 2) a\nmechanism that balances exploration and exploitation in the equality saturation\nalgorithm, called Pulsing Caviar; 3) a technique to stop e-graph construction\nbefore reaching saturation when a non-provable pattern is detected, called\nNon-Provable Patterns Detection (NPPD). We evaluate caviar on Halide, an\noptimizing compiler that relies on a greedy-algorithm-based TRS to simplify and\nprove its expressions. The proposed techniques allow Caviar to accelerate\ne-graph expansion by 20x for the task of proving expressions. They also allow\nCaviar to prove 51% of the expressions that Halide's TRS cannot prove while\nbeing only 0.68x slower.",
    "descriptor": "",
    "authors": [
      "Smail Kourta",
      "Adel Namani",
      "Fatima Benbouzid-Si Tayeb",
      "Kim Hazelwood",
      "Chris Cummins",
      "Hugh Leather",
      "Riyadh Baghdadi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.12116"
  },
  {
    "id": "arXiv:2111.12122",
    "title": "Bounding Box-Free Instance Segmentation Using Semi-Supervised Learning  for Generating a City-Scale Vehicle Dataset",
    "abstract": "Vehicle classification is a hot computer vision topic, with studies ranging\nfrom ground-view up to top-view imagery. In remote sensing, the usage of\ntop-view images allows for understanding city patterns, vehicle concentration,\ntraffic management, and others. However, there are some difficulties when\naiming for pixel-wise classification: (a) most vehicle classification studies\nuse object detection methods, and most publicly available datasets are designed\nfor this task, (b) creating instance segmentation datasets is laborious, and\n(c) traditional instance segmentation methods underperform on this task since\nthe objects are small. Thus, the present research objectives are: (1) propose a\nnovel semi-supervised iterative learning approach using GIS software, (2)\npropose a box-free instance segmentation approach, and (3) provide a city-scale\nvehicle dataset. The iterative learning procedure considered: (1) label a small\nnumber of vehicles, (2) train on those samples, (3) use the model to classify\nthe entire image, (4) convert the image prediction into a polygon shapefile,\n(5) correct some areas with errors and include them in the training data, and\n(6) repeat until results are satisfactory. To separate instances, we considered\nvehicle interior and vehicle borders, and the DL model was the U-net with the\nEfficient-net-B7 backbone. When removing the borders, the vehicle interior\nbecomes isolated, allowing for unique object identification. To recover the\ndeleted 1-pixel borders, we proposed a simple method to expand each prediction.\nThe results show better pixel-wise metrics when compared to the Mask-RCNN (82%\nagainst 67% in IoU). On per-object analysis, the overall accuracy, precision,\nand recall were greater than 90%. This pipeline applies to any remote sensing\ntarget, being very efficient for segmentation and generating datasets.",
    "descriptor": "\nComments: 38 pages, 10 figures, submitted to journal\n",
    "authors": [
      "Osmar Luiz Ferreira de Carvalho",
      "Osmar Ab\u00edlio de Carvalho J\u00fanior",
      "Anesmar Olino de Albuquerque",
      "Nickolas Castro Santana",
      "Dibio Leandro Borges",
      "Roberto Arnaldo Trancoso Gomes",
      "Renato Fontes Guimar\u00e3es"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.12122"
  },
  {
    "id": "arXiv:2111.12123",
    "title": "MICS : Multi-steps, Inverse Consistency and Symmetric deep learning  registration network",
    "abstract": "Deformable registration consists of finding the best dense correspondence\nbetween two different images. Many algorithms have been published, but the\nclinical application was made difficult by the high calculation time needed to\nsolve the optimisation problem. Deep learning overtook this limitation by\ntaking advantage of GPU calculation and the learning process. However, many\ndeep learning methods do not take into account desirable properties respected\nby classical algorithms.\nIn this paper, we present MICS, a novel deep learning algorithm for medical\nimaging registration. As registration is an ill-posed problem, we focused our\nalgorithm on the respect of different properties: inverse consistency, symmetry\nand orientation conservation. We also combined our algorithm with a multi-step\nstrategy to refine and improve the deformation grid. While many approaches\napplied registration to brain MRI, we explored a more challenging body\nlocalisation: abdominal CT. Finally, we evaluated our method on a dataset used\nduring the Learn2Reg challenge, allowing a fair comparison with published\nmethods.",
    "descriptor": "\nComments: In submission\n",
    "authors": [
      "Th\u00e9o Estienne",
      "Maria Vakalopoulou",
      "Enzo Battistella",
      "Theophraste Henry",
      "Marvin Lerousseau",
      "Amaury Leroy",
      "Nikos Paragios",
      "Eric Deutsch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12123"
  },
  {
    "id": "arXiv:2111.12124",
    "title": "Towards Learning Universal Audio Representations",
    "abstract": "The ability to learn universal audio representations that can solve diverse\nspeech, music, and environment tasks can spur many applications that require\ngeneral sound content understanding. In this work, we introduce a holistic\naudio representation evaluation suite (HARES) spanning 12 downstream tasks\nacross audio domains and provide a thorough empirical study of recent sound\nrepresentation learning systems on that benchmark. We discover that previous\nsound event classification or speech models do not generalize outside of their\ndomains. We observe that more robust audio representations can be learned with\nthe SimCLR objective; however, the model's transferability depends heavily on\nthe model architecture. We find the Slowfast architecture is good at learning\nrich representations required by different domains, but its performance is\naffected by the normalization scheme. Based on these findings, we propose a\nnovel normalizer-free Slowfast NFNet and achieve state-of-the-art performance\nacross all domains.",
    "descriptor": "",
    "authors": [
      "Luyu Wang",
      "Pauline Luc",
      "Yan Wu",
      "Adria Recasens",
      "Lucas Smaira",
      "Andrew Brock",
      "Andrew Jaegle",
      "Jean-Baptiste Alayrac",
      "Sander Dieleman",
      "Joao Carreira",
      "Aaron van den Oord"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.12124"
  },
  {
    "id": "arXiv:2111.12126",
    "title": "Panoptic Segmentation Meets Remote Sensing",
    "abstract": "Panoptic segmentation combines instance and semantic predictions, allowing\nthe detection of \"things\" and \"stuff\" simultaneously. Effectively approaching\npanoptic segmentation in remotely sensed data can be auspicious in many\nchallenging problems since it allows continuous mapping and specific target\ncounting. Several difficulties have prevented the growth of this task in remote\nsensing: (a) most algorithms are designed for traditional images, (b) image\nlabelling must encompass \"things\" and \"stuff\" classes, and (c) the annotation\nformat is complex. Thus, aiming to solve and increase the operability of\npanoptic segmentation in remote sensing, this study has five objectives: (1)\ncreate a novel data preparation pipeline for panoptic segmentation, (2) propose\nan annotation conversion software to generate panoptic annotations; (3) propose\na novel dataset on urban areas, (4) modify the Detectron2 for the task, and (5)\nevaluate difficulties of this task in the urban setting. We used an aerial\nimage with a 0,24-meter spatial resolution considering 14 classes. Our pipeline\nconsiders three image inputs, and the proposed software uses point shapefiles\nfor creating samples in the COCO format. Our study generated 3,400 samples with\n512x512 pixel dimensions. We used the Panoptic-FPN with two backbones\n(ResNet-50 and ResNet-101), and the model evaluation considered semantic\ninstance and panoptic metrics. We obtained 93.9, 47.7, and 64.9 for the mean\nIoU, box AP, and PQ. Our study presents the first effective pipeline for\npanoptic segmentation and an extensive database for other researchers to use\nand deal with other data or related problems requiring a thorough scene\nunderstanding.",
    "descriptor": "\nComments: 43 pages, 10 figures, submitted to journal\n",
    "authors": [
      "Osmar Luiz Ferreira de Carvalho",
      "Osmar Ab\u00edlio de Carvalho J\u00fanior",
      "Cristiano Rosa e Silva",
      "Anesmar Olino de Albuquerque",
      "Nickolas Castro Santana",
      "Dibio Leandro Borges",
      "Roberto Arnaldo Trancoso Gomes",
      "Renato Fontes Guimar\u00e3es"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.12126"
  },
  {
    "id": "arXiv:2111.12128",
    "title": "On the Unreasonable Effectiveness of Feature propagation in Learning on  Graphs with Missing Node Features",
    "abstract": "While Graph Neural Networks (GNNs) have recently become the de facto standard\nfor modeling relational data, they impose a strong assumption on the\navailability of the node or edge features of the graph. In many real-world\napplications, however, features are only partially available; for example, in\nsocial networks, age and gender are available only for a small subset of users.\nWe present a general approach for handling missing features in graph machine\nlearning applications that is based on minimization of the Dirichlet energy and\nleads to a diffusion-type differential equation on the graph. The\ndiscretization of this equation produces a simple, fast and scalable algorithm\nwhich we call Feature Propagation. We experimentally show that the proposed\napproach outperforms previous methods on seven common node-classification\nbenchmarks and can withstand surprisingly high rates of missing features: on\naverage we observe only around 4% relative accuracy drop when 99% of the\nfeatures are missing. Moreover, it takes only 10 seconds to run on a graph with\n$\\sim$2.5M nodes and $\\sim$123M edges on a single GPU.",
    "descriptor": "",
    "authors": [
      "Emanuele Rossi",
      "Henry Kenlay",
      "Maria I. Gorinova",
      "Benjamin Paul Chamberlain",
      "Xiaowen Dong",
      "Michael Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12128"
  },
  {
    "id": "arXiv:2111.12132",
    "title": "Robust Principal Component Analysis: A Construction Error Minimization  Perspective",
    "abstract": "In this paper we propose a novel optimization framework to systematically\nsolve robust PCA problem with rigorous theoretical guarantee, based on which we\ninvestigate very computationally economic updating algorithms.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Kai Liu",
      "Yarui Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12132"
  },
  {
    "id": "arXiv:2111.12137",
    "title": "Learning Interactive Driving Policies via Data-driven Simulation",
    "abstract": "Data-driven simulators promise high data-efficiency for driving policy\nlearning. When used for modelling interactions, this data-efficiency becomes a\nbottleneck: Small underlying datasets often lack interesting and challenging\nedge cases for learning interactive driving. We address this challenge by\nproposing a simulation method that uses in-painted ado vehicles for learning\nrobust driving policies. Thus, our approach can be used to learn policies that\ninvolve multi-agent interactions and allows for training via state-of-the-art\npolicy learning methods. We evaluate the approach for learning standard\ninteraction scenarios in driving. In extensive experiments, our work\ndemonstrates that the resulting policies can be directly transferred to a\nfull-scale autonomous vehicle without making use of any traditional sim-to-real\ntransfer techniques such as domain randomization.",
    "descriptor": "\nComments: The first two authors contributed equally to this this work. Code is available here: this http URL\n",
    "authors": [
      "Tsun-Hsuan Wang",
      "Alexander Amini",
      "Wilko Schwarting",
      "Igor Gilitschenski",
      "Sertac Karaman",
      "Daniela Rus"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12137"
  },
  {
    "id": "arXiv:2111.12139",
    "title": "ChebLieNet: Invariant Spectral Graph NNs Turned Equivariant by  Riemannian Geometry on Lie Groups",
    "abstract": "We introduce ChebLieNet, a group-equivariant method on (anisotropic)\nmanifolds. Surfing on the success of graph- and group-based neural networks, we\ntake advantage of the recent developments in the geometric deep learning field\nto derive a new approach to exploit any anisotropies in data. Via discrete\napproximations of Lie groups, we develop a graph neural network made of\nanisotropic convolutional layers (Chebyshev convolutions), spatial pooling and\nunpooling layers, and global pooling layers. Group equivariance is achieved via\nequivariant and invariant operators on graphs with anisotropic left-invariant\nRiemannian distance-based affinities encoded on the edges. Thanks to its simple\nform, the Riemannian metric can model any anisotropies, both in the spatial and\norientation domains. This control on anisotropies of the Riemannian metrics\nallows to balance equivariance (anisotropic metric) against invariance\n(isotropic metric) of the graph convolution layers. Hence we open the doors to\na better understanding of anisotropic properties. Furthermore, we empirically\nprove the existence of (data-dependent) sweet spots for anisotropic parameters\non CIFAR10. This crucial result is evidence of the benefice we could get by\nexploiting anisotropic properties in data. We also evaluate the scalability of\nthis approach on STL10 (image data) and ClimateNet (spherical data), showing\nits remarkable adaptability to diverse tasks.",
    "descriptor": "\nComments: submitted to NeurIPS'21, this https URL\n",
    "authors": [
      "Hugo Aguettaz",
      "Erik J. Bekkers",
      "Micha\u00ebl Defferrard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12139"
  },
  {
    "id": "arXiv:2111.12140",
    "title": "Filter Methods for Feature Selection in Supervised Machine Learning  Applications -- Review and Benchmark",
    "abstract": "The amount of data for machine learning (ML) applications is constantly\ngrowing. Not only the number of observations, especially the number of measured\nvariables (features) increases with ongoing digitization. Selecting the most\nappropriate features for predictive modeling is an important lever for the\nsuccess of ML applications in business and research. Feature selection methods\n(FSM) that are independent of a certain ML algorithm - so-called filter methods\n- have been numerously suggested, but little guidance for researchers and\nquantitative modelers exists to choose appropriate approaches for typical ML\nproblems. This review synthesizes the substantial literature on feature\nselection benchmarking and evaluates the performance of 58 methods in the\nwidely used R environment. For concrete guidance, we consider four typical\ndataset scenarios that are challenging for ML models (noisy, redundant,\nimbalanced data and cases with more features than observations). Drawing on the\nexperience of earlier benchmarks, which have considered much fewer FSMs, we\ncompare the performance of the methods according to four criteria (predictive\nperformance, number of relevant features selected, stability of the feature\nsets and runtime). We found methods relying on the random forest approach, the\ndouble input symmetrical relevance filter (DISR) and the joint impurity filter\n(JIM) were well-performing candidate methods for the given dataset scenarios.",
    "descriptor": "\nComments: Source code of the analysis is available on request\n",
    "authors": [
      "Konstantin Hopf",
      "Sascha Reifenrath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12140"
  },
  {
    "id": "arXiv:2111.12143",
    "title": "Critical initialization of wide and deep neural networks through partial  Jacobians: general theory and applications to LayerNorm",
    "abstract": "Deep neural networks are notorious for defying theoretical treatment.\nHowever, when the number of parameters in each layer tends to infinity the\nnetwork function is a Gaussian process (GP) and quantitatively predictive\ndescription is possible. Gaussian approximation allows to formulate criteria\nfor selecting hyperparameters, such as variances of weights and biases, as well\nas the learning rate. These criteria rely on the notion of criticality defined\nfor deep neural networks. In this work we describe a new way to diagnose (both\ntheoretically and empirically) this criticality. To that end, we introduce\npartial Jacobians of a network, defined as derivatives of preactivations in\nlayer $l$ with respect to preactivations in layer $l_0<l$. These quantities are\nparticularly useful when the network architecture involves many different\nlayers. We discuss various properties of the partial Jacobians such as their\nscaling with depth and relation to the neural tangent kernel (NTK). We derive\nthe recurrence relations for the partial Jacobians and utilize them to analyze\ncriticality of deep MLP networks with (and without) LayerNorm. We find that the\nnormalization layer changes the optimal values of hyperparameters and critical\nexponents. We argue that LayerNorm is more stable when applied to\npreactivations, rather than activations due to larger correlation depth.",
    "descriptor": "\nComments: 28 pages, 8 figures\n",
    "authors": [
      "Darshil Doshi",
      "Tianyu He",
      "Andrey Gromov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12143"
  },
  {
    "id": "arXiv:2111.12144",
    "title": "Mimicking Playstyle by Adapting Parameterized Behavior Trees in RTS  Games",
    "abstract": "The discovery of Behavior Trees (BTs) impacted the field of Artificial\nIntelligence (AI) in games, by providing flexible and natural representation of\nnon-player characters (NPCs) logic, manageable by game-designers. Nevertheless,\nincreased pressure on ever better NPCs AI-agents forced complexity of\nhandcrafted BTs to became barely-tractable and error-prone. On the other hand,\nwhile many just-launched on-line games suffer from player-shortage, the\nexistence of AI with a broad-range of capabilities could increase players\nretention. Therefore, to handle above challenges, recent trends in the field\nfocused on automatic creation of AI-agents: from deep- and\nreinforcementlearning techniques to combinatorial (constrained) optimization\nand evolution of BTs. In this paper, we present a novel approach to\nsemi-automatic construction of AI-agents, that mimic and generalize given human\ngameplays by adapting and tuning of expert-created BT under a developed\nsimilarity metric between source and BT gameplays. To this end, we formulated\nmixed discrete-continuous optimization problem, in which topological and\nfunctional changes of the BT are reflected in numerical variables, and\nconstructed a dedicated hybrid-metaheuristic. The performance of presented\napproach was verified experimentally in a prototype real-time strategy game.\nCarried out experiments confirmed efficiency and perspectives of presented\napproach, which is going to be applied in a commercial game.",
    "descriptor": "",
    "authors": [
      "Andrzej Kozik",
      "Tomasz Machalewski",
      "Mariusz Marek",
      "Adrian Ochmann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12144"
  },
  {
    "id": "arXiv:2111.12146",
    "title": "Sharing to learn and learning to share - Fitting together Meta-Learning,  Multi-Task Learning, and Transfer Learning : A meta review",
    "abstract": "Integrating knowledge across different domains is an essential feature of\nhuman learning. Learning paradigms like transfer learning, meta learning, and\nmulti-task learning reflect the human learning process by exploiting the prior\nknowledge for new tasks, encouraging faster learning and good generalization\nfor new tasks. This article gives a detailed view of these learning paradigms\nalong with a comparative analysis. The weakness of a learning algorithm turns\nout to be the strength of another, and thereby merging them is a prevalent\ntrait in the literature. This work delivers a literature review of the\narticles, which fuses two algorithms to accomplish multiple tasks. A global\ngeneric learning network, an ensemble of meta learning, transfer learning, and\nmulti-task learning, is also introduced here, along with some open research\nquestions and directions for future research.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Richa Upadhyay",
      "Ronald Phlypo",
      "Rajkumar Saini",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12146"
  },
  {
    "id": "arXiv:2111.12147",
    "title": "kmclib: Automated Inference and Verification of Session Types}",
    "abstract": "Theories and tools based on multiparty session types offer correctness\nguarantees for concurrent programs that communicate using message-passing.\nThese guarantees usually come at the cost of an intrinsically top-down\napproach, which requires the communication behaviour of the entire program to\nbe specified as a global type. This paper introduces kmclib: an OCaml library\nthat supports the development of correct message-passing programs without\nhaving to write any types. The library utilises the meta-programming facilities\nof OCaml to automatically infer the session types of concurrent programs and\nverify their compatibility (k-MC). Well-typed programs, written with kmclib, do\nnot lead to communication errors and cannot get stuck.",
    "descriptor": "\nComments: kmclib is available at this https URL\n",
    "authors": [
      "Keigo Imai",
      "Julien Lange",
      "Rumyana Neykova"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.12147"
  },
  {
    "id": "arXiv:2111.12150",
    "title": "Jointly Learning from Decentralized (Federated) and Centralized Data to  Mitigate Distribution Shift",
    "abstract": "With privacy as a motivation, Federated Learning (FL) is an increasingly used\nparadigm where learning takes place collectively on edge devices, each with a\ncache of user-generated training examples that remain resident on the local\ndevice. These on-device training examples are gathered in situ during the\ncourse of users' interactions with their devices, and thus are highly\nreflective of at least part of the inference data distribution. Yet a\ndistribution shift may still exist; the on-device training examples may lack\nfor some data inputs expected to be encountered at inference time. This paper\nproposes a way to mitigate this shift: selective usage of datacenter data,\nmixed in with FL. By mixing decentralized (federated) and centralized\n(datacenter) data, we can form an effective training data distribution that\nbetter matches the inference data distribution, resulting in more useful models\nwhile still meeting the private training data access constraints imposed by FL.",
    "descriptor": "\nComments: 9 pages, 1 figure. Camera-ready NeurIPS 2021 DistShift workshop version\n",
    "authors": [
      "Sean Augenstein",
      "Andrew Hard",
      "Kurt Partridge",
      "Rajiv Mathews"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.12150"
  },
  {
    "id": "arXiv:2111.12151",
    "title": "Best Arm Identification with Safety Constraints",
    "abstract": "The best arm identification problem in the multi-armed bandit setting is an\nexcellent model of many real-world decision-making problems, yet it fails to\ncapture the fact that in the real-world, safety constraints often must be met\nwhile learning. In this work we study the question of best-arm identification\nin safety-critical settings, where the goal of the agent is to find the best\nsafe option out of many, while exploring in a way that guarantees certain,\ninitially unknown safety constraints are met. We first analyze this problem in\nthe setting where the reward and safety constraint takes a linear structure,\nand show nearly matching upper and lower bounds. We then analyze a much more\ngeneral version of the problem where we only assume the reward and safety\nconstraint can be modeled by monotonic functions, and propose an algorithm in\nthis setting which is guaranteed to learn safely. We conclude with experimental\nresults demonstrating the effectiveness of our approaches in scenarios such as\nsafely identifying the best drug out of many in order to treat an illness.",
    "descriptor": "",
    "authors": [
      "Zhenlin Wang",
      "Andrew Wagenmaker",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12151"
  },
  {
    "id": "arXiv:2111.12153",
    "title": "Methodology and feasibility of neurofeedback to improve visual attention  to letters in mild Alzheimer's disease",
    "abstract": "Brain computer interfaces systems are controlled by users through\nneurophysiological input for a variety of applications including communication,\nenvironmental control, motor rehabilitation, and cognitive training. Although\nindividuals with severe speech and physical impairment are the primary users of\nthis technology, BCIs have emerged as a potential tool for broader populations,\nespecially with regards to delivering cognitive training or interventions with\nneurofeedback. The goal of this study was to investigate the feasibility of\nusing a BCI system with neurofeedback as an intervention for people with mild\nAlzheimer's disease. The study focused on visual attention and language since\nad is often associated with functional impairments in language and reading. The\nstudy enrolled five adults with mild ad in a nine to thirteen week BCI EEG\nbased neurofeedback intervention to improve attention and reading skills. Two\nparticipants completed intervention entirely. The remaining three participants\ncould not complete the intervention phase because of restrictions related to\ncovid. Pre and post assessment measures were used to assess reliability of\noutcome measures and generalization of treatment to functional reading,\nprocessing speed, attention, and working memory skills. Participants\ndemonstrated steady improvement in most cognitive measures across experimental\nphases, although there was not a significant effect of NFB on most measures of\nattention. One subject demonstrated significantly significant improvement in\nletter cancellation during NFB. All participants with mild AD learned to\noperate a BCI system with training. Results have broad implications for the\ndesign and use of bci systems for participants with cognitive impairment.\nPreliminary evidence justifies implementing NFB-based cognitive measures in AD.",
    "descriptor": "\nComments: 50 pages including 6 figures and 4 tables\n",
    "authors": [
      "Deirdre McLaughlin",
      "Daniel Klee",
      "Tab Memmott",
      "Betts Peters",
      "Jack Wiedrick",
      "Melanie Fried-Oken",
      "Barry Oken"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.12153"
  },
  {
    "id": "arXiv:2111.12154",
    "title": "A Review on Analysis and Visualization Methods for Biclustering",
    "abstract": "Recently, biclustering is one of the hot topics in bioinformatics and takes\nthe attention of authors from several different disciplines. Hence, many\ndifferent methodologies from a variety of disciplines are proposed as a\nsolution to the biclustering problem. As a consequence of this issue, a variety\nof solutions makes it harder to evaluate the proposed methods. With this review\npaper, we are aimed to discuss both analysis and visualization of biclustering\nas a guide for the comparisons between brand new and existing biclustering\nalgorithms. Additionally, we concentrate on the tools that provide\nvisualizations with accompanied analysis techniques. Through the paper, we give\nseveral references that are also a short review of the state of the art for the\nones who will pursue research on biclustering. The Paper outline is as follows;\nwe first give the visualization and analysis methods, then we evaluate each\nproposed tool with the visualization contribution and analysis options,\nfinally, we discuss future directions for biclustering and we propose standards\nfor future work.",
    "descriptor": "\nComments: 13 pages, 1 figure and 1 table\n",
    "authors": [
      "Melih Sozdinler"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.12154"
  },
  {
    "id": "arXiv:2111.12155",
    "title": "In-field early disease recognition of potato late blight based on deep  learning and proximal hyperspectral imaging",
    "abstract": "Effective early detection of potato late blight (PLB) is an essential aspect\nof potato cultivation. However, it is a challenge to detect late blight at an\nearly stage in fields with conventional imaging approaches because of the lack\nof visual cues displayed at the canopy level. Hyperspectral imaging can,\ncapture spectral signals from a wide range of wavelengths also outside the\nvisual wavelengths. In this context, we propose a deep learning classification\narchitecture for hyperspectral images by combining 2D convolutional neural\nnetwork (2D-CNN) and 3D-CNN with deep cooperative attention networks\n(PLB-2D-3D-A). First, 2D-CNN and 3D-CNN are used to extract rich spectral space\nfeatures, and then the attention mechanism AttentionBlock and SE-ResNet are\nused to emphasize the salient features in the feature maps and increase the\ngeneralization ability of the model. The dataset is built with 15,360 images\n(64x64x204), cropped from 240 raw images captured in an experimental field with\nover 20 potato genotypes. The accuracy in the test dataset of 2000 images\nreached 0.739 in the full band and 0.790 in the specific bands (492nm, 519nm,\n560nm, 592nm, 717nm and 765nm). This study shows an encouraging result for\nearly detection of PLB with deep learning and proximal hyperspectral imaging.",
    "descriptor": "",
    "authors": [
      "Chao Qi",
      "Murilo Sandroni",
      "Jesper Cairo Westergaard",
      "Ea H\u00f8egh Riis Sundmark",
      "Merethe Bagge",
      "Erik Alexandersson",
      "Junfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12155"
  },
  {
    "id": "arXiv:2111.12158",
    "title": "Using Language Model to Bootstrap Human Activity Recognition Ambient  Sensors Based in Smart Homes",
    "abstract": "Long Short Term Memory LSTM-based structures have demonstrated their\nefficiency for daily living recognition activities in smart homes by capturing\nthe order of sensor activations and their temporal dependencies. Nevertheless,\nthey still fail in dealing with the semantics and the context of the sensors.\nMore than isolated id and their ordered activation values, sensors also carry\nmeaning. Indeed, their nature and type of activation can translate various\nactivities. Their logs are correlated with each other, creating a global\ncontext. We propose to use and compare two Natural Language Processing\nembedding methods to enhance LSTM-based structures in activity-sequences\nclassification tasks: Word2Vec, a static semantic embedding, and ELMo, a\ncontextualized embedding. Results, on real smart homes datasets, indicate that\nthis approach provides useful information, such as a sensor organization map,\nand makes less confusion between daily activity classes. It helps to better\nperform on datasets with competing activities of other residents or pets. Our\ntests show also that the embeddings can be pretrained on different datasets\nthan the target one, enabling transfer learning. We thus demonstrate that\ntaking into account the context of the sensors and their semantics increases\nthe classification performances and enables transfer learning.",
    "descriptor": "",
    "authors": [
      "Damien Bouchabou",
      "Sao Mai Nguyen",
      "Christophe Lohr",
      "Benoit Leduc",
      "Ioannis Kanellos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12158"
  },
  {
    "id": "arXiv:2111.12159",
    "title": "Rhythm is a Dancer: Music-Driven Motion Synthesis with Global Structure",
    "abstract": "Synthesizing human motion with a global structure, such as a choreography, is\na challenging task. Existing methods tend to concentrate on local smooth pose\ntransitions and neglect the global context or the theme of the motion. In this\nwork, we present a music-driven motion synthesis framework that generates\nlong-term sequences of human motions which are synchronized with the input\nbeats, and jointly form a global structure that respects a specific dance\ngenre. In addition, our framework enables generation of diverse motions that\nare controlled by the content of the music, and not only by the beat. Our\nmusic-driven dance synthesis framework is a hierarchical system that consists\nof three levels: pose, motif, and choreography. The pose level consists of an\nLSTM component that generates temporally coherent sequences of poses. The motif\nlevel guides sets of consecutive poses to form a movement that belongs to a\nspecific distribution using a novel motion perceptual-loss. And the\nchoreography level selects the order of the performed movements and drives the\nsystem to follow the global structure of a dance genre. Our results demonstrate\nthe effectiveness of our music-driven framework to generate natural and\nconsistent movements on various dance types, having control over the content of\nthe synthesized motions, and respecting the overall structure of the dance.",
    "descriptor": "",
    "authors": [
      "Andreas Aristidou",
      "Anastasios Yiannakidis",
      "Kfir Aberman",
      "Daniel Cohen-Or",
      "Ariel Shamir",
      "Yiorgos Chrysanthou"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12159"
  },
  {
    "id": "arXiv:2111.12166",
    "title": "Towards Empirical Sandwich Bounds on the Rate-Distortion Function",
    "abstract": "Rate-distortion (R-D) function, a key quantity in information theory,\ncharacterizes the fundamental limit of how much a data source can be compressed\nsubject to a fidelity criterion, by any compression algorithm. As researchers\npush for ever-improving compression performance, establishing the R-D function\nof a given data source is not only of scientific interest, but also sheds light\non the possible room for improving compression algorithms. Previous work on\nthis problem relied on distributional assumptions on the data source (Gibson,\n2017) or only applied to discrete data. By contrast, this paper makes the first\nattempt at an algorithm for sandwiching the R-D function of a general (not\nnecessarily discrete) source requiring only i.i.d. data samples. We estimate\nR-D sandwich bounds on Gaussian and high-dimension banana-shaped sources, as\nwell as GAN-generated images. Our R-D upper bound on natural images indicates\nroom for improving the performance of state-of-the-art image compression\nmethods by 1 dB in PSNR at various bitrates.",
    "descriptor": "",
    "authors": [
      "Yibo Yang",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12166"
  },
  {
    "id": "arXiv:2111.12167",
    "title": "PT-VTON: an Image-Based Virtual Try-On Network with Progressive Pose  Attention Transfer",
    "abstract": "The virtual try-on system has gained great attention due to its potential to\ngive customers a realistic, personalized product presentation in virtualized\nsettings. In this paper, we present PT-VTON, a novel pose-transfer-based\nframework for cloth transfer that enables virtual try-on with arbitrary poses.\nPT-VTON can be applied to the fashion industry within minimal modification of\nexisting systems while satisfying the overall visual fashionability and\ndetailed fabric appearance requirements. It enables efficient clothes\ntransferring between model and user images with arbitrary pose and body shape.\nWe implement a prototype of PT-VTON and demonstrate that our system can match\nor surpass many other approaches when facing a drastic variation of poses by\npreserving detailed human and fabric characteristic appearances. PT-VTON is\nshown to outperform alternative approaches both on machine-based quantitative\nmetrics and qualitative results.",
    "descriptor": "\nComments: Short Version with 4 pages\n",
    "authors": [
      "Hanhan Zhou",
      "Tian Lan",
      "Guru Venkataramani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12167"
  },
  {
    "id": "arXiv:2111.12170",
    "title": "Domain-Agnostic Clustering with Self-Distillation",
    "abstract": "Recent advancements in self-supervised learning have reduced the gap between\nsupervised and unsupervised representation learning. However, most\nself-supervised and deep clustering techniques rely heavily on data\naugmentation, rendering them ineffective for many learning tasks where\ninsufficient domain knowledge exists for performing augmentation. We propose a\nnew self-distillation based algorithm for domain-agnostic clustering. Our\nmethod builds upon the existing deep clustering frameworks and requires no\nseparate student model. The proposed method outperforms existing domain\nagnostic (augmentation-free) algorithms on CIFAR-10. We empirically demonstrate\nthat knowledge distillation can improve unsupervised representation learning by\nextracting richer `dark knowledge' from the model than using predicted labels\nalone. Preliminary experiments also suggest that self-distillation improves the\nconvergence of DeepCluster-v2.",
    "descriptor": "\nComments: NeurIPS 2021 Workshop: Self-Supervised Learning - Theory and Practice\n",
    "authors": [
      "Mohammed Adnan",
      "Yani A. Ioannou",
      "Chuan-Yung Tsai",
      "Graham W. Taylor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12170"
  },
  {
    "id": "arXiv:2111.12172",
    "title": "Multi-label Iterated Learning for Image Classification with Label  Ambiguity",
    "abstract": "Transfer learning from large-scale pre-trained models has become essential\nfor many computer vision tasks. Recent studies have shown that datasets like\nImageNet are weakly labeled since images with multiple object classes present\nare assigned a single label. This ambiguity biases models towards a single\nprediction, which could result in the suppression of classes that tend to\nco-occur in the data. Inspired by language emergence literature, we propose\nmulti-label iterated learning (MILe) to incorporate the inductive biases of\nmulti-label learning from single labels using the framework of iterated\nlearning. MILe is a simple yet effective procedure that builds a multi-label\ndescription of the image by propagating binary predictions through successive\ngenerations of teacher and student networks with a learning bottleneck.\nExperiments show that our approach exhibits systematic benefits on ImageNet\naccuracy as well as ReaL F1 score, which indicates that MILe deals better with\nlabel ambiguity than the standard training procedure, even when fine-tuning\nfrom self-supervised weights. We also show that MILe is effective reducing\nlabel noise, achieving state-of-the-art performance on real-world large-scale\nnoisy data such as WebVision. Furthermore, MILe improves performance in class\nincremental settings such as IIRC and it is robust to distribution shifts.\nCode: https://github.com/rajeswar18/MILe",
    "descriptor": "",
    "authors": [
      "Sai Rajeswar",
      "Pau Rodriguez",
      "Soumye Singhal",
      "David Vazquez",
      "Aaron Courville"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12172"
  },
  {
    "id": "arXiv:2111.12174",
    "title": "Using Distributional Principles for the Semantic Study of Contextual  Language Models",
    "abstract": "Many studies were recently done for investigating the properties of\ncontextual language models but surprisingly, only a few of them consider the\nproperties of these models in terms of semantic similarity. In this article, we\nfirst focus on these properties for English by exploiting the distributional\nprinciple of substitution as a probing mechanism in the controlled context of\nSemCor and WordNet paradigmatic relations. Then, we propose to adapt the same\nmethod to a more open setting for characterizing the differences between static\nand contextual language models.",
    "descriptor": "\nComments: PACLIC 35\n",
    "authors": [
      "Olivier Ferret"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.12174"
  },
  {
    "id": "arXiv:2111.12175",
    "title": "Three-Way Deep Neural Network for Radio Frequency Map Generation and  Source Localization",
    "abstract": "In this paper, we present a Generative Adversarial Network (GAN) machine\nlearning model to interpolate irregularly distributed measurements across the\nspatial domain to construct a smooth radio frequency map (RFMap) and then\nperform localization using a deep neural network. Monitoring wireless spectrum\nover spatial, temporal, and frequency domains will become a critical feature in\nfacilitating dynamic spectrum access (DSA) in beyond-5G and 6G communication\ntechnologies. Localization, wireless signal detection, and spectrum\npolicy-making are several of the applications where distributed spectrum\nsensing will play a significant role. Detection and positioning of wireless\nemitters is a very challenging task in a large spectral and spatial area. In\norder to construct a smooth RFMap database, a large number of measurements are\nrequired which can be very expensive and time consuming. One approach to help\nrealize these systems is to collect finite localized measurements across a\ngiven area and then interpolate the measurement values to construct the\ndatabase. Current methods in the literature employ channel modeling to\nconstruct the radio frequency map, which lacks the granularity for accurate\nlocalization whereas our proposed approach reconstructs a new generalized\nRFMap. Localization results are presented and compared with conventional\nchannel models.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Kuldeep S. Gill",
      "Son Nguyen",
      "Myo M. Thein",
      "Alexander M. Wyglinski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.12175"
  },
  {
    "id": "arXiv:2111.12181",
    "title": "Channel Characterization of Diffusion-based Molecular Communication with  Multiple Fully-absorbing Receivers",
    "abstract": "In this paper an analytical model is introduced to describe the impulse\nresponse of the diffusive channel between a pointwise transmitter and a given\nfully-absorbing (FA) receiver in a molecular communication (MC) system. The\npresence of neighbouring FA nanomachines in the environment is taken into\naccount by describing them as sources of negative molecules. The channel\nimpulse responses of all the receivers are linked in a system of integral\nequations. The solution of the system with two receivers is obtained\nanalytically. For a higher number of receivers the system of integral equations\nis solved numerically. It is also shown that the channel impulse response shape\nis distorted by the presence of the interferers. For instance, there is a time\nshift of the peak in the number of absorbed molecules compared to the case\nwithout interference, as predicted by the proposed model. The analytical\nderivations are validated by means of particle based simulations.",
    "descriptor": "",
    "authors": [
      "Marco Ferrari",
      "Fardad Vakilipoor",
      "Eric Regonesi",
      "Mariangela Rapisarda",
      "Maurizio Magarini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.12181"
  },
  {
    "id": "arXiv:2111.12182",
    "title": "Identifying Terms and Conditions Important to Consumers using  Crowdsourcing",
    "abstract": "Terms and conditions (T&Cs) are pervasive on the web and often contain\nimportant information for consumers, but are rarely read. Previous research has\nexplored methods to surface alarming privacy policies using manual labelers,\nnatural language processing, and deep learning techniques. However, this prior\nwork used pre-determined categories for annotations, and did not investigate\nwhat consumers really deem as important from their perspective. In this paper,\nwe instead combine crowdsourcing with an open definition of \"what is important\"\nin T&Cs. We present a workflow consisting of pairwise comparisons, agreement\nvalidation, and Bradley-Terry rank modeling, to effectively establish rankings\nof T&C statements from non-expert crowdworkers on this open definition, and\nfurther analyzed consumers' preferences. We applied this workflow to 1,551 T&C\nstatements from 27 e-commerce websites, contributed by 3,462 unique crowd\nworkers doing 203,068 pairwise comparisons, and conducted thematic and\nreadability analysis on the statements considered as important/unimportant. We\nfound that consumers especially cared about policies related to after-sales and\nmoney, and tended to regard harder-to-understand statements as more important.\nWe also present machine learning models to identify T&C clauses that consumers\nconsidered important, achieving at best a 92.7% balanced accuracy, 91.6%\nrecall, and 89.2% precision. We foresee using our workflow and model to\nefficiently and reliably highlight important T&Cs on websites at a large scale,\nimproving consumers' awareness",
    "descriptor": "",
    "authors": [
      "Xingyu Liu",
      "Annabel Sun",
      "Jason I. Hong"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.12182"
  },
  {
    "id": "arXiv:2111.12184",
    "title": "Style-Guided Web Application Exploration",
    "abstract": "A wide range of analysis and testing techniques targeting modern web apps\nrely on the automated exploration of their state space by firing events that\nmimic user interactions. However, finding out which elements are actionable in\nweb apps is not a trivial task. To improve the efficacy of exploring the event\nspace of web apps, we propose a browser-independent, instrumentation-free\napproach based on structural and visual stylistic cues. Our approach,\nimplemented in a tool called StyleX, employs machine learning models, trained\non 700,000 web elements from 1,000 real-world websites, to predict actionable\nelements on a webpage a priori. In addition, our approach uses stylistic cues\nfor ranking these actionable elements while exploring the app. Our actionable\npredictor models achieve 90.14\\% precision and 87.76\\% recall when considering\nthe click event listener, and on average, 75.42\\% precision and 77.76\\% recall\nwhen considering the five most-frequent event types. Our evaluations show that\nStyleX can improve the JavaScript code coverage achieved by a general-purpose\ncrawler by up to 23\\%.",
    "descriptor": "",
    "authors": [
      "Davood Mazinanian",
      "Mohammad Bajammal",
      "Ali Mesbah"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.12184"
  },
  {
    "id": "arXiv:2111.12187",
    "title": "Input Convex Gradient Networks",
    "abstract": "The gradients of convex functions are expressive models of non-trivial vector\nfields. For example, Brenier's theorem yields that the optimal transport map\nbetween any two measures on Euclidean space under the squared distance is\nrealized as a convex gradient, which is a key insight used in recent generative\nflow models. In this paper, we study how to model convex gradients by\nintegrating a Jacobian-vector product parameterized by a neural network, which\nwe call the Input Convex Gradient Network (ICGN). We theoretically study ICGNs\nand compare them to taking the gradient of an Input-Convex Neural Network\n(ICNN), empirically demonstrating that a single layer ICGN can fit a toy\nexample better than a single layer ICNN. Lastly, we explore extensions to\ndeeper networks and connections to constructions from Riemannian geometry.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 Optimal Transport and Machine Learning Workshop this https URL\n",
    "authors": [
      "Jack Richter-Powell",
      "Jonathan Lorraine",
      "Brandon Amos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12187"
  },
  {
    "id": "arXiv:2111.12193",
    "title": "Multiset-Equivariant Set Prediction with Approximate Implicit  Differentiation",
    "abstract": "Most set prediction models in deep learning use set-equivariant operations,\nbut they actually operate on multisets. We show that set-equivariant functions\ncannot represent certain functions on multisets, so we introduce the more\nappropriate notion of multiset-equivariance. We identify that the existing Deep\nSet Prediction Network (DSPN) can be multiset-equivariant without being\nhindered by set-equivariance and improve it with approximate implicit\ndifferentiation, allowing for better optimization while being faster and saving\nmemory. In a range of toy experiments, we show that the perspective of\nmultiset-equivariance is beneficial and that our changes to DSPN achieve better\nresults in most cases. On CLEVR object property prediction, we substantially\nimprove over the state-of-the-art Slot Attention from 8% to 77% in one of the\nstrictest evaluation metrics because of the benefits made possible by implicit\ndifferentiation.",
    "descriptor": "",
    "authors": [
      "Yan Zhang",
      "David W. Zhang",
      "Simon Lacoste-Julien",
      "Gertjan J. Burghouts",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12193"
  },
  {
    "id": "arXiv:2111.12197",
    "title": "Fixed Points in Cyber Space: Rethinking Optimal Evasion Attacks in the  Age of AI-NIDS",
    "abstract": "Cyber attacks are increasing in volume, frequency, and complexity. In\nresponse, the security community is looking toward fully automating cyber\ndefense systems using machine learning. However, so far the resultant effects\non the coevolutionary dynamics of attackers and defenders have not been\nexamined. In this whitepaper, we hypothesise that increased automation on both\nsides will accelerate the coevolutionary cycle, thus begging the question of\nwhether there are any resultant fixed points, and how they are characterised.\nWorking within the threat model of Locked Shields, Europe's largest\ncyberdefense exercise, we study blackbox adversarial attacks on network\nclassifiers. Given already existing attack capabilities, we question the\nutility of optimal evasion attack frameworks based on minimal evasion\ndistances. Instead, we suggest a novel reinforcement learning setting that can\nbe used to efficiently generate arbitrary adversarial perturbations. We then\nargue that attacker-defender fixed points are themselves general-sum games with\ncomplex phase transitions, and introduce a temporally extended multi-agent\nreinforcement learning framework in which the resultant dynamics can be\nstudied. We hypothesise that one plausible fixed point of AI-NIDS may be a\nscenario where the defense strategy relies heavily on whitelisted feature flow\nsubspaces. Finally, we demonstrate that a continual learning approach is\nrequired to study attacker-defender dynamics in temporally extended general-sum\ngames.",
    "descriptor": "",
    "authors": [
      "Christian Schroeder de Witt",
      "Yongchao Huang",
      "Philip H.S. Torr",
      "Martin Strohmeier"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12197"
  },
  {
    "id": "arXiv:2111.12202",
    "title": "Combinations of Jaccard with Numerical Measures for Collaborative  Filtering Enhancement: Current Work and Future Proposal",
    "abstract": "Collaborative filtering (CF) is an important approach for recommendation\nsystem which is widely used in a great number of aspects of our life, heavily\nin the online-based commercial systems. One popular algorithms in CF is the\nK-nearest neighbors (KNN) algorithm, in which the similarity measures are used\nto determine nearest neighbors of a user, and thus to quantify the dependency\ndegree between the relative user/item pair. Consequently, CF approach is not\njust sensitive to the similarity measure, yet it is completely contingent on\nselection of that measure. While Jaccard - as one of those commonly used\nsimilarity measures for CF tasks - concerns the existence of ratings, other\nnumerical measures such as cosine and Pearson concern the magnitude of ratings.\nParticularly speaking, Jaccard is not a dominant measure, but it is long proven\nto be an important factor to improve any measure. Therefore, in our continuous\nefforts to find the most effective similarity measures for CF, this research\nfocuses on proposing new similarity measure via combining Jaccard with several\nnumerical measures. The combined measures would take the advantages of both\nexistence and magnitude. Experimental results on, Movie-lens dataset, showed\nthat the combined measures are preeminent outperforming all single measures\nover the considered evaluation metrics.",
    "descriptor": "\nComments: 13 pages, 6 Tables and 2 Figures\n",
    "authors": [
      "Ali A. Amer",
      "Loc Nguyen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12202"
  },
  {
    "id": "arXiv:2111.12204",
    "title": "The Reproducibility of Programming-Related Issues in Stack Overflow  Questions",
    "abstract": "Software developers often look for solutions to their code-level problems\nusing the Stack Overflow Q&A website. To receive help, developers frequently\nsubmit questions containing sample code segments and the description of the\nprogramming issue. Unfortunately, it is not always possible to reproduce the\nissues from the code segments that may impede questions from receiving prompt\nand appropriate solutions. We conducted an exploratory study on the\nreproducibility of issues discussed in 400 Java and 400 Python questions. We\nparsed, compiled, executed, and carefully examined the code segments from these\nquestions to reproduce the reported programming issues. The outcomes of our\nstudy are three-fold. First, we found that we can reproduce approximately 68%\nof Java and 71% of Python issues, whereas we were unable to reproduce\napproximately 22% of Java and 19% of Python issues using the code segments. Of\nthe issues that were reproducible, approximately 67% of the Java code segments\nand 20% of the Python code segments required minor or major modifications to\nreproduce the issues. Second, we carefully investigated why programming issues\ncould not be reproduced and provided evidence-based guidelines for writing\neffective code examples for Stack Overflow questions. Third, we investigated\nthe correlation between the issue reproducibility status of questions and the\ncorresponding answer meta-data, such as the presence of an accepted answer.\nAccording to our analysis, a reproducible question has at least two times\nhigher chance of receiving an accepted answer than an irreproducible question.\nBesides, the median time delay in receiving accepted answers is double if the\nissues reported in questions could not be reproduced. We also investigate the\nconfounding factors (e.g., reputation) and find that confounding factors do not\nhurt the correlation between reproducibility status and answer meta-data.",
    "descriptor": "\nComments: This article is under the minor revision of the EMSE journal\n",
    "authors": [
      "Saikat Mondal",
      "Mohammad Masudur Rahman",
      "Chanchal K. Roy",
      "Kevin Schneider"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.12204"
  },
  {
    "id": "arXiv:2111.12209",
    "title": "Sistema de sensoriamento sem fio aplicavel a deteccao de incendios  florestais",
    "abstract": "In this research work, a hardware and software system is developed that uses\nwireless sensors to monitor environmental variables such as temperature, gas\nconcentration and luminosity, in order to detect the existence of forest fires.\nLora technology was used for wireless sensor networks with communication range\nthat can reach on average up to 5km in urban areas and 10km in rural areas. The\ndeveloped system also has an integrated web application (dashboard) and that in\nreal time, collects data from wireless sensors, which together form the sensor\nmodule, also called device. Then, this data is presented on a map associ- ated\nwith the positioning of each sensor module. The developed system was tested\nusing practical experiments that used flames, gases and lighting, simulating\nthe occurrence of fires. With the tests performed, it was observed the\nfeasibility of the system, hardware/software developed, in detecting the fires\nin the simulated scenarios. Therefore, it was found that the research is\npromising, and may advance in the future for the detection of real fires.",
    "descriptor": "\nComments: in Portuguese\n",
    "authors": [
      "Lucas Santos Goncalves",
      "Celso Barbosa Carvalho"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.12209"
  },
  {
    "id": "arXiv:2111.12210",
    "title": "From Kepler to Newton: the Role of Explainable AI in Science Discovery",
    "abstract": "The research paradigm of the\nObservation--Hypothesis--Prediction--Experimentation loop has been practiced by\nresearchers for years towards scientific discovery. However, with the data\nexplosion in both mega-scale and milli-scale scientific research, it has been\nsometimes very difficult to manually analyze the data and propose new\nhypothesis to drive the cycle for scientific discovery.\nIn this paper, we introduce an Explainable AI-assisted paradigm for science\ndiscovery. The key is to use Explainable AI (XAI) to help derive data or model\ninterpretations and science discoveries. We show how computational and\ndata-intensive methodology -- together with experimental and theoretical\nmethodology -- can be seamlessly integrated for scientific research. To\ndemonstrate the AI-assisted science discovery process, and to pay our respect\nto some of the greatest minds in human history, we show how Kepler's laws of\nplanetary motion and Newton's law of universal gravitation can be rediscovered\nby (explainable) AI based on Tycho Brahe's astronomical observation data, whose\nworks were leading the scientific revolution in the 16-17th century. This work\nalso highlights the importance of Explainable AI (as compared to black-box AI)\nin science discovery to help humans prevent or better prepare for the possible\ntechnological singularity which may happen in the future.",
    "descriptor": "\nComments: 14 pages, 8 figures, 6 tables\n",
    "authors": [
      "Zelong Li",
      "Jianchao Ji",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2111.12210"
  },
  {
    "id": "arXiv:2111.12212",
    "title": "Long-Term CSI-based Design for RIS-Aided Multiuser MISO Systems  Exploiting Deep Reinforcement Learning",
    "abstract": "In this paper, we study the transmission design for reconfigurable\nintelligent surface (RIS)-aided multiuser communication networks. Different\nfrom most of the existing contributions, we consider long-term CSI-based\ntransmission design, where both the beamforming vectors at the base station\n(BS) and the phase shifts at the RIS are designed based on long-term CSI, which\ncan significantly reduce the channel estimation overhead. Due to the lack of\nexplicit ergodic data rate expression, we propose a novel deep deterministic\npolicy gradient (DDPG) based algorithm to solve the optimization problem, which\nwas trained by using the channel vectors generated in an offline manner.\nSimulation results demonstrate that the achievable net throughput is higher\nthan that achieved by the conventional instantaneous-CSI based scheme when\ntaking the channel estimation overhead into account.",
    "descriptor": "\nComments: Under revision in IEEE journal. Keywords: Reconfigurable intelligent surface (RIS), intelligent reflecting surface (IRS)\n",
    "authors": [
      "Hong Ren",
      "Cunhua Pan",
      "Liang Wang",
      "Zhoubing Kou",
      "Kezhi Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.12212"
  },
  {
    "id": "arXiv:2111.12213",
    "title": "Ex-DoF: Expansion of Action Degree-of-Freedom with Virtual Camera  Rotation for Omnidirectional Image",
    "abstract": "Inter-robot transfer of training data is a little explored topic in learning\nand vision-based robot control. Thus, we propose a transfer method from a robot\nwith a lower Degree-of-Freedom (DoF) action to one with a higher DoF utilizing\nan omnidirectional camera. The virtual rotation of the robot camera enables\ndata augmentation in this transfer learning process. In this study, a\nvision-based control policy for a 6-DoF robot was trained using a dataset\ncollected by a differential wheeled ground robot with only three DoFs. Towards\napplication of robotic manipulations, we also demonstrate a control system of a\n6-DoF arm robot using multiple policies with different fields of view to enable\nobject reaching tasks.",
    "descriptor": "\nComments: 8 pages, 9 figures, 2 tables\n",
    "authors": [
      "Kosuke Tahara",
      "Noriaki Hirose"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.12213"
  },
  {
    "id": "arXiv:2111.12217",
    "title": "Scale-Invariant Strength Assortativity of Streaming Butterflies",
    "abstract": "Bipartite graphs are rich data structures with prevalent applications and\nidentifier structural features. However, less is known about their growth\npatterns, particularly in streaming settings. Current works study the patterns\nof static or aggregated temporal graphs optimized for certain down-stream\nanalytics or ignoring multipartite/non-stationary data distributions, emergence\npatterns of subgraphs, and streaming paradigms. To address these, we perform\nstatistical network analysis over web log streams and identify the governing\npatterns underlying the bursty emergence of mesoscopic building blocks,\n2,2-bicliques known as butterflies, leading to a phenomenon that we call\n\"scale-invariant strength assortativity of streaming butterflies\". We provide\nthe graph-theoretic explanation of this phenomenon. We further introduce a set\nof micro-mechanics in the body of a streaming growth algorithm, sGrow, to\npinpoint the generative origins. sGrow supports streaming paradigms, emergence\nof 4-vertex graphlets, and provides user-specified configurations for the\nscale, burstiness, level of strength assortativity, probability of out-of-order\nrecords, generation time, and time-sensitive connections. Comprehensive\nEvaluations on pattern reproducing and stress testing validate the\neffectiveness, efficiency, and robustness of sGrow in realization of the\nobserved patterns independent of initial conditions, scale, temporal\ncharacteristics, and model configurations. Theoretical and experimental\nanalysis verify the robust ability of sGrow in generating streaming graphs\nbased on user-specified configurations that affect the scale and burstiness of\nthe stream, level of strength assortativity, probability of-of-order streaming\nrecords, generation time, and time-sensitive connections.",
    "descriptor": "\nComments: Submitted for publication\n",
    "authors": [
      "Aida Sheshbolouki",
      "M. Tamer \u00d6zsu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)",
      "Discrete Mathematics (cs.DM)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.12217"
  },
  {
    "id": "arXiv:2111.12218",
    "title": "Flexible Pattern Discovery and Analysis",
    "abstract": "Based on the analysis of the proportion of utility in the supporting\ntransactions used in the field of data mining, high utility-occupancy pattern\nmining (HUOPM) has recently attracted widespread attention. Unlike high-utility\npattern mining (HUPM), which involves the enumeration of high-utility (e.g.,\nprofitable) patterns, HUOPM aims to find patterns representing a collection of\nexisting transactions. In practical applications, however, not all patterns are\nused or valuable. For example, a pattern might contain too many items, that is,\nthe pattern might be too specific and therefore lack value for users in real\nlife. To achieve qualified patterns with a flexible length, we constrain the\nminimum and maximum lengths during the mining process and introduce a novel\nalgorithm for the mining of flexible high utility-occupancy patterns. Our\nalgorithm is referred to as HUOPM+. To ensure the flexibility of the patterns\nand tighten the upper bound of the utility-occupancy, a strategy called the\nlength upper-bound (LUB) is presented to prune the search space. In addition, a\nutility-occupancy nested list (UO-nlist) and a frequency-utility-occupancy\ntable (FUO-table) are employed to avoid multiple scans of the database.\nEvaluation results of the subsequent experiments confirm that the proposed\nalgorithm can effectively control the length of the derived patterns, for both\nreal-world and synthetic datasets. Moreover, it can decrease the execution time\nand memory consumption.",
    "descriptor": "\nComments: Preprint. 10 figures, 4 tables\n",
    "authors": [
      "Chien-Ming Chen",
      "Lili Chen",
      "Wensheng Gan"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12218"
  },
  {
    "id": "arXiv:2111.12221",
    "title": "Source-free unsupervised domain adaptation for cross-modality abdominal  multi-organ segmentation",
    "abstract": "It is valuable to achieve domain adaptation to transfer the learned knowledge\nfrom the source labeled CT dataset to the target unlabeled MR dataset for\nabdominal multi-organ segmentation. Meanwhile, it is highly desirable to avoid\nhigh annotation cost of target dataset and protect privacy of source dataset.\nTherefore, we propose an effective source-free unsupervised domain adaptation\nmethod for cross-modality abdominal multi-organ segmentation without accessing\nthe source dataset. The process of the proposed framework includes two stages.\nAt the first stage, the feature map statistics loss is used to align the\ndistributions of the source and target features in the top segmentation\nnetwork, and entropy minimization loss is used to encourage high confidence\nsegmentations. The pseudo-labels outputted from the top segmentation network is\nused to guide the style compensation network to generate source-like images.\nThe pseudo-labels outputted from the middle segmentation network is used to\nsupervise the learning of the desired model (the bottom segmentation network).\nAt the second stage, the circular learning and the pixel-adaptive mask\nrefinement are used to further improve the performance of the desired model.\nWith this approach, we achieve satisfactory performances on the segmentations\nof liver, right kidney, left kidney, and spleen with the dice similarity\ncoefficients of 0.884, 0.891, 0.864, and 0.911, respectively. In addition, the\nproposed approach can be easily extended to the situation when there exists\ntarget annotation data. The performance improves from 0.888 to 0.922 in average\ndice similarity coefficient, close to the supervised learning (0.929), with\nonly one labeled MR volume.",
    "descriptor": "",
    "authors": [
      "Jin Hong",
      "Yu-Dong Zhang",
      "Weitian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12221"
  },
  {
    "id": "arXiv:2111.12229",
    "title": "Subspace Adversarial Training",
    "abstract": "Single-step adversarial training (AT) has received wide attention as it\nproved to be both efficient and robust. However, a serious problem of\ncatastrophic overfitting exists, i.e., the robust accuracy against projected\ngradient descent (PGD) attack suddenly drops to $0\\%$ during the training. In\nthis paper, we understand this problem from a novel perspective of optimization\nand firstly reveal the close link between the fast-growing gradient of each\nsample and overfitting, which can also be applied to understand the robust\noverfitting phenomenon in multi-step AT. To control the growth of the gradient\nduring the training, we propose a new AT method, subspace adversarial training\n(Sub-AT), which constrains the AT in a carefully extracted subspace. It\nsuccessfully resolves both two kinds of overfitting and hence significantly\nboosts the robustness. In subspace, we also allow single-step AT with larger\nsteps and larger radius, which further improves the robustness performance. As\na result, we achieve the state-of-the-art single-step AT performance: our pure\nsingle-step AT can reach over $\\mathbf{51}\\%$ robust accuracy against strong\nPGD-50 attack with radius $8/255$ on CIFAR-10, even surpassing the standard\nmulti-step PGD-10 AT with huge computational advantages. The code is\nreleased$\\footnote{\\url{https://github.com/nblt/Sub-AT}}$.",
    "descriptor": "",
    "authors": [
      "Tao Li",
      "Yingwen Wu",
      "Sizhe Chen",
      "Kun Fang",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12229"
  },
  {
    "id": "arXiv:2111.12231",
    "title": "Universal Deep Network for Steganalysis of Color Image based on Channel  Representation",
    "abstract": "Up to now, most existing steganalytic methods are designed for grayscale\nimages, and they are not suitable for color images that are widely used in\ncurrent social networks. In this paper, we design a universal color image\nsteganalysis network (called UCNet) in spatial and JPEG domains. The proposed\nmethod includes preprocessing, convolutional, and classification modules. To\npreserve the steganographic artifacts in each color channel, in preprocessing\nmodule, we firstly separate the input image into three channels according to\nthe corresponding embedding spaces (i.e. RGB for spatial steganography and\nYCbCr for JPEG steganography), and then extract the image residuals with 62\nfixed high-pass filters, finally concatenate all truncated residuals for\nsubsequent analysis rather than adding them together with normal convolution\nlike existing CNN-based steganalyzers. To accelerate the network convergence\nand effectively reduce the number of parameters, in convolutional module, we\ncarefully design three types of layers with different shortcut connections and\ngroup convolution structures to further learn high-level steganalytic features.\nIn classification module, we employ a global average pooling and fully\nconnected layer for classification. We conduct extensive experiments on ALASKA\nII to demonstrate that the proposed method can achieve state-of-the-art results\ncompared with the modern CNN-based steganalyzers (e.g., SRNet and J-YeNet) in\nboth spatial and JPEG domains, while keeping relatively few memory requirements\nand training time. Furthermore, we also provide necessary descriptions and many\nablation experiments to verify the rationality of the network design.",
    "descriptor": "\nComments: To be improved version\n",
    "authors": [
      "Kangkang Wei",
      "Weiqi Luo",
      "Shunquan Tan",
      "Jiwu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.12231"
  },
  {
    "id": "arXiv:2111.12232",
    "title": "PMSSC: Parallelizable Multi-Subset based Self-Expressive Model for  Subspace Clustering",
    "abstract": "Subspace clustering methods embrace a self-expressive model that represents\neach data point as a linear combination of other data points in the dataset are\npowerful unsupervised learning techniques. However, when dealing with\nlarge-scale datasets, the representation of each data point by referring to all\ndata points as a dictionary suffers from high computational complexity. To\nalleviate this issue, we introduce a parallelizable multi-subset based\nself-expressive model (PMS) which represents each data point by combing\nmultiple subsets, with each consisting of only a small percentage of samples.\nThe adoption of PMS in subspace clustering (PMSSC) leads to computational\nadvantages because each optimization problem decomposed into each subset is\nsmall, and can be solved efficiently in parallel. Besides, PMSSC is able to\ncombine multiple self-expressive coefficient vectors obtained from subsets,\nwhich contributes to the improvement of self-expressiveness. Extensive\nexperiments on synthetic data and real-world datasets show the efficiency and\neffectiveness of our approach against competitive methods.",
    "descriptor": "",
    "authors": [
      "Katsuya Hotta",
      "Takuya Akashi",
      "Shogo Tokai",
      "Chao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12232"
  },
  {
    "id": "arXiv:2111.12233",
    "title": "Scaling Up Vision-Language Pre-training for Image Captioning",
    "abstract": "In recent years, we have witnessed significant performance boost in the image\ncaptioning task based on vision-language pre-training (VLP). Scale is believed\nto be an important factor for this advance. However, most existing work only\nfocuses on pre-training transformers with moderate sizes (e.g., 12 or 24\nlayers) on roughly 4 million images. In this paper, we present LEMON, a\nLargE-scale iMage captiONer, and provide the first empirical study on the\nscaling behavior of VLP for image captioning. We use the state-of-the-art VinVL\nmodel as our reference model, which consists of an image feature extractor and\na transformer model, and scale the transformer both up and down, with model\nsizes ranging from 13 to 675 million parameters. In terms of data, we conduct\nexperiments with up to 200 million image-text pairs which are automatically\ncollected from web based on the alt attribute of the image (dubbed as ALT200M).\nExtensive analysis helps to characterize the performance trend as the model\nsize and the pre-training data size increase. We also compare different\ntraining recipes, especially for training on large-scale noisy data. As a\nresult, LEMON achieves new state of the arts on several major image captioning\nbenchmarks, including COCO Caption, nocaps, and Conceptual Captions. We also\nshow LEMON can generate captions with long-tail visual concepts when used in a\nzero-shot manner.",
    "descriptor": "",
    "authors": [
      "Xiaowei Hu",
      "Zhe Gan",
      "Jianfeng Wang",
      "Zhengyuan Yang",
      "Zicheng Liu",
      "Yumao Lu",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.12233"
  },
  {
    "id": "arXiv:2111.12238",
    "title": "Composing Loop-carried Dependence with Other Loops",
    "abstract": "Sparse fusion is a compile-time loop transformation and runtime scheduling\nimplemented as a domain-specific code generator. Sparse fusion generates\nefficient parallel code for the combination of two sparse matrix kernels where\nat least one of the kernels has loop-carried dependencies. Available\nimplementations optimize individual sparse kernels. When optimized separately,\nthe irregular dependence patterns of sparse kernels create synchronization\noverheads and load imbalance, and their irregular memory access patterns result\nin inefficient cache usage, which reduces parallel efficiency. Sparse fusion\nuses a novel inspection strategy with code transformations to generate parallel\nfused code for sparse kernel combinations that is optimized for data locality\nand load balance. Code generated by Sparse fusion outperforms the existing\nimplementations ParSy and MKL on average 1.6X and 5.1X respectively and\noutperforms the LBC and DAGP coarsening strategies applied to a fused data\ndependence graph on average 5.1X and 7.2X respectively for various kernel\ncombinations.",
    "descriptor": "",
    "authors": [
      "Kazem Cheshmi",
      "Michelle Mills Strout",
      "Maryam Mehri Dehnavi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.12238"
  },
  {
    "id": "arXiv:2111.12239",
    "title": "Harmonic Centrality of Some Graph Families",
    "abstract": "One of the more recent measures of centrality in social network analysis is\nthe normalized harmonic centrality. A variant of the closeness centrality,\nharmonic centrality sums the inverse of the geodesic distances of each node to\nother nodes where it is 0 if there is no path from one node to another. It is\nthen normalized by dividing it by m-1, where m is the number of nodes of the\ngraph. In this paper, we present notions regarding the harmonic centrality of\nsome important classes of graphs.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Jose Mari E. Ortega",
      "Rolito G. Eballe"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.12239"
  },
  {
    "id": "arXiv:2111.12241",
    "title": "Hierarchical Federated Learning based Anomaly Detection using Digital  Twins for Smart Healthcare",
    "abstract": "Internet of Medical Things (IoMT) is becoming ubiquitous with a proliferation\nof smart medical devices and applications used in smart hospitals, smart-home\nbased care, and nursing homes.It utilizes smart medical devices and cloud\ncomputing services along with core Internet of Things (IoT) technologies to\nsense patients' vital body parameters, monitor health conditions and generate\nmultivariate data to support just-in-time health services. Mostly, this large\namount of data is analyzed in centralized servers. Anomaly Detection (AD) in a\ncentralized healthcare ecosystem is often plagued by significant delays in\nresponse time with high performance overhead. Moreover, there are inherent\nprivacy issues associated with sending patients' personal health data to a\ncentralized server, which may also introduce several security threats to the AD\nmodel, such as possibility of data poisoning. To overcome these issues with\ncentralized AD models, here we propose a Federated Learning (FL) based AD model\nwhich utilizes edge cloudlets to run AD models locally without sharing\npatients' data. Since existing FL approaches perform aggregation on a single\nserver which restricts the scope of FL, in this paper, we introduce a\nhierarchical FL that allows aggregation at different levels enabling\nmulti-party collaboration. We introduce a novel disease-based grouping\nmechanism where different AD models are grouped based on specific types of\ndiseases. Furthermore, we develop a new Federated Time Distributed (FedTimeDis)\nLong Short-Term Memory (LSTM) approach to train the AD model. We present a\nRemote Patient Monitoring (RPM) use case to demonstrate our model, and\nillustrate a proof-of-concept implementation using Digital Twin (DT) and edge\ncloudlets.",
    "descriptor": "",
    "authors": [
      "Deepti Gupta",
      "Olumide Kayode",
      "Smriti Bhatt",
      "Maanak Gupta",
      "Ali Saman Tosun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.12241"
  },
  {
    "id": "arXiv:2111.12242",
    "title": "PU-Transformer: Point Cloud Upsampling Transformer",
    "abstract": "Given the rapid development of 3D scanners, point clouds are becoming popular\nin AI-driven machines. However, point cloud data is inherently sparse and\nirregular, causing major difficulties for machine perception. In this work, we\nfocus on the point cloud upsampling task that intends to generate dense\nhigh-fidelity point clouds from sparse input data. Specifically, to activate\nthe transformer's strong capability in representing features, we develop a new\nvariant of a multi-head self-attention structure to enhance both point-wise and\nchannel-wise relations of the feature map. In addition, we leverage a\npositional fusion block to comprehensively capture the local context of point\ncloud data, providing more position-related information about the scattered\npoints. As the first transformer model introduced for point cloud upsampling,\nwe demonstrate the outstanding performance of our approach by comparing with\nthe state-of-the-art CNN-based methods on different benchmarks quantitatively\nand qualitatively.",
    "descriptor": "",
    "authors": [
      "Shi Qiu",
      "Saeed Anwar",
      "Nick Barnes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12242"
  },
  {
    "id": "arXiv:2111.12243",
    "title": "Differentiating-based Vectorization for Sparse Kernels",
    "abstract": "Sparse computations frequently appear in scientific simulations and the\nperformance of these simulations rely heavily on the optimization of the sparse\ncodes. The compact data structures and irregular computation patterns in sparse\nmatrix computations introduce challenges to vectorizing these codes. Available\napproaches primarily vectorize regular regions of computations in the sparse\ncode. They also reorganize data and computations, at a cost, to increase the\nnumber of regular regions. In this work, we propose a novel polyhedral model,\ncalled the partially strided codelets (PSC), that enables the vectorization of\ncomputation regions with irregular data access patterns. PSCs also improve data\nlocality in sparse computation. Our DDF inspector-executor framework\nefficiently mines the memory accesses in the sparse computation, using an\naccess function differentiation approach, to find PSC codelets. It generates\nvectorized code for the sparse matrix multiplication kernel (SpMV), a kernel\nwith parallel outer loops, and for kernels with carried dependence,\nspecifically the sparse triangular solver (SpTRSV). We demonstrate the\nperformance of the DDF-generated code on a set of 60 large and small matrices\n(0.05-130M nonzeros). DDF outperforms the highly specialized library MKL with\nan average speedup of 1.93 and 4.5X for SpMV and SpTRSV, respectively. For the\nsame matrices, DDF outperforms the state-of-the-art inspector-executor\nframework Sympiler [1] for the SpTRSV kernel by up to 11X and the work by\nAugustine et. al [2] for the SpMV kernel by up to 12X.",
    "descriptor": "",
    "authors": [
      "Zachary Cetinic",
      "Kazem Cheshmi",
      "Maryam Mehri Dehnavi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.12243"
  },
  {
    "id": "arXiv:2111.12253",
    "title": "Third-party Service Dependencies and Centralization Around the World",
    "abstract": "There is a growing concern about consolidation trends in Internet services,\nwith, for instance, a large fraction of popular websites depending on a handful\nof third-party service providers. In this paper, we report on a large-scale\nstudy of third-party dependencies around the world, using vantage points from\n50 countries, from all inhabited continents, and regional top-500 popular\nwebsites.This broad perspective shows that dependencies vary widely around the\nworld. We find that between 15% and as much as 80% of websites, across all\ncountries, depend on a DNS, CDN or CA third-party provider.Sites critical\ndependencies, while lower, are equally spread ranging from 9% and 61% (CDN and\nDNS in China, respectively).Despite this high variability, our results suggest\na highly concentrated market of third-party providers: three third-party\nproviders across all countries serve an average of 91.2% and Google, by itself,\nserves an average of 72% of the surveyed websites. We explore various factors\nthat may help explain the differences and similarities in degrees of\nthird-party dependency across countries, including economic conditions,\nInternet development, language, and economic trading partners.",
    "descriptor": "\nComments: 17 pages, 14 figures\n",
    "authors": [
      "Rashna Kumar",
      "Sana Asif",
      "Elise Lee",
      "Fabi'an E. Bustamante"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.12253"
  },
  {
    "id": "arXiv:2111.12255",
    "title": "A Family of Independent Variable Eddington Factor Methods with Efficient  Linear Solvers",
    "abstract": "We present a family of discretizations for the Variable Eddington Factor\n(VEF) equations that have high-order accuracy on curved meshes and efficient\npreconditioned iterative solvers. The VEF discretizations are combined with a\nhigh-order Discontinuous Galerkin transport discretization to form an effective\nhigh-order, linear transport method. The VEF discretizations are derived by\nextending the unified analysis of Discontinuous Galerkin methods for elliptic\nproblems to the VEF equations. This framework is used to define analogs of the\ninterior penalty, second method of Bassi and Rebay, minimal dissipation local\nDiscontinuous Galerkin, and continuous finite element methods. The analysis of\nsubspace correction preconditioners, which use a continuous operator to\niteratively precondition the discontinuous discretization, is extended to the\ncase of the non-symmetric VEF system. Numerical results demonstrate that the\nVEF discretizations have arbitrary-order accuracy on curved meshes, preserve\nthe thick diffusion limit, and are effective on a proxy problem from thermal\nradiative transfer in both outer transport iterations and inner preconditioned\nlinear solver iterations. In addition, a parallel weak scaling study of the\ninterior penalty VEF discretization demonstrates the scalability of the method\nout to 1152 processors.",
    "descriptor": "",
    "authors": [
      "Samuel Olivier",
      "Will Pazner",
      "Terry S. Haut",
      "Ben C. Yee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.12255"
  },
  {
    "id": "arXiv:2111.12256",
    "title": "ACD-EDMD: Analytical Construction for Dictionaries of Lifting Functions  in Koopman Operator-based Nonlinear Robotic Systems",
    "abstract": "Koopman operator theory has been gaining momentum for model extraction,\nplanning, and control of data-driven robotic systems. The Koopman operator's\nability to extract dynamics from data depends heavily on the selection of an\nappropriate dictionary of lifting functions. In this paper we propose ACD-EDMD,\na new method for Analytical Construction of Dictionaries of appropriate lifting\nfunctions for a range of data-driven Koopman operator based nonlinear robotic\nsystems. The key insight of this work is that information about fundamental\ntopological spaces of the nonlinear system (such as its configuration space and\nworkspace) can be exploited to steer the construction of Hermite\npolynomial-based lifting functions. We show that the proposed method leads to\ndictionaries that are simple to implement while enjoying provable completeness\nand convergence guarantees when observables are weighted bounded. We evaluate\nACD-EDMD using a range of diverse nonlinear robotic systems in both simulated\nand physical hardware experimentation (a wheeled mobile robot, a\ntwo-revolute-joint robotic arm, and a soft robotic leg). Results reveal that\nour method leads to dictionaries that enable high-accuracy prediction and that\ncan generalize to diverse validation sets. The associated GitHub repository of\nour algorithm can be accessed at\n\\url{https://github.com/UCR-Robotics/ACD-EDMD}.",
    "descriptor": "\nComments: Accepted to IEEE Robotics and Automation Letters (RA-L), November 2021\n",
    "authors": [
      "Lu Shi",
      "Konstantinos Karydis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.12256"
  },
  {
    "id": "arXiv:2111.12257",
    "title": "Post-Quantum Zero Knowledge, Revisited (or: How to Do Quantum Rewinding  Undetectably)",
    "abstract": "A major difficulty in quantum rewinding is the fact that measurement is\ndestructive: extracting information from a quantum state irreversibly changes\nit. This is especially problematic in the context of zero-knowledge simulation,\nwhere preserving the adversary's state is essential.\nIn this work, we develop new techniques for quantum rewinding in the context\nof extraction and zero-knowledge simulation:\n(1) We show how to extract information from a quantum adversary by rewinding\nit without disturbing its internal state. We use this technique to prove that\nimportant interactive protocols, such as the Goldreich-Micali-Wigderson\nprotocol for graph non-isomorphism and the Feige-Shamir protocol for NP, are\nzero-knowledge against quantum adversaries.\n(2) We prove that the Goldreich-Kahan protocol for NP is post-quantum zero\nknowledge using a simulator that can be seen as a natural quantum extension of\nthe classical simulator.\nOur results achieve (constant-round) black-box zero-knowledge with negligible\nsimulation error, appearing to contradict a recent impossibility result due to\nChia-Chung-Liu-Yamakawa (FOCS 2021). This brings us to our final contribution:\n(3) We introduce coherent-runtime expected quantum polynomial time, a\ncomputational model that (a) captures all of our zero-knowledge simulators, (b)\ncannot break any polynomial hardness assumptions, and (c) is not subject to the\nCCLY impossibility. In light of our positive results and the CCLY negative\nresults, we propose coherent-runtime simulation to be the right quantum\nanalogue of classical expected polynomial-time simulation.",
    "descriptor": "\nComments: 96 pages, 9 figures\n",
    "authors": [
      "Alex Lombardi",
      "Fermi Ma",
      "Nicholas Spooner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.12257"
  },
  {
    "id": "arXiv:2111.12262",
    "title": "Reinforcement Learning based Path Exploration for Sequential Explainable  Recommendation",
    "abstract": "Recent advances in path-based explainable recommendation systems have\nattracted increasing attention thanks to the rich information provided by\nknowledge graphs. Most existing explainable recommendations only utilize static\nknowledge graphs and ignore the dynamic user-item evolutions, leading to less\nconvincing and inaccurate explanations. Although there are some works that\nrealize that modelling user's temporal sequential behaviour could boost the\nperformance and explainability of the recommender systems, most of them either\nonly focus on modelling user's sequential interactions within a path or\nindependently and separately of the recommendation mechanism. In this paper, we\npropose a novel Temporal Meta-path Guided Explainable Recommendation leveraging\nReinforcement Learning (TMER-RL), which utilizes reinforcement item-item path\nmodelling between consecutive items with attention mechanisms to sequentially\nmodel dynamic user-item evolutions on dynamic knowledge graph for explainable\nrecommendation. Compared with existing works that use heavy recurrent neural\nnetworks to model temporal information, we propose simple but effective neural\nnetworks to capture users' historical item features and path-based context to\ncharacterize the next purchased item. Extensive evaluations of TMER on two\nreal-world datasets show state-of-the-art performance compared against recent\nstrong baselines.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2101.01433\n",
    "authors": [
      "Yicong Li",
      "Hongxu Chen",
      "Yile Li",
      "Lin Li",
      "Philip S. Yu",
      "Guandong Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12262"
  },
  {
    "id": "arXiv:2111.12263",
    "title": "APANet: Adaptive Prototypes Alignment Network for Few-Shot Semantic  Segmentation",
    "abstract": "Few-shot semantic segmentation aims to segment novel-class objects in a given\nquery image with only a few labeled support images. Most advanced solutions\nexploit a metric learning framework that performs segmentation through matching\neach query feature to a learned class-specific prototype. However, this\nframework suffers from biased classification due to incomplete feature\ncomparisons. To address this issue, we present an adaptive prototype\nrepresentation by introducing class-specific and class-agnostic prototypes and\nthus construct complete sample pairs for learning semantic alignment with query\nfeatures. The complementary features learning manner effectively enriches\nfeature comparison and helps yield an unbiased segmentation model in the\nfew-shot setting. It is implemented with a two-branch end-to-end network (\\ie,\na class-specific branch and a class-agnostic branch), which generates\nprototypes and then combines query features to perform comparisons. In\naddition, the proposed class-agnostic branch is simple yet effective. In\npractice, it can adaptively generate multiple class-agnostic prototypes for\nquery images and learn feature alignment in a self-contrastive manner.\nExtensive experiments on PASCAL-5$^i$ and COCO-20$^i$ demonstrate the\nsuperiority of our method. At no expense of inference efficiency, our model\nachieves state-of-the-art results in both 1-shot and 5-shot settings for\nsemantic segmentation.",
    "descriptor": "\nComments: 11 pages, Submitted to IEEE TMM. arXiv admin note: substantial text overlap with arXiv:2104.09216\n",
    "authors": [
      "Jiacheng Chen",
      "Bin-Bin Gao",
      "Zongqing Lu",
      "Jing-Hao Xue",
      "Chengjie Wang",
      "Qingmin Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12263"
  },
  {
    "id": "arXiv:2111.12264",
    "title": "Pixel-wise Energy-biased Abstention Learning for Anomaly Segmentation on  Complex Urban Driving Scenes",
    "abstract": "State-of-the-art (SOTA) anomaly segmentation approaches on complex urban\ndriving scenes explore pixel-wise classification uncertainty learned from\noutlier exposure, or external reconstruction models. However, previous\nuncertainty approaches that directly associate high uncertainty to anomaly may\nsometimes lead to incorrect anomaly predictions, and external reconstruction\nmodels tend to be too inefficient for real-time self-driving embedded systems.\nIn this paper, we propose a new anomaly segmentation method, named pixel-wise\nenergy-biased abstention learning (PEBAL), that explores pixel-wise abstention\nlearning (AL) with a model that learns an adaptive pixel-level anomaly class,\nand an energy-based model (EBM) that learns inlier pixel distribution. More\nspecifically, PEBAL is based on a non-trivial joint training of EBM and AL,\nwhere EBM is trained to output high-energy for anomaly pixels (from outlier\nexposure) and AL is trained such that these high-energy pixels receive adaptive\nlow penalty for being included to the anomaly class. We extensively evaluate\nPEBAL against the SOTA and show that it achieves the best performance across\nfour benchmarks. Code is available at https://github.com/tianyu0207/PEBAL.",
    "descriptor": "",
    "authors": [
      "Yu Tian",
      "Yuyuan Liu",
      "Guansong Pang",
      "Fengbei Liu",
      "Yuanhong Chen",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12264"
  },
  {
    "id": "arXiv:2111.12265",
    "title": "Distribution Estimation to Automate Transformation Policies for  Self-Supervision",
    "abstract": "In recent visual self-supervision works, an imitated classification\nobjective, called pretext task, is established by assigning labels to\ntransformed or augmented input images. The goal of pretext can be predicting\nwhat transformations are applied to the image. However, it is observed that\nimage transformations already present in the dataset might be less effective in\nlearning such self-supervised representations. Building on this observation, we\npropose a framework based on generative adversarial network to automatically\nfind the transformations which are not present in the input dataset and thus\neffective for the self-supervised learning. This automated policy allows to\nestimate the transformation distribution of a dataset and also construct its\ncomplementary distribution from which training pairs are sampled for the\npretext task. We evaluated our framework using several visual recognition\ndatasets to show the efficacy of our automated transformation policy.",
    "descriptor": "\nComments: NeurIPS 2021 Workshop: Self-Supervised Learning - Theory and Practice\n",
    "authors": [
      "Seunghan Yang",
      "Debasmit Das",
      "Simyung Chang",
      "Sungrack Yun",
      "Fatih Porikli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12265"
  },
  {
    "id": "arXiv:2111.12273",
    "title": "Sharpness-aware Quantization for Deep Neural Networks",
    "abstract": "Network quantization is an effective compression method to reduce the model\nsize and computational cost. Despite the high compression ratio, training a\nlow-precision model is difficult due to the discrete and non-differentiable\nnature of quantization, resulting in considerable performance degradation.\nRecently, Sharpness-Aware Minimization (SAM) is proposed to improve the\ngeneralization performance of the models by simultaneously minimizing the loss\nvalue and the loss curvature. In this paper, we devise a Sharpness-Aware\nQuantization (SAQ) method to train quantized models, leading to better\ngeneralization performance. Moreover, since each layer contributes differently\nto the loss value and the loss sharpness of a network, we further devise an\neffective method that learns a configuration generator to automatically\ndetermine the bitwidth configurations of each layer, encouraging lower bits for\nflat regions and vice versa for sharp landscapes, while simultaneously\npromoting the flatness of minima to enable more aggressive quantization.\nExtensive experiments on CIFAR-100 and ImageNet show the superior performance\nof the proposed methods. For example, our quantized ResNet-18 with 55.1x\nBit-Operation (BOP) reduction even outperforms the full-precision one by 0.7%\nin terms of the Top-1 accuracy. Code is available at\nhttps://github.com/zhuang-group/SAQ.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Jing Liu",
      "Jianfei Cai",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12273"
  },
  {
    "id": "arXiv:2111.12274",
    "title": "Formalization of Bond Graph using Higher-order-logic Theorem Proving",
    "abstract": "Bond graph is a unified graphical approach for describing the dynamics of\ncomplex engineering and physical systems and is widely adopted in a variety of\ndomains, such as, electrical, mechanical, medical, thermal and fluid mechanics.\nTraditionally, these dynamics are analyzed using paper-and-pencil proof methods\nand computer-based techniques. However, both of these techniques suffer from\ntheir inherent limitations, such as human-error proneness, approximations of\nresults and enormous computational requirements. Thus, these techniques cannot\nbe trusted for performing the bond graph based dynamical analysis of systems\nfrom the safety-critical domains like robotics and medicine. Formal methods, in\nparticular, higher-order-logic theorem proving, can overcome the shortcomings\nof these traditional methods and provide an accurate analysis of these systems.\nIt has been widely used for analyzing the dynamics of engineering and physical\nsystems. In this paper, we propose to use higher-order-logic theorem proving\nfor performing the bond graph based analysis of the physical systems. In\nparticular, we provide formalization of bond graph, which mainly includes\nfunctions that allow conversion of a bond graph to its corresponding\nmathematical model (state-space model) and the verification of its various\nproperties, such as, stability. To illustrate the practical effectiveness of\nour proposed approach, we present the formal stability analysis of a prosthetic\nmechatronic hand using HOL Light theorem prover. Moreover, to help non-experts\nin HOL, we encode our formally verified stability theorems in MATLAB to perform\nthe stability analysis of an anthropomorphic prosthetic mechatronic hand.",
    "descriptor": "\nComments: ISA Transactions, Elsevier\n",
    "authors": [
      "Ujala Qasim",
      "Adnan Rashid",
      "Osman Hasan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.12274"
  },
  {
    "id": "arXiv:2111.12276",
    "title": "Utilizing Resource-Rich Language Datasets for End-to-End Scene Text  Recognition in Resource-Poor Languages",
    "abstract": "This paper presents a novel training method for end-to-end scene text\nrecognition. End-to-end scene text recognition offers high recognition\naccuracy, especially when using the encoder-decoder model based on Transformer.\nTo train a highly accurate end-to-end model, we need to prepare a large\nimage-to-text paired dataset for the target language. However, it is difficult\nto collect this data, especially for resource-poor languages. To overcome this\ndifficulty, our proposed method utilizes well-prepared large datasets in\nresource-rich languages such as English, to train the resource-poor\nencoder-decoder model. Our key idea is to build a model in which the encoder\nreflects knowledge of multiple languages while the decoder specializes in\nknowledge of just the resource-poor language. To this end, the proposed method\npre-trains the encoder by using a multilingual dataset that combines the\nresource-poor language's dataset and the resource-rich language's dataset to\nlearn language-invariant knowledge for scene text recognition. The proposed\nmethod also pre-trains the decoder by using the resource-poor language's\ndataset to make the decoder better suited to the resource-poor language.\nExperiments on Japanese scene text recognition using a small, publicly\navailable dataset demonstrate the effectiveness of the proposed method.",
    "descriptor": "\nComments: Accept as short paper at ACM MMAsia 2021\n",
    "authors": [
      "Shota Orihashi",
      "Yoshihiro Yamazaki",
      "Naoki Makishima",
      "Mana Ihori",
      "Akihiko Takashima",
      "Tomohiro Tanaka",
      "Ryo Masumura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12276"
  },
  {
    "id": "arXiv:2111.12278",
    "title": "An efficient estimation of nested expectations without conditional  sampling",
    "abstract": "Estimating nested expectations is an important task in computational\nmathematics and statistics. In this paper we propose a new Monte Carlo method\nusing post-stratification to estimate nested expectations efficiently without\ntaking samples of the inner random variable from the conditional distribution\ngiven the outer random variable. This property provides the advantage over many\nexisting methods that it enables us to estimate nested expectations only with a\ndataset on the pair of the inner and outer variables drawn from the joint\ndistribution. We show an upper bound on the mean squared error of the proposed\nmethod under some assumptions. Numerical experiments are conducted to compare\nour proposed method with several existing methods (nested Monte Carlo method,\nmultilevel Monte Carlo method, and regression-based method), and we see that\nour proposed method is superior to the compared methods in terms of efficiency\nand applicability.",
    "descriptor": "",
    "authors": [
      "Tomohiko Hironaka",
      "Takashi Goda"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12278"
  },
  {
    "id": "arXiv:2111.12281",
    "title": "Locality-based Graph Reordering for Processing Speed-Ups and Impact of  Diameter",
    "abstract": "Graph analysis involves a high number of random memory access patterns.\nEarlier research has shownthat the cache miss latency is responsible for more\nthan half of the graph processing time, with the CPU execution having the\nsmaller share. There has been significant study on decreasing the CPU computing\ntime for example, by employing better cache prefetching and replacement\npolicies. In thispaper, we study the various methods that do so by attempting\nto decrease the CPU cache miss ratio.Graph Reordering attempts to exploit the\npower-law distribution of graphs- few sparsely-populated vertices in the graph\nhave high number of connections- to keep the frequently accessed vertices\ntogether locally and hence decrease the cache misses. However, reordering the\ngraph by keeping the hot vertices together may affect the spatial locality of\nthe graph, and thus add to the total CPU compute time.Also, we also need to\nhave a control over the total reordering time and its inverse relation with\nthefinal CPU execution timeIn order to exploit this trade-off between\nreordering as per vertex hotness and spatial locality, we introduce the\nlight-weight Community-based Reordering. We attempt to maintain the\ncommunity-structureof the graph by storing the hot-members in the community\nlocally together. The implementation also takes into consideration the impact\nof graph diameter on the execution time. We compare our implementation with\nother reordering implementations and find a significantly better result on five\ngraph processing algorithms- BFS, CC, CCSV, PR and BC. Lorder achieved speed-up\nof upto 7x and an average speed-up of 1.2x as compared to other reordering\nalgorithms",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Vedant Satav",
      "Virendra Singh"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.12281"
  },
  {
    "id": "arXiv:2111.12282",
    "title": "Self-orthogonality matrix and Reed-Muller code",
    "abstract": "Kim et al. (2021) gave a method to embed a given binary $[n,k]$ code\n$\\mathcal{C}$ $(k = 3, 4)$ into a self-orthogonal code of the shortest length\nwhich has the same dimension $k$ and minimum distance $d' \\ge d(\\mathcal{C})$.\nWe extends this result for $k=5$ and $6$ by proposing a new method related to a\nspecial matrix, called the self-orthogonality matrix $SO_k$, obtained by\nshortnening a Reed-Muller code $\\mathcal{R}(2,k)$. Furthermore, we disprove\npartially the conjecture (Kim et al. (2021)) by showing that if $31 \\le n \\le\n256$ and $n\\equiv 14,22,29 \\pmod{31}$, then there exist optimal $[n,5]$ codes\nwhich are self-orthogonal. We also construct optimal self-orthogonal $[n,6]$\ncodes when $41 \\le n \\le 256$ satisfies $n \\ne 46, 54, 61$ and $n \\not\\equiv 7,\n14, 22, 29, 38, 45, 53, 60 \\pmod{63}$.",
    "descriptor": "",
    "authors": [
      "Jon-Lark Kim",
      "Whan-Hyuk Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.12282"
  },
  {
    "id": "arXiv:2111.12284",
    "title": "A Self-Supervised Automatic Post-Editing Data Generation Tool",
    "abstract": "Data building for automatic post-editing (APE) requires extensive and\nexpert-level human effort, as it contains an elaborate process that involves\nidentifying errors in sentences and providing suitable revisions. Hence, we\ndevelop a self-supervised data generation tool, deployable as a web\napplication, that minimizes human supervision and constructs personalized APE\ndata from a parallel corpus for several language pairs with English as the\ntarget language. Data-centric APE research can be conducted using this tool,\ninvolving many language pairs that have not been studied thus far owing to the\nlack of suitable data.",
    "descriptor": "",
    "authors": [
      "Hyeonseok Moon",
      "Chanjun Park",
      "Sugyeong Eo",
      "Jaehyung Seo",
      "SeungJun Lee",
      "Heuiseok Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.12284"
  },
  {
    "id": "arXiv:2111.12289",
    "title": "Real-time smart vehicle surveillance system",
    "abstract": "Over the last decade, there has been a spike in criminal activity all around\nthe globe. According to the Indian police department, vehicle theft is one of\nthe least solved offenses, and almost 19% of all recorded cases are related to\nmotor vehicle theft. To overcome these adversaries, we propose a real-time\nvehicle surveillance system, which detects and tracks the suspect vehicle using\nthe CCTV video feed. The proposed system extracts various attributes of the\nvehicle such as Make, Model, Color, License plate number, and type of the\nlicense plate. Various image processing and deep learning algorithms are\nemployed to meet the objectives of the proposed system. The extracted features\ncan be used as evidence to report violations of law. Although the system uses\nmore parameters, it is still able to make real time predictions with minimal\nlatency and accuracy loss.",
    "descriptor": "",
    "authors": [
      "Shantha Kumar S",
      "Vykunth P",
      "Jayanthi D"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12289"
  },
  {
    "id": "arXiv:2111.12290",
    "title": "Attention-based Dual-stream Vision Transformer for Radar Gait  Recognition",
    "abstract": "Radar gait recognition is robust to light variations and less infringement on\nprivacy. Previous studies often utilize either spectrograms or cadence velocity\ndiagrams. While the former shows the time-frequency patterns, the latter\nencodes the repetitive frequency patterns. In this work, a dual-stream neural\nnetwork with attention-based fusion is proposed to fully aggregate the\ndiscriminant information from these two representations. The both streams are\ndesigned based on the Vision Transformer, which well captures the gait\ncharacteristics embedded in these representations. The proposed method is\nvalidated on a large benchmark dataset for radar gait recognition, which shows\nthat it significantly outperforms state-of-the-art solutions.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Shiliang Chen",
      "Wentao He",
      "Jianfeng Ren",
      "Xudong Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.12290"
  },
  {
    "id": "arXiv:2111.12292",
    "title": "Improved Fine-tuning by Leveraging Pre-training Data: Theory and  Practice",
    "abstract": "As a dominant paradigm, fine-tuning a pre-trained model on the target data is\nwidely used in many deep learning applications, especially for small data sets.\nHowever, recent studies have empirically shown that training from scratch has\nthe final performance that is no worse than this pre-training strategy once the\nnumber of training iterations is increased in some vision tasks. In this work,\nwe revisit this phenomenon from the perspective of generalization analysis\nwhich is popular in learning theory. Our result reveals that the final\nprediction precision may have a weak dependency on the pre-trained model\nespecially in the case of large training iterations. The observation inspires\nus to leverage pre-training data for fine-tuning, since this data is also\navailable for fine-tuning. The generalization result of using pre-training data\nshows that the final performance on a target task can be improved when the\nappropriate pre-training data is included in fine-tuning. With the insight of\nthe theoretical finding, we propose a novel selection strategy to select a\nsubset from pre-training data to help improve the generalization on the target\ntask. Extensive experimental results for image classification tasks on 8\nbenchmark data sets verify the effectiveness of the proposed data selection\nbased fine-tuning pipeline.",
    "descriptor": "",
    "authors": [
      "Ziquan Liu",
      "Yi Xu",
      "Yuanhong Xu",
      "Qi Qian",
      "Hao Li",
      "Antoni Chan",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12292"
  },
  {
    "id": "arXiv:2111.12293",
    "title": "PTQ4ViT: Post-Training Quantization Framework for Vision Transformers",
    "abstract": "Quantization is one of the most effective methods to compress neural\nnetworks, which has achieved great success on convolutional neural networks\n(CNNs). Recently, vision transformers have demonstrated great potential in\ncomputer vision. However, previous post-training quantization methods performed\nnot well on vision transformer, resulting in more than 1% accuracy drop even in\n8-bit quantization. Therefore, we analyze the problems of quantization on\nvision transformers. We observe the distributions of activation values after\nsoftmax and GELU functions are quite different from the Gaussian distribution.\nWe also observe that common quantization metrics, such as MSE and cosine\ndistance, are inaccurate to determine the optimal scaling factor. In this\npaper, we propose the twin uniform quantization method to reduce the\nquantization error on these activation values. And we propose to use a Hessian\nguided metric to evaluate different scaling factors, which improves the\naccuracy of calibration with a small cost. To enable the fast quantization of\nvision transformers, we develop an efficient framework, PTQ4ViT. Experiments\nshow the quantized vision transformers achieve near-lossless prediction\naccuracy (less than 0.5% drop at 8-bit quantization) on the ImageNet\nclassification task.",
    "descriptor": "",
    "authors": [
      "Zhihang Yuan",
      "Chenhao Xue",
      "Yiqi Chen",
      "Qiang Wu",
      "Guangyu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12293"
  },
  {
    "id": "arXiv:2111.12294",
    "title": "An Image Patch is a Wave: Phase-Aware Vision MLP",
    "abstract": "Different from traditional convolutional neural network (CNN) and vision\ntransformer, the multilayer perceptron (MLP) is a new kind of vision model with\nextremely simple architecture that only stacked by fully-connected layers. An\ninput image of vision MLP is usually split into multiple tokens (patches),\nwhile the existing MLP models directly aggregate them with fixed weights,\nneglecting the varying semantic information of tokens from different images. To\ndynamically aggregate tokens, we propose to represent each token as a wave\nfunction with two parts, amplitude and phase. Amplitude is the original feature\nand the phase term is a complex value changing according to the semantic\ncontents of input images. Introducing the phase term can dynamically modulate\nthe relationship between tokens and fixed weights in MLP. Based on the\nwave-like token representation, we establish a novel Wave-MLP architecture for\nvision tasks. Extensive experiments demonstrate that the proposed Wave-MLP is\nsuperior to the state-of-the-art MLP architectures on various vision tasks such\nas image classification, object detection and semantic segmentation.",
    "descriptor": "",
    "authors": [
      "Yehui Tang",
      "Kai Han",
      "Jianyuan Guo",
      "Chang Xu",
      "Yanxi Li",
      "Chao Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12294"
  },
  {
    "id": "arXiv:2111.12295",
    "title": "Animal Behavior Classification via Deep Learning on Embedded Systems",
    "abstract": "We develop an end-to-end deep-neural-network-based algorithm for classifying\nanimal behavior using accelerometry data on the embedded system of an\nartificial intelligence of things (AIoT) device installed in a wearable collar\ntag. The proposed algorithm jointly performs feature extraction and\nclassification utilizing a set of infinite-impulse-response (IIR) and\nfinite-impulse-response (FIR) filters together with a multilayer perceptron.\nThe utilized IIR and FIR filters can be viewed as specific types of recurrent\nand convolutional neural network layers, respectively. We evaluate the\nperformance of the proposed algorithm via two real-world datasets collected\nfrom grazing cattle. The results show that the proposed algorithm offers good\nintra- and inter-dataset classification accuracy and outperforms its closest\ncontenders including two state-of-the-art convolutional-neural-network-based\ntime-series classification algorithms, which are significantly more complex. We\nimplement the proposed algorithm on the embedded system of the collar tag's\nAIoT device to perform in-situ classification of animal behavior. We achieve\nreal-time in-situ behavior inference from accelerometry data without imposing\nany strain on the available computational, memory, or energy resources of the\nembedded system.",
    "descriptor": "",
    "authors": [
      "Reza Arablouei",
      "Liang Wang",
      "Lachlan Currie",
      "Flavio A. P. Alvarenga",
      "Greg J. Bishop-Hurley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12295"
  },
  {
    "id": "arXiv:2111.12296",
    "title": "Spatial-context-aware deep neural network for multi-class image  classification",
    "abstract": "Multi-label image classification is a fundamental but challenging task in\ncomputer vision. Over the past few decades, solutions exploring relationships\nbetween semantic labels have made great progress. However, the underlying\nspatial-contextual information of labels is under-exploited. To tackle this\nproblem, a spatial-context-aware deep neural network is proposed to predict\nlabels taking into account both semantic and spatial information. This proposed\nframework is evaluated on Microsoft COCO and PASCAL VOC, two widely used\nbenchmark datasets for image multi-labelling. The results show that the\nproposed approach is superior to the state-of-the-art solutions on dealing with\nthe multi-label image classification problem.",
    "descriptor": "",
    "authors": [
      "Jialu Zhang",
      "Qian Zhang",
      "Jianfeng Ren",
      "Yitian Zhao",
      "Jiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12296"
  },
  {
    "id": "arXiv:2111.12299",
    "title": "EH-DNAS: End-to-End Hardware-aware Differentiable Neural Architecture  Search",
    "abstract": "In hardware-aware Differentiable Neural Architecture Search (DNAS), it is\nchallenging to compute gradients of hardware metrics to perform architecture\nsearch. Existing works rely on linear approximations with limited support to\ncustomized hardware accelerators. In this work, we propose End-to-end\nHardware-aware DNAS (EH-DNAS), a seamless integration of end-to-end hardware\nbenchmarking, and fully automated DNAS to deliver hardware-efficient deep\nneural networks on various platforms, including Edge GPUs, Edge TPUs, Mobile\nCPUs, and customized accelerators. Given a desired hardware platform, we\npropose to learn a differentiable model predicting the end-to-end hardware\nperformance of neural network architectures for DNAS. We also introduce\nE2E-Perf, an end-to-end hardware benchmarking tool for customized accelerators.\nExperiments on CIFAR10 and ImageNet show that EH-DNAS improves the hardware\nperformance by an average of $1.4\\times$ on customized accelerators and\n$1.6\\times$ on existing hardware processors while maintaining the\nclassification accuracy.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Qian Jiang",
      "Xiaofan Zhang",
      "Deming Chen",
      "Minh N. Do",
      "Raymond A. Yeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12299"
  },
  {
    "id": "arXiv:2111.12301",
    "title": "One-shot Visual Reasoning on RPMs with an Application to Video Frame  Prediction",
    "abstract": "Raven's Progressive Matrices (RPMs) are frequently used in evaluating human's\nvisual reasoning ability. Researchers have made considerable effort in\ndeveloping a system which could automatically solve the RPM problem, often\nthrough a black-box end-to-end Convolutional Neural Network (CNN) for both\nvisual recognition and logical reasoning tasks. Towards the objective of\ndeveloping a highly explainable solution, we propose a One-shot\nHuman-Understandable ReaSoner (Os-HURS), which is a two-step framework\nincluding a perception module and a reasoning module, to tackle the challenges\nof real-world visual recognition and subsequent logical reasoning tasks,\nrespectively. For the reasoning module, we propose a \"2+1\" formulation that can\nbe better understood by humans and significantly reduces the model complexity.\nAs a result, a precise reasoning rule can be deduced from one RPM sample only,\nwhich is not feasible for existing solution methods. The proposed reasoning\nmodule is also capable of yielding a set of reasoning rules, precisely modeling\nthe human knowledge in solving the RPM problem. To validate the proposed method\non real-world applications, an RPM-like One-shot Frame-prediction (ROF) dataset\nis constructed, where visual reasoning is conducted on RPMs constructed using\nreal-world video frames instead of synthetic images. Experimental results on\nvarious RPM-like datasets demonstrate that the proposed Os-HURS achieves a\nsignificant and consistent performance gain compared with the state-of-the-art\nmodels.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Wentao He",
      "Jianfeng Ren",
      "Ruibin Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12301"
  },
  {
    "id": "arXiv:2111.12305",
    "title": "Thundernna: a white box adversarial attack",
    "abstract": "The existing work shows that the neural network trained by naive\ngradient-based optimization method is prone to adversarial attacks, adds small\nmalicious on the ordinary input is enough to make the neural network wrong. At\nthe same time, the attack against a neural network is the key to improving its\nrobustness. The training against adversarial examples can make neural networks\nresist some kinds of adversarial attacks. At the same time, the adversarial\nattack against a neural network can also reveal some characteristics of the\nneural network, a complex high-dimensional non-linear function, as discussed in\nprevious work.\nIn This project, we develop a first-order method to attack the neural\nnetwork. Compare with other first-order attacks, our method has a much higher\nsuccess rate. Furthermore, it is much faster than second-order attacks and\nmulti-steps first-order attacks.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Linfeng Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12305"
  },
  {
    "id": "arXiv:2111.12306",
    "title": "Efficient and Optimal Algorithms for Contextual Dueling Bandits under  Realizability",
    "abstract": "We study the $K$-armed contextual dueling bandit problem, a sequential\ndecision making setting in which the learner uses contextual information to\nmake two decisions, but only observes \\emph{preference-based feedback}\nsuggesting that one decision was better than the other. We focus on the regret\nminimization problem under realizability, where the feedback is generated by a\npairwise preference matrix that is well-specified by a given function class\n$\\mathcal F$. We provide a new algorithm that achieves the optimal regret rate\nfor a new notion of best response regret, which is a strictly stronger\nperformance measure than those considered in prior works. The algorithm is also\ncomputationally efficient, running in polynomial time assuming access to an\nonline oracle for square loss regression over $\\mathcal F$. This resolves an\nopen problem of Dud\\'ik et al. [2015] on oracle efficient, regret-optimal\nalgorithms for contextual dueling bandits.",
    "descriptor": "",
    "authors": [
      "Aadirupa Saha",
      "Akshay Krishnamurthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12306"
  },
  {
    "id": "arXiv:2111.12309",
    "title": "RegionCL: Can Simple Region Swapping Contribute to Contrastive Learning?",
    "abstract": "Self-supervised methods (SSL) have achieved significant success via\nmaximizing the mutual information between two augmented views, where cropping\nis a popular augmentation technique. Cropped regions are widely used to\nconstruct positive pairs, while the left regions after cropping have rarely\nbeen explored in existing methods, although they together constitute the same\nimage instance and both contribute to the description of the category. In this\npaper, we make the first attempt to demonstrate the importance of both regions\nin cropping from a complete perspective and propose a simple yet effective\npretext task called Region Contrastive Learning (RegionCL). Specifically, given\ntwo different images, we randomly crop a region (called the paste view) from\neach image with the same size and swap them to compose two new images together\nwith the left regions (called the canvas view), respectively. Then, contrastive\npairs can be efficiently constructed according to the following simple\ncriteria, i.e., each view is (1) positive with views augmented from the same\noriginal image and (2) negative with views augmented from other images. With\nminor modifications to popular SSL methods, RegionCL exploits those abundant\npairs and helps the model distinguish the regions features from both canvas and\npaste views, therefore learning better visual representations. Experiments on\nImageNet, MS COCO, and Cityscapes demonstrate that RegionCL improves MoCo v2,\nDenseCL, and SimSiam by large margins and achieves state-of-the-art performance\non classification, detection, and segmentation tasks. The code will be\navailable at https://github.com/Annbless/RegionCL.git.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Yufei Xu",
      "Qiming Zhang",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12309"
  },
  {
    "id": "arXiv:2111.12313",
    "title": "Explicit solution of divide-and-conquer dividing by a half recurrences  with polynomial independent term",
    "abstract": "Divide-and-conquer dividing by a half recurrences, of the form $x_n =a\\cdot\nx_{\\left\\lceil{n}/{2}\\right\\rceil}+a\\cdot\nx_{\\left\\lfloor{n}/{2}\\right\\rfloor}+p(n)$, $n\\geq 2$, appear in many areas of\napplied mathematics, from the analysis of algorithms to the optimization of\nphylogenetic balance indices. The Master Theorems that solve these equations do\nnot provide the solution's explicit expression, only its big-$\\Theta$ order of\ngrowth. In this paper we give an explicit expression (in terms of the binary\ndecomposition of $n$) for the solution $x_n$ of a recurrence of this form, with\ngiven initial condition $x_1$, when the independent term $p(n)$ is a polynomial\nin $\\lceil{n}/{2}\\rceil$ and $\\lfloor{n}/{2}\\rfloor$.",
    "descriptor": "\nComments: 50 pages\n",
    "authors": [
      "Tom\u00e1s M. Coronado",
      "Arnau Mir",
      "Francesc Rossell\u00f3"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2111.12313"
  },
  {
    "id": "arXiv:2111.12315",
    "title": "Dynamic Texture Recognition using PDV Hashing and Dictionary Learning on  Multi-scale Volume Local Binary Pattern",
    "abstract": "Spatial-temporal local binary pattern (STLBP) has been widely used in dynamic\ntexture recognition. STLBP often encounters the high-dimension problem as its\ndimension increases exponentially, so that STLBP could only utilize a small\nneighborhood. To tackle this problem, we propose a method for dynamic texture\nrecognition using PDV hashing and dictionary learning on multi-scale volume\nlocal binary pattern (PHD-MVLBP). Instead of forming very high-dimensional LBP\nhistogram features, it first uses hash functions to map the pixel difference\nvectors (PDVs) to binary vectors, then forms a dictionary using the derived\nbinary vector, and encodes them using the derived dictionary. In such a way,\nthe PDVs are mapped to feature vectors of the size of dictionary, instead of\nLBP histograms of very high dimension. Such an encoding scheme could extract\nthe discriminant information from videos in a much larger neighborhood\neffectively. The experimental results on two widely-used dynamic textures\ndatasets, DynTex++ and UCLA, show the superiority performance of the proposed\napproach over the state-of-the-art methods.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Ruxin Ding",
      "Jianfeng Ren",
      "Heng Yu",
      "Jiawei Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12315"
  },
  {
    "id": "arXiv:2111.12317",
    "title": "Handling tree-structured text: parsing directory pages",
    "abstract": "The determination of the reading sequence of text is fundamental to document\nunderstanding. This problem is easily solved in pages where the text is\norganized into a sequence of lines and vertical alignment runs the height of\nthe page (producing multiple columns which can be read from left to right). We\npresent a situation -- the directory page parsing problem -- where information\nis presented on the page in an irregular, visually-organized, two-dimensional\nformat. Directory pages are fairly common in financial prospectuses and carry\ninformation about organizations, their addresses and relationships that is key\nto business tasks in client onboarding. Interestingly, directory pages\nsometimes have hierarchical structure, motivating the need to generalize the\nreading sequence to a reading tree. We present solutions to the problem of\nidentifying directory pages and constructing the reading tree, using (learnt)\nclassifiers for text segments and a bottom-up (right to left, bottom-to-top)\ntraversal of segments. The solution is a key part of a production service\nsupporting automatic extraction of organization, address and relationship\ninformation from client onboarding documents.",
    "descriptor": "",
    "authors": [
      "Sarang Shrivastava",
      "Afreen Shaikh",
      "Shivani Shrivastava",
      "Chung Ming Ho",
      "Pradeep Reddy",
      "Vijay Saraswat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.12317"
  },
  {
    "id": "arXiv:2111.12320",
    "title": "Consistency Regularization for Deep Face Anti-Spoofing",
    "abstract": "Face anti-spoofing (FAS) plays a crucial role in securing face recognition\nsystems. Empirically, given an image, a model with more consistent output on\ndifferent views of this image usually performs better, as shown in Fig.1.\nMotivated by this exciting observation, we conjecture that encouraging feature\nconsistency of different views may be a promising way to boost FAS models. In\nthis paper, we explore this way thoroughly by enhancing both Embedding-level\nand Prediction-level Consistency Regularization (EPCR) in FAS. Specifically, at\nthe embedding-level, we design a dense similarity loss to maximize the\nsimilarities between all positions of two intermediate feature maps in a\nself-supervised fashion; while at the prediction-level, we optimize the mean\nsquare error between the predictions of two views. Notably, our EPCR is free of\nannotations and can directly integrate into semi-supervised learning schemes.\nConsidering different application scenarios, we further design five diverse\nsemi-supervised protocols to measure semi-supervised FAS techniques. We conduct\nextensive experiments to show that EPCR can significantly improve the\nperformance of several supervised and semi-supervised tasks on benchmark\ndatasets. The codes and protocols will be released soon.",
    "descriptor": "\nComments: 10 tables, 4 figures\n",
    "authors": [
      "Zezheng Wang",
      "Zitong Yu",
      "Xun Wang",
      "Yunxiao Qin",
      "Jiahong Li",
      "Chenxu Zhao",
      "Zhen Lei",
      "Xin Liu",
      "Size Li",
      "Zhongyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12320"
  },
  {
    "id": "arXiv:2111.12321",
    "title": "Efficient Secure Aggregation Based on SHPRG For Federated Learning",
    "abstract": "We propose a novel secure aggregation scheme based on seed-homomorphic\npseudo-random generator (SHPRG) to prevent private training data leakage from\nmodel-related information in Federated Learning systems. Our constructions\nleverage the homomorphic property of SHPRG to simplify the masking and\ndemasking scheme, which entails a linear overhead while revealing nothing\nbeyond the aggregation result against colluding entities. Additionally, our\nscheme is resilient to dropouts without extra overhead. We experimentally\ndemonstrate our scheme significantly improves the efficiency to 20 times over\nbaseline, especially in the more realistic case in which the number of clients\nand model size become large and a certain percentage of clients drop out from\nthe system.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Zizhen Liu",
      "Si Chen",
      "Jing Ye",
      "Junfeng Fan",
      "Huawei Li",
      "Xiaowei Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.12321"
  },
  {
    "id": "arXiv:2111.12322",
    "title": "Stochastic optimal scheduling of demand response-enabled microgrids with  renewable generations: An analytical-heuristic approach",
    "abstract": "In the context of transition towards cleaner and sustainable energy\nproduction, microgrids have become an effective way for tackling environmental\npollution and energy crisis issues. With the increasing penetration of\nrenewables, how to coordinate demand response and renewable generations is a\ncritical and challenging issue in the field of microgrid scheduling. To this\nend, a bi-level scheduling model is put forward for isolated microgrids with\nconsideration of multi-stakeholders in this paper, where the lower- and\nupper-level models respectively aim to the minimization of user cost and\nmicrogrid operational cost under real-time electricity pricing environments. In\norder to solve this model, this research combines Jaya algorithm and interior\npoint method (IPM) to develop a hybrid analysis-heuristic solution method\ncalled Jaya-IPM, where the lower- and upper- levels are respectively addressed\nby the IPM and the Jaya, and the scheduling scheme is obtained via iterations\nbetween the two levels. After that, the real-time prices updated by the\nupper-level model and the electricity plans determined by the lower-level model\nwill be alternately iterated between the upper- and lower- levels through the\nreal-time pricing mechanism to obtain an optimal scheduling plan. The test\nresults show that the proposed method can coordinate the uncertainty of\nrenewable generations with demand response strategies, thereby achieving a\nbalance between the interests of microgrid and users; and that by leveraging\ndemand response, the flexibility of the load side can be fully exploited to\nachieve peak load shaving while maintaining the balance of supply and demand.\nIn addition, the Jaya-IPM algorithm is proven to be superior to the traditional\nhybrid intelligent algorithm (HIA) and the CPLEX solver in terms of\noptimization results and calculation efficiency.",
    "descriptor": "\nComments: Accepted by Journal of Cleaner Production\n",
    "authors": [
      "Yang Li",
      "Kang Li",
      "Zhen Yang",
      "Yang Yu",
      "Runnan Xu",
      "Miaosen Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.12322"
  },
  {
    "id": "arXiv:2111.12323",
    "title": "Information Dispersal with Provable Retrievability for Rollups",
    "abstract": "The ability to verifiably retrieve transaction or state data stored off-chain\nis crucial to blockchain scaling techniques such as rollups or sharding. We\nformalize the problem and design a storage- and communication-efficient\nprotocol using linear erasure-correcting codes and homomorphic vector\ncommitments. Motivated by application requirements for rollups, our solution\ndeparts from earlier Verifiable Information Dispersal schemes in that we do not\nrequire comprehensive termination properties or retrievability from any but\nonly from some known sufficiently large set of storage nodes. Compared to Data\nAvailability Oracles, under no circumstance do we fall back to returning empty\nblocks. Distributing a file of 28.8 MB among 900 storage nodes (up to 300 of\nwhich may be adversarial) requires in total approx. 95 MB of communication and\nstorage and approx. 30 seconds of cryptographic computation on a\nsingle-threaded consumer-grade laptop computer. Our solution requires no\nmodification to on-chain contracts of Validium rollups such as StarkWare's\nStarkEx. Additionally, it provides privacy of the dispersed data against\nhonest-but-curious storage nodes.",
    "descriptor": "",
    "authors": [
      "Kamilla Nazirkhanova",
      "Joachim Neu",
      "David Tse"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.12323"
  },
  {
    "id": "arXiv:2111.12324",
    "title": "How Speech is Recognized to Be Emotional - A Study Based on Information  Decomposition",
    "abstract": "The way that humans encode their emotion into speech signals is complex. For\ninstance, an angry man may increase his pitch and speaking rate, and use\nimpolite words. In this paper, we present a preliminary study on various\nemotional factors and investigate how each of them impacts modern emotion\nrecognition systems. The key tool of our study is the SpeechFlow model\npresented recently, by which we are able to decompose speech signals into\nseparate information factors (content, pitch, rhythm). Based on this\ndecomposition, we carefully studied the performance of each information\ncomponent and their combinations. We conducted the study on three different\nspeech emotion corpora and chose an attention-based convolutional RNN as the\nemotion classifier. Our results show that rhythm is the most important\ncomponent for emotional expression. Moreover, the cross-corpus results are very\nbad (even worse than guess), demonstrating that the present speech emotion\nrecognition model is rather weak. Interestingly, by removing one or several\nunimportant components, the cross-corpus results can be improved. This\ndemonstrates the potential of the decomposition approach towards a\ngeneralizable emotion recognition.",
    "descriptor": "",
    "authors": [
      "Haoran Sun",
      "Lantian Li",
      "Thomas Fang Zheng",
      "Dong Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.12324"
  },
  {
    "id": "arXiv:2111.12325",
    "title": "MonoPLFlowNet: Permutohedral Lattice FlowNet for Real-Scale 3D Scene  FlowEstimation with Monocular Images",
    "abstract": "Real-scale scene flow estimation has become increasingly important for 3D\ncomputer vision. Some works successfully estimate real-scale 3D scene flow with\nLiDAR. However, these ubiquitous and expensive sensors are still unlikely to be\nequipped widely for real application. Other works use monocular images to\nestimate scene flow, but their scene flow estimations are normalized with scale\nambiguity, where additional depth or point cloud ground truth are required to\nrecover the real scale. Even though they perform well in 2D, these works do not\nprovide accurate and reliable 3D estimates. We present a deep learning\narchitecture on permutohedral lattice - MonoPLFlowNet. Different from all\nprevious works, our MonoPLFlowNet is the first work where only two consecutive\nmonocular images are used as input, while both depth and 3D scene flow are\nestimated in real scale. Our real-scale scene flow estimation outperforms all\nstate-of-the-art monocular-image based works recovered to real scale by ground\ntruth, and is comparable to LiDAR approaches. As a by-product, our real-scale\ndepth estimation also outperforms other state-of-the-art works.",
    "descriptor": "",
    "authors": [
      "Runfa Li",
      "Truong Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12325"
  },
  {
    "id": "arXiv:2111.12326",
    "title": "A Study on Decoupled Probabilistic Linear Discriminant Analysis",
    "abstract": "Probabilistic linear discriminant analysis (PLDA) has broad application in\nopen-set verification tasks, such as speaker verification. A key concern for\nPLDA is that the model is too simple (linear Gaussian) to deal with complicated\ndata; however, the simplicity by itself is a major advantage of PLDA, as it\nleads to desirable generalization. An interesting research therefore is how to\nimprove modeling capacity of PLDA while retaining the simplicity. This paper\npresents a decoupling approach, which involves a global model that is simple\nand generalizable, and a local model that is complex and expressive. While the\nglobal model holds a bird view on the entire data, the local model represents\nthe details of individual classes. We conduct a preliminary study towards this\ndirection and investigate a simple decoupling model including both the global\nand local models. The new model, which we call decoupled PLDA, is tested on a\nspeaker verification task. Experimental results show that it consistently\noutperforms the vanilla PLDA when the model is based on raw speaker vectors.\nHowever, when the speaker vectors are processed by length normalization, the\nadvantage of decoupled PLDA will be largely lost, suggesting future research on\nnon-linear local models.",
    "descriptor": "",
    "authors": [
      "Di Wang",
      "Lantian Li",
      "Hongzhi Yu",
      "Dong Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.12326"
  },
  {
    "id": "arXiv:2111.12330",
    "title": "Hidden-Fold Networks: Random Recurrent Residuals Using Sparse Supermasks",
    "abstract": "Deep neural networks (DNNs) are so over-parametrized that recent research has\nfound them to already contain a subnetwork with high accuracy at their randomly\ninitialized state. Finding these subnetworks is a viable alternative training\nmethod to weight learning. In parallel, another line of work has hypothesized\nthat deep residual networks (ResNets) are trying to approximate the behaviour\nof shallow recurrent neural networks (RNNs) and has proposed a way for\ncompressing them into recurrent models. This paper proposes blending these\nlines of research into a highly compressed yet accurate model: Hidden-Fold\nNetworks (HFNs). By first folding ResNet into a recurrent structure and then\nsearching for an accurate subnetwork hidden within the randomly initialized\nmodel, a high-performing yet tiny HFN is obtained without ever updating the\nweights. As a result, HFN achieves equivalent performance to ResNet50 on\nCIFAR100 while occupying 38.5x less memory, and similar performance to ResNet34\non ImageNet with a memory size 26.8x smaller. The HFN will become even more\nattractive by minimizing data transfers while staying accurate when it runs on\nhighly-quantized and randomly-weighted DNN inference accelerators. Code\navailable at https://github.com/Lopez-Angel/hidden-fold-networks",
    "descriptor": "\nComments: 13 pages, 7 figures. Accepted to the British Machine Vision Conference (BMVC) 2021\n",
    "authors": [
      "\u00c1ngel L\u00f3pez Garc\u00eda-Arias",
      "Masanori Hashimoto",
      "Masato Motomura",
      "Jaehoon Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12330"
  },
  {
    "id": "arXiv:2111.12331",
    "title": "An MAP Estimation for Between-Class Variance",
    "abstract": "Probabilistic linear discriminant analysis (PLDA) has been widely used in\nopen-set verification tasks, such as speaker verification. A potential issue of\nthis model is that the training set often contains limited number of classes,\nwhich makes the estimation for the between-class variance unreliable. This\nunreliable estimation often leads to degraded generalization. In this paper, we\npresent an MAP estimation for the between-class variance, by employing an\nInverse-Wishart prior. A key problem is that with hierarchical models such as\nPLDA, the prior is placed on the variance of class means while the likelihood\nis based on class members, which makes the posterior inference intractable. We\nderive a simple MAP estimation for such a model, and test it in both PLDA\nscoring and length normalization. In both cases, the MAP-based estimation\ndelivers interesting performance improvement.",
    "descriptor": "",
    "authors": [
      "Jiao Han",
      "Yunqi Cai",
      "Lantian Li",
      "Guanyu Li",
      "Dong Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.12331"
  },
  {
    "id": "arXiv:2111.12332",
    "title": "Securing Proof-of-Stake Nakamoto Consensus Under Bandwidth Constraint",
    "abstract": "Satoshi Nakamoto's Proof-of-Work (PoW) longest chain (LC) protocol was a\nbreakthrough for Internet-scale open-participation consensus. Many\nProof-of-Stake (PoS) variants of Nakamoto's protocol such as Ouroboros or Snow\nWhite aim to preserve the advantages of LC by mimicking PoW LC closely, while\nmitigating downsides of PoW by using PoS for Sybil resistance. Previous works\nhave proven these PoS LC protocols secure assuming all network messages are\ndelivered within a bounded delay. However, this assumption is not compatible\nwith PoS when considering bandwidth constraints in the underlying communication\nnetwork. This is because PoS enables the adversary to reuse block production\nopportunities and spam the network with equivocating blocks, which is\nimpossible in PoW. The bandwidth constraint necessitates that nodes choose\ncarefully which blocks to spend their limited download budget on. We show that\n'download along the longest header chain', a natural download rule for PoW LC,\nemulated by PoS variants, is insecure for PoS LC. Instead, we propose 'download\ntowards the freshest block' and prove that PoS LC with this download rule is\nsecure in bandwidth constrained networks. Our result can be viewed as a first\nstep towards the co-design of consensus and network layer protocols.",
    "descriptor": "",
    "authors": [
      "Joachim Neu",
      "Srivatsan Sridhar",
      "Lei Yang",
      "David Tse",
      "Mohammad Alizadeh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.12332"
  },
  {
    "id": "arXiv:2111.12334",
    "title": "MobileXNet: An Efficient Convolutional Neural Network for Monocular  Depth Estimation",
    "abstract": "Depth is a vital piece of information for autonomous vehicles to perceive\nobstacles. Due to the relatively low price and small size of monocular cameras,\ndepth estimation from a single RGB image has attracted great interest in the\nresearch community. In recent years, the application of Deep Neural Networks\n(DNNs) has significantly boosted the accuracy of monocular depth estimation\n(MDE). State-of-the-art methods are usually designed on top of complex and\nextremely deep network architectures, which require more computational\nresources and cannot run in real-time without using high-end GPUs. Although\nsome researchers tried to accelerate the running speed, the accuracy of depth\nestimation is degraded because the compressed model does not represent images\nwell. In addition, the inherent characteristic of the feature extractor used by\nthe existing approaches results in severe spatial information loss in the\nproduced feature maps, which also impairs the accuracy of depth estimation on\nsmall sized images. In this study, we are motivated to design a novel and\nefficient Convolutional Neural Network (CNN) that assembles two shallow\nencoder-decoder style subnetworks in succession to address these problems. In\nparticular, we place our emphasis on the trade-off between the accuracy and\nspeed of MDE. Extensive experiments have been conducted on the NYU depth v2,\nKITTI, Make3D and Unreal data sets. Compared with the state-of-the-art\napproaches which have an extremely deep and complex architecture, the proposed\nnetwork not only achieves comparable performance but also runs at a much faster\nspeed on a single, less powerful GPU.",
    "descriptor": "",
    "authors": [
      "Xingshuai Dong",
      "Matthew A. Garratt",
      "Sreenatha G. Anavatti",
      "Hussein A. Abbass"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.12334"
  },
  {
    "id": "arXiv:2111.12340",
    "title": "How does AI play football? An analysis of RL and real-world football  strategies",
    "abstract": "Recent advances in reinforcement learning (RL) have made it possible to\ndevelop sophisticated agents that excel in a wide range of applications.\nSimulations using such agents can provide valuable information in scenarios\nthat are difficult to scientifically experiment in the real world. In this\npaper, we examine the play-style characteristics of football RL agents and\nuncover how strategies may develop during training. The learnt strategies are\nthen compared with those of real football players. We explore what can be\nlearnt from the use of simulated environments by using aggregated statistics\nand social network analysis (SNA). As a result, we found that (1) there are\nstrong correlations between the competitiveness of an agent and various SNA\nmetrics and (2) aspects of the RL agents play style become similar to real\nworld footballers as the agent becomes more competitive. We discuss further\nadvances that may be necessary to improve our understanding necessary to fully\nutilise RL for the analysis of football.",
    "descriptor": "\nComments: 11 pages, 7 figures; accepted as a full paper for a 25 minutes oral presentation at ICAART 2022 (URL will be updated when available)\n",
    "authors": [
      "Atom Scott",
      "Keisuke Fujii",
      "Masaki Onishi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.12340"
  },
  {
    "id": "arXiv:2111.12341",
    "title": "EvDistill: Asynchronous Events to End-task Learning via Bidirectional  Reconstruction-guided Cross-modal Knowledge Distillation",
    "abstract": "Event cameras sense per-pixel intensity changes and produce asynchronous\nevent streams with high dynamic range and less motion blur, showing advantages\nover conventional cameras. A hurdle of training event-based models is the lack\nof large qualitative labeled data. Prior works learning end-tasks mostly rely\non labeled or pseudo-labeled datasets obtained from the active pixel sensor\n(APS) frames; however, such datasets' quality is far from rivaling those based\non the canonical images. In this paper, we propose a novel approach, called\n\\textbf{EvDistill}, to learn a student network on the unlabeled and unpaired\nevent data (target modality) via knowledge distillation (KD) from a teacher\nnetwork trained with large-scale, labeled image data (source modality). To\nenable KD across the unpaired modalities, we first propose a bidirectional\nmodality reconstruction (BMR) module to bridge both modalities and\nsimultaneously exploit them to distill knowledge via the crafted pairs, causing\nno extra computation in the inference. The BMR is improved by the end-tasks and\nKD losses in an end-to-end manner. Second, we leverage the structural\nsimilarities of both modalities and adapt the knowledge by matching their\ndistributions. Moreover, as most prior feature KD methods are uni-modality and\nless applicable to our problem, we propose to leverage an affinity graph KD\nloss to boost the distillation. Our extensive experiments on semantic\nsegmentation and object recognition demonstrate that EvDistill achieves\nsignificantly better results than the prior works and KD with only events and\nAPS frames.",
    "descriptor": "\nComments: CVPR 2021 (updated references in this version)\n",
    "authors": [
      "Lin Wang",
      "Yujeong Chae",
      "Sung-Hoon Yoon",
      "Tae-Kyun Kim",
      "Kuk-Jin Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12341"
  },
  {
    "id": "arXiv:2111.12345",
    "title": "dCSR: A Memory-Efficient Sparse Matrix Representation for Parallel  Neural Network Inference",
    "abstract": "Reducing the memory footprint of neural networks is a crucial prerequisite\nfor deploying them in small and low-cost embedded devices. Network parameters\ncan often be reduced significantly through pruning. We discuss how to best\nrepresent the indexing overhead of sparse networks for the coming generation of\nSingle Instruction, Multiple Data (SIMD)-capable microcontrollers. From this,\nwe develop Delta-Compressed Storage Row (dCSR), a storage format for sparse\nmatrices that allows for both low overhead storage and fast inference on\nembedded systems with wide SIMD units. We demonstrate our method on an ARM\nCortex-M55 MCU prototype with M-Profile Vector Extension(MVE). A comparison of\nmemory consumption and throughput shows that our method achieves competitive\ncompression ratios and increases throughput over dense methods by up to $2.9\n\\times$ for sparse matrix-vector multiplication (SpMV)-based kernels and $1.06\n\\times$ for sparse matrix-matrix multiplication (SpMM). This is accomplished\nthrough handling the generation of index information directly in the SIMD unit,\nleading to an increase in effective memory bandwidth.",
    "descriptor": "\nComments: Accepted at International Conference on Computer-Aided Design (ICCAD) 2021\n",
    "authors": [
      "Elias Trommer",
      "Bernd Waschneck",
      "Akash Kumar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.12345"
  },
  {
    "id": "arXiv:2111.12346",
    "title": "Arbitrary Virtual Try-On Network: Characteristics Preservation and  Trade-off between Body and Clothing",
    "abstract": "Deep learning based virtual try-on system has achieved some encouraging\nprogress recently, but there still remain several big challenges that need to\nbe solved, such as trying on arbitrary clothes of all types, trying on the\nclothes from one category to another and generating image-realistic results\nwith few artifacts. To handle this issue, we in this paper first collect a new\ndataset with all types of clothes, \\ie tops, bottoms, and whole clothes, each\none has multiple categories with rich information of clothing characteristics\nsuch as patterns, logos, and other details. Based on this dataset, we then\npropose the Arbitrary Virtual Try-On Network (AVTON) that is utilized for\nall-type clothes, which can synthesize realistic try-on images by preserving\nand trading off characteristics of the target clothes and the reference person.\nOur approach includes three modules: 1) Limbs Prediction Module, which is\nutilized for predicting the human body parts by preserving the characteristics\nof the reference person. This is especially good for handling cross-category\ntry-on task (\\eg long sleeves \\(\\leftrightarrow\\) short sleeves or long pants\n\\(\\leftrightarrow\\) skirts, \\etc), where the exposed arms or legs with the skin\ncolors and details can be reasonably predicted; 2) Improved Geometric Matching\nModule, which is designed to warp clothes according to the geometry of the\ntarget person. We improve the TPS based warping method with a compactly\nsupported radial function (Wendland's \\(\\Psi\\)-function); 3) Trade-Off Fusion\nModule, which is to trade off the characteristics of the warped clothes and the\nreference person. This module is to make the generated try-on images look more\nnatural and realistic based on a fine-tune symmetry of the network structure.\nExtensive simulations are conducted and our approach can achieve better\nperformance compared with the state-of-the-art virtual try-on methods.",
    "descriptor": "",
    "authors": [
      "Yu Liu",
      "Mingbo Zhao",
      "Zhao Zhang",
      "Haijun Zhang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12346"
  },
  {
    "id": "arXiv:2111.12350",
    "title": "Supervised Neural Discrete Universal Denoiser for Adaptive Denoising",
    "abstract": "We improve the recently developed Neural DUDE, a neural network-based\nadaptive discrete denoiser, by combining it with the supervised learning\nframework. Namely, we make the supervised pre-training of Neural DUDE\ncompatible with the adaptive fine-tuning of the parameters based on the given\nnoisy data subject to denoising. As a result, we achieve a significant\ndenoising performance boost compared to the vanilla Neural DUDE, which only\ncarries out the adaptive fine-tuning step with randomly initialized parameters.\nMoreover, we show the adaptive fine-tuning makes the algorithm robust such that\na noise-mismatched or blindly trained supervised model can still achieve the\nperformance of that of the matched model. Furthermore, we make a few\nalgorithmic advancements to make Neural DUDE more scalable and deal with\nmulti-dimensional data or data with larger alphabet size. We systematically\nshow our improvements on two very diverse datasets, binary images and DNA\nsequences.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Sungmin Cha",
      "Seonwoo Min",
      "Sungroh Yoon",
      "Taesup Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12350"
  },
  {
    "id": "arXiv:2111.12351",
    "title": "Decoupling Visual-Semantic Feature Learning for Robust Scene Text  Recognition",
    "abstract": "Semantic information has been proved effective in scene text recognition.\nMost existing methods tend to couple both visual and semantic information in an\nattention-based decoder. As a result, the learning of semantic features is\nprone to have a bias on the limited vocabulary of the training set, which is\ncalled vocabulary reliance. In this paper, we propose a novel Visual-Semantic\nDecoupling Network (VSDN) to address the problem. Our VSDN contains a Visual\nDecoder (VD) and a Semantic Decoder (SD) to learn purer visual and semantic\nfeature representation respectively. Besides, a Semantic Encoder (SE) is\ndesigned to match SD, which can be pre-trained together by additional\ninexpensive large vocabulary via a simple word correction task. Thus the\nsemantic feature is more unbiased and precise to guide the visual feature\nalignment and enrich the final character representation. Experiments show that\nour method achieves state-of-the-art or competitive results on the standard\nbenchmarks, and outperforms the popular baseline by a large margin under\ncircumstances where the training set has a small size of vocabulary.",
    "descriptor": "",
    "authors": [
      "Changxu Cheng",
      "Bohan Li",
      "Qi Zheng",
      "Yongpan Wang",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12351"
  },
  {
    "id": "arXiv:2111.12358",
    "title": "SPCL: A New Framework for Domain Adaptive Semantic Segmentation via  Semantic Prototype-based Contrastive Learning",
    "abstract": "Although there is significant progress in supervised semantic segmentation,\nit remains challenging to deploy the segmentation models to unseen domains due\nto domain biases. Domain adaptation can help in this regard by transferring\nknowledge from a labeled source domain to an unlabeled target domain. Previous\nmethods typically attempt to perform the adaptation on global features,\nhowever, the local semantic affiliations accounting for each pixel in the\nfeature space are often ignored, resulting in less discriminability. To solve\nthis issue, we propose a novel semantic prototype-based contrastive learning\nframework for fine-grained class alignment. Specifically, the semantic\nprototypes provide supervisory signals for per-pixel discriminative\nrepresentation learning and each pixel of source and target domains in the\nfeature space is required to reflect the content of the corresponding semantic\nprototype. In this way, our framework is able to explicitly make intra-class\npixel representations closer and inter-class pixel representations further\napart to improve the robustness of the segmentation model as well as alleviate\nthe domain shift problem. Our method is easy to implement and attains superior\nresults compared to state-of-the-art approaches, as is demonstrated with a\nnumber of experiments. The code is publicly available at [this https\nURL](https://github.com/BinhuiXie/SPCL).",
    "descriptor": "\nComments: 15 pages; The code is publicly available at this https URL\n",
    "authors": [
      "Binhui Xie",
      "Kejia Yin",
      "Shuang Li",
      "Xinjing Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12358"
  },
  {
    "id": "arXiv:2111.12360",
    "title": "Fault-Tolerant Perception for Automated Driving A Lightweight Monitoring  Approach",
    "abstract": "While the most visible part of the safety verification process of automated\nvehicles concerns the planning and control system, it is often overlooked that\nsafety of the latter crucially depends on the fault-tolerance of the preceding\nenvironment perception. Modern perception systems feature complex and often\nmachine-learning-based components with various failure modes that can\njeopardize the overall safety. At the same time, a verification by for example\nredundant execution is not always feasible due to resource constraints. In this\npaper, we address the need for feasible and efficient perception monitors and\npropose a lightweight approach that helps to protect the integrity of the\nperception system while keeping the additional compute overhead minimal. In\ncontrast to existing solutions, the monitor is realized by a well-balanced\ncombination of sensor checks -- here using LiDAR information -- and\nplausibility checks on the object motion history. It is designed to detect\nrelevant errors in the distance and velocity of objects in the environment of\nthe automated vehicle. In conjunction with an appropriate planning system, such\na monitor can help to make safe automated driving feasible.",
    "descriptor": "",
    "authors": [
      "Cornelius Buerkle",
      "Florian Geissler",
      "Michael Paulitsch",
      "Kay-Ulrich Scholl"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.12360"
  },
  {
    "id": "arXiv:2111.12364",
    "title": "Crawling the MobileCoin Quorum System",
    "abstract": "We continuously crawl the young MobileCoin network, uncovering the quorum\nconfigurations of core nodes and the quorum system resulting from these\nconfigurations. This report discusses our crawl methodology, encountered\nchallenges, and our current empirical results. We find that the MobileCoin\nquorum system currently comprises of 7 organisations controlling a total of 10\nvalidator nodes. Current quorum set configurations prioritise safety over\nliveness. At the time of writing, one of the involved organisations is\ntechnically able to block the approval of new blocks, as is the case for one of\nthe (two) ISPs employed by crawled nodes.",
    "descriptor": "",
    "authors": [
      "Charmaine Ndolo",
      "Sebastian Henningsen",
      "Martin Florian"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.12364"
  },
  {
    "id": "arXiv:2111.12370",
    "title": "Uniform Convergence Rates for Lipschitz Learning on Graphs",
    "abstract": "Lipschitz learning is a graph-based semi-supervised learning method where one\nextends labels from a labeled to an unlabeled data set by solving the infinity\nLaplace equation on a weighted graph. In this work we prove uniform convergence\nrates for solutions of the graph infinity Laplace equation as the number of\nvertices grows to infinity. Their continuum limits are absolutely minimizing\nLipschitz extensions with respect to the geodesic metric of the domain where\nthe graph vertices are sampled from. We work under very general assumptions on\nthe graph weights, the set of labeled vertices, and the continuum domain. Our\nmain contribution is that we obtain quantitative convergence rates even for\nvery sparsely connected graphs, as they typically appear in applications like\nsemi-supervised learning. In particular, our framework allows for graph\nbandwidths down to the connectivity radius. For proving this we first show a\nquantitative convergence statement for graph distance functions to geodesic\ndistance functions in the continuum. Using the \"comparison with distance\nfunctions\" principle, we can pass these convergence statements to infinity\nharmonic functions and absolutely minimizing Lipschitz extensions.",
    "descriptor": "",
    "authors": [
      "Leon Bungert",
      "Jeff Calder",
      "Tim Roith"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.12370"
  },
  {
    "id": "arXiv:2111.12372",
    "title": "Privacy-Preserving Biometric Matching Using Homomorphic Encryption",
    "abstract": "Biometric matching involves storing and processing sensitive user\ninformation. Maintaining the privacy of this data is thus a major challenge,\nand homomorphic encryption offers a possible solution. We propose a\nprivacy-preserving biometrics-based authentication protocol based on fully\nhomomorphic encryption, where the biometric sample for a user is gathered by a\nlocal device but matched against a biometric template by a remote server\noperating solely on encrypted data. The design ensures that 1) the user's\nsensitive biometric data remains private, and 2) the user and client device are\nsecurely authenticated to the server. A proof-of-concept implementation\nbuilding on the TFHE library is also presented, which includes the underlying\nbasic operations needed to execute the biometric matching. Performance results\nfrom the implementation show how complex it is to make FHE practical in this\ncontext, but it appears that, with implementation optimisations and\nimprovements, the protocol could be used for real-world applications.",
    "descriptor": "",
    "authors": [
      "Ga\u00ebtan Pradel",
      "Chris Mitchell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.12372"
  },
  {
    "id": "arXiv:2111.12373",
    "title": "Solving cubic matrix equations arising in conservative dynamics",
    "abstract": "In this paper we consider the spatial semi-discretization of conservative\nPDEs. Such finite dimensional approximations of infinite dimensional dynamical\nsystems can be described as flows in suitable matrix spaces, which in turn\nleads to the need to solve polynomial matrix equations, a classical and\nimportant topic both in theoretical and in applied mathematics. Solving\nnumerically these equations is challenging due to the presence of several\nconservation laws which our finite models incorporate and which must be\nretained while integrating the equations of motion. In the last thirty years,\nthe theory of geometric integration has provided a variety of techniques to\ntackle this problem. These numerical methods require to solve both direct and\ninverse problems in matrix spaces. We present two algorithms to solve a cubic\nmatrix equation arising in the geometric integration of isospectral flows. This\ntype of ODEs includes finite models of ideal hydrodynamics, plasma dynamics,\nand spin particles, which we use as test problems for our algorithms.",
    "descriptor": "\nComments: 11 pages, 1 figure\n",
    "authors": [
      "Michele Benzi",
      "Milo Viviani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12373"
  },
  {
    "id": "arXiv:2111.12374",
    "title": "MM-Pyramid: Multimodal Pyramid Attentional Network for Audio-Visual  Event Localization and Video Parsing",
    "abstract": "Recognizing and localizing events in videos is a fundamental task for video\nunderstanding. Since events may occur in auditory and visual modalities,\nmultimodal detailed perception is essential for complete scene comprehension.\nMost previous works attempted to analyze videos from a holistic perspective.\nHowever, they do not consider semantic information at multiple scales, which\nmakes the model difficult to localize events in various lengths. In this paper,\nwe present a Multimodal Pyramid Attentional Network (MM-Pyramid) that captures\nand integrates multi-level temporal features for audio-visual event\nlocalization and audio-visual video parsing. Specifically, we first propose the\nattentive feature pyramid module. This module captures temporal pyramid\nfeatures via several stacking pyramid units, each of them is composed of a\nfixed-size attention block and dilated convolution block. We also design an\nadaptive semantic fusion module, which leverages a unit-level attention block\nand a selective fusion block to integrate pyramid features interactively.\nExtensive experiments on audio-visual event localization and weakly-supervised\naudio-visual video parsing tasks verify the effectiveness of our approach.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Jiashuo Yu",
      "Ying Cheng",
      "Rui-Wei Zhao",
      "Rui Feng",
      "Yuejie Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12374"
  },
  {
    "id": "arXiv:2111.12375",
    "title": "Human Activity Recognition Using 3D Orthogonally-projected EfficientNet  on Radar Time-Range-Doppler Signature",
    "abstract": "In radar activity recognition, 2D signal representations such as spectrogram,\ncepstrum and cadence velocity diagram are often utilized, while range\ninformation is often neglected. In this work, we propose to utilize the 3D\ntime-range-Doppler (TRD) representation, and design a 3D Orthogonally-Projected\nEfficientNet (3D-OPEN) to effectively capture the discriminant information\nembedded in the 3D TRD cubes for accurate classification. The proposed model\naggregates the discriminant information from three orthogonal planes projected\nfrom the 3D feature space. It alleviates the difficulty of 3D CNNs in\nexploiting sparse semantic abstractions directly from the high-dimensional 3D\nrepresentation. The proposed method is evaluated on the Millimeter-Wave Radar\nWalking Dataset. It significantly and consistently outperforms the\nstate-of-the-art methods for radar activity recognition.",
    "descriptor": "",
    "authors": [
      "Zeyu Wang",
      "Chenglin Yao",
      "Jianfeng Ren",
      "Xudong Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12375"
  },
  {
    "id": "arXiv:2111.12379",
    "title": "Efficient Anomaly Detection Using Self-Supervised Multi-Cue Tasks",
    "abstract": "Deep anomaly detection has proven to be an efficient and robust approach in\nseveral fields. The introduction of self-supervised learning has greatly helped\nmany methods including anomaly detection where simple geometric transformation\nrecognition tasks are used. However these methods do not perform well on\nfine-grained problems since they lack finer features and are usually highly\ndependent on the anomaly type. In this paper, we explore each step of\nself-supervised anomaly detection with pretext tasks. First, we introduce novel\ndiscriminative and generative tasks which focus on different visual cues. A\npiece-wise jigsaw puzzle task focuses on structure cues, while a tint rotation\nrecognition is used on each piece for colorimetry and a partial re-colorization\ntask is performed. In order for the re-colorization task to focus more on the\nobject rather than on the background, we propose to include the contextual\ncolor information of the image border. Then, we present a new\nout-of-distribution detection function and highlight its better stability\ncompared to other out-of-distribution detection methods. Along with it, we also\nexperiment different score fusion functions. Finally, we evaluate our method on\na comprehensive anomaly detection protocol composed of object anomalies with\nclassical object recognition, style anomalies with fine-grained classification\nand local anomalies with face anti-spoofing datasets. Our model can more\naccurately learn highly discriminative features using these self-supervised\ntasks. It outperforms state-of-the-art with up to 36% relative error\nimprovement on object anomalies and 40% on face anti-spoofing problems.",
    "descriptor": "",
    "authors": [
      "Loic Jezequel",
      "Ngoc-Son Vu",
      "Jean Beaudet",
      "Aymeric Histace"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12379"
  },
  {
    "id": "arXiv:2111.12382",
    "title": "Compressed Sensing Channel Estimation for OTFS Modulation in Non-Integer  Delay-Doppler Domain",
    "abstract": "This paper introduces a Compressed Sensing (CS) estimation scheme for\nOrthogonal Time Frequency Space (OTFS) channels with sparse multipath. The OTFS\nwaveform represents signals in a two dimensional Delay-Doppler (DD) orthonormal\nbasis. The proposed model does not require the assumption that the delays are\ninteger multiples of the sampling period. The analysis shows that non-integer\ndelay and Doppler shifts in the channel cannot be accurately modelled by\ninteger approximations. An Orthogonal Matching Pursuit with Binary-division\nRefinement (OMPBR) estimation algorithm is proposed. The proposed estimator\nfinds the best channel approximation over a continuous DD dictionary without\ninteger approximations. This results in a significant reduction of the\nestimation normalized mean squared error with reasonable computational\ncomplexity.",
    "descriptor": "\nComments: This is the author's self-archive preprint of a paper accepted in IEEE GLOBECOM 2021\n",
    "authors": [
      "Felipe G\u00f3mez-Cuba"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.12382"
  },
  {
    "id": "arXiv:2111.12385",
    "title": "Space-Partitioning RANSAC",
    "abstract": "A new algorithm is proposed to accelerate RANSAC model quality calculations.\nThe method is based on partitioning the joint correspondence space, e.g., 2D-2D\npoint correspondences, into a pair of regular grids. The grid cells are mapped\nby minimal sample models, estimated within RANSAC, to reject correspondences\nthat are inconsistent with the model parameters early. The proposed technique\nis general. It works with arbitrary transformations even if a point is mapped\nto a point set, e.g., as a fundamental matrix maps to epipolar lines. The\nmethod is tested on thousands of image pairs from publicly available datasets\non fundamental and essential matrix, homography and radially distorted\nhomography estimation. On average, it reduces the RANSAC run-time by 41% with\nprovably no deterioration in the accuracy. It can be straightforwardly plugged\ninto state-of-the-art RANSAC frameworks, e.g. VSAC.",
    "descriptor": "",
    "authors": [
      "Daniel Barath",
      "Gabor Valasek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12385"
  },
  {
    "id": "arXiv:2111.12386",
    "title": "One to Transfer All: A Universal Transfer Framework for Vision  Foundation Model with Few Data",
    "abstract": "The foundation model is not the last chapter of the model production\npipeline. Transferring with few data in a general way to thousands of\ndownstream tasks is becoming a trend of the foundation model's application. In\nthis paper, we proposed a universal transfer framework: One to Transfer All\n(OTA) to transfer any Vision Foundation Model (VFM) to any downstream tasks\nwith few downstream data. We first transfer a VFM to a task-specific model by\nImage Re-representation Fine-tuning (IRF) then distilling knowledge from a\ntask-specific model to a deployed model with data produced by Downstream\nImage-Guided Generation (DIGG). OTA has no dependency on upstream data, VFM,\nand downstream tasks when transferring. It also provides a way for VFM\nresearchers to release their upstream information for better transferring but\nnot leaking data due to privacy requirements. Massive experiments validate the\neffectiveness and superiority of our methods in few data setting. Our code will\nbe released.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Yujie Wang",
      "Junqin Huang",
      "Mengya Gao",
      "Yichao Wu",
      "Zhenfei Yin",
      "Ding Liang",
      "Junjie Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12386"
  },
  {
    "id": "arXiv:2111.12389",
    "title": "Track Boosting and Synthetic Data Aided Drone Detection",
    "abstract": "As the usage of drones increases with lowered costs and improved drone\ntechnology, drone detection emerges as a vital object detection task. However,\ndetecting distant drones under unfavorable conditions, namely weak contrast,\nlong-range, low visibility, requires effective algorithms. Our method\napproaches the drone detection problem by fine-tuning a YOLOv5 model with real\nand synthetically generated data using a Kalman-based object tracker to boost\ndetection confidence. Our results indicate that augmenting the real data with\nan optimal subset of synthetic data can increase the performance. Moreover,\ntemporal information gathered by object tracking methods can increase\nperformance further.",
    "descriptor": "",
    "authors": [
      "Fatih Cagatay Akyon",
      "Ogulcan Eryuksel",
      "Kamil Anil Ozfuttu",
      "Sinan Onur Altinuc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12389"
  },
  {
    "id": "arXiv:2111.12392",
    "title": "Characterization of canonical systems with six types of coins for the  change-making problem",
    "abstract": "This paper analyzes a necessary and sufficient condition for the\nchange-making problem to be solvable with a greedy algorithm. The change-making\nproblem is to minimize the number of coins used to pay a given value in a\nspecified currency system. This problem is NP-hard, and therefore the greedy\nalgorithm does not always yield an optimal solution. Yet for almost all real\ncurrency systems, the greedy algorithm outputs an optimal solution. A currency\nsystem for which the greedy algorithm returns an optimal solution for any value\nof payment is called a canonical system. Canonical systems with at most five\ntypes of coins have been characterized in previous studies. In this paper, we\ngive characterization of canonical systems with six types of coins, and we\npropose a partial generalization of characterization of canonical systems.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Yuma Suzuki",
      "Ryuhei Miyashiro"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.12392"
  },
  {
    "id": "arXiv:2111.12393",
    "title": "On the convergence of Broyden's method and some accelerated schemes for  singular problems",
    "abstract": "We consider Broyden's method and some accelerated schemes for nonlinear\nequations having a strongly regular singularity of first order with a\none-dimensional nullspace. Our two main results are as follows. First, we show\nthat the use of a preceding Newton--like step ensures convergence for starting\npoints in a starlike domain with density 1. This extends the domain of\nconvergence of these methods significantly. Second, we establish that the\nmatrix updates of Broyden's method converge q-linearly with the same asymptotic\nfactor as the iterates. This contributes to the long--standing question whether\nthe Broyden matrices converge by showing that this is indeed the case for the\nsetting at hand. Furthermore, we prove that the Broyden directions violate\nuniform linear independence, which implies that existing results for\nconvergence of the Broyden matrices cannot be applied. Numerical experiments of\nhigh precision confirm the enlarged domain of convergence, the q-linear\nconvergence of the matrix updates, and the lack of uniform linear independence.\nIn addition, they suggest that these results can be extended to singularities\nof higher order and that Broyden's method can converge r-linearly without\nconverging q-linearly. The underlying code is freely available.",
    "descriptor": "\nComments: 32 pages, 8 tables, 1 figure\n",
    "authors": [
      "Florian Mannel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12393"
  },
  {
    "id": "arXiv:2111.12395",
    "title": "I'll be back: Examining Restored Accounts On Twitter",
    "abstract": "Online social networks like Twitter actively monitor their platform to\nidentify accounts that go against their rules. Twitter enforces account level\nmoderation, i.e. suspension of a Twitter account in severe cases of platform\nabuse. A point of note is that these suspensions are sometimes temporary and\neven incorrect. Twitter provides a redressal mechanism to 'restore' suspended\naccounts. We refer to all suspended accounts who later have their suspension\nreversed as 'restored accounts'. In this paper, we release the firstever\ndataset and methodology 1 to identify restored accounts. We inspect account\nproperties and tweets of these restored accounts to get key insights into the\neffects of suspension.We build a prediction model to classify an account into\nnormal, suspended or restored. We use SHAP values to interpret this model and\nidentify important features. SHAP (SHapley Additive exPlanations) is a method\nto explain individual predictions. We show that profile features like date of\naccount creation and the ratio of retweets to total tweets are more important\nthan content-based features like sentiment scores and Ekman emotion scores when\nit comes to classification of an account as normal, suspended or restored. We\ninvestigate restored accounts further in the pre-suspension and\npost-restoration phases. We see that the number of tweets per account drop by\n53.95% in the post-restoration phase, signifying less 'spammy' behaviour after\nreversal of suspension. However, there was no substantial difference in the\ncontent of the tweets posted in the pre-suspension and post-restoration phases.",
    "descriptor": "",
    "authors": [
      "Arnav Kapoor",
      "Rishi Raj Jain",
      "Avinash Prabhu",
      "Tanvi Karandikar",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.12395"
  },
  {
    "id": "arXiv:2111.12399",
    "title": "Dictionary-based Low-Rank Approximations and the Mixed Sparse Coding  problem",
    "abstract": "Constrained tensor and matrix factorization models allow to extract\ninterpretable patterns from multiway data. Therefore identifiability properties\nand efficient algorithms for constrained low-rank approximations are nowadays\nimportant research topics. This work deals with columns of factor matrices of a\nlow-rank approximation being sparse in a known and possibly overcomplete basis,\na model coined as Dictionary-based Low-Rank Approximation (DLRA). While earlier\ncontributions focused on finding factor columns inside a dictionary of\ncandidate columns, i.e. one-sparse approximations, this work is the first to\ntackle DLRA with sparsity larger than one. I propose to focus on the\nsparse-coding subproblem coined Mixed Sparse-Coding (MSC) that emerges when\nsolving DLRA with an alternating optimization strategy. Several algorithms\nbased on sparse-coding heuristics (greedy methods, convex relaxations) are\nprovided to solve MSC. The performance of these heuristics is evaluated on\nsimulated data. Then, I show how to adapt an efficient MSC solver based on the\nLASSO to compute Dictionary-based Matrix Factorization and Canonical Polyadic\nDecomposition in the context of hyperspectral image processing and\nchemometrics. These experiments suggest that DLRA extends the modeling\ncapabilities of low-rank approximations, helps reducing estimation variance and\nenhances the identifiability and interpretability of estimated factors.",
    "descriptor": "",
    "authors": [
      "Jeremy E. Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12399"
  },
  {
    "id": "arXiv:2111.12405",
    "title": "An Attack on Feature Level-based Facial Soft-biometric Privacy  Enhancement",
    "abstract": "In the recent past, different researchers have proposed novel\nprivacy-enhancing face recognition systems designed to conceal soft-biometric\ninformation at feature level. These works have reported impressive results, but\nusually do not consider specific attacks in their analysis of privacy\nprotection. In most cases, the privacy protection capabilities of these schemes\nare tested through simple machine learning-based classifiers and visualisations\nof dimensionality reduction tools. In this work, we introduce an attack on\nfeature level-based facial soft-biometric privacy-enhancement techniques. The\nattack is based on two observations: (1) to achieve high recognition accuracy,\ncertain similarities between facial representations have to be retained in\ntheir privacy-enhanced versions; (2) highly similar facial representations\nusually originate from face images with similar soft-biometric attributes.\nBased on these observations, the proposed attack compares a privacy-enhanced\nface representation against a set of privacy-enhanced face representations with\nknown soft-biometric attributes. Subsequently, the best obtained similarity\nscores are analysed to infer the unknown soft-biometric attributes of the\nattacked privacy-enhanced face representation. That is, the attack only\nrequires a relatively small database of arbitrary face images and the\nprivacy-enhancing face recognition algorithm as a black-box. In the\nexperiments, the attack is applied to two representative approaches which have\npreviously been reported to reliably conceal the gender in privacy-enhanced\nface representations. It is shown that the presented attack is able to\ncircumvent the privacy enhancement to a considerable degree and is able to\ncorrectly classify gender with an accuracy of up to approximately 90% for both\nof the analysed privacy-enhancing face recognition systems.",
    "descriptor": "",
    "authors": [
      "Dail\u00e9 Osorio-Roig",
      "Christian Rathgeb",
      "Pawel Drozdowski",
      "Philipp Terh\u00f6rst",
      "Vitomir \u0160truc",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12405"
  },
  {
    "id": "arXiv:2111.12406",
    "title": "Auto robust relative radiometric normalization via latent change noise  modelling",
    "abstract": "Relative radiometric normalization(RRN) of different satellite images of the\nsame terrain is necessary for change detection, object\nclassification/segmentation, and map-making tasks. However, traditional RRN\nmodels are not robust, disturbing by object change, and RRN models precisely\nconsidering object change can not robustly obtain the no-change set. This paper\nproposes auto robust relative radiometric normalization methods via latent\nchange noise modeling. They utilize the prior knowledge that no change points\npossess small-scale noise under relative radiometric normalization and that\nchange points possess large-scale radiometric noise after radiometric\nnormalization, combining the stochastic expectation maximization method to\nquickly and robustly extract the no-change set to learn the relative\nradiometric normalization mapping functions. This makes our model theoretically\ngrounded regarding the probabilistic theory and mathematics deduction.\nSpecifically, when we select histogram matching as the relative radiometric\nnormalization learning scheme integrating with the mixture of Gaussian\nnoise(HM-RRN-MoG), the HM-RRN-MoG model achieves the best performance. Our\nmodel possesses the ability to robustly against clouds/fogs/changes. Our method\nnaturally generates a robust evaluation indicator for RRN that is the no-change\nset root mean square error. We apply the HM-RRN-MoG model to the latter\nvegetation/water change detection task, which reduces the radiometric contrast\nand NDVI/NDWI differences on the no-change set, generates consistent and\ncomparable results. We utilize the no-change set into the building change\ndetection task, efficiently reducing the pseudo-change and boosting the\nprecision.",
    "descriptor": "",
    "authors": [
      "Shiqi Liu",
      "Lu Wang",
      "Jie Lian",
      "Ting chen",
      "Cong Liu",
      "Xuchen Zhan",
      "Jintao Lu",
      "Jie Liu",
      "Ting Wang",
      "Dong Geng",
      "Hongwei Duan",
      "Yuze Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12406"
  },
  {
    "id": "arXiv:2111.12408",
    "title": "Markov Chain Generative Adversarial Neural Networks for Solving Bayesian  Inverse Problems in Physics Applications",
    "abstract": "In the context of solving inverse problems for physics applications within a\nBayesian framework, we present a new approach, Markov Chain Generative\nAdversarial Neural Networks (MCGANs), to alleviate the computational costs\nassociated with solving the Bayesian inference problem. GANs pose a very\nsuitable framework to aid in the solution of Bayesian inference problems, as\nthey are designed to generate samples from complicated high-dimensional\ndistributions. By training a GAN to sample from a low-dimensional latent space\nand then embedding it in a Markov Chain Monte Carlo method, we can highly\nefficiently sample from the posterior, by replacing both the high-dimensional\nprior and the expensive forward map. We prove that the proposed methodology\nconverges to the true posterior in the Wasserstein-1 distance and that sampling\nfrom the latent space is equivalent to sampling in the high-dimensional space\nin a weak sense. The method is showcased on three test cases where we perform\nboth state and parameter estimation simultaneously. The approach is shown to be\nup to two orders of magnitude more accurate than alternative approaches while\nalso being up to an order of magnitude computationally faster, in several test\ncases, including the important engineering setting of detecting leaks in\npipelines.",
    "descriptor": "",
    "authors": [
      "Nikolaj T. M\u00fccke",
      "Benjamin Sanderse",
      "Sander Boht\u00e9",
      "Cornelis W. Oosterlee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12408"
  },
  {
    "id": "arXiv:2111.12417",
    "title": "N\u00dcWA: Visual Synthesis Pre-training for Neural visUal World creAtion",
    "abstract": "This paper presents a unified multimodal pre-trained model called N\\\"UWA that\ncan generate new or manipulate existing visual data (i.e., images and videos)\nfor various visual synthesis tasks. To cover language, image, and video at the\nsame time for different scenarios, a 3D transformer encoder-decoder framework\nis designed, which can not only deal with videos as 3D data but also adapt to\ntexts and images as 1D and 2D data, respectively. A 3D Nearby Attention (3DNA)\nmechanism is also proposed to consider the nature of the visual data and reduce\nthe computational complexity. We evaluate N\\\"UWA on 8 downstream tasks.\nCompared to several strong baselines, N\\\"UWA achieves state-of-the-art results\non text-to-image generation, text-to-video generation, video prediction, etc.\nFurthermore, it also shows surprisingly good zero-shot capabilities on\ntext-guided image and video manipulation tasks. Project repo is\nhttps://github.com/microsoft/NUWA.",
    "descriptor": "",
    "authors": [
      "Chenfei Wu",
      "Jian Liang",
      "Lei Ji",
      "Fan Yang",
      "Yuejian Fang",
      "Daxin Jiang",
      "Nan Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12417"
  },
  {
    "id": "arXiv:2111.12419",
    "title": "NAM: Normalization-based Attention Module",
    "abstract": "Recognizing less salient features is the key for model compression. However,\nit has not been investigated in the revolutionary attention mechanisms. In this\nwork, we propose a novel normalization-based attention module (NAM), which\nsuppresses less salient weights. It applies a weight sparsity penalty to the\nattention modules, thus, making them more computational efficient while\nretaining similar performance. A comparison with three other attention\nmechanisms on both Resnet and Mobilenet indicates that our method results in\nhigher accuracy. Code for this paper can be publicly accessed at\nhttps://github.com/Christian-lyc/NAM.",
    "descriptor": "\nComments: 3 pages, 2 figures, 2 tables, 2 tables in the appendix\n",
    "authors": [
      "Yichao Liu",
      "Zongru Shao",
      "Yueyang Teng",
      "Nico Hoffmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.12419"
  },
  {
    "id": "arXiv:2111.12420",
    "title": "CircuitFlow: A Domain Specific Language for Dataflow Programming (with  appendices)",
    "abstract": "Dataflow applications, such as machine learning algorithms, can run for days,\nmaking it desirable to have assurances that they will work correctly. Current\ntools are not good enough: too often the interactions between tasks are not\ntype-safe, leading to undesirable run-time errors. This paper presents a new\ndeclarative Haskell Embedded DSL (eDSL) for dataflow programming: CircuitFlow.\nDefined as a Symmetric Monoidal Preorder (SMP) on data that models dependencies\nin the workflow, it has a strong mathematical basis, refocusing on how data\nflows through an application, resulting in a more expressive solution that not\nonly catches errors statically, but also achieves competitive run-time\nperformance. In our preliminary evaluation, CircuitFlow outperforms the\nindustry-leading Luigi library of Spotify by scaling better with the number of\ninputs. The innovative creation of CircuitFlow is also of note, exemplifying\nhow to create a modular eDSL whose semantics necessitates effects, and where\nstoring complex type information for program correctness is paramount.",
    "descriptor": "\nComments: 31 pages, 5 figures, to be published in PADL 2022\n",
    "authors": [
      "Riley Evans",
      "Samantha Frohlich",
      "Meng Wang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.12420"
  },
  {
    "id": "arXiv:2111.12421",
    "title": "Few-shot Named Entity Recognition with Cloze Questions",
    "abstract": "Despite the huge and continuous advances in computational linguistics, the\nlack of annotated data for Named Entity Recognition (NER) is still a\nchallenging issue, especially in low-resource languages and when domain\nknowledge is required for high-quality annotations. Recent findings in NLP show\nthe effectiveness of cloze-style questions in enabling language models to\nleverage the knowledge they acquired during the pre-training phase. In our\nwork, we propose a simple and intuitive adaptation of Pattern-Exploiting\nTraining (PET), a recent approach which combines the cloze-questions mechanism\nand fine-tuning for few-shot learning: the key idea is to rephrase the NER task\nwith patterns. Our approach achieves considerably better performance than\nstandard fine-tuning and comparable or improved results with respect to other\nfew-shot baselines without relying on manually annotated data or distant\nsupervision on three benchmark datasets: NCBI-disease, BC2GM and a private\nItalian biomedical corpus.",
    "descriptor": "",
    "authors": [
      "Valerio La Gatta",
      "Vincenzo Moscato",
      "Marco Postiglione",
      "Giancarlo Sperl\u00ec"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.12421"
  },
  {
    "id": "arXiv:2111.12423",
    "title": "Machine Learning Guided Cross-Contract Fuzzing",
    "abstract": "Smart contract transactions are increasingly interleaved by cross-contract\ncalls. While many tools have been developed to identify a common set of\nvulnerabilities to guard smart contracts, the cross-contract vulnerability is\nhowever overlooked by existing tools. Cross-contract vulnerabilities are\nexploitable bugs that manifest in the presence of more than two interacting\ncontracts. Existing methods are however limited to analyze a maximum of two\ncontracts at the same time. Detecting cross-contract vulnerabilities is highly\nnon-trivial. With multiple interacting contracts, the search space is much\nlarger than that of a single contract. To address this problem, we present\nxFuzz, a machine learning guided smart contract fuzzing framework. The machine\nlearning models are trained with novel features (e.g., word vectors and\ninstructions) and are used to filter likely benign program paths. Comparing\nwith existing static tools, machine learning model is proven to be more robust,\navoiding directly adopting manually-defined rules in specific tools. We compare\nxFuzz with three state-of-the-art tools on 7,391 contracts. xFuzz detects 18\nexploitable cross-contract vulnerabilities, of which 15 vulnerabilities are\nexposed for the first time. Furthermore, our approach is shown to be efficient\nin detecting non-cross-contract vulnerabilities as well-using less than 20%\ntime as that of other fuzzing tools, xFuzz detects twice as many\nvulnerabilities.",
    "descriptor": "",
    "authors": [
      "Yinxing Xue",
      "Jiaming Ye",
      "Wei Zhang",
      "Jun Sun",
      "Lei Ma",
      "Haijun Wang",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.12423"
  },
  {
    "id": "arXiv:2111.12427",
    "title": "Challenges of Adversarial Image Augmentations",
    "abstract": "Image augmentations applied during training are crucial for the\ngeneralization performance of image classifiers. Therefore, a large body of\nresearch has focused on finding the optimal augmentation policy for a given\ntask. Yet, RandAugment [2], a simple random augmentation policy, has recently\nbeen shown to outperform existing sophisticated policies. Only Adversarial\nAutoAugment (AdvAA) [11], an approach based on the idea of adversarial\ntraining, has shown to be better than RandAugment. In this paper, we show that\nrandom augmentations are still competitive compared to an optimal adversarial\napproach, as well as to simple curricula, and conjecture that the success of\nAdvAA is due to the stochasticity of the policy controller network, which\nintroduces a mild form of curriculum.",
    "descriptor": "\nComments: To appear at the ICBINB 2021 Neurips Workshop\n",
    "authors": [
      "Arno Blaas",
      "Xavier Suau",
      "Jason Ramapuram",
      "Nicholas Apostoloff",
      "Luca Zappella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12427"
  },
  {
    "id": "arXiv:2111.12429",
    "title": "tsflex: flexible time series processing & feature extraction",
    "abstract": "Time series processing and feature extraction are crucial and time-intensive\nsteps in conventional machine learning pipelines. Existing packages are limited\nin their real-world applicability, as they cannot cope with irregularly-sampled\nand asynchronous data. We therefore present $\\texttt{tsflex}$, a\ndomain-independent, flexible, and sequence first Python toolkit for processing\n& feature extraction, that is capable of handling irregularly-sampled sequences\nwith unaligned measurements. This toolkit is sequence first as (1) sequence\nbased arguments are leveraged for strided-window feature extraction, and (2)\nthe sequence-index is maintained through all supported operations.\n$\\texttt{tsflex}$ is flexible as it natively supports (1) multivariate time\nseries, (2) multiple window-stride configurations, and (3) integrates with\nprocessing and feature functions from other packages, while (4) making no\nassumptions about the data sampling rate regularity and synchronization. Other\nfunctionalities from this package are multiprocessing, in-depth execution time\nlogging, support for categorical & time based data, chunking sequences, and\nembedded serialization. $\\texttt{tsflex}$ is developed to enable fast and\nmemory-efficient time series processing & feature extraction. Results indicate\nthat $\\texttt{tsflex}$ is more flexible than similar packages while\noutperforming these toolkits in both runtime and memory usage.",
    "descriptor": "\nComments: The first two authors contributed equally. Submitted to SoftwareX\n",
    "authors": [
      "Jonas Van Der Donckt",
      "Jeroen Van Der Donckt",
      "Emiel Deprost",
      "Sofie Van Hoecke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12429"
  },
  {
    "id": "arXiv:2111.12434",
    "title": "The Evolving Path of \"the Right to Be Left Alone\" - When Privacy Meets  Technology",
    "abstract": "This paper deals with the hot, evergreen topic of the relationship between\nprivacy and technology. We give extensive motivation for why the privacy debate\nis still alive for private citizens and institutions, and we investigate the\nprivacy concept. This paper proposes a novel vision of the privacy ecosystem,\nintroducing privacy dimensions, the related users' expectations, the privacy\nviolations, and the changing factors. We provide a critical assessment of the\nPrivacy by Design paradigm, strategies, tactics, patterns, and\nPrivacy-Enhancing Technologies, highlighting the current open issues. We\nbelieve that promising approaches to tackle the privacy challenges move in two\ndirections: (i) identification of effective privacy metrics; and (ii) adoption\nof formal tools to design privacy-compliant applications.",
    "descriptor": "\nComments: Accepted at IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications 2021 (IEEE TPS-ISA 2021)\n",
    "authors": [
      "Michela Iezzi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.12434"
  },
  {
    "id": "arXiv:2111.12436",
    "title": "Matroid Partition Property and the Secretary Problem",
    "abstract": "A matroid $\\mathcal{M}$ on a set $E$ of elements has the $\\alpha$-partition\nproperty, for some $\\alpha>0$, if it is possible to (randomly) construct a\npartition matroid $\\mathcal{P}$ on (a subset of) elements of $\\mathcal{M}$ such\nthat every independent set of $\\mathcal{P}$ is independent in $\\mathcal{M}$ and\nfor any weight function $w:E\\to\\mathbb{R}_{\\geq 0}$, the expected value of the\noptimum of the matroid secretary problem on $\\mathcal{P}$ is at least an\n$\\alpha$-fraction of the optimum on $\\mathcal{M}$. We show that the complete\nbinary matroid, ${\\cal B}_d$ on $\\mathbb{F}_2^d$ does not satisfy the\n$\\alpha$-partition property for any constant $\\alpha>0$ (independent of $d$).\nFurthermore, we refute a recent conjecture of B\\'erczi, Schwarcz, and\nYamaguchi by showing the same matroid is $2^d/d$-colorable but cannot be\nreduced to an $\\alpha 2^d/d$-colorable partition matroid for any $\\alpha$ that\nis sublinear in $d$.",
    "descriptor": "",
    "authors": [
      "Dorna Abdolazimi",
      "Anna R. Karlin",
      "Nathan Klein",
      "Shayan Oveis Gharan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.12436"
  },
  {
    "id": "arXiv:2111.12443",
    "title": "A topology optimisation of acoustic devices based on the frequency  response estimation with the Pad\u00e9 approximation",
    "abstract": "We propose a topology optimisation of acoustic devices that work in a certain\nbandwidth. To achieve this, we define the objective function as the\nfrequency-averaged sound intensity at given observation points, which is\nrepresented by a frequency integral over a given frequency band. It is,\nhowever, prohibitively expensive to evaluate such an integral naively by a\nquadrature. We thus estimate the frequency response by the Pad\\'{e}\napproximation and integrate the approximated function to obtain the objective\nfunction. The corresponding topological derivative is derived with the help of\nthe adjoint variable method and chain rule. It is shown that the objective and\nits sensitivity can be evaluated semi-analytically. We present efficient\nnumerical procedures to compute them and incorporate them into a topology\noptimisation based on the level-set method. We confirm the validity and\neffectiveness of the present method through some numerical examples.",
    "descriptor": "",
    "authors": [
      "Yuta Honshuku",
      "Hiroshi Isakari"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.12443"
  },
  {
    "id": "arXiv:2111.12444",
    "title": "Edge Artificial Intelligence for 6G: Vision, Enabling Technologies, and  Applications",
    "abstract": "The thriving of artificial intelligence (AI) applications is driving the\nfurther evolution of wireless networks. It has been envisioned that 6G will be\ntransformative and will revolutionize the evolution of wireless from \"connected\nthings\" to \"connected intelligence\". However, state-of-the-art deep learning\nand big data analytics based AI systems require tremendous computation and\ncommunication resources, causing significant latency, energy consumption,\nnetwork congestion, and privacy leakage in both of the training and inference\nprocesses. By embedding model training and inference capabilities into the\nnetwork edge, edge AI stands out as a disruptive technology for 6G to\nseamlessly integrate sensing, communication, computation, and intelligence,\nthereby improving the efficiency, effectiveness, privacy, and security of 6G\nnetworks. In this paper, we shall provide our vision for scalable and\ntrustworthy edge AI systems with integrated design of wireless communication\nstrategies and decentralized machine learning models. New design principles of\nwireless networks, service-driven resource allocation optimization methods, as\nwell as a holistic end-to-end system architecture to support edge AI will be\ndescribed. Standardization, software and hardware platforms, and application\nscenarios are also discussed to facilitate the industrialization and\ncommercialization of edge AI systems.",
    "descriptor": "\nComments: This work is a JSAC invited survey & tutorial paper. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Khaled B. Letaief",
      "Yuanming Shi",
      "Jianmin Lu",
      "Jianhua Lu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.12444"
  },
  {
    "id": "arXiv:2111.12447",
    "title": "Revisiting Contextual Toxicity Detection in Conversations",
    "abstract": "Understanding toxicity in user conversations is undoubtedly an important\nproblem. As it has been argued in previous work, addressing \"covert\" or\nimplicit cases of toxicity is particularly hard and requires context. Very few\nprevious studies have analysed the influence of conversational context in human\nperception or in automated detection models. We dive deeper into both these\ndirections. We start by analysing existing contextual datasets and come to the\nconclusion that toxicity labelling by humans is in general influenced by the\nconversational structure, polarity and topic of the context. We then propose to\nbring these findings into computational detection models by introducing (a)\nneural architectures for contextual toxicity detection that are aware of the\nconversational structure, and (b) data augmentation strategies that can help\nmodel contextual toxicity detection. Our results have shown the encouraging\npotential of neural architectures that are aware of the conversation structure.\nWe have also demonstrated that such models can benefit from synthetic data,\nespecially in the social media domain.",
    "descriptor": "",
    "authors": [
      "Julia Ive",
      "Atijit Anuchitanukul",
      "Lucia Specia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.12447"
  },
  {
    "id": "arXiv:2111.12448",
    "title": "3D Shape Variational Autoencoder Latent Disentanglement via Mini-Batch  Feature Swapping for Bodies and Faces",
    "abstract": "Learning a disentangled, interpretable, and structured latent representation\nin 3D generative models of faces and bodies is still an open problem. The\nproblem is particularly acute when control over identity features is required.\nIn this paper, we propose an intuitive yet effective self-supervised approach\nto train a 3D shape variational autoencoder (VAE) which encourages a\ndisentangled latent representation of identity features. Curating the\nmini-batch generation by swapping arbitrary features across different shapes\nallows to define a loss function leveraging known differences and similarities\nin the latent representations. Experimental results conducted on 3D meshes show\nthat state-of-the-art methods for latent disentanglement are not able to\ndisentangle identity features of faces and bodies. Our proposed method properly\ndecouples the generation of such features while maintaining good representation\nand reconstruction capabilities.",
    "descriptor": "",
    "authors": [
      "Simone Foti",
      "Bongjin Koo",
      "Danail Stoyanov",
      "Matthew J. Clarkson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12448"
  },
  {
    "id": "arXiv:2111.12449",
    "title": "Background-Click Supervision for Temporal Action Localization",
    "abstract": "Weakly supervised temporal action localization aims at learning the\ninstance-level action pattern from the video-level labels, where a significant\nchallenge is action-context confusion. To overcome this challenge, one recent\nwork builds an action-click supervision framework. It requires similar\nannotation costs but can steadily improve the localization performance when\ncompared to the conventional weakly supervised methods. In this paper, by\nrevealing that the performance bottleneck of the existing approaches mainly\ncomes from the background errors, we find that a stronger action localizer can\nbe trained with labels on the background video frames rather than those on the\naction frames. To this end, we convert the action-click supervision to the\nbackground-click supervision and develop a novel method, called BackTAL.\nSpecifically, BackTAL implements two-fold modeling on the background video\nframes, i.e. the position modeling and the feature modeling. In position\nmodeling, we not only conduct supervised learning on the annotated video frames\nbut also design a score separation module to enlarge the score differences\nbetween the potential action frames and backgrounds. In feature modeling, we\npropose an affinity module to measure frame-specific similarities among\nneighboring frames and dynamically attend to informative neighbors when\ncalculating temporal convolution. Extensive experiments on three benchmarks are\nconducted, which demonstrate the high performance of the established BackTAL\nand the rationality of the proposed background-click supervision. Code is\navailable at https://github.com/VividLe/BackTAL.",
    "descriptor": "\nComments: To appear at TPAMI\n",
    "authors": [
      "Le Yang",
      "Junwei Han",
      "Tao Zhao",
      "Tianwei Lin",
      "Dingwen Zhang",
      "Jianxin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12449"
  },
  {
    "id": "arXiv:2111.12454",
    "title": "Exploring Business Process Deviance with Sequential and Declarative  Patterns",
    "abstract": "Business process deviance refers to the phenomenon whereby a subset of the\nexecutions of a business process deviate, in a negative or positive way, with\nrespect to {their} expected or desirable outcomes. Deviant executions of a\nbusiness process include those that violate compliance rules, or executions\nthat undershoot or exceed performance targets. Deviance mining is concerned\nwith uncovering the reasons for deviant executions by analyzing event logs\nstored by the systems supporting the execution of a business process. In this\npaper, the problem of explaining deviations in business processes is first\ninvestigated by using features based on sequential and declarative patterns,\nand a combination of them. Then, the explanations are further improved by\nleveraging the data attributes of events and traces in event logs through\nfeatures based on pure data attribute values and data-aware declarative rules.\nThe explanations characterizing the deviances are then extracted by direct and\nindirect methods for rule induction. Using real-life logs from multiple\ndomains, a range of feature types and different forms of decision rules are\nevaluated in terms of their ability to accurately discriminate between\nnon-deviant and deviant executions of a process as well as in terms of\nunderstandability of the final outcome returned to the users.",
    "descriptor": "",
    "authors": [
      "Giacomo Bergami",
      "Chiara Di Francescomarino",
      "Chiara Ghidini",
      "Fabrizio Maria Maggi",
      "Joonas Puura"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12454"
  },
  {
    "id": "arXiv:2111.12456",
    "title": "SoK: Untangling File-based Encryption on Mobile Devices",
    "abstract": "File-based encryption (FBE) schemes have been developed by software vendors\nto address security concerns related to data storage. While methods of\nencrypting data-at-rest may seem relatively straightforward, the main\nproponents of these technologies in mobile devices have nonetheless created\nseemingly different FBE solutions. As most of the underlying design decisions\nare described either at a high-level in whitepapers, or are accessible at a\nlow-level by examining the corresponding source code (Android) or through\nreverse-engineering (iOS), comparisons between schemes and discussions on their\nrelative strengths are scarce. In this paper, we propose a formal framework for\nthe study of file-based encryption systems, focusing on two prominent\nimplementations: the FBE scheme used in Android and Linux operating systems, as\nwell as the FBE scheme used in iOS. Our proposed formal model and our detailed\ndescription of the existing algorithms are based on documentation of diverse\nnature, such as whitepapers, technical reports, presentations and blog posts,\namong others. Using our framework we validate the security of the existing key\nderivation chains, as well as the security of the overall designs, under\nwidely-known security assumptions for symmetric ciphers, such as IND-CPA or\nINT-CTXT security, in the random-oracle model.",
    "descriptor": "",
    "authors": [
      "David Galindo",
      "Jia Liu",
      "Chris McMahon Stone",
      "Mihai Ordean"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.12456"
  },
  {
    "id": "arXiv:2111.12460",
    "title": "ViCE: Self-Supervised Visual Concept Embeddings as Contextual and Pixel  Appearance Invariant Semantic Representations",
    "abstract": "This work presents a self-supervised method to learn dense semantically rich\nvisual concept embeddings for images inspired by methods for learning word\nembeddings in NLP. Our method improves on prior work by generating more\nexpressive embeddings and by being applicable for high-resolution images.\nViewing the generation of natural images as a stochastic process where a set of\nlatent visual concepts give rise to observable pixel appearances, our method is\nformulated to learn the inverse mapping from pixels to concepts. Our method\ngreatly improves the effectiveness of self-supervised learning for dense\nembedding maps by introducing superpixelization as a natural hierarchical step\nup from pixels to a small set of visually coherent regions. Additional\ncontributions are regional contextual masking with nonuniform shapes matching\nvisually coherent patches and complexity-based view sampling inspired by masked\nlanguage models. The enhanced expressiveness of our dense embeddings is\ndemonstrated by significantly improving the state-of-the-art representation\nquality benchmarks on COCO (+12.94 mIoU, +87.6\\%) and Cityscapes (+16.52 mIoU,\n+134.2\\%). Results show favorable scaling and domain generalization properties\nnot demonstrated by prior work.",
    "descriptor": "",
    "authors": [
      "Robin Karlsson",
      "Tomoki Hayashi",
      "Keisuke Fujii",
      "Alexander Carballo",
      "Kento Ohtani",
      "Kazuya Takeda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12460"
  },
  {
    "id": "arXiv:2111.12465",
    "title": "Introduction to Presentation Attack Detection in Iris Biometrics and  Recent Advances",
    "abstract": "Iris recognition technology has attracted an increasing interest in the last\ndecades in which we have witnessed a migration from research laboratories to\nreal world applications. The deployment of this technology raises questions\nabout the main vulnerabilities and security threats related to these systems.\nAmong these threats presentation attacks stand out as some of the most relevant\nand studied. Presentation attacks can be defined as presentation of human\ncharacteristics or artifacts directly to the capture device of a biometric\nsystem trying to interfere its normal operation. In the case of the iris, these\nattacks include the use of real irises as well as artifacts with different\nlevel of sophistication such as photographs or videos. This chapter introduces\niris Presentation Attack Detection (PAD) methods that have been developed to\nreduce the risk posed by presentation attacks. First, we summarise the most\npopular types of attacks including the main challenges to address. Secondly, we\npresent a taxonomy of Presentation Attack Detection methods as a brief\nintroduction to this very active research area. Finally, we discuss the\nintegration of these methods into Iris Recognition Systems according to the\nmost important scenarios of practical application.",
    "descriptor": "\nComments: Chapter of the Handbook of Biometric Anti-Spoofing (Third Edition)\n",
    "authors": [
      "Aythami Morales",
      "Julian Fierrez",
      "Javier Galbally",
      "Marta Gomez-Barrero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12465"
  },
  {
    "id": "arXiv:2111.12472",
    "title": "COVID-19 vaccination certificates in the Darkweb",
    "abstract": "COVID-19 vaccines have been rolled out in many countries and with them a\nnumber of vaccination certificates. For instance, the EU is utilizing a digital\ncertificate in the form of a QR-code that is digitally signed and can be easily\nvalidated throughout all EU countries.In this paper, we investigate the current\nstate of the COVID-19 vaccination certificate market in the darkweb with a\nfocus on the EU Digital Green Certificate (DGC). We investigate $17$\nmarketplaces and $10$ vendor shops, that include vaccination certificates in\ntheir listings. Our results suggest that a multitude of sellers in both types\nof platforms are advertising selling capabilities. According to their claims,\nit is possible to buy fake vaccination certificates issued in most countries\nworldwide. We demonstrate some examples of such sellers, including how they\nadvertise their capabilities, and the methods they claim to be using to provide\ntheir services. We highlight two particular cases of vendor shops, with one of\nthem showing an elevated degree of professionalism, showcasing forged valid\ncertificates, the validity of which we verify using two different national\nmobile COVID-19 applications.",
    "descriptor": "",
    "authors": [
      "Dimitrios Georgoulias",
      "Jens Myrup Pedersen",
      "Morten Falch",
      "Emmanouil Vasilomanolakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.12472"
  },
  {
    "id": "arXiv:2111.12476",
    "title": "Hierarchical Modular Network for Video Captioning",
    "abstract": "Video captioning aims to generate natural language descriptions according to\nthe content, where representation learning plays a crucial role. Existing\nmethods are mainly developed within the supervised learning framework via\nword-by-word comparison of the generated caption against the ground-truth text\nwithout fully exploiting linguistic semantics. In this work, we propose a\nhierarchical modular network to bridge video representations and linguistic\nsemantics from three levels before generating captions. In particular, the\nhierarchy is composed of: (I) Entity level, which highlights objects that are\nmost likely to be mentioned in captions. (II) Predicate level, which learns the\nactions conditioned on highlighted objects and is supervised by the predicate\nin captions. (III) Sentence level, which learns the global semantic\nrepresentation and is supervised by the whole caption. Each level is\nimplemented by one module. Extensive experimental results show that the\nproposed method performs favorably against the state-of-the-art models on the\ntwo widely-used benchmarks: MSVD 104.0% and MSR-VTT 51.5% in CIDEr score.",
    "descriptor": "",
    "authors": [
      "Hanhua Ye",
      "Guorong Li",
      "Yuankai Qi",
      "Shuhui Wang",
      "Qingming Huang",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12476"
  },
  {
    "id": "arXiv:2111.12477",
    "title": "Selection of pseudo-annotated data for adverse drug reaction  classification across drug groups",
    "abstract": "Automatic monitoring of adverse drug events (ADEs) or reactions (ADRs) is\ncurrently receiving significant attention from the biomedical community. In\nrecent years, user-generated data on social media has become a valuable\nresource for this task. Neural models have achieved impressive performance on\nautomatic text classification for ADR detection. Yet, training and evaluation\nof these methods are carried out on user-generated texts about a targeted drug.\nIn this paper, we assess the robustness of state-of-the-art neural\narchitectures across different drug groups. We investigate several strategies\nto use pseudo-labeled data in addition to a manually annotated train set.\nOut-of-dataset experiments diagnose the bottleneck of supervised models in\nterms of breakdown performance, while additional pseudo-labeled data improves\noverall results regardless of the text selection strategy.",
    "descriptor": "\nComments: Accepted to AIST 2021\n",
    "authors": [
      "Ilseyar Alimova",
      "Elena Tutubalina"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12477"
  },
  {
    "id": "arXiv:2111.12478",
    "title": "Predictive Data Race Detection for GPUs",
    "abstract": "The high degree of parallelism and relatively complicated synchronization\nmechanisms in GPUs make writing correct kernels difficult. Data races pose one\nsuch concurrency correctness challenge, and therefore, effective methods of\ndetecting as many data races as possible are required.\nPredictive partial order relations for CPU programs aim to expose data races\nthat can be hidden during a dynamic execution. Existing predictive partial\norders cannot be na\\\"ively applied to analyze GPU kernels because of the\ndifferences in programming models. This work proposes GWCP, a predictive\npartial order for data race detection of GPU kernels. GWCP extends a sound and\nprecise relation called weak-causally-precedes (WCP) proposed in the context of\nmultithreaded shared memory CPU programs to GPU kernels. GWCP takes into\naccount the GPU thread hierarchy and different synchronization semantics such\nas barrier synchronization and scoped atomics and locks.\nWe implement a tool called PreDataR that tracks the GWCP relation using\nbinary instrumentation. PreDataR includes three optimizations and a novel\nvector clock compression scheme that are readily applicable to other partial\norder based analyses. Our evaluation with several microbenchmarks and\nbenchmarks shows that PreDataR has better data race coverage compared to prior\ntechniques at practical run-time overheads.",
    "descriptor": "\nComments: 14 pages, 12 figures, 4 tables\n",
    "authors": [
      "Sagnik Dey",
      "Mayant Mukul",
      "Parth Sharma",
      "Swarnendu Biswas"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.12478"
  },
  {
    "id": "arXiv:2111.12479",
    "title": "Construction and evaluation of PH curves in exponential-polynomial  spaces",
    "abstract": "In the past few decades polynomial curves with Pythagorean Hodograph (for\nshort PH curves) have received considerable attention due to their usefulness\nin various CAD/CAM areas, manufacturing, numerical control machining and\nrobotics. This work deals with classes of PH curves built-upon\nexponential-polynomial spaces (for short EPH curves). In particular, for the\ntwo most frequently encountered exponential-polynomial spaces, we first provide\nnecessary and sufficient conditions to be satisfied by the control polygon of\nthe B\\'{e}zier-like curve in order to fulfill the PH property. Then, for such\nEPH curves, fundamental characteristics like parametric speed or cumulative and\ntotal arc length are discussed to show the interesting analogies with their\nwell-known polynomial counterparts. Differences and advantages with respect to\nordinary PH curves become commendable when discussing the solutions to\napplication problems like the interpolation of first-order Hermite data.\nFinally, a new evaluation algorithm for EPH curves is proposed and shown to\ncompare favorably with the celebrated de Casteljau-like algorithm and two\nrecently proposed methods: Wo\\'zny and Chudy's algorithm and the dynamic\nevaluation procedure by Yang and Hong.",
    "descriptor": "",
    "authors": [
      "Lucia Romani",
      "Alberto Viscardi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12479"
  },
  {
    "id": "arXiv:2111.12480",
    "title": "Octree Transformer: Autoregressive 3D Shape Generation on Hierarchically  Structured Sequences",
    "abstract": "Autoregressive models have proven to be very powerful in NLP text generation\ntasks and lately have gained popularity for image generation as well. However,\nthey have seen limited use for the synthesis of 3D shapes so far. This is\nmainly due to the lack of a straightforward way to linearize 3D data as well as\nto scaling problems with the length of the resulting sequences when describing\ncomplex shapes. In this work we address both of these problems. We use octrees\nas a compact hierarchical shape representation that can be sequentialized by\ntraversal ordering. Moreover, we introduce an adaptive compression scheme, that\nsignificantly reduces sequence lengths and thus enables their effective\ngeneration with a transformer, while still allowing fully autoregressive\nsampling and parallel training. We demonstrate the performance of our model by\ncomparing against the state-of-the-art in shape generation.",
    "descriptor": "",
    "authors": [
      "Moritz Ibing",
      "Gregor Kobsik",
      "Leif Kobbelt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12480"
  },
  {
    "id": "arXiv:2111.12481",
    "title": "It Is Different When Items Are Older: Debiasing Recommendations When  Selection Bias and User Preferences Are Dynamic",
    "abstract": "User interactions with recommender systems (RSs) are affected by user\nselection bias, e.g., users are more likely to rate popular items (popularity\nbias) or items that they expect to enjoy beforehand (positivity bias). Methods\nexist for mitigating the effects of selection bias in user ratings on the\nevaluation and optimization of RSs. However, these methods treat selection bias\nas static, despite the fact that the popularity of an item may change\ndrastically over time and the fact that user preferences may also change over\ntime. We focus on the age of an item and its effect on selection bias and user\npreferences. Our experimental analysis reveals that the rating behavior of\nusers on the MovieLens dataset is better captured by methods that consider\neffects from the age of item on bias and preferences. We theoretically show\nthat in a dynamic scenario in which both the selection bias and user\npreferences are dynamic, existing debiasing methods are no longer unbiased. To\naddress this limitation, we introduce DebiAsing in the dyNamiC scEnaRio\n(DANCER), a novel debiasing method that extends the inverse propensity scoring\ndebiasing method to account for dynamic selection bias and user preferences.\nOur experimental results indicate that DANCER improves rating prediction\nperformance compared to debiasing methods that incorrectly assume that\nselection bias is static in a dynamic scenario. To the best of our knowledge,\nDANCER is the first debiasing method that accounts for dynamic selection bias\nand user preferences in RSs.",
    "descriptor": "\nComments: WSDM 2022\n",
    "authors": [
      "Jin Huang",
      "Harrie Oosterhuis",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.12481"
  },
  {
    "id": "arXiv:2111.12485",
    "title": "Graph Modularity: Towards Understanding the Cross-Layer Transition of  Feature Representations in Deep Neural Networks",
    "abstract": "There are good arguments to support the claim that feature representations\neventually transition from general to specific in deep neural networks (DNNs),\nbut this transition remains relatively underexplored. In this work, we move a\ntiny step towards understanding the transition of feature representations. We\nfirst characterize this transition by analyzing the class separation in\nintermediate layers, and next model the process of class separation as\ncommunity evolution in dynamic graphs. Then, we introduce modularity, a common\nmetric in graph theory, to quantify the evolution of communities. We find that\nmodularity tends to rise as the layer goes deeper, but descends or reaches a\nplateau at particular layers. Through an asymptotic analysis, we show that\nmodularity can provide quantitative analysis of the transition of the feature\nrepresentations. With the insight on feature representations, we demonstrate\nthat modularity can also be used to identify and locate redundant layers in\nDNNs, which provides theoretical guidance for layer pruning. Based on this\ninspiring finding, we propose a layer-wise pruning method based on modularity.\nFurther experiments show that our method can prune redundant layers with\nminimal impact on performance. The codes are available at\nhttps://github.com/yaolu-zjut/Dynamic-Graphs-Construction.",
    "descriptor": "",
    "authors": [
      "Yao Lu",
      "Wen Yang",
      "Yunzhe Zhang",
      "Jinhuan Wang",
      "Shengbo Gong",
      "Zhuangzhi Chen",
      "Zuohui Chen",
      "Qi Xuan",
      "Xiaoniu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12485"
  },
  {
    "id": "arXiv:2111.12487",
    "title": "Distributed Evaluation of Graph Queries using Recursive Relational  Algebra",
    "abstract": "We present a system called Dist-$\\mu$-RA for the distributed evaluation of\nrecursive graph queries. Dist-$\\mu$-RA builds on the recursive relational\nalgebra and extends it with evaluation plans suited for the distributed\nsetting. The goal is to offer expressivity for high-level queries while\nproviding efficiency at scale and reducing communication costs. Experimental\nresults on both real and synthetic graphs show the effectiveness of the\nproposed approach compared to existing systems.",
    "descriptor": "",
    "authors": [
      "Sarah Chlyah",
      "Pierre Genev\u00e8s",
      "Nabil Laya\u00efda"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.12487"
  },
  {
    "id": "arXiv:2111.12488",
    "title": "Intuitive Shape Editing in Latent Space",
    "abstract": "The use of autoencoders for shape generation and editing suffers from\nmanipulations in latent space that may lead to unpredictable changes in the\noutput shape. We present an autoencoder-based method that enables intuitive\nshape editing in latent space by disentangling latent sub-spaces to obtain\ncontrol points on the surface and style variables that can be manipulated\nindependently. The key idea is adding a Lipschitz-type constraint to the loss\nfunction, i.e. bounding the change of the output shape proportionally to the\nchange in latent space, leading to interpretable latent space representations.\nThe control points on the surface can then be freely moved around, allowing for\nintuitive shape editing directly in latent space. We evaluate our method by\ncomparing it to state-of-the-art data-driven shape editing methods. Besides\nshape manipulation, we demonstrate the expressiveness of our control points by\nleveraging them for unsupervised part segmentation.",
    "descriptor": "",
    "authors": [
      "Tim Elsner",
      "Moritz Ibing",
      "Victor Czech",
      "Julius Nehring-Wirxel",
      "Leif Kobbelt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12488"
  },
  {
    "id": "arXiv:2111.12489",
    "title": "Repeated-root Constacyclic Codes with Optimal Locality",
    "abstract": "A code is called a locally repairable code (LRC) if any code symbol is a\nfunction of a small fraction of other code symbols. When a locally repairable\ncode is employed in a distributed storage systems, an erased symbol can be\nrecovered by accessing only a small number of other symbols, and hence\nalleviating the network resources required during the repair process. In this\npaper we consider repeated-root constacyclic codes, which is a generalization\nof cyclic codes, that are optimal with respect to a Singleton-like bound on\nminimum distance. An LRC with the structure of a constacyclic code can be\nencoded efficiently using any encoding algorithm for constacyclic codes in\ngeneral. In this paper we obtain optimal LRCs among these repeated-root\nconstacyclic codes. Several infinite classes of optimal LRCs over a fixed\nalphabet are found. Under a further assumption that the ambient space of the\nrepeated-root constacyclic codes is a chain ring, we show that there is no\nother optimal LRC.",
    "descriptor": "",
    "authors": [
      "Wei Zhao",
      "Kenneth W. Shum",
      "Shenghao Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.12489"
  },
  {
    "id": "arXiv:2111.12490",
    "title": "Causal Regularization Using Domain Priors",
    "abstract": "Neural networks leverage both causal and correlation-based relationships in\ndata to learn models that optimize a given performance criterion, such as\nclassification accuracy. This results in learned models that may not\nnecessarily reflect the true causal relationships between input and output.\nWhen domain priors of causal relationships are available at the time of\ntraining, it is essential that a neural network model maintains these\nrelationships as causal, even as it learns to optimize the performance\ncriterion. We propose a causal regularization method that can incorporate such\ncausal domain priors into the network and which supports both direct and total\ncausal effects. We show that this approach can generalize to various kinds of\nspecifications of causal priors, including monotonicity of causal effect of a\ngiven input feature or removing a certain influence for purposes of fairness.\nOur experiments on eleven benchmark datasets show the usefulness of this\napproach in regularizing a learned neural network model to maintain desired\ncausal effects. On most datasets, domain-prior consistent models can be\nobtained without compromising on accuracy.",
    "descriptor": "",
    "authors": [
      "Abbavaram Gowtham Reddy",
      "Sai Srinivas Kancheti",
      "Vineeth N Balasubramanian",
      "Amit Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12490"
  },
  {
    "id": "arXiv:2111.12493",
    "title": "Time and Memory Efficient Algorithm for Structural Graph Summaries over  Evolving Graphs",
    "abstract": "Existing graph summarization algorithms are tailored to specific graph\nsummary models, only support one-time batch computation, are designed and\nimplemented for a specific task, or are evaluated using static graphs. Our\nnovel, incremental, parallel algorithm addresses all of these shortcomings. We\nsupport infinitely many structural graph summary models defined in a formal\nlanguage. All graph summaries can be updated in time $\\mathcal{O}(\\Delta \\cdot\nd^k)$, where $\\Delta$ is the number of additions, deletions, and modifications\nto the input graph, $d$ is its maximum degree, and $k$ is the maximum distance\nin the subgraphs considered while summarizing. We empirically evaluate the\nperformance of our incremental algorithm on benchmark and real-world datasets.\nOverall our experiments show that, for commonly used summary models and\ndatasets, the incremental summarization algorithm almost always outperforms its\nbatch counterpart, even when about $50\\%$ of the graph database changes.\nUpdating the summaries of the real-world DyLDO-core dataset with our\nincremental algorithm is $5$ to $44$~times faster than computing a new summary,\nwhen using four cores. Furthermore, the incremental computations require a low\nmemory overhead of only $8\\%$ ($\\pm 1\\%$). Finally, the incremental\nsummarization algorithm outperforms the batch algorithm even when using fewer\ncores.",
    "descriptor": "",
    "authors": [
      "Till Blume",
      "David Richerby",
      "Ansgar Scherp"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.12493"
  },
  {
    "id": "arXiv:2111.12494",
    "title": "Time-Energy-Constrained Closed-Loop FBL Communication for Dependable MEC",
    "abstract": "The deployment of multi-access edge computing (MEC) is paving the way towards\npervasive intelligence in future 6G networks. This new paradigm also proposes\nemerging requirements of dependable communications, which goes beyond the\nultra-reliable low latency communication (URLLC), focusing on the performance\nof a closed loop instead of that of an unidirectional link. This work studies\nthe simple but efficient one-shot transmission scheme, investigating the\nclosed-loop-reliability-optimal policy of blocklength allocation under\nstringent time and energy constraints.",
    "descriptor": "\nComments: Accepted for publication at CSCN 2021\n",
    "authors": [
      "Bin Han",
      "Yao Zhu",
      "Anke Schmeink",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.12494"
  },
  {
    "id": "arXiv:2111.12495",
    "title": "Softmax Gradient Tampering: Decoupling the Backward Pass for Improved  Fitting",
    "abstract": "We introduce Softmax Gradient Tampering, a technique for modifying the\ngradients in the backward pass of neural networks in order to enhance their\naccuracy. Our approach transforms the predicted probability values using a\npower-based probability transformation and then recomputes the gradients in the\nbackward pass. This modification results in a smoother gradient profile, which\nwe demonstrate empirically and theoretically. We do a grid search for the\ntransform parameters on residual networks. We demonstrate that modifying the\nsoftmax gradients in ConvNets may result in increased training accuracy, thus\nincreasing the fit across the training data and maximally utilizing the\nlearning capacity of neural networks. We get better test metrics and lower\ngeneralization gaps when combined with regularization techniques such as label\nsmoothing. Softmax gradient tampering improves ResNet-50's test accuracy by\n$0.52\\%$ over the baseline on the ImageNet dataset. Our approach is very\ngeneric and may be used across a wide range of different network architectures\nand datasets.",
    "descriptor": "\nComments: 13 pages, 4 figures, conference\n",
    "authors": [
      "Bishshoy Das",
      "Milton Mondal",
      "Brejesh Lall",
      "Shiv Dutt Joshi",
      "Sumantra Dutta Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12495"
  },
  {
    "id": "arXiv:2111.12497",
    "title": "Performance of Reconfigurable Intelligent Surfaces in the Presence of  Generalized Gaussian Noise",
    "abstract": "In this letter, we investigate the performance of reconfigurable intelligent\nsurface (RIS)-assisted communications, under the assumption of generalized\nGaussian noise (GGN), over Rayleigh fading channels. Specifically, we consider\nan RIS, equipped with $N$ reflecting elements, and derive a novel closed-form\nexpression for the symbol error rate (SER) of arbitrary modulation schemes. The\nusefulness of the derived new expression is that it can be used to capture the\nSER performance in the presence of special additive noise distributions such as\nGamma, Laplacian, and Gaussian noise. These special cases are also considered\nand their associated asymptotic SER expressions are derived, and then employed\nto quantify the achievable diversity order of the system. The theoretical\nframework is corroborated by numerical results, which reveal that the shaping\nparameter of the GGN ($\\alpha$) has a negligible effect on the diversity order\nof RIS-assisted systems, particularly for large $\\alpha$ values. Accordingly,\nthe maximum achievable diversity order is determined by $N$.",
    "descriptor": "",
    "authors": [
      "Lina Mohjazi",
      "Lina Bariah",
      "Sami Muhaidat",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.12497"
  },
  {
    "id": "arXiv:2111.12498",
    "title": "Meta Mask Correction for Nuclei Segmentation in Histopathological Image",
    "abstract": "Nuclei segmentation is a fundamental task in digital pathology analysis and\ncan be automated by deep learning-based methods. However, the development of\nsuch an automated method requires a large amount of data with precisely\nannotated masks which is hard to obtain. Training with weakly labeled data is a\npopular solution for reducing the workload of annotation. In this paper, we\npropose a novel meta-learning-based nuclei segmentation method which follows\nthe label correction paradigm to leverage data with noisy masks. Specifically,\nwe design a fully conventional meta-model that can correct noisy masks using a\nsmall amount of clean meta-data. Then the corrected masks can be used to\nsupervise the training of the segmentation model. Meanwhile, a bi-level\noptimization method is adopted to alternately update the parameters of the main\nsegmentation model and the meta-model in an end-to-end way. Extensive\nexperimental results on two nuclear segmentation datasets show that our method\nachieves the state-of-the-art result. It even achieves comparable performance\nwith the model training on supervised data in some noisy settings.",
    "descriptor": "\nComments: Accepted by BIBM 2021\n",
    "authors": [
      "Jiangbo Shi",
      "Chang Jia",
      "Zeyu Gao",
      "Tieliang Gong",
      "Chunbao Wang",
      "Chen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12498"
  },
  {
    "id": "arXiv:2111.12502",
    "title": "TriStereoNet: A Trinocular Framework for Multi-baseline Disparity  Estimation",
    "abstract": "Stereo vision is an effective technique for depth estimation with broad\napplicability in autonomous urban and highway driving. While various deep\nlearning-based approaches have been developed for stereo, the input data from a\nbinocular setup with a fixed baseline are limited. Addressing such a problem,\nwe present an end-to-end network for processing the data from a trinocular\nsetup, which is a combination of a narrow and a wide stereo pair. In this\ndesign, two pairs of binocular data with a common reference image are treated\nwith shared weights of the network and a mid-level fusion. We also propose a\nGuided Addition method for merging the 4D data of the two baselines.\nAdditionally, an iterative sequential self-supervised and supervised learning\non real and synthetic datasets is presented, making the training of the\ntrinocular system practical with no need to ground-truth data of the real\ndataset. Experimental results demonstrate that the trinocular disparity network\nsurpasses the scenario where individual pairs are fed into a similar\narchitecture. Code and dataset:\nhttps://github.com/cogsys-tuebingen/tristereonet.",
    "descriptor": "",
    "authors": [
      "Faranak Shamsafar",
      "Andreas Zell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12502"
  },
  {
    "id": "arXiv:2111.12503",
    "title": "Extracting Triangular 3D Models, Materials, and Lighting From Images",
    "abstract": "We present an efficient method for joint optimization of topology, materials\nand lighting from multi-view image observations. Unlike recent multi-view\nreconstruction approaches, which typically produce entangled 3D representations\nencoded in neural networks, we output triangle meshes with spatially-varying\nmaterials and environment lighting that can be deployed in any traditional\ngraphics engine unmodified. We leverage recent work in differentiable\nrendering, coordinate-based networks to compactly represent volumetric\ntexturing, alongside differentiable marching tetrahedrons to enable\ngradient-based optimization directly on the surface mesh. Finally, we introduce\na differentiable formulation of the split sum approximation of environment\nlighting to efficiently recover all-frequency lighting. Experiments show our\nextracted models used in advanced scene editing, material decomposition, and\nhigh quality view interpolation, all running at interactive rates in\ntriangle-based renderers (rasterizers and path tracers).",
    "descriptor": "",
    "authors": [
      "Jacob Munkberg",
      "Jon Hasselgren",
      "Tianchang Shen",
      "Jun Gao",
      "Wenzheng Chen",
      "Alex Evans",
      "Thomas M\u00fcller",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.12503"
  },
  {
    "id": "arXiv:2111.12506",
    "title": "A Unified Approach to Variational Autoencoders and Stochastic  Normalizing Flows via Markov Chains",
    "abstract": "Normalizing flows, diffusion normalizing flows and variational autoencoders\nare powerful generative models. In this paper, we provide a unified framework\nto handle these approaches via Markov chains. Indeed, we consider stochastic\nnormalizing flows as pair of Markov chains fulfilling some properties and show\nthat many state-of-the-art models for data generation fit into this framework.\nThe Markov chains point of view enables us to couple both deterministic layers\nas invertible neural networks and stochastic layers as Metropolis-Hasting\nlayers, Langevin layers and variational autoencoders in a mathematically sound\nway. Besides layers with densities as Langevin layers, diffusion layers or\nvariational autoencoders, also layers having no densities as deterministic\nlayers or Metropolis-Hasting layers can be handled. Hence our framework\nestablishes a useful mathematical tool to combine the various approaches.",
    "descriptor": "",
    "authors": [
      "Johannes Hertrich",
      "Paul Hagemann",
      "Gabriele Steidl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.12506"
  },
  {
    "id": "arXiv:2111.12511",
    "title": "Deep learning-based reduced order models for the real-time simulation of  the nonlinear dynamics of microstructures",
    "abstract": "We propose a non-intrusive Deep Learning-based Reduced Order Model (DL-ROM)\ncapable of capturing the complex dynamics of mechanical systems showing inertia\nand geometric nonlinearities. In the first phase, a limited number of high\nfidelity snapshots are used to generate a POD-Galerkin ROM which is\nsubsequently exploited to generate the data, covering the whole parameter\nrange, used in the training phase of the DL-ROM. A convolutional autoencoder is\nemployed to map the system response onto a low-dimensional representation and,\nin parallel, to model the reduced nonlinear trial manifold. The system dynamics\non the manifold is described by means of a deep feedforward neural network that\nis trained together with the autoencoder. The strategy is benchmarked against\nhigh fidelity solutions on a clamped-clamped beam and on a real micromirror\nwith softening response and multiplicity of solutions. By comparing the\ndifferent computational costs, we discuss the impressive gain in performance\nand show that the DL-ROM truly represents a real-time tool which can be\nprofitably and efficiently employed in complex system-level simulation\nprocedures for design and optimisation purposes.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2001.04001\n",
    "authors": [
      "Stefania Fresca",
      "Giorgio Gobat",
      "Patrick Fedeli",
      "Attilio Frangi",
      "Andrea Manzoni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12511"
  },
  {
    "id": "arXiv:2111.12513",
    "title": "FLACOCO: Fault Localization for Java based on Industry-grade Coverage",
    "abstract": "Fault localization is an essential step in the debugging process.\nSpectrum-Based Fault Localization (SBFL) is a popular fault localization family\nof techniques, utilizing code-coverage to predict suspicious lines of code. In\nthis paper, we present FLACOCO, a new fault localization tool for Java. The key\nnovelty of FLACOCO is that it is built on top of one of the most used and most\nreliable coverage libraries for Java, JaCoCo. FLACOCO is made available through\na well-designed command-line interface and Java API and supports all Java\nversions. We validate FLACOCO on two use-cases from the automatic program\nrepair domain by reproducing previous scientific experiments. We find it is\ncapable of effectively replacing the state-of-the-art FL library. Overall, we\nhope that FLACOCO will help research in fault localization as well as industry\nadoption thanks to being founded on industry-grade code coverage. An\nintroductory video is available at https://youtu.be/RFRyvQuwRYA",
    "descriptor": "\nComments: 4 pages, tool paper, demo available under this https URL, code available under this https URL\n",
    "authors": [
      "Andr\u00e9 Silva",
      "Matias Martinez",
      "Benjamin Danglot",
      "Davide Ginelli",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.12513"
  },
  {
    "id": "arXiv:2111.12525",
    "title": "Causality-inspired Single-source Domain Generalization for Medical Image  Segmentation",
    "abstract": "Deep learning models usually suffer from domain shift issues, where models\ntrained on one source domain do not generalize well to other unseen domains. In\nthis work, we investigate the single-source domain generalization problem:\ntraining a deep network that is robust to unseen domains, under the condition\nthat training data is only available from one source domain, which is common in\nmedical imaging applications. We tackle this problem in the context of\ncross-domain medical image segmentation. Under this scenario, domain shifts are\nmainly caused by different acquisition processes. We propose a simple\ncausality-inspired data augmentation approach to expose a segmentation model to\nsynthesized domain-shifted training examples. Specifically, 1) to make the deep\nmodel robust to discrepancies in image intensities and textures, we employ a\nfamily of randomly-weighted shallow networks. They augment training images\nusing diverse appearance transformations. 2) Further we show that spurious\ncorrelations among objects in an image are detrimental to domain robustness.\nThese correlations might be taken by the network as domain-specific clues for\nmaking predictions, and they may break on unseen domains. We remove these\nspurious correlations via causal intervention. This is achieved by stratifying\nthe appearances of potentially correlated objects. The proposed approach is\nvalidated on three cross-domain segmentation tasks: cross-modality (CT-MRI)\nabdominal image segmentation, cross-sequence (bSSFP-LGE) cardiac MRI\nsegmentation, and cross-center prostate MRI segmentation. The proposed approach\nyields consistent performance gains compared with competitive methods when\ntested on unseen domains.",
    "descriptor": "\nComments: Preprint.10 pages\n",
    "authors": [
      "Cheng Ouyang",
      "Chen Chen",
      "Surui Li",
      "Zeju Li",
      "Chen Qin",
      "Wenjia Bai",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12525"
  },
  {
    "id": "arXiv:2111.12527",
    "title": "MorphMLP: A Self-Attention Free, MLP-Like Backbone for Image and Video",
    "abstract": "Self-attention has become an integral component of the recent network\narchitectures, e.g., Transformer, that dominate major image and video\nbenchmarks. This is because self-attention can flexibly model long-range\ninformation. For the same reason, researchers make attempts recently to revive\nMultiple Layer Perceptron (MLP) and propose a few MLP-Like architectures,\nshowing great potential. However, the current MLP-Like architectures are not\ngood at capturing local details and lack progressive understanding of core\ndetails in the images and/or videos. To overcome this issue, we propose a novel\nMorphMLP architecture that focuses on capturing local details at the low-level\nlayers, while gradually changing to focus on long-term modeling at the\nhigh-level layers. Specifically, we design a Fully-Connected-Like layer, dubbed\nas MorphFC, of two morphable filters that gradually grow its receptive field\nalong the height and width dimension. More interestingly, we propose to\nflexibly adapt our MorphFC layer in the video domain. To our best knowledge, we\nare the first to create a MLP-Like backbone for learning video representation.\nFinally, we conduct extensive experiments on image classification, semantic\nsegmentation and video classification. Our MorphMLP, such a self-attention free\nbackbone, can be as powerful as and even outperform self-attention based\nmodels.",
    "descriptor": "\nComments: preprint version\n",
    "authors": [
      "David Junhao Zhang",
      "Kunchang Li",
      "Yunpeng Chen",
      "Yali Wang",
      "Shashwat Chandra",
      "Yu Qiao",
      "Luoqi Liu",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12527"
  },
  {
    "id": "arXiv:2111.12528",
    "title": "Systematic Analysis of Programming Languages and Their Execution  Environments for Spectre Attacks",
    "abstract": "In this paper, we analyze the security of programming languages and their\nexecution environments (compilers and interpreters) with respect to Spectre\nattacks. The analysis shows that only 16 out of 42 execution environments have\nmitigations against at least one Spectre variant, i.e., 26 have no mitigations\nagainst any Spectre variant. Using our novel tool Speconnector, we develop\nSpectre proof-of-concept attacks in 8 programming languages and on code\ngenerated by 11 execution environments that were previously not known to be\naffected. Our results highlight some programming languages that are used to\nimplement security-critical code, but remain entirely unprotected, even three\nyears after the discovery of Spectre.",
    "descriptor": "",
    "authors": [
      "Amir Naseredini",
      "Stefan Gast",
      "Martin Schwarzl",
      "Pedro Miguel Sousa Bernardo",
      "Amel Smajic",
      "Claudio Canella",
      "Martin Berger",
      "Daniel Gruss"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.12528"
  },
  {
    "id": "arXiv:2111.12531",
    "title": "Non-Intrusive Binaural Speech Intelligibility Prediction from Discrete  Latent Representations",
    "abstract": "Non-intrusive speech intelligibility (SI) prediction from binaural signals is\nuseful in many applications. However, most existing signal-based measures are\ndesigned to be applied to single-channel signals. Measures specifically\ndesigned to take into account the binaural properties of the signal are often\nintrusive - characterised by requiring access to a clean speech signal - and\ntypically rely on combining both channels into a single-channel signal before\nmaking predictions. This paper proposes a non-intrusive SI measure that\ncomputes features from a binaural input signal using a combination of vector\nquantization (VQ) and contrastive predictive coding (CPC) methods. VQ-CPC\nfeature extraction does not rely on any model of the auditory system and is\ninstead trained to maximise the mutual information between the input signal and\noutput features. The computed VQ-CPC features are input to a predicting\nfunction parameterized by a neural network. Two predicting functions are\nconsidered in this paper. Both feature extractor and predicting functions are\ntrained on simulated binaural signals with isotropic noise. They are tested on\nsimulated signals with isotropic and real noise. For all signals, the ground\ntruth scores are the (intrusive) deterministic binaural STOI. Results are\npresented in terms of correlations and MSE and demonstrate that VQ-CPC features\nare able to capture information relevant to modelling SI and outperform all the\nconsidered benchmarks - even when evaluating on data comprising of different\nnoise field types.",
    "descriptor": "\nComments: 4 pages + 1 refs; 1 figure; submitted to IEEE SPL (pending review)\n",
    "authors": [
      "Alex F. McKinney",
      "Benjamin Cauchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.12531"
  },
  {
    "id": "arXiv:2111.12535",
    "title": "Knowledge Enhanced Sports Game Summarization",
    "abstract": "Sports game summarization aims at generating sports news from live\ncommentaries. However, existing datasets are all constructed through automated\ncollection and cleaning processes, resulting in a lot of noise. Besides,\ncurrent works neglect the knowledge gap between live commentaries and sports\nnews, which limits the performance of sports game summarization. In this paper,\nwe introduce K-SportsSum, a new dataset with two characteristics: (1)\nK-SportsSum collects a large amount of data from massive games. It has 7,854\ncommentary-news pairs. To improve the quality, K-SportsSum employs a manual\ncleaning process; (2) Different from existing datasets, to narrow the knowledge\ngap, K-SportsSum further provides a large-scale knowledge corpus that contains\nthe information of 523 sports teams and 14,724 sports players. Additionally, we\nalso introduce a knowledge-enhanced summarizer that utilizes both live\ncommentaries and the knowledge to generate sports news. Extensive experiments\non K-SportsSum and SportsSum datasets show that our model achieves new\nstate-of-the-art performances. Qualitative analysis and human study further\nverify that our model generates more informative sports news.",
    "descriptor": "\nComments: Accepted to WSDM 2022\n",
    "authors": [
      "Jiaan Wang",
      "Zhixu Li",
      "Tingyi Zhang",
      "Duo Zheng",
      "Jianfeng Qu",
      "An Liu",
      "Lei Zhao",
      "Zhigang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12535"
  },
  {
    "id": "arXiv:2111.12537",
    "title": "Processing of optical signals by \"surgical\" methods for the  Gelfand-Levitan-Marchenko equation",
    "abstract": "We propose a new method for solving the Gelfand-Levitan-Marchenko equation\n(GLME) based on the block version of the Toeplitz Inner-Bordering (TIB) with an\narbitrary point to start the calculation. This makes it possible to find\nsolutions of the GLME at an arbitrary point with a cutoff of the matrix\ncoefficient, which allows to avoid the occurrence of numerical instability and\nto perform calculations for soliton solutions spaced apart in the time domain.\nUsing an example of two solitons, we demonstrate our method and its range of\napplicability. An example of eight solitons shows how the method can be applied\nto a more complex signal configuration.",
    "descriptor": "",
    "authors": [
      "Sergey Medvedev",
      "Irina Vaseva",
      "Mikhail Fedoruk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12537"
  },
  {
    "id": "arXiv:2111.12539",
    "title": "Information-Theoretic Approach for Model Reduction Over Finite Time  Horizon",
    "abstract": "This paper presents an information-theoretic approach for model reduction for\nfinite time simulation. Although system models are typically used for\nsimulation over a finite time, most of the metrics (and pseudo-metrics) used\nfor model accuracy assessment consider asymptotic behavior e.g., Hankel\nsingular values and Kullback-Leibler(KL) rate metric. These metrics could\nfurther be used for model order reduction. Hence, in this paper, we propose a\ngeneralization of KL divergence-based metric called n-step KL rate metric,\nwhich could be used to compare models over a finite time horizon. We then\ndemonstrate that the asymptotic metrics for comparing dynamical systems may not\naccurately assess the model prediction uncertainties over a finite time\nhorizon. Motivated by this finite time analysis, we propose a new pragmatic\napproach to compute the influence of a subset of states on a combination of\nstates called information transfer (IT). Model reduction typically involves the\nremoval or truncation of states. IT combines the concepts from the n-step KL\nrate metric and model reduction. Finally, we demonstrate the application of\ninformation transfer for model reduction. Although the analysis and definitions\npresented in this paper assume linear systems, they can be extended for\nnonlinear systems.",
    "descriptor": "",
    "authors": [
      "Punit Tulpule",
      "Umesh Vaidya"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.12539"
  },
  {
    "id": "arXiv:2111.12542",
    "title": "Autonomous bot with ML-based reactive navigation for indoor environment",
    "abstract": "Local or reactive navigation is essential for autonomous mobile robots which\noperate in an indoor environment. Techniques such as SLAM, computer vision\nrequire significant computational power which increases cost. Similarly, using\nrudimentary methods makes the robot susceptible to inconsistent behavior. This\npaper aims to develop a robot that balances cost and accuracy by using machine\nlearning to predict the best obstacle avoidance move based on distance inputs\nfrom four ultrasonic sensors that are strategically mounted on the front,\nfront-left, front-right, and back of the robot. The underlying hardware\nconsists of an Arduino Uno and a Raspberry Pi 3B. The machine learning model is\nfirst trained on the data collected by the robot. Then the Arduino continuously\npolls the sensors and calculates the distance values, and in case of critical\nneed for avoidance, a suitable maneuver is made by the Arduino. In other\nscenarios, sensor data is sent to the Raspberry Pi using a USB connection and\nthe machine learning model generates the best move for navigation, which is\nsent to the Arduino for driving motors accordingly. The system is mounted on a\n2-WD robot chassis and tested in a cluttered indoor setting with most\nimpressive results.",
    "descriptor": "\nComments: This paper was presented in RIACT2021, an international conference, and was awarded 'outstanding oral presentation'. It was also selected for publication in springer special issue 2021. 12 pages, with 6 main figures and 1 figure in appendix\n",
    "authors": [
      "Yash Srivastava",
      "Saumya Singh",
      "S.P. Syed Ibrahim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12542"
  },
  {
    "id": "arXiv:2111.12544",
    "title": "LDDMM meets GANs: Generative Adversarial Networks for diffeomorphic  registration",
    "abstract": "The purpose of this work is to contribute to the state of the art of\ndeep-learning methods for diffeomorphic registration. We propose an adversarial\nlearning LDDMM method for pairs of 3D mono-modal images based on Generative\nAdversarial Networks. The method is inspired by the recent literature for\ndeformable image registration with adversarial learning. We combine the best\nperforming generative, discriminative, and adversarial ingredients from the\nstate of the art within the LDDMM paradigm. We have successfully implemented\ntwo models with the stationary and the EPDiff-constrained non-stationary\nparameterizations of diffeomorphisms. Our unsupervised and data-hungry approach\nhas shown a competitive performance with respect to a benchmark supervised and\nrich-data approach. In addition, our method has shown similar results to\nmodel-based methods with a computational time under one second.",
    "descriptor": "",
    "authors": [
      "Ubaldo Ramon",
      "Monica Hernandez",
      "Elvira Mayordomo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.12544"
  },
  {
    "id": "arXiv:2111.12545",
    "title": "Learning to Refit for Convex Learning Problems",
    "abstract": "Machine learning (ML) models need to be frequently retrained on changing\ndatasets in a wide variety of application scenarios, including data valuation\nand uncertainty quantification. To efficiently retrain the model, linear\napproximation methods such as influence function have been proposed to estimate\nthe impact of data changes on model parameters. However, these methods become\ninaccurate for large dataset changes. In this work, we focus on convex learning\nproblems and propose a general framework to learn to estimate optimized model\nparameters for different training sets using neural networks. We propose to\nenforce the predicted model parameters to obey optimality conditions and\nmaintain utility through regularization techniques, which significantly improve\ngeneralization. Moreover, we rigorously characterize the expressive power of\nneural networks to approximate the optimizer of convex problems. Empirical\nresults demonstrate the advantage of the proposed method in accurate and\nefficient model parameter estimation compared to the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Yingyan Zeng",
      "Tianhao Wang",
      "Si Chen",
      "Hoang Anh Just",
      "Ran Jin",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.12545"
  },
  {
    "id": "arXiv:2111.12548",
    "title": "AutoDC: Automated data-centric processing",
    "abstract": "AutoML (automated machine learning) has been extensively developed in the\npast few years for the model-centric approach. As for the data-centric\napproach, the processes to improve the dataset, such as fixing incorrect\nlabels, adding examples that represent edge cases, and applying data\naugmentation, are still very artisanal and expensive. Here we develop an\nautomated data-centric tool (AutoDC), similar to the purpose of AutoML, aims to\nspeed up the dataset improvement processes. In our preliminary tests on 3 open\nsource image classification datasets, AutoDC is estimated to reduce roughly 80%\nof the manual time for data improvement tasks, at the same time, improve the\nmodel accuracy by 10-15% with the fixed ML code.",
    "descriptor": "\nComments: NeurIPS 2021- Data-Centric AI (DCAI) workshop\n",
    "authors": [
      "Zac Yung-Chun Liu",
      "Shoumik Roychowdhury",
      "Scott Tarlow",
      "Akash Nair",
      "Shweta Badhe",
      "Tejas Shah"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12548"
  },
  {
    "id": "arXiv:2111.12549",
    "title": "Interpolating Rotations with Non-abelian Kuramoto Model on the 3-Sphere",
    "abstract": "The paper presents a novel method for interpolating rotations based on the\nnon-Abelian Kuramoto model on sphere S3. The algorithm, introduced in this\npaper, finds the shortest and most direct path between two rotations. We have\ndiscovered that it gives approximately the same results as a Spherical Linear\nInterpolation algorithm. Simulation results of our algorithm are visualized on\nS2 using Hopf fibration. In addition, in order to gain a better insight, we\nhave provided one short video illustrating the rotation of an object between\ntwo positions.",
    "descriptor": "",
    "authors": [
      "Zinaid Kapi\u0107",
      "Aladin Crnki\u0107"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.12549"
  },
  {
    "id": "arXiv:2111.12550",
    "title": "A Worker-Task Specialization Model for Crowdsourcing: Efficient  Inference and Fundamental Limits",
    "abstract": "Crowdsourcing system has emerged as an effective platform to label data with\nrelatively low cost by using non-expert workers. However, inferring correct\nlabels from multiple noisy answers on data has been a challenging problem,\nsince the quality of answers varies widely across tasks and workers. Many\nprevious works have assumed a simple model where the order of workers in terms\nof their reliabilities is fixed across tasks, and focused on estimating the\nworker reliabilities to aggregate answers with different weights. We propose a\nhighly general $d$-type worker-task specialization model in which the\nreliability of each worker can change depending on the type of a given task,\nwhere the number $d$ of types can scale in the number of tasks. In this model,\nwe characterize the optimal sample complexity to correctly infer labels with\nany given recovery accuracy, and propose an inference algorithm achieving the\norder-wise optimal bound. We conduct experiments both on synthetic and\nreal-world datasets, and show that our algorithm outperforms the existing\nalgorithms developed based on strict model assumptions.",
    "descriptor": "",
    "authors": [
      "Doyeon Kim",
      "Jeonghwan Lee",
      "Hye Won Chung"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12550"
  },
  {
    "id": "arXiv:2111.12553",
    "title": "CycleQ: An Efficient Basis for Cyclic Equational Reasoning",
    "abstract": "We propose a new cyclic proof system for automated, equational reasoning\nabout the behaviour of pure functional programs. The key to the system is the\nway in which cyclic proof and equational reasoning are mediated by the use of\ncontextual substitution as a cut rule. We show that our system, although\nsimple, already subsumes several of the approaches to implicit induction\nvariously known as \"inductionless induction\", \"rewriting induction\", and \"proof\nby consistency\". By restricting the form of the traces, we show that global\ncorrectness in our system can be verified incrementally, taking advantage of\nthe well-known size-change principle, which leads to an efficient\nimplementation of proof search. Our CycleQ tool, accessible as a GHC plugin,\nshows promising results on a number of standard benchmarks.",
    "descriptor": "",
    "authors": [
      "Eddie Jones",
      "C-.H. Luke Ong",
      "Steven Ramsay"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.12553"
  },
  {
    "id": "arXiv:2111.12555",
    "title": "Serpens: A High Bandwidth Memory Based Accelerator for General-Purpose  Sparse Matrix-Vector Multiplication",
    "abstract": "Sparse matrix-vector multiplication (SpMV) multiplies a sparse matrix with a\ndense vector. SpMV plays a crucial role in many applications, from graph\nanalytics to deep learning. The random memory accesses of the sparse matrix\nmake accelerator design challenging. However, high bandwidth memory (HBM) based\nFPGAs are a good fit for designing accelerators for SpMV. In this paper, we\npresent Serpens, an HBM based accelerator for general-purpose SpMV.Serpens\nfeatures (1) a general-purpose design, (2) memory-centric processing engines,\nand (3) index coalescing to support the efficient processing of arbitrary\nSpMVs. From the evaluation of twelve large-size matrices, Serpens is 1.91x and\n1.76x better in terms of geomean throughput than the latest accelerators\nGraphLiLy and Sextans, respectively. We also evaluate 2,519 SuiteSparse\nmatrices, and Serpens achieves 2.10x higher throughput than a K80 GPU. For the\nenergy efficiency, Serpens is 1.71x, 1.90x, and 42.7x better compared with\nGraphLily, Sextans, and K80, respectively. After scaling up to 24 HBM channels,\nSerpens achieves up to 30,204MTEPS and up to 3.79x over GraphLily.",
    "descriptor": "",
    "authors": [
      "Linghao Song",
      "Yuze Chi",
      "Licheng Guo",
      "Jason Cong"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.12555"
  },
  {
    "id": "arXiv:2111.12557",
    "title": "Optimization-free Ground Contact Force Constraint Satisfaction in  Quadrupedal Locomotion",
    "abstract": "We are seeking control design paradigms for legged systems that allow\nbypassing costly algorithms that depend on heavy on-board computers widely used\nin these systems and yet being able to match what they can do by using less\nexpensive optimization-free frameworks. In this work, we present our\npreliminary results in modeling and control design of a quadrupedal robot\ncalled \\textit{Husky Carbon}, which under development at Northeastern\nUniversity (NU) in Boston. In our approach, we utilized a supervisory\ncontroller and an Explicit Reference Governor (ERG) to enforce ground reaction\nforce constraints. These constraints are usually enforced using costly\noptimizations. However, in this work, the ERG manipulates the state references\napplied to the supervisory controller to enforce the ground contact constraints\nthrough an updated law based on Lyapunov stability arguments. As a result, the\napproach is much faster to compute than the widely used optimization-based\nmethods.",
    "descriptor": "",
    "authors": [
      "Eric Sihite",
      "Pravin Dangol",
      "Alireza Ramezani"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.12557"
  },
  {
    "id": "arXiv:2111.12560",
    "title": "Building Object-based Causal Programs for Human-like Generalization",
    "abstract": "We present a novel task that measures how people generalize objects' causal\npowers based on observing a single (Experiment 1) or a few (Experiment 2)\ncausal interactions between object pairs. We propose a computational modeling\nframework that can synthesize human-like generalization patterns in our task\nsetting, and sheds light on how people may navigate the compositional space of\npossible causal functions and categories efficiently. Our modeling framework\ncombines a causal function generator that makes use of agent and recipient\nobjects' features and relations, and a Bayesian non-parametric inference\nprocess to govern the degree of similarity-based generalization. Our model has\na natural \"resource-rational\" variant that outperforms a naive Bayesian account\nin describing participants, in particular reproducing a generalization-order\neffect and causal asymmetry observed in our behavioral experiments. We argue\nthat this modeling framework provides a computationally plausible mechanism for\nreal world causal generalization.",
    "descriptor": "\nComments: To appear in NeurIPs workshop WHY-21 - Causal Inference & Machine Learning: Why now?\n",
    "authors": [
      "Bonan Zhao",
      "Christopher G. Lucas",
      "Neil R. Bramley"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2111.12560"
  },
  {
    "id": "arXiv:2111.12577",
    "title": "A Method for Evaluating the Capacity of Generative Adversarial Networks  to Reproduce High-order Spatial Context",
    "abstract": "Generative adversarial networks are a kind of deep generative model with the\npotential to revolutionize biomedical imaging. This is because GANs have a\nlearned capacity to draw whole-image variates from a lower-dimensional\nrepresentation of an unknown, high-dimensional distribution that fully\ndescribes the input training images. The overarching problem with GANs in\nclinical applications is that there is not adequate or automatic means of\nassessing the diagnostic quality of images generated by GANs. In this work, we\ndemonstrate several tests of the statistical accuracy of images output by two\npopular GAN architectures. We designed several stochastic object models (SOMs)\nof distinct features that can be recovered after generation by a trained GAN.\nSeveral of these features are high-order, algorithmic pixel-arrangement rules\nwhich are not readily expressed in covariance matrices. We designed and\nvalidated statistical classifiers to detect the known arrangement rules. We\nthen tested the rates at which the different GANs correctly reproduced the\nrules under a variety of training scenarios and degrees of feature-class\nsimilarity. We found that ensembles of generated images can appear accurate\nvisually, and correspond to low Frechet Inception Distance scores (FID), while\nnot exhibiting the known spatial arrangements. Furthermore, GANs trained on a\nspectrum of distinct spatial orders did not respect the given prevalence of\nthose orders in the training data. The main conclusion is that while low-order\nensemble statistics are largely correct, there are numerous quantifiable errors\nper image that plausibly can affect subsequent use of the GAN-generated images.",
    "descriptor": "\nComments: Submitted to IEEE-TPAMI. Early version with partial results has been accepted for poster presentation at SPIE-MI 2022\n",
    "authors": [
      "Rucha Deshpande",
      "Mark A. Anastasio",
      "Frank J. Brooks"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12577"
  },
  {
    "id": "arXiv:2111.12579",
    "title": "Water Care: Water Surface Cleaning Bot and Water Body Surveillance  System",
    "abstract": "Whenever a person hears about pollution, more often than not, the first\nthought that comes to their mind is air pollution. One of the most\nunder-mentioned and under-discussed pollution globally is that caused by the\nnon-biodegradable waste in our water bodies. In the case of India, there is a\nlot of plastic waste on the surface of rivers and lakes. The Ganga river is one\nof the 10 rivers which account for 90 percent of the plastic that ends up in\nthe sea and there are major cases of local nalaas and lakes being contaminated\ndue to this waste. This limits the source of clean water which leads to major\ndepletion in water sources. From 2001 to 2012, in the city of Hyderabad, 3245\nhectares of lakes dissipated. The water recedes by nine feet a year on average\nin southern New Delhi. Thus, cleaning of these local water bodies and rivers is\nof utmost importance. Our aim is to develop a water surface cleaning bot that\nis deployed across the shore. The bot will detect garbage patches on its way\nand collect the garbage thus making the water bodies clean. This solution\nemploys a surveillance mechanism in order to alert the authorities in case\nanyone is found polluting the water bodies. A more sustainable system by using\nsolar energy to power the system has been developed. Computer vision algorithms\nare used for detecting trash on the surface of the water. This trash is\ncollected by the bot and is disposed of at a designated location. In addition\nto cleaning the water bodies, preventive measures have been also implemented\nwith the help of a virtual fencing algorithm that alerts the authorities if\nanyone tries to pollute the water premises. A web application and a mobile app\nis deployed to keep a check on the movement of the bot and shore surveillance\nrespectively. This complete solution involves both preventive and curative\nmeasures that are required for water care.",
    "descriptor": "\nComments: This paper was presented in RIACT 2021, an international conference, and was selected for publication in springer special issue 2021\n",
    "authors": [
      "Harsh Sankar Naicker",
      "Yash Srivastava",
      "Akshara Pramod",
      "Niket Paresh Ganatra",
      "Deepakshi Sood",
      "Saumya Singh",
      "Velmathi Guruviah"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12579"
  },
  {
    "id": "arXiv:2111.12580",
    "title": "UDA-COPE: Unsupervised Domain Adaptation for Category-level Object Pose  Estimation",
    "abstract": "Learning to estimate object pose often requires ground-truth (GT) labels,\nsuch as CAD model and absolute-scale object pose, which is expensive and\nlaborious to obtain in the real world. To tackle this problem, we propose an\nunsupervised domain adaptation (UDA) for category-level object pose estimation,\ncalled \\textbf{UDA-COPE}. Inspired by the recent multi-modal UDA techniques,\nthe proposed method exploits a teacher-student self-supervised learning scheme\nto train a pose estimation network without using target domain labels. We also\nintroduce a bidirectional filtering method between predicted normalized object\ncoordinate space (NOCS) map and observed point cloud, to not only make our\nteacher network more robust to the target domain but also to provide more\nreliable pseudo labels for the student network training. Extensive experimental\nresults demonstrate the effectiveness of our proposed method both\nquantitatively and qualitatively. Notably, without leveraging target-domain GT\nlabels, our proposed method achieves comparable or sometimes superior\nperformance to existing methods that depend on the GT labels.",
    "descriptor": "",
    "authors": [
      "Taeyeop Lee",
      "Byeong-Uk Lee",
      "Inkyu Shin",
      "Jaesung Choe",
      "Ukcheol Shin",
      "In So Kweon",
      "Kuk-Jin Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12580"
  },
  {
    "id": "arXiv:2111.12581",
    "title": "Medium Access Control protocol for Collaborative Spectrum Learning in  Wireless Networks",
    "abstract": "In recent years there is a growing effort to provide learning algorithms for\nspectrum collaboration. In this paper we present a medium access control\nprotocol which allows spectrum collaboration with minimal regret and high\nspectral efficiency in highly loaded networks. We present a fully-distributed\nalgorithm for spectrum collaboration in congested ad-hoc networks. The\nalgorithm jointly solves both the channel allocation and access scheduling\nproblems. We prove that the algorithm has an optimal logarithmic regret. Based\non the algorithm we provide a medium access control protocol which allows\ndistributed implementation of the algorithm in ad-hoc networks. The protocol\nutilizes single-channel opportunistic carrier sensing to carry out a\nlow-complexity distributed auction in time and frequency. We also discuss\npractical implementation issues such as bounded frame size and speed of\nconvergence. Computer simulations comparing the algorithm to state-of-the-art\ndistributed medium access control protocols show the significant advantage of\nthe proposed scheme.",
    "descriptor": "",
    "authors": [
      "Tomer Boyarski",
      "Amir Leshem"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.12581"
  },
  {
    "id": "arXiv:2111.12583",
    "title": "Optimizing Latent Space Directions For GAN-based Local Image Editing",
    "abstract": "Generative Adversarial Network (GAN) based localized image editing can suffer\nambiguity between semantic attributes. We thus present a novel objective\nfunction to evaluate the locality of an image edit. By introducing the\nsupervision from a pre-trained segmentation network and optimizing the\nobjective function, our framework, called Locally Effective Latent Space\nDirection (LELSD), is applicable to any dataset and GAN architecture. Our\nmethod is also computationally fast and exhibits a high extent of\ndisentanglement, which allows users to interactively perform a sequence of\nedits on an image. Our experiments on both GAN-generated and real images\nqualitatively demonstrate the high quality and advantages of our method.",
    "descriptor": "\nComments: 4 pages, 5 figures, 1 table\n",
    "authors": [
      "Ehsan Pajouheshgar",
      "Tong Zhang",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12583"
  },
  {
    "id": "arXiv:2111.12588",
    "title": "Towards Cross-Cultural Analysis using Music Information Dynamics",
    "abstract": "A music piece is both comprehended hierarchically, from sonic events to\nmelodies, and sequentially, in the form of repetition and variation. Music from\ndifferent cultures establish different aesthetics by having different style\nconventions on these two aspects. We propose a framework that could be used to\nquantitatively compare music from different cultures by looking at these two\naspects.\nThe framework is based on an Music Information Dynamics model, a Variable\nMarkov Oracle (VMO), and is extended with a variational representation learning\nof audio. A variational autoencoder (VAE) is trained to map audio fragments\ninto a latent representation. The latent representation is fed into a VMO. The\nVMO then learns a clustering of the latent representation via a threshold that\nmaximizes the information rate of the quantized latent representation sequence.\nThis threshold effectively controls the sensibility of the predictive step to\nacoustic changes, which determines the framework's ability to track repetitions\non longer time scales. This approach allows characterization of the overall\ninformation contents of a musical signal at each level of acoustic sensibility.\nOur findings under this framework show that sensibility to subtle acoustic\nchanges is higher for East-Asian musical traditions, while the Western works\nexhibit longer motivic structures at higher thresholds of differences in the\nlatent space. This suggests that a profile of information contents, analyzed as\na function of the level of acoustic detail can serve as a possible cultural\ncharacteristic.",
    "descriptor": "",
    "authors": [
      "Shlomo Dubnov",
      "Kevin Huang",
      "Cheng-i Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.12588"
  },
  {
    "id": "arXiv:2111.12591",
    "title": "Lepard: Learning partial point cloud matching in rigid and deformable  scenes",
    "abstract": "We present Lepard, a Learning based approach for partial point cloud matching\nfor rigid and deformable scenes. The key characteristic of Lepard is the\nfollowing approaches that exploit 3D positional knowledge for point cloud\nmatching: 1) An architecture that disentangles point cloud representation into\nfeature space and 3D position space. 2) A position encoding method that\nexplicitly reveals 3D relative distance information through the dot product of\nvectors. 3) A repositioning technique that modifies the cross-point-cloud\nrelative positions. Ablation studies demonstrate the effectiveness of the above\ntechniques. For rigid point cloud matching, Lepard sets a new state-of-the-art\non the 3DMatch / 3DLoMatch benchmarks with 93.6% / 69.0% registration recall.\nIn deformable cases, Lepard achieves +27.1% / +34.8% higher non-rigid feature\nmatching recall than the prior art on our newly constructed 4DMatch / 4DLoMatch\nbenchmark.",
    "descriptor": "\nComments: Code and data: this https URL\n",
    "authors": [
      "Yang Li",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12591"
  },
  {
    "id": "arXiv:2111.12594",
    "title": "Conditional Object-Centric Learning from Video",
    "abstract": "Object-centric representations are a promising path toward more systematic\ngeneralization by providing flexible abstractions upon which compositional\nworld models can be built. Recent work on simple 2D and 3D datasets has shown\nthat models with object-centric inductive biases can learn to segment and\nrepresent meaningful objects from the statistical structure of the data alone\nwithout the need for any supervision. However, such fully-unsupervised methods\nstill fail to scale to diverse realistic data, despite the use of increasingly\ncomplex inductive biases such as priors for the size of objects or the 3D\ngeometry of the scene. In this paper, we instead take a weakly-supervised\napproach and focus on how 1) using the temporal dynamics of video data in the\nform of optical flow and 2) conditioning the model on simple object location\ncues can be used to enable segmenting and tracking objects in significantly\nmore realistic synthetic data. We introduce a sequential extension to Slot\nAttention which we train to predict optical flow for realistic looking\nsynthetic scenes and show that conditioning the initial state of this model on\na small set of hints, such as center of mass of objects in the first frame, is\nsufficient to significantly improve instance segmentation. These benefits\ngeneralize beyond the training distribution to novel objects, novel\nbackgrounds, and to longer video sequences. We also find that such\ninitial-state-conditioning can be used during inference as a flexible interface\nto query the model for specific objects or parts of objects, which could pave\nthe way for a range of weakly-supervised approaches and allow more effective\ninteraction with trained models.",
    "descriptor": "\nComments: Project page at this https URL\n",
    "authors": [
      "Thomas Kipf",
      "Gamaleldin F. Elsayed",
      "Aravindh Mahendran",
      "Austin Stone",
      "Sara Sabour",
      "Georg Heigold",
      "Rico Jonschkowski",
      "Alexey Dosovitskiy",
      "Klaus Greff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12594"
  },
  {
    "id": "arXiv:2111.12600",
    "title": "Learning State Representations via Retracing in Reinforcement Learning",
    "abstract": "We propose learning via retracing, a novel self-supervised approach for\nlearning the state representation (and the associated dynamics model) for\nreinforcement learning tasks. In addition to the predictive (reconstruction)\nsupervision in the forward direction, we propose to include `\"retraced\"\ntransitions for representation/model learning, by enforcing the\ncycle-consistency constraint between the original and retraced states, hence\nimprove upon the sample efficiency of learning. Moreover, learning via\nretracing explicitly propagates information about future transitions backward\nfor inferring previous states, thus facilitates stronger representation\nlearning. We introduce Cycle-Consistency World Model (CCWM), a concrete\ninstantiation of learning via retracing implemented under existing model-based\nreinforcement learning framework. Additionally we propose a novel adaptive\n\"truncation\" mechanism for counteracting the negative impacts brought by the\n\"irreversible\" transitions such that learning via retracing can be maximally\neffective. Through extensive empirical studies on continuous control\nbenchmarks, we demonstrates that CCWM achieves state-of-the-art performance in\nterms of sample efficiency and asymptotic performance.",
    "descriptor": "",
    "authors": [
      "Changmin Yu",
      "Dong Li",
      "Jianye Hao",
      "Jun Wang",
      "Neil Burgess"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12600"
  },
  {
    "id": "arXiv:2111.12602",
    "title": "Hierarchical Graph-Convolutional Variational AutoEncoding for Generative  Modelling of Human Motion",
    "abstract": "Models of human motion commonly focus either on trajectory prediction or\naction classification but rarely both. The marked heterogeneity and intricate\ncompositionality of human motion render each task vulnerable to the data\ndegradation and distributional shift common to real-world scenarios. A\nsufficiently expressive generative model of action could in theory enable data\nconditioning and distributional resilience within a unified framework\napplicable to both tasks. Here we propose a novel architecture based on\nhierarchical variational autoencoders and deep graph convolutional neural\nnetworks for generating a holistic model of action over multiple time-scales.\nWe show this Hierarchical Graph-convolutional Variational Autoencoder (HG-VAE)\nto be capable of generating coherent actions, detecting out-of-distribution\ndata, and imputing missing data by gradient ascent on the model's posterior.\nTrained and evaluated on H3.6M and the largest collection of open source human\nmotion data, AMASS, we show HG-VAE can facilitate downstream discriminative\nlearning better than baseline models.",
    "descriptor": "\nComments: Under Review at CVPR\n",
    "authors": [
      "Anthony Bourached",
      "Robert Gray",
      "Ryan-Rhys Griffiths",
      "Ashwani Jha",
      "Parashkev Nachev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.12602"
  },
  {
    "id": "arXiv:2111.12606",
    "title": "Deep metric learning improves lab of origin prediction of genetically  engineered plasmids",
    "abstract": "Genome engineering is undergoing unprecedented development and is now\nbecoming widely available. To ensure responsible biotechnology innovation and\nto reduce misuse of engineered DNA sequences, it is vital to develop tools to\nidentify the lab-of-origin of engineered plasmids. Genetic engineering\nattribution (GEA), the ability to make sequence-lab associations, would support\nforensic experts in this process. Here, we propose a method, based on metric\nlearning, that ranks the most likely labs-of-origin whilst simultaneously\ngenerating embeddings for plasmid sequences and labs. These embeddings can be\nused to perform various downstream tasks, such as clustering DNA sequences and\nlabs, as well as using them as features in machine learning models. Our\napproach employs a circular shift augmentation approach and is able to\ncorrectly rank the lab-of-origin $90\\%$ of the time within its top 10\npredictions - outperforming all current state-of-the-art approaches. We also\ndemonstrate that we can perform few-shot-learning and obtain $76\\%$ top-10\naccuracy using only $10\\%$ of the sequences. This means, we outperform the\nprevious CNN approach using only one-tenth of the data. We also demonstrate\nthat we are able to extract key signatures in plasmid sequences for particular\nlabs, allowing for an interpretable examination of the model's outputs.",
    "descriptor": "\nComments: 20 pages, 7 figures, 48 citations\n",
    "authors": [
      "Igor M. Soares",
      "Fernando H. F. Camargo",
      "Adriano Marques",
      "Oliver M. Crook"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.12606"
  },
  {
    "id": "arXiv:2111.12608",
    "title": "Cerberus Transformer: Joint Semantic, Affordance and Attribute Parsing",
    "abstract": "Multi-task indoor scene understanding is widely considered as an intriguing\nformulation, as the affinity of different tasks may lead to improved\nperformance. In this paper, we tackle the new problem of joint semantic,\naffordance and attribute parsing. However, successfully resolving it requires a\nmodel to capture long-range dependency, learn from weakly aligned data and\nproperly balance sub-tasks during training. To this end, we propose an\nattention-based architecture named Cerberus and a tailored training framework.\nOur method effectively addresses the aforementioned challenges and achieves\nstate-of-the-art performance on all three tasks. Moreover, an in-depth analysis\nshows concept affinity consistent with human cognition, which inspires us to\nexplore the possibility of weakly supervised learning. Surprisingly, Cerberus\nachieves strong results using only 0.1%-1% annotation. Visualizations further\nconfirm that this success is credited to common attention maps across tasks.\nCode and models can be accessed at https://github.com/OPEN-AIR-SUN/Cerberus.",
    "descriptor": "\nComments: code: this https URL\n",
    "authors": [
      "Xiaoxue Chen",
      "Tianyu Liu",
      "Hao Zhao",
      "Guyue Zhou",
      "Ya-Qin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12608"
  },
  {
    "id": "arXiv:2111.12609",
    "title": "GreedyNASv2: Greedier Search with a Greedy Path Filter",
    "abstract": "Training a good supernet in one-shot NAS methods is difficult since the\nsearch space is usually considerably huge (e.g., $13^{21}$). In order to\nenhance the supernet's evaluation ability, one greedy strategy is to sample\ngood paths, and let the supernet lean towards the good ones and ease its\nevaluation burden as a result. However, in practice the search can be still\nquite inefficient since the identification of good paths is not accurate enough\nand sampled paths still scatter around the whole search space. In this paper,\nwe leverage an explicit path filter to capture the characteristics of paths and\ndirectly filter those weak ones, so that the search can be thus implemented on\nthe shrunk space more greedily and efficiently. Concretely, based on the fact\nthat good paths are much less than the weak ones in the space, we argue that\nthe label of \"weak paths\" will be more confident and reliable than that of\n``good paths\" in multi-path sampling. In this way, we thus cast the training of\npath filter in the positive and unlabeled (PU) learning paradigm, and also\nencourage a \\textit{path embedding} as better path/operation representation to\nenhance the identification capacity of the learned filter. By dint of this\nembedding, we can further shrink the search space by aggregating similar\noperations with similar embeddings, and the search can be more efficient and\naccurate. Extensive experiments validate the effectiveness of the proposed\nmethod GreedyNASv2. For example, our obtained GreedyNASv2-L achieves $81.1\\%$\nTop-1 accuracy on ImageNet dataset, significantly outperforming the ResNet-50\nstrong baselines.",
    "descriptor": "",
    "authors": [
      "Tao Huang",
      "Shan You",
      "Fei Wang",
      "Chen Qian",
      "Changshui Zhang",
      "Xiaogang Wang",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12609"
  },
  {
    "id": "arXiv:2111.12614",
    "title": "PSSL: Self-supervised Learning for Personalized Search with Contrastive  Sampling",
    "abstract": "Personalized search plays a crucial role in improving user search experience\nowing to its ability to build user profiles based on historical behaviors.\nPrevious studies have made great progress in extracting personal signals from\nthe query log and learning user representations. However, neural personalized\nsearch is extremely dependent on sufficient data to train the user model. Data\nsparsity is an inevitable challenge for existing methods to learn high-quality\nuser representations. Moreover, the overemphasis on final ranking quality leads\nto rough data representations and impairs the generalizability of the model. To\ntackle these issues, we propose a Personalized Search framework with\nSelf-supervised Learning (PSSL) to enhance data representations. Specifically,\nwe adopt a contrastive sampling method to extract paired self-supervised\ninformation from sequences of user behaviors in query logs. Four auxiliary\ntasks are designed to pre-train the sentence encoder and the sequence encoder\nused in the ranking model. They are optimized by contrastive loss which aims to\nclose the distance between similar user sequences, queries, and documents.\nExperimental results on two datasets demonstrate that our proposed model PSSL\nachieves state-of-the-art performance compared with existing baselines.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Yujia Zhou",
      "Zhicheng Dou",
      "Yutao Zhu",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.12614"
  },
  {
    "id": "arXiv:2111.12618",
    "title": "Group based Personalized Search by Integrating Search Behaviour and  Friend Network",
    "abstract": "The key to personalized search is to build the user profile based on\nhistorical behaviour. To deal with the users who lack historical data, group\nbased personalized models were proposed to incorporate the profiles of similar\nusers when re-ranking the results. However, similar users are mostly found\nbased on simple lexical or topical similarity in search behaviours. In this\npaper, we propose a neural network enhanced method to highlight similar users\nin semantic space. Furthermore, we argue that the behaviour-based similar users\nare still insufficient to understand a new query when user's historical\nactivities are limited. To tackle this issue, we introduce the friend network\ninto personalized search to determine the closeness between users in another\nway. Since the friendship is often formed based on similar background or\ninterest, there are plenty of personalized signals hidden in the friend network\nnaturally. Specifically, we propose a friend network enhanced personalized\nsearch model, which groups the user into multiple friend circles based on\nsearch behaviours and friend relations respectively. These two types of friend\ncircles are complementary to construct a more comprehensive group profile for\nrefining the personalization. Experimental results show the significant\nimprovement of our model over existing personalized search models.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Yujia Zhou",
      "Zhicheng Dou",
      "Bingzheng Wei",
      "Ruobing Xievand Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.12618"
  },
  {
    "id": "arXiv:2111.12620",
    "title": "Convergence of the harmonic balance method for smooth Hilbert space  valued differential-algebraic equations",
    "abstract": "We analyze the convergence of the harmonic balance method for computing\nisolated periodic solutions of a large class of continuously differentiable\nHilbert space valued differential-algebraic equations (DAEs). We establish\nasymptotic convergence estimates for (i) the approximate periodic solution in\nterms of the number of approximated harmonics and (ii) the inexact Newton\nmethod used to compute the approximate Fourier coefficients. The convergence\nestimates are deter-mined by the rate of convergence of the Fourier series of\nthe exact solution and the structure of the DAE. Both the case that the period\nis known and unknown are analyzed, where in the latter case we require\nenforcing an appropriately defined phase condition. The theoretical results are\nillustrated with several numerical experiments from circuit modeling and\nstructural dynamics.",
    "descriptor": "",
    "authors": [
      "Andrew Steyer",
      "Robert J. Kuether"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12620"
  },
  {
    "id": "arXiv:2111.12621",
    "title": "Accelerating Deep Learning with Dynamic Data Pruning",
    "abstract": "Deep learning's success has been attributed to the training of large,\noverparameterized models on massive amounts of data. As this trend continues,\nmodel training has become prohibitively costly, requiring access to powerful\ncomputing systems to train state-of-the-art networks. A large body of research\nhas been devoted to addressing the cost per iteration of training through\nvarious model compression techniques like pruning and quantization. Less effort\nhas been spent targeting the number of iterations. Previous work, such as\nforget scores and GraNd/EL2N scores, address this problem by identifying\nimportant samples within a full dataset and pruning the remaining samples,\nthereby reducing the iterations per epoch. Though these methods decrease the\ntraining time, they use expensive static scoring algorithms prior to training.\nWhen accounting for the scoring mechanism, the total run time is often\nincreased. In this work, we address this shortcoming with dynamic data pruning\nalgorithms. Surprisingly, we find that uniform random dynamic pruning can\noutperform the prior work at aggressive pruning rates. We attribute this to the\nexistence of \"sometimes\" samples -- points that are important to the learned\ndecision boundary only some of the training time. To better exploit the\nsubtlety of sometimes samples, we propose two algorithms, based on\nreinforcement learning techniques, to dynamically prune samples and achieve\neven higher accuracy than the random dynamic method. We test all our methods\nagainst a full-dataset baseline and the prior work on CIFAR-10 and CIFAR-100,\nand we can reduce the training time by up to 2x without significant performance\nloss. Our results suggest that data pruning should be understood as a dynamic\nprocess that is closely tied to a model's training trajectory, instead of a\nstatic step based solely on the dataset alone.",
    "descriptor": "\nComments: 11 pages, 13 figures, under review\n",
    "authors": [
      "Ravi S Raju",
      "Kyle Daruwalla",
      "Mikko Lipasti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12621"
  },
  {
    "id": "arXiv:2111.12624",
    "title": "Self-slimmed Vision Transformer",
    "abstract": "Vision transformers (ViTs) have become the popular structures and\noutperformed convolutional neural networks (CNNs) on various vision tasks.\nHowever, such powerful transformers bring a huge computation burden. And the\nessential barrier behind this is the exhausting token-to-token comparison. To\nalleviate this, we delve deeply into the model properties of ViT and observe\nthat ViTs exhibit sparse attention with high token similarity. This intuitively\nintroduces us a feasible structure-agnostic dimension, token number, to reduce\nthe computational cost. Based on this exploration, we propose a generic\nself-slimmed learning approach for vanilla ViTs, namely SiT. Specifically, we\nfirst design a novel Token Slimming Module (TSM), which can boost the inference\nefficiency of ViTs by dynamic token aggregation. Different from the token hard\ndropping, our TSM softly integrates redundant tokens into fewer informative\nones, which can dynamically zoom visual attention without cutting off\ndiscriminative token relations in the images. Furthermore, we introduce a\nconcise Dense Knowledge Distillation (DKD) framework, which densely transfers\nunorganized token information in a flexible auto-encoder manner. Due to the\nsimilar structure between teacher and student, our framework can effectively\nleverage structure knowledge for better convergence. Finally, we conduct\nextensive experiments to evaluate our SiT. It demonstrates that our method can\nspeed up ViTs by 1.7x with negligible accuracy drop, and even speed up ViTs by\n3.6x while maintaining 97% of their performance. Surprisingly, by simply arming\nLV-ViT with our SiT, we achieve new state-of-the-art performance on ImageNet,\nsurpassing all the CNNs and ViTs in the recent literature.",
    "descriptor": "",
    "authors": [
      "Zhuofan Zong",
      "Kunchang Li",
      "Guanglu Song",
      "Yali Wang",
      "Yu Qiao",
      "Biao Leng",
      "Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12624"
  },
  {
    "id": "arXiv:2111.12628",
    "title": "Efficient Decompositional Rule Extraction for Deep Neural Networks",
    "abstract": "In recent years, there has been significant work on increasing both\ninterpretability and debuggability of a Deep Neural Network (DNN) by extracting\na rule-based model that approximates its decision boundary. Nevertheless,\ncurrent DNN rule extraction methods that consider a DNN's latent space when\nextracting rules, known as decompositional algorithms, are either restricted to\nsingle-layer DNNs or intractable as the size of the DNN or data grows. In this\npaper, we address these limitations by introducing ECLAIRE, a novel\npolynomial-time rule extraction algorithm capable of scaling to both large DNN\narchitectures and large training datasets. We evaluate ECLAIRE on a wide\nvariety of tasks, ranging from breast cancer prognosis to particle detection,\nand show that it consistently extracts more accurate and comprehensible rule\nsets than the current state-of-the-art methods while using orders of magnitude\nless computational resources. We make all of our methods available, including a\nrule set visualisation interface, through the open-source REMIX library\n(https://github.com/mateoespinosa/remix).",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 Workshop on eXplainable AI approaches for debugging and diagnosis (XAI4Debugging)\n",
    "authors": [
      "Mateo Espinosa Zarlenga",
      "Zohreh Shams",
      "Mateja Jamnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12628"
  },
  {
    "id": "arXiv:2111.12629",
    "title": "WFDefProxy: Modularly Implementing and Empirically Evaluating Website  Fingerprinting Defenses",
    "abstract": "Tor, an onion-routing anonymity network, has been shown to be vulnerable to\nWebsite Fingerprinting (WF), which de-anonymizes web browsing by analyzing the\nunique characteristics of the encrypted network traffic. Although many defenses\nhave been proposed, few have been implemented and tested in the real world;\nothers were only simulated. Due to its synthetic nature, simulation may fail to\ncapture the real performance of these defenses. To figure out how these\ndefenses perform in the real world, we propose WFDefProxy, a general platform\nfor WF defense implementation on Tor using pluggable transports. We create the\nfirst full implementation of three WF defenses: FRONT, Tamaraw and Random-WT.\nWe evaluate each defense in both simulation and implementation to compare their\nresults, and we find that simulation correctly captures the strength of each\ndefense against attacks. In addition, we confirm that Random-WT is not\neffective in both simulation and implementation, reducing the strongest\nattacker's accuracy by only 7%.\nWe also found a minor difference in overhead between simulation and\nimplementation. We analyze how this may be due to assumptions made in\nsimulation regarding packet delays and queuing, or the soft stop condition we\nimplemented in WFDefProxy to detect the end of a page load. The implementation\nof FRONT cost about 23% more data overhead than simulation, while the\nimplementation of Tamaraw cost about 28% - 45% less data overhead. In addition,\nthe implementation of Tamaraw incurred only 21% time overhead, compared to 51%\n- 242% estimated by simulation in previous work.",
    "descriptor": "",
    "authors": [
      "Jiajun Gong",
      "Wuqi Zhang",
      "Charles Zhang",
      "Tao Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.12629"
  },
  {
    "id": "arXiv:2111.12631",
    "title": "EAD: an ensemble approach to detect adversarial examples from the hidden  features of deep neural networks",
    "abstract": "One of the key challenges in Deep Learning is the definition of effective\nstrategies for the detection of adversarial examples. To this end, we propose a\nnovel approach named Ensemble Adversarial Detector (EAD) for the identification\nof adversarial examples, in a standard multiclass classification scenario. EAD\ncombines multiple detectors that exploit distinct properties of the input\ninstances in the internal representation of a pre-trained Deep Neural Network\n(DNN). Specifically, EAD integrates the state-of-the-art detectors based on\nMahalanobis distance and on Local Intrinsic Dimensionality (LID) with a newly\nintroduced method based on One-class Support Vector Machines (OSVMs). Although\nall constituting methods assume that the greater the distance of a test\ninstance from the set of correctly classified training instances, the higher\nits probability to be an adversarial example, they differ in the way such\ndistance is computed. In order to exploit the effectiveness of the different\nmethods in capturing distinct properties of data distributions and,\naccordingly, efficiently tackle the trade-off between generalization and\noverfitting, EAD employs detector-specific distance scores as features of a\nlogistic regression classifier, after independent hyperparameters optimization.\nWe evaluated the EAD approach on distinct datasets (CIFAR-10, CIFAR-100 and\nSVHN) and models (ResNet and DenseNet) and with regard to four adversarial\nattacks (FGSM, BIM, DeepFool and CW), also by comparing with competing\napproaches. Overall, we show that EAD achieves the best AUROC and AUPR in the\nlarge majority of the settings and comparable performance in the others. The\nimprovement over the state-of-the-art, and the possibility to easily extend EAD\nto include any arbitrary set of detectors, pave the way to a widespread\nadoption of ensemble approaches in the broad field of adversarial example\ndetection.",
    "descriptor": "",
    "authors": [
      "Francesco Craighero",
      "Fabrizio Angaroni",
      "Fabio Stella",
      "Chiara Damiani",
      "Marco Antoniotti",
      "Alex Graudenzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12631"
  },
  {
    "id": "arXiv:2111.12638",
    "title": "Optimal Robust Exact Differentiation via Linear Adaptive Techniques",
    "abstract": "The problem of differentiating a function with bounded second derivative in\nthe presence of bounded measurement noise is considered. Performance\nlimitations in terms of the smallest achievable worst-case differentiation\nerror of causal and exact differentiators are shown. A robust exact\ndifferentiator is then constructed via the adaptation of a single parameter of\na linear differentiator. It is demonstrated that the resulting differentiator\nis robust with respect to noise, that it instantaneously converges to the exact\nderivative in the absence of noise, and that it attains the smallest possible\n-- hence optimal -- upper bound on its differentiation error under noisy\nmeasurements. For practical realization in the presence of sampled\nmeasurements, a discrete-time realization is shown that achieves optimal\nasymptotic accuracy with respect to the noise and the sampling period.",
    "descriptor": "",
    "authors": [
      "Richard Seeber",
      "Hernan Haimovich"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.12638"
  },
  {
    "id": "arXiv:2111.12642",
    "title": "A global quadratic speed-up for computing the principal eigenvalue of  Perron-like operators",
    "abstract": "We consider a new algorithm in light of the min-max Collatz-Wielandt\nformalism to compute the principal eigenvalue and the eigenvector\n(eigen-function) for a class of positive Perron-Frobenius-like operators. Such\noperators are natural generalizations of the usual nonnegative primitive\nmatrices. These have nontrivial applications in PDE problems such as computing\nthe principal eigenvalue of Dirichlet Laplacian operators on general domains.\nWe rigorously prove that for general initial data the corresponding numerical\niterates converge globally to the unique principal eigenvalue with quadratic\nconvergence. We show that the quadratic convergence is sharp with compatible\nupper and lower bounds. We demonstrate the effectiveness of the scheme via\nseveral illustrative numerical examples.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Dong Li",
      "Jianan Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.12642"
  },
  {
    "id": "arXiv:2111.12643",
    "title": "SM3D: Simultaneous Monocular Mapping and 3D Detection",
    "abstract": "Mapping and 3D detection are two major issues in vision-based robotics, and\nself-driving. While previous works only focus on each task separately, we\npresent an innovative and efficient multi-task deep learning framework (SM3D)\nfor Simultaneous Mapping and 3D Detection by bridging the gap with robust depth\nestimation and \"Pseudo-LiDAR\" point cloud for the first time. The Mapping\nmodule takes consecutive monocular frames to generate depth and pose\nestimation. In 3D Detection module, the depth estimation is projected into 3D\nspace to generate \"Pseudo-LiDAR\" point cloud, where LiDAR-based 3D detector can\nbe leveraged on point cloud for vehicular 3D detection and localization. By\nend-to-end training of both modules, the proposed mapping and 3D detection\nmethod outperforms the state-of-the-art baseline by 10.0% and 13.2% in\naccuracy, respectively. While achieving better accuracy, our monocular\nmulti-task SM3D is more than 2 times faster than pure stereo 3D detector, and\n18.3% faster than using two modules separately.",
    "descriptor": "\nComments: This paper is published on 2021 IEEE International Conference on Image Processing (ICIP 2021), this https URL\n",
    "authors": [
      "Runfa Li",
      "Truong Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12643"
  },
  {
    "id": "arXiv:2111.12661",
    "title": "Analysing Statistical methods for Automatic Detection of Image Forgery",
    "abstract": "Image manipulation and forgery detection have been a topic of research for\nmore than a decade now. New-age tools and large-scale social platforms have\ngiven space for manipulated media to thrive. These media can be potentially\ndangerous and thus innumerable methods have been designed and tested to prove\ntheir robustness in detecting forgery. However, the results reported by\nstate-of-the-art systems indicate that supervised approaches achieve almost\nperfect performance but only with particular datasets. In this work, we analyze\nthe issue of out-of-distribution generalisability of the current\nstate-of-the-art image forgery detection techniques through several\nexperiments. Our study focuses on models that utilise handcrafted features for\nimage forgery detection. We show that the developed methods fail to perform\nwell on cross-dataset evaluations and in-the-wild manipulated media. As a\nconsequence, a question is raised about the current evaluation and\noverestimated performance of the systems under consideration. Note: This work\nwas done during a summer research internship at ITMR Lab, IIIT-Allahabad under\nthe supervision of Prof. Anupam Agarwal.",
    "descriptor": "",
    "authors": [
      "Umar Masud",
      "Anupam Agarwal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12661"
  },
  {
    "id": "arXiv:2111.12663",
    "title": "PointPCA: Point Cloud Objective Quality Assessment Using PCA-Based  Descriptors",
    "abstract": "With the increasing popularity of extended reality technology and the\nadoption of depth-enhanced visual data in information exchange and\ntelecommunication systems, point clouds have emerged as a promising 3D imaging\nmodality. Similarly to other types of content representations, visual quality\npredictors for point cloud data are vital for a wide range of applications,\nenabling perceptually optimized solutions from acquisition to rendering. Recent\nstandardization activities on point cloud compression have urged the need for\nobjective quality evaluation methods, driving the research community to the\ndevelopment of relevant algorithms. In this work, we complement existing\napproaches by proposing a new quality metric that compares local shape and\nappearance measurements between a reference and a distorted point cloud. To\nthis aim, a large set of geometric and textural descriptors is defined, and the\nprediction accuracy of corresponding statistical features is evaluated in the\ncontext of quality assessment. Different combination strategies are examined,\nproviding insights regarding the effectiveness of different metric designs. The\nperformance of the proposed method is validated against subjectively-annotated\ndatasets, showing better performance against state-of-the-art solutions in the\nmajority of cases. A software implementation of the metric is made available\nhere: https://github.com/cwi-dis/pointpca.",
    "descriptor": "\nComments: 14 pages, 9 figures, 6 tables\n",
    "authors": [
      "Evangelos Alexiou",
      "Irene Viola",
      "Pablo Cesar"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.12663"
  },
  {
    "id": "arXiv:2111.12664",
    "title": "MIO : Mutual Information Optimization using Self-Supervised Binary  Contrastive Learning",
    "abstract": "Self-supervised contrastive learning is one of the domains which has\nprogressed rapidly over the last few years. Most of the state-of-the-art\nself-supervised algorithms use a large number of negative samples, momentum\nupdates, specific architectural modifications, or extensive training to learn\ngood representations. Such arrangements make the overall training process\ncomplex and challenging to realize analytically. In this paper, we propose a\nmutual information optimization based loss function for contrastive learning\nwhere we model contrastive learning into a binary classification problem to\npredict if a pair is positive or not. This formulation not only helps us to\ntrack the problem mathematically but also helps us to outperform existing\nalgorithms. Unlike the existing methods that only maximize the mutual\ninformation in a positive pair, the proposed loss function optimizes the mutual\ninformation in both positive and negative pairs. We also present a mathematical\nexpression for the parameter gradients flowing into the projector and the\ndisplacement of the feature vectors in the feature space. This helps us to get\na mathematical insight into the working principle of contrastive learning. An\nadditive $L_2$ regularizer is also used to prevent diverging of the feature\nvectors and to improve performance. The proposed method outperforms the\nstate-of-the-art algorithms on benchmark datasets like STL-10, CIFAR-10,\nCIFAR-100. After only 250 epochs of pre-training, the proposed model achieves\nthe best accuracy of 85.44\\%, 60.75\\%, 56.81\\% on CIFAR-10, STL-10, CIFAR-100\ndatasets, respectively.",
    "descriptor": "",
    "authors": [
      "Siladittya Manna",
      "Saumik Bhattacharya",
      "Umapada Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12664"
  },
  {
    "id": "arXiv:2111.12665",
    "title": "Finite-Time Error Bounds for Distributed Linear Stochastic Approximation",
    "abstract": "This paper considers a novel multi-agent linear stochastic approximation\nalgorithm driven by Markovian noise and general consensus-type interaction, in\nwhich each agent evolves according to its local stochastic approximation\nprocess which depends on the information from its neighbors. The\ninterconnection structure among the agents is described by a time-varying\ndirected graph. While the convergence of consensus-based stochastic\napproximation algorithms when the interconnection among the agents is described\nby doubly stochastic matrices (at least in expectation) has been studied, less\nis known about the case when the interconnection matrix is simply stochastic.\nFor any uniformly strongly connected graph sequences whose associated\ninteraction matrices are stochastic, the paper derives finite-time bounds on\nthe mean-square error, defined as the deviation of the output of the algorithm\nfrom the unique equilibrium point of the associated ordinary differential\nequation. For the case of interconnection matrices being stochastic, the\nequilibrium point can be any unspecified convex combination of the local\nequilibria of all the agents in the absence of communication. Both the cases\nwith constant and time-varying step-sizes are considered. In the case when the\nconvex combination is required to be a straight average and interaction between\nany pair of neighboring agents may be uni-directional, so that doubly\nstochastic matrices cannot be implemented in a distributed manner, the paper\nproposes a push-sum-type distributed stochastic approximation algorithm and\nprovides its finite-time bound for the time-varying step-size case by\nleveraging the analysis for the consensus-type algorithm with stochastic\nmatrices and developing novel properties of the push-sum algorithm.",
    "descriptor": "",
    "authors": [
      "Yixuan Lin",
      "Vijay Gupta",
      "Ji Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12665"
  },
  {
    "id": "arXiv:2111.12673",
    "title": "Adaptively Calibrated Critic Estimates for Deep Reinforcement Learning",
    "abstract": "Accurate value estimates are important for off-policy reinforcement learning.\nAlgorithms based on temporal difference learning typically are prone to an\nover- or underestimation bias building up over time. In this paper, we propose\na general method called Adaptively Calibrated Critics (ACC) that uses the most\nrecent high variance but unbiased on-policy rollouts to alleviate the bias of\nthe low variance temporal difference targets. We apply ACC to Truncated\nQuantile Critics, which is an algorithm for continuous control that allows\nregulation of the bias with a hyperparameter tuned per environment. The\nresulting algorithm adaptively adjusts the parameter during training rendering\nhyperparameter search unnecessary and sets a new state of the art on the OpenAI\ngym continuous control benchmark among all algorithms that do not tune\nhyperparameters for each environment. Additionally, we demonstrate that ACC is\nquite general by further applying it to TD3 and showing an improved performance\nalso in this setting.",
    "descriptor": "",
    "authors": [
      "Nicolai Dorka",
      "Joschka Boedecker",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.12673"
  },
  {
    "id": "arXiv:2111.12675",
    "title": "The Surprising Benefits of Hysteresis in Unlimited Sampling: Theory,  Algorithms and Experiments",
    "abstract": "The Unlimited Sensing Framework (USF) was recently introduced to overcome the\nsensor saturation bottleneck in conventional digital acquisition systems. At\nits core, the USF allows for high-dynamic-range (HDR) signal reconstruction by\nconverting a continuous-time signal into folded, low-dynamic-range (LDR),\nmodulo samples. HDR reconstruction is then carried out by algorithmic unfolding\nof the folded samples. In hardware, however, implementing an ideal modulo\nfolding requires careful calibration, analog design and high precision. At the\ninterface of theory and practice, this paper explores a computational sampling\nstrategy that relaxes strict hardware requirements by compensating them via a\nnovel, mathematically guaranteed recovery method. Our starting point is a\ngeneralized model for USF. The generalization relies on two new parameters\nmodeling hysteresis and folding transients} in addition to the modulo\nthreshold. Hysteresis accounts for the mismatch between the reset threshold and\nthe amplitude displacement at the folding time and we refer to a continuous\ntransition period in the implementation of a reset as folding transient. Both\nthese effects are motivated by our hardware experiments and also occur in\nprevious, domain-specific applications. We show that the effect of hysteresis\nis beneficial for the USF and we leverage it to derive the first recovery\nguarantees in the context of our generalized USF model. Additionally, we show\nhow the proposed recovery can be directly generalized for the case of lower\nsampling rates. Our theoretical work is corroborated by hardware experiments\nthat are based on a hysteresis enabled, modulo ADC testbed comprising\noff-the-shelf electronic components. Thus, by capitalizing on a collaboration\nbetween hardware and algorithms, our paper enables an end-to-end pipeline for\nHDR sampling allowing more flexible hardware implementations.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Dorian Florescu",
      "Felix Krahmer",
      "Ayush Bhandari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.12675"
  },
  {
    "id": "arXiv:2111.12677",
    "title": "Topological and Algebraic Structures of the Space of Atanassov's  Intuitionistic Fuzzy Values",
    "abstract": "We demonstrate that the space of intuitionistic fuzzy values (IFVs) with the\nlinear order based on a score function and an accuracy function has the same\nalgebraic structure as the one induced by the linear order based on a\nsimilarity function and an accuracy function. By introducing a new operator for\nIFVs via the linear order based on a score function and an accuracy function,\nwe present that such an operator is a strong negation on IFVs. Moreover, we\npropose that the space of IFVs is a complete lattice and a Kleene algebra with\nthe new operator. We also observe that the topological space of IFVs with the\norder topology induced by the above two linear orders is not separable and\nmetrizable but compact and connected. From exactly new perspectives, our\nresults partially answer three open problems posed by Atanassov [Intuitionistic\nFuzzy Sets: Theory and Applications, Springer, 1999] and [On Intuitionistic\nFuzzy Sets Theory, Springer, 2012]. Furthermore, we construct an isomorphism\nbetween the spaces of IFVs and q-rung orthopedic fuzzy values (q-ROFVs) under\nthe corresponding linear orders. Meanwhile, we introduce the concept of the\nadmissible similarity measures with particular orders for IFSs, extending the\nprevious definition of the similarity measure for IFSs, and construct an\nadmissible similarity measure with the linear order based on a score function\nand an accuracy function, which is effectively applied to a pattern recognition\nproblem about the classification of building materials.",
    "descriptor": "",
    "authors": [
      "Xinxing Wu",
      "Tao Wang",
      "Peide Liu",
      "Gul Deniz Cayli",
      "Xu Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12677"
  },
  {
    "id": "arXiv:2111.12678",
    "title": "Output Regulation by Postprocessing Internal Models for a Class of  Multivariable Nonlinear Systems",
    "abstract": "In this paper we propose a new design paradigm, which employing a\npostprocessing internal model unit, to approach the problem of output\nregulation for a class of multivariable minimum-phase nonlinear systems\npossessing a partial normal form. Contrary to previous approaches, the proposed\nregulator handles control inputs of dimension larger than the number of\nregulated variables, provided that a controllability assumption holds, and can\nemploy additional measurements that need not to vanish at the ideal\nerror-zeroing steady state, but that can be useful for stabilization purposes\nor to fulfil the minimum-phase requirement. Conditions for practical and\nasymptotic output regulation are given, underlying how in postprocessing\nschemes the design of internal models is necessarily intertwined with that of\nthe stabilizer.",
    "descriptor": "\nComments: The published version contains a few small rendering issues in some formulae. Here, these are corrected\n",
    "authors": [
      "Michelangelo Bin",
      "Lorenzo Marconi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.12678"
  },
  {
    "id": "arXiv:2111.12679",
    "title": "Reinforcement Learning for General LTL Objectives Is Intractable",
    "abstract": "In recent years, researchers have made significant progress in devising\nreinforcement-learning algorithms for optimizing linear temporal logic (LTL)\nobjectives and LTL-like objectives. Despite these advancements, there are\nfundamental limitations to how well this problem can be solved that previous\nstudies have alluded to but, to our knowledge, have not examined in depth. In\nthis paper, we address theoretically the hardness of learning with general LTL\nobjectives. We formalize the problem under the probably approximately correct\nlearning in Markov decision processes (PAC-MDP) framework, a standard framework\nfor measuring sample complexity in reinforcement learning. In this\nformalization, we prove that the optimal policy for any LTL formula is\nPAC-MDP-learnable only if the formula is in the most limited class in the LTL\nhierarchy, consisting of only finite-horizon-decidable properties. Practically,\nour result implies that it is impossible for a reinforcement-learning algorithm\nto obtain a PAC-MDP guarantee on the performance of its learned policy after\nfinitely many interactions with an unconstrained environment for\nnon-finite-horizon-decidable LTL objectives.",
    "descriptor": "",
    "authors": [
      "Cambridge Yang",
      "Michael Littman",
      "Michael Carbin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12679"
  },
  {
    "id": "arXiv:2111.12680",
    "title": "An XGBoost-Based Forecasting Framework for Product Cannibalization",
    "abstract": "Two major challenges in demand forecasting are product cannibalization and\nlong term forecasting. Product cannibalization is a phenomenon in which high\ndemand of some products leads to reduction in sales of other products. Long\nterm forecasting involves forecasting the sales over longer time frame that is\ncritical for strategic business purposes. Also, conventional methods, for\ninstance, recurrent neural networks may be ineffective where train data size is\nsmall as in the case in this study. This work presents XGBoost-based\nthree-stage framework that addresses product cannibalization and associated\nlong term error propagation problems. The performance of the proposed\nthree-stage XGBoost-based framework is compared to and is found superior than\nthat of regular XGBoost algorithm.",
    "descriptor": "",
    "authors": [
      "Gautham Bekal",
      "Mohammad Bari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12680"
  },
  {
    "id": "arXiv:2111.12681",
    "title": "VIOLET : End-to-End Video-Language Transformers with Masked Visual-token  Modeling",
    "abstract": "A great challenge in video-language (VidL) modeling lies in the disconnection\nbetween fixed video representations extracted from image/video understanding\nmodels and downstream VidL data. Recent studies try to mitigate this\ndisconnection via end-to-end training. To make it computationally feasible,\nprior works tend to \"imagify\" video inputs, i.e., a handful of sparsely sampled\nframes are fed into a 2D CNN, followed by a simple mean-pooling or\nconcatenation to obtain the overall video representations. Although achieving\npromising results, such simple approaches may lose temporal information that is\nessential for performing downstream VidL tasks. In this work, we present\nVIOLET, a fully end-to-end VIdeO-LanguagE Transformer, which adopts a video\ntransformer to explicitly model the temporal dynamics of video inputs. Further,\nunlike previous studies that found pre-training tasks on video inputs (e.g.,\nmasked frame modeling) not very effective, we design a new pre-training task,\nMasked Visual-token Modeling (MVM), for better video modeling. Specifically,\nthe original video frame patches are \"tokenized\" into discrete visual tokens,\nand the goal is to recover the original visual tokens based on the masked\npatches. Comprehensive analysis demonstrates the effectiveness of both explicit\ntemporal modeling via video transformer and MVM. As a result, VIOLET achieves\nnew state-of-the-art performance on 5 video question answering tasks and 4\ntext-to-video retrieval tasks.",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Tsu-Jui Fu",
      "Linjie Li",
      "Zhe Gan",
      "Kevin Lin",
      "William Yang Wang",
      "Lijuan Wang",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12681"
  },
  {
    "id": "arXiv:2111.12682",
    "title": "A Formally-Verified Framework for Fair Synchronization in Kotlin  Coroutines",
    "abstract": "Writing concurrent code that is both correct and efficient is notoriously\ndifficult: thus, programmers often prefer to use synchronization abstractions,\nwhich render code simpler and easier to reason about. Despite a wealth of work\non this topic, there is still a gap between the rich semantics provided by\nsynchronization abstractions in modern programming languages--specifically,\nfair FIFO ordering of synchronization requests and support for abortable\noperations--and frameworks for implementing such semantics correctly and\nefficiently. Supporting such semantics is critical given the rising popularity\nof constructs for asynchronous programming, such as coroutines, which abort\nfrequently, and should be cheaper to suspend and resume compared to native\nthreads.\nWe introduce a new framework called the CancellableQueueSynchronizer (CQS),\nwhich enables efficient fair and abortable implementations of fundamental\nsynchronization primitives such as mutexes, semaphores, barriers,\ncount-down-latches, and blocking pools. Our first contribution is algorithmic,\nas implementing both fairness and abortability efficiently at this level of\ngenerality is non-trivial. Importantly, all our algorithms come with formal\nproofs in the Iris framework for Coq. These proofs are modular, so it is easy\nto prove correctness for new primitives implemented on top of CQS. To validate\npractical impact, we integrated CQS into the Kotlin Coroutines library.\nCompared against Java's AbstractQueuedSynchronizer, the only practical\nabstraction to provide similar semantics, CQS shows significant improvements\nacross all benchmarks, of up to two orders of magnitude. In sum, CQS is the\nfirst framework to combine expressiveness with formal guarantees and strong\npractical performance, and should be extensible to other languages and other\nfamilies of synchronization primitives.",
    "descriptor": "",
    "authors": [
      "Nikita Koval",
      "Dmitry Khalanskiy",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.12682"
  },
  {
    "id": "arXiv:2111.12685",
    "title": "EgoRenderer: Rendering Human Avatars from Egocentric Camera Images",
    "abstract": "We present EgoRenderer, a system for rendering full-body neural avatars of a\nperson captured by a wearable, egocentric fisheye camera that is mounted on a\ncap or a VR headset. Our system renders photorealistic novel views of the actor\nand her motion from arbitrary virtual camera locations. Rendering full-body\navatars from such egocentric images come with unique challenges due to the\ntop-down view and large distortions. We tackle these challenges by decomposing\nthe rendering process into several steps, including texture synthesis, pose\nconstruction, and neural image translation. For texture synthesis, we propose\nEgo-DPNet, a neural network that infers dense correspondences between the input\nfisheye images and an underlying parametric body model, and to extract textures\nfrom egocentric inputs. In addition, to encode dynamic appearances, our\napproach also learns an implicit texture stack that captures detailed\nappearance variation across poses and viewpoints. For correct pose generation,\nwe first estimate body pose from the egocentric view using a parametric model.\nWe then synthesize an external free-viewpoint pose image by projecting the\nparametric model to the user-specified target viewpoint. We next combine the\ntarget pose image and the textures into a combined feature image, which is\ntransformed into the output color image using a neural image translation\nnetwork. Experimental evaluations show that EgoRenderer is capable of\ngenerating realistic free-viewpoint avatars of a person wearing an egocentric\ncamera. Comparisons to several baselines demonstrate the advantages of our\napproach.",
    "descriptor": "\nComments: ICCV 2021. this https URL\n",
    "authors": [
      "Tao Hu",
      "Kripasindhu Sarkar",
      "Lingjie Liu",
      "Matthias Zwicker",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12685"
  },
  {
    "id": "arXiv:2111.12689",
    "title": "A stacked deep convolutional neural network to predict the remaining  useful life of a turbofan engine",
    "abstract": "This paper presents the data-driven techniques and methodologies used to\npredict the remaining useful life (RUL) of a fleet of aircraft engines that can\nsuffer failures of diverse nature. The solution presented is based on two Deep\nConvolutional Neural Networks (DCNN) stacked in two levels. The first DCNN is\nused to extract a low-dimensional feature vector using the normalized raw data\nas input. The second DCNN ingests a list of vectors taken from the former DCNN\nand estimates the RUL. Model selection was carried out by means of Bayesian\noptimization using a repeated random subsampling validation approach. The\nproposed methodology was ranked in the third place of the 2021 PHM Conference\nData Challenge.",
    "descriptor": "",
    "authors": [
      "David Solis-Martin",
      "Juan Galan-Paez",
      "Joaquin Borrego-Diaz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12689"
  },
  {
    "id": "arXiv:2111.12690",
    "title": "Automatic Mapping with Obstacle Identification for Indoor Human Mobility  Assessment",
    "abstract": "We propose a framework that allows a mobile robot to build a map of an indoor\nscenario, identifying and highlighting objects that may be considered a\nhindrance to people with limited mobility. The map is built by combining recent\ndevelopments in monocular SLAM with information from inertial sensors of the\nrobot platform, resulting in a metric point cloud that can be further processed\nto obtain a mesh. The images from the monocular camera are simultaneously\nanalyzed with an object recognition neural network, tuned to detect a\nparticular class of targets. This information is then processed and\nincorporated on the metric map, resulting in a detailed survey of the locations\nand bounding volumes of the objects of interest. The result can be used to\ninform policy makers and users with limited mobility of the hazards present in\na particular indoor location. Our initial tests were performed using a\nmicro-UAV and will be extended to other robotic platforms.",
    "descriptor": "",
    "authors": [
      "V. Ayala-Alfaro",
      "J. A. Vilchis-Mar",
      "F. E. Correa-Tome",
      "J. P. Ramirez-Paredes"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.12690"
  },
  {
    "id": "arXiv:2111.12696",
    "title": "A Lightweight Graph Transformer Network for Human Mesh Reconstruction  from 2D Human Pose",
    "abstract": "Existing deep learning-based human mesh reconstruction approaches have a\ntendency to build larger networks in order to achieve higher accuracy.\nComputational complexity and model size are often neglected, despite being key\ncharacteristics for practical use of human mesh reconstruction models (e.g.\nvirtual try-on systems). In this paper, we present GTRS, a lightweight\npose-based method that can reconstruct human mesh from 2D human pose. We\npropose a pose analysis module that uses graph transformers to exploit\nstructured and implicit joint correlations, and a mesh regression module that\ncombines the extracted pose feature with the mesh template to reconstruct the\nfinal human mesh. We demonstrate the efficiency and generalization of GTRS by\nextensive evaluations on the Human3.6M and 3DPW datasets. In particular, GTRS\nachieves better accuracy than the SOTA pose-based method Pose2Mesh while only\nusing 10.2% of the parameters (Params) and 2.5% of the FLOPs on the challenging\nin-the-wild 3DPW dataset. Code will be publicly available.",
    "descriptor": "",
    "authors": [
      "Ce Zheng",
      "Matias Mendieta",
      "Pu Wang",
      "Aidong Lu",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.12696"
  },
  {
    "id": "arXiv:2111.12698",
    "title": "Open-Vocabulary Instance Segmentation via Robust Cross-Modal  Pseudo-Labeling",
    "abstract": "Open-vocabulary instance segmentation aims at segmenting novel classes\nwithout mask annotations. It is an important step toward reducing laborious\nhuman supervision. Most existing works first pretrain a model on captioned\nimages covering many novel classes and then finetune it on limited base classes\nwith mask annotations. However, the high-level textual information learned from\ncaption pretraining alone cannot effectively encode the details required for\npixel-wise segmentation. To address this, we propose a cross-modal\npseudo-labeling framework, which generates training pseudo masks by aligning\nword semantics in captions with visual features of object masks in images.\nThus, our framework is capable of labeling novel classes in captions via their\nword semantics to self-train a student model. To account for noises in pseudo\nmasks, we design a robust student model that selectively distills mask\nknowledge by estimating the mask noise levels, hence mitigating the adverse\nimpact of noisy pseudo masks. By extensive experiments, we show the\neffectiveness of our framework, where we significantly improve mAP score by\n4.5% on MS-COCO and 5.1% on the large-scale Open Images & Conceptual Captions\ndatasets compared to the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Dat Huynh",
      "Jason Kuen",
      "Zhe Lin",
      "Jiuxiang Gu",
      "Ehsan Elhamifar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12698"
  },
  {
    "id": "arXiv:2111.12701",
    "title": "Unleashing Transformers: Parallel Token Prediction with Discrete  Absorbing Diffusion for Fast High-Resolution Image Generation from  Vector-Quantized Codes",
    "abstract": "Whilst diffusion probabilistic models can generate high quality image\ncontent, key limitations remain in terms of both generating high-resolution\nimagery and their associated high computational requirements. Recent\nVector-Quantized image models have overcome this limitation of image resolution\nbut are prohibitively slow and unidirectional as they generate tokens via\nelement-wise autoregressive sampling from the prior. By contrast, in this paper\nwe propose a novel discrete diffusion probabilistic model prior which enables\nparallel prediction of Vector-Quantized tokens by using an unconstrained\nTransformer architecture as the backbone. During training, tokens are randomly\nmasked in an order-agnostic manner and the Transformer learns to predict the\noriginal tokens. This parallelism of Vector-Quantized token prediction in turn\nfacilitates unconditional generation of globally consistent high-resolution and\ndiverse imagery at a fraction of the computational expense. In this manner, we\ncan generate image resolutions exceeding that of the original training set\nsamples whilst additionally provisioning per-image likelihood estimates (in a\ndeparture from generative adversarial approaches). Our approach achieves\nstate-of-the-art results in terms of Density (LSUN Bedroom: 1.51; LSUN\nChurches: 1.12; FFHQ: 1.20) and Coverage (LSUN Bedroom: 0.83; LSUN Churches:\n0.73; FFHQ: 0.80), and performs competitively on FID (LSUN Bedroom: 3.64; LSUN\nChurches: 4.07; FFHQ: 6.11) whilst offering advantages in terms of both\ncomputation and reduced training set requirements.",
    "descriptor": "\nComments: 19 pages, 14 figures\n",
    "authors": [
      "Sam Bond-Taylor",
      "Peter Hessey",
      "Hiroshi Sasaki",
      "Toby P. Breckon",
      "Chris G. Willcocks"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12701"
  },
  {
    "id": "arXiv:2111.12702",
    "title": "Density-aware Chamfer Distance as a Comprehensive Metric for Point Cloud  Completion",
    "abstract": "Chamfer Distance (CD) and Earth Mover's Distance (EMD) are two broadly\nadopted metrics for measuring the similarity between two point sets. However,\nCD is usually insensitive to mismatched local density, and EMD is usually\ndominated by global distribution while overlooks the fidelity of detailed\nstructures. Besides, their unbounded value range induces a heavy influence from\nthe outliers. These defects prevent them from providing a consistent\nevaluation. To tackle these problems, we propose a new similarity measure named\nDensity-aware Chamfer Distance (DCD). It is derived from CD and benefits from\nseveral desirable properties: 1) it can detect disparity of density\ndistributions and is thus a more intensive measure of similarity compared to\nCD; 2) it is stricter with detailed structures and significantly more\ncomputationally efficient than EMD; 3) the bounded value range encourages a\nmore stable and reasonable evaluation over the whole test set. We adopt DCD to\nevaluate the point cloud completion task, where experimental results show that\nDCD pays attention to both the overall structure and local geometric details\nand provides a more reliable evaluation even when CD and EMD contradict each\nother. We can also use DCD as the training loss, which outperforms the same\nmodel trained with CD loss on all three metrics. In addition, we propose a\nnovel point discriminator module that estimates the priority for another guided\ndown-sampling step, and it achieves noticeable improvements under DCD together\nwith competitive results for both CD and EMD. We hope our work could pave the\nway for a more comprehensive and practical point cloud similarity evaluation.\nOur code will be available at:\nhttps://github.com/wutong16/Density_aware_Chamfer_Distance .",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Tong Wu",
      "Liang Pan",
      "Junzhe Zhang",
      "Tai Wang",
      "Ziwei Liu",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12702"
  },
  {
    "id": "arXiv:2111.12704",
    "title": "Investigating Tradeoffs in Real-World Video Super-Resolution",
    "abstract": "The diversity and complexity of degradations in real-world video\nsuper-resolution (VSR) pose non-trivial challenges in inference and training.\nFirst, while long-term propagation leads to improved performance in cases of\nmild degradations, severe in-the-wild degradations could be exaggerated through\npropagation, impairing output quality. To balance the tradeoff between detail\nsynthesis and artifact suppression, we found an image pre-cleaning stage\nindispensable to reduce noises and artifacts prior to propagation. Equipped\nwith a carefully designed cleaning module, our RealBasicVSR outperforms\nexisting methods in both quality and efficiency. Second, real-world VSR models\nare often trained with diverse degradations to improve generalizability,\nrequiring increased batch size to produce a stable gradient. Inevitably, the\nincreased computational burden results in various problems, including 1)\nspeed-performance tradeoff and 2) batch-length tradeoff. To alleviate the first\ntradeoff, we propose a stochastic degradation scheme that reduces up to 40\\% of\ntraining time without sacrificing performance. We then analyze different\ntraining settings and suggest that employing longer sequences rather than\nlarger batches during training allows more effective uses of temporal\ninformation, leading to more stable performance during inference. To facilitate\nfair comparisons, we propose the new VideoLQ dataset, which contains a large\nvariety of real-world low-quality video sequences containing rich textures and\npatterns. Our dataset can serve as a common ground for benchmarking. Code,\nmodels, and the dataset will be made publicly available.",
    "descriptor": "\nComments: Tech report, 14 pages, 14 figures. Code can be found at this https URL\n",
    "authors": [
      "Kelvin C.K. Chan",
      "Shangchen Zhou",
      "Xiangyu Xu",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12704"
  },
  {
    "id": "arXiv:2111.12705",
    "title": "MixSyn: Learning Composition and Style for Multi-Source Image Synthesis",
    "abstract": "Synthetic images created by generative models increase in quality and\nexpressiveness as newer models utilize larger datasets and novel architectures.\nAlthough this photorealism is a positive side-effect from a creative\nstandpoint, it becomes problematic when such generative models are used for\nimpersonation without consent. Most of these approaches are built on the\npartial transfer between source and target pairs, or they generate completely\nnew samples based on an ideal distribution, still resembling the closest real\nsample in the dataset. We propose MixSyn (read as \" mixin' \") for learning\nnovel fuzzy compositions from multiple sources and creating novel images as a\nmix of image regions corresponding to the compositions. MixSyn not only\ncombines uncorrelated regions from multiple source masks into a coherent\nsemantic composition, but also generates mask-aware high quality\nreconstructions of non-existing images. We compare MixSyn to state-of-the-art\nsingle-source sequential generation and collage generation approaches in terms\nof quality, diversity, realism, and expressive power; while also showcasing\ninteractive synthesis, mix & match, and edit propagation tasks, with no mask\ndependency.",
    "descriptor": "",
    "authors": [
      "Ilke Demir",
      "Umur A. Ciftci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12705"
  },
  {
    "id": "arXiv:2111.12706",
    "title": "Gap Edit Distance via Non-Adaptive Queries: Simple and Optimal",
    "abstract": "We study the problem of approximating edit distance in sublinear time. This\nis formalized as a promise problem $(k,k^c)$-Gap Edit Distance, where the input\nis a pair of strings $X,Y$ and parameters $k,c>1$, and the goal is to return\nYES if $ED(X,Y)\\leq k$ and NO if $ED(X,Y)> k^c$. Recent years have witnessed\nsignificant interest in designing sublinear-time algorithms for Gap Edit\nDistance.\nWe resolve the non-adaptive query complexity of Gap Edit Distance, improving\nover several previous results. Specifically, we design a non-adaptive algorithm\nwith query complexity $\\tilde{O}(\\frac{n}{k^{c-0.5}})$, and further prove that\nthis bound is optimal up to polylogarithmic factors.\nOur algorithm also achieves optimal time complexity\n$\\tilde{O}(\\frac{n}{k^{c-0.5}})$ whenever $c\\geq 1.5$. For $1<c<1.5$, the\nrunning time of our algorithm is $\\tilde{O}(\\frac{n}{k^{2c-1}})$. For the\nrestricted case of $k^c=\\Omega(n)$, this matches a known result [Batu, Erg\\\"un,\nKilian, Magen, Raskhodnikova, Rubinfeld, and Sami, STOC 2003], and in all other\n(nontrivial) cases, our running time is strictly better than all previous\nalgorithms, including the adaptive ones.",
    "descriptor": "",
    "authors": [
      "Elazar Goldenberg",
      "Tomasz Kociumaka",
      "Robert Krauthgamer",
      "Barna Saha"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.12706"
  },
  {
    "id": "arXiv:2111.12707",
    "title": "MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation",
    "abstract": "Estimating 3D human poses from monocular videos is a challenging task due to\ndepth ambiguity and self-occlusion. Most existing works attempt to solve both\nissues by exploiting spatial and temporal relationships. However, those works\nignore the fact that it is an inverse problem where multiple feasible solutions\n(i.e., hypotheses) exist. To relieve this limitation, we propose a\nMulti-Hypothesis Transformer (MHFormer) that learns spatio-temporal\nrepresentations of multiple plausible pose hypotheses. In order to effectively\nmodel multi-hypothesis dependencies and build strong relationships across\nhypothesis features, the task is decomposed into three stages: (i) Generate\nmultiple initial hypothesis representations; (ii) Model self-hypothesis\ncommunication, merge multiple hypotheses into a single converged representation\nand then partition it into several diverged hypotheses; (iii) Learn\ncross-hypothesis communication and aggregate the multi-hypothesis features to\nsynthesize the final 3D pose. Through the above processes, the final\nrepresentation is enhanced and the synthesized pose is much more accurate.\nExtensive experiments show that MHFormer achieves state-of-the-art results on\ntwo challenging datasets: Human3.6M and MPI-INF-3DHP. Without bells and\nwhistles, its performance surpasses the previous best result by a large margin\nof 3% on Human3.6M. Code and models are available at\nhttps://github.com/Vegetebird/MHFormer.",
    "descriptor": "\nComments: open sourced\n",
    "authors": [
      "Wenhao Li",
      "Hong Liu",
      "Hao Tang",
      "Pichao Wang",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12707"
  },
  {
    "id": "arXiv:2111.12710",
    "title": "PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers",
    "abstract": "This paper explores a better codebook for BERT pre-training of vision\ntransformers. The recent work BEiT successfully transfers BERT pre-training\nfrom NLP to the vision field. It directly adopts one simple discrete VAE as the\nvisual tokenizer, but has not considered the semantic level of the resulting\nvisual tokens. By contrast, the discrete tokens in NLP field are naturally\nhighly semantic. This difference motivates us to learn a perceptual codebook.\nAnd we surprisingly find one simple yet effective idea: enforcing perceptual\nsimilarity during the dVAE training. We demonstrate that the visual tokens\ngenerated by the proposed perceptual codebook do exhibit better semantic\nmeanings, and subsequently help pre-training achieve superior transfer\nperformance in various downstream tasks. For example, we achieve 84.5 Top-1\naccuracy on ImageNet-1K with ViT-B backbone, outperforming the competitive\nmethod BEiT by +1.3 with the same pre-training epochs. It can also improve the\nperformance of object detection and segmentation tasks on COCO val by +1.3 box\nAP and +1.0 mask AP, semantic segmentation on ADE20k by +1.0 mIoU, The code and\nmodels will be available at \\url{https://github.com/microsoft/PeCo}.",
    "descriptor": "",
    "authors": [
      "Xiaoyi Dong",
      "Jianmin Bao",
      "Ting Zhang",
      "Dongdong Chen",
      "Weiming Zhang",
      "Lu Yuan",
      "Dong Chen",
      "Fang Wen",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12710"
  },
  {
    "id": "arXiv:2111.12138",
    "title": "Multi-Modality Microscopy Image Style Transfer for Nuclei Segmentation",
    "abstract": "Annotating microscopy images for nuclei segmentation is laborious and\ntime-consuming. To leverage the few existing annotations, also across multiple\nmodalities, we propose a novel microscopy-style augmentation technique based on\na generative adversarial network (GAN). Unlike other style transfer methods, it\ncan not only deal with different cell assay types and lighting conditions, but\nalso with different imaging modalities, such as bright-field and fluorescence\nmicroscopy. Using disentangled representations for content and style, we can\npreserve the structure of the original image while altering its style during\naugmentation. We evaluate our data augmentation on the 2018 Data Science Bowl\ndataset consisting of various cell assays, lighting conditions, and imaging\nmodalities. With our style augmentation, the segmentation accuracy of the two\ntop-ranked Mask R-CNN-based nuclei segmentation algorithms in the competition\nincreases significantly. Thus, our augmentation technique renders the\ndownstream task more robust to the test data heterogeneity and helps counteract\nclass imbalance without resampling of minority classes.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ye Liu",
      "Sophia J. Wagner",
      "Tingying Peng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.12138"
  },
  {
    "id": "arXiv:2111.12157",
    "title": "Bayesian Sample Size Prediction for Online Activity",
    "abstract": "In many contexts it is useful to predict the number of individuals in some\npopulation who will initiate a particular activity during a given period. For\nexample, the number of users who will install a software update, the number of\ncustomers who will use a new feature on a website or who will participate in an\nA/B test. In practical settings, there is heterogeneity amongst individuals\nwith regard to the distribution of time until they will initiate. For these\nreasons it is inappropriate to assume that the number of new individuals\nobserved on successive days will be identically distributed. Given observations\non the number of unique users participating in an initial period, we present a\nsimple but novel Bayesian method for predicting the number of additional\nindividuals who will subsequently participate during a subsequent period. We\nillustrate the performance of the method in predicting sample size in online\nexperimentation.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Thomas Richardson",
      "Yu Liu",
      "James McQueen",
      "Doug Hains"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12157"
  },
  {
    "id": "arXiv:2111.12203",
    "title": "KUIELab-MDX-Net: A Two-Stream Neural Network for Music Demixing",
    "abstract": "Recently, many methods based on deep learning have been proposed for music\nsource separation. Some state-of-the-art methods have shown that stacking many\nlayers with many skip connections improve the SDR performance. Although such a\ndeep and complex architecture shows outstanding performance, it usually\nrequires numerous computing resources and time for training and evaluation.\nThis paper proposes a two-stream neural network for music demixing, called\nKUIELab-MDX-Net, which shows a good balance of performance and required\nresources. The proposed model has a time-frequency branch and a time-domain\nbranch, where each branch separates stems, respectively. It blends results from\ntwo streams to generate the final estimation. KUIELab-MDX-Net took second place\non leaderboard A and third place on leaderboard B in the Music Demixing\nChallenge at ISMIR 2021. This paper also summarizes experimental results on\nanother benchmark, MUSDB18. Our source code is available online.",
    "descriptor": "\nComments: MDX Workshop @ ISMIR 2021, 7 pages, 3 figures\n",
    "authors": [
      "Minseok Kim",
      "Woosung Choi",
      "Jaehwa Chung",
      "Daewon Lee",
      "Soonyoung Jung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.12203"
  },
  {
    "id": "arXiv:2111.12215",
    "title": "Explainable multiple abnormality classification of chest CT volumes with  AxialNet and HiResCAM",
    "abstract": "Understanding model predictions is critical in healthcare, to facilitate\nrapid verification of model correctness and to guard against use of models that\nexploit confounding variables. We introduce the challenging new task of\nexplainable multiple abnormality classification in volumetric medical images,\nin which a model must indicate the regions used to predict each abnormality. To\nsolve this task, we propose a multiple instance learning convolutional neural\nnetwork, AxialNet, that allows identification of top slices for each\nabnormality. Next we incorporate HiResCAM, an attention mechanism, to identify\nsub-slice regions. We prove that for AxialNet, HiResCAM explanations are\nguaranteed to reflect the locations the model used, unlike Grad-CAM which\nsometimes highlights irrelevant locations. Armed with a model that produces\nfaithful explanations, we then aim to improve the model's learning through a\nnovel mask loss that leverages HiResCAM and 3D allowed regions to encourage the\nmodel to predict abnormalities based only on the organs in which those\nabnormalities appear. The 3D allowed regions are obtained automatically through\na new approach, PARTITION, that combines location information extracted from\nradiology reports with organ segmentation maps obtained through morphological\nimage processing. Overall, we propose the first model for explainable\nmulti-abnormality prediction in volumetric medical images, and then use the\nmask loss to achieve a 33% improvement in organ localization of multiple\nabnormalities in the RAD-ChestCT data set of 36,316 scans, representing the\nstate of the art. This work advances the clinical applicability of multiple\nabnormality modeling in chest CT volumes.",
    "descriptor": "\nComments: 25 pages, 7 figures, 6 tables\n",
    "authors": [
      "Rachel Lea Draelos",
      "Lawrence Carin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12215"
  },
  {
    "id": "arXiv:2111.12272",
    "title": "Causal Analysis and Prediction of Human Mobility in the U.S. during the  COVID-19 Pandemic",
    "abstract": "Since the increasing outspread of COVID-19 in the U.S., with the highest\nnumber of confirmed cases and deaths in the world as of September 2020, most\nstates in the country have enforced travel restrictions resulting in sharp\nreductions in mobility. However, the overall impact and long-term implications\nof this crisis to travel and mobility remain uncertain. To this end, this study\ndevelops an analytical framework that determines and analyzes the most dominant\nfactors impacting human mobility and travel in the U.S. during this pandemic.\nIn particular, the study uses Granger causality to determine the important\npredictors influencing daily vehicle miles traveled and utilize linear\nregularization algorithms, including Ridge and LASSO techniques, to model and\npredict mobility. State-level time-series data were obtained from various\nopen-access sources for the period starting from March 1, 2020 through June 13,\n2020 and the entire data set was divided into two parts for training and\ntesting purposes. The variables selected by Granger causality were used to\ntrain the three different reduced order models by ordinary least square\nregression, Ridge regression, and LASSO regression algorithms. Finally, the\nprediction accuracy of the developed models was examined on the test data. The\nresults indicate that the factors including the number of new COVID cases,\nsocial distancing index, population staying at home, percent of out of county\ntrips, trips to different destinations, socioeconomic status, percent of people\nworking from home, and statewide closure, among others, were the most important\nfactors influencing daily VMT. Also, among all the modeling techniques, Ridge\nregression provides the most superior performance with the least error, while\nLASSO regression also performed better than the ordinary least square model.",
    "descriptor": "",
    "authors": [
      "Subhrajit Sinha",
      "Meghna Chakraborty"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12272"
  },
  {
    "id": "arXiv:2111.12277",
    "title": "One-shot Voice Conversion For Style Transfer Based On Speaker Adaptation",
    "abstract": "One-shot style transfer is a challenging task, since training on one\nutterance makes model extremely easy to over-fit to training data and causes\nlow speaker similarity and lack of expressiveness. In this paper, we build on\nthe recognition-synthesis framework and propose a one-shot voice conversion\napproach for style transfer based on speaker adaptation. First, a speaker\nnormalization module is adopted to remove speaker-related information in\nbottleneck features extracted by ASR. Second, we adopt weight regularization in\nthe adaptation process to prevent over-fitting caused by using only one\nutterance from target speaker as training data. Finally, to comprehensively\ndecouple the speech factors, i.e., content, speaker, style, and transfer source\nstyle to the target, a prosody module is used to extract prosody\nrepresentation. Experiments show that our approach is superior to the\nstate-of-the-art one-shot VC systems in terms of style and speaker similarity;\nadditionally, our approach also maintains good speech quality.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Zhichao Wang",
      "Qicong Xie",
      "Tao Li",
      "Hongqiang Du",
      "Lei Xie",
      "Pengcheng Zhu",
      "Mengxiao Bi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.12277"
  },
  {
    "id": "arXiv:2111.12312",
    "title": "Lossy Compression of General Random Variables",
    "abstract": "This paper is concerned with the lossy compression of general random\nvariables, specifically with rate-distortion theory and quantization of random\nvariables taking values in general measurable spaces such as, e.g., manifolds\nand fractal sets. Manifold structures are prevalent in data science, e.g., in\ncompressed sensing, machine learning, image processing, and handwritten digit\nrecognition. Fractal sets find application in image compression and in the\nmodeling of Ethernet traffic. Our main contributions are bounds on the\nrate-distortion function and the quantization error. These bounds are very\ngeneral and essentially only require the existence of reference measures\nsatisfying certain regularity conditions in terms of small ball probabilities.\nTo illustrate the wide applicability of our results, we particularize them to\nrandom variables taking values in i) manifolds, namely, hyperspheres and\nGrassmannians, and ii) self-similar sets characterized by iterated function\nsystems satisfying the weak separation property.",
    "descriptor": "",
    "authors": [
      "Erwin Riegler",
      "Helmut B\u00f6lcskei",
      "G\u00fcnther Koliander"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.12312"
  },
  {
    "id": "arXiv:2111.12316",
    "title": "A comment on stabilizing reinforcement learning",
    "abstract": "This is a short comment on the paper \"Asymptotically Stable Adaptive-Optimal\nControl Algorithm With Saturating Actuators and Relaxed Persistence of\nExcitation\" by Vamvoudakis et al. The question of stability of reinforcement\nlearning (RL) agents remains hard and the said work suggested an on-policy\napproach with a suitable stability property using a technique from adaptive\ncontrol - a robustifying term to be added to the action. However, there is an\nissue with this approach to stabilizing RL, which we will explain in this note.\nFurthermore, Vamvoudakis et al. seems to have made a fallacious assumption on\nthe Hamiltonian under a generic policy. To provide a positive result, we will\nnot only indicate this mistake, but show critic neural network weight\nconvergence under a stochastic, continuous-time environment, provided certain\nconditions on the behavior policy hold.",
    "descriptor": "",
    "authors": [
      "Pavel Osinenko",
      "Georgiy Malaniya",
      "Grigory Yaremenko",
      "Ilya Osokin"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.12316"
  },
  {
    "id": "arXiv:2111.12451",
    "title": "Geometrically reduced modelling of pulsatile flow in perivascular  networks",
    "abstract": "Flow of cerebrospinal fluid in perivascular spaces is a key mechanism\nunderlying brain transport and clearance. In this paper, we present a\nmathematical and numerical formalism for reduced models of pulsatile viscous\nfluid flow in networks of generalized annular cylinders. We apply this\nframework to study cerebrospinal fluid flow in perivascular spaces induced by\npressure differences, cardiac pulse wave-induced vascular wall motion and\nvasomotion. The reduced models provide approximations of the cross-section\naverage pressure and cross-section flux, both defined over the topologically\none-dimensional centerlines of the network geometry. Comparing the full and\nreduced model predictions, we find that the reduced models capture pulsatile\nflow characteristics and provide accurate pressure and flux predictions across\nthe range of idealized and image-based scenarios investigated at a fraction of\nthe computational cost of the corresponding full models. The framework\npresented thus provides a robust and effective computational approach for large\nscale in-silico studies of pulsatile perivascular fluid flow and transport.",
    "descriptor": "",
    "authors": [
      "C\u00e9cile Daversin-Catty",
      "Ingeborg G. Gjerde",
      "Marie E. Rognes"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12451"
  },
  {
    "id": "arXiv:2111.12470",
    "title": "Combinatorial Optimization Problems with Balanced Regret",
    "abstract": "For decision making under uncertainty, min-max regret has been established as\na popular methodology to find robust solutions. In this approach, we compare\nthe performance of our solution against the best possible performance had we\nknown the true scenario in advance. We introduce a generalization of this\nsetting which allows us to compare against solutions that are also affected by\nuncertainty, which we call balanced regret. Using budgeted uncertainty sets,\nthis allows for a wider range of possible alternatives the decision maker may\nchoose from. We analyze this approach for general combinatorial problems,\nproviding an iterative solution method and insights into solution properties.\nWe then consider a type of selection problem in more detail and show that,\nwhile the classic regret setting with budgeted uncertainty sets can be solved\nin polynomial time, the balanced regret problem becomes NP-hard. In\ncomputational experiments using random and real-world data, we show that\nbalanced regret solutions provide a useful trade-off for the performance in\nclassic performance measures.",
    "descriptor": "",
    "authors": [
      "Marc Goerigk",
      "Michael Hartisch"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.12470"
  },
  {
    "id": "arXiv:2111.12482",
    "title": "One More Step Towards Reality: Cooperative Bandits with Imperfect  Communication",
    "abstract": "The cooperative bandit problem is increasingly becoming relevant due to its\napplications in large-scale decision-making. However, most research for this\nproblem focuses exclusively on the setting with perfect communication, whereas\nin most real-world distributed settings, communication is often over stochastic\nnetworks, with arbitrary corruptions and delays. In this paper, we study\ncooperative bandit learning under three typical real-world communication\nscenarios, namely, (a) message-passing over stochastic time-varying networks,\n(b) instantaneous reward-sharing over a network with random delays, and (c)\nmessage-passing with adversarially corrupted rewards, including byzantine\ncommunication. For each of these environments, we propose decentralized\nalgorithms that achieve competitive performance, along with near-optimal\nguarantees on the incurred group regret as well. Furthermore, in the setting\nwith perfect communication, we present an improved delayed-update algorithm\nthat outperforms the existing state-of-the-art on various network topologies.\nFinally, we present tight network-dependent minimax lower bounds on the group\nregret. Our proposed algorithms are straightforward to implement and obtain\ncompetitive empirical performance.",
    "descriptor": "",
    "authors": [
      "Udari Madhushani",
      "Abhimanyu Dubey",
      "Naomi Ehrich Leonard",
      "Alex Pentland"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12482"
  },
  {
    "id": "arXiv:2111.12483",
    "title": "LDP-Net: An Unsupervised Pansharpening Network Based on Learnable  Degradation Processes",
    "abstract": "Pansharpening in remote sensing image aims at acquiring a high-resolution\nmultispectral (HRMS) image directly by fusing a low-resolution multispectral\n(LRMS) image with a panchromatic (PAN) image. The main concern is how to\neffectively combine the rich spectral information of LRMS image with the\nabundant spatial information of PAN image. Recently, many methods based on deep\nlearning have been proposed for the pansharpening task. However, these methods\nusually has two main drawbacks: 1) requiring HRMS for supervised learning; and\n2) simply ignoring the latent relation between the MS and PAN image and fusing\nthem directly. To solve these problems, we propose a novel unsupervised network\nbased on learnable degradation processes, dubbed as LDP-Net. A reblurring block\nand a graying block are designed to learn the corresponding degradation\nprocesses, respectively. In addition, a novel hybrid loss function is proposed\nto constrain both spatial and spectral consistency between the pansharpened\nimage and the PAN and LRMS images at different resolutions. Experiments on\nWorldview2 and Worldview3 images demonstrate that our proposed LDP-Net can fuse\nPAN and LRMS images effectively without the help of HRMS samples, achieving\npromising performance in terms of both qualitative visual effects and\nquantitative metrics.",
    "descriptor": "",
    "authors": [
      "Jiahui Ni",
      "Zhimin Shao",
      "Zhongzhou Zhang",
      "Mingzheng Hou",
      "Jiliu Zhou",
      "Leyuan Fang",
      "Yi Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12483"
  },
  {
    "id": "arXiv:2111.12491",
    "title": "Efficient semidefinite bounds for multi-label discrete graphical models",
    "abstract": "By concisely representing a joint function of many variables as the\ncombination of small functions, discrete graphical models (GMs) provide a\npowerful framework to analyze stochastic and deterministic systems of\ninteracting variables. One of the main queries on such models is to identify\nthe extremum of this joint function. This is known as the Weighted Constraint\nSatisfaction Problem (WCSP) on deterministic Cost Function Networks and as\nMaximum a Posteriori (MAP) inference on stochastic Markov Random Fields.\nAlgorithms for approximate WCSP inference typically rely on local consistency\nalgorithms or belief propagation. These methods are intimately related to\nlinear programming (LP) relaxations and often coupled with reparametrizations\ndefined by the dual solution of the associated LP. Since the seminal work of\nGoemans and Williamson, it is well understood that convex SDP relaxations can\nprovide superior guarantees to LP. But the inherent computational cost of\ninterior point methods has limited their application. The situation has\nimproved with the introduction of non-convex Burer-Monteiro style methods which\nare well suited to handle the SDP relaxation of combinatorial problems with\nbinary variables (such as MAXCUT, MaxSAT or MAP/Ising). We compute low rank SDP\nupper and lower bounds for discrete pairwise graphical models with arbitrary\nnumber of values and arbitrary binary cost functions by extending a\nBurer-Monteiro style method based on row-by-row updates. We consider a\ntraditional dualized constraint approach and a dedicated Block Coordinate\nDescent approach which avoids introducing large penalty coefficients to the\nformulation. On increasingly hard and dense WCSP/CFN instances, we observe that\nthe BCD approach can outperform the dualized approach and provide tighter\nbounds than local consistencies/convergent message passing approaches.",
    "descriptor": "",
    "authors": [
      "Valentin Durante",
      "George Katsirelos",
      "Thomas Schiex"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12491"
  },
  {
    "id": "arXiv:2111.12516",
    "title": "LightSAFT: Lightweight Latent Source Aware Frequency Transform for  Source Separation",
    "abstract": "Conditioned source separations have attracted significant attention because\nof their flexibility, applicability and extensionality. Their performance was\nusually inferior to the existing approaches, such as the single source\nseparation model. However, a recently proposed method called LaSAFT-Net has\nshown that conditioned models can show comparable performance against existing\nsingle-source separation models. This paper presents LightSAFT-Net, a\nlightweight version of LaSAFT-Net. As a baseline, it provided a sufficient SDR\nperformance for comparison during the Music Demixing Challenge at ISMIR 2021.\nThis paper also enhances the existing LightSAFT-Net by replacing the LightSAFT\nblocks in the encoder with TFC-TDF blocks. Our enhanced LightSAFT-Net\noutperforms the previous one with fewer parameters.",
    "descriptor": "\nComments: MDX Workshop @ ISMIR 2021, 7 pages, 1 figure\n",
    "authors": [
      "Yeong-Seok Jeong",
      "Jinsung Kim",
      "Woosung Choi",
      "Jaehwa Chung",
      "Soonyoung Jung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.12516"
  },
  {
    "id": "arXiv:2111.12521",
    "title": "Probabilistic Behavioral Distance and Tuning - Reducing and aggregating  complex systems",
    "abstract": "Given a complex system with a given interface to the rest of the world, what\ndoes it mean for a the system to behave close to a simpler specification\ndescribing the behavior at the interface? We give several definitions for\nuseful notions of distances between a complex system and a specification by\ncombining a behavioral and probabilistic perspective. These distances can be\nused to tune a complex system to a specification. We show that our approach can\nsuccessfully tune non-linear networked systems to behave like much smaller\nnetworks, allowing us to aggregate large sub-networks into one or two effective\nnodes. Finally, we discuss similarities and differences between our approach\nand $H_\\infty$ model reduction.",
    "descriptor": "",
    "authors": [
      "Frank Hellmann",
      "Ekaterina Zolotarevskaia",
      "J\u00fcrgen Kurths",
      "J\u00f6rg Raisch"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2111.12521"
  },
  {
    "id": "arXiv:2111.12526",
    "title": "Mining Meta-indicators of University Ranking: A Machine Learning  Approach Based on SHAP",
    "abstract": "University evaluation and ranking is an extremely complex activity. Major\nuniversities are struggling because of increasingly complex indicator systems\nof world university rankings. So can we find the meta-indicators of the index\nsystem by simplifying the complexity? This research discovered three\nmeta-indicators based on interpretable machine learning. The first one is time,\nto be friends with time, and believe in the power of time, and accumulate\nhistorical deposits; the second one is space, to be friends with city, and grow\ntogether by co-develop; the third one is relationships, to be friends with\nalumni, and strive for more alumni donations without ceiling.",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Shudong Yang",
      "Miaomiao Liu"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12526"
  },
  {
    "id": "arXiv:2111.12533",
    "title": "Tight bounds on the expected number of holes in random point sets",
    "abstract": "For integers $d \\geq 2$ and $k \\geq d+1$, a $k$-hole in a set $S$ of points\nin general position in $\\mathbb{R}^d$ is a $k$-tuple of points from $S$ in\nconvex position such that the interior of their convex hull does not contain\nany point from $S$. For a convex body $K \\subseteq \\mathbb{R}^d$ of unit\n$d$-dimensional volume, we study the expected number $EH^K_{d,k}(n)$ of\n$k$-holes in a set of $n$ points drawn uniformly and independently at random\nfrom $K$.\nWe prove an asymptotically tight lower bound on $EH^K_{d,k}(n)$ by showing\nthat, for all fixed integers $d \\geq 2$ and $k\\geq d+1$, the number\n$EH_{d,k}^K(n)$ is at least $\\Omega(n^d)$. For some small holes, we even\ndetermine the leading constant $\\lim_{n \\to \\infty}n^{-d}EH^K_{d,k}(n)$\nexactly. We improve the currently best known lower bound on $\\lim_{n \\to\n\\infty}n^{-d}EH^K_{d,d+1}(n)$ by Reitzner and Temesvari (2019). In the plane,\nwe show that the constant $\\lim_{n \\to \\infty}n^{-2}EH^K_{2,k}(n)$ is\nindependent of $K$ for every fixed $k \\geq 3$ and we compute it exactly for\n$k=4$, improving earlier estimates by Fabila-Monroy, Huemer, and Mitsche (2015)\nand by the authors (2020).",
    "descriptor": "",
    "authors": [
      "Martin Balko",
      "Manfred Scheucher",
      "Pavel Valtr"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.12533"
  },
  {
    "id": "arXiv:2111.12541",
    "title": "Rethinking the modeling of the instrumental response of telescopes with  a differentiable optical model",
    "abstract": "We propose a paradigm shift in the data-driven modeling of the instrumental\nresponse field of telescopes. By adding a differentiable optical forward model\ninto the modeling framework, we change the data-driven modeling space from the\npixels to the wavefront. This allows to transfer a great deal of complexity\nfrom the instrumental response into the forward model while being able to adapt\nto the observations, remaining data-driven. Our framework allows a way forward\nto building powerful models that are physically motivated, interpretable, and\nthat do not require special calibration data. We show that for a simplified\nsetting of a space telescope, this framework represents a real performance\nbreakthrough compared to existing data-driven approaches with reconstruction\nerrors decreasing 5 fold at observation resolution and more than 10 fold for a\n3x super-resolution. We successfully model chromatic variations of the\ninstrument's response only using noisy broad-band in-focus observations.",
    "descriptor": "\nComments: 10 pages. Accepted for the Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021)\n",
    "authors": [
      "Tobias Liaudat",
      "Jean-Luc Starck",
      "Martin Kilbinger",
      "Pierre-Antoine Frugier"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2111.12541"
  },
  {
    "id": "arXiv:2111.12559",
    "title": "Two step clustering for data reduction combining DBSCAN and k-means  clustering",
    "abstract": "A novel combination of two widely-used clustering algorithms is proposed here\nfor the detection and reduction of high data density regions. The Density Based\nSpatial Clustering of Applications with Noise (DBSCAN) algorithm is used for\nthe detection of high data density regions and the k-means algorithm for\nreduction. The proposed algorithm iterates while successively decrementing the\nDBSCAN search radius, allowing for an adaptive reduction factor based on the\neffective data density. The algorithm is demonstrated for a physics simulation\napplication, where a surrogate model for fusion reactor plasma turbulence is\ngenerated with neural networks. A training dataset for the surrogate model is\ncreated with a quasilinear gyrokinetics code for turbulent transport\ncalculations in fusion plasmas. The training set consists of model inputs\nderived from a repository of experimental measurements, meaning there is a\npotential risk of over-representing specific regions of this input parameter\nspace. By applying the proposed reduction algorithm to this dataset, this study\ndemonstrates that the training dataset can be reduced by a factor ~20 using the\nproposed algorithm, without a noticeable loss in the surrogate model accuracy.\nThis reduction provides a novel way of analyzing existing high-dimensional\ndatasets for biases and consequently reducing them, which lowers the cost of\nre-populating that parameter space with higher quality data.",
    "descriptor": "",
    "authors": [
      "Bart J. J. Kremers",
      "Aaron Ho",
      "Jonathan Citrin",
      "Karel L. van de Plassche"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Databases (cs.DB)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.12559"
  },
  {
    "id": "arXiv:2111.12566",
    "title": "Acoustical Analysis of Speech Under Physical Stress in Relation to  Physical Activities and Physical Literacy",
    "abstract": "Human speech production encompasses physiological processes that naturally\nreact to physic stress. Stress caused by physical activity (PA), e.g., running,\nmay lead to significant changes in a person's speech. The major changes are\nrelated to the aspects of pitch level, speaking rate, pause pattern, and\nbreathiness. The extent of change depends presumably on physical fitness and\nwell-being of the person, as well as intensity of PA. The general wellness of a\nperson is further related to his/her physical literacy (PL), which refers to a\nholistic description of engagement in PA. This paper presents the development\nof a Cantonese speech database that contains audio recordings of speech before\nand after physical exercises of different intensity levels. The corpus design\nand data collection process are described. Preliminary results of acoustical\nanalysis are presented to illustrate the impact of PA on pitch level, pitch\nrange, speaking and articulation rate, and time duration of pauses. It is also\nnoted that the effect of PA is correlated to some of the PA and PL measures.",
    "descriptor": "\nComments: Submitted to Speech Prosody 2022\n",
    "authors": [
      "Si-Ioi Ng",
      "Rui-Si Ma",
      "Tan Lee",
      "Raymond Kim-Wai Sum"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.12566"
  },
  {
    "id": "arXiv:2111.12574",
    "title": "Citation method, please? A case study in astrophysics",
    "abstract": "Software citation has accelerated in astrophysics in the past decade,\nresulting in the field now having multiple trackable ways to cite computational\nmethods. Yet most software authors do not specify how they would like their\ncode to be cited, while others specify a citation method that is not easily\ntracked (or tracked at all) by most indexers. Two metadata file formats,\ncodemeta.json and CITATION.cff, developed in 2016 and 2017 respectively, are\nuseful for specifying how software should be cited. In 2020, the Astrophysics\nSource Code Library (ASCL, ascl.net) undertook a year-long effort to generate\nand send these software metadata files, specific to each computational method,\nto code authors for editing and inclusion on their code sites. We wanted to\nanswer the question, \"Would sending these files to software authors increase\nadoption of one, the other, or both of these metadata files?\" The answer in\nthis case was no. Furthermore, only 41% of the 135 code sites examined for use\nof these files had citation information in any form available. The lack of such\ninformation creates an obstacle for article authors to provide credit to\nsoftware creators, thus hindering citation of and recognition for computational\ncontributions to research and the scientists who develop and maintain software.",
    "descriptor": "\nComments: 11 pages, 6 figures, 1 table\n",
    "authors": [
      "Alice Allen"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.12574"
  },
  {
    "id": "arXiv:2111.12641",
    "title": "A Classical Algorithm Which Also Beats  $\\frac{1}{2}+\\frac{2}\u03c0\\frac{1}{\\sqrt{D}}$ For High Girth MAX-CUT",
    "abstract": "We give a simple classical algorithm which provably achieves the performance\nin the title. The algorithm is a simple modification of the Gaussian wave\nprocess.",
    "descriptor": "\nComments: 4 pages, 0 figures\n",
    "authors": [
      "Matthew B. Hastings"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.12641"
  },
  {
    "id": "arXiv:2111.12649",
    "title": "Global Output Feedback Stabilization of Semilinear Reaction-Diffusion  PDEs",
    "abstract": "This paper addresses the topic of global output feedback stabilization of\nsemilinear reaction-diffusion PDEs. The semilinearity is assumed to be confined\ninto a sector condition. We consider two different types of actuation\nconfigurations, namely: bounded control operator and right Robin boundary\ncontrol. The measurement is selected as a left Dirichlet trace. The control\nstrategy is finite dimensional and is designed based on a linear version of the\nplant. We derive a set of sufficient conditions ensuring the global exponential\nstabilization of the semilinear reaction-diffusion PDE. These conditions are\nshown to be feasible provided the order of the controller is large enough and\nthe size of the sector condition in which the semilinearity is confined into is\nsmall enough.",
    "descriptor": "",
    "authors": [
      "Hugo Lhachemi",
      "Christophe Prieur"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.12649"
  },
  {
    "id": "arXiv:2111.12676",
    "title": "Super-polynomial accuracy of one dimensional randomized nets using the  median-of-means",
    "abstract": "Let $f$ be analytic on $[0,1]$ with $|f^{(k)}(1/2)|\\leq A\\alpha^kk!$ for some\nconstant $A$ and $\\alpha<2$. We show that the median estimate of\n$\\mu=\\int_0^1f(x)\\,\\mathrm{d}x$ under random linear scrambling with $n=2^m$\npoints converges at the rate $O(n^{-c\\log(n)})$ for any $c<\n3\\log(2)/\\pi^2\\approx 0.21$. We also get a super-polynomial convergence rate\nfor the sample median of $2k-1$ random linearly scrambled estimates, when\n$k=\\Omega(m)$. When $f$ has a $p$'th derivative that satisfies a\n$\\lambda$-H\\\"older condition then the median-of-means has error $O(\nn^{-(p+\\lambda)+\\epsilon})$ for any $\\epsilon>0$, if $k\\to\\infty$ as\n$m\\to\\infty$.",
    "descriptor": "",
    "authors": [
      "Zexin Pan",
      "Art B. Owen"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.12676"
  },
  {
    "id": "arXiv:2111.12683",
    "title": "Data-Based Models for Hurricane Evolution Prediction: A Deep Learning  Approach",
    "abstract": "Fast and accurate prediction of hurricane evolution from genesis onwards is\nneeded to reduce loss of life and enhance community resilience. In this work, a\nnovel model development methodology for predicting storm trajectory is proposed\nbased on two classes of Recurrent Neural Networks (RNNs). The RNN models are\ntrained on input features available in or derived from the HURDAT2 North\nAtlantic hurricane database maintained by the National Hurricane Center (NHC).\nThe models use probabilities of storms passing through any location, computed\nfrom historical data. A detailed analysis of model forecasting error shows that\nMany-To-One prediction models are less accurate than Many-To-Many models owing\nto compounded error accumulation, with the exception of $6-hr$ predictions, for\nwhich the two types of model perform comparably. Application to 75 or more test\nstorms in the North Atlantic basin showed that, for short-term forecasting up\nto 12 hours, the Many-to-Many RNN storm trajectory prediction models presented\nherein are significantly faster than ensemble models used by the NHC, while\nleading to errors of comparable magnitude.",
    "descriptor": "",
    "authors": [
      "Rikhi Bose",
      "Adam Pintar",
      "Emil Simiu"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.12683"
  },
  {
    "id": "arXiv:1607.03943",
    "title": "Generalized hybrid iterative methods for large-scale Bayesian inverse  problems",
    "abstract": "Generalized hybrid iterative methods for large-scale Bayesian inverse  problems",
    "descriptor": "",
    "authors": [
      "Julianne Chung",
      "Arvind K. Saibaba"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1607.03943"
  },
  {
    "id": "arXiv:1612.05924",
    "title": "Asymmetric Hat Game with three players and three colors",
    "abstract": "Comments: it is now part of arXiv:1612.00276 (Ebert's asymmetric Hat Game)",
    "descriptor": "\nComments: it is now part of arXiv:1612.00276 (Ebert's asymmetric Hat Game)\n",
    "authors": [
      "Theo van Uem"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1612.05924"
  },
  {
    "id": "arXiv:1704.04244",
    "title": "General three person two color Hat Game",
    "abstract": "Comments: it is now part of arXiv:1612.00276 (Ebert's asymmetric Hat Game)",
    "descriptor": "\nComments: it is now part of arXiv:1612.00276 (Ebert's asymmetric Hat Game)\n",
    "authors": [
      "Theo van Uem"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1704.04244"
  },
  {
    "id": "arXiv:1802.00938",
    "title": "DeepProcess: Supporting business process execution using a MANN-based  recommender system",
    "abstract": "Comments: Accepted at ICSOC 2021",
    "descriptor": "\nComments: Accepted at ICSOC 2021\n",
    "authors": [
      "Asjad Khan",
      "Hung Le",
      "Kien Do",
      "Truyen Tran",
      "Aditya Ghose",
      "Hoa Dam",
      "Renuka Sindhgatta"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1802.00938"
  },
  {
    "id": "arXiv:1807.07686",
    "title": "Exact minimum number of bits to stabilize a linear system",
    "abstract": "Comments: Extended version of the paper accepted to IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: Extended version of the paper accepted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Victoria Kostina",
      "Yuval Peres",
      "Gireeja Ranade",
      "Mark Sellke"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1807.07686"
  },
  {
    "id": "arXiv:1904.12218",
    "title": "Graph Kernels: A Survey",
    "abstract": "Graph Kernels: A Survey",
    "descriptor": "",
    "authors": [
      "Giannis Nikolentzos",
      "Giannis Siglidis",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1904.12218"
  },
  {
    "id": "arXiv:1905.11968",
    "title": "Chasing Convex Bodies Optimally",
    "abstract": "Chasing Convex Bodies Optimally",
    "descriptor": "",
    "authors": [
      "Mark Sellke"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/1905.11968"
  },
  {
    "id": "arXiv:1907.02064",
    "title": "Accelerator-level Parallelism",
    "abstract": "Comments: 6 pages, 3 figures, & 7 references",
    "descriptor": "\nComments: 6 pages, 3 figures, & 7 references\n",
    "authors": [
      "Mark D. Hill",
      "Vijay Janapa Reddi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Operating Systems (cs.OS)",
      "Performance (cs.PF)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1907.02064"
  },
  {
    "id": "arXiv:1909.00426",
    "title": "Global Entity Disambiguation with Pretrained Contextualized Embeddings  of Words and Entities",
    "abstract": "Global Entity Disambiguation with Pretrained Contextualized Embeddings  of Words and Entities",
    "descriptor": "",
    "authors": [
      "Ikuya Yamada",
      "Koki Washio",
      "Hiroyuki Shindo",
      "Yuji Matsumoto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1909.00426"
  },
  {
    "id": "arXiv:1910.02534",
    "title": "The CEO problem with inter-block memory",
    "abstract": "The CEO problem with inter-block memory",
    "descriptor": "",
    "authors": [
      "Victoria Kostina",
      "Babak Hassibi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1910.02534"
  },
  {
    "id": "arXiv:1911.06442",
    "title": "Weak Monotone Comparative Statics",
    "abstract": "Weak Monotone Comparative Statics",
    "descriptor": "",
    "authors": [
      "Yeon-Koo Che",
      "Jinwoo Kim",
      "Fuhito Kojima"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1911.06442"
  },
  {
    "id": "arXiv:2001.04194",
    "title": "Cascaded Coded Distributed Computing Schemes Based on Placement Delivery  Arrays",
    "abstract": "Cascaded Coded Distributed Computing Schemes Based on Placement Delivery  Arrays",
    "descriptor": "",
    "authors": [
      "Jing Jiang",
      "Lingxiao Qu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2001.04194"
  },
  {
    "id": "arXiv:2002.09827",
    "title": "A Formal Treatment of Contract Signature",
    "abstract": "Comments: This paper has been accepted to IEEE Transactions on Services Computing. Revisions to the previous version include expanded material on smart contracts in Section 9",
    "descriptor": "\nComments: This paper has been accepted to IEEE Transactions on Services Computing. Revisions to the previous version include expanded material on smart contracts in Section 9\n",
    "authors": [
      "Ron van der Meyden"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2002.09827"
  },
  {
    "id": "arXiv:2003.04175",
    "title": "Phase Transition Analysis for Covariance Based Massive Random Access  with Massive MIMO",
    "abstract": "Comments: Accepted in IEEE Transactions on Information Theory",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Information Theory\n",
    "authors": [
      "Zhilin Chen",
      "Foad Sohrabi",
      "Ya-Feng Liu",
      "Wei Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2003.04175"
  },
  {
    "id": "arXiv:2004.09963",
    "title": "Structural clustering of volatility regimes for dynamic trading  strategies",
    "abstract": "Comments: Accepted manuscript",
    "descriptor": "\nComments: Accepted manuscript\n",
    "authors": [
      "Arjun Prakash",
      "Nick James",
      "Max Menzies",
      "Gilad Francis"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2004.09963"
  },
  {
    "id": "arXiv:2006.10679",
    "title": "REGroup: Rank-aggregating Ensemble of Generative Classifiers for Robust  Predictions",
    "abstract": "Comments: WACV,2022. Project Page : this https URL",
    "descriptor": "\nComments: WACV,2022. Project Page : this https URL\n",
    "authors": [
      "Lokender Tiwari",
      "Anish Madan",
      "Saket Anand",
      "Subhashis Banerjee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10679"
  },
  {
    "id": "arXiv:2007.04171",
    "title": "Domain Adaptation with Auxiliary Target Domain-Oriented Classifier",
    "abstract": "Comments: Fix typos after CVPR 2021. Code is available at this https URL",
    "descriptor": "\nComments: Fix typos after CVPR 2021. Code is available at this https URL\n",
    "authors": [
      "Jian Liang",
      "Dapeng Hu",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.04171"
  },
  {
    "id": "arXiv:2007.05046",
    "title": "RulePad: Interactive Authoring of Checkable Design Rules",
    "abstract": "RulePad: Interactive Authoring of Checkable Design Rules",
    "descriptor": "",
    "authors": [
      "Sahar Mehrpour",
      "Thomas D. LaToza",
      "Hamed Sarvari"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2007.05046"
  },
  {
    "id": "arXiv:2007.06226",
    "title": "AMITE: A Novel Polynomial Expansion for Analyzing Neural Network  Nonlinearities",
    "abstract": "Comments: 13 pages, 2 tables, 9 figures, LaTeX; minor grammar updates, equation numbering, and exposition clarification updates",
    "descriptor": "\nComments: 13 pages, 2 tables, 9 figures, LaTeX; minor grammar updates, equation numbering, and exposition clarification updates\n",
    "authors": [
      "Mauro J. Sanchirico III",
      "Xun Jiao",
      "C. Nataraj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.06226"
  },
  {
    "id": "arXiv:2009.01826",
    "title": "A Python Library for Exploratory Data Analysis on Twitter Data based on  Tokens and Aggregated Origin-Destination Information",
    "abstract": "A Python Library for Exploratory Data Analysis on Twitter Data based on  Tokens and Aggregated Origin-Destination Information",
    "descriptor": "",
    "authors": [
      "Mario Graff",
      "Daniela Moctezuma",
      "Sabino Miranda-Jim\u00e9nez",
      "Eric S. Tellez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.01826"
  },
  {
    "id": "arXiv:2009.09379",
    "title": "Exploring the Generalizability of Spatio-Temporal Crowd Flow Prediction:  Meta-Modeling and an Analytic Framework",
    "abstract": "Exploring the Generalizability of Spatio-Temporal Crowd Flow Prediction:  Meta-Modeling and an Analytic Framework",
    "descriptor": "",
    "authors": [
      "Leye Wang",
      "Di Chai",
      "Xuanzhe Liu",
      "Liyue Chen",
      "Kai Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.09379"
  },
  {
    "id": "arXiv:2009.09525",
    "title": "Deep Autoencoders: From Understanding to Generalization Guarantees",
    "abstract": "Deep Autoencoders: From Understanding to Generalization Guarantees",
    "descriptor": "",
    "authors": [
      "Romain Cosentino",
      "Randall Balestriero",
      "Richard Baraniuk",
      "Behnaam Aazhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Group Theory (math.GR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.09525"
  },
  {
    "id": "arXiv:2010.01184",
    "title": "Effective Sample Size, Dimensionality, and Generalization in Covariate  Shift Adaptation",
    "abstract": "Effective Sample Size, Dimensionality, and Generalization in Covariate  Shift Adaptation",
    "descriptor": "",
    "authors": [
      "Felipe Maia Polo",
      "Renato Vicente"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2010.01184"
  },
  {
    "id": "arXiv:2010.09145",
    "title": "MROS: Runtime Adaptation For Robot Control Architectures",
    "abstract": "MROS: Runtime Adaptation For Robot Control Architectures",
    "descriptor": "",
    "authors": [
      "Darko Bozhinoski",
      "Carlos Hernandez Corbato",
      "Mario Garzon Oviedo",
      "Gijs van der Hoorn",
      "Nadia Hammoudeh Garcia",
      "Harshavardhan Deshpande",
      "Jon Tjerngren",
      "Andrzej Wasowski"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2010.09145"
  },
  {
    "id": "arXiv:2010.11625",
    "title": "One-shot Distributed Algorithm for Generalized Eigenvalue Problem",
    "abstract": "Comments: The derivation of the bound in the proof of Theorem 1 contains some errors. And it cannot be resolved at this time.",
    "descriptor": "\nComments: The derivation of the bound in the proof of Theorem 1 contains some errors. And it cannot be resolved at this time.\n",
    "authors": [
      "Kexin Lv",
      "Fan He",
      "Xiaolin Huang",
      "Jie Yang",
      "Liming Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.11625"
  },
  {
    "id": "arXiv:2010.15764",
    "title": "Domain adaptation under structural causal models",
    "abstract": "Comments: 80 pages, 22 figures, accepted in JMLR",
    "descriptor": "\nComments: 80 pages, 22 figures, accepted in JMLR\n",
    "authors": [
      "Yuansi Chen",
      "Peter B\u00fchlmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2010.15764"
  },
  {
    "id": "arXiv:2011.04138",
    "title": "Posture Adjustment for a Wheel-legged Robotic System via Leg Force  Control with Prescribed Transient Performance",
    "abstract": "Posture Adjustment for a Wheel-legged Robotic System via Leg Force  Control with Prescribed Transient Performance",
    "descriptor": "",
    "authors": [
      "Dongchen Liu",
      "Junzheng Wang",
      "Shoukun Wang",
      "Dawei Shi",
      "Huaihang Zheng",
      "Yuan Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.04138"
  },
  {
    "id": "arXiv:2011.09468",
    "title": "Gradient Starvation: A Learning Proclivity in Neural Networks",
    "abstract": "Comments: Proceeding of NeurIPS 2021",
    "descriptor": "\nComments: Proceeding of NeurIPS 2021\n",
    "authors": [
      "Mohammad Pezeshki",
      "S\u00e9kou-Oumar Kaba",
      "Yoshua Bengio",
      "Aaron Courville",
      "Doina Precup",
      "Guillaume Lajoie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.09468"
  },
  {
    "id": "arXiv:2011.14814",
    "title": "Cost Function Unrolling in Unsupervised Optical Flow",
    "abstract": "Cost Function Unrolling in Unsupervised Optical Flow",
    "descriptor": "",
    "authors": [
      "Gal Lifshitz",
      "Dan Raviv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.14814"
  },
  {
    "id": "arXiv:2012.00968",
    "title": "Reconfigurable Intelligent Surfaces in Action for Non-Terrestrial  Networks",
    "abstract": "Comments: 7 pages, 6 figures",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "K\u00fcr\u015fat Tekb\u0131y\u0131k",
      "G\u00fcne\u015f Karabulut Kurt",
      "Ali R\u0131za Ekti",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2012.00968"
  },
  {
    "id": "arXiv:2012.04515",
    "title": "Digital Gimbal: End-to-end Deep Image Stabilization with Learnable  Exposure Times",
    "abstract": "Comments: CVPR 2021",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Omer Dahary",
      "Matan Jacoby",
      "Alex M. Bronstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2012.04515"
  },
  {
    "id": "arXiv:2012.04946",
    "title": "Generating semantic maps through multidimensional scaling: linguistic  applications and theory",
    "abstract": "Comments: 40 pages; pre-print; accepted for publication in Corpus Linguistics & Linguistic Theory (Nov. 2021)",
    "descriptor": "\nComments: 40 pages; pre-print; accepted for publication in Corpus Linguistics & Linguistic Theory (Nov. 2021)\n",
    "authors": [
      "Martijn van der Klis",
      "Jos Tellings"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.04946"
  },
  {
    "id": "arXiv:2012.08729",
    "title": "Data Trading with a Monopoly Social Network: Outcomes are Mostly Privacy  Welfare Damaging",
    "abstract": "Comments: incrementally updated version to version in IEEE Networking Letters; This work is based upon results in NBER w26296",
    "descriptor": "\nComments: incrementally updated version to version in IEEE Networking Letters; This work is based upon results in NBER w26296\n",
    "authors": [
      "Ranjan Pal",
      "Junhui Li",
      "Yixuan Wang",
      "Mingyan Liu",
      "Swades De",
      "Jon Crowcroft"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2012.08729"
  },
  {
    "id": "arXiv:2012.12468",
    "title": "CN-Celeb: multi-genre speaker recognition",
    "abstract": "Comments: submitted to Speech Communication",
    "descriptor": "\nComments: submitted to Speech Communication\n",
    "authors": [
      "Lantian Li",
      "Ruiqi Liu",
      "Jiawen Kang",
      "Yue Fan",
      "Hao Cui",
      "Yunqi Cai",
      "Ravichander Vipperla",
      "Thomas Fang Zheng",
      "Dong Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2012.12468"
  },
  {
    "id": "arXiv:2012.12471",
    "title": "A Principle Solution for Enroll-Test Mismatch in Speaker Recognition",
    "abstract": "A Principle Solution for Enroll-Test Mismatch in Speaker Recognition",
    "descriptor": "",
    "authors": [
      "Lantian Li",
      "Dong Wang",
      "Jiawen Kang",
      "Renyu Wang",
      "Jing Wu",
      "Zhendong Gao",
      "Xiao Chen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2012.12471"
  },
  {
    "id": "arXiv:2012.13806",
    "title": "Time-Fluid Field-Based Coordination through Programmable Distributed  Schedulers",
    "abstract": "Time-Fluid Field-Based Coordination through Programmable Distributed  Schedulers",
    "descriptor": "",
    "authors": [
      "Danilo Pianini",
      "Roberto Casadei",
      "Mirko Viroli",
      "Stefano Mariani",
      "Franco Zambonelli"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2012.13806"
  },
  {
    "id": "arXiv:2012.15197",
    "title": "SemGloVe: Semantic Co-occurrences for GloVe from BERT",
    "abstract": "Comments: 10 pages, 3 figures, 5 tables",
    "descriptor": "\nComments: 10 pages, 3 figures, 5 tables\n",
    "authors": [
      "Leilei Gan",
      "Zhiyang Teng",
      "Yue Zhang",
      "Linchao Zhu",
      "Fei Wu",
      "Yi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.15197"
  },
  {
    "id": "arXiv:2101.00304",
    "title": "Interval Type-2 Enhanced Possibilistic Fuzzy C-Means Clustering for Gene  Expression Data Analysis",
    "abstract": "Interval Type-2 Enhanced Possibilistic Fuzzy C-Means Clustering for Gene  Expression Data Analysis",
    "descriptor": "",
    "authors": [
      "Shahabeddin Sotudian",
      "Mohammad Hossein Fazel Zarandi"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.00304"
  },
  {
    "id": "arXiv:2101.03329",
    "title": "Coupling a generative model with a discriminative learning framework for  speaker verification",
    "abstract": "Coupling a generative model with a discriminative learning framework for  speaker verification",
    "descriptor": "",
    "authors": [
      "Xugang Lu",
      "Peng Shen",
      "Yu Tsao",
      "Hisashi Kawai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2101.03329"
  },
  {
    "id": "arXiv:2101.11529",
    "title": "NTU-X: An Enhanced Large-scale Dataset for Improving Pose-based  Recognition of Subtle Human Actions",
    "abstract": "Comments: First two authors contributed equally. Code repository at this https URL",
    "descriptor": "\nComments: First two authors contributed equally. Code repository at this https URL\n",
    "authors": [
      "Neel Trivedi",
      "Anirudh Thatipelli",
      "Ravi Kiran Sarvadevabhatla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2101.11529"
  },
  {
    "id": "arXiv:2101.11948",
    "title": "Choice modelling in the age of machine learning - discussion paper",
    "abstract": "Comments: 40 pages, 2 tables, 0 figures",
    "descriptor": "\nComments: 40 pages, 2 tables, 0 figures\n",
    "authors": [
      "S. Van Cranenburgh",
      "S. Wang",
      "A. Vij",
      "F. Pereira",
      "J. Walker"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.11948"
  },
  {
    "id": "arXiv:2102.03906",
    "title": "Causal versions of Maximum Entropy and Principle of Insufficient Reason",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Dominik Janzing"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.03906"
  },
  {
    "id": "arXiv:2102.04525",
    "title": "Unified Focal loss: Generalising Dice and cross entropy-based losses to  handle class imbalanced medical image segmentation",
    "abstract": "Unified Focal loss: Generalising Dice and cross entropy-based losses to  handle class imbalanced medical image segmentation",
    "descriptor": "",
    "authors": [
      "Michael Yeung",
      "Evis Sala",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Leonardo Rundo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.04525"
  },
  {
    "id": "arXiv:2102.06462",
    "title": "Two Sides of the Same Coin: Heterophily and Oversmoothing in Graph  Convolutional Neural Networks",
    "abstract": "Comments: Including 15 page supplement",
    "descriptor": "\nComments: Including 15 page supplement\n",
    "authors": [
      "Yujun Yan",
      "Milad Hashemi",
      "Kevin Swersky",
      "Yaoqing Yang",
      "Danai Koutra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06462"
  },
  {
    "id": "arXiv:2102.08098",
    "title": "GradInit: Learning to Initialize Neural Networks for Stable and  Efficient Training",
    "abstract": "Comments: NeurIPS 2021, fixing typos",
    "descriptor": "\nComments: NeurIPS 2021, fixing typos\n",
    "authors": [
      "Chen Zhu",
      "Renkun Ni",
      "Zheng Xu",
      "Kezhi Kong",
      "W. Ronny Huang",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.08098"
  },
  {
    "id": "arXiv:2102.09159",
    "title": "Robust and Differentially Private Mean Estimation",
    "abstract": "Comments: 58 pages, 2 figures, both exponential time and efficient algorithms no longer require a known bound on the true mean",
    "descriptor": "\nComments: 58 pages, 2 figures, both exponential time and efficient algorithms no longer require a known bound on the true mean\n",
    "authors": [
      "Xiyang Liu",
      "Weihao Kong",
      "Sham Kakade",
      "Sewoong Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09159"
  },
  {
    "id": "arXiv:2102.09788",
    "title": "Sequential- and Parallel- Constrained Max-value Entropy Search via  Information Lower Bound",
    "abstract": "Comments: 39pages, 10 figures",
    "descriptor": "\nComments: 39pages, 10 figures\n",
    "authors": [
      "Shion Takeno",
      "Tomoyuki Tamura",
      "Kazuki Shitara",
      "Masayuki Karasuyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09788"
  },
  {
    "id": "arXiv:2103.00782",
    "title": "Sparse Activity Detection in Multi-Cell Massive MIMO Exploiting Channel  Large-Scale Fading",
    "abstract": "Comments: This is the final version published in IEEE Transactions on Signal Processing",
    "descriptor": "\nComments: This is the final version published in IEEE Transactions on Signal Processing\n",
    "authors": [
      "Zhilin Chen",
      "Foad Sohrabi",
      "Wei Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.00782"
  },
  {
    "id": "arXiv:2103.02434",
    "title": "5G New Radio for Public Safety Mission Critical Communications",
    "abstract": "Comments: 8 pages, 5 figures, 1 table, Accepted by IEEE Communications Standards Magazine",
    "descriptor": "\nComments: 8 pages, 5 figures, 1 table, Accepted by IEEE Communications Standards Magazine\n",
    "authors": [
      "Jingya Li",
      "Keerthi Kumar Nagalapur",
      "Erik Stare",
      "Satyam Dwivedi",
      "Shehzad Ali Ashraf",
      "Per-Erik Eriksson",
      "Ulrika Engstr\u00f6m",
      "Woong-Hee Lee",
      "Thorsten Lohmar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2103.02434"
  },
  {
    "id": "arXiv:2103.06342",
    "title": "Continual Semantic Segmentation via Repulsion-Attraction of Sparse and  Disentangled Latent Representations",
    "abstract": "Comments: CVPR 2021. 22 pages, 10 figures, 11 tables",
    "descriptor": "\nComments: CVPR 2021. 22 pages, 10 figures, 11 tables\n",
    "authors": [
      "Umberto Michieli",
      "Pietro Zanuttigh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2103.06342"
  },
  {
    "id": "arXiv:2103.13581",
    "title": "EfficientTDNN: Efficient Architecture Search for Speaker Recognition",
    "abstract": "Comments: 13 pages, 12 figures, submitted to TASLP",
    "descriptor": "\nComments: 13 pages, 12 figures, submitted to TASLP\n",
    "authors": [
      "Rui Wang",
      "Zhihua Wei",
      "Haoran Duan",
      "Shouling Ji",
      "Yang Long",
      "Zhen Hong"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.13581"
  },
  {
    "id": "arXiv:2103.14799",
    "title": "A Survey of Orthogonal Moments for Image Representation: Theory,  Implementation, and Evaluation",
    "abstract": "Comments: ACM Computing Surveys, Volume 55, Issue 1, January 2023, Article No 1, pp 1-35, this https URL",
    "descriptor": "\nComments: ACM Computing Surveys, Volume 55, Issue 1, January 2023, Article No 1, pp 1-35, this https URL\n",
    "authors": [
      "Shuren Qi",
      "Yushu Zhang",
      "Chao Wang",
      "Jiantao Zhou",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14799"
  },
  {
    "id": "arXiv:2104.06219",
    "title": "UAV-ReID: A Benchmark on Unmanned Aerial Vehicle Re-identification",
    "abstract": "UAV-ReID: A Benchmark on Unmanned Aerial Vehicle Re-identification",
    "descriptor": "",
    "authors": [
      "Daniel Organisciak",
      "Matthew Poyser",
      "Aishah Alsehaim",
      "Shanfeng Hu",
      "Brian K. S. Isaac-Medina",
      "Toby P. Breckon",
      "Hubert P. H. Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.06219"
  },
  {
    "id": "arXiv:2104.08013",
    "title": "Data-Driven 3D Reconstruction of Dressed Humans From Sparse Views",
    "abstract": "Comments: 3DV 2021",
    "descriptor": "\nComments: 3DV 2021\n",
    "authors": [
      "Pierre Zins",
      "Yuanlu Xu",
      "Edmond Boyer",
      "Stefanie Wuhrer",
      "Tony Tung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08013"
  },
  {
    "id": "arXiv:2105.05364",
    "title": "A Hermite Method with a Discontinuity Sensor for Hamilton-Jacobi  Equations",
    "abstract": "A Hermite Method with a Discontinuity Sensor for Hamilton-Jacobi  Equations",
    "descriptor": "",
    "authors": [
      "Allen Alvarez Loya",
      "Daniel Appel\u00f6"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.05364"
  },
  {
    "id": "arXiv:2105.05458",
    "title": "Distributionally Robust Graph Learning from Smooth Signals under Moment  Uncertainty",
    "abstract": "Distributionally Robust Graph Learning from Smooth Signals under Moment  Uncertainty",
    "descriptor": "",
    "authors": [
      "Xiaolu Wang",
      "Yuen-Man Pun",
      "Anthony Man-Cho So"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.05458"
  },
  {
    "id": "arXiv:2105.05801",
    "title": "SoK: Practical Foundations for Software Spectre Defenses",
    "abstract": "SoK: Practical Foundations for Software Spectre Defenses",
    "descriptor": "",
    "authors": [
      "Sunjay Cauligi",
      "Craig Disselkoen",
      "Daniel Moghimi",
      "Gilles Barthe",
      "Deian Stefan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.05801"
  },
  {
    "id": "arXiv:2105.08291",
    "title": "Independent Asymmetric Embedding for Cascade Prediction on Social  Networks",
    "abstract": "Independent Asymmetric Embedding for Cascade Prediction on Social  Networks",
    "descriptor": "",
    "authors": [
      "Wenjin Xie",
      "Xiaomeng Wang",
      "Tao Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.08291"
  },
  {
    "id": "arXiv:2105.10362",
    "title": "Functionals in the Clouds: An abstract architecture of serverless  Cloud-Native Apps",
    "abstract": "Comments: improved version submitted to CCGrid_2022",
    "descriptor": "\nComments: improved version submitted to CCGrid_2022\n",
    "authors": [
      "Stanislaw Ambroszkiewicz",
      "Waldemar Bartyna",
      "Stanislaw Bylka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.10362"
  },
  {
    "id": "arXiv:2105.10598",
    "title": "Embracing New Techniques in Deep Learning for Estimating Image  Memorability",
    "abstract": "Comments: 27 pages, 15 figures, Presented at the Proceedings of the Vision Sciences Society 2021",
    "descriptor": "\nComments: 27 pages, 15 figures, Presented at the Proceedings of the Vision Sciences Society 2021\n",
    "authors": [
      "Coen D. Needell",
      "Wilma A. Bainbridge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10598"
  },
  {
    "id": "arXiv:2105.13889",
    "title": "Equilibrium and non-Equilibrium regimes in the learning of Restricted  Boltzmann Machines",
    "abstract": "Comments: 12 page, 4 figures. accepted to Neurips 2021 Supplementary Material",
    "descriptor": "\nComments: 12 page, 4 figures. accepted to Neurips 2021 Supplementary Material\n",
    "authors": [
      "Aur\u00e9lien Decelle",
      "Cyril Furtlehner",
      "Beatriz Seoane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2105.13889"
  },
  {
    "id": "arXiv:2105.14024",
    "title": "Near-Optimal Multi-Perturbation Experimental Design for Causal Structure  Learning",
    "abstract": "Comments: 10 pages, 2 figures, appendix, to be published in 35th Conference on Neural Information Processing Systems (NeurIPS 2021), fixed typos and clarified wording",
    "descriptor": "\nComments: 10 pages, 2 figures, appendix, to be published in 35th Conference on Neural Information Processing Systems (NeurIPS 2021), fixed typos and clarified wording\n",
    "authors": [
      "Scott Sussex",
      "Andreas Krause",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14024"
  },
  {
    "id": "arXiv:2106.00058",
    "title": "PUDLE: Implicit Acceleration of Dictionary Learning by Backpropagation",
    "abstract": "PUDLE: Implicit Acceleration of Dictionary Learning by Backpropagation",
    "descriptor": "",
    "authors": [
      "Bahareh Tolooshams",
      "Demba Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00058"
  },
  {
    "id": "arXiv:2106.03719",
    "title": "Incremental False Negative Detection for Contrastive Learning",
    "abstract": "Incremental False Negative Detection for Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Tsai-Shien Chen",
      "Wei-Chih Hung",
      "Hung-Yu Tseng",
      "Shao-Yi Chien",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03719"
  },
  {
    "id": "arXiv:2106.03969",
    "title": "Chow-Liu++: Optimal Prediction-Centric Learning of Tree Ising Models",
    "abstract": "Comments: 49 pages, 3 figures, to appear in FOCS'21",
    "descriptor": "\nComments: 49 pages, 3 figures, to appear in FOCS'21\n",
    "authors": [
      "Enric Boix-Adsera",
      "Guy Bresler",
      "Frederic Koehler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.03969"
  },
  {
    "id": "arXiv:2106.04284",
    "title": "LLAMA: The Low-Level Abstraction For Memory Access",
    "abstract": "Comments: 40 pages, 10 figures, 11 listings",
    "descriptor": "\nComments: 40 pages, 10 figures, 11 listings\n",
    "authors": [
      "Bernhard Manfred Gruber",
      "Guilherme Amadio",
      "Jakob Blomer",
      "Alexander Matthes",
      "Ren\u00e9 Widera",
      "Michael Bussmann"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2106.04284"
  },
  {
    "id": "arXiv:2106.05234",
    "title": "Do Transformers Really Perform Bad for Graph Representation?",
    "abstract": "Do Transformers Really Perform Bad for Graph Representation?",
    "descriptor": "",
    "authors": [
      "Chengxuan Ying",
      "Tianle Cai",
      "Shengjie Luo",
      "Shuxin Zheng",
      "Guolin Ke",
      "Di He",
      "Yanming Shen",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05234"
  },
  {
    "id": "arXiv:2106.06935",
    "title": "Neural Bellman-Ford Networks: A General Graph Neural Network Framework  for Link Prediction",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Zhaocheng Zhu",
      "Zuobai Zhang",
      "Louis-Pascal Xhonneux",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06935"
  },
  {
    "id": "arXiv:2106.08827",
    "title": "JRDB-Act: A Large-scale Dataset for Spatio-temporal Action, Social Group  and Activity Detection",
    "abstract": "JRDB-Act: A Large-scale Dataset for Spatio-temporal Action, Social Group  and Activity Detection",
    "descriptor": "",
    "authors": [
      "Mahsa Ehsanpour",
      "Fatemeh Saleh",
      "Silvio Savarese",
      "Ian Reid",
      "Hamid Rezatofighi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08827"
  },
  {
    "id": "arXiv:2106.10717",
    "title": "Strategies for convex potential games and an application to  decision-theoretic online learning",
    "abstract": "Strategies for convex potential games and an application to  decision-theoretic online learning",
    "descriptor": "",
    "authors": [
      "Yoav Freund"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10717"
  },
  {
    "id": "arXiv:2106.10933",
    "title": "Semi-uniform Input-to-state Stability of Infinite-dimensional Systems",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Masashi Wakaiki"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10933"
  },
  {
    "id": "arXiv:2106.14020",
    "title": "An Improved Physical ZKP for Nonogram",
    "abstract": "Comments: This paper has appeared at COCOA 2021",
    "descriptor": "\nComments: This paper has appeared at COCOA 2021\n",
    "authors": [
      "Suthee Ruangwises"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.14020"
  },
  {
    "id": "arXiv:2106.14472",
    "title": "Hyperbolic Busemann Learning with Ideal Prototypes",
    "abstract": "Comments: accepted at NeurIPS 2021 (35th Conference on Neural Information Processing Systems)",
    "descriptor": "\nComments: accepted at NeurIPS 2021 (35th Conference on Neural Information Processing Systems)\n",
    "authors": [
      "Mina Ghadimi Atigh",
      "Martin Keller-Ressel",
      "Pascal Mettes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.14472"
  },
  {
    "id": "arXiv:2106.15715",
    "title": "No Calm in The Storm: Investigating QAnon Website Relationships",
    "abstract": "No Calm in The Storm: Investigating QAnon Website Relationships",
    "descriptor": "",
    "authors": [
      "Hans W. A. Hanley",
      "Deepak Kumar",
      "Zakir Durumeric"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.15715"
  },
  {
    "id": "arXiv:2107.07653",
    "title": "TAPEX: Table Pre-training via Learning a Neural SQL Executor",
    "abstract": "Comments: Work in progress, the project homepage is at this https URL, the code is released at this https URL",
    "descriptor": "\nComments: Work in progress, the project homepage is at this https URL, the code is released at this https URL\n",
    "authors": [
      "Qian Liu",
      "Bei Chen",
      "Jiaqi Guo",
      "Morteza Ziyadi",
      "Zeqi Lin",
      "Weizhu Chen",
      "Jian-Guang Lou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07653"
  },
  {
    "id": "arXiv:2107.09507",
    "title": "EEG-based Cross-Subject Driver Drowsiness Recognition with an  Interpretable Convolutional Neural Network",
    "abstract": "EEG-based Cross-Subject Driver Drowsiness Recognition with an  Interpretable Convolutional Neural Network",
    "descriptor": "",
    "authors": [
      "Jian Cui",
      "Zirui Lan",
      "Olga Sourina",
      "Wolfgang M\u00fcller-Wittig"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2107.09507"
  },
  {
    "id": "arXiv:2107.10138",
    "title": "Secure Random Sampling in Differential Privacy",
    "abstract": "Secure Random Sampling in Differential Privacy",
    "descriptor": "",
    "authors": [
      "Naoise Holohan",
      "Stefano Braghin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.10138"
  },
  {
    "id": "arXiv:2107.10294",
    "title": "User-Centric Perspective in Random Access Cell-Free Aided by Spatial  Separability",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Victor Croisfelt",
      "Taufik Abr\u00e3o",
      "Jos\u00e9 Carlos Marinello"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.10294"
  },
  {
    "id": "arXiv:2107.11665",
    "title": "Clinical Utility of the Automatic Phenotype Annotation in Unstructured  Clinical Notes: ICU Use Cases",
    "abstract": "Comments: Manuscript under review",
    "descriptor": "\nComments: Manuscript under review\n",
    "authors": [
      "Jingqing Zhang",
      "Luis Bolanos",
      "Ashwani Tanwar",
      "Julia Ive",
      "Vibhor Gupta",
      "Yike Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.11665"
  },
  {
    "id": "arXiv:2107.14669",
    "title": "Representing preorders with injective monotones",
    "abstract": "Representing preorders with injective monotones",
    "descriptor": "",
    "authors": [
      "Pedro Hack",
      "Daniel A. Braun",
      "Sebastian Gottwald"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.14669"
  },
  {
    "id": "arXiv:2108.01115",
    "title": "Triangular body-cover model of the vocal folds with coordinated  activation of the five intrinsic laryngeal muscles",
    "abstract": "Comments: Primitive version, 54 pages, 8 figures, 4 tables. The present manuscript has been submitted to the Journal of the Acoustical Society of America (JASA)",
    "descriptor": "\nComments: Primitive version, 54 pages, 8 figures, 4 tables. The present manuscript has been submitted to the Journal of the Acoustical Society of America (JASA)\n",
    "authors": [
      "Gabriel A. Alzamendi",
      "Sean D. Peterson",
      "Byron D. Erath",
      "Robert E. Hillman",
      "Mat\u00edas Za\u00f1artu"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.01115"
  },
  {
    "id": "arXiv:2108.01265",
    "title": "Memorize, Factorize, or be Na\u00efve: Learning Optimal Feature Interaction  Methods for CTR Prediction",
    "abstract": "Comments: Published in ICDE 2022",
    "descriptor": "\nComments: Published in ICDE 2022\n",
    "authors": [
      "Fuyuan Lyu",
      "Xing Tang",
      "Huifeng Guo",
      "Ruiming Tang",
      "Xiuqiang He",
      "Rui Zhang",
      "Xue Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.01265"
  },
  {
    "id": "arXiv:2108.01584",
    "title": "Numerical Solution of Stiff ODEs with Physics-Informed RPNNs",
    "abstract": "Numerical Solution of Stiff ODEs with Physics-Informed RPNNs",
    "descriptor": "",
    "authors": [
      "Evangelos Galaris",
      "Gianluca Fabiani",
      "Francesco Calabr\u00f2",
      "Daniela di Serafino",
      "Constantinos Siettos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.01584"
  },
  {
    "id": "arXiv:2108.02040",
    "title": "Convergence of gradient descent for learning linear neural networks",
    "abstract": "Comments: Minor changes",
    "descriptor": "\nComments: Minor changes\n",
    "authors": [
      "Gabin Maxime Nguegnang",
      "Holger Rauhut",
      "Ulrich Terstiege"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.02040"
  },
  {
    "id": "arXiv:2108.02446",
    "title": "Finetuning Pretrained Transformers into Variational Autoencoders",
    "abstract": "Comments: Proceedings of the Second Workshop on Insights from Negative Results in NLP",
    "descriptor": "\nComments: Proceedings of the Second Workshop on Insights from Negative Results in NLP\n",
    "authors": [
      "Seongmin Park",
      "Jihwa Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.02446"
  },
  {
    "id": "arXiv:2108.03227",
    "title": "Bird's-Eye-View Panoptic Segmentation Using Monocular Frontal View  Images",
    "abstract": "Comments: 17 pages, 13 figures",
    "descriptor": "\nComments: 17 pages, 13 figures\n",
    "authors": [
      "Nikhil Gosala",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.03227"
  },
  {
    "id": "arXiv:2108.03980",
    "title": "Decentralized Deep Learning for Multi-Access Edge Computing: A Survey on  Communication Efficiency and Trustworthiness",
    "abstract": "Comments: 11 pages, 8 figures",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Yuwei Sun",
      "Hideya Ochiai",
      "Hiroshi Esaki"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.03980"
  },
  {
    "id": "arXiv:2108.08723",
    "title": "Feature-weighted Stacking for Nonseasonal Time Series Forecasts: A Case  Study of the COVID-19 Epidemic Curves",
    "abstract": "Feature-weighted Stacking for Nonseasonal Time Series Forecasts: A Case  Study of the COVID-19 Epidemic Curves",
    "descriptor": "",
    "authors": [
      "Pieter Cawood",
      "Terence L. van Zyl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.08723"
  },
  {
    "id": "arXiv:2108.09640",
    "title": "DenseTNT: End-to-end Trajectory Prediction from Dense Goal Sets",
    "abstract": "Comments: Accepted to ICCV 2021",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Junru Gu",
      "Chen Sun",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.09640"
  },
  {
    "id": "arXiv:2108.10218",
    "title": "Analysis of Chronic Pain Experiences Based on Online Reports: the RRCP  Dataset for quality-of-life assessment",
    "abstract": "Comments: 10 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 10 pages, 5 figures, 3 tables\n",
    "authors": [
      "Diogo A.P. Nunes",
      "David Martins de Matos",
      "Fani Neto",
      "Joana Ferreira Gomes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2108.10218"
  },
  {
    "id": "arXiv:2108.10573",
    "title": "The staircase property: How hierarchical structure can guide deep  learning",
    "abstract": "Comments: 60 pages, accepted to NeurIPS '21",
    "descriptor": "\nComments: 60 pages, accepted to NeurIPS '21\n",
    "authors": [
      "Emmanuel Abbe",
      "Enric Boix-Adsera",
      "Matthew Brennan",
      "Guy Bresler",
      "Dheeraj Nagaraj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.10573"
  },
  {
    "id": "arXiv:2108.13033",
    "title": "Resource Allocation for Active IRS-Assisted Multiuser Communication  Systems",
    "abstract": "Comments: 3 figures, submitted to Asilomar 2021",
    "descriptor": "\nComments: 3 figures, submitted to Asilomar 2021\n",
    "authors": [
      "Dongfang Xu",
      "Xianghao Yu",
      "Derrick Wing Kwan Ng",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.13033"
  },
  {
    "id": "arXiv:2109.01303",
    "title": "Self-supervised Multi-class Pre-training for Unsupervised Anomaly  Detection and Segmentation in Medical Images",
    "abstract": "Self-supervised Multi-class Pre-training for Unsupervised Anomaly  Detection and Segmentation in Medical Images",
    "descriptor": "",
    "authors": [
      "Yu Tian",
      "Fengbei Liu",
      "Guansong Pang",
      "Yuanhong Chen",
      "Yuyuan Liu",
      "Johan W. Verjans",
      "Rajvinder Singh",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.01303"
  },
  {
    "id": "arXiv:2109.01801",
    "title": "Dual Transfer Learning for Event-based End-task Prediction via Pluggable  Event to Image Translation",
    "abstract": "Comments: ICCV 2021 (updated references in this version)",
    "descriptor": "\nComments: ICCV 2021 (updated references in this version)\n",
    "authors": [
      "Lin Wang",
      "Yujeong Chae",
      "Kuk-Jin Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.01801"
  },
  {
    "id": "arXiv:2109.05735",
    "title": "The decidability of the genus of regular languages and directed  emulators",
    "abstract": "Comments: 35 pages",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Guillaume Bonfante",
      "Florian Deloup"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2109.05735"
  },
  {
    "id": "arXiv:2109.07346",
    "title": "Introducing an Abusive Language Classification Framework for Telegram to  Investigate the German Hater Community",
    "abstract": "Introducing an Abusive Language Classification Framework for Telegram to  Investigate the German Hater Community",
    "descriptor": "",
    "authors": [
      "Maximilian Wich",
      "Adrian Gorniak",
      "Tobias Eder",
      "Daniel Bartmann",
      "Burak Enes \u00c7akici",
      "Georg Groh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07346"
  },
  {
    "id": "arXiv:2109.08229",
    "title": "Policy Choice and Best Arm Identification: Asymptotic Analysis of  Exploration Sampling",
    "abstract": "Comments: Submitted to Econometrica",
    "descriptor": "\nComments: Submitted to Econometrica\n",
    "authors": [
      "Kaito Ariu",
      "Masahiro Kato",
      "Junpei Komiyama",
      "Kenichiro McAlinn",
      "Chao Qin"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.08229"
  },
  {
    "id": "arXiv:2109.08717",
    "title": "The Optimization of the Constant Flow Parallel Micropump Using RBF  Neural Network",
    "abstract": "Comments: Accepted to International Conference on Robotics and Automation Engineering (ICRAE), 2021",
    "descriptor": "\nComments: Accepted to International Conference on Robotics and Automation Engineering (ICRAE), 2021\n",
    "authors": [
      "Chenyang Ma",
      "Boyuan Xu",
      "Hesheng Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.08717"
  },
  {
    "id": "arXiv:2109.10617",
    "title": "Solving Large Steiner Tree Problems in Graphs for Cost-Efficient  Fiber-To-The-Home Network Expansion",
    "abstract": "Comments: Accepted at ICAART 2022, 10 pages, 18 figures",
    "descriptor": "\nComments: Accepted at ICAART 2022, 10 pages, 18 figures\n",
    "authors": [
      "Tobias M\u00fcller",
      "Kyrill Schmid",
      "Dani\u00eblle Schuman",
      "Thomas Gabor",
      "Markus Friedrich",
      "Marc Geitz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.10617"
  },
  {
    "id": "arXiv:2109.11159",
    "title": "OH-Former: Omni-Relational High-Order Transformer for Person  Re-Identification",
    "abstract": "OH-Former: Omni-Relational High-Order Transformer for Person  Re-Identification",
    "descriptor": "",
    "authors": [
      "Xianing Chen",
      "Chunlin Xu",
      "Qiong Cao",
      "Jialang Xu",
      "Yujie Zhong",
      "Jiale Xu",
      "Zhengxin Li",
      "Jingya Wang",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.11159"
  },
  {
    "id": "arXiv:2109.11939",
    "title": "Discovering PDEs from Multiple Experiments",
    "abstract": "Comments: Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021)",
    "descriptor": "\nComments: Fourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021)\n",
    "authors": [
      "Georges Tod",
      "Gert-Jan Both",
      "Remy Kusters"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.11939"
  },
  {
    "id": "arXiv:2109.12848",
    "title": "A General Gaussian Heatmap Labeling for Arbitrary-Oriented Object  Detection",
    "abstract": "Comments: 15 pages, 12 figures",
    "descriptor": "\nComments: 15 pages, 12 figures\n",
    "authors": [
      "Zhanchao Huang",
      "Wei Li",
      "Xiang-Gen Xia",
      "Ran Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12848"
  },
  {
    "id": "arXiv:2109.14501",
    "title": "Towards a theory of out-of-distribution learning",
    "abstract": "Towards a theory of out-of-distribution learning",
    "descriptor": "",
    "authors": [
      "Ali Geisa",
      "Ronak Mehta",
      "Hayden S. Helm",
      "Jayanta Dey",
      "Eric Eaton",
      "Jeffery Dick",
      "Carey E. Priebe",
      "Joshua T. Vogelstein"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.14501"
  },
  {
    "id": "arXiv:2109.15169",
    "title": "Variational learning of quantum ground states on spiking neuromorphic  hardware",
    "abstract": "Comments: 14 pages, 7 figures",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Robert Klassert",
      "Andreas Baumbach",
      "Mihai A. Petrovici",
      "Martin G\u00e4rttner"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.15169"
  },
  {
    "id": "arXiv:2110.05428",
    "title": "Learning Temporally Causal Latent Processes from General Temporal Data",
    "abstract": "Learning Temporally Causal Latent Processes from General Temporal Data",
    "descriptor": "",
    "authors": [
      "Weiran Yao",
      "Yuewen Sun",
      "Alex Ho",
      "Changyin Sun",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05428"
  },
  {
    "id": "arXiv:2110.06178",
    "title": "TAda! Temporally-Adaptive Convolutions for Video Understanding",
    "abstract": "TAda! Temporally-Adaptive Convolutions for Video Understanding",
    "descriptor": "",
    "authors": [
      "Ziyuan Huang",
      "Shiwei Zhang",
      "Liang Pan",
      "Zhiwu Qing",
      "Mingqian Tang",
      "Ziwei Liu",
      "Marcelo H. Ang Jr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06178"
  },
  {
    "id": "arXiv:2110.06532",
    "title": "An Efficient Source Model Selection Framework in Model Databases",
    "abstract": "An Efficient Source Model Selection Framework in Model Databases",
    "descriptor": "",
    "authors": [
      "Minjun Zhao",
      "Lu Chen",
      "Keyu Yang",
      "Yuntao Du",
      "Yunjun Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.06532"
  },
  {
    "id": "arXiv:2110.09748",
    "title": "User Based Design and Evaluation Pipeline for Indoor Airships",
    "abstract": "Comments: Submitting to ICRA 2022",
    "descriptor": "\nComments: Submitting to ICRA 2022\n",
    "authors": [
      "Zhaoliang Zheng",
      "Jiahao Li",
      "Parth Agrawal",
      "Zhao Lei",
      "Aaron John-Sabu",
      "Ankur Mehta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.09748"
  },
  {
    "id": "arXiv:2110.11024",
    "title": "Watermarking Graph Neural Networks based on Backdoor Attacks",
    "abstract": "Watermarking Graph Neural Networks based on Backdoor Attacks",
    "descriptor": "",
    "authors": [
      "Jing Xu",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11024"
  },
  {
    "id": "arXiv:2110.15292",
    "title": "Class-wise Thresholding for Detecting Out-of-Distribution Data",
    "abstract": "Comments: 12 pages, 7 figures, 7 tables",
    "descriptor": "\nComments: 12 pages, 7 figures, 7 tables\n",
    "authors": [
      "Matteo Guarrera",
      "Baihong Jin",
      "Tung-Wei Lin",
      "Maria Zuluaga",
      "Yuxin Chen",
      "Alberto Sangiovanni-Vincentelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15292"
  },
  {
    "id": "arXiv:2110.15742",
    "title": "Barlow Graph Auto-Encoder for Unsupervised Network Embedding",
    "abstract": "Barlow Graph Auto-Encoder for Unsupervised Network Embedding",
    "descriptor": "",
    "authors": [
      "Rayyan Ahmad Khan",
      "Martin Kleinsteuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15742"
  },
  {
    "id": "arXiv:2111.03380",
    "title": "Integral state-feedback control of linear time-varying systems: A  performance preserving approach",
    "abstract": "Integral state-feedback control of linear time-varying systems: A  performance preserving approach",
    "descriptor": "",
    "authors": [
      "Richard Seeber",
      "Markus Tranninger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.03380"
  },
  {
    "id": "arXiv:2111.03977",
    "title": "A Virtual Reality Simulation Pipeline for Online Mental Workload  Modeling",
    "abstract": "Comments: 7 pages, 4 figures, and 1 table Currently under review as a conference paper for IEEE VR 2022, v2 - Spelling Corrections",
    "descriptor": "\nComments: 7 pages, 4 figures, and 1 table Currently under review as a conference paper for IEEE VR 2022, v2 - Spelling Corrections\n",
    "authors": [
      "Robert L. Wilson",
      "Daniel Browne",
      "Jonathan Wagstaff",
      "Steve McGuire"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.03977"
  },
  {
    "id": "arXiv:2111.03984",
    "title": "Proposing an Interactive Audit Pipeline for Visual Privacy Research",
    "abstract": "Comments: Extended version of IEEE BigData 2021 Short Paper, 14 pages, grammar edits",
    "descriptor": "\nComments: Extended version of IEEE BigData 2021 Short Paper, 14 pages, grammar edits\n",
    "authors": [
      "Jasmine DeHart",
      "Chenguang Xu",
      "Lisa Egede",
      "Christan Grant"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03984"
  },
  {
    "id": "arXiv:2111.04398",
    "title": "Sub-realtime simulation of a neuronal network of natural density",
    "abstract": "Sub-realtime simulation of a neuronal network of natural density",
    "descriptor": "",
    "authors": [
      "Anno C. Kurth",
      "Johanna Senk",
      "Dennis Terhorst",
      "Justin Finnerty",
      "Markus Diesmann"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2111.04398"
  },
  {
    "id": "arXiv:2111.04805",
    "title": "Solution to the Non-Monotonicity and Crossing Problems in Quantile  Regression",
    "abstract": "Comments: 8 pages, 14 figures, IEEE conference format",
    "descriptor": "\nComments: 8 pages, 14 figures, IEEE conference format\n",
    "authors": [
      "Resve A. Saleh",
      "A.K.Md. Ehsanes Saleh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.04805"
  },
  {
    "id": "arXiv:2111.05070",
    "title": "Almost Optimal Universal Lower Bound for Learning Causal DAGs with  Atomic Interventions",
    "abstract": "Comments: Added a new upper bound",
    "descriptor": "\nComments: Added a new upper bound\n",
    "authors": [
      "Vibhor Porwal",
      "Piyush Srivastava",
      "Gaurav Sinha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.05070"
  },
  {
    "id": "arXiv:2111.05177",
    "title": "On Training Implicit Models",
    "abstract": "Comments: 24 pages, 4 figures, in The 35th Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: 24 pages, 4 figures, in The 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Zhengyang Geng",
      "Xin-Yu Zhang",
      "Shaojie Bai",
      "Yisen Wang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05177"
  },
  {
    "id": "arXiv:2111.05225",
    "title": "Helly systems and certificates in optimization",
    "abstract": "Helly systems and certificates in optimization",
    "descriptor": "",
    "authors": [
      "Amitabh Basu",
      "Tongtong Chen",
      "Michele Conforti",
      "Hongyi Jiang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.05225"
  },
  {
    "id": "arXiv:2111.05792",
    "title": "HARPO: Learning to Subvert Online Behavioral Advertising",
    "abstract": "Comments: Accepted at NDSS'22",
    "descriptor": "\nComments: Accepted at NDSS'22\n",
    "authors": [
      "Jiang Zhang",
      "Konstantinos Psounis",
      "Muhammad Haroon",
      "Zubair Shafiq"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.05792"
  },
  {
    "id": "arXiv:2111.06240",
    "title": "Improvements to short-term weather prediction with  recurrent-convolutional networks",
    "abstract": "Comments: 6 pages, 4 figures. Accepted to the session \"Bigdata Cup Challenges: IARAI's Weather4cast Competition\" at IEEE Big Data Conference 2021",
    "descriptor": "\nComments: 6 pages, 4 figures. Accepted to the session \"Bigdata Cup Challenges: IARAI's Weather4cast Competition\" at IEEE Big Data Conference 2021\n",
    "authors": [
      "Jussi Leinonen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.06240"
  },
  {
    "id": "arXiv:2111.06366",
    "title": "Answer Set Programming Made Easy",
    "abstract": "Answer Set Programming Made Easy",
    "descriptor": "",
    "authors": [
      "Jorge Fandinno",
      "Seemran Mishra",
      "Javier Romero",
      "Torsten Schaub"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.06366"
  },
  {
    "id": "arXiv:2111.06628",
    "title": "Learning to Break Deep Perceptual Hashing: The Use Case NeuralHash",
    "abstract": "Comments: 22 pages, 15 figures, 5 tables",
    "descriptor": "\nComments: 22 pages, 15 figures, 5 tables\n",
    "authors": [
      "Lukas Struppek",
      "Dominik Hintersdorf",
      "Daniel Neider",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06628"
  },
  {
    "id": "arXiv:2111.08283",
    "title": "Hierarchical Topometric Representation of 3D Robotic Maps",
    "abstract": "Comments: Temporarily",
    "descriptor": "\nComments: Temporarily\n",
    "authors": [
      "Zhenpeng He",
      "Hao Sun",
      "Jiawei Hou",
      "Yajun Ha",
      "S\u00f6ren Schwertfeger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.08283"
  },
  {
    "id": "arXiv:2111.09298",
    "title": "SeCGAN: Parallel Conditional Generative Adversarial Networks for Face  Editing via Semantic Consistency",
    "abstract": "SeCGAN: Parallel Conditional Generative Adversarial Networks for Face  Editing via Semantic Consistency",
    "descriptor": "",
    "authors": [
      "Jiaze Sun",
      "Binod Bhattarai",
      "Zhixiang Chen",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09298"
  },
  {
    "id": "arXiv:2111.09444",
    "title": "Hypercontractivity on High Dimensional Expanders: a Local-to-Global  Approach for Higher Moments",
    "abstract": "Comments: New title to distinguish from independent work of Gur, Lifshitz, and Liu",
    "descriptor": "\nComments: New title to distinguish from independent work of Gur, Lifshitz, and Liu\n",
    "authors": [
      "Mitali Bafna",
      "Max Hopkins",
      "Tali Kaufman",
      "Shachar Lovett"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.09444"
  },
  {
    "id": "arXiv:2111.10434",
    "title": "Machine Learning for Mechanical Ventilation Control (Extended Abstract)",
    "abstract": "Comments: Machine Learning for Health (ML4H) at NeurIPS 2021 - Extended Abstract. arXiv admin note: substantial text overlap with arXiv:2102.06779",
    "descriptor": "\nComments: Machine Learning for Health (ML4H) at NeurIPS 2021 - Extended Abstract. arXiv admin note: substantial text overlap with arXiv:2102.06779\n",
    "authors": [
      "Daniel Suo",
      "Cyril Zhang",
      "Paula Gradu",
      "Udaya Ghai",
      "Xinyi Chen",
      "Edgar Minasyan",
      "Naman Agarwal",
      "Karan Singh",
      "Julienne LaChance",
      "Tom Zajdel",
      "Manuel Schottdorf",
      "Daniel Cohen",
      "Elad Hazan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10434"
  },
  {
    "id": "arXiv:2111.10491",
    "title": "Malicious Selling Strategies in Livestream Shopping: A Case Study of  Alibaba's Taobao and ByteDance's Douyin",
    "abstract": "Malicious Selling Strategies in Livestream Shopping: A Case Study of  Alibaba's Taobao and ByteDance's Douyin",
    "descriptor": "",
    "authors": [
      "Qunfang Wu",
      "Yisi Sang",
      "Dakuo Wang",
      "Zhicong Lu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.10491"
  },
  {
    "id": "arXiv:2111.10520",
    "title": "StylePart: Image-based Shape Part Manipulation",
    "abstract": "Comments: 10 pages, Project page: this https URL",
    "descriptor": "\nComments: 10 pages, Project page: this https URL\n",
    "authors": [
      "I-Chao Shen",
      "Li-Wen Su",
      "Yu-Ting Wu",
      "Bing-Yu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.10520"
  },
  {
    "id": "arXiv:2111.10954",
    "title": "Generation Drawing/Grinding Trajectoy Based on Hierarchical CVAE",
    "abstract": "Comments: 7pages, 18figures",
    "descriptor": "\nComments: 7pages, 18figures\n",
    "authors": [
      "Masahiro Aita",
      "Keito Sugawara",
      "Sho Sakaino",
      "Toshiaki Tsuji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10954"
  },
  {
    "id": "arXiv:2111.11001",
    "title": "Easy construction of representations of multivariate functions with  low-dimensional terms via Gaussian process regression kernel design",
    "abstract": "Comments: 8 pages, 1 figure, 2 tables",
    "descriptor": "\nComments: 8 pages, 1 figure, 2 tables\n",
    "authors": [
      "Eita Sasaki",
      "Manabu Ihara",
      "Sergei Manzhos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2111.11001"
  },
  {
    "id": "arXiv:2111.11025",
    "title": "On immersed boundary kernel functions: a constrained quadratic  minimization perspective",
    "abstract": "On immersed boundary kernel functions: a constrained quadratic  minimization perspective",
    "descriptor": "",
    "authors": [
      "Amneet Pal Singh Bhalla"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.11025"
  },
  {
    "id": "arXiv:2111.11087",
    "title": "Bayesian Inversion of Log-normal Eikonal Equations",
    "abstract": "Comments: fixed bbl errors on page 3, immediately before and after eq. (2.4)",
    "descriptor": "\nComments: fixed bbl errors on page 3, immediately before and after eq. (2.4)\n",
    "authors": [
      "Zhan Fei Yeo",
      "Viet Ha Hoang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.11087"
  },
  {
    "id": "arXiv:2111.11133",
    "title": "L-Verse: Bidirectional Generation Between Image and Text",
    "abstract": "L-Verse: Bidirectional Generation Between Image and Text",
    "descriptor": "",
    "authors": [
      "Taehoon Kim",
      "Gwangmo Song",
      "Sihaeng Lee",
      "Sangyun Kim",
      "Yewon Seo",
      "Soonyoung Lee",
      "Seung Hwan Kim",
      "Honglak Lee",
      "Kyunghoon Bae"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11133"
  },
  {
    "id": "arXiv:2111.11148",
    "title": "A Novel Randomized XR-Based Preconditioned CholeskyQR Algorithm",
    "abstract": "Comments: 23 pages, 11 figures, 6 tables",
    "descriptor": "\nComments: 23 pages, 11 figures, 6 tables\n",
    "authors": [
      "Yuwei Fan",
      "Yixiao Guo",
      "Ting Lin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.11148"
  },
  {
    "id": "arXiv:2111.11426",
    "title": "Neural Fields in Visual Computing and Beyond",
    "abstract": "Comments: Equal advising: Vincent Sitzmann and Srinath Sridhar",
    "descriptor": "\nComments: Equal advising: Vincent Sitzmann and Srinath Sridhar\n",
    "authors": [
      "Yiheng Xie",
      "Towaki Takikawa",
      "Shunsuke Saito",
      "Or Litany",
      "Shiqin Yan",
      "Numair Khan",
      "Federico Tombari",
      "James Tompkin",
      "Vincent Sitzmann",
      "Srinath Sridhar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11426"
  },
  {
    "id": "arXiv:2111.11534",
    "title": "Poisoning Attacks to Local Differential Privacy Protocols for Key-Value  Data",
    "abstract": "Comments: To appear in USENIX Security Symposium, 2022",
    "descriptor": "\nComments: To appear in USENIX Security Symposium, 2022\n",
    "authors": [
      "Yongji Wu",
      "Xiaoyu Cao",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.11534"
  },
  {
    "id": "arXiv:2111.11646",
    "title": "CytoImageNet: A large-scale pretraining dataset for bioimage transfer  learning",
    "abstract": "Comments: Accepted paper at NeurIPS 2021 Learning Meaningful Representations for Life (LMRL) Workshop",
    "descriptor": "\nComments: Accepted paper at NeurIPS 2021 Learning Meaningful Representations for Life (LMRL) Workshop\n",
    "authors": [
      "Stanley Bryan Z. Hua",
      "Alex X. Lu",
      "Alan M. Moses"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.11646"
  },
  {
    "id": "arXiv:2111.11655",
    "title": "Multi-task manifold learning for small sample size datasets",
    "abstract": "Comments: 22 pages, 15 figures",
    "descriptor": "\nComments: 22 pages, 15 figures\n",
    "authors": [
      "Hideaki Ishibashi",
      "Kazushi Higa",
      "Tetsuo Furukawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.11655"
  },
  {
    "id": "arXiv:2111.11720",
    "title": "Gait Identification under Surveillance Environment based on Human  Skeleton",
    "abstract": "Gait Identification under Surveillance Environment based on Human  Skeleton",
    "descriptor": "",
    "authors": [
      "Xingkai Zheng",
      "Xirui Li",
      "Ke Xu",
      "Xinghao Jiang",
      "Tanfeng Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.11720"
  },
  {
    "id": "arXiv:2111.11723",
    "title": "A new dynamical model for solving rotation averaging problem",
    "abstract": "A new dynamical model for solving rotation averaging problem",
    "descriptor": "",
    "authors": [
      "Zinaid Kapi\u0107",
      "Aladin Crnki\u0107",
      "Vladimir Ja\u0107imovi\u0107",
      "Nevena Mijajlovi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11723"
  },
  {
    "id": "arXiv:2111.11750",
    "title": "S-SimCSE: Sampled Sub-networks for Contrastive Learning of Sentence  Embedding",
    "abstract": "Comments: 2 pages",
    "descriptor": "\nComments: 2 pages\n",
    "authors": [
      "Junlei Zhang",
      "Zhenzhong lan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.11750"
  },
  {
    "id": "arXiv:2111.11843",
    "title": "U-shape Transformer for Underwater Image Enhancement",
    "abstract": "Comments: 8 pages, 6 images",
    "descriptor": "\nComments: 8 pages, 6 images\n",
    "authors": [
      "Lintao Peng",
      "Chunli Zhu",
      "Liheng Bian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.11843"
  },
  {
    "id": "arXiv:2111.12000",
    "title": "Virtual element method for elliptic bulk-surface PDEs in three space  dimensions",
    "abstract": "Comments: 24 pages, 4 figures, 1 table. This replacement adds a \"Data availability\" statement to the manuscript and fixes a capital letter in the bibliography. arXiv admin note: substantial text overlap with arXiv:2002.11748",
    "descriptor": "\nComments: 24 pages, 4 figures, 1 table. This replacement adds a \"Data availability\" statement to the manuscript and fixes a capital letter in the bibliography. arXiv admin note: substantial text overlap with arXiv:2002.11748\n",
    "authors": [
      "Massimo Frittelli",
      "Anotida Madzvamuse",
      "Ivonne Sgura"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12000"
  },
  {
    "id": "arXiv:2111.12026",
    "title": "CINNAMON: A Module for AUTOSAR Secure Onboard Communication",
    "abstract": "CINNAMON: A Module for AUTOSAR Secure Onboard Communication",
    "descriptor": "",
    "authors": [
      "Giampaolo Bella",
      "Pietro Biondi",
      "Gianpiero Costantino",
      "Ilaria Matteucci"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.12026"
  },
  {
    "id": "arXiv:2111.12027",
    "title": "Privacy and modern cars through a dual lens",
    "abstract": "Privacy and modern cars through a dual lens",
    "descriptor": "",
    "authors": [
      "Giampaolo Bella",
      "Pietro Biondi",
      "Marco De Vincenzi",
      "Giuseppe Tudisco"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.12027"
  },
  {
    "id": "arXiv:2111.12077",
    "title": "Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Jonathan T. Barron",
      "Ben Mildenhall",
      "Dor Verbin",
      "Pratul P. Srinivasan",
      "Peter Hedman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.12077"
  }
]
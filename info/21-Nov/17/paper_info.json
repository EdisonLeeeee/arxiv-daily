[
  {
    "id": "arXiv:2111.08002",
    "title": "Natural Gradient Variational Inference with Gaussian Mixture Models",
    "abstract": "Bayesian methods estimate a measure of uncertainty by using the posterior\ndistribution. One source of difficulty in these methods is the computation of\nthe normalizing constant. Calculating exact posterior is generally intractable\nand we usually approximate it. Variational Inference (VI) methods approximate\nthe posterior with a distribution usually chosen from a simple family using\noptimization. The main contribution of this work is described is a set of\nupdate rules for natural gradient variational inference with mixture of\nGaussians, which can be run independently for each of the mixture components,\npotentially in parallel.",
    "descriptor": "",
    "authors": [
      "Farzaneh Mahdisoltani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.08002"
  },
  {
    "id": "arXiv:2111.08004",
    "title": "Bag of Tricks and A Strong baseline for Image Copy Detection",
    "abstract": "Image copy detection is of great importance in real-life social media. In\nthis paper, a bag of tricks and a strong baseline are proposed for image copy\ndetection. Unsupervised pre-training substitutes the commonly-used supervised\none. Beyond that, we design a descriptor stretching strategy to stabilize the\nscores of different queries. Experiments demonstrate that the proposed method\nis effective. The proposed baseline ranks third out of 526 participants on the\nFacebook AI Image Similarity Challenge: Descriptor Track. The code and trained\nmodels are available at\nhttps://github.com/WangWenhao0716/ISC-Track2-Submission.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2111.07090\n",
    "authors": [
      "Wenhao Wang",
      "Weipu Zhang",
      "Yifan Sun",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08004"
  },
  {
    "id": "arXiv:2111.08009",
    "title": "Piano Fingering with Reinforcement Learning",
    "abstract": "Hand and finger movements are a mainstay of piano technique. Automatic\nFingering from symbolic music data allows us to simulate finger and hand\nmovements. Previous proposals achieve automatic piano fingering based on\nknowledge-driven or data-driven techniques. We combine both approaches with\ndeep reinforcement learning techniques to derive piano fingering. Finally, we\nexplore how to incorporate past experience into reinforcement learning-based\npiano fingering in further work.",
    "descriptor": "",
    "authors": [
      "Pedro Ramoneda",
      "Marius Miron",
      "Xavier Serra"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2111.08009"
  },
  {
    "id": "arXiv:2111.08010",
    "title": "Modular Networks Prevent Catastrophic Interference in Model-Based  Multi-Task Reinforcement Learning",
    "abstract": "In a multi-task reinforcement learning setting, the learner commonly benefits\nfrom training on multiple related tasks by exploiting similarities among them.\nAt the same time, the trained agent is able to solve a wider range of different\nproblems. While this effect is well documented for model-free multi-task\nmethods, we demonstrate a detrimental effect when using a single learned\ndynamics model for multiple tasks. Thus, we address the fundamental question of\nwhether model-based multi-task reinforcement learning benefits from shared\ndynamics models in a similar way model-free methods do from shared policy\nnetworks. Using a single dynamics model, we see clear evidence of task\nconfusion and reduced performance. As a remedy, enforcing an internal structure\nfor the learned dynamics model by training isolated sub-networks for each task\nnotably improves performance while using the same amount of parameters. We\nillustrate our findings by comparing both methods on a simple gridworld and a\nmore complex vizdoom multi-task experiment.",
    "descriptor": "\nComments: 15 pages, preprint of a paper presented at the LOD 2021\n",
    "authors": [
      "Robin Schiewer",
      "Laurenz Wiskott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08010"
  },
  {
    "id": "arXiv:2111.08046",
    "title": "Beyond Mono to Binaural: Generating Binaural Audio from Mono Audio with  Depth and Cross Modal Attention",
    "abstract": "Binaural audio gives the listener an immersive experience and can enhance\naugmented and virtual reality. However, recording binaural audio requires\nspecialized setup with a dummy human head having microphones in left and right\nears. Such a recording setup is difficult to build and setup, therefore mono\naudio has become the preferred choice in common devices. To obtain the same\nimpact as binaural audio, recent efforts have been directed towards lifting\nmono audio to binaural audio conditioned on the visual input from the scene.\nSuch approaches have not used an important cue for the task: the distance of\ndifferent sound producing objects from the microphones. In this work, we argue\nthat depth map of the scene can act as a proxy for inducing distance\ninformation of different objects in the scene, for the task of audio\nbinauralization. We propose a novel encoder-decoder architecture with a\nhierarchical attention mechanism to encode image, depth and audio feature\njointly. We design the network on top of state-of-the-art transformer networks\nfor image and depth representation. We show empirically that the proposed\nmethod outperforms state-of-the-art methods comfortably for two challenging\npublic datasets FAIR-Play and MUSIC-Stereo. We also demonstrate with\nqualitative results that the method is able to focus on the right information\nrequired for the task. The project details are available at\n\\url{https://krantiparida.github.io/projects/bmonobinaural.html}",
    "descriptor": "\nComments: To appear in WACV 2022. arXiv admin note: text overlap with arXiv:2108.04906\n",
    "authors": [
      "Kranti Kumar Parida",
      "Siddharth Srivastava",
      "Gaurav Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.08046"
  },
  {
    "id": "arXiv:2111.08048",
    "title": "Sometimes, Convex Separable Optimization Is Much Harder than Linear  Optimization, and Other Surprises",
    "abstract": "An influential 1990 paper of Hochbaum and Shanthikumar made it common wisdom\nthat \"convex separable optimization is not much harder than linear\noptimization\" [JACM 1990]. We exhibit two fundamental classes of mixed integer\n(linear) programs that run counter this intuition. Namely those whose\nconstraint matrices have small coefficients and small primal or dual treedepth:\nWhile linear optimization is easy [Brand, Kouteck\\'y, Ordyniak, AAAI 2021], we\nprove that separable convex optimization IS much harder. Moreover, in the pure\ninteger and mixed integer linear cases, these two classes have the same\nparameterized complexity. We show that they yet behave quite differently in the\nseparable convex mixed integer case.\nOur approach employs the mixed Graver basis introduced by Hemmecke [Math.\nProg. 2003]. We give the first non-trivial lower and upper bounds on the norm\nof mixed Graver basis elements. In previous works involving the integer Graver\nbasis, such upper bounds have consistently resulted in efficient algorithms for\ninteger programming. Curiously, this does not happen in our case. In fact, we\neven rule out such an algorithm.",
    "descriptor": "",
    "authors": [
      "Cornelius Brand",
      "Martin Kouteck\u00fd",
      "Alexandra Lassota",
      "Sebastian Ordyniak"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.08048"
  },
  {
    "id": "arXiv:2111.08051",
    "title": "Common Language for Goal-Oriented Semantic Communications: A Curriculum  Learning Framework",
    "abstract": "Semantic communications will play a critical role in enabling goal-oriented\nservices over next-generation wireless systems. However, most prior art in this\ndomain is restricted to specific applications (e.g., text or image), and it\ndoes not enable goal-oriented communications in which the effectiveness of the\ntransmitted information must be considered along with the semantics so as to\nexecute a certain task. In this paper, a comprehensive semantic communications\nframework is proposed for enabling goal-oriented task execution. To capture the\nsemantics between a speaker and a listener, a common language is defined using\nthe concept of beliefs to enable the speaker to describe the environment\nobservations to the listener. Then, an optimization problem is posed to choose\nthe minimum set of beliefs that perfectly describes the observation while\nminimizing the task execution time and transmission cost. A novel top-down\nframework that combines curriculum learning (CL) and reinforcement learning\n(RL) is proposed to solve this problem. Simulation results show that the\nproposed CL method outperforms traditional RL in terms of convergence time,\ntask execution time, and transmission cost during training.",
    "descriptor": "",
    "authors": [
      "Mohammad Karimzadeh Farshbafan",
      "Walid Saad",
      "Merouane Debbah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08051"
  },
  {
    "id": "arXiv:2111.08057",
    "title": "Margin-Independent Online Multiclass Learning via Convex Geometry",
    "abstract": "We consider the problem of multi-class classification, where a stream of\nadversarially chosen queries arrive and must be assigned a label online. Unlike\ntraditional bounds which seek to minimize the misclassification rate, we\nminimize the total distance from each query to the region corresponding to its\ncorrect label. When the true labels are determined via a nearest neighbor\npartition -- i.e. the label of a point is given by which of $k$ centers it is\nclosest to in Euclidean distance -- we show that one can achieve a loss that is\nindependent of the total number of queries. We complement this result by\nshowing that learning general convex sets requires an almost linear loss per\nquery. Our results build off of regret guarantees for the geometric problem of\ncontextual search. In addition, we develop a novel reduction technique from\nmulticlass classification to binary classification which may be of independent\ninterest.",
    "descriptor": "",
    "authors": [
      "Guru Guruganesh",
      "Allen Liu",
      "Jon Schneider",
      "Joshua Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.08057"
  },
  {
    "id": "arXiv:2111.08060",
    "title": "A Multi-criteria Approach to Evolve Sparse Neural Architectures for  Stock Market Forecasting",
    "abstract": "This study proposes a new framework to evolve efficacious yet parsimonious\nneural architectures for the movement prediction of stock market indices using\ntechnical indicators as inputs. In the light of a sparse signal-to-noise ratio\nunder the Efficient Market hypothesis, developing machine learning methods to\npredict the movement of a financial market using technical indicators has shown\nto be a challenging problem. To this end, the neural architecture search is\nposed as a multi-criteria optimization problem to balance the efficacy with the\ncomplexity of architectures. In addition, the implications of different\ndominant trading tendencies which may be present in the pre-COVID and\nwithin-COVID time periods are investigated. An $\\epsilon-$ constraint framework\nis proposed as a remedy to extract any concordant information underlying the\npossibly conflicting pre-COVID data. Further, a new search paradigm,\nTwo-Dimensional Swarms (2DS) is proposed for the multi-criteria neural\narchitecture search, which explicitly integrates sparsity as an additional\nsearch dimension in particle swarms. A detailed comparative evaluation of the\nproposed approach is carried out by considering genetic algorithm and several\ncombinations of empirical neural design rules with a filter-based feature\nselection method (mRMR) as baseline approaches. The results of this study\nconvincingly demonstrate that the proposed approach can evolve parsimonious\nnetworks with better generalization capabilities.",
    "descriptor": "\nComments: 29 pages, 6 figures\n",
    "authors": [
      "Faizal Hafiz",
      "Jan Broekaert",
      "Davide La Torre",
      "Akshya Swain"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.08060"
  },
  {
    "id": "arXiv:2111.08062",
    "title": "Synthetic Unknown Class Learning for Learning Unknowns",
    "abstract": "This paper addresses the open set recognition (OSR) problem, where the goal\nis to correctly classify samples of known classes while detecting unknown\nsamples to reject. In the OSR problem, \"unknown\" is assumed to have infinite\npossibilities because we have no knowledge about unknowns until they emerge.\nIntuitively, the more an OSR system explores the possibilities of unknowns, the\nmore likely it is to detect unknowns. Thus, this paper proposes a novel\nsynthetic unknown class learning method that generates unknown-like samples\nwhile maintaining diversity between the generated samples and learns these\nsamples. In addition to this unknown sample generation process, knowledge\ndistillation is introduced to provide room for learning synthetic unknowns. By\nlearning the unknown-like samples and known samples in an alternating manner,\nthe proposed method can not only experience diverse synthetic unknowns but also\nreduce overgeneralization with respect to known classes. Experiments on several\nbenchmark datasets show that the proposed method significantly outperforms\nother state-of-the-art approaches. It is also shown that realistic unknown\ndigits can be generated and learned via the proposed method after training on\nthe MNIST dataset.",
    "descriptor": "\nComments: 11 pages, 7 figures, 4 tables\n",
    "authors": [
      "Jaeyeon Jang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08062"
  },
  {
    "id": "arXiv:2111.08066",
    "title": "Exploiting Action Impact Regularity and Partially Known Models for  Offline Reinforcement Learning",
    "abstract": "Offline reinforcement learning-learning a policy from a batch of data-is\nknown to be hard: without making strong assumptions, it is easy to construct\ncounterexamples such that existing algorithms fail. In this work, we instead\nconsider a property of certain real world problems where offline reinforcement\nlearning should be effective: those where actions only have limited impact for\na part of the state. We formalize and introduce this Action Impact Regularity\n(AIR) property. We further propose an algorithm that assumes and exploits the\nAIR property, and bound the suboptimality of the output policy when the MDP\nsatisfies AIR. Finally, we demonstrate that our algorithm outperforms existing\noffline reinforcement learning algorithms across different data collection\npolicies in two simulated environments where the regularity holds.",
    "descriptor": "",
    "authors": [
      "Vincent Liu",
      "James Wright",
      "Martha White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08066"
  },
  {
    "id": "arXiv:2111.08067",
    "title": "ModelLight: Model-Based Meta-Reinforcement Learning for Traffic Signal  Control",
    "abstract": "Traffic signal control is of critical importance for the effective use of\ntransportation infrastructures. The rapid increase of vehicle traffic and\nchanges in traffic patterns make traffic signal control more and more\nchallenging. Reinforcement Learning (RL)-based algorithms have demonstrated\ntheir potential in dealing with traffic signal control. However, most existing\nsolutions require a large amount of training data, which is unacceptable for\nmany real-world scenarios. This paper proposes a novel model-based\nmeta-reinforcement learning framework (ModelLight) for traffic signal control.\nWithin ModelLight, an ensemble of models for road intersections and the\noptimization-based meta-learning method are used to improve the data efficiency\nof an RL-based traffic light control method. Experiments on real-world datasets\ndemonstrate that ModelLight can outperform state-of-the-art traffic light\ncontrol algorithms while substantially reducing the number of required\ninteractions with the real-world environment.",
    "descriptor": "",
    "authors": [
      "Xingshuai Huang",
      "Di Wu",
      "Michael Jenkin",
      "Benoit Boulet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08067"
  },
  {
    "id": "arXiv:2111.08069",
    "title": "Two-dimensional Deep Regression for Early Yield Prediction of Winter  Wheat",
    "abstract": "Crop yield prediction is one of the tasks of Precision Agriculture that can\nbe automated based on multi-source periodic observations of the fields. We\ntackle the yield prediction problem using a Convolutional Neural Network (CNN)\ntrained on data that combines radar satellite imagery and on-ground\ninformation. We present a CNN architecture called Hyper3DNetReg that takes in a\nmulti-channel input image and outputs a two-dimensional raster, where each\npixel represents the predicted yield value of the corresponding input pixel. We\nutilize radar data acquired from the Sentinel-1 satellites, while the on-ground\ndata correspond to a set of six raster features: nitrogen rate applied,\nprecipitation, slope, elevation, topographic position index (TPI), and aspect.\nWe use data collected during the early stage of the winter wheat growing season\n(March) to predict yield values during the harvest season (August). We present\nexperiments over four fields of winter wheat and show that our proposed\nmethodology yields better results than five compared methods, including\nmultiple linear regression, an ensemble of feedforward networks using AdaBoost,\na stacked autoencoder, and two other CNN architectures.",
    "descriptor": "\nComments: Accepted to appear in the SPIE Future Sensing Technologies 2021\n",
    "authors": [
      "Giorgio Morales",
      "John W. Sheppard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.08069"
  },
  {
    "id": "arXiv:2111.08073",
    "title": "Learning Robust Scheduling with Search and Attention",
    "abstract": "Allocating physical layer resources to users based on channel quality, buffer\nsize, requirements and constraints represents one of the central optimization\nproblems in the management of radio resources. The solution space grows\ncombinatorially with the cardinality of each dimension making it hard to find\noptimal solutions using an exhaustive search or even classical optimization\nalgorithms given the stringent time requirements. This problem is even more\npronounced in MU-MIMO scheduling where the scheduler can assign multiple users\nto the same time-frequency physical resources. Traditional approaches thus\nresort to designing heuristics that trade optimality in favor of feasibility of\nexecution. In this work we treat the MU-MIMO scheduling problem as a\ntree-structured combinatorial problem and, borrowing from the recent successes\nof AlphaGo Zero, we investigate the feasibility of searching for the best\nperforming solutions using a combination of Monte Carlo Tree Search and\nReinforcement Learning. To cater to the nature of the problem at hand, like the\nlack of an intrinsic ordering of the users as well as the importance of\ndependencies between combinations of users, we make fundamental modifications\nto the neural network architecture by introducing the self-attention mechanism.\nWe then demonstrate that the resulting approach is not only feasible but vastly\noutperforms state-of-the-art heuristic-based scheduling approaches in the\npresence of measurement uncertainties and finite buffers.",
    "descriptor": "",
    "authors": [
      "David Sandberg",
      "Tor Kvernvik",
      "Francesco Davide Calabrese"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08073"
  },
  {
    "id": "arXiv:2111.08082",
    "title": "Learning Graph Neural Networks for Multivariate Time Series Anomaly  Detection",
    "abstract": "In this work, we propose GLUE (Graph Deviation Network with Local Uncertainty\nEstimation), building on the recently proposed Graph Deviation Network (GDN).\nGLUE not only automatically learns complex dependencies between variables and\nuses them to better identify anomalous behavior, but also quantifies its\npredictive uncertainty, allowing us to account for the variation in the data as\nwell to have more interpretable anomaly detection thresholds. Results on two\nreal world datasets tell us that optimizing the negative Gaussian log\nlikelihood is reasonable because GLUE's forecasting results are at par with GDN\nand in fact better than the vector autoregressor baseline, which is significant\ngiven that GDN directly optimizes the MSE loss. In summary, our experiments\ndemonstrate that GLUE is competitive with GDN at anomaly detection, with the\nadded benefit of uncertainty estimations. We also show that GLUE learns\nmeaningful sensor embeddings which clusters similar sensors together.",
    "descriptor": "",
    "authors": [
      "Saswati Ray",
      "Sana Lakdawala",
      "Mononito Goswami",
      "Chufan Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08082"
  },
  {
    "id": "arXiv:2111.08084",
    "title": "Dense Circulant Lattices From Nonlinear Systems",
    "abstract": "Circulant lattices are those with a circulant generator matrix. They can be\ndescribed by a basis containing a vector and its circular shifts. In this\npaper, we present certain conditions under which the norm expression of an\narbitrary vector of a circulant lattice is substantially simplified, and then\ninvestigate some of the lattices obtained under these conditions. We exhibit\nsystems of nonlinear equations whose solutions yield lattices as dense as $D_n$\nin odd dimensions.",
    "descriptor": "\nComments: preprint, 21 pages, 5 figures\n",
    "authors": [
      "William Lima da Silva Pinto",
      "Carina Alves"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.08084"
  },
  {
    "id": "arXiv:2111.08088",
    "title": "Assessing gender bias in medical and scientific masked language models  with StereoSet",
    "abstract": "NLP systems use language models such as Masked Language Models (MLMs) that\nare pre-trained on large quantities of text such as Wikipedia create\nrepresentations of language. BERT is a powerful and flexible general-purpose\nMLM system developed using unlabeled text. Pre-training on large quantities of\ntext also has the potential to transparently embed the cultural and social\nbiases found in the source text into the MLM system. This study aims to compare\nbiases in general purpose and medical MLMs with the StereoSet bias assessment\ntool. The general purpose MLMs showed significant bias overall, with BERT\nscoring 57 and RoBERTa scoring 61. The category of gender bias is where the\nbest performances were found, with 63 for BERT and 73 for RoBERTa. Performances\nfor profession, race, and religion were similar to the overall bias scores for\nthe general-purpose MLMs.Medical MLMs showed more bias in all categories than\nthe general-purpose MLMs except for SciBERT, which showed a race bias score of\n55, which was superior to the race bias score of 53 for BERT. More gender\n(Medical 54-58 vs. General 63-73) and religious (46-54 vs. 58) biases were\nfound with medical MLMs. This evaluation of four medical MLMs for stereotyped\nassessments about race, gender, religion, and profession showed inferior\nperformance to general-purpose MLMs. These medically focused MLMs differ\nconsiderably in training source data, which is likely the root cause of the\ndifferences in ratings for stereotyped biases from the StereoSet tool.",
    "descriptor": "\nComments: 5 pages, 1 table\n",
    "authors": [
      "Robert Robinson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.08088"
  },
  {
    "id": "arXiv:2111.08091",
    "title": "Joint State and Input Estimation of Agent Based on Recursive Kalman  Filter Given Prior Knowledge",
    "abstract": "Modern autonomous systems are purposed for many challenging scenarios, where\nagents will face unexpected events and complicated tasks. The presence of\ndisturbance noise with control command and unknown inputs can negatively impact\nrobot performance. Previous research of joint input and state estimation\nseparately study the continuous and discrete cases without any prior\ninformation. This paper combines the continuous space and discrete space\nestimation into a unified theory based on the Expectation-Maximum (EM)\nalgorithm. By introducing prior knowledge of events as the constraint,\ninequality optimization problems are formulated to determine a gain matrix or\ndynamic weights to realize an optimal input estimation with lower variance and\nmore accurate decision-making. Finally, statistical results from experiments\nshow that our algorithm owns 81\\% improvement of the variance than KF and 47\\%\nimprovement than RKF in continuous space; a remarkable improvement of right\ndecision-making probability of our input estimator in discrete space,\nidentification ability is also analyzed by experiments.",
    "descriptor": "",
    "authors": [
      "Zida Wu",
      "Zhaoliang Zheng",
      "Ankur Mehta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.08091"
  },
  {
    "id": "arXiv:2111.08092",
    "title": "Improving the performance of reputation evaluating by combining the  structure of network and nonlinear recovery",
    "abstract": "Characterizing the reputation of an evaluator is particularly significant for\nconsumer to obtain useful information from online rating systems. Furthermore,\nto overcome the difficulties with spam attacks on the rating system and to get\nthe reliable on reputation of evaluators is an important topic in the research.\nWe have noticed that most of the existing evaluator reputation evaluation\nmethods only rely on the evaluator's rating information and abnormal behavior\nto establish a reputation system, which miss the systematic aspects of the\nrating systems including the structure of the evaluator-object bipartite\nnetwork and the effects of nonlinear effects. This study we propose an improved\nreputation evaluation method by combining the structure of the evaluator-object\nbipartite network with rating information and introducing penalty and reward\nfactors. This novel method has been empirically analyzed on a large-scale\nartificial data set and two real data sets. The results show that the proposed\nmethod is more accurate and robust in the presence of spam attacks. This fresh\nidea contributes a new way for building reputation evaluation models in sparse\nbipartite rating network.",
    "descriptor": "\nComments: 12 pages, 5 figures, submitted to NJP\n",
    "authors": [
      "Meng Li",
      "Chengyuan Han",
      "Yuanxiang Jiang",
      "Zengru Di"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.08092"
  },
  {
    "id": "arXiv:2111.08094",
    "title": "LIMEcraft: Handcrafted superpixel selection and inspection for Visual  eXplanations",
    "abstract": "The increased interest in deep learning applications, and their\nhard-to-detect biases result in the need to validate and explain complex\nmodels. However, current explanation methods are limited as far as both the\nexplanation of the reasoning process and prediction results are concerned. They\nusually only show the location in the image that was important for model\nprediction. The lack of possibility to interact with explanations makes it\ndifficult to verify and understand exactly how the model works. This creates a\nsignificant risk when using the model. It is compounded by the fact that\nexplanations do not take into account the semantic meaning of the explained\nobjects. To escape from the trap of static explanations, we propose an approach\ncalled LIMEcraft that allows a user to interactively select semantically\nconsistent areas and thoroughly examine the prediction for the image instance\nin case of many image features. Experiments on several models showed that our\nmethod improves model safety by inspecting model fairness for image pieces that\nmay indicate model bias. The code is available at:\nthis http URL",
    "descriptor": "",
    "authors": [
      "Weronika Hryniewska",
      "Adrianna Grudzie\u0144",
      "Przemys\u0142aw Biecek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08094"
  },
  {
    "id": "arXiv:2111.08095",
    "title": "TimeVAE: A Variational Auto-Encoder for Multivariate Time Series  Generation",
    "abstract": "Recent work in synthetic data generation in the time-series domain has\nfocused on the use of Generative Adversarial Networks. We propose a novel\narchitecture for synthetically generating time-series data with the use of\nVariational Auto-Encoders (VAEs). The proposed architecture has several\ndistinct properties: interpretability, ability to encode domain knowledge, and\nreduced training times. We evaluate data generation quality by similarity and\npredictability against four multivariate datasets. We experiment with varying\nsizes of training data to measure the impact of data availability on generation\nquality for our VAE method as well as several state-of-the-art data generation\nmethods. Our results on similarity tests show that the VAE approach is able to\naccurately represent the temporal attributes of the original data. On next-step\nprediction tasks using generated data, the proposed VAE architecture\nconsistently meets or exceeds performance of state-of-the-art data generation\nmethods. While noise reduction may cause the generated data to deviate from\noriginal data, we demonstrate the resulting de-noised data can significantly\nimprove performance for next-step prediction using generated data. Finally, the\nproposed architecture can incorporate domain-specific time-patterns such as\npolynomial trends and seasonalities to provide interpretable outputs. Such\ninterpretability can be highly advantageous in applications requiring\ntransparency of model outputs or where users desire to inject prior knowledge\nof time-series patterns into the generative model.",
    "descriptor": "",
    "authors": [
      "Abhyuday Desai",
      "Cynthia Freeman",
      "Zuhui Wang",
      "Ian Beaver"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08095"
  },
  {
    "id": "arXiv:2111.08096",
    "title": "VisualEnv: visual Gym environments with Blender",
    "abstract": "In this paper VisualEnv, a new tool for creating visual environment for\nreinforcement learning is introduced. It is the product of an integration of an\nopen-source modelling and rendering software, Blender, and a python module used\nto generate environment model for simulation, OpenAI Gym. VisualEnv allows the\nuser to create custom environments with photorealistic rendering capabilities\nand full integration with python. The framework is described and tested on a\nseries of example problems that showcase its features for training\nreinforcement learning agents.",
    "descriptor": "",
    "authors": [
      "Andrea Scorsoglio",
      "Roberto Furfaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08096"
  },
  {
    "id": "arXiv:2111.08097",
    "title": "Virtual Reality for Synergistic Surgical Training and Data Generation",
    "abstract": "Surgical simulators not only allow planning and training of complex\nprocedures, but also offer the ability to generate structured data for\nalgorithm development, which may be applied in image-guided computer assisted\ninterventions. While there have been efforts on either developing training\nplatforms for surgeons or data generation engines, these two features, to our\nknowledge, have not been offered together. We present our developments of a\ncost-effective and synergistic framework, named Asynchronous Multibody\nFramework Plus (AMBF+), which generates data for downstream algorithm\ndevelopment simultaneously with users practicing their surgical skills. AMBF+\noffers stereoscopic display on a virtual reality (VR) device and haptic\nfeedback for immersive surgical simulation. It can also generate diverse data\nsuch as object poses and segmentation maps. AMBF+ is designed with a flexible\nplugin setup which allows for unobtrusive extension for simulation of different\nsurgical procedures. We show one use case of AMBF+ as a virtual drilling\nsimulator for lateral skull-base surgery, where users can actively modify the\npatient anatomy using a virtual surgical drill. We further demonstrate how the\ndata generated can be used for validating and training downstream computer\nvision algorithms",
    "descriptor": "\nComments: MICCAI 2021 AE-CAI \"Outstanding Paper Award\" Code: this https URL\n",
    "authors": [
      "Adnan Munawar",
      "Zhaoshuo Li",
      "Punit Kunjam",
      "Nimesh Nagururu",
      "Andy S. Ding",
      "Peter Kazanzides",
      "Thomas Looi",
      "Francis X. Creighton",
      "Russell H. Taylor",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.08097"
  },
  {
    "id": "arXiv:2111.08099",
    "title": "Moebius: Metaprogramming using Contextual Types -- The stage where  System F can pattern match on itself (Long Version)",
    "abstract": "We describe the foundation of the metaprogramming language, Moebius, which\nsupports the generation of polymorphic code and, more importantly the analysis\nof polymorphic code via pattern matching.\nMoebius has two main ingredients: 1) we exploit contextual modal types to\ndescribe open code together with the context in which it is meaningful. In\nMoebius, open code can depend on type and term variables (level 0) whose values\nare supplied at a later stage, as well as code variables (level 1) that stand\nfor code templates supplied at a later stage. This leads to a multi-level modal\nlambda-calculus that supports System-F style polymorphism and forms the basis\nfor polymorphic code generation. 2) we extend the multi-level modal\nlambda-calculus to support pattern matching on code. As pattern matching on\npolymorphic code may refine polymorphic type variables, we extend our\ntype-theoretic foundation to generate and track typing constraints that arise.\nWe also give an operational semantics and prove type preservation.\nOur multi-level modal foundation for Moebius provides the appropriate\nabstractions for both generating and pattern matching on open code without\ncommitting to a concrete representation of variable binding and contexts.\nHence, our work is a step towards building a general type-theoretic foundation\nfor multi-staged metaprogramming that, on the one hand, enforces strong type\nguarantees and, on the other hand, makes it easy to generate and manipulate\ncode. This will allow us to exploit the full potential of metaprogramming\nwithout sacrificing the reliability of and trust in the code we are producing\nand running.",
    "descriptor": "",
    "authors": [
      "Junyoung Jang",
      "Samuel G\u00e9lineau",
      "Stefan Monnier",
      "Brigitte Pientka"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.08099"
  },
  {
    "id": "arXiv:2111.08100",
    "title": "A Chronology of Set Cover Inapproximability Results",
    "abstract": "It is well-known that an algorithm exists which approximates the NP-complete\nproblem of Set Cover within a factor of ln(n), and it was recently proven that\nthis approximation ratio is optimal unless P = NP. This optimality result is\nthe product of many advances in characterizations of NP, in terms of\ninteractive proof systems and probabilistically checkable proofs (PCP), and\nimprovements to the analyses thereof. However, as a result, it is difficult to\nextract the development of Set Cover approximation bounds from the greater\nscope of proof system analysis. This paper attempts to present a chronological\nprogression of results on lower-bounding the approximation ratio of Set Cover.\nWe analyze a series of proofs of progressively better bounds and unify the\nresults under similar terminologies and frameworks to provide an accurate\ncomparison of proof techniques and their results. We also treat many\npreliminary results as black-boxes to better focus our analysis on the core\nreductions to Set Cover instances. The result is alternative versions of\nseveral hardness proofs, beginning with initial inapproximability results and\nculminating in a version of the proof that ln(n) is a tight lower bound.",
    "descriptor": "\nComments: 32 pages, 8 figures. Created as a scholarly paper for the University of Maryland, College Park\n",
    "authors": [
      "Erika Melder"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.08100"
  },
  {
    "id": "arXiv:2111.08102",
    "title": "The Partially Observable History Process",
    "abstract": "We introduce the partially observable history process (POHP) formalism for\nreinforcement learning. POHP centers around the actions and observations of a\nsingle agent and abstracts away the presence of other players without reducing\nthem to stochastic processes. Our formalism provides a streamlined interface\nfor designing algorithms that defy categorization as exclusively single or\nmulti-agent, and for developing theory that applies across these domains. We\nshow how the POHP formalism unifies traditional models including the Markov\ndecision process, the Markov game, the extensive-form game, and their partially\nobservable extensions, without introducing burdensome technical machinery or\nviolating the philosophical underpinnings of reinforcement learning. We\nillustrate the utility of our formalism by concisely exploring observable\nsequential rationality, re-deriving the extensive-form regret minimization\n(EFR) algorithm, and examining EFR's theoretical properties in greater\ngenerality.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Dustin Morrill",
      "Amy R. Greenwald",
      "Michael Bowling"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.08102"
  },
  {
    "id": "arXiv:2111.08105",
    "title": "El impacto del buffer en la calidad de servicio",
    "abstract": "The response in data flows transmission in real time is analyzed, for access\nnetwork scenarios, in which said flows converge on an outgoing link, competing\nto achieve a certain level of quality of service. The concurrence of these\ntypes of flows can generate bursts of packets, which in certain circumstances\ncan compromise the capacity of the buffers to absorb packets in congestion\nperiods. In addition, an analysis of the characteristics of buffers in access\ndevices is presented, especially their size and packet loss. In particular, it\ndescribes how these characteristics can affect the quality of multimedia\napplications when bursty traffic is generated, it also presents possible\neffects on the traffic of other applications that share a common link.",
    "descriptor": "\nComments: in Spanish. The content is a revised and edited version of parts of the doctoral thesis \"T\\'ecnicas de estimaci\\'on de buffer, centradas en las redes de acceso, para la transmisi\\'on de flujos IP en tiempo real\" published in Zaragoza, Spain, 2015. Thanks to Idelkys Quintana for careful revisions of the book, pointing out errors in the text, suggesting improvements, and for all his valuable comments\n",
    "authors": [
      "Luis Sequeira"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.08105"
  },
  {
    "id": "arXiv:2111.08117",
    "title": "Neural networks with linear threshold activations: structure and  algorithms",
    "abstract": "In this article we present new results on neural networks with linear\nthreshold activation functions. We precisely characterize the class of\nfunctions that are representable by such neural networks and show that 2 hidden\nlayers are necessary and sufficient to represent any function representable in\nthe class. This is a surprising result in the light of recent exact\nrepresentability investigations for neural networks using other popular\nactivation functions like rectified linear units (ReLU). We also give precise\nbounds on the sizes of the neural networks required to represent any function\nin the class. Finally, we design an algorithm to solve the empirical risk\nminimization (ERM) problem to global optimality for these neural networks with\na fixed architecture. The algorithm's running time is polynomial in the size of\nthe data sample, if the input dimension and the size of the network\narchitecture are considered fixed constants. The algorithm is unique in the\nsense that it works for any architecture with any number of layers, whereas\nprevious polynomial time globally optimal algorithms work only for very\nrestricted classes of architectures.",
    "descriptor": "",
    "authors": [
      "Sammy Khalife",
      "Amitabh Basu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08117"
  },
  {
    "id": "arXiv:2111.08123",
    "title": "The Bubble Transform and the de Rham Complex",
    "abstract": "The purpose of this paper is to discuss a generalization of the bubble\ntransform to differential forms. The bubble transform was discussed in a\nprevious paper by the authors for scalar valued functions, or zero-forms, and\nrepresents a new tool for the understanding of finite element spaces of\narbitrary polynomial degree. The present paper contains a similar study for\ndifferential forms. From a simplicial mesh of the domain, we build a map which\ndecomposes piecewise smooth $k$-forms into a sum of local bubbles supported on\nappropriate macroelements. The key properties of the decomposition are that it\ncommutes with the exterior derivative and preserves the piecewise polynomial\nstructure of the standard finite element spaces of $k$-forms. Furthermore, the\ntransform is bounded in $L^2$ and also on the appropriate subspace consisting\nof $k$-forms with exterior derivatives in $L^2$.",
    "descriptor": "",
    "authors": [
      "Richard S. Falk",
      "Ragnar Winther"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.08123"
  },
  {
    "id": "arXiv:2111.08133",
    "title": "Exploring Story Generation with Multi-task Objectives in Variational  Autoencoders",
    "abstract": "GPT-2 has been frequently adapted in story generation models as it provides\npowerful generative capability. However, it still fails to generate consistent\nstories and lacks diversity. Current story generation models leverage\nadditional information such as plots or commonsense into GPT-2 to guide the\ngeneration process. These approaches focus on improving generation quality of\nstories while our work look at both quality and diversity. We explore combining\nBERT and GPT-2 to build a variational autoencoder (VAE), and extend it by\nadding additional objectives to learn global features such as story topic and\ndiscourse relations. Our evaluations show our enhanced VAE can provide better\nquality and diversity trade off, generate less repetitive story content and\nlearn a more informative latent variable.",
    "descriptor": "\nComments: 10 pages, 3 figures, ALTA2021\n",
    "authors": [
      "Zhuohan Xie",
      "Trevor Cohn",
      "Jey Han Lau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08133"
  },
  {
    "id": "arXiv:2111.08134",
    "title": "A fixed latency ORBGRAND decoder architecture with LUT-aided  error-pattern scheduling",
    "abstract": "Guessing Random Additive Noise Decoding (GRAND) is a universal decoding\nalgorithm that has been recently proposed as a practical way to perform maximum\nlikelihood decoding. It generates a sequence of possible error patterns and\napplies them to the received vector, checking if the result is a valid\ncodeword. Ordered reliability bits GRAND (ORBGRAND) improves on GRAND by\nconsidering soft information received from the channel. Both GRAND and ORBGRAND\nhave been implemented in hardware, focusing on average performance, sacrificing\nworst case throughput and latency. In this work, an improved pattern schedule\nfor ORBGRAND is proposed. It provides $>0.5$dB gain over the standard schedule\nat a block error rate $\\le 10^{-5}$, and outperforms more complex GRAND flavors\nwith a fraction of the complexity. The proposed schedule is used within a novel\ncode-agnositic decoder architecture: the decoder guarantees fixed high\nthroughput and low latency, making it attractive for latency-constrained\napplications. It outperforms the worst-case performance of decoders by orders\nof magnitude, and outperforms many best-case figures. Decoding a code of length\n128, it achieves a throughput of $79.21$Gb/s with $58.49$ns latency, and of\n$69.61$Gb/s with $40.58$ns latency, yielding better energy efficiency and\ncomparable area efficiency with respect to the state of the art.",
    "descriptor": "\nComments: Submitted for publication on IEEE Transactions on Circuits and Systems I\n",
    "authors": [
      "Carlo Condo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.08134"
  },
  {
    "id": "arXiv:2111.08136",
    "title": "Convergence of Anisotropic Consensus-Based Optimization in Mean-Field  Law",
    "abstract": "In this paper we study anisotropic consensus-based optimization (CBO), a\nmulti-agent metaheuristic derivative-free optimization method capable of\nglobally minimizing nonconvex and nonsmooth functions in high dimensions. CBO\nis based on stochastic swarm intelligence, and inspired by consensus dynamics\nand opinion formation. Compared to other metaheuristic algorithms like particle\nswarm optimization, CBO is of a simpler nature and therefore more amenable to\ntheoretical analysis. By adapting a recently established proof technique, we\nshow that anisotropic CBO converges globally with a dimension-independent rate\nfor a rich class of objective functions under minimal assumptions on the\ninitialization of the method. Moreover, the proof technique reveals that CBO\nperforms a convexification of the optimization problem as the number of agents\ngoes to infinity, thus providing an insight into the internal CBO mechanisms\nresponsible for the success of the method. To motivate anisotropic CBO from a\npractical perspective, we further test the method on a complicated\nhigh-dimensional benchmark problem, which is well understood in the machine\nlearning literature.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Massimo Fornasier",
      "Timo Klock",
      "Konstantin Riedl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.08136"
  },
  {
    "id": "arXiv:2111.08137",
    "title": "Joint Unsupervised and Supervised Training for Multilingual ASR",
    "abstract": "Self-supervised training has shown promising gains in pretraining models and\nfacilitating the downstream finetuning for speech recognition, like\nmultilingual ASR. Most existing methods adopt a 2-stage scheme where the\nself-supervised loss is optimized in the first pretraining stage, and the\nstandard supervised finetuning resumes in the second stage. In this paper, we\npropose an end-to-end (E2E) Joint Unsupervised and Supervised Training (JUST)\nmethod to combine the supervised RNN-T loss and the self-supervised contrastive\nand masked language modeling (MLM) losses. We validate its performance on the\npublic dataset Multilingual LibriSpeech (MLS), which includes 8 languages and\nis extremely imbalanced. On MLS, we explore (1) JUST trained from scratch, and\n(2) JUST finetuned from a pretrained checkpoint. Experiments show that JUST can\nconsistently outperform other existing state-of-the-art methods, and beat the\nmonolingual baseline by a significant margin, demonstrating JUST's capability\nof handling low-resource languages in multilingual ASR. Our average WER of all\nlanguages outperforms average monolingual baseline by 33.3%, and the\nstate-of-the-art 2-stage XLSR by 32%. On low-resource languages like Polish,\nour WER is less than half of the monolingual baseline and even beats the\nsupervised transfer learning method which uses external supervision.",
    "descriptor": "",
    "authors": [
      "Junwen Bai",
      "Bo Li",
      "Yu Zhang",
      "Ankur Bapna",
      "Nikhil Siddhartha",
      "Khe Chai Sim",
      "Tara N. Sainath"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.08137"
  },
  {
    "id": "arXiv:2111.08138",
    "title": "Improved Approximations for CVRP with Unsplittable Demands",
    "abstract": "In this paper, we present improved approximation algorithms for the\n(unsplittable) Capacitated Vehicle Routing Problem (CVRP) in general metrics.\nIn CVRP, introduced by Dantzig and Ramser (1959), we are given a set of points\n(clients) $V$ together with a depot $r$ in a metric space, with each $v\\in V$\nhaving a demand $d_v>0$, and a vehicle of bounded capacity $Q$. The goal is to\nfind a minimum cost collection of tours for the vehicle, each starting and\nending at the depot, such that each client is visited at least once and the\ntotal demands of the clients in each tour is at most $Q$. In the unsplittable\nvariant we study, the demand of a node must be served entirely by one tour. We\npresent two approximation algorithms for unsplittable CVRP: a combinatorial\n$(\\alpha+1.75)$-approximation, where $\\alpha$ is the approximation factor for\nthe Traveling Salesman Problem, and an approximation algorithm based on LP\nrounding with approximation guarantee $\\alpha+\\ln(2) + \\delta \\approx 3.194 +\n\\delta$ in $n^{O(1/\\delta)}$ time. Both approximations can further be improved\nby a small amount when combined with recent work by Blauth, Traub, and Vygen\n(2021), who obtained an $(\\alpha + 2\\cdot (1 -\\epsilon))$-approximation for\nunsplittable CVRP for some constant $\\epsilon$ depending on $\\alpha$ ($\\epsilon\n> 1/3000$ for $\\alpha = 1.5$).",
    "descriptor": "",
    "authors": [
      "Zachary Friggstad",
      "Ramin Mousavi",
      "Mirmahdi Rahgoshay",
      "Mohammad R. Salavatipour"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.08138"
  },
  {
    "id": "arXiv:2111.08142",
    "title": "Quo Vadis MPI RMA? Towards a More Efficient Use of MPI One-Sided  Communication",
    "abstract": "The MPI standard has long included one-sided communication abstractions\nthrough the MPI Remote Memory Access (RMA) interface. Unfortunately, the MPI\nRMA chapter in the 4.0 version of the MPI standard still contains both\nwell-known and lesser known short-comings for both implementations and users,\nwhich lead to potentially non-optimal usage patterns. In this paper, we\nidentify a set of issues and propose ways for applications to better express\nanticipated usage of RMA routines, allowing the MPI implementation to better\nadapt to the application's needs. In order to increase the flexibility of the\nRMA interface, we add the capability to duplicate windows, allowing access to\nthe same resources encapsulated by a window using different configurations. In\nthe same vein, we introduce the concept of MPI memory handles, meant to provide\nlife-time guarantees on memory attached to dynamic windows, removing the\noverhead currently present in using dynamically exposed memory. We will show\nthat our extensions provide improved accumulate latencies, reduced overheads\nfor multi-threaded flushes, and allow for zero overhead dynamic memory window\nusage.",
    "descriptor": "\nComments: 11 pages, presented at EuroMPI'21\n",
    "authors": [
      "Joseph Schuchart",
      "Christoph Niethammer",
      "Jos\u00e9 Gracia",
      "George Bosilca"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.08142"
  },
  {
    "id": "arXiv:2111.08146",
    "title": "A note on averaging prediction accuracy, Green's functions and other  kernels",
    "abstract": "In this note, we analyze a procedure used in predictive security applications\nthat motivates the definition of the integral average transform. Our motivation\ncomes from the need for a better mathematical understanding of the prediction\naccuracy index. This index is used to identify hot spots in predictive security\nand other applications. We present the mathematical context of the predictive\naccuracy index and then introduce the definition of integral average transform.\nWe establish the relation of our definition with two variables kernels $K({\\bf\ny},{\\bf x})$. As an example of an application we show that integrating against\nthe fundamental solution of the Laplace operator, that is, solving the Poisson\nequation, can be re-interpreted as an integral of averages of the forcing term\nover balls.",
    "descriptor": "",
    "authors": [
      "J. Galvis",
      "Freddy Hern\u00e1ndez",
      "Francisco G\u00f3mez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Analysis of PDEs (math.AP)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2111.08146"
  },
  {
    "id": "arXiv:2111.08147",
    "title": "Rearranging the Environment to Maximize Energy with a Robotic Circuit  Drawing",
    "abstract": "Robots with the ability to actively acquire power from surroundings will be\ngreatly beneficial for long-term autonomy and to survive in uncertain\nenvironments. In this work, we present a robot capable of drawing circuits with\nconductive ink while also rearranging the visual world to receive maximum\nenergy from a power source. A range of circuit drawing tasks is designed to\nsimulate real-world scenarios, including avoiding physical obstacles and\nregions that would discontinue drawn circuits. We adopt the state-of-the-art\nTransporter networks for pick-and-place manipulation from visual observation.\nWe conduct experiments in both simulation and real-world settings, and our\nresults show that, with a small number of demonstrations, the robot learns to\nrearrange the placement of objects (removing obstacles and bridging areas\nunsuitable for drawing) and to connect a power source with a minimum amount of\nconductive ink. As autonomous robots become more present, in our houses and\nother planets, our proposed method brings a novel way for machines to keep\nthemselves functional by rearranging their surroundings to create their own\nelectric circuits.",
    "descriptor": "",
    "authors": [
      "Xianglong Tan",
      "Zhikang Liu",
      "Chen Yu",
      "Andre Rosendo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.08147"
  },
  {
    "id": "arXiv:2111.08148",
    "title": "Improved Bounds for Scheduling Flows under Endpoint Capacity Constraints",
    "abstract": "We study flow scheduling under node capacity constraints. We are given\ncapacitated nodes and an online sequence of jobs, each with a release time and\na demand to be routed between two nodes. A schedule specifies which jobs are\nrouted in each step, guaranteeing that the total demand on a node in any step\nis at most its capacity. A key metric in this scenario is response time: the\ntime between a job's release and its completion. Prior work shows no\nun-augmented algorithm is competitive for average response time, and that a\nconstant factor competitive ratio is achievable with augmentation exceeding 2\n(Dinitz-Moseley Infocom 2020). For maximum response time, the best known result\nis a 2-competitive algorithm with a augmentation 4 (Jahanjou et al SPAA 2020).\nWe improve these bounds under various response time objectives. We show that,\nwithout resource augmentation, the best competitive ratio for maximum response\ntime is $\\Omega(n)$, where $n$ is the number of nodes. Our Proportional\nAllocation algorithm uses $(1+\\varepsilon)$ resource augmentation to achieve a\n$(1/\\varepsilon)$-competitive ratio in the setting with general demands and\ncapacities, and splittable jobs. Our Batch Decomposition algorithm is\n$2$-competitive (resp., optimal) for maximum response time using resource\naugmentation 2 (resp., 4) in the setting with unit demands and capacities, and\nunsplittable jobs. We also derive bounds for the simultaneous approximation of\naverage and maximum response time metrics.",
    "descriptor": "",
    "authors": [
      "Searidang Pa",
      "Rajmohan Rajaraman",
      "David Stalfa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.08148"
  },
  {
    "id": "arXiv:2111.08154",
    "title": "On the utility of power spectral techniques with feature selection  techniques for effective mental task classification in noninvasive BCI",
    "abstract": "In this paper classification of mental task-root Brain-Computer Interfaces\n(BCI) is being investigated, as those are a dominant area of investigations in\nBCI and are of utmost interest as these systems can be augmented life of people\nhaving severe disabilities. The BCI model's performance is primarily dependent\non the size of the feature vector, which is obtained through multiple channels.\nIn the case of mental task classification, the availability of training samples\nto features are minimal. Very often, feature selection is used to increase the\nratio for the mental task classification by getting rid of irrelevant and\nsuperfluous features. This paper proposes an approach to select relevant and\nnon-redundant spectral features for the mental task classification. This can be\ndone by using four very known multivariate feature selection methods viz,\nBhattacharya's Distance, Ratio of Scatter Matrices, Linear Regression and\nMinimum Redundancy & Maximum Relevance. This work also deals with a comparative\nanalysis of multivariate and univariate feature selection for mental task\nclassification. After applying the above-stated method, the findings\ndemonstrate substantial improvements in the performance of the learning model\nfor mental task classification. Moreover, the efficacy of the proposed approach\nis endorsed by carrying out a robust ranking algorithm and Friedman's\nstatistical test for finding the best combinations and comparing different\ncombinations of power spectral density and feature selection methods.",
    "descriptor": "",
    "authors": [
      "Akshansh Gupta",
      "Ramesh Kumar Agrawal",
      "Jyoti Singh Kirar",
      "Javier Andreu-Perez",
      "Wei-Ping Ding",
      "Chin-Teng Lin",
      "Mukesh Prasad"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2111.08154"
  },
  {
    "id": "arXiv:2111.08156",
    "title": "Improving Learning from Demonstrations by Learning from Experience",
    "abstract": "How to make imitation learning more general when demonstrations are\nrelatively limited has been a persistent problem in reinforcement learning\n(RL). Poor demonstrations lead to narrow and biased date distribution,\nnon-Markovian human expert demonstration makes it difficult for the agent to\nlearn, and over-reliance on sub-optimal trajectories can make it hard for the\nagent to improve its performance. To solve these problems we propose a new\nalgorithm named TD3fG that can smoothly transition from learning from experts\nto learning from experience. Our algorithm achieves good performance in the\nMUJOCO environment with limited and sub-optimal demonstrations. We use behavior\ncloning to train the network as a reference action generator and utilize it in\nterms of both loss function and exploration noise. This innovation can help\nagents extract a priori knowledge from demonstrations while reducing the\ndetrimental effects of the poor Markovian properties of the demonstrations. It\nhas a better performance compared to the BC+ fine-tuning and DDPGfD approach,\nespecially when the demonstrations are relatively limited. We call our method\nTD3fG meaning TD3 from a generator.",
    "descriptor": "",
    "authors": [
      "Haofeng Liu",
      "Yiwen Chen",
      "Jiayi Tan",
      "Marcelo H Ang Jr"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08156"
  },
  {
    "id": "arXiv:2111.08159",
    "title": "Hybrid Beam Alignment for Multi-Path Channels: A Group Testing Viewpoint",
    "abstract": "Directional beams are key to enabling wireless communications at\nhigh-frequency bands such as millimeter-wave and terahertz. Beam alignment (BA)\nmethods allow the transceivers to adjust the directions of these beams in an\nefficient manner by exploiting the channel sparsity at high frequencies. This\npaper considers an uplink scenario consisting of a user equipment (UE) and a\nbase station (BS), where the channel between the UE and BS consists of multiple\npaths. The BS wishes to localize the angle of arrival of each of these paths\nwith a given resolution. At each time slot of the BA, the UE transmits a BA\npacket and the BS uses hybrid beamforming to scan its angular region. In order\nto minimize the expected BA duration, a group testing framework is devised, and\nthe associated novel analog and hybrid BA strategies are described. Simulation\nstudies suggest that the proposed schemes outperform the state-of-the-art\nmulti-path BA methods.",
    "descriptor": "",
    "authors": [
      "Ozlem Yildiz",
      "Abbas Khalili",
      "Elza Erkip"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.08159"
  },
  {
    "id": "arXiv:2111.08160",
    "title": "Implicit Method for Degenerated Differential-Algebraic Equations and  Applications",
    "abstract": "Systems of differential-algebraic equations are routinely automatically\nproduced by modeling enviroments such as Maplesim, System Modeler and Modelica.\nStructural methods are important for reducing the index and obtaining hidden\nconstraints of such daes. This is especially the case for high index non-linear\ndaes. Although such structural analysis is often successful for many dynamic\nsystems, it may fail if the resulting Jacobian is still singular due to\nsymbolic cancellation or numerical degeneration. Existing modified structural\nmethods can handle some cases caused by symbolic cancellation, where assumes\nthe determinant of a Jacobian matrix is identically zero. This paper removes\nsuch assumptions and provides numerical methods to analyze such degenerated\ncases using real algebraic geometry for polynomially nonlinear daes. Firstly,\nwe provide a witness point method, which produces witness points on all\ncomponents and can help to detect degeneration on all components of\npolynomially daes. Secondly, we propose an implicit index reduction method\nwhich can restore a full rank Jacobian matrix for degenerated dae. Thirdly,\nbased on IIR, we introduce an improved structural method, which can numerically\nsolve degenerated daes on all components. Examples are given to illustrate our\nmethods and show their advantages for degenerated daes.",
    "descriptor": "\nComments: 31 pages, 7 figures,4 tables\n",
    "authors": [
      "Wenqiang Yang",
      "Wenyuan Wu",
      "Greg Reid"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.08160"
  },
  {
    "id": "arXiv:2111.08162",
    "title": "On Bock's Conjecture Regarding the Adam Optimizer",
    "abstract": "In 2014, Kingma and Ba published their Adam optimizer algorithm, together\nwith a mathematical argument that was meant to help justify it. In 2018, Bock\nand colleagues reported that a key piece was missing from that argument $-$ an\nunproven lemma which we will call Bock's conjecture. Here we show that this\nconjecture is false, but a modified version of it does hold, and fills the gap\nin Bock's proof of convergence for Adam.",
    "descriptor": "",
    "authors": [
      "Mohamed Akrout",
      "Douglas Tweed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08162"
  },
  {
    "id": "arXiv:2111.08163",
    "title": "An Underexplored Dilemma between Confidence and Calibration in Quantized  Neural Networks",
    "abstract": "Modern convolutional neural networks (CNNs) are known to be overconfident in\nterms of their calibration on unseen input data. That is to say, they are more\nconfident than they are accurate. This is undesirable if the probabilities\npredicted are to be used for downstream decision making. When considering\naccuracy, CNNs are also surprisingly robust to compression techniques, such as\nquantization, which aim to reduce computational and memory costs. We show that\nthis robustness can be partially explained by the calibration behavior of\nmodern CNNs, and may be improved with overconfidence. This is due to an\nintuitive result: low confidence predictions are more likely to change\npost-quantization, whilst being less accurate. High confidence predictions will\nbe more accurate, but more difficult to change. Thus, a minimal drop in\npost-quantization accuracy is incurred. This presents a potential conflict in\nneural network design: worse calibration from overconfidence may lead to better\nrobustness to quantization. We perform experiments applying post-training\nquantization to a variety of CNNs, on the CIFAR-100 and ImageNet datasets.",
    "descriptor": "\nComments: Accepted at I (Still) Can't Believe It's Not Better Workshop at NeurIPS 2021\n",
    "authors": [
      "Guoxuan Xia",
      "Sangwon Ha",
      "Tiago Azevedo",
      "Partha Maji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08163"
  },
  {
    "id": "arXiv:2111.08164",
    "title": "A Survey on Neural-symbolic Systems",
    "abstract": "In recent years, neural systems have demonstrated superior perceptual\nintelligence through highly effective learning, but their reasoning\ncapabilities remain poor. In contrast, symbolic systems have exceptional\ncognitive intelligence through efficient reasoning, but their learning\ncapabilities are poor. In this case, an ideal intelligent system--a\nneural-symbolic system--with high perceptual and cognitive intelligence through\npowerful learning and reasoning capabilities gains a growing interest in the\nresearch community. Combining the fast computation ability of neural systems\nand the powerful expression ability of symbolic systems, neural-symbolic\nsystems can perform effective learning and reasoning in multi-domain tasks,\ndemonstrating concurrent perception and cognition capabilities in intelligent\nsystems. This paper surveys the latest research in neural-symbolic systems\nalong four dimensions: the necessity of combination, technical challenges,\nmethods, and applications. This paper aims to help advance this emerging area\nof research by providing researchers with a holistic and comprehensive view,\nhighlighting the state of art and identifying the opportunities.",
    "descriptor": "",
    "authors": [
      "Dongran Yu",
      "Bo Yang",
      "Dayou Liu",
      "Hui Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08164"
  },
  {
    "id": "arXiv:2111.08165",
    "title": "RapidRead: Global Deployment of State-of-the-art Radiology AI for a  Large Veterinary Teleradiology Practice",
    "abstract": "This work describes the development and real-world deployment of a deep\nlearning-based AI system for evaluating canine and feline radiographs across a\nbroad range of findings and abnormalities. We describe a new semi-supervised\nlearning approach that combines NLP-derived labels with self-supervised\ntraining leveraging more than 2.5 million x-ray images. Finally we describe the\nclinical deployment of the model including system architecture, real-time\nperformance evaluation and data drift detection.",
    "descriptor": "",
    "authors": [
      "Michael Fitzke",
      "Conrad Stack",
      "Andre Dourson",
      "Rodrigo M. B. Santana",
      "Diane Wilson",
      "Lisa Ziemer",
      "Arjun Soin",
      "Matthew P. Lungren",
      "Paul Fisher",
      "Mark Parkinson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.08165"
  },
  {
    "id": "arXiv:2111.08168",
    "title": "Explaining medical AI performance disparities across sites with  confounder Shapley value analysis",
    "abstract": "Medical AI algorithms can often experience degraded performance when\nevaluated on previously unseen sites. Addressing cross-site performance\ndisparities is key to ensuring that AI is equitable and effective when deployed\non diverse patient populations. Multi-site evaluations are key to diagnosing\nsuch disparities as they can test algorithms across a broader range of\npotential biases such as patient demographics, equipment types, and technical\nparameters. However, such tests do not explain why the model performs worse.\nOur framework provides a method for quantifying the marginal and cumulative\neffect of each type of bias on the overall performance difference when a model\nis evaluated on external data. We demonstrate its usefulness in a case study of\na deep learning model trained to detect the presence of pneumothorax, where our\nframework can help explain up to 60% of the discrepancy in performance across\ndifferent sites with known biases like disease comorbidities and imaging\nparameters.",
    "descriptor": "\nComments: Machine Learning for Health (ML4H) - Extended Abstract\n",
    "authors": [
      "Eric Wu",
      "Kevin Wu",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08168"
  },
  {
    "id": "arXiv:2111.08169",
    "title": "A Supervised Feature Selection Method For Mixed-Type Data using  Density-based Feature Clustering",
    "abstract": "Feature selection methods are widely used to address the high computational\noverheads and curse of dimensionality in classifying high-dimensional data.\nMost conventional feature selection methods focus on handling homogeneous\nfeatures, while real-world datasets usually have a mixture of continuous and\ndiscrete features. Some recent mixed-type feature selection studies only select\nfeatures with high relevance to class labels and ignore the redundancy among\nfeatures. The determination of an appropriate feature subset is also a\nchallenge. In this paper, a supervised feature selection method using\ndensity-based feature clustering (SFSDFC) is proposed to obtain an appropriate\nfinal feature subset for mixed-type data. SFSDFC decomposes the feature space\ninto a set of disjoint feature clusters using a novel density-based clustering\nmethod. Then, an effective feature selection strategy is employed to obtain a\nsubset of important features with minimal redundancy from those feature\nclusters. Extensive experiments as well as comparison studies with five\nstate-of-the-art methods are conducted on SFSDFC using thirteen real-world\nbenchmark datasets and results justify the efficacy of the SFSDFC method.",
    "descriptor": "\nComments: 6 pages, 3 figures, 4 tables, accepted by the IEEE SMC 2021\n",
    "authors": [
      "Xuyang Yan",
      "Mrinmoy Sarkar",
      "Biniam Gebru",
      "Shabnam Nazmi",
      "Abdollah Homaifar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08169"
  },
  {
    "id": "arXiv:2111.08171",
    "title": "Solving Linear Algebra by Program Synthesis",
    "abstract": "We solve MIT's Linear Algebra 18.06 course and Columbia University's\nComputational Linear Algebra COMS3251 courses with perfect accuracy by\ninteractive program synthesis. This surprisingly strong result is achieved by\nturning the course questions into programming tasks and then running the\nprograms to produce the correct answers. We use OpenAI Codex with zero-shot\nlearning, without providing any examples in the prompts, to synthesize code\nfrom questions. We quantify the difference between the original question text\nand the transformed question text that yields a correct answer. Since all\nCOMS3251 questions are not available online the model is not overfitting. We go\nbeyond just generating code for questions with numerical answers by\ninteractively generating code that also results visually pleasing plots as\noutput. Finally, we automatically generate new questions given a few sample\nquestions which may be used as new course content. This work is a significant\nstep forward in solving quantitative math problems and opens the door for\nsolving many university level STEM courses by machine.",
    "descriptor": "\nComments: 32 pages, 3 figures\n",
    "authors": [
      "Iddo Drori",
      "Nakul Verma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.08171"
  },
  {
    "id": "arXiv:2111.08172",
    "title": "Off-Policy Actor-Critic with Emphatic Weightings",
    "abstract": "A variety of theoretically-sound policy gradient algorithms exist for the\non-policy setting due to the policy gradient theorem, which provides a\nsimplified form for the gradient. The off-policy setting, however, has been\nless clear due to the existence of multiple objectives and the lack of an\nexplicit off-policy policy gradient theorem. In this work, we unify these\nobjectives into one off-policy objective, and provide a policy gradient theorem\nfor this unified objective. The derivation involves emphatic weightings and\ninterest functions. We show multiple strategies to approximate the gradients,\nin an algorithm called Actor Critic with Emphatic weightings (ACE). We prove in\na counterexample that previous (semi-gradient) off-policy actor-critic\nmethods--particularly OffPAC and DPG--converge to the wrong solution whereas\nACE finds the optimal solution. We also highlight why these semi-gradient\napproaches can still perform well in practice, suggesting strategies for\nvariance reduction in ACE. We empirically study several variants of ACE on two\nclassic control environments and an image-based environment designed to\nillustrate the tradeoffs made by each gradient approximation. We find that by\napproximating the emphatic weightings directly, ACE performs as well as or\nbetter than OffPAC in all settings tested.",
    "descriptor": "",
    "authors": [
      "Eric Graves",
      "Ehsan Imani",
      "Raksha Kumaraswamy",
      "Martha White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08172"
  },
  {
    "id": "arXiv:2111.08174",
    "title": "ShapeY: Measuring Shape Recognition Capacity Using Nearest Neighbor  Matching",
    "abstract": "Object recognition in humans depends primarily on shape cues. We have\ndeveloped a new approach to measuring the shape recognition performance of a\nvision system based on nearest neighbor view matching within the system's\nembedding space. Our performance benchmark, ShapeY, allows for precise control\nof task difficulty, by enforcing that view matching span a specified degree of\n3D viewpoint change and/or appearance change. As a first test case we measured\nthe performance of ResNet50 pre-trained on ImageNet. Matching error rates were\nhigh. For example, a 27 degree change in object pitch led ResNet50 to match the\nincorrect object 45% of the time. Appearance changes were also highly\ndisruptive. Examination of false matches indicates that ResNet50's embedding\nspace is severely \"tangled\". These findings suggest ShapeY can be a useful tool\nfor charting the progress of artificial vision systems towards human-level\nshape recognition capabilities.",
    "descriptor": "\nComments: 6 pages, 5 figures, Accepted to NeurIPS: ImageNet Past, Present, and Future\n",
    "authors": [
      "Jong Woo Nam",
      "Amanda S. Rios",
      "Bartlett W. Mel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08174"
  },
  {
    "id": "arXiv:2111.08175",
    "title": "Inverse-Weighted Survival Games",
    "abstract": "Deep models trained through maximum likelihood have achieved state-of-the-art\nresults for survival analysis. Despite this training scheme, practitioners\nevaluate models under other criteria, such as binary classification losses at a\nchosen set of time horizons, e.g. Brier score (BS) and Bernoulli log likelihood\n(BLL). Models trained with maximum likelihood may have poor BS or BLL since\nmaximum likelihood does not directly optimize these criteria. Directly\noptimizing criteria like BS requires inverse-weighting by the censoring\ndistribution, estimation of which itself also requires inverse-weighted by the\nfailure distribution. But neither are known. To resolve this dilemma, we\nintroduce Inverse-Weighted Survival Games to train both failure and censoring\nmodels with respect to criteria such as BS or BLL. In these games, objectives\nfor each model are built from re-weighted estimates featuring the other model,\nwhere the re-weighting model is held fixed during training. When the loss is\nproper, we show that the games always have the true failure and censoring\ndistributions as a stationary point. This means models in the game do not leave\nthe correct distributions once reached. We construct one case where this\nstationary point is unique. We show that these games optimize BS on simulations\nand then apply these principles on real world cancer and critically-ill patient\ndata.",
    "descriptor": "\nComments: Neurips 2021\n",
    "authors": [
      "Xintian Han",
      "Mark Goldstein",
      "Aahlad Puli",
      "Thomas Wies",
      "Adler J Perotte",
      "Rajesh Ranganath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08175"
  },
  {
    "id": "arXiv:2111.08176",
    "title": "Coarse-to-fine Animal Pose and Shape Estimation",
    "abstract": "Most existing animal pose and shape estimation approaches reconstruct animal\nmeshes with a parametric SMAL model. This is because the low-dimensional pose\nand shape parameters of the SMAL model makes it easier for deep networks to\nlearn the high-dimensional animal meshes. However, the SMAL model is learned\nfrom scans of toy animals with limited pose and shape variations, and thus may\nnot be able to represent highly varying real animals well. This may result in\npoor fittings of the estimated meshes to the 2D evidences, e.g. 2D keypoints or\nsilhouettes. To mitigate this problem, we propose a coarse-to-fine approach to\nreconstruct 3D animal mesh from a single image. The coarse estimation stage\nfirst estimates the pose, shape and translation parameters of the SMAL model.\nThe estimated meshes are then used as a starting point by a graph convolutional\nnetwork (GCN) to predict a per-vertex deformation in the refinement stage. This\ncombination of SMAL-based and vertex-based representations benefits from both\nparametric and non-parametric representations. We design our mesh refinement\nGCN (MRGCN) as an encoder-decoder structure with hierarchical feature\nrepresentations to overcome the limited receptive field of traditional GCNs.\nMoreover, we observe that the global image feature used by existing animal mesh\nreconstruction works is unable to capture detailed shape information for mesh\nrefinement. We thus introduce a local feature extractor to retrieve a\nvertex-level feature and use it together with the global feature as the input\nof the MRGCN. We test our approach on the StanfordExtra dataset and achieve\nstate-of-the-art results. Furthermore, we test the generalization capacity of\nour approach on the Animal Pose and BADJA datasets. Our code is available at\nthe project website.",
    "descriptor": "\nComments: Accepted by Neurips2021\n",
    "authors": [
      "Chen Li",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08176"
  },
  {
    "id": "arXiv:2111.08181",
    "title": "Adversarially Constructed Evaluation Sets Are More Challenging, but May  Not Be Fair",
    "abstract": "More capable language models increasingly saturate existing task benchmarks,\nin some cases outperforming humans. This has left little headroom with which to\nmeasure further progress. Adversarial dataset creation has been proposed as a\nstrategy to construct more challenging datasets, and two common approaches are:\n(1) filtering out easy examples and (2) model-in-the-loop data collection. In\nthis work, we study the impact of applying each approach to create more\nchallenging evaluation datasets. We adapt the AFLite algorithm to filter\nevaluation data, and run experiments against 18 different adversary models. We\nfind that AFLite indeed selects more challenging examples, lowering the\nperformance of evaluated models more as stronger adversary models are used.\nHowever, the resulting ranking of models can also be unstable and highly\nsensitive to the choice of adversary model used. Moreover, AFLite oversamples\nexamples with low annotator agreement, meaning that model comparisons hinge on\nthe most contentiously labeled examples. Smaller-scale experiments on the\nadversarially collected datasets ANLI and AdversarialQA show similar findings,\nbroadly lowering performance with stronger adversaries while disproportionately\naffecting the adversary model.",
    "descriptor": "",
    "authors": [
      "Jason Phang",
      "Angelica Chen",
      "William Huang",
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.08181"
  },
  {
    "id": "arXiv:2111.08184",
    "title": "$AIR^2$ for Interaction Prediction",
    "abstract": "The 2021 Waymo Interaction Prediction Challenge introduced a problem of\npredicting the future trajectories and confidences of two interacting agents\njointly. We developed a solution that takes an anchored marginal motion\nprediction model with rasterization and augments it to model agent interaction.\nWe do this by predicting the joint confidences using a rasterized image that\nhighlights the ego agent and the interacting agent. Our solution operates on\nthe cartesian product space of the anchors; hence the $\"^2\"$ in $AIR^2$. Our\nmodel achieved the highest mAP (the primary metric) on the leaderboard.",
    "descriptor": "",
    "authors": [
      "David Wu",
      "Yunnan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08184"
  },
  {
    "id": "arXiv:2111.08185",
    "title": "Graph neural network-based fault diagnosis: a review",
    "abstract": "Graph neural network (GNN)-based fault diagnosis (FD) has received increasing\nattention in recent years, due to the fact that data coming from several\napplication domains can be advantageously represented as graphs. Indeed, this\nparticular representation form has led to superior performance compared to\ntraditional FD approaches. In this review, an easy introduction to GNN,\npotential applications to the field of fault diagnosis, and future perspectives\nare given. First, the paper reviews neural network-based FD methods by focusing\non their data representations, namely, time-series, images, and graphs. Second,\nbasic principles and principal architectures of GNN are introduced, with\nattention to graph convolutional networks, graph attention networks, graph\nsample and aggregate, graph auto-encoder, and spatial-temporal graph\nconvolutional networks. Third, the most relevant fault diagnosis methods based\non GNN are validated through the detailed experiments, and conclusions are made\nthat the GNN-based methods can achieve good fault diagnosis performance.\nFinally, discussions and future challenges are provided.",
    "descriptor": "\nComments: 17 pages, 18 figures, 10 tables\n",
    "authors": [
      "Zhiwen Chen",
      "Jiamin Xu",
      "Cesare Alippi",
      "Steven X. Ding",
      "Yuri Shardt",
      "Tao Peng",
      "Chunhua Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08185"
  },
  {
    "id": "arXiv:2111.08189",
    "title": "Soft Delivery: Survey on A New Paradigm for Wireless and Mobile  Multimedia Streaming",
    "abstract": "The increasing demand for video streaming services is the key driver of\nmodern wireless and mobile communications. For robust and high-quality delivery\nof video content over wireless and mobile networks, the main challenge is\nsending image and video signals to single and multiple users over unstable and\ndiverse channel environments. To this end, many studies have designed\ndigital-based video delivery schemes, which mainly consist of a sequence of\ndigital-based coding and transmission schemes. Although digital-based schemes\nperform well when the channel characteristics are known in advance, significant\nquality degradation, known as cliff and leveling effects, often occurs owing to\nthe fluctuating channel characteristics. To prevent cliff and leveling effects\nirrespective of the channel characteristics of each user, a new paradigm for\nwireless and mobile video streaming has been proposed. Soft delivery schemes\nskip the digital operations of quantization and entropy and channel coding\nwhile directly mapping the power-assigned frequency--domain coefficients onto\nthe transmission symbols. This modification is based on the fact that the pixel\ndistortion due to communication noise is proportional to the magnitude of the\nnoise, resulting in graceful quality improvement, wherein quality is improved\ngradually, according to the wireless channel quality without any cliff and\nleveling effects. Herein, we present a comprehensive summary of soft delivery\nschemes.",
    "descriptor": "",
    "authors": [
      "Takuya Fujihashi",
      "Toshiaki Koike-Akino",
      "Takashi Watanabe"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.08189"
  },
  {
    "id": "arXiv:2111.08190",
    "title": "Learning Augmentation Distributions using Transformed Risk Minimization",
    "abstract": "Adapting to the structure of data distributions (such as symmetry and\ntransformation invariances) is an important challenge in machine learning.\nInvariances can be built into the learning process by architecture design, or\nby augmenting the dataset. Both require a priori knowledge about the exact\nnature of the symmetries. Absent this knowledge, practitioners resort to\nexpensive and time-consuming tuning. To address this problem, we propose a new\napproach to learn distributions of augmentation transforms, in a new\n\\emph{Transformed Risk Minimization} (TRM) framework. In addition to predictive\nmodels, we also optimize over transformations chosen from a hypothesis space.\nAs an algorithmic framework, our TRM method is (1) efficient (jointly learns\naugmentations and models in a \\emph{single training loop}), (2) modular (works\nwith \\emph{any} training algorithm), and (3) general (handles \\emph{both\ndiscrete and continuous} augmentations). We theoretically compare TRM with\nstandard risk minimization, and give a PAC-Bayes upper bound on its\ngeneralization error. We propose to optimize this bound over a rich\naugmentation space via a new parametrization over compositions of blocks,\nleading to the new \\emph{Stochastic Compositional Augmentation Learning}\n(SCALE) algorithm. We compare SCALE experimentally with prior methods (Fast\nAutoAugment and Augerino) on CIFAR10/100, SVHN . Additionally, we show that\nSCALE can correctly learn certain symmetries in the data distribution\n(recovering rotations on rotated MNIST) and can also improve calibration of the\nlearned model.",
    "descriptor": "",
    "authors": [
      "Evangelos Chatzipantazis",
      "Stefanos Pertigkiozoglou",
      "Edgar Dobriban",
      "Kostas Daniilidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08190"
  },
  {
    "id": "arXiv:2111.08191",
    "title": "CCA-MDD: A Coupled Cross-Attention based Framework for Streaming  Mispronunciation detection and diagnosis",
    "abstract": "End-to-end models are becoming popular approaches for mispronunciation\ndetection and diagnosis (MDD). A streaming MDD framework which is demanded by\nmany practical applications still remains a challenge. This paper proposes a\nstreaming end-to-end MDD framework called CCA-MDD. CCA-MDD supports online\nprocessing and is able to run strictly in real-time. The encoder of CCA-MDD\nconsists of a conv-Transformer network based streaming acoustic encoder and an\nimproved cross-attention named coupled cross-attention (CCA). The coupled\ncross-attention integrates encoded acoustic features with pre-encoded\nlinguistic features. An ensemble of decoders trained from multi-task learning\nis applied for final MDD decision. Experiments on publicly available corpora\ndemonstrate that CCA-MDD achieves comparable performance to published offline\nend-to-end MDD models.",
    "descriptor": "\nComments: 5pages, 4 figures, submitted to ICASSP2022\n",
    "authors": [
      "Nianzu Zheng",
      "Liqun Deng",
      "Wenyong Huang",
      "Yu Ting Yeung",
      "Baohua Xu",
      "Yuanyuan Guo",
      "Yasheng Wang",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.08191"
  },
  {
    "id": "arXiv:2111.08193",
    "title": "HyperNAT: Scaling Up Network AddressTranslation with SmartNICs for  Clouds",
    "abstract": "Network address translation (NAT) is a basic functionality in cloud gateways.\nWith the increasing traffic volume and number of flows introduced by the cloud\ntenants, the NAT gateway needs to be implemented on a cluster of servers. We\npropose to scale up the gateway servers, which could reduce the number of\nservers so as to reduce the capital expense and operation expense. We design\nHyperNAT, which leverages smartNICs to improve the server's processing\ncapacity. In HyperNAT, the NAT functionality is distributed on multiple NICs,\nand the flow space is divided and assigned accordingly. HyperNAT overcomes the\nchallenge that the packets in two directions of one connection need to be\nprocessed by the same NAT rule (named two-direction consistency, TDC) by\ncloning the rule to both data paths of the two directions. Our implementation\nand evaluation of HyperNAT show that HyperNAT could scale up cloud gateway\neffectively with low overhead.",
    "descriptor": "\nComments: 6 pages, it has been accepted at Globecom 2021\n",
    "authors": [
      "Shaoke Fang",
      "Qingsong Liu",
      "Wenfei Wu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.08193"
  },
  {
    "id": "arXiv:2111.08195",
    "title": "MoRe-Fi: Motion-robust and Fine-grained Respiration Monitoring via  Deep-Learning UWB Radar",
    "abstract": "Crucial for healthcare and biomedical applications, respiration monitoring\noften employs wearable sensors in practice, causing inconvenience due to their\ndirect contact with human bodies. Therefore, researchers have been constantly\nsearching for contact-free alternatives. Nonetheless, existing contact-free\ndesigns mostly require human subjects to remain static, largely confining their\nadoptions in everyday environments where body movements are inevitable.\nFortunately, radio-frequency (RF) enabled contact-free sensing, though\nsuffering motion interference inseparable by conventional filtering, may offer\na potential to distill respiratory waveform with the help of deep learning. To\nrealize this potential, we introduce MoRe-Fi to conduct fine-grained\nrespiration monitoring under body movements. MoRe-Fi leverages an IR-UWB radar\nto achieve contact-free sensing, and it fully exploits the complex radar signal\nfor data augmentation. The core of MoRe-Fi is a novel variational\nencoder-decoder network; it aims to single out the respiratory waveforms that\nare modulated by body movements in a non-linear manner. Our experiments with 12\nsubjects and 66-hour data demonstrate that MoRe-Fi accurately recovers\nrespiratory waveform despite the interference caused by body movements. We also\ndiscuss potential applications of MoRe-Fi for pulmonary disease diagnoses.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Tianyue Zheng",
      "Zhe Chen",
      "Shujie Zhang",
      "Chao Cai",
      "Jun Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08195"
  },
  {
    "id": "arXiv:2111.08196",
    "title": "An Exploratory Study on Perceptual Spaces of the Singing Voice",
    "abstract": "Sixty participants provided dissimilarity ratings between various singing\ntechniques. Multidimensional scaling, class averaging and clustering techniques\nwere used to analyse timbral spaces and how they change between different\nsingers, genders and registers. Clustering analysis showed that ground-truth\nsimilarity and silhouette scores that were not significantly different between\ngender or register conditions, while similarity scores were positively\ncorrelated with participants' instrumental abilities and task comprehension.\nParticipant feedback showed how a revised study design might mitigate noise in\nour data, leading to more detailed statistical results. Timbre maps and class\ndistance analysis showed us which singing techniques remained similar to one\nanother across gender and register conditions. This research provides insight\ninto how the timbre space of singing changes under different conditions,\nhighlights the subjectivity of perception between participants, and provides\ngeneralised timbre maps for regularisation in machine learning.",
    "descriptor": "\nComments: In Proceedings of the 2020 Joint Conference on AI Music Creativity (CSMC-MuMe 2020), Stockholm, Sweden, October 15-19, 2020\n",
    "authors": [
      "Brendan O'Connor",
      "Simon Dixon",
      "George Fazekas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.08196"
  },
  {
    "id": "arXiv:2111.08198",
    "title": "Weak convergence rates for a full implicit scheme of stochastic  Cahn-Hilliard equation with additive noise",
    "abstract": "The aim of this study is the weak convergence rate of a temporal and spatial\ndiscretization scheme for stochastic Cahn-Hilliard equation with additive\nnoise, where the spectral Galerkin method is used in space and the backward\nEuler scheme is used in time. The presence of the unbounded operator in front\nof the nonlinear term and the lack of the associated Kolmogorov equations make\nthe error analysis much more challenging and demanding. To overcome these\ndifficulties, we further exploit a novel approach proposed in [7] and combine\nit with Malliavin calculus to obtain an improved weak rate of convergence, in\ncomparison with the corresponding strong convergence rates. The techniques used\nhere are quite general and hence have the potential to be applied to other\nnon-Markovian equations. As a byproduct the rate of the strong error can also\nbe easily obtained.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Meng Cai",
      "Siqing Gan",
      "Yaozhong Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.08198"
  },
  {
    "id": "arXiv:2111.08202",
    "title": "Learn Locally, Correct Globally: A Distributed Algorithm for Training  Graph Neural Networks",
    "abstract": "Despite the recent success of Graph Neural Networks (GNNs), training GNNs on\nlarge graphs remains challenging. The limited resource capacities of the\nexisting servers, the dependency between nodes in a graph, and the privacy\nconcern due to the centralized storage and model learning have spurred the need\nto design an effective distributed algorithm for GNN training. However,\nexisting distributed GNN training methods impose either excessive communication\ncosts or large memory overheads that hinders their scalability. To overcome\nthese issues, we propose a communication-efficient distributed GNN training\ntechnique named $\\text{{Learn Locally, Correct Globally}}$ (LLCG). To reduce\nthe communication and memory overhead, each local machine in LLCG first trains\na GNN on its local data by ignoring the dependency between nodes among\ndifferent machines, then sends the locally trained model to the server for\nperiodic model averaging. However, ignoring node dependency could result in\nsignificant performance degradation. To solve the performance degradation, we\npropose to apply $\\text{{Global Server Corrections}}$ on the server to refine\nthe locally learned models. We rigorously analyze the convergence of\ndistributed methods with periodic model averaging for training GNNs and show\nthat naively applying periodic model averaging but ignoring the dependency\nbetween nodes will suffer from an irreducible residual error. However, this\nresidual error can be eliminated by utilizing the proposed global corrections\nto entail fast convergence rate. Extensive experiments on real-world datasets\nshow that LLCG can significantly improve the efficiency without hurting the\nperformance.",
    "descriptor": "",
    "authors": [
      "Morteza Ramezani",
      "Weilin Cong",
      "Mehrdad Mahdavi",
      "Mahmut T. Kandemir",
      "Anand Sivasubramaniam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08202"
  },
  {
    "id": "arXiv:2111.08203",
    "title": "Is CADP an Applicable Formal Method?",
    "abstract": "CADP is a comprehensive toolbox implementing results of concurrency theory.\nThis paper addresses the question, whether CADP qualifies as an applicable\nformal method, based on the experience of the authors and feedback reported by\nusers.",
    "descriptor": "\nComments: In Proceedings AppFM 2021, arXiv:2111.07538\n",
    "authors": [
      "Hubert Garavel",
      "Fr\u00e9d\u00e9ric Lang",
      "Radu Mateescu",
      "Wendelin Serwe"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.08203"
  },
  {
    "id": "arXiv:2111.08204",
    "title": "Developing a Prototype of a Mechanical Ventilator Controller from  Requirements to Code with ASMETA",
    "abstract": "Rigorous development processes aim to be effective in developing critical\nsystems, especially if failures can have catastrophic consequences for humans\nand the environment. Such processes generally rely on formal methods, which can\nguarantee, thanks to their mathematical foundation, model preciseness, and\nproperties assurance. However, they are rarely adopted in practice. In this\npaper, we report our experience in using the Abstract State Machine formal\nmethod and the ASMETA framework in developing a prototype of the control\nsoftware of the MVM (Mechanical Ventilator Milano), a mechanical lung\nventilator that has been designed, successfully certified, and deployed during\nthe COVID-19 pandemic. Due to time constraints and lack of skills, no formal\nmethod was applied for the MVM project. However, we here want to assess the\nfeasibility of developing (part of) the ventilator by using a formal\nmethod-based approach. Our development process starts from a high-level formal\nspecification of the system to describe the MVM main operation modes. Then,\nthrough a sequence of refined models, all the other requirements are captured,\nup to a level in which a C++ implementation of a prototype of the MVM\ncontroller is automatically generated from the model, and tested. Along the\nprocess, at each refinement level, different model validation and verification\nactivities are performed, and each refined model is proved to be a correct\nrefinement of the previous level. By means of the MVM case study, we evaluate\nthe effectiveness and usability of our formal approach.",
    "descriptor": "\nComments: In Proceedings AppFM 2021, arXiv:2111.07538\n",
    "authors": [
      "Andrea Bombarda",
      "Silvia Bonfanti",
      "Angelo Gargantini",
      "Elvinia Riccobene"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.08204"
  },
  {
    "id": "arXiv:2111.08205",
    "title": "A Maude Implementation of Rewritable Petri Nets: a Feasible Model for  Dynamically Reconfigurable Systems",
    "abstract": "Petri Nets (PN) are a central, theoretically sound model for concurrent or\ndistributed systems but, at least in their classical definition, not expressive\nenough to represent dynamic reconfiguration capabilities. On the other side,\nRewriting Logic has proved to be a natural semantic framework for several\nformal models of concurrent/distributed systems. We propose a compact,\nefficient Maude formalization of dynamically reconfigurable PT nets (with\ninhibitor arcs), using as a running example the specification of a simple,\nfault-tolerant manufacturing system. We discuss the advantages of such a\ncombined approach, as well as some concerns that it raises.",
    "descriptor": "\nComments: In Proceedings AppFM 2021, arXiv:2111.07538\n",
    "authors": [
      "Lorenzo Capra"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.08205"
  },
  {
    "id": "arXiv:2111.08206",
    "title": "JMSNAS: Joint Model Split and Neural Architecture Search for Learning  over Mobile Edge Networks",
    "abstract": "The main challenge to deploy deep neural network (DNN) over a mobile edge\nnetwork is how to split the DNN model so as to match the network architecture\nas well as all the nodes' computation and communication capacity. This\nessentially involves two highly coupled procedures: model generating and model\nsplitting. In this paper, a joint model split and neural architecture search\n(JMSNAS) framework is proposed to automatically generate and deploy a DNN model\nover a mobile edge network. Considering both the computing and communication\nresource constraints, a computational graph search problem is formulated to\nfind the multi-split points of the DNN model, and then the model is trained to\nmeet some accuracy requirements. Moreover, the trade-off between model accuracy\nand completion latency is achieved through the proper design of the objective\nfunction. The experiment results confirm the superiority of the proposed\nframework over the state-of-the-art split machine learning design methods.",
    "descriptor": "\nComments: 6 pages, 6 figures, Submitted to IEEE ICC'22 - CRAIN Symposium\n",
    "authors": [
      "Yuqing Tian",
      "Zhaoyang Zhang",
      "Zhaohui Yang",
      "Qianqian Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.08206"
  },
  {
    "id": "arXiv:2111.08207",
    "title": "F-IDEs with Features and VCs Designed to Assist Human Reasoning When  Verification Fails",
    "abstract": "This paper summarizes our efforts to aid human reasoning when verification\nfails through the use of two distinct Formalization Integrated Development\nEnvironments (F-IDEs) that we have developed. Both environments are modular and\nfacilitate reasoning about the full behavior of object-based code. The first\nenvironment, referred to as the web-IDE, has been used for several years to\nteach aspects of formal specification and verification, including why and where\nverification conditions (VCs) arise and how to use them when verification\nfails. The second F-IDE, RESOLVE Studio, remains experimental, but is a more\nfully-fledged environment backed by a sequent-based VC generator that produces\nVCs with fewer extraneous givens. While the environments and VC generation\ntechniques are necessarily language specific, the principles of alternative VC\ngeneration methods, F-IDE features, and observations about their impact on\nnovices and experienced users are more generally applicable.",
    "descriptor": "\nComments: In Proceedings AppFM 2021, arXiv:2111.07538\n",
    "authors": [
      "Yu-Shan Sun",
      "Daniel Welch",
      "Murali Sitaraman"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.08207"
  },
  {
    "id": "arXiv:2111.08208",
    "title": "Experience Report: Teaching Code Analysis and Verification Using Frama-C",
    "abstract": "Formal methods provide systematic and rigorous techniques for software\ndevelopment. We strongly believe that they must be taught in computer science\ncurricula. In this paper we present the pedagogic rationale and the concrete\nimplementation of two courses on the use of formal methods, sharing some\nmaterial. These courses promote the usage of formal verification to ensure\nsafety and security of software, exemplified in the domain of the Internet of\nThings.",
    "descriptor": "\nComments: In Proceedings AppFM 2021, arXiv:2111.07538\n",
    "authors": [
      "Salwa Souaf",
      "Fr\u00e9d\u00e9ric Loulergue"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.08208"
  },
  {
    "id": "arXiv:2111.08209",
    "title": "Exploring Usable Security to Improve the Impact of Formal Verification:  A Research Agenda",
    "abstract": "As software becomes more complex and assumes an even greater role in our\nlives, formal verification is set to become the gold standard in securing\nsoftware systems into the future, since it can guarantee the absence of errors\nand entire classes of attack. Recent advances in formal verification are being\nused to secure everything from unmanned drones to the internet.\nAt the same time, the usable security research community has made huge\nprogress in improving the usability of security products and end-users\ncomprehension of security issues. However, there have been no human-centered\nstudies focused on the impact of formal verification on the use and adoption of\nformally verified software products. We propose a research agenda to fill this\ngap and to contribute with the first collection of studies on people's mental\nmodels on formal verification and associated security and privacy guarantees\nand threats. The proposed research has the potential to increase the adoption\nof more secure products and it can be directly used by the security and formal\nmethods communities to create more effective and secure software tools.",
    "descriptor": "\nComments: In Proceedings AppFM 2021, arXiv:2111.07538\n",
    "authors": [
      "Carolina Carreira",
      "Jo\u00e3o F. Ferreira",
      "Alexandra Mendes",
      "Nicolas Christin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.08209"
  },
  {
    "id": "arXiv:2111.08210",
    "title": "Meeting Summarization with Pre-training and Clustering Methods",
    "abstract": "Automatic meeting summarization is becoming increasingly popular these days.\nThe ability to automatically summarize meetings and to extract key information\ncould greatly increase the efficiency of our work and life. In this paper, we\nexperiment with different approaches to improve the performance of query-based\nmeeting summarization. We started with HMNet\\cite{hmnet}, a hierarchical\nnetwork that employs both a word-level transformer and a turn-level\ntransformer, as the baseline. We explore the effectiveness of pre-training the\nmodel with a large news-summarization dataset. We investigate adding the\nembeddings of queries as a part of the input vectors for query-based\nsummarization. Furthermore, we experiment with extending the\nlocate-then-summarize approach of QMSum\\cite{qmsum} with an intermediate\nclustering step. Lastly, we compare the performance of our baseline models with\nBART, a state-of-the-art language model that is effective for summarization. We\nachieved improved performance by adding query embeddings to the input of the\nmodel, by using BART as an alternative language model, and by using clustering\nmethods to extract key information at utterance level before feeding the text\ninto summarization models.",
    "descriptor": "",
    "authors": [
      "Andras Huebner",
      "Wei Ji",
      "Xiang Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.08210"
  },
  {
    "id": "arXiv:2111.08211",
    "title": "FedCG: Leverage Conditional GAN for Protecting Privacy and Maintaining  Competitive Performance in Federated Learning",
    "abstract": "Federated learning (FL) aims to protect data privacy by enabling clients to\ncollaboratively build machine learning models without sharing their private\ndata. However, recent works demonstrate that FL is vulnerable to gradient-based\ndata recovery attacks. Varieties of privacy-preserving technologies have been\nleveraged to further enhance the privacy of FL. Nonetheless, they either are\ncomputational or communication expensive (e.g., homomorphic encryption) or\nsuffer from precision loss (e.g., differential privacy). In this work, we\npropose \\textsc{FedCG}, a novel \\underline{fed}erated learning method that\nleverages \\underline{c}onditional \\underline{g}enerative adversarial networks\nto achieve high-level privacy protection while still maintaining competitive\nmodel performance. More specifically, \\textsc{FedCG} decomposes each client's\nlocal network into a private extractor and a public classifier and keeps the\nextractor local to protect privacy. Instead of exposing extractors which is the\nculprit of privacy leakage, \\textsc{FedCG} shares clients' generators with the\nserver for aggregating common knowledge aiming to enhance the performance of\nclients' local networks. Extensive experiments demonstrate that \\textsc{FedCG}\ncan achieve competitive model performance compared with baseline FL methods,\nand numerical privacy analysis shows that \\textsc{FedCG} has high-level\nprivacy-preserving capability.",
    "descriptor": "",
    "authors": [
      "Yuezhou Wu",
      "Yan Kang",
      "Jiahuan Luo",
      "Yuanqin He",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08211"
  },
  {
    "id": "arXiv:2111.08214",
    "title": "Exploring Augmented Reality Games in Accessible Learning: A Systematic  Review",
    "abstract": "Augmented Reality (AR) learning games, on average, have been shown to have a\npositive impact on student learning. However, the exploration of AR learning\ngames in special education settings, where accessibility is a concern, has not\nbeen well explored. Thus, the purpose of this study is to explore the use of AR\ngames in accessible learning applications and to provide a comprehensive\nunderstanding of its advantages over traditional learning approaches. In this\npaper, we present our systematic review of previous studies included in major\ndatabases in the past decade. We explored the characteristics of user\nevaluation, learning effects on students, and features of implemented systems\nmentioned in the literature. The results showed that AR game applications can\npromote students learning activities from three perspectives: cognitive,\naffective, and retention. We also found there were still several drawbacks to\ncurrent AR learning game designs for special needs despite the positive effects\nassociated with AR game use. Based on our findings, we propose potential design\nstrategies for future AR learning games for accessible education.",
    "descriptor": "\nComments: ACM CHI2021 Workshop - Adaptive Accessible AR/VR Systems\n",
    "authors": [
      "Minghao Cai",
      "Gokce Akcayir",
      "Carrie Demmans Epp"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.08214"
  },
  {
    "id": "arXiv:2111.08217",
    "title": "NatiDroid: Cross-Language Android Permission Specification",
    "abstract": "The Android system manages access to sensitive APIs by permission\nenforcement. An application (app) must declare proper permissions before\ninvoking specific Android APIs. However, there is no official documentation\nproviding the complete list of permission-protected APIs and the corresponding\npermissions to date. Researchers have spent significant efforts extracting such\nAPI protection mapping from the Android API framework, which leverages static\ncode analysis to determine if specific permissions are required before\naccessing an API. Nevertheless, none of them has attempted to analyze the\nprotection mapping in the native library (i.e., code written in C and C++), an\nessential component of the Android framework that handles communication with\nthe lower-level hardware, such as cameras and sensors. While the protection\nmapping can be utilized to detect various security vulnerabilities in Android\napps, such as permission over-privilege and component hijacking, imprecise\nmapping will lead to false results in detecting such security vulnerabilities.\nTo fill this gap, we develop a prototype system, named NatiDroid, to facilitate\nthe cross-language static analysis to benchmark against two state-of-the-art\ntools, termed Axplorer and Arcade. We evaluate NatiDroid on more than 11,000\nAndroid apps, including system apps from custom Android ROMs and third-party\napps from the Google Play. Our NatiDroid can identify up to 464 new\nAPI-permission mappings, in contrast to the worst-case results derived from\nboth Axplorer and Arcade, where approximately 71% apps have at least one false\npositive in permission over-privilege and up to 3.6% apps have at least one\nfalse negative in component hijacking. Additionally, we identify that 24\ncomponents with at least one Native-triggered component hijacking vulnerability\nare misidentified by two benchmarks.",
    "descriptor": "",
    "authors": [
      "Chaoran Li",
      "Xiao Chen",
      "Ruoxi Sun",
      "Jason Xue",
      "Sheng Wen",
      "Muhammad Ejaz Ahmed",
      "Seyit Camtepe",
      "Yang Xiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.08217"
  },
  {
    "id": "arXiv:2111.08221",
    "title": "Fairness-aware Online Price Discrimination with Nonparametric Demand  Models",
    "abstract": "Price discrimination, which refers to the strategy of setting different\nprices for different customer groups, has been widely used in online retailing.\nAlthough it helps boost the collected revenue for online retailers, it might\ncreate serious concern in fairness, which even violates the regulation and law.\nThis paper studies the problem of dynamic discriminatory pricing under fairness\nconstraints. In particular, we consider a finite selling horizon of length $T$\nfor a single product with two groups of customers. Each group of customers has\nits unknown demand function that needs to be learned. For each selling period,\nthe seller determines the price for each group and observes their purchase\nbehavior. While existing literature mainly focuses on maximizing revenue,\nensuring fairness among different customers has not been fully explored in the\ndynamic pricing literature. In this work, we adopt the fairness notion from\n(Cohen et al. 2021a). For price fairness, we propose an optimal dynamic pricing\npolicy in terms of regret, which enforces the strict price fairness constraint.\nIn contrast to the standard $\\sqrt{T}$-type regret in online learning, we show\nthat the optimal regret in our case is $\\tilde{\\Theta}(T^{4/5})$. We further\nextend our algorithm to a more general notion of fairness, which includes\ndemand fairness as a special case. To handle this general class, we propose a\nsoft fairness constraint and develop the dynamic pricing policy that achieves\n$\\tilde{O}(T^{4/5})$ regret.",
    "descriptor": "\nComments: 33pages, 6 figures\n",
    "authors": [
      "Xi Chen",
      "Xuan Zhang",
      "Yuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08221"
  },
  {
    "id": "arXiv:2111.08222",
    "title": "Will We Trust What We Don't Understand? Impact of Model Interpretability  and Outcome Feedback on Trust in AI",
    "abstract": "Despite AI's superhuman performance in a variety of domains, humans are often\nunwilling to adopt AI systems. The lack of interpretability inherent in many\nmodern AI techniques is believed to be hurting their adoption, as users may not\ntrust systems whose decision processes they do not understand. We investigate\nthis proposition with a novel experiment in which we use an interactive\nprediction task to analyze the impact of interpretability and outcome feedback\non trust in AI and on human performance in AI-assisted prediction tasks. We\nfind that interpretability led to no robust improvements in trust, while\noutcome feedback had a significantly greater and more reliable effect. However,\nboth factors had modest effects on participants' task performance. Our findings\nsuggest that (1) factors receiving significant attention, such as\ninterpretability, may be less effective at increasing trust than factors like\noutcome feedback, and (2) augmenting human performance via AI systems may not\nbe a simple matter of increasing trust in AI, as increased trust is not always\nassociated with equally sizable improvements in performance. These findings\ninvite the research community to focus not only on methods for generating\ninterpretations but also on techniques for ensuring that interpretations impact\ntrust and performance in practice.",
    "descriptor": "",
    "authors": [
      "Daehwan Ahn",
      "Abdullah Almaatouq",
      "Monisha Gulabani",
      "Kartik Hosanagar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.08222"
  },
  {
    "id": "arXiv:2111.08223",
    "title": "A Survey on Adversarial Attacks for Malware Analysis",
    "abstract": "Machine learning has witnessed tremendous growth in its adoption and\nadvancement in the last decade. The evolution of machine learning from\ntraditional algorithms to modern deep learning architectures has shaped the way\ntoday's technology functions. Its unprecedented ability to discover\nknowledge/patterns from unstructured data and automate the decision-making\nprocess led to its application in wide domains. High flying machine learning\narena has been recently pegged back by the introduction of adversarial attacks.\nAdversaries are able to modify data, maximizing the classification error of the\nmodels. The discovery of blind spots in machine learning models has been\nexploited by adversarial attackers by generating subtle intentional\nperturbations in test samples. Increasing dependency on data has paved the\nblueprint for ever-high incentives to camouflage machine learning models. To\ncope with probable catastrophic consequences in the future, continuous research\nis required to find vulnerabilities in form of adversarial and design remedies\nin systems. This survey aims at providing the encyclopedic introduction to\nadversarial attacks that are carried out against malware detection systems. The\npaper will introduce various machine learning techniques used to generate\nadversarial and explain the structure of target files. The survey will also\nmodel the threat posed by the adversary and followed by brief descriptions of\nwidely accepted adversarial algorithms. Work will provide a taxonomy of\nadversarial evasion attacks on the basis of attack domain and adversarial\ngeneration techniques. Adversarial evasion attacks carried out against malware\ndetectors will be discussed briefly under each taxonomical headings and\ncompared with concomitant researches. Analyzing the current research challenges\nin an adversarial generation, the survey will conclude by pinpointing the open\nfuture research directions.",
    "descriptor": "\nComments: 42 Pages, 31 Figures, 11 Tables\n",
    "authors": [
      "Kshitiz Aryal",
      "Maanak Gupta",
      "Mahmoud Abdelsalam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.08223"
  },
  {
    "id": "arXiv:2111.08226",
    "title": "Comparative Analysis of Machine Learning Models for Predicting Travel  Time",
    "abstract": "In this paper, five different deep learning models are being compared for\npredicting travel time. These models are autoregressive integrated moving\naverage (ARIMA) model, recurrent neural network (RNN) model, autoregressive\n(AR) model, Long-short term memory (LSTM) model, and gated recurrent units\n(GRU) model. The aim of this study is to investigate the performance of each\ndeveloped model for forecasting travel time. The dataset used in this paper\nconsists of travel time and travel speed information from the state of\nMissouri. The learning rate used for building each model was varied from\n0.0001-0.01. The best learning rate was found to be 0.001. The study concluded\nthat the ARIMA model was the best model architecture for travel time prediction\nand forecasting.",
    "descriptor": "",
    "authors": [
      "Armstrong Aboah",
      "Elizabeth Arthur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08226"
  },
  {
    "id": "arXiv:2111.08227",
    "title": "Phase function estimation from a diffuse optical image via deep learning",
    "abstract": "The phase function is a key element of a light propagation model for Monte\nCarlo (MC) simulation, which is usually fitted with an analytic function with\nassociated parameters. In recent years, machine learning methods were reported\nto estimate the parameters of the phase function of a particular form such as\nthe Henyey-Greenstein phase function but, to our knowledge, no studies have\nbeen performed to determine the form of the phase function. Here we design a\nconvolutional neural network to estimate the phase function from a diffuse\noptical image without any explicit assumption on the form of the phase\nfunction. Specifically, we use a Gaussian mixture model as an example to\nrepresent the phase function generally and learn the model parameters\naccurately. The Gaussian mixture model is selected because it provides the\nanalytic expression of phase function to facilitate deflection angle sampling\nin MC simulation, and does not significantly increase the number of free\nparameters. Our proposed method is validated on MC-simulated reflectance images\nof typical biological tissues using the Henyey-Greenstein phase function with\ndifferent anisotropy factors. The effects of field of view (FOV) and spatial\nresolution on the errors are analyzed to optimize the estimation method. The\nmean squared error of the phase function is 0.01 and the relative error of the\nanisotropy factor is 3.28%.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Yuxuan Liang",
      "Chuang Niu",
      "Chen Wei",
      "Shenghan Ren",
      "Wenxiang Cong",
      "Ge Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.08227"
  },
  {
    "id": "arXiv:2111.08229",
    "title": "QA4PRF: A Question Answering based Framework for Pseudo Relevance  Feedback",
    "abstract": "Pseudo relevance feedback (PRF) automatically performs query expansion based\non top-retrieved documents to better represent the user's information need so\nas to improve the search results. Previous PRF methods mainly select expansion\nterms with high occurrence frequency in top-retrieved documents or with high\nsemantic similarity with the original query. However, existing PRF methods\nhardly try to understand the content of documents, which is very important in\nperforming effective query expansion to reveal the user's information need. In\nthis paper, we propose a QA-based framework for PRF called QA4PRF to utilize\ncontextual information in documents. In such a framework, we formulate PRF as a\nQA task, where the query and each top-retrieved document play the roles of\nquestion and context in the corresponding QA system, while the objective is to\nfind some proper terms to expand the original query by utilizing contextual\ninformation, which are similar answers in QA task. Besides, an attention-based\npointer network is built on understanding the content of top-retrieved\ndocuments and selecting the terms to represent the original query better. We\nalso show that incorporating the traditional supervised learning methods, such\nas LambdaRank, to integrate PRF information will further improve the\nperformance of QA4PRF. Extensive experiments on three real-world datasets\ndemonstrate that QA4PRF significantly outperforms the state-of-the-art methods.",
    "descriptor": "\nComments: accepted by Access\n",
    "authors": [
      "Handong Ma",
      "Jiawei Hou",
      "Chenxu Zhu",
      "Weinan Zhang",
      "Ruiming Tang",
      "Jincai Lai",
      "Jieming Zhu",
      "Xiuqiang He",
      "Yong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.08229"
  },
  {
    "id": "arXiv:2111.08230",
    "title": "Selective Ensembles for Consistent Predictions",
    "abstract": "Recent work has shown that models trained to the same objective, and which\nachieve similar measures of accuracy on consistent test data, may nonetheless\nbehave very differently on individual predictions. This inconsistency is\nundesirable in high-stakes contexts, such as medical diagnosis and finance. We\nshow that this inconsistent behavior extends beyond predictions to feature\nattributions, which may likewise have negative implications for the\nintelligibility of a model, and one's ability to find recourse for subjects. We\nthen introduce selective ensembles to mitigate such inconsistencies by applying\nhypothesis testing to the predictions of a set of models trained using\nrandomly-selected starting conditions; importantly, selective ensembles can\nabstain in cases where a consistent outcome cannot be achieved up to a\nspecified confidence level. We prove that that prediction disagreement between\nselective ensembles is bounded, and empirically demonstrate that selective\nensembles achieve consistent predictions and feature attributions while\nmaintaining low abstention rates. On several benchmark datasets, selective\nensembles reach zero inconsistently predicted points, with abstention rates as\nlow 1.5%.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Emily Black",
      "Klas Leino",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08230"
  },
  {
    "id": "arXiv:2111.08232",
    "title": "Online Self-Evolving Anomaly Detection in Cloud Computing Environments",
    "abstract": "Modern cloud computing systems contain hundreds to thousands of computing and\nstorage servers. Such a scale, combined with ever-growing system complexity, is\ncausing a key challenge to failure and resource management for dependable cloud\ncomputing. Autonomic failure detection is a crucial technique for understanding\nemergent, cloud-wide phenomena and self-managing cloud resources for\nsystem-level dependability assurance. To detect failures, we need to monitor\nthe cloud execution and collect runtime performance data. These data are\nusually unlabeled, and thus a prior failure history is not always available in\nproduction clouds. In this paper, we present a \\emph{self-evolving anomaly\ndetection} (SEAD) framework for cloud dependability assurance. Our framework\nself-evolves by recursively exploring newly verified anomaly records and\ncontinuously updating the anomaly detector online. As a distinct advantage of\nour framework, cloud system administrators only need to check a small number of\ndetected anomalies, and their decisions are leveraged to update the detector.\nThus, the detector evolves following the upgrade of system hardware, update of\nthe software stack, and change of user workloads. Moreover, we design two types\nof detectors, one for general anomaly detection and the other for type-specific\nanomaly detection. With the help of self-evolving techniques, our detectors can\nachieve 88.94\\% in sensitivity and 94.60\\% in specificity on average, which\nmakes them suitable for real-world deployment.",
    "descriptor": "",
    "authors": [
      "Haili Wang",
      "Jingda Guo",
      "Xu Ma",
      "Song Fu",
      "Qing Yang",
      "Yunzhong Xu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08232"
  },
  {
    "id": "arXiv:2111.08238",
    "title": "A Simple Algorithm for Computing the Zone of a Line in an Arrangement of  Lines",
    "abstract": "Let $L$ be a set of $n$ lines in the plane. The zone $Z(\\ell)$ of a line\n$\\ell$ in the arrangement $\\mathcal{A}(L)$ of $L$ is the set of faces of\n$\\mathcal{A}(L)$ whose closure intersects $\\ell$. It is known that the\ncombinatorial size of $Z(\\ell)$ is $O(n)$. Given $L$ and $\\ell$, computing\n$Z(\\ell)$ is a fundamental problem. Linear-time algorithms exist for computing\n$Z(\\ell)$ if $\\mathcal{A}(L)$ has already been built, but building\n$\\mathcal{A}(L)$ takes $O(n^2)$ time. On the other hand, $O(n\\log n)$-time\nalgorithms are also known for computing $Z(\\ell)$ without relying on\n$\\mathcal{A}(L)$, but these algorithms are relatively complicated. In this\npaper, we present a simple algorithm that can compute $Z(\\ell)$ in $O(n\\log n)$\ntime. More specifically, once the sorted list of the intersections between\n$\\ell$ and the lines of $L$ is known, the algorithm runs in $O(n)$ time. A big\nadvantage of our algorithm, which mainly involves a Graham's scan style\nprocedure, is its simplicity.",
    "descriptor": "\nComments: To appear in SOSA 2022\n",
    "authors": [
      "Haitao Wang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.08238"
  },
  {
    "id": "arXiv:2111.08239",
    "title": "Assessing Deep Neural Networks as Probability Estimators",
    "abstract": "Deep Neural Networks (DNNs) have performed admirably in classification tasks.\nHowever, the characterization of their classification uncertainties, required\nfor certain applications, has been lacking. In this work, we investigate the\nissue by assessing DNNs' ability to estimate conditional probabilities and\npropose a framework for systematic uncertainty characterization. Denoting the\ninput sample as x and the category as y, the classification task of assigning a\ncategory y to a given input x can be reduced to the task of estimating the\nconditional probabilities p(y|x), as approximated by the DNN at its last layer\nusing the softmax function. Since softmax yields a vector whose elements all\nfall in the interval (0, 1) and sum to 1, it suggests a probabilistic\ninterpretation to the DNN's outcome. Using synthetic and real-world datasets,\nwe look into the impact of various factors, e.g., probability density f(x) and\ninter-categorical sparsity, on the precision of DNNs' estimations of p(y|x),\nand find that the likelihood probability density and the inter-categorical\nsparsity have greater impacts than the prior probability to DNNs'\nclassification uncertainty.",
    "descriptor": "\nComments: Accepted at 2021 IEEE International Conference on Big Data (IEEE BigData 2021)\n",
    "authors": [
      "Yu Pan",
      "Kwo-Sen Kuo",
      "Michael L. Rilee",
      "Hongfeng Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08239"
  },
  {
    "id": "arXiv:2111.08243",
    "title": "CAR -- Cityscapes Attributes Recognition A Multi-category Attributes  Dataset for Autonomous Vehicles",
    "abstract": "Self-driving vehicles are the future of transportation. With current\nadvancements in this field, the world is getting closer to safe roads with\nalmost zero probability of having accidents and eliminating human errors.\nHowever, there is still plenty of research and development necessary to reach a\nlevel of robustness. One important aspect is to understand a scene fully\nincluding all details. As some characteristics (attributes) of objects in a\nscene (drivers' behavior for instance) could be imperative for correct decision\nmaking. However, current algorithms suffer from low-quality datasets with such\nrich attributes. Therefore, in this paper, we present a new dataset for\nattributes recognition -- Cityscapes Attributes Recognition (CAR). The new\ndataset extends the well-known dataset Cityscapes by adding an additional yet\nimportant annotation layer of attributes of objects in each image. Currently,\nwe have annotated more than 32k instances of various categories (Vehicles,\nPedestrians, etc.). The dataset has a structured and tailored taxonomy where\neach category has its own set of possible attributes. The tailored taxonomy\nfocuses on attributes that is of most beneficent for developing better\nself-driving algorithms that depend on accurate computer vision and scene\ncomprehension. We have also created an API for the dataset to ease the usage of\nCAR. The API can be accessed through https://github.com/kareem-metwaly/CAR-API.",
    "descriptor": "",
    "authors": [
      "Kareem Metwaly",
      "Aerin Kim",
      "Elliot Branson",
      "Vishal Monga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.08243"
  },
  {
    "id": "arXiv:2111.08246",
    "title": "Self-encoding Barnacle Mating Optimizer Algorithm for Manpower  Scheduling in Flow Shop",
    "abstract": "Flow Shop Scheduling (FSS) has been widely researched due to its application\nin many types of fields, while the human participant brings great challenges to\nthis problem. Manpower scheduling captures attention for assigning workers with\ndiverse proficiency to the appropriate stages, which is of great significance\nto production efficiency.\nIn this paper, we present a novel algorithm called Self-encoding Barnacle\nMating Optimizer (SBMO), which solves the FSS problem considering worker\nproficiency, defined as a new problem, Flow Shop Manpower Scheduling Problem\n(FSMSP). The highlight of the SBMO algorithm is the combination with the\nencoding method, crossover and mutation operators. Moreover, in order to solve\nthe local optimum problem, we design a neighborhood search scheme. Finally, the\nextensive comparison simulations are conducted to demonstrate the superiority\nof the proposed SBMO. The results indicate the effectiveness of SBMO in\napproximate ratio, powerful stability, and execution time, compared with the\nclassic and popular counterparts.",
    "descriptor": "",
    "authors": [
      "Shuyun Luo",
      "Wushuang Wang",
      "Mengyuan Fang",
      "Weiqiang Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08246"
  },
  {
    "id": "arXiv:2111.08248",
    "title": "Active Vapor-Based Robotic Wiper",
    "abstract": "This paper presents a method of normal estimation for mirrors and transparent\nobjects, which are difficult to recognize with a camera. To create a diffuse\nreflective surface, we propose to spray the water vapor onto the transparent or\nmirror surface. In the proposed method, we move an ultrasonic humidifier\nequipped on the tip of a robotic arm to apply the sprayed water vapor onto a\nplane of a target object so as to form a cross-shaped misted area. Diffuse\nreflective surfaces are partially generated as the misted area, which allows\nthe camera to detect a surface of the target object. The viewpoint of the\ngripper-mounted camera is adjusted so that the extracted misted area appears as\nlargest in the image, and finally the plane normal of the target object surface\nare estimated. We conducted normal estimation experiments to evaluate the\neffectiveness of the proposed method. The RMSEs of the azimuth estimation for a\nmirror and a transparent glass are about 4.2 and 5.8 degrees, respectively.\nConsequently, our robot experiments demonstrate that our robotic wiper can\nperform contact-force-regulated wiping motions for cleaning a transparent\nwindow as humans do.",
    "descriptor": "\nComments: 7 pages, 12 figures\n",
    "authors": [
      "Takuya Kiyokawa",
      "Hiroki Katayama",
      "Jun Takamatsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.08248"
  },
  {
    "id": "arXiv:2111.08249",
    "title": "Bengali Handwritten Grapheme Classification: Deep Learning Approach",
    "abstract": "Despite being one of the most spoken languages in the world ($6^{th}$ based\non population), research regarding Bengali handwritten grapheme (smallest\nfunctional unit of a writing system) classification has not been explored\nwidely compared to other prominent languages. Moreover, the large number of\ncombinations of graphemes in the Bengali language makes this classification\ntask very challenging. With an effort to contribute to this research problem,\nwe participate in a Kaggle competition \\cite{kaggle_link} where the challenge\nis to separately classify three constituent elements of a Bengali grapheme in\nthe image: grapheme root, vowel diacritics, and consonant diacritics. We\nexplore the performances of some existing neural network models such as\nMulti-Layer Perceptron (MLP) and state of the art ResNet50. To further improve\nthe performance we propose our own convolution neural network (CNN) model for\nBengali grapheme classification with validation root accuracy 95.32\\%, vowel\naccuracy 98.61\\%, and consonant accuracy 98.76\\%. We also explore Region\nProposal Network (RPN) using VGGNet with a limited setting that can be a\npotential future direction to improve the performance.",
    "descriptor": "\nComments: 8 pages, 15 figures, pre-print\n",
    "authors": [
      "Tarun Roy",
      "Hasib Hasan",
      "Kowsar Hossain",
      "Masuma Akter Rumi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08249"
  },
  {
    "id": "arXiv:2111.08251",
    "title": "Enabling equivariance for arbitrary Lie groups",
    "abstract": "Although provably robust to translational perturbations, convolutional neural\nnetworks (CNNs) are known to suffer from extreme performance degradation when\npresented at test time with more general geometric transformations of inputs.\nRecently, this limitation has motivated a shift in focus from CNNs to Capsule\nNetworks (CapsNets). However, CapsNets suffer from admitting relatively few\ntheoretical guarantees of invariance. We introduce a rigourous mathematical\nframework to permit invariance to any Lie group of warps, exclusively using\nconvolutions (over Lie groups), without the need for capsules. Previous work on\ngroup convolutions has been hampered by strong assumptions about the group,\nwhich precludes the application of such techniques to common warps in computer\nvision such as affine and homographic. Our framework enables the implementation\nof group convolutions over \\emph{any} finite-dimensional Lie group. We\nempirically validate our approach on the benchmark affine-invariant\nclassification task, where we achieve $\\sim$30\\% improvement in accuracy\nagainst conventional CNNs while outperforming the state-of-the-art CapsNet. As\nfurther illustration of the generality of our framework, we train a\nhomography-convolutional model which achieves superior robustness on a\nhomography-perturbed dataset, where CapsNet results degrade.",
    "descriptor": "",
    "authors": [
      "Lachlan E. MacDonald",
      "Sameera Ramasinghe",
      "Simon Lucey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.08251"
  },
  {
    "id": "arXiv:2111.08253",
    "title": "Generalization Bounds and Algorithms for Learning to Communicate over  Additive Noise Channels",
    "abstract": "An additive noise channel is considered, in which the distribution of the\nnoise is nonparametric and unknown. The problem of learning encoders and\ndecoders based on noise samples is considered. For uncoded communication\nsystems, the problem of choosing a codebook and possibly also a generalized\nminimal distance decoder (which is parameterized by a covariance matrix) is\naddressed. High probability generalization bounds for the error probability\nloss function, as well as for a hinge-type surrogate loss function are\nprovided. A stochastic-gradient based alternating-minimization algorithm for\nthe latter loss function is proposed. In addition, a Gibbs-based algorithm that\ngradually expurgates an initial codebook from codewords in order to obtain a\nsmaller codebook with improved error probability is proposed, and bounds on its\naverage empirical error and generalization error, as well as a high probability\ngeneralization bound, are stated. Various experiments demonstrate the\nperformance of the proposed algorithms. For coded systems, the problem of\nmaximizing the mutual information between the input and the output with respect\nto the input distribution is addressed, and uniform convergence bounds for two\ndifferent classes of input distributions are obtained.",
    "descriptor": "",
    "authors": [
      "Nir Weinberger"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.08253"
  },
  {
    "id": "arXiv:2111.08255",
    "title": "A Unified and Fast Interpretable Model for Predictive Analytics",
    "abstract": "In this paper, we propose FXAM (Fast and eXplainable Additive Model), a\nunified and fast interpretable model for predictive analytics. FXAM extends\nGAM's (Generalized Additive Model) modeling capability with a unified additive\nmodel for numerical, categorical, and temporal features. FXAM conducts a novel\ntraining procedure called Three-Stage Iteration (TSI). The three stages\ncorrespond to learning over numerical, categorical and temporal features\nrespectively. Each stage learns a local optimum by fixing parameters of other\nstages. We design joint learning over categorical features and partial learning\nover temporal features to achieve high accuracy and training efficiency. We\nprove that TSI is guaranteed to converge to global optimum. We further propose\na set of optimization techniques to speed up FXAM's training algorithm to meet\nthe needs of interactive analysis. Evaluations verify that FXAM significantly\noutperforms existing GAMs in terms of training speed and modeling categorical\nand temporal features.",
    "descriptor": "",
    "authors": [
      "Rui Ding",
      "Tianchi Qiao",
      "Yunan Zhu",
      "Zhitao Zou",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08255"
  },
  {
    "id": "arXiv:2111.08258",
    "title": "Faster-than-Nyquist Asynchronous NOMA Outperforms Synchronous NOMA",
    "abstract": "Faster-than-Nyquist (FTN) signaling aided non-orthogonal multiple access\n(NOMA) is conceived and its achievable rate is quantified in the presence of\n\\emph{random} link delays of the different users. We reveal that exploiting the\nlink delays may potentially lead to a signal-to-interference-plus-noise ratio\n(SINR) gain, while transmitting the data symbols at FTN rates has the potential\nof increasing the degree-of-freedom (DoF). We then unveil the fundamental\ntrade-off between the SINR and DoF. In particular, at a sufficiently high\nsymbol rate, the SINR gain vanishes while the DoF gain achieves its maximum,\nwhere the achievable rate is almost $(1+\\beta)$ times higher than that of the\nconventional synchronous NOMA transmission in the high signal-to-noise ratio\n(SNR) regime, with $\\beta$ being the roll-off factor of the signaling pulse.\nOur simulation results verify our analysis and demonstrate considerable rate\nimprovements over the conventional power-domain NOMA scheme.",
    "descriptor": "",
    "authors": [
      "Shuagyang Li",
      "Zhiqiang Wei",
      "Weijie Yuan",
      "Jinhong Yuan",
      "Baoming Bai",
      "Derrick Wing Kwan Ng",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.08258"
  },
  {
    "id": "arXiv:2111.08259",
    "title": "Pose Recognition in the Wild: Animal pose estimation using Agglomerative  Clustering and Contrastive Learning",
    "abstract": "Animal pose estimation has recently come into the limelight due to its\napplication in biology, zoology, and aquaculture. Deep learning methods have\neffectively been applied to human pose estimation. However, the major\nbottleneck to the application of these methods to animal pose estimation is the\nunavailability of sufficient quantities of labeled data. Though there are ample\nquantities of unlabelled data publicly available, it is economically\nimpractical to label large quantities of data for each animal. In addition, due\nto the wide variety of body shapes in the animal kingdom, the transfer of\nknowledge across domains is ineffective. Given the fact that the human brain is\nable to recognize animal pose without requiring large amounts of labeled data,\nit is only reasonable that we exploit unsupervised learning to tackle the\nproblem of animal pose recognition from the available, unlabelled data. In this\npaper, we introduce a novel architecture that is able to recognize the pose of\nmultiple animals fromunlabelled data. We do this by (1) removing background\ninformation from each image and employing an edge detection algorithm on the\nbody of the animal, (2) Tracking motion of the edge pixels and performing\nagglomerative clustering to segment body parts, (3) employing contrastive\nlearning to discourage grouping of distant body parts together. Hence we are\nable to distinguish between body parts of the animal, based on their visual\nbehavior, instead of the underlying anatomy. Thus, we are able to achieve a\nmore effective classification of the data than their human-labeled\ncounterparts. We test our model on the TigDog and WLD (WildLife Documentary)\ndatasets, where we outperform state-of-the-art approaches by a significant\nmargin. We also study the performance of our model on other public data to\ndemonstrate the generalization ability of our model.",
    "descriptor": "\nComments: 9 pages, 4 figures, 3 tables\n",
    "authors": [
      "Samayan Bhattacharya",
      "Sk Shahnawaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08259"
  },
  {
    "id": "arXiv:2111.08262",
    "title": "Larger Corner-Free Sets from Combinatorial Degenerations",
    "abstract": "There is a large and important collection of Ramsey-type combinatorial\nproblems, closely related to central problems in complexity theory, that can be\nformulated in terms of the asymptotic growth of the size of the maximum\nindependent sets in powers of a fixed small (directed or undirected)\nhypergraph, also called the Shannon capacity. An important instance of this is\nthe corner problem studied in the context of multiparty communication\ncomplexity in the Number On the Forehead (NOF) model. Versions of this problem\nand the NOF connection have seen much interest (and progress) in recent works\nof Linial, Pitassi and Shraibman (ITCS 2019) and Linial and Shraibman (CCC\n2021).\nWe introduce and study a general algebraic method for lower bounding the\nShannon capacity of directed hypergraphs via combinatorial degenerations, a\ncombinatorial kind of \"approximation\" of subgraphs that originates from the\nstudy of matrix multiplication in algebraic complexity theory (and which play\nan important role there) but which we use in a novel way.\nUsing the combinatorial degeneration method, we make progress on the corner\nproblem by explicitly constructing a corner-free subset in $F_2^n \\times F_2^n$\nof size $\\Omega(3.39^n/poly(n))$, which improves the previous lower bound\n$\\Omega(2.82^n)$ of Linial, Pitassi and Shraibman (ITCS 2019) and which gets us\ncloser to the best upper bound $4^{n - o(n)}$. Our new construction of\ncorner-free sets implies an improved NOF protocol for the Eval problem. In the\nEval problem over a group $G$, three players need to determine whether their\ninputs $x_1, x_2, x_3 \\in G$ sum to zero. We find that the NOF communication\ncomplexity of the Eval problem over $F_2^n$ is at most $0.24n + O(\\log n)$,\nwhich improves the previous upper bound $0.5n + O(\\log n)$.",
    "descriptor": "\nComments: A short version of this paper will appear in the proceedings of ITCS 2022. This paper improves results that appeared in arxiv:2104.01130v1\n",
    "authors": [
      "Matthias Christandl",
      "Omar Fawzi",
      "Hoang Ta",
      "Jeroen Zuiddam"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.08262"
  },
  {
    "id": "arXiv:2111.08264",
    "title": "Analysis of 5G academic Network based on graph representation learning  method",
    "abstract": "With the rapid development of 5th Generation Mobile Communication Technology\n(5G), the diverse forms of collaboration and extensive data in academic social\nnetworks constructed by 5G papers make the management and analysis of academic\nsocial networks increasingly challenging. Despite the particular success\nachieved by representation learning in analyzing academic and social networks,\nmost present presentation learning models focus on maintaining the first-order\nand second-order similarity of nodes. They rarely possess similar structural\ncharacteristics of spatial independence in the network. This paper proposes a\nLow-order Network representation Learning Model (LNLM) based on Non-negative\nMatrix Factorization (NMF) to solve these problems. The model uses the random\nwalk method to extract low-order features of nodes and map multiple components\nto a low-dimensional space, effectively maintaining the internal correlation\nbetween members. This paper verifies the performance of this model, conducts\ncomparative experiments on four test datasets and four real network datasets\nthrough downstream tasks such as multi-label classification, clustering, and\nlink prediction. Comparing eight mainstream network representation learning\nmodels shows that the proposed model can significantly improve the detection\nefficiency and learning methods and effectively extract local and low-order\nfeatures of the network.",
    "descriptor": "\nComments: 38 pages, 9 figures\n",
    "authors": [
      "Xiaoming Li",
      "Guangquan Xu",
      "Wei Yu",
      "Pengfei Jiao",
      "Xiangyu Song"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.08264"
  },
  {
    "id": "arXiv:2111.08267",
    "title": "Solving Probability and Statistics Problems by Program Synthesis",
    "abstract": "We solve university level probability and statistics questions by program\nsynthesis using OpenAI's Codex, a Transformer trained on text and fine-tuned on\ncode. We transform course problems from MIT's 18.05 Introduction to Probability\nand Statistics and Harvard's STAT110 Probability into programming tasks. We\nthen execute the generated code to get a solution. Since these course questions\nare grounded in probability, we often aim to have Codex generate probabilistic\nprograms that simulate a large number of probabilistic dependencies to compute\nits solution. Our approach requires prompt engineering to transform the\nquestion from its original form to an explicit, tractable form that results in\na correct program and solution. To estimate the amount of work needed to\ntranslate an original question into its tractable form, we measure the\nsimilarity between original and transformed questions. Our work is the first to\nintroduce a new dataset of university-level probability and statistics problems\nand solve these problems in a scalable fashion using the program synthesis\ncapabilities of large language models.",
    "descriptor": "\nComments: 33 pages, 4 figures\n",
    "authors": [
      "Leonard Tang",
      "Elizabeth Ke",
      "Nikhil Singh",
      "Nakul Verma",
      "Iddo Drori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.08267"
  },
  {
    "id": "arXiv:2111.08268",
    "title": "Pre-training Graph Neural Network for Cross Domain Recommendation",
    "abstract": "A recommender system predicts users' potential interests in items, where the\ncore is to learn user/item embeddings. Nevertheless, it suffers from the\ndata-sparsity issue, which the cross-domain recommendation can alleviate.\nHowever, most prior works either jointly learn the source domain and target\ndomain models, or require side-features. However, jointly training and side\nfeatures would affect the prediction on the target domain as the learned\nembedding is dominated by the source domain containing bias information.\nInspired by the contemporary arts in pre-training from graph representation\nlearning, we propose a pre-training and fine-tuning diagram for cross-domain\nrecommendation. We devise a novel Pre-training Graph Neural Network for\nCross-Domain Recommendation (PCRec), which adopts the contrastive\nself-supervised pre-training of a graph encoder. Then, we transfer the\npre-trained graph encoder to initialize the node embeddings on the target\ndomain, which benefits the fine-tuning of the single domain recommender system\non the target domain. The experimental results demonstrate the superiority of\nPCRec. Detailed analyses verify the superiority of PCRec in transferring\ninformation while avoiding biases from source domains.",
    "descriptor": "",
    "authors": [
      "Chen Wang",
      "Yueqing Liang",
      "Zhiwei Liu",
      "Tao Zhang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08268"
  },
  {
    "id": "arXiv:2111.08270",
    "title": "Data Augmentation using Random Image Cropping for High-resolution  Virtual Try-On (VITON-CROP)",
    "abstract": "Image-based virtual try-on provides the capacity to transfer a clothing item\nonto a photo of a given person, which is usually accomplished by warping the\nitem to a given human pose and adjusting the warped item to the person.\nHowever, the results of real-world synthetic images (e.g., selfies) from the\nprevious method is not realistic because of the limitations which result in the\nneck being misrepresented and significant changes to the style of the garment.\nTo address these challenges, we propose a novel method to solve this unique\nissue, called VITON-CROP. VITON-CROP synthesizes images more robustly when\nintegrated with random crop augmentation compared to the existing\nstate-of-the-art virtual try-on models. In the experiments, we demonstrate that\nVITON-CROP is superior to VITON-HD both qualitatively and quantitatively.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Taewon Kang",
      "Sunghyun Park",
      "Seunghwan Choi",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08270"
  },
  {
    "id": "arXiv:2111.08272",
    "title": "Task allocation for decentralized training in heterogeneous environment",
    "abstract": "The demand for large-scale deep learning is increasing, and distributed\ntraining is the current mainstream solution. Ring AllReduce is widely used as a\ndata parallel decentralized algorithm. However, in a heterogeneous environment,\neach worker calculates the same amount of data, so that there is a lot of\nwaiting time loss among different workers, which makes the algorithm unable to\nadapt well to heterogeneous clusters. Resources are not used as they should be.\nIn this paper, we design an implementation of static allocation algorithm. The\ndataset is artificially allocated to each worker, and samples are drawn\nproportionally for training, thereby speeding up the training speed of the\nnetwork in a heterogeneous environment. We verify the convergence and influence\non training speed of the network model under this algorithm on one machine with\nmulti-card and multi-machine with multi-card. On this basis of feasibility, we\npropose a self-adaptive allocation algorithm that allows each machine to find\nthe data it needs to adapt to the current environment. The self-adaptive\nallocation algorithm can reduce the training time by nearly one-third to half\ncompared to the same proportional allocation.In order to better show the\napplicability of the algorithm in heterogeneous clusters, We replace a poorly\nperforming worker with a good performing worker or add a poorly performing\nworker to the heterogeneous cluster. Experimental results show that training\ntime will decrease as the overall performance improves. Therefore, it means\nthat resources are fully used. Further, this algorithm is not only suitable for\nstraggler problems, but also for most heterogeneous situations. It can be used\nas a plug-in for AllReduce and its variant algorithms.",
    "descriptor": "",
    "authors": [
      "Yongyue Chao",
      "Mingxue Liao",
      "Jiaxin Gao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.08272"
  },
  {
    "id": "arXiv:2111.08274",
    "title": "HADFL: Heterogeneity-aware Decentralized Federated Learning Framework",
    "abstract": "Federated learning (FL) supports training models on geographically\ndistributed devices. However, traditional FL systems adopt a centralized\nsynchronous strategy, putting high communication pressure and model\ngeneralization challenge. Existing optimizations on FL either fail to speedup\ntraining on heterogeneous devices or suffer from poor communication efficiency.\nIn this paper, we propose HADFL, a framework that supports decentralized\nasynchronous training on heterogeneous devices. The devices train model locally\nwith heterogeneity-aware local steps using local data. In each aggregation\ncycle, they are selected based on probability to perform model synchronization\nand aggregation. Compared with the traditional FL system, HADFL can relieve the\ncentral server's communication pressure, efficiently utilize heterogeneous\ncomputing power, and can achieve a maximum speedup of 3.15x than\ndecentralized-FedAvg and 4.68x than Pytorch distributed training scheme,\nrespectively, with almost no loss of convergence accuracy.",
    "descriptor": "\nComments: Accepted by DAC 2021\n",
    "authors": [
      "Jing Cao",
      "Zirui Lian",
      "Weihong Liu",
      "Zongwei Zhu",
      "Cheng Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08274"
  },
  {
    "id": "arXiv:2111.08275",
    "title": "Deep Distilling: automated code generation using explainable deep  learning",
    "abstract": "Human reasoning can distill principles from observed patterns and generalize\nthem to explain and solve novel problems. The most powerful artificial\nintelligence systems lack explainability and symbolic reasoning ability, and\nhave therefore not achieved supremacy in domains requiring human understanding,\nsuch as science or common sense reasoning. Here we introduce deep distilling, a\nmachine learning method that learns patterns from data using explainable deep\nlearning and then condenses it into concise, executable computer code. The\ncode, which can contain loops, nested logical statements, and useful\nintermediate variables, is equivalent to the neural network but is generally\norders of magnitude more compact and human-comprehensible. On a diverse set of\nproblems involving arithmetic, computer vision, and optimization, we show that\ndeep distilling generates concise code that generalizes out-of-distribution to\nsolve problems orders-of-magnitude larger and more complex than the training\ndata. For problems with a known ground-truth rule set, deep distilling\ndiscovers the rule set exactly with scalable guarantees. For problems that are\nambiguous or computationally intractable, the distilled rules are similar to\nexisting human-derived algorithms and perform at par or better. Our approach\ndemonstrates that unassisted machine intelligence can build generalizable and\nintuitive rules explaining patterns in large datasets that would otherwise\noverwhelm human reasoning.",
    "descriptor": "",
    "authors": [
      "Paul J. Blazek",
      "Kesavan Venkatesh",
      "Milo M. Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08275"
  },
  {
    "id": "arXiv:2111.08276",
    "title": "Multi-Grained Vision Language Pre-Training: Aligning Texts with Visual  Concepts",
    "abstract": "Most existing methods in vision language pre-training rely on object-centric\nfeatures extracted through object detection, and make fine-grained alignments\nbetween the extracted features and texts. We argue that the use of object\ndetection may not be suitable for vision language pre-training. Instead, we\npoint out that the task should be performed so that the regions of `visual\nconcepts' mentioned in the texts are located in the images, and in the meantime\nalignments between texts and visual concepts are identified, where the\nalignments are in multi-granularity. This paper proposes a new method called\nX-VLM to perform `multi-grained vision language pre-training'. Experimental\nresults show that X-VLM consistently outperforms state-of-the-art methods in\nmany downstream vision language tasks.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Yan Zeng",
      "Xinsong Zhang",
      "Hang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08276"
  },
  {
    "id": "arXiv:2111.08277",
    "title": "Wyner-Ziv Gradient Compression for Federated Learning",
    "abstract": "Due to limited communication resources at the client and a massive number of\nmodel parameters, large-scale distributed learning tasks suffer from\ncommunication bottleneck. Gradient compression is an effective method to reduce\ncommunication load by transmitting compressed gradients. Motivated by the fact\nthat in the scenario of stochastic gradients descent, gradients between\nadjacent rounds may have a high correlation since they wish to learn the same\nmodel, this paper proposes a practical gradient compression scheme for\nfederated learning, which uses historical gradients to compress gradients and\nis based on Wyner-Ziv coding but without any probabilistic assumption. We also\nimplement our gradient quantization method on the real dataset, and the\nperformance of our method is better than the previous schemes.",
    "descriptor": "",
    "authors": [
      "Kai Liang",
      "Huiru Zhong",
      "Haoning Chen",
      "Youlong Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08277"
  },
  {
    "id": "arXiv:2111.08279",
    "title": "Keypoint Message Passing for Video-based Person Re-Identification",
    "abstract": "Video-based person re-identification (re-ID) is an important technique in\nvisual surveillance systems which aims to match video snippets of people\ncaptured by different cameras. Existing methods are mostly based on\nconvolutional neural networks (CNNs), whose building blocks either process\nlocal neighbor pixels at a time, or, when 3D convolutions are used to model\ntemporal information, suffer from the misalignment problem caused by person\nmovement. In this paper, we propose to overcome the limitations of normal\nconvolutions with a human-oriented graph method. Specifically, features located\nat person joint keypoints are extracted and connected as a spatial-temporal\ngraph. These keypoint features are then updated by message passing from their\nconnected nodes with a graph convolutional network (GCN). During training, the\nGCN can be attached to any CNN-based person re-ID model to assist\nrepresentation learning on feature maps, whilst it can be dropped after\ntraining for better inference speed. Our method brings significant improvements\nover the CNN-based baseline model on the MARS dataset with generated person\nkeypoints and a newly annotated dataset: PoseTrackReID. It also defines a new\nstate-of-the-art method in terms of top-1 accuracy and mean average precision\nin comparison to prior works.",
    "descriptor": "",
    "authors": [
      "Di Chen",
      "Andreas Doering",
      "Shanshan Zhang",
      "Jian Yang",
      "Juergen Gall",
      "Bernt Schiele"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08279"
  },
  {
    "id": "arXiv:2111.08282",
    "title": "Self-supervised High-fidelity and Re-renderable 3D Facial Reconstruction  from a Single Image",
    "abstract": "Reconstructing high-fidelity 3D facial texture from a single image is a\nchallenging task since the lack of complete face information and the domain gap\nbetween the 3D face and 2D image. The most recent works tackle facial texture\nreconstruction problem by applying either generation-based or\nreconstruction-based methods. Although each method has its own advantage, none\nof them is capable of recovering a high-fidelity and re-renderable facial\ntexture, where the term 're-renderable' demands the facial texture to be\nspatially complete and disentangled with environmental illumination. In this\npaper, we propose a novel self-supervised learning framework for reconstructing\nhigh-quality 3D faces from single-view images in-the-wild. Our main idea is to\nfirst utilize the prior generation module to produce a prior albedo, then\nleverage the detail refinement module to obtain detailed albedo. To further\nmake facial textures disentangled with illumination, we present a novel\ndetailed illumination representation which is reconstructed with the detailed\nalbedo together. We also design several regularization loss functions on both\nthe albedo side and illumination side to facilitate the disentanglement of\nthese two factors. Finally, thanks to the differentiable rendering technique,\nour neural network can be efficiently trained in a self-supervised manner.\nExtensive experiments on challenging datasets demonstrate that our framework\nsubstantially outperforms state-of-the-art approaches in both qualitative and\nquantitative comparisons.",
    "descriptor": "",
    "authors": [
      "Mingxin Yang",
      "Jianwei Guo",
      "Zhanglin Cheng",
      "Xiaopeng Zhang",
      "Dong-Ming Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.08282"
  },
  {
    "id": "arXiv:2111.08283",
    "title": "Hierarchical Topometric Representation of 3D Robotic Maps",
    "abstract": "In this paper, we propose a method for generating a hierarchical, volumetric\ntopological map from 3D point clouds. There are three basic hierarchical levels\nin our map: $storey - region - volume$. The advantages of our method are\nreflected in both input and output. In terms of input, we accept multi-storey\npoint clouds and building structures with sloping roofs or ceilings. In terms\nof output, we can generate results with metric information of different\ndimensionality, that are suitable for different robotics applications. The\nalgorithm generates the volumetric representation by generating $volumes$ from\na 3D voxel occupancy map. We then add $passage$s (connections between\n$volumes$), combine small $volumes$ into a big $region$ and use a 2D\nsegmentation method for better topological representation. We evaluate our\nmethod on several freely available datasets. The experiments highlight the\nadvantages of our approach.",
    "descriptor": "\nComments: Temporarily\n",
    "authors": [
      "ZhenpengHe",
      "HaoSun",
      "JiaweiHou",
      "YajunHa",
      "S\u00f6ren Schwertfeger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.08283"
  },
  {
    "id": "arXiv:2111.08284",
    "title": "Few-Shot Self-Rationalization with Natural Language Prompts",
    "abstract": "Self-rationalization models that predict task labels and generate free-text\nelaborations for their predictions could enable more intuitive interaction with\nNLP systems. These models are, however, currently trained with a large amount\nof human-written free-text explanations for each task which hinders their\nbroader usage. We propose to study a more realistic setting of\nself-rationalization using few training examples. We present FEB -- a\nstandardized collection of four existing English-language datasets and\nassociated metrics. We identify the right prompting approach by extensively\nexploring natural language prompts on FEB. Then, by using this prompt and\nscaling the model size, we demonstrate that making progress on few-shot\nself-rationalization is possible. We show there is still ample room for\nimprovement in this task: the average plausibility of generated explanations\nassessed by human annotators is at most 51%, while plausibility of human\nexplanations is 76%. We hope that FEB together with our proposed approach will\nspur the community to take on the few-shot self-rationalization challenge.",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Ana Marasovi\u0107",
      "Iz Beltagy",
      "Doug Downey",
      "Matthew E. Peters"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.08284"
  },
  {
    "id": "arXiv:2111.08291",
    "title": "Switching Recurrent Kalman Networks",
    "abstract": "Forecasting driving behavior or other sensor measurements is an essential\ncomponent of autonomous driving systems. Often real-world multivariate time\nseries data is hard to model because the underlying dynamics are nonlinear and\nthe observations are noisy. In addition, driving data can often be multimodal\nin distribution, meaning that there are distinct predictions that are likely,\nbut averaging can hurt model performance. To address this, we propose the\nSwitching Recurrent Kalman Network (SRKN) for efficient inference and\nprediction on nonlinear and multi-modal time-series data. The model switches\namong several Kalman filters that model different aspects of the dynamics in a\nfactorized latent state. We empirically test the resulting scalable and\ninterpretable deep state-space model on toy data sets and real driving data\nfrom taxis in Porto. In all cases, the model can capture the multimodal nature\nof the dynamics in the data.",
    "descriptor": "\nComments: Machine Learning for Autonomous Driving Workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia\n",
    "authors": [
      "Giao Nguyen-Quynh",
      "Philipp Becker",
      "Chen Qiu",
      "Maja Rudolph",
      "Gerhard Neumann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08291"
  },
  {
    "id": "arXiv:2111.08295",
    "title": "Machine Learning-Based Assessment of Energy Behavior of RC Shear Walls",
    "abstract": "Current seismic design codes primarily rely on the strength and displacement\ncapacity of structural members and do not account for the influence of the\nground motion duration or the hysteretic behavior characteristics. The\nenergy-based approach serves as a supplemental index to response quantities and\nincludes the effect of repeated loads in seismic performance. The design\nphilosophy suggests that the seismic demands are met by the energy dissipation\ncapacity of the structural members. Therefore, the energy dissipation behavior\nof the structural members should be well understood to achieve an effective\nenergy-based design approach. This study focuses on the energy dissipation\ncapacity of reinforced concrete (RC) shear walls that are widely used in high\nseismic regions as they provide significant stiffness and strength to resist\nlateral forces. A machine learning (Gaussian Process Regression (GPR))-based\npredictive model for energy dissipation capacity of shear walls is developed as\na function of wall design parameters. Eighteen design parameters are shown to\ninfluence energy dissipation, whereas the most important ones are determined by\napplying sequential backward elimination and by using feature selection methods\nto reduce the complexity of the predictive model. The ability of the proposed\nmodel to make robust and accurate predictions is validated based on novel data\nwith a prediction accuracy (the ratio of predicted/actual values) of around\n1.00 and a coefficient of determination (R2) of 0.93. The outcomes of this\nstudy are believed to contribute to the energy-based approach by (i) defining\nthe most influential wall properties on the seismic energy dissipation capacity\nof shear walls and (ii) providing predictive models that can enable comparisons\nof different wall design configurations to achieve higher energy dissipation\ncapacity.",
    "descriptor": "\nComments: 21 pages, 10 figures, 4 Tables. Submitted to Elsevier\n",
    "authors": [
      "Berkay Topaloglu",
      "Gulsen Taskin Kaya",
      "Fatih Sutcu",
      "Zeynep Tuna Deger"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08295"
  },
  {
    "id": "arXiv:2111.08296",
    "title": "A Markov Chain Approach for Myopic Multi-hop Relaying: Outage and  Diversity Analysis",
    "abstract": "In this paper, a cooperative protocol is investigated for a multi-hop network\nconsisting of relays with buffers of finite size, which may operate in\ndifferent communication modes. The protocol is based on the myopic\ndecode-and-forward strategy, where each node of the network cooperates with a\nlimited number of neighboring nodes for the transmission of the signals. Each\nrelay stores in its buffer the messages that were successfully decoded, in\norder to forward them through the appropriate channel links, based on its\nsupported communication modes. A complete theoretical framework is investigated\nthat models the evolution of the buffers and the transitions at the operations\nof each relay as a state Markov chain (MC). We analyze the performance of the\nproposed protocol in terms of outage probability and derive an expression for\nthe achieved diversity-multiplexing tradeoff, by using the state transition\nmatrix and the related steady state of the MC. Our results show that the\nproposed protocol outperforms the conventional multi-hop relaying scheme and\nthe system's outage probability as well as the achieved diversity order depend\non the degree of cooperation among neighboring nodes and the communication\nmodel that is considered for every relay of the network.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Andreas Nicolaides",
      "Constantinos Psomas",
      "Ioannis Krikidis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08296"
  },
  {
    "id": "arXiv:2111.08299",
    "title": "Accounting for Gaussian Process Imprecision in Bayesian Optimization",
    "abstract": "Bayesian optimization (BO) with Gaussian processes (GP) as surrogate models\nis widely used to optimize analytically unknown and expensive-to-evaluate\nfunctions. In this paper, we propose Prior-mean-RObust Bayesian Optimization\n(PROBO) that outperforms classical BO on specific problems. First, we study the\neffect of the Gaussian processes' prior specifications on classical BO's\nconvergence. We find the prior's mean parameters to have the highest influence\non convergence among all prior components. In response to this result, we\nintroduce PROBO as a generalization of BO that aims at rendering the method\nmore robust towards prior mean parameter misspecification. This is achieved by\nexplicitly accounting for GP imprecision via a prior near-ignorance model. At\nthe heart of this is a novel acquisition function, the generalized lower\nconfidence bound (GLCB). We test our approach against classical BO on a\nreal-world problem from material science and observe PROBO to converge faster.\nFurther experiments on multimodal and wiggly target functions confirm the\nsuperiority of our method.",
    "descriptor": "",
    "authors": [
      "Julian Rodemann",
      "Thomas Augustin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.08299"
  },
  {
    "id": "arXiv:2111.08300",
    "title": "Highly Efficient Indexing Scheme for k-Dominant Skyline Processing over  Uncertain Data Streams",
    "abstract": "Skyline is widely used in reality to solve multi-criteria problems, such as\nenvironmental monitoring and business decision-making. When a data is not worse\nthan another data on all criteria and is better than another data at least one\ncriterion, the data is said to dominate another data. When a data item is not\ndominated by any other data item, this data is said to be a member of the\nskyline. However, as the number of criteria increases, the possibility that a\ndata dominates another data decreases, resulting in too many members of the\nskyline set. To solve this kind of problem, the concept of the k-dominant\nskyline was proposed, which reduces the number of skyline members by relaxing\nthe limit. The uncertainty of the data makes each data have a probability of\nappearing, so each data has the probability of becoming a member of the\nk-dominant skyline. When a new data item is added, the probability of other\ndata becoming members of the k-dominant skyline may change. How to quickly\nupdate the k-dominant skyline for real-time applications is a serious problem.\nThis paper proposes an effective method, Middle Indexing (MI), which filters\nout a large amount of irrelevant data in the uncertain data stream by sorting\ndata specifically, so as to improve the efficiency of updating the k-dominant\nskyline. Experiments show that the proposed MI outperforms the existing method\nby approximately 13% in terms of computation time.",
    "descriptor": "\nComments: 5 pages, 6 figures, accepted by The 30th Wireless and Optical Communications Conference (WOCC 2021)\n",
    "authors": [
      "Chuan-Chi Lai",
      "Hsuan-Yu Lin",
      "Chuan-Ming Liu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.08300"
  },
  {
    "id": "arXiv:2111.08309",
    "title": "Implementation and user acceptance of research information systems",
    "abstract": "PurposeThe purpose of this paper is to present empirical evidence on the\nimplementation, acceptance and quality-related aspects of research information\nsystems (RIS) in academic institutions.Design/methodology/approachThe study is\nbased on a 2018 survey with 160 German universities and research\ninstitutions.FindingsThe paper presents recent figures about the implementation\nof RIS in German academic institutions, including results on the satisfaction,\nperceived usefulness and ease of use. It contains also information about the\nperceived data quality and the preferred quality management. RIS acceptance can\nbe achieved only if the highest possible quality of the data is to be ensured.\nFor this reason, the impact of data quality on the technology acceptance model\n(TAM) is examined, and the relation between the level of data quality and user\nacceptance of the associated institutional RIS is addressed.Research\nlimitations/implicationsThe data provide empirical elements for a better\nunderstanding of the role of the data quality for the acceptance of RIS, in the\nframework of a TAM. The study puts the focus on commercial and open-source\nsolutions while in-house developments have been excluded. Also, mainly because\nof the small sample size, the data analysis was limited to descriptive\nstatistics.Practical implicationsThe results are helpful for the management of\nRIS projects, to increase acceptance and satisfaction with the system, and for\nthe further development of RIS functionalities.Originality/valueThe number of\nempirical studies on the implementation and acceptance of RIS is low, and very\nfew address in this context the question of data quality. The study tries to\nfill the gap.",
    "descriptor": "",
    "authors": [
      "Otmane Azeroual",
      "Joachim Sch\u00f6pfel",
      "Gunter Saake"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.08309"
  },
  {
    "id": "arXiv:2111.08312",
    "title": "Automated System-Level Software Testing of Industrial Networked Embedded  Systems",
    "abstract": "Embedded systems are ubiquitous and play critical roles in management systems\nfor industry and transport. Software failures in these domains may lead to loss\nof production or even loss of life, so the software in these systems needs to\nbe reliable. Software testing is a standard approach for quality assurance of\nembedded software, and many software development processes strive for test\nautomation. Out of the many challenges for successful software test automation,\nthis thesis addresses five: (i) understanding how updated software reaches a\ntest environment, how testing is conducted in the test environment, and how\ntest results reach the developers that updated the software in the first place;\n(ii) selecting which test cases to execute in a test suite given constraints on\navailable time and test systems; (iii) given that the test cases are run on\ndifferent configurations of connected devices, selecting which hardware to use\nfor each test case to be executed; (iv) analyzing test cases that, when\nexecuted over time on evolving software, testware or hardware revisions, appear\nto randomly fail; and (v) making test results information actionable with test\nresults exploration and visualization. The challenges are tackled in several\nways. [Abstract truncated.]",
    "descriptor": "\nComments: This is a compact version of the introduction (kappa) of my doctoral thesis. The public defense will take place at M\\\"alardalen University, room Gamma (V\\\"aster{\\aa}s Campus) and Teams at 13.15 on November 22, 2021\n",
    "authors": [
      "Per Erik Strandberg"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.08312"
  },
  {
    "id": "arXiv:2111.08313",
    "title": "NENet: Monocular Depth Estimation via Neural Ensembles",
    "abstract": "Depth estimation is getting a widespread popularity in the computer vision\ncommunity, and it is still quite difficult to recover an accurate depth map\nusing only one single RGB image. In this work, we observe a phenomenon that\nexisting methods tend to exhibit asymmetric errors, which might open up a new\ndirection for accurate and robust depth estimation. We carefully investigate\ninto the phenomenon, and construct a two-level ensemble scheme, NENet, to\nintegrate multiple predictions from diverse base predictors. The NENet forms a\nmore reliable depth estimator, which substantially boosts the performance over\nbase predictors. Notably, this is the first attempt to introduce ensemble\nlearning and evaluate its utility for monocular depth estimation to the best of\nour knowledge. Extensive experiments demonstrate that the proposed NENet\nachieves better results than previous state-of-the-art approaches on the\nNYU-Depth-v2 and KITTI datasets. In particular, our method improves previous\nstate-of-the-art methods from 0.365 to 0.349 on the metric RMSE on the NYU\ndataset. To validate the generalizability across cameras, we directly apply the\nmodels trained on the NYU dataset to the SUN RGB-D dataset without any\nfine-tuning, and achieve the superior results, which indicate its strong\ngeneralizability. The source code and trained models will be publicly available\nupon the acceptance.",
    "descriptor": "",
    "authors": [
      "Shuwei Shao",
      "Ran Li",
      "Zhongcai Pei",
      "Zhong Liu",
      "Weihai Chen",
      "Wentao Zhu",
      "Xingming Wu",
      "Baochang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08313"
  },
  {
    "id": "arXiv:2111.08314",
    "title": "TRIG: Transformer-Based Text Recognizer with Initial Embedding Guidance",
    "abstract": "Scene text recognition (STR) is an important bridge between images and text,\nattracting abundant research attention. While convolutional neural networks\n(CNNS) have achieved remarkable progress in this task, most of the existing\nworks need an extra module (context modeling module) to help CNN to capture\nglobal dependencies to solve the inductive bias and strengthen the relationship\nbetween text features. Recently, the transformer has been proposed as a\npromising network for global context modeling by self-attention mechanism, but\none of the main shortcomings, when applied to recognition, is the efficiency.\nWe propose a 1-D split to address the challenges of complexity and replace the\nCNN with the transformer encoder to reduce the need for a context modeling\nmodule. Furthermore, recent methods use a frozen initial embedding to guide the\ndecoder to decode the features to text, leading to a loss of accuracy. We\npropose to use a learnable initial embedding learned from the transformer\nencoder to make it adaptive to different input images. Above all, we introduce\na novel architecture for text recognition, named TRansformer-based text\nrecognizer with Initial embedding Guidance (TRIG), composed of three stages\n(transformation, feature extraction, and prediction). Extensive experiments\nshow that our approach can achieve state-of-the-art on text recognition\nbenchmarks.",
    "descriptor": "",
    "authors": [
      "Yue Tao",
      "Zhiwei Jia",
      "Runze Ma",
      "Shugong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08314"
  },
  {
    "id": "arXiv:2111.08318",
    "title": "DRINet++: Efficient Voxel-as-point Point Cloud Segmentation",
    "abstract": "Recently, many approaches have been proposed through single or multiple\nrepresentations to improve the performance of point cloud semantic\nsegmentation. However, these works do not maintain a good balance among\nperformance, efficiency, and memory consumption. To address these issues, we\npropose DRINet++ that extends DRINet by enhancing the sparsity and geometric\nproperties of a point cloud with a voxel-as-point principle. To improve\nefficiency and performance, DRINet++ mainly consists of two modules: Sparse\nFeature Encoder and Sparse Geometry Feature Enhancement. The Sparse Feature\nEncoder extracts the local context information for each point, and the Sparse\nGeometry Feature Enhancement enhances the geometric properties of a sparse\npoint cloud via multi-scale sparse projection and attentive multi-scale fusion.\nIn addition, we propose deep sparse supervision in the training phase to help\nconvergence and alleviate the memory consumption problem. Our DRINet++ achieves\nstate-of-the-art outdoor point cloud segmentation on both SemanticKITTI and\nNuscenes datasets while running significantly faster and consuming less memory.",
    "descriptor": "",
    "authors": [
      "Maosheng Ye",
      "Rui Wan",
      "Shuangjie Xu",
      "Tongyi Cao",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.08318"
  },
  {
    "id": "arXiv:2111.08319",
    "title": "A Performance Bound for Model Based Online Reinforcement Learning",
    "abstract": "Model based reinforcement learning (RL) refers to an approximate optimal\ncontrol design for infinite-horizon (IH) problems that aims at approximating\nthe optimal IH controller and associated cost parametrically. In online RL, the\ntraining process of the respective approximators is performed along the de\nfacto system trajectory (potentially in addition to offline data). While there\nexist stability results for online RL, the IH controller performance has been\naddressed only fragmentary, rarely considering the parametric and error-prone\nnature of the approximation explicitly even in the model based case. To assess\nthe performance for such a case, this work utilizes a model predictive control\nframework to mimic an online RL controller. More precisely, the optimization\nbased controller is associated with an online adapted approximate cost which\nserves as a terminal cost function. The results include a stability and\nperformance estimate statement for the control and training scheme and\ndemonstrate the dependence of the controller's performance bound on the error\nresulting from parameterized cost approximation.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Lukas Beckenbach",
      "Stefan Streif"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.08319"
  },
  {
    "id": "arXiv:2111.08320",
    "title": "Which CNNs and Training Settings to Choose for Action Unit Detection? A  Study Based on a Large-Scale Dataset",
    "abstract": "In this paper we explore the influence of some frequently used Convolutional\nNeural Networks (CNNs), training settings, and training set structures, on\nAction Unit (AU) detection. Specifically, we first compare 10 different shallow\nand deep CNNs in AU detection. Second, we investigate how the different\ntraining settings (i.e. centering/normalizing the inputs, using different\naugmentation severities, and balancing the data) impact the performance in AU\ndetection. Third, we explore the effect of increasing the number of labelled\nsubjects and frames in the training set on the AU detection performance. These\ncomparisons provide the research community with useful tips about the choice of\ndifferent CNNs and training settings in AU detection. In our analysis, we use a\nlarge-scale naturalistic dataset, consisting of ~55K videos captured in the\nwild. To the best of our knowledge, there is no work that had investigated the\nimpact of such settings on a large-scale AU dataset.",
    "descriptor": "\nComments: FG 2021\n",
    "authors": [
      "Mina Bishay",
      "Ahmed Ghoneim",
      "Mohamed Ashraf",
      "Mohammad Mavadati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08320"
  },
  {
    "id": "arXiv:2111.08322",
    "title": "An Empirical Study of Finding Similar Exercises",
    "abstract": "Education artificial intelligence aims to profit tasks in the education\ndomain such as intelligent test paper generation and consolidation exercises\nwhere the main technique behind is how to match the exercises, known as the\nfinding similar exercises(FSE) problem. Most of these approaches emphasized\ntheir model abilities to represent the exercise, unfortunately there are still\nmany challenges such as the scarcity of data, insufficient understanding of\nexercises and high label noises. We release a Chinese education pre-trained\nlanguage model BERT$_{Edu}$ for the label-scarce dataset and introduce the\nexercise normalization to overcome the diversity of mathematical formulas and\nterms in exercise. We discover new auxiliary tasks in an innovative way depends\non problem-solving ideas and propose a very effective MoE enhanced multi-task\nmodel for FSE task to attain better understanding of exercises. In addition,\nconfidence learning was utilized to prune train-set and overcome high noises in\nlabeling data. Experiments show that these methods proposed in this paper are\nvery effective.",
    "descriptor": "\nComments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Workshop on Math AI for Education(MATHAI4ED)\n",
    "authors": [
      "Tongwen Huang",
      "Xihua Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08322"
  },
  {
    "id": "arXiv:2111.08324",
    "title": "Choose Settings Carefully: Comparing Action Unit detection at Different  Settings Using a Large-Scale Dataset",
    "abstract": "In this paper, we investigate the impact of some of the commonly used\nsettings for (a) preprocessing face images, and (b) classification and\ntraining, on Action Unit (AU) detection performance and complexity. We use in\nour investigation a large-scale dataset, consisting of ~55K videos collected in\nthe wild for participants watching commercial ads. The preprocessing settings\ninclude scaling the face to a fixed resolution, changing the color information\n(RGB to gray-scale), aligning the face, and cropping AU regions, while the\nclassification and training settings include the kind of classifier\n(multi-label vs. binary) and the amount of data used for training models. To\nthe best of our knowledge, no work had investigated the effect of those\nsettings on AU detection. In our analysis we use CNNs as our baseline\nclassification model.",
    "descriptor": "\nComments: ICIP 2021\n",
    "authors": [
      "Mina Bishay",
      "Ahmed Ghoneim",
      "Mohamed Ashraf",
      "Mohammad Mavadati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08324"
  },
  {
    "id": "arXiv:2111.08326",
    "title": "Moving the Network to the Cloud: the Cloud Central Office Revolution and  its Implications for the Optical Layer",
    "abstract": "SDN and NFV have recently changed the way we operate networks. By decoupling\ncontrol and data plane operations and virtualising their components, they have\nopened up new frontiers towards reducing network ownership costs and improving\nusability and efficiency. Recently, their applicability has moved towards\npublic telecommunications networks, with concepts such as the cloud-CO that\nhave pioneered its use in access and metro networks: an idea that has quickly\nattracted the interest of network operators. By merging mobile, residential and\nenterprise services into a common framework, built around commoditised data\ncentre types of architectures, future embodiments of this CO virtualisation\nconcept could achieve significant capital and operational cost savings, while\nproviding customised network experience to high-capacity and low-latency future\napplications.\nThis tutorial provides an overview of the various frameworks and\narchitectures outlining current network disaggregation trends that are leading\nto the virtualisation/cloudification of central offices. It also provides\ninsight on the virtualisation of the access-metro network, showcasing new\nsoftware functionalities like the virtual \\ac{DBA} mechanisms for \\acp{PON}. In\naddition, we explore how it can bring together different network technologies\nto enable convergence of mobile and optical access networks and pave the way\nfor the integration of disaggregated ROADM networks. Finally, this paper\ndiscusses some of the open challenges towards the realisation of networks\ncapable of delivering guaranteed performance, while sharing resources across\nmultiple operators and services.",
    "descriptor": "",
    "authors": [
      "M. Ruffini",
      "F. Slyne"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.08326"
  },
  {
    "id": "arXiv:2111.08327",
    "title": "Detecting acoustic reflectors using a robot's ego-noise",
    "abstract": "In this paper, we propose a method to estimate the proximity of an acoustic\nreflector, e.g., a wall, using ego-noise, i.e., the noise produced by the\nmoving parts of a listening robot. This is achieved by estimating the times of\narrival of acoustic echoes reflected from the surface. Simulated experiments\nshow that the proposed nonintrusive approach is capable of accurately\nestimating the distance of a reflector up to 1 meter and outperforms a\npreviously proposed intrusive approach under loud ego-noise conditions. The\nproposed method is helped by a probabilistic echo detector that estimates\nwhether or not an acoustic reflector is within a short range of the robotic\nplatform. This preliminary investigation paves the way towards a new kind of\ncollision avoidance system that would purely rely on audio sensors rather than\nconventional proximity sensors.",
    "descriptor": "",
    "authors": [
      "Usama Saqib",
      "Antoine Deleforge",
      "Jesper Jensen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.08327"
  },
  {
    "id": "arXiv:2111.08328",
    "title": "On The Complexity of Maximizing Temporal Reachability via Trip  Temporalisation",
    "abstract": "We consider the problem of assigning appearing times to the edges of a\ndigraph in order to maximize the (average) temporal reachability between pairs\nof nodes. Motivated by the application to public transit networks, where edges\ncannot be scheduled independently one of another, we consider the setting where\nthe edges are grouped into certain walks (called trips) in the digraph and\nwhere assigning the appearing time to the first edge of a trip forces the\nappearing times of the subsequent edges. In this setting, we show that, quite\nsurprisingly, it is NP-complete to decide whether there exists an assignment of\ntimes connecting a given pair of nodes. This result allows us to prove that the\nproblem of maximising the temporal reachability cannot be approximated within a\nfactor better than some polynomial term in the size of the graph. We thus focus\non the case where, for each pair of nodes, there exists an assignment of times\nsuch that one node is reachable from the other. We call this property strong\ntemporalisability. It is a very natural assumption for the application to\npublic transit networks. On the negative side, the problem of maximising the\ntemporal reachability remains hard to approximate within a factor $\\sqrt$ n/12\nin that setting. Moreover, we show the existence of collections of trips that\nare strongly temporalisable but for which any assignment of starting times to\nthe trips connects at most an O(1/ $\\sqrt$ n) fraction of all pairs of nodes.\nOn the positive side, we show that there must exist an assignment of times that\nconnects a constant fraction of all pairs in the strongly temporalisable and\nsymmetric case, that is, when the set of trips to be scheduled is such that,\nfor each trip, there is a symmetric trip visiting the same nodes in reverse\norder. Keywords:edge labeling edge scheduled network network optimisation\ntemporal graph temporal path temporal reachability time assignment",
    "descriptor": "",
    "authors": [
      "Filippo Brunelli",
      "Pierluigi Crescenzi",
      "Laurent Viennot"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.08328"
  },
  {
    "id": "arXiv:2111.08333",
    "title": "Reshaping Smart Energy Transition: An analysis of human-building  interactions in Qatar Using Machine Learning Techniques",
    "abstract": "Policy Planning have the potential to contribute to the strategic development\nand economic diversification of developing countries even without considerable\nstructural changes. In this study, we analyzed a set of human-oriented\ndimensions aimed at improving energy policies related to the building sector in\nQatar. Considering the high percentage of expatriate and migrant communities\nwith different financial and cultural backgrounds and behavioral patterns\ncompared with local communities in the GCC Union, it is required to investigate\nhuman dimensions to propose adequate energy policies. This study explored the\ncorrelations of socioeconomic, behavioral, and demographic dimensions to\ndetermine the main factors behind discrepancies in energy use,\nresponsibilities, motivations, habits, and overall well-being. The sample\nincluded 2,200 people in Qatar, and it was clustered into two consumer\ncategories: high and low. In particular, the study focused on exploring human\nindoor comfort perception dependencies with building features. Financial\ndrivers, such as demand programs and energy subsidies, were explored in\nrelation to behavioral patterns. Subsequently, the data analysis resulted in\nimplications for energy policies regarding interventions, social well-being,\nand awareness. Machine learning methods were used to perform a feature\nimportance analysis to determine the main factors of human behavior. The\nfindings of this study demonstrated how human factors impact comfort perception\nin residential and work environments, norms, habits, self-responsibility,\nconsequence awareness, and consumption. The study has important implications\nfor developing targeted strategies aimed at improving the efficacy of energy\npolicies and sustainability performance indicators.",
    "descriptor": "\nComments: 57th ISOCARP World Planning Congress, Doha, Qatar, 17 pages, 20 figures\n",
    "authors": [
      "Rateb Jabbar",
      "Esmat Zaidan",
      "Ahmed ben Said",
      "Ali Ghofrani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08333"
  },
  {
    "id": "arXiv:2111.08334",
    "title": "Pansharpening by convolutional neural networks in the full resolution  framework",
    "abstract": "In recent years, there has been a growing interest on deep learning-based\npansharpening. Research has mainly focused on architectures. However, lacking a\nground truth, model training is also a major issue. A popular approach is to\ntrain networks in a reduced resolution domain, using the original data as\nground truths. The trained networks are then used on full resolution data,\nrelying on an implicit scale invariance hypothesis. Results are generally good\nat reduced resolution, but more questionable at full resolution. Here, we\npropose a full-resolution training framework for deep learning-based\npansharpening. Training takes place in the high resolution domain, relying only\non the original data, with no loss of information. To ensure spectral and\nspatial fidelity, suitable losses are defined, which force the pansharpened\noutput to be consistent with the available panchromatic and multispectral\ninput. Experiments carried out on WorldView-3, WorldView-2, and GeoEye-1 images\nshow that methods trained with the proposed framework guarantee an excellent\nperformance in terms of both full-resolution numerical indexes and visual\nquality. The framework is fully general, and can be used to train and fine-tune\nany deep learning-based pansharpening network.",
    "descriptor": "",
    "authors": [
      "Matteo Ciotola",
      "Sergio Vitale",
      "Antonio Mazza",
      "Giovanni Poggi",
      "Giuseppe Scarpa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.08334"
  },
  {
    "id": "arXiv:2111.08342",
    "title": "Perfect Conductor Boundary Conditions for Geometric Particle-in-Cell  Simulations of the Vlasov-Maxwell System in Curvilinear Coordinates",
    "abstract": "Structure-preserving methods can be derived for the Vlasov-Maxwell system\nfrom a discretisation of the Poisson bracket with compatible finite-elements\nfor the fields and a particle representation of the distribution function.\nThese geometric electromagnetic particle-in-cell (GEMPIC) discretisations\nfeature excellent conservation properties and long-time numerical stability.\nThis paper extends the GEMPIC formulation in curvilinear coordinates to\nrealistic boundary conditions. We build a de Rham sequence based on spline\nfunctions with clamped boundaries and apply perfect conductor boundary\nconditions for the fields and reflecting boundary conditions for the particles.\nThe spatial semi-discretisation forms a discrete Poisson system. Time\ndiscretisation is either done by Hamiltonian splitting yielding a semi-explicit\nGauss conserving scheme or by a discrete gradient scheme applied to a Poisson\nsplitting yielding a semi-implicit energy-conserving scheme. Our system\nrequires the inversion of the spline finite element mass matrices, which we\nprecondition with the combination of a Jacobi preconditioner and the spectrum\nof the mass matrices on a periodic tensor product grid.",
    "descriptor": "",
    "authors": [
      "Benedikt Perse",
      "Katharina Kormann",
      "Eric Sonnendr\u00fccker"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.08342"
  },
  {
    "id": "arXiv:2111.08344",
    "title": "Mathematical Models for Local Sensing Hashes",
    "abstract": "As data volumes continue to grow, searches in data are becoming increasingly\ntime-consuming. Classical index structures for neighbor search are no longer\nsustainable due to the \"curse of dimensionality\". Instead, approximated index\nstructures offer a good opportunity to significantly accelerate the neighbor\nsearch for clustering and outlier detection and to have the lowest possible\nerror rate in the results of the algorithms. Local sensing hashes is one of\nthose. We indicate directions to mathematically model the properties of it.",
    "descriptor": "",
    "authors": [
      "Li Wang",
      "Lilon Wangner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.08344"
  },
  {
    "id": "arXiv:2111.08348",
    "title": "Self-Stabilization and Byzantine Tolerance for Maximal Independent Set",
    "abstract": "We analyze the impact of transient and Byzantine faults on the construction\nof a maximal independent set in a general network. We adapt the\nself-stabilizing algorithm presented by Turau \\cite{turau2007linear} for\ncomputing such a vertex set. Our algorithm is self-stabilizing and also works\nunder the more difficult context of arbitrary Byzantine faults.\nByzantine nodes can prevent nodes close to them from taking part in the\nindependent set for an arbitrarily long time. We give boundaries to their\nimpact by focusing on the set of all nodes excluding nodes at distance 1 or\nless of Byzantine nodes, and excluding some of the nodes at distance 2. As far\nas we know, we present the first algorithm tolerating both transient and\nByzantine faults under the fair distributed daemon. We prove that this\nalgorithm converges in $ \\mathcal O(\\Delta n)$ rounds w.h.p., where $n$ and\n$\\Delta$ are the size and the maximum degree of the network, resp.\nAdditionally, we present a modified version of this algorithm for anonymous\nsystems under the adversarial distributed daemon that converges in\n$ \\mathcal O(n^{2})$ expected number of steps.",
    "descriptor": "\nComments: This article is long version of Self-Stabilization and Byzantine Tolerance for Maximal Independant Set in 23rd International Symposium on Stabilization, Safety, and Security of Distributed Systems\n",
    "authors": [
      "Johanne Cohen",
      "Laurence Pilard",
      "Jonas S\u00e9nizergues"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.08348"
  },
  {
    "id": "arXiv:2111.08349",
    "title": "SEnSeI: A Deep Learning Module for Creating Sensor Independent Cloud  Masks",
    "abstract": "We introduce a novel neural network architecture -- Spectral ENcoder for\nSEnsor Independence (SEnSeI) -- by which several multispectral instruments,\neach with different combinations of spectral bands, can be used to train a\ngeneralised deep learning model. We focus on the problem of cloud masking,\nusing several pre-existing datasets, and a new, freely available dataset for\nSentinel-2. Our model is shown to achieve state-of-the-art performance on the\nsatellites it was trained on (Sentinel-2 and Landsat 8), and is able to\nextrapolate to sensors it has not seen during training such as Landsat 7,\nPer\\'uSat-1, and Sentinel-3 SLSTR. Model performance is shown to improve when\nmultiple satellites are used in training, approaching or surpassing the\nperformance of specialised, single-sensor models. This work is motivated by the\nfact that the remote sensing community has access to data taken with a hugely\nvariety of sensors. This has inevitably led to labelling efforts being\nundertaken separately for different sensors, which limits the performance of\ndeep learning models, given their need for huge training sets to perform\noptimally. Sensor independence can enable deep learning models to utilise\nmultiple datasets for training simultaneously, boosting performance and making\nthem much more widely applicable. This may lead to deep learning approaches\nbeing used more frequently for on-board applications and in ground segment data\nprocessing, which generally require models to be ready at launch or soon\nafterwards.",
    "descriptor": "\nComments: 22 pages, 7 figures. This is an accepted version of work to be published in the IEEE Transactions on Geoscience and Remote Sensing\n",
    "authors": [
      "Alistair Francis",
      "John Mrziglod",
      "Panagiotis Sidiropoulos",
      "Jan-Peter Muller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08349"
  },
  {
    "id": "arXiv:2111.08350",
    "title": "Learning Equilibria in Mean-Field Games: Introducing Mean-Field PSRO",
    "abstract": "Recent advances in multiagent learning have seen the introduction ofa family\nof algorithms that revolve around the population-based trainingmethod PSRO,\nshowing convergence to Nash, correlated and coarse corre-lated equilibria.\nNotably, when the number of agents increases, learningbest-responses becomes\nexponentially more difficult, and as such ham-pers PSRO training methods. The\nparadigm of mean-field games pro-vides an asymptotic solution to this problem\nwhen the considered gamesare anonymous-symmetric. Unfortunately, the mean-field\napproximationintroduces non-linearities which prevent a straightforward\nadaptation ofPSRO. Building upon optimization and adversarial regret\nminimization,this paper sidesteps this issue and introduces mean-field PSRO, an\nadap-tation of PSRO which learns Nash, coarse correlated and correlated\nequi-libria in mean-field games. The key is to replace the exact\ndistributioncomputation step by newly-defined mean-field no-adversarial-regret\nlearn-ers, or by black-box optimization. We compare the asymptotic complexityof\nthe approach to standard PSRO, greatly improve empirical bandit con-vergence\nspeed by compressing temporal mixture weights, and ensure itis theoretically\nrobust to payoff noise. Finally, we illustrate the speed andaccuracy of\nmean-field PSRO on several mean-field games, demonstratingconvergence to strong\nand weak equilibria.",
    "descriptor": "",
    "authors": [
      "Paul Muller",
      "Mark Rowland",
      "Romuald Elie",
      "Georgios Piliouras",
      "Julien Perolat",
      "Mathieu Lauriere",
      "Raphael Marinier",
      "Olivier Pietquin",
      "Karl Tuyls"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.08350"
  },
  {
    "id": "arXiv:2111.08352",
    "title": "On The Number of Different Entries in Involutory MDS Matrices over  Finite Fields of Characteristic Two",
    "abstract": "Two of many criteria of a good MDS matrix are being involutory and having few\ndifferent elements. This paper investigates the number of different entries in\nan involutory MDS matrices of order 1, 2, 3, and 4 over finite fields of\ncharacteristic two. There are at least three and four different elements in an\ninvolutory MDS matrices with, respectively, order three and four, over finite\nfields of characteristic two.",
    "descriptor": "\nComments: The following article has been accepted by AIP Conference Proceedings. Presented (online) in The International Conference on Mathematical Sciences and Technology, (MathTech) 2020 in School of Mathematical Sciences, Universiti Sains Malaysia\n",
    "authors": [
      "Muhammad Afifurrahman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.08352"
  },
  {
    "id": "arXiv:2111.08355",
    "title": "Hybrid Reflection Modulation",
    "abstract": "Reconfigurable intelligent surface (RIS)-empowered communication has emerged\nas a novel concept for customizing future wireless environments in a cost- and\nenergy-efficient way. However, due to double path loss, existing fully passive\nRIS systems that purely reflect the incident signals into preferred directions\nattain an unsatisfactory performance improvement over the traditional wireless\nnetworks in certain conditions. To overcome this bottleneck, we propose a novel\ntransmission scheme, named hybrid reflection modulation (HRM), exploiting both\nactive and passive reflecting elements at the RIS and their combinations, which\nenables to convey information without using any radio frequency (RF) chains. In\nthe HRM scheme, the active reflecting elements using additional power\namplifiers are able to amplify and reflect the incoming signal, while the\nremaining passive elements can simply reflect the signals with appropriate\nphase shifts. Based on this novel transmission model, we obtain an upper bound\nfor the average bit error probability (ABEP), and derive achievable rate of the\nsystem using an information theoretic approach. Moreover, comprehensive\ncomputer simulations are performed to prove the superiority of the proposed HRM\nscheme over existing fully passive, fully active and reflection modulation (RM)\nsystems.",
    "descriptor": "\nComments: 9 pages, 9 figures\n",
    "authors": [
      "Zehra Yigit",
      "Ertugrul Basar",
      "Miaowen Wen",
      "Ibrahim Altunbas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08355"
  },
  {
    "id": "arXiv:2111.08356",
    "title": "Inference-Time Personalized Federated Learning",
    "abstract": "In Federated learning (FL), multiple clients collaborate to learn a model\nthrough a central server but keep the data decentralized. Personalized\nfederated learning (PFL) further extends FL to handle data heterogeneity\nbetween clients by learning personalized models. In both FL and PFL, all\nclients participate in the training process and their labeled data is used for\ntraining. However, in reality, novel clients may wish to join a prediction\nservice after it has been deployed, obtaining predictions for their own\nunlabeled data.\nHere, we defined a new learning setup, Inference-Time PFL (IT-PFL), where a\nmodel trained on a set of clients, needs to be later evaluated on novel\nunlabeled clients at inference time. We propose a novel approach to this\nproblem IT-PFL-HN, based on a hypernetwork module and an encoder module.\nSpecifically, we train an encoder network that learns a representation for a\nclient given its unlabeled data. That client representation is fed to a\nhypernetwork that generates a personalized model for that client. Evaluated on\nfour benchmark datasets, we find that IT-PFL-HN generalizes better than current\nFL and PFL methods, especially when the novel client has a large domain shift.\nWe also analyzed the generalization error for the novel client, showing how it\ncan be bounded using results from multi-task learning and domain adaptation.\nFinally, since novel clients do not contribute their data to training, they can\npotentially have better control over their data privacy; indeed, we showed\nanalytically and experimentally how novel clients can apply differential\nprivacy to their data.",
    "descriptor": "",
    "authors": [
      "Ohad Amosy",
      "Gal Eyal",
      "Gal Chechik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08356"
  },
  {
    "id": "arXiv:2111.08357",
    "title": "A first approach to closeness distributions",
    "abstract": "Probabilistic graphical models allow us to encode a large probability\ndistribution as a composition of smaller ones. It is oftentimes the case that\nwe are interested in incorporating in the model the idea that some of these\nsmaller distributions are likely to be similar to one another. In this paper we\nprovide an information geometric approach on how to incorporate this\ninformation, and see that it allows us to reinterpret some already existing\nmodels.",
    "descriptor": "",
    "authors": [
      "Jesus Cerquides"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08357"
  },
  {
    "id": "arXiv:2111.08361",
    "title": "From Convolutions towards Spikes: The Environmental Metric that the  Community currently Misses",
    "abstract": "Today, the AI community is obsessed with 'state-of-the-art' scores (80%\npapers in NeurIPS) as the major performance metrics, due to which an important\nparameter, i.e., the environmental metric, remains unreported. Computational\ncapabilities were a limiting factor a decade ago; however, in foreseeable\nfuture circumstances, the challenge will be to develop environment-friendly and\npower-efficient algorithms. The human brain, which has been optimizing itself\nfor almost a million years, consumes the same amount of power as a typical\nlaptop. Therefore, developing nature-inspired algorithms is one solution to it.\nIn this study, we show that currently used ANNs are not what we find in nature,\nand why, although having lower performance, spiking neural networks, which\nmirror the mammalian visual cortex, have attracted much interest. We further\nhighlight the hardware gaps restricting the researchers from using spike-based\ncomputation for developing neuromorphic energy-efficient microchips on a large\nscale. Using neuromorphic processors instead of traditional GPUs might be more\nenvironment friendly and efficient. These processors will turn SNNs into an\nideal solution for the problem. This paper presents in-depth attention\nhighlighting the current gaps, the lack of comparative research, while\nproposing new research directions at the intersection of two fields --\nneuroscience and deep learning. Further, we define a new evaluation metric\n'NATURE' for reporting the carbon footprint of AI models.",
    "descriptor": "\nComments: NeurIPS 2021 Human-Centered AI Workshop\n",
    "authors": [
      "Aviral Chharia",
      "Shivu Chauhan",
      "Rahul Upadhyay",
      "Vinay Kumar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08361"
  },
  {
    "id": "arXiv:2111.08363",
    "title": "Batch Model Predictive Control for Selective Laser Melting",
    "abstract": "Selective laser melting is a promising additive manufacturing technology\nenabling the fabrication of highly customizable products. A major challenge in\nselective laser melting is ensuring the quality of produced parts, which is\ninfluenced greatly by the thermal history of printed layers. We propose a\nBatch-Model Predictive Control technique based on the combination of model\npredictive control and iterative learning control. This approach succeeds in\nrejecting both repetitive and non-repetitive disturbances and thus achieves\nimproved tracking performance and process quality. In a simulation study, the\nselective laser melting dynamics is approximated with a reduced-order\ncontrol-oriented linear model to ensure reasonable computational complexity.\nThe proposed approach provides convergence to the desired temperature field\nprofile despite model uncertainty and disturbances.",
    "descriptor": "",
    "authors": [
      "Riccardo Zuliani",
      "Efe C. Balta",
      "Alisa Rupenyan",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.08363"
  },
  {
    "id": "arXiv:2111.08364",
    "title": "Learning to Navigate in a VUCA Environment: Hierarchical Multi-expert  Approach",
    "abstract": "Despite decades of efforts, robot navigation in a real scenario with\nvolatility, uncertainty, complexity, and ambiguity (VUCA for short), remains a\nchallenging topic. Inspired by the central nervous system (CNS), we propose a\nhierarchical multi-expert learning framework for autonomous navigation in a\nVUCA environment. With a heuristic exploration mechanism considering target\nlocation, path cost, and safety level, the upper layer performs simultaneous\nmap exploration and route-planning to avoid trapping in a blind alley, similar\nto the cerebrum in the CNS. Using a local adaptive model fusing multiple\ndiscrepant strategies, the lower layer pursuits a balance between\ncollision-avoidance and go-straight strategies, acting as the cerebellum in the\nCNS. We conduct simulation and real-world experiments on multiple platforms,\nincluding legged and wheeled robots. Experimental results demonstrate our\nalgorithm outperforms the existing methods in terms of task achievement, time\nefficiency, and security.",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "Wenqi Zhang",
      "Kai Zhao",
      "Peng Li",
      "Xiao Zhu",
      "Faping Ye",
      "Weijie Jiang",
      "Huiqiao Fu",
      "Tao Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.08364"
  },
  {
    "id": "arXiv:2111.08366",
    "title": "Multi-Vector Models with Textual Guidance for Fine-Grained Scientific  Document Similarity",
    "abstract": "We present Aspire, a new scientific document similarity model based on\nmatching fine-grained aspects. Our model is trained using co-citation contexts\nthat describe related paper aspects as a novel form of textual supervision. We\nuse multi-vector document representations, recently explored in settings with\nshort query texts but under-explored in the challenging document-document\nsetting. We present a fast method that involves matching only single sentence\npairs, and a method that makes sparse multiple matches with optimal transport.\nOur model improves performance on document similarity tasks across four\ndatasets. Moreover, our fast single-match method achieves competitive results,\nopening up the possibility of applying fine-grained document similarity models\nto large-scale scientific corpora.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Sheshera Mysore",
      "Arman Cohan",
      "Tom Hope"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.08366"
  },
  {
    "id": "arXiv:2111.08369",
    "title": "Introduction to Set Shaping Theory",
    "abstract": "In this article, we define the Set Shaping Theory whose goal is the study of\nthe bijection functions that transform a set of strings into a set of equal\nsize made up of strings of greater length. The functions that meet this\ncondition are many but since the goal of this theory is the transmission of\ndata, we have analyzed the function that minimizes the average information\ncontent. The results obtained show how this type of function can be useful in\ndata compression.",
    "descriptor": "",
    "authors": [
      "Solomon Kozlov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.08369"
  },
  {
    "id": "arXiv:2111.08370",
    "title": "Fight Detection from Still Images in the Wild",
    "abstract": "Detecting fights from still images shared on social media is an important\ntask required to limit the distribution of violent scenes in order to prevent\ntheir negative effects. For this reason, in this study, we address the problem\nof fight detection from still images collected from the web and social media.\nWe explore how well one can detect fights from just a single still image. We\nalso propose a new dataset, named Social Media Fight Images (SMFI), comprising\nreal-world images of fight actions. Results of the extensive experiments on the\nproposed dataset show that fight actions can be recognized successfully from\nstill images. That is, even without exploiting the temporal information, it is\npossible to detect fights with high accuracy by utilizing appearance only. We\nalso perform cross-dataset experiments to evaluate the representation capacity\nof the collected dataset. These experiments indicate that, as in the other\ncomputer vision problems, there exists a dataset bias for the fight recognition\nproblem. Although the methods achieve close to 100% accuracy when trained and\ntested on the same fight dataset, the cross-dataset accuracies are\nsignificantly lower, i.e., around 70% when more representative datasets are\nused for training. SMFI dataset is found to be one of the two most\nrepresentative datasets among the utilized five fight datasets.",
    "descriptor": "",
    "authors": [
      "\u015eeymanur Akt\u0131",
      "Ferda Ofli",
      "Muhammad Imran",
      "Haz\u0131m Kemal Ekenel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08370"
  },
  {
    "id": "arXiv:2111.08374",
    "title": "Literature-Augmented Clinical Outcome Prediction",
    "abstract": "Predictive models for medical outcomes hold great promise for enhancing\nclinical decision-making. These models are trained on rich patient data such as\nclinical notes, aggregating many patient signals into an outcome prediction.\nHowever, AI-based clinical models have typically been developed in isolation\nfrom the prominent paradigm of Evidence Based Medicine (EBM), in which medical\ndecisions are based on explicit evidence from existing literature. In this\nwork, we introduce techniques to help bridge this gap between EBM and AI-based\nclinical models, and show that these methods can improve predictive accuracy.\nWe propose a novel system that automatically retrieves patient-specific\nliterature based on intensive care (ICU) patient information, aggregates\nrelevant papers and fuses them with internal admission notes to form outcome\npredictions. Our model is able to substantially boost predictive accuracy on\nthree challenging tasks in comparison to strong recent baselines; for\nin-hospital mortality, we are able to boost top-10% precision by a large margin\nof over 25%.",
    "descriptor": "",
    "authors": [
      "Aakanksha Naik",
      "Sravanthi Parasa",
      "Sergey Feldman",
      "Lucy Lu Wang",
      "Tom Hope"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.08374"
  },
  {
    "id": "arXiv:2111.08380",
    "title": "Video Background Music Generation with Controllable Music Transformer",
    "abstract": "In this work, we address the task of video background music generation. Some\nprevious works achieve effective music generation but are unable to generate\nmelodious music tailored to a particular video, and none of them considers the\nvideo-music rhythmic consistency. To generate the background music that matches\nthe given video, we first establish the rhythmic relations between video and\nbackground music. In particular, we connect timing, motion speed, and motion\nsaliency from video with beat, simu-note density, and simu-note strength from\nmusic, respectively. We then propose CMT, a Controllable Music Transformer that\nenables local control of the aforementioned rhythmic features and global\ncontrol of the music genre and instruments. Objective and subjective\nevaluations show that the generated background music has achieved satisfactory\ncompatibility with the input videos, and at the same time, impressive music\nquality. Code and models are available at\nhttps://github.com/wzk1015/video-bgm-generation.",
    "descriptor": "\nComments: Accepted to ACM Multimedia 2021. Project website at this https URL\n",
    "authors": [
      "Shangzhe Di",
      "Zeren Jiang",
      "Si Liu",
      "Zhaokai Wang",
      "Leyan Zhu",
      "Zexin He",
      "Hongming Liu",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.08380"
  },
  {
    "id": "arXiv:2111.08383",
    "title": "Single Image Object Counting and Localizing using Active-Learning",
    "abstract": "The need to count and localize repeating objects in an image arises in\ndifferent scenarios, such as biological microscopy studies, production lines\ninspection, and surveillance recordings analysis. The use of supervised\nConvoutional Neural Networks (CNNs) achieves accurate object detection when\ntrained over large class-specific datasets. The labeling effort in this\napproach does not pay-off when the counting is required over few images of a\nunique object class.\nWe present a new method for counting and localizing repeating objects in\nsingle-image scenarios, assuming no pre-trained classifier is available. Our\nmethod trains a CNN over a small set of labels carefully collected from the\ninput image in few active-learning iterations. At each iteration, the latent\nspace of the network is analyzed to extract a minimal number of user-queries\nthat strives to both sample the in-class manifold as thoroughly as possible as\nwell as avoid redundant labels.\nCompared with existing user-assisted counting methods, our active-learning\niterations achieve state-of-the-art performance in terms of counting and\nlocalizing accuracy, number of user mouse clicks, and running-time. This\nevaluation was performed through a large user study over a wide range of image\nclasses with diverse conditions of illumination and occlusions.",
    "descriptor": "\nComments: Published in IEEE Winter Conference on Applications of Computer Vision (WACV) 2022\n",
    "authors": [
      "Inbar Huberman-Spiegelglas",
      "Raanan Fattal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08383"
  },
  {
    "id": "arXiv:2111.08386",
    "title": "Towards Generating Real-World Time Series Data",
    "abstract": "Time series data generation has drawn increasing attention in recent years.\nSeveral generative adversarial network (GAN) based methods have been proposed\nto tackle the problem usually with the assumption that the targeted time series\ndata are well-formatted and complete. However, real-world time series (RTS)\ndata are far away from this utopia, e.g., long sequences with variable lengths\nand informative missing data raise intractable challenges for designing\npowerful generation algorithms. In this paper, we propose a novel generative\nframework for RTS data - RTSGAN to tackle the aforementioned challenges. RTSGAN\nfirst learns an encoder-decoder module which provides a mapping between a time\nseries instance and a fixed-dimension latent vector and then learns a\ngeneration module to generate vectors in the same latent space. By combining\nthe generator and the decoder, RTSGAN is able to generate RTS which respect the\noriginal feature distributions and the temporal dynamics. To generate time\nseries with missing values, we further equip RTSGAN with an observation\nembedding layer and a decide-and-generate decoder to better utilize the\ninformative missing patterns. Experiments on the four RTS datasets show that\nthe proposed framework outperforms the previous generation methods in terms of\nsynthetic data utility for downstream classification and prediction tasks.",
    "descriptor": "\nComments: Accepted in 21th IEEE International Conference on Data Mining (ICDM 2021). Code is available at this https URL\n",
    "authors": [
      "Hengzhi Pei",
      "Kan Ren",
      "Yuqing Yang",
      "Chang Liu",
      "Tao Qin",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08386"
  },
  {
    "id": "arXiv:2111.08389",
    "title": "Analysis of Model-Free Reinforcement Learning Control Schemes on  self-balancing Wheeled Extendible System",
    "abstract": "Traditional linear control strategies have been extensively researched and\nutilized in many robotic and industrial applications and yet they dont respond\nto total dynamics of the systems To avoid tedious calculations for nonlinear\ncontrol schemes like H infinity control and Predictive Control application of\nReinforcement Learning can provide alternative solutions This article presents\nthe implementation of RL control with Deep Deterministic Policy Gradient and\nProximal Policy Optimization on a mobile selfbalancing Extendible Wheeled\nInverted Pendulum EWIP system Such RL models make the task of finding\nsatisfactory control scheme easier and respond to the dynamics effectively\nwhile self-tuning the parameters to provide better control In this article two\nRLbased controllers are pitted against an MPC controller to evaluate the\nperformance on the basis of state variables of the EWIP system while following\na specific desired trajectory",
    "descriptor": "",
    "authors": [
      "Kanishk .",
      "Rushil Kumar",
      "Vikas Rastogi",
      "Ajeet Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.08389"
  },
  {
    "id": "arXiv:2111.08397",
    "title": "CLARA: A Constrained Reinforcement Learning Based Resource Allocation  Framework for Network Slicing",
    "abstract": "As mobile networks proliferate, we are experiencing a strong diversification\nof services, which requires greater flexibility from the existing network.\nNetwork slicing is proposed as a promising solution for resource utilization in\n5G and future networks to address this dire need. In network slicing, dynamic\nresource orchestration and network slice management are crucial for maximizing\nresource utilization. Unfortunately, this process is too complex for\ntraditional approaches to be effective due to a lack of accurate models and\ndynamic hidden structures. We formulate the problem as a Constrained Markov\nDecision Process (CMDP) without knowing models and hidden structures.\nAdditionally, we propose to solve the problem using CLARA, a Constrained\nreinforcement LeArning based Resource Allocation algorithm. In particular, we\nanalyze cumulative and instantaneous constraints using adaptive interior-point\npolicy optimization and projection layer, respectively. Evaluations show that\nCLARA clearly outperforms baselines in resource allocation with service demand\nguarantees.",
    "descriptor": "\nComments: Paper accepted at IEEE BigData 2021\n",
    "authors": [
      "Yongshuai Liu",
      "Jiaxin Ding",
      "Zhi-Li Zhang",
      "Xin Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08397"
  },
  {
    "id": "arXiv:2111.08398",
    "title": "2.5D Vehicle Odometry Estimation",
    "abstract": "It is well understood that in ADAS applications, a good estimate of the pose\nof the vehicle is required. This paper proposes a metaphorically named 2.5D\nodometry, whereby the planar odometry derived from the yaw rate sensor and four\nwheel speed sensors is augmented by a linear model of suspension. While the\ncore of the planar odometry is a yaw rate model that is already understood in\nthe literature, we augment this by fitting a quadratic to the incoming signals,\nenabling interpolation, extrapolation, and a finer integration of the vehicle\nposition. We show, by experimental results with a DGPS/IMU reference, that this\nmodel provides highly accurate odometry estimates, compared with existing\nmethods. Utilising sensors that return the change in height of vehicle\nreference points with changing suspension configurations, we define a planar\nmodel of the vehicle suspension, thus augmenting the odometry model. We present\nan experimental framework and evaluations criteria by which the goodness of the\nodometry is evaluated and compared with existing methods. This odometry model\nhas been designed to support low-speed surround-view camera systems that are\nwell-known. Thus, we present some application results that show a performance\nboost for viewing and computer vision applications using the proposed odometry",
    "descriptor": "\nComments: 13 pages, 16 figures, 2 tables\n",
    "authors": [
      "Ciaran Eising",
      "Leroy-Francisco Pereira",
      "Jonathan Horgan",
      "Anbuchezhiyan Selvaraju",
      "John McDonald",
      "Paul Moran"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08398"
  },
  {
    "id": "arXiv:2111.08400",
    "title": "Integrated Semantic and Phonetic Post-correction for Chinese Speech  Recognition",
    "abstract": "Due to the recent advances of natural language processing, several works have\napplied the pre-trained masked language model (MLM) of BERT to the\npost-correction of speech recognition. However, existing pre-trained models\nonly consider the semantic correction while the phonetic features of words is\nneglected. The semantic-only post-correction will consequently decrease the\nperformance since homophonic errors are fairly common in Chinese ASR. In this\npaper, we proposed a novel approach to collectively exploit the contextualized\nrepresentation and the phonetic information between the error and its replacing\ncandidates to alleviate the error rate of Chinese ASR. Our experiment results\non real world speech recognition datasets showed that our proposed method has\nevidently lower CER than the baseline model, which utilized a pre-trained BERT\nMLM as the corrector.",
    "descriptor": "",
    "authors": [
      "Yi-Chang Chen",
      "Chun-Yen Cheng",
      "Chien-An Chen",
      "Ming-Chieh Sung",
      "Yi-Ren Yeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.08400"
  },
  {
    "id": "arXiv:2111.08401",
    "title": "Weakly-supervised fire segmentation by visualizing intermediate CNN  layers",
    "abstract": "Fire localization in images and videos is an important step for an autonomous\nsystem to combat fire incidents. State-of-art image segmentation methods based\non deep neural networks require a large number of pixel-annotated samples to\ntrain Convolutional Neural Networks (CNNs) in a fully-supervised manner. In\nthis paper, we consider weakly supervised segmentation of fire in images, in\nwhich only image labels are used to train the network. We show that in the case\nof fire segmentation, which is a binary segmentation problem, the mean value of\nfeatures in a mid-layer of classification CNN can perform better than\nconventional Class Activation Mapping (CAM) method. We also propose to further\nimprove the segmentation accuracy by adding a rotation equivariant\nregularization loss on the features of the last convolutional layer. Our\nresults show noticeable improvements over baseline method for weakly-supervised\nfire segmentation.",
    "descriptor": "",
    "authors": [
      "Milad Niknejad",
      "Alexandre Bernardino"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08401"
  },
  {
    "id": "arXiv:2111.08404",
    "title": "Practical Timing Side Channel Attacks on Memory Compression",
    "abstract": "Compression algorithms are widely used as they save memory without losing\ndata. However, elimination of redundant symbols and sequences in data leads to\na compression side channel. So far, compression attacks have only focused on\nthe compression-ratio side channel, i.e., the size of compressed data,and\nlargely targeted HTTP traffic and website content.\nIn this paper, we present the first memory compression attacks exploiting\ntiming side channels in compression algorithms, targeting a broad set of\napplications using compression. Our work systematically analyzes different\ncompression algorithms and demonstrates timing leakage in each. We present\nComprezzor,an evolutionary fuzzer which finds memory layouts that lead to\namplified latency differences for decompression and therefore enable remote\nattacks. We demonstrate a remote covert channel exploiting small local timing\ndifferences transmitting on average 643.25 bit/h over 14 hops over the\ninternet. We also demonstrate memory compression attacks that can leak secrets\nbytewise as well as in dictionary attacks in three different case studies.\nFirst, we show that an attacker can disclose secrets co-located and compressed\nwith attacker data in PHP applications using Memcached. Second, we present an\nattack that leaks database records from PostgreSQL, managed by a Python-Flask\napplication, over the internet. Third, we demonstrate an attack that leaks\nsecrets from transparently compressed pages with ZRAM,the memory compression\nmodule in Linux. We conclude that memory-compression attacks are a practical\nthreat.",
    "descriptor": "",
    "authors": [
      "Martin Schwarzl",
      "Pietro Borrello",
      "Gururaj Saileshwar",
      "Hanna M\u00fcller",
      "Michael Schwarz",
      "Daniel Gruss"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.08404"
  },
  {
    "id": "arXiv:2111.08406",
    "title": "Tridiagonal and Block Tridiagonal computed Sparse Preconditioners for  large Electrodynamic Electric Field Integral Equation (EFIE) Solution",
    "abstract": "In this work, we propose simple and efficient tridiagonal computed sparse\npreconditioners for improving the condition number for large compressed\nElectric Field Integral Equation (EFIE) Method of Moment (MoM) matrix. The\npreconditioner computation is based on the triangle and block triangle\ninteraction and filled tridiagonally. The computed preconditioner is highly\nsparse and retains the O(N) complexity of computation and preconditioner matrix\nsolution time. Numerical results show the efficiency and accuracy of the\nproposed preconditioner.",
    "descriptor": "",
    "authors": [
      "Yoginder Kumar Negi",
      "N. Balakrishnan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.08406"
  },
  {
    "id": "arXiv:2111.08408",
    "title": "STAMP 4 NLP -- An Agile Framework for Rapid Quality-Driven NLP  Applications Development",
    "abstract": "The progress in natural language processing (NLP) research over the last\nyears, offers novel business opportunities for companies, as automated user\ninteraction or improved data analysis. Building sophisticated NLP applications\nrequires dealing with modern machine learning (ML) technologies, which impedes\nenterprises from establishing successful NLP projects. Our experience in\napplied NLP research projects shows that the continuous integration of research\nprototypes in production-like environments with quality assurance builds trust\nin the software and shows convenience and usefulness regarding the business\ngoal. We introduce STAMP 4 NLP as an iterative and incremental process model\nfor developing NLP applications. With STAMP 4 NLP, we merge software\nengineering principles with best practices from data science. Instantiating our\nprocess model allows efficiently creating prototypes by utilizing templates,\nconventions, and implementations, enabling developers and data scientists to\nfocus on the business goals. Due to our iterative-incremental approach,\nbusinesses can deploy an enhanced version of the prototype to their software\nenvironment after every iteration, maximizing potential business value and\ntrust early and avoiding the cost of successful yet never deployed experiments.",
    "descriptor": "\nComments: Preprint of short paper for QUATIC 2021 conference\n",
    "authors": [
      "Philipp Kohl",
      "Oliver Schmidts",
      "Lars Kl\u00f6ser",
      "Henri Werth",
      "Bodo Kraft",
      "Albert Z\u00fcndorf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08408"
  },
  {
    "id": "arXiv:2111.08409",
    "title": "Grounding Psychological Shape Space in Convolutional Neural Networks",
    "abstract": "Shape information is crucial for human perception and cognition, and should\ntherefore also play a role in cognitive AI systems. We employ the\ninterdisciplinary framework of conceptual spaces, which proposes a geometric\nrepresentation of conceptual knowledge through low-dimensional interpretable\nsimilarity spaces. These similarity spaces are often based on psychological\ndissimilarity ratings for a small set of stimuli, which are then transformed\ninto a spatial representation by a technique called multidimensional scaling.\nUnfortunately, this approach is incapable of generalizing to novel stimuli. In\nthis paper, we use convolutional neural networks to learn a generalizable\nmapping between perceptual inputs (pixels of grayscale line drawings) and a\nrecently proposed psychological similarity space for the shape domain. We\ninvestigate different network architectures (classification network vs.\nautoencoder) and different training regimes (transfer learning vs. multi-task\nlearning). Our results indicate that a classification-based multi-task learning\nscenario yields the best results, but that its performance is relatively\nsensitive to the dimensionality of the similarity space.",
    "descriptor": "\nComments: accepted at CIFMA2021 (this https URL)\n",
    "authors": [
      "Lucas Bechberger",
      "Kai-Uwe K\u00fchnberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08409"
  },
  {
    "id": "arXiv:2111.08410",
    "title": "Thoughts on the Consistency between Ricci Flow and Neural Network  Behavior",
    "abstract": "The Ricci flow is a partial differential equation for evolving the metric in\na Riemannian manifold to make it more regular. However, in most cases, the\nRicci flow tends to develop singularities and lead to divergence of the\nsolution. In this paper, we propose the linearly nearly Euclidean metric to\nassist manifold micro-surgery, which means that we prove the dynamical\nstability and convergence of the metrics close to the linearly nearly Euclidean\nmetric under the Ricci-DeTurck flow. In practice, from the information geometry\nand mirror descent points of view, we give the steepest descent gradient flow\nfor neural networks on the linearly nearly Euclidean manifold. During the\ntraining process of the neural network, we observe that its metric will also\nregularly converge to the linearly nearly Euclidean metric, which is consistent\nwith the convergent behavior of linearly nearly Euclidean manifolds under\nRicci-DeTurck flow.",
    "descriptor": "",
    "authors": [
      "Jun Chen",
      "Tianxin Huang",
      "Wenzhou Chen",
      "Yong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.08410"
  },
  {
    "id": "arXiv:2111.08413",
    "title": "Improved Robustness of Vision Transformer via PreLayerNorm in Patch  Embedding",
    "abstract": "Vision transformers (ViTs) have recently demonstrated state-of-the-art\nperformance in a variety of vision tasks, replacing convolutional neural\nnetworks (CNNs). Meanwhile, since ViT has a different architecture than CNN, it\nmay behave differently. To investigate the reliability of ViT, this paper\nstudies the behavior and robustness of ViT. We compared the robustness of CNN\nand ViT by assuming various image corruptions that may appear in practical\nvision tasks. We confirmed that for most image transformations, ViT showed\nrobustness comparable to CNN or more improved. However, for contrast\nenhancement, severe performance degradations were consistently observed in ViT.\nFrom a detailed analysis, we identified a potential problem: positional\nembedding in ViT's patch embedding could work improperly when the color scale\nchanges. Here we claim the use of PreLayerNorm, a modified patch embedding\nstructure to ensure scale-invariant behavior of ViT. ViT with PreLayerNorm\nshowed improved robustness in various corruptions including contrast-varying\nenvironments.",
    "descriptor": "\nComments: 7 pages, 8 figures. Work in Progress\n",
    "authors": [
      "Bum Jun Kim",
      "Hyeyeon Choi",
      "Hyeonah Jang",
      "Dong Gu Lee",
      "Wonseok Jeong",
      "Sang Woo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08413"
  },
  {
    "id": "arXiv:2111.08415",
    "title": "Causal policy ranking",
    "abstract": "Policies trained via reinforcement learning (RL) are often very complex even\nfor simple tasks. In an episode with $n$ time steps, a policy will make $n$\ndecisions on actions to take, many of which may appear non-intuitive to the\nobserver. Moreover, it is not clear which of these decisions directly\ncontribute towards achieving the reward and how significant is their\ncontribution. Given a trained policy, we propose a black-box method based on\ncounterfactual reasoning that estimates the causal effect that these decisions\nhave on reward attainment and ranks the decisions according to this estimate.\nIn this preliminary work, we compare our measure against an alternative,\nnon-causal, ranking procedure, highlight the benefits of causality-based policy\nranking, and discuss potential future work integrating causal algorithms into\nthe interpretation of RL agent policies.",
    "descriptor": "\nComments: preprint; 6 pages. arXiv admin note: substantial text overlap with arXiv:2008.13607\n",
    "authors": [
      "Daniel McNamee",
      "Hana Chockler"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08415"
  },
  {
    "id": "arXiv:2111.08418",
    "title": "Complete topological asymptotic expansion for $L_2$ and $H^1$  tracking-type cost functionals in dimension two and three",
    "abstract": "In this paper, we study the topological asymptotic expansion of a topology\noptimisation problem that is constrained by the Poisson equation with the\ndesign/shape variable entering through the right hand side. Using an averaged\nadjoint approach, we give explicit formulas for topological derivatives of\narbitrary order for both an $L_2$ and $H^1$ tracking-type cost function in both\ndimension two and three and thereby derive the complete asymptotic expansion.\nAs the asymptotic behaviour of the fundamental solution of the Laplacian\ndiffers in dimension two and three, also the derivation of the topological\nexpansion significantly differs in dimension two and three. The complete\nexpansion for the $H^1$ cost functional directly follows from the analysis of\nthe variation of the state equation. However, the proof of the asymptotics of\nthe $L_2$ tracking-type cost functional is significantly more involved and,\nsurprisingly, the asymptotic behaviour of the bi-harmonic equation plays a\ncrucial role in our proof.",
    "descriptor": "",
    "authors": [
      "Phillip Baumann",
      "Peter Gangl",
      "Kevin Sturm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.08418"
  },
  {
    "id": "arXiv:2111.08419",
    "title": "Delta-GAN-Encoder: Encoding Semantic Changes for Explicit Image Editing,  using Few Synthetic Samples",
    "abstract": "Understating and controlling generative models' latent space is a complex\ntask.\nIn this paper, we propose a novel method for learning to control any desired\nattribute in a pre-trained GAN's latent space, for the purpose of editing\nsynthesized and real-world data samples accordingly.\nWe perform Sim2Real learning, relying on minimal samples to achieve an\nunlimited amount of continuous precise edits.\nWe present an Autoencoder-based model that learns to encode the semantics of\nchanges between images as a basis for editing new samples later on, achieving\nprecise desired results - example shown in Fig. 1.\nWhile previous editing methods rely on a known structure of latent spaces\n(e.g., linearity of some semantics in StyleGAN), our method inherently does not\nrequire any structural constraints.\nWe demonstrate our method in the domain of facial imagery: editing different\nexpressions, poses, and lighting attributes, achieving state-of-the-art\nresults.",
    "descriptor": "\nComments: 8 pages, 13 figures\n",
    "authors": [
      "Nir Diamant",
      "Nitsan Shandor",
      "Alex M Bronstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08419"
  },
  {
    "id": "arXiv:2111.08426",
    "title": "Formal Quantum Software Engineering: Introducing the Formal Methods of  Software Engineering to Quantum Computing",
    "abstract": "Quantum computing (QC) represents the future of computing systems, but the\ntools for reasoning about the quantum model of computation, in which the laws\nobeyed are those on the quantum mechanical scale, are still a mix of linear\nalgebra and Dirac notation; two subjects more suitable for physicists, rather\nthan computer scientists and software engineers. On this ground, we believe it\nis possible to provide a more intuitive approach to thinking and writing about\nquantum computing systems, in order to simplify the design of quantum\nalgorithms and the development of quantum software. In this paper, we move the\nfirst step in such direction, introducing a specification language as the tool\nto represent the operations of a quantum computer via axiomatic definitions, by\nadopting the same symbolisms and reasoning principles used by formal methods in\nsoftware engineering. We name this approach formal quantum software engineering\n(F-QSE). This work assumes familiarity with the basic principles of quantum\nmechanics (QM), with the use of Zed (Z) which is a formal language of software\nengineering (SE), and with the notation and techniques of first-order logic\n(FOL) and functional programming (FP).",
    "descriptor": "",
    "authors": [
      "Carmelo R. Cartiere"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.08426"
  },
  {
    "id": "arXiv:2111.08429",
    "title": "An Overview of Backdoor Attacks Against Deep Neural Networks and  Possible Defences",
    "abstract": "Together with impressive advances touching every aspect of our society, AI\ntechnology based on Deep Neural Networks (DNN) is bringing increasing security\nconcerns. While attacks operating at test time have monopolised the initial\nattention of researchers, backdoor attacks, exploiting the possibility of\ncorrupting DNN models by interfering with the training process, represents a\nfurther serious threat undermining the dependability of AI techniques. In a\nbackdoor attack, the attacker corrupts the training data so to induce an\nerroneous behaviour at test time. Test time errors, however, are activated only\nin the presence of a triggering event corresponding to a properly crafted input\nsample. In this way, the corrupted network continues to work as expected for\nregular inputs, and the malicious behaviour occurs only when the attacker\ndecides to activate the backdoor hidden within the network. In the last few\nyears, backdoor attacks have been the subject of an intense research activity\nfocusing on both the development of new classes of attacks, and the proposal of\npossible countermeasures. The goal of this overview paper is to review the\nworks published until now, classifying the different types of attacks and\ndefences proposed so far. The classification guiding the analysis is based on\nthe amount of control that the attacker has on the training process, and the\ncapability of the defender to verify the integrity of the data used for\ntraining, and to monitor the operations of the DNN at training and test time.\nAs such, the proposed analysis is particularly suited to highlight the\nstrengths and weaknesses of both attacks and defences with reference to the\napplication scenarios they are operating in.",
    "descriptor": "",
    "authors": [
      "Wei Guo",
      "Benedetta Tondi",
      "Mauro Barni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08429"
  },
  {
    "id": "arXiv:2111.08434",
    "title": "Robust 3D Scene Segmentation through Hierarchical and Learnable  Part-Fusion",
    "abstract": "3D semantic segmentation is a fundamental building block for several scene\nunderstanding applications such as autonomous driving, robotics and AR/VR.\nSeveral state-of-the-art semantic segmentation models suffer from the part\nmisclassification problem, wherein parts of the same object are labelled\nincorrectly. Previous methods have utilized hierarchical, iterative methods to\nfuse semantic and instance information, but they lack learnability in context\nfusion, and are computationally complex and heuristic driven. This paper\npresents Segment-Fusion, a novel attention-based method for hierarchical fusion\nof semantic and instance information to address the part misclassifications.\nThe presented method includes a graph segmentation algorithm for grouping\npoints into segments that pools point-wise features into segment-wise features,\na learnable attention-based network to fuse these segments based on their\nsemantic and instance features, and followed by a simple yet effective\nconnected component labelling algorithm to convert segment features to instance\nlabels. Segment-Fusion can be flexibly employed with any network architecture\nfor semantic/instance segmentation. It improves the qualitative and\nquantitative performance of several semantic segmentation backbones by upto 5%\nwhen evaluated on the ScanNet and S3DIS datasets.",
    "descriptor": "",
    "authors": [
      "Anirud Thyagharajan",
      "Benjamin Ummenhofer",
      "Prashant Laddha",
      "Om J Omer",
      "Sreenivas Subramoney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08434"
  },
  {
    "id": "arXiv:2111.08435",
    "title": "Free Will Belief as a consequence of Model-based Reinforcement Learning",
    "abstract": "The debate on whether or not humans have free will has been raging for\ncenturies. Although there are good arguments based on our current understanding\nof the laws of nature for the view that it is not possible for humans to have\nfree will, most people believe they do. This discrepancy begs for an\nexplanation. If we accept that we do not have free will, we are faced with two\nproblems: (1) while freedom is a very commonly used concept that everyone\nintuitively understands, what are we actually referring to when we say that an\naction or choice is \"free\" or not? And, (2) why is the belief in free will so\ncommon? Where does this belief come from, and what is its purpose, if any? In\nthis paper, we examine these questions from the perspective of reinforcement\nlearning (RL). RL is a framework originally developed for training artificial\nintelligence agents. However, it can also be used as a computational model of\nhuman decision making and learning, and by doing so, we propose that the first\nproblem can be answered by observing that people's common sense understanding\nof freedom is closely related to the information entropy of an RL agent's\nnormalized action values, while the second can be explained by the necessity\nfor agents to model themselves as if they could have taken decisions other than\nthose they actually took, when dealing with the temporal credit assignment\nproblem. Put simply, we suggest that by applying the RL framework as a model\nfor human learning it becomes evident that in order for us to learn efficiently\nand be intelligent we need to view ourselves as if we have free will.",
    "descriptor": "",
    "authors": [
      "Erik M. Rehn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08435"
  },
  {
    "id": "arXiv:2111.08438",
    "title": "Fourier Neural Networks for Function Approximation",
    "abstract": "The success of Neural networks in providing miraculous results when applied\nto a wide variety of tasks is astonishing. Insight in the working can be\nobtained by studying the universal approximation property of neural networks.\nIt is proved extensively that neural networks are universal approximators.\nFurther it is proved that deep Neural networks are better approximators. It is\nspecifically proved that for a narrow neural network to approximate a function\nwhich is otherwise implemented by a deep Neural network, the network take\nexponentially large number of neurons. In this work, we have implemented\nexisting methodologies for a variety of synthetic functions and identified\ntheir deficiencies. Further, we examined that Fourier neural network is able to\nperform fairly good with only two layers in the neural network. A modified\nFourier Neural network which has sinusoidal activation and two hidden layer is\nproposed and the results are tabulated.",
    "descriptor": "",
    "authors": [
      "R Subhash Chandra Bose",
      "Kakarla Yaswanth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08438"
  },
  {
    "id": "arXiv:2111.08440",
    "title": "On the Importance of Difficulty Calibration in Membership Inference  Attacks",
    "abstract": "The vulnerability of machine learning models to membership inference attacks\nhas received much attention in recent years. However, existing attacks mostly\nremain impractical due to having high false positive rates, where non-member\nsamples are often erroneously predicted as members. This type of error makes\nthe predicted membership signal unreliable, especially since most samples are\nnon-members in real world applications. In this work, we argue that membership\ninference attacks can benefit drastically from \\emph{difficulty calibration},\nwhere an attack's predicted membership score is adjusted to the difficulty of\ncorrectly classifying the target sample. We show that difficulty calibration\ncan significantly reduce the false positive rate of a variety of existing\nattacks without a loss in accuracy.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Lauren Watson",
      "Chuan Guo",
      "Graham Cormode",
      "Alex Sablayrolles"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08440"
  },
  {
    "id": "arXiv:2111.08445",
    "title": "Conjugate gradient MIMO iterative learning control using data-driven  stochastic gradients",
    "abstract": "Data-driven iterative learning control can achieve high performance for\nsystems performing repeating tasks without the need for modeling. The aim of\nthis paper is to develop a fast data-driven method for iterative learning\ncontrol that is suitable for massive MIMO systems through the use of efficient\nunbiased gradient estimates. A stochastic conjugate gradient descent algorithm\nis developed that uses dedicated experiments to determine the conjugate search\ndirection and optimal step size at each iteration. The approach is illustrated\non a multivariable example, and it is shown that the method is superior to both\nthe earlier stochastic gradient descent and deterministic conjugate gradient\ndescent methods.",
    "descriptor": "\nComments: 6 pages, 4 figures, 60th IEEE Conference on Decision and Control 2021\n",
    "authors": [
      "Leontine Aarnoudse",
      "Tom Oomen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.08445"
  },
  {
    "id": "arXiv:2111.08449",
    "title": "Complementary Ensemble Learning",
    "abstract": "To achieve high performance of a machine learning (ML) task, a deep\nlearning-based model must implicitly capture the entire distribution from data.\nThus, it requires a huge amount of training samples, and data are expected to\nfully present the real distribution, especially for high dimensional data,\ne.g., images, videos. In practice, however, data are usually collected with a\ndiversity of styles, and several of them have insufficient number of\nrepresentatives. This might lead to uncertainty in models' prediction, and\nsignificantly reduce ML task performance.\nIn this paper, we provide a comprehensive study on this problem by looking at\nmodel uncertainty. From this, we derive a simple but efficient technique to\nimprove performance of state-of-the-art deep learning models. Specifically, we\ntrain auxiliary models which are able to complement state-of-the-art model\nuncertainty. As a result, by assembling these models, we can significantly\nimprove the ML task performance for types of data mentioned earlier. While\nslightly improving ML classification accuracy on benchmark datasets (e.g., 0.2%\non MNIST), our proposed method significantly improves on limited data (i.e.,\n1.3% on Eardrum and 3.5% on ChestXray).",
    "descriptor": "",
    "authors": [
      "Hung Nguyen",
      "Morris Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08449"
  },
  {
    "id": "arXiv:2111.08450",
    "title": "A Spatial-temporal Graph Deep Learning Model for Urban Flood Nowcasting  Leveraging Heterogeneous Community Features",
    "abstract": "The objective of this study is to develop and test a novel structured\ndeep-learning modeling framework for urban flood nowcasting by integrating\nphysics-based and human-sensed features. We present a new computational\nmodeling framework including an attention-based spatial-temporal graph\nconvolution network (ASTGCN) model and different streams of data that are\ncollected in real-time, preprocessed, and fed into the model to consider\nspatial and temporal information and dependencies that improve flood\nnowcasting. The novelty of the computational modeling framework is threefold;\nfirst, the model is capable of considering spatial and temporal dependencies in\ninundation propagation thanks to the spatial and temporal graph convolutional\nmodules; second, it enables capturing the influence of heterogeneous temporal\ndata streams that can signal flooding status, including physics-based features\nsuch as rainfall intensity and water elevation, and human-sensed data such as\nflood reports and fluctuations of human activity. Third, its attention\nmechanism enables the model to direct its focus on the most influential\nfeatures that vary dynamically. We show the application of the modeling\nframework in the context of Harris County, Texas, as the case study and\nHurricane Harvey as the flood event. Results indicate that the model provides\nsuperior performance for the nowcasting of urban flood inundation at the census\ntract level, with a precision of 0.808 and a recall of 0.891, which shows the\nmodel performs better compared with some other novel models. Moreover, ASTGCN\nmodel performance improves when heterogeneous dynamic features are added into\nthe model that solely relies on physics-based features, which demonstrates the\npromise of using heterogenous human-sensed data for flood nowcasting,",
    "descriptor": "",
    "authors": [
      "Hamed Farahmand",
      "Yuanchang Xu",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.08450"
  },
  {
    "id": "arXiv:2111.08451",
    "title": "Which is Making the Contribution: Modulating Unimodal and Cross-modal  Dynamics for Multimodal Sentiment Analysis",
    "abstract": "Multimodal sentiment analysis (MSA) draws increasing attention with the\navailability of multimodal data. The boost in performance of MSA models is\nmainly hindered by two problems. On the one hand, recent MSA works mostly focus\non learning cross-modal dynamics, but neglect to explore an optimal solution\nfor unimodal networks, which determines the lower limit of MSA models. On the\nother hand, noisy information hidden in each modality interferes the learning\nof correct cross-modal dynamics. To address the above-mentioned problems, we\npropose a novel MSA framework \\textbf{M}odulation \\textbf{M}odel for\n\\textbf{M}ultimodal \\textbf{S}entiment \\textbf{A}nalysis ({$ M^3SA $}) to\nidentify the contribution of modalities and reduce the impact of noisy\ninformation, so as to better learn unimodal and cross-modal dynamics.\nSpecifically, modulation loss is designed to modulate the loss contribution\nbased on the confidence of individual modalities in each utterance, so as to\nexplore an optimal update solution for each unimodal network. Besides, contrary\nto most existing works which fail to explicitly filter out noisy information,\nwe devise a modality filter module to identify and filter out modality noise\nfor the learning of correct cross-modal embedding. Extensive experiments on\npublicly datasets demonstrate that our approach achieves state-of-the-art\nperformance.",
    "descriptor": "\nComments: Updated version\n",
    "authors": [
      "Ying Zeng",
      "Sijie Mai",
      "Haifeng Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08451"
  },
  {
    "id": "arXiv:2111.08452",
    "title": "On minimizers and convolutional filters: a partial justification for the  unreasonable effectiveness of CNNs in categorical sequence analysis",
    "abstract": "Minimizers and convolutional neural networks (CNNs) are two quite distinct\npopular techniques that have both been employed to analyze biological\nsequences. At face value, the methods seem entirely dissimilar. Minimizers use\nmin-wise hashing on a rolling window to extract a single important k-mer\nfeature per window. CNNs start with a wide array of randomly initialized\nconvolutional filters, paired with a pooling operation, and then multiple\nadditional neural layers to learn both the filters themselves and how those\nfilters can be used to classify the sequence. In this manuscript, I demonstrate\nthrough a careful mathematical analysis of hash function properties that there\nare deep theoretical connections between minimizers and convolutional filters\n-- in short, for sequences over a categorical alphabet, random Gaussian\ninitialization of convolutional filters with max-pooling is equivalent to\nchoosing minimizers from a random hash function biased towards more distinct\nk-mers. This provides a partial explanation for the unreasonable effectiveness\nof CNNs in categorical sequence analysis.",
    "descriptor": "\nComments: 10 pages, 0 figures, submitted to a conference\n",
    "authors": [
      "Yun William Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2111.08452"
  },
  {
    "id": "arXiv:2111.08453",
    "title": "Entropy optimized semi-supervised decomposed vector-quantized  variational autoencoder model based on transfer learning for multiclass text  classification and generation",
    "abstract": "Semisupervised text classification has become a major focus of research over\nthe past few years. Hitherto, most of the research has been based on supervised\nlearning, but its main drawback is the unavailability of labeled data samples\nin practical applications. It is still a key challenge to train the deep\ngenerative models and learn comprehensive representations without supervision.\nEven though continuous latent variables are employed primarily in deep latent\nvariable models, discrete latent variables, with their enhanced\nunderstandability and better compressed representations, are effectively used\nby researchers. In this paper, we propose a semisupervised discrete latent\nvariable model for multi-class text classification and text generation. The\nproposed model employs the concept of transfer learning for training a\nquantized transformer model, which is able to learn competently using fewer\nlabeled instances. The model applies decomposed vector quantization technique\nto overcome problems like posterior collapse and index collapse. Shannon\nentropy is used for the decomposed sub-encoders, on which a variable\nDropConnect is applied, to retain maximum information. Moreover, gradients of\nthe Loss function are adaptively modified during backpropagation from decoder\nto encoder to enhance the performance of the model. Three conventional datasets\nof diversified range have been used for validating the proposed model on a\nvariable number of labeled instances. Experimental results indicate that the\nproposed model has surpassed the state-of-the-art models remarkably.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Shivani Malhotra",
      "Vinay Kumar",
      "Alpana Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.08453"
  },
  {
    "id": "arXiv:2111.08455",
    "title": "Integrating On-chain and Off-chain Governance for Supply Chain  Transparency and Integrity",
    "abstract": "Integrating on-chain and off-chain data storage for decentralised and\ndistributed information systems, such as blockchain, presents specific\nchallenges for providing transparency of data governance and ensuring data\nintegrity through stakeholder engagement. Current research on blockchain-based\nsupply chains focuses on using on-chain governance rules developed for\ncryptocurrency blockchains to store some critical data points without designing\ntailored on-chain governance mechanisms and disclosing off-chain\ndecision-making processes on data governance. In response to this research gap,\nthis paper presents an integrated data governance framework that coordinates\nsupply chain stakeholders with inter-linked on-chain and off-chain governance\nto disclose on-chain and off-chain rules and decision-making processes for\nsupply chain transparency and integrity. We present a Proof-of-Concept (PoC) of\nour integrated data governance approach and suggest future research to\nstrengthen scaling up and supply chain-based use cases based on our learnings.",
    "descriptor": "\nComments: The 5th Symposium on Distributed Ledger Technology\n",
    "authors": [
      "Shoufeng Cao",
      "Thomas Miller",
      "Marcus Foth",
      "Warwick Powell",
      "Xavier Boyen",
      "Charles Turner-Morris"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.08455"
  },
  {
    "id": "arXiv:2111.08456",
    "title": "Trustworthy Multimodal Regression with Mixture of Normal-inverse Gamma  Distributions",
    "abstract": "Multimodal regression is a fundamental task, which integrates the information\nfrom different sources to improve the performance of follow-up applications.\nHowever, existing methods mainly focus on improving the performance and often\nignore the confidence of prediction for diverse situations. In this study, we\nare devoted to trustworthy multimodal regression which is critical in\ncost-sensitive domains. To this end, we introduce a novel Mixture of\nNormal-Inverse Gamma distributions (MoNIG) algorithm, which efficiently\nestimates uncertainty in principle for adaptive integration of different\nmodalities and produces a trustworthy regression result. Our model can be\ndynamically aware of uncertainty for each modality, and also robust for\ncorrupted modalities. Furthermore, the proposed MoNIG ensures explicitly\nrepresentation of (modality-specific/global) epistemic and aleatoric\nuncertainties, respectively. Experimental results on both synthetic and\ndifferent real-world data demonstrate the effectiveness and trustworthiness of\nour method on various multimodal regression tasks (e.g., temperature prediction\nfor superconductivity, relative location prediction for CT slices, and\nmultimodal sentiment analysis).",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Huan Ma",
      "Zongbo Han",
      "Changqing Zhang",
      "Huazhu Fu",
      "Joey Tianyi Zhou",
      "Qinghua Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08456"
  },
  {
    "id": "arXiv:2111.08458",
    "title": "Lifelong Learning from Event-based Data",
    "abstract": "Lifelong learning is a long-standing aim for artificial agents that act in\ndynamic environments, in which an agent needs to accumulate knowledge\nincrementally without forgetting previously learned representations. We\ninvestigate methods for learning from data produced by event cameras and\ncompare techniques to mitigate forgetting while learning incrementally. We\npropose a model that is composed of both, feature extraction and continuous\nlearning. Furthermore, we introduce a habituation-based method to mitigate\nforgetting. Our experimental results show that the combination of different\ntechniques can help to avoid catastrophic forgetting while learning\nincrementally from the features provided by the extraction module.",
    "descriptor": "\nComments: In Proceedings of the 29th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning\n",
    "authors": [
      "Vadym Gryshchuk",
      "Cornelius Weber",
      "Chu Kiong Loo",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08458"
  },
  {
    "id": "arXiv:2111.08460",
    "title": "Enabling human-centered AI: A new junction and shared journey",
    "abstract": "AI has unique characteristics compared to non-AI systems. The AI/CS\ncommunities have recently made huge investments in the ethics of AI systems,\nacknowledging the value of identifying human-centered principles that can guide\nhow AI systems are deployed. The HCI community has been applying the\nhuman-centered approach to computing systems but faces some challenges in\napplying it to AI systems. How can the AI/CS and HCI communities work together\nto develop human-centered AI (HCAI) systems? We recommend that both communities\nwork together for a shared journey of enabling HCAI. Just as the culture of\nuser experience has been jointly promoted over the last forty years, we thus\nfind ourselves at a new historical junction, which requires a new journey of\ncollaboration across the AI/CS and HCI communities to develop human-centered AI\nsystems.",
    "descriptor": "",
    "authors": [
      "Wei Xu",
      "Marvin Dainoff"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.08460"
  },
  {
    "id": "arXiv:2111.08462",
    "title": "Towards Lightweight Controllable Audio Synthesis with Conditional  Implicit Neural Representations",
    "abstract": "The high temporal resolution of audio and our perceptual sensitivity to small\nirregularities in waveforms make synthesizing at high sampling rates a complex\nand computationally intensive task, prohibiting real-time, controllable\nsynthesis within many approaches. In this work we aim to shed light on the\npotential of Conditional Implicit Neural Representations (CINRs) as lightweight\nbackbones in generative frameworks for audio synthesis.\nImplicit neural representations (INRs) are neural networks used to\napproximate low-dimensional functions, trained to represent a single geometric\nobject by mapping input coordinates to structural information at input\nlocations. In contrast with other neural methods for representing geometric\nobjects, the memory required to parameterize the object is independent of\nresolution, and only scales with its complexity. A corollary of this is that\nINRs have infinite resolution, as they can be sampled at arbitrary resolutions.\nTo apply the concept of INRs in the generative domain we frame generative\nmodelling as learning a distribution of continuous functions. This can be\nachieved by introducing conditioning methods to INRs.\nOur experiments show that Periodic Conditional INRs (PCINRs) learn faster and\ngenerally produce quantitatively better audio reconstructions than Transposed\nConvolutional Neural Networks with equal parameter counts. However, their\nperformance is very sensitive to activation scaling hyperparameters. When\nlearning to represent more uniform sets, PCINRs tend to introduce artificial\nhigh-frequency components in reconstructions. We validate this noise can be\nminimized by applying standard weight regularization during training or\ndecreasing the compositional depth of PCINRs, and suggest directions for future\nresearch.",
    "descriptor": "\nComments: Accepted to \"Deep Generative Models and Downstream Applications\" and \"Machine Learning for Creativity and Design\" workshops at NeurIPS 2021\n",
    "authors": [
      "Jan Zuiderveld",
      "Marco Federici",
      "Erik J. Bekkers"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08462"
  },
  {
    "id": "arXiv:2111.08463",
    "title": "Multi-Centroid Hyperdimensional Computing Approach for Epileptic Seizure  Detection",
    "abstract": "Long-term monitoring of patients with epilepsy presents a challenging problem\nfrom the engineering perspective of real-time detection and wearable devices\ndesign. It requires new solutions that allow continuous unobstructed monitoring\nand reliable detection and prediction of seizures. A high variability in the\nelectroencephalogram (EEG) patterns exists among people, brain states, and time\ninstances during seizures, but also during non-seizure periods. This makes\nepileptic seizure detection very challenging, especially if data is grouped\nunder only seizure and non-seizure labels.\nHyperdimensional (HD) computing, a novel machine learning approach, comes in\nas a promising tool. However, it has certain limitations when the data shows a\nhigh intra-class variability. Therefore, in this work, we propose a novel\nsemi-supervised learning approach based on a multi-centroid HD computing. The\nmulti-centroid approach allows to have several prototype vectors representing\nseizure and non-seizure states, which leads to significantly improved\nperformance when compared to a simple 2-class HD model.\nFurther, real-life data imbalance poses an additional challenge and the\nperformance reported on balanced subsets of data is likely to be overestimated.\nThus, we test our multi-centroid approach with three different dataset\nbalancing scenarios, showing that performance improvement is higher for the\nless balanced dataset. More specifically, up to 14% improvement is achieved on\nan unbalanced test set with 10 times more non-seizure than seizure data. At the\nsame time, the total number of sub-classes is not significantly increased\ncompared to the balanced dataset. Thus, the proposed multi-centroid approach\ncan be an important element in achieving a high performance of epilepsy\ndetection with real-life data balance or during online learning, where seizures\nare infrequent.",
    "descriptor": "",
    "authors": [
      "Una Pale",
      "Tomas Teijeiro",
      "David Atienza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08463"
  },
  {
    "id": "arXiv:2111.08465",
    "title": "The role of attraction-repulsion dynamics in simulating the emergence of  inflectional class systems",
    "abstract": "Dynamic models of paradigm change can elucidate how the simplest of processes\nmay lead to unexpected outcomes, and thereby can reveal new potential\nexplanations for observed linguistic phenomena. Ackerman & Malouf (2015)\npresent a model in which inflectional systems reduce in disorder through the\naction of an attraction-only dynamic, in which lexemes only ever grow more\nsimilar to one another over time. Here we emphasise that: (1) Attraction-only\nmodels cannot evolve the structured diversity which characterises true\ninflectional systems, because they inevitably remove all variation; and (2)\nModels with both attraction and repulsion enable the emergence of systems that\nare strikingly reminiscent of morphomic structure such as inflection classes.\nThus, just one small ingredient -- change based on dissimilarity -- separates\nmodels that tend inexorably to uniformity, and which therefore are implausible\nfor inflectional morphology, from those which evolve stable, morphome-like\nstructure. These models have the potential to alter how we attempt to account\nfor morphological complexity.",
    "descriptor": "\nComments: International Symposium of Morphology 2021\n",
    "authors": [
      "Erich R. Round",
      "Sacha Beniamine",
      "Louise Esher"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.08465"
  },
  {
    "id": "arXiv:2111.08466",
    "title": "Interpretable and Fair Boolean Rule Sets via Column Generation",
    "abstract": "This paper considers the learning of Boolean rules in either disjunctive\nnormal form (DNF, OR-of-ANDs, equivalent to decision rule sets) or conjunctive\nnormal form (CNF, AND-of-ORs) as an interpretable model for classification. An\ninteger program is formulated to optimally trade classification accuracy for\nrule simplicity. We also consider the fairness setting and extend the\nformulation to include explicit constraints on two different measures of\nclassification parity: equality of opportunity and equalized odds. Column\ngeneration (CG) is used to efficiently search over an exponential number of\ncandidate clauses (conjunctions or disjunctions) without the need for heuristic\nrule mining. This approach also bounds the gap between the selected rule set\nand the best possible rule set on the training data. To handle large datasets,\nwe propose an approximate CG algorithm using randomization. Compared to three\nrecently proposed alternatives, the CG algorithm dominates the\naccuracy-simplicity trade-off in 8 out of 16 datasets. When maximized for\naccuracy, CG is competitive with rule learners designed for this purpose,\nsometimes finding significantly simpler solutions that are no less accurate.\nCompared to other fair and interpretable classifiers, our method is able to\nfind rule sets that meet stricter notions of fairness with a modest trade-off\nin accuracy.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2107.01325, arXiv:1805.09901\n",
    "authors": [
      "Connor Lawless",
      "Sanjeeb Dash",
      "Oktay Gunluk",
      "Dennis Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.08466"
  },
  {
    "id": "arXiv:2111.08468",
    "title": "Point detection through multi-instance deep heatmap regression for  sutures in endoscopy",
    "abstract": "Purpose: Mitral valve repair is a complex minimally invasive surgery of the\nheart valve. In this context, suture detection from endoscopic images is a\nhighly relevant task that provides quantitative information to analyse suturing\npatterns, assess prosthetic configurations and produce augmented reality\nvisualisations. Facial or anatomical landmark detection tasks typically contain\na fixed number of landmarks, and use regression or fixed heatmap-based\napproaches to localize the landmarks. However in endoscopy, there are a varying\nnumber of sutures in every image, and the sutures may occur at any location in\nthe annulus, as they are not semantically unique. Method: In this work, we\nformulate the suture detection task as a multi-instance deep heatmap regression\nproblem, to identify entry and exit points of sutures. We extend our previous\nwork, and introduce the novel use of a 2D Gaussian layer followed by a\ndifferentiable 2D spatial Soft-Argmax layer to function as a local non-maximum\nsuppression. Results: We present extensive experiments with multiple heatmap\ndistribution functions and two variants of the proposed model. In the\nintra-operative domain, Variant 1 showed a mean F1 of +0.0422 over the\nbaseline. Similarly, in the simulator domain, Variant 1 showed a mean F1 of\n+0.0865 over the baseline. Conclusion: The proposed model shows an improvement\nover the baseline in the intra-operative and the simulator domains. The data is\nmade publicly available within the scope of the MICCAI AdaptOR2021 Challenge\nhttps://adaptor2021.github.io/, and the code at\nhttps://github.com/Cardio-AI/suture-detection-pytorch/.\nDOI:10.1007/s11548-021-02523-w. The link to the open access article can be\nfound here: https://link.springer.com/article/10.1007%2Fs11548-021-02523-w",
    "descriptor": "\nComments: Accepted to International Journal of Computer Assisted Radiology and Surgery, 15 pages, 5 figures\n",
    "authors": [
      "Lalith Sharan",
      "Gabriele Romano",
      "Julian Brand",
      "Halvar Kelm",
      "Matthias Karck",
      "Raffaele De Simone",
      "Sandy Engelhardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08468"
  },
  {
    "id": "arXiv:2111.08472",
    "title": "An Energy Consumption Model for Electrical Vehicle Networks via Extended  Federated-learning",
    "abstract": "Electrical vehicle (EV) raises to promote an eco-sustainable society.\nNevertheless, the ``range anxiety'' of EV hinders its wider acceptance among\ncustomers. This paper proposes a novel solution to range anxiety based on a\nfederated-learning model, which is capable of estimating battery consumption\nand providing energy-efficient route planning for vehicle networks.\nSpecifically, the new approach extends the federated-learning structure with\ntwo components: anomaly detection and sharing policy. The first component\nidentifies preventing factors in model learning, while the second component\noffers guidelines for information sharing amongst vehicle networks when the\nsharing is necessary to preserve learning efficiency. The two components\ncollaborate to enhance learning robustness against data heterogeneities in\nnetworks. Numerical experiments are conducted, and the results show that\ncompared with considered solutions, the proposed approach could provide higher\naccuracy of battery-consumption estimation for vehicles under heterogeneous\ndata distributions, without increasing the time complexity or transmitting raw\ndata among vehicle networks.",
    "descriptor": "",
    "authors": [
      "Shiliang Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08472"
  },
  {
    "id": "arXiv:2111.08477",
    "title": "On Reverse Elastic Channels and the Asymmetry of Commitment Capacity  under Channel Elasticity",
    "abstract": "Commitment is an important cryptographic primitive. It is well known that\nnoisy channels are a promising resource to realize commitment in an\ninformation-theoretically secure manner. However, oftentimes, channel behaviour\nmay be poorly characterized thereby limiting the commitment throughput and/or\ndegrading the security guarantees; particularly problematic is when a dishonest\nparty, unbeknown to the honest one, can maliciously alter the channel\ncharacteristics. Reverse elastic channels (RECs) are an interesting class of\nsuch unreliable channels, where only a dishonest committer, say, Alice can\nmaliciously alter the channel. RECs have attracted recent interest in the study\nof several cryptographic primitives.\nOur principal contribution is the REC commitment capacity characterization;\nthis proves a recent related conjecture. A key result is our tight converse\nwhich analyses a specific cheating strategy by Alice. RECs are closely related\nto the classic unfair noisy channels (UNCs); elastic channels (ECs), where only\na dishonest receiver Bob can alter the channel, are similarly related. In stark\ncontrast to UNCs, both RECs and ECs always exhibit positive commitment\nthroughput for all non-trivial parameters. Interestingly, our results show that\nchannels with exclusive one-sided elasticity for dishonest parties, exhibit a\nfundamental asymmetry where a committer with one-sided elasticity has a more\ndebilitating effect on the commitment throughput than a receiver.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Amitalok J. Budkuley",
      "Pranav Joshi",
      "Manideep Mamindlapally",
      "Anuj Kumar Yadav"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.08477"
  },
  {
    "id": "arXiv:2111.08478",
    "title": "Spatial machine-learning model diagnostics: a model-agnostic  distance-based approach",
    "abstract": "While significant progress has been made towards explaining black-box\nmachine-learning (ML) models, there is still a distinct lack of diagnostic\ntools that elucidate the spatial behaviour of ML models in terms of predictive\nskill and variable importance. This contribution proposes spatial prediction\nerror profiles (SPEPs) and spatial variable importance profiles (SVIPs) as\nnovel model-agnostic assessment and interpretation tools for spatial prediction\nmodels with a focus on prediction distance. Their suitability is demonstrated\nin two case studies representing a regionalization task in an\nenvironmental-science context, and a classification task from remotely-sensed\nland cover classification. In these case studies, the SPEPs and SVIPs of\ngeostatistical methods, linear models, random forest, and hybrid algorithms\nshow striking differences but also relevant similarities. Limitations of\nrelated cross-validation techniques are outlined, and the case is made that\nmodelers should focus their model assessment and interpretation on the intended\nspatial prediction horizon. The range of autocorrelation, in contrast, is not a\nsuitable criterion for defining spatial cross-validation test sets. The novel\ndiagnostic tools enrich the toolkit of spatial data science, and may improve ML\nmodel interpretation, selection, and design.",
    "descriptor": "",
    "authors": [
      "Alexander Brenning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08478"
  },
  {
    "id": "arXiv:2111.08481",
    "title": "PySINDy: A comprehensive Python package for robust sparse system  identification",
    "abstract": "Automated data-driven modeling, the process of directly discovering the\ngoverning equations of a system from data, is increasingly being used across\nthe scientific community. PySINDy is a Python package that provides tools for\napplying the sparse identification of nonlinear dynamics (SINDy) approach to\ndata-driven model discovery. In this major update to PySINDy, we implement\nseveral advanced features that enable the discovery of more general\ndifferential equations from noisy and limited data. The library of candidate\nterms is extended for the identification of actuated systems, partial\ndifferential equations (PDEs), and implicit differential equations. Robust\nformulations, including the integral form of SINDy and ensembling techniques,\nare also implemented to improve performance for real-world data. Finally, we\nprovide a range of new optimization algorithms, including several sparse\nregression techniques and algorithms to enforce and promote inequality\nconstraints and stability. Together, these updates enable entirely new SINDy\nmodel discovery capabilities that have not been reported in the literature,\nsuch as constrained PDE identification and ensembling with different sparse\nregression optimizers.",
    "descriptor": "",
    "authors": [
      "Alan A. Kaptanoglu",
      "Brian M. de Silva",
      "Urban Fasel",
      "Kadierdan Kaheman",
      "Jared L. Callaham",
      "Charles B. Delahunt",
      "Kathleen Champion",
      "Jean-Christophe Loiseau",
      "J. Nathan Kutz",
      "Steven L. Brunton"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2111.08481"
  },
  {
    "id": "arXiv:2111.08482",
    "title": "Distributed Optimal Output Consensus of Uncertain Nonlinear Multi-Agent  Systems over Unbalanced Directed Networks via Output Feedback",
    "abstract": "In this note, a novel observer-based output feedback control approach is\nproposed to address the distributed optimal output consensus problem of\nuncertain nonlinear multi-agent systems in the normal form over unbalanced\ndirected graphs. The main challenges of the concerned problem lie in unbalanced\ndirected graphs and nonlinearities of multi-agent systems with their agent\nstates not available for feedback control. Based on a two-layer controller\nstructure, a distributed optimal coordinator is first designed to convert the\nconsidered problem into a reference-tracking problem. Then a decentralized\noutput feedback controller is developed to stabilize the resulting augmented\nsystem. A high-gain observer is exploited in controller design to estimate the\nagent states in the presence of uncertainties and disturbances so that the\nproposed controller relies only on agent outputs. The semi-global convergence\nof the agent outputs toward the optimal solution that minimizes the sum of all\nlocal cost functions is proved under standard assumptions. A key feature of the\nobtained results is that the nonlinear agents under consideration are only\nrequired to be locally Lipschitz and possess globally asymptotically stable and\nlocally exponentially stable zero dynamics.",
    "descriptor": "\nComments: 8 pages, 2 figures. arXiv admin note: text overlap with arXiv:2107.04056\n",
    "authors": [
      "Jin Zhang",
      "Lu Liu",
      "Xinghu Wang",
      "Haibo Ji"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.08482"
  },
  {
    "id": "arXiv:2111.08485",
    "title": "Consistent Semantic Attacks on Optical Flow",
    "abstract": "We present a novel approach for semantically targeted adversarial attacks on\nOptical Flow. In such attacks the goal is to corrupt the flow predictions of a\nspecific object category or instance. Usually, an attacker seeks to hide the\nadversarial perturbations in the input. However, a quick scan of the output\nreveals the attack. In contrast, our method helps to hide the attackers intent\nin the output as well. We achieve this thanks to a regularization term that\nencourages off-target consistency. We perform extensive tests on leading\noptical flow models to demonstrate the benefits of our approach in both\nwhite-box and black-box settings. Also, we demonstrate the effectiveness of our\nattack on subsequent tasks that depend on the optical flow.",
    "descriptor": "\nComments: Paper and supplementary material\n",
    "authors": [
      "Tom Koren",
      "Lior Talker",
      "Michael Dinerstein",
      "Roy J Jevnisek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08485"
  },
  {
    "id": "arXiv:2111.08486",
    "title": "Neural Class Expression Synthesis",
    "abstract": "Class expression learning is a branch of explainable supervised machine\nlearning of increasing importance. Most existing approaches for class\nexpression learning in description logics are search algorithms or\nhard-rule-based. In particular, approaches based on refinement operators suffer\nfrom scalability issues as they rely on heuristic functions to explore a large\nsearch space for each learning problem. We propose a new family of approaches,\nwhich we dub synthesis approaches. Instances of this family compute class\nexpressions directly from the examples provided. Consequently, they are not\nsubject to the runtime limitations of search-based approaches nor the lack of\nflexibility of hard-rule-based approaches. We study three instances of this\nnovel family of approaches that use lightweight neural network architectures to\nsynthesize class expressions from sets of positive examples. The results of\ntheir evaluation on four benchmark datasets suggest that they can effectively\nsynthesize high-quality class expressions with respect to the input examples in\nunder a second on average. Moreover, a comparison with the state-of-the-art\napproaches CELOE and ELTL suggests that we achieve significantly better\nF-measures on large ontologies. For reproducibility purposes, we provide our\nimplementation as well as pre-trained models in the public GitHub repository at\nhttps://github.com/ConceptLengthLearner/NCES",
    "descriptor": "\nComments: 12 pages, 2 figures, 7 tables\n",
    "authors": [
      "N'Dah Jean Kouagou",
      "Stefan Heindorf",
      "Caglar Demir",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08486"
  },
  {
    "id": "arXiv:2111.08489",
    "title": "Generative Pre-Trained Transformer for Design Concept Generation: An  Exploration",
    "abstract": "Novel concepts are essential for design innovation and can be generated with\nthe aid of data stimuli and computers. However, current generative design\nalgorithms focus on diagrammatic or spatial concepts that are either too\nabstract to understand or too detailed for early phase design exploration. This\npaper explores the uses of generative pre-trained transformers (GPT) for\nnatural language design concept generation. Our experiments involve the use of\nGPT-2 and GPT-3 for different creative reasonings in design tasks. Both show\nreasonably good performance for verbal design concept generation.",
    "descriptor": "\nComments: Submitted to the DESIGN 2022 Conference\n",
    "authors": [
      "Qihao Zhu",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08489"
  },
  {
    "id": "arXiv:2111.08492",
    "title": "SequentialPointNet: A strong parallelized point cloud sequence network  for 3D action recognition",
    "abstract": "Point cloud sequences of 3D human actions exhibit unordered intra-frame\nspatial information and ordered interframe temporal information. In order to\ncapture the spatiotemporal structures of the point cloud sequences, cross-frame\nspatio-temporal local neighborhoods around the centroids are usually\nconstructed. However, the computationally expensive construction procedure of\nspatio-temporal local neighborhoods severely limits the parallelism of models.\nMoreover, it is unreasonable to treat spatial and temporal information equally\nin spatio-temporal local learning, because human actions are complicated along\nthe spatial dimensions and simple along the temporal dimension. In this paper,\nto avoid spatio-temporal local encoding, we propose a strong parallelized point\ncloud sequence network referred to as SequentialPointNet for 3D action\nrecognition. SequentialPointNet is composed of two serial modules, i.e., an\nintra-frame appearance encoding module and an inter-frame motion encoding\nmodule. For modeling the strong spatial structures of human actions, each point\ncloud frame is processed in parallel in the intra-frame appearance encoding\nmodule and the feature vector of each frame is output to form a feature vector\nsequence that characterizes static appearance changes along the temporal\ndimension. For modeling the weak temporal changes of human actions, in the\ninter-frame motion encoding module, the temporal position encoding and the\nhierarchical pyramid pooling strategy are implemented on the feature vector\nsequence. In addition, in order to better explore spatio-temporal content,\nmultiple level features of human movements are aggregated before performing the\nend-to-end 3D action recognition. Extensive experiments conducted on three\npublic datasets show that SequentialPointNet outperforms stateof-the-art\napproaches.",
    "descriptor": "",
    "authors": [
      "Xing Li",
      "Qian Huang",
      "Zhijian Wang",
      "Zhenjie Hou",
      "Tianjin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08492"
  },
  {
    "id": "arXiv:2111.08498",
    "title": "Reducing the Long Tail Losses in Scientific Emulations with Active  Learning",
    "abstract": "Deep-learning-based models are increasingly used to emulate scientific\nsimulations to accelerate scientific research. However, accurate, supervised\ndeep learning models require huge amount of labelled data, and that often\nbecomes the bottleneck in employing neural networks. In this work, we leveraged\nan active learning approach called core-set selection to actively select data,\nper a pre-defined budget, to be labelled for training. To further improve the\nmodel performance and reduce the training costs, we also warm started the\ntraining using a shrink-and-perturb trick. We tested on two case studies in\ndifferent fields, namely galaxy halo occupation distribution modelling in\nastrophysics and x-ray emission spectroscopy in plasma physics, and the results\nare promising: we achieved competitive overall performance compared to using a\nrandom sampling baseline, and more importantly, successfully reduced the larger\nabsolute losses, i.e. the long tail in the loss distribution, at virtually no\noverhead costs.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Yi Heng Lim",
      "Muhammad Firmansyah Kasim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08498"
  },
  {
    "id": "arXiv:2111.08500",
    "title": "Patent Data for Engineering Design: A Review",
    "abstract": "Patent data have been utilized for engineering design research for long\nbecause it contains massive amount of design information. Recent advances in\nartificial intelligence and data science present unprecedented opportunities to\nmine, analyse and make sense of patent data to develop design theory and\nmethodology. Herein, we survey the patent-for-design literature by their\ncontributions to design theories, methods, tools, and strategies, as well as\ndifferent forms of patent data and various methods. Our review sheds light on\npromising future research directions for the field.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Shuo Jiang",
      "Serhad Sarica",
      "Binyang Song",
      "Jie Hu",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08500"
  },
  {
    "id": "arXiv:2111.08501",
    "title": "A Survey on Task Assignment in Crowdsourcing",
    "abstract": "Quality improvement methods are essential to gathering high-quality\ncrowdsourced data, both for research and industry applications. A popular and\nbroadly applicable method is task assignment that dynamically adjusts crowd\nworkflow parameters. In this survey, we review task assignment methods that\naddress: heterogeneous task assignment, question assignment, and plurality\nproblems in crowdsourcing. We discuss and contrast how these methods estimate\nworker performance, and highlight potential challenges in their implementation.\nFinally, we discuss future research directions for task assignment methods, and\nhow crowdsourcing platforms and other stakeholders can benefit from them.",
    "descriptor": "\nComments: 36 pages, To appear in ACM Computing Surveys\n",
    "authors": [
      "Danula Hettiachchi",
      "Vassilis Kostakos",
      "Jorge Goncalves"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.08501"
  },
  {
    "id": "arXiv:2111.08510",
    "title": "CVSS-BERT: Explainable Natural Language Processing to Determine the  Severity of a Computer Security Vulnerability from its Description",
    "abstract": "When a new computer security vulnerability is publicly disclosed, only a\ntextual description of it is available. Cybersecurity experts later provide an\nanalysis of the severity of the vulnerability using the Common Vulnerability\nScoring System (CVSS). Specifically, the different characteristics of the\nvulnerability are summarized into a vector (consisting of a set of metrics),\nfrom which a severity score is computed. However, because of the high number of\nvulnerabilities disclosed everyday this process requires lot of manpower, and\nseveral days may pass before a vulnerability is analyzed. We propose to\nleverage recent advances in the field of Natural Language Processing (NLP) to\ndetermine the CVSS vector and the associated severity score of a vulnerability\nfrom its textual description in an explainable manner. To this purpose, we\ntrained multiple BERT classifiers, one for each metric composing the CVSS\nvector. Experimental results show that our trained classifiers are able to\ndetermine the value of the metrics of the CVSS vector with high accuracy. The\nseverity score computed from the predicted CVSS vector is also very close to\nthe real severity score attributed by a human expert. For explainability\npurpose, gradient-based input saliency method was used to determine the most\nrelevant input words for a given prediction made by our classifiers. Often, the\ntop relevant words include terms in agreement with the rationales of a human\ncybersecurity expert, making the explanation comprehensible for end-users.",
    "descriptor": "\nComments: 2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA), Dec 2021, Pasadena, United States\n",
    "authors": [
      "Mustafizur Shahid",
      "Herv\u00e9 Debar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08510"
  },
  {
    "id": "arXiv:2111.08513",
    "title": "Comparing Cross Correlation-Based Similarities",
    "abstract": "The common product between two multisets or functions can be understood as\nbeing analogue to the inner product in real vector or function spaces in spite\nof its non-linear nature. In addition to other interesting features, it also\nallows respective correlations to be derived which, in addition to their\nconceptual and computational simplicity, have been verified to be able to\nprovide enhanced results in tasks such as template matching. The multiset-based\ncorrelations based on the real-valued multiset Jaccard and coincidence indices\nare compared in this work, with encouraging results which have immediate\nimplications not only in pattern recognition and deep learning, but also in\nscientific modeling in general. As expected, the multiset correlation methods,\nand especially the coincidence index, presented remarkable performance\ncharacterized by sharper and narrower peaks while secondary peaks were\nattenuated, even in presence of noise. In particular, the two methods derived\nfrom the coincidence index led to the sharpest and narrowest peaks, as well as\nintense attenuation of the secondary peaks. The cross correlation, however,\npresented the best robustness to symmetric additive noise, which suggested a\ncombination of the considered approaches. After a preliminary investigation of\nthe performance of the multiset approaches, as well as the classic\ncross-correlation, a systematic comparison framework is proposed and applied\nfor the study of the aforementioned methods. Several interesting results are\nreported, including the confirmation, at least for the considered type of data,\nof the coincidence correlation as providing enhanced performance regarding\ndetection of narrow, sharp peaks while secondary matches are duly attenuated.\nThe combined method also confirmed its good performance for signals in presence\nof intense additive noise.",
    "descriptor": "\nComments: 13 pages, 8 figures. A preprint\n",
    "authors": [
      "Luciano da F. Costa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08513"
  },
  {
    "id": "arXiv:2111.08514",
    "title": "Multiset Signal Processing and Electronics",
    "abstract": "Multisets are an intuitive extension of the traditional concept of sets that\nallow repetition of elements, with the number of times each element appears\nbeing understood as the respective multiplicity. Recent generalizations of\nmultisets to real-valued functions, accounting for possibly negative values,\nhave paved the way to a number of interesting implications and applications,\nincluding respective implementations as electronic systems. The basic multiset\noperations include the set complementation (sign change), intersection (minimum\nbetween two values), union (maximum between two values), difference and sum\n(identical to the algebraic counterparts). When applied to functions or\nsignals, the sign and conjoint sign functions are also required. Given that\nsignals are functions, it becomes possible to effectively translate the\nmultiset and multifunction operations to analog electronics, which is the\nobjective of the present work. It is proposed that effective multiset\noperations capable of high performance self and cross-correlation can be\nobtained with relative simplicity in either discrete or integrated circuits.\nThe problem of switching noise is also briefly discussed. The present results\nhave great potential for applications and related developments in analog and\ndigital electronics, as well as for pattern recognition, signal processing, and\ndeep learning.",
    "descriptor": "\nComments: 7 pages, 8 figures. A preprint of a work submitted to a scientific journal\n",
    "authors": [
      "Luciano da F. Costa"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08514"
  },
  {
    "id": "arXiv:2111.08515",
    "title": "Local News Online and COVID in the U.S.: Relationships among Coverage,  Cases, Deaths, and Audience",
    "abstract": "We present analyses from a real-time information monitoring system of online\nlocal news in the U.S. We study relationships among online local news coverage\nof COVID, cases and deaths in an area, and properties of local news outlets and\ntheir audiences. Our analysis relies on a unique dataset of the online content\nof over 300 local news outlets, encompassing over 750,000 articles over a\nperiod of 10 months spanning April 2020 to February 2021. We find that the rate\nof COVID coverage over time by local news outlets was primarily associated with\ndeath rates at the national level, but that this effect dissipated over the\ncourse of the pandemic as news about COVID was steadily displaced by\nsociopolitical events, like the 2020 U.S. elections. We also find that both the\nvolume and content of COVID coverage differed depending on local politics, and\noutlet audience size, as well as evidence that more vulnerable populations\nreceived less pandemic-related news.",
    "descriptor": "\nComments: Accepted, ICWSM'22\n",
    "authors": [
      "Kenneth Joseph",
      "Benjamin D. Horne",
      "Jon Green",
      "John P. Wihbey"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.08515"
  },
  {
    "id": "arXiv:2111.08516",
    "title": "Common Product Neurons",
    "abstract": "The present work develops a comparative performance of artificial neurons\nobtained in terms of the recently introduced real-valued Jaccard and\ncoincidence indices and respective functionals. The interiority index and\nclassic cross-correlation are also included in our study. After presenting the\nbasic concepts related to multisets and the adopted similarity metrics,\nincluding new results about the generalization of the family of real-valued\nJaccard and conicidence indices to higher orders, we proceed to studying the\nresponse of a single neuron, not taking into account the output non-linearity\n(e.g.~sigmoid), respectively to the detection of a gaussian stimulus in\npresence of displacement, magnification, intensity variation, noise and\ninterference from additional patterns. It is shown that the real-valued Jaccard\nand coincidence approaches are substantially more robust and effective than the\ninteriority index and the classic cross-correlation. The coincidence based\nneurons are shown to have the best overall performance for the considered type\nof data and perturbations. The reported concepts, methods, and results, have\nsubstantial implications not only for patter recognition and deep learning, but\nalso regarding neurobiology and neuroscience.",
    "descriptor": "\nComments: 10 pages, 12 figures. A preprint of a work submitted to a scientific journal\n",
    "authors": [
      "Luciano da F. Costa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08516"
  },
  {
    "id": "arXiv:2111.08519",
    "title": "Block preconditioning methods for asymptotic preserving scheme arising  in anisotropic elliptic problems",
    "abstract": "Efficient and robust iterative solvers for strong anisotropic elliptic\nequations are very challenging. In this paper a block preconditioning method is\nintroduced to solve the linear algebraic systems of a class of micro-macro\nasymptotic-preserving (MMAP) scheme. MMAP method was developed by Degond {\\it\net al.} in 2012 where the discrete matrix has a $2\\times2$ block structure. By\nthe approximate Schur complement a series of block preconditioners are\nconstructed. We first analyze a natural approximate Schur complement that is\nthe coefficient matrix of the original non-AP discretization. However it tends\nto be singular for very small anisotropic parameters. We then improve it by\nusing more suitable approximation for boundary rows of the exact Schur\ncomplement. With these block preconditioners, preconditioned GMRES iterative\nmethod is developed to solve the discrete equations. Several numerical tests\nshow that block preconditioning methods can be a robust strategy with respect\nto grid refinement and the anisotropic strengths.",
    "descriptor": "",
    "authors": [
      "Lingxiao Li",
      "Chang Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.08519"
  },
  {
    "id": "arXiv:2111.08520",
    "title": "Hyperbolicity Computation through Dominating Sets *",
    "abstract": "Hyperbolicity is a graph parameter related to how much a graph resembles a\ntree with respect to distances. Its computation is challenging as the main\napproaches consist in scanning all quadruples of the graph or using fast matrix\nmultiplication as building block, both are not practical for large graphs. In\nthis paper, we propose and evaluate an approach that uses a hierarchy of\ndistance-k dominating sets to reduce the search space. This technique, compared\nto the previous best practical algorithms, enables us to compute the\nhyperbolicity of graphs with unprecedented size (up to a million nodes) and\nspeeds up the computation of previously attainable graphs by up to 3 orders of\nmagnitude while reducing the memory consumption by up to more than a factor of\n23.",
    "descriptor": "",
    "authors": [
      "David Coudert",
      "Andr\u00e9 Nusser",
      "Laurent Viennot"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.08520"
  },
  {
    "id": "arXiv:2111.08521",
    "title": "Learning Intrinsic Images for Clothing",
    "abstract": "Reconstruction of human clothing is an important task and often relies on\nintrinsic image decomposition. With a lack of domain-specific data and coarse\nevaluation metrics, existing models failed to produce satisfying results for\ngraphics applications. In this paper, we focus on intrinsic image decomposition\nfor clothing images and have comprehensive improvements. We collected\nCloIntrinsics, a clothing intrinsic image dataset, including a synthetic\ntraining set and a real-world testing set. A more interpretable edge-aware\nmetric and an annotation scheme is designed for the testing set, which allows\ndiagnostic evaluation for intrinsic models. Finally, we propose ClothInNet\nmodel with carefully designed loss terms and an adversarial module. It utilizes\neasy-to-acquire labels to learn from real-world shading, significantly improves\nperformance with only minor additional annotation effort. We show that our\nproposed model significantly reduce texture-copying artifacts while retaining\nsurprisingly tiny details, outperforming existing state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Kuo Jiang",
      "Zian Wang",
      "Xiaodong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08521"
  },
  {
    "id": "arXiv:2111.08524",
    "title": "Non-separable Spatio-temporal Graph Kernels via SPDEs",
    "abstract": "Gaussian processes (GPs) provide a principled and direct approach for\ninference and learning on graphs. However, the lack of justified graph kernels\nfor spatio-temporal modelling has held back their use in graph problems. We\nleverage an explicit link between stochastic partial differential equations\n(SPDEs) and GPs on graphs, and derive non-separable spatio-temporal graph\nkernels that capture interaction across space and time. We formulate the graph\nkernels for the stochastic heat equation and wave equation. We show that by\nproviding novel tools for spatio-temporal GP modelling on graphs, we outperform\npre-existing graph kernels in real-world applications that feature diffusion,\noscillation, and other complicated interactions.",
    "descriptor": "",
    "authors": [
      "Alexander Nikitin",
      "ST John",
      "Arno Solin",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08524"
  },
  {
    "id": "arXiv:2111.08529",
    "title": "Improving the robustness and accuracy of biomedical language models  through adversarial training",
    "abstract": "Deep transformer neural network models have improved the predictive accuracy\nof intelligent text processing systems in the biomedical domain. They have\nobtained state-of-the-art performance scores on a wide variety of biomedical\nand clinical Natural Language Processing (NLP) benchmarks. However, the\nrobustness and reliability of these models has been less explored so far.\nNeural NLP models can be easily fooled by adversarial samples, i.e. minor\nchanges to input that preserve the meaning and understandability of the text\nbut force the NLP system to make erroneous decisions. This raises serious\nconcerns about the security and trust-worthiness of biomedical NLP systems,\nespecially when they are intended to be deployed in real-world use cases. We\ninvestigated the robustness of several transformer neural language models, i.e.\nBioBERT, SciBERT, BioMed-RoBERTa, and Bio-ClinicalBERT, on a wide range of\nbiomedical and clinical text processing tasks. We implemented various\nadversarial attack methods to test the NLP systems in different attack\nscenarios. Experimental results showed that the biomedical NLP models are\nsensitive to adversarial samples; their performance dropped in average by 21\nand 18.9 absolute percent on character-level and word-level adversarial noise,\nrespectively. Conducting extensive adversarial training experiments, we\nfine-tuned the NLP models on a mixture of clean samples and adversarial inputs.\nResults showed that adversarial training is an effective defense mechanism\nagainst adversarial noise; the models robustness improved in average by 11.3\nabsolute percent. In addition, the models performance on clean data increased\nin average by 2.4 absolute present, demonstrating that adversarial training can\nboost generalization abilities of biomedical NLP systems.",
    "descriptor": "",
    "authors": [
      "Milad Moradi",
      "Matthias Samwald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08529"
  },
  {
    "id": "arXiv:2111.08531",
    "title": "Language bias in Visual Question Answering: A Survey and Taxonomy",
    "abstract": "Visual question answering (VQA) is a challenging task, which has attracted\nmore and more attention in the field of computer vision and natural language\nprocessing. However, the current visual question answering has the problem of\nlanguage bias, which reduces the robustness of the model and has an adverse\nimpact on the practical application of visual question answering. In this\npaper, we conduct a comprehensive review and analysis of this field for the\nfirst time, and classify the existing methods according to three categories,\nincluding enhancing visual information, weakening language priors, data\nenhancement and training strategies. At the same time, the relevant\nrepresentative methods are introduced, summarized and analyzed in turn. The\ncauses of language bias are revealed and classified. Secondly, this paper\nintroduces the datasets mainly used for testing, and reports the experimental\nresults of various existing methods. Finally, we discuss the possible future\nresearch directions in this field.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Desen Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08531"
  },
  {
    "id": "arXiv:2111.08534",
    "title": "Finite element based model order reduction for parametrized one-way  coupled steady state linear thermomechanical problems",
    "abstract": "This contribution focuses on the development of Model Order Reduction (MOR)\nfor one-way coupled steady state linear thermomechanical problems in a finite\nelement setting. We apply Proper Orthogonal Decomposition (POD) for the\ncomputation of reduced basis space. On the other hand, for the evaluation of\nthe modal coefficients, we use two different methodologies: the one based on\nthe Galerkin projection (G) and the other one based on Artificial Neural\nNetwork (ANN). We aim at comparing POD-G and POD-ANN in terms of relevant\nfeatures including errors and computational efficiency. In this context, both\nphysical and geometrical parametrization are considered. We also carry out a\nvalidation of the Full Order Model (FOM) based on customized benchmarks in\norder to provide a complete computational pipeline. The framework proposed is\napplied to a relevant industrial problem related to the investigation of\nthermomechanical phenomena arising in blast furnace hearth walls.\nKeywords: Thermomechanical problems, Finite element method, Proper orthogonal\ndecomposition, Galerkin projection, Artificial neural network, Geometric and\nphysical parametrization, Blast furnace.",
    "descriptor": "\nComments: 33 pages, 42 references\n",
    "authors": [
      "Nirav Vasant Shah",
      "Michele Girfoglio",
      "Peregrina Quintela",
      "Gianluigi Rozza",
      "Alejandro Lengomin",
      "Francesco Ballarin",
      "Patricia Barral"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.08534"
  },
  {
    "id": "arXiv:2111.08536",
    "title": "HiRID-ICU-Benchmark -- A Comprehensive Machine Learning Benchmark on  High-resolution ICU Data",
    "abstract": "The recent success of machine learning methods applied to time series\ncollected from Intensive Care Units (ICU) exposes the lack of standardized\nmachine learning benchmarks for developing and comparing such methods. While\nraw datasets, such as MIMIC-IV or eICU, can be freely accessed on Physionet,\nthe choice of tasks and pre-processing is often chosen ad-hoc for each\npublication, limiting comparability across publications. In this work, we aim\nto improve this situation by providing a benchmark covering a large spectrum of\nICU-related tasks. Using the HiRID dataset, we define multiple clinically\nrelevant tasks developed in collaboration with clinicians. In addition, we\nprovide a reproducible end-to-end pipeline to construct both data and labels.\nFinally, we provide an in-depth analysis of current state-of-the-art sequence\nmodeling methods, highlighting some limitations of deep learning approaches for\nthis type of data. With this benchmark, we hope to give the research community\nthe possibility of a fair comparison of their work.",
    "descriptor": "\nComments: NeurIPS 2021 (Datasets and Benchmarks)\n",
    "authors": [
      "Hugo Y\u00e8che",
      "Rita Kuznetsova",
      "Marc Zimmermann",
      "Matthias H\u00fcser",
      "Xinrui Lyu",
      "Martin Faltys",
      "Gunnar R\u00e4tsch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08536"
  },
  {
    "id": "arXiv:2111.08538",
    "title": "Utilizing Textual Reviews in Latent Factor Models for Recommender  Systems",
    "abstract": "Most of the existing recommender systems are based only on the rating data,\nand they ignore other sources of information that might increase the quality of\nrecommendations, such as textual reviews, or user and item characteristics.\nMoreover, the majority of those systems are applicable only on small datasets\n(with thousands of observations) and are unable to handle large datasets (with\nmillions of observations). We propose a recommender algorithm that combines a\nrating modelling technique (i.e., Latent Factor Model) with a topic modelling\nmethod based on textual reviews (i.e., Latent Dirichlet Allocation), and we\nextend the algorithm such that it allows adding extra user- and item-specific\ninformation to the system. We evaluate the performance of the algorithm using\nAmazon.com datasets with different sizes, corresponding to 23 product\ncategories. After comparing the built model to four other models we found that\ncombining textual reviews with ratings leads to better recommendations.\nMoreover, we found that adding extra user and item features to the model\nincreases its prediction accuracy, which is especially true for medium and\nlarge datasets.",
    "descriptor": "",
    "authors": [
      "Tatev Karen Aslanyan",
      "Flavius Frasincar"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08538"
  },
  {
    "id": "arXiv:2111.08542",
    "title": "Sensitivity to User Mischaracterizations in Electric Vehicle Charging",
    "abstract": "In this paper, we consider electric vehicle charging facilities that offer\nvarious levels of service for varying prices such that rational users choose a\nlevel of service that minimizes the total cost to themselves including an\nopportunity cost that incorporates users' value of time. In this setting, we\nstudy the sensitivity of the expected occupancy at the facility to\nmischaracterizations of user profiles and uncharacterized heterogeneity. For\nuser profile mischaracterizations, we first provide a fundamental upper bound\nfor the difference between the expected occupancy under any two different\ndistributions on a user's impatience (i.e., value of time) that only depends on\nthe minimum and maximum charging rate offered by the charging facility. Next,\nwe consider the case when a user's impatience is a discrete random variable and\nstudy the sensitivity of the expected occupancy to the probability masses and\nattained values of the random variable. We show that the expected occupancy\nvaries linearly with respect to the probability masses and is piecewise\nconstant with respect to the attained values. Furthermore, we study the effects\non the expected occupancy from the occurrence of heterogeneous user\npopulations. In particular, we quantify the effect on the expected occupancy\nfrom the existence of sub-populations that may only select a subset of the\noffered service levels. Lastly, we quantify the variability of early departures\non the expected occupancy. These results demonstrate how the facility operator\nmight design prices such that the expected occupancy does not vary much under\nsmall changes in the distribution of a user's impatience, variable and limited\nuser service needs, or uncharacterized early departure, quantities which are\ngenerally difficult to characterize accurately from data. We further\ndemonstrate our results via examples.",
    "descriptor": "",
    "authors": [
      "Cesar Santoyo",
      "Gustav Nilsson",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.08542"
  },
  {
    "id": "arXiv:2111.08543",
    "title": "WikiContradiction: Detecting Self-Contradiction Articles on Wikipedia",
    "abstract": "While Wikipedia has been utilized for fact-checking and claim verification to\ndebunk misinformation and disinformation, it is essential to either improve\narticle quality and rule out noisy articles. Self-contradiction is one of the\nlow-quality article types in Wikipedia. In this work, we propose a task of\ndetecting self-contradiction articles in Wikipedia. Based on the\n\"self-contradictory\" template, we create a novel dataset for the\nself-contradiction detection task. Conventional contradiction detection focuses\non comparing pairs of sentences or claims, but self-contradiction detection\nneeds to further reason the semantics of an article and simultaneously learn\nthe contradiction-aware comparison from all pairs of sentences. Therefore, we\npresent the first model, Pairwise Contradiction Neural Network (PCNN), to not\nonly effectively identify self-contradiction articles, but also highlight the\nmost contradiction pairs of contradiction sentences. The main idea of PCNN is\ntwo-fold. First, to mitigate the effect of data scarcity on self-contradiction\narticles, we pre-train the module of pairwise contradiction learning using SNLI\nand MNLI benchmarks. Second, we select top-K sentence pairs with the highest\ncontradiction probability values and model their correlation to determine\nwhether the corresponding article belongs to self-contradiction. Experiments\nconducted on the proposed WikiContradiction dataset exhibit that PCNN can\ngenerate promising performance and comprehensively highlight the sentence pairs\nthe contradiction locates.",
    "descriptor": "\nComments: Published at IEEE BigData 2021 (regular paper). Data and code can be access via: this https URL\n",
    "authors": [
      "Cheng Hsu",
      "Cheng-Te Li",
      "Diego Saez-Trumper",
      "Yi-Zhan Hsu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08543"
  },
  {
    "id": "arXiv:2111.08545",
    "title": "Coral: An Approach for Conversational Agents in Mental Health  Applications",
    "abstract": "It may be difficult for some individuals to open up and share their thoughts\nand feelings in front of a mental health expert. For those who are more at ease\nwith a virtual agent, conversational agents can serve as an intermediate step\nin the right direction. The conversational agent must therefore be empathetic\nand able to conduct free-flowing conversations. To this effect, we present an\napproach for creating a generative empathetic open-domain chatbot that can be\nused for mental health applications. We leverage large scale pre-training and\nempathetic conversational data to make the responses more empathetic in nature\nand a multi-turn dialogue arrangement to maintain context. Our models achieve\nstate-of-the-art results on the Empathetic Dialogues test set.",
    "descriptor": "\nComments: Accepted at the 5th Workshop on Widening Natural Language Processing at the Empirical Methods in Natural Language Processing Conference (EMNLP-WiNLP), 2021\n",
    "authors": [
      "Harsh Sakhrani",
      "Saloni Parekh",
      "Shubham Mahajan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.08545"
  },
  {
    "id": "arXiv:2111.08546",
    "title": "Interpreting Language Models Through Knowledge Graph Extraction",
    "abstract": "Transformer-based language models trained on large text corpora have enjoyed\nimmense popularity in the natural language processing community and are\ncommonly used as a starting point for downstream tasks. While these models are\nundeniably useful, it is a challenge to quantify their performance beyond\ntraditional accuracy metrics. In this paper, we compare BERT-based language\nmodels through snapshots of acquired knowledge at sequential stages of the\ntraining process. Structured relationships from training corpora may be\nuncovered through querying a masked language model with probing tasks. We\npresent a methodology to unveil a knowledge acquisition timeline by generating\nknowledge graph extracts from cloze \"fill-in-the-blank\" statements at various\nstages of RoBERTa's early training. We extend this analysis to a comparison of\npretrained variations of BERT models (DistilBERT, BERT-base, RoBERTa). This\nwork proposes a quantitative framework to compare language models through\nknowledge graph extraction (GED, Graph2Vec) and showcases a part-of-speech\nanalysis (POSOR) to identify the linguistic strengths of each model variant.\nUsing these metrics, machine learning practitioners can compare models,\ndiagnose their models' behavioral strengths and weaknesses, and identify new\ntargeted datasets to improve model performance.",
    "descriptor": "\nComments: Published at NeurIPS 2021: eXplainable AI for Debugging and Diagnosis Workshop\n",
    "authors": [
      "Vinitra Swamy",
      "Angelika Romanou",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.08546"
  },
  {
    "id": "arXiv:2111.08550",
    "title": "On Effective Scheduling of Model-based Reinforcement Learning",
    "abstract": "Model-based reinforcement learning has attracted wide attention due to its\nsuperior sample efficiency. Despite its impressive success so far, it is still\nunclear how to appropriately schedule the important hyperparameters to achieve\nadequate performance, such as the real data ratio for policy optimization in\nDyna-style model-based algorithms. In this paper, we first theoretically\nanalyze the role of real data in policy training, which suggests that gradually\nincreasing the ratio of real data yields better performance. Inspired by the\nanalysis, we propose a framework named AutoMBPO to automatically schedule the\nreal data ratio as well as other hyperparameters in training model-based policy\noptimization (MBPO) algorithm, a representative running case of model-based\nmethods. On several continuous control tasks, the MBPO instance trained with\nhyperparameters scheduled by AutoMBPO can significantly surpass the original\none, and the real data ratio schedule found by AutoMBPO shows consistency with\nour theoretical analysis.",
    "descriptor": "\nComments: Accepted at NeurIPS2021\n",
    "authors": [
      "Hang Lai",
      "Jian Shen",
      "Weinan Zhang",
      "Yimin Huang",
      "Xing Zhang",
      "Ruiming Tang",
      "Yong Yu",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08550"
  },
  {
    "id": "arXiv:2111.08553",
    "title": "Remote Memory-Deduplication Attacks",
    "abstract": "Memory utilization can be reduced by merging identical memory blocks into\ncopy-on-write mappings. Previous work showed that this so-called memory\ndeduplication can be exploited in local attacks to break ASLR, spy on other\nprograms,and determine the presence of data, i.e., website images. All these\nattacks exploit memory deduplication across security domains, which in turn was\ndisabled. However, within a security domain or on an isolated system with no\nuntrusted local access, memory deduplication is still not considered a security\nrisk and was recently re-enabled on Windows by default.\nIn this paper, we present the first fully remote memorydeduplication attacks.\nUnlike previous attacks, our attacks require no local code execution.\nConsequently, we can disclose memory contents from a remote server merely by\nsending and timing HTTP/1 and HTTP/2 network requests. We demonstrate our\nattacks on deduplication both on Windows and Linux and attack widely used\nserver software such as Memcached and InnoDB. Our side channel leaks up to\n34.41 B/h over the internet, making it faster than comparable remote\nmemory-disclosure channels. We showcase our remote memory-deduplication attack\nin three case studies: First, we show that an attacker can disclose the\npresence of data in memory on a server running Memcached. We show that this\ninformation disclosure channel can also be used for fingerprinting and detect\nthe correct libc version over the internet in 166.51 s. Second, in combination\nwith InnoDB, we present an information disclosure attack to leak MariaDB\ndatabase records. Third, we demonstrate a fully remote KASLR break in less than\n4 minutes allowing to derandomize the kernel image of a virtual machine over\nthe Internet, i.e., 14 network hops away. We conclude that memory deduplication\nmust also be considered a security risk if only applied within a single\nsecurity domain.",
    "descriptor": "",
    "authors": [
      "Martin Schwarzl",
      "Erik Kraft",
      "Moritz Lipp",
      "Daniel Gruss"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.08553"
  },
  {
    "id": "arXiv:2111.08557",
    "title": "Rethinking Keypoint Representations: Modeling Keypoints and Poses as  Objects for Multi-Person Human Pose Estimation",
    "abstract": "In keypoint estimation tasks such as human pose estimation, heatmap-based\nregression is the dominant approach despite possessing notable drawbacks:\nheatmaps intrinsically suffer from quantization error and require excessive\ncomputation to generate and post-process. Motivated to find a more efficient\nsolution, we propose a new heatmap-free keypoint estimation method in which\nindividual keypoints and sets of spatially related keypoints (i.e., poses) are\nmodeled as objects within a dense single-stage anchor-based detection\nframework. Hence, we call our method KAPAO (pronounced \"Ka-Pow!\") for Keypoints\nAnd Poses As Objects. We apply KAPAO to the problem of single-stage\nmulti-person human pose estimation by simultaneously detecting human pose\nobjects and keypoint objects and fusing the detections to exploit the strengths\nof both object representations. In experiments, we observe that KAPAO is\nsignificantly faster and more accurate than previous methods, which suffer\ngreatly from heatmap post-processing. Moreover, the accuracy-speed trade-off is\nespecially favourable in the practical setting when not using test-time\naugmentation. Our large model, KAPAO-L, achieves an AP of 70.6 on the Microsoft\nCOCO Keypoints validation set without test-time augmentation, which is 2.5x\nfaster and 4.0 AP more accurate than the next best single-stage model.\nFurthermore, KAPAO excels in the presence of heavy occlusion. On the CrowdPose\ntest set, KAPAO-L achieves new state-of-the-art accuracy for a single-stage\nmethod with an AP of 68.9.",
    "descriptor": "",
    "authors": [
      "William McNally",
      "Kanav Vats",
      "Alexander Wong",
      "John McPhee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08557"
  },
  {
    "id": "arXiv:2111.08562",
    "title": "Incentives Against Power Grabs or How to Engineer the Revolution in a  Pooled Proof of Stake System",
    "abstract": "Proof-of-Stake (PoS) blockchain systems, especially those that allow\nstakeholders to organize themselves in ``stake-pools'', have emerged as a\ncompelling paradigm for the deployment of large scale distributed ledgers. A\nstake-pool operates a node that engages in the PoS protocol and potentially\nrepresents a large number of smaller stakeholders. While such pooled PoS\noperation is attractive from various angles, it also exhibits a significant\nshortcoming that, so far and to the best of our knowledge, has not been\nsufficiently understood or investigated. Pooled PoS operation, to be effective\nand not lead to sub-optimal dictatorial or cartel-like configurations, should\nenable the stakeholders to revoke and re-delegate their stake in a way that is\naligned with their incentives. However, given that stake-pool operators are\nexactly those entities who determine what transactions are to be recorded in\nthe ledger, they are quite likely to form a cartel and censor any transaction\nthey want, such as those that attempt to adjust the current stake-pool lineup.\nIn this way, a power grab takes place, where the stake-pool cartel perpetuates\nits control over the PoS system. We first model and observe formally the\nemergence of the above problem in pooled PoS systems, and then we describe an\nanti-censorship mechanism that takes advantage of the underlying cryptographic\nfunctions of the ledger and the nature of peer-to-peer networks to diffuse\ninformation without suppression. We provide a thorough game-theoretic analysis\nof this mechanism discovering various types of Nash equilibria which\ndemonstrate that the ``revolution'', i.e., the strategic decision of pool\nmembers to withdraw support from a censoring cartel as well as the pool\noperators to step down, can be incentivized, under suitable and plausible\nconditions in the utility functions of the involved participants.",
    "descriptor": "\nComments: 2021 IEEE International Conference on Decentralized Applications and Infrastructures (DAPPS)\n",
    "authors": [
      "Aggelos Kiayias",
      "Elias Koutsoupias",
      "Aikaterini-Panagiota Stouka"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.08562"
  },
  {
    "id": "arXiv:2111.08563",
    "title": "Rank-Regret Minimization",
    "abstract": "Multi-criteria decision-making often requires finding a small representative\nsubset from the database. A recently proposed method is the regret minimization\nset (RMS) query. RMS returns a fixed size subset S of dataset D that minimizes\nthe regret ratio of S (the difference between the score of top1 in S and the\nscore of top-1 in D, for any possible utility function). Existing work showed\nthat the regret-ratio is not able to accurately quantify the regret level of a\nuser. Further, relative to the regret-ratio, users do understand the notion of\nrank. Consequently, it considered the problem of finding a minimal set S with\nat most k rank-regret (the minimal rank of tuples of S in the sorted list of\nD).\nCorresponding to RMS, we focus on the dual version of the above problem,\ndefined as the rank-regret minimization (RRM) problem, which seeks to find a\nfixed size set S that minimizes the maximum rank-regret for all possible\nutility functions. Further, we generalize RRM and propose the restricted\nrank-regret minimization (RRRM) problem to minimize the rank-regret of S for\nfunctions in a restricted space. The solution for RRRM usually has a lower\nregret level and can better serve the specific preferences of some users. In 2D\nspace, we design a dynamic programming algorithm 2DRRM to find the optimal\nsolution for RRM. In HD space, we propose an algorithm HDRRM for RRM that\nbounds the output size and introduces a double approximation guarantee for\nrank-regret. Both 2DRRM and HDRRM can be generalized to the RRRM problem.\nExtensive experiments are performed on the synthetic and real datasets to\nverify the efficiency and effectiveness of our algorithms.",
    "descriptor": "",
    "authors": [
      "Xingxing Xiao",
      "Jianzhong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.08563"
  },
  {
    "id": "arXiv:2111.08564",
    "title": "Doxastic Extensions of \u0141ukasiewicz Logic",
    "abstract": "We propose two new doxastic extensions of fuzzy \\L ukasiewicz logic in which\ntheir semantics are Kripke-based with both fuzzy atomic propositions and fuzzy\naccessibility relations. A class of these extensions is equipped with\nuninformed belief operator, and the other class is based on a new notion of\nskeptical belief. We model a fuzzy version of muddy children problem and a\nCPA-security experiment using uniformed belief and skeptical belief,\nrespectively. Moreover, we prove soundness and completeness for both of these\nbelief extensions.",
    "descriptor": "",
    "authors": [
      "Doratossadat Dastgheib",
      "Hadi Farahani"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.08564"
  },
  {
    "id": "arXiv:2111.08565",
    "title": "Polymatrix Competitive Gradient Descent",
    "abstract": "Many economic games and machine learning approaches can be cast as\ncompetitive optimization problems where multiple agents are minimizing their\nrespective objective function, which depends on all agents' actions. While\ngradient descent is a reliable basic workhorse for single-agent optimization,\nit often leads to oscillation in competitive optimization. In this work we\npropose polymatrix competitive gradient descent (PCGD) as a method for solving\ngeneral sum competitive optimization involving arbitrary numbers of agents. The\nupdates of our method are obtained as the Nash equilibria of a local polymatrix\napproximation with a quadratic regularization, and can be computed efficiently\nby solving a linear system of equations. We prove local convergence of PCGD to\nstable fixed points for $n$-player general-sum games, and show that it does not\nrequire adapting the step size to the strength of the player-interactions. We\nuse PCGD to optimize policies in multi-agent reinforcement learning and\ndemonstrate its advantages in Snake, Markov soccer and an electricity market\ngame. Agents trained by PCGD outperform agents trained with simultaneous\ngradient descent, symplectic gradient adjustment, and extragradient in Snake\nand Markov soccer games and on the electricity market game, PCGD trains faster\nthan both simultaneous gradient descent and the extragradient method.",
    "descriptor": "",
    "authors": [
      "Jeffrey Ma",
      "Alistair Letcher",
      "Florian Sch\u00e4fer",
      "Yuanyuan Shi",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.08565"
  },
  {
    "id": "arXiv:2111.08566",
    "title": "SPANN: Highly-efficient Billion-scale Approximate Nearest Neighbor  Search",
    "abstract": "The in-memory algorithms for approximate nearest neighbor search (ANNS) have\nachieved great success for fast high-recall search, but are extremely expensive\nwhen handling very large scale database. Thus, there is an increasing request\nfor the hybrid ANNS solutions with small memory and inexpensive solid-state\ndrive (SSD). In this paper, we present a simple but efficient memory-disk\nhybrid indexing and search system, named SPANN, that follows the inverted index\nmethodology. It stores the centroid points of the posting lists in the memory\nand the large posting lists in the disk. We guarantee both disk-access\nefficiency (low latency) and high recall by effectively reducing the\ndisk-access number and retrieving high-quality posting lists. In the\nindex-building stage, we adopt a hierarchical balanced clustering algorithm to\nbalance the length of posting lists and augment the posting list by adding the\npoints in the closure of the corresponding clusters. In the search stage, we\nuse a query-aware scheme to dynamically prune the access of unnecessary posting\nlists. Experiment results demonstrate that SPANN is 2$\\times$ faster than the\nstate-of-the-art ANNS solution DiskANN to reach the same recall quality $90\\%$\nwith same memory cost in three billion-scale datasets. It can reach $90\\%$\nrecall@1 and recall@10 in just around one millisecond with only 32GB memory\ncost. Code is available at:\n{\\footnotesize\\color{blue}{\\url{https://github.com/microsoft/SPTAG}}}.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Qi Chen",
      "Bing Zhao",
      "Haidong Wang",
      "Mingqin Li",
      "Chuanjie Liu",
      "Zengzhong Li",
      "Mao Yang",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08566"
  },
  {
    "id": "arXiv:2111.08567",
    "title": "Joint Learning of Visual-Audio Saliency Prediction and Sound Source  Localization on Multi-face Videos",
    "abstract": "Visual and audio events simultaneously occur and both attract attention.\nHowever, most existing saliency prediction works ignore the influence of audio\nand only consider vision modality. In this paper, we propose a multitask\nlearning method for visual-audio saliency prediction and sound source\nlocalization on multi-face video by leveraging visual, audio and face\ninformation. Specifically, we first introduce a large-scale database of\nmulti-face video in visual-audio condition (MVVA), containing eye-tracking data\nand sound source annotations. Using this database, we find that sound\ninfluences human attention, and conversly attention offers a cue to determine\nsound source on multi-face video. Guided by these findings, a visual-audio\nmulti-task network (VAM-Net) is introduced to predict saliency and locate sound\nsource. VAM-Net consists of three branches corresponding to visual, audio and\nface modalities. Visual branch has a two-stream architecture to capture spatial\nand temporal information. Face and audio branches encode audio signals and\nfaces, respectively. Finally, a spatio-temporal multi-modal graph (STMG) is\nconstructed to model the interaction among multiple faces. With joint\noptimization of these branches, the intrinsic correlation of the tasks of\nsaliency prediction and sound source localization is utilized and their\nperformance is boosted by each other. Experiments show that the proposed method\noutperforms 12 state-of-the-art saliency prediction methods, and achieves\ncompetitive results in sound source localization.",
    "descriptor": "\nComments: 21 pages, 15 figures\n",
    "authors": [
      "Minglang Qiao",
      "Yufan Liu",
      "Mai Xu",
      "Xin Deng",
      "Bing Li",
      "Weiming Hu",
      "Ali Borji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08567"
  },
  {
    "id": "arXiv:2111.08568",
    "title": "Robust recovery for stochastic block models",
    "abstract": "We develop an efficient algorithm for weak recovery in a robust version of\nthe stochastic block model. The algorithm matches the statistical guarantees of\nthe best known algorithms for the vanilla version of the stochastic block\nmodel. In this sense, our results show that there is no price of robustness in\nthe stochastic block model. Our work is heavily inspired by recent work of\nBanks, Mohanty, and Raghavendra (SODA 2021) that provided an efficient\nalgorithm for the corresponding distinguishing problem. Our algorithm and its\nanalysis significantly depart from previous ones for robust recovery. A key\nchallenge is the peculiar optimization landscape underlying our algorithm: The\nplanted partition may be far from optimal in the sense that completely\nunrelated solutions could achieve the same objective value. This phenomenon is\nrelated to the push-out effect at the BBP phase transition for PCA. To the best\nof our knowledge, our algorithm is the first to achieve robust recovery in the\npresence of such a push-out effect in a non-asymptotic setting. Our algorithm\nis an instantiation of a framework based on convex optimization (related to but\ndistinct from sum-of-squares), which may be useful for other robust matrix\nestimation problems. A by-product of our analysis is a general technique that\nboosts the probability of success (over the randomness of the input) of an\narbitrary robust weak-recovery algorithm from constant (or slowly vanishing)\nprobability to exponentially high probability.",
    "descriptor": "\nComments: 203 pages, to appear in FOCS 2021\n",
    "authors": [
      "Jingqiu Ding",
      "Tommaso d'Orsi",
      "Rajai Nasser",
      "David Steurer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08568"
  },
  {
    "id": "arXiv:2111.08572",
    "title": "Saath: Speeding up CoFlows by Exploiting the Spatial Dimension",
    "abstract": "Coflow scheduling improves data-intensive application performance by\nimproving their networking performance. State-of-the-art Coflow schedulers in\nessence approximate the classic online Shortest-Job-First (SJF) scheduling,\ndesigned for a single CPU, in a distributed setting, with no coordination among\nhow the flows of a Coflow at individual ports are scheduled, and as a result\nsuffer two performance drawbacks: (1) The flows of a Coflow may suffer the\nout-of-sync problem -- they may be scheduled at different times and become\ndrifting apart, negatively affecting the Coflow completion time (CCT); (2) FIFO\nscheduling of flows at each port bears no notion of SJF, leading to suboptimal\nCCT. We propose SAATH, an online Coflow scheduler that overcomes the above\ndrawbacks by explicitly exploiting the spatial dimension of Coflows. In SAATH,\nthe global scheduler schedules the flows of a Coflow using an all-or-none\npolicy which mitigates the out-of-sync problem. To order the Coflows within\neach queue, SAATH resorts to a Least-Contention-First (LCoF) policy which we\nshow extends the gist of SJF to the spatial dimension, complemented with\nstarvation freedom. Our evaluation using an Azure testbed and simulations of\ntwo production cluster traces show that compared to Aalo, SAATH reduces the CCT\nin median (P90) cases by 1.53x (4.5x) and 1.42x (37x), respectively.",
    "descriptor": "",
    "authors": [
      "Akshay Jajoo",
      "Rohan Gandhi",
      "Y. Charlie Hu",
      "Cheng-Kok Koh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.08572"
  },
  {
    "id": "arXiv:2111.08575",
    "title": "GRI: General Reinforced Imitation and its Application to Vision-Based  Autonomous Driving",
    "abstract": "Deep reinforcement learning (DRL) has been demonstrated to be effective for\nseveral complex decision-making applications such as autonomous driving and\nrobotics. However, DRL is notoriously limited by its high sample complexity and\nits lack of stability. Prior knowledge, e.g. as expert demonstrations, is often\navailable but challenging to leverage to mitigate these issues. In this paper,\nwe propose General Reinforced Imitation (GRI), a novel method which combines\nbenefits from exploration and expert data and is straightforward to implement\nover any off-policy RL algorithm. We make one simplifying hypothesis: expert\ndemonstrations can be seen as perfect data whose underlying policy gets a\nconstant high reward. Based on this assumption, GRI introduces the notion of\noffline demonstration agents. This agent sends expert data which are processed\nboth concurrently and indistinguishably with the experiences coming from the\nonline RL exploration agent. We show that our approach enables major\nimprovements on vision-based autonomous driving in urban environments. We\nfurther validate the GRI method on Mujoco continuous control tasks with\ndifferent off-policy RL algorithms. Our method ranked first on the CARLA\nLeaderboard and outperforms World on Rails, the previous state-of-the-art, by\n17%.",
    "descriptor": "",
    "authors": [
      "Raphael Chekroun",
      "Marin Toromanoff",
      "Sascha Hornauer",
      "Fabien Moutarde"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08575"
  },
  {
    "id": "arXiv:2111.08577",
    "title": "Neuron-based Pruning of Deep Neural Networks with Better Generalization  using Kronecker Factored Curvature Approximation",
    "abstract": "Existing methods of pruning deep neural networks focus on removing\nunnecessary parameters of the trained network and fine tuning the model\nafterwards to find a good solution that recovers the initial performance of the\ntrained model. Unlike other works, our method pays special attention to the\nquality of the solution in the compressed model and inference computation time\nby pruning neurons. The proposed algorithm directs the parameters of the\ncompressed model toward a flatter solution by exploring the spectral radius of\nHessian which results in better generalization on unseen data. Moreover, the\nmethod does not work with a pre-trained network and performs training and\npruning simultaneously. Our result shows that it improves the state-of-the-art\nresults on neuron compression. The method is able to achieve very small\nnetworks with small accuracy degradation across different neural network\nmodels.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Abdolghani Ebrahimi",
      "Diego Klabjan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08577"
  },
  {
    "id": "arXiv:2111.08581",
    "title": "Words of Wisdom: Representational Harms in Learning From AI  Communication",
    "abstract": "Many educational technologies use artificial intelligence (AI) that presents\ngenerated or produced language to the learner. We contend that all language,\nincluding all AI communication, encodes information about the identity of the\nhuman or humans who contributed to crafting the language. With AI\ncommunication, however, the user may index identity information that does not\nmatch the source. This can lead to representational harms if language\nassociated with one cultural group is presented as \"standard\" or \"neutral\", if\nthe language advantages one group over another, or if the language reinforces\nnegative stereotypes. In this work, we discuss a case study using a Visual\nQuestion Generation (VQG) task involving gathering crowdsourced data from\ntargeted demographic groups. Generated questions will be presented to human\nevaluators to understand how they index the identity behind the language,\nwhether and how they perceive any representational harms, and how they would\nideally address any such harms caused by AI communication. We reflect on the\neducational applications of this work as well as the implications for equality,\ndiversity, and inclusion (EDI).",
    "descriptor": "",
    "authors": [
      "Amanda Buddemeyer",
      "Erin Walker",
      "Malihe Alikhani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.08581"
  },
  {
    "id": "arXiv:2111.08585",
    "title": "CEHR-BERT: Incorporating temporal information from structured EHR data  to improve prediction tasks",
    "abstract": "Embedding algorithms are increasingly used to represent clinical concepts in\nhealthcare for improving machine learning tasks such as clinical phenotyping\nand disease prediction. Recent studies have adapted state-of-the-art\nbidirectional encoder representations from transformers (BERT) architecture to\nstructured electronic health records (EHR) data for the generation of\ncontextualized concept embeddings, yet do not fully incorporate temporal data\nacross multiple clinical domains. Therefore we developed a new BERT adaptation,\nCEHR-BERT, to incorporate temporal information using a hybrid approach by\naugmenting the input to BERT using artificial time tokens, incorporating time,\nage, and concept embeddings, and introducing a new second learning objective\nfor visit type. CEHR-BERT was trained on a subset of Columbia University Irving\nMedical Center-York Presbyterian Hospital's clinical data, which includes 2.4M\npatients, spanning over three decades, and tested using 4-fold cross-validation\non the following prediction tasks: hospitalization, death, new heart failure\n(HF) diagnosis, and HF readmission. Our experiments show that CEHR-BERT\noutperformed existing state-of-the-art clinical BERT adaptations and baseline\nmodels across all 4 prediction tasks in both ROC-AUC and PR-AUC. CEHR-BERT also\ndemonstrated strong transfer learning capability, as our model trained on only\n5% of data outperformed comparison models trained on the entire data set.\nAblation studies to better understand the contribution of each time component\nshowed incremental gains with every element, suggesting that CEHR-BERT's\nincorporation of artificial time tokens, time and age embeddings with concept\nembeddings, and the addition of the second learning objective represents a\npromising approach for future BERT-based clinical embeddings.",
    "descriptor": "",
    "authors": [
      "Chao Pang",
      "Xinzhuo Jiang",
      "Krishna S Kalluri",
      "Matthew Spotnitz",
      "RuiJun Chen",
      "Adler Perotte",
      "Karthik Natarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08585"
  },
  {
    "id": "arXiv:2111.08587",
    "title": "Offline Contextual Bandits for Wireless Network Optimization",
    "abstract": "The explosion in mobile data traffic together with the ever-increasing\nexpectations for higher quality of service call for the development of AI\nalgorithms for wireless network optimization. In this paper, we investigate how\nto learn policies that can automatically adjust the configuration parameters of\nevery cell in the network in response to the changes in the user demand. Our\nsolution combines existent methods for offline learning and adapts them in a\nprincipled way to overcome crucial challenges arising in this context.\nEmpirical results suggest that our proposed method will achieve important\nperformance gains when deployed in the real network while satisfying practical\nconstrains on computational efficiency.",
    "descriptor": "",
    "authors": [
      "Miguel Suau",
      "Alexandros Agapitos",
      "David Lynch",
      "Derek Farrell",
      "Mingqi Zhou",
      "Aleksandar Milenovic"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08587"
  },
  {
    "id": "arXiv:2111.08589",
    "title": "Bicriteria Nash Flows over Time",
    "abstract": "Flows over time are a natural way to incorporate flow dynamics that arise in\nvarious applications such as traffic networks. In this paper we introduce a\nnatural variant of the deterministic fluid queuing model in which users aim to\nminimize their costs subject to arrival at their destination before a\npre-specified deadline. We determine the existence and the structure of Nash\nflows over time and fully characterize the price of anarchy for this model. The\nprice of anarchy measures the ratio of the quality of the equilibrium and the\nquality of the optimum flow, where we evaluate the quality using two different\nnatural performance measures: the throughput for a given deadline and the\nmakespan for a given amount of flow. While it turns out that both prices of\nanarchy can be unbounded in general, we provide tight bounds for the important\nsubclass of parallel path networks. Surprisingly, the two performance measures\nyield different results here.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Tim Oosterwijk",
      "Daniel Schmand",
      "Marc Schr\u00f6der"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.08589"
  },
  {
    "id": "arXiv:2111.08591",
    "title": "Robustness of Bayesian Neural Networks to White-Box Adversarial Attacks",
    "abstract": "Bayesian Neural Networks (BNNs), unlike Traditional Neural Networks (TNNs)\nare robust and adept at handling adversarial attacks by incorporating\nrandomness. This randomness improves the estimation of uncertainty, a feature\nlacking in TNNs. Thus, we investigate the robustness of BNNs to white-box\nattacks using multiple Bayesian neural architectures. Furthermore, we create\nour BNN model, called BNN-DenseNet, by fusing Bayesian inference (i.e.,\nvariational Bayes) to the DenseNet architecture, and BDAV, by combining this\nintervention with adversarial training. Experiments are conducted on the\nCIFAR-10 and FGVC-Aircraft datasets. We attack our models with strong white-box\nattacks ($l_\\infty$-FGSM, $l_\\infty$-PGD, $l_2$-PGD, EOT $l_\\infty$-FGSM, and\nEOT $l_\\infty$-PGD). In all experiments, at least one BNN outperforms\ntraditional neural networks during adversarial attack scenarios. An\nadversarially-trained BNN outperforms its non-Bayesian, adversarially-trained\ncounterpart in most experiments, and often by significant margins. Lastly, we\ninvestigate network calibration and find that BNNs do not make overconfident\npredictions, providing evidence that BNNs are also better at measuring\nuncertainty.",
    "descriptor": "\nComments: Accepted at the fourth IEEE International Conference on Artificial Intelligence and Knowledge Engineering (AIKE 2021)\n",
    "authors": [
      "Adaku Uchendu",
      "Daniel Campoy",
      "Christopher Menart",
      "Alexandra Hildenbrandt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08591"
  },
  {
    "id": "arXiv:2111.08596",
    "title": "Reinforcement Learning with Feedback from Multiple Humans with Diverse  Skills",
    "abstract": "A promising approach to improve the robustness and exploration in\nReinforcement Learning is collecting human feedback and that way incorporating\nprior knowledge of the target environment. It is, however, often too expensive\nto obtain enough feedback of good quality. To mitigate the issue, we aim to\nrely on a group of multiple experts (and non-experts) with different skill\nlevels to generate enough feedback. Such feedback can therefore be inconsistent\nand infrequent. In this paper, we build upon prior work -- Advise, a Bayesian\napproach attempting to maximise the information gained from human feedback --\nextending the algorithm to accept feedback from this larger group of humans,\nthe trainers, while also estimating each trainer's reliability. We show how\naggregating feedback from multiple trainers improves the total feedback's\naccuracy and make the collection process easier in two ways. Firstly, this\napproach addresses the case of some of the trainers being adversarial.\nSecondly, having access to the information about each trainer reliability\nprovides a second layer of robustness and offers valuable information for\npeople managing the whole system to improve the overall trust in the system. It\noffers an actionable tool for improving the feedback collection process or\nmodifying the reward function design if needed. We empirically show that our\napproach can accurately learn the reliability of each trainer correctly and use\nit to maximise the information gained from the multiple trainers' feedback,\neven if some of the sources are adversarial.",
    "descriptor": "\nComments: Accepted NeurIPS 2021 Workshop on Safe and Robust Control of Uncertain Systems. arXiv admin note: text overlap with arXiv:1908.06134\n",
    "authors": [
      "Taku Yamagata",
      "Ryan McConville",
      "Raul Santos-Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08596"
  },
  {
    "id": "arXiv:2111.08600",
    "title": "Towards Real-Time Monocular Depth Estimation for Robotics: A Survey",
    "abstract": "As an essential component for many autonomous driving and robotic activities\nsuch as ego-motion estimation, obstacle avoidance and scene understanding,\nmonocular depth estimation (MDE) has attracted great attention from the\ncomputer vision and robotics communities. Over the past decades, a large number\nof methods have been developed. To the best of our knowledge, however, there is\nnot a comprehensive survey of MDE. This paper aims to bridge this gap by\nreviewing 197 relevant articles published between 1970 and 2021. In particular,\nwe provide a comprehensive survey of MDE covering various methods, introduce\nthe popular performance evaluation metrics and summarize publically available\ndatasets. We also summarize available open-source implementations of some\nrepresentative methods and compare their performances. Furthermore, we review\nthe application of MDE in some important robotic tasks. Finally, we conclude\nthis paper by presenting some promising directions for future research. This\nsurvey is expected to assist readers to navigate this research field.",
    "descriptor": "",
    "authors": [
      "Xingshuai Dong",
      "Matthew A. Garratt",
      "Sreenatha G. Anavatti",
      "Hussein A. Abbass"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.08600"
  },
  {
    "id": "arXiv:2111.08604",
    "title": "Conservative invariant finite-difference schemes for the modified  shallow water equations in Lagrangian coordinates",
    "abstract": "The one-dimensional modified shallow water equations in Lagrangian\ncoordinates are considered. It is shown the relationship between symmetries and\nconservation laws in Lagrangian coordinates, in mass Lagrangian variables, and\nEulerian coordinates. For equations in Lagrangian coordinates an invariant\nfinite-difference scheme is constructed for all cases for which conservation\nlaws exist in the differential model. Such schemes possess the difference\nanalogues of the conservation laws of mass, momentum, energy, the law of center\nof mass motion for horizontal, inclined and parabolic bottom topographies.\nInvariant conservative difference scheme is tested numerically in comparison\nwith naive approximation invariant scheme.",
    "descriptor": "\nComments: 30 pages, 12 figures\n",
    "authors": [
      "V. A. Dorodnitsyn",
      "E. I. Kaptsov",
      "S. V. Meleshko"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.08604"
  },
  {
    "id": "arXiv:2111.08609",
    "title": "Document AI: Benchmarks, Models and Applications",
    "abstract": "Document AI, or Document Intelligence, is a relatively new research topic\nthat refers to the techniques for automatically reading, understanding, and\nanalyzing business documents. It is an important research direction for natural\nlanguage processing and computer vision. In recent years, the popularity of\ndeep learning technology has greatly advanced the development of Document AI,\nsuch as document layout analysis, visual information extraction, document\nvisual question answering, document image classification, etc. This paper\nbriefly reviews some of the representative models, tasks, and benchmark\ndatasets. Furthermore, we also introduce early-stage heuristic rule-based\ndocument analysis, statistical machine learning algorithms, and deep learning\napproaches especially pre-training methods. Finally, we look into future\ndirections for Document AI research.",
    "descriptor": "",
    "authors": [
      "Lei Cui",
      "Yiheng Xu",
      "Tengchao Lv",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.08609"
  },
  {
    "id": "arXiv:2111.08614",
    "title": "IKEA Object State Dataset: A 6DoF object pose estimation dataset and  benchmark for multi-state assembly objects",
    "abstract": "Utilizing 6DoF(Degrees of Freedom) pose information of an object and its\ncomponents is critical for object state detection tasks. We present IKEA Object\nState Dataset, a new dataset that contains IKEA furniture 3D models, RGBD video\nof the assembly process, the 6DoF pose of furniture parts and their bounding\nbox. The proposed dataset will be available at\nhttps://github.com/mxllmx/IKEAObjectStateDataset.",
    "descriptor": "",
    "authors": [
      "Yongzhi Su",
      "Mingxin Liu",
      "Jason Rambach",
      "Antonia Pehrson",
      "Anton Berg",
      "Didier Stricker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08614"
  },
  {
    "id": "arXiv:2111.08617",
    "title": "Project CGX: Scalable Deep Learning on Commodity GPUs",
    "abstract": "The ability to scale out training workloads has been one of the key\nperformance enablers of deep learning. The main scaling approach is\ndata-parallel GPU-based training, which has been boosted by hardware and\nsoftware support for highly efficient inter-GPU communication, in particular\nvia bandwidth overprovisioning. This support comes at a price: there is an\norder of magnitude cost difference between \"cloud-grade\" servers with such\nsupport, relative to their \"consumer-grade\" counterparts, although server-grade\nand consumer-grade GPUs can have similar computational envelopes. In this\npaper, we investigate whether the expensive hardware overprovisioning approach\ncan be supplanted via algorithmic and system design, and propose a framework\ncalled CGX, which provides efficient software support for communication\ncompression. We show that this framework is able to remove communication\nbottlenecks from consumer-grade multi-GPU systems, in the absence of hardware\nsupport: when training modern models and tasks to full accuracy, our framework\nenables self-speedups of 2-3X on a commodity system using 8 consumer-grade\nNVIDIA RTX 3090 GPUs, and enables it to surpass the throughput of an NVIDIA\nDGX-1 server, which has similar peak FLOPS but benefits from bandwidth\noverprovisioning.",
    "descriptor": "",
    "authors": [
      "Ilia Markov",
      "Hamidreza Ramezani",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08617"
  },
  {
    "id": "arXiv:2111.08618",
    "title": "Inverse heat conduction to model and optimise a geothermal field",
    "abstract": "The design of heat exchanger fields is a key phase to ensure the long-term\nsustainability of such renewable energy systems. This task has to be\naccomplished by modelling the relevant processes in the complex system made up\nof different exchangers, where the heat transfer must be considered within\nexchangers and outside exchangers. We propose a mathematical model for the\nstudy of the heat conduction into the soil as consequence of the presence of\nexchangers. Such a problem is formulated and solved with an analytical\napproach. On the basis of such analytical solution, we propose an optimisation\nprocedure to compute the best position of the exchangers by minimising the\nadverse effects of neighbouring devices. Some numerical experiments are used to\nshow the effectiveness of the proposed method also by taking into account a\nreference approximation procedure of the problem based on a finite difference\nmethod.",
    "descriptor": "",
    "authors": [
      "Nadaniela Egidi",
      "Josephin Giacomini",
      "Pierluigi Maponi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Analysis of PDEs (math.AP)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2111.08618"
  },
  {
    "id": "arXiv:2111.08620",
    "title": "A Data-Driven Approach for Linear and Nonlinear Damage Detection Using  Variational Mode Decomposition and GARCH Model",
    "abstract": "In this article, an original data-driven approach is proposed to detect both\nlinear and nonlinear damage in structures using output-only responses. The\nmethod deploys variational mode decomposition (VMD) and a generalised\nautoregressive conditional heteroscedasticity (GARCH) model for signal\nprocessing and feature extraction. To this end, VMD decomposes the response\nsignals into intrinsic mode functions (IMFs). Afterwards, the GARCH model is\nutilised to represent the statistics of IMFs. The model coefficients of IMFs\nconstruct the primary feature vector. Kernel-based principal component analysis\n(PCA) and linear discriminant analysis (LDA) are utilised to reduce the\nredundancy of the primary features by mapping them to the new feature space.\nThe informative features are then fed separately into three supervised\nclassifiers, namely support vector machine (SVM), k-nearest neighbour (kNN),\nand fine tree. The performance of the proposed method is evaluated on two\nexperimentally scaled models in terms of linear and nonlinear damage\nassessment. Kurtosis and ARCH tests proved the compatibility of the GARCH\nmodel.",
    "descriptor": "\nComments: 30 Pages, 12 Figures and 8 Tables, Submitted Journal: Engineering with Computers, Springer\n",
    "authors": [
      "Vahid Reza Gharehbaghi",
      "Hashem Kalbkhani",
      "Ehsan Noroozinejad Farsangi",
      "T.Y. Yang",
      "Seyedali Mirjalili"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08620"
  },
  {
    "id": "arXiv:2111.08621",
    "title": "Real-time Bidding for Time Constrained Impression Contracts in First and  Second Price Auctions -- Theory and Algorithms",
    "abstract": "We study the optimal behavior of a bidder in a real-time auction subject to\nthe requirement that a specified collections of heterogeneous items be acquired\nwithin given time constraints. The problem facing this bidder is cast as a\ncontinuous time optimization problem which we show can, under certain weak\nassumptions, be reduced to a convex optimization problem. Focusing on the\nstandard first and second price auction mechanisms, we first show, using convex\nduality, that the optimal (infinite dimensional) bidding policy can be\nrepresented by a single finite vector of so-called \"pseudo-bids\". Using this\nresult we are able to show that, in contrast to the first price auction, the\noptimal solution in the second price case turns out to be a very simple\npiecewise constant function of time. Moreover, despite the fact that the\noptimal solution for the first price auction is genuinely dynamic, we show that\nthere remains a close connection between the two cases and that, empirically,\nthere is almost no difference between optimal behavior in either setting.\nFinally, we detail methods for implementing our bidding policies in practice\nwith further numerical simulations illustrating the performance.",
    "descriptor": "",
    "authors": [
      "Ryan J. Kinnear",
      "Ravi R. Mazumdar",
      "Peter Marbach"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.08621"
  },
  {
    "id": "arXiv:2111.08625",
    "title": "Uncertainty-Aware Multiple Instance Learning fromLarge-Scale Long Time  Series Data",
    "abstract": "We propose a novel framework to classify large-scale time series data with\nlong duration. Long time seriesclassification (L-TSC) is a challenging problem\nbecause the dataoften contains a large amount of irrelevant information to\ntheclassification target. The irrelevant period degrades the classifica-tion\nperformance while the relevance is unknown to the system.This paper proposes an\nuncertainty-aware multiple instancelearning (MIL) framework to identify the\nmost relevant periodautomatically. The predictive uncertainty enables designing\nanattention mechanism that forces the MIL model to learn from thepossibly\ndiscriminant period. Moreover, the predicted uncertaintyyields a principled\nestimator to identify whether a prediction istrustworthy or not. We further\nincorporate another modality toaccommodate unreliable predictions by training a\nseparate modelbased on its availability and conduct uncertainty aware fusion\ntoproduce the final prediction. Systematic evaluation is conductedon the\nAutomatic Identification System (AIS) data, which is col-lected to identify and\ntrack real-world vessels. Empirical resultsdemonstrate that the proposed method\ncan effectively detect thetypes of vessels based on the trajectory and the\nuncertainty-awarefusion with other available data modality\n(Synthetic-ApertureRadar or SAR imagery is used in our experiments) can\nfurtherimprove the detection accuracy.",
    "descriptor": "\nComments: Accepted to IEEE BigData 2021\n",
    "authors": [
      "Yuansheng Zhu",
      "Weishi Shi",
      "Deep Shankar Pandey",
      "Yang Liu",
      "Xiaofan Que",
      "Daniel E. Krutz",
      "Qi Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08625"
  },
  {
    "id": "arXiv:2111.08626",
    "title": "Adjoint-Matching Neural Network Surrogates for Fast 4D-Var Data  Assimilation",
    "abstract": "The data assimilation procedures used in many operational numerical weather\nforecasting systems are based around variants of the 4D-Var algorithm. The cost\nof solving the 4D-Var problem is dominated by the cost of forward and adjoint\nevaluations of the physical model. This motivates their substitution by fast,\napproximate surrogate models. Neural networks offer a promising approach for\nthe data-driven creation of surrogate models. The accuracy of the surrogate\n4D-Var problem's solution has been shown to depend explicitly on accurate\nmodeling of the forward and adjoint for other surrogate modeling approaches and\nin the general nonlinear setting. We formulate and analyze several approaches\nto incorporating derivative information into the construction of neural network\nsurrogates. The resulting networks are tested on out of training set data and\nin a sequential data assimilation setting on the Lorenz-63 system. Two methods\ndemonstrate superior performance when compared with a surrogate network trained\nwithout adjoint information, showing the benefit of incorporating adjoint\ninformation into the training process.",
    "descriptor": "",
    "authors": [
      "Austin Chennault",
      "Andrey A. Popov",
      "Amit N. Subrahmanya",
      "Rachel Cooper",
      "Anuj Karpatne",
      "Adrian Sandu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.08626"
  },
  {
    "id": "arXiv:2111.08629",
    "title": "Communication by means of Modulated Johnson Noise",
    "abstract": "We present the design of a new passive communication method that does not\nrely on ambient or generated RF sources. Instead, we exploit the Johnson\n(thermal) noise generated by a resistor to transmit information bits\nwirelessly. By switching the load connected to an antenna between a resistor\nand open circuit, we can achieve data rates of up to 26bps and distances of up\nto 7.3 meters. This communication method is orders of magnitude less power\nconsuming than conventional communication schemes and presents the opportunity\nto enable wireless communication in areas with a complete lack of connectivity.",
    "descriptor": "",
    "authors": [
      "Zerina Kapetanovic",
      "Joshua R. Smith"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08629"
  },
  {
    "id": "arXiv:2111.08630",
    "title": "Continuous-Aperture MIMO for Electromagnetic Information Theory",
    "abstract": "In recent years, the concept of continuous-aperture MIMO (CAP-MIMO) is\nreinvestigated to achieve improved communication performance with limited\nantenna apertures. Unlike the classical MIMO composed of discrete antennas,\nCAP-MIMO has a continuous antenna surface, which is expected to generate any\ncurrent distribution (i.e., pattern) and induce controllable spatial\nelectromagnetic waves. In this way, the information can be modulated on the\nelectromagnetic waves, which makes it promising to approach the ultimate\ncapacity of finite apertures. The pattern design is the key factor to determine\nthe system performance of CAP-MIMO, but it has not been well studied in the\nliterature. In this paper, we propose the pattern-division multiplexing to\ndesign the patterns for CAP-MIMO. Specifically, we first derive the system\nmodel of a typical CAP-MIMO system, which allows us to formulate the capacity\nmaximization problem. Then we propose a general pattern-division multiplexing\ntechnique to transform the design of continuous pattern functions to the design\nof their projection lengths on finite orthogonal bases, which is able to\novercome the design challenge of continuous functions. Based on this technique,\nwe further propose an alternating optimization based pattern design scheme to\nsolve the formulated capacity maximization problem. Simulation results show\nthat, the capacity achieved by the proposed scheme is about 260% higher than\nthat achieved by the benchmark scheme, which demonstrates the effectiveness of\nthe proposed pattern-division multiplexing for CAP-MIMO.",
    "descriptor": "\nComments: 13 pages, twocolumn, 9 figures. The simulation codes will be provided at: this http URL\n",
    "authors": [
      "Zijian Zhang",
      "Linglong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.08630"
  },
  {
    "id": "arXiv:2111.08634",
    "title": "NVIDIA NeMo Neural Machine Translation Systems for English-German and  English-Russian News and Biomedical Tasks at WMT21",
    "abstract": "This paper provides an overview of NVIDIA NeMo's neural machine translation\nsystems for the constrained data track of the WMT21 News and Biomedical Shared\nTranslation Tasks. Our news task submissions for English-German (En-De) and\nEnglish-Russian (En-Ru) are built on top of a baseline transformer-based\nsequence-to-sequence model. Specifically, we use a combination of 1) checkpoint\naveraging 2) model scaling 3) data augmentation with backtranslation and\nknowledge distillation from right-to-left factorized models 4) finetuning on\ntest sets from previous years 5) model ensembling 6) shallow fusion decoding\nwith transformer language models and 7) noisy channel re-ranking. Additionally,\nour biomedical task submission for English-Russian uses a biomedically biased\nvocabulary and is trained from scratch on news task data, medically relevant\ntext curated from the news task dataset, and biomedical data provided by the\nshared task. Our news system achieves a sacreBLEU score of 39.5 on the WMT'20\nEn-De test set outperforming the best submission from last year's task of 38.8.\nOur biomedical task Ru-En and En-Ru systems reach BLEU scores of 43.8 and 40.3\nrespectively on the WMT'20 Biomedical Task Test set, outperforming the previous\nyear's best submissions.",
    "descriptor": "\nComments: WMT'21 news and biomedical shared task submission\n",
    "authors": [
      "Sandeep Subramanian",
      "Oleksii Hrinchuk",
      "Virginia Adams",
      "Oleksii Kuchaiev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08634"
  },
  {
    "id": "arXiv:2111.08643",
    "title": "An Online Efficient Two-Scale Reduced Basis Approach for the Localized  Orthogonal Decomposition",
    "abstract": "We are concerned with employing Model Order Reduction (MOR) to efficiently\nsolve parameterized multiscale problems using the Localized Orthogonal\nDecomposition (LOD) multiscale method. Like many multiscale methods, the LOD\nfollows the idea of separating the problem into localized fine-scale\nsubproblems and an effective coarse-scale system derived from the solutions of\nthe local problems. While the Reduced Basis (RB) method has already been used\nto speed up the solution of the fine-scale problems, the resulting coarse\nsystem remained untouched, thus limiting the achievable speed up. In this work\nwe address this issue by applying the RB methodology to a new two-scale\nformulation of the LOD. By reducing the entire two-scale system, this two-scale\nReduced Basis LOD (TSRBLOD) approach, yields reduced order models that are\ncompletely independent from the size of the coarse mesh of the multiscale\napproach, allowing an efficient approximation of the solutions of parameterized\nmultiscale problems even for very large domains. A rigorous and efficient a\nposteriori estimator bounds the model reduction error, taking into account the\napproximation error for both the local fine-scale problems and the global\ncoarse-scale system.",
    "descriptor": "",
    "authors": [
      "Tim Keil",
      "Stephan Rave"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.08643"
  },
  {
    "id": "arXiv:2111.08644",
    "title": "UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection",
    "abstract": "Detecting abnormal events in video is commonly framed as a one-class\nclassification task, where training videos contain only normal events, while\ntest videos encompass both normal and abnormal events. In this scenario,\nanomaly detection is an open-set problem. However, some studies assimilate\nanomaly detection to action recognition. This is a closed-set scenario that\nfails to test the capability of systems at detecting new anomaly types. To this\nend, we propose UBnormal, a new supervised open-set benchmark composed of\nmultiple virtual scenes for video anomaly detection. Unlike existing data sets,\nwe introduce abnormal events annotated at the pixel level at training time, for\nthe first time enabling the use of fully-supervised learning methods for\nabnormal event detection. To preserve the typical open-set formulation, we make\nsure to include disjoint sets of anomaly types in our training and test\ncollections of videos. To our knowledge, UBnormal is the first video anomaly\ndetection benchmark to allow a fair head-to-head comparison between one-class\nopen-set models and supervised closed-set models, as shown in our experiments.\nMoreover, we provide empirical evidence showing that UBnormal can enhance the\nperformance of a state-of-the-art anomaly detection framework on two prominent\ndata sets, Avenue and ShanghaiTech.",
    "descriptor": "",
    "authors": [
      "Andra Acsintoae",
      "Andrei Florescu",
      "Mariana-Iuliana Georgescu",
      "Tudor Mare",
      "Paul Sumedrea",
      "Radu Tudor Ionescu",
      "Fahad Shahbaz Khan",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08644"
  },
  {
    "id": "arXiv:2111.08645",
    "title": "Machine Learning-Assisted Analysis of Small Angle X-ray Scattering",
    "abstract": "Small angle X-ray scattering (SAXS) is extensively used in materials science\nas a way of examining nanostructures. The analysis of experimental SAXS data\ninvolves mapping a rather simple data format to a vast amount of structural\nmodels. Despite various scientific computing tools to assist the model\nselection, the activity heavily relies on the SAXS analysts' experience, which\nis recognized as an efficiency bottleneck by the community. To cope with this\ndecision-making problem, we develop and evaluate the open-source, Machine\nLearning-based tool SCAN (SCattering Ai aNalysis) to provide recommendations on\nmodel selection. SCAN exploits multiple machine learning algorithms and uses\nmodels and a simulation tool implemented in the SasView package for generating\na well defined set of datasets. Our evaluation shows that SCAN delivers an\noverall accuracy of 95%-97%. The XGBoost Classifier has been identified as the\nmost accurate method with a good balance between accuracy and training time.\nWith eleven predefined structural models for common nanostructures and an easy\ndraw-drop function to expand the number and types training models, SCAN can\naccelerate the SAXS data analysis workflow.",
    "descriptor": "\nComments: Accepted for the 9th Swedish Workshop on Data Science\n",
    "authors": [
      "Piotr Tomaszewski",
      "Shun Yu",
      "Markus Borg",
      "Jerk R\u00f6nnols"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08645"
  },
  {
    "id": "arXiv:2111.08647",
    "title": "DataCLUE: A Benchmark Suite for Data-centric NLP",
    "abstract": "Data-centric AI has recently proven to be more effective and\nhigh-performance, while traditional model-centric AI delivers fewer and fewer\nbenefits. It emphasizes improving the quality of datasets to achieve better\nmodel performance. This field has significant potential because of its great\npracticability and getting more and more attention. However, we have not seen\nsignificant research progress in this field, especially in NLP. We propose\nDataCLUE, which is the first Data-Centric benchmark applied in NLP field. We\nalso provide three simple but effective baselines to foster research in this\nfield (improve Macro-F1 up to 5.7% point). In addition, we conduct\ncomprehensive experiments with human annotators and show the hardness of\nDataCLUE. We also try an advanced method: the forgetting informed bootstrapping\nlabel correction method. All the resources related to DataCLUE, including\ndataset, toolkit, leaderboard, and baselines, is available online at\nhttps://github.com/CLUEbenchmark/DataCLUE",
    "descriptor": "\nComments: Working In Progress. 8 pages, 9 tables, 6 figures\n",
    "authors": [
      "Liang Xu",
      "Jiacheng Liu",
      "Xiang Pan",
      "Xiaojing Lu",
      "Xiaofeng Hou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08647"
  },
  {
    "id": "arXiv:2111.08649",
    "title": "FedCostWAvg: A new averaging for better Federated Learning",
    "abstract": "We propose a simple new aggregation strategy for federated learning that won\nthe MICCAI Federated Tumor Segmentation Challenge 2021 (FETS), the first ever\nchallenge on Federated Learning in the Machine Learning community. Our method\naddresses the problem of how to aggregate multiple models that were trained on\ndifferent data sets. Conceptually, we propose a new way to choose the weights\nwhen averaging the different models, thereby extending the current state of the\nart (FedAvg). Empirical validation demonstrates that our approach reaches a\nnotable improvement in segmentation performance compared to FedAvg.",
    "descriptor": "",
    "authors": [
      "Leon M\u00e4chler",
      "Ivan Ezhov",
      "Florian Kofler",
      "Suprosanna Shit",
      "Johannes C. Paetzold",
      "Timo Loehr",
      "Benedikt Wiestler",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08649"
  },
  {
    "id": "arXiv:2111.08651",
    "title": "Diversified Multi-prototype Representation for Semi-supervised  Segmentation",
    "abstract": "This work considers semi-supervised segmentation as a dense prediction\nproblem based on prototype vector correlation and proposes a simple way to\nrepresent each segmentation class with multiple prototypes. To avoid degenerate\nsolutions, two regularization strategies are applied on unlabeled images. The\nfirst one leverages mutual information maximization to ensure that all\nprototype vectors are considered by the network. The second explicitly enforces\nprototypes to be orthogonal by minimizing their cosine distance. Experimental\nresults on two benchmark medical segmentation datasets reveal our method's\neffectiveness in improving segmentation performance when few annotated images\nare available.",
    "descriptor": "",
    "authors": [
      "Jizong Peng",
      "Christian Desrosiers",
      "Marco Pedersoli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08651"
  },
  {
    "id": "arXiv:2111.08656",
    "title": "Causal Effect Variational Autoencoder with Uniform Treatment",
    "abstract": "Causal effect variational autoencoder (CEVAE) are trained to predict the\noutcome given observational treatment data, while uniform treatment variational\nautoencoders (UTVAE) are trained with uniform treatment distribution using\nimportance sampling. In this paper, we show that using uniform treatment over\nobservational treatment distribution leads to better causal inference by\nmitigating the distribution shift that occurs from training to test time. We\nalso explore the combination of uniform and observational treatment\ndistributions with inference and generative network training objectives to find\na better training procedure for inferring treatment effect. Experimentally, we\nfind that the proposed UTVAE yields better absolute average treatment effect\nerror and precision in estimation of heterogeneous effect error than the CEVAE\non synthetic and IHDP datasets.",
    "descriptor": "",
    "authors": [
      "Daniel Jiwoong Im",
      "Kyunghyun Cho",
      "Narges Razavian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08656"
  },
  {
    "id": "arXiv:2111.08658",
    "title": "A Comparative Study on Transfer Learning and Distance Metrics in  Semantic Clustering over the COVID-19 Tweets",
    "abstract": "This paper is a comparison study in the context of Topic Detection on\nCOVID-19 data. There are various approaches for Topic Detection, among which\nthe Clustering approach is selected in this paper. Clustering requires distance\nand calculating distance needs embedding. The aim of this research is to\nsimultaneously study the three factors of embedding methods, distance metrics\nand clustering methods and their interaction. A dataset including one-month\ntweets collected with COVID-19-related hashtags is used for this study. Five\nmethods, from earlier to new methods, are selected among the embedding methods:\nWord2Vec, fastText, GloVe, BERT and T5. Five clustering methods are\ninvestigated in this paper that are: k-means, DBSCAN, OPTICS, spectral and\nJarvis-Patrick. Euclidian distance and Cosine distance as the most important\ndistance metrics in this field are also examined. First, more than 7,500 tests\nare performed to tune the parameters. Then, all the different combinations of\nembedding methods with distance metrics and clustering methods are investigated\nby silhouette metric. The number of these combinations is 50 cases. First, the\nresults of these 50 tests are examined. Then, the rank of each method is taken\ninto account in all the tests of that method. Finally, the major variables of\nthe research (embedding methods, distance metrics and clustering methods) are\nstudied separately. Averaging is performed over the control variables to\nneutralize their effect. The experimental results show that T5 strongly\noutperforms other embedding methods in terms of silhouette metric. In terms of\ndistance metrics, cosine distance is weakly better. DBSCAN is also superior to\nother methods in terms of clustering methods.",
    "descriptor": "",
    "authors": [
      "Elnaz Zafarani-Moattar",
      "Mohammad Reza Kangavari",
      "Amir Masoud Rahmani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08658"
  },
  {
    "id": "arXiv:2111.08662",
    "title": "RemoteVote and SAFE Vote: Towards Usable End-to-End Verification for  Vote-by-Mail",
    "abstract": "Postal voting is growing rapidly in the U.S., with 43% of voters casting\nballots by mail in 2020, yet until recently there has been little research\nabout extending the protections of end-to-end verifiable (E2E-V) election\nschemes to vote-by-mail contexts. The first - and to date, only - framework to\nfocus on this setting is STROBE, which has important usability limitations. In\nthis work, we present two approaches, RemoteVote and SAFE Vote, that allow\nmail-in voters to benefit from E2E-V without changing the voter experience for\nthose who choose not to participate in verification. To evaluate these systems\nand compare them with STROBE, we consider an expansive set of properties,\nincluding novel attributes of usability and verifiability, several of which\nhave applicability beyond vote-by-mail contexts. We hope that our work will\nhelp catalyze further progress towards universal applicability of E2E-V for\nreal-world elections.",
    "descriptor": "",
    "authors": [
      "Braden L. Crimmins",
      "Marshal Rhea",
      "J. Alex Halderman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.08662"
  },
  {
    "id": "arXiv:2111.08663",
    "title": "Engineering Edge-Cloud Offloading of Big Data for Channel Modelling in  THz-range Communications",
    "abstract": "Channel estimation in mmWave and THz-range wireless communications (producing\nGb/Tb-range of data) is critical to configuring system parameters related to\ntransmission signal quality, and yet it remains a daunting challenge both in\nsoftware and hardware. Current methods of channel estimations, be it modeling-\nor data-based (machine learning (ML)), - use and create big data. This in turn\nrequires a large amount of computational resources, read operations to prove if\nthere is some predefined channel configurations, e.g., QoS requirements, in the\ndatabase, as well as write operations to store the new combinations of QoS\nparameters in the database. Especially the ML-based approach requires high\ncomputational and storage resources, low latency and a higher hardware\nflexibility. In this paper, we engineer and study the offloading of the above\noperations to edge and cloud computing systems to understand the suitability of\nedge and cloud computing to provide rapid response with channel and link\nconfiguration parameters on the example of THz channel modeling. We evaluate\nthe performance of the engineered system when the computational and storage\nresources are orchestrated based on: 1) monolithic architecture, 2)\nmicroservices architectures, both in edge-cloud based approach. For\nmicroservices approach, we engineer both Docker Swarm and Kubernetes systems.\nThe measurements show a great promise of edge computing and microservices that\ncan quickly respond to properly configure parameters and improve transmission\ndistance and signal quality with ultra-high speed wireless communications.",
    "descriptor": "\nComments: This paper is uploaded here for research community, thus it is for non-commercial purposes\n",
    "authors": [
      "Zied Ennaceur",
      "Anna Engelmann",
      "Admela Jukan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.08663"
  },
  {
    "id": "arXiv:2111.08665",
    "title": "Post-Quantum Simulatable Extraction with Minimal Assumptions: Black-Box  and Constant-Round",
    "abstract": "From the minimal assumption of post-quantum semi-honest oblivious transfers,\nwe build the first $\\epsilon$-simulatable two-party computation (2PC) against\nquantum polynomial-time (QPT) adversaries that is both constant-round and\nblack-box (for both the construction and security reduction). A recent work by\nChia, Chung, Liu, and Yamakawa (FOCS'21) shows that post-quantum 2PC with\nstandard simulation-based security is impossible in constant rounds, unless\neither $\\mathbf{NP} \\subseteq \\mathbf{BQP}$ or relying on non-black-box\nsimulation. The $\\epsilon$-simulatability we target is a relaxation of the\nstandard simulation-based security that allows for an arbitrarily small\nnoticeable simulation error $\\epsilon$. Moreover, when quantum communication is\nallowed, we can further weaken the assumption to post-quantum secure one-way\nfunctions (PQ-OWFs), while maintaining the constant-round and black-box\nproperty.\nOur techniques also yield the following set of constant-round and black-box\ntwo-party protocols secure against QPT adversaries, only assuming black-box\naccess to PQ-OWFs:\n- extractable commitments for which the extractor is also an\n$\\epsilon$-simulator;\n- $\\epsilon$-zero-knowledge commit-and-prove whose commit stage is\nextractable with $\\epsilon$-simulation;\n- $\\epsilon$-simulatable coin-flipping;\n- $\\epsilon$-zero-knowledge arguments of knowledge for $\\mathbf{NP}$ for\nwhich the knowledge extractor is also an $\\epsilon$-simulator;\n- $\\epsilon$-zero-knowledge arguments for $\\mathbf{QMA}$.\nAt the heart of the above results is a black-box extraction lemma showing how\nto efficiently extract secrets from QPT adversaries while disturbing their\nquantum state in a controllable manner, i.e., achieving\n$\\epsilon$-simulatability of the after-extraction state of the adversary.",
    "descriptor": "",
    "authors": [
      "Nai-Hui Chia",
      "Kai-Min Chung",
      "Xiao Liang",
      "Takashi Yamakawa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.08665"
  },
  {
    "id": "arXiv:2111.08667",
    "title": "Machine Learning and Ensemble Approach Onto Predicting Heart Disease",
    "abstract": "The four essential chambers of one's heart that lie in the thoracic cavity\nare crucial for one's survival, yet ironically prove to be the most vulnerable.\nCardiovascular disease (CVD) also commonly referred to as heart disease has\nsteadily grown to the leading cause of death amongst humans over the past few\ndecades. Taking this concerning statistic into consideration, it is evident\nthat patients suffering from CVDs need a quick and correct diagnosis in order\nto facilitate early treatment to lessen the chances of fatality. This paper\nattempts to utilize the data provided to train classification models such as\nLogistic Regression, K Nearest Neighbors, Support Vector Machine, Decision\nTree, Gaussian Naive Bayes, Random Forest, and Multi-Layer Perceptron\n(Artificial Neural Network) and eventually using a soft voting ensemble\ntechnique in order to attain as many correct diagnoses as possible.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Aaditya Surya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08667"
  },
  {
    "id": "arXiv:2111.08679",
    "title": "Automatically detecting anomalous exoplanet transits",
    "abstract": "Raw light curve data from exoplanet transits is too complex to naively apply\ntraditional outlier detection methods. We propose an architecture which\nestimates a latent representation of both the main transit and residual\ndeviations with a pair of variational autoencoders. We show, using two\nfabricated datasets, that our latent representations of anomalous transit\nresiduals are significantly more amenable to outlier detection than raw data or\nthe latent representation of a traditional variational autoencoder. We then\napply our method to real exoplanet transit data. Our study is the first which\nautomatically identifies anomalous exoplanet transit light curves. We\nadditionally release three first-of-their-kind datasets to enable further\nresearch.",
    "descriptor": "\nComments: 12 pages, 4 figures, 4 tables, Accepted at NeurIPS 2021 (Workshop for Machine Learning and the Physical Sciences)\n",
    "authors": [
      "Christoph J. H\u00f6nes",
      "Benjamin Kurt Miller",
      "Ana M. Heras",
      "Bernard H. Foing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.08679"
  },
  {
    "id": "arXiv:2111.08684",
    "title": "Understanding How Programmers Can Use Annotations on Documentation",
    "abstract": "Modern software development requires developers to find and effectively\nutilize new APIs and their documentation, but documentation has many well-known\nissues. Despite this, developers eventually overcome these issues but have no\nway of sharing what they learned. We investigate sharing this\ndocumentation-specific information through \\textit{annotations}, which have\nadvantages over developer forums as the information is contextualized, not\ndisruptive, and is short, thus easy to author. Developers can also author\nannotations to support their own comprehension. In order to support the\ndocumentation usage behaviors we found, we built the Adamite annotation tool,\nwhich supports features such as multi-anchoring, annotation types, and pinning.\nIn our user study, we found that developers are able to create annotations that\nare useful to themselves and are able to utilize annotations created by other\ndevelopers when learning a new API, with readers of the annotations completing\n79\\% more of the task, on average, than the baseline.",
    "descriptor": "\nComments: Conditionally accepted for publication at CHI '22\n",
    "authors": [
      "Amber Horvath",
      "Michael Xieyang Liu",
      "River Hendriksen",
      "Connor Shannon",
      "Emma Paterson",
      "Kazi Jawad",
      "Andrew Macvean",
      "Brad Myers"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.08684"
  },
  {
    "id": "arXiv:2111.08687",
    "title": "INTERN: A New Learning Paradigm Towards General Vision",
    "abstract": "Enormous waves of technological innovations over the past several years,\nmarked by the advances in AI technologies, are profoundly reshaping the\nindustry and the society. However, down the road, a key challenge awaits us,\nthat is, our capability of meeting rapidly-growing scenario-specific demands is\nseverely limited by the cost of acquiring a commensurate amount of training\ndata. This difficult situation is in essence due to limitations of the\nmainstream learning paradigm: we need to train a new model for each new\nscenario, based on a large quantity of well-annotated data and commonly from\nscratch. In tackling this fundamental problem, we move beyond and develop a new\nlearning paradigm named INTERN. By learning with supervisory signals from\nmultiple sources in multiple stages, the model being trained will develop\nstrong generalizability. We evaluate our model on 26 well-known datasets that\ncover four categories of tasks in computer vision. In most cases, our models,\nadapted with only 10% of the training data in the target domain, outperform the\ncounterparts trained with the full set of data, often by a significant margin.\nThis is an important step towards a promising prospect where such a model with\ngeneral vision capability can dramatically reduce our reliance on data, thus\nexpediting the adoption of AI technologies. Furthermore, revolving around our\nnew paradigm, we also introduce a new data system, a new architecture, and a\nnew benchmark, which, together, form a general vision ecosystem to support its\nfuture development in an open and inclusive manner.",
    "descriptor": "",
    "authors": [
      "Jing Shao",
      "Siyu Chen",
      "Yangguang Li",
      "Kun Wang",
      "Zhenfei Yin",
      "Yinan He",
      "Jianing Teng",
      "Qinghong Sun",
      "Mengya Gao",
      "Jihao Liu",
      "Gengshi Huang",
      "Guanglu Song",
      "Yichao Wu",
      "Yuming Huang",
      "Fenggang Liu",
      "Huan Peng",
      "Shuo Qin",
      "Chengyu Wang",
      "Yujie Wang",
      "Conghui He",
      "Ding Liang",
      "Yu Liu",
      "Fengwei Yu",
      "Junjie Yan",
      "Dahua Lin",
      "Xiaogang Wang",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08687"
  },
  {
    "id": "arXiv:2111.08691",
    "title": "Uncertainty quantification and inverse modeling for subsurface flow in  3D heterogeneous formations using a theory-guided convolutional  encoder-decoder network",
    "abstract": "We build surrogate models for dynamic 3D subsurface single-phase flow\nproblems with multiple vertical producing wells. The surrogate model provides\nefficient pressure estimation of the entire formation at any timestep given a\nstochastic permeability field, arbitrary well locations and penetration\nlengths, and a timestep matrix as inputs. The well production rate or bottom\nhole pressure can then be determined based on Peaceman's formula. The original\nsurrogate modeling task is transformed into an image-to-image regression\nproblem using a convolutional encoder-decoder neural network architecture. The\nresidual of the governing flow equation in its discretized form is incorporated\ninto the loss function to impose theoretical guidance on the model training\nprocess. As a result, the accuracy and generalization ability of the trained\nsurrogate models are significantly improved compared to fully data-driven\nmodels. They are also shown to have flexible extrapolation ability to\npermeability fields with different statistics. The surrogate models are used to\nconduct uncertainty quantification considering a stochastic permeability field,\nas well as to infer unknown permeability information based on limited well\nproduction data and observation data of formation properties. Results are shown\nto be in good agreement with traditional numerical simulation tools, but\ncomputational efficiency is dramatically improved.",
    "descriptor": "\nComments: 42 pages, 22 figures\n",
    "authors": [
      "Rui Xu",
      "Dongxiao Zhang",
      "Nanzhe Wang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.08691"
  },
  {
    "id": "arXiv:2111.08692",
    "title": "Unicode at Gigabytes per Second",
    "abstract": "We often represent text using Unicode formats (UTF-8 and UTF-16). The UTF-8\nformat is increasingly popular, especially on the web (XML, HTML, JSON, Rust,\nGo, Swift, Ruby). The UTF-16 format is most common in Java, .NET, and inside\noperating systems such as Windows.\nSoftware systems frequently have to convert text from one Unicode format to\nthe other. While recent disks have bandwidths of 5 GiB/s or more, conventional\napproaches transcode non-ASCII text at a fraction of a gigabyte per second.\nWe show that we can validate and transcode Unicode text at gigabytes per\nsecond on current systems (x64 and ARM) without sacrificing safety. Our\nopen-source library can be ten times faster than the popular ICU library on\nnon-ASCII strings and even faster on ASCII strings.",
    "descriptor": "\nComments: SPIRE 2021: String Processing and Information Retrieval\n",
    "authors": [
      "Daniel Lemire"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.08692"
  },
  {
    "id": "arXiv:2111.08697",
    "title": "On algebraically stabilized schemes for convection-diffusion-reaction  problems",
    "abstract": "An abstract framework is developed that enables the analysis of algebraically\nstabilized discretizations in a unified way. This framework is applied to a\ndiscretization of this kind for convection-diffusion-reaction equations. The\ndefinition of this scheme contains a new limiter that improves a standard one\nin such a way that local and global discrete maximum principles are satisfied\non arbitrary simplicial meshes.",
    "descriptor": "\nComments: 34 pages, 4 figures\n",
    "authors": [
      "Volker John",
      "Petr Knobloch"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.08697"
  },
  {
    "id": "arXiv:2111.08698",
    "title": "On the Randomized Metric Distortion Conjecture",
    "abstract": "In the single winner determination problem, we have n voters and m candidates\nand each voter j incurs a cost c(i, j) if candidate i is chosen. Our objective\nis to choose a candidate that minimizes the expected total cost incurred by the\nvoters; however as we only have access to the agents' preference rankings over\nthe outcomes, a loss of efficiency is inevitable. This loss of efficiency is\nquantified by distortion. We give an instance of the metric single winner\ndetermination problem for which any randomized social choice function has\ndistortion at least 2.063164. This disproves the long-standing conjecture is\nthat there exists a randomized social choice function that has a worst-case\ndistortion of at most 2.",
    "descriptor": "\nComments: 13 pages, 1 figure\n",
    "authors": [
      "Haripriya Pulyassary",
      "Chaitanya Swamy"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.08698"
  },
  {
    "id": "arXiv:2111.01633",
    "title": "Neural Program Generation Modulo Static Analysis",
    "abstract": "State-of-the-art neural models of source code tend to be evaluated on the\ngeneration of individual expressions and lines of code, and commonly fail on\nlong-horizon tasks such as the generation of entire method bodies. We propose\nto address this deficiency using weak supervision from a static program\nanalyzer. Our neurosymbolic method allows a deep generative model to\nsymbolically compute, using calls to a static-analysis tool, long-distance\nsemantic relationships in the code that it has already generated. During\ntraining, the model observes these relationships and learns to generate\nprograms conditioned on them. We apply our approach to the problem of\ngenerating entire Java methods given the remainder of the class that contains\nthe method. Our experiments show that the approach substantially outperforms\nstate-of-the-art transformers and a model that explicitly tries to learn\nprogram semantics on this task, both in terms of producing programs free of\nbasic semantic errors and in terms of syntactically matching the ground truth.",
    "descriptor": "\nComments: Accepted for publication at Neurips 2021\n",
    "authors": [
      "Rohan Mukherjee",
      "Yeming Wen",
      "Dipak Chaudhari",
      "Thomas W. Reps",
      "Swarat Chaudhuri",
      "Chris Jermaine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.01633"
  },
  {
    "id": "arXiv:2111.07829",
    "title": "Hybrid transforms of constructible functions",
    "abstract": "We introduce a general definition of hybrid transforms for constructible\nfunctions. These are integral transforms combining Lebesgue integration and\nEuler calculus. Lebesgue integration gives access to well-studied kernels and\nto regularity results, while Euler calculus conveys topological information and\nallows for compatibility with operations on constructible functions. We conduct\na systematic study of such transforms and introduce two new ones: the\nEuler-Fourier and Euler-Laplace transforms. We show that the first has a left\ninverse and that the second provides a satisfactory generalization of Govc and\nHepworth's persistent magnitude to constructible sheaves, in particular to\nmulti-parameter persistent modules. Finally, we prove index-theoretic formulae\nexpressing a wide class of hybrid transforms as generalized Euler integral\ntransforms. This yields expectation formulae for transforms of constructible\nfunctions associated to (sub)level-sets persistence of random Gaussian\nfiltrations.",
    "descriptor": "\nComments: 48 pages, 5 figures. Comments are welcome\n",
    "authors": [
      "Vadim Lebovici"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2111.07829"
  },
  {
    "id": "arXiv:2111.08001",
    "title": "Metagenome2Vec: Building Contextualized Representations for Scalable  Metagenome Analysis",
    "abstract": "Advances in next-generation metagenome sequencing have the potential to\nrevolutionize the point-of-care diagnosis of novel pathogen infections, which\ncould help prevent potential widespread transmission of diseases. Given the\nhigh volume of metagenome sequences, there is a need for scalable frameworks to\nanalyze and segment metagenome sequences from clinical samples, which can be\nhighly imbalanced. There is an increased need for learning robust\nrepresentations from metagenome reads since pathogens within a family can have\nhighly similar genome structures (some more than 90%) and hence enable the\nsegmentation and identification of novel pathogen sequences with limited\nlabeled data. In this work, we propose Metagenome2Vec - a contextualized\nrepresentation that captures the global structural properties inherent in\nmetagenome data and local contextualized properties through self-supervised\nrepresentation learning. We show that the learned representations can help\ndetect six (6) related pathogens from clinical samples with less than 100\nlabeled sequences. Extensive experiments on simulated and clinical metagenome\ndata show that the proposed representation encodes compositional properties\nthat can generalize beyond annotations to segment novel pathogens in an\nunsupervised setting.",
    "descriptor": "\nComments: To appear in DMBIH Workshop at ICDM 2021\n",
    "authors": [
      "Sathyanarayanan N. Aakur",
      "Vineela Indla",
      "Vennela Indla",
      "Sai Narayanan",
      "Arunkumar Bagavathi",
      "Vishalini Laguduva Ramnath",
      "Akhilesh Ramachandran"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08001"
  },
  {
    "id": "arXiv:2111.08005",
    "title": "Solving Inverse Problems in Medical Imaging with Score-Based Generative  Models",
    "abstract": "Reconstructing medical images from partial measurements is an important\ninverse problem in Computed Tomography (CT) and Magnetic Resonance Imaging\n(MRI). Existing solutions based on machine learning typically train a model to\ndirectly map measurements to medical images, leveraging a training dataset of\npaired images and measurements. These measurements are typically synthesized\nfrom images using a fixed physical model of the measurement process, which\nhinders the generalization capability of models to unknown measurement\nprocesses. To address this issue, we propose a fully unsupervised technique for\ninverse problem solving, leveraging the recently introduced score-based\ngenerative models. Specifically, we first train a score-based generative model\non medical images to capture their prior distribution. Given measurements and a\nphysical model of the measurement process at test time, we introduce a sampling\nmethod to reconstruct an image consistent with both the prior and the observed\nmeasurements. Our method does not assume a fixed measurement process during\ntraining, and can thus be flexibly adapted to different measurement processes\nat test time. Empirically, we observe comparable or better performance to\nsupervised learning techniques in several medical imaging tasks in CT and MRI,\nwhile demonstrating significantly better generalization to unknown measurement\nprocesses.",
    "descriptor": "",
    "authors": [
      "Yang Song",
      "Liyue Shen",
      "Lei Xing",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08005"
  },
  {
    "id": "arXiv:2111.08006",
    "title": "Disparities in Dermatology AI: Assessments Using Diverse Clinical Images",
    "abstract": "More than 3 billion people lack access to care for skin disease. AI\ndiagnostic tools may aid in early skin cancer detection; however most models\nhave not been assessed on images of diverse skin tones or uncommon diseases. To\naddress this, we curated the Diverse Dermatology Images (DDI) dataset - the\nfirst publicly available, pathologically confirmed images featuring diverse\nskin tones. We show that state-of-the-art dermatology AI models perform\nsubstantially worse on DDI, with ROC-AUC dropping 29-40 percent compared to the\nmodels' original results. We find that dark skin tones and uncommon diseases,\nwhich are well represented in the DDI dataset, lead to performance drop-offs.\nAdditionally, we show that state-of-the-art robust training methods cannot\ncorrect for these biases without diverse training data. Our findings identify\nimportant weaknesses and biases in dermatology AI that need to be addressed to\nensure reliable application to diverse patients and across all disease.",
    "descriptor": "\nComments: Machine Learning for Health (ML4H) - Extended Abstract\n",
    "authors": [
      "Roxana Daneshjou",
      "Kailas Vodrahalli",
      "Weixin Liang",
      "Roberto A Novoa",
      "Melissa Jenkins",
      "Veronica Rotemberg",
      "Justin Ko",
      "Susan M Swetter",
      "Elizabeth E Bailey",
      "Olivier Gevaert",
      "Pritam Mukherjee",
      "Michelle Phung",
      "Kiana Yekrang",
      "Bradley Fong",
      "Rachna Sahasrabudhe",
      "James Zou",
      "Albert Chiou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08006"
  },
  {
    "id": "arXiv:2111.08008",
    "title": "SPLDExtraTrees: Robust machine learning approach for predicting kinase  inhibitor resistance",
    "abstract": "Drug resistance is a major threat to the global health and a significant\nconcern throughout the clinical treatment of diseases and drug development. The\nmutation in proteins that is related to drug binding is a common cause for\nadaptive drug resistance. Therefore, quantitative estimations of how mutations\nwould affect the interaction between a drug and the target protein would be of\nvital significance for the drug development and the clinical practice.\nComputational methods that rely on molecular dynamics simulations, Rosetta\nprotocols, as well as machine learning methods have been proven to be capable\nof predicting ligand affinity changes upon protein mutation. However, the\nseverely limited sample size and heavy noise induced overfitting and\ngeneralization issues have impeded wide adoption of machine learning for\nstudying drug resistance. In this paper, we propose a robust machine learning\nmethod, termed SPLDExtraTrees, which can accurately predict ligand binding\naffinity changes upon protein mutation and identify resistance-causing\nmutations. Especially, the proposed method ranks training data following a\nspecific scheme that starts with easy-to-learn samples and gradually\nincorporates harder and diverse samples into the training, and then iterates\nbetween sample weight recalculations and model updates. In addition, we\ncalculate additional physics-based structural features to provide the machine\nlearning model with the valuable domain knowledge on proteins for this\ndata-limited predictive tasks. The experiments substantiate the capability of\nthe proposed method for predicting kinase inhibitor resistance under three\nscenarios, and achieves predictive accuracy comparable to that of molecular\ndynamics and Rosetta methods with much less computational costs.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Ziyi Yang",
      "Zhaofeng Ye",
      "Yijia Xiao",
      "Changyu Hsieh"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08008"
  },
  {
    "id": "arXiv:2111.08011",
    "title": "Advantage of Machine Learning over Maximum Likelihood in Limited-Angle  Low-Photon X-Ray Tomography",
    "abstract": "Limited-angle X-ray tomography reconstruction is an ill-conditioned inverse\nproblem in general. Especially when the projection angles are limited and the\nmeasurements are taken in a photon-limited condition, reconstructions from\nclassical algorithms such as filtered backprojection may lose fidelity and\nacquire artifacts due to the missing-cone problem. To obtain satisfactory\nreconstruction results, prior assumptions, such as total variation minimization\nand nonlocal image similarity, are usually incorporated within the\nreconstruction algorithm. In this work, we introduce deep neural networks to\ndetermine and apply a prior distribution in the reconstruction process. Our\nneural networks learn the prior directly from synthetic training samples. The\nneural nets thus obtain a prior distribution that is specific to the class of\nobjects we are interested in reconstructing. In particular, we used deep\ngenerative models with 3D convolutional layers and 3D attention layers which\nare trained on 3D synthetic integrated circuit (IC) data from a model dubbed\nCircuitFaker. We demonstrate that, when the projection angles and photon\nbudgets are limited, the priors from our deep generative models can\ndramatically improve the IC reconstruction quality on synthetic data compared\nwith maximum likelihood estimation. Training the deep generative models with\nsynthetic IC data from CircuitFaker illustrates the capabilities of the learned\nprior from machine learning. We expect that if the process were reproduced with\nexperimental data, the advantage of the machine learning would persist. The\nadvantages of machine learning in limited angle X-ray tomography may further\nenable applications in low-photon nanoscale imaging.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Zhen Guo",
      "Jung Ki Song",
      "George Barbastathis",
      "Michael E. Glinsky",
      "Courtenay T. Vaughan",
      "Kurt W. Larson",
      "Bradley K. Alpert",
      "Zachary H. Levine"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08011"
  },
  {
    "id": "arXiv:2111.08014",
    "title": "Tensor network to learn the wavefunction of data",
    "abstract": "How many different ways are there to handwrite digit 3? To quantify this\nquestion imagine extending a dataset of handwritten digits MNIST by sampling\nadditional images until they start repeating. We call the collection of all\nresulting images of digit 3 the \"full set.\" To study the properties of the full\nset we introduce a tensor network architecture which simultaneously\naccomplishes both classification (discrimination) and sampling tasks.\nQualitatively, our trained network represents the indicator function of the\nfull set. It therefore can be used to characterize the data itself. We\nillustrate that by studying the full sets associated with the digits of MNIST.\nUsing quantum mechanical interpretation of our network we characterize the\nfull set by calculating its entanglement entropy. We also study its geometric\nproperties such as mean Hamming distance, effective dimension, and size. The\nlatter answers the question above -- the total number of black and white threes\nwritten MNIST style is $2^{72}$.",
    "descriptor": "",
    "authors": [
      "Anatoly Dymarsky",
      "Kirill Pavlenko"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08014"
  },
  {
    "id": "arXiv:2111.08030",
    "title": "Fast and Credible Likelihood-Free Cosmology with Truncated Marginal  Neural Ratio Estimation",
    "abstract": "Sampling-based inference techniques are central to modern cosmological data\nanalysis; these methods, however, scale poorly with dimensionality and\ntypically require approximate or intractable likelihoods. In this paper we\ndescribe how Truncated Marginal Neural Ratio Estimation (TMNRE) (a new approach\nin so-called simulation-based inference) naturally evades these issues,\nimproving the $(i)$ efficiency, $(ii)$ scalability, and $(iii)$ trustworthiness\nof the inferred posteriors. Using measurements of the Cosmic Microwave\nBackground (CMB), we show that TMNRE can achieve converged posteriors using\norders of magnitude fewer simulator calls than conventional Markov Chain Monte\nCarlo (MCMC) methods. Remarkably, the required number of samples is effectively\nindependent of the number of nuisance parameters. In addition, a property\ncalled \\emph{local amortization} allows the performance of rigorous statistical\nconsistency checks that are not accessible to sampling-based methods. TMNRE\npromises to become a powerful tool for cosmological data analysis, particularly\nin the context of extended cosmologies, where the timescale required for\nconventional sampling-based inference methods to converge can greatly exceed\nthat of simple cosmological models such as $\\Lambda$CDM. To perform these\ncomputations, we use an implementation of TMNRE via the open-source code\n\\texttt{swyft}.",
    "descriptor": "\nComments: 37 pages, 13 figures. \\texttt{swyft} is available at this https URL, and demonstration code for cosmological examples is available at this https URL\n",
    "authors": [
      "Alex Cole",
      "Benjamin Kurt Miller",
      "Samuel J. Witte",
      "Maxwell X. Cai",
      "Meiert W. Grootes",
      "Francesco Nattino",
      "Christoph Weniger"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08030"
  },
  {
    "id": "arXiv:2111.08054",
    "title": "Revisiting C.S.Peirce's Experiment: 150 Years Later",
    "abstract": "An iconoclastic philosopher and polymath, Charles Sanders Peirce (1837-1914)\nis among the greatest of American minds. In 1872, Peirce conducted a series of\nexperiments to determine the distribution of response times to an auditory\nstimulus, which is widely regarded as one of the most significant statistical\ninvestigations in the history of nineteenth-century American mathematical\nresearch (Stigler, 1978). On the 150th anniversary of this historic experiment,\nwe look back at Peirce's view on empirical modeling through a modern\nstatistical lens.",
    "descriptor": "\nComments: One of the oldest and fundamental problems of learning from data: How should a model adapt and generalize in the face of surprise? We demonstrate how this question can be addressed by connecting Peirce's abductive inference with density-sharpening principle. The concepts and core ideas are presented using a detailed empirical analysis of Peirce's own experimental data that he did it 150 years ago\n",
    "authors": [
      "Deep Mukhopadhyay"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.08054"
  },
  {
    "id": "arXiv:2111.08093",
    "title": "Capturing Acceleration in Monotone Inclusion: A Closed-Loop Control  Perspective",
    "abstract": "We propose and analyze a new dynamical system with \\textit{a closed-loop\ncontrol law} in a Hilbert space $\\mathcal{H}$, aiming to shed light on the\nacceleration phenomenon for \\textit{monotone inclusion} problems, which unifies\na broad class of optimization, saddle point and variational inequality (VI)\nproblems under a single framework. Given an operator $A: \\mathcal{H}\n\\rightrightarrows \\mathcal{H}$ that is maximal monotone, we study a closed-loop\ncontrol system that is governed by the operator $I - (I + \\lambda(t)A)^{-1}$\nwhere $\\lambda(\\cdot)$ is tuned by the resolution of the algebraic equation\n$\\lambda(t)\\|(I + \\lambda(t)A)^{-1}x(t) - x(t)\\|^{p-1} = \\theta$ for some\n$\\theta \\in (0, 1)$. Our first contribution is to prove the existence and\nuniqueness of a global solution via the Cauchy-Lipschitz theorem. We present a\nLyapunov function that allows for establishing the weak convergence of\ntrajectories and strong convergence results under additional conditions. We\nestablish a global ergodic rate of $O(t^{-(p+1)/2})$ in terms of a gap function\nand a global pointwise rate of $O(t^{-p/2})$ in terms of a residue function.\nLocal linear convergence is established in terms of a distance function under\nan error bound condition. Further, we provide an algorithmic framework based on\nimplicit discretization of our system in a Euclidean setting, generalizing the\nlarge-step HPE framework of~\\citet{Monteiro-2012-Iteration}. While the\ndiscrete-time analysis is a simplification and generalization of the previous\nanalysis for bounded domain, it is motivated by the aforementioned\ncontinuous-time analysis, illustrating the fundamental role that the\nclosed-loop control plays in acceleration in monotone inclusion. A highlight of\nour analysis is set of new results concerning $p$-th order tensor algorithms\nfor monotone inclusion problems, which complement the recent analysis for\nsaddle point and VI problems.",
    "descriptor": "\nComments: 45 Pages\n",
    "authors": [
      "Tianyi Lin",
      "Michael. I. Jordan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.08093"
  },
  {
    "id": "arXiv:2111.08108",
    "title": "Learning Optimal Control with Stochastic Models of Hamiltonian Dynamics",
    "abstract": "Optimal control problems can be solved by first applying the Pontryagin\nmaximum principle, followed by computing a solution of the corresponding\nunconstrained Hamiltonian dynamical system. In this paper, and to achieve a\nbalance between robustness and efficiency, we learn a reduced Hamiltonian of\nthe unconstrained Hamiltonian. This reduced Hamiltonian is learned by going\nbackward in time and by minimizing the loss function resulting from application\nof the Pontryagin maximum principle conditions. The robustness of our learning\nprocess is then further improved by progressively learning a posterior\ndistribution of reduced Hamiltonians. This leads to a more efficient sampling\nof the generalized coordinates (position, velocity) of our phase space. Our\nsolution framework applies to not only optimal control problems with\nfinite-dimensional phase (state) spaces but also the infinite dimensional case.",
    "descriptor": "\nComments: 11 pages, 11 figures\n",
    "authors": [
      "Chandrajit Bajaj",
      "Minh Nguyen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08108"
  },
  {
    "id": "arXiv:2111.08112",
    "title": "Biologically inspired speech emotion recognition",
    "abstract": "Conventional feature-based classification methods do not apply well to\nautomatic recognition of speech emotions, mostly because the precise set of\nspectral and prosodic features that is required to identify the emotional state\nof a speaker has not been determined yet. This paper presents a method that\noperates directly on the speech signal, thus avoiding the problematic step of\nfeature extraction. Furthermore, this method combines the strengths of the\nclassical source-filter model of human speech production with those of the\nrecently introduced liquid state machine (LSM), a biologically-inspired spiking\nneural network (SNN). The source and vocal tract components of the speech\nsignal are first separated and converted into perceptually relevant spectral\nrepresentations. These representations are then processed separately by two\nreservoirs of neurons. The output of each reservoir is reduced in\ndimensionality and fed to a final classifier. This method is shown to provide\nvery good classification performance on the Berlin Database of Emotional Speech\n(Emo-DB). This seems a very promising framework for solving efficiently many\nother problems in speech processing.",
    "descriptor": "",
    "authors": [
      "Reza Lotfidereshgi",
      "Philippe Gournay"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.08112"
  },
  {
    "id": "arXiv:2111.08118",
    "title": "Neuro-Hotnet: A Graph Theoretic Approach for Brain FC Estimation",
    "abstract": "Functional connectivity (FC) for quantifying interactions between regions of\nthe brain is commonly estimated from functional magnetic resonance imaging\n(fMRI). There has been increasing interest in the potential of multimodal\nimaging to obtain more robust estimates of FC in high-dimensional settings.\nRecent work has found uses for graphical algorithms in combining fMRI signals\nwith structural connectivity estimated from diffusion tensor imaging (DTI) for\nFC estimation. At the same time new algorithms focused on de novo\nidentification of graphical subnetworks with significant levels of connectivity\nare finding other biological applications with great success. Such algorithms\ndevelop notions of graphical influence that aid in revealing subnetworks of\ninterest while maintaining rigorous statistical control on discoveries. We\ndevelop a novel algorithm adapting some of these methods to FC estimation with\ncomputational efficiency and scalability. Our proposed algorithm leverages a\ngraphical random walk on DTI data to define a new measure of structural\ninfluence that highlights connected components of maximal interest. The\nsubnetwork topology is then compared to a suitable null hypothesis using\npermutation testing. Finally, individual discovered components are tested for\nsignificance. Extensive simulations show our method is comparable in power to\nthose currently in use while being fast, robust, and simple to implement. We\nalso analyze task-fMRI data from the Human Connectome Project database and find\nnovel insights into brain interactions during the performance of a motor task.\nIt is anticipated that the transparency and flexibility of our approach will\nprove valuable as further understanding of the structure-function relationship\ninforms the future of network estimation. Scalability will also only become\nmore important as neurological data become more granular and grow in dimension.",
    "descriptor": "\nComments: 36 pages, 13 figures, 3 tables, to be published in NeuroImage\n",
    "authors": [
      "Nathan Tung",
      "Eli Upfal",
      "Jerome Sanes",
      "Ani Eloyan"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.08118"
  },
  {
    "id": "arXiv:2111.08131",
    "title": "Quantum soundness of testing tensor codes",
    "abstract": "A locally testable code is an error-correcting code that admits very\nefficient probabilistic tests of membership. Tensor codes provide a simple\nfamily of combinatorial constructions of locally testable codes that generalize\nthe family of Reed-Muller codes. The natural test for tensor codes, the\naxis-parallel line vs. point test, plays an essential role in constructions of\nprobabilistically checkable proofs.\nWe analyze the axis-parallel line vs. point test as a two-prover game and\nshow that the test is sound against quantum provers sharing entanglement. Our\nresult implies the quantum-soundness of the low individual degree test, which\nis an essential component of the MIP* = RE theorem. Our proof also generalizes\nto the infinite-dimensional commuting-operator model of quantum provers.",
    "descriptor": "\nComments: In FOCS 2021\n",
    "authors": [
      "Zhengfeng Ji",
      "Anand Natarajan",
      "Thomas Vidick",
      "John Wright",
      "Henry Yuen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/2111.08131"
  },
  {
    "id": "arXiv:2111.08140",
    "title": "Bayesian inference of the climbing grade scale",
    "abstract": "Climbing grades are used to classify a climbing route based on its perceived\ndifficulty, and have come to play a central role in the sport of rock climbing.\nRecently, the first statistically rigorous method for estimating climbing\ngrades from whole-history ascent data was described, based on the dynamic\nBradley-Terry model for games between players of time-varying ability. In this\npaper, we implement inference under the whole-history rating model using Markov\nchain Monte Carlo and apply the method to a curated data set made up of\nclimbers who climb regularly. We use these data to get an estimate of the\nmodel's fundamental scale parameter m, which defines the proportional increase\nin difficulty associated with an increment of grade. We show that the data\nconform to assumptions that the climbing grade scale is a logarithmic scale of\ndifficulty, like decibels or stellar magnitude. We estimate that an increment\nin Ewbank, French and UIAA climbing grade systems corresponds to 2.1, 2.09 and\n2.13 times increase in difficulty respectively, assuming a logistic model of\nprobability of success as a function of grade. Whereas we find that the Vermin\nscale for bouldering (V-grade scale) corresponds to a 3.17 increase in\ndifficulty per grade increment. In addition, we highlight potential connections\nbetween the logarithmic properties of climbing grade scales and the\npsychophysical laws of Weber and Fechner.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Alexei Drummond",
      "Alex Popinga"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08140"
  },
  {
    "id": "arXiv:2111.08161",
    "title": "Sparse Graph Learning Under Laplacian-Related Constraints",
    "abstract": "We consider the problem of learning a sparse undirected graph underlying a\ngiven set of multivariate data. We focus on graph Laplacian-related constraints\non the sparse precision matrix that encodes conditional dependence between the\nrandom variables associated with the graph nodes. Under these constraints the\noff-diagonal elements of the precision matrix are non-positive (total\npositivity), and the precision matrix may not be full-rank. We investigate\nmodifications to widely used penalized log-likelihood approaches to enforce\ntotal positivity but not the Laplacian structure. The graph Laplacian can then\nbe extracted from the off-diagonal precision matrix. An alternating direction\nmethod of multipliers (ADMM) algorithm is presented and analyzed for\nconstrained optimization under Laplacian-related constraints and lasso as well\nas adaptive lasso penalties. Numerical results based on synthetic data show\nthat the proposed constrained adaptive lasso approach significantly outperforms\nexisting Laplacian-based approaches. We also evaluate our approach on real\nfinancial data.",
    "descriptor": "\nComments: 13 pages, 5 figures, 3 tables. To be published in IEEE Access\n",
    "authors": [
      "Jitendra K. Tugnait"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08161"
  },
  {
    "id": "arXiv:2111.08177",
    "title": "Deep Diffusion Models for Robust Channel Estimation",
    "abstract": "Channel estimation is a critical task in digital communications that greatly\nimpacts end-to-end system performance. In this work, we introduce a novel\napproach for multiple-input multiple-output (MIMO) channel estimation using\ndeep diffusion models. Our method uses a deep neural network that is trained to\nestimate the gradient of the log-likelihood of wireless channels at any point\nin high-dimensional space, and leverages this model to solve channel estimation\nvia posterior sampling. We train a deep diffusion model on channel realizations\nfrom the CDL-D model for two antenna spacings and show that the approach leads\nto competitive in- and out-of-distribution performance when compared to\ngenerative adversarial network (GAN) and compressed sensing (CS) methods. When\ntested on CDL-C channels which are never seen during training or fine-tuned on,\nour approach leads to end-to-end coded performance gains of up to $3$ dB\ncompared to CS methods and losses of only $0.5$ dB compared to ideal channel\nknowledge. To encourage open and reproducible research, our source code is\navailable at https://github.com/utcsilab/diffusion-channels .",
    "descriptor": "",
    "authors": [
      "Marius Arvinte",
      "Jonathan I Tamir"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08177"
  },
  {
    "id": "arXiv:2111.08183",
    "title": "Computational tools for assessing gene therapy under branching process  models of mutation",
    "abstract": "Multitype branching processes are ideal for studying the population dynamics\nof stem cell populations undergoing mutation accumulation over the years\nfollowing transplant. In such stochastic models, several quantities are of\nclinical interest as insertional mutagenesis carries the potential threat of\nleukemogenesis following gene therapy with autologous stem cell\ntransplantation. In this paper, we develop a three-type branching process model\ndescribing accumulations of mutations in a population of stem cells\ndistinguished by their ability for long-term self-renewal. Our outcome of\ninterest is the appearance of a double-mutant cell, which carries a high\npotential for leukemic transformation. In our model, a single-hit mutation\ncarries a slight proliferative advantage over a wild-type stem cells. We\ncompute marginalized transition probabilities that allow us to capture\nimportant quantitative aspects of our model, including the probability of\nobserving a double-hit mutant and relevant moments of a single-hit mutation\npopulation over time. We thoroughly explore the model behavior numerically,\nvarying birth rates across the initial sizes and populations of wild type stem\ncells and single-hit mutants, and compare the probability of observing a\ndouble-hit mutant under these conditions. We find that increasing the number of\nsingle-mutants over wild-type particles initially present has a large effect on\nthe occurrence of a double-mutant, and that it is relatively safe for\nsingle-mutants to be quite proliferative, provided the lentiviral gene addition\navoids creating single mutants in the original insertion process. Our approach\nis broadly applicable to an important set of questions in cancer modeling and\nother population processes involving multiple stages, compartments, or types.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Timothy C Stutz",
      "Janet S. Sinsheimer",
      "Mary Sehl",
      "Jason Xu"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.08183"
  },
  {
    "id": "arXiv:2111.08192",
    "title": "SALSA-Lite: A Fast and Effective Feature for Polyphonic Sound Event  Localization and Detection with Microphone Arrays",
    "abstract": "Polyphonic sound event localization and detection (SELD) has many practical\napplications in acoustic sensing and monitoring. However, the development of\nreal-time SELD has been limited by the demanding computational requirement of\nmost recent SELD systems. In this work, we introduce SALSA-Lite, a fast and\neffective feature for polyphonic SELD using microphone array inputs. SALSA-Lite\nis a lightweight variation of a previously proposed SALSA feature for\npolyphonic SELD. SALSA, which stands for Spatial Cue-Augmented Log-Spectrogram,\nconsists of multichannel log-spectrograms stacked channelwise with the\nnormalized principal eigenvectors of the spectrotemporally corresponding\nspatial covariance matrices. In contrast to SALSA, which uses eigenvector-based\nspatial features, SALSA-Lite uses normalized inter-channel phase differences as\nspatial features, allowing a 30-fold speedup compared to the original SALSA\nfeature. Experimental results on the TAU-NIGENS Spatial Sound Events 2021\ndataset showed that the SALSA-Lite feature achieved competitive performance\ncompared to the full SALSA feature, and significantly outperformed the\ntraditional feature set of multichannel log-mel spectrograms with generalized\ncross-correlation spectra. Specifically, using SALSA-Lite features increased\nlocalization-dependent F1 score and class-dependent localization recall by 15%\nand 5%, respectively, compared to using multichannel log-mel spectrograms with\ngeneralized cross-correlation spectra.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2110.00275\n",
    "authors": [
      "Thi Ngoc Tho Nguyen",
      "Douglas L. Jones",
      "Karn N. Watcharasupat",
      "Huy Phan",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.08192"
  },
  {
    "id": "arXiv:2111.08201",
    "title": "Attention-based Multi-hypothesis Fusion for Speech Summarization",
    "abstract": "Speech summarization, which generates a text summary from speech, can be\nachieved by combining automatic speech recognition (ASR) and text summarization\n(TS). With this cascade approach, we can exploit state-of-the-art models and\nlarge training datasets for both subtasks, i.e., Transformer for ASR and\nBidirectional Encoder Representations from Transformers (BERT) for TS. However,\nASR errors directly affect the quality of the output summary in the cascade\napproach. We propose a cascade speech summarization model that is robust to ASR\nerrors and that exploits multiple hypotheses generated by ASR to attenuate the\neffect of ASR errors on the summary. We investigate several schemes to combine\nASR hypotheses. First, we propose using the sum of sub-word embedding vectors\nweighted by their posterior values provided by an ASR system as an input to a\nBERT-based TS system. Then, we introduce a more general scheme that uses an\nattention-based fusion module added to a pre-trained BERT module to align and\ncombine several ASR hypotheses. Finally, we perform speech summarization\nexperiments on the How2 dataset and a newly assembled TED-based dataset that we\nwill release with this paper. These experiments show that retraining the\nBERT-based TS system with these schemes can improve summarization performance\nand that the attention-based fusion module is particularly effective.",
    "descriptor": "",
    "authors": [
      "Takatomo Kano",
      "Atsunori Ogawa",
      "Marc Delcroix",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.08201"
  },
  {
    "id": "arXiv:2111.08216",
    "title": "Second-order statistics of fermionic Gaussian states",
    "abstract": "We study the statistical behavior of entanglement in quantum bipartite\nsystems over fermionic Gaussian states as measured by von Neumann entropy and\nentanglement capacity. The focus is on the variance of von Neumann entropy and\nthe mean entanglement capacity that belong to the so-defined second-order\nstatistics. The main results are the exact yet explicit formulas of the two\nconsidered second-order statistics for fixed subsystem dimension differences.\nWe also conjecture the exact variance of von Neumann entropy valid for\narbitrary subsystem dimensions. Based on the obtained results, we analytically\nstudy the numerically observed phenomena of Gaussianity of von Neumann entropy\nand linear growth of average capacity.",
    "descriptor": "\nComments: 23 pages, 3 figures\n",
    "authors": [
      "Youyi Huang",
      "Lu Wei"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Information Theory (cs.IT)",
      "High Energy Physics - Theory (hep-th)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.08216"
  },
  {
    "id": "arXiv:2111.08228",
    "title": "SStaGCN: Simplified stacking based graph convolutional networks",
    "abstract": "Graph convolutional network (GCN) is a powerful model studied broadly in\nvarious graph structural data learning tasks. However, to mitigate the\nover-smoothing phenomenon, and deal with heterogeneous graph structural data,\nthe design of GCN model remains a crucial issue to be investigated. In this\npaper, we propose a novel GCN called SStaGCN (Simplified stacking based GCN) by\nutilizing the ideas of stacking and aggregation, which is an adaptive general\nframework for tackling heterogeneous graph data. Specifically, we first use the\nbase models of stacking to extract the node features of a graph. Subsequently,\naggregation methods such as mean, attention and voting techniques are employed\nto further enhance the ability of node features extraction. Thereafter, the\nnode features are considered as inputs and fed into vanilla GCN model.\nFurthermore, theoretical generalization bound analysis of the proposed model is\nexplicitly given. Extensive experiments on $3$ public citation networks and\nanother $3$ heterogeneous tabular data demonstrate the effectiveness and\nefficiency of the proposed approach over state-of-the-art GCNs. Notably, the\nproposed SStaGCN can efficiently mitigate the over-smoothing problem of GCN.",
    "descriptor": "",
    "authors": [
      "Jia Cai",
      "Zhilong Xiong",
      "Shaogao Lv"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08228"
  },
  {
    "id": "arXiv:2111.08234",
    "title": "Covariate Shift in High-Dimensional Random Feature Regression",
    "abstract": "A significant obstacle in the development of robust machine learning models\nis covariate shift, a form of distribution shift that occurs when the input\ndistributions of the training and test sets differ while the conditional label\ndistributions remain the same. Despite the prevalence of covariate shift in\nreal-world applications, a theoretical understanding in the context of modern\nmachine learning has remained lacking. In this work, we examine the exact\nhigh-dimensional asymptotics of random feature regression under covariate shift\nand present a precise characterization of the limiting test error, bias, and\nvariance in this setting. Our results motivate a natural partial order over\ncovariate shifts that provides a sufficient condition for determining when the\nshift will harm (or even help) test performance. We find that overparameterized\nmodels exhibit enhanced robustness to covariate shift, providing one of the\nfirst theoretical explanations for this intriguing phenomenon. Additionally,\nour analysis reveals an exact linear relationship between in-distribution and\nout-of-distribution generalization performance, offering an explanation for\nthis surprising recent empirical observation.",
    "descriptor": "\nComments: 107 pages, 10 figures\n",
    "authors": [
      "Nilesh Tripuraneni",
      "Ben Adlam",
      "Jeffrey Pennington"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08234"
  },
  {
    "id": "arXiv:2111.08242",
    "title": "Blockage Prediction Using Wireless Signatures: Deep Learning Enables  Real-World Demonstration",
    "abstract": "Overcoming the link blockage challenges is essential for enhancing the\nreliability and latency of millimeter wave (mmWave) and sub-terahertz (sub-THz)\ncommunication networks. Previous approaches relied mainly on either (i)\nmultiple-connectivity, which under-utilizes the network resources, or on (ii)\nthe use of out-of-band and non-RF sensors to predict link blockages, which is\nassociated with increased cost and system complexity. In this paper, we propose\na novel solution that relies only on in-band mmWave wireless measurements to\nproactively predict future dynamic line-of-sight (LOS) link blockages. The\nproposed solution utilizes deep neural networks and special patterns of\nreceived signal power, that we call pre-blockage wireless signatures to infer\nfuture blockages. Specifically, the developed machine learning models attempt\nto predict: (i) If a future blockage will occur? (ii) When will this blockage\nhappen? (iii) What is the type of the blockage? And (iv) what is the direction\nof the moving blockage? To evaluate our proposed approach, we build a\nlarge-scale real-world dataset comprising nearly $0.5$ million data points\n(mmWave measurements) for both indoor and outdoor blockage scenarios. The\nresults, using this dataset, show that the proposed approach can successfully\npredict the occurrence of future dynamic blockages with more than 85\\%\naccuracy. Further, for the outdoor scenario with highly-mobile vehicular\nblockages, the proposed model can predict the exact time of the future blockage\nwith less than $80$ms error for blockages happening within the future $500$ms.\nThese results, among others, highlight the promising gains of the proposed\nproactive blockage prediction solution which could potentially enhance the\nreliability and latency of future wireless networks.",
    "descriptor": "\nComments: Submitted to IEEE. The dataset and code files will be available on the DeepSense 6G website this https URL\n",
    "authors": [
      "Shunyao Wu",
      "Muhammad Alrabeiah",
      "Chaitali Chakrabarti",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.08242"
  },
  {
    "id": "arXiv:2111.08256",
    "title": "Online Meta Adaptation for Variable-Rate Learned Image Compression",
    "abstract": "This work addresses two major issues of end-to-end learned image compression\n(LIC) based on deep neural networks: variable-rate learning where separate\nnetworks are required to generate compressed images with varying qualities, and\nthe train-test mismatch between differentiable approximate quantization and\ntrue hard quantization. We introduce an online meta-learning (OML) setting for\nLIC, which combines ideas from meta learning and online learning in the\nconditional variational auto-encoder (CVAE) framework. By treating the\nconditional variables as meta parameters and treating the generated conditional\nfeatures as meta priors, the desired reconstruction can be controlled by the\nmeta parameters to accommodate compression with variable qualities. The online\nlearning framework is used to update the meta parameters so that the\nconditional reconstruction is adaptively tuned for the current image. Through\nthe OML mechanism, the meta parameters can be effectively updated through SGD.\nThe conditional reconstruction is directly based on the quantized latent\nrepresentation in the decoder network, and therefore helps to bridge the gap\nbetween the training estimation and true quantized latent distribution.\nExperiments demonstrate that our OML approach can be flexibly applied to\ndifferent state-of-the-art LIC methods to achieve additional performance\nimprovements with little computation and transmission overhead.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Wei Jiang",
      "Wei Wang",
      "Songnan Li",
      "Shan Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08256"
  },
  {
    "id": "arXiv:2111.08308",
    "title": "Learning with convolution and pooling operations in kernel methods",
    "abstract": "Recent empirical work has shown that hierarchical convolutional kernels\ninspired by convolutional neural networks (CNNs) significantly improve the\nperformance of kernel methods in image classification tasks. A widely accepted\nexplanation for the success of these architectures is that they encode\nhypothesis classes that are suitable for natural images. However, understanding\nthe precise interplay between approximation and generalization in convolutional\narchitectures remains a challenge. In this paper, we consider the stylized\nsetting of covariates (image pixels) uniformly distributed on the hypercube,\nand fully characterize the RKHS of kernels composed of single layers of\nconvolution, pooling, and downsampling operations. We then study the gain in\nsample efficiency of kernel methods using these kernels over standard\ninner-product kernels. In particular, we show that 1) the convolution layer\nbreaks the curse of dimensionality by restricting the RKHS to `local'\nfunctions; 2) local pooling biases learning towards low-frequency functions,\nwhich are stable by small translations; 3) downsampling may modify the\nhigh-frequency eigenspaces but leaves the low-frequency part approximately\nunchanged. Notably, our results quantify how choosing an architecture adapted\nto the target function leads to a large improvement in the sample complexity.",
    "descriptor": "\nComments: 52 pages, 6 figures\n",
    "authors": [
      "Theodor Misiakiewicz",
      "Song Mei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08308"
  },
  {
    "id": "arXiv:2111.08330",
    "title": "Bayesian Optimization for Cascade-type Multi-stage Processes",
    "abstract": "Complex processes in science and engineering are often formulated as\nmulti-stage decision-making problems. In this paper, we consider a type of\nmulti-stage decision-making process called a cascade process. A cascade process\nis a multi-stage process in which the output of one stage is used as an input\nfor the next stage. When the cost of each stage is expensive, it is difficult\nto search for the optimal controllable parameters for each stage exhaustively.\nTo address this problem, we formulate the optimization of the cascade process\nas an extension of Bayesian optimization framework and propose two types of\nacquisition functions (AFs) based on credible intervals and expected\nimprovement. We investigate the theoretical properties of the proposed AFs and\ndemonstrate their effectiveness through numerical experiments. In addition, we\nconsider an extension called suspension setting in which we are allowed to\nsuspend the cascade process at the middle of the multi-stage decision-making\nprocess that often arises in practical problems. We apply the proposed method\nin the optimization problem of the solar cell simulator, which was the\nmotivation for this study.",
    "descriptor": "\nComments: 50 pages, 8 figures\n",
    "authors": [
      "Shunya Kusakawa",
      "Shion Takeno",
      "Yu Inatsu",
      "Kentaro Kutsukake",
      "Shogo Iwazaki",
      "Takashi Nakano",
      "Toru Ujihara",
      "Masayuki Karasuyama",
      "Ichiro Takeuchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.08330"
  },
  {
    "id": "arXiv:2111.08339",
    "title": "Global Sensitivity Analysis of Four Chamber Heart Hemodynamics Using  Surrogate Models",
    "abstract": "Computational Fluid Dynamics (CFD) is used to assist in designing artificial\nvalves and planning procedures, focusing on local flow features. However,\nassessing the impact on overall cardiovascular function or predicting\nlonger-term outcomes may require more comprehensive whole heart CFD models.\nFitting such models to patient data requires numerous computationally expensive\nsimulations, and depends on specific clinical measurements to constrain model\nparameters, hampering clinical adoption. Surrogate models can help to\naccelerate the fitting process while accounting for the added uncertainty. We\ncreate a validated patient-specific four-chamber heart CFD model based on the\nNavier-Stokes-Brinkman (NSB) equations and test Gaussian Process Emulators\n(GPEs) as a surrogate model for performing a variance-based global sensitivity\nanalysis (GSA). GSA identified preload as the dominant driver of flow in both\nthe right and left side of the heart, respectively. Left-right differences were\nseen in terms of vascular outflow resistances, with pulmonary artery resistance\nhaving a much larger impact on flow than aortic resistance. Our results suggest\nthat GPEs can be used to identify parameters in personalized whole heart CFD\nmodels, and highlight the importance of accurate preload measurements.",
    "descriptor": "\nComments: 8 pages plus 15 pages supplement, 6 figures, 3 tables, submitted to IEEE Transactions on Biomedical Engineering\n",
    "authors": [
      "Elias Karabelas",
      "Stefano Longobardi",
      "Jana Fuchsberger",
      "Orod Razeghi",
      "Cristobal Rodero",
      "Marina Strocchi",
      "Ronak Rajani",
      "Gundolf Haase",
      "Gernot Plank",
      "Steven Niederer"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Emerging Technologies (cs.ET)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.08339"
  },
  {
    "id": "arXiv:2111.08362",
    "title": "Image-specific Convolutional Kernel Modulation for Single Image  Super-resolution",
    "abstract": "Recently, deep-learning-based super-resolution methods have achieved\nexcellent performances, but mainly focus on training a single generalized deep\nnetwork by feeding numerous samples. Yet intuitively, each image has its\nrepresentation, and is expected to acquire an adaptive model. For this issue,\nwe propose a novel image-specific convolutional kernel modulation (IKM) by\nexploiting the global contextual information of image or feature to generate an\nattention weight for adaptively modulating the convolutional kernels, which\noutperforms the vanilla convolution and several existing attention mechanisms\nwhile embedding into the state-of-the-art architectures without any additional\nparameters. Particularly, to optimize our IKM in mini-batch training, we\nintroduce an image-specific optimization (IsO) algorithm, which is more\neffective than the conventional mini-batch SGD optimization. Furthermore, we\ninvestigate the effect of IKM on the state-of-the-art architectures and exploit\na new backbone with U-style residual learning and hourglass dense block\nlearning, terms U-Hourglass Dense Network (U-HDN), which is an appropriate\narchitecture to utmost improve the effectiveness of IKM theoretically and\nexperimentally. Extensive experiments on single image super-resolution show\nthat the proposed methods achieve superior performances over state-of-the-art\nmethods. Code is available at github.com/YuanfeiHuang/IKM.",
    "descriptor": "\nComments: 13 pages, submitted to IEEE Transactions, codes are available at this https URL\n",
    "authors": [
      "Yuanfei Huang",
      "Jie Li",
      "Yanting Hu",
      "Xinbo Gao",
      "Hua Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08362"
  },
  {
    "id": "arXiv:2111.08387",
    "title": "S-DCCRN: Super Wide Band DCCRN with learnable complex feature for speech  enhancement",
    "abstract": "In speech enhancement, complex neural network has shown promising performance\ndue to their effectiveness in processing complex-valued spectrum. Most of the\nrecent speech enhancement approaches mainly focus on wide-band signal with a\nsampling rate of 16K Hz. However, research on super wide band (e.g., 32K Hz) or\neven full-band (48K) denoising is still lacked due to the difficulty of\nmodeling more frequency bands and particularly high frequency components. In\nthis paper, we extend our previous deep complex convolution recurrent neural\nnetwork (DCCRN) substantially to a super wide band version -- S-DCCRN, to\nperform speech denoising on speech of 32K Hz sampling rate. We first employ a\ncascaded sub-band and full-band processing module, which consists of two\nsmall-footprint DCCRNs -- one operates on sub-band signal and one operates on\nfull-band signal, aiming at benefiting from both local and global frequency\ninformation. Moreover, instead of simply adopting the STFT feature as input, we\nuse a complex feature encoder trained in an end-to-end manner to refine the\ninformation of different frequency bands. We also use a complex feature decoder\nto revert the feature to time-frequency domain. Finally, a learnable spectrum\ncompression method is adopted to adjust the energy of different frequency\nbands, which is beneficial for neural network learning. The proposed model,\nS-DCCRN, has surpassed PercepNet as well as several competitive models and\nachieves state-of-the-art performance in terms of speech quality and\nintelligibility. Ablation studies also demonstrate the effectiveness of\ndifferent contributions.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Shubo Lv",
      "Yihui Fu",
      "Mengtao Xing",
      "Jiayao Sun",
      "Lei Xie",
      "Jun Huang",
      "Yannan Wang",
      "Tao Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.08387"
  },
  {
    "id": "arXiv:2111.08430",
    "title": "Code-free development and deployment of deep segmentation models for  digital pathology",
    "abstract": "Application of deep learning on histopathological whole slide images (WSIs)\nholds promise of improving diagnostic efficiency and reproducibility but is\nlargely dependent on the ability to write computer code or purchase commercial\nsolutions. We present a code-free pipeline utilizing free-to-use, open-source\nsoftware (QuPath, DeepMIB, and FastPathology) for creating and deploying deep\nlearning-based segmentation models for computational pathology. We demonstrate\nthe pipeline on a use case of separating epithelium from stroma in colonic\nmucosa. A dataset of 251 annotated WSIs, comprising 140 hematoxylin-eosin\n(HE)-stained and 111 CD3 immunostained colon biopsy WSIs, were developed\nthrough active learning using the pipeline. On a hold-out test set of 36 HE and\n21 CD3-stained WSIs a mean intersection over union score of 96.6% and 95.3% was\nachieved on epithelium segmentation. We demonstrate pathologist-level\nsegmentation accuracy and clinical acceptable runtime performance and show that\npathologists without programming experience can create near state-of-the-art\nsegmentation solutions for histopathological WSIs using only free-to-use\nsoftware. The study further demonstrates the strength of open-source solutions\nin its ability to create generalizable, open pipelines, of which trained models\nand predictions can seamlessly be exported in open formats and thereby used in\nexternal solutions. All scripts, trained models, a video tutorial, and the full\ndataset of 251 WSIs with ~31k epithelium annotations are made openly available\nat https://github.com/andreped/NoCodeSeg to accelerate research in the field.",
    "descriptor": "\nComments: 18 pages, 4 figures, 2 tables\n",
    "authors": [
      "Henrik Sahlin Pettersen",
      "Ilya Belevich",
      "Elin Synn\u00f8ve R\u00f8yset",
      "Erik Smistad",
      "Eija Jokitalo",
      "Ingerid Reinertsen",
      "Ingunn Bakke",
      "Andr\u00e9 Pedersen"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.08430"
  },
  {
    "id": "arXiv:2111.08441",
    "title": "Use of machine learning in geriatric clinical care for chronic diseases:  a systematic literature review",
    "abstract": "Objectives-Geriatric clinical care is a multidisciplinary assessment designed\nto evaluate older patients (age 65 years and above) functional ability,\nphysical health, and cognitive wellbeing. The majority of these patients suffer\nfrom multiple chronic conditions and require special attention. Recently,\nhospitals utilize various artificial intelligence (AI) systems to improve care\nfor elderly patients. The purpose of this systematic literature review is to\nunderstand the current use of AI systems, particularly machine learning (ML),\nin geriatric clinical care for chronic diseases. Materials and Methods-We\nrestricted our search to eight databases, namely PubMed, WorldCat, MEDLINE,\nProQuest, ScienceDirect, SpringerLink, Wiley, and ERIC, to analyze research\narticles published in English between January 2010 and June 2019. We focused on\nstudies that used ML algorithms in the care of geriatrics patients with chronic\nconditions. Results-We identified 35 eligible studies and classified in three\ngroups-psychological disorder (n=22), eye diseases (n=6), and others (n=7).\nThis review identified the lack of standardized ML evaluation metrics and the\nneed for data governance specific to health care applications. Conclusion- More\nstudies and ML standardization tailored to health care applications are\nrequired to confirm whether ML could aid in improving geriatric clinical care.",
    "descriptor": "",
    "authors": [
      "Avishek Choudhury",
      "Emily Renjilian",
      "Onur Asan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08441"
  },
  {
    "id": "arXiv:2111.08446",
    "title": "Automatic Sleep Staging: Recent Development, Challenges, and Future  Directions",
    "abstract": "Modern deep learning holds a great potential to transform clinical practice\non human sleep. Teaching a machine to carry out routine tasks would be a\ntremendous reduction in workload for clinicians. Sleep staging, a fundamental\nstep in sleep practice, is a suitable task for this and will be the focus in\nthis article. Recently, automatic sleep staging systems have been trained to\nmimic manual scoring, leading to similar performance to human sleep experts, at\nleast on scoring of healthy subjects. Despite tremendous progress, we have not\nseen automatic sleep scoring adopted widely in clinical environments. This\nreview aims to give a shared view of the authors on the most recent\nstate-of-the-art development in automatic sleep staging, the challenges that\nstill need to be addressed, and the future directions for automatic sleep\nscoring to achieve clinical value.",
    "descriptor": "\nComments: 28 pages, 2 figures\n",
    "authors": [
      "Huy Phan",
      "Kaare Mikkelsen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08446"
  },
  {
    "id": "arXiv:2111.08457",
    "title": "A Novel TSK Fuzzy System Incorporating Multi-view Collaborative Transfer  Learning for Personalized Epileptic EEG Detection",
    "abstract": "In clinical practice, electroencephalography (EEG) plays an important role in\nthe diagnosis of epilepsy. EEG-based computer-aided diagnosis of epilepsy can\ngreatly improve the ac-curacy of epilepsy detection while reducing the workload\nof physicians. However, there are many challenges in practical applications for\npersonalized epileptic EEG detection (i.e., training of detection model for a\nspecific person), including the difficulty in extracting effective features\nfrom one single view, the undesirable but common scenario of lacking sufficient\ntraining data in practice, and the no guarantee of identically distributed\ntraining and test data. To solve these problems, we propose a TSK fuzzy\nsystem-based epilepsy detection algorithm that integrates multi-view\ncollaborative transfer learning. To address the challenge due to the limitation\nof single-view features, multi-view learning ensures the diversity of features\nby extracting them from different views. The lack of training data for building\na personalized detection model is tackled by leveraging the knowledge from the\nsource domain (reference scene) to enhance the performance of the target domain\n(current scene of interest), where mismatch of data distributions between the\ntwo domains is resolved with adaption technique based on maximum mean\ndiscrepancy. Notably, the transfer learning and multi-view feature extraction\nare performed at the same time. Furthermore, the fuzzy rules of the TSK fuzzy\nsystem equip the model with strong fuzzy logic inference capability. Hence, the\nproposed method has the potential to detect epileptic EEG signals effectively,\nwhich is demonstrated with the positive results from a large number of\nexperiments on the CHB-MIT dataset.",
    "descriptor": "\nComments: Submitted to IEEE Trans\n",
    "authors": [
      "Andong Li",
      "Zhaohong Deng",
      "Qiongdan Lou",
      "Kup-Sze Choi",
      "Hongbin Shen",
      "Shitong Wang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08457"
  },
  {
    "id": "arXiv:2111.08476",
    "title": "An analogue of the ElGamal scheme based on the Markovski algorithm",
    "abstract": "We give an analogue of the ElGamal encryption system based on the Markovski\nalgorithm [4; 5].",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Nadeghda Malyutina",
      "Victor Shcherbacov"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Cryptography and Security (cs.CR)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.08476"
  },
  {
    "id": "arXiv:2111.08480",
    "title": "A Shallow U-Net Architecture for Reliably Predicting Blood Pressure (BP)  from Photoplethysmogram (PPG) and Electrocardiogram (ECG) Signals",
    "abstract": "Cardiovascular diseases are the most common causes of death around the world.\nTo detect and treat heart-related diseases, continuous Blood Pressure (BP)\nmonitoring along with many other parameters are required. Several invasive and\nnon-invasive methods have been developed for this purpose. Most existing\nmethods used in the hospitals for continuous monitoring of BP are invasive. On\nthe contrary, cuff-based BP monitoring methods, which can predict Systolic\nBlood Pressure (SBP) and Diastolic Blood Pressure (DBP), cannot be used for\ncontinuous monitoring. Several studies attempted to predict BP from\nnon-invasively collectible signals such as Photoplethysmogram (PPG) and\nElectrocardiogram (ECG), which can be used for continuous monitoring. In this\nstudy, we explored the applicability of autoencoders in predicting BP from PPG\nand ECG signals. The investigation was carried out on 12,000 instances of 942\npatients of the MIMIC-II dataset and it was found that a very shallow,\none-dimensional autoencoder can extract the relevant features to predict the\nSBP and DBP with the state-of-the-art performance on a very large dataset.\nIndependent test set from a portion of the MIMIC-II dataset provides an MAE of\n2.333 and 0.713 for SBP and DBP, respectively. On an external dataset of forty\nsubjects, the model trained on the MIMIC-II dataset, provides an MAE of 2.728\nand 1.166 for SBP and DBP, respectively. For both the cases, the results met\nBritish Hypertension Society (BHS) Grade A and surpassed the studies from the\ncurrent literature.",
    "descriptor": "\nComments: 22 pages, Figure 8, Table 13\n",
    "authors": [
      "Sakib Mahmud",
      "Nabil Ibtehaz",
      "Amith Khandakar",
      "Anas Tahir",
      "Tawsifur Rahman",
      "Khandaker Reajul Islam",
      "Md Shafayet Hossain",
      "M. Sohel Rahman",
      "Mohammad Tariqul Islam",
      "Muhammad E. H. Chowdhury"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08480"
  },
  {
    "id": "arXiv:2111.08484",
    "title": "Asymptotically secure All-or-nothing Quantum Oblivious Transfer",
    "abstract": "We present a device independently secure quantum scheme for p-threshold\nall-or-nothing oblivious transfer. Novelty of the scheme is that, its security\ndoes not depend -- unlike the usual case -- on any quantum bit commitment\nprotocol, rather it depends on Hardy's argument for two-qubit system. This\nscheme is shown to be unconditionally secure against any strategy allowed by\nquantum mechanics. By providing a secure scheme for all-or-nothing quantum\noblivious transfer, we have answered a long standing open problem, other than\nthe quantum key distribution, whether there is any two-party quantum\ncryptographic protocol, which is unconditionally secure.",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Ramij Rahaman"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.08484"
  },
  {
    "id": "arXiv:2111.08493",
    "title": "An adaptive dimension reduction algorithm for latent variables of  variational autoencoder",
    "abstract": "Constructed by the neural network, variational autoencoder has the\noverfitting problem caused by setting too many neural units, we develop an\nadaptive dimension reduction algorithm that can automatically learn the\ndimension of latent variable vector, moreover, the dimension of every hidden\nlayer. This approach not only apply to the variational autoencoder but also\nother variants like Conditional VAE(CVAE), and we show the empirical results on\nsix data sets which presents the universality and efficiency of this algorithm.\nThe key advantages of this algorithm is that it can converge the dimension of\nlatent variable vector which approximates the dimension reaches minimum loss of\nvariational autoencoder(VAE), also speeds up the generating and computing speed\nby reducing the neural units.",
    "descriptor": "\nComments: 11 pages 12 figures\n",
    "authors": [
      "Yiran Dong",
      "Chuanhou Gao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08493"
  },
  {
    "id": "arXiv:2111.08502",
    "title": "Human-error-potential Estimation based on Wearable Biometric Sensors",
    "abstract": "This study tackles on a new problem of estimating human-error potential on a\nshop floor on the basis of wearable sensors. Unlike existing studies that\nutilize biometric sensing technology to estimate people's internal state such\nas fatigue and mental stress, we attempt to estimate the human-error potential\nin a situation where a target person does not stay calm, which is much more\ndifficult as sensor noise significantly increases. We propose a novel\nformulation, in which the human-error-potential estimation problem is reduced\nto a classification problem, and introduce a new method that can be used for\nsolving the classification problem even with noisy sensing data. The key ideas\nare to model the process of calculating biometric indices probabilistically so\nthat the prior knowledge on the biometric indices can be integrated, and to\nutilize the features that represent the movement of target persons in\ncombination with biometric features. The experimental analysis showed that our\nmethod effectively estimates the human-error potential.",
    "descriptor": "\nComments: Accepted by KDIR 2021 : 13th International Conference on Knowledge Discovery and Information Retrieval. (ISBN 978-989-758-533-3; ISSN 2184-3228, this https URL&t=1)\n",
    "authors": [
      "Hiroki Ohashi",
      "Hiroto Nagayoshi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.08502"
  },
  {
    "id": "arXiv:2111.08503",
    "title": "Binary classification of spoken words with passive elastic  metastructures",
    "abstract": "Many electronic devices spend most of their time waiting for a wake-up event:\npacemakers waiting for an anomalous heartbeat, security systems on alert to\ndetect an intruder, smartphones listening for the user to say a wake-up phrase.\nThese devices continuously convert physical signals into electrical currents\nthat are then analyzed on a digital computer -- leading to power consumption\neven when no event is taking place. Solving this problem requires the ability\nto passively distinguish relevant from irrelevant events (e.g. tell a wake-up\nphrase from a regular conversation). Here, we experimentally demonstrate an\nelastic metastructure, consisting of a network of coupled silicon resonators,\nthat passively discriminates between pairs of spoken words -- solving the\nwake-up problem for scenarios where only two classes of events are possible.\nThis passive speech recognition is demonstrated on a dataset from speakers with\nsignificant gender and accent diversity. The geometry of the metastructure is\ndetermined during the design process, in which the network of resonators\n('mechanical neurones') learns to selectively respond to spoken words. Training\nis facilitated by a machine learning model that reduces the number of\ncomputationally expensive three-dimensional elastic wave simulations. By\nembedding event detection in the structural dynamics, mechanical neural\nnetworks thus enable novel classes of always-on smart devices with no standby\npower consumption.",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Tena Dub\u010dek",
      "Daniel Moreno-Garcia",
      "Thomas Haag",
      "Henrik R. Thomsen",
      "Theodor S. Becker",
      "Christoph B\u00e4rlocher",
      "Fredrik Andersson",
      "Sebastian D. Huber",
      "Dirk-Jan van Manen",
      "Luis Guillermo Villanueva",
      "Johan O.A. Robertsson",
      "Marc Serra-Garcia"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Emerging Technologies (cs.ET)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.08503"
  },
  {
    "id": "arXiv:2111.08507",
    "title": "Machine Learning for Genomic Data",
    "abstract": "This report explores the application of machine learning techniques on short\ntimeseries gene expression data. Although standard machine learning algorithms\nwork well on longer time-series', they often fail to find meaningful insights\nfrom fewer timepoints. In this report, we explore model-based clustering\ntechniques. We combine popular unsupervised learning techniques like K-Means,\nGaussian Mixture Models, Bayesian Networks, Hidden Markov Models with the\nwell-known Expectation Maximization algorithm. K-Means and Gaussian Mixture\nModels are fairly standard, while Hidden Markov Model and Bayesian Networks\nclustering are more novel ideas that suit time-series gene expression data.",
    "descriptor": "\nComments: Number of pages: 53\n",
    "authors": [
      "Akankshita Dash"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08507"
  },
  {
    "id": "arXiv:2111.08535",
    "title": "Sequential Community Mode Estimation",
    "abstract": "We consider a population, partitioned into a set of communities, and study\nthe problem of identifying the largest community within the population via\nsequential, random sampling of individuals. There are multiple sampling\ndomains, referred to as \\emph{boxes}, which also partition the population. Each\nbox may consist of individuals of different communities, and each community may\nin turn be spread across multiple boxes. The learning agent can, at any time,\nsample (with replacement) a random individual from any chosen box; when this is\ndone, the agent learns the community the sampled individual belongs to, and\nalso whether or not this individual has been sampled before. The goal of the\nagent is to minimize the probability of mis-identifying the largest community\nin a \\emph{fixed budget} setting, by optimizing both the sampling strategy as\nwell as the decision rule. We propose and analyse novel algorithms for this\nproblem, and also establish information theoretic lower bounds on the\nprobability of error under any algorithm. In several cases of interest, the\nexponential decay rates of the probability of error under our algorithms are\nshown to be optimal up to constant factors. The proposed algorithms are further\nvalidated via simulations on real-world datasets.",
    "descriptor": "\nComments: Presented in part at Performance'21. Full version in Elsevier Performance Evaluation, Dec. 21\n",
    "authors": [
      "Shubham Anand Jain",
      "Shreyas Goenka",
      "Divyam Bapna",
      "Nikhil Karamchandani",
      "Jayakrishnan Nair"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08535"
  },
  {
    "id": "arXiv:2111.08547",
    "title": "Modelling airborne transmission of SARS-CoV-2 at a local scale",
    "abstract": "The coronavirus disease (COVID-19) pandemic has changed our lives and still\nposes a challenge to science. Numerous studies have contributed to a better\nunderstanding of the pandemic. In particular, inhalation of aerosolised\npathogens has been identified as essential for transmission. This information\nis crucial to slow the spread, but the individual likelihood of becoming\ninfected in everyday situations remains uncertain. Mathematical models help\nestimate such risks. In this study, we propose how to model airborne\ntransmission of SARS-CoV-2 at a local scale. In this regard, we combine\nmicroscopic crowd simulation with a new model for disease transmission.\nInspired by compartmental models, we describe agents' health status as\nsusceptible, exposed, infectious or recovered. Infectious agents exhale\npathogens bound to persistent aerosols, whereas susceptible agents absorb\npathogens when moving through an aerosol cloud left by the infectious agent.\nThe transmission depends on the pathogen load of the aerosol cloud, which\nchanges over time. We propose a 'high risk' benchmark scenario to distinguish\ncritical from non-critical situations. Simulating indoor situations show that\nthe new model is suitable to evaluate the risk of exposure qualitatively and,\nthus, enables scientists or even decision-makers to better assess the spread of\nCOVID-19 and similar diseases.",
    "descriptor": "\nComments: 12 pages, 12 figures, 3 tables\n",
    "authors": [
      "Simon Rahn",
      "Marion G\u00f6del",
      "Gerta K\u00f6ster",
      "Gesine Hofinger"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.08547"
  },
  {
    "id": "arXiv:2111.08558",
    "title": "Solving sums of squares in global fields",
    "abstract": "The problem of writing a totally positive element as a sum of squares has a\nlong history in mathematics, going back to Bachet and Lagrange. While for some\nspecific rings (like integers or polynomials over the rationals), there are\nknown methods for decomposing an element into a sum of squares, in general, for\nmany other important rings and fields, the problem is still widely open. In\nthis paper, we present an explicit algorithm for decomposing an element of an\narbitrary global field (either a number field or a global function field) into\na sum of squares of minimal length.",
    "descriptor": "",
    "authors": [
      "Przemys\u0142aw Koprowski"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2111.08558"
  },
  {
    "id": "arXiv:2111.08569",
    "title": "Isotropic vectors over global fields",
    "abstract": "We present a complete suite of algorithms for finding isotropic vectors of\nquadratic forms (of any dimension) over an arbitrary global field of\ncharacteristic different from 2.",
    "descriptor": "",
    "authors": [
      "Przemys\u0142aw Koprowski"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2111.08569"
  },
  {
    "id": "arXiv:2111.08570",
    "title": "Tracking Blobs in the Turbulent Edge Plasma of Tokamak Fusion Reactors",
    "abstract": "The analysis of turbulent flows is a significant area in fusion plasma\nphysics. Current theoretical models quantify the degree of turbulence based on\nthe evolution of certain plasma density structures, called blobs. In this work\nwe track the shape and the position of these blobs in high frequency video data\nobtained from Gas Puff Imaging (GPI) diagnostics, by training a mask R-CNN\nmodel on synthetic data and testing on both synthetic and real data. As a\nresult, our model effectively tracks blob structures on both synthetic and real\nexperimental GPI data, showing its prospect as a powerful tool to estimate blob\nstatistics linked with edge turbulence of the tokamak plasma.",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Woonghee Han",
      "Randall A. Pietersen",
      "Rafael Villamor-Lora",
      "Matthew Beveridge",
      "Nicola Offeddu",
      "Theodore Golfinopoulos",
      "Christian Theiler",
      "James L. Terry",
      "Earl S. Marmar",
      "Iddo Drori"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08570"
  },
  {
    "id": "arXiv:2111.08597",
    "title": "A layer-stress learning framework universally augments deep neural  network tasks",
    "abstract": "Deep neural networks (DNN) such as Multi-Layer Perception (MLP) and\nConvolutional Neural Networks (CNN) represent one of the most established deep\nlearning algorithms. Given the tremendous effects of the number of hidden\nlayers on network architecture and performance, it is very important to choose\nthe number of hidden layers but still a serious challenge. More importantly,\nthe current network architectures can only process the information from the\nlast layer of the feature extractor, which greatly limited us to further\nimprove its performance. Here we presented a layer-stress deep learning\nframework (x-NN) which implemented automatic and wise depth decision on shallow\nor deep feature map in a deep network through firstly designing enough number\nof layers and then trading off them by Multi-Head Attention Block. The x-NN can\nmake use of features from various depth layers through attention allocation and\nthen help to make final decision as well. As a result, x-NN showed outstanding\nprediction ability in the Alzheimer's Disease Classification Technique\nChallenge PRCV 2021, in which it won the top laurel and outperformed all other\nAI models. Moreover, the performance of x-NN was verified by one more AD\nneuroimaging dataset and other AI tasks.",
    "descriptor": "",
    "authors": [
      "Shihao Shao",
      "Yong Liu",
      "Qinghua Cui"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08597"
  },
  {
    "id": "arXiv:2111.08606",
    "title": "Advancement of Deep Learning in Pneumonia and Covid-19 Classification  and Localization: A Qualitative and Quantitative Analysis",
    "abstract": "Around 450 million people are affected by pneumonia every year which results\nin 2.5 million deaths. Covid-19 has also affected 181 million people which has\nlead to 3.92 million casualties. The chances of death in both of these diseases\ncan be significantly reduced if they are diagnosed early. However, the current\nmethods of diagnosing pneumonia (complaints + chest X-ray) and covid-19\n(RT-PCR) require the presence of expert radiologists and time, respectively.\nWith the help of Deep Learning models, pneumonia and covid-19 can be detected\ninstantly from Chest X-rays or CT scans. This way, the process of diagnosing\nPneumonia/Covid-19 can be made more efficient and widespread. In this paper, we\naim to elicit, explain, and evaluate, qualitatively and quantitatively, major\nadvancements in deep learning methods aimed at detecting or localizing\ncommunity-acquired pneumonia (CAP), viral pneumonia, and covid-19 from images\nof chest X-rays and CT scans. Being a systematic review, the focus of this\npaper lies in explaining deep learning model architectures which have either\nbeen modified or created from scratch for the task at hand wiwth focus on\ngeneralizability. For each model, this paper answers the question of why the\nmodel is designed the way it is, the challenges that a particular model\novercomes, and the tradeoffs that come with modifying a model to the required\nspecifications. A quantitative analysis of all models described in the paper is\nalso provided to quantify the effectiveness of different models with a similar\ngoal. Some tradeoffs cannot be quantified, and hence they are mentioned\nexplicitly in the qualitative analysis, which is done throughout the paper. By\ncompiling and analyzing a large quantum of research details in one place with\nall the datasets, model architectures, and results, we aim to provide a\none-stop solution to beginners and current researchers interested in this\nfield.",
    "descriptor": "\nComments: 20 pages, 5 figures, 5 tables\n",
    "authors": [
      "Aakash Shah",
      "Manan Shah"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08606"
  },
  {
    "id": "arXiv:2111.08611",
    "title": "Stochastic Extragradient: General Analysis and Improved Rates",
    "abstract": "The Stochastic Extragradient (SEG) method is one of the most popular\nalgorithms for solving min-max optimization and variational inequalities\nproblems (VIP) appearing in various machine learning tasks. However, several\nimportant questions regarding the convergence properties of SEG are still open,\nincluding the sampling of stochastic gradients, mini-batching, convergence\nguarantees for the monotone finite-sum variational inequalities with possibly\nnon-monotone terms, and others. To address these questions, in this paper, we\ndevelop a novel theoretical framework that allows us to analyze several\nvariants of SEG in a unified manner. Besides standard setups, like Same-Sample\nSEG under Lipschitzness and monotonicity or Independent-Samples SEG under\nuniformly bounded variance, our approach allows us to analyze variants of SEG\nthat were never explicitly considered in the literature before. Notably, we\nanalyze SEG with arbitrary sampling which includes importance sampling and\nvarious mini-batching strategies as special cases. Our rates for the new\nvariants of SEG outperform the current state-of-the-art convergence guarantees\nand rely on less restrictive assumptions.",
    "descriptor": "\nComments: 50 pages, 3 figures, 2 tables\n",
    "authors": [
      "Eduard Gorbunov",
      "Hugo Berard",
      "Gauthier Gidel",
      "Nicolas Loizou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08611"
  },
  {
    "id": "arXiv:2111.08635",
    "title": "Single-channel speech separation using Soft-minimum Permutation  Invariant Training",
    "abstract": "The goal of speech separation is to extract multiple speech sources from a\nsingle microphone recording. Recently, with the advancement of deep learning\nand availability of large datasets, speech separation has been formulated as a\nsupervised learning problem. These approaches aim to learn discriminative\npatterns of speech, speakers, and background noise using a supervised learning\nalgorithm, typically a deep neural network. A long-lasting problem in\nsupervised speech separation is finding the correct label for each separated\nspeech signal, referred to as label permutation ambiguity. Permutation\nambiguity refers to the problem of determining the output-label assignment\nbetween the separated sources and the available single-speaker speech labels.\nFinding the best output-label assignment is required for calculation of\nseparation error, which is later used for updating parameters of the model.\nRecently, Permutation Invariant Training (PIT) has been shown to be a promising\nsolution in handling the label ambiguity problem. However, the overconfident\nchoice of the output-label assignment by PIT results in a sub-optimal trained\nmodel. In this work, we propose a probabilistic optimization framework to\naddress the inefficiency of PIT in finding the best output-label assignment.\nOur proposed method entitled trainable Soft-minimum PIT is then employed on the\nsame Long-Short Term Memory (LSTM) architecture used in Permutation Invariant\nTraining (PIT) speech separation method. The results of our experiments show\nthat the proposed method outperforms conventional PIT speech separation\nsignificantly (p-value $ < 0.01$) by +1dB in Signal to Distortion Ratio (SDR)\nand +1.5dB in Signal to Interference Ratio (SIR).",
    "descriptor": "",
    "authors": [
      "Midia Yousefi",
      "John H.L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.08635"
  },
  {
    "id": "arXiv:2111.08646",
    "title": "Evaluation problems for the Thompson group and the Brin-Thompson group,  and their relation to the word problem",
    "abstract": "The Thompson group $V$, as well as the Brin-Thompson group $2V$, is finitely\ngenerated and can be defined as a monoid acting on bitstrings, respectively\npairs of bitstrings. Therefore evaluation problems can be defined for $V$ and\n$2V$. We show that these evaluation problems reduce to the corresponding word\nproblems, and that in general, these evaluation problems are actually\nequivalent to the word problems. The long-input version of the evaluation\nproblem is deterministic context-free and reverse deterministic context-free\nfor $V,$ and P-complete for $2V$.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "J.C. Birget"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.08646"
  },
  {
    "id": "arXiv:2111.08664",
    "title": "An Empirical Evaluation of the Impact of New York's Bail Reform on Crime  Using Synthetic Controls",
    "abstract": "We conduct an empirical evaluation of the impact of New York's bail reform on\ncrime. New York State's Bail Elimination Act went into effect on January 1,\n2020, eliminating money bail and pretrial detention for nearly all misdemeanor\nand nonviolent felony defendants. Our analysis of effects on aggregate crime\nrates after the reform informs the understanding of bail reform and general\ndeterrence. We conduct a synthetic control analysis for a comparative case\nstudy of impact of bail reform. We focus on synthetic control analysis of\npost-intervention changes in crime for assault, theft, burglary, robbery, and\ndrug crimes, constructing a dataset from publicly reported crime data of 27\nlarge municipalities. Our findings, including placebo checks and other\nrobustness checks, show that for assault, theft, and drug crimes, there is no\nsignificant impact of bail reform on crime; for burglary and robbery, we\nsimilarly have null findings but the synthetic control is also more variable so\nthese are deemed less conclusive.",
    "descriptor": "",
    "authors": [
      "Angela Zhou",
      "Andrew Koo",
      "Nathan Kallus",
      "Rene Ropac",
      "Richard Peterson",
      "Stephen Koppel",
      "Tiffany Bergin"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2111.08664"
  },
  {
    "id": "arXiv:2111.08674",
    "title": "Multiclass Optimal Classification Trees with SVM-splits",
    "abstract": "In this paper we present a novel mathematical optimization-based methodology\nto construct tree-shaped classification rules for multiclass instances. Our\napproach consists of building Classification Trees in which, except for the\nleaf nodes, the labels are temporarily left out and grouped into two classes by\nmeans of a SVM separating hyperplane. We provide a Mixed Integer Non Linear\nProgramming formulation for the problem and report the results of an extended\nbattery of computational experiments to assess the performance of our proposal\nwith respect to other benchmarking classification methods.",
    "descriptor": "\nComments: 26 pages, 8 Figures, 3 tables\n",
    "authors": [
      "V\u00edctor Blanco",
      "Alberto Jap\u00f3n",
      "Justo Puerto"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08674"
  },
  {
    "id": "arXiv:2111.08678",
    "title": "Unsupervised Speech Enhancement with speech recognition embedding and  disentanglement losses",
    "abstract": "Speech enhancement has recently achieved great success with various deep\nlearning methods. However, most conventional speech enhancement systems are\ntrained with supervised methods that impose two significant challenges. First,\na majority of training datasets for speech enhancement systems are synthetic.\nWhen mixing clean speech and noisy corpora to create the synthetic datasets,\ndomain mismatches occur between synthetic and real-world recordings of noisy\nspeech or audio. Second, there is a trade-off between increasing speech\nenhancement performance and degrading speech recognition (ASR) performance.\nThus, we propose an unsupervised loss function to tackle those two problems.\nOur function is developed by extending the MixIT loss function with speech\nrecognition embedding and disentanglement loss. Our results show that the\nproposed function effectively improves the speech enhancement performance\ncompared to a baseline trained in a supervised way on the noisy VoxCeleb\ndataset. While fully unsupervised training is unable to exceed the\ncorresponding baseline, with joint super- and unsupervised training, the system\nis able to achieve similar speech quality and better ASR performance than the\nbest supervised baseline.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Viet Anh Trinh",
      "Sebastian Braun"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.08678"
  },
  {
    "id": "arXiv:2111.08683",
    "title": "Inferring halo masses with Graph Neural Networks",
    "abstract": "Understanding the halo-galaxy connection is fundamental in order to improve\nour knowledge on the nature and properties of dark matter. In this work we\nbuild a model that infers the mass of a halo given the positions, velocities,\nstellar masses, and radii of the galaxies it hosts. In order to capture\ninformation from correlations among galaxy properties and their phase-space, we\nuse Graph Neural Networks (GNNs), that are designed to work with irregular and\nsparse data. We train our models on galaxies from more than 2,000\nstate-of-the-art simulations from the Cosmology and Astrophysics with MachinE\nLearning Simulations (CAMELS) project. Our model, that accounts for\ncosmological and astrophysical uncertainties, is able to constrain the masses\nof the halos with a $\\sim$0.2 dex accuracy. Furthermore, a GNN trained on a\nsuite of simulations is able to preserve part of its accuracy when tested on\nsimulations run with a different code that utilizes a distinct subgrid physics\nmodel, showing the robustness of our method. The PyTorch Geometric\nimplementation of the GNN is publicly available on Github at\nhttps://github.com/PabloVD/HaloGraphNet",
    "descriptor": "\nComments: 18 pages, 8 figures, code publicly available at this https URL\n",
    "authors": [
      "Pablo Villanueva-Domingo",
      "Francisco Villaescusa-Navarro",
      "Daniel Angl\u00e9s-Alc\u00e1zar",
      "Shy Genel",
      "Federico Marinacci",
      "David N. Spergel",
      "Lars Hernquist",
      "Mark Vogelsberger",
      "Romeel Dave",
      "Desika Narayanan"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08683"
  },
  {
    "id": "arXiv:2111.08685",
    "title": "A Latent Encoder Coupled Generative Adversarial Network (LE-GAN) for  Efficient Hyperspectral Image Super-resolution",
    "abstract": "Realistic hyperspectral image (HSI) super-resolution (SR) techniques aim to\ngenerate a high-resolution (HR) HSI with higher spectral and spatial fidelity\nfrom its low-resolution (LR) counterpart. The generative adversarial network\n(GAN) has proven to be an effective deep learning framework for image\nsuper-resolution. However, the optimisation process of existing GAN-based\nmodels frequently suffers from the problem of mode collapse, leading to the\nlimited capacity of spectral-spatial invariant reconstruction. This may cause\nthe spectral-spatial distortion on the generated HSI, especially with a large\nupscaling factor. To alleviate the problem of mode collapse, this work has\nproposed a novel GAN model coupled with a latent encoder (LE-GAN), which can\nmap the generated spectral-spatial features from the image space to the latent\nspace and produce a coupling component to regularise the generated samples.\nEssentially, we treat an HSI as a high-dimensional manifold embedded in a\nlatent space. Thus, the optimisation of GAN models is converted to the problem\nof learning the distributions of high-resolution HSI samples in the latent\nspace, making the distributions of the generated super-resolution HSIs closer\nto those of their original high-resolution counterparts. We have conducted\nexperimental evaluations on the model performance of super-resolution and its\ncapability in alleviating mode collapse. The proposed approach has been tested\nand validated based on two real HSI datasets with different sensors (i.e.\nAVIRIS and UHD-185) for various upscaling factors and added noise levels, and\ncompared with the state-of-the-art super-resolution models (i.e. HyCoNet, LTTR,\nBAGAN, SR- GAN, WGAN).",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "Yue Shi",
      "Liangxiu Han",
      "Lianghao Han",
      "Sheng Chang",
      "Tongle Hu",
      "Darren Dancey"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08685"
  },
  {
    "id": "arXiv:2111.08693",
    "title": "Inverting brain grey matter models with likelihood-free inference: a  tool for trustable cytoarchitecture measurements",
    "abstract": "Effective characterisation of the brain grey matter cytoarchitecture with\nquantitative sensitivity to soma density and volume remains an unsolved\nchallenge in diffusion MRI (dMRI). Solving the problem of relating the dMRI\nsignal with cytoarchitectural characteristics calls for the definition of a\nmathematical model that describes brain tissue via a handful of\nphysiologically-relevant parameters and an algorithm for inverting the model.\nTo address this issue, we propose a new forward model, specifically a new\nsystem of equations, requiring a few relatively sparse b-shells. We then apply\nmodern tools from Bayesian analysis known as likelihood-free inference (LFI) to\ninvert our proposed model. As opposed to other approaches from the literature,\nour algorithm yields not only an estimation of the parameter vector $\\theta$\nthat best describes a given observed data point $x_0$, but also a full\nposterior distribution $p(\\theta|x_0)$ over the parameter space. This enables a\nricher description of the model inversion, providing indicators such as\ncredible intervals for the estimated parameters and a complete characterization\nof the parameter regions where the model may present indeterminacies. We\napproximate the posterior distribution using deep neural density estimators,\nknown as normalizing flows, and fit them using a set of repeated simulations\nfrom the forward model. We validate our approach on simulations using dmipy and\nthen apply the whole pipeline on two publicly available datasets.",
    "descriptor": "",
    "authors": [
      "Ma\u00ebliss Jallais",
      "Pedro Rodrigues",
      "Alexandre Gramfort",
      "Demian Wassermann"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08693"
  },
  {
    "id": "arXiv:1605.07725",
    "title": "Adversarial Training Methods for Semi-Supervised Text Classification",
    "abstract": "Comments: Published as a conference paper at ICLR 2017",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2017\n",
    "authors": [
      "Takeru Miyato",
      "Andrew M. Dai",
      "Ian Goodfellow"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1605.07725"
  },
  {
    "id": "arXiv:1704.08680",
    "title": "Dual Growth with Variable Rates: An Improved Integrality Gap for Steiner  Tree",
    "abstract": "Dual Growth with Variable Rates: An Improved Integrality Gap for Steiner  Tree",
    "descriptor": "",
    "authors": [
      "Ali \u00c7ivril"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1704.08680"
  },
  {
    "id": "arXiv:1709.05506",
    "title": "A statistical interpretation of spectral embedding: the generalised  random dot product graph",
    "abstract": "Comments: 34 pages; 12 figures",
    "descriptor": "\nComments: 34 pages; 12 figures\n",
    "authors": [
      "Patrick Rubin-Delanchy",
      "Joshua Cape",
      "Minh Tang",
      "Carey E. Priebe"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1709.05506"
  },
  {
    "id": "arXiv:1808.04218",
    "title": "Android HIV: A Study of Repackaging Malware for Evading Machine-Learning  Detection",
    "abstract": "Comments: 14 pages, 11 figures",
    "descriptor": "\nComments: 14 pages, 11 figures\n",
    "authors": [
      "Xiao Chen",
      "Chaoran Li",
      "Derui Wang",
      "Sheng Wen",
      "Jun Zhang",
      "Surya Nepal",
      "Yang Xiang",
      "Kui Ren"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1808.04218"
  },
  {
    "id": "arXiv:1809.03461",
    "title": "Physics-Information-Aided Kriging: Constructing Covariance Functions  using Stochastic Simulation Models",
    "abstract": "Comments: Updated Figure 2(b),(c), Figure 3(c), Figure 4 and Figure 5",
    "descriptor": "\nComments: Updated Figure 2(b),(c), Figure 3(c), Figure 4 and Figure 5\n",
    "authors": [
      "Xiu Yang",
      "Guzel Tartakovsky",
      "Alexandre Tartakovsky"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1809.03461"
  },
  {
    "id": "arXiv:1809.09582",
    "title": "Contextual Bandits with Cross-learning",
    "abstract": "Comments: 58 pages, 4 figures",
    "descriptor": "\nComments: 58 pages, 4 figures\n",
    "authors": [
      "Santiago Balseiro",
      "Negin Golrezaei",
      "Mohammad Mahdian",
      "Vahab Mirrokni",
      "Jon Schneider"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1809.09582"
  },
  {
    "id": "arXiv:1811.02309",
    "title": "An Enhanced Multi-Objective Biogeography-Based Optimization for  Overlapping Community Detection in Social Networks with Node Attributes",
    "abstract": "Comments: 1. The title has been revised. 2. First Author's affiliation has been changed. 3. References have been updated. 4. Some typos have been corrected",
    "descriptor": "\nComments: 1. The title has been revised. 2. First Author's affiliation has been changed. 3. References have been updated. 4. Some typos have been corrected\n",
    "authors": [
      "Ali Reihanian",
      "Mohammad-Reza Feizi-Derakhshi",
      "Hadi S. Aghdasi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1811.02309"
  },
  {
    "id": "arXiv:1811.12369",
    "title": "Small Hazard-free Transducers",
    "abstract": "Comments: This work has been accepted for publication at the 13th Innovations in Theoretical Computer Science Conference (ITCS 2022)",
    "descriptor": "\nComments: This work has been accepted for publication at the 13th Innovations in Theoretical Computer Science Conference (ITCS 2022)\n",
    "authors": [
      "Johannes Bund",
      "Christoph Lenzen",
      "Moti Medina"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/1811.12369"
  },
  {
    "id": "arXiv:1902.00194",
    "title": "Sharp Analysis of Expectation-Maximization for Weakly Identifiable  Models",
    "abstract": "Comments: 30 pages, 4 figures. The first three authors contributed equally to this work. To appear in AISTATS 2020",
    "descriptor": "\nComments: 30 pages, 4 figures. The first three authors contributed equally to this work. To appear in AISTATS 2020\n",
    "authors": [
      "Raaz Dwivedi",
      "Nhat Ho",
      "Koulik Khamaru",
      "Martin J. Wainwright",
      "Michael I. Jordan",
      "Bin Yu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1902.00194"
  },
  {
    "id": "arXiv:1905.10651",
    "title": "Asymptotic Distributions and Rates of Convergence for Random Forests via  Generalized U-statistics",
    "abstract": "Comments: 76 pages, 7 figure",
    "descriptor": "\nComments: 76 pages, 7 figure\n",
    "authors": [
      "Wei Peng",
      "Tim Coleman",
      "Lucas Mentch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/1905.10651"
  },
  {
    "id": "arXiv:2002.12398",
    "title": "TSS: Transformation-Specific Smoothing for Robustness Certification",
    "abstract": "Comments: 2021 ACM SIGSAC Conference on Computer and Communications Security (CCS '21)",
    "descriptor": "\nComments: 2021 ACM SIGSAC Conference on Computer and Communications Security (CCS '21)\n",
    "authors": [
      "Linyi Li",
      "Maurice Weber",
      "Xiaojun Xu",
      "Luka Rimanic",
      "Bhavya Kailkhura",
      "Tao Xie",
      "Ce Zhang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.12398"
  },
  {
    "id": "arXiv:2003.10402",
    "title": "DevSecOps in Robotics",
    "abstract": "DevSecOps in Robotics",
    "descriptor": "",
    "authors": [
      "V\u00edctor Mayoral-Vilches",
      "Nuria Garc\u00eda-Maestro",
      "McKenna Towers",
      "Endika Gil-Uriarte"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2003.10402"
  },
  {
    "id": "arXiv:2004.08730",
    "title": "Predicting MMSE Score from Finger-Tapping Measurement",
    "abstract": "Comments: 11 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 11 pages, 4 figures, 2 tables\n",
    "authors": [
      "Jian Ma"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2004.08730"
  },
  {
    "id": "arXiv:2006.07897",
    "title": "Entropic gradient descent algorithms and wide flat minima",
    "abstract": "Comments: ICLR 2021 camera-ready",
    "descriptor": "\nComments: ICLR 2021 camera-ready\n",
    "authors": [
      "Fabrizio Pittorino",
      "Carlo Lucibello",
      "Christoph Feinauer",
      "Gabriele Perugini",
      "Carlo Baldassi",
      "Elizaveta Demyanenko",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07897"
  },
  {
    "id": "arXiv:2006.16142",
    "title": "$k$FW: A Frank-Wolfe style algorithm with stronger subproblem oracles",
    "abstract": "Comments: 20 pages main text, 10 figures",
    "descriptor": "\nComments: 20 pages main text, 10 figures\n",
    "authors": [
      "Lijun Ding",
      "Jicong Fan",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.16142"
  },
  {
    "id": "arXiv:2007.01033",
    "title": "Characteristic Logics for Behavioural Hemimetrics via Fuzzy Lax  Extensions",
    "abstract": "Characteristic Logics for Behavioural Hemimetrics via Fuzzy Lax  Extensions",
    "descriptor": "",
    "authors": [
      "Paul Wild",
      "Lutz Schr\u00f6der"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2007.01033"
  },
  {
    "id": "arXiv:2007.07449",
    "title": "Downsampling for Testing and Learning in Product Distributions",
    "abstract": "Comments: 48 pages, 1 figure. Updated to include some new results; in particular the monotonicity tester now has 1-sided error",
    "descriptor": "\nComments: 48 pages, 1 figure. Updated to include some new results; in particular the monotonicity tester now has 1-sided error\n",
    "authors": [
      "Nathaniel Harms",
      "Yuichi Yoshida"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.07449"
  },
  {
    "id": "arXiv:2007.13695",
    "title": "Adaptive Height Optimisation for Cellular-Connected UAVs using  Reinforcement Learning",
    "abstract": "Adaptive Height Optimisation for Cellular-Connected UAVs using  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Erika Fonseca",
      "Boris Galkin",
      "Ramy Amer",
      "Luiz A. DaSilva",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.13695"
  },
  {
    "id": "arXiv:2008.00113",
    "title": "Multi-officer Routing for Patrolling High Risk Areas Jointly Learned  from Check-ins, Crime and Incident Response Data",
    "abstract": "Comments: 10 pages, 7 figures; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 10 pages, 7 figures; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Shakila Khan Rumi",
      "Kyle K. Qin",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2008.00113"
  },
  {
    "id": "arXiv:2008.01704",
    "title": "Verifying Pufferfish Privacy in Hidden Markov Models",
    "abstract": "Comments: To be published in the proceedings of VMCAI 2022",
    "descriptor": "\nComments: To be published in the proceedings of VMCAI 2022\n",
    "authors": [
      "Depeng Liu",
      "Bow-yaw Wang",
      "Lijun Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2008.01704"
  },
  {
    "id": "arXiv:2008.13777",
    "title": "Low-rank matrix recovery with non-quadratic loss: projected gradient  method and regularity projection oracle",
    "abstract": "Comments: 30 pages and 3 figures",
    "descriptor": "\nComments: 30 pages and 3 figures\n",
    "authors": [
      "Lijun Ding",
      "Yuqian Zhang",
      "Yudong Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2008.13777"
  },
  {
    "id": "arXiv:2009.06472",
    "title": "Estimating Individual Treatment Effects using Non-Parametric Regression  Models: a Review",
    "abstract": "Comments: 24 pages, 7 figures",
    "descriptor": "\nComments: 24 pages, 7 figures\n",
    "authors": [
      "Alberto Caron",
      "Gianluca Baio",
      "Ioanna Manolopoulou"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.06472"
  },
  {
    "id": "arXiv:2009.07096",
    "title": "Analysis of finite-volume discrete adjoint fields for two-dimensional  compressible Euler flows",
    "abstract": "Analysis of finite-volume discrete adjoint fields for two-dimensional  compressible Euler flows",
    "descriptor": "",
    "authors": [
      "Jacques Peter",
      "Florent Renac",
      "Cl\u00e9ment Labb\u00e9"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2009.07096"
  },
  {
    "id": "arXiv:2009.10931",
    "title": "Drug Repurposing for COVID-19 using Graph Neural Network with Genetic,  Mechanistic, and Epidemiological Validation",
    "abstract": "Drug Repurposing for COVID-19 using Graph Neural Network with Genetic,  Mechanistic, and Epidemiological Validation",
    "descriptor": "",
    "authors": [
      "Kanglin Hsieh",
      "Yinyin Wang",
      "Luyao Chen",
      "Zhongming Zhao",
      "Sean Savitz",
      "Xiaoqian Jiang",
      "Jing Tang",
      "Yejin Kim"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.10931"
  },
  {
    "id": "arXiv:2009.14388",
    "title": "Secure Aggregation with Heterogeneous Quantization in Federated Learning",
    "abstract": "Secure Aggregation with Heterogeneous Quantization in Federated Learning",
    "descriptor": "",
    "authors": [
      "Ahmed Roushdy Elkordy",
      "A. Salman Avestimehr"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.14388"
  },
  {
    "id": "arXiv:2010.01909",
    "title": "Deliberative Acting, Online Planning and Learning with Hierarchical  Operational Models",
    "abstract": "Comments: Published in Artificial Intelligence (AIJ). Please cite as: Sunandita Patra, James Mason, Malik Ghallab, Dana Nau, Paolo Traverso. Deliberative Acting, Planning and Learning with Hierarchical Operational Models. Artificial Intelligence, Elsevier, 2021, 299, pp.103523. 10.1016/j.artint.2021.103523. arXiv admin note: text overlap with arXiv:2003.03932",
    "descriptor": "\nComments: Published in Artificial Intelligence (AIJ). Please cite as: Sunandita Patra, James Mason, Malik Ghallab, Dana Nau, Paolo Traverso. Deliberative Acting, Planning and Learning with Hierarchical Operational Models. Artificial Intelligence, Elsevier, 2021, 299, pp.103523. 10.1016/j.artint.2021.103523. arXiv admin note: text overlap with arXiv:2003.03932\n",
    "authors": [
      "Sunandita Patra",
      "James Mason",
      "Malik Ghallab",
      "Dana Nau",
      "Paolo Traverso"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.01909"
  },
  {
    "id": "arXiv:2010.09188",
    "title": "A Bayesian Approach for Characterizing and Mitigating Gate and  Measurement Errors",
    "abstract": "Comments: Updated the introduction and the description of methodology in the new version",
    "descriptor": "\nComments: Updated the introduction and the description of methodology in the new version\n",
    "authors": [
      "Muqing Zheng",
      "Ang Li",
      "Tam\u00e1s Terlaky",
      "Xiu Yang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2010.09188"
  },
  {
    "id": "arXiv:2011.00197",
    "title": "Mitigating Coherent Noise by Balancing Weight-2 $Z$-Stabilizers",
    "abstract": "Comments: Jingzhen Hu and Qingzhong Liang contributed equally to this work. The paper was accepted to IEEE Transactions on Information Theory. The ISIT paper is available as an ancillary file",
    "descriptor": "\nComments: Jingzhen Hu and Qingzhong Liang contributed equally to this work. The paper was accepted to IEEE Transactions on Information Theory. The ISIT paper is available as an ancillary file\n",
    "authors": [
      "Jingzhen Hu",
      "Qingzhong Liang",
      "Narayanan Rengaswamy",
      "Robert Calderbank"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2011.00197"
  },
  {
    "id": "arXiv:2011.08174",
    "title": "Policy design in experiments with unknown interference",
    "abstract": "Policy design in experiments with unknown interference",
    "descriptor": "",
    "authors": [
      "Davide Viviano"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2011.08174"
  },
  {
    "id": "arXiv:2011.08557",
    "title": "A Simple Method for Convex Optimization in the Oracle Model",
    "abstract": "Comments: Major revision",
    "descriptor": "\nComments: Major revision\n",
    "authors": [
      "Daniel Dadush",
      "Christopher Hojny",
      "Sophie Huiberts",
      "Stefan Weltge"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.08557"
  },
  {
    "id": "arXiv:2011.09052",
    "title": "Visual Time Series Forecasting: An Image-driven Approach",
    "abstract": "Comments: This work appeared in KDD-MiLeTS '21: 7th SIGKDD Workshop on Mining and Learning from Time Series. Previously, this version appeared as 2017.01273, which was submitted as a new work by accident",
    "descriptor": "\nComments: This work appeared in KDD-MiLeTS '21: 7th SIGKDD Workshop on Mining and Learning from Time Series. Previously, this version appeared as 2017.01273, which was submitted as a new work by accident\n",
    "authors": [
      "Naftali Cohen",
      "Srijan Sood",
      "Zhen Zeng",
      "Tucker Balch",
      "Manuela Veloso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2011.09052"
  },
  {
    "id": "arXiv:2011.11311",
    "title": "Uncovering the Bias in Facial Expressions",
    "abstract": "Comments: Accepted at the Kolloquium Forschende Frauen 2020 - published in \"Gender in Gesellschaft 4.0: Beitr\\\"age Bamberger Nachwuchswissenschaftlerinnen(2021)\"",
    "descriptor": "\nComments: Accepted at the Kolloquium Forschende Frauen 2020 - published in \"Gender in Gesellschaft 4.0: Beitr\\\"age Bamberger Nachwuchswissenschaftlerinnen(2021)\"\n",
    "authors": [
      "Jessica Deuschel",
      "Bettina Finzel",
      "Ines Rieger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.11311"
  },
  {
    "id": "arXiv:2011.13147",
    "title": "Generalized Mutual Information-Maximizing Quantized Decoding of LDPC  Codes with Layered Scheduling",
    "abstract": "Comments: 13 pages main body, 8 figures, journal manuscript",
    "descriptor": "\nComments: 13 pages main body, 8 figures, journal manuscript\n",
    "authors": [
      "Peng Kang",
      "Kui Cai",
      "Xuan He",
      "Shuangyang Li",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2011.13147"
  },
  {
    "id": "arXiv:2012.04705",
    "title": "Structured Index Coding Problem and Multi-access Coded Caching",
    "abstract": "Comments: 44 pages, single column, ITW and JSAIT",
    "descriptor": "\nComments: 44 pages, single column, ITW and JSAIT\n",
    "authors": [
      "Kota Srinivas Reddy",
      "Nikhil Karamchandani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2012.04705"
  },
  {
    "id": "arXiv:2012.06157",
    "title": "Fairness in Rating Prediction by Awareness of Verbal and Gesture Quality  of Public Speeches",
    "abstract": "Fairness in Rating Prediction by Awareness of Verbal and Gesture Quality  of Public Speeches",
    "descriptor": "",
    "authors": [
      "Ankani Chattoraj",
      "Rupam Acharyya",
      "Shouman Das",
      "Md. Iftekhar Tanveer",
      "Ehsan Hoque"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.06157"
  },
  {
    "id": "arXiv:2012.08892",
    "title": "E$ \\mathbf{^3} $MoP: Efficient Motion Planning Based on Heuristic-Guided  Motion Primitives Pruning and Path Optimization With Sparse-Banded Structure",
    "abstract": "Comments: This paper has been accepted for publication in the IEEE Transactions on Automation Science and Engineering",
    "descriptor": "\nComments: This paper has been accepted for publication in the IEEE Transactions on Automation Science and Engineering\n",
    "authors": [
      "Jian Wen",
      "Xuebo Zhang",
      "Haiming Gao",
      "Jing Yuan",
      "Yongchun Fang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.08892"
  },
  {
    "id": "arXiv:2012.09742",
    "title": "AutoCaption: Image Captioning with Neural Architecture Search",
    "abstract": "AutoCaption: Image Captioning with Neural Architecture Search",
    "descriptor": "",
    "authors": [
      "Xinxin Zhu",
      "Weining Wang",
      "Longteng Guo",
      "Jing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.09742"
  },
  {
    "id": "arXiv:2012.12070",
    "title": "Criteria for integer and modulo 2 embeddability of graphs to surfaces",
    "abstract": "Criteria for integer and modulo 2 embeddability of graphs to surfaces",
    "descriptor": "",
    "authors": [
      "Arthur Bikeev"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2012.12070"
  },
  {
    "id": "arXiv:2012.13442",
    "title": "Multi-channel Multi-frame ADL-MVDR for Target Speech Separation",
    "abstract": "Comments: Accepted by IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP); Demos available at this https URL",
    "descriptor": "\nComments: Accepted by IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP); Demos available at this https URL\n",
    "authors": [
      "Zhuohuang Zhang",
      "Yong Xu",
      "Meng Yu",
      "Shi-Xiong Zhang",
      "Lianwu Chen",
      "Donald S. Williamson",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2012.13442"
  },
  {
    "id": "arXiv:2101.02615",
    "title": "Benchmarking Buffer Size in IoT Devices Deploying REST HTTP",
    "abstract": "Comments: This paper is uploaded here for research community, thus it is for non-commercial purposes",
    "descriptor": "\nComments: This paper is uploaded here for research community, thus it is for non-commercial purposes\n",
    "authors": [
      "Cao Vien Phung",
      "Mounir Bensalem",
      "Admela Jukan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2101.02615"
  },
  {
    "id": "arXiv:2101.08681",
    "title": "Streaming from the Air: Enabling Drone-sourced Video Streaming  Applications on 5G Open-RAN Architectures",
    "abstract": "Streaming from the Air: Enabling Drone-sourced Video Streaming  Applications on 5G Open-RAN Architectures",
    "descriptor": "",
    "authors": [
      "Lorenzo Bertizzolo",
      "Tuyen X. Tran",
      "John Buczek",
      "Bharath Balasubramanian",
      "Rittwik Jana",
      "Yu Zhou",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2101.08681"
  },
  {
    "id": "arXiv:2101.11952",
    "title": "Rethinking Rotated Object Detection with Gaussian Wasserstein Distance  Loss",
    "abstract": "Comments: 15 pages, 6 figures, 9 tables, accepted by ICML21, codes are available at this https URL",
    "descriptor": "\nComments: 15 pages, 6 figures, 9 tables, accepted by ICML21, codes are available at this https URL\n",
    "authors": [
      "Xue Yang",
      "Junchi Yan",
      "Qi Ming",
      "Wentao Wang",
      "Xiaopeng Zhang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.11952"
  },
  {
    "id": "arXiv:2102.01034",
    "title": "On the dichromatic number of surfaces",
    "abstract": "Comments: 26 pages, 5 figures, improved asymptotic bounds",
    "descriptor": "\nComments: 26 pages, 5 figures, improved asymptotic bounds\n",
    "authors": [
      "Pierre Aboulker",
      "Fr\u00e9d\u00e9ric Havet",
      "Kolja Knauer",
      "Cl\u00e9ment Rambaud"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2102.01034"
  },
  {
    "id": "arXiv:2102.06573",
    "title": "Shrinkage Bayesian Causal Forests for Heterogeneous Treatment Effects  Estimation",
    "abstract": "Shrinkage Bayesian Causal Forests for Heterogeneous Treatment Effects  Estimation",
    "descriptor": "",
    "authors": [
      "Alberto Caron",
      "Gianluca Baio",
      "Ioanna Manolopoulou"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06573"
  },
  {
    "id": "arXiv:2102.09683",
    "title": "Detecting Communities in a Gossip Model with Stubborn Agents",
    "abstract": "Detecting Communities in a Gossip Model with Stubborn Agents",
    "descriptor": "",
    "authors": [
      "Yu Xing",
      "Xingkang He",
      "Haitao Fang",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.09683"
  },
  {
    "id": "arXiv:2102.10172",
    "title": "Channel Estimation and Data Detection Analysis of Massive MIMO with  1-Bit ADCs",
    "abstract": "Comments: IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Italo Atzeni",
      "Antti T\u00f6lli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2102.10172"
  },
  {
    "id": "arXiv:2102.13042",
    "title": "Loss Surface Simplexes for Mode Connecting Volumes and Fast Ensembling",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Gregory W. Benton",
      "Wesley J. Maddox",
      "Sanae Lotfi",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.13042"
  },
  {
    "id": "arXiv:2103.00845",
    "title": "A Brief Summary of Interactions Between Meta-Learning and  Self-Supervised Learning",
    "abstract": "A Brief Summary of Interactions Between Meta-Learning and  Self-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Huimin Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.00845"
  },
  {
    "id": "arXiv:2103.01640",
    "title": "Double Coverage with Machine-Learned Advice",
    "abstract": "Comments: Accepted at ITCS 2022",
    "descriptor": "\nComments: Accepted at ITCS 2022\n",
    "authors": [
      "Alexander Lindermayr",
      "Nicole Megow",
      "Bertrand Simon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2103.01640"
  },
  {
    "id": "arXiv:2103.01649",
    "title": "Learning with Hyperspherical Uniformity",
    "abstract": "Comments: AISTATS 2021 (v3: fixed typos)",
    "descriptor": "\nComments: AISTATS 2021 (v3: fixed typos)\n",
    "authors": [
      "Weiyang Liu",
      "Rongmei Lin",
      "Zhen Liu",
      "Li Xiong",
      "Bernhard Sch\u00f6lkopf",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.01649"
  },
  {
    "id": "arXiv:2103.02362",
    "title": "Video Sentiment Analysis with Bimodal Information-augmented Multi-Head  Attention",
    "abstract": "Comments: 12 pages, 4 figures, content and journal information updated",
    "descriptor": "\nComments: 12 pages, 4 figures, content and journal information updated\n",
    "authors": [
      "Ting Wu",
      "Junjie Peng",
      "Wenqiang Zhang",
      "Huiran Zhang",
      "Chuanshuai Ma",
      "Yansong Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.02362"
  },
  {
    "id": "arXiv:2103.13514",
    "title": "Constrained Deep Learning-based Model Predictive Control with Improved  Constraint Satisfaction",
    "abstract": "Comments: I found mistakes in the theoretical parts of the paper. May continue to work on it independently and fix it later",
    "descriptor": "\nComments: I found mistakes in the theoretical parts of the paper. May continue to work on it independently and fix it later\n",
    "authors": [
      "Farshid Asadi",
      "Jingang Yi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.13514"
  },
  {
    "id": "arXiv:2103.14144",
    "title": "Dynamic Posted-Price Mechanisms for the Blockchain Transaction Fee  Market",
    "abstract": "Dynamic Posted-Price Mechanisms for the Blockchain Transaction Fee  Market",
    "descriptor": "",
    "authors": [
      "Matheus V. X. Ferreira",
      "Daniel J. Moroz",
      "David C. Parkes",
      "Mitchell Stern"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)",
      "Theoretical Economics (econ.TH)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.14144"
  },
  {
    "id": "arXiv:2103.14400",
    "title": "Data-driven sparse skin stimulation can convey social touch information  to humans",
    "abstract": "Comments: Awaiting publication for IEEE Transactions on Haptics",
    "descriptor": "\nComments: Awaiting publication for IEEE Transactions on Haptics\n",
    "authors": [
      "M. Salvato",
      "Sophia R. Williams",
      "Cara M. Nunez",
      "Xin Zhu",
      "Ali Israr",
      "Frances Lau",
      "Keith Klumb",
      "Freddy Abnousi",
      "Allison M. Okamura",
      "Heather Culbertson"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2103.14400"
  },
  {
    "id": "arXiv:2104.00460",
    "title": "Augmenting Zero Trust Architecture to Endpoints Using Blockchain: A  State-of-The-Art Review",
    "abstract": "Comments: (1) Fixed the reference numbering (2) Fixed syntax errors, improvements (3) document re-structured",
    "descriptor": "\nComments: (1) Fixed the reference numbering (2) Fixed syntax errors, improvements (3) document re-structured\n",
    "authors": [
      "Lampis Alevizos",
      "Vinh Thong Ta",
      "Max Hashem Eiza"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.00460"
  },
  {
    "id": "arXiv:2104.02336",
    "title": "SimMBM Channel Simulator for Media-Based Modulation Systems",
    "abstract": "Comments: accepted in IEEE 32nd Int. Symp. Personal, Indoor and Mobile Radio Commun. (PIMRC 2021)",
    "descriptor": "\nComments: accepted in IEEE 32nd Int. Symp. Personal, Indoor and Mobile Radio Commun. (PIMRC 2021)\n",
    "authors": [
      "Zehra Yigit",
      "Ertugrul Basar",
      "Ibrahim Altunbas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.02336"
  },
  {
    "id": "arXiv:2104.06188",
    "title": "Sectors, Beams and Environmental Impact on the Performance of Commercial  5G mmWave Cells: an Empirical Study",
    "abstract": "Comments: 9 pages, 10 figures, 4 tables",
    "descriptor": "\nComments: 9 pages, 10 figures, 4 tables\n",
    "authors": [
      "Salman Mohebi",
      "Foivos Michelinakis",
      "Ahmed Elmokashfi",
      "Ole Gr\u00f8ndalen",
      "Kashif Mahmood",
      "Andrea Zanella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.06188"
  },
  {
    "id": "arXiv:2104.06706",
    "title": "Towards Off-the-grid Algorithms for Total Variation Regularized Inverse  Problems",
    "abstract": "Comments: For the short conference version see arXiv:2104.06706v2. For the long journal version see arXiv:2104.06706v3",
    "descriptor": "\nComments: For the short conference version see arXiv:2104.06706v2. For the long journal version see arXiv:2104.06706v3\n",
    "authors": [
      "Yohann de Castro",
      "Vincent Duval",
      "Romain Petit"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.06706"
  },
  {
    "id": "arXiv:2104.08122",
    "title": "Benchmarking Machine Learning Techniques for THz Channel Estimation  Problems",
    "abstract": "Comments: This paper is uploaded here for research community, thus it is for non-commercial purposes",
    "descriptor": "\nComments: This paper is uploaded here for research community, thus it is for non-commercial purposes\n",
    "authors": [
      "Mounir Bensalem",
      "Admela Jukan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.08122"
  },
  {
    "id": "arXiv:2104.12050",
    "title": "Attention on Global-Local Representation Spaces in Recommender Systems",
    "abstract": "Comments: This paper was accepted by IEEE Transactions on Computational Social Systems (TCSS) in November 2021",
    "descriptor": "\nComments: This paper was accepted by IEEE Transactions on Computational Social Systems (TCSS) in November 2021\n",
    "authors": [
      "Munlika Rattaphun",
      "Wen-Chieh Fang",
      "Chih-Yi Chiu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2104.12050"
  },
  {
    "id": "arXiv:2104.12146",
    "title": "3D Adversarial Attacks Beyond Point Cloud",
    "abstract": "Comments: 8 pages, 6 figs",
    "descriptor": "\nComments: 8 pages, 6 figs\n",
    "authors": [
      "Jinlai Zhang",
      "Lyujie Chen",
      "Binbin Liu",
      "Bo Ouyang",
      "Qizhi Xie",
      "Jihong Zhu",
      "Weiming Li",
      "Yanmei Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.12146"
  },
  {
    "id": "arXiv:2104.13281",
    "title": "Complete Deterministic Dynamics and Spectral Decomposition of the  Ensemble Kalman Inversion",
    "abstract": "Comments: Added covariance correction terms to averaged stochastic EKI equations",
    "descriptor": "\nComments: Added covariance correction terms to averaged stochastic EKI equations\n",
    "authors": [
      "Leon Bungert",
      "Philipp Wacker"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2104.13281"
  },
  {
    "id": "arXiv:2104.13421",
    "title": "Canonical automata via distributive law homomorphisms",
    "abstract": "Canonical automata via distributive law homomorphisms",
    "descriptor": "",
    "authors": [
      "Stefan Zetzsche",
      "Gerco van Heerdt",
      "Alexandra Silva",
      "Matteo Sammartino"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2104.13421"
  },
  {
    "id": "arXiv:2105.03641",
    "title": "Diversifying Neural Text Generation with Part-of-Speech Guided Softmax  and Sampling",
    "abstract": "Diversifying Neural Text Generation with Part-of-Speech Guided Softmax  and Sampling",
    "descriptor": "",
    "authors": [
      "Zhixian Yang",
      "Pengxuan Xu",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03641"
  },
  {
    "id": "arXiv:2105.05622",
    "title": "On risk-based active learning for structural health monitoring",
    "abstract": "Comments: 30 pages. 23 figures. Published in Mechanical Systems and Signal Processing",
    "descriptor": "\nComments: 30 pages. 23 figures. Published in Mechanical Systems and Signal Processing\n",
    "authors": [
      "A.J. Hughes",
      "L.A. Bull",
      "P. Gardner",
      "R.J. Barthorpe",
      "N. Dervilis",
      "K. Worden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.05622"
  },
  {
    "id": "arXiv:2105.05720",
    "title": "Breaking the Computation and Communication Abstraction Barrier in  Distributed Machine Learning Workloads",
    "abstract": "Breaking the Computation and Communication Abstraction Barrier in  Distributed Machine Learning Workloads",
    "descriptor": "",
    "authors": [
      "Abhinav Jangda",
      "Jun Huang",
      "Guodong Liu",
      "Amir Hossein Nodehi Sabet",
      "Saeed Maleki",
      "Youshan Miao",
      "Madanlal Musuvathi",
      "Todd Mytkowicz",
      "Olli Sarikivi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.05720"
  },
  {
    "id": "arXiv:2105.12787",
    "title": "Self-Supervised Bug Detection and Repair",
    "abstract": "Comments: Published in NeurIPS 2021",
    "descriptor": "\nComments: Published in NeurIPS 2021\n",
    "authors": [
      "Miltiadis Allamanis",
      "Henry Jackson-Flux",
      "Marc Brockschmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.12787"
  },
  {
    "id": "arXiv:2105.15005",
    "title": "Rapid mixing of Glauber dynamics via spectral independence for all  degrees",
    "abstract": "Rapid mixing of Glauber dynamics via spectral independence for all  degrees",
    "descriptor": "",
    "authors": [
      "Xiaoyu Chen",
      "Weiming Feng",
      "Yitong Yin",
      "Xinyuan Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.15005"
  },
  {
    "id": "arXiv:2106.01883",
    "title": "Learning High-Precision Bounding Box for Rotated Object Detection via  Kullback-Leibler Divergence",
    "abstract": "Comments: 16 pages, 5 figures, 8 tables, accepted by NeurIPS21, codes are available at this https URL",
    "descriptor": "\nComments: 16 pages, 5 figures, 8 tables, accepted by NeurIPS21, codes are available at this https URL\n",
    "authors": [
      "Xue Yang",
      "Xiaojiang Yang",
      "Jirui Yang",
      "Qi Ming",
      "Wentao Wang",
      "Qi Tian",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01883"
  },
  {
    "id": "arXiv:2106.02394",
    "title": "On the Strategyproofness of the Geometric Median",
    "abstract": "Comments: 55 pages, 7 figures",
    "descriptor": "\nComments: 55 pages, 7 figures\n",
    "authors": [
      "El-Mahdi El-Mhamdi",
      "Sadegh Farhadkhani",
      "Rachid Guerraoui",
      "L\u00ea-Nguy\u00ean Hoang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.02394"
  },
  {
    "id": "arXiv:2106.02839",
    "title": "Upward planar drawings with two slopes",
    "abstract": "Upward planar drawings with two slopes",
    "descriptor": "",
    "authors": [
      "Jonathan Klawitter",
      "Tamara Mchedlidze"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.02839"
  },
  {
    "id": "arXiv:2106.03845",
    "title": "A Matrix Trickle-Down Theorem on Simplicial Complexes and Applications  to Sampling Colorings",
    "abstract": "A Matrix Trickle-Down Theorem on Simplicial Complexes and Applications  to Sampling Colorings",
    "descriptor": "",
    "authors": [
      "Dorna Abdolazimi",
      "Kuikui Liu",
      "Shayan Oveis Gharan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.03845"
  },
  {
    "id": "arXiv:2106.05121",
    "title": "Grounding inductive biases in natural images:invariance stems from  variations in data",
    "abstract": "Grounding inductive biases in natural images:invariance stems from  variations in data",
    "descriptor": "",
    "authors": [
      "Diane Bouchacourt",
      "Mark Ibrahim",
      "Ari S. Morcos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05121"
  },
  {
    "id": "arXiv:2106.12894",
    "title": "InFlow: Robust outlier detection utilizing Normalizing Flows",
    "abstract": "InFlow: Robust outlier detection utilizing Normalizing Flows",
    "descriptor": "",
    "authors": [
      "Nishant Kumar",
      "Pia Hanfeld",
      "Michael Hecht",
      "Michael Bussmann",
      "Stefan Gumhold",
      "Nico Hoffmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.12894"
  },
  {
    "id": "arXiv:2106.13398",
    "title": "Code-Verification Techniques for the Method-of-Moments Implementation of  the Electric-Field Integral Equation",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2012.08681",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2012.08681\n",
    "authors": [
      "Brian A. Freno",
      "Neil R. Matula",
      "Justin I. Owen",
      "William A. Johnson"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13398"
  },
  {
    "id": "arXiv:2106.13733",
    "title": "Graph and hypergraph colouring via nibble methods: A survey",
    "abstract": "Comments: Final version, to appear in the proceedings of the 8th European Congress of Mathematics; 33 pages, 3 figures",
    "descriptor": "\nComments: Final version, to appear in the proceedings of the 8th European Congress of Mathematics; 33 pages, 3 figures\n",
    "authors": [
      "Dong Yeap Kang",
      "Tom Kelly",
      "Daniela K\u00fchn",
      "Abhishek Methuku",
      "Deryk Osthus"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.13733"
  },
  {
    "id": "arXiv:2106.13940",
    "title": "Adaptive Smooth Disturbance Observer-Based Fast Finite-Time Adaptive  Backstepping Control for Attitude Tracking of a 3-DOF Helicopter",
    "abstract": "Comments: 6 pages,4 figures",
    "descriptor": "\nComments: 6 pages,4 figures\n",
    "authors": [
      "Xidong Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13940"
  },
  {
    "id": "arXiv:2107.01273",
    "title": "Visual Time Series Forecasting: An Image-driven Approach",
    "abstract": "Comments: This work was intended as a replacement of arXiv:2011.09052 and any subsequent updates will appear there",
    "descriptor": "\nComments: This work was intended as a replacement of arXiv:2011.09052 and any subsequent updates will appear there\n",
    "authors": [
      "Naftali Cohen",
      "Srijan Sood",
      "Zhen Zeng",
      "Tucker Balch",
      "Manuela Veloso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2107.01273"
  },
  {
    "id": "arXiv:2107.02823",
    "title": "Deep Learning for Micro-expression Recognition: A Survey",
    "abstract": "Comments: 20 pages, 8 figures",
    "descriptor": "\nComments: 20 pages, 8 figures\n",
    "authors": [
      "Yante Li",
      "Jinsheng Wei",
      "Yang Liu",
      "Janne Kauttonen",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.02823"
  },
  {
    "id": "arXiv:2107.03337",
    "title": "Samplets: A new paradigm for data compression",
    "abstract": "Samplets: A new paradigm for data compression",
    "descriptor": "",
    "authors": [
      "Helmut Harbrecht",
      "Michael Multerer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.03337"
  },
  {
    "id": "arXiv:2107.03466",
    "title": "A repeated-measures study on emotional responses after a year in the  pandemic",
    "abstract": "Comments: author version of accepted paper (Scientific Reports)",
    "descriptor": "\nComments: author version of accepted paper (Scientific Reports)\n",
    "authors": [
      "Maximilian Mozes",
      "Isabelle van der Vegt",
      "Bennett Kleinberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.03466"
  },
  {
    "id": "arXiv:2107.04457",
    "title": "Aligning an optical interferometer with beam divergence control and  continuous action space",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Stepan Makarenko",
      "Dmitry Sorokin",
      "Alexander Ulanov",
      "A. I. Lvovsky"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2107.04457"
  },
  {
    "id": "arXiv:2107.07263",
    "title": "Performance Analysis of MDPC and RS codes in Two-channel THz  Communication Systems",
    "abstract": "Comments: This paper is uploaded here for research community, thus it is for non-commercial purposes",
    "descriptor": "\nComments: This paper is uploaded here for research community, thus it is for non-commercial purposes\n",
    "authors": [
      "Cao Vien Phung",
      "Christoph Herold",
      "David Humphreys",
      "Thomas Kurner",
      "Admela Jukan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.07263"
  },
  {
    "id": "arXiv:2107.10332",
    "title": "Machine Learning Characterization of Cancer Patients-Derived  Extracellular Vesicles using Vibrational Spectroscopies",
    "abstract": "Comments: 41 pages",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Abicumaran Uthamacumaran",
      "Samir Elouatik",
      "Mohamed Abdouh",
      "Michael Berteau-Rainville",
      "Zu-hua Gao",
      "Goffredo Arena"
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.10332"
  },
  {
    "id": "arXiv:2107.14124",
    "title": "Calculating elements of matrix functions using divided differences",
    "abstract": "Comments: 14 pages, 7 figures, 2 tables",
    "descriptor": "\nComments: 14 pages, 7 figures, 2 tables\n",
    "authors": [
      "Lev Barash",
      "Stefan G\u00fcttel",
      "Itay Hen"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Other Condensed Matter (cond-mat.other)",
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.14124"
  },
  {
    "id": "arXiv:2108.01034",
    "title": "An Efficient Image-to-Image Translation HourGlass-based Architecture for  Object Pushing Policy Learning",
    "abstract": "Comments: 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
    "descriptor": "\nComments: 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Marco Ewerton",
      "Angel Mart\u00ednez-Gonz\u00e1lez",
      "Jean-Marc Odobez"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.01034"
  },
  {
    "id": "arXiv:2108.01341",
    "title": "Using Throughput-Centric Byzantine Broadcast to Tolerate Malicious  Majority in Blockchains",
    "abstract": "Using Throughput-Centric Byzantine Broadcast to Tolerate Malicious  Majority in Blockchains",
    "descriptor": "",
    "authors": [
      "Ruomu Hou",
      "Haifeng Yu",
      "Prateek Saxena"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.01341"
  },
  {
    "id": "arXiv:2108.01595",
    "title": "Extending a Physics-Based Constitutive Model using Genetic Programming",
    "abstract": "Comments: Preprint submitted to Applications in Engineering Sciences",
    "descriptor": "\nComments: Preprint submitted to Applications in Engineering Sciences\n",
    "authors": [
      "Gabriel Kronberger",
      "Evgeniya Kabliman",
      "Johannes Kronsteiner",
      "Michael Kommenda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2108.01595"
  },
  {
    "id": "arXiv:2108.03172",
    "title": "A General Regularized Distributed Solution for System State Estimation  from Relative Measurements",
    "abstract": "Comments: 6 pages, 1 figure. Index Terms: Sensor networks, Estimation, Network analysis and control",
    "descriptor": "\nComments: 6 pages, 1 figure. Index Terms: Sensor networks, Estimation, Network analysis and control\n",
    "authors": [
      "Marco Fabris",
      "Giulia Michieletto",
      "Angelo Cenedese"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.03172"
  },
  {
    "id": "arXiv:2108.03836",
    "title": "The mysteries of the best approximation and Chebyshev expansion for the  function with logarithmic regularities",
    "abstract": "Comments: 14pages",
    "descriptor": "\nComments: 14pages\n",
    "authors": [
      "Xiaolong Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.03836"
  },
  {
    "id": "arXiv:2108.07232",
    "title": "Better GPU Hash Tables",
    "abstract": "Comments: Our implementation is available at this https URL",
    "descriptor": "\nComments: Our implementation is available at this https URL\n",
    "authors": [
      "Muhammad A. Awad",
      "Saman Ashkiani",
      "Serban D. Porumbescu",
      "Mart\u00edn Farach-Colton",
      "John D. Owens"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.07232"
  },
  {
    "id": "arXiv:2108.09789",
    "title": "An Exploration of Factors Influencing the Adoption of ICT Enabled  Entrepreneurship Applications in Namibian Rural Communities",
    "abstract": "Comments: In proceedings of the 1st Virtual Conference on Implications of Information and Digital Technologies for Development, 2021",
    "descriptor": "\nComments: In proceedings of the 1st Virtual Conference on Implications of Information and Digital Technologies for Development, 2021\n",
    "authors": [
      "Elizabeth Ujarura Kamutuezu",
      "Heike Winschiers-Theophilus",
      "Anicia Peters"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2108.09789"
  },
  {
    "id": "arXiv:2108.10464",
    "title": "The Case for Task Sampling based Learning for Cluster Job Scheduling",
    "abstract": "The Case for Task Sampling based Learning for Cluster Job Scheduling",
    "descriptor": "",
    "authors": [
      "Akshay Jajoo",
      "Y. Charlie Hu",
      "Xiaojun Lin",
      "Nan Deng"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.10464"
  },
  {
    "id": "arXiv:2108.11255",
    "title": "A Case for Sampling Based Learning Techniques in Coflow Scheduling",
    "abstract": "A Case for Sampling Based Learning Techniques in Coflow Scheduling",
    "descriptor": "",
    "authors": [
      "Akshay Jajoo",
      "Y. Charlie Hu",
      "Xiaojun Lin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.11255"
  },
  {
    "id": "arXiv:2108.12056",
    "title": "Continual learning under domain transfer with sparse synaptic bursting",
    "abstract": "Continual learning under domain transfer with sparse synaptic bursting",
    "descriptor": "",
    "authors": [
      "Shawn L. Beaulieu",
      "Jeff Clune",
      "Nick Cheney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.12056"
  },
  {
    "id": "arXiv:2108.13327",
    "title": "N15News: A New Dataset for Multimodal News Classification",
    "abstract": "N15News: A New Dataset for Multimodal News Classification",
    "descriptor": "",
    "authors": [
      "Zhen Wang",
      "Xu Shan",
      "Jie Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13327"
  },
  {
    "id": "arXiv:2109.01876",
    "title": "Attentive Neural Controlled Differential Equations for Time-series  Classification and Forecasting",
    "abstract": "Comments: Accepted in ICDM 2021, Corrected typos",
    "descriptor": "\nComments: Accepted in ICDM 2021, Corrected typos\n",
    "authors": [
      "Sheo Yon Jhin",
      "Heejoo Shin",
      "Seoyoung Hong",
      "Solhee Park",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.01876"
  },
  {
    "id": "arXiv:2109.02411",
    "title": "Data-Driven Wind Turbine Wake Modeling via Probabilistic Machine  Learning",
    "abstract": "Comments: 18 pages, 10 figures",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "S. Ashwin Renganathan",
      "Romit Maulik",
      "Stefano Letizia",
      "Giacomo Valerio Iungo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2109.02411"
  },
  {
    "id": "arXiv:2109.02704",
    "title": "gen2Out: Detecting and Ranking Generalized Anomalies",
    "abstract": "Comments: In Proceedings of 2021 IEEE International Conference on Big Data (Big Data)",
    "descriptor": "\nComments: In Proceedings of 2021 IEEE International Conference on Big Data (Big Data)\n",
    "authors": [
      "Meng-Chieh Lee",
      "Shubhranshu Shekhar",
      "Christos Faloutsos",
      "T. Noah Hutson",
      "Leon Iasemidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02704"
  },
  {
    "id": "arXiv:2109.03523",
    "title": "The convergence of the Regula Falsi method",
    "abstract": "The convergence of the Regula Falsi method",
    "descriptor": "",
    "authors": [
      "Trung Nguyen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.03523"
  },
  {
    "id": "arXiv:2109.06515",
    "title": "Netmarble AI Center's WMT21 Automatic Post-Editing Shared Task  Submission",
    "abstract": "Comments: WMT21 Automatic Post-Editing Shared Task System Paper (at EMNLP2021 Workshop)",
    "descriptor": "\nComments: WMT21 Automatic Post-Editing Shared Task System Paper (at EMNLP2021 Workshop)\n",
    "authors": [
      "Shinhyeok Oh",
      "Sion Jang",
      "Hu Xu",
      "Shounan An",
      "Insoo Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06515"
  },
  {
    "id": "arXiv:2109.09113",
    "title": "HPTQ: Hardware-Friendly Post Training Quantization",
    "abstract": "HPTQ: Hardware-Friendly Post Training Quantization",
    "descriptor": "",
    "authors": [
      "Hai Victor Habi",
      "Reuven Peretz",
      "Elad Cohen",
      "Lior Dikstein",
      "Oranit Dror",
      "Idit Diamant",
      "Roy H. Jennings",
      "Arnon Netzer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.09113"
  },
  {
    "id": "arXiv:2109.10231",
    "title": "SalienTrack: providing salient information for semi-automated  self-tracking feedback with model explanations",
    "abstract": "SalienTrack: providing salient information for semi-automated  self-tracking feedback with model explanations",
    "descriptor": "",
    "authors": [
      "Yunlong Wang",
      "Jiaying Liu",
      "Homin Park",
      "Jordan Schultz-McArdle",
      "Stephanie Rosenthal",
      "Brian Y. Lim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.10231"
  },
  {
    "id": "arXiv:2110.00846",
    "title": "Repttack: Exploiting Cloud Schedulers to Guide Co-Location Attacks",
    "abstract": "Repttack: Exploiting Cloud Schedulers to Guide Co-Location Attacks",
    "descriptor": "",
    "authors": [
      "Chongzhou Fang",
      "Han Wang",
      "Najmeh Nazari",
      "Behnam Omidi",
      "Avesta Sasan",
      "Khaled N. Khasawneh",
      "Setareh Rafatirad",
      "Houman Homayoun"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.00846"
  },
  {
    "id": "arXiv:2110.01593",
    "title": "Generalized Kernel Thinning",
    "abstract": "Generalized Kernel Thinning",
    "descriptor": "",
    "authors": [
      "Raaz Dwivedi",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.01593"
  },
  {
    "id": "arXiv:2110.03177",
    "title": "EE-Net: Exploitation-Exploration Neural Networks in Contextual Bandits",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Yikun Ban",
      "Yuchen Yan",
      "Arindam Banerjee",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03177"
  },
  {
    "id": "arXiv:2110.03588",
    "title": "A transformer-based deep learning approach for classifying brain  metastases into primary organ sites using clinical whole brain MRI",
    "abstract": "A transformer-based deep learning approach for classifying brain  metastases into primary organ sites using clinical whole brain MRI",
    "descriptor": "",
    "authors": [
      "Qing Lyu",
      "Sanjeev V. Namjoshi",
      "Emory McTyre",
      "Umit Topaloglu",
      "Richard Barcus",
      "Michael D. Chan",
      "Christina K. Cramer",
      "Waldemar Debinski",
      "Metin N. Gurcan",
      "Glenn J. Lesser",
      "Hui-Kuan Lin",
      "Reginald F. Munden",
      "Boris C. Pasche",
      "Kiran Kumar Solingapuram Sai",
      "Roy E. Strowd",
      "Stephen B. Tatter",
      "Kounosuke Watabe",
      "Wei Zhang",
      "Ge Wang",
      "Christopher T. Whitlow"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.03588"
  },
  {
    "id": "arXiv:2110.03666",
    "title": "Joint inference of multiple graphs with hidden variables from stationary  graph signals",
    "abstract": "Joint inference of multiple graphs with hidden variables from stationary  graph signals",
    "descriptor": "",
    "authors": [
      "Samuel Rey",
      "Andrei Buciulea",
      "Madeline Navarro",
      "Santiago Segarra",
      "Antonio G. Marques"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.03666"
  },
  {
    "id": "arXiv:2110.03726",
    "title": "Bisimulations for Neural Network Reduction",
    "abstract": "Bisimulations for Neural Network Reduction",
    "descriptor": "",
    "authors": [
      "Pavithra Prabhakar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.03726"
  },
  {
    "id": "arXiv:2110.05610",
    "title": "TSK Fuzzy System Towards Few Labeled Incomplete Multi-View Data  Classification",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Wei Zhang",
      "Zhaohong Deng",
      "Qiongdan Lou",
      "Te Zhang",
      "Kup-Sze Choi",
      "Shitong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05610"
  },
  {
    "id": "arXiv:2110.07110",
    "title": "Weakly Supervised Semantic Segmentation by Pixel-to-Prototype Contrast",
    "abstract": "Weakly Supervised Semantic Segmentation by Pixel-to-Prototype Contrast",
    "descriptor": "",
    "authors": [
      "Ye Du",
      "Zehua Fu",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.07110"
  },
  {
    "id": "arXiv:2110.08187",
    "title": "Crop Rotation Modeling for Deep Learning-Based Parcel Classification  from Satellite Time Series",
    "abstract": "Comments: Published in Remote Sensing",
    "descriptor": "\nComments: Published in Remote Sensing\n",
    "authors": [
      "F\u00e9lix Quinton",
      "Loic Landrieu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08187"
  },
  {
    "id": "arXiv:2110.08243",
    "title": "Neural Dubber: Dubbing for Videos According to Scripts",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Chenxu Hu",
      "Qiao Tian",
      "Tingle Li",
      "Yuping Wang",
      "Yuxuan Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.08243"
  },
  {
    "id": "arXiv:2110.08477",
    "title": "FedMM: Saddle Point Optimization for Federated Adversarial Domain  Adaptation",
    "abstract": "Comments: 34 pages",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Yan Shen",
      "Jian Du",
      "Han Zhao",
      "Benyu Zhang",
      "Zhanghexuan Ji",
      "Mingchen Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08477"
  },
  {
    "id": "arXiv:2110.08861",
    "title": "3D-RETR: End-to-End Single and Multi-View 3D Reconstruction with  Transformers",
    "abstract": "3D-RETR: End-to-End Single and Multi-View 3D Reconstruction with  Transformers",
    "descriptor": "",
    "authors": [
      "Zai Shi",
      "Zhao Meng",
      "Yiran Xing",
      "Yunpu Ma",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08861"
  },
  {
    "id": "arXiv:2110.10540",
    "title": "On the Integration of Course of Action Playbooks into Shareable Cyber  Threat Intelligence",
    "abstract": "On the Integration of Course of Action Playbooks into Shareable Cyber  Threat Intelligence",
    "descriptor": "",
    "authors": [
      "Vasileios Mavroeidis",
      "Pavel Eis",
      "Martin Zadnik",
      "Marco Caselli",
      "Bret Jordan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.10540"
  },
  {
    "id": "arXiv:2110.10548",
    "title": "Synthesizing Optimal Parallelism Placement and Reduction Strategies on  Hierarchical Systems for Deep Learning",
    "abstract": "Synthesizing Optimal Parallelism Placement and Reduction Strategies on  Hierarchical Systems for Deep Learning",
    "descriptor": "",
    "authors": [
      "Ningning Xie",
      "Tamara Norman",
      "Dominik Grewe",
      "Dimitrios Vytiniotis"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10548"
  },
  {
    "id": "arXiv:2110.12397",
    "title": "Motion Planning of a Spin-Rolling Sphere on a Plane",
    "abstract": "Comments: 23 Pages, 16 figures, under review",
    "descriptor": "\nComments: 23 Pages, 16 figures, under review\n",
    "authors": [
      "Seyed Amir Tafrishi",
      "Mikhail Svinin",
      "Motoji Yamamoto",
      "Yasuhisa Hirata"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2110.12397"
  },
  {
    "id": "arXiv:2110.13884",
    "title": "Overcoming Pedestrian Blockage in mm-Wave Bands using Ground Reflections",
    "abstract": "Overcoming Pedestrian Blockage in mm-Wave Bands using Ground Reflections",
    "descriptor": "",
    "authors": [
      "Santosh Ganji",
      "Romil Sonigra",
      "P. R. Kumar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13884"
  },
  {
    "id": "arXiv:2110.14034",
    "title": "r-local sensing: Improved algorithm and applications",
    "abstract": "r-local sensing: Improved algorithm and applications",
    "descriptor": "",
    "authors": [
      "Ahmed Ali Abbasi",
      "Abiy Tasissa",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.14034"
  },
  {
    "id": "arXiv:2110.15317",
    "title": "Bridge the Gap Between CV and NLP! A Gradient-based Textual Adversarial  Attack Framework",
    "abstract": "Comments: Work on progress",
    "descriptor": "\nComments: Work on progress\n",
    "authors": [
      "Lifan Yuan",
      "Yichi Zhang",
      "Yangyi Chen",
      "Wei Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15317"
  },
  {
    "id": "arXiv:2111.00086",
    "title": "Measuring a Texts Fairness Dimensions Using Machine Learning Based on  Social Psychological Factors",
    "abstract": "Comments: 38 pages, 9 figures",
    "descriptor": "\nComments: 38 pages, 9 figures\n",
    "authors": [
      "A. Izzidien",
      "J. Watson",
      "B. Loe",
      "P. Romero",
      "S. Fitz",
      "D. Stillwell"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.00086"
  },
  {
    "id": "arXiv:2111.00901",
    "title": "Click-Based Student Performance Prediction: A Clustering Guided  Meta-Learning Approach",
    "abstract": "Comments: 10 pages, IEEE BigData 2021",
    "descriptor": "\nComments: 10 pages, IEEE BigData 2021\n",
    "authors": [
      "Yun-Wei Chu",
      "Elizabeth Tenorio",
      "Laura Cruz",
      "Kerrie Douglas",
      "Andrew S. Lan",
      "Christopher G. Brinton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00901"
  },
  {
    "id": "arXiv:2111.01714",
    "title": "Meta-Learning the Search Distribution of Black-Box Random Search Based  Adversarial Attacks",
    "abstract": "Comments: accepted at NeurIPS 2021; updated the numbers in Table 5 and added references",
    "descriptor": "\nComments: accepted at NeurIPS 2021; updated the numbers in Table 5 and added references\n",
    "authors": [
      "Maksym Yatsura",
      "Jan Hendrik Metzen",
      "Matthias Hein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01714"
  },
  {
    "id": "arXiv:2111.02098",
    "title": "Distributed Extended Object Tracking Information Filter Over Sensor  Networks",
    "abstract": "Comments: This paper contains 17 pages with single-column, 8 figures. This paper have been uploaded the journal of Signal Processing",
    "descriptor": "\nComments: This paper contains 17 pages with single-column, 8 figures. This paper have been uploaded the journal of Signal Processing\n",
    "authors": [
      "Zhifei Li",
      "Yan Liang",
      "Linfeng Xu",
      "Shuli Ma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02098"
  },
  {
    "id": "arXiv:2111.02357",
    "title": "Multivariate feature ranking of gene expression data",
    "abstract": "Multivariate feature ranking of gene expression data",
    "descriptor": "",
    "authors": [
      "Fernando Jim\u00e9nez",
      "Gracia S\u00e1nchez",
      "Jos\u00e9 Palma",
      "Luis Miralles-Pechu\u00e1n",
      "Juan Bot\u00eda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02357"
  },
  {
    "id": "arXiv:2111.02921",
    "title": "Map-Assisted Power Allocation and Constellation Design for mmWave WDM  with OAM in Short-Range LOS Environment",
    "abstract": "Map-Assisted Power Allocation and Constellation Design for mmWave WDM  with OAM in Short-Range LOS Environment",
    "descriptor": "",
    "authors": [
      "Yuan Wang",
      "Chen Gong",
      "Zhengyuan Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02921"
  },
  {
    "id": "arXiv:2111.03559",
    "title": "Computability and Beltrami fields in Euclidean space",
    "abstract": "Comments: minor changes, 36 pages, 3 figures",
    "descriptor": "\nComments: minor changes, 36 pages, 3 figures\n",
    "authors": [
      "Robert Cardona",
      "Eva Miranda",
      "Daniel Peralta-Salas"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Computational Complexity (cs.CC)",
      "Mathematical Physics (math-ph)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.03559"
  },
  {
    "id": "arXiv:2111.04060",
    "title": "Are we ready for a new paradigm shift? A Survey on Visual Deep MLP",
    "abstract": "Are we ready for a new paradigm shift? A Survey on Visual Deep MLP",
    "descriptor": "",
    "authors": [
      "Ruiyang Liu",
      "Yinghui Li",
      "Linmi Tao",
      "Dun Liang",
      "Shi-Min Hu",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.04060"
  },
  {
    "id": "arXiv:2111.04909",
    "title": "FPM: A Collection of Large-scale Foundation Pre-trained Language Models",
    "abstract": "Comments: Not ready in detail",
    "descriptor": "\nComments: Not ready in detail\n",
    "authors": [
      "Dezhou Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.04909"
  },
  {
    "id": "arXiv:2111.05504",
    "title": "Collocation approximation by deep neural ReLU networks for parametric  elliptic PDEs with lognormal inputs",
    "abstract": "Collocation approximation by deep neural ReLU networks for parametric  elliptic PDEs with lognormal inputs",
    "descriptor": "",
    "authors": [
      "Dinh D\u0169ng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.05504"
  },
  {
    "id": "arXiv:2111.05819",
    "title": "Look Before You Leap: Safe Model-Based Reinforcement Learning with Human  Intervention",
    "abstract": "Comments: CoRL 2021 accepted",
    "descriptor": "\nComments: CoRL 2021 accepted\n",
    "authors": [
      "Yunkun Xu",
      "Zhenyu Liu",
      "Guifang Duan",
      "Jiangcheng Zhu",
      "Xiaolong Bai",
      "Jianrong Tan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.05819"
  },
  {
    "id": "arXiv:2111.06155",
    "title": "A Novel Approach for Deterioration and Damage Identification in Building  Structures Based on Stockwell-Transform and Deep Convolutional Neural Network",
    "abstract": "Comments: 11 figures and 11 Tables, Accepted in Journal of Structural Integrity and Maintenance",
    "descriptor": "\nComments: 11 figures and 11 Tables, Accepted in Journal of Structural Integrity and Maintenance\n",
    "authors": [
      "Vahidreza Gharehbaghi",
      "Hashem Kalbkhani",
      "Ehsan Noroozinejad Farsangi",
      "T.Y. Yang",
      "Andy Nguyen",
      "Seyedali Mirjalili",
      "C. Malaga-Chuquitaype"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06155"
  },
  {
    "id": "arXiv:2111.06739",
    "title": "Neural Motion Planning for Autonomous Parking",
    "abstract": "Comments: 8 pages, 11 figures",
    "descriptor": "\nComments: 8 pages, 11 figures\n",
    "authors": [
      "Dongchan Kim",
      "Kunsoo Huh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.06739"
  },
  {
    "id": "arXiv:2111.06967",
    "title": "CSAT is not in P",
    "abstract": "Comments: Uncorrect proof",
    "descriptor": "\nComments: Uncorrect proof\n",
    "authors": [
      "Fabio Romano"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.06967"
  },
  {
    "id": "arXiv:2111.06975",
    "title": "Meshfree implementation of the cardiac monodomain model through the  Fragile Points Method",
    "abstract": "Comments: 14 pages, 7 figures, 3 tables, research article",
    "descriptor": "\nComments: 14 pages, 7 figures, 3 tables, research article\n",
    "authors": [
      "Konstantinos A. Mountris",
      "Leiting Dong",
      "Yue Guan",
      "Satya N. Atluri",
      "Esther Pueyo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.06975"
  },
  {
    "id": "arXiv:2111.07106",
    "title": "An upwind lattice Boltzmann scheme",
    "abstract": "An upwind lattice Boltzmann scheme",
    "descriptor": "",
    "authors": [
      "Megala A",
      "S.V. Raghurama Rao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.07106"
  },
  {
    "id": "arXiv:2111.07377",
    "title": "Eco-Coasting Strategies Using Road Grade Preview: Evaluation and Online  Implementation Based on Mixed Integer Model Predictive Control",
    "abstract": "Comments: 15 pages, 18 figures",
    "descriptor": "\nComments: 15 pages, 18 figures\n",
    "authors": [
      "Yongjun Yan",
      "Nan Li",
      "Ziyou Song",
      "Jinlong Hong",
      "Bingzhao Gao",
      "Hong Chen",
      "Jing Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.07377"
  },
  {
    "id": "arXiv:2111.07572",
    "title": "Fast, Algebraic Multivariate Multipoint Evaluation in Small  Characteristic and Applications",
    "abstract": "Fast, Algebraic Multivariate Multipoint Evaluation in Small  Characteristic and Applications",
    "descriptor": "",
    "authors": [
      "Vishwas Bhargava",
      "Sumanta Ghosh",
      "Mrinal Kumar",
      "Chandra Kanta Mohapatra"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.07572"
  },
  {
    "id": "arXiv:2111.07597",
    "title": "DFC: Deep Feature Consistency for Robust Point Cloud Registration",
    "abstract": "Comments: 12 pages, 7 figures, 6 tables",
    "descriptor": "\nComments: 12 pages, 7 figures, 6 tables\n",
    "authors": [
      "Zhu Xu",
      "Zhengyao Bai",
      "Huijie Liu",
      "Qianjie Lu",
      "Shenglan Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.07597"
  },
  {
    "id": "arXiv:2111.07637",
    "title": "Drone delivery: Reliable Cellular UAV Communication Using Multi-Operator  Diversity",
    "abstract": "Comments: 6 pages, 8 figures, ICC2022",
    "descriptor": "\nComments: 6 pages, 8 figures, ICC2022\n",
    "authors": [
      "Achiel Colpaert",
      "Micha\u00ebl Raes",
      "Evgenii Vinogradov",
      "Sofie Pollin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.07637"
  },
  {
    "id": "arXiv:2111.07677",
    "title": "FastFlow: Unsupervised Anomaly Detection and Localization via 2D  Normalizing Flows",
    "abstract": "Comments: 11 pages,8 figures",
    "descriptor": "\nComments: 11 pages,8 figures\n",
    "authors": [
      "Jiawei Yu",
      "Ye Zheng",
      "Xiang Wang",
      "Wei Li",
      "Yushuang Wu",
      "Rui Zhao",
      "Liwei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.07677"
  },
  {
    "id": "arXiv:2111.07839",
    "title": "Learnable Locality-Sensitive Hashing for Video Anomaly Detection",
    "abstract": "Learnable Locality-Sensitive Hashing for Video Anomaly Detection",
    "descriptor": "",
    "authors": [
      "Yue Lu",
      "Congqi Cao",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.07839"
  },
  {
    "id": "arXiv:2111.07867",
    "title": "Faster-than-Nyquist Signaling for MIMO Communications",
    "abstract": "Comments: Have been submitted to IEEE transactions on wireless communications",
    "descriptor": "\nComments: Have been submitted to IEEE transactions on wireless communications\n",
    "authors": [
      "Zichao Zhang",
      "Melda Yuksel",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.07867"
  },
  {
    "id": "arXiv:2111.07944",
    "title": "The Projection Extension Method: A Spectrally Accurate Technique for  Complex Domains",
    "abstract": "Comments: 27 pages, approved for release by Pacific Northwest National Laboratory (PNNL-SA-168413)",
    "descriptor": "\nComments: 27 pages, approved for release by Pacific Northwest National Laboratory (PNNL-SA-168413)\n",
    "authors": [
      "Saad Qadeer",
      "Ehssan Nazockdast",
      "Boyce E. Griffith"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.07944"
  }
]
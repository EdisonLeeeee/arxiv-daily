[
  {
    "id": "arXiv:2203.13258",
    "title": "Multi-platform Process Flow Models and Algorithms for Extraction and  Documentation of Digital Forensic Evidence from Mobile Devices",
    "abstract": "The increasing need for the examination of evidence from mobile and portable\ngadgets increases the essential need to establish dependable measures for the\ninvestigation of these gadgets. Many differences exist while detailing the\nrequirement for the examination of each gadget, to help detectives and\nexaminers in guaranteeing that of any kind piece of evidence extracted/\ncollected from any mobile devices is well documented and the outcomes can be\nrepeatable, a reliable and well-documented investigation process must be\nimplemented if the results of the examination are to be repeatable and\ndefensible in courts of law. In this paper we developed a generic process flow\nmodel for the extraction of digital evidence in mobile devices running on\nandroid, Windows, iOs and Blackberry operating system. The research adopted\nsurvey approach and extensive literature review a s means to collect data. The\nmodels developed were validate through expert opinion. Results of this work can\nguide solution developers in ensuring standardization of evidence extraction\ntools for mobile devices.",
    "descriptor": "\nComments: 23 pages, 16 tables, 6 figures\n",
    "authors": [
      "Gilbert Gilibrays Ocen",
      "Ocident Bongomin",
      "Gilbert Barasa Mugeni",
      "Mutua Stephen Makau",
      "Twaibu Semwogerere"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.13258"
  },
  {
    "id": "arXiv:2203.13262",
    "title": "Interpretability of Neural Network With Physiological Mechanisms",
    "abstract": "Deep learning continues to play as a powerful state-of-art technique that has\nachieved extraordinary accuracy levels in various domains of regression and\nclassification tasks, including images, video, signal, and natural language\ndata. The original goal of proposing the neural network model is to improve the\nunderstanding of complex human brains using a mathematical expression approach.\nHowever, recent deep learning techniques continue to lose the interpretations\nof its functional process by being treated mostly as a black-box approximator.\nTo address this issue, such an AI model needs to be biological and\nphysiological realistic to incorporate a better understanding of human-machine\nevolutionary intelligence. In this study, we compare neural networks and\nbiological circuits to discover the similarities and differences from various\nperspective views. We further discuss the insights into how neural networks\nlearn from data by investigating human biological behaviors and understandable\njustifications.",
    "descriptor": "",
    "authors": [
      "Anna Zou",
      "Zhiyuan Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2203.13262"
  },
  {
    "id": "arXiv:2203.13263",
    "title": "Precipitaion Nowcasting using Deep Neural Network",
    "abstract": "Precipitation nowcasting is of great importance for weather forecast users,\nfor activities ranging from outdoor activities and sports competitions to\nairport traffic management. In contrast to long-term precipitation forecasts\nwhich are traditionally obtained from numerical models, precipitation\nnowcasting needs to be very fast. It is therefore more challenging to obtain\nbecause of this time constraint. Recently, many machine learning based methods\nhad been proposed. We propose the use three popular deep learning models\n(U-net, ConvLSTM and SVG-LP) trained on two-dimensional precipitation maps for\nprecipitation nowcasting. We proposed an algorithm for patch extraction to\nobtain high resolution precipitation maps. We proposed a loss function to solve\nthe blurry image issue and to reduce the influence of zero value pixels in\nprecipitation maps.",
    "descriptor": "",
    "authors": [
      "Mohamed Chafik Bakkay",
      "Mathieu Serrurier",
      "Valentin Kivachuk Burda",
      "Florian Dupuy",
      "Naty Citlali Cabrera-Gutierrez",
      "Michael Zamo",
      "Maud-Alix Mader",
      "Olivier Mestre",
      "Guillaume Oller",
      "Jean-Christophe Jouhaud",
      "Laurent Terray"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13263"
  },
  {
    "id": "arXiv:2203.13273",
    "title": "On Exploiting Layerwise Gradient Statistics for Effective Training of  Deep Neural Networks",
    "abstract": "Adam and AdaBelief compute and make use of elementwise adaptive stepsizes in\ntraining deep neural networks (DNNs) by tracking the exponential moving average\n(EMA) of the squared-gradient g_t^2 and the squared prediction error\n(m_t-g_t)^2, respectively, where m_t is the first momentum at iteration t and\ncan be viewed as a prediction of g_t. In this work, we attempt to find out if\nlayerwise gradient statistics can be expoited in Adam and AdaBelief to allow\nfor more effective training of DNNs. We address the above research question in\ntwo steps. Firstly, we slightly modify Adam and AdaBelief by introducing\nlayerwise adaptive stepsizes in their update procedures via either pre or post\nprocessing. Empirical study indicates that the slight modification produces\ncomparable performance for training VGG and ResNet models over CIFAR10,\nsuggesting that layer-wise gradient statistics plays an important role towards\nthe success of Adam and AdaBelief for at least certian DNN tasks. In the second\nstep, instead of manual setup of layerwise stepsizes, we propose Aida, a new\noptimisation method, with the objective that the elementwise stepsizes within\neach layer have significantly small statistic variances. Motivated by the fact\nthat (m_t-g_t)^2 in AdaBelief is conservative in comparison to g_t^2 in Adam in\nterms of layerwise statistic averages and variances, Aida is designed by\ntracking a more conservative function of m_t and g_t than (m_t-g_t)^2 in\nAdaBelief via layerwise orthogonal vector projections. Experimental results\nshow that Aida produces either competitive or better performance with respect\nto a number of existing methods including Adam and AdaBelief for a set of\nchallenging DNN tasks.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Guoqiang Zhang",
      "Kenta Niwa",
      "W. Bastiaan Kleijn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13273"
  },
  {
    "id": "arXiv:2203.13277",
    "title": "A Manifold View of Adversarial Risk",
    "abstract": "The adversarial risk of a machine learning model has been widely studied.\nMost previous works assume that the data lies in the whole ambient space. We\npropose to take a new angle and take the manifold assumption into\nconsideration. Assuming data lies in a manifold, we investigate two new types\nof adversarial risk, the normal adversarial risk due to perturbation along\nnormal direction, and the in-manifold adversarial risk due to perturbation\nwithin the manifold. We prove that the classic adversarial risk can be bounded\nfrom both sides using the normal and in-manifold adversarial risks. We also\nshow with a surprisingly pessimistic case that the standard adversarial risk\ncan be nonzero even when both normal and in-manifold risks are zero. We\nfinalize the paper with empirical studies supporting our theoretical results.\nOur results suggest the possibility of improving the robustness of a classifier\nby only focusing on the normal adversarial risk.",
    "descriptor": "",
    "authors": [
      "Wenjia Zhang",
      "Yikai Zhang",
      "Xiaolin Hu",
      "Mayank Goswami",
      "Chao Chen",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13277"
  },
  {
    "id": "arXiv:2203.13278",
    "title": "Practical Blind Denoising via Swin-Conv-UNet and Data Synthesis",
    "abstract": "While recent years have witnessed a dramatic upsurge of exploiting deep\nneural networks toward solving image denoising, existing methods mostly rely on\nsimple noise assumptions, such as additive white Gaussian noise (AWGN), JPEG\ncompression noise and camera sensor noise, and a general-purpose blind\ndenoising method for real images remains unsolved. In this paper, we attempt to\nsolve this problem from the perspective of network architecture design and\ntraining data synthesis. Specifically, for the network architecture design, we\npropose a swin-conv block to incorporate the local modeling ability of residual\nconvolutional layer and non-local modeling ability of swin transformer block,\nand then plug it as the main building block into the widely-used image-to-image\ntranslation UNet architecture. For the training data synthesis, we design a\npractical noise degradation model which takes into consideration different\nkinds of noise (including Gaussian, Poisson, speckle, JPEG compression, and\nprocessed camera sensor noises) and resizing, and also involves a random\nshuffle strategy and a double degradation strategy. Extensive experiments on\nAGWN removal and real image denoising demonstrate that the new network\narchitecture design achieves state-of-the-art performance and the new\ndegradation model can help to significantly improve the practicability. We\nbelieve our work can provide useful insights into current denoising research.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Kai Zhang",
      "Yawei Li",
      "Jingyun Liang",
      "Jiezhang Cao",
      "Yulun Zhang",
      "Hao Tang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.13278"
  },
  {
    "id": "arXiv:2203.13281",
    "title": "Effectively leveraging Multi-modal Features for Movie Genre  Classification",
    "abstract": "Movie genre classification has been widely studied in recent years due to its\nvarious applications in video editing, summarization, and recommendation. Prior\nwork has typically addressed this task by predicting genres based solely on the\nvisual content. As a result, predictions from these methods often perform\npoorly for genres such as documentary or musical, since non-visual modalities\nlike audio or language play an important role in correctly classifying these\ngenres. In addition, the analysis of long videos at frame level is always\nassociated with high computational cost and makes the prediction less\nefficient. To address these two issues, we propose a Multi-Modal approach\nleveraging shot information, MMShot, to classify video genres in an efficient\nand effective way. We evaluate our method on MovieNet and Condensed Movies for\ngenre classification, achieving 17% ~ 21% improvement on mean Average Precision\n(mAP) over the state-of-the-art. Extensive experiments are conducted to\ndemonstrate the ability of MMShot for long video analysis and uncover the\ncorrelations between genres and multiple movie elements. We also demonstrate\nour approach's ability to generalize by evaluating the scene boundary detection\ntask, achieving 1.1% improvement on Average Precision (AP) over the\nstate-of-the-art.",
    "descriptor": "",
    "authors": [
      "Zhongping Zhang",
      "Yiwen Gu",
      "Bryan A. Plummer",
      "Xin Miao",
      "Jiayi Liu",
      "Huayan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13281"
  },
  {
    "id": "arXiv:2203.13282",
    "title": "Dynamically Avoiding Amorphous Obstacles with Topological Manifold  Learning and Deep Autoencoding",
    "abstract": "To achieve conflict-free human-machine collaborations, robotic agents need to\nskillfully avoid continuously moving obstacles while achieving collective\nobjectives. Sometimes, these obstacles can even change their 3D shapes and\nforms simultaneously, hence being \"amorphous\". To this end, this paper\nformulates the problem of Dynamic Amorphous Obstacle Avoidance (DAO-A), where a\nrobotic arm can dexterously avoid dynamically generated obstacles that\nconstantly change their trajectories and their 3D forms. Specifically, we\nintroduce a novel control strategy for robotic arms that leverages both\ntopological manifold learning and latest deep learning advancements. We test\nour learning framework, using a 7-DoF robotic manipulator, in both simulation\nand physical experiments, where the robot satisfactorily learns and synthesizes\nrealistic skills avoiding previously-unseen obstacles, while generating novel\nmovements to achieve predefined motion objectives. Most notably, our learned\nmethodology, once finalized, for a given robotic manipulator, can avoid any\nnumber of 3D obstacles with arbitrary and unseen moving trajectories, therefore\nit is universal, versatile, and completely reusable. Complete video\ndemonstrations of our experiments can be found in\nhttps://sites.google.com/view/daoa/home.",
    "descriptor": "\nComments: Submitted to IROS 2022\n",
    "authors": [
      "Apan Dastider",
      "Mingjie Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.13282"
  },
  {
    "id": "arXiv:2203.13283",
    "title": "On the Fast Direct Solution of a Preconditioned Electromagnetic Integral  Equation",
    "abstract": "This work presents a fast direct solver strategy for electromagnetic integral\nequations in the high-frequency regime. The new scheme relies on a suitably\npreconditioned combined field formulation and results in a single skeleton form\nplus identity equation. This is obtained after a regularization of the elliptic\nspectrum through the extraction of a suitably chosen equivalent circulant\nproblem. The inverse of the system matrix is then obtained by leveraging the\nWoodbury matrix identity, the low-rank representation of the extracted part of\nthe operator, and fast circulant algebra yielding a scheme with a favorable\ncomplexity and suitable for the solution of multiple right-hand sides.\nTheoretical considerations are accompanied by numerical results both of which\nare confirming and showing the practical relevance of the newly developed\nscheme.",
    "descriptor": "",
    "authors": [
      "Davide Consoli",
      "Cl\u00e9ment Henry",
      "Alexandre D\u00e9ly",
      "Lyes Rahmouni",
      "John Erik Ortiz Guzman",
      "Tiffany L. Chhim",
      "Simon B. Adrian",
      "Adrien Merlini",
      "Francesco P. Andriulli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.13283"
  },
  {
    "id": "arXiv:2203.13285",
    "title": "Continuous-Time Audiovisual Fusion with Recurrence vs. Attention for  In-The-Wild Affect Recognition",
    "abstract": "In this paper, we present our submission to 3rd Affective Behavior Analysis\nin-the-wild (ABAW) challenge. Learningcomplex interactions among multimodal\nsequences is critical to recognise dimensional affect from in-the-wild\naudiovisual data. Recurrence and attention are the two widely used sequence\nmodelling mechanisms in the literature. To clearly understand the performance\ndifferences between recurrent and attention models in audiovisual affect\nrecognition, we present a comprehensive evaluation of fusion models based on\nLSTM-RNNs, self-attention and cross-modal attention, trained for valence and\narousal estimation. Particularly, we study the impact of some key design\nchoices: the modelling complexity of CNN backbones that provide features to the\nthe temporal models, with and without end-to-end learning. We trained the\naudiovisual affect recognition models on in-the-wild ABAW corpus by\nsystematically tuning the hyper-parameters involved in the network architecture\ndesign and training optimisation. Our extensive evaluation of the audiovisual\nfusion models shows that LSTM-RNNs can outperform the attention models when\ncoupled with low-complex CNN backbones and trained in an end-to-end fashion,\nimplying that attention models may not necessarily be the optimal choice for\ncontinuous-time multimodal emotion recognition.",
    "descriptor": "\nComments: 7 pages, 0 figures\n",
    "authors": [
      "Vincent Karas",
      "Mani Kumar Tellamekala",
      "Adria Mallol-Ragolta",
      "Michel Valstar",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13285"
  },
  {
    "id": "arXiv:2203.13291",
    "title": "Searching for fingerspelled content in American Sign Language",
    "abstract": "Natural language processing for sign language video - including tasks like\nrecognition, translation, and search - is crucial for making artificial\nintelligence technologies accessible to deaf individuals, and is gaining\nresearch interest in recent years. In this paper, we address the problem of\nsearching for fingerspelled key-words or key phrases in raw sign language\nvideos. This is an important task since significant content in sign language is\noften conveyed via fingerspelling, and to our knowledge the task has not been\nstudied before. We propose an end-to-end model for this task, FSS-Net, that\njointly detects fingerspelling and matches it to a text sequence. Our\nexperiments, done on a large public dataset of ASL fingerspelling in the wild,\nshow the importance of fingerspelling detection as a component of a search and\nretrieval model. Our model significantly outperforms baseline methods adapted\nfrom prior work on related tasks",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Bowen Shi",
      "Diane Brentari",
      "Greg Shakhnarovich",
      "Karen Livescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13291"
  },
  {
    "id": "arXiv:2203.13292",
    "title": "Coordination and Collaboration: How do Volunteer Moderators Work as a  Team in Live Streaming Communities?",
    "abstract": "Volunteer moderators (mods) play significant roles in developing moderation\nstandards and dealing with harmful content in their micro-communities. However,\nlittle work explores how volunteer mods work as a team. In line with prior work\nabout understanding volunteer moderation, we interview 40 volunteer mods on\nTwitch - a leading live streaming platform. We identify how mods collaborate on\ntasks (off-streaming coordination and preparation, in-stream real-time\ncollaboration, and relationship building both off-stream and in-stream to\nreinforce collaboration) and how mods contribute to moderation standards\n(collaboratively working on the community rulebook and individually shaping\ncommunity norms). We uncover how volunteer mods work as an effective team. We\nalso discuss how the affordances of multi-modal communication and informality\nof volunteer moderation contribute to task collaboration, standards\ndevelopment, and mod's roles and responsibilities.",
    "descriptor": "\nComments: Accepted at CHI 2022\n",
    "authors": [
      "Jie Cai",
      "Donghee Yvette Wohn"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.13292"
  },
  {
    "id": "arXiv:2203.13294",
    "title": "Learning Spatiotemporal Chaos Using Next-Generation Reservoir Computing",
    "abstract": "Forecasting the behavior of high-dimensional dynamical systems using machine\nlearning (ML) requires efficient methods to learn the underlying physical\nmodel. We demonstrate spatiotemporal chaos prediction of a heuristic\natmospheric weather model using an ML architecture that, when combined with a\nnext-generation reservoir computer, displays state-of-the-art performance with\na training time $10^3-10^4$ times faster and training data set $\\sim 10^2$\ntimes smaller than other ML algorithms. We also take advantage of the\ntranslational symmetry of the model to further reduce the computational cost\nand training data, each by a factor of $\\sim$10.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Wendson A. S. Barbosa",
      "Daniel J. Gauthier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2203.13294"
  },
  {
    "id": "arXiv:2203.13296",
    "title": "RayTran: 3D pose estimation and shape reconstruction of multiple objects  from videos with ray-traced transformers",
    "abstract": "We propose a transformer-based neural network architecture for multi-object\n3D reconstruction from RGB videos. It relies on two alternative ways to\nrepresent its knowledge: as a global 3D grid of features and an array of\nview-specific 2D grids. We progressively exchange information between the two\nwith a dedicated bidirectional attention mechanism. We exploit knowledge about\nthe image formation process to significantly sparsify the attention weight\nmatrix, making our architecture feasible on current hardware, both in terms of\nmemory and computation. We attach a DETR-style head on top of the 3D feature\ngrid in order to detect the objects in the scene and to predict their 3D pose\nand 3D shape. Compared to previous methods, our architecture is single stage,\nend-to-end trainable, and it can reason holistically about a scene from\nmultiple video frames without needing a brittle tracking step. We evaluate our\nmethod on the challenging Scan2CAD dataset, where we outperform (1) recent\nstate-of-the-art methods for 3D object pose estimation from RGB videos; and (2)\na strong alternative method combining Multi-view Stereo with RGB-D CAD\nalignment. We plan to release our source code.",
    "descriptor": "",
    "authors": [
      "Micha\u0142 J. Tyszkiewicz",
      "Kevis-Kokitsi Maninis",
      "Stefan Popov",
      "Vittorio Ferrari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13296"
  },
  {
    "id": "arXiv:2203.13299",
    "title": "Mix and Match: Learning-free Controllable Text Generation using Energy  Language Models",
    "abstract": "Recent work on controlled text generation has either required attribute-based\nfine-tuning of the base language model (LM), or has restricted the\nparameterization of the attribute discriminator to be compatible with the base\nautoregressive LM. In this work, we propose Mix and Match LM, a global\nscore-based alternative for controllable text generation that combines\narbitrary pre-trained black-box models for achieving the desired attributes in\nthe generated text without involving any fine-tuning or structural assumptions\nabout the black-box models. We interpret the task of controllable generation as\ndrawing samples from an energy-based model whose energy values are a linear\ncombination of scores from black-box models that are separately responsible for\nfluency, the control attribute, and faithfulness to any conditioning context.\nWe use a Metropolis-Hastings sampling scheme to sample from this energy-based\nmodel using bidirectional context and global attribute features. We validate\nthe effectiveness of our approach on various controlled generation and\nstyle-based text revision tasks by outperforming recently proposed methods that\ninvolve extra training, fine-tuning, or restrictive assumptions over the form\nof models.",
    "descriptor": "\nComments: Camera ready--ACL 2022\n",
    "authors": [
      "Fatemehsadat Mireshghallah",
      "Kartik Goyal",
      "Taylor Berg-Kirkpatrick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13299"
  },
  {
    "id": "arXiv:2203.13301",
    "title": "Multi-modal Multi-label Facial Action Unit Detection with Transformer",
    "abstract": "Facial Action Coding System is an important approach of facial expression\nanalysis.This paper describes our submission to the third Affective Behavior\nAnalysis (ABAW) 2022 competition. We proposed a transfomer based model to\ndetect facial action unit (FAU) in video. To be specific, we firstly trained a\nmulti-modal model to extract both audio and visual feature. After that, we\nproposed a action units correlation module to learn relationships between each\naction unit labels and refine action unit detection result. Experimental\nresults on validation dataset shows that our method achieves better performance\nthan baseline model, which verifies that the effectiveness of proposed network.",
    "descriptor": "",
    "authors": [
      "Lingfeng Wang",
      "Shisen Wang",
      "Jin Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13301"
  },
  {
    "id": "arXiv:2203.13307",
    "title": "Tackling Online One-Class Incremental Learning by Removing Negative  Contrasts",
    "abstract": "Recent work studies the supervised online continual learning setting where a\nlearner receives a stream of data whose class distribution changes over time.\nDistinct from other continual learning settings the learner is presented new\nsamples only once and must distinguish between all seen classes. A number of\nsuccessful methods in this setting focus on storing and replaying a subset of\nsamples alongside incoming data in a computationally efficient manner. One\nrecent proposal ER-AML achieved strong performance in this setting by applying\nan asymmetric loss based on contrastive learning to the incoming data and\nreplayed data. However, a key ingredient of the proposed method is avoiding\ncontrasts between incoming data and stored data, which makes it impractical for\nthe setting where only one new class is introduced in each phase of the stream.\nIn this work we adapt a recently proposed approach (\\textit{BYOL}) from\nself-supervised learning to the supervised learning setting, unlocking the\nconstraint on contrasts. We then show that supplementing this with additional\nregularization on class prototypes yields a new method that achieves strong\nperformance in the one-class incremental learning setting and is competitive\nwith the top performing methods in the multi-class incremental setting.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 Workshop on Distribution Shifts\n",
    "authors": [
      "Nader Asadi",
      "Sudhir Mudur",
      "Eugene Belilovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13307"
  },
  {
    "id": "arXiv:2203.13308",
    "title": "Verifiable Access Control for Augmented Reality Localization and Mapping",
    "abstract": "Localization and mapping is a key technology for bridging the virtual and\nphysical worlds in augmented reality (AR). Localization and mapping works by\ncreating and querying maps made of anchor points that enable the overlay of\nthese two worlds. As a result, information about the physical world is captured\nin the map and naturally gives rise to concerns around who can map physical\nspaces as well as who can access or modify the virtual ones. This paper\ndiscusses how we can provide access controls over virtual maps as a basic\nbuilding block to enhance security and privacy of AR systems. In particular, we\npropose VACMaps: an access control system for localization and mapping using\nformal methods. VACMaps defines a domain-specific language that enables users\nto specify access control policies for virtual spaces. Access requests to\nvirtual spaces are then evaluated against relevant policies in a way that\npreserves confidentiality and integrity of virtual spaces owned by the users.\nThe precise semantics of the policies are defined by SMT formulas, which allow\nVACMaps to reason about properties of access policies automatically. An\nevaluation of VACMaps is provided using an AR testbed of a single-family home.\nWe show that VACMaps is scalable in that it can run at practical speeds and\nthat it can also reason about access control policies automatically to detect\npotential policy misconfigurations.",
    "descriptor": "",
    "authors": [
      "Shaowei Zhu",
      "Hyo Jin Kim",
      "Maurizio Monge",
      "G. Edward Suh",
      "Armin Alaghi",
      "Brandon Reagen",
      "Vincent Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.13308"
  },
  {
    "id": "arXiv:2203.13309",
    "title": "Weakly-Supervised Online Action Segmentation in Multi-View Instructional  Videos",
    "abstract": "This paper addresses a new problem of weakly-supervised online action\nsegmentation in instructional videos. We present a framework to segment\nstreaming videos online at test time using Dynamic Programming and show its\nadvantages over greedy sliding window approach. We improve our framework by\nintroducing the Online-Offline Discrepancy Loss (OODL) to encourage the\nsegmentation results to have a higher temporal consistency. Furthermore, only\nduring training, we exploit frame-wise correspondence between multiple views as\nsupervision for training weakly-labeled instructional videos. In particular, we\ninvestigate three different multi-view inference techniques to generate more\naccurate frame-wise pseudo ground-truth with no additional annotation cost. We\npresent results and ablation studies on two benchmark multi-view datasets,\nBreakfast and IKEA ASM. Experimental results show efficacy of the proposed\nmethods both qualitatively and quantitatively in two domains of cooking and\nassembly.",
    "descriptor": "\nComments: Accepted CVPR 2022\n",
    "authors": [
      "Reza Ghoddoosian",
      "Isht Dwivedi",
      "Nakul Agarwal",
      "Chiho Choi",
      "Behzad Dariush"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13309"
  },
  {
    "id": "arXiv:2203.13310",
    "title": "MonoDETR: Depth-aware Transformer for Monocular 3D Object Detection",
    "abstract": "Monocular 3D object detection has long been a challenging task in autonomous\ndriving, which requires to decode 3D predictions solely from a single 2D image.\nMost existing methods follow conventional 2D object detectors to first localize\nobjects by their centers, and then predict 3D attributes using\ncenter-neighboring local features. However, such center-based pipeline views 3D\nprediction as a subordinate task and lacks inter-object depth interactions with\nglobal spatial clues. In this paper, we introduce a simple framework for\nMonocular DEtection with depth-aware TRansformer, named MonoDETR. We enable the\nvanilla transformer to be depth-aware and enforce the whole detection process\nguided by depth. Specifically, we represent 3D object candidates as a set of\nqueries and produce non-local depth embeddings of the input image by a\nlightweight depth predictor and an attention-based depth encoder. Then, we\npropose a depth-aware decoder to conduct both inter-query and query-scene depth\nfeature communication. In this way, each object estimates its 3D attributes\nadaptively from the depth-informative regions on the image, not limited by\ncenter-around features. With minimal handcrafted designs, MonoDETR is an\nend-to-end framework without additional data, anchors or NMS and achieves\ncompetitive performance on KITTI benchmark among state-of-the-art center-based\nnetworks. Extensive ablation studies demonstrate the effectiveness of our\napproach and its potential to serve as a transformer baseline for future\nmonocular research. Code is available at\nhttps://github.com/ZrrSkywalker/MonoDETR.git.",
    "descriptor": "\nComments: 10 pages, 5 figures, submitted to CVPR 2022\n",
    "authors": [
      "Renrui Zhang",
      "Han Qiu",
      "Tai Wang",
      "Xuanzhuo Xu",
      "Ziyu Guo",
      "Yu Qiao",
      "Peng Gao",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.13310"
  },
  {
    "id": "arXiv:2203.13312",
    "title": "SharpContour: A Contour-based Boundary Refinement Approach for Efficient  and Accurate Instance Segmentation",
    "abstract": "Excellent performance has been achieved on instance segmentation but the\nquality on the boundary area remains unsatisfactory, which leads to a rising\nattention on boundary refinement. For practical use, an ideal post-processing\nrefinement scheme are required to be accurate, generic and efficient. However,\nmost of existing approaches propose pixel-wise refinement, which either\nintroduce a massive computation cost or design specifically for different\nbackbone models. Contour-based models are efficient and generic to be\nincorporated with any existing segmentation methods, but they often generate\nover-smoothed contour and tend to fail on corner areas. In this paper, we\npropose an efficient contour-based boundary refinement approach, named\nSharpContour, to tackle the segmentation of boundary area. We design a novel\ncontour evolution process together with an Instance-aware Point Classifier. Our\nmethod deforms the contour iteratively by updating offsets in a discrete\nmanner. Differing from existing contour evolution methods, SharpContour\nestimates each offset more independently so that it predicts much sharper and\naccurate contours. Notably, our method is generic to seamlessly work with\ndiverse existing models with a small computational cost. Experiments show that\nSharpContour achieves competitive gains whilst preserving high efficiency",
    "descriptor": "\nComments: 10pages, 5 figures, accepted by CVPR 2022, project page: see this this https URL\n",
    "authors": [
      "Chenming Zhu",
      "Xuanye Zhang",
      "Yanran Li",
      "Liangdong Qiu",
      "Kai Han",
      "Xiaoguang Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13312"
  },
  {
    "id": "arXiv:2203.13316",
    "title": "Immersive Visual Analysis of Cello Bow Movements",
    "abstract": "We propose a 3D immersive visualization environment for analyzing the right\nhand movements of a cello player. To achieve this, we track the position and\norientation of the cello bow and record audio. As movements mostly occur in a\nshallow volume and the motion is therefore mostly two-dimensional, we use the\nthird dimension to encode time. Our concept further explores various mappings\nfrom motion and audio data to spatial and other visual attributes. We work in\nclose cooperation with a cellist and plan to evaluate our prototype through a\nuser study with a group of cellists in the near future.",
    "descriptor": "\nComments: CHI 2022 IMI Workshop this https URL\n",
    "authors": [
      "Frank Heyen",
      "Yannik Kohler",
      "Sebastian Triebener",
      "Sebastian Rigling",
      "Michael Sedlmair"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.13316"
  },
  {
    "id": "arXiv:2203.13317",
    "title": "Human Gait Recognition Using Bag of Words Feature Representation Method",
    "abstract": "In this paper, we propose a novel gait recognition method based on a\nbag-of-words feature representation method. The algorithm is trained, tested\nand evaluated on a unique human gait data consisting of 93 individuals who\nwalked with comfortable pace between two end points during two different\nsessions. To evaluate the effectiveness of the proposed model, the results are\ncompared with the outputs of the classification using extracted features. As it\nis presented, the proposed method results in significant improvement accuracy\ncompared to using common statistical features, in all the used classifiers.",
    "descriptor": "\nComments: 14 pages, 7 figures, submitted to AHFE conference\n",
    "authors": [
      "Nasrin Bayat",
      "Elham Rastegari",
      "Qifeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13317"
  },
  {
    "id": "arXiv:2203.13318",
    "title": "NPBG++: Accelerating Neural Point-Based Graphics",
    "abstract": "We present a new system (NPBG++) for the novel view synthesis (NVS) task that\nachieves high rendering realism with low scene fitting time. Our method\nefficiently leverages the multiview observations and the point cloud of a\nstatic scene to predict a neural descriptor for each point, improving upon the\npipeline of Neural Point-Based Graphics in several important ways. By\npredicting the descriptors with a single pass through the source images, we\nlift the requirement of per-scene optimization while also making the neural\ndescriptors view-dependent and more suitable for scenes with strong\nnon-Lambertian effects. In our comparisons, the proposed system outperforms\nprevious NVS approaches in terms of fitting and rendering runtimes while\nproducing images of similar quality.",
    "descriptor": "\nComments: Accepted to CVPR 2022. The project page: this https URL\n",
    "authors": [
      "Ruslan Rakhimov",
      "Andrei-Timotei Ardelean",
      "Victor Lempitsky",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13318"
  },
  {
    "id": "arXiv:2203.13319",
    "title": "Remember and Forget Experience Replay for Multi-Agent Reinforcement  Learning",
    "abstract": "We present the extension of the Remember and Forget for Experience Replay\n(ReF-ER) algorithm to Multi-Agent Reinforcement Learning (MARL). {ReF-ER} was\nshown to outperform state of the art algorithms for continuous control in\nproblems ranging from the OpenAI Gym to complex fluid flows. In MARL, the\ndependencies between the agents are included in the state-value estimator and\nthe environment dynamics are modeled via the importance weights used by ReF-ER.\nIn collaborative environments, we find the best performance when the value is\nestimated using individual rewards and we ignore the effects of other actions\non the transition map. We benchmark the performance of ReF-ER MARL on the\nStanford Intelligent Systems Laboratory (SISL) environments. We find that\nemploying a single feed-forward neural network for the policy and the value\nfunction in ReF-ER MARL, outperforms state of the art algorithms that rely on\ncomplex neural network architectures.",
    "descriptor": "",
    "authors": [
      "Pascal Weber",
      "Daniel W\u00e4lchli",
      "Mustafa Zeqiri",
      "Petros Koumoutsakos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13319"
  },
  {
    "id": "arXiv:2203.13320",
    "title": "Data-Driven Visual Reflection on Music Instrument Practice",
    "abstract": "We propose a data-driven approach to music instrument practice that allows\nstudying patterns and long-term trends through visualization. Inspired by life\nlogging and fitness tracking, we imagine musicians to record their practice\nsessions over the span of months or years. The resulting data in the form of\nMIDI or audio recordings can then be analyzed sporadically to track progress\nand guide decisions. Toward this vision, we started exploring various\nvisualization designs together with a group of nine guitarists, who provided us\nwith data and feedback over the course of three months.",
    "descriptor": "\nComments: CHI 2022 IMI Workshop this https URL\n",
    "authors": [
      "Frank Heyen",
      "Quynh Quang Ngo",
      "Kuno Kurzhals",
      "Michael Sedlmair"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.13320"
  },
  {
    "id": "arXiv:2203.13321",
    "title": "Addressing Client Drift in Federated Continual Learning with Adaptive  Optimization",
    "abstract": "Federated learning has been extensively studied and is the prevalent method\nfor privacy-preserving distributed learning in edge devices. Correspondingly,\ncontinual learning is an emerging field targeted towards learning multiple\ntasks sequentially. However, there is little attention towards additional\nchallenges emerging when federated aggregation is performed in a continual\nlearning system. We identify \\textit{client drift} as one of the key weaknesses\nthat arise when vanilla federated averaging is applied in such a system,\nespecially since each client can independently have different order of tasks.\nWe outline a framework for performing Federated Continual Learning (FCL) by\nusing NetTailor as a candidate continual learning approach and show the extent\nof the problem of client drift. We show that adaptive federated optimization\ncan reduce the adverse impact of client drift and showcase its effectiveness on\nCIFAR100, MiniImagenet, and Decathlon benchmarks. Further, we provide an\nempirical analysis highlighting the interplay between different hyperparameters\nsuch as client and server learning rates, the number of local training\niterations, and communication rounds. Finally, we evaluate our framework on\nuseful characteristics of federated learning systems such as scalability,\nrobustness to the skewness in clients' data distribution, and stragglers.",
    "descriptor": "",
    "authors": [
      "Yeshwanth Venkatesha",
      "Youngeun Kim",
      "Hyoungseob Park",
      "Yuhang Li",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13321"
  },
  {
    "id": "arXiv:2203.13324",
    "title": "Resilient Execution of Data-triggered Applications on Edge, Fog and  Cloud Resources",
    "abstract": "Internet of Things (IoT) is leading to the pervasive availability of\nstreaming data about the physical world, coupled with edge computing\ninfrastructure deployed as part of smart cities and 5G rollout. These\nconstrained, less reliable but cheap resources are complemented by fog\nresources that offer federated management and accelerated computing, and\npay-as-you-go cloud resources. There is a lack of intuitive means to deploy\napplication pipelines to consume such diverse streams, and to execute them\nreliably on edge and fog resources. We propose an innovative application model\nto declaratively specify queries to match streams of micro-batch data from\nstream sources and trigger the distributed execution of data pipelines. We also\ndesign a resilient scheduling strategy using advanced reservation on reliable\nfogs to guarantee dataflow completion within a deadline while minimizing the\nexecution cost. Our detailed experiments on over 100 virtual IoT resources and\nfor $\\approx 10k$ task executions, with comparison against baseline scheduling\nstrategies, illustrates the cost-effectiveness, resilience and scalability of\nour framework.",
    "descriptor": "",
    "authors": [
      "Prateeksha Varshney",
      "Shriram Ramesh",
      "Shayal Chhabra",
      "Aakash Khochare",
      "Yogesh Simmhan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.13324"
  },
  {
    "id": "arXiv:2203.13333",
    "title": "Text to Mesh Without 3D Supervision Using Limit Subdivision",
    "abstract": "We present a technique for zero-shot generation of a 3D model using only a\ntarget text prompt. Without a generative model or any 3D supervision our method\ndeforms a control shape of a limit subdivided surface along with a texture map\nand normal map to obtain a 3D model asset that matches the input text prompt\nand can be deployed into games or modeling applications. We rely only on a\npre-trained CLIP model that compares the input text prompt with differentiably\nrendered images of our 3D model. While previous works have focused on\nstylization or required training of generative models we perform optimization\non mesh parameters directly to generate shape and texture. To improve the\nquality of results we also introduce a set of techniques such as render\naugmentations, primitive selection, prompt augmentation that guide the mesh\ntowards a suitable result.",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Nasir Khalid",
      "Tianhao Xie",
      "Eugene Belilovsky",
      "Tiberiu Popa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13333"
  },
  {
    "id": "arXiv:2203.13339",
    "title": "Leveraging unsupervised and weakly-supervised data to improve direct  speech-to-speech translation",
    "abstract": "End-to-end speech-to-speech translation (S2ST) without relying on\nintermediate text representations is a rapidly emerging frontier of research.\nRecent works have demonstrated that the performance of such direct S2ST systems\nis approaching that of conventional cascade S2ST when trained on comparable\ndatasets. However, in practice, the performance of direct S2ST is bounded by\nthe availability of paired S2ST training data. In this work, we explore\nmultiple approaches for leveraging much more widely available unsupervised and\nweakly-supervised speech and text data to improve the performance of direct\nS2ST based on Translatotron 2. With our most effective approaches, the average\ntranslation quality of direct S2ST on 21 language pairs on the CVSS-C corpus is\nimproved by +13.6 BLEU (or +113% relatively), as compared to the previous\nstate-of-the-art trained without additional data. The improvements on\nlow-resource language are even more significant (+398% relatively on average).\nOur comparative studies suggest future research directions for S2ST and speech\nrepresentation learning.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Ye Jia",
      "Yifan Ding",
      "Ankur Bapna",
      "Colin Cherry",
      "Yu Zhang",
      "Alexis Conneau",
      "Nobuyuki Morioka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13339"
  },
  {
    "id": "arXiv:2203.13344",
    "title": "Linking Emergent and Natural Languages via Corpus Transfer",
    "abstract": "The study of language emergence aims to understand how human languages are\nshaped by perceptual grounding and communicative intent. Computational\napproaches to emergent communication (EC) predominantly consider referential\ngames in limited domains and analyze the learned protocol within the game\nframework. As a result, it remains unclear how the emergent languages from\nthese settings connect to natural languages or provide benefits in real-world\nlanguage processing tasks, where statistical models trained on large text\ncorpora dominate. In this work, we propose a novel way to establish such a link\nby corpus transfer, i.e. pretraining on a corpus of emergent language for\ndownstream natural language tasks, which is in contrast to prior work that\ndirectly transfers speaker and listener parameters. Our approach showcases\nnon-trivial transfer benefits for two different tasks -- language modeling and\nimage captioning. For example, in a low-resource setup (modeling 2 million\nnatural language tokens), pre-training on an emergent language corpus with just\n2 million tokens reduces model perplexity by $24.6\\%$ on average across ten\nnatural languages. We also introduce a novel metric to predict the\ntransferability of an emergent language by translating emergent messages to\nnatural language captions grounded on the same images. We find that our\ntranslation-based metric highly correlates with the downstream performance on\nmodeling natural languages (for instance $\\rho=0.83$ on Hebrew), while\ntopographic similarity, a popular metric in previous work, shows surprisingly\nlow correlation ($\\rho=0.003$), hinting that simple properties like attribute\ndisentanglement from synthetic domains might not capture the full complexities\nof natural language. Our findings also indicate potential benefits of moving\nlanguage emergence forward with natural language resources and models.",
    "descriptor": "\nComments: ICLR 2022 Spotlight. Github repo: this https URL\n",
    "authors": [
      "Shunyu Yao",
      "Mo Yu",
      "Yang Zhang",
      "Karthik R Narasimhan",
      "Joshua B. Tenenbaum",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13344"
  },
  {
    "id": "arXiv:2203.13347",
    "title": "Multi-modal multi-objective model-based genetic programming to find  multiple diverse high-quality models",
    "abstract": "Explainable artificial intelligence (XAI) is an important and rapidly\nexpanding research topic. The goal of XAI is to gain trust in a machine\nlearning (ML) model through clear insights into how the model arrives at its\npredictions. Genetic programming (GP) is often cited as being uniquely\nwell-suited to contribute to XAI because of its capacity to learn (small)\nsymbolic models that have the potential to be interpreted. Nevertheless, like\nmany ML algorithms, GP typically results in a single best model. However, in\npractice, the best model in terms of training error may well not be the most\nsuitable one as judged by a domain expert for various reasons, including\noverfitting, multiple different models existing that have similar accuracy, and\nunwanted errors on particular data points due to typical accuracy measures like\nmean squared error. Hence, to increase chances that domain experts deem a\nresulting model plausible, it becomes important to be able to explicitly search\nfor multiple, diverse, high-quality models that trade-off different meanings of\naccuracy. In this paper, we achieve exactly this with a novel multi-modal\nmulti-tree multi-objective GP approach that extends a modern model-based GP\nalgorithm known as GP-GOMEA that is already effective at searching for small\nexpressions.",
    "descriptor": "",
    "authors": [
      "E.M.C. Sijben",
      "T. Alderliesten",
      "P.A.N. Bosman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.13347"
  },
  {
    "id": "arXiv:2203.13349",
    "title": "Occluded Human Mesh Recovery",
    "abstract": "Top-down methods for monocular human mesh recovery have two stages: (1)\ndetect human bounding boxes; (2) treat each bounding box as an independent\nsingle-human mesh recovery task. Unfortunately, the single-human assumption\ndoes not hold in images with multi-human occlusion and crowding. Consequently,\ntop-down methods have difficulties in recovering accurate 3D human meshes under\nsevere person-person occlusion. To address this, we present Occluded Human Mesh\nRecovery (OCHMR) - a novel top-down mesh recovery approach that incorporates\nimage spatial context to overcome the limitations of the single-human\nassumption. The approach is conceptually simple and can be applied to any\nexisting top-down architecture. Along with the input image, we condition the\ntop-down model on spatial context from the image in the form of body-center\nheatmaps. To reason from the predicted body centermaps, we introduce Contextual\nNormalization (CoNorm) blocks to adaptively modulate intermediate features of\nthe top-down model. The contextual conditioning helps our model disambiguate\nbetween two severely overlapping human bounding-boxes, making it robust to\nmulti-person occlusion. Compared with state-of-the-art methods, OCHMR achieves\nsuperior performance on challenging multi-person benchmarks like 3DPW,\nCrowdPose and OCHuman. Specifically, our proposed contextual reasoning\narchitecture applied to the SPIN model with ResNet-50 backbone results in 75.2\nPMPJPE on 3DPW-PC, 23.6 AP on CrowdPose and 37.7 AP on OCHuman datasets, a\nsignificant improvement of 6.9 mm, 6.4 AP and 20.8 AP respectively over the\nbaseline. Code and models will be released.",
    "descriptor": "",
    "authors": [
      "Rawal Khirodkar",
      "Shashank Tripathi",
      "Kris Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13349"
  },
  {
    "id": "arXiv:2203.13351",
    "title": "Predicting Personas Using Mechanic Frequencies and Game State Traces",
    "abstract": "We investigate how to efficiently predict play personas based on playtraces.\nPlay personas can be computed by calculating the action agreement ratio between\na player and a generative model of playing behavior, a so-called procedural\npersona. But this is computationally expensive and assumes that appropriate\nprocedural personas are readily available. We present two methods for\nestimating player persona, one using regular supervised learning and aggregate\nmeasures of game mechanics initiated, and another based on sequence learning on\na trace of closely cropped gameplay observations. While both of these methods\nachieve high accuracy when predicting play personas defined by agreement with\nprocedural personas, they utterly fail to predict play style as defined by the\nplayers themselves using a questionnaire. This interesting result highlights\nthe value of using computational methods in defining play personas.",
    "descriptor": "\nComments: 9 pages, 3 tables, 2 figures\n",
    "authors": [
      "Michael Cerny Green",
      "Ahmed Khalifa",
      "M Charity",
      "Debosmita Bhaumik",
      "Julian Togelius"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13351"
  },
  {
    "id": "arXiv:2203.13352",
    "title": "Does human speech follow Benford's Law?",
    "abstract": "Researchers have observed that the frequencies of leading digits in many\nman-made and naturally occurring datasets follow a logarithmic curve, with\ndigits that start with the number 1 accounting for $\\sim 30\\%$ of all numbers\nin the dataset and digits that start with the number 9 accounting for $\\sim\n5\\%$ of all numbers in the dataset. This phenomenon, known as Benford's Law, is\nhighly repeatable and appears in lists of numbers from electricity bills, stock\nprices, tax returns, house prices, death rates, lengths of rivers, and\nnaturally occurring images. In this paper we demonstrate that human speech\nspectra also follow Benford's Law. We use this observation to motivate a new\nset of features that can be efficiently extracted from speech and demonstrate\nthat these features can be used to classify between human speech and synthetic\nspeech.",
    "descriptor": "",
    "authors": [
      "Leo Hsu",
      "Visar Berisha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13352"
  },
  {
    "id": "arXiv:2203.13357",
    "title": "One Country, 700+ Languages: NLP Challenges for Underrepresented  Languages and Dialects in Indonesia",
    "abstract": "NLP research is impeded by a lack of resources and awareness of the\nchallenges presented by underrepresented languages and dialects. Focusing on\nthe languages spoken in Indonesia, the second most linguistically diverse and\nthe fourth most populous nation of the world, we provide an overview of the\ncurrent state of NLP research for Indonesia's 700+ languages. We highlight\nchallenges in Indonesian NLP and how these affect the performance of current\nNLP systems. Finally, we provide general recommendations to help develop NLP\ntechnology not only for languages of Indonesia but also other underrepresented\nlanguages.",
    "descriptor": "\nComments: Accepted in ACL 2022\n",
    "authors": [
      "Alham Fikri Aji",
      "Genta Indra Winata",
      "Fajri Koto",
      "Samuel Cahyawijaya",
      "Ade Romadhony",
      "Rahmad Mahendra",
      "Kemal Kurniawan",
      "David Moeljadi",
      "Radityo Eko Prasojo",
      "Timothy Baldwin",
      "Jey Han Lau",
      "Sebastian Ruder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13357"
  },
  {
    "id": "arXiv:2203.13366",
    "title": "Recommendation as Language Processing (RLP): A Unified Pretrain,  Personalized Prompt & Predict Paradigm (P5)",
    "abstract": "For a long period, different recommendation tasks typically require designing\ntask-specific architectures and training objectives. As a result, it is hard to\ntransfer the learned knowledge and representations from one task to another,\nthus restricting the generalization ability of existing recommendation\napproaches, e.g., a sequential recommendation model can hardly be applied or\ntransferred to a review generation method. To deal with such issues,\nconsidering that language grounding is a powerful medium to describe and\nrepresent various problems or tasks, we present a flexible and unified\ntext-to-text paradigm called \"Pretrain, Personalized Prompt, and Predict\nParadigm\" (P5) for recommendation, which unifies various recommendation tasks\nin a shared framework. In P5, all data such as user-item interactions, item\nmetadata, and user reviews are converted to a common format -- natural language\nsequences. The rich information from natural language assist P5 to capture\ndeeper semantics for recommendation. P5 learns different tasks with the same\nlanguage modeling objective during pretraining. Thus, it possesses the\npotential to serve as the foundation model for downstream recommendation tasks,\nallows easy integration with other modalities, and enables instruction-based\nrecommendation, which will revolutionize the technical form of recommender\nsystem towards unified recommendation engine. With adaptive personalized prompt\nfor different users, P5 is able to make predictions in a zero-shot or few-shot\nmanner and largely reduces the necessity for extensive fine-tuning. On several\nrecommendation benchmarks, we conduct experiments to show the effectiveness of\nour generative approach. We will release our prompts and pretrained P5 language\nmodel to help advance future research on Recommendation as Language Processing\n(RLP) and Personalized Foundation Models.",
    "descriptor": "",
    "authors": [
      "Shijie Geng",
      "Shuchang Liu",
      "Zuohui Fu",
      "Yingqiang Ge",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13366"
  },
  {
    "id": "arXiv:2203.13369",
    "title": "Gender and Racial Stereotype Detection in Legal Opinion Word Embeddings",
    "abstract": "Studies have shown that some Natural Language Processing (NLP) systems encode\nand replicate harmful biases with potential adverse ethical effects in our\nsociety. In this article, we propose an approach for identifying gender and\nracial stereotypes in word embeddings trained on judicial opinions from U.S.\ncase law. Embeddings containing stereotype information may cause harm when used\nby downstream systems for classification, information extraction, question\nanswering, or other machine learning systems used to build legal research\ntools. We first explain how previously proposed methods for identifying these\nbiases are not well suited for use with word embeddings trained on legal\nopinion text. We then propose a domain adapted method for identifying gender\nand racial biases in the legal domain. Our analyses using these methods suggest\nthat racial and gender biases are encoded into word embeddings trained on legal\nopinions. These biases are not mitigated by exclusion of historical data, and\nappear across multiple large topical areas of the law. Implications for\ndownstream systems that use legal opinion word embeddings and suggestions for\npotential mitigation strategies based on our observations are also discussed.",
    "descriptor": "\nComments: Accepted at AAAI-22, AI for Social Impact Track\n",
    "authors": [
      "Sean Matthews",
      "John Hudzina",
      "Dawn Sepehr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13369"
  },
  {
    "id": "arXiv:2203.13371",
    "title": "FitCLIP: Refining Large-Scale Pretrained Image-Text Models for Zero-Shot  Video Understanding Tasks",
    "abstract": "Large-scale pretrained image-text models have shown incredible zero-shot\nperformance in a handful of tasks, including video ones such as action\nrecognition and text-to-video retrieval. However, these models haven't been\nadapted to video, mainly because they don't account for the time dimension but\nalso because video frames are different from the typical images (e.g.,\ncontaining motion blur, less sharpness). In this paper, we present a\nfine-tuning strategy to refine these large-scale pretrained image-text models\nfor zero-shot video understanding tasks. We show that by carefully adapting\nthese models we obtain considerable improvements on two zero-shot Action\nRecognition tasks and three zero-shot Text-to-video Retrieval tasks. The code\nis available at https://github.com/bryant1410/fitclip",
    "descriptor": "",
    "authors": [
      "Santiago Castro",
      "Fabian Caba Heilbron"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13371"
  },
  {
    "id": "arXiv:2203.13380",
    "title": "Email Summarization to Assist Users in Phishing Identification",
    "abstract": "Cyber-phishing attacks recently became more precise, targeted, and tailored\nby training data to activate only in the presence of specific information or\ncues. They are adaptable to a much greater extent than traditional phishing\ndetection. Hence, automated detection systems cannot always be 100% accurate,\nincreasing the uncertainty around expected behavior when faced with a potential\nphishing email. On the other hand, human-centric defence approaches focus\nextensively on user training but face the difficulty of keeping users up to\ndate with continuously emerging patterns. Therefore, advances in analyzing the\ncontent of an email in novel ways along with summarizing the most pertinent\ncontent to the recipients of emails is a prospective gateway to furthering how\nto combat these threats. Addressing this gap, this work leverages\ntransformer-based machine learning to (i) analyze prospective psychological\ntriggers, to (ii) detect possible malicious intent, and (iii) create\nrepresentative summaries of emails. We then amalgamate this information and\npresent it to the user to allow them to (i) easily decide whether the email is\n\"phishy\" and (ii) self-learn advanced malicious patterns.",
    "descriptor": "\nComments: 3 pages, Accepted at the 17th ACM ASIA Conference on Computer and Communications Security (ACM ASIACCS 2022)\n",
    "authors": [
      "Amir Kashapov",
      "Tingmin Wu",
      "Alsharif Abuadbba",
      "Carsten Rudolph"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13380"
  },
  {
    "id": "arXiv:2203.13381",
    "title": "Probing Representation Forgetting in Supervised and Unsupervised  Continual Learning",
    "abstract": "Continual Learning research typically focuses on tackling the phenomenon of\ncatastrophic forgetting in neural networks. Catastrophic forgetting is\nassociated with an abrupt loss of knowledge previously learned by a model when\nthe task, or more broadly the data distribution, being trained on changes. In\nsupervised learning problems this forgetting, resulting from a change in the\nmodel's representation, is typically measured or observed by evaluating the\ndecrease in old task performance. However, a model's representation can change\nwithout losing knowledge about prior tasks. In this work we consider the\nconcept of representation forgetting, observed by using the difference in\nperformance of an optimal linear classifier before and after a new task is\nintroduced. Using this tool we revisit a number of standard continual learning\nbenchmarks and observe that, through this lens, model representations trained\nwithout any explicit control for forgetting often experience small\nrepresentation forgetting and can sometimes be comparable to methods which\nexplicitly control for forgetting, especially in longer task sequences. We also\nshow that representation forgetting can lead to new insights on the effect of\nmodel capacity and loss function used in continual learning. Based on our\nresults, we show that a simple yet competitive approach is to learn\nrepresentations continually with standard supervised contrastive learning while\nconstructing prototypes of class samples when queried on old samples.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "MohammadReza Davari",
      "Nader Asadi",
      "Sudhir Mudur",
      "Rahaf Aljundi",
      "Eugene Belilovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13381"
  },
  {
    "id": "arXiv:2203.13382",
    "title": "Fast multigrid reduction-in-time for advection via modified  semi-Lagrangian coarse-grid operators",
    "abstract": "Many iterative parallel-in-time algorithms have been shown to be highly\nefficient for diffusion-dominated partial differential equations (PDEs), but\nare inefficient or even divergent when applied to advection-dominated PDEs. We\nconsider the application of the multigrid reduction-in-time (MGRIT) algorithm\nto linear advection PDEs. The key to efficient time integration with this\nmethod is using a coarse-grid operator that provides a sufficiently accurate\napproximation to the the so-called ideal coarse-grid operator. For certain\nclasses of semi-Lagrangian discretizations, we present a novel\nsemi-Lagrangian-based coarse-grid operator that leads to fast and scalable\nmultilevel time integration of linear advection PDEs. The coarse-grid operator\nis composed of a semi-Lagrangian discretization followed by a correction term,\nwith the correction designed so that the leading-order truncation error of the\ncomposite operator is approximately equal to that of the ideal coarse-grid\noperator. Parallel results show substantial speed-ups over sequential time\nintegration for variable-wave-speed advection problems in one and two spatial\ndimensions, and using high-order discretizations up to order five. The proposed\napproach establishes the first practical method that provides small and\nscalable MGRIT iteration counts for advection problems.",
    "descriptor": "",
    "authors": [
      "H. De Sterck",
      "R. D. Falgout",
      "O. A. Krzysik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.13382"
  },
  {
    "id": "arXiv:2203.13387",
    "title": "CrossFormer: Cross Spatio-Temporal Transformer for 3D Human Pose  Estimation",
    "abstract": "3D human pose estimation can be handled by encoding the geometric\ndependencies between the body parts and enforcing the kinematic constraints.\nRecently, Transformer has been adopted to encode the long-range dependencies\nbetween the joints in the spatial and temporal domains. While they had shown\nexcellence in long-range dependencies, studies have noted the need for\nimproving the locality of vision Transformers. In this direction, we propose a\nnovel pose estimation Transformer featuring rich representations of body joints\ncritical for capturing subtle changes across frames (i.e., inter-feature\nrepresentation). Specifically, through two novel interaction modules;\nCross-Joint Interaction and Cross-Frame Interaction, the model explicitly\nencodes the local and global dependencies between the body joints. The proposed\narchitecture achieved state-of-the-art performance on two popular 3D human pose\nestimation datasets, Human3.6 and MPI-INF-3DHP. In particular, our proposed\nCrossFormer method boosts performance by 0.9% and 0.3%, compared to the closest\ncounterpart, PoseFormer, using the detected 2D poses and ground-truth settings\nrespectively.",
    "descriptor": "",
    "authors": [
      "Mohammed Hassanin",
      "Abdelwahed Khamiss",
      "Mohammed Bennamoun",
      "Farid Boussaid",
      "Ibrahim Radwan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13387"
  },
  {
    "id": "arXiv:2203.13392",
    "title": "Automated Algorithm Selection: from Feature-Based to Feature-Free  Approaches",
    "abstract": "We propose a novel technique for algorithm-selection, applicable to\noptimisation domains in which there is implicit sequential information\nencapsulated in the data, e.g., in online bin-packing. Specifically we train\ntwo types of recurrent neural networks to predict a packing heuristic in online\nbin-packing, selecting from four well-known heuristics. As input, the RNN\nmethods only use the sequence of item-sizes. This contrasts to typical\napproaches to algorithm-selection which require a model to be trained using\ndomain-specific instance features that need to be first derived from the input\ndata. The RNN approaches are shown to be capable of achieving within 5% of the\noracle performance on between 80.88% to 97.63% of the instances, depending on\nthe dataset. They are also shown to outperform classical machine learning\nmodels trained using derived features. Finally, we hypothesise that the\nproposed methods perform well when the instances exhibit some implicit\nstructure that results in discriminatory performance with respect to a set of\nheuristics. We test this hypothesis by generating fourteen new datasets with\nincreasing levels of structure, and show that there is a critical threshold of\nstructure required before algorithm-selection delivers benefit.",
    "descriptor": "\nComments: pre-print paper\n",
    "authors": [
      "Mohamad Alissa",
      "Kevin Sim",
      "Emma Hart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.13392"
  },
  {
    "id": "arXiv:2203.13394",
    "title": "Point2Seq: Detecting 3D Objects as Sequences",
    "abstract": "We present a simple and effective framework, named Point2Seq, for 3D object\ndetection from point clouds. In contrast to previous methods that normally\n{predict attributes of 3D objects all at once}, we expressively model the\ninterdependencies between attributes of 3D objects, which in turn enables a\nbetter detection accuracy. Specifically, we view each 3D object as a sequence\nof words and reformulate the 3D object detection task as decoding words from 3D\nscenes in an auto-regressive manner. We further propose a lightweight\nscene-to-sequence decoder that can auto-regressively generate words conditioned\non features from a 3D scene as well as cues from the preceding words. The\npredicted words eventually constitute a set of sequences that completely\ndescribe the 3D objects in the scene, and all the predicted sequences are then\nautomatically assigned to the respective ground truths through similarity-based\nsequence matching. Our approach is conceptually intuitive and can be readily\nplugged upon most existing 3D-detection backbones without adding too much\ncomputational overhead; the sequential decoding paradigm we proposed, on the\nother hand, can better exploit information from complex 3D scenes with the aid\nof preceding predicted words. Without bells and whistles, our method\nsignificantly outperforms previous anchor- and center-based 3D object detection\nframeworks, yielding the new state of the art on the challenging ONCE dataset\nas well as the Waymo Open Dataset. Code is available at\n\\url{https://github.com/ocNflag/point2seq}.",
    "descriptor": "\nComments: To appear in CVPR2022\n",
    "authors": [
      "Yujing Xue",
      "Jiageng Mao",
      "Minzhe Niu",
      "Hang Xu",
      "Michael Bi Mi",
      "Wei Zhang",
      "Xiaogang Wang",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13394"
  },
  {
    "id": "arXiv:2203.13395",
    "title": "Using Reinforcement Learning to Study Platform Economies under Market  Shocks",
    "abstract": "Driven by rapid digitization and expansive internet access, market-driven\nplatforms (e.g., Amazon, DoorDash, Uber, TaskRabbit) are increasingly prevalent\nand becoming key drivers of the economy. Across many industries, platforms\nleverage digital infrastructure to efficiently match producers and consumers,\ndynamically set prices, and enable economies of scale. This increasing\nprominence makes it important to understand the behavior of platforms, which\ninduces complex phenomenon especially in the presence of severe market shocks\n(e.g., during pandemics). In this work, we develop a multi-agent simulation\nenvironment to capture key elements of a platform economy, including the kinds\nof economic shocks that disrupt a traditional, off-platform market. We use deep\nreinforcement learning (RL) to model the pricing and matching behavior of a\nplatform that optimizes for revenue and various socially-aware objectives. We\nstart with tractable motivating examples to establish intuitions about the\ndynamics and function of optimal platform policies. We then conduct extensive\nempirical simulations on multi-period environments, including settings with\nmarket shocks. We characterize the effect of a platform on the efficiency and\nresilience of an economic system under different platform design objectives. We\nfurther analyze the consequences of regulation fixing platform fees, and study\nthe alignment of a revenue-maximizing platform with social welfare under\ndifferent platform matching policies. As such, our RL-based framework provides\na foundation for understanding platform economies under different designs and\nfor yielding new economic insights that are beyond analytical tractability.",
    "descriptor": "",
    "authors": [
      "Xintong Wang",
      "Gary Qiurui Ma",
      "Alon Eden",
      "Clara Li",
      "Alexander Trott",
      "Stephan Zheng",
      "David C. Parkes"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.13395"
  },
  {
    "id": "arXiv:2203.13396",
    "title": "HetSched: Quality-of-Mission Aware Scheduling for Autonomous Vehicle  SoCs",
    "abstract": "Systems-on-Chips (SoCs) that power autonomous vehicles (AVs) must meet\nstringent performance and safety requirements prior to deployment. With\nincreasing complexity in AV applications, the system needs to meet these\nreal-time demands of multiple safety-critical applications simultaneously. A\ntypical AV-SoC is a heterogeneous multiprocessor consisting of accelerators\nsupported by general-purpose cores. Such heterogeneity, while needed for\npower-performance efficiency, complicates the art of task scheduling.\nIn this paper, we demonstrate that hardware heterogeneity impacts the\nscheduler's effectiveness and that optimizing for only the real-time aspect of\napplications is not sufficient in AVs. Therefore, a more holistic approach is\nrequired -- one that considers global Quality-of-Mission (QoM) metrics, as\ndefined in the paper. We then propose HetSched, a multi-step scheduler that\nleverages dynamic runtime information about the underlying heterogeneous\nhardware platform, along with the applications' real-time constraints and the\ntask traffic in the system to optimize overall mission performance. HetSched\nproposes two scheduling policies: MSstat and MSdyn and scheduling optimizations\nlike task pruning, hybrid heterogeneous ranking and rank update. HetSched\nimproves overall mission performance on average by 4.6x, 2.6x and 2.6x when\ncompared against CPATH, ADS and 2lvl-EDF (state-of-the-art real-time schedulers\nbuilt for heterogeneous systems), respectively, and achieves an average of\n53.3% higher hardware utilization, while meeting 100% critical deadlines for\nreal-world applications of autonomous vehicles. Furthermore, when used as part\nof an SoC design space exploration loop, in comparison to prior schedulers,\nHetSched reduces the number of processing elements required by an SoC to safely\ncomplete AV's missions by 35% on average while achieving 2.7x lower\nenergy-mission time product.",
    "descriptor": "\nComments: 14 pages, 11 figures, 4 tables\n",
    "authors": [
      "Aporva Amarnath",
      "Subhankar Pal",
      "Hiwot Kassa",
      "Augusto Vega",
      "Alper Buyuktosunoglu",
      "Hubertus Franke",
      "John-David Wellman",
      "Ronald Dreslinski",
      "Pradip Bose"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2203.13396"
  },
  {
    "id": "arXiv:2203.13397",
    "title": "GPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate  Degradation of Artificial Neural Language Models",
    "abstract": "Deep learning (DL) techniques involving fine-tuning large numbers of model\nparameters have delivered impressive performance on the task of discriminating\nbetween language produced by cognitively healthy individuals, and those with\nAlzheimer's disease (AD). However, questions remain about their ability to\ngeneralize beyond the small reference sets that are publicly available for\nresearch. As an alternative to fitting model parameters directly, we propose a\nnovel method by which a Transformer DL model (GPT-2) pre-trained on general\nEnglish text is paired with an artificially degraded version of itself (GPT-D),\nto compute the ratio between these two models' \\textit{perplexities} on\nlanguage from cognitively healthy and impaired individuals. This technique\napproaches state-of-the-art performance on text data from a widely used \"Cookie\nTheft\" picture description task, and unlike established alternatives also\ngeneralizes well to spontaneous conversations. Furthermore, GPT-D generates\ntext with characteristics known to be associated with AD, demonstrating the\ninduction of dementia-related linguistic anomalies. Our study is a step toward\nbetter understanding of the relationships between the inner workings of\ngenerative neural language models, the language that they produce, and the\ndeleterious effects of dementia on human speech and language characteristics.",
    "descriptor": "\nComments: This paper has been accepted by ACL 2022\n",
    "authors": [
      "Changye Li",
      "David Knopman",
      "Weizhe Xu",
      "Trevor Cohen",
      "Serguei Pakhomov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13397"
  },
  {
    "id": "arXiv:2203.13409",
    "title": "Multi-scale and Cross-scale Contrastive Learning for Semantic  Segmentation",
    "abstract": "This work considers supervised contrastive learning for semantic\nsegmentation. Our approach is model agnostic. We apply contrastive learning to\nenhance the discriminative power of the multi-scale features extracted by\nsemantic segmentation networks. Our key methodological insight is to leverage\nsamples from the feature spaces emanating from multiple stages of a model's\nencoder itself requiring neither data augmentation nor online memory banks to\nobtain a diverse set of samples. To allow for such an extension we introduce an\nefficient and effective sampling process, that enables applying contrastive\nlosses over the encoder's features at multiple scales. Furthermore, by first\nmapping the encoder's multi-scale representations to a common feature space, we\ninstantiate a novel form of supervised local-global constraint by introducing\ncross-scale contrastive learning linking high-resolution local features to\nlow-resolution global features. Combined, our multi-scale and cross-scale\ncontrastive losses boost performance of various models (DeepLabV3, HRNet,\nOCRNet, UPerNet) with both CNN and Transformer backbones, when evaluated on 4\ndiverse datasets from natural (Cityscapes, PascalContext, ADE20K) but also\nsurgical (CaDIS) domains.",
    "descriptor": "",
    "authors": [
      "Theodoros Pissas",
      "Claudio S. Ravasio",
      "Lyndon Da Cruz",
      "Christos Bergeles"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13409"
  },
  {
    "id": "arXiv:2203.13410",
    "title": "Qualitative neural network approximation over R and C: Elementary proofs  for analytic and polynomial activation",
    "abstract": "In this article, we prove approximation theorems in classes of deep and\nshallow neural networks with analytic activation functions by elementary\narguments. We prove for both real and complex networks with non-polynomial\nactivation that the closure of the class of neural networks coincides with the\nclosure of the space of polynomials. The closure can further be characterized\nby the Stone-Weierstrass theorem (in the real case) and Mergelyan's theorem (in\nthe complex case). In the real case, we further prove approximation results for\nnetworks with higher-dimensional harmonic activation and orthogonally projected\nlinear maps. We further show that fully connected and residual networks of\nlarge depth with polynomial activation functions can approximate any polynomial\nunder certain width requirements. All proofs are entirely elementary.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Josiah Park",
      "Stephan Wojtowytsch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13410"
  },
  {
    "id": "arXiv:2203.13411",
    "title": "Reshaping Robot Trajectories Using Natural Language Commands: A Study of  Multi-Modal Data Alignment Using Transformers",
    "abstract": "Natural language is the most intuitive medium for us to interact with other\npeople when expressing commands and instructions. However, using language is\nseldom an easy task when humans need to express their intent towards robots,\nsince most of the current language interfaces require rigid templates with a\nstatic set of action targets and commands. In this work, we provide a flexible\nlanguage-based interface for human-robot collaboration, which allows a user to\nreshape existing trajectories for an autonomous agent. We take advantage of\nrecent advancements in the field of large language models (BERT and CLIP) to\nencode the user command, and then combine these features with trajectory\ninformation using multi-modal attention transformers. We train the model using\nimitation learning over a dataset containing robot trajectories modified by\nlanguage commands, and treat the trajectory generation process as a sequence\nprediction problem, analogously to how language generation architectures\noperate. We evaluate the system in multiple simulated trajectory scenarios, and\nshow a significant performance increase of our model over baseline approaches.\nIn addition, our real-world experiments with a robot arm show that users\nsignificantly prefer our natural language interface over traditional methods\nsuch as kinesthetic teaching or cost-function programming. Our study shows how\nthe field of robotics can take advantage of large pre-trained language models\ntowards creating more intuitive interfaces between robots and machines. Project\nwebpage: https://arthurfenderbucker.github.io/NL_trajectory_reshaper/",
    "descriptor": "",
    "authors": [
      "Arthur Bucker",
      "Luis Figueredo",
      "Sami Haddadin",
      "Ashish Kapoor",
      "Shuang Ma",
      "Rogerio Bonatti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.13411"
  },
  {
    "id": "arXiv:2203.13412",
    "title": "Self-Supervised Predictive Learning: A Negative-Free Method for Sound  Source Localization in Visual Scenes",
    "abstract": "Sound source localization in visual scenes aims to localize objects emitting\nthe sound in a given image. Recent works showing impressive localization\nperformance typically rely on the contrastive learning framework. However, the\nrandom sampling of negatives, as commonly adopted in these methods, can result\nin misalignment between audio and visual features and thus inducing ambiguity\nin localization. In this paper, instead of following previous literature, we\npropose Self-Supervised Predictive Learning (SSPL), a negative-free method for\nsound localization via explicit positive mining. Specifically, we first devise\na three-stream network to elegantly associate sound source with two augmented\nviews of one corresponding video frame, leading to semantically coherent\nsimilarities between audio and visual features. Second, we introduce a novel\npredictive coding module for audio-visual feature alignment. Such a module\nassists SSPL to focus on target objects in a progressive manner and effectively\nlowers the positive-pair learning difficulty. Experiments show surprising\nresults that SSPL outperforms the state-of-the-art approach on two standard\nsound localization benchmarks. In particular, SSPL achieves significant\nimprovements of 8.6% cIoU and 3.4% AUC on SoundNet-Flickr compared to the\nprevious best. Code is available at: https://github.com/zjsong/SSPL.",
    "descriptor": "\nComments: Camera-ready, CVPR 2022. Code: this https URL\n",
    "authors": [
      "Zengjie Song",
      "Yuxi Wang",
      "Junsong Fan",
      "Tieniu Tan",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13412"
  },
  {
    "id": "arXiv:2203.13420",
    "title": "Automatic Song Translation for Tonal Languages",
    "abstract": "This paper develops automatic song translation (AST) for tonal languages and\naddresses the unique challenge of aligning words' tones with melody of a song\nin addition to conveying the original meaning. We propose three criteria for\neffective AST -- preserving meaning, singability and intelligibility -- and\ndesign metrics for these criteria. We develop a new benchmark for\nEnglish--Mandarin song translation and develop an unsupervised AST system,\nGuided AliGnment for Automatic Song Translation (GagaST), which combines\npre-training with three decoding constraints. Both automatic and human\nevaluations show GagaST successfully balances semantics and singability.",
    "descriptor": "\nComments: Accepted at Findings of ACL 2022, 15 pages, 4 Tables and 10 Figures\n",
    "authors": [
      "Fenfei Guo",
      "Chen Zhang",
      "Zhirui Zhang",
      "Qixin He",
      "Kejun Zhang",
      "Jun Xie",
      "Jordan Boyd-Graber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13420"
  },
  {
    "id": "arXiv:2203.13421",
    "title": "Learning Losses for Strategic Classification",
    "abstract": "Strategic classification, i.e. classification under possible strategic\nmanipulations of features, has received a lot of attention from both the\nmachine learning and the game theory community. Most works focus on analysing\nproperties of the optimal decision rule under such manipulations. In our work\nwe take a learning theoretic perspective, focusing on the sample complexity\nneeded to learn a good decision rule which is robust to strategic manipulation.\nWe perform this analysis by introducing a novel loss function, the\n\\emph{strategic manipulation loss}, which takes into account both the accuracy\nof the final decision rule and its vulnerability to manipulation. We analyse\nthe sample complexity for a known graph of possible manipulations in terms of\nthe complexity of the function class and the manipulation graph. Additionally,\nwe initialize the study of learning under unknown manipulation capabilities of\nthe involved agents. Using techniques from transfer learning theory, we define\na similarity measure for manipulation graphs and show that learning outcomes\nare robust with respect to small changes in the manipulation graph. Lastly, we\nanalyse the (sample complexity of) learning of the manipulation capability of\nagents with respect to this similarity measure, providing novel guarantees for\nstrategic classification with respect to an unknown manipulation graph.",
    "descriptor": "\nComments: This paper will appear in the proceedings of AAAI 2022\n",
    "authors": [
      "Tosca Lechner",
      "Ruth Urner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13421"
  },
  {
    "id": "arXiv:2203.13423",
    "title": "Modeling Attrition in Recommender Systems with Departing Bandits",
    "abstract": "Traditionally, when recommender systems are formalized as multi-armed\nbandits, the policy of the recommender system influences the rewards accrued,\nbut not the length of interaction. However, in real-world systems, dissatisfied\nusers may depart (and never come back). In this work, we propose a novel\nmulti-armed bandit setup that captures such policy-dependent horizons. Our\nsetup consists of a finite set of user types, and multiple arms with Bernoulli\npayoffs. Each (user type, arm) tuple corresponds to an (unknown) reward\nprobability. Each user's type is initially unknown and can only be inferred\nthrough their response to recommendations. Moreover, if a user is dissatisfied\nwith their recommendation, they might depart the system. We first address the\ncase where all users share the same type, demonstrating that a recent UCB-based\nalgorithm is optimal. We then move forward to the more challenging case, where\nusers are divided among two types. While naive approaches cannot handle this\nsetting, we provide an efficient learning algorithm that achieves\n$\\tilde{O}(\\sqrt{T})$ regret, where $T$ is the number of users.",
    "descriptor": "\nComments: Accepted at AAAI 2022\n",
    "authors": [
      "Omer Ben-Porat",
      "Lee Cohen",
      "Liu Leqi",
      "Zachary C. Lipton",
      "Yishay Mansour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13423"
  },
  {
    "id": "arXiv:2203.13424",
    "title": "Dealing with Sparse Rewards Using Graph Neural Networks",
    "abstract": "Deep reinforcement learning in partially observable environments is a\ndifficult task in itself, and can be further complicated by a sparse reward\nsignal. Most tasks involving navigation in three-dimensional environments\nprovide the agent with extremely limited information. Typically, the agent\nreceives a visual observation input from the environment and is rewarded once\nat the end of the episode. A good reward function could substantially improve\nthe convergence of reinforcement learning algorithms for such tasks. The\nclassic approach to increase the density of the reward signal is to augment it\nwith supplementary rewards. This technique is called the reward shaping. In\nthis study, we propose two modifications of one of the recent reward shaping\nmethods based on graph convolutional networks: the first involving advanced\naggregation functions, and the second utilizing the attention mechanism. We\nempirically validate the effectiveness of our solutions for the task of\nnavigation in a 3D environment with sparse rewards. For the solution featuring\nattention mechanism, we are also able to show that the learned attention is\nconcentrated on edges corresponding to important transitions in 3D environment.",
    "descriptor": "",
    "authors": [
      "Matvey Gerasyov",
      "Ilya Makarov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.13424"
  },
  {
    "id": "arXiv:2203.13427",
    "title": "Noisy Boundaries: Lemon or Lemonade for Semi-supervised Instance  Segmentation?",
    "abstract": "Current instance segmentation methods rely heavily on pixel-level annotated\nimages. The huge cost to obtain such fully-annotated images restricts the\ndataset scale and limits the performance. In this paper, we formally address\nsemi-supervised instance segmentation, where unlabeled images are employed to\nboost the performance. We construct a framework for semi-supervised instance\nsegmentation by assigning pixel-level pseudo labels. Under this framework, we\npoint out that noisy boundaries associated with pseudo labels are double-edged.\nWe propose to exploit and resist them in a unified manner simultaneously: 1) To\ncombat the negative effects of noisy boundaries, we propose a noise-tolerant\nmask head by leveraging low-resolution features. 2) To enhance the positive\nimpacts, we introduce a boundary-preserving map for learning detailed\ninformation within boundary-relevant regions. We evaluate our approach by\nextensive experiments. It behaves extraordinarily, outperforming the supervised\nbaseline by a large margin, more than 6% on Cityscapes, 7% on COCO and 4.5% on\nBDD100k. On Cityscapes, our method achieves comparable performance by utilizing\nonly 30% labeled images.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Zhenyu Wang",
      "Yali Li",
      "Shengjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13427"
  },
  {
    "id": "arXiv:2203.13429",
    "title": "Risk-Aware Off-Road Navigation via a Learned Speed Distribution Map",
    "abstract": "Motion planning in off-road environments requires reasoning about both the\ngeometry and semantics of the scene (e.g., a robot may be able to drive through\nsoft bushes but not a fallen log). In many recent works, the world is\nclassified into a finite number of semantic categories that often are not\nsufficient to capture the ability (i.e., the speed) with which a robot can\ntraverse off-road terrain. Instead, this work proposes a new representation of\ntraversability based exclusively on robot speed that can be learned from data,\noffers interpretability and intuitive tuning, and can be easily integrated with\na variety of planning paradigms in the form of a costmap. Specifically, given a\ndataset of experienced trajectories, the proposed algorithm learns to predict a\ndistribution of speeds the robot could achieve, conditioned on the environment\nsemantics and commanded speed. The learned speed distribution map is converted\ninto costmaps with a risk-aware cost term based on conditional value at risk\n(CVaR). Numerical simulations demonstrate that the proposed risk-aware planning\nalgorithm leads to faster average time-to-goals compared to a method that only\nconsiders expected behavior, and the planner can be tuned for slightly slower,\nbut less variable behavior. Furthermore, the approach is integrated into a full\nautonomy stack and demonstrated in a high-fidelity Unity environment and is\nshown to provide a 30\\% improvement in the success rate of navigation.",
    "descriptor": "\nComments: 7 pages and 9 figures\n",
    "authors": [
      "Xiaoyi Cai",
      "Michael Everett",
      "Jonathan Fink",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.13429"
  },
  {
    "id": "arXiv:2203.13430",
    "title": "Plagiarism Detection in the Bengali Language: A Text Similarity-Based  Approach",
    "abstract": "Plagiarism means taking another person's work and not giving any credit to\nthem for it. Plagiarism is one of the most serious problems in academia and\namong researchers. Even though there are multiple tools available to detect\nplagiarism in a document but most of them are domain-specific and designed to\nwork in English texts, but plagiarism is not limited to a single language only.\nBengali is the most widely spoken language of Bangladesh and the second most\nspoken language in India with 300 million native speakers and 37 million\nsecond-language speakers. Plagiarism detection requires a large corpus for\ncomparison. Bengali Literature has a history of 1300 years. Hence most Bengali\nLiterature books are not yet digitalized properly. As there was no such corpus\npresent for our purpose so we have collected Bengali Literature books from the\nNational Digital Library of India and with a comprehensive methodology\nextracted texts from it and constructed our corpus. Our experimental results\nfind out average accuracy between 72.10 % - 79.89 % in text extraction using\nOCR. Levenshtein Distance algorithm is used for determining Plagiarism. We have\nbuilt a web application for end-user and successfully tested it for Plagiarism\ndetection in Bengali texts. In future, we aim to construct a corpus with more\nbooks for more accurate detection.",
    "descriptor": "\nComments: A preprint is done on preprints.org\n",
    "authors": [
      "Satyajit Ghosh",
      "Aniruddha Ghosh",
      "Bittaswer Ghosh",
      "Abhishek Roy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13430"
  },
  {
    "id": "arXiv:2203.13431",
    "title": "Aspect-Oriented Programming based building block platform to construct  Domain-Specific Language for HPC application",
    "abstract": "The world of HPC systems is changing to a more complicated system because the\nperformance improvement of processors has been slowed down. One of the\npromising approaches is Domain-Specific Language(DSL), which provides a\nproductive environment to create a high-efficient program without pain.\nHowever, existing DSL platforms themselves often lack portability and cost DSL\ndevelopers great effort. To solve this issue, we propose an Aspect-Oriented\nProgramming(AOP) based DSL constructing platform, enabling developers to build\na DSL platform by combining Aspect modules. Aspect modules manage abstracted\napplication flow, data structure, and memory access on our platform. Therefore,\ndevelopers can create any DSL platform whose target application has the\nattributes which HPC applications usually have, the abstraction assumes. This\nstudy implemented a prototype platform that can handle MPI and OpenMP layers.\nThe prototype supports three types of applications (Structured-Grid,\nUnstructured-Grid, and Particle Simulation). Then, we evaluated the overheads\ncaused by achieving flexibility and productivity of the platform.",
    "descriptor": "",
    "authors": [
      "Osamu Ishimura",
      "Yoshihide Yoshimoto"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.13431"
  },
  {
    "id": "arXiv:2203.13432",
    "title": "Nash Neural Networks : Inferring Utilities from Optimal Behaviour",
    "abstract": "We propose Nash Neural Networks ($N^3$) as a new type of Physics Informed\nNeural Network that is able to infer the underlying utility from observations\nof how rational individuals behave in a differential game with a Nash\nequilibrium. We assume that the dynamics for both the population and the\nindividual are known, but not the payoff function, which specifies the cost per\nunit time of being in any particular state. We construct our network in such a\nway that the Euler-Lagrange equations of the corresponding optimal control\nproblem are satisfied and the optimal control is self-consistently determined.\nIn this way, we are able to learn the unknown payoff function in an\nunsupervised manner. We have applied the $N^3$ to study the optimal behaviour\nduring epidemics, in which individuals can choose to socially distance\ndepending on the state of the pandemic and the cost of being infected. Training\nour network against synthetic data for a simple SIR model, we showed that it is\npossible to accurately reproduce the hidden payoff function, in such a way that\nthe game dynamics are respected. Our approach will have far-reaching\napplications, as it allows one to infer utilities from behavioural data, and\ncan thus be applied to study a wide array of problems in science, engineering,\neconomics and government planning.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "John J. Molina",
      "Simon K. Schnyder",
      "Matthew S. Turner",
      "Ryoichi Yamamoto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2203.13432"
  },
  {
    "id": "arXiv:2203.13435",
    "title": "Independent set reconfiguration on directed graphs",
    "abstract": "\\textsc{Directed Token Sliding} asks, given a directed graph and two sets of\npairwise nonadjacent vertices, whether one can reach from one set to the other\nby repeatedly applying a local operation that exchanges a vertex in the current\nset with one of its out-neighbors, while keeping the nonadjacency. It can be\nseen as a reconfiguration process where a token is placed on each vertex in the\ncurrent set, and the local operation slides a token along an arc respecting its\ndirection. Previously, such a problem was extensively studied on undirected\ngraphs, where the edges have no directions and thus the local operation is\nsymmetric. \\textsc{Directed Token Sliding} is a generalization of its\nundirected variant since an undirected edge can be simulated by two arcs of\nopposite directions.\nIn this paper, we initiate the algorithmic study of \\textsc{Directed Token\nSliding}. We first observe that the problem is PSPACE-complete even if we\nforbid parallel arcs in opposite directions and that the problem on directed\nacyclic graphs is NP-complete and W[1]-hard parameterized by the size of the\nsets in consideration. We then show our main result: a linear-time algorithm\nfor the problem on directed graphs whose underlying undirected graphs are\ntrees, which are called polytrees. Such a result is also known for the\nundirected variant of the problem on trees~[Demaine et al.~TCS 2015], but the\ntechniques used here are quite different because of the asymmetric nature of\nthe directed problem. We present a characterization of yes-instances based on\nthe existence of a certain set of directed paths, and then derive simple\nequivalent conditions from it by some observations, which admits an efficient\nalgorithm. For the polytree case, we also present a quadratic-time algorithm\nthat outputs, if the input is a yes-instance, one of the shortest\nreconfiguration sequences.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Takehiro Ito",
      "Yuni Iwamasa",
      "Yasuaki Kobayashi",
      "Yu Nakahata",
      "Yota Otachi",
      "Masahiro Takahashi",
      "Kunihiro Wasa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.13435"
  },
  {
    "id": "arXiv:2203.13436",
    "title": "Frame-level Prediction of Facial Expressions, Valence, Arousal and  Action Units for Mobile Devices",
    "abstract": "In this paper, we consider the problem of real-time video-based facial\nemotion analytics, namely, facial expression recognition, prediction of valence\nand arousal and detection of action unit points. We propose the novel\nframe-level emotion recognition algorithm by extracting facial features with\nthe single EfficientNet model pre-trained on AffectNet. As a result, our\napproach may be implemented even for video analytics on mobile devices.\nExperimental results for the large scale Aff-Wild2 database from the third\nAffective Behavior Analysis in-the-wild (ABAW) Competition demonstrate that our\nsimple model is significantly better when compared to the VggFace baseline. In\nparticular, our method is characterized by 0.15-0.2 higher performance measures\nfor validation sets in uni-task Expression Classification, Valence-Arousal\nEstimation and Expression Classification. Due to simplicity, our approach may\nbe considered as a new baseline for all four sub-challenges.",
    "descriptor": "\nComments: 6 pages, 2 figures, 5 tables\n",
    "authors": [
      "Andrey V. Savchenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13436"
  },
  {
    "id": "arXiv:2203.13437",
    "title": "BCOT: A Markerless High-Precision 3D Object Tracking Benchmark",
    "abstract": "Template-based 3D object tracking still lacks a high-precision benchmark of\nreal scenes due to the difficulty of annotating the accurate 3D poses of real\nmoving video objects without using markers. In this paper, we present a\nmulti-view approach to estimate the accurate 3D poses of real moving objects,\nand then use binocular data to construct a new benchmark for monocular\ntextureless 3D object tracking. The proposed method requires no markers, and\nthe cameras only need to be synchronous, relatively fixed as cross-view and\ncalibrated. Based on our object-centered model, we jointly optimize the object\npose by minimizing shape re-projection constraints in all views, which greatly\nimproves the accuracy compared with the single-view approach, and is even more\naccurate than the depth-based method. Our new benchmark dataset contains 20\ntextureless objects, 22 scenes, 404 video sequences and 126K images captured in\nreal scenes. The annotation error is guaranteed to be less than 2mm, according\nto both theoretical analysis and validation experiments. We re-evaluate the\nstate-of-the-art 3D object tracking methods with our dataset, reporting their\nperformance ranking in real scenes. Our BCOT benchmark and code can be found at\nhttps://ar3dv.github.io/BCOT-Benchmark/.",
    "descriptor": "",
    "authors": [
      "Jiachen Li",
      "Bin Wang",
      "Shiqiang Zhu",
      "Xin Cao",
      "Fan Zhong",
      "Wenxuan Chen",
      "Te Li",
      "Jason Gu",
      "Xueying Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13437"
  },
  {
    "id": "arXiv:2203.13438",
    "title": "Microstructure Surface Reconstruction from SEM Images: An Alternative to  Digital Image Correlation (DIC)",
    "abstract": "We reconstruct a 3D model of the surface of a material undergoing fatigue\ntesting and experiencing cracking. Specifically we reconstruct the surface\ndepth (out of plane intrusions and extrusions) and lateral (in-plane) motion\nfrom multiple views of the sample at the end of the experiment, combined with a\nreverse optical flow propagation backwards in time that utilizes interim single\nview images. These measurements can be mapped to a material strain tensor which\nhelps to understand material life and predict failure. This approach offers an\nalternative to the commonly used Digital Image Correlation (DIC) technique\nwhich relies on tracking a speckle pattern applied to the material surface. DIC\nonly produces in-plane (2D) measurements whereas our approach is 3D and\nnon-invasive (requires no pattern being applied to the material).",
    "descriptor": "\nComments: 8 pages, 12 figures\n",
    "authors": [
      "Khalid El-Awady"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13438"
  },
  {
    "id": "arXiv:2203.13441",
    "title": "3D GAN Inversion for Controllable Portrait Image Animation",
    "abstract": "Millions of images of human faces are captured every single day; but these\nphotographs portray the likeness of an individual with a fixed pose,\nexpression, and appearance. Portrait image animation enables the post-capture\nadjustment of these attributes from a single image while maintaining a\nphotorealistic reconstruction of the subject's likeness or identity. Still,\ncurrent methods for portrait image animation are typically based on 2D warping\noperations or manipulations of a 2D generative adversarial network (GAN) and\nlack explicit mechanisms to enforce multi-view consistency. Thus these methods\nmay significantly alter the identity of the subject, especially when the\nviewpoint relative to the camera is changed. In this work, we leverage newly\ndeveloped 3D GANs, which allow explicit control over the pose of the image\nsubject with multi-view consistency. We propose a supervision strategy to\nflexibly manipulate expressions with 3D morphable models, and we show that the\nproposed method also supports editing appearance attributes, such as age or\nhairstyle, by interpolating within the latent space of the GAN. The proposed\ntechnique for portrait image animation outperforms previous methods in terms of\nimage quality, identity preservation, and pose transfer while also supporting\nattribute editing.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Connor Z. Lin",
      "David B. Lindell",
      "Eric R. Chan",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13441"
  },
  {
    "id": "arXiv:2203.13443",
    "title": "MDAN: Multi-level Dependent Attention Network for Visual Emotion  Analysis",
    "abstract": "Visual Emotion Analysis (VEA) is attracting increasing attention. One of the\nbiggest challenges of VEA is to bridge the affective gap between visual clues\nin a picture and the emotion expressed by the picture. As the granularity of\nemotions increases, the affective gap increases as well. Existing deep\napproaches try to bridge the gap by directly learning discrimination among\nemotions globally in one shot without considering the hierarchical relationship\namong emotions at different affective levels and the affective level of\nemotions to be classified. In this paper, we present the Multi-level Dependent\nAttention Network (MDAN) with two branches, to leverage the emotion hierarchy\nand the correlation between different affective levels and semantic levels. The\nbottom-up branch directly learns emotions at the highest affective level and\nstrictly follows the emotion hierarchy while predicting emotions at lower\naffective levels. In contrast, the top-down branch attempt to disentangle the\naffective gap by one-to-one mapping between semantic levels and affective\nlevels, namely, Affective Semantic Mapping. At each semantic level, a local\nclassifier learns discrimination among emotions at the corresponding affective\nlevel. Finally, We integrate global learning and local learning into a unified\ndeep framework and optimize the network simultaneously. Moreover, to properly\nextract and leverage channel dependencies and spatial attention while\ndisentangling the affective gap, we carefully designed two attention modules:\nthe Multi-head Cross Channel Attention module and the Level-dependent Class\nActivation Map module. Finally, the proposed deep framework obtains new\nstate-of-the-art performance on six VEA benchmarks, where it outperforms\nexisting state-of-the-art methods by a large margin, e.g., +3.85% on the WEBEmo\ndataset at 25 classes classification accuracy.",
    "descriptor": "\nComments: Published in CVPR 2022\n",
    "authors": [
      "Liwen Xu",
      "Zhengtao Wang",
      "Bin Wu",
      "Simon Lui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13443"
  },
  {
    "id": "arXiv:2203.13444",
    "title": "Vision Transformer Compression with Structured Pruning and Low Rank  Approximation",
    "abstract": "Transformer architecture has gained popularity due to its ability to scale\nwith large dataset. Consequently, there is a need to reduce the model size and\nlatency, especially for on-device deployment. We focus on vision transformer\nproposed for image recognition task (Dosovitskiy et al., 2021), and explore the\napplication of different compression techniques such as low rank approximation\nand pruning for this purpose. Specifically, we investigate a structured pruning\nmethod proposed recently in Zhu et al. (2021) and find that mostly feedforward\nblocks are pruned with this approach, that too, with severe degradation in\naccuracy. We propose a hybrid compression approach to mitigate this where we\ncompress the attention blocks using low rank approximation and use the\npreviously mentioned pruning with a lower rate for feedforward blocks in each\ntransformer layer. Our technique results in 50% compression with 14% relative\nincrease in classification error whereas we obtain 44% compression with 20%\nrelative increase in error when only pruning is applied. We propose further\nenhancements to bridge the accuracy gap but leave it as a future work.",
    "descriptor": "",
    "authors": [
      "Ankur Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13444"
  },
  {
    "id": "arXiv:2203.13445",
    "title": "C to Checked C by 3C",
    "abstract": "Owing to the continued use of C (and C++), spatial safety violations (e.g.,\nbuffer overflows) still constitute one of today's most dangerous and prevalent\nsecurity vulnerabilities. To combat these violations, Checked C extends C with\nbounds-enforced checked pointer types. Checked C is essentially a gradually\ntyped spatially safe C - checked pointers are backwards-binary compatible with\nlegacy pointers, and the language allows them to be added piecemeal, rather\nthan necessarily all at once, so that safety retrofitting can be incremental.\nThis paper presents a semi-automated process for porting a legacy C program to\nChecked C. The process centers on 3C, a static analysis-based annotation tool.\n3C employs two novel static analysis algorithms - typ3c and boun3c - to\nannotate legacy pointers as checked pointers, and to infer array bounds\nannotations for pointers that need them. 3C performs a root cause analysis to\ndirect a human developer to code that should be refactored; once done, 3C can\nbe re-run to infer further annotations (and updated root causes). Experiments\non 11 programs totaling 319KLoC show 3C to be effective at inferring checked\npointer types, and experience with previously and newly ported code finds 3C\nworks well when combined with human-driven refactoring.",
    "descriptor": "",
    "authors": [
      "Aravind Machiry",
      "John Kastner",
      "Matt McCutchen",
      "Aaron Eline",
      "Kyle Headley",
      "Michael Hicks"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.13445"
  },
  {
    "id": "arXiv:2203.13447",
    "title": "Component-wise Analysis of Automatically Designed Multiobjective  Algorithms on Constrained Problems",
    "abstract": "The performance of multiobjective algorithms varies across problems, making\nit hard to develop new algorithms or apply existing ones to new problems. To\nsimplify the development and application of new multiobjective algorithms,\nthere has been an increasing interest in their automatic design from component\nparts. These automatically designed metaheuristics can outperform their\nhuman-developed counterparts. However, it is still uncertain what are the most\ninfluential components leading to their performance improvement. This study\nintroduces a new methodology to investigate the effects of the final\nconfiguration of an automatically designed algorithm. We apply this methodology\nto a well-performing Multiobjective Evolutionary Algorithm Based on\nDecomposition (MOEA/D) designed by the irace package on nine constrained\nproblems. We then contrast the impact of the algorithm components in terms of\ntheir Search Trajectory Networks (STNs), the diversity of the population, and\nthe hypervolume. Our results indicate that the most influential components were\nthe restart and update strategies, with higher increments in performance and\nmore distinct metric values. Also, their relative influence depends on the\nproblem difficulty: not using the restart strategy was more influential in\nproblems where MOEA/D performs better; while the update strategy was more\ninfluential in problems where MOEA/D performs the worst.",
    "descriptor": "",
    "authors": [
      "Yuri Lavinas",
      "Gabriela Ochoa",
      "Claus Aranha"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13447"
  },
  {
    "id": "arXiv:2203.13448",
    "title": "AudioTagging Done Right: 2nd comparison of deep learning methods for  environmental sound classification",
    "abstract": "After its sweeping success in vision and language tasks, pure attention-based\nneural architectures (e.g. DeiT) are emerging to the top of audio tagging (AT)\nleaderboards, which seemingly obsoletes traditional convolutional neural\nnetworks (CNNs), feed-forward networks or recurrent networks. However, taking a\ncloser look, there is great variability in published research, for instance,\nperformances of models initialized with pretrained weights differ drastically\nfrom without pretraining, training time for a model varies from hours to weeks,\nand often, essences are hidden in seemingly trivial details. This urgently\ncalls for a comprehensive study since our 1st comparison is half-decade old. In\nthis work, we perform extensive experiments on AudioSet which is the largest\nweakly-labeled sound event dataset available, we also did an analysis based on\nthe data quality and efficiency. We compare a few state-of-the-art baselines on\nthe AT task, and study the performance and efficiency of 2 major categories of\nneural architectures: CNN variants and attention-based variants. We also\nclosely examine their optimization procedures. Our opensourced experimental\nresults provide insights to trade-off between performance, efficiency,\noptimization process, for both practitioners and researchers. Implementation:\nhttps://github.com/lijuncheng16/AudioTaggingDoneRight",
    "descriptor": "",
    "authors": [
      "Juncheng B Li",
      "Shuhui Qu",
      "Po-Yao",
      "Huang",
      "Florian Metze"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13448"
  },
  {
    "id": "arXiv:2203.13449",
    "title": "A Comparative Evaluation of Machine Learning Algorithms for the  Prediction of R/C Buildings' Seismic Damage",
    "abstract": "Seismic assessment of buildings and determination of their structural damage\nis at the forefront of modern scientific research. Since now, several\nresearchers have proposed a number of procedures, in an attempt to estimate the\ndamage response of the buildings subjected to strong ground motions, without\nconducting time-consuming analyses. These procedures, e.g. construction of\nfragility curves, usually utilize methods based on the application of\nstatistical theory. In the last decades, the increase of the computers' power\nhas led to the development of modern soft computing methods based on the\nadoption of Machine Learning algorithms. The present paper attempts an\nextensive comparative evaluation of the capability of various Machine Learning\nmethods to adequately predict the seismic response of R/C buildings. The\ntraining dataset is created by means of Nonlinear Time History Analyses of 90\n3D R/C buildings with three different masonry infills' distributions, which are\nsubjected to 65 earthquakes. The seismic damage is expressed in terms of the\nMaximum Interstory Drift Ratio. A large-scale comparison study is utilized by\nthe most efficient Machine Learning algorithms. The experimentation shows that\nthe LightGBM approach produces training stability, high overall performance and\na remarkable coefficient of determination to estimate the ability to predict\nthe buildings' damage response. Due to the extremely urgent issue, civil\nprotection mechanisms need to incorporate in their technological systems\nscientific methodologies and appropriate technical or modeling tools such as\nthe proposed one, which can offer valuable assistance in making optimal\ndecisions.",
    "descriptor": "",
    "authors": [
      "Konstantinos Demertzis",
      "Konstantinos Kostinakis",
      "Konstantinos Morfidis",
      "Lazaros Iliadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13449"
  },
  {
    "id": "arXiv:2203.13450",
    "title": "A Comparative Survey of Deep Active Learning",
    "abstract": "Active Learning (AL) is a set of techniques for reducing labeling cost by\nsequentially selecting data samples from a large unlabeled data pool for\nlabeling. Meanwhile, Deep Learning (DL) is data-hungry, and the performance of\nDL models scales monotonically with more training data. Therefore, in recent\nyears, Deep Active Learning (DAL) has risen as feasible solutions for\nmaximizing model performance while minimizing the expensive labeling cost.\nAbundant methods have sprung up and literature reviews of DAL have been\npresented before. However, the performance comparison of different branches of\nDAL methods under various tasks is still insufficient and our work fills this\ngap. In this paper, we survey and categorize DAL-related work and construct\ncomparative experiments across frequently used datasets and DAL algorithms.\nAdditionally, we explore some factors (e.g., batch size, number of epochs in\nthe training process) that influence the efficacy of DAL, which provides better\nreferences for researchers to design their own DAL experiments or carry out\nDAL-related applications. We construct a DAL toolkit, DeepAL+, by\nre-implementing many highly-cited DAL-related methods, and it will be released\nto the public.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Xueying Zhan",
      "Qingzhong Wang",
      "Kuan-hao Huang",
      "Haoyi Xiong",
      "Dejing Dou",
      "Antoni B. Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13450"
  },
  {
    "id": "arXiv:2203.13452",
    "title": "PCA-Based Knowledge Distillation Towards Lightweight and Content-Style  Balanced Photorealistic Style Transfer Models",
    "abstract": "Photorealistic style transfer entails transferring the style of a reference\nimage to another image so the result seems like a plausible photo. Our work is\ninspired by the observation that existing models are slow due to their large\nsizes. We introduce PCA-based knowledge distillation to distill lightweight\nmodels and show it is motivated by theory. To our knowledge, this is the first\nknowledge distillation method for photorealistic style transfer. Our\nexperiments demonstrate its versatility for use with different backbone\narchitectures, VGG and MobileNet, across six image resolutions. Compared to\nexisting models, our top-performing model runs at speeds 5-20x faster using at\nmost 1\\% of the parameters. Additionally, our distilled models achieve a better\nbalance between stylization strength and content preservation than existing\nmodels. To support reproducing our method and models, we share the code at\n\\textit{https://github.com/chiutaiyin/PCA-Knowledge-Distillation}.",
    "descriptor": "",
    "authors": [
      "Tai-Yin Chiu",
      "Danna Gurari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13452"
  },
  {
    "id": "arXiv:2203.13453",
    "title": "CNN LEGO: Disassembling and Assembling Convolutional Neural Network",
    "abstract": "Convolutional Neural Network (CNN), which mimics human visual perception\nmechanism, has been successfully used in many computer vision areas. Some\npsychophysical studies show that the visual perception mechanism synchronously\nprocesses the form, color, movement, depth, etc., in the initial stage [7,20]\nand then integrates all information for final recognition [38]. What's more,\nthe human visual system [20] contains different subdivisions or different\ntasks. Inspired by the above visual perception mechanism, we investigate a new\ntask, termed as Model Disassembling and Assembling (MDA-Task), which can\ndisassemble the deep models into independent parts and assemble those parts\ninto a new deep model without performance cost like playing LEGO toys. To this\nend, we propose a feature route attribution technique (FRAT) for disassembling\nCNN classifiers in this paper. In FRAT, the positive derivatives of predicted\nclass probability w.r.t. the feature maps are adopted to locate the critical\nfeatures in each layer. Then, relevance analysis between the critical features\nand preceding/subsequent parameter layers is adopted to bridge the route\nbetween two adjacent parameter layers. In the assembling phase, class-wise\ncomponents of each layer are assembled into a new deep model for a specific\ntask. Extensive experiments demonstrate that the assembled CNN classifier can\nachieve close accuracy with the original classifier without any fine-tune, and\nexcess original performance with one-epoch fine-tune. What's more, we also\nconduct massive experiments to verify the broad application of MDA-Task on\nmodel decision route visualization, model compression, knowledge distillation,\ntransfer learning, incremental learning, and so on.",
    "descriptor": "",
    "authors": [
      "Jiacong Hu",
      "Jing Gao",
      "Zunlei Feng",
      "Lechao Cheng",
      "Jie Lei",
      "Hujun Bao",
      "Mingli Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13453"
  },
  {
    "id": "arXiv:2203.13455",
    "title": "A Unified Contrastive Energy-based Model for Understanding the  Generative Ability of Adversarial Training",
    "abstract": "Adversarial Training (AT) is known as an effective approach to enhance the\nrobustness of deep neural networks. Recently researchers notice that robust\nmodels with AT have good generative ability and can synthesize realistic\nimages, while the reason behind it is yet under-explored. In this paper, we\ndemystify this phenomenon by developing a unified probabilistic framework,\ncalled Contrastive Energy-based Models (CEM). On the one hand, we provide the\nfirst probabilistic characterization of AT through a unified understanding of\nrobustness and generative ability. On the other hand, our unified framework can\nbe extended to the unsupervised scenario, which interprets unsupervised\ncontrastive learning as an important sampling of CEM. Based on these, we\npropose a principled method to develop adversarial learning and sampling\nmethods. Experiments show that the sampling methods derived from our framework\nimprove the sample quality in both supervised and unsupervised learning.\nNotably, our unsupervised adversarial sampling method achieves an Inception\nscore of 9.61 on CIFAR-10, which is superior to previous energy-based models\nand comparable to state-of-the-art generative models.",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Yifei Wang",
      "Yisen Wang",
      "Jiansheng Yang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13455"
  },
  {
    "id": "arXiv:2203.13457",
    "title": "Chaos is a Ladder: A New Theoretical Understanding of Contrastive  Learning via Augmentation Overlap",
    "abstract": "Recently, contrastive learning has risen to be a promising approach for\nlarge-scale self-supervised learning. However, theoretical understanding of how\nit works is still unclear. In this paper, we propose a new guarantee on the\ndownstream performance without resorting to the conditional independence\nassumption that is widely adopted in previous work but hardly holds in\npractice. Our new theory hinges on the insight that the support of different\nintra-class samples will become more overlapped under aggressive data\naugmentations, thus simply aligning the positive samples (augmented views of\nthe same sample) could make contrastive learning cluster intra-class samples\ntogether. Based on this augmentation overlap perspective, theoretically, we\nobtain asymptotically closed bounds for downstream performance under weaker\nassumptions, and empirically, we propose an unsupervised model selection metric\nARC that aligns well with downstream accuracy. Our theory suggests an\nalternative understanding of contrastive learning: the role of aligning\npositive samples is more like a surrogate task than an ultimate goal, and the\noverlapped augmented views (i.e., the chaos) create a ladder for contrastive\nlearning to gradually learn class-separated representations. The code for\ncomputing ARC is available at https://github.com/zhangq327/ARC.",
    "descriptor": "\nComments: Accepeted by ICLR 2022\n",
    "authors": [
      "Yifei Wang",
      "Qi Zhang",
      "Yisen Wang",
      "Jiansheng Yang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13457"
  },
  {
    "id": "arXiv:2203.13458",
    "title": "PANDORA: Polarization-Aided Neural Decomposition Of Radiance",
    "abstract": "Reconstructing an object's geometry and appearance from multiple images, also\nknown as inverse rendering, is a fundamental problem in computer graphics and\nvision. Inverse rendering is inherently ill-posed because the captured image is\nan intricate function of unknown lighting conditions, material properties and\nscene geometry. Recent progress in representing scene properties as\ncoordinate-based neural networks have facilitated neural inverse rendering\nresulting in impressive geometry reconstruction and novel-view synthesis. Our\nkey insight is that polarization is a useful cue for neural inverse rendering\nas polarization strongly depends on surface normals and is distinct for diffuse\nand specular reflectance. With the advent of commodity, on-chip, polarization\nsensors, capturing polarization has become practical. Thus, we propose PANDORA,\na polarimetric inverse rendering approach based on implicit neural\nrepresentations. From multi-view polarization images of an object, PANDORA\njointly extracts the object's 3D geometry, separates the outgoing radiance into\ndiffuse and specular and estimates the illumination incident on the object. We\nshow that PANDORA outperforms state-of-the-art radiance decomposition\ntechniques. PANDORA outputs clean surface reconstructions free from texture\nartefacts, models strong specularities accurately and estimates illumination\nunder practical unstructured scenarios.",
    "descriptor": "\nComments: Project webpage: this https URL\n",
    "authors": [
      "Akshat Dave",
      "Yongyi Zhao",
      "Ashok Veeraraghavan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.13458"
  },
  {
    "id": "arXiv:2203.13459",
    "title": "Semi-supervised and Deep learning Frameworks for Video Classification  and Key-frame Identification",
    "abstract": "Automating video-based data and machine learning pipelines poses several\nchallenges including metadata generation for efficient storage and retrieval\nand isolation of key-frames for scene understanding tasks. In this work, we\npresent two semi-supervised approaches that automate this process of manual\nframe sifting in video streams by automatically classifying scenes for content\nand filtering frames for fine-tuning scene understanding tasks. The first\nrule-based method starts from a pre-trained object detector and it assigns\nscene type, uncertainty and lighting categories to each frame based on\nprobability distributions of foreground objects. Next, frames with the highest\nuncertainty and structural dissimilarity are isolated as key-frames. The second\nmethod relies on the simCLR model for frame encoding followed by\nlabel-spreading from 20% of frame samples to label the remaining frames for\nscene and lighting categories. Also, clustering the video frames in the encoded\nfeature space further isolates key-frames at cluster boundaries. The proposed\nmethods achieve 64-93% accuracy for automated scene categorization for outdoor\nimage videos from public domain datasets of JAAD and KITTI. Also, less than 10%\nof all input frames can be filtered as key-frames that can then be sent for\nannotation and fine tuning of machine vision algorithms. Thus, the proposed\nframework can be scaled to additional video data streams for automated training\nof perception-driven systems with minimal training images.",
    "descriptor": "\nComments: 9 pages, 7 images, 3 tables\n",
    "authors": [
      "Sohini Roychowdhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13459"
  },
  {
    "id": "arXiv:2203.13461",
    "title": "Interpretation of Chest x-rays affected by bullets using deep transfer  learning",
    "abstract": "The potential of deep learning, especially in medical imaging, initiated\nastonishing results and improved the methodologies after every passing day.\nDeep learning in radiology provides the opportunity to classify, detect and\nsegment different diseases automatically. In the proposed study, we worked on a\nnon-trivial aspect of medical imaging where we classified and localized the\nX-Rays affected by bullets. We tested Images on different classification and\nlocalization models to get considerable accuracy. The replicated data set used\nin the study was replicated on different images of chest X-Rays. The proposed\nmodel worked not only on chest radiographs but other body organs X-rays like\nleg, abdomen, head, even the training dataset based on chest radiographs.\nCustom models have been used for classification and localization purposes after\ntuning parameters. Finally, the results of our findings manifested using\ndifferent frameworks. This might assist the research enlightening towards this\nfield. To the best of our knowledge, this is the first study on the detection\nand classification of radiographs affected by bullets using deep learning.",
    "descriptor": "\nComments: 10 pages, 8 figures, 1 table, Paper is intended to publish in journal and first author reserves all copyrights of reproduction\n",
    "authors": [
      "Shaheer Khan",
      "Azib Farooq",
      "Israr Khan",
      "Muhammad Gulraiz Khan",
      "Abdul Razzaq"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13461"
  },
  {
    "id": "arXiv:2203.13464",
    "title": "From MIM-Based GAN to Anomaly Detection:Event Probability Influence on  Generative Adversarial Networks",
    "abstract": "In order to introduce deep learning technologies into anomaly detection,\nGenerative Adversarial Networks (GANs) are considered as important roles in the\nalgorithm design and realistic applications. In terms of GANs, event\nprobability reflected in the objective function, has an impact on the event\ngeneration which plays a crucial part in GAN-based anomaly detection. The\ninformation metric, e.g. Kullback-Leibler divergence in the original GAN, makes\nthe objective function have different sensitivity on different event\nprobability, which provides an opportunity to refine GAN-based anomaly\ndetection by influencing data generation. In this paper, we introduce the\nexponential information metric into the GAN, referred to as MIM-based GAN,\nwhose superior characteristics on data generation are discussed in theory.\nFurthermore, we propose an anomaly detection method with MIM-based GAN, as well\nas explain its principle for the unsupervised learning case from the viewpoint\nof probability event generation. Since this method is promising to detect\nanomalies in Internet of Things (IoT), such as environmental, medical and\nbiochemical outliers, we make use of several datasets from the online ODDS\nrepository to evaluate its performance and compare it with other methods.",
    "descriptor": "",
    "authors": [
      "Rui She",
      "Pingyi Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.13464"
  },
  {
    "id": "arXiv:2203.13465",
    "title": "CAD: Co-Adapting Discriminative Features for Improved Few-Shot  Classification",
    "abstract": "Few-shot classification is a challenging problem that aims to learn a model\nthat can adapt to unseen classes given a few labeled samples. Recent approaches\npre-train a feature extractor, and then fine-tune for episodic meta-learning.\nOther methods leverage spatial features to learn pixel-level correspondence\nwhile jointly training a classifier. However, results using such approaches\nshow marginal improvements. In this paper, inspired by the transformer style\nself-attention mechanism, we propose a strategy to cross-attend and re-weight\ndiscriminative features for few-shot classification. Given a base\nrepresentation of support and query images after global pooling, we introduce a\nsingle shared module that projects features and cross-attends in two aspects:\n(i) query to support, and (ii) support to query. The module computes attention\nscores between features to produce an attention pooled representation of\nfeatures in the same class that is later added to the original representation\nfollowed by a projection head. This effectively re-weights features in both\naspects (i & ii) to produce features that better facilitate improved\nmetric-based meta-learning. Extensive experiments on public benchmarks show our\napproach outperforms state-of-the-art methods by 3%~5%.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Philip Chikontwe",
      "Soopil Kim",
      "Sang Hyun Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13465"
  },
  {
    "id": "arXiv:2203.13470",
    "title": "Interactive Style Transfer: All is Your Palette",
    "abstract": "Neural style transfer (NST) can create impressive artworks by transferring\nreference style to content image. Current image-to-image NST methods are short\nof fine-grained controls, which are often demanded by artistic editing. To\nmitigate this limitation, we propose a drawing-like interactive style transfer\n(IST) method, by which users can interactively create a harmonious-style image.\nOur IST method can serve as a brush, dip style from anywhere, and then paint to\nany region of the target content image. To determine the action scope, we\nformulate a fluid simulation algorithm, which takes styles as pigments around\nthe position of brush interaction, and diffusion in style or content images\naccording to the similarity maps. Our IST method expands the creative dimension\nof NST. By dipping and painting, even employing one style image can produce\nthousands of eye-catching works. The demo video is available in supplementary\nfiles or in this http URL",
    "descriptor": "\nComments: 8 pages, 11 figures\n",
    "authors": [
      "Zheng Lin",
      "Zhao Zhang",
      "Kang-Rui Zhang",
      "Bo Ren",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13470"
  },
  {
    "id": "arXiv:2203.13471",
    "title": "Non-Probability Sampling Network for Stochastic Human Trajectory  Prediction",
    "abstract": "Capturing multimodal natures is essential for stochastic pedestrian\ntrajectory prediction, to infer a finite set of future trajectories. The\ninferred trajectories are based on observation paths and the latent vectors of\npotential decisions of pedestrians in the inference step. However, stochastic\napproaches provide varying results for the same data and parameter settings,\ndue to the random sampling of the latent vector. In this paper, we analyze the\nproblem by reconstructing and comparing probabilistic distributions from\nprediction samples and socially-acceptable paths, respectively. Through this\nanalysis, we observe that the inferences of all stochastic models are biased\ntoward the random sampling, and fail to generate a set of realistic paths from\nfinite samples. The problem cannot be resolved unless an infinite number of\nsamples is available, which is infeasible in practice. We introduce that the\nQuasi-Monte Carlo (QMC) method, ensuring uniform coverage on the sampling\nspace, as an alternative to the conventional random sampling. With the same\nfinite number of samples, the QMC improves all the multimodal prediction\nresults. We take an additional step ahead by incorporating a learnable sampling\nnetwork into the existing networks for trajectory prediction. For this purpose,\nwe propose the Non-Probability Sampling Network (NPSN), a very small network\n(~5K parameters) that generates purposive sample sequences using the past paths\nof pedestrians and their social interactions. Extensive experiments confirm\nthat NPSN can significantly improve both the prediction accuracy (up to 60%)\nand reliability of the public pedestrian trajectory prediction benchmark. Code\nis publicly available at https://github.com/inhwanbae/NPSN .",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Inhwan Bae",
      "Jin-Hwi Park",
      "Hae-Gon Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.13471"
  },
  {
    "id": "arXiv:2203.13472",
    "title": "Facial Expression Recognition with Swin Transformer",
    "abstract": "The task of recognizing human facial expressions plays a vital role in\nvarious human-related systems, including health care and medical fields. With\nthe recent success of deep learning and the accessibility of a large amount of\nannotated data, facial expression recognition research has been mature enough\nto be utilized in real-world scenarios with audio-visual datasets. In this\npaper, we introduce Swin transformer-based facial expression approach for an\nin-the-wild audio-visual dataset of the Aff-Wild2 Expression dataset.\nSpecifically, we employ a three-stream network (i.e., Visual stream, Temporal\nstream, and Audio stream) for the audio-visual videos to fuse the multi-modal\ninformation into facial expression recognition. Experimental results on the\nAff-Wild2 dataset show the effectiveness of our proposed multi-modal\napproaches.",
    "descriptor": "",
    "authors": [
      "Jun-Hwa Kim",
      "Namho Kim",
      "Chee Sun Won"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13472"
  },
  {
    "id": "arXiv:2203.13474",
    "title": "A Conversational Paradigm for Program Synthesis",
    "abstract": "Program synthesis strives to generate a computer program as a solution to a\ngiven problem specification. We propose a conversational program synthesis\napproach via large language models, which addresses the challenges of searching\nover a vast program space and user intent specification faced in prior\napproaches. Our new approach casts the process of writing a specification and\nprogram as a multi-turn conversation between a user and a system. It treats\nprogram synthesis as a sequence prediction problem, in which the specification\nis expressed in natural language and the desired program is conditionally\nsampled. We train a family of large language models, called CodeGen, on natural\nlanguage and programming language data. With weak supervision in the data and\nthe scaling up of data size and model size, conversational capacities emerge\nfrom the simple autoregressive language modeling. To study the model behavior\non conversational program synthesis, we develop a multi-turn programming\nbenchmark (MTPB), where solving each problem requires multi-step synthesis via\nmulti-turn conversation between the user and the model. Our findings show the\nemergence of conversational capabilities and the effectiveness of the proposed\nconversational program synthesis paradigm. In addition, our model CodeGen (with\nup to 16B parameters trained on TPU-v4) outperforms OpenAI's Codex on the\nHumanEval benchmark. We plan to make the training library JaxFormer including\ncheckpoints available as open source.",
    "descriptor": "",
    "authors": [
      "Erik Nijkamp",
      "Bo Pang",
      "Hiroaki Hayashi",
      "Lifu Tu",
      "Huan Wang",
      "Yingbo Zhou",
      "Silvio Savarese",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.13474"
  },
  {
    "id": "arXiv:2203.13475",
    "title": "A Dichotomy in Consistent Query Answering for Primary Keys and Unary  Foreign Keys",
    "abstract": "Since 2005, significant progress has been made in the problem of Consistent\nQuery Answering (CQA) with respect to primary keys. In this problem, the input\nis a database instance that may violate one or more primary key constraints. A\nrepair is defined as a maximal subinstance that satisfies all primary keys.\nGiven a Boolean query q, the question then is whether q holds true in every\nrepair.\nSo far, theoretical research in this field has not addressed the combination\nof primary key and foreign key constraints, despite the importance of\nreferential integrity in database systems. This paper addresses the problem of\nCQA with respect to both primary keys and foreign keys. In this setting, it is\nnatural to adopt the notion of symmetric-difference repairs, because foreign\nkeys can be repaired by inserting new tuples.\nWe consider the case where foreign keys are unary, and queries are\nconjunctive queries without self-joins. In this setting, we characterize the\nboundary between those CQA problems that admit a consistent first-order\nrewriting, and those that do not.",
    "descriptor": "",
    "authors": [
      "Miika Hannula",
      "Jef Wijsen"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.13475"
  },
  {
    "id": "arXiv:2203.13478",
    "title": "Smart Wireless Environments Enabled by RISs: Deployment Scenarios and  Two Key Challenges",
    "abstract": "Reconfigurable Intelligent Surfaces (RISs) constitute the enabler for\nprogrammable propagation of electromagnetic signals, and are lately being\nconsidered as a candidate physical-layer technology for the demanding\nconnectivity, reliability, localization, and sustainability requirements of\nnext generation wireless communications networks. In this paper, we present\nvarious deployment scenarios for RIS-enabled smart wireless environments that\nhave been recently designed by the ongoing EU H2020 RISE-6G project. The\nscenarios are taxonomized according to performance objectives, in particular,\nconnectivity and reliability, localization and sensing, as well as\nsustainability and secrecy. We identify various deployment strategies and\nsketch the core architectural requirements in terms of RIS control and\nsignaling, depending on the RIS hardware architectures and their respective\ncapabilities. Furthermore, we introduce and discuss, via preliminary simulation\nresults and reflectarray measurements, two key novel challenges with\nRIS-enabled smart wireless environments, namely, the area of influence and the\nbandwidth of influence of RISs, which corroborate the need for careful\ndeployment and planning of this new technology.",
    "descriptor": "\nComments: 6 pages, 6 figures, international conference\n",
    "authors": [
      "George C. Alexandropoulos",
      "Maurizio Crozzoli",
      "Dinh-Thuy Phan-Huy",
      "Konstantinos D. Katsanos",
      "Henk Wymeersch",
      "Petar Popovski",
      "Philippe Ratajczak",
      "Yohann B\u00e9n\u00e9dic",
      "Marie-Helene Hamon",
      "Sebastien Herraiz Gonzalez",
      "Raffaele D'Errico",
      "Emilio Calvanese Strinati"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.13478"
  },
  {
    "id": "arXiv:2203.13479",
    "title": "Improving Adversarial Transferability with Spatial Momentum",
    "abstract": "Deep Neural Networks (DNN) are vulnerable to adversarial examples. Although\nmany adversarial attack methods achieve satisfactory attack success rates under\nthe white-box setting, they usually show poor transferability when attacking\nother DNN models. Momentum-based attack (MI-FGSM) is one effective method to\nimprove transferability. It integrates the momentum term into the iterative\nprocess, which can stabilize the update directions by adding the gradients'\ntemporal correlation for each pixel. We argue that only this temporal momentum\nis not enough, the gradients from the spatial domain within an image, i.e.\ngradients from the context pixels centered on the target pixel are also\nimportant to the stabilization. For that, in this paper, we propose a novel\nmethod named Spatial Momentum Iterative FGSM Attack (SMI-FGSM), which\nintroduces the mechanism of momentum accumulation from temporal domain to\nspatial domain by considering the context gradient information from different\nregions within the image. SMI-FGSM is then integrated with MI-FGSM to\nsimultaneously stabilize the gradients' update direction from both the temporal\nand spatial domain. The final method is called SM$^2$I-FGSM. Extensive\nexperiments are conducted on the ImageNet dataset and results show that\nSM$^2$I-FGSM indeed further enhances the transferability. It achieves the best\ntransferability success rate for multiple mainstream undefended and defended\nmodels, which outperforms the state-of-the-art methods by a large margin.",
    "descriptor": "",
    "authors": [
      "Guoqiu Wang",
      "Xingxing Wei",
      "Huanqian Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13479"
  },
  {
    "id": "arXiv:2203.13483",
    "title": "MKQ-BERT: Quantized BERT with 4-bits Weights and Activations",
    "abstract": "Recently, pre-trained Transformer based language models, such as BERT, have\nshown great superiority over the traditional methods in many Natural Language\nProcessing (NLP) tasks. However, the computational cost for deploying these\nmodels is prohibitive on resource-restricted devices. One method to alleviate\nthis computation overhead is to quantize the original model into fewer bits\nrepresentation, and previous work has proved that we can at most quantize both\nweights and activations of BERT into 8-bits, without degrading its performance.\nIn this work, we propose MKQ-BERT, which further improves the compression level\nand uses 4-bits for quantization. In MKQ-BERT, we propose a novel way for\ncomputing the gradient of the quantization scale, combined with an advanced\ndistillation strategy. On the one hand, we prove that MKQ-BERT outperforms the\nexisting BERT quantization methods for achieving a higher accuracy under the\nsame compression level. On the other hand, we are the first work that\nsuccessfully deploys the 4-bits BERT and achieves an end-to-end speedup for\ninference. Our results suggest that we could achieve 5.3x of bits reduction\nwithout degrading the model accuracy, and the inference speed of one int4 layer\nis 15x faster than a float32 layer in Transformer based model.",
    "descriptor": "",
    "authors": [
      "Hanlin Tang",
      "Xipeng Zhang",
      "Kai Liu",
      "Jianchen Zhu",
      "Zhanhui Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13483"
  },
  {
    "id": "arXiv:2203.13487",
    "title": "Compare learning: bi-attention network for few-shot learning",
    "abstract": "Learning with few labeled data is a key challenge for visual recognition, as\ndeep neural networks tend to overfit using a few samples only. One of the\nFew-shot learning methods called metric learning addresses this challenge by\nfirst learning a deep distance metric to determine whether a pair of images\nbelong to the same category, then applying the trained metric to instances from\nother test set with limited labels. This method makes the most of the few\nsamples and limits the overfitting effectively. However, extant metric networks\nusually employ Linear classifiers or Convolutional neural networks (CNN) that\nare not precise enough to globally capture the subtle differences between\nvectors. In this paper, we propose a novel approach named Bi-attention network\nto compare the instances, which can measure the similarity between embeddings\nof instances precisely, globally and efficiently. We verify the effectiveness\nof our model on two benchmarks. Experiments show that our approach achieved\nimproved accuracy and convergence speed over baseline models.",
    "descriptor": "",
    "authors": [
      "Li Ke",
      "Meng Pan",
      "Weigao Wen",
      "Dong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13487"
  },
  {
    "id": "arXiv:2203.13491",
    "title": "Striking a Balance: Alleviating Inconsistency in Pre-trained Models for  Symmetric Classification Tasks",
    "abstract": "While fine-tuning pre-trained models for downstream classification is the\nconventional paradigm in NLP, often task-specific nuances may not get captured\nin the resultant models. Specifically, for tasks that take two inputs and\nrequire the output to be invariant of the order of the inputs, inconsistency is\noften observed in the predicted labels or confidence scores. We highlight this\nmodel shortcoming and apply a consistency loss function to alleviate\ninconsistency in symmetric classification. Our results show an improved\nconsistency in predictions for three paraphrase detection datasets without a\nsignificant drop in the accuracy scores. We examine the classification\nperformance of six datasets (both symmetric and non-symmetric) to showcase the\nstrengths and limitations of our approach.",
    "descriptor": "\nComments: 9 pages, 2 figures, ACL Findings 2022\n",
    "authors": [
      "Ashutosh Kumar",
      "Aditya Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13491"
  },
  {
    "id": "arXiv:2203.13492",
    "title": "Move Complexity of a Self-Stabilizing Algorithm for Maximal Independent  Sets",
    "abstract": "${\\cal A}_\\mathsf{deg}$ is a self-stabilizing algorithm that computes a\nmaximal independent set in a finite graph with approximation ratio $(\\Delta +\n2)/3$. In this note we show that under the central scheduler the number of\nmoves of ${\\cal A}_\\mathsf{deg}$ is not bounded by a polynomial in $n$.",
    "descriptor": "",
    "authors": [
      "Volker Turau"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.13492"
  },
  {
    "id": "arXiv:2203.13494",
    "title": "Big data ethics, machine ethics or information ethics? Navigating the  maze of applied ethics in IT",
    "abstract": "Digitalization efforts are rapidly spreading across societies, challenging\nnew and important ethical issues that arise from technological development.\nSoftware developers, designers and managerial decision-makers are ever more\nexpected to consider ethical values and conduct normative evaluations when\nbuilding digital products. Yet, when one looks for guidance in the academic\nliterature one encounters a plethora of branches of applied ethics. Depending\non the context of the system that is to be developed, interesting subfields\nlike big data ethics, machine ethics, information ethics, AI ethics or computer\nethics (to only name a few) may present themselves. In this paper we want to\noffer assistance to any member of a development team by giving a clear and\nbrief introduction into two fields of ethical endeavor (normative ethics and\napplied ethics), describing how they are related to each other and, finally,\nprovide an ordering of the different branches of applied ethics (big data\nethics, machine ethics, information ethics, AI ethics or computer ethics etc.)\nwhich have gained traction over the last years. Finally, we discuss an example\nin the domain of facial recognition software in the domain of medicine to\nillustrate how this process of normative analysis might be conducted.",
    "descriptor": "",
    "authors": [
      "Niina Zuber",
      "Severin Kacianka",
      "Jan Gogoll"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.13494"
  },
  {
    "id": "arXiv:2203.13495",
    "title": "Machine-Learning Based Objective Function Selection for Community  Detection",
    "abstract": "NECTAR, a Node-centric ovErlapping Community deTection AlgoRithm, presented\nin 2016 by Cohen et. al, chooses dynamically between two objective functions\nwhich function to optimize, based on the network on which it is invoked. This\napproach, as shown by Cohen et al., outperforms six state-of-the-art algorithms\nfor overlapping community detection. In this work, we present NECTAR-ML, an\nextension of the NECTAR algorithm that uses a machine-learning based model for\nautomating the selection of the objective function, trained and evaluated on a\ndataset of 15,755 synthetic and 7 real-world networks. Our analysis shows that\nin approximately 90% of the cases our model was able to successfully select the\ncorrect objective function. We conducted a competitive analysis of NECTAR and\nNECTAR-ML. NECTAR-ML was shown to significantly outperform NECTAR's ability to\nselect the best objective function. We also conducted a competitive analysis of\nNECTAR-ML and two additional state-of-the-art multi-objective community\ndetection algorithms. NECTAR-ML outperformed both algorithms in terms of\naverage detection quality. Multiobjective EAs (MOEAs) are considered to be the\nmost popular approach to solve MOP and the fact that NECTAR-ML significantly\noutperforms them demonstrates the effectiveness of ML-based objective function\nselection.",
    "descriptor": "",
    "authors": [
      "Asa Bornstein",
      "Amir Rubin",
      "Danny Hendler"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13495"
  },
  {
    "id": "arXiv:2203.13497",
    "title": "WaveFuzz: A Clean-Label Poisoning Attack to Protect Your Voice",
    "abstract": "People are not always receptive to their voice data being collected and\nmisused. Training the audio intelligence systems needs these data to build\nuseful features, but the cost for getting permissions or purchasing data is\nvery high, which inevitably encourages hackers to collect these voice data\nwithout people's awareness. To discourage the hackers from proactively\ncollecting people's voice data, we are the first to propose a clean-label\npoisoning attack, called WaveFuzz, which can prevent intelligence audio models\nfrom building useful features from protected (poisoned) voice data but still\npreserve the semantic information to the humans. Specifically, WaveFuzz\nperturbs the voice data to cause Mel Frequency Cepstral Coefficients (MFCC)\n(typical representations of audio signals) to generate the poisoned frequency\nfeatures. These poisoned features are then fed to audio prediction models,\nwhich degrades the performance of audio intelligence systems. Empirically, we\nshow the efficacy of WaveFuzz by attacking two representative types of\nintelligent audio systems, i.e., speaker recognition system (SR) and speech\ncommand recognition system (SCR). For example, the accuracies of models are\ndeclined by $19.78\\%$ when only $10\\%$ of the poisoned voice data is to\nfine-tune models, and the accuracies of models declined by $6.07\\%$ when only\n$10\\%$ of the training voice data is poisoned. Consequently, WaveFuzz is an\neffective technique that enables people to fight back to protect their own\nvoice data, which sheds new light on ameliorating privacy issues.",
    "descriptor": "",
    "authors": [
      "Yunjie Ge",
      "Qian Wang",
      "Jingfeng Zhang",
      "Juntao Zhou",
      "Yunzhu Zhang",
      "Chao Shen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13497"
  },
  {
    "id": "arXiv:2203.13501",
    "title": "Cooperative Path-following Control of Remotely Operated Underwater  Robots for Human Visual Inspection Task",
    "abstract": "Remotely operated vehicles (ROVs) have drawn much attention to underwater\ntasks, such as the inspection and maintenance of infrastructure. The workload\nof ROV operators tends to be high, even for the skilled ones. Therefore,\nassistance methods for the operators are desired. This study focuses on a task\nin which a human operator controls an underwater robot to follow a certain path\nwhile visually inspecting objects in the vicinity of the path. In such a task,\nit is desirable to realize the speed of trajectory control manually because the\nvisual inspection is performed by a human operator. However, to allocate\nresources to visual inspection, it is desirable to minimize the workload on the\npath-following by assisting with the automatic control. Therefore, the\nobjective of this study was to develop a cooperative path-following control\nmethod that achieves the above-mentioned task by expanding a robust\npath-following control law of nonholonomic wheeled vehicles. To simplify this\nproblem, we considered a path-following and visual objects recognition task in\na two-dimensional plane. We conducted an experiment with participants (n=16)\nwho completed the task using the proposed method and manual control. The\nresults showed that both the path-following errors and the workload of the\nparticipants were significantly smaller with the proposed method than with\nmanual control. In addition, subjective responses demonstrated that operator\nattention tended to be allocated to objects recognition rather than robot\noperation tasks with the proposed method. These results indicate the\neffectiveness of the proposed cooperative path-following control method.",
    "descriptor": "\nComments: 8 pages, 11figures\n",
    "authors": [
      "Eito Sato",
      "Hailong Liu",
      "Norimitsu Sakagami",
      "Takahiro Wada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.13501"
  },
  {
    "id": "arXiv:2203.13502",
    "title": "CVEM-BEM coupling with decoupled orders for 2D exterior Poisson problems",
    "abstract": "For the solution of 2D exterior Dirichlet Poisson problems we propose the\ncoupling of a Curved Virtual Element Method (CVEM) with a Boundary Element\nMethod (BEM), by using decoupled approximation orders. We provide optimal\nconvergence error estimates, in the energy and in the weaker\n$\\textit{L}^\\text{2}$-norm, in which the CVEM and BEM contributions to the\nerror are separated. This allows taking advantage of the high order flexibility\nof the CVEM to retrieve an accurate discrete solution by using a low order BEM.\nThe numerical results confirm the a priori estimates and show the effectiveness\nof the proposed approach.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.04794\n",
    "authors": [
      "Luca Desiderio",
      "Silvia Falletta",
      "Matteo Ferrari",
      "Letizia Scuderi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.13502"
  },
  {
    "id": "arXiv:2203.13503",
    "title": "Supplemental Material: Lifelong Generative Modelling Using Dynamic  Expansion Graph Model",
    "abstract": "In this article, we provide the appendix for Lifelong Generative Modelling\nUsing Dynamic Expansion Graph Model. This appendix includes additional visual\nresults as well as the numerical results on the challenging datasets. In\naddition, we also provide detailed proofs for the proposed theoretical analysis\nframework. The source code can be found in\nhttps://github.com/dtuzi123/Expansion-Graph-Model.",
    "descriptor": "",
    "authors": [
      "Fei Ye",
      "Adrian G. Bors"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13503"
  },
  {
    "id": "arXiv:2203.13504",
    "title": "EmoCaps: Emotion Capsule based Model for Conversational Emotion  Recognition",
    "abstract": "Emotion recognition in conversation (ERC) aims to analyze the speaker's state\nand identify their emotion in the conversation. Recent works in ERC focus on\ncontext modeling but ignore the representation of contextual emotional\ntendency. In order to extract multi-modal information and the emotional\ntendency of the utterance effectively, we propose a new structure named\nEmoformer to extract multi-modal emotion vectors from different modalities and\nfuse them with sentence vector to be an emotion capsule. Furthermore, we design\nan end-to-end ERC model called EmoCaps, which extracts emotion vectors through\nthe Emoformer structure and obtain the emotion classification results from a\ncontext analysis model. Through the experiments with two benchmark datasets,\nour model shows better performance than the existing state-of-the-art models.",
    "descriptor": "\nComments: 9 pages, 5 figures, accepted by Finding of ACL 2022\n",
    "authors": [
      "Zaijing Li",
      "Fengxiao Tang",
      "Ming Zhao",
      "Yusen Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13504"
  },
  {
    "id": "arXiv:2203.13505",
    "title": "Contrastive learning of Class-agnostic Activation Map for Weakly  Supervised Object Localization and Semantic Segmentation",
    "abstract": "While class activation map (CAM) generated by image classification network\nhas been widely used for weakly supervised object localization (WSOL) and\nsemantic segmentation (WSSS), such classifiers usually focus on discriminative\nobject regions. In this paper, we propose Contrastive learning for\nClass-agnostic Activation Map (C$^2$AM) generation only using unlabeled image\ndata, without the involvement of image-level supervision. The core idea comes\nfrom the observation that i) semantic information of foreground objects usually\ndiffers from their backgrounds; ii) foreground objects with similar appearance\nor background with similar color/texture have similar representations in the\nfeature space. We form the positive and negative pairs based on the above\nrelations and force the network to disentangle foreground and background with a\nclass-agnostic activation map using a novel contrastive loss. As the network is\nguided to discriminate cross-image foreground-background, the class-agnostic\nactivation maps learned by our approach generate more complete object regions.\nWe successfully extracted from C$^2$AM class-agnostic object bounding boxes for\nobject localization and background cues to refine CAM generated by\nclassification network for semantic segmentation. Extensive experiments on\nCUB-200-2011, ImageNet-1K, and PASCAL VOC2012 datasets show that both WSOL and\nWSSS can benefit from the proposed C$^2$AM.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Jinheng Xie",
      "Jianfeng Xiang",
      "Junliang Chen",
      "Xianxu Hou",
      "Xiaodong Zhao",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13505"
  },
  {
    "id": "arXiv:2203.13506",
    "title": "Analysis of the Production Strategy of Mask Types in the COVID-19  Environment",
    "abstract": "Since the outbreak of the COVID-19 in December 2019, medical protective\nequipment such as disposable medical masks and KN95 masks have become essential\nresources for the public. Enterprises in all sectors of society have also\ntransformed the production of medical masks. After the outbreak, how to choose\nthe right time to produce medical protective masks, and what type of medical\nmasks to produce will play a positive role in preventing and controlling the\nepidemic in a short time. In this regard, the evolutionary game competition\nanalysis will be conducted through the relevant data of disposable medical\nmasks and KN95 masks to determine the appropriate nodes for the production of\ncorresponding mask types. After the research and analysis of the production\nstrategy of mask types, it has a positive effect on how to guide the resumption\nof work and production.",
    "descriptor": "",
    "authors": [
      "Xiangri Lu",
      "Zhanqing Wang",
      "Hongbin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13506"
  },
  {
    "id": "arXiv:2203.13510",
    "title": "On the Correlation between Angle and Distance Distributions in Finite  Wireless Networks",
    "abstract": "Directional beamforming will play a paramount role in 5G and beyond networks\nin order to combat the higher path losses incurred at millimeter wave bands.\nAppropriate modeling and analysis of the angles and distances between\ntransmitters and receivers in these networks are thus essential to understand\nperformance and limiting factors. Most existing literature considers either\ninfinite and uniform networks, where nodes are drawn according to a Poisson\npoint process, or finite networks with the reference receiver placed at the\norigin of a disk. Under either of these assumptions, the distance and azimuth\nangle between transmitter and receiver are independent, and the angle follows a\nuniform distribution between $0$ and $2\\pi$. Here, we consider a more realistic\ncase of finite networks where the reference node is placed at any arbitrary\nlocation. We obtain the joint distribution between the distance and azimuth\nangle and demonstrate that these random variables do exhibit certain\ncorrelation, which depends on the shape of the region and the location of the\nreference node. To conduct the analysis, we present a general mathematical\nframework which is specialized to exemplify the case of a rectangular region.\nWe then also derive the statistics for the 3D case where, considering antenna\nheights, the joint distribution of distance, azimuth and zenith angles is\nobtained. Finally, we describe some immediate applications of the present work,\nincluding the analysis of directional beamforming, the design of analog\ncodebooks and wireless routing algorithms.",
    "descriptor": "\nComments: 15 pages, 14 figures\n",
    "authors": [
      "Francisco J. Mart\u00edn-Vega",
      "Gerardo G\u00f3mez",
      "David Morales-Jim\u00e9nez",
      "F. Javier L\u00f3pez-Mart\u00ednez",
      "Mari Carmen Aguayo-Torres"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.13510"
  },
  {
    "id": "arXiv:2203.13511",
    "title": "Rapid prototyping and performance evaluation of MEC-based applications",
    "abstract": "Multi-access Edge Computing (MEC) will enable context-aware services for\nusers of mobile 4G/5G networks. MEC application developers need tools to aid\nthe design and the performance evaluation of their apps. During the early\nstages of deployment, they should be able to evaluate the performance impact of\ndesign choices - e.g., what round-trip delay can be expected due to the\ninterplay of computation, communication and service consumption. When a\nprototype of the app exists, it needs to be tested it live, under controllable\nconditions, to measure key performance indicators. In this paper, we present an\nopen-source framework that allows developers to do all the above. Our framework\nis based on Simu5G, the OMNeT++-based simulator of 5G (NewRadio) and 4G (LTE)\nmobile networks. It includes models of MEC entities (i.e., MEC orchestrator,\nMEC host, etc.) and provides a standard-compliant RESTful interface towards\napplication endpoints. Moreover, it can interface with external applications,\nand can also run in real time. Therefore, one can use it as a cradle to run a\nMEC app live, having underneath both 4G/5G data packet transport and MEC\nservices based on information generated by the underlying emulated radio access\nnetwork. We describe our framework and present a use-case of an emulated\nMEC-enabled 5G scenario.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Alessandro Noferi",
      "Giovanni Nardini",
      "Giovanni Stea",
      "Antonio Virdis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.13511"
  },
  {
    "id": "arXiv:2203.13512",
    "title": "Efficient k-clique Listing with Set Intersection Speedup [Technical  Report]",
    "abstract": "Listing all k-cliques is a fundamental problem in graph mining, with\napplications in finance, biology, and social network analysis. However, owing\nto the exponential growth of the search space as k increases, listing all\nk-cliques is algorithmically challenging. DDegree and DDegCol are the\nstate-of-the-art algorithms that exploit ordering heuristics based on degree\nordering and color ordering, respectively. Both DDegree and DDegCol induce high\ntime and space overhead for set intersections cause they construct and maintain\nall induced subgraphs. Meanwhile, it is non-trivial to implement the data level\nparallelism to further accelerate on DDegree and DDegCol.\nIn this paper, we propose two efficient algorithms SDegree and BitCol for\nk-clique listing. We mainly focus on accelerating the set intersections for\nk-clique listing. Both SDegree and BitCol exploit the data level parallelism\nfor further acceleration with single instruction multiple data (SIMD) or vector\ninstruction sets. Furthermore, we propose two preprocessing techniques Pre-Core\nand Pre-List, which run in linear time. The preprocessing techniques\nsignificantly reduce the size of the original graph and prevent exploring a\nlarge number of invalid nodes. In the theoretical analysis, our algorithms have\na comparable time complexity and a slightly lower space complexity than the\nstate-of-the-art algorithms. The comprehensive experiments reveal that our\nalgorithms outperform the state-of-the-art algorithms by 3.75x for degree\nordering and 5.67x for color ordering on average.",
    "descriptor": "\nComments: 15 pages, IEEE 2023\n",
    "authors": [
      "Zhirong Yuan",
      "You Peng",
      "Peng Cheng",
      "Li Han",
      "Xuemin Lin",
      "Lei Chen",
      "Wenjie Zhang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.13512"
  },
  {
    "id": "arXiv:2203.13517",
    "title": "Sparse Federated Learning with Hierarchical Personalization Models",
    "abstract": "Federated learning (FL) is widely used in the Internet of Things (IoT),\nwireless networks, mobile devices, autonomous vehicles, and human activity due\nto its excellent potential in cybersecurity and privacy security. Though FL\nmethod can achieve privacy-safe and reliable collaborative training without\ncollecting users' privacy data, it suffers from many challenges during both\ntraining and deployment. The main challenges in FL are the difficulty of\nnon-i.i.d co-training data caused by the statistical diversity of the data from\nvarious participants, and the difficulty of application deployment caused by\nthe excessive traffic volume and long communication delay between the central\nserver and the client. To address these problems, we propose a sparse FL scheme\nwith hierarchical personalization models (sFedHP), which minimizes clients'\nloss functions including the properties of an approximated L1-norm and the\nhierarchical proximal mapping, to reduce the communicational and computational\nloads required in the network, while improving the performance on statistical\ndiversity data. Convergence analysis shows that the sparse constraint in sFedHP\nonly reduces the convergence speed to a small extent, while the communication\ncost is greatly reduced. Experimentally, we demonstrate the benefits of this\nsparse hierarchical personalization architecture compared with the\nclient-edge-cloud hierarchical FedAvg and the state-of-the-art personalization\nmethods.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.05330\n",
    "authors": [
      "Xiaofeng Liu",
      "Yinchuan Li",
      "Yunfeng Shao",
      "Qing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13517"
  },
  {
    "id": "arXiv:2203.13525",
    "title": "Topology optimization of wind farm layouts",
    "abstract": "A novel approach for the solution of the wind farm layout optimization\nproblem is presented. The annual energy production is maximized with\nconstraints on the minimum and maximum number of wind turbines placed, and on\nthe minimum spacing between the wind turbines. The proposed approach relies on\na density-based topology optimization method, where continuous density\nvariables varying between zero and one are assigned to each potential wind\nturbine location. A wind turbine exists if its associated variable equals one,\notherwise it does not exist if the associated variable is zero. Intermediate\nvalues of the density variables are penalized with interpolation schemes\ntraditionally used in the context of multi-material structural topology\noptimization. The penalized intermediate values of the design variables become\nuneconomical and the optimization algorithm is implicitly pushed towards a\npreference of crisp 0-1 final values. The optimization problem is solved with a\ngradient-based algorithm based on first-order information. Because of the\nproposed problem formulation, the functions involved are formulated explicitly\nin terms of the design variables and their analytical gradients can be\ncalculated directly. The numerical results highlight the capability of the\nproposed approach in finding far from intuitive wind farm layouts with small\ncomputational resources and time.",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Pollini"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.13525"
  },
  {
    "id": "arXiv:2203.13528",
    "title": "Single Model Ensemble for Subword Regularized Models in Low-Resource  Machine Translation",
    "abstract": "Subword regularizations use multiple subword segmentations during training to\nimprove the robustness of neural machine translation models. In previous\nsubword regularizations, we use multiple segmentations in the training process\nbut use only one segmentation in the inference. In this study, we propose an\ninference strategy to address this discrepancy. The proposed strategy\napproximates the marginalized likelihood by using multiple segmentations\nincluding the most plausible segmentation and several sampled segmentations.\nBecause the proposed strategy aggregates predictions from several\nsegmentations, we can regard it as a single model ensemble that does not\nrequire any additional cost for training. Experimental results show that the\nproposed strategy improves the performance of models trained with subword\nregularization in low-resource machine translation tasks.",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Sho Takase",
      "Tatsuya Hiraoka",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13528"
  },
  {
    "id": "arXiv:2203.13530",
    "title": "Multimodal Pre-training Based on Graph Attention Network for Document  Understanding",
    "abstract": "Document intelligence as a relatively new research topic supports many\nbusiness applications. Its main task is to automatically read, understand, and\nanalyze documents. However, due to the diversity of formats (invoices, reports,\nforms, etc.) and layouts in documents, it is difficult to make machines\nunderstand documents. In this paper, we present the GraphDoc, a multimodal\ngraph attention-based model for various document understanding tasks. GraphDoc\nis pre-trained in a multimodal framework by utilizing text, layout, and image\ninformation simultaneously. In a document, a text block relies heavily on its\nsurrounding contexts, so we inject the graph structure into the attention\nmechanism to form a graph attention layer so that each input node can only\nattend to its neighborhoods. The input nodes of each graph attention layer are\ncomposed of textual, visual, and positional features from semantically\nmeaningful regions in a document image. We do the multimodal feature fusion of\neach node by the gate fusion layer. The contextualization between each node is\nmodeled by the graph attention layer. GraphDoc learns a generic representation\nfrom only 320k unlabeled documents via the Masked Sentence Modeling task.\nExtensive experimental results on the publicly available datasets show that\nGraphDoc achieves state-of-the-art performance, which demonstrates the\neffectiveness of our proposed method.",
    "descriptor": "",
    "authors": [
      "Zhenrong Zhang",
      "Jiefeng Ma",
      "Jun Du",
      "Licheng Wang",
      "Jianshu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13530"
  },
  {
    "id": "arXiv:2203.13532",
    "title": "Frequency response of diffusion-based molecular communication channels  in bounded environment",
    "abstract": "Recently, molecular communication (MC) has been studied as a micro-scale\ncommunication between cells or molecular robots. In previous works, the MC\nchannels in unbounded environment was analyzed. However, many of the\nexperimentally implemented MC channels are surrounded by walls, thus the\nboundary condition should be explicitly considered to analyze the dynamics of\nMC channels. In this paper, we propose a framework to analyze the frequency\nresponse of one-dimensional MC channels based on a diffusion equation with a\nboundary. In particular, we decompose the MC channel into the diffusion system\nand the boundary system, and show the relation between the cut-off frequency of\nthe MC channel and the communication distance based on the transfer function.\nWe then analyze the frequency response of a specific MC channel and reveal that\nthe boundary can restrict the communication bandwidth of the MC channel.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Taishi Kotsuka",
      "Yutaka Hori"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2203.13532"
  },
  {
    "id": "arXiv:2203.13533",
    "title": "High-Performance Transformer Tracking",
    "abstract": "Correlation has a critical role in the tracking field, especially in recent\npopular Siamese-based trackers. The correlation operation is a simple fusion\nmanner to consider the similarity between the template and the search region.\nHowever, the correlation operation is a local linear matching process, losing\nsemantic information and falling into local optimum easily, which may be the\nbottleneck of designing high-accuracy tracking algorithms. In this work, to\ndetermine whether a better feature fusion method exists than correlation, a\nnovel attention-based feature fusion network, inspired by Transformer, is\npresented. This network effectively combines the template and the search region\nfeatures using attention. Specifically, the proposed method includes an\nego-context augment module based on self-attention and a cross-feature augment\nmodule based on cross-attention. First, we present a Transformer tracking\n(named TransT) method based on the Siamese-like feature extraction backbone,\nthe designed attention-based fusion mechanism, and the classification and\nregression head. Based on the TransT baseline, we further design a segmentation\nbranch to generate an accurate mask. Finally, we propose a stronger version of\nTransT by extending TransT with a multi-template design and an IoU prediction\nhead, named TransT-M. Experiments show that our TransT and TransT-M methods\nachieve promising results on seven popular datasets. Code and models are\navailable at https://github.com/chenxin-dlut/TransT-M.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.15436\n",
    "authors": [
      "Xin Chen",
      "Bin Yan",
      "Jiawen Zhu",
      "Dong Wang",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13533"
  },
  {
    "id": "arXiv:2203.13534",
    "title": "Generalization bounds for learning under graph-dependence: A survey",
    "abstract": "Traditional statistical learning theory relies on the assumption that data\nare identically and independently generated from a given distribution (i.i.d.).\nThe independently distributed assumption, on the other hand, fails to hold in\nmany real applications. In this survey, we consider learning settings in which\nexamples are dependent and their dependence relationship can be characterized\nby a graph. We collect various graph-dependent concentration bounds, which are\nthen used to derive Rademacher and stability generalization bounds for learning\nfrom graph-dependent data. We illustrate this paradigm with three learning\ntasks and provide some research directions for future work. To the best of our\nknowledge, this is the first survey on this subject.",
    "descriptor": "",
    "authors": [
      "Rui-Ray Zhang",
      "Massih-Reza Amini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13534"
  },
  {
    "id": "arXiv:2203.13535",
    "title": "SeCo: Separating Unknown Musical Visual Sounds with Consistency Guidance",
    "abstract": "Recent years have witnessed the success of deep learning on the visual sound\nseparation task. However, existing works follow similar settings where the\ntraining and testing datasets share the same musical instrument categories,\nwhich to some extent limits the versatility of this task. In this work, we\nfocus on a more general and challenging scenario, namely the separation of\nunknown musical instruments, where the categories in training and testing\nphases have no overlap with each other. To tackle this new setting, we propose\nthe Separation-with-Consistency (SeCo) framework, which can accomplish the\nseparation on unknown categories by exploiting the consistency constraints.\nFurthermore, to capture richer characteristics of the novel melodies, we devise\nan online matching strategy, which can bring stable enhancements with no cost\nof extra parameters. Experiments demonstrate that our SeCo framework exhibits\nstrong adaptation ability on the novel musical categories and outperforms the\nbaseline methods by a significant margin.",
    "descriptor": "",
    "authors": [
      "Xinchi Zhou",
      "Dongzhan Zhou",
      "Wanli Ouyang",
      "Hang Zhou",
      "Ziwei Liu",
      "Di Hu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13535"
  },
  {
    "id": "arXiv:2203.13537",
    "title": "Efficient Visual Tracking via Hierarchical Cross-Attention Transformer",
    "abstract": "In recent years, target tracking has made great progress in accuracy. This\ndevelopment is mainly attributed to powerful networks (such as transformers)\nand additional modules (such as online update and refinement modules). However,\nless attention has been paid to tracking speed. Most state-of-the-art trackers\nare satisfied with the real-time speed on powerful GPUs. However, practical\napplications necessitate higher requirements for tracking speed, especially\nwhen edge platforms with limited resources are used. In this work, we present\nan efficient tracking method via a hierarchical cross-attention transformer\nnamed HCAT. Our model runs about 195 fps on GPU, 45 fps on CPU, and 55 fps on\nthe edge AI platform of NVidia Jetson AGX Xavier. Experiments show that our\nHCAT achieves promising results on LaSOT, GOT-10k, TrackingNet, NFS, OTB100,\nUAV123, and VOT2020. Code and models are available at\nhttps://github.com/chenxin-dlut/HCAT.",
    "descriptor": "",
    "authors": [
      "Xin Chen",
      "Dong Wang",
      "Dongdong Li",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13537"
  },
  {
    "id": "arXiv:2203.13540",
    "title": "Supporting tangible multi-factor key exchange in households",
    "abstract": "A common approach to securing end-to-end connectivity between devices on the\nInternet is to utilise a cloud-based intermediary. With this reliance upon a\nthird-party comes a set of security and privacy concerns that are difficult to\nmitigate. A promising new protocol, Wireguard, dispenses with the middleman to\nprovide secure peer-to-peer communication. However, support for initial key\nexchange falls outside Wireguard's scope, making it potentially vulnerable to\ninsecure out-of-band key exchange. The design of secure and usable key exchange\nmethods is challenging, not least in domestic spaces, as they're often\ncharacterised by technically naive users in multi-occupancy environments,\nmaking them susceptible to insider and passer-by attacks (i.e.: theft,\nobservation attacks, relay and impersonation attacks). We describe and present\nthe results from a design ideation study that probes the use of tangible,\nmulti-factor approaches for securing key exchange in domestic spaces. The study\nsuggests that a home's semi-fixed features (e.g.: lamps, shelves, chairs) can\nbe instrumented to support a promising three-factor authentication approach\n('what you have, what you know and where you are') to enable key exchange\nsolutions that are i. more secure than commonly used naive approaches and ii.\ndesirable for end users.",
    "descriptor": "",
    "authors": [
      "Thomas Lodge",
      "Sameh Zakhary",
      "Derek McAuley"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.13540"
  },
  {
    "id": "arXiv:2203.13542",
    "title": "EnHDC: Ensemble Learning for Brain-Inspired Hyperdimensional Computing",
    "abstract": "Ensemble learning is a classical learning method utilizing a group of weak\nlearners to form a strong learner, which aims to increase the accuracy of the\nmodel. Recently, brain-inspired hyperdimensional computing (HDC) becomes an\nemerging computational paradigm that has achieved success in various domains\nsuch as human activity recognition, voice recognition, and bio-medical signal\nclassification. HDC mimics the brain cognition and leverages high-dimensional\nvectors (e.g., 10000 dimensions) with fully distributed holographic\nrepresentation and (pseudo-)randomness. This paper presents the first effort in\nexploring ensemble learning in the context of HDC and proposes the first\nensemble HDC model referred to as EnHDC. EnHDC uses a majority voting-based\nmechanism to synergistically integrate the prediction outcomes of multiple base\nHDC classifiers. To enhance the diversity of base classifiers, we vary the\nencoding mechanisms, dimensions, and data width settings among base\nclassifiers. By applying EnHDC on a wide range of applications, results show\nthat the EnHDC can achieve on average 3.2\\% accuracy improvement over a single\nHDC classifier. Further, we show that EnHDC with reduced dimensionality, e.g.,\n1000 dimensions, can achieve similar or even surpass the accuracy of baseline\nHDC with higher dimensionality, e.g., 10000 dimensions. This leads to a 20\\%\nreduction of storage requirement of HDC model, which is key to enabling HDC on\nlow-power computing platforms.",
    "descriptor": "",
    "authors": [
      "Ruixuan Wang",
      "Dongning Ma",
      "Xun Jiao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13542"
  },
  {
    "id": "arXiv:2203.13544",
    "title": "Performance evaluation of switching between WiFi and LiFi under a common  virtual network interface",
    "abstract": "The LiFi paradigm is rapidly emerging as one of the technologies that will\nenable an impressive increase in the bandwidth made available to wireless\ndevices in 6G networks. Due to their intrinsic physical characteristics,\nvisible light and infrared communications present coverage features that are\ndifferent from their radio wave counterparts. A popular paradigm which has\nrecently emerged is that of hybrid networks, in which the two wireless\nconnection are used together in an hybrid configuration. We consider a hybrid\nwireless local area network composed of both WiFi and LiFi Access Points (AP)\nand wireless devices, in which the union of the two technologies is performed\nat the data link layer, i.e., each device is identified in the network by a\nunique IP address, using a virtual network interface obtained by bonding the\nWiFi and LiFi physical interfaces, implemented through commercially available\nproducts. We measure the time it takes to switch across the two physical\ninterfaces and its impact on the traffic flow, under specific triggering events\nfor the switch, namely an interface malfunctioning, a loss of signal, and a\nmanual switch. Our experimental results show that the different types of\ntriggering events have an impact on the time it takes to reconfigure the\ncurrently active interface, with recovery times ranging from few tens\nmilliseconds to few seconds. In terms of packet losses at the flow level, a\nswitch can entail a maximum packet loss percentage in the order of 10% during 1\nsecond.",
    "descriptor": "\nComments: 8 pages, 12 figures, 4 tables, conference paper\n",
    "authors": [
      "Loreto Pescosolido",
      "Emilio Ancillotti",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.13544"
  },
  {
    "id": "arXiv:2203.13550",
    "title": "Modeling Target-Side Morphology in Neural Machine Translation: A  Comparison of Strategies",
    "abstract": "Morphologically rich languages pose difficulties to machine translation.\nMachine translation engines that rely on statistical learning from parallel\ntraining data, such as state-of-the-art neural systems, face challenges\nespecially with rich morphology on the output language side. Key challenges of\nrich target-side morphology in data-driven machine translation include: (1) A\nlarge amount of differently inflected word surface forms entails a larger\nvocabulary and thus data sparsity. (2) Some inflected forms of infrequent terms\ntypically do not appear in the training corpus, which makes closed-vocabulary\nsystems unable to generate these unobserved variants. (3) Linguistic agreement\nrequires the system to correctly match the grammatical categories between\ninflected word forms in the output sentence, both in terms of target-side\nmorpho-syntactic wellformedness and semantic adequacy with respect to the\ninput.\nIn this paper, we re-investigate two target-side linguistic processing\ntechniques: a lemma-tag strategy and a linguistically informed word\nsegmentation strategy. Our experiments are conducted on a English-German\ntranslation task under three training corpus conditions of different\nmagnitudes. We find that a stronger Transformer baseline leaves less room for\nimprovement than a shallow-RNN encoder-decoder model when translating\nin-domain. However, we find that linguistic modeling of target-side morphology\ndoes benefit the Transformer model when the same system is applied to\nout-of-domain input text. We also successfully apply our approach to English to\nCzech translation.",
    "descriptor": "",
    "authors": [
      "Marion Weller-Di Marco",
      "Matthias Huck",
      "Alexander Fraser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13550"
  },
  {
    "id": "arXiv:2203.13551",
    "title": "Feature extraction using Spectral Clustering for Gene Function  Prediction",
    "abstract": "Gene annotation addresses the problem of predicting unknown associations\nbetween gene and functions (e.g., biological processes) of a specific organism.\nDespite recent advances, the cost and time demanded by annotation procedures\nthat rely largely on in vivo biological experiments remain prohibitively high.\nThis paper presents a novel in silico approach for to the annotation problem\nthat combines cluster analysis and hierarchical multi-label classification\n(HMC). The approach uses spectral clustering to extract new features from the\ngene co-expression network (GCN) and enrich the prediction task. HMC is used to\nbuild multiple estimators that consider the hierarchical structure of gene\nfunctions. The proposed approach is applied to a case study on Zea mays, one of\nthe most dominant and productive crops in the world. The results illustrate how\nin silico approaches are key to reduce the time and costs of gene annotation.\nMore specifically, they highlight the importance of: (i) building new features\nthat represent the structure of gene relationships in GCNs to annotate genes;\nand (ii) taking into account the structure of biological processes to obtain\nconsistent predictions.",
    "descriptor": "",
    "authors": [
      "Miguel Romero",
      "Oscar Ram\u00edrez",
      "Jorge Finke",
      "Camilo Rocha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13551"
  },
  {
    "id": "arXiv:2203.13552",
    "title": "Quantized Guessing Random Additive Noise Decoding",
    "abstract": "We introduce a soft-detection variant of Guessing Random Additive Noise\nDecoding (GRAND) called Quantized GRAND (QGRAND) that can efficiently decode\nany moderate redundancy block-code in an algorithm that is suitable for highly\nparallelized implementation in hardware. QGRAND can avail of any level of\nquantized soft information, and is shown to provide near maximum likelihood\ndecoding performance when provided with five or more bits of soft information\nper received bit.",
    "descriptor": "",
    "authors": [
      "Ken R. Duffy",
      "Evan P. Gabhart",
      "Muriel Medard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.13552"
  },
  {
    "id": "arXiv:2203.13553",
    "title": "Preprocessing Reward Functions for Interpretability",
    "abstract": "In many real-world applications, the reward function is too complex to be\nmanually specified. In such cases, reward functions must instead be learned\nfrom human feedback. Since the learned reward may fail to represent user\npreferences, it is important to be able to validate the learned reward function\nprior to deployment. One promising approach is to apply interpretability tools\nto the reward function to spot potential deviations from the user's intention.\nExisting work has applied general-purpose interpretability tools to understand\nlearned reward functions. We propose exploiting the intrinsic structure of\nreward functions by first preprocessing them into simpler but equivalent reward\nfunctions, which are then visualized. We introduce a general framework for such\nreward preprocessing and propose concrete preprocessing algorithms. Our\nempirical evaluation shows that preprocessed rewards are often significantly\neasier to understand than the original reward.",
    "descriptor": "\nComments: Presented at the NeurIPS 2021 Cooperative AI workshop. Code available at this https URL\n",
    "authors": [
      "Erik Jenner",
      "Adam Gleave"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13553"
  },
  {
    "id": "arXiv:2203.13556",
    "title": "Deformable Butterfly: A Highly Structured and Sparse Linear Transform",
    "abstract": "We introduce a new kind of linear transform named Deformable Butterfly\n(DeBut) that generalizes the conventional butterfly matrices and can be adapted\nto various input-output dimensions. It inherits the fine-to-coarse-grained\nlearnable hierarchy of traditional butterflies and when deployed to neural\nnetworks, the prominent structures and sparsity in a DeBut layer constitutes a\nnew way for network compression. We apply DeBut as a drop-in replacement of\nstandard fully connected and convolutional layers, and demonstrate its\nsuperiority in homogenizing a neural network and rendering it favorable\nproperties such as light weight and low inference complexity, without\ncompromising accuracy. The natural complexity-accuracy tradeoff arising from\nthe myriad deformations of a DeBut layer also opens up new rooms for analytical\nand practical research. The codes and Appendix are publicly available at:\nhttps://github.com/ruilin0212/DeBut.",
    "descriptor": "",
    "authors": [
      "Rui Lin",
      "Jie Ran",
      "King Hung Chiu",
      "Graziano Chesi",
      "Ngai Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13556"
  },
  {
    "id": "arXiv:2203.13558",
    "title": "Neural Networks with Divisive normalization for image segmentation with  application in cityscapes dataset",
    "abstract": "One of the key problems in computer vision is adaptation: models are too\nrigid to follow the variability of the inputs. The canonical computation that\nexplains adaptation in sensory neuroscience is divisive normalization, and it\nhas appealing effects on image manifolds. In this work we show that including\ndivisive normalization in current deep networks makes them more invariant to\nnon-informative changes in the images. In particular, we focus on U-Net\narchitectures for image segmentation. Experiments show that the inclusion of\ndivisive normalization in the U-Net architecture leads to better segmentation\nresults with respect to conventional U-Net. The gain increases steadily when\ndealing with images acquired in bad weather conditions. In addition to the\nresults on the Cityscapes and Foggy Cityscapes datasets, we explain these\nadvantages through visualization of the responses: the equalization induced by\nthe divisive normalization leads to more invariant features to local changes in\ncontrast and illumination.",
    "descriptor": "",
    "authors": [
      "Pablo Hern\u00e1ndez-C\u00e1mara",
      "Valero Laparra",
      "Jes\u00fas Malo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13558"
  },
  {
    "id": "arXiv:2203.13560",
    "title": "MISC: A MIxed Strategy-Aware Model Integrating COMET for Emotional  Support Conversation",
    "abstract": "Applying existing methods to emotional support conversation -- which provides\nvaluable assistance to people who are in need -- has two major limitations: (a)\nthey generally employ a conversation-level emotion label, which is too\ncoarse-grained to capture user's instant mental state; (b) most of them focus\non expressing empathy in the response(s) rather than gradually reducing user's\ndistress. To address the problems, we propose a novel model \\textbf{MISC},\nwhich firstly infers the user's fine-grained emotional status, and then\nresponds skillfully using a mixture of strategy. Experimental results on the\nbenchmark dataset demonstrate the effectiveness of our method and reveal the\nbenefits of fine-grained emotion understanding as well as mixed-up strategy\nmodeling. Our code and data could be found in\n\\url{https://github.com/morecry/MISC}.",
    "descriptor": "\nComments: 12 pages, 5 figures, accepted by ACL 2022 main conference\n",
    "authors": [
      "Quan Tu",
      "Yanran Li",
      "Jianwei Cui",
      "Bin Wang",
      "Ji-Rong Wen",
      "Rui Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13560"
  },
  {
    "id": "arXiv:2203.13561",
    "title": "Personalize Web Searching Strategies Classification and Comparison",
    "abstract": "Personalization is becoming very important direction in semantic web search\nfor the users that needs to find appropriate information. In this paper, a\nclassification of web personalization is proposed and semantic web search tools\nare investigated. Building user interest profile is essential for\npersonalizing. Nowadays, semantic web tools use ontologies for personalization\nbecause of their advantages. It is important to mention that most of the\nsemantic web search tools use agent technologies for implementation.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Mariya Evtimova-Gardair",
      "Ivan Momtchev"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13561"
  },
  {
    "id": "arXiv:2203.13563",
    "title": "An Intelligent End-to-End Neural Architecture Search Framework for  Electricity Forecasting Model Development",
    "abstract": "Recent years have witnessed an exponential growth in developing deep learning\n(DL) models for the time-series electricity forecasting in power systems.\nHowever, most of the proposed models are designed based on the designers'\ninherent knowledge and experience without elaborating on the suitability of the\nproposed neural architectures. Moreover, these models cannot be self-adjusted\nto the dynamically changing data patterns due to an inflexible design of their\nstructures. Even though several latest studies have considered application of\nthe neural architecture search (NAS) technique for obtaining a network with an\noptimized structure in the electricity forecasting sector, their training\nprocess is quite time-consuming, computationally expensive and not intelligent,\nindicating that the NAS application in electricity forecasting area is still at\nan infancy phase. In this research study, we propose an intelligent automated\narchitecture search (IAAS) framework for the development of time-series\nelectricity forecasting models. The proposed framework contains two primary\ncomponents, i.e., network function-preserving transformation operation and\nreinforcement learning (RL)-based network transformation control. In the first\ncomponent, we introduce a theoretical function-preserving transformation of\nrecurrent neural networks (RNN) to the literature for capturing the hidden\ntemporal patterns within the time-series data. In the second component, we\ndevelop three RL-based transformation actors and a net pool to intelligently\nand effectively search a high-quality neural architecture. After conducting\ncomprehensive experiments on two publicly-available electricity load datasets\nand two wind power datasets, we demonstrate that the proposed IAAS framework\nsignificantly outperforms the ten existing models or methods in terms of\nforecasting accuracy and stability.",
    "descriptor": "",
    "authors": [
      "Jin Yang",
      "Yingying Huang",
      "Guangxin Jiang",
      "Ying Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13563"
  },
  {
    "id": "arXiv:2203.13565",
    "title": "Self-Assessing Creative Problem Solving for Aspiring Software  Developers: A Pilot Study",
    "abstract": "We developed a self-assessment tool for computing students in higher\neducation to measure their Creative Problem Solving skills. Our survey\nencompasses 7 dimensions of creativity, based on existing validated scales and\nconducted focus groups. These are: technical knowledge, communication,\nconstraints, critical thinking, curiosity, creative state of mind, and creative\ntechniques. Principal axis factor analysis groups the dimensions into three\noverarching constructs: ability, mindset, and interaction. The results of a\npilot study (n = 269) provide evidence for its psychometric qualities, making\nit a useful instrument for educational researchers to investigate students'\ncreative skills.",
    "descriptor": "",
    "authors": [
      "Wouter Groeneveld",
      "Lynn Van den Broeck",
      "Joost Vennekens",
      "Kris Aerts"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.13565"
  },
  {
    "id": "arXiv:2203.13568",
    "title": "$p$-Generalized Probit Regression and Scalable Maximum Likelihood  Estimation via Sketching and Coresets",
    "abstract": "We study the $p$-generalized probit regression model, which is a generalized\nlinear model for binary responses. It extends the standard probit model by\nreplacing its link function, the standard normal cdf, by a $p$-generalized\nnormal distribution for $p\\in[1, \\infty)$. The $p$-generalized normal\ndistributions \\citep{Sub23} are of special interest in statistical modeling\nbecause they fit much more flexibly to data. Their tail behavior can be\ncontrolled by choice of the parameter $p$, which influences the model's\nsensitivity to outliers. Special cases include the Laplace, the Gaussian, and\nthe uniform distributions. We further show how the maximum likelihood estimator\nfor $p$-generalized probit regression can be approximated efficiently up to a\nfactor of $(1+\\varepsilon)$ on large data by combining sketching techniques\nwith importance subsampling to obtain a small data summary called coreset.",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Alexander Munteanu",
      "Simon Omlor",
      "Christian Peters"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13568"
  },
  {
    "id": "arXiv:2203.13570",
    "title": "Improving Question Answering over Knowledge Graphs Using Graph  Summarization",
    "abstract": "Question Answering (QA) systems over Knowledge Graphs (KGs) (KGQA)\nautomatically answer natural language questions using triples contained in a\nKG. The key idea is to represent questions and entities of a KG as\nlow-dimensional embeddings. Previous KGQAs have attempted to represent entities\nusing Knowledge Graph Embedding (KGE) and Deep Learning (DL) methods. However,\nKGEs are too shallow to capture the expressive features and DL methods process\neach triple independently. Recently, Graph Convolutional Network (GCN) has\nshown to be excellent in providing entity embeddings. However, using GCNs to\nKGQAs is inefficient because GCNs treat all relations equally when aggregating\nneighbourhoods. Also, a problem could occur when using previous KGQAs: in most\ncases, questions often have an uncertain number of answers. To address the\nabove issues, we propose a graph summarization technique using Recurrent\nConvolutional Neural Network (RCNN) and GCN. The combination of GCN and RCNN\nensures that the embeddings are propagated together with the relations relevant\nto the question, and thus better answers. The proposed graph summarization\ntechnique can be used to tackle the issue that KGQAs cannot answer questions\nwith an uncertain number of answers. In this paper, we demonstrated the\nproposed technique on the most common type of questions, which is\nsingle-relation questions. Experiments have demonstrated that the proposed\ngraph summarization technique using RCNN and GCN can provide better results\nwhen compared to the GCN. The proposed graph summarization technique\nsignificantly improves the recall of actual answers when the questions have an\nuncertain number of answers.",
    "descriptor": "\nComments: The paper is accepted by ICONIP 2021\n",
    "authors": [
      "Sirui Li",
      "Kok Kai Wong",
      "Dengya Zhu",
      "Chun Che Fung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13570"
  },
  {
    "id": "arXiv:2203.13571",
    "title": "Adaptive Neural Network-based OFDM Receivers",
    "abstract": "We propose and examine the idea of continuously adapting state-of-the-art\nneural network (NN)-based orthogonal frequency division multiplex (OFDM)\nreceivers to current channel conditions. This online adaptation via retraining\nis mainly motivated by two reasons: First, receiver design typically focuses on\nthe universal optimal performance for a wide range of possible channel\nrealizations. However, in actual applications and within short time intervals,\nonly a subset of these channel parameters is likely to occur, as macro\nparameters, e.g., the maximum channel delay, can assumed to be static. Second,\nin-the-field alterations like temporal interferences or other conditions out of\nthe originally intended specifications can occur on a practical (real-world)\ntransmission. While conventional (filter-based) systems would require\nreconfiguration or additional signal processing to cope with these unforeseen\nconditions, NN-based receivers can learn to mitigate previously unseen effects\neven after their deployment. For this, we showcase on-the-fly adaption to\ncurrent channel conditions and temporal alterations solely based on recovered\nlabels from an outer forward error correction (FEC) code without any additional\npiloting overhead. To underline the flexibility of the proposed adaptive\ntraining, we showcase substantial gains for scenarios with static channel macro\nparameters, for out-ofspecification usage and for interference compensation.",
    "descriptor": "\nComments: Submitted to SPAWC 2022\n",
    "authors": [
      "Moritz Benedikt Fischer",
      "Sebastian D\u00f6rner",
      "Sebastian Cammerer",
      "Takayuki Shimizu",
      "Hongsheng Lu",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.13571"
  },
  {
    "id": "arXiv:2203.13572",
    "title": "A Visual Navigation Perspective for Category-Level Object Pose  Estimation",
    "abstract": "This paper studies category-level object pose estimation based on a single\nmonocular image. Recent advances in pose-aware generative models have paved the\nway for addressing this challenging task using analysis-by-synthesis. The idea\nis to sequentially update a set of latent variables, e.g., pose, shape, and\nappearance, of the generative model until the generated image best agrees with\nthe observation. However, convergence and efficiency are two challenges of this\ninference procedure. In this paper, we take a deeper look at the inference of\nanalysis-by-synthesis from the perspective of visual navigation, and\ninvestigate what is a good navigation policy for this specific task. We\nevaluate three different strategies, including gradient descent, reinforcement\nlearning and imitation learning, via thorough comparisons in terms of\nconvergence, robustness and efficiency. Moreover, we show that a simple hybrid\napproach leads to an effective and efficient solution. We further compare these\nstrategies to state-of-the-art methods, and demonstrate superior performance on\nsynthetic and real-world datasets leveraging off-the-shelf pose-aware\ngenerative models.",
    "descriptor": "",
    "authors": [
      "Jiaxin Guo",
      "Fangxun Zhong",
      "Rong Xiong",
      "Yunhui Liu",
      "Yue Wang",
      "Yiyi Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.13572"
  },
  {
    "id": "arXiv:2203.13573",
    "title": "Unsupervised Learning of Temporal Abstractions with Slot-based  Transformers",
    "abstract": "The discovery of reusable sub-routines simplifies decision-making and\nplanning in complex reinforcement learning problems. Previous approaches\npropose to learn such temporal abstractions in a purely unsupervised fashion\nthrough observing state-action trajectories gathered from executing a policy.\nHowever, a current limitation is that they process each trajectory in an\nentirely sequential manner, which prevents them from revising earlier decisions\nabout sub-routine boundary points in light of new incoming information. In this\nwork we propose SloTTAr, a fully parallel approach that integrates sequence\nprocessing Transformers with a Slot Attention module and adaptive computation\nfor learning about the number of such sub-routines in an unsupervised fashion.\nWe demonstrate how SloTTAr is capable of outperforming strong baselines in\nterms of boundary point discovery, even for sequences containing variable\namounts of sub-routines, while being up to 7x faster to train on existing\nbenchmarks.",
    "descriptor": "\nComments: 26 pages, 8 figures\n",
    "authors": [
      "Anand Gopalakrishnan",
      "Kazuki Irie",
      "J\u00fcrgen Schmidhuber",
      "Sjoerd van Steenkiste"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.13573"
  },
  {
    "id": "arXiv:2203.13577",
    "title": "Analyzing Search Techniques for Autotuning Image-based GPU Kernels: The  Impact of Sample Sizes",
    "abstract": "Modern computing systems are increasingly more complex, with their multicore\nCPUs and GPUs accelerators changing yearly, if not more often. It thus has\nbecome very challenging to write programs that efficiently use the associated\ncomplex memory systems and take advantage of the available parallelism.\nAutotuning addresses this by optimizing parameterized code to the targeted\nhardware by searching for the optimal set of parameters. Empirical autotuning\nhas therefore gained interest during the past decades. While new autotuning\nalgorithms are regularly presented and published, we will show why comparing\nthese autotuning algorithms is a deceptively difficult task.\nIn this paper, we describe our empirical study of state-of-the-art search\ntechniques for autotuning by comparing them on a range of sample sizes,\nbenchmarks and architectures. We optimize 6 tunable parameters with a\nsearch-space size of over 2 million. The algorithms studied include Random\nSearch (RS), Random Forest Regression (RF), Genetic Algorithms (GA), Bayesian\nOptimization with Gaussian Processes (BO GP) and Bayesian Optimization with\nTree-Parzen Estimators (BO TPE).\nOur results on the ImageCL benchmark suite suggest that the ideal autotuning\nalgorithm heavily depends on the sample size. In our study, BO GP and BO TPE\noutperform the other algorithms in most scenarios with sample sizes from 25 to\n100. However, GA usually outperforms the others for sample sizes 200 and\nbeyond. We generally see the most speedup to be gained over RS in the lower\nrange of sample sizes (25-100). However, the algorithms more consistently\noutperform RS for higher sample sizes (200-400). Hence, no single\nstate-of-the-art algorithm outperforms the rest for all sample sizes. Some\nsuggestions for future work are also included.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Jacob O. T\u00f8rring",
      "Anne C. Elster"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.13577"
  },
  {
    "id": "arXiv:2203.13590",
    "title": "Impact of Dataset on Acoustic Models for Automatic Speech Recognition",
    "abstract": "In Automatic Speech Recognition, GMM-HMM had been widely used for acoustic\nmodelling. With the current advancement of deep learning, the Gaussian Mixture\nModel (GMM) from acoustic models has been replaced with Deep Neural Network,\nnamely DNN-HMM Acoustic Models. The GMM models are widely used to create the\nalignments of the training data for the hybrid deep neural network model, thus\nmaking it an important task to create accurate alignments. Many factors such as\ntraining dataset size, training data augmentation, model hyperparameters, etc.,\naffect the model learning. Traditionally in machine learning, larger datasets\ntend to have better performance, while smaller datasets tend to trigger\nover-fitting. The collection of speech data and their accurate transcriptions\nis a significant challenge that varies over different languages, and in most\ncases, it might be limited to big organizations. Moreover, in the case of\navailable large datasets, training a model using such data requires additional\ntime and computing resources, which may not be available. While the data about\nthe accuracy of state-of-the-art ASR models on open-source datasets are\npublished, the study about the impact of the size of a dataset on acoustic\nmodels is not readily available. This work aims to investigate the impact of\ndataset size variations on the performance of various GMM-HMM Acoustic Models\nand their respective computational costs.",
    "descriptor": "",
    "authors": [
      "Siddhesh Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13590"
  },
  {
    "id": "arXiv:2203.13591",
    "title": "Continual Test-Time Domain Adaptation",
    "abstract": "Test-time domain adaptation aims to adapt a source pre-trained model to a\ntarget domain without using any source data. Existing works mainly consider the\ncase where the target domain is static. However, real-world machine perception\nsystems are running in non-stationary and continually changing environments\nwhere the target domain distribution can change over time. Existing methods,\nwhich are mostly based on self-training and entropy regularization, can suffer\nfrom these non-stationary environments. Due to the distribution shift over time\nin the target domain, pseudo-labels become unreliable. The noisy pseudo-labels\ncan further lead to error accumulation and catastrophic forgetting. To tackle\nthese issues, we propose a continual test-time adaptation approach~(CoTTA)\nwhich comprises two parts. Firstly, we propose to reduce the error accumulation\nby using weight-averaged and augmentation-averaged predictions which are often\nmore accurate. On the other hand, to avoid catastrophic forgetting, we propose\nto stochastically restore a small part of the neurons to the source pre-trained\nweights during each iteration to help preserve source knowledge in the\nlong-term. The proposed method enables the long-term adaptation for all\nparameters in the network. CoTTA is easy to implement and can be readily\nincorporated in off-the-shelf pre-trained models. We demonstrate the\neffectiveness of our approach on four classification tasks and a segmentation\ntask for continual test-time adaptation, on which we outperform existing\nmethods. Our code is available at \\url{https://qin.ee/cotta}.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Qin Wang",
      "Olga Fink",
      "Luc Van Gool",
      "Dengxin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13591"
  },
  {
    "id": "arXiv:2203.13592",
    "title": "ILoveEye: Eyeliner Makeup Guidance System with Eye Shape Features",
    "abstract": "Drawing eyeliner is not an easy task for whom lacks experience in eye makeup.\nEveryone has a unique pair of eyes, so they need to draw eyeliner in a style\nthat suits their eyes. We proposed ILoveEye, an interactive system that\nsupports eye-makeup novices to draw natural and suitable eyeliner. The proposed\nsystem analyzes the shape of the user's eyes and classifies the eye types from\ncamera frame. The system can recommend the eyeliner style to the user based on\nthe designed recommendation rules. Then, the system can generate the original\npatterns corresponding to the eyeliner style, and the user can draw the\neyeliner while observing the real-time makeup guidance. The user evaluation\nexperiments are conducted to verify that the proposed ILoveEye system can help\nsome users to draw reasonable eyeliner based on the specific eye shapes and\nimprove their eye makeup skills.",
    "descriptor": "\nComments: 17 pages, 13 figures. Accepted in proceedings of HCII 2022\n",
    "authors": [
      "Hange Wang",
      "Haoran Xie",
      "Kazunori Miyata"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.13592"
  },
  {
    "id": "arXiv:2203.13595",
    "title": "Fast Hybrid Image Retargeting",
    "abstract": "Image retargeting changes the aspect ratio of images while aiming to preserve\ncontent and minimise noticeable distortion. Fast and high-quality methods are\nparticularly relevant at present, due to the large variety of image and display\naspect ratios. We propose a retargeting method that quantifies and limits\nwarping distortions with the use of content-aware cropping. The pipeline of the\nproposed approach consists of the following steps. First, an importance map of\na source image is generated using deep semantic segmentation and saliency\ndetection models. Then, a preliminary warping mesh is computed using axis\naligned deformations, enhanced with the use of a distortion measure to ensure\nlow warping deformations. Finally, the retargeted image is produced using a\ncontent-aware cropping algorithm. In order to evaluate our method, we perform a\nuser study based on the RetargetMe benchmark. Experimental analyses show that\nour method outperforms recent approaches, while running in a fraction of their\nexecution time.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Daniel Valdez-Balderas",
      "Oleg Muraveynyk",
      "Timothy Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13595"
  },
  {
    "id": "arXiv:2203.13596",
    "title": "DeepALM: Holistic Optical Network Monitoring based on Machine Learning",
    "abstract": "We demonstrate a machine learning-based optical network monitoring system\nwhich can integrate fiber monitoring, predictive maintenance of optical\nhardware, and security information management in a single solution.",
    "descriptor": "",
    "authors": [
      "Joo Yeon Cho",
      "Jose-Juan Pedreno-Manresa",
      "Sai Kireet Patri",
      "Khouloud Abdelli",
      "Carsten Tropschug",
      "Jim Zou",
      "Piotr Rydlichowski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.13596"
  },
  {
    "id": "arXiv:2203.13599",
    "title": "Learning Relational Rules from Rewards",
    "abstract": "Humans perceive the world in terms of objects and relations between them. In\nfact, for any given pair of objects, there is a myriad of relations that apply\nto them. How does the cognitive system learn which relations are useful to\ncharacterize the task at hand? And how can it use these representations to\nbuild a relational policy to interact effectively with the environment? In this\npaper we proposed that this problem can be understood through the lens of a\nsub-field of symbolic machine learning called relational reinforcement learning\n(RRL). To demonstrate the potential of our approach, we build a simple model of\nrelational policy learning based on a function approximator developed in RRL.\nWe trained and tested our model in three Atari games that required to consider\nan increasingly number of potential relations: Breakout, Pong and Demon Attack.\nIn each game, our model was able to select adequate relational representations\nand build a relational policy incrementally. We discuss the relationship\nbetween our model with models of relational and analogical reasoning, as well\nas its limitations and future directions of research.",
    "descriptor": "",
    "authors": [
      "Guillermo Puebla",
      "Leonidas A. A. Doumas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13599"
  },
  {
    "id": "arXiv:2203.13601",
    "title": "Navigable Proximity Graph-Driven Native Hybrid Queries with Structured  and Unstructured Constraints",
    "abstract": "As research interest surges, vector similarity search is applied in multiple\nfields, including data mining, computer vision, and information retrieval.\n{Given a set of objects (e.g., a set of images) and a query object, we can\neasily transform each object into a feature vector and apply the vector\nsimilarity search to retrieve the most similar objects. However, the original\nvector similarity search cannot well support \\textit{hybrid queries}, where\nusers not only input unstructured query constraint (i.e., the feature vector of\nquery object) but also structured query constraint (i.e., the desired\nattributes of interest). Hybrid query processing aims at identifying these\nobjects with similar feature vectors to query object and satisfying the given\nattribute constraints. Recent efforts have attempted to answer a hybrid query\nby performing attribute filtering and vector similarity search separately and\nthen merging the results later, which limits efficiency and accuracy because\nthey are not purpose-built for hybrid queries.} In this paper, we propose a\nnative hybrid query (NHQ) framework based on proximity graph (PG), which\nprovides the specialized \\textit{composite index and joint pruning} modules for\nhybrid queries. We easily deploy existing various PGs on this framework to\nprocess hybrid queries efficiently. Moreover, we present two novel navigable\nPGs (NPGs) with optimized edge selection and routing strategies, which obtain\nbetter overall performance than existing PGs. After that, we deploy the\nproposed NPGs in NHQ to form two hybrid query methods, which significantly\noutperform the state-of-the-art competitors on all experimental datasets\n(10$\\times$ faster under the same \\textit{Recall}), including eight public and\none in-house real-world datasets. Our code and datasets have been released at\n\\url{https://github.com/AshenOn3/NHQ}.",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Mengzhao Wang",
      "Lingwei Lv",
      "Xiaoliang Xu",
      "Yuxiang Wang",
      "Qiang Yue",
      "Jiongkang Ni"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.13601"
  },
  {
    "id": "arXiv:2203.13602",
    "title": "ZS4IE: A toolkit for Zero-Shot Information Extraction with simple  Verbalizations",
    "abstract": "The current workflow for Information Extraction (IE) analysts involves the\ndefinition of the entities/relations of interest and a training corpus with\nannotated examples. In this demonstration we introduce a new workflow where the\nanalyst directly verbalizes the entities/relations, which are then used by a\nTextual Entailment model to perform zero-shot IE. We present the design and\nimplementation of a toolkit with a user interface, as well as experiments on\nfour IE tasks that show that the system achieves very good performance at\nzero-shot learning using only 5--15 minutes per type of a user's effort. Our\ndemonstration system is open-sourced at https://github.com/BBN-E/ZS4IE . A\ndemonstration video is available at https://vimeo.com/676138340 .",
    "descriptor": "",
    "authors": [
      "Oscar Sainz",
      "Haoling Qiu",
      "Oier Lopez de Lacalle",
      "Eneko Agirre",
      "Bonan Min"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13602"
  },
  {
    "id": "arXiv:2203.13603",
    "title": "Making Nonlinear Systems Negative Imaginary via State Feedback",
    "abstract": "This paper provides a state feedback stabilization approach for nonlinear\nsystems of relative degree less than or equal to two by rendering them\nnonlinear negative imaginary (NI) systems. Conditions are provided under which\na nonlinear system can be made a nonlinear NI system or a nonlinear output\nstrictly NI (OSNI) system. Roughly speaking, an affine nonlinear system which\nhas a normal form with relative degree less than or equal to two after possible\noutput transformation can be rendered nonlinear NI and nonlinear OSNI. In\naddition, if the internal dynamics of the normal form is input-to-state stable,\nthen there exists a state feedback input that stabilizes the system. This\nstabilization result is then extended to achieve stability for system with a\nnonlinear NI uncertainty.",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Kanghong Shi",
      "Ian R. Petersen",
      "Igor G. Vladimirov"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.13603"
  },
  {
    "id": "arXiv:2203.13604",
    "title": "Formal Semantics and Formally Verified Validation for Temporal Planning",
    "abstract": "We present a simple and concise semantics for temporal planning. Our\nsemantics are developed and formalised in the logic of the interactive theorem\nprover Isabelle/HOL. We derive from those semantics a validation algorithm for\ntemporal planning and show, using a formal proof in Isabelle/HOL, that this\nvalidation algorithm implements our semantics. We experimentally evaluate our\nverified validation algorithm and show that it is practical.",
    "descriptor": "",
    "authors": [
      "Mohammad Abdulaziz",
      "Lukas Koller"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.13604"
  },
  {
    "id": "arXiv:2203.13607",
    "title": "Fast and computationally efficient generative adversarial network  algorithm for unmanned aerial vehicle-based network coverage optimization",
    "abstract": "The challenge of dynamic traffic demand in mobile networks is tackled by\nmoving cells based on unmanned aerial vehicles. Considering the tremendous\npotential of unmanned aerial vehicles in the future, we propose a new heuristic\nalgorithm for coverage optimization. The proposed algorithm is implemented\nbased on a conditional generative adversarial neural network, with a unique\nmultilayer sum-pooling loss function. To assess the performance of the proposed\napproach, we compare it with the optimal core-set algorithm and quasi-optimal\nspiral algorithm. Simulation results show that the proposed approach converges\nto the quasi-optimal solution with a negligible difference from the global\noptimum while maintaining a quadratic complexity regardless of the number of\nusers.",
    "descriptor": "\nComments: International Journal of Distributed Sensor Networks. 2022\n",
    "authors": [
      "Marek Ru\u017ei\u010dka",
      "Marcel Volo\u0161in",
      "Juraj Gazda",
      "Taras Maksymyuk",
      "Longzhe Han",
      "Mischa Dohler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.13607"
  },
  {
    "id": "arXiv:2203.13608",
    "title": "Rope3D: TheRoadside Perception Dataset for Autonomous Driving and  Monocular 3D Object Detection Task",
    "abstract": "Concurrent perception datasets for autonomous driving are mainly limited to\nfrontal view with sensors mounted on the vehicle. None of them is designed for\nthe overlooked roadside perception tasks. On the other hand, the data captured\nfrom roadside cameras have strengths over frontal-view data, which is believed\nto facilitate a safer and more intelligent autonomous driving system. To\naccelerate the progress of roadside perception, we present the first\nhigh-diversity challenging Roadside Perception 3D dataset- Rope3D from a novel\nview. The dataset consists of 50k images and over 1.5M 3D objects in various\nscenes, which are captured under different settings including various cameras\nwith ambiguous mounting positions, camera specifications, viewpoints, and\ndifferent environmental conditions. We conduct strict 2D-3D joint annotation\nand comprehensive data analysis, as well as set up a new 3D roadside perception\nbenchmark with metrics and evaluation devkit. Furthermore, we tailor the\nexisting frontal-view monocular 3D object detection approaches and propose to\nleverage the geometry constraint to solve the inherent ambiguities caused by\nvarious sensors, viewpoints. Our dataset is available on\nhttps://thudair.baai.ac.cn/rope.",
    "descriptor": "\nComments: To appear in CVPR2022\n",
    "authors": [
      "Xiaoqing Ye",
      "Mao Shu",
      "Hanyu Li",
      "Yifeng Shi",
      "Yingying Li",
      "Guangjie Wang",
      "Xiao Tan",
      "Errui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13608"
  },
  {
    "id": "arXiv:2203.13609",
    "title": "Unsupervised Pre-training for Temporal Action Localization Tasks",
    "abstract": "Unsupervised video representation learning has made remarkable achievements\nin recent years. However, most existing methods are designed and optimized for\nvideo classification. These pre-trained models can be sub-optimal for temporal\nlocalization tasks due to the inherent discrepancy between video-level\nclassification and clip-level localization. To bridge this gap, we make the\nfirst attempt to propose a self-supervised pretext task, coined as Pseudo\nAction Localization (PAL) to Unsupervisedly Pre-train feature encoders for\nTemporal Action Localization tasks (UP-TAL). Specifically, we first randomly\nselect temporal regions, each of which contains multiple clips, from one video\nas pseudo actions and then paste them onto different temporal positions of the\nother two videos. The pretext task is to align the features of pasted pseudo\naction regions from two synthetic videos and maximize the agreement between\nthem. Compared to the existing unsupervised video representation learning\napproaches, our PAL adapts better to downstream TAL tasks by introducing a\ntemporal equivariant contrastive learning paradigm in a temporally dense and\nscale-aware manner. Extensive experiments show that PAL can utilize large-scale\nunlabeled video data to significantly boost the performance of existing TAL\nmethods. Our codes and models will be made publicly available at\nhttps://github.com/zhang-can/UP-TAL.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Can Zhang",
      "Tianyu Yang",
      "Junwu Weng",
      "Meng Cao",
      "Jue Wang",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13609"
  },
  {
    "id": "arXiv:2203.13610",
    "title": "Learning to Adapt to Unseen Abnormal Activities under Weak Supervision",
    "abstract": "We present a meta-learning framework for weakly supervised anomaly detection\nin videos, where the detector learns to adapt to unseen types of abnormal\nactivities effectively when only video-level annotations of binary labels are\navailable. Our work is motivated by the fact that existing methods suffer from\npoor generalization to diverse unseen examples. We claim that an anomaly\ndetector equipped with a meta-learning scheme alleviates the limitation by\nleading the model to an initialization point for better optimization. We\nevaluate the performance of our framework on two challenging datasets,\nUCF-Crime and ShanghaiTech. The experimental results demonstrate that our\nalgorithm boosts the capability to localize unseen abnormal events in a weakly\nsupervised setting. Besides the technical contributions, we perform the\nannotation of missing labels in the UCF-Crime dataset and make our task\nevaluated effectively.",
    "descriptor": "\nComments: 20 pages, ACCV 2020\n",
    "authors": [
      "Jaeyoo Park",
      "Junha Kim",
      "Bohyung Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13610"
  },
  {
    "id": "arXiv:2203.13611",
    "title": "Class-Incremental Learning for Action Recognition in Videos",
    "abstract": "We tackle catastrophic forgetting problem in the context of class-incremental\nlearning for video recognition, which has not been explored actively despite\nthe popularity of continual learning. Our framework addresses this challenging\ntask by introducing time-channel importance maps and exploiting the importance\nmaps for learning the representations of incoming examples via knowledge\ndistillation. We also incorporate a regularization scheme in our objective\nfunction, which encourages individual features obtained from different time\nsteps in a video to be uncorrelated and eventually improves accuracy by\nalleviating catastrophic forgetting. We evaluate the proposed approach on\nbrand-new splits of class-incremental action recognition benchmarks constructed\nupon the UCF101, HMDB51, and Something-Something V2 datasets, and demonstrate\nthe effectiveness of our algorithm in comparison to the existing continual\nlearning methods that are originally designed for image data.",
    "descriptor": "\nComments: 12 pages, ICCV 2021\n",
    "authors": [
      "Jaeyoo Park",
      "Minsoo Kang",
      "Bohyung Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13611"
  },
  {
    "id": "arXiv:2203.13612",
    "title": "Repairing Group-Level Errors for DNNs Using Weighted Regularization",
    "abstract": "Deep Neural Networks (DNNs) have been widely used in software making\ndecisions impacting people's lives. However, they have been found to exhibit\nsevere erroneous behaviors that may lead to unfortunate outcomes. Previous work\nshows that such misbehaviors often occur due to class property violations\nrather than errors on a single image. Although methods for detecting such\nerrors have been proposed, fixing them has not been studied so far. Here, we\npropose a generic method called Weighted Regularization (WR) consisting of five\nconcrete methods targeting the error-producing classes to fix the DNNs. In\nparticular, it can repair confusion error and bias error of DNN models for both\nsingle-label and multi-label image classifications. A confusion error happens\nwhen a given DNN model tends to confuse between two classes. Each method in WR\nassigns more weights at a stage of DNN retraining or inference to mitigate the\nconfusion between target pair. A bias error can be fixed similarly. We evaluate\nand compare the proposed methods along with baselines on six widely-used\ndatasets and architecture combinations. The results suggest that WR methods\nhave different trade-offs but under each setting at least one WR method can\ngreatly reduce confusion/bias errors at a very limited cost of the overall\nperformance.",
    "descriptor": "",
    "authors": [
      "Ziyuan Zhong",
      "Yuchi Tian",
      "Conor J.Sweeney",
      "Vicente Ordonez-Roman",
      "Baishakhi Ray"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.13612"
  },
  {
    "id": "arXiv:2203.13616",
    "title": "Lightweight Graph Convolutional Networks with Topologically Consistent  Magnitude Pruning",
    "abstract": "Graph convolution networks (GCNs) are currently mainstream in learning with\nirregular data. These models rely on message passing and attention mechanisms\nthat capture context and node-to-node relationships. With multi-head attention,\nGCNs become highly accurate but oversized, and their deployment on cheap\ndevices requires their pruning. However, pruning at high regimes usually leads\nto topologically inconsistent networks with weak generalization. In this paper,\nwe devise a novel method for lightweight GCN design. Our proposed approach\nparses and selects subnetworks with the highest magnitudes while guaranteeing\ntheir topological consistency. The latter is obtained by selecting only\naccessible and co-accessible connections which actually contribute in the\nevaluation of the selected subnetworks. Experiments conducted on the\nchallenging FPHA dataset show the substantial gain of our topologically\nconsistent pruning method especially at very high pruning regimes.",
    "descriptor": "",
    "authors": [
      "Hichem Sahbi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13616"
  },
  {
    "id": "arXiv:2203.13619",
    "title": "Answering Should Self-Publishing Video Game Developers Market Their Game  on Twitter",
    "abstract": "In the marketing of video games made by self-publishing, independent\ndevelopers, there is common advice to market a game using the social media\nplatform Twitter. However, the advice that stems from industry sources is\nsomewhat contradictory, and many self-publishing independent developers elect\nnot to use Twitter at all. This presents an opportunity for researchers to\ninvestigate this tension and determine if using Twitter does have a causal\ninfluence on the successful release of a game by using relatively recent\ndevelopments in causal data science techniques. In this sense, this paper\nhighlights these causal inference developments while simultaneously informing\nself-publishing independent developers whether they should indeed market their\ngames using Twitter. It was found that using Twitter results in an average\nincrease of 85.4 reviews during release week, corresponding to a 314% positive\ndifference. Using Twitter also doubles the chance of reaching a critical\n10-review inflection point threshold on release week. These effects, however,\nare moderated by the characteristics of the game, expressed as 'tags', yet in\nno case is the effect of Twitter use reduced to 0. Based on these findings, it\nis advised that new, self-publishing video game developers do use Twitter to\nmarket their games.",
    "descriptor": "\nComments: Keywords: Twitter, Social Media Marketing, video games, independent developers, self-publishing\n",
    "authors": [
      "Nathaniel Francis Golding"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.13619"
  },
  {
    "id": "arXiv:2203.13620",
    "title": "Semi-Supervised Formality Style Transfer with Consistency Training",
    "abstract": "Formality style transfer (FST) is a task that involves paraphrasing an\ninformal sentence into a formal one without altering its meaning. To address\nthe data-scarcity problem of existing parallel datasets, previous studies tend\nto adopt a cycle-reconstruction scheme to utilize additional unlabeled data,\nwhere the FST model mainly benefits from target-side unlabeled sentences. In\nthis work, we propose a simple yet effective semi-supervised framework to\nbetter utilize source-side unlabeled sentences based on consistency training.\nSpecifically, our approach augments pseudo-parallel data obtained from a\nsource-side informal sentence by enforcing the model to generate similar\noutputs for its perturbed version. Moreover, we empirically examined the\neffects of various data perturbation methods and propose effective data\nfiltering strategies to improve our framework. Experimental results on the\nGYAFC benchmark demonstrate that our approach can achieve state-of-the-art\nresults, even with less than 40% of the parallel data.",
    "descriptor": "\nComments: ACL 2022 main conference\n",
    "authors": [
      "Ao Liu",
      "An Wang",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13620"
  },
  {
    "id": "arXiv:2203.13621",
    "title": "Post-Disaster Communications: Enabling Technologies, Architectures, and  Open Challenges",
    "abstract": "The number of disasters has increased over the past decade where these\ncalamities significantly affect the functionality of communication networks. In\nthe context of 6G, airborne and spaceborne networks offer hope in disaster\nrecovery to serve the underserved and to be resilient in calamities. Therefore,\nthis paper surveys the state-of-the-art literature on post-disaster wireless\ncommunication networks and provides insights for the future establishment of\nsuch networks. In particular, we first give an overview of the works\ninvestigating the general procedures and strategies for counteracting any\nlarge-scale disasters. Then, we present the possible technological solutions\nfor post-disaster communications, such as the recovery of the terrestrial\ninfrastructure, installing aerial networks, and using spaceborne networks.\nAfterward, we shed light on the technological aspects of post-disaster\nnetworks, primarily the physical and networking issues. We present the\nliterature on channel modeling, coverage and capacity, radio resource\nmanagement, localization, and energy efficiency in the physical layer and\ndiscuss the integrated space-air-ground architectures, routing,\ndelay-tolerant/software-defined networks, and edge computing in the networking\nlayer. This paper also presents interesting simulation results which can\nprovide practical guidelines about the deployment of ad hoc network\narchitectures in emergency scenarios. Finally, we present several promising\nresearch directions, namely backhauling, placement optimization of aerial base\nstations, and the mobility-related aspects that come into play when deploying\naerial networks, such as planning their trajectories and the consequent\nhandovers.",
    "descriptor": "",
    "authors": [
      "Maurilio Matracia",
      "Nasir Saeed",
      "Mustafa A. Kishk",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.13621"
  },
  {
    "id": "arXiv:2203.13623",
    "title": "The best defense is a good defense: adapting negotiation methods for  tackling pressure over software project estimates",
    "abstract": "Software estimation is critical for a software project's success and a\nchallenging activity. We argue that estimation problems are not restricted to\nthe generation of estimates but also their use for commitment establishment:\nproject stakeholders pressure estimators to change their estimates or to accept\nunrealistic commitments to attain business goals. In this study, we employed a\nDesign Science Research (DSR) methodology to design an artifact based on\nnegotiation methods, to empower software estimators in defending their\nestimates and searching for alternatives to unrealistic commitments when facing\npressure. The artifact is a concrete step towards disseminating the soft skill\nof negotiation among practitioners. We present the preliminary results from a\nfocus group that showed that practitioners from the software industry could use\nthe artifact in a concrete scenario when estimating and establishing\ncommitments about a software project. Our future steps include improving the\nartifact with the suggestions from focus group participants and evaluating it\nempirically in real software projects in the industry.",
    "descriptor": "\nComments: 5 pages, 1 figure, 1 table\n",
    "authors": [
      "Patricia G. F. Matsubara",
      "Igor Steinmacher",
      "Bruno Gadelha",
      "Tayana Conte"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.13623"
  },
  {
    "id": "arXiv:2203.13628",
    "title": "DeLoRes: Decorrelating Latent Spaces for Low-Resource Audio  Representation Learning",
    "abstract": "Inspired by the recent progress in self-supervised learning for computer\nvision, in this paper, through the DeLoRes learning framework, we introduce two\nnew general-purpose audio representation learning approaches, the DeLoRes-S and\nDeLoRes-M. Our main objective is to make our network learn representations in a\nresource-constrained setting (both data and compute), that can generalize well\nacross a diverse set of downstream tasks. Inspired from the Barlow Twins\nobjective function, we propose to learn embeddings that are invariant to\ndistortions of an input audio sample, while making sure that they contain\nnon-redundant information about the sample. To achieve this, we measure the\ncross-correlation matrix between the outputs of two identical networks fed with\ndistorted versions of an audio segment sampled from an audio file and make it\nas close to the identity matrix as possible. We call this the DeLoRes learning\nframework, which we employ in different fashions with the DeLoRes-S and\nDeLoRes-M. We use a combination of a small subset of the large-scale AudioSet\ndataset and FSD50K for self-supervised learning and are able to learn with less\nthan half the parameters compared to state-of-the-art algorithms. For\nevaluation, we transfer these learned representations to 11 downstream\nclassification tasks, including speech, music, and animal sounds, and achieve\nstate-of-the-art results on 7 out of 11 tasks on linear evaluation with\nDeLoRes-M and show competitive results with DeLoRes-S, even when pre-trained\nusing only a fraction of the total data when compared to prior art. Our\ntransfer learning evaluation setup also shows extremely competitive results for\nboth DeLoRes-S and DeLoRes-M, with DeLoRes-M achieving state-of-the-art in 4\ntasks.",
    "descriptor": "\nComments: Submitted to IEEE JSTSP Special Issue on Self-Supervised Learning for Speech and Audio Processing\n",
    "authors": [
      "Sreyan Ghosh",
      "Ashish Seth",
      "S Umesh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13628"
  },
  {
    "id": "arXiv:2203.13639",
    "title": "Give Me Your Attention: Dot-Product Attention Considered Harmful for  Adversarial Patch Robustness",
    "abstract": "Neural architectures based on attention such as vision transformers are\nrevolutionizing image recognition. Their main benefit is that attention allows\nreasoning about all parts of a scene jointly. In this paper, we show how the\nglobal reasoning of (scaled) dot-product attention can be the source of a major\nvulnerability when confronted with adversarial patch attacks. We provide a\ntheoretical understanding of this vulnerability and relate it to an adversary's\nability to misdirect the attention of all queries to a single key token under\nthe control of the adversarial patch. We propose novel adversarial objectives\nfor crafting adversarial patches which target this vulnerability explicitly. We\nshow the effectiveness of the proposed patch attacks on popular image\nclassification (ViTs and DeiTs) and object detection models (DETR). We find\nthat adversarial patches occupying 0.5% of the input can lead to robust\naccuracies as low as 0% for ViT on ImageNet, and reduce the mAP of DETR on MS\nCOCO to less than 3%.",
    "descriptor": "\nComments: to be published in IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022, CVPR22\n",
    "authors": [
      "Giulio Lovisotto",
      "Nicole Finnie",
      "Mauricio Munoz",
      "Chaithanya Kumar Mummadi",
      "Jan Hendrik Metzen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13639"
  },
  {
    "id": "arXiv:2203.13641",
    "title": "StretchBEV: Stretching Future Instance Prediction Spatially and  Temporally",
    "abstract": "In self-driving, predicting future in terms of location and motion of all the\nagents around the vehicle is a crucial requirement for planning. Recently, a\nnew joint formulation of perception and prediction has emerged by fusing rich\nsensory information perceived from multiple cameras into a compact bird's-eye\nview representation to perform prediction. However, the quality of future\npredictions degrades over time while extending to longer time horizons due to\nmultiple plausible predictions. In this work, we address this inherent\nuncertainty in future predictions with a stochastic temporal model. Our model\nlearns temporal dynamics in a latent space through stochastic residual updates\nat each time step. By sampling from a learned distribution at each time step,\nwe obtain more diverse future predictions that are also more accurate compared\nto previous work, especially stretching both spatially further regions in the\nscene and temporally over longer time horizons. Despite separate processing of\neach time step, our model is still efficient through decoupling of the learning\nof dynamics and the generation of future predictions.",
    "descriptor": "",
    "authors": [
      "Adil Kaan Akan",
      "Fatma G\u00fcney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13641"
  },
  {
    "id": "arXiv:2203.13645",
    "title": "Audio-text Retrieval in Context",
    "abstract": "Audio-text retrieval based on natural language descriptions is a challenging\ntask. It involves learning cross-modality alignments between long sequences\nunder inadequate data conditions. In this work, we investigate several audio\nfeatures as well as sequence aggregation methods for better audio-text\nalignment. Moreover, through a qualitative analysis we observe that semantic\nmapping is more important than temporal relations in contextual retrieval.\nUsing pre-trained audio features and a descriptor-based aggregation method, we\nbuild our contextual audio-text retrieval system. Specifically, we utilize\nPANNs features pre-trained on a large sound event dataset and NetRVLAD pooling,\nwhich directly works with averaged descriptors. Experiments are conducted on\nthe AudioCaps and CLOTHO datasets, and results are compared with the previous\nstate-of-the-art system. With our proposed system, a significant improvement\nhas been achieved on bidirectional audio-text retrieval, on all metrics\nincluding recall, median and mean rank.",
    "descriptor": "",
    "authors": [
      "Siyu Lou",
      "Xuenan Xu",
      "Mengyue Wu",
      "Kai Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13645"
  },
  {
    "id": "arXiv:2203.13648",
    "title": "Understanding the Difficulty of Training Physics-Informed Neural  Networks on Dynamical Systems",
    "abstract": "Physics-informed neural networks (PINNs) seamlessly integrate data and\nphysical constraints into the solving of problems governed by differential\nequations. In settings with little labeled training data, their optimization\nrelies on the complexity of the embedded physics loss function. Two fundamental\nquestions arise in any discussion of frequently reported convergence issues in\nPINNs: Why does the optimization often converge to solutions that lack physical\nbehavior? And why do reduced domain methods improve convergence behavior in\nPINNs? We answer these questions by studying the physics loss function in the\nvicinity of fixed points of dynamical systems. Experiments on a simple\ndynamical system demonstrate that physics loss residuals are trivially\nminimized in the vicinity of fixed points. As a result we observe that\nsolutions corresponding to nonphysical system dynamics can be dominant in the\nphysics loss landscape and optimization. We find that reducing the\ncomputational domain lowers the optimization complexity and chance of getting\ntrapped with nonphysical solutions.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Franz M. Rohrhofer",
      "Stefan Posch",
      "Clemens G\u00f6\u00dfnitzer",
      "Bernhard C. Geiger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13648"
  },
  {
    "id": "arXiv:2203.13652",
    "title": "HYDRA: Competing convolutional kernels for fast and accurate time series  classification",
    "abstract": "We demonstrate a simple connection between dictionary methods for time series\nclassification, which involve extracting and counting symbolic patterns in time\nseries, and methods based on transforming input time series using convolutional\nkernels, namely ROCKET and its variants. We show that by adjusting a single\nhyperparameter it is possible to move by degrees between models resembling\ndictionary methods and models resembling ROCKET. We present HYDRA, a simple,\nfast, and accurate dictionary method for time series classification using\ncompeting convolutional kernels, combining key aspects of both ROCKET and\nconventional dictionary methods. HYDRA is faster and more accurate than the\nmost accurate existing dictionary methods, and can be combined with ROCKET and\nits variants to further improve the accuracy of these methods.",
    "descriptor": "\nComments: 27 pages, 18 figures\n",
    "authors": [
      "Angus Dempster",
      "Daniel F. Schmidt",
      "Geoffrey I. Webb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13652"
  },
  {
    "id": "arXiv:2203.13653",
    "title": "An introduction to using dual quaternions to study kinematics",
    "abstract": "We advocate for the use of dual quaternions to represent poses, twists, and\nwrenches.",
    "descriptor": "\nComments: This is the advocacy part of arXiv:2202.09268\n",
    "authors": [
      "Stephen Montgomery-Smith",
      "Cecil Shy"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.13653"
  },
  {
    "id": "arXiv:2203.13654",
    "title": "Rank-based Non-dominated Sorting",
    "abstract": "Non-dominated sorting is a computational bottleneck in Pareto-based\nmulti-objective evolutionary algorithms (MOEAs) due to the runtime-intensive\ncomparison operations involved in establishing dominance relationships between\nsolution candidates. In this paper we introduce Rank Sort, a non-dominated\nsorting approach exploiting sorting stability and ordinal information to avoid\nexpensive dominance comparisons in the rank assignment phase. Two algorithmic\nvariants are proposed: the first one, RankOrdinal (RO), uses ordinal rank\ncomparisons in order to determine dominance and requires $O(N)$ space; the\nsecond one, RankIntersect (RS), uses set intersections and bit-level\nparallelism and requires O(N^2) space. We demonstrate the efficiency of the\nproposed methods in comparison with other state of the art algorithms in\nempirical simulations using the NSGA2 algorithm as well as synthetic\nbenchmarks. The RankIntersect algorithm is able to significantly outperform the\ncurrent state of the art offering up to 30% speed-up for many objectives. C++\nimplementations are provided for all algorithms.",
    "descriptor": "",
    "authors": [
      "Bogdan Burlacu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.13654"
  },
  {
    "id": "arXiv:2203.13655",
    "title": "Gransformer: Transformer-based Graph Generation",
    "abstract": "Transformers have become widely used in modern models for various tasks such\nas natural language processing and machine vision. This paper, proposes\nGransformer, an algorithm for generating graphs that takes advantage of the\ntransformer. We extend a simple autoregressive transformer encoder to exploit\nthe structural information of the graph through efficient modifications. The\nattention mechanism is modified to consider the presence or absence of edges\nbetween each pair of nodes. We also introduce a graph-based familiarity measure\nthat applies to both the attention and the positional coding. This\nautoregressive criterion, inspired by message passing algorithms, contains\nstructural information about the graph. In the output layer, we also use a\nmasked autoencoder for density estimation to efficiently model the generation\nof dependent edges. We also propose a technique to prevent the model from\ngenerating isolated nodes. We evaluate this method on two real-world datasets\nand compare it with some state-of-the-art autoregressive graph generation\nmethods. Experimental results have shown that the proposed method performs\ncomparative to these methods, including recurrent models and graph\nconvolutional networks.",
    "descriptor": "",
    "authors": [
      "Ahmad Khajenezhad",
      "Seyed Ali Osia",
      "Mahmood Karimian",
      "Hamid Beigy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13655"
  },
  {
    "id": "arXiv:2203.13658",
    "title": "MDsrv -- visual sharing and analysis of molecular dynamics simulations",
    "abstract": "Molecular dynamics simulation is a proven technique for computing and\nvisualizing the time-resolved motion of macromolecules at atomic resolution.\nThe MDsrv is a tool that streams MD trajectories and displays them\ninteractively in web browsers without requiring advanced skills, facilitating\ninteractive exploration and collaborative visual analysis. We have now enhanced\nthe MDsrv to further simplify the upload and sharing of MD trajectories and\nimprove their online viewing and analysis. With the new instance, the MDsrv\nsimplifies the creation of sessions, which allows the exchange of MD\ntrajectories with preset representations and perspectives. An important\ninnovation is that the MDsrv can now access and visualize trajectories from\nremote datasets, which greatly expands its applicability and use, as the data\nno longer needs to be accessible on a local server. In addition, initial\nanalyses such as sequence or structure alignments, distance measurements, or\nRMSD calculations have been implemented, which optionally support visual\nanalysis. Finally, the MDsrv now offers a faster and more efficient\nvisualization of even large trajectories.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Michelle Kampfrath",
      "Ren\u00e9 Staritzbichler",
      "Guillermo P\u00e9rez Hern\u00e1ndez",
      "Alexander S. Rose",
      "Johanna K.S. Tiemann",
      "Gerik Scheuermann",
      "Daniel Wiegreffe",
      "Peter W. Hildebrand"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.13658"
  },
  {
    "id": "arXiv:2203.13661",
    "title": "Common Failure Modes of Subcluster-based Sampling in Dirichlet Process  Gaussian Mixture Models -- and a Deep-learning Solution",
    "abstract": "The Dirichlet Process Gaussian Mixture Model (DPGMM) is often used to cluster\ndata when the number of clusters is unknown. One main DPGMM inference paradigm\nrelies on sampling. Here we consider a known state-of-art sampler (proposed by\nChang and Fisher III (2013) and improved by Dinari et al. (2019)), analyze its\nfailure modes, and show how to improve it, often drastically. Concretely, in\nthat sampler, whenever a new cluster is formed it is augmented with two\nsubclusters whose labels are initialized at random. Upon their evolution, the\nsubclusters serve to propose a split of the parent cluster. We show that the\nrandom initialization is often problematic and hurts the otherwise-effective\nsampler. Specifically, we demonstrate that this initialization tends to lead to\npoor split proposals and/or too many iterations before a desired split is\naccepted. This slows convergence and can damage the clustering. As a remedy, we\npropose two drop-in-replacement options for the subcluster-initialization\nsubroutine. The first is an intuitive heuristic while the second is based on\ndeep learning. We show that the proposed approach yields better splits, which\nin turn translate to substantial improvements in performance, results, and\nstability.",
    "descriptor": "\nComments: 24 pages, 18 figures. To be published in AISTATS 2022\n",
    "authors": [
      "Vlad Winter",
      "Or Dinari",
      "Oren Freifeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13661"
  },
  {
    "id": "arXiv:2203.13662",
    "title": "Efficient Strong Privacy-Preserving Conjunctive Keyword Search Over  Encrypted Cloud Data",
    "abstract": "Searchable symmetric encryption (SSE) supports keyword search over outsourced\nsymmetrically encrypted data. Dynamic searchable symmetric encryption (DSSE), a\nvariant of SSE, further enables data updating. Most prior DSSE works primarily\nfocus on single keyword search, and some have later expanded to support\nconjunctive keyword search. These works on conjunctive DSSE primarily consider\nforward and backward privacy. Ideally, the server should only learn the result\nsets related to all the keywords in the conjunction. However, existing schemes\nsuffer from keyword pair result pattern (KPRP) leakage, making the server\nreveal the partial result sets containing two of the query keywords. We propose\nthe first DSSE scheme to address the above concerns that achieves strong\nprivacy-preserving conjunctive keyword search. Specifically, our scheme can\nmaintain forward and backward privacy and eliminate KPRP leakage, offering a\nhigher level of security for DSSE. The search complexity is proportional to the\nnumber of documents stored in the database in several existing schemes.\nHowever, the complexity of our scheme scales with the update frequency of the\nleast frequent keyword in the conjunction, which is much smaller than the size\nof the entire database. Besides, we devise a least frequent keyword acquisition\nprotocol to reduce the frequent interactions between the data owner and search\nusers. Finally, we analyze the security of our scheme and evaluate its\nperformance theoretically and experimentally. The results show that our scheme\nhas strong privacy preservation and efficiency.",
    "descriptor": "",
    "authors": [
      "Chang Xu",
      "Ruijuan Wang",
      "Liehuang Zhu",
      "Chuan Zhang",
      "Rongxing Lu",
      "Kashif Sharif"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.13662"
  },
  {
    "id": "arXiv:2203.13663",
    "title": "FedGradNorm: Personalized Federated Gradient-Normalized Multi-Task  Learning",
    "abstract": "Multi-task learning (MTL) is a novel framework to learn several tasks\nsimultaneously with a single shared network where each task has its distinct\npersonalized header network for fine-tuning. MTL can be implemented in\nfederated learning settings as well, in which tasks are distributed across\nclients. In federated settings, the statistical heterogeneity due to different\ntask complexities and data heterogeneity due to non-iid nature of local\ndatasets can both degrade the learning performance of the system. In addition,\ntasks can negatively affect each other's learning performance due to negative\ntransference effects. To cope with these challenges, we propose FedGradNorm\nwhich uses a dynamic-weighting method to normalize gradient norms in order to\nbalance learning speeds among different tasks. FedGradNorm improves the overall\nlearning performance in a personalized federated learning setting. We provide\nconvergence analysis for FedGradNorm by showing that it has an exponential\nconvergence rate. We also conduct experiments on multi-task facial landmark\n(MTFL) and wireless communication system dataset (RadComDynamic). The\nexperimental results show that our framework can achieve faster training\nperformance compared to equal-weighting strategy. In addition to improving\ntraining speed, FedGradNorm also compensates for the imbalanced datasets among\nclients.",
    "descriptor": "",
    "authors": [
      "Matin Mortaheb",
      "Cemil Vahapoglu",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13663"
  },
  {
    "id": "arXiv:2203.13664",
    "title": "Adjacent Context Coordination Network for Salient Object Detection in  Optical Remote Sensing Images",
    "abstract": "Salient object detection (SOD) in optical remote sensing images (RSIs), or\nRSI-SOD, is an emerging topic in understanding optical RSIs. However, due to\nthe difference between optical RSIs and natural scene images (NSIs), directly\napplying NSI-SOD methods to optical RSIs fails to achieve satisfactory results.\nIn this paper, we propose a novel Adjacent Context Coordination Network\n(ACCoNet) to explore the coordination of adjacent features in an\nencoder-decoder architecture for RSI-SOD. Specifically, ACCoNet consists of\nthree parts: an encoder, Adjacent Context Coordination Modules (ACCoMs), and a\ndecoder. As the key component of ACCoNet, ACCoM activates the salient regions\nof output features of the encoder and transmits them to the decoder. ACCoM\ncontains a local branch and two adjacent branches to coordinate the multi-level\nfeatures simultaneously. The local branch highlights the salient regions in an\nadaptive way, while the adjacent branches introduce global information of\nadjacent levels to enhance salient regions. Additionally, to extend the\ncapabilities of the classic decoder block (i.e., several cascaded convolutional\nlayers), we extend it with two bifurcations and propose a\nBifurcation-Aggregation Block to capture the contextual information in the\ndecoder. Extensive experiments on two benchmark datasets demonstrate that the\nproposed ACCoNet outperforms 22 state-of-the-art methods under nine evaluation\nmetrics, and runs up to 81 fps on a single NVIDIA Titan X GPU. The code and\nresults of our method are available at https://github.com/MathLee/ACCoNet.",
    "descriptor": "\nComments: 13 pages, 7 figures, Accepted by IEEE Transactions on Cybernetics 2022\n",
    "authors": [
      "Gongyang Li",
      "Zhi Liu",
      "Dan Zeng",
      "Weisi Lin",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13664"
  },
  {
    "id": "arXiv:2203.13671",
    "title": "Flexible development and evaluation of machine-learning-supported  optimal control and estimation methods via HILO-MPC",
    "abstract": "Model-based optimization approaches for monitoring and control, such as model\npredictive control and optimal state and parameter estimation, have been used\nfor decades in many engineering applications. Models describing the dynamics,\nconstraints, and desired performance criteria are fundamental to model-based\napproaches. Thanks to recent technological advancements in digitalization,\nmachine learning methods such as deep learning, and computing power, there has\nbeen an increasing interest in using machine learning methods alongside\nmodel-based approaches for control and estimation. The number of new methods\nand theoretical findings using machine learning for model-based control and\noptimization is increasing rapidly. This paper outlines the basic ideas and\nprinciples behind an easy-to-use Python toolbox that allows to quickly and\nefficiently solve machine-learning-supported optimization, model predictive\ncontrol, and estimation problems. The toolbox leverages state-of-the-art\nmachine learning libraries to train components used to define the problem. It\nallows to efficiently solve the resulting optimization problems. Machine\nlearning can be used for a broad spectrum of tasks, ranging from model\npredictive control for stabilization, setpoint tracking, path following, and\ntrajectory tracking to moving horizon estimation and Kalman filtering. For\nlinear systems, it enables quick code generation for embedded MPC applications.\nHILO-MPC is flexible and adaptable, making it especially suitable for research\nand fundamental development tasks. Due to its simplicity and numerous already\nimplemented examples, it is also a powerful teaching tool. The usability is\nunderlined, presenting a series of application examples.",
    "descriptor": "",
    "authors": [
      "Johannes Pohlodek",
      "Bruno Morabito. Christian Schlauch",
      "Pablo Zometa",
      "Rolf Findeisen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.13671"
  },
  {
    "id": "arXiv:2203.13674",
    "title": "Dense Continuous-Time Optical Flow from Events and Frames",
    "abstract": "We present a method for estimating dense continuous-time optical flow.\nTraditional dense optical flow methods compute the pixel displacement between\ntwo images. Due to missing information, these approaches cannot recover the\npixel trajectories in the blind time between two images. In this work, we show\nthat it is possible to compute per-pixel, continuous-time optical flow by\nadditionally using events from an event camera. Events provide temporally\nfine-grained information about movement in image space due to their\nasynchronous nature and microsecond response time. We leverage these benefits\nto predict pixel trajectories densely in continuous-time via parameterized\nB\\'ezier curves. To achieve this, we introduce multiple innovations to build a\nneural network with strong inductive biases for this task: First, we build\nmultiple sequential correlation volumes in time using event data. Second, we\nuse B\\'ezier curves to index these correlation volumes at multiple timestamps\nalong the trajectory. Third, we use the retrieved correlation to update the\nB\\'ezier curve representations iteratively. Our method can optionally include\nimage pairs to boost performance further. The proposed approach outperforms\nexisting image-based and event-based methods by 11.5 % lower EPE on DSEC-Flow.\nFinally, we introduce a novel synthetic dataset MultiFlow for pixel trajectory\nregression on which our method is currently the only successful approach.",
    "descriptor": "",
    "authors": [
      "Mathias Gehrig",
      "Manasi Muglikar",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13674"
  },
  {
    "id": "arXiv:2203.13675",
    "title": "On the performance of preconditioned methods to solve \\(L^p\\)-norm phase  unwrapping",
    "abstract": "In this paper, we analyze and evaluate suitable preconditioning techniques to\nimprove the performance of the $L^p$-norm phase unwrapping method. We consider\nfive preconditioning techniques commonly found in the literature, and analyze\ntheir performance with different sizes of wrapped-phase maps. Keywords.- Phase\nunwrapping, $L^p$-norm based method, Preconditioning techniques.",
    "descriptor": "",
    "authors": [
      "Ricardo Legarda-Saenz",
      "Carlos Brito-Loeza",
      "Arturo Espinosa-Romero"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13675"
  },
  {
    "id": "arXiv:2203.13678",
    "title": "LQoCo: Learning to Optimize Cache Capacity Overloading in Storage  Systems",
    "abstract": "Cache plays an important role to maintain high and stable performance (i.e.\nhigh throughput, low tail latency and throughput jitter) in storage systems.\nExisting rule-based cache management methods, coupled with engineers' manual\nconfigurations, cannot meet ever-growing requirements of both time-varying\nworkloads and complex storage systems, leading to frequent cache overloading.\nIn this paper, we for the first time propose a light-weight learning-based\ncache bandwidth control technique, called \\LQoCo which can adaptively control\nthe cache bandwidth so as to effectively prevent cache overloading in storage\nsystems. Extensive experiments with various workloads on real systems show that\nLQoCo, with its strong adaptability and fast learning ability, can adapt to\nvarious workloads to effectively control cache bandwidth, thereby significantly\nimproving the storage performance (e.g. increasing the throughput by 10\\%-20\\%\nand reducing the throughput jitter and tail latency by 2X-6X and 1.5X-4X,\nrespectively, compared with two representative rule-based methods).",
    "descriptor": "\nComments: This paper has been accepted by DAC 2022. Xijun is the correspoonding author\n",
    "authors": [
      "Ji Zhang",
      "Xijun Li",
      "Xiyao Zhou",
      "Mingxuan Yuan",
      "Zhuo Cheng",
      "Keji Huang",
      "Yifan Li"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.13678"
  },
  {
    "id": "arXiv:2203.13685",
    "title": "Learning to Mediate Disparities Towards Pragmatic Communication",
    "abstract": "Human communication is a collaborative process. Speakers, on top of conveying\ntheir own intent, adjust the content and language expressions by taking the\nlisteners into account, including their knowledge background, personalities,\nand physical capabilities. Towards building AI agents with similar abilities in\nlanguage communication, we propose Pragmatic Rational Speaker (PRS), a\nframework extending Rational Speech Act (RSA). The PRS attempts to learn the\nspeaker-listener disparity and adjust the speech accordingly, by adding a\nlight-weighted disparity adjustment layer into working memory on top of\nspeaker's long-term memory system. By fixing the long-term memory, the PRS only\nneeds to update its working memory to learn and adapt to different types of\nlisteners. To validate our framework, we create a dataset that simulates\ndifferent types of speaker-listener disparities in the context of referential\ngames. Our empirical results demonstrate that the PRS is able to shift its\noutput towards the language that listener are able to understand, significantly\nimprove the collaborative task outcome.",
    "descriptor": "\nComments: 9 pages. Accepted to ACL 2022\n",
    "authors": [
      "Yuwei Bao",
      "Sayan Ghosh",
      "Joyce Chai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13685"
  },
  {
    "id": "arXiv:2203.13686",
    "title": "Satellite Infrastructure/Mission Tradeoffs",
    "abstract": "If a unit cannot receive intelligence from a source due to external factors,\nwe consider them disadvantaged users. We categorize this as a preoccupied unit\nworking on a low connectivity device on the edge. This case requires that we\nuse a different approach to deliver intelligence, particularly satellite\nimagery information, than normally employed. To address this, we propose a\nsurvey of information reduction techniques to deliver the information from a\nsatellite image in a smaller package. We investigate four techniques to aid in\nthe reduction of delivered information: traditional image compression, neural\nnetwork image compression, object detection image cutout, and image to caption.\nEach of these mechanisms have their benefits and tradeoffs when considered for\na disadvantaged user.",
    "descriptor": "\nComments: 3 Pages, 2 Figures, 1 Table, 31 Refereneces\n",
    "authors": [
      "Matthew Ciolino"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.13686"
  },
  {
    "id": "arXiv:2203.13687",
    "title": "Chain-based Discriminative Autoencoders for Speech Recognition",
    "abstract": "In our previous work, we proposed a discriminative autoencoder (DcAE) for\nspeech recognition. DcAE combines two training schemes into one. First, since\nDcAE aims to learn encoder-decoder mappings, the squared error between the\nreconstructed speech and the input speech is minimized. Second, in the code\nlayer, frame-based phonetic embeddings are obtained by minimizing the\ncategorical cross-entropy between ground truth labels and predicted\ntriphone-state scores. DcAE is developed based on the Kaldi toolkit by treating\nvarious TDNN models as encoders. In this paper, we further propose three new\nversions of DcAE. First, a new objective function that considers both\ncategorical cross-entropy and mutual information between ground truth and\npredicted triphone-state sequences is used. The resulting DcAE is called a\nchain-based DcAE (c-DcAE). For application to robust speech recognition, we\nfurther extend c-DcAE to hierarchical and parallel structures, resulting in\nhc-DcAE and pc-DcAE. In these two models, both the error between the\nreconstructed noisy speech and the input noisy speech and the error between the\nenhanced speech and the reference clean speech are taken into the objective\nfunction. Experimental results on the WSJ and Aurora-4 corpora show that our\nDcAE models outperform baseline systems.",
    "descriptor": "\nComments: submitted to Interspeech 2022\n",
    "authors": [
      "Hung-Shin Lee",
      "Pin-Tuan Huang",
      "Yao-Fei Cheng",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13687"
  },
  {
    "id": "arXiv:2203.13691",
    "title": "The TerraByte Client: providing access to terabytes of plant data",
    "abstract": "In this paper we demonstrate the TerraByte Client, a software to download\nuser-defined plant datasets from a data portal hosted at Compute Canada. To\nthat end the client offers two key functionalities: (1) It allows the user to\nget an overview on what data is available and a quick way to visually check\nsamples of that data. For this the client receives the results of queries to a\ndatabase and displays the number of images that fulfill the search criteria.\nFurthermore, a sample can be downloaded within seconds to confirm that the data\nsuits the user's needs. (2) The user can then download the specified data to\ntheir own drive. This data is prepared into chunks server-side and sent to the\nuser's end-system, where it is automatically extracted into individual files.\nThe first chunks of data are available for inspection after a brief waiting\nperiod of a minute or less depending on available bandwidth and type of data.\nThe TerraByte Client has a full graphical user interface for easy usage and\nuses end-to-end encryption. The user interface is built on top of a low-level\nclient. This architecture in combination of offering the client program\nopen-source makes it possible for the user to develop their own user interface\nor use the client's functionality directly. An example for direct usage could\nbe to download specific data on demand within a larger application, such as\ntraining machine learning models.",
    "descriptor": "",
    "authors": [
      "Michael A. Beck",
      "Christopher P. Bidinosti",
      "Christopher J. Henry",
      "Manisha Ajmani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.13691"
  },
  {
    "id": "arXiv:2203.13692",
    "title": "Bisimulations for Verifying Strategic Abilities with an Application to  the ThreeBallot Voting Protocol",
    "abstract": "We propose a notion of alternating bisimulation for strategic abilities under\nimperfect information. The bisimulation preserves formulas of ATL$^*$ for both\nthe {\\em objective} and {\\em subjective} variants of the state-based semantics\nwith imperfect information, which are commonly used in the modeling and\nverification of multi-agent systems. Furthermore, we apply the theoretical\nresult to the verification of coercion-resistance in the ThreeBallot voting\nsystem, a voting protocol that does not use cryptography. In particular, we\nshow that natural simplifications of an initial model of the protocol are in\nfact bisimulations of the original model, and therefore satisfy the same\nATL$^*$ properties, including coercion-resistance. These simplifications allow\nthe model-checking tool MCMAS to terminate on models with a larger number of\nvoters and candidates, compared with the initial model.",
    "descriptor": "",
    "authors": [
      "Francesco Belardinelli",
      "Rodica Condurache",
      "Catalin Dima",
      "Wojciech Jamroga",
      "Michal Knapik"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.13692"
  },
  {
    "id": "arXiv:2203.13693",
    "title": "UKP-SQUARE: An Online Platform for Question Answering Research",
    "abstract": "Recent advances in NLP and information retrieval have given rise to a diverse\nset of question answering tasks that are of different formats (e.g.,\nextractive, abstractive), require different model architectures (e.g.,\ngenerative, discriminative), and setups (e.g., with or without retrieval).\nDespite having a large number of powerful, specialized QA pipelines (which we\nrefer to as Skills) that consider a single domain, model or setup, there exists\nno framework where users can easily explore and compare such pipelines and can\nextend them according to their needs. To address this issue, we present\nUKP-SQUARE, an extensible online QA platform for researchers which allows users\nto query and analyze a large collection of modern Skills via a user-friendly\nweb interface and integrated behavioural tests. In addition, QA researchers can\ndevelop, manage, and share their custom Skills using our microservices that\nsupport a wide range of models (Transformers, Adapters, ONNX), datastores and\nretrieval techniques (e.g., sparse and dense). UKP-SQUARE is available on\nhttps://square.ukp-lab.de.",
    "descriptor": "\nComments: Accepted at ACL 2022 Demo Track\n",
    "authors": [
      "Tim Baumg\u00e4rtner",
      "Kexin Wang",
      "Rachneet Sachdeva",
      "Max Eichler",
      "Gregor Geigle",
      "Clifton Poth",
      "Hannah Sterz",
      "Haritz Puerto",
      "Leonardo F. R. Ribeiro",
      "Jonas Pfeiffer",
      "Nils Reimers",
      "G\u00f6zde G\u00fcl \u015eahin",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.13693"
  },
  {
    "id": "arXiv:2203.13694",
    "title": "Implicit Neural Representations for Variable Length Human Motion  Generation",
    "abstract": "We propose an action-conditional human motion generation method using\nvariational implicit neural representations (INR). The variational formalism\nenables action-conditional distributions of INRs, from which one can easily\nsample representations to generate novel human motion sequences. Our method\noffers variable-length sequence generation by construction because a part of\nINR is optimized for a whole sequence of arbitrary length with temporal\nembeddings. In contrast, previous works reported difficulties with modeling\nvariable-length sequences. We confirm that our method with a Transformer\ndecoder outperforms all relevant methods on HumanAct12, NTU-RGBD, and UESTC\ndatasets in terms of realism and diversity of generated motions. Surprisingly,\neven our method with an MLP decoder consistently outperforms the\nstate-of-the-art Transformer-based auto-encoder. In particular, we show that\nvariable-length motions generated by our method are better than fixed-length\nmotions generated by the state-of-the-art method in terms of realism and\ndiversity.",
    "descriptor": "",
    "authors": [
      "Pablo Cervantes",
      "Yusuke Sekikawa",
      "Ikuro Sato",
      "Koichi Shinoda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13694"
  },
  {
    "id": "arXiv:2203.13696",
    "title": "Speech-enhanced and Noise-aware Networks for Robust Speech Recognition",
    "abstract": "Compensation for channel mismatch and noise interference is essential for\nrobust automatic speech recognition. Enhanced speech has been introduced into\nthe multi-condition training of acoustic models to improve their generalization\nability. In this paper, a noise-aware training framework based on two cascaded\nneural structures is proposed to jointly optimize speech enhancement and speech\nrecognition. The feature enhancement module is composed of a multi-task\nautoencoder, where noisy speech is decomposed into clean speech and noise. By\nconcatenating its enhanced, noise-aware, and noisy features for each frame, the\nacoustic-modeling module maps each feature-augmented frame into a triphone\nstate by optimizing the lattice-free maximum mutual information and cross\nentropy between the predicted and actual state sequences. On top of the\nfactorized time delay neural network (TDNN-F) and its convolutional variant\n(CNN-TDNNF), both with SpecAug, the two proposed systems achieve word error\nrate (WER) of 3.90% and 3.55%, respectively, on the Aurora-4 task. Compared\nwith the best existing systems that use bigram and trigram language models for\ndecoding, the proposed CNN-TDNNF-based system achieves a relative WER reduction\nof 15.20% and 33.53%, respectively. In addition, the proposed CNN-TDNNF-based\nsystem also outperforms the baseline CNN-TDNNF system on the AMI task.",
    "descriptor": "\nComments: submitted to Interspeech 2022\n",
    "authors": [
      "Hung-Shin Lee",
      "Pin-Yuan Chen",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13696"
  },
  {
    "id": "arXiv:2203.13699",
    "title": "Unsupervised Image Deraining: Optimization Model Driven Deep CNN",
    "abstract": "The deep convolutional neural network has achieved significant progress for\nsingle image rain streak removal. However, most of the data-driven learning\nmethods are full-supervised or semi-supervised, unexpectedly suffering from\nsignificant performance drops when dealing with real rain. These data-driven\nlearning methods are representative yet generalize poor for real rain. The\nopposite holds true for the model-driven unsupervised optimization methods. To\novercome these problems, we propose a unified unsupervised learning framework\nwhich inherits the generalization and representation merits for real rain\nremoval. Specifically, we first discover a simple yet important domain\nknowledge that directional rain streak is anisotropic while the natural clean\nimage is isotropic, and formulate the structural discrepancy into the energy\nfunction of the optimization model. Consequently, we design an optimization\nmodel-driven deep CNN in which the unsupervised loss function of the\noptimization model is enforced on the proposed network for better\ngeneralization. In addition, the architecture of the network mimics the main\nrole of the optimization models with better feature representation. On one\nhand, we take advantage of the deep network to improve the representation. On\nthe other hand, we utilize the unsupervised loss of the optimization model for\nbetter generalization. Overall, the unsupervised learning framework achieves\ngood generalization and representation: unsupervised training (loss) with only\na few real rainy images (input) and physical meaning network (architecture).\nExtensive experiments on synthetic and real-world rain datasets show the\nsuperiority of the proposed method.",
    "descriptor": "\nComments: Accept to 2021ACMMM\n",
    "authors": [
      "Changfeng Yu",
      "Yi Chang",
      "Yi Li",
      "Xile Zhao",
      "Luxin Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.13699"
  },
  {
    "id": "arXiv:2203.13704",
    "title": "Clustering Aided Weakly Supervised Training to Detect Anomalous Events  in Surveillance Videos",
    "abstract": "Formulating learning systems for the detection of real-world anomalous events\nusing only video-level labels is a challenging task mainly due to the presence\nof noisy labels as well as the rare occurrence of anomalous events in the\ntraining data. We propose a weakly supervised anomaly detection system which\nhas multiple contributions including a random batch selection mechanism to\nreduce inter-batch correlation and a normalcy suppression block which learns to\nminimize anomaly scores over normal regions of a video by utilizing the overall\ninformation available in a training batch. In addition, a clustering loss block\nis proposed to mitigate the label noise and to improve the representation\nlearning for the anomalous and normal regions. This block encourages the\nbackbone network to produce two distinct feature clusters representing normal\nand anomalous events. Extensive analysis of the proposed approach is provided\nusing three popular anomaly detection datasets including UCF-Crime,\nShanghaiTech, and UCSD Ped2. The experiments demonstrate a superior anomaly\ndetection capability of our approach.",
    "descriptor": "\nComments: This work has been submitted to the IEEE Transactions on Neural Networks and Learning Systems (TNNLS) for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Muhammad Zaigham Zaheer",
      "Arif Mahmood",
      "Marcella Astrid",
      "Seung-Ik Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13704"
  },
  {
    "id": "arXiv:2203.13705",
    "title": "Anchoring Code Understandability Evaluations Through Task Descriptions",
    "abstract": "In code comprehension experiments, participants are usually told at the\nbeginning what kind of code comprehension task to expect. Describing experiment\nscenarios and experimental tasks will influence participants in ways that are\nsometimes hard to predict and control. In particular, describing or even\nmentioning the difficulty of a code comprehension task might anchor\nparticipants and their perception of the task itself. In this study, we\ninvestigated in a randomized, controlled experiment with 256 participants (50\nsoftware professionals and 206 computer science students) whether a hint about\nthe difficulty of the code to be understood in a task description anchors\nparticipants in their own code comprehensibility ratings. Subjective code\nevaluations are a commonly used measure for how well a developer in a code\ncomprehension study understood code. Accordingly, it is important to understand\nhow robust these measures are to cognitive biases such as the anchoring effect.\nOur results show that participants are significantly influenced by the initial\nscenario description in their assessment of code comprehensibility. An initial\nhint of hard to understand code leads participants to assess the code as harder\nto understand than participants who received no hint or a hint of easy to\nunderstand code. This affects students and professionals alike. We discuss\nexamples of design decisions and contextual factors in the conduct of code\ncomprehension experiments that can induce an anchoring effect, and recommend\nthe use of more robust comprehension measures in code comprehension studies to\nenhance the validity of results.",
    "descriptor": "\nComments: 8 pages, 2 figures. To appear in ICPC '22: IEEE/ACM International Conference on Program Comprehension, May 21-22, 2022, Pittsburgh, Pennsylvania, United States\n",
    "authors": [
      "Marvin Wyrich",
      "Lasse Merz",
      "Daniel Graziotin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.13705"
  },
  {
    "id": "arXiv:2203.13708",
    "title": "LAMBDA: Covering the Solution Set of Black-Box Inequality by Search  Space Quantization",
    "abstract": "Black-box functions are broadly used to model complex problems that provide\nno explicit information but the input and output. Despite existing studies of\nblack-box function optimization, the solution set satisfying an inequality with\na black-box function plays a more significant role than only one optimum in\nmany practical situations. Covering as much as possible of the solution set\nthrough limited evaluations to the black-box objective function is defined as\nthe Black-Box Coverage (BBC) problem in this paper. We formalized this problem\nin a sample-based search paradigm and constructed a coverage criterion with\nConfusion Matrix Analysis. Further, we propose LAMBDA (Latent-Action\nMonte-Carlo Beam Search with Density Adaption) to solve BBC problems. LAMBDA\ncan focus around the solution set quickly by recursively partitioning the\nsearch space into accepted and rejected sub-spaces. Compared with La-MCTS,\nLAMBDA introduces density information to overcome the sampling bias of\noptimization and obtain more exploration. Benchmarking shows, LAMBDA achieved\nstate-of-the-art performance among all baselines and was at most 33x faster to\nget 95% coverage than Random Search. Experiments also demonstrate that LAMBDA\nhas a promising future in the verification of autonomous systems in virtual\ntests.",
    "descriptor": "",
    "authors": [
      "Lihao Liu",
      "Tianyue Feng",
      "Xingyu Xing",
      "Junyi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.13708"
  },
  {
    "id": "arXiv:2203.13710",
    "title": "Internet of Drones Simulator: Design, Implementation, and Performance  Evaluation",
    "abstract": "The Internet of Drones (IoD) is a networking architecture that stems from the\ninterplay between Unmanned Aerial Vehicles (UAVs) and wireless communication\ntechnologies. Networked drones can unleash disruptive scenarios in many\napplication domains. At the same time, to really capitalize their potential,\naccurate modeling techniques are required to catch the fine details that\ncharacterize the features and limitations of UAVs, wireless communications, and\nnetworking protocols. To this end, the present contribution proposes the\nInternet of Drones Simulator (IoD-Sim), a comprehensive and versatile open\nsource tool that addresses the many facets of the IoD. IoD-Sim is a Network\nSimulator 3 (ns-3)-based simulator organized in a 3-layer stack, composed by\n(i) the Underlying Platform, which provides the telecommunication primitives\nfor different standardized protocol stacks, (ii) the Core, that implements all\nthe fundamental features of an IoD scenario, and (iii) the Simulation\nDevelopment Platform, mainly composed by a set of tools that speeds up the\ngraphical design for every possible use-case. In order to prove the huge\npotential of this proposal, three different scenarios are presented and\nanalyzed from both a software perspective and a telecommunication standpoint.\nThe peculiarities of this open-source tool are of interest for researchers in\nacademia, as they will be able to extend to model upcoming specifications,\nincluding, but not limited to, mobile networks and satellite communications.\nStill, it will certainly be of relevance in industry to accelerate the design\nphase, thus improving the time-to-market of IoD-based services.",
    "descriptor": "",
    "authors": [
      "Giovanni Grieco",
      "Giovanni Iacovelli",
      "Pietro Boccadoro",
      "Luigi Alfredo Grieco"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.13710"
  },
  {
    "id": "arXiv:2203.13712",
    "title": "Effective and Efficient Core Decomposition in Signed Networks",
    "abstract": "With the proliferation of mobile technology and IT development, people can\nuse social network services at any place and anytime. Among many social network\nmining problems, identifying cohesive subgraphs attract many attentions from\ndifferent fields due to its numerous applications. Among many cohesive subgraph\nmodels, k-core is the most widely used model due to its simple and intuitive\nstructure. In this paper, we formulate (p,n)-core in signed networks by\nextending k-core. (p,n)-core simultaneously guarantees the sufficient internal\npositive edges and deficient internal negative edges. We formally prove that\nfinding an exact (p,n)-core is NP-hard. Hence, we propose three efficient and\neffective algorithms to find a solution. Using real-world and synthetic\nnetworks, we demonstrate the superiority of our proposed algorithms.",
    "descriptor": "",
    "authors": [
      "Junghoon Kim",
      "Sungsu Lim",
      "Jungeun Kim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.13712"
  },
  {
    "id": "arXiv:2203.13714",
    "title": "Searching for Network Width with Bilaterally Coupled Network",
    "abstract": "Searching for a more compact network width recently serves as an effective\nway of channel pruning for the deployment of convolutional neural networks\n(CNNs) under hardware constraints. To fulfill the searching, a one-shot\nsupernet is usually leveraged to efficiently evaluate the performance\n\\wrt~different network widths. However, current methods mainly follow a\n\\textit{unilaterally augmented} (UA) principle for the evaluation of each\nwidth, which induces the training unfairness of channels in supernet. In this\npaper, we introduce a new supernet called Bilaterally Coupled Network (BCNet)\nto address this issue. In BCNet, each channel is fairly trained and responsible\nfor the same amount of network widths, thus each network width can be evaluated\nmore accurately. Besides, we propose to reduce the redundant search space and\npresent the BCNetV2 as the enhanced supernet to ensure rigorous training\nfairness over channels. Furthermore, we leverage a stochastic complementary\nstrategy for training the BCNet, and propose a prior initial population\nsampling method to boost the performance of the evolutionary search. We also\npropose the first open-source width benchmark on macro structures named\nChannel-Bench-Macro for the better comparison of width search algorithms.\nExtensive experiments on benchmark CIFAR-10 and ImageNet datasets indicate that\nour method can achieve state-of-the-art or competing performance over other\nbaseline methods. Moreover, our method turns out to further boost the\nperformance of NAS models by refining their network widths. For example, with\nthe same FLOPs budget, our obtained EfficientNet-B0 achieves 77.53\\% Top-1\naccuracy on ImageNet dataset, surpassing the performance of original setting by\n0.65\\%.",
    "descriptor": "\nComments: Extended version of CVPR 2021 paper BCNet arXiv:2105.10533\n",
    "authors": [
      "Xiu Su",
      "Shan You",
      "Jiyang Xie",
      "Fei Wang",
      "Chen Qian",
      "Changshui Zhang",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13714"
  },
  {
    "id": "arXiv:2203.13716",
    "title": "Stabilizing Adversarially Learned One-Class Novelty Detection Using  Pseudo Anomalies",
    "abstract": "Recently, anomaly scores have been formulated using reconstruction loss of\nthe adversarially learned generators and/or classification loss of\ndiscriminators. Unavailability of anomaly examples in the training data makes\noptimization of such networks challenging. Attributed to the adversarial\ntraining, performance of such models fluctuates drastically with each training\nstep, making it difficult to halt the training at an optimal point. In the\ncurrent study, we propose a robust anomaly detection framework that overcomes\nsuch instability by transforming the fundamental role of the discriminator from\nidentifying real vs. fake data to distinguishing good vs. bad quality\nreconstructions. For this purpose, we propose a method that utilizes the\ncurrent state as well as an old state of the same generator to create good and\nbad quality reconstruction examples. The discriminator is trained on these\nexamples to detect the subtle distortions that are often present in the\nreconstructions of anomalous data. In addition, we propose an efficient generic\ncriterion to stop the training of our model, ensuring elevated performance.\nExtensive experiments performed on six datasets across multiple domains\nincluding image and video based anomaly detection, medical diagnosis, and\nnetwork security, have demonstrated excellent performance of our approach.",
    "descriptor": "\nComments: This work has been submitted to the IEEE Transactions on Image Processing for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Muhammad Zaigham Zaheer",
      "Jin Ha Lee",
      "Arif Mahmood",
      "Marcella Astrid",
      "Seung-Ik Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13716"
  },
  {
    "id": "arXiv:2203.13718",
    "title": "Digital Fingerprinting of Microstructures",
    "abstract": "Finding efficient means of fingerprinting microstructural information is a\ncritical step towards harnessing data-centric machine learning approaches. A\nstatistical framework is systematically developed for compressed\ncharacterisation of a population of images, which includes some classical\ncomputer vision methods as special cases. The focus is on materials\nmicrostructure. The ultimate purpose is to rapidly fingerprint sample images in\nthe context of various high-throughput design/make/test scenarios. This\nincludes, but is not limited to, quantification of the disparity between\nmicrostructures for quality control, classifying microstructures, predicting\nmaterials properties from image data and identifying potential processing\nroutes to engineer new materials with specific properties. Here, we consider\nmicrostructure classification and utilise the resulting features over a range\nof related machine learning tasks, namely supervised, semi-supervised, and\nunsupervised learning.\nThe approach is applied to two distinct datasets to illustrate various\naspects and some recommendations are made based on the findings. In particular,\nmethods that leverage transfer learning with convolutional neural networks\n(CNNs), pretrained on the ImageNet dataset, are generally shown to outperform\nother methods. Additionally, dimensionality reduction of these CNN-based\nfingerprints is shown to have negligible impact on classification accuracy for\nthe supervised learning approaches considered. In situations where there is a\nlarge dataset with only a handful of images labelled, graph-based label\npropagation to unlabelled data is shown to be favourable over discarding\nunlabelled data and performing supervised learning. In particular, label\npropagation by Poisson learning is shown to be highly effective at low label\nrates.",
    "descriptor": "",
    "authors": [
      "Michael D. White",
      "Alexander Tarakanov",
      "Christopher P. Race",
      "Philip J. Withers",
      "Kody J.H. Law"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.13718"
  },
  {
    "id": "arXiv:2203.13721",
    "title": "Salt Detection Using Segmentation of Seismic Image",
    "abstract": "In this project, a state-of-the-art deep convolution neural network (DCNN) is\npresented to segment seismic images for salt detection below the earth's\nsurface. Detection of salt location is very important for starting mining.\nHence, a seismic image is used to detect the exact salt location under the\nearth's surface. However, precisely detecting the exact location of salt\ndeposits is difficult. Therefore, professional seismic imaging still requires\nexpert human interpretation of salt bodies. This leads to very subjective,\nhighly variable renderings. Hence, to create the most accurate seismic images\nand 3D renderings, we need a robust algorithm that automatically and accurately\nidentifies if a surface target is a salt or not. Since the performance of DCNN\nis well-known and well-established for object recognition in images, DCNN is a\nvery good choice for this particular problem and being successfully applied to\na dataset of seismic images in which each pixel is labeled as salt or not. The\nresult of this algorithm is promising.",
    "descriptor": "",
    "authors": [
      "Mrinmoy Sarkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.13721"
  },
  {
    "id": "arXiv:2203.13722",
    "title": "Probing Pre-Trained Language Models for Cross-Cultural Differences in  Values",
    "abstract": "Language embeds information about social, cultural, and political values\npeople hold. Prior work has explored social and potentially harmful biases\nencoded in Pre-Trained Language models (PTLMs). However, there has been no\nsystematic study investigating how values embedded in these models vary across\ncultures. In this paper, we introduce probes to study which values across\ncultures are embedded in these models, and whether they align with existing\ntheories and cross-cultural value surveys. We find that PTLMs capture\ndifferences in values across cultures, but those only weakly align with\nestablished value surveys. We discuss implications of using mis-aligned models\nin cross-cultural settings, as well as ways of aligning PTLMs with value\nsurveys.",
    "descriptor": "",
    "authors": [
      "Arnav Arora",
      "Lucie-Aim\u00e9e Kaffee",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13722"
  },
  {
    "id": "arXiv:2203.13724",
    "title": "PDE-based Dynamic Control and Estimation of Soft Robotic Arms",
    "abstract": "Compared with traditional rigid-body robots, soft robots not only exhibit\nunprecedented adaptation and flexibility, but also present novel challenges in\ntheir modelling and control because of their infinite degrees of freedom. Most\nof the existing approaches have mainly relied on approximated models so that\nthe well-developed finite-dimensional control theory can be exploited. However,\nthis Approximate-then-Design approach may bring in modelling uncertainty and\nperformance degradation. Hence, we adopt the opposite approach and exploit\ninfinite-dimensional analysis for soft robotic systems. Our control design is\nbased on the increasingly adopted Cosserat rod model, which describes the\nkinematics and dynamics of soft robotic arms with a set of nonlinear partial\ndifferential equations (PDE). We design infinite-dimensional state feedback\ncontrol laws for the Cosserat PDE model to achieve trajectory tracking in the\ntask space (consisting of position, rotation, linear and angular velocities),\nand prove their uniform tracking convergence. To estimate the feedback states,\nwe design an infinite-dimensional extended Kalman filter on Lie groups for the\nPDE system to estimate all the state variables (including position, rotation,\nstrains, curvature, linear and angular velocities) using only position\nmeasurements. The proposed algorithms are evaluated using simulations.",
    "descriptor": "",
    "authors": [
      "Tongjia Zheng",
      "Hai Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.13724"
  },
  {
    "id": "arXiv:2203.13725",
    "title": "Data-driven kinematics-consistent model order reduction of  fluid-structure interaction problems: application to deformable microcapsules  in a Stokes flow",
    "abstract": "In this paper, we present a generic approach of a dynamical data-driven model\norder reduction technique for three-dimensional fluid-structure interaction\nproblems. A low-order continuous linear differential system is identified from\nsnapshot solutions of a high-fidelity solver. The reduced order model (ROM)\nuses different ingredients like proper orthogonal decomposition (POD), dynamic\nmode decomposition (DMD) and Tikhonov-based robust identification techniques.\nAn interpolation method is used to predict the capsule dynamics for any value\nof the governing non-dimensional parameters that are not in the training\ndatabase. Then a dynamical system is built from the predicted solution.\nNumerical evidence shows the ability of the reduced model to predict the\ntime-evolution of the capsule deformation from its initial state, whatever the\nparameter values. Accuracy and stability properties of the resulting low-order\ndynamical system are analyzed numerically. The numerical experiments show a\nvery good agreement, measured in terms of modified Hausdorff distance between\ncapsule solutions of the full-order and low-order models both in the case of\nconfined and unconfined flows. This work is a first milestone to move towards\nreal time simulation of fluid-structure problems, which can be extended to\nnon-linear low-order systems to account for strong material and flow\nnon-linearities. It is a valuable innovation tool for rapid design and for the\ndevelopment of innovative devices.",
    "descriptor": "",
    "authors": [
      "Claire Dupont",
      "Florian De Vuyst",
      "Anne-Virginie Salsac"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.13725"
  },
  {
    "id": "arXiv:2203.13729",
    "title": "FReSCO: Flow Reconstruction and Segmentation for low latency Cardiac  Output monitoring using deep artifact suppression and segmentation",
    "abstract": "Purpose: Real-time monitoring of cardiac output (CO) requires low latency\nreconstruction and segmentation of real-time phase contrast MR (PCMR), which\nhas previously been difficult to perform. Here we propose a deep learning\nframework for 'Flow Reconstruction and Segmentation for low latency Cardiac\nOutput monitoring' (FReSCO).\nMethods: Deep artifact suppression and segmentation U-Nets were independently\ntrained. Breath hold spiral PCMR data (n=516) was synthetically undersampled\nusing a variable density spiral sampling pattern and gridded to create aliased\ndata for training of the artifact suppression U-net. A subset of the data\n(n=96) was segmented and used to train the segmentation U-net. Real-time spiral\nPCMR was prospectively acquired and then reconstructed and segmented using the\ntrained models (FReSCO) at low latency at the scanner in 10 healthy subjects\nduring rest, exercise and recovery periods. CO obtained via FReSCO was compared\nto a reference rest CO and rest and exercise Compressed Sensing (CS) CO.\nResults: FReSCO was demonstrated prospectively at the scanner. Beat-to-beat\nheartrate, stroke volume and CO could be visualized with a mean latency of\n622ms. No significant differences were noted when compared to reference at rest\n(Bias = -0.21+-0.50 L/min, p=0.246) or CS at peak exercise (Bias=0.12+-0.48\nL/min, p=0.458).\nConclusion: FReSCO was successfully demonstrated for real-time monitoring of\nCO during exercise and could provide a convenient tool for assessment of the\nhemodynamic response to a range of stressors.",
    "descriptor": "\nComments: 10 pages, 5 Figures, 4 Supporting Information Figures\n",
    "authors": [
      "Olivier Jaubert",
      "Javier Montalt-Tordera",
      "James Brown",
      "Daniel Knight",
      "Simon Arridge",
      "Jennifer Steeden",
      "Vivek Muthurangu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13729"
  },
  {
    "id": "arXiv:2203.13733",
    "title": "Blocks Assemble! Learning to Assemble with Large-Scale Structured  Reinforcement Learning",
    "abstract": "Assembly of multi-part physical structures is both a valuable end product for\nautonomous robotics, as well as a valuable diagnostic task for open-ended\ntraining of embodied intelligent agents. We introduce a naturalistic\nphysics-based environment with a set of connectable magnet blocks inspired by\nchildren's toy kits. The objective is to assemble blocks into a succession of\ntarget blueprints. Despite the simplicity of this objective, the compositional\nnature of building diverse blueprints from a set of blocks leads to an\nexplosion of complexity in structures that agents encounter. Furthermore,\nassembly stresses agents' multi-step planning, physical reasoning, and bimanual\ncoordination. We find that the combination of large-scale reinforcement\nlearning and graph-based policies -- surprisingly without any additional\ncomplexity -- is an effective recipe for training agents that not only\ngeneralize to complex unseen blueprints in a zero-shot manner, but even operate\nin a reset-free setting without being trained to do so. Through extensive\nexperiments, we highlight the importance of large-scale training, structured\nrepresentations, contributions of multi-task vs. single-task learning, as well\nas the effects of curriculums, and discuss qualitative behaviors of trained\nagents.",
    "descriptor": "\nComments: Accompanying project webpage can be found at: this https URL\n",
    "authors": [
      "Seyed Kamyar Seyed Ghasemipour",
      "Daniel Freeman",
      "Byron David",
      "Shixiang",
      "Satoshi Kataoka",
      "Igor Mordatch"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13733"
  },
  {
    "id": "arXiv:2203.13737",
    "title": "Using Solver-Aided Languages to Build Package Managers",
    "abstract": "Open-source software is critical for modern development, but most open-source\npackages require large networks of prerequisite packages, or dependencies, in\norder to function correctly. Modern software development workflows use package\nmanagers to ease this burden. Given a set of constraints, these systems use\ndependency solving to select compatible versions of dependencies before\ninstalling. However, many dependency solvers make ad hoc implementation choices\nand use heuristics that affect the set of chosen dependencies, and thus affect\ncorrectness, code size, and other factors of the final bundled software in ways\nthat are opaque and confusing to programmers.\nWe present PacSolve, a unifying formal semantics of dependency solving.\nPacSolve can compactly represent the key features and differences between NPM,\nPIP and Cargo, and express a wide variety of alternative semantics for\ndependency solving. PacSolve lends itself to a solver-aided implementation in\nRosette, which we use to build a drop-in replacement for NPM called MinNPM.\nMinNPM allows the user to customize the dependency solving semantics to choose\nbetween different objectives and consistency criteria. We show empirically that\nPacSolve is performant and effective on real-world code. For example, on the\ntop 1000 most downloaded NPM packages, we show that MinNPM can shrink the\nfootprint of 20% of packages and produce a newer set of dependencies for 14% of\npackages. Moreover, MinNPM only takes 1.7s longer than NPM on average. We also\nuse MinNPM to show that NPM's tree-solving semantics is only necessary for 3%\nof these packages.",
    "descriptor": "",
    "authors": [
      "Donald Pinckney",
      "Arjun Guha",
      "Massimiliano Culpo",
      "Todd Gamblin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.13737"
  },
  {
    "id": "arXiv:2203.13738",
    "title": "Nonlinear Field-split Preconditioners for Solving Monolithic Phase-field  Models of Brittle Fracture",
    "abstract": "One of the state-of-the-art strategies for predicting crack propagation,\nnucleation, and interaction is the phase-field approach. Despite its\nreliability and robustness, the phase-field approach suffers from burdensome\ncomputational cost, caused by the non-convexity of the underlying energy\nfunctional and a large number of unknowns required to resolve the damage\ngradients. In this work, we propose to solve such nonlinear systems in a\nmonolithic manner using the Schwarz preconditioned inexact Newton's (SPIN)\nmethod. The proposed SPIN method leverages the field split approach and\nminimizes the energy functional separately with respect to displacement and the\nphase-field, in an additive and multiplicative manner. In contrast to the\nstandard alternate minimization, the result of this decoupled minimization\nprocess is used to construct a preconditioner for a coupled linear system,\narising at each Newton's iteration. The overall performance and the convergence\nproperties of the proposed additive and multiplicative SPIN methods are\ninvestigated by means of several numerical examples. Comparison with\nwidely-used alternate minimization is also performed and we show a reduction in\nthe execution time up to a factor of 50. Moreover, we also demonstrate that\nthis reduction grows even further with increasing problem size and larger\nloading increments.",
    "descriptor": "",
    "authors": [
      "Alena Kopani\u010d\u00e1kov\u00e1",
      "Hardik Kothari",
      "Rolf Krause"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.13738"
  },
  {
    "id": "arXiv:2203.13746",
    "title": "Code Smells for Machine Learning Applications",
    "abstract": "The popularity of machine learning has wildly expanded in recent years.\nMachine learning techniques have been heatedly studied in academia and applied\nin the industry to create business value. However, there is a lack of\nguidelines for code quality in machine learning applications. In particular,\ncode smells have rarely been studied in this domain. Although machine learning\ncode is usually integrated as a small part of an overarching system, it usually\nplays an important role in its core functionality. Hence ensuring code quality\nis quintessential to avoid issues in the long run. This paper proposes and\nidentifies a list of 22 machine learning-specific code smells collected from\nvarious sources, including papers, grey literature, GitHub commits, and Stack\nOverflow posts. We pinpoint each smell with a description of its context,\npotential issues in the long run, and proposed solutions. In addition, we link\nthem to their respective pipeline stage and the evidence from both academic and\ngrey literature. The code smell catalog helps data scientists and developers\nproduce and maintain high-quality machine learning application code.",
    "descriptor": "\nComments: Accepted at CAIN\n",
    "authors": [
      "Haiyin Zhang",
      "Lu\u00eds Cruz",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13746"
  },
  {
    "id": "arXiv:2203.13751",
    "title": "Efficient-VDVAE: Less is more",
    "abstract": "Hierarchical VAEs have emerged in recent years as a reliable option for\nmaximum likelihood estimation. However, instability issues and demanding\ncomputational requirements have hindered research progress in the area. We\npresent simple modifications to the Very Deep VAE to make it converge up to\n$2.6\\times$ faster, save up to $20\\times$ in memory load and improve stability\nduring training. Despite these changes, our models achieve comparable or better\nnegative log-likelihood performance than current state-of-the-art models on all\n$7$ commonly used image datasets we evaluated on. We also make an argument\nagainst using 5-bit benchmarks as a way to measure hierarchical VAE's\nperformance due to undesirable biases caused by the 5-bit quantization.\nAdditionally, we empirically demonstrate that roughly $3\\%$ of the hierarchical\nVAE's latent space dimensions is sufficient to encode most of the image\ninformation, without loss of performance, opening up the doors to efficiently\nleverage the hierarchical VAEs' latent space in downstream tasks. We release\nour source code and models at https://github.com/Rayhane-mamah/Efficient-VDVAE .",
    "descriptor": "",
    "authors": [
      "Louay Hazami",
      "Rayhane Mama",
      "Ragavan Thurairatnam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13751"
  },
  {
    "id": "arXiv:2203.13762",
    "title": "A World-Self Model Towards Understanding Intelligence",
    "abstract": "Artificial intelligence has achieved tremendous successes in various tasks,\nwhile it is still out of question that there are big gaps between artificial\nand human intelligence, and the nature of intelligence is still in darkness. In\nthis work we will first stress the importance of scope of discussion and\ngranularity of investigation for this type of research. We will carefully\ncompare human and artificial intelligence, and propose that a certain aspect\n(Aspect 3) of human intelligence is the key to connect perception and\ncognition, and the lack of a new model is preventing the understanding and\nnext-level implementation of intelligence. We will present the broader idea of\n\"concept\", the principles and mathematical frameworks of the new model\nWorld-Self Model (WSM) of intelligence, and finally an unified general\nframework of intelligence based on WSM. Rather than focusing on solving a\nspecific problem or discussing a certain kind of intelligence, our work is\ninstead towards a better understanding of the nature of the general phenomenon\nof intelligence, independent of the kind of task or system of investigation.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Yutao Yue"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.13762"
  },
  {
    "id": "arXiv:2203.13769",
    "title": "An Audit of Misinformation Filter Bubbles on YouTube: Bubble Bursting  and Recent Behavior Changes",
    "abstract": "The negative effects of misinformation filter bubbles in adaptive systems\nhave been known to researchers for some time. Several studies investigated,\nmost prominently on YouTube, how fast a user can get into a misinformation\nfilter bubble simply by selecting wrong choices from the items offered. Yet, no\nstudies so far have investigated what it takes to burst the bubble, i.e.,\nrevert the bubble enclosure. We present a study in which pre-programmed agents\n(acting as YouTube users) delve into misinformation filter bubbles by watching\nmisinformation promoting content (for various topics). Then, by watching\nmisinformation debunking content, the agents try to burst the bubbles and reach\nmore balanced recommendation mixes. We recorded the search results and\nrecommendations, which the agents encountered, and analyzed them for the\npresence of misinformation. Our key finding is that bursting of a filter bubble\nis possible, albeit it manifests differently from topic to topic. Moreover, we\nobserve that filter bubbles do not truly appear in some situations. We also\ndraw a direct comparison with a previous study. Sadly, we did not find much\nimprovements in misinformation occurrences, despite recent pledges by YouTube.",
    "descriptor": "\nComments: RecSys '21: Fifteenth ACM Conference on Recommender System\n",
    "authors": [
      "Matus Tomlein",
      "Branislav Pecher",
      "Jakub Simko",
      "Ivan Srba",
      "Robert Moro",
      "Elena Stefancova",
      "Michal Kompan",
      "Andrea Hrckova",
      "Juraj Podrouzek",
      "Maria Bielikova"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13769"
  },
  {
    "id": "arXiv:2203.13770",
    "title": "Analysis of the use of color and its emotional relationship in visual  creations based on experiences during the context of the COVID-19 pandemic",
    "abstract": "Color is a complex communicative element that helps us understand and\nevaluate our environment. At the level of artistic creation, this component\ninfluences both the formal aspects of the composition and the symbolic weight,\ndirectly affecting the construction and transmission of the message that you\nwant to communicate, creating a specific emotional reaction. During the\nCOVID-19 pandemic, people generated countless images transmitting this event's\nsubjective experiences. Using the repository of images created in the Instagram\naccount CAM (The COVID Art Museum), we propose a methodology to understand the\nuse of color and its emotional relationship in this context. The process\nconsiders two stages in parallel that are then combined. First, emotions are\nextracted and classified from the CAM dataset images through a convolutional\nneural network. Second, we extract the colors and their harmonies through a\nclustering process. Once both processes are completed, we combine the results\ngenerating an expanded discussion on the usage of color, harmonies, and\nemotion. The results indicate that warm colors are prevalent in the sample,\nwith a preference for analog compositions over complementary ones. The\nrelationship between emotions and these compositions shows a trend in positive\nemotions, reinforced by the results of the algorithm a priori and the emotional\nrelationship analysis of the attributes of color (hue, chroma, and lighting).",
    "descriptor": "",
    "authors": [
      "C\u00e9sar Gonz\u00e1lez-Mart\u00edn",
      "Miguel Carrasco",
      "Germ\u00e1n Oviedo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.13770"
  },
  {
    "id": "arXiv:2203.13777",
    "title": "Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion",
    "abstract": "Human behavior has the nature of indeterminacy, which requires the pedestrian\ntrajectory prediction system to model the multi-modality of future motion\nstates. Unlike existing stochastic trajectory prediction methods which usually\nuse a latent variable to represent multi-modality, we explicitly simulate the\nprocess of human motion variation from indeterminate to determinate. In this\npaper, we present a new framework to formulate the trajectory prediction task\nas a reverse process of motion indeterminacy diffusion (MID), in which we\nprogressively discard indeterminacy from all the walkable areas until reaching\nthe desired trajectory. This process is learned with a parameterized Markov\nchain conditioned by the observed trajectories. We can adjust the length of the\nchain to control the degree of indeterminacy and balance the diversity and\ndeterminacy of the predictions. Specifically, we encode the history behavior\ninformation and the social interactions as a state embedding and devise a\nTransformer-based diffusion model to capture the temporal dependencies of\ntrajectories. Extensive experiments on the human trajectory prediction\nbenchmarks including the Stanford Drone and ETH/UCY datasets demonstrate the\nsuperiority of our method. Code is available at\nhttps://github.com/gutianpei/MID.",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Tianpei Gu",
      "Guangyi Chen",
      "Junlong Li",
      "Chunze Lin",
      "Yongming Rao",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13777"
  },
  {
    "id": "arXiv:2203.13778",
    "title": "L3Cube-MahaHate: A Tweet-based Marathi Hate Speech Detection Dataset and  BERT models",
    "abstract": "Social media platforms are used by a large number of people prominently to\nexpress their thoughts and opinions. However, these platforms have contributed\nto a substantial amount of hateful and abusive content as well. Therefore, it\nis important to curb the spread of hate speech on these platforms. In India,\nMarathi is one of the most popular languages used by a wide audience. In this\nwork, we present L3Cube-MahaHate, the first major Hate Speech Dataset in\nMarathi. The dataset is curated from Twitter, annotated manually. Our dataset\nconsists of over 25000 distinct tweets labeled into four major classes i.e\nhate, offensive, profane, and not. We present the approaches used for\ncollecting and annotating the data and the challenges faced during the process.\nFinally, we present baseline classification results using deep learning models\nbased on CNN, LSTM, and Transformers. We explore mono-lingual and multi-lingual\nvariants of BERT like MahaBERT, IndicBERT, mBERT, and xlm-RoBERTa and show that\nmono-lingual models perform better than their multi-lingual counterparts. The\nMahaBERT model provides the best results on L3Cube-MahaHate Corpus. The data\nand models are available at https://github.com/l3cube-pune/MarathiNLP .",
    "descriptor": "",
    "authors": [
      "Abhishek Velankar",
      "Hrushikesh Patil",
      "Amol Gore",
      "Shubham Salunke",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13778"
  },
  {
    "id": "arXiv:2203.13783",
    "title": "Ensemble Spectral Prediction (ESP) Model for Metabolite Annotation",
    "abstract": "A key challenge in metabolomics is annotating measured spectra from a\nbiological sample with chemical identities. Currently, only a small fraction of\nmeasurements can be assigned identities. Two complementary computational\napproaches have emerged to address the annotation problem: mapping candidate\nmolecules to spectra, and mapping query spectra to molecular candidates. In\nessence, the candidate molecule with the spectrum that best explains the query\nspectrum is recommended as the target molecule. Despite candidate ranking being\nfundamental in both approaches, no prior works utilized rank learning tasks in\ndetermining the target molecule. We propose a novel machine learning model,\nEnsemble Spectral Prediction (ESP), for metabolite annotation. ESP takes\nadvantage of prior neural network-based annotation models that utilize\nmultilayer perceptron (MLP) networks and Graph Neural Networks (GNNs). Based on\nthe ranking results of the MLP and GNN-based models, ESP learns a weighting for\nthe outputs of MLP and GNN spectral predictors to generate a spectral\nprediction for a query molecule. Importantly, training data is stratified by\nmolecular formula to provide candidate sets during model training. Further,\nbaseline MLP and GNN models are enhanced by considering peak dependencies\nthrough multi-head attention mechanism and multi-tasking on spectral topic\ndistributions. ESP improves average rank by 41% and 30% over the MLP and GNN\nbaselines, respectively, demonstrating remarkable performance gain over\nstate-of-the-art neural network approaches. We show that annotation\nperformance, for ESP and other models, is a strong function of the number of\nmolecules in the candidate set and their similarity to the target molecule.",
    "descriptor": "",
    "authors": [
      "Xinmeng Li",
      "Hao Zhu",
      "Li-ping Liu",
      "Soha Hassoun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2203.13783"
  },
  {
    "id": "arXiv:2203.13789",
    "title": "FLUTE: A Scalable, Extensible Framework for High-Performance Federated  Learning Simulations",
    "abstract": "In this paper we introduce \"Federated Learning Utilities and Tools for\nExperimentation\" (FLUTE), a high-performance open source platform for federated\nlearning research and offline simulations. The goal of FLUTE is to enable rapid\nprototyping and simulation of new federated learning algorithms at scale,\nincluding novel optimization, privacy, and communications strategies. We\ndescribe the architecture of FLUTE, enabling arbitrary federated modeling\nschemes to be realized, we compare the platform with other state-of-the-art\nplatforms, and we describe available features of FLUTE for experimentation in\ncore areas of active research, such as optimization, privacy and scalability.\nWe demonstrate the effectiveness of the platform with a series of experiments\nfor text prediction and speech recognition, including the addition of\ndifferential privacy, quantization, scaling and a variety of optimization and\nfederation approaches.",
    "descriptor": "\nComments: 13 Pages, 5 Figures, 8 Tables\n",
    "authors": [
      "Dimitrios Dimitriadis",
      "Mirian Hipolito Garcia",
      "Daniel Madrigal Diaz",
      "Andre Manoel",
      "Robert Sim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13789"
  },
  {
    "id": "arXiv:2203.13792",
    "title": "Visual-based Safe Landing for UAVs in Populated Areas: Real-time  Validation in Virtual Environments",
    "abstract": "Safe autonomous landing for Unmanned Aerial Vehicles (UAVs) in populated\nareas is a crucial aspect for successful urban deployment, particularly in\nemergency landing situations. Nonetheless, validating autonomous landing in\nreal scenarios is a challenging task involving a high risk of injuring people.\nIn this work, we propose a framework for real-time safe and thorough evaluation\nof vision-based autonomous landing in populated scenarios, using\nphoto-realistic virtual environments. We propose to use the Unreal graphics\nengine coupled with the AirSim plugin for drone's simulation, and evaluate\nautonomous landing strategies based on visual detection of Safe Landing Zones\n(SLZ) in populated scenarios. Then, we study two different criteria for\nselecting the \"best\" SLZ, and evaluate them during autonomous landing of a\nvirtual drone in different scenarios and conditions, under different\ndistributions of people in urban scenes, including moving people. We evaluate\ndifferent metrics to quantify the performance of the landing strategies,\nestablishing a baseline for comparison with future works in this challenging\ntask, and analyze them through an important number of randomized iterations.\nThe study suggests that the use of the autonomous landing algorithms\nconsiderably helps to prevent accidents involving humans, which may allow to\nunleash the full potential of drones in urban environments near to people.",
    "descriptor": "",
    "authors": [
      "Hector Tovanche-Picon",
      "Javier Gonzalez-Trejo",
      "Angel Flores-Abad",
      "Diego Mercado-Ravell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13792"
  },
  {
    "id": "arXiv:2203.13799",
    "title": "Gravity-constrained point cloud registration",
    "abstract": "Visual and lidar Simultaneous Localization and Mapping (SLAM) algorithms\nbenefit from the Inertial Measurement Unit (IMU) modality. The high-rate\ninertial data complement the other lower-rate modalities. Moreover, in the\nabsence of constant acceleration, the gravity vector makes two attitude angles\nout of three observable in the global coordinate frame. In visual odometry,\nthis is already being used to reduce the 6-Degrees Of Freedom (DOF) pose\nestimation problem to 4-DOF. In lidar SLAM, the gravity measurements are often\nused as a penalty in the back-end global map optimization to prevent map\ndeformations. In this work, we propose an Iterative Closest Point (ICP)-based\nfront-end which exploits the observable DOF and provides pose estimates aligned\nwith the gravity vector. We believe that this front-end has the potential to\nsupport the loop closure identification, thus speeding up convergences of\nglobal map optimizations. The presented approach has been extensively tested in\nlarge-scale outdoor environments as well as in the Subterranean Challenge\norganized by Defense Advanced Research Projects Agency (DARPA). We show that it\ncan reduce the localization drift by 30% when compared to the standard 6-DOF\nICP. Moreover, the code is readily available to the community as a part of the\nlibpointmatcher library.",
    "descriptor": "\nComments: Preprint. Submitted to IROS 2022. 7 pages, 9 figures\n",
    "authors": [
      "Vladim\u00edr Kubelka",
      "Maxime Vaidis",
      "Fran\u00e7ois Pomerleau"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.13799"
  },
  {
    "id": "arXiv:2203.13800",
    "title": "Continuous Dynamic-NeRF: Spline-NeRF",
    "abstract": "The problem of reconstructing continuous functions over time is important for\nproblems such as reconstructing moving scenes, and interpolating between time\nsteps. Previous approaches that use deep-learning rely on regularization to\nensure that reconstructions are approximately continuous, which works well on\nshort sequences. As sequence length grows, though, it becomes more difficult to\nregularize, and it becomes less feasible to learn only through regularization.\nWe propose a new architecture for function reconstruction based on classical\nBezier splines, which ensures $C^0$ and $C^1$-continuity, where $C^0$\ncontinuity is that $\\forall c:\\lim\\limits_{x\\to c} f(x)\n= f(c)$, or more intuitively that there are no breaks at any point in the\nfunction. In order to demonstrate our architecture, we reconstruct dynamic\nscenes using Neural Radiance Fields, but hope it is clear that our approach is\ngeneral and can be applied to a variety of problems. We recover a Bezier spline\n$B(\\beta, t\\in[0,1])$, parametrized by the control points $\\beta$. Using Bezier\nsplines ensures reconstructions have $C^0$ and $C^1$ continuity, allowing for\nguaranteed interpolation over time. We reconstruct $\\beta$ with a multi-layer\nperceptron (MLP), blending machine learning with classical animation\ntechniques. All code is available at https://github.com/JulianKnodt/nerf_atlas,\nand datasets are from prior work.",
    "descriptor": "",
    "authors": [
      "Julian Knodt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13800"
  },
  {
    "id": "arXiv:2203.13802",
    "title": "Playing Lottery Tickets in Style Transfer Models",
    "abstract": "Style transfer has achieved great success and attracted a wide range of\nattention from both academic and industrial communities due to its flexible\napplication scenarios. However, the dependence on pretty large VGG based\nautoencoder leads to existing style transfer models have a high parameter\ncomplexities which limits the application for resource-constrained devices.\nUnfortunately, the compression of style transfer model has less been explored.\nIn parallel, study on the lottery ticket hypothesis (LTH) has shown great\npotential in finding extremely sparse matching subnetworks which can achieve on\npar or even better performance than original full networks when trained in\nisolation. In this work, we perform the first empirical study to verify whether\nsuch trainable networks also exist in style transfer models. From a wide range\nof style transfer methods, we choose two of the most popular style transfer\nmodels as the main testbeds, i.e., AdaIN and SANet, representing approaches of\nglobal and local transformation based style transfer respectively. Through\nextensive experiments and comprehensive analysis, we draw the following main\nconclusions. (1) Compared with fixing VGG encoder, style transfer models can\nbenefit more from training the whole network together. (2) Using iterative\nmagnitude pruning, we find the most sparse matching subnetworks at 89.2% in\nAdaIN and 73.7% in SANet, which suggests that style transfer models can play\nlottery tickets too. (3) Feature transformation module should also be pruned to\nget a sparser model without affecting the existence and quality of matching\nsubnetworks. (4) Besides AdaIN and SANet, other models such as LST, MANet,\nAdaAttN and MCCNet can also play lottert tickets, which shows that LTH can be\ngeneralized to various style transfer models.",
    "descriptor": "",
    "authors": [
      "Meihao Kong",
      "Jing Huo",
      "Wenbin Li",
      "Jing Wu",
      "Yu-Kun Lai",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.13802"
  },
  {
    "id": "arXiv:2203.13803",
    "title": "Opportunistic Qualitative Planning in Stochastic Systems with  Preferences over Temporal Logic Objectives",
    "abstract": "Preferences play a key role in determining what goals/constraints to satisfy\nwhen not all constraints can be satisfied simultaneously. In this work, we\nstudy preference-based planning in a stochastic system modeled as a Markov\ndecision process, subject to a possible incomplete preference over temporally\nextended goals. Our contributions are three folds: First, we introduce a\npreference language to specify preferences over temporally extended goals.\nSecond, we define a novel automata-theoretic model to represent the preorder\ninduced by given preference relation. The automata representation of\npreferences enables us to develop a preference-based planning algorithm for\nstochastic systems. Finally, we show how to synthesize opportunistic strategies\nthat achieves an outcome that improves upon the current satisfiable outcome,\nwith positive probability or with probability one, in a stochastic system. We\nillustrate our solution approaches using a robot motion planning example.",
    "descriptor": "\nComments: 6 pages, 3 figure, submitted to IEEE L-CSS\n",
    "authors": [
      "Abhishek Ninad Kulkarni",
      "Jie Fu"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.13803"
  },
  {
    "id": "arXiv:2203.13809",
    "title": "DOTS: An Open Testbed for Industrial Swarm Robotic Solutions",
    "abstract": "We present DOTS, a new open access testbed for industrial swarm robotics\nexperimentation. It consists of 20 fast agile robots with high sensing and\ncomputational performance, and real-world payload capability. They are housed\nin an arena equipped with private 5G, motion capture, multiple cameras, and\nopenly accessible via an online portal. We reduce barriers to entry by\nproviding a complete platform-agnostic pipeline to develop, simulate, and\ndeploy experimental applications to the swarm. We showcase the testbed\ncapabilities with a swarm logistics application, autonomously and reliably\nsearching for and retrieving multiple cargo carriers.",
    "descriptor": "\nComments: 16 pages, 17 figures, for associated video, see this https URL\n",
    "authors": [
      "Simon Jones",
      "Emma Milner",
      "Mahesh Sooriyabandara",
      "Sabine Hauert"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.13809"
  },
  {
    "id": "arXiv:2203.13812",
    "title": "Spatially Multi-conditional Image Generation",
    "abstract": "In most scenarios, conditional image generation can be thought of as an\ninversion of the image understanding process. Since generic image understanding\ninvolves the solving of multiple tasks, it is natural to aim at the generation\nof images via multi-conditioning. However, multi-conditional image generation\nis a very challenging problem due to the heterogeneity and the sparsity of the\n(in practice) available conditioning labels. In this work, we propose a novel\nneural architecture to address the problem of heterogeneity and sparsity of the\nspatially multi-conditional labels. Our choice of spatial conditioning, such as\nby semantics and depth, is driven by the promise it holds for better control of\nthe image generation process. The proposed method uses a transformer-like\narchitecture operating pixel-wise, which receives the available labels as input\ntokens to merge them in a learned homogeneous space of labels. The merged\nlabels are then used for image generation via conditional generative\nadversarial training. In this process, the sparsity of the labels is handled by\nsimply dropping the input tokens corresponding to the missing labels at the\ndesired locations, thanks to the proposed pixel-wise operating architecture.\nOur experiments on three benchmark datasets demonstrate the clear superiority\nof our method over the state-of-the-art and the compared baselines.",
    "descriptor": "",
    "authors": [
      "Ritika Chakraborty",
      "Nikola Popovic",
      "Danda Pani Paudel",
      "Thomas Probst",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13812"
  },
  {
    "id": "arXiv:2203.13815",
    "title": "Versatile Multi-Modal Pre-Training for Human-Centric Perception",
    "abstract": "Human-centric perception plays a vital role in vision and graphics. But their\ndata annotations are prohibitively expensive. Therefore, it is desirable to\nhave a versatile pre-train model that serves as a foundation for data-efficient\ndownstream tasks transfer. To this end, we propose the Human-Centric\nMulti-Modal Contrastive Learning framework HCMoCo that leverages the\nmulti-modal nature of human data (e.g. RGB, depth, 2D keypoints) for effective\nrepresentation learning. The objective comes with two main challenges: dense\npre-train for multi-modality data, efficient usage of sparse human priors. To\ntackle the challenges, we design the novel Dense Intra-sample Contrastive\nLearning and Sparse Structure-aware Contrastive Learning targets by\nhierarchically learning a modal-invariant latent space featured with continuous\nand ordinal feature distribution and structure-aware semantic consistency.\nHCMoCo provides pre-train for different modalities by combining heterogeneous\ndatasets, which allows efficient usage of existing task-specific human data.\nExtensive experiments on four downstream tasks of different modalities\ndemonstrate the effectiveness of HCMoCo, especially under data-efficient\nsettings (7.16% and 12% improvement on DensePose Estimation and Human Parsing).\nMoreover, we demonstrate the versatility of HCMoCo by exploring cross-modality\nsupervision and missing-modality inference, validating its strong ability in\ncross-modal association and reasoning.",
    "descriptor": "\nComments: CVPR 2022; Project Page this https URL; Codes available at this https URL\n",
    "authors": [
      "Fangzhou Hong",
      "Liang Pan",
      "Zhongang Cai",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13815"
  },
  {
    "id": "arXiv:2203.13817",
    "title": "AutoAvatar: Autoregressive Neural Fields for Dynamic Avatar Modeling",
    "abstract": "Neural fields such as implicit surfaces have recently enabled avatar modeling\nfrom raw scans without explicit temporal correspondences. In this work, we\nexploit autoregressive modeling to further extend this notion to capture\ndynamic effects, such as soft-tissue deformations. Although autoregressive\nmodels are naturally capable of handling dynamics, it is non-trivial to apply\nthem to implicit representations, as explicit state decoding is infeasible due\nto prohibitive memory requirements. In this work, for the first time, we enable\nautoregressive modeling of implicit avatars. To reduce the memory bottleneck\nand efficiently model dynamic implicit surfaces, we introduce the notion of\narticulated observer points, which relate implicit states to the explicit\nsurface of a parametric human body model. We demonstrate that encoding implicit\nsurfaces as a set of height fields defined on articulated observer points leads\nto significantly better generalization compared to a latent representation. The\nexperiments show that our approach outperforms the state of the art, achieving\nplausible dynamic deformations even for unseen motions.\nhttps://zqbai-jeremy.github.io/autoavatar",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Ziqian Bai",
      "Timur Bagautdinov",
      "Javier Romero",
      "Michael Zollh\u00f6fer",
      "Ping Tan",
      "Shunsuke Saito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.13817"
  },
  {
    "id": "arXiv:2203.13256",
    "title": "Power Network Uniqueness and Synchronization Stability from a  Higher-order Structure Perspective",
    "abstract": "Triadic subgraph analysis reveals the structural features in power networks\nbased on higher-order connectivity patterns. Power networks have a unique triad\nsignificance profile (TSP) of the five unidirectional triadic subgraphs in\ncomparison with the scale-free, small-world and random networks. Notably, the\ntriadic closure has the highest significance in power networks. Thus, the\nunique TSP can serve as a structural identifier to differentiate power networks\nfrom other complex networks. Power networks form a network superfamily.\nFurthermore, synthetic power networks based on the random growth model grow up\nto be networks belonging to the superfamily with a fewer number of transmission\nlines. The significance of triadic closures strongly correlates with the\nconstruction cost measured by network redundancy. The trade off between the\nsynchronization stability and the construction cost leads to the power network\nsuperfamily. The power network characterized by the unique TSP is the\nconsequence of the trade-off essentially. The uniqueness of the power network\nsuperfamily tells an important fact that power networks.",
    "descriptor": "",
    "authors": [
      "Hao Liu",
      "Xin Chen",
      "Long Huo",
      "Chunming Niu"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2203.13256"
  },
  {
    "id": "arXiv:2203.13257",
    "title": "Dynamics and Control of Bubble-Propelled Microrobots",
    "abstract": "Having the advantage of being relatively fast and powerful, as well as\nreadily fabricated, spherical bubble-propelled microrobots are particularly\nwell suited for applications such as cargo delivery, micromanipulation, and\nbiological or environmental remediation. However, there have been limited\nexamples of control and manipulation with these microrobots and few studies on\ntheir dynamics. Here we investigate the bubble formation and dynamics of both\nhemispherically coated Janus microrobots as well as GLAD \"patchy\" microrobots\nwhich not only provide for an interesting comparison, but also exhibit useful\nproperties in their own right. Specifically, we find that the patchy\nmicrorobots have a tendency to produce smaller bubbles and undergo smoother\nmotion, properties that are beneficial for applications such as precise\nmicro-manipulation, for example. We demonstrate manipulation and assemble of\npassive spheres on a substrate as well as at an air-liquid interface. We also\ncharacterize the propulsion and bubble formation of both types of microrobots\nand find that previously proposed theories insufficiently describe their motion\nand bubble bursting mechanism. Additionally, we observe that the microrobots,\nwhich reside at the air-liquid interface, demonstrate positive gravitaxis\ntowards the droplet edges which we attribute to a torque resulting from\nopposing downward and buoyant forces on the microrobot.",
    "descriptor": "",
    "authors": [
      "David P. Rivas",
      "Max Sokolich",
      "Harrison Muller",
      "Sambeeta Das"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.13257"
  },
  {
    "id": "arXiv:2203.13259",
    "title": "Computing Optimal Location of Microphone for Improved Speech Recognition",
    "abstract": "It was shown in our earlier work that the measurement error in the microphone\nposition affected the room impulse response (RIR) which in turn affected the\nsingle-channel close microphone and multi-channel distant microphone speech\nrecognition. In this paper, as an extension, we systematically study to\nidentify the optimal location of the microphone, given an approximate and hence\nerroneous location of the microphone in 3D space. The primary idea is to use\nMonte-Carlo technique to generate a large number of random microphone positions\naround the erroneous microphone position and select the microphone position\nthat results in the best performance of a general purpose automatic speech\nrecognition (gp-asr). We experiment with clean and noisy speech and show that\nthe optimal location of the microphone is unique and is affected by noise.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Karan Nathwani",
      "Bhavya Dixit",
      "Sunil Kumar Kopparapu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.13259"
  },
  {
    "id": "arXiv:2203.13260",
    "title": "Adaptive job and resource management for the growing quantum cloud",
    "abstract": "As the popularity of quantum computing continues to grow, efficient quantum\nmachine access over the cloud is critical to both academic and industry\nresearchers across the globe. And as cloud quantum computing demands increase\nexponentially, the analysis of resource consumption and execution\ncharacteristics are key to efficient management of jobs and resources at both\nthe vendor-end as well as the client-end. While the analysis and optimization\nof job / resource consumption and management are popular in the classical HPC\ndomain, it is severely lacking for more nascent technology like quantum\ncomputing. This paper proposes optimized adaptive job scheduling to the quantum\ncloud taking note of primary characteristics such as queuing times and fidelity\ntrends across machines, as well as other characteristics such as quality of\nservice guarantees and machine calibration constraints. Key components of the\nproposal include a) a prediction model which predicts fidelity trends across\nmachine based on compiled circuit features such as circuit depth and different\nforms of errors, as well as b) queuing time prediction for each machine based\non execution time estimations. Overall, this proposal is evaluated on simulated\nIBM machines across a diverse set of quantum applications and system loading\nscenarios, and is able to reduce wait times by over 3x and improve fidelity by\nover 40\\% on specific usecases, when compared to traditional job schedulers.",
    "descriptor": "\nComments: Appeared at the 2021 IEEE International Conference on Quantum Computing and Engineering. arXiv admin note: text overlap with arXiv:2203.13121. substantial text overlap with arXiv:2203.13121\n",
    "authors": [
      "Gokul Subramanian Ravi",
      "Kaitlin N. Smith",
      "Prakash Murali",
      "Frederic T. Chong"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.13260"
  },
  {
    "id": "arXiv:2203.13261",
    "title": "Quantum Feature Selection",
    "abstract": "In machine learning, fewer features reduce model complexity. Carefully\nassessing the influence of each input feature on the model quality is therefore\na crucial preprocessing step. We propose a novel feature selection algorithm\nbased on a quadratic unconstrained binary optimization (QUBO) problem, which\nallows to select a specified number of features based on their importance and\nredundancy. In contrast to iterative or greedy methods, our direct approach\nyields higherquality solutions. QUBO problems are particularly interesting\nbecause they can be solved on quantum hardware. To evaluate our proposed\nalgorithm, we conduct a series of numerical experiments using a classical\ncomputer, a quantum gate computer and a quantum annealer. Our evaluation\ncompares our method to a range of standard methods on various benchmark\ndatasets. We observe competitive performance.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Sascha M\u00fccke",
      "Raoul Heese",
      "Sabine M\u00fcller",
      "Moritz Wolter",
      "Nico Piatkowski"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13261"
  },
  {
    "id": "arXiv:2203.13270",
    "title": "Shoring Up the Foundations: Fusing Model Embeddings and Weak Supervision",
    "abstract": "Foundation models offer an exciting new paradigm for constructing models with\nout-of-the-box embeddings and a few labeled examples. However, it is not clear\nhow to best apply foundation models without labeled data. A potential approach\nis to fuse foundation models with weak supervision frameworks, which use weak\nlabel sources -- pre-trained models, heuristics, crowd-workers -- to construct\npseudolabels. The challenge is building a combination that best exploits the\nsignal available in both foundation models and weak sources. We propose Liger,\na combination that uses foundation model embeddings to improve two crucial\nelements of existing weak supervision techniques. First, we produce finer\nestimates of weak source quality by partitioning the embedding space and\nlearning per-part source accuracies. Second, we improve source coverage by\nextending source votes in embedding space. Despite the black-box nature of\nfoundation models, we prove results characterizing how our approach improves\nperformance and show that lift scales with the smoothness of label\ndistributions in embedding space. On six benchmark NLP and video tasks, Liger\noutperforms vanilla weak supervision by 14.1 points, weakly-supervised kNN and\nadapters by 11.8 points, and kNN and adapters supervised by traditional hand\nlabels by 7.2 points.",
    "descriptor": "",
    "authors": [
      "Mayee F. Chen",
      "Daniel Y. Fu",
      "Dyah Adila",
      "Michael Zhang",
      "Frederic Sala",
      "Kayvon Fatahalian",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13270"
  },
  {
    "id": "arXiv:2203.13284",
    "title": "Local optimisation of Nystr\u00f6m samples through stochastic gradient  descent",
    "abstract": "We study a relaxed version of the column-sampling problem for the Nystr\\\"om\napproximation of kernel matrices, where approximations are defined from\nmultisets of landmark points in the ambient space; such multisets are referred\nto as Nystr\\\"om samples. We consider an unweighted variation of the radial\nsquared-kernel discrepancy (SKD) criterion as a surrogate for the classical\ncriteria used to assess the Nystr\\\"om approximation accuracy; in this setting,\nwe discuss how Nystr\\\"om samples can be efficiently optimised through\nstochastic gradient descent. We perform numerical experiments which demonstrate\nthat the local minimisation of the radial SKD yields Nystr\\\"om samples with\nimproved Nystr\\\"om approximation accuracy.",
    "descriptor": "\nComments: 14 pages, 5 figures. Submitted to LOD 2022 conference\n",
    "authors": [
      "Matthew Hutchings",
      "Bertrand Gauthier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13284"
  },
  {
    "id": "arXiv:2203.13313",
    "title": "Deep learning for laboratory earthquake prediction and autoregressive  forecasting of fault zone stress",
    "abstract": "Earthquake forecasting and prediction have long and in some cases sordid\nhistories but recent work has rekindled interest based on advances in early\nwarning, hazard assessment for induced seismicity and successful prediction of\nlaboratory earthquakes. In the lab, frictional stick-slip events provide an\nanalog for earthquakes and the seismic cycle. Labquakes are ideal targets for\nmachine learning (ML) because they can be produced in long sequences under\ncontrolled conditions. Recent works show that ML can predict several aspects of\nlabquakes using fault zone acoustic emissions. Here, we generalize these\nresults and explore deep learning (DL) methods for labquake prediction and\nautoregressive (AR) forecasting. DL improves existing ML methods of labquake\nprediction. AR methods allow forecasting at future horizons via iterative\npredictions. We demonstrate that DL models based on Long-Short Term Memory\n(LSTM) and Convolution Neural Networks predict labquakes under several\nconditions, and that fault zone stress can be predicted with fidelity,\nconfirming that acoustic energy is a fingerprint of fault zone stress. We\npredict also time to start of failure (TTsF) and time to the end of Failure\n(TTeF) for labquakes. Interestingly, TTeF is successfully predicted in all\nseismic cycles, while the TTsF prediction varies with the amount of preseismic\nfault creep. We report AR methods to forecast the evolution of fault stress\nusing three sequence modeling frameworks: LSTM, Temporal Convolution Network\nand Transformer Network. AR forecasting is distinct from existing predictive\nmodels, which predict only a target variable at a specific time. The results\nfor forecasting beyond a single seismic cycle are limited but encouraging. Our\nML/DL models outperform the state-of-the-art and our autoregressive model\nrepresents a novel framework that could enhance current methods of earthquake\nforecasting.",
    "descriptor": "\nComments: Under review in EPSL\n",
    "authors": [
      "Laura Laurenti",
      "Elisa Tinti",
      "Fabio Galasso",
      "Luca Franco",
      "Chris Marone"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13313"
  },
  {
    "id": "arXiv:2203.13375",
    "title": "Deep reinforcement learning for optimal well control in subsurface  systems with uncertain geology",
    "abstract": "A general control policy framework based on deep reinforcement learning (DRL)\nis introduced for closed-loop decision making in subsurface flow settings.\nTraditional closed-loop modeling workflows in this context involve the repeated\napplication of data assimilation/history matching and robust optimization\nsteps. Data assimilation can be particularly challenging in cases where both\nthe geological style (scenario) and individual model realizations are\nuncertain. The closed-loop reservoir management (CLRM) problem is formulated\nhere as a partially observable Markov decision process, with the associated\noptimization problem solved using a proximal policy optimization algorithm.\nThis provides a control policy that instantaneously maps flow data observed at\nwells (as are available in practice) to optimal well pressure settings. The\npolicy is represented by a temporal convolution and gated transformer blocks.\nTraining is performed in a preprocessing step with an ensemble of prior\ngeological models, which can be drawn from multiple geological scenarios.\nExample cases involving the production of oil via water injection, with both 2D\nand 3D geological models, are presented. The DRL-based methodology is shown to\nresult in an NPV increase of 15% (for the 2D cases) and 33% (3D cases) relative\nto robust optimization over prior models, and to an average improvement of 4%\nin NPV relative to traditional CLRM. The solutions from the control policy are\nfound to be comparable to those from deterministic optimization, in which the\ngeological model is assumed to be known, even when multiple geological\nscenarios are considered. The control policy approach results in a 76% decrease\nin computational cost relative to traditional CLRM with the algorithms and\nparameter settings considered in this work.",
    "descriptor": "",
    "authors": [
      "Yusuf Nasir",
      "Louis J. Durlofsky"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.13375"
  },
  {
    "id": "arXiv:2203.13377",
    "title": "Statistic Selection and MCMC for Differentially Private Bayesian  Estimation",
    "abstract": "This paper concerns differentially private Bayesian estimation of the\nparameters of a population distribution, when a statistic of a sample from that\npopulation is shared in noise to provide differential privacy.\nThis work mainly addresses two problems: (1) What statistic of the sample\nshould be shared privately? For the first question, i.e., the one about\nstatistic selection, we promote using the Fisher information. We find out that,\nthe statistic that is most informative in a non-privacy setting may not be the\noptimal choice under the privacy restrictions. We provide several examples to\nsupport that point. We consider several types of data sharing settings and\npropose several Monte Carlo-based numerical estimation methods for calculating\nthe Fisher information for those settings. The second question concerns\ninference: (2) Based on the shared statistics, how could we perform effective\nBayesian inference? We propose several Markov chain Monte Carlo (MCMC)\nalgorithms for sampling from the posterior distribution of the parameter given\nthe noisy statistic. The proposed MCMC algorithms can be preferred over one\nanother depending on the problem. For example, when the shared statistics is\nadditive and added Gaussian noise, a simple Metropolis-Hasting algorithm that\nutilizes the central limit theorem is a decent choice. We propose more advanced\nMCMC algorithms for several other cases of practical relevance.\nOur numerical examples involve comparing several candidate statistics to be\nshared privately. For each statistic, we perform Bayesian estimation based on\nthe posterior distribution conditional on the privatized version of that\nstatistic. We demonstrate that, the relative performance of a statistic, in\nterms of the mean squared error of the Bayesian estimator based on the\ncorresponding privatized statistic, is adequately predicted by the Fisher\ninformation of the privatized statistic.",
    "descriptor": "\nComments: 32 pages, 9 figures\n",
    "authors": [
      "Baris Alparslan",
      "Sinan Yildirim"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13377"
  },
  {
    "id": "arXiv:2203.13417",
    "title": "Amortized Projection Optimization for Sliced Wasserstein Generative  Models",
    "abstract": "Seeking informative projecting directions has been an important task in\nutilizing sliced Wasserstein distance in applications. However, finding these\ndirections usually requires an iterative optimization procedure over the space\nof projecting directions, which is computationally expensive. Moreover, the\ncomputational issue is even more severe in deep learning applications, where\ncomputing the distance between two mini-batch probability measures is repeated\nseveral times. This nested-loop has been one of the main challenges that\nprevent the usage of sliced Wasserstein distances based on good projections in\npractice. To address this challenge, we propose to utilize the\nlearning-to-optimize technique or amortized optimization to predict the\ninformative direction of any given two mini-batch probability measures. To the\nbest of our knowledge, this is the first work that bridges amortized\noptimization and sliced Wasserstein generative models. In particular, we derive\nlinear amortized models, generalized linear amortized models, and non-linear\namortized models which are corresponding to three types of novel mini-batch\nlosses, named amortized sliced Wasserstein. We demonstrate the favorable\nperformance of the proposed sliced losses in deep generative modeling on\nstandard benchmark datasets.",
    "descriptor": "\nComments: 24 pages, 6 figures\n",
    "authors": [
      "Khai Nguyen",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13417"
  },
  {
    "id": "arXiv:2203.13422",
    "title": "Pseudo-Label Transfer From Frame-Level To Note-Level In A  Teacher-Student Framework for Singing Transcription From Polyphonic Music",
    "abstract": "Lack of large-scale note-level labeled data is the major obstacle to singing\ntranscription from polyphonic music. We address the issue by using pseudo\nlabels from vocal pitch estimation models given unlabeled data. The proposed\nmethod first converts the frame-level pseudo labels to note-level through pitch\nand rhythm quantization steps. Then, it further improves the label quality\nthrough self-training in a teacher-student framework. To validate the method,\nwe conduct various experiment settings by investigating two vocal pitch\nestimation models as pseudo-label generators, two setups of teacher-student\nframeworks, and the number of iterations in self-training. The results show\nthat the proposed method can effectively leverage large-scale unlabeled audio\ndata and self-training with the noisy student model helps to improve\nperformance. Finally, we show that the model trained with only unlabeled data\nhas comparable performance to previous works and the model trained with\nadditional labeled data achieves higher accuracy than the model trained with\nonly labeled data.",
    "descriptor": "\nComments: Accepted for publication at the 45th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2022)\n",
    "authors": [
      "Sangeun Kum",
      "Jongpil Lee",
      "Keunhyoung Luke Kim",
      "Taehyoung Kim",
      "Juhan Nam"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.13422"
  },
  {
    "id": "arXiv:2203.13446",
    "title": "Randomized Policy Optimization for Optimal Stopping",
    "abstract": "Optimal stopping is the problem of determining when to stop a stochastic\nsystem in order to maximize reward, which is of practical importance in domains\nsuch as finance, operations management and healthcare. Existing methods for\nhigh-dimensional optimal stopping that are popular in practice produce\ndeterministic linear policies -- policies that deterministically stop based on\nthe sign of a weighted sum of basis functions -- but are not guaranteed to find\nthe optimal policy within this policy class given a fixed basis function\narchitecture. In this paper, we propose a new methodology for optimal stopping\nbased on randomized linear policies, which choose to stop with a probability\nthat is determined by a weighted sum of basis functions. We motivate these\npolicies by establishing that under mild conditions, given a fixed basis\nfunction architecture, optimizing over randomized linear policies is equivalent\nto optimizing over deterministic linear policies. We formulate the problem of\nlearning randomized linear policies from data as a smooth non-convex sample\naverage approximation (SAA) problem. We theoretically prove the almost sure\nconvergence of our randomized policy SAA problem and establish bounds on the\nout-of-sample performance of randomized policies obtained from our SAA problem\nbased on Rademacher complexity. We also show that the SAA problem is in general\nNP-Hard, and consequently develop a practical heuristic for solving our\nrandomized policy problem. Through numerical experiments on a benchmark family\nof option pricing problem instances, we show that our approach can\nsubstantially outperform state-of-the-art methods.",
    "descriptor": "\nComments: 65 pages, 1 figure\n",
    "authors": [
      "Xinyi Guan",
      "Velibor V. Mi\u0161i\u0107"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13446"
  },
  {
    "id": "arXiv:2203.13467",
    "title": "RD-Optimized Trit-Plane Coding of Deep Compressed Image Latent Tensors",
    "abstract": "DPICT is the first learning-based image codec supporting fine granular\nscalability. In this paper, we describe how to implement two key components of\nDPICT efficiently: trit-plane slicing and RD-prioritized transmission. In\nDPICT, we transform an image into a latent tensor, represent the tensor in\nternary digits (trits), and encode the trits in the decreasing order of\nsignificance. For entropy encoding, we should compute the probability of each\ntrit, which demands high time complexity in both the encoder and the decoder.\nTo reduce the complexity, we develop a parallel computing scheme for the\nprobabilities and describe it in detail with pseudo-codes. Moreover, in this\npaper, we compare the trit-plane slicing in DPICT with the alternative\nbit-plane slicing. Experimental results show that the time complexity is\nreduced significantly by the parallel computing and that the trit-plane slicing\nprovides better rate-distortion performances than the bit-plane slicing.",
    "descriptor": "",
    "authors": [
      "Seungmin Jeon",
      "Jae-Han Lee",
      "Chang-Su Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13467"
  },
  {
    "id": "arXiv:2203.13482",
    "title": "Polarization Multiplexed Diffractive Computing: All-Optical  Implementation of a Group of Linear Transformations Through a  Polarization-Encoded Diffractive Network",
    "abstract": "Research on optical computing has recently attracted significant attention\ndue to the transformative advances in machine learning. Among different\napproaches, diffractive optical networks composed of spatially-engineered\ntransmissive surfaces have been demonstrated for all-optical statistical\ninference and performing arbitrary linear transformations using passive,\nfree-space optical layers. Here, we introduce a polarization multiplexed\ndiffractive processor to all-optically perform multiple, arbitrarily-selected\nlinear transformations through a single diffractive network trained using deep\nlearning. In this framework, an array of pre-selected linear polarizers is\npositioned between trainable transmissive diffractive materials that are\nisotropic, and different target linear transformations (complex-valued) are\nuniquely assigned to different combinations of input/output polarization\nstates. The transmission layers of this polarization multiplexed diffractive\nnetwork are trained and optimized via deep learning and error-backpropagation\nby using thousands of examples of the input/output fields corresponding to each\none of the complex-valued linear transformations assigned to different\ninput/output polarization combinations. Our results and analysis reveal that a\nsingle diffractive network can successfully approximate and all-optically\nimplement a group of arbitrarily-selected target transformations with a\nnegligible error when the number of trainable diffractive features/neurons (N)\napproaches N_p x N_i x N_o, where N_i and N_o represent the number of pixels at\nthe input and output fields-of-view, respectively, and N_p refers to the number\nof unique linear transformations assigned to different input/output\npolarization combinations. This polarization-multiplexed all-optical\ndiffractive processor can find various applications in optical computing and\npolarization-based machine vision tasks.",
    "descriptor": "\nComments: 31 pages, 7 figures\n",
    "authors": [
      "Jingxi Li",
      "Yi-Chun Hung",
      "Onur Kulce",
      "Deniz Mengu",
      "Aydogan Ozcan"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.13482"
  },
  {
    "id": "arXiv:2203.13508",
    "title": "BDDM: Bilateral Denoising Diffusion Models for Fast and High-Quality  Speech Synthesis",
    "abstract": "Diffusion probabilistic models (DPMs) and their extensions have emerged as\ncompetitive generative models yet confront challenges of efficient sampling. We\npropose a new bilateral denoising diffusion model (BDDM) that parameterizes\nboth the forward and reverse processes with a schedule network and a score\nnetwork, which can train with a novel bilateral modeling objective. We show\nthat the new surrogate objective can achieve a lower bound of the log marginal\nlikelihood tighter than a conventional surrogate. We also find that BDDM allows\ninheriting pre-trained score network parameters from any DPMs and consequently\nenables speedy and stable learning of the schedule network and optimization of\na noise schedule for sampling. Our experiments demonstrate that BDDMs can\ngenerate high-fidelity audio samples with as few as three sampling steps.\nMoreover, compared to other state-of-the-art diffusion-based neural vocoders,\nBDDMs produce comparable or higher quality samples indistinguishable from human\nspeech, notably with only seven sampling steps (143x faster than WaveGrad and\n28.6x faster than DiffWave). We release our code at\nhttps://github.com/tencent-ailab/bddm.",
    "descriptor": "\nComments: Accepted in ICLR 2022. arXiv admin note: text overlap with arXiv:2108.11514\n",
    "authors": [
      "Max W. Y. Lam",
      "Jun Wang",
      "Dan Su",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.13508"
  },
  {
    "id": "arXiv:2203.13522",
    "title": "New Quantum Algorithms for Computing Quantum Entropies and Distances",
    "abstract": "We propose a series of quantum algorithms for computing a wide range of\nquantum entropies and distances, including the von Neumann entropy, quantum\nR\\'{e}nyi entropy, trace distance, and fidelity. The proposed algorithms\nsignificantly outperform the best known (and even quantum) ones in the low-rank\ncase, some of which achieve exponential speedups. In particular, for\n$N$-dimensional quantum states of rank $r$, our proposed quantum algorithms for\ncomputing the von Neumann entropy, trace distance and fidelity within additive\nerror $\\varepsilon$ have time complexity of $\\tilde O(r^2/\\varepsilon^2)$,\n$\\tilde O(r^5/\\varepsilon^6)$ and $\\tilde O(r^{6.5}/\\varepsilon^{7.5})$,\nrespectively. In contrast, the known algorithms for the von Neumann entropy and\ntrace distance require quantum time complexity of $\\Omega(N)$\n[AISW19,GL20,GHS21], and the best known one for fidelity requires $\\tilde\nO(r^{21.5}/\\varepsilon^{23.5})$ [WZC+21].\nThe key idea of our quantum algorithms is to extend block-encoding from\nunitary operators in previous work to quantum states (i.e., density operators).\nIt is realized by developing several convenient techniques to manipulate\nquantum states and extract information from them. In particular, we introduce a\nnovel technique for eigenvalue transformation of density operators and their\n(non-integer) positive powers, based on the powerful quantum singular value\ntransformation (QSVT) [GSLW19]. The advantage of our techniques over the\nexisting methods is that no restrictions on density operators are required; in\nsharp contrast, the previous methods usually require a lower bound of the\nminimal non-zero eigenvalue of density operators. In addition, we provide some\ntechniques of independent interest for trace estimation, linear combinations,\nand eigenvalue threshold projectors of (subnormalized) density operators, which\nwill be, we believe, useful in other quantum algorithms.",
    "descriptor": "\nComments: 51 pages\n",
    "authors": [
      "Qisheng Wang",
      "Ji Guan",
      "Junyi Liu",
      "Zhicheng Zhang",
      "Mingsheng Ying"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.13522"
  },
  {
    "id": "arXiv:2203.13523",
    "title": "Linear Complexity of Sequences on Koblitz Curves of Genus 2",
    "abstract": "In this paper, we consider the hyperelliptic analogue of the Frobenius\nendomorphism generator and show that it produces sequences with large linear\ncomplexity on the Jacobian of genus 2 curves.",
    "descriptor": "",
    "authors": [
      "Vishnupriya Anupindi"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.13523"
  },
  {
    "id": "arXiv:2203.13574",
    "title": "Embedding Recurrent Layers with Dual-Path Strategy in a Variant of  Convolutional Network for Speaker-Independent Speech Separation",
    "abstract": "Speaker-independent speech separation has achieved remarkable performance in\nrecent years with the development of deep neural network (DNN). Various network\narchitectures, from traditional convolutional neural network (CNN) and\nrecurrent neural network (RNN) to advanced transformer, have been designed\nsophistically to improve separation performance. However, the state-of-the-art\nmodels usually suffer from several flaws related to the computation, such as\nlarge model size, huge memory consumption and computational complexity. To find\nthe balance between the performance and computational efficiency and to further\nexplore the modeling ability of traditional network structure, we combine RNN\nand a newly proposed variant of convolutional network to cope with speech\nseparation problem. By embedding two RNNs into basic block of this variant with\nthe help of dual-path strategy, the proposed network can effectively learn the\nlocal information and global dependency. Besides, a four-staged structure\nenables the separation procedure to be performed gradually at finer and finer\nscales as the feature dimension increases. The experimental results on various\ndatasets have proven the effectiveness of the proposed method and shown that a\ntrade-off between the separation performance and computational efficiency is\nwell achieved.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Xue Yang",
      "Changchun Bao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.13574"
  },
  {
    "id": "arXiv:2203.13617",
    "title": "EmotionNAS: Two-stream Architecture Search for Speech Emotion  Recognition",
    "abstract": "Speech emotion recognition (SER) is a crucial research topic in\nhuman-computer interactions. Existing works are mainly based on manually\ndesigned models. Despite their great success, these methods heavily rely on\nhistorical experience, which are time-consuming but cannot exhaust all possible\nstructures. To address this problem, we propose a neural architecture search\n(NAS) based framework for SER, called \"EmotionNAS\". We take spectrogram and\nwav2vec features as the inputs, followed with NAS to optimize the network\nstructure for these features separately. We further incorporate complementary\ninformation in these features through decision-level fusion. Experimental\nresults on IEMOCAP demonstrate that our method succeeds over existing\nstate-of-the-art strategies on SER.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Haiyang Sun",
      "Zheng Lian",
      "Bin Liu",
      "Ying Li",
      "Licai Sun",
      "Cong Cai",
      "Jianhua Tao",
      "Meng Wang",
      "Yuan Cheng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.13617"
  },
  {
    "id": "arXiv:2203.13633",
    "title": "Dealing with collinearity in large-scale linear system identification  using Bayesian regularization",
    "abstract": "We consider the identification of large-scale linear and stable dynamic\nsystems whose outputs may be the result of many correlated inputs. Hence,\nsevere ill-conditioning may affect the estimation problem. This is a scenario\noften arising when modeling complex physical systems given by the\ninterconnection of many sub-units where feedback and algebraic loops can be\nencountered. We develop a strategy based on Bayesian regularization where any\nimpulse response is modeled as the realization of a zero-mean Gaussian process.\nThe stable spline covariance is used to include information on smooth\nexponential decay of the impulse responses. We then design a new Markov chain\nMonte Carlo scheme that deals with collinearity and is able to efficiently\nreconstruct the posterior of the impulse responses. It is based on a variation\nof Gibbs sampling which updates possibly overlapping blocks of the parameter\nspace on the basis of the level of collinearity affecting the different inputs.\nNumerical experiments are included to test the goodness of the approach where\nhundreds of impulse responses form the system and inputs correlation may be\nvery high.",
    "descriptor": "\nComments: 7 pages, 10 figures; Keywords: linear system identification, Bayesian regularization, MCMC, stable spline prior\n",
    "authors": [
      "Wenqi Cao",
      "Gianluigi Pillonetto"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13633"
  },
  {
    "id": "arXiv:2203.13680",
    "title": "ST-FL: Style Transfer Preprocessing in Federated Learning for COVID-19  Segmentation",
    "abstract": "Chest Computational Tomography (CT) scans present low cost, speed and\nobjectivity for COVID-19 diagnosis and deep learning methods have shown great\npromise in assisting the analysis and interpretation of these images. Most\nhospitals or countries can train their own models using in-house data, however\nempirical evidence shows that those models perform poorly when tested on new\nunseen cases, surfacing the need for coordinated global collaboration. Due to\nprivacy regulations, medical data sharing between hospitals and nations is\nextremely difficult. We propose a GAN-augmented federated learning model,\ndubbed ST-FL (Style Transfer Federated Learning), for COVID-19 image\nsegmentation. Federated learning (FL) permits a centralised model to be learned\nin a secure manner from heterogeneous datasets located in disparate private\ndata silos. We demonstrate that the widely varying data quality on FL client\nnodes leads to a sub-optimal centralised FL model for COVID-19 chest CT image\nsegmentation. ST-FL is a novel FL framework that is robust in the face of\nhighly variable data quality at client nodes. The robustness is achieved by a\ndenoising CycleGAN model at each client of the federation that maps arbitrary\nquality images into the same target quality, counteracting the severe data\nvariability evident in real-world FL use-cases. Each client is provided with\nthe target style, which is the same for all clients, and trains their own\ndenoiser. Our qualitative and quantitative results suggest that this FL model\nperforms comparably to, and in some cases better than, a model that has\ncentralised access to all the training data.",
    "descriptor": "\nComments: 5 pages, 1 figure, full version (15 pages, 13 figures) to be published in SPIE: Medical Imaging 2022 Proceedings\n",
    "authors": [
      "Antonios Georgiadis",
      "Varun Babbar",
      "Fran Silavong",
      "Sean Moran",
      "Rob Otter"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13680"
  },
  {
    "id": "arXiv:2203.13739",
    "title": "High Dimensional Quantum Learning With Small Quantum Computers",
    "abstract": "Quantum computers hold great promise to enhance machine learning, but their\ncurrent qubit counts restrict the realisation of this promise. In an attempt to\nplacate this limitation techniques can be applied for evaluating a quantum\ncircuit using a machine with fewer qubits than the circuit naively requires.\nThese techniques work by evaluating many smaller circuits on the smaller\nmachine, that are then combined in a polynomial to replicate the output of the\nlarger machine. This scheme requires more circuit evaluations than are\npractical for general circuits. However, we investigate the possibility that\nfor certain applications many of these subcircuits are superfluous, and that a\nmuch smaller sum is sufficient to estimate the full circuit. We construct a\nmachine learning model that may be capable of approximating the outputs of the\nlarger circuit with much fewer circuit evaluations. We successfully apply our\nmodel to the task of digit recognition, using simulated quantum computers much\nsmaller than the data dimension. The model is also applied to the task of\napproximating a random 10 qubit PQC with simulated access to a 5 qubit\ncomputer, even with only relatively modest number of circuits our model\nprovides an accurate approximation of the 10 qubit PQCs output, superior to a\nneural network attempt. The developed method might be useful for implementing\nquantum models on larger data throughout the NISQ era.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Simon C. Marshall",
      "Casper Gyurik",
      "Vedran Dunjko"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13739"
  },
  {
    "id": "arXiv:2203.13754",
    "title": "Fast fluorescence lifetime imaging analysis via extreme learning machine",
    "abstract": "We present a fast and accurate analytical method for fluorescence lifetime\nimaging microscopy (FLIM) using the extreme learning machine (ELM). We used\nextensive metrics to evaluate ELM and existing algorithms. First, we compared\nthese algorithms using synthetic datasets. Results indicate that ELM can obtain\nhigher fidelity, even in low-photon conditions. Afterwards, we used ELM to\nretrieve lifetime components from human prostate cancer cells loaded with gold\nnanosensors, showing that ELM also outperforms the iterative fitting and\nnon-fitting algorithms. By comparing ELM with a computational efficient neural\nnetwork, ELM achieves comparable accuracy with less training and inference\ntime. As there is no back-propagation process for ELM during the training\nphase, the training speed is much higher than existing neural network\napproaches. The proposed strategy is promising for edge computing with online\ntraining.",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Zhenya Zang",
      "Dong Xiao",
      "Quan Wang",
      "Zinuo Li",
      "Wujun Xie",
      "Yu Chen",
      "David Day Uei Li"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13754"
  },
  {
    "id": "arXiv:2203.13760",
    "title": "JAX-FLUIDS: A fully-differentiable high-order computational fluid  dynamics solver for compressible two-phase flows",
    "abstract": "Physical systems are governed by partial differential equations (PDEs). The\nNavier-Stokes equations describe fluid flows and are representative of\nnonlinear physical systems with complex spatio-temporal interactions. Fluid\nflows are omnipresent in nature and engineering applications, and their\naccurate simulation is essential for providing insights into these processes.\nWhile PDEs are typically solved with numerical methods, the recent success of\nmachine learning (ML) has shown that ML methods can provide novel avenues of\nfinding solutions to PDEs. ML is becoming more and more present in\ncomputational fluid dynamics (CFD). However, up to this date, there does not\nexist a general-purpose ML-CFD package which provides 1) powerful\nstate-of-the-art numerical methods, 2) seamless hybridization of ML with CFD,\nand 3) automatic differentiation (AD) capabilities. AD in particular is\nessential to ML-CFD research as it provides gradient information and enables\noptimization of preexisting and novel CFD models. In this work, we propose\nJAX-FLUIDS: a comprehensive fully-differentiable CFD Python solver for\ncompressible two-phase flows. JAX-FLUIDS allows the simulation of complex fluid\ndynamics with phenomena like three-dimensional turbulence, compressibility\neffects, and two-phase flows. Written entirely in JAX, it is straightforward to\ninclude existing ML models into the proposed framework. Furthermore, JAX-FLUIDS\nenables end-to-end optimization. I.e., ML models can be optimized with\ngradients that are backpropagated through the entire CFD algorithm, and\ntherefore contain not only information of the underlying PDE but also of the\napplied numerical methods. We believe that a Python package like JAX-FLUIDS is\ncrucial to facilitate research at the intersection of ML and CFD and may pave\nthe way for an era of differentiable fluid dynamics.",
    "descriptor": "\nComments: 53 pages, 23 figures\n",
    "authors": [
      "Deniz A. Bezgin",
      "Aaron B. Buhendwa",
      "Nikolaus A. Adams"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13760"
  },
  {
    "id": "arXiv:2203.13779",
    "title": "Origins of Low-dimensional Adversarial Perturbations",
    "abstract": "In this note, we initiate a rigorous study of the phenomenon of\nlow-dimensional adversarial perturbations in classification. These are\nadversarial perturbations wherein, unlike the classical setting, the attacker's\nsearch is limited to a low-dimensional subspace of the feature space. The goal\nis to fool the classifier into flipping its decision on a nonzero fraction of\ninputs from a designated class, upon the addition of perturbations from a\nsubspace chosen by the attacker and fixed once and for all. It is desirable\nthat the dimension $k$ of the subspace be much smaller than the dimension $d$\nof the feature space, while the norm of the perturbations should be negligible\ncompared to the norm of a typical data point. In this work, we consider binary\nclassification models under very general regularity conditions, which are\nverified by certain feedforward neural networks (e.g., with sufficiently\nsmooth, or else ReLU activation function), and compute analytical lower-bounds\nfor the fooling rate of any subspace. These bounds explicitly highlight the\ndependence that the fooling rate has on the margin of the model (i.e., the\nratio of the output to its $L_2$-norm of its gradient at a test point), and on\nthe alignment of the given subspace with the gradients of the model w.r.t.\ninputs. Our results provide a theoretical explanation for the recent success of\nheuristic methods for efficiently generating low-dimensional adversarial\nperturbations. Moreover, our theoretical results are confirmed by experiments.",
    "descriptor": "",
    "authors": [
      "Elvis Dohmatob",
      "Chuan Guo",
      "Morgane Goibert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13779"
  },
  {
    "id": "arXiv:2203.13784",
    "title": "Disadvantaged Communities Have Lower Access to Urban Infrastructure",
    "abstract": "Disparity in spatial accessibility is strongly associated with growing\ninequalities among urban communities. Since improving levels of accessibility\nfor certain communities can provide them with upward social mobility and\naddress social exclusion and inequalities in cities, it is important to\nunderstand the nature and distribution of spatial accessibility among urban\ncommunities. To support decision-makers in achieving inclusion and fairness in\npolicy interventions in cities, we present an open-source and data-driven\nframework to understand the spatial nature of accessibility to infrastructure\namong the different demographics. We find that accessibility to a wide range of\ninfrastructure in any city (54 cities) converges to a Zipf's law, suggesting\nthat inequalities also appear proportional to growth processes in these cities.\nThen, assessing spatial inequalities among the socioeconomically clustered\nurban profiles for 10 of those cities, we find urban communities are distinctly\nsegregated along social and spatial lines. We find low accessibility scores for\npopulations who have a larger share of minorities, earn less, and have a\nrelatively lower number of individuals with a university degree. These findings\nsuggest that the reproducible framework we propose may be instrumental in\nunderstanding processes leading to spatial inequalities and in supporting\ncities to devise targeted measures for addressing inequalities for certain\nunderprivileged communities.",
    "descriptor": "\nComments: 35 pages, 6 figures\n",
    "authors": [
      "Leonardo Nicoletti",
      "Mikhail Sirenko",
      "Trivik Verma"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.13784"
  },
  {
    "id": "arXiv:2203.13787",
    "title": "A Hybrid Framework for Sequential Data Prediction with End-to-End  Optimization",
    "abstract": "We investigate nonlinear prediction in an online setting and introduce a\nhybrid model that effectively mitigates, via an end-to-end architecture, the\nneed for hand-designed features and manual model selection issues of\nconventional nonlinear prediction/regression methods. In particular, we use\nrecursive structures to extract features from sequential signals, while\npreserving the state information, i.e., the history, and boosted decision trees\nto produce the final output. The connection is in an end-to-end fashion and we\njointly optimize the whole architecture using stochastic gradient descent, for\nwhich we also provide the backward pass update equations. In particular, we\nemploy a recurrent neural network (LSTM) for adaptive feature extraction from\nsequential data and a gradient boosting machinery (soft GBDT) for effective\nsupervised regression. Our framework is generic so that one can use other deep\nlearning architectures for feature extraction (such as RNNs and GRUs) and\nmachine learning algorithms for decision making as long as they are\ndifferentiable. We demonstrate the learning behavior of our algorithm on\nsynthetic data and the significant performance improvements over the\nconventional methods over various real life datasets. Furthermore, we openly\nshare the source code of the proposed method to facilitate further research.",
    "descriptor": "",
    "authors": [
      "Mustafa E. Ayd\u0131n",
      "Suleyman S. Kozat"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.13787"
  },
  {
    "id": "arXiv:1605.01661",
    "title": "Parallels of human language in the behavior of bottlenose dolphins",
    "abstract": "Comments: In press in Linguistic Frontiers",
    "descriptor": "\nComments: In press in Linguistic Frontiers\n",
    "authors": [
      "R. Ferrer-i-Cancho",
      "D. Lusseau",
      "B. McCowan"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1605.01661"
  },
  {
    "id": "arXiv:1804.01018",
    "title": "Distributionally Linearizable Data Structures",
    "abstract": "Distributionally Linearizable Data Structures",
    "descriptor": "",
    "authors": [
      "Dan Alistarh",
      "Trevor Brown",
      "Justin Kopinsky",
      "Jerry Z. Li",
      "Giorgi Nadiradze"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/1804.01018"
  },
  {
    "id": "arXiv:1904.02342",
    "title": "Text Generation from Knowledge Graphs with Graph Transformers",
    "abstract": "Comments: Accepted as a long paper in NAACL 2019",
    "descriptor": "\nComments: Accepted as a long paper in NAACL 2019\n",
    "authors": [
      "Rik Koncel-Kedziorski",
      "Dhanush Bekal",
      "Yi Luan",
      "Mirella Lapata",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1904.02342"
  },
  {
    "id": "arXiv:1906.02831",
    "title": "Detection and Tracking of Multiple Mice Using Part Proposal Networks",
    "abstract": "Detection and Tracking of Multiple Mice Using Part Proposal Networks",
    "descriptor": "",
    "authors": [
      "Zheheng Jiang",
      "Zhihua Liu",
      "Long Chen",
      "Lei Tong",
      "Xiangrong Zhang",
      "Xiangyuan Lan",
      "Danny Crookes",
      "Ming-Hsuan Yang",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1906.02831"
  },
  {
    "id": "arXiv:1908.01909",
    "title": "Circular Proofs as Session-Typed Processes: A Local Validity Condition",
    "abstract": "Comments: The final version, submitted to Logical Methods in Computer Science for publication",
    "descriptor": "\nComments: The final version, submitted to Logical Methods in Computer Science for publication\n",
    "authors": [
      "Farzaneh Derakhshan",
      "Frank Pfenning"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1908.01909"
  },
  {
    "id": "arXiv:1910.05115",
    "title": "Identifying Mood Episodes Using Dialogue Features from Clinical  Interviews",
    "abstract": "Identifying Mood Episodes Using Dialogue Features from Clinical  Interviews",
    "descriptor": "",
    "authors": [
      "Zakaria Aldeneh",
      "Mimansa Jaiswal",
      "Michael Picheny",
      "Melvin McInnis",
      "Emily Mower Provost"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/1910.05115"
  },
  {
    "id": "arXiv:1910.12308",
    "title": "Asynchronous Decentralized SGD with Quantized and Local Updates",
    "abstract": "Asynchronous Decentralized SGD with Quantized and Local Updates",
    "descriptor": "",
    "authors": [
      "Giorgi Nadiradze",
      "Amirmojtaba Sabour",
      "Peter Davies",
      "Shigang Li",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.12308"
  },
  {
    "id": "arXiv:2003.00537",
    "title": "Gender Disparities in International Research Collaboration: A  Large-scale Bibliometric Study of 25,000 University Professors",
    "abstract": "Comments: 37 pages, 8 figures,6 tables",
    "descriptor": "\nComments: 37 pages, 8 figures,6 tables\n",
    "authors": [
      "Marek Kwiek",
      "Wojciech Roszka"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2003.00537"
  },
  {
    "id": "arXiv:2005.10400",
    "title": "Principal Fairness for Human and Algorithmic Decision-Making",
    "abstract": "Principal Fairness for Human and Algorithmic Decision-Making",
    "descriptor": "",
    "authors": [
      "Kosuke Imai",
      "Zhichao Jiang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.10400"
  },
  {
    "id": "arXiv:2010.06402",
    "title": "Which Model to Transfer? Finding the Needle in the Growing Haystack",
    "abstract": "Which Model to Transfer? Finding the Needle in the Growing Haystack",
    "descriptor": "",
    "authors": [
      "Cedric Renggli",
      "Andr\u00e9 Susano Pinto",
      "Luka Rimanic",
      "Joan Puigcerver",
      "Carlos Riquelme",
      "Ce Zhang",
      "Mario Lucic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.06402"
  },
  {
    "id": "arXiv:2010.11372",
    "title": "Symmetrical Z-Complementary Code Sets (SZCCSs) for Optimal Training in  Generalized Spatial Modulation",
    "abstract": "Comments: 13 pages, 7 figures, submitted to IEEE Transactions on Signal Processing",
    "descriptor": "\nComments: 13 pages, 7 figures, submitted to IEEE Transactions on Signal Processing\n",
    "authors": [
      "Yajing Zhou",
      "Zhengchun Zhou",
      "Zilong Liu",
      "Yang Yang",
      "Ping Yang",
      "Pingzhi Fan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.11372"
  },
  {
    "id": "arXiv:2010.12243",
    "title": "An analysis of the SIGMOD 2014 Programming Contest: Complex queries on  the LDBC social network graph",
    "abstract": "An analysis of the SIGMOD 2014 Programming Contest: Complex queries on  the LDBC social network graph",
    "descriptor": "",
    "authors": [
      "M\u00e1rton Elekes",
      "J\u00e1nos Benjamin Antal",
      "G\u00e1bor Sz\u00e1rnyas"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2010.12243"
  },
  {
    "id": "arXiv:2011.12382",
    "title": "Reinforced optimal control",
    "abstract": "Reinforced optimal control",
    "descriptor": "",
    "authors": [
      "Christian Bayer",
      "Denis Belomestny",
      "Paul Hager",
      "Paolo Pigato",
      "John Schoenmakers",
      "Vladimir Spokoiny"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.12382"
  },
  {
    "id": "arXiv:2012.12368",
    "title": "Understanding and Increasing Efficiency of Frank-Wolfe Adversarial  Training",
    "abstract": "Comments: IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022. Preliminary version ICML 2021 Adversarial Machine Learning Workshop. Code: this https URL",
    "descriptor": "\nComments: IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022. Preliminary version ICML 2021 Adversarial Machine Learning Workshop. Code: this https URL\n",
    "authors": [
      "Theodoros Tsiligkaridis",
      "Jay Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.12368"
  },
  {
    "id": "arXiv:2101.07395",
    "title": "Spectral convergence of probability densities for forward problems in  uncertainty quantification",
    "abstract": "Spectral convergence of probability densities for forward problems in  uncertainty quantification",
    "descriptor": "",
    "authors": [
      "Amir Sagiv"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2101.07395"
  },
  {
    "id": "arXiv:2102.05912",
    "title": "On Transportation of Mini-batches: A Hierarchical Approach",
    "abstract": "Comments: 46 pages, 17 figures, 8 tables",
    "descriptor": "\nComments: 46 pages, 17 figures, 8 tables\n",
    "authors": [
      "Khai Nguyen",
      "Dang Nguyen",
      "Quoc Nguyen",
      "Tung Pham",
      "Hung Bui",
      "Dinh Phung",
      "Trung Le",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05912"
  },
  {
    "id": "arXiv:2103.04505",
    "title": "Split Computing and Early Exiting for Deep Learning Applications: Survey  and Research Challenges",
    "abstract": "Comments: Accepted to ACM Computing Surveys (CSUR)",
    "descriptor": "\nComments: Accepted to ACM Computing Surveys (CSUR)\n",
    "authors": [
      "Yoshitomo Matsubara",
      "Marco Levorato",
      "Francesco Restuccia"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.04505"
  },
  {
    "id": "arXiv:2103.12468",
    "title": "Approximately Counting Answers to Conjunctive Queries with Disequalities  and Negations",
    "abstract": "Comments: An extended abstract of this work is accepted for publication at PODS22. 30 pages, 1 figure",
    "descriptor": "\nComments: An extended abstract of this work is accepted for publication at PODS22. 30 pages, 1 figure\n",
    "authors": [
      "Jacob Focke",
      "Leslie Ann Goldberg",
      "Marc Roth",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2103.12468"
  },
  {
    "id": "arXiv:2104.14362",
    "title": "From Distributed Machine Learning to Federated Learning: A Survey",
    "abstract": "Comments: Accepted by KAIS",
    "descriptor": "\nComments: Accepted by KAIS\n",
    "authors": [
      "Ji Liu",
      "Jizhou Huang",
      "Yang Zhou",
      "Xuhong Li",
      "Shilei Ji",
      "Haoyi Xiong",
      "Dejing Dou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14362"
  },
  {
    "id": "arXiv:2105.02725",
    "title": "CrossWalk: Fairness-enhanced Node Representation Learning",
    "abstract": "Comments: Association for the Advancement of Artificial Intelligence (AAAI) 2022",
    "descriptor": "\nComments: Association for the Advancement of Artificial Intelligence (AAAI) 2022\n",
    "authors": [
      "Ahmad Khajehnejad",
      "Moein Khajehnejad",
      "Mahmoudreza Babaei",
      "Krishna P. Gummadi",
      "Adrian Weller",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.02725"
  },
  {
    "id": "arXiv:2105.12941",
    "title": "CrystalCandle: A User-Facing Model Explainer for Narrative Explanations",
    "abstract": "CrystalCandle: A User-Facing Model Explainer for Narrative Explanations",
    "descriptor": "",
    "authors": [
      "Jilei Yang",
      "Diana Negoescu",
      "Parvez Ahammad"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.12941"
  },
  {
    "id": "arXiv:2105.15168",
    "title": "MSG-Transformer: Exchanging Local Spatial Information by Manipulating  Messenger Tokens",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Jiemin Fang",
      "Lingxi Xie",
      "Xinggang Wang",
      "Xiaopeng Zhang",
      "Wenyu Liu",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15168"
  },
  {
    "id": "arXiv:2106.03645",
    "title": "Photonic Differential Privacy with Direct Feedback Alignment",
    "abstract": "Photonic Differential Privacy with Direct Feedback Alignment",
    "descriptor": "",
    "authors": [
      "Ruben Ohana",
      "Hamlet J. Medina Ruiz",
      "Julien Launay",
      "Alessandro Cappelli",
      "Iacopo Poli",
      "Liva Ralaivola",
      "Alain Rakotomamonjy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.03645"
  },
  {
    "id": "arXiv:2106.04530",
    "title": "Learning from Multiple Noisy Partial Labelers",
    "abstract": "Comments: In Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS) 2022",
    "descriptor": "\nComments: In Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS) 2022\n",
    "authors": [
      "Peilin Yu",
      "Tiffany Ding",
      "Stephen H. Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04530"
  },
  {
    "id": "arXiv:2106.05864",
    "title": "Verifiable and Compositional Reinforcement Learning Systems",
    "abstract": "Comments: Accepted for publication at ICAPS 2022. Changes since last version: An additional example with continuous states and actions has been added. An additional figure providing an overview of the presented framework has been added to the introduction. Additional discussion has been added to the section presenting the algorithm, and to the section presenting the numerical experiments",
    "descriptor": "\nComments: Accepted for publication at ICAPS 2022. Changes since last version: An additional example with continuous states and actions has been added. An additional figure providing an overview of the presented framework has been added to the introduction. Additional discussion has been added to the section presenting the algorithm, and to the section presenting the numerical experiments\n",
    "authors": [
      "Cyrus Neary",
      "Christos Verginis",
      "Murat Cubuktepe",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05864"
  },
  {
    "id": "arXiv:2106.09584",
    "title": "SIFT Matching by Context Exposed",
    "abstract": "Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), March 2022. Project page: this https URL",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), March 2022. Project page: this https URL\n",
    "authors": [
      "Fabio Bellavia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09584"
  },
  {
    "id": "arXiv:2106.11193",
    "title": "Multi-level Feature Learning for Contrastive Multi-view Clustering",
    "abstract": "Multi-level Feature Learning for Contrastive Multi-view Clustering",
    "descriptor": "",
    "authors": [
      "Jie Xu",
      "Huayi Tang",
      "Yazhou Ren",
      "Liang Peng",
      "Xiaofeng Zhu",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11193"
  },
  {
    "id": "arXiv:2106.15661",
    "title": "A Semantic Model for Interacting Cyber-Physical Systems",
    "abstract": "A Semantic Model for Interacting Cyber-Physical Systems",
    "descriptor": "",
    "authors": [
      "Benjamin Lion",
      "Farhad Arbab",
      "Carolyn Talcott"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15661"
  },
  {
    "id": "arXiv:2107.06499",
    "title": "Deduplicating Training Data Makes Language Models Better",
    "abstract": "Comments: Accepted to ACL 2022",
    "descriptor": "\nComments: Accepted to ACL 2022\n",
    "authors": [
      "Katherine Lee",
      "Daphne Ippolito",
      "Andrew Nystrom",
      "Chiyuan Zhang",
      "Douglas Eck",
      "Chris Callison-Burch",
      "Nicholas Carlini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06499"
  },
  {
    "id": "arXiv:2107.09234",
    "title": "Shared Interest: Measuring Human-AI Alignment to Identify Recurring  Patterns in Model Behavior",
    "abstract": "Comments: 17 pages, 10 figures. Published in CHI 2022. For more details, see this http URL",
    "descriptor": "\nComments: 17 pages, 10 figures. Published in CHI 2022. For more details, see this http URL\n",
    "authors": [
      "Angie Boggust",
      "Benjamin Hoover",
      "Arvind Satyanarayan",
      "Hendrik Strobelt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.09234"
  },
  {
    "id": "arXiv:2107.11253",
    "title": "State, global and local parameter estimation using local ensemble Kalman  filters: applications to online machine learning of chaotic dynamics",
    "abstract": "State, global and local parameter estimation using local ensemble Kalman  filters: applications to online machine learning of chaotic dynamics",
    "descriptor": "",
    "authors": [
      "Quentin Malartic",
      "Alban Farchi",
      "Marc Bocquet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2107.11253"
  },
  {
    "id": "arXiv:2107.13444",
    "title": "Operationally-Safe Peer-to-Peer Energy Trading in Distribution Grids: A  Game-Theoretic Market-Clearing Mechanism",
    "abstract": "Comments: 11 pages, 8 figures. Published in IEEE Transactions on Smart Grid, 2022",
    "descriptor": "\nComments: 11 pages, 8 figures. Published in IEEE Transactions on Smart Grid, 2022\n",
    "authors": [
      "Giuseppe Belgioioso",
      "Wicak Ananduta",
      "Sergio Grammatico",
      "Carlos Ocampo-Martinez"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.13444"
  },
  {
    "id": "arXiv:2108.02802",
    "title": "Lower Bounds for Shared-Memory Leader Election under Bounded Write  Contention",
    "abstract": "Lower Bounds for Shared-Memory Leader Election under Bounded Write  Contention",
    "descriptor": "",
    "authors": [
      "Dan Alistarh",
      "Rati Gelashvili",
      "Giorgi Nadiradze"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.02802"
  },
  {
    "id": "arXiv:2108.08871",
    "title": "Structure Learning for Directed Trees",
    "abstract": "Structure Learning for Directed Trees",
    "descriptor": "",
    "authors": [
      "Martin Emil Jakobsen",
      "Rajen D. Shah",
      "Peter B\u00fchlmann",
      "Jonas Peters"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08871"
  },
  {
    "id": "arXiv:2108.09490",
    "title": "Incrementally Stochastic and Accelerated Gradient Information mixed  Optimization for Manipulator Motion Planning",
    "abstract": "Incrementally Stochastic and Accelerated Gradient Information mixed  Optimization for Manipulator Motion Planning",
    "descriptor": "",
    "authors": [
      "Yichang Feng",
      "Jin Wang",
      "Haiyun Zhang",
      "Guodong Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.09490"
  },
  {
    "id": "arXiv:2108.11179",
    "title": "Recall@k Surrogate Loss with Large Batches and Similarity Mixup",
    "abstract": "Comments: CVPR 2022 camera-ready version",
    "descriptor": "\nComments: CVPR 2022 camera-ready version\n",
    "authors": [
      "Yash Patel",
      "Giorgos Tolias",
      "Jiri Matas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11179"
  },
  {
    "id": "arXiv:2109.00301",
    "title": "$\\infty$-former: Infinite Memory Transformer",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Pedro Henrique Martins",
      "Zita Marinho",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.00301"
  },
  {
    "id": "arXiv:2109.00605",
    "title": "Backstepping Mean-Field Density Control for Large-Scale Heterogeneous  Nonlinear Stochastic Systems",
    "abstract": "Backstepping Mean-Field Density Control for Large-Scale Heterogeneous  Nonlinear Stochastic Systems",
    "descriptor": "",
    "authors": [
      "Tongjia Zheng",
      "Qing Han",
      "Hai Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.00605"
  },
  {
    "id": "arXiv:2109.03892",
    "title": "Retrieve, Caption, Generate: Visual Grounding for Enhancing Commonsense  in Text Generation Models",
    "abstract": "Comments: Accepted to AAAI 2022. Code at this https URL",
    "descriptor": "\nComments: Accepted to AAAI 2022. Code at this https URL\n",
    "authors": [
      "Steven Y. Feng",
      "Kevin Lu",
      "Zhuofu Tao",
      "Malihe Alikhani",
      "Teruko Mitamura",
      "Eduard Hovy",
      "Varun Gangal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03892"
  },
  {
    "id": "arXiv:2109.05488",
    "title": "ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation via  Online Exploration and Synthesis",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Kailin Li",
      "Lixin Yang",
      "Xinyu Zhan",
      "Jun Lv",
      "Wenqiang Xu",
      "Jiefeng Li",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.05488"
  },
  {
    "id": "arXiv:2109.05830",
    "title": "Adversarial Bone Length Attack on Action Recognition",
    "abstract": "Comments: 12 pages, 8 figures, accepted to AAAI2022",
    "descriptor": "\nComments: 12 pages, 8 figures, accepted to AAAI2022\n",
    "authors": [
      "Nariki Tanaka",
      "Hiroshi Kera",
      "Kazuhiko Kawamoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05830"
  },
  {
    "id": "arXiv:2109.06352",
    "title": "Uncertainty-Aware Machine Translation Evaluation",
    "abstract": "Comments: Findings of EMNLP 2021 v2: corrected typos (esp. Tab 5)",
    "descriptor": "\nComments: Findings of EMNLP 2021 v2: corrected typos (esp. Tab 5)\n",
    "authors": [
      "Taisiya Glushkova",
      "Chrysoula Zerva",
      "Ricardo Rei",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06352"
  },
  {
    "id": "arXiv:2109.08029",
    "title": "Image Captioning for Effective Use of Language Models in Knowledge-Based  Visual Question Answering",
    "abstract": "Comments: Under review. 25 pages with 4 figures",
    "descriptor": "\nComments: Under review. 25 pages with 4 figures\n",
    "authors": [
      "Ander Salaberria",
      "Gorka Azkune",
      "Oier Lopez de Lacalle",
      "Aitor Soroa",
      "Eneko Agirre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.08029"
  },
  {
    "id": "arXiv:2109.09847",
    "title": "Fast TreeSHAP: Accelerating SHAP Value Computation for Trees",
    "abstract": "Comments: 21 pages (including 9-page appendix), 1 figure",
    "descriptor": "\nComments: 21 pages (including 9-page appendix), 1 figure\n",
    "authors": [
      "Jilei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.09847"
  },
  {
    "id": "arXiv:2109.13675",
    "title": "FlowVocoder: A small Footprint Neural Vocoder based Normalizing flow for  Speech Synthesis",
    "abstract": "FlowVocoder: A small Footprint Neural Vocoder based Normalizing flow for  Speech Synthesis",
    "descriptor": "",
    "authors": [
      "Manh Luong",
      "Viet Anh Tran"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.13675"
  },
  {
    "id": "arXiv:2110.00880",
    "title": "Effective grading refinement for locally linearly independent LR  B-splines",
    "abstract": "Comments: 16 pages, 9 figures",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Francesco Patrizi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.00880"
  },
  {
    "id": "arXiv:2110.06441",
    "title": "Incentive-aware Electric Vehicle Routing Problem: a Bi-level Model and a  Joint Solution Algorithm",
    "abstract": "Comments: Accepted by ACC2022",
    "descriptor": "\nComments: Accepted by ACC2022\n",
    "authors": [
      "Canqi Yao",
      "Shibo Chen",
      "Mauro Salazar",
      "Zaiyue Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06441"
  },
  {
    "id": "arXiv:2110.07374",
    "title": "Physics informed neural networks for continuum micromechanics",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Alexander Henkes",
      "Henning Wessels",
      "Rolf Mahnken"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07374"
  },
  {
    "id": "arXiv:2110.07753",
    "title": "On Efficient Range-Summability of Ideally IID Random Variables in Two or  Higher Dimensions",
    "abstract": "On Efficient Range-Summability of Ideally IID Random Variables in Two or  Higher Dimensions",
    "descriptor": "",
    "authors": [
      "Jingfan Meng",
      "Huayi Wang",
      "Jun Xu",
      "Mitsunori Ogihara"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.07753"
  },
  {
    "id": "arXiv:2110.08388",
    "title": "Probing as Quantifying Inductive Bias",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Alexander Immer",
      "Lucas Torroba Hennigen",
      "Vincent Fortuin",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08388"
  },
  {
    "id": "arXiv:2110.10097",
    "title": "Data-Driven Predictive Control for Connected and Autonomous Vehicles in  Mixed Traffic",
    "abstract": "Comments: 7 figures, 3 figures",
    "descriptor": "\nComments: 7 figures, 3 figures\n",
    "authors": [
      "Jiawei Wang",
      "Yang Zheng",
      "Qing Xu",
      "Keqiang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10097"
  },
  {
    "id": "arXiv:2110.11855",
    "title": "Auctions Between Regret-Minimizing Agents",
    "abstract": "Comments: Published in Proceedings of the ACM Web Conference 2022 (WWW '22)",
    "descriptor": "\nComments: Published in Proceedings of the ACM Web Conference 2022 (WWW '22)\n",
    "authors": [
      "Yoav Kolumbus",
      "Noam Nisan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11855"
  },
  {
    "id": "arXiv:2110.14181",
    "title": "QU-net++: Image Quality Detection Framework for Segmentation of 3D  Medical Image Stacks",
    "abstract": "Comments: 4 pages, 7 figures, 1 Table",
    "descriptor": "\nComments: 4 pages, 7 figures, 1 Table\n",
    "authors": [
      "Sohini Roychowdhury"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14181"
  },
  {
    "id": "arXiv:2110.14953",
    "title": "Multi-Task Neural Processes",
    "abstract": "Comments: 49 pages, 19 figures",
    "descriptor": "\nComments: 49 pages, 19 figures\n",
    "authors": [
      "Donggyun Kim",
      "Seongwoong Cho",
      "Wonkwang Lee",
      "Seunghoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14953"
  },
  {
    "id": "arXiv:2111.00600",
    "title": "Minimum Description Length Recurrent Neural Networks",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Nur Lan",
      "Michal Geyer",
      "Emmanuel Chemla",
      "Roni Katzir"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00600"
  },
  {
    "id": "arXiv:2111.02080",
    "title": "An Explanation of In-context Learning as Implicit Bayesian Inference",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Sang Michael Xie",
      "Aditi Raghunathan",
      "Percy Liang",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02080"
  },
  {
    "id": "arXiv:2111.07941",
    "title": "Distribution Compression in Near-linear Time",
    "abstract": "Comments: Accepted to ICLR 2022",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "Abhishek Shetty",
      "Raaz Dwivedi",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.07941"
  },
  {
    "id": "arXiv:2111.07991",
    "title": "LiT: Zero-Shot Transfer with Locked-image text Tuning",
    "abstract": "Comments: Xiaohua, Xiao, Basil, Andreas and Lucas contributed equally; CVPR 2022",
    "descriptor": "\nComments: Xiaohua, Xiao, Basil, Andreas and Lucas contributed equally; CVPR 2022\n",
    "authors": [
      "Xiaohua Zhai",
      "Xiao Wang",
      "Basil Mustafa",
      "Andreas Steiner",
      "Daniel Keysers",
      "Alexander Kolesnikov",
      "Lucas Beyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.07991"
  },
  {
    "id": "arXiv:2111.08918",
    "title": "Local Texture Estimator for Implicit Representation Function",
    "abstract": "Comments: CVPR 2022 camera-ready version",
    "descriptor": "\nComments: CVPR 2022 camera-ready version\n",
    "authors": [
      "Jaewon Lee",
      "Kyong Hwan Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.08918"
  },
  {
    "id": "arXiv:2111.09030",
    "title": "Trustworthy Long-Tailed Classification",
    "abstract": "Comments: IEEE Conference on Computer Vision and Pattern Recognition 2022",
    "descriptor": "\nComments: IEEE Conference on Computer Vision and Pattern Recognition 2022\n",
    "authors": [
      "Bolian Li",
      "Zongbo Han",
      "Haining Li",
      "Huazhu Fu",
      "Changqing Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09030"
  },
  {
    "id": "arXiv:2111.09154",
    "title": "Execution Order Matters in Greedy Algorithms with Limited Information",
    "abstract": "Execution Order Matters in Greedy Algorithms with Limited Information",
    "descriptor": "",
    "authors": [
      "Rohit Konda",
      "David Grimsman",
      "Jason Marden"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.09154"
  },
  {
    "id": "arXiv:2111.11293",
    "title": "GHRS: Graph-based Hybrid Recommendation System with Application to Movie  Recommendation",
    "abstract": "Comments: 14 pages, 13 figures, under review in an Elsevier journal",
    "descriptor": "\nComments: 14 pages, 13 figures, under review in an Elsevier journal\n",
    "authors": [
      "Zahra Zamanzadeh Darban",
      "Mohammad Hadi Valipour"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11293"
  },
  {
    "id": "arXiv:2111.13087",
    "title": "BoxeR: Box-Attention for 2D and 3D Transformers",
    "abstract": "Comments: In Proceeding of CVPR'2022",
    "descriptor": "\nComments: In Proceeding of CVPR'2022\n",
    "authors": [
      "Duy-Kien Nguyen",
      "Jihong Ju",
      "Olaf Booij",
      "Martin R. Oswald",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13087"
  },
  {
    "id": "arXiv:2111.13585",
    "title": "Evaluating importance of nodes in complex networks with local volume  information dimension",
    "abstract": "Evaluating importance of nodes in complex networks with local volume  information dimension",
    "descriptor": "",
    "authors": [
      "Hanwen Li",
      "Qiuyan Shang",
      "Fangzheng Duan",
      "Yong Deng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.13585"
  },
  {
    "id": "arXiv:2111.15667",
    "title": "Adaptive Inverse Transform Sampling For Efficient Vision Transformers",
    "abstract": "Adaptive Inverse Transform Sampling For Efficient Vision Transformers",
    "descriptor": "",
    "authors": [
      "Mohsen Fayyaz",
      "Soroush Abbasi Koohpayegani",
      "Farnoush Rezaei Jafari",
      "Sunando Sengupta",
      "Hamid Reza Vaezi Joze",
      "Eric Sommerlade",
      "Hamed Pirsiavash",
      "Juergen Gall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15667"
  },
  {
    "id": "arXiv:2112.00229",
    "title": "Frequency Fitness Assignment: Optimization without a Bias for Good  Solutions can be Efficient",
    "abstract": "Frequency Fitness Assignment: Optimization without a Bias for Good  Solutions can be Efficient",
    "descriptor": "",
    "authors": [
      "Thomas Weise",
      "Zhize Wu",
      "Xinlu Li",
      "Yan Chen",
      "J\u00f6rg L\u00e4ssig"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.00229"
  },
  {
    "id": "arXiv:2112.01589",
    "title": "InfoLM: A New Metric to Evaluate Summarization & Data2Text Generation",
    "abstract": "InfoLM: A New Metric to Evaluate Summarization & Data2Text Generation",
    "descriptor": "",
    "authors": [
      "Pierre Colombo",
      "Chloe Clavel",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01589"
  },
  {
    "id": "arXiv:2112.01917",
    "title": "A Structured Dictionary Perspective on Implicit Neural Representations",
    "abstract": "Comments: Accepted to IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022 (26 pages, 16 figures)",
    "descriptor": "\nComments: Accepted to IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022 (26 pages, 16 figures)\n",
    "authors": [
      "Gizem Y\u00fcce",
      "Guillermo Ortiz-Jim\u00e9nez",
      "Beril Besbinar",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01917"
  },
  {
    "id": "arXiv:2112.02500",
    "title": "Global-Local Context Network for Person Search",
    "abstract": "Global-Local Context Network for Person Search",
    "descriptor": "",
    "authors": [
      "Peng Zheng",
      "Jie Qin",
      "Yichao Yan",
      "Shengcai Liao",
      "Bingbing Ni",
      "Xiaogang Cheng",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02500"
  },
  {
    "id": "arXiv:2112.02789",
    "title": "HumanNeRF: Efficiently Generated Human Radiance Field from Sparse Inputs",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Fuqiang Zhao",
      "Wei Yang",
      "Jiakai Zhang",
      "Pei Lin",
      "Yingliang Zhang",
      "Jingyi Yu",
      "Lan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.02789"
  },
  {
    "id": "arXiv:2112.03497",
    "title": "Dataset Geography: Mapping Language Data to Language Users",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Fahim Faisal",
      "Yinkai Wang",
      "Antonios Anastasopoulos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03497"
  },
  {
    "id": "arXiv:2112.04016",
    "title": "DeepFace-EMD: Re-ranking Using Patch-wise Earth Mover's Distance  Improves Out-Of-Distribution Face Identification",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Hai Phan",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04016"
  },
  {
    "id": "arXiv:2112.04120",
    "title": "Feature Statistics Mixing Regularization for Generative Adversarial  Networks",
    "abstract": "Comments: Accepted to CVPR 2022. Our code is available at this https URL",
    "descriptor": "\nComments: Accepted to CVPR 2022. Our code is available at this https URL\n",
    "authors": [
      "Junho Kim",
      "Yunjey Choi",
      "Youngjung Uh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04120"
  },
  {
    "id": "arXiv:2112.04731",
    "title": "Mimicking the Oracle: An Initial Phase Decorrelation Approach for Class  Incremental Learning",
    "abstract": "Comments: CVPR 2022 Camera-Ready Version",
    "descriptor": "\nComments: CVPR 2022 Camera-Ready Version\n",
    "authors": [
      "Yujun Shi",
      "Kuangqi Zhou",
      "Jian Liang",
      "Zihang Jiang",
      "Jiashi Feng",
      "Philip Torr",
      "Song Bai",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04731"
  },
  {
    "id": "arXiv:2112.07068",
    "title": "Score-Based Generative Modeling with Critically-Damped Langevin  Diffusion",
    "abstract": "Comments: ICLR 2022 (Spotlight)",
    "descriptor": "\nComments: ICLR 2022 (Spotlight)\n",
    "authors": [
      "Tim Dockhorn",
      "Arash Vahdat",
      "Karsten Kreis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07068"
  },
  {
    "id": "arXiv:2112.10838",
    "title": "One Sketch for All: One-Shot Personalized Sketch Segmentation",
    "abstract": "Comments: IEEE Transactions on Image Processing, 2022",
    "descriptor": "\nComments: IEEE Transactions on Image Processing, 2022\n",
    "authors": [
      "Anran Qi",
      "Yulia Gryaditskaya",
      "Tao Xiang",
      "Yi-Zhe Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.10838"
  },
  {
    "id": "arXiv:2112.12999",
    "title": "Total Energy Shaping with Neural Interconnection and Damping Assignment  -- Passivity Based Control",
    "abstract": "Comments: Accepted in 4th Annual Learning for Dynamics and Control (L4DC) Conference",
    "descriptor": "\nComments: Accepted in 4th Annual Learning for Dynamics and Control (L4DC) Conference\n",
    "authors": [
      "Santiago Sanchez-Escalonilla",
      "Rodolfo Reyes-Baez",
      "Bayu Jayawardhana"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.12999"
  },
  {
    "id": "arXiv:2201.02409",
    "title": "Amplitude SAR Imagery Splicing Localization",
    "abstract": "Amplitude SAR Imagery Splicing Localization",
    "descriptor": "",
    "authors": [
      "Edoardo Daniele Cannas",
      "Nicol\u00f2 Bonettini",
      "Sara Mandelli",
      "Paolo Bestagini",
      "Stefano Tubaro"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.02409"
  },
  {
    "id": "arXiv:2201.05758",
    "title": "Robust Safe Control Synthesis with Disturbance Observer-Based Control  Barrier Functions",
    "abstract": "Comments: 6 pages, 2 figures",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Ersin Da\u015f",
      "Richard M. Murray"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.05758"
  },
  {
    "id": "arXiv:2201.07197",
    "title": "Finding Strong Components Using Depth-First Search",
    "abstract": "Comments: 27 pages. In memory of Pierre Rosenstiehl",
    "descriptor": "\nComments: 27 pages. In memory of Pierre Rosenstiehl\n",
    "authors": [
      "Robert E. Tarjan",
      "Uri Zwick"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.07197"
  },
  {
    "id": "arXiv:2201.08368",
    "title": "An Alternative Issue Tracking Dataset of Public Jira Repositories",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Lloyd Montgomery",
      "Clara L\u00fcders",
      "Walid Maalej"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08368"
  },
  {
    "id": "arXiv:2201.12383",
    "title": "Bounding Training Data Reconstruction in Private (Deep) Learning",
    "abstract": "Bounding Training Data Reconstruction in Private (Deep) Learning",
    "descriptor": "",
    "authors": [
      "Chuan Guo",
      "Brian Karrer",
      "Kamalika Chaudhuri",
      "Laurens van der Maaten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.12383"
  },
  {
    "id": "arXiv:2201.12680",
    "title": "Deep Contrastive Learning is Provably (almost) Principal Component  Analysis",
    "abstract": "Deep Contrastive Learning is Provably (almost) Principal Component  Analysis",
    "descriptor": "",
    "authors": [
      "Yuandong Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.12680"
  },
  {
    "id": "arXiv:2201.13001",
    "title": "Deep discriminative to kernel generative modeling",
    "abstract": "Deep discriminative to kernel generative modeling",
    "descriptor": "",
    "authors": [
      "Jayanta Dey",
      "Will LeVine",
      "Ashwin De Silva",
      "Ali Geisa",
      "Jong M. Shin",
      "Haoyin Xu",
      "Tiffany Chu",
      "Leyla Isik",
      "Joshua T. Vogelstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.13001"
  },
  {
    "id": "arXiv:2202.02113",
    "title": "From Discrimination to Generation: Knowledge Graph Completion with  Generative Transformer",
    "abstract": "Comments: Accepted by WWW 2022 Poster",
    "descriptor": "\nComments: Accepted by WWW 2022 Poster\n",
    "authors": [
      "Xin Xie",
      "Ningyu Zhang",
      "Zhoubo Li",
      "Shumin Deng",
      "Hui Chen",
      "Feiyu Xiong",
      "Mosha Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02113"
  },
  {
    "id": "arXiv:2202.02169",
    "title": "Wideband Multi-User MIMO Communications with Frequency Selective RISs:  Element Response Modeling and Sum-Rate Maximization",
    "abstract": "Comments: 6 pages; 4 figures; to be presented in IEEE ICC 2022",
    "descriptor": "\nComments: 6 pages; 4 figures; to be presented in IEEE ICC 2022\n",
    "authors": [
      "Konstantinos D. Katsanos",
      "Nir Shlezinger",
      "Mohammadreza F. Imani",
      "George C. Alexandropoulos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02169"
  },
  {
    "id": "arXiv:2202.02914",
    "title": "Global convergence and asymptotic optimality of the heavy ball method  for a class of non-convex optimization problems",
    "abstract": "Comments: 6 pages, 4 figures, to appear in CSS Letters",
    "descriptor": "\nComments: 6 pages, 4 figures, to appear in CSS Letters\n",
    "authors": [
      "Valery Ugrinovskii",
      "Ian R. Petersen",
      "Iman Shames"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02914"
  },
  {
    "id": "arXiv:2202.03956",
    "title": "From Generalisation Error to Transportation-cost Inequalities and Back",
    "abstract": "Comments: Submitted to ISIT 2022",
    "descriptor": "\nComments: Submitted to ISIT 2022\n",
    "authors": [
      "Amedeo Roberto Esposito",
      "Michael Gastpar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.03956"
  },
  {
    "id": "arXiv:2202.04382",
    "title": "Leveraging Experience in Lifelong Multi-Agent Pathfinding",
    "abstract": "Leveraging Experience in Lifelong Multi-Agent Pathfinding",
    "descriptor": "",
    "authors": [
      "Nitzan Madar",
      "Kiril Solovey",
      "Oren Salzman"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04382"
  },
  {
    "id": "arXiv:2202.05932",
    "title": "Metadata-Induced Contrastive Learning for Zero-Shot Multi-Label Text  Classification",
    "abstract": "Comments: 12 pages; Accepted to WWW 2022",
    "descriptor": "\nComments: 12 pages; Accepted to WWW 2022\n",
    "authors": [
      "Yu Zhang",
      "Zhihong Shen",
      "Chieh-Han Wu",
      "Boya Xie",
      "Junheng Hao",
      "Ye-Yi Wang",
      "Kuansan Wang",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.05932"
  },
  {
    "id": "arXiv:2202.07508",
    "title": "Deep Constrained Least Squares for Blind Image Super-Resolution",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Ziwei Luo",
      "Haibin Huang",
      "Lei Yu",
      "Youwei Li",
      "Haoqiang Fan",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07508"
  },
  {
    "id": "arXiv:2202.08679",
    "title": "Where Is My Training Bottleneck? Hidden Trade-Offs in Deep Learning  Preprocessing Pipelines",
    "abstract": "Comments: To be published in SIGMOD, June 12-17, 2022, Philadelphia, PA, USA. Repository: this https URL",
    "descriptor": "\nComments: To be published in SIGMOD, June 12-17, 2022, Philadelphia, PA, USA. Repository: this https URL\n",
    "authors": [
      "Alexander Isenko",
      "Ruben Mayer",
      "Jeffrey Jedele",
      "Hans-Arno Jacobsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.08679"
  },
  {
    "id": "arXiv:2202.08766",
    "title": "Can DtN and GenEO coarse spaces be sufficiently robust for heterogeneous  Helmholtz problems?",
    "abstract": "Can DtN and GenEO coarse spaces be sufficiently robust for heterogeneous  Helmholtz problems?",
    "descriptor": "",
    "authors": [
      "Niall Bootland",
      "Victorita Dolean"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08766"
  },
  {
    "id": "arXiv:2202.09830",
    "title": "Practical Interference Exploitation Precoding without Symbol-by-Symbol  Optimization: A Block-Level Approach",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. v2: Update Eq. 41 v3: Update Eq. 5 Thx Yuming for corrections",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. v2: Update Eq. 41 v3: Update Eq. 5 Thx Yuming for corrections\n",
    "authors": [
      "Ang Li",
      "Chao Shen",
      "Xuewen Liao",
      "Christos Masouros",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.09830"
  },
  {
    "id": "arXiv:2202.11782",
    "title": "Prune and Tune Ensembles: Low-Cost Ensemble Learning With Sparse  Independent Subnetworks",
    "abstract": "Comments: 12 pages, 7 figures, Accepted to AAAI-22; appendix added",
    "descriptor": "\nComments: 12 pages, 7 figures, Accepted to AAAI-22; appendix added\n",
    "authors": [
      "Tim Whitaker",
      "Darrell Whitley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11782"
  },
  {
    "id": "arXiv:2202.12625",
    "title": "Constructive subsampling of finite frames with applications in optimal  function recovery",
    "abstract": "Constructive subsampling of finite frames with applications in optimal  function recovery",
    "descriptor": "",
    "authors": [
      "Felix Bartel",
      "Martin Sch\u00e4fer",
      "Tino Ullrich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.12625"
  },
  {
    "id": "arXiv:2202.12834",
    "title": "An ultraweak variational method for parameterized linear  differential-algebraic equations",
    "abstract": "Comments: 19 pages, 6 figures",
    "descriptor": "\nComments: 19 pages, 6 figures\n",
    "authors": [
      "Emil Beurer",
      "Moritz Feuerle",
      "Niklas Reich",
      "Karsten Urban"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.12834"
  },
  {
    "id": "arXiv:2202.13900",
    "title": "Bounded-error constrained state estimation in presence of sporadic  measurements",
    "abstract": "Comments: 47 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2012.03267",
    "descriptor": "\nComments: 47 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2012.03267\n",
    "authors": [
      "Yasmina Becis-Aubry"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.13900"
  },
  {
    "id": "arXiv:2203.01714",
    "title": "Weakly Supervised Object Localization as Domain Adaption",
    "abstract": "Comments: Accept by CVPR 2022 Conference",
    "descriptor": "\nComments: Accept by CVPR 2022 Conference\n",
    "authors": [
      "Lei Zhu",
      "Qi She",
      "Qian Chen",
      "Yunfei You",
      "Boyu Wang",
      "Yanye Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01714"
  },
  {
    "id": "arXiv:2203.01785",
    "title": "On Learning Contrastive Representations for Learning with Noisy Labels",
    "abstract": "On Learning Contrastive Representations for Learning with Noisy Labels",
    "descriptor": "",
    "authors": [
      "Li Yi",
      "Sheng Liu",
      "Qi She",
      "A. Ian McLeod",
      "Boyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01785"
  },
  {
    "id": "arXiv:2203.01824",
    "title": "LGT-Net: Indoor Panoramic Room Layout Estimation with Geometry-Aware  Transformer Network",
    "abstract": "Comments: To Appear in CVPR 2022",
    "descriptor": "\nComments: To Appear in CVPR 2022\n",
    "authors": [
      "Zhigang Jiang",
      "Zhongzheng Xiang",
      "Jinhua Xu",
      "Ming Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01824"
  },
  {
    "id": "arXiv:2203.01850",
    "title": "T-Cal: An optimal test for the calibration of predictive models",
    "abstract": "Comments: The implementation of T-Cal is available at this https URL",
    "descriptor": "\nComments: The implementation of T-Cal is available at this https URL\n",
    "authors": [
      "Donghwan Lee",
      "Xinmeng Huang",
      "Hamed Hassani",
      "Edgar Dobriban"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01850"
  },
  {
    "id": "arXiv:2203.02540",
    "title": "Evolving symbolic density functionals",
    "abstract": "Evolving symbolic density functionals",
    "descriptor": "",
    "authors": [
      "He Ma",
      "Arunachalam Narayanaswamy",
      "Patrick Riley",
      "Li Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.02540"
  },
  {
    "id": "arXiv:2203.02651",
    "title": "Ensemble Knowledge Guided Sub-network Search and Fine-tuning for Filter  Pruning",
    "abstract": "Ensemble Knowledge Guided Sub-network Search and Fine-tuning for Filter  Pruning",
    "descriptor": "",
    "authors": [
      "Seunghyun Lee",
      "Byung Cheol Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02651"
  },
  {
    "id": "arXiv:2203.02668",
    "title": "Cross Language Image Matching for Weakly Supervised Semantic  Segmentation",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Jinheng Xie",
      "Xianxu Hou",
      "Kai Ye",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.02668"
  },
  {
    "id": "arXiv:2203.03820",
    "title": "A Variational Hierarchical Model for Neural Cross-Lingual Summarization",
    "abstract": "Comments: Accepted at ACL 2022 as a long paper of main conference. Code: this https URL",
    "descriptor": "\nComments: Accepted at ACL 2022 as a long paper of main conference. Code: this https URL\n",
    "authors": [
      "Yunlong Liang",
      "Fandong Meng",
      "Chulun Zhou",
      "Jinan Xu",
      "Yufeng Chen",
      "Jinsong Su",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03820"
  },
  {
    "id": "arXiv:2203.03898",
    "title": "Yet another DE-Sinc indefinite integration formula",
    "abstract": "Yet another DE-Sinc indefinite integration formula",
    "descriptor": "",
    "authors": [
      "Tomoaki Okayama",
      "Ken'ichiro Tanaka"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.03898"
  },
  {
    "id": "arXiv:2203.03978",
    "title": "Contrastive Conditional Neural Processes",
    "abstract": "Comments: accepted to CVPR2022",
    "descriptor": "\nComments: accepted to CVPR2022\n",
    "authors": [
      "Zesheng Ye",
      "Lina Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.03978"
  },
  {
    "id": "arXiv:2203.04132",
    "title": "Motron: Multimodal Probabilistic Human Motion Forecasting",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Tim Salzmann",
      "Marco Pavone",
      "Markus Ryll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.04132"
  },
  {
    "id": "arXiv:2203.05154",
    "title": "Practical Evaluation of Adversarial Robustness via Adaptive Auto Attack",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Ye Liu",
      "Yaya Cheng",
      "Lianli Gao",
      "Xianglong Liu",
      "Qilong Zhang",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05154"
  },
  {
    "id": "arXiv:2203.05181",
    "title": "LineVD: Statement-level Vulnerability Detection using Graph Neural  Networks",
    "abstract": "Comments: Accepted in the 19th International Conference on Mining Software Repositories Technical Papers",
    "descriptor": "\nComments: Accepted in the 19th International Conference on Mining Software Repositories Technical Papers\n",
    "authors": [
      "David Hin",
      "Andrey Kan",
      "Huaming Chen",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.05181"
  },
  {
    "id": "arXiv:2203.06459",
    "title": "An edge centrality measure based on the Kemeny constant",
    "abstract": "An edge centrality measure based on the Kemeny constant",
    "descriptor": "",
    "authors": [
      "D. Altafini",
      "D.A.Bini",
      "V. Cutini",
      "B. Meini",
      "F. Poloni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.06459"
  },
  {
    "id": "arXiv:2203.06517",
    "title": "SA-SASV: An End-to-End Spoof-Aggregated Spoofing-Aware Speaker  Verification System",
    "abstract": "Comments: Update Experiment Results in ASV2019 protocol",
    "descriptor": "\nComments: Update Experiment Results in ASV2019 protocol\n",
    "authors": [
      "Zhongwei Teng",
      "Quchen Fu",
      "Jules White",
      "Maria E. Powell",
      "Douglas C. Schmidt"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.06517"
  },
  {
    "id": "arXiv:2203.06749",
    "title": "Decontextualized I3D ConvNet for ultra-distance runners performance  analysis at a glance",
    "abstract": "Comments: Accepted at ICIAP 2021",
    "descriptor": "\nComments: Accepted at ICIAP 2021\n",
    "authors": [
      "David Freire-Obreg\u00f3n",
      "Javier Lorenzo-Navarro",
      "Modesto Castrill\u00f3n-Santana"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06749"
  },
  {
    "id": "arXiv:2203.06995",
    "title": "The many facets of academic mobility and its impact on scholars' career",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Fakhri Momeni",
      "Fariba Karimi",
      "Philipp Mayr",
      "Isabella Peters",
      "Stefan Dietze"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2203.06995"
  },
  {
    "id": "arXiv:2203.07740",
    "title": "Exact Feature Distribution Matching for Arbitrary Style Transfer and  Domain Generalization",
    "abstract": "Comments: To appear in CVPR2022; codes and supplementary material are available at: this https URL",
    "descriptor": "\nComments: To appear in CVPR2022; codes and supplementary material are available at: this https URL\n",
    "authors": [
      "Yabin Zhang",
      "Minghan Li",
      "Ruihuang Li",
      "Kui Jia",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07740"
  },
  {
    "id": "arXiv:2203.08007",
    "title": "Data Smells in Public Datasets",
    "abstract": "Data Smells in Public Datasets",
    "descriptor": "",
    "authors": [
      "Arumoy Shome",
      "Luis Cruz",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08007"
  },
  {
    "id": "arXiv:2203.08368",
    "title": "Mixed-Precision Neural Network Quantization via Learned Layer-wise  Importance",
    "abstract": "Mixed-Precision Neural Network Quantization via Learned Layer-wise  Importance",
    "descriptor": "",
    "authors": [
      "Chen Tang",
      "Kai Ouyang",
      "Zhi Wang",
      "Yifei Zhu",
      "Yaowei Wang",
      "Wen Ji",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08368"
  },
  {
    "id": "arXiv:2203.09041",
    "title": "DATA: Domain-Aware and Task-Aware Self-supervised Learning",
    "abstract": "Comments: CVPR 2022,8 pages,3 figures",
    "descriptor": "\nComments: CVPR 2022,8 pages,3 figures\n",
    "authors": [
      "Qing Chang",
      "Junran Peng",
      "Lingxie Xie",
      "Jiajun Sun",
      "Haoran Yin",
      "Qi Tian",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09041"
  },
  {
    "id": "arXiv:2203.10117",
    "title": "Towards a Perceptual Model for Estimating the Quality of Visual Speech",
    "abstract": "Comments: Submitted to Interspeech 2022",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Zakaria Aldeneh",
      "Masha Fedzechkina",
      "Skyler Seto",
      "Katherine Metcalf",
      "Miguel Sarabia",
      "Nicholas Apostoloff",
      "Barry-John Theobald"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.10117"
  },
  {
    "id": "arXiv:2203.10214",
    "title": "Thompson Sampling on Asymmetric $\u03b1$-Stable Bandits",
    "abstract": "Comments: 8 pages, 4 figures",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Zhendong Shi",
      "Ercan E. Kuruoglu",
      "Xiaoli Wei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.10214"
  },
  {
    "id": "arXiv:2203.10666",
    "title": "YouTube, The Great Radicalizer? Auditing and Mitigating Ideological  Biases in YouTube Recommendations",
    "abstract": "YouTube, The Great Radicalizer? Auditing and Mitigating Ideological  Biases in YouTube Recommendations",
    "descriptor": "",
    "authors": [
      "Muhammad Haroon",
      "Anshuman Chhabra",
      "Xin Liu",
      "Prasant Mohapatra",
      "Zubair Shafiq",
      "Magdalena Wojcieszak"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.10666"
  },
  {
    "id": "arXiv:2203.10965",
    "title": "PTM4Tag: Sharpening Tag Recommendation of Stack Overflow Posts with  Pre-trained Models",
    "abstract": "Comments: Accepted for Research Track ICPC 2022",
    "descriptor": "\nComments: Accepted for Research Track ICPC 2022\n",
    "authors": [
      "Junda He",
      "Bowen Xu",
      "Zhou Yang",
      "DongGyun Han",
      "Chengran Yang",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.10965"
  },
  {
    "id": "arXiv:2203.11692",
    "title": "Panoptic segmentation with highly imbalanced semantic labels",
    "abstract": "Comments: This submission was uploaded for a challenge but publication date was delayed by arxiv, so we uploaded it on zenodo to match challenge deadlines. This preprint is obsolete now",
    "descriptor": "\nComments: This submission was uploaded for a challenge but publication date was delayed by arxiv, so we uploaded it on zenodo to match challenge deadlines. This preprint is obsolete now\n",
    "authors": [
      "Josef Lorenz Rumberger",
      "Elias Baumann",
      "Peter Hirsch",
      "Dagmar Kainmueller"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11692"
  },
  {
    "id": "arXiv:2203.12078",
    "title": "Modelling and Analysis of Car Following Algorithms for Fuel Economy  Improvement in Connected and Autonomous Vehicles (CAVs)",
    "abstract": "Modelling and Analysis of Car Following Algorithms for Fuel Economy  Improvement in Connected and Autonomous Vehicles (CAVs)",
    "descriptor": "",
    "authors": [
      "Ozgenur Kavas-Torris",
      "Levent Guvenc"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.12078"
  },
  {
    "id": "arXiv:2203.12088",
    "title": "Deep Portrait Delighting",
    "abstract": "Comments: 25 pages, 16 figures",
    "descriptor": "\nComments: 25 pages, 16 figures\n",
    "authors": [
      "Joshua Weir",
      "Junhong Zhao",
      "Andrew Chalmers",
      "Taehyun Rhee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.12088"
  },
  {
    "id": "arXiv:2203.12208",
    "title": "Self-supervised Learning of Adversarial Example: Towards Good  Generalizations for Deepfake Detection",
    "abstract": "Comments: To appear in CVPR 2022",
    "descriptor": "\nComments: To appear in CVPR 2022\n",
    "authors": [
      "Liang Chen",
      "Yong Zhang",
      "Yibing Song",
      "Lingqiao Liu",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12208"
  },
  {
    "id": "arXiv:2203.12245",
    "title": "Quantitative Evaluation Approach for Translation of Perceptual  Soundscape Attributes: Initial Application to the Thai Language",
    "abstract": "Comments: Submitted to Applied Acoustics (Special Issue on Soundscape Attributes Translation: Current Projects and Challenges)",
    "descriptor": "\nComments: Submitted to Applied Acoustics (Special Issue on Soundscape Attributes Translation: Current Projects and Challenges)\n",
    "authors": [
      "Karn N. Watcharasupat",
      "Sureenate Jaratjarungkiat",
      "Bhan Lam",
      "Sujinat Jitwiriyanont",
      "Kanyanut Akaratham",
      "Kenneth Ooi",
      "Zhen-Ting Ong",
      "Titima Suthiwan",
      "Nitipong Pichetpan",
      "Monthita Rojtinnakorn",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.12245"
  },
  {
    "id": "arXiv:2203.12529",
    "title": "A Deep Learning Approach to Probabilistic Forecasting of Weather",
    "abstract": "Comments: 12 pages, 5 figures. Submitted to Artificial Intelligence for Earth Systems",
    "descriptor": "\nComments: 12 pages, 5 figures. Submitted to Artificial Intelligence for Earth Systems\n",
    "authors": [
      "Nick Rittler",
      "Carlo Graziani",
      "Jiali Wang",
      "Rao Kotamarthi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.12529"
  },
  {
    "id": "arXiv:2203.12818",
    "title": "Random Forest Regression for continuous affect using Facial Action Units",
    "abstract": "Random Forest Regression for continuous affect using Facial Action Units",
    "descriptor": "",
    "authors": [
      "Saurabh Hinduja",
      "Shaun Canavan",
      "Liza Jivnani",
      "Sk Rahatul Jannat",
      "V Sri Chakra Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.12818"
  },
  {
    "id": "arXiv:2203.12870",
    "title": "RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust  Correspondence Field Estimation and Pose Optimization",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Yan Xu",
      "Kwan-Yee Lin",
      "Guofeng Zhang",
      "Xiaogang Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.12870"
  },
  {
    "id": "arXiv:2203.12898",
    "title": "Reputation structure in indirect reciprocity under noisy and private  assessment",
    "abstract": "Comments: 13 pages, 5 figure (mainmanuscript); 3 pages (supplement)",
    "descriptor": "\nComments: 13 pages, 5 figure (mainmanuscript); 3 pages (supplement)\n",
    "authors": [
      "Yuma Fujimoto",
      "Hisashi Ohtsuki"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.12898"
  },
  {
    "id": "arXiv:2203.12903",
    "title": "Identifying Boundary Conditions with the Syntax and Semantic Information  of Goals",
    "abstract": "Identifying Boundary Conditions with the Syntax and Semantic Information  of Goals",
    "descriptor": "",
    "authors": [
      "Yechuan Xia",
      "Jianwen Li",
      "Shengping Xiao",
      "Weikai Miao",
      "Geguang Pu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2203.12903"
  },
  {
    "id": "arXiv:2203.12932",
    "title": "Bioformers: Embedding Transformers for Ultra-Low Power sEMG-based  Gesture Recognition",
    "abstract": "Bioformers: Embedding Transformers for Ultra-Low Power sEMG-based  Gesture Recognition",
    "descriptor": "",
    "authors": [
      "Alessio Burrello",
      "Francesco Bianco Morghet",
      "Moritz Scherer",
      "Simone Benatti",
      "Luca Benini",
      "Enrico Macii",
      "Massimo Poncino",
      "Daniele Jahier Pagliari"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.12932"
  },
  {
    "id": "arXiv:2203.13032",
    "title": "Multi-modal Emotion Estimation for in-the-wild Videos",
    "abstract": "Multi-modal Emotion Estimation for in-the-wild Videos",
    "descriptor": "",
    "authors": [
      "Liyu Meng",
      "Yuchen Liu",
      "Xiaolong Liu",
      "Zhaopei Huang",
      "Wenqiang Jiang",
      "Tenggan Zhang",
      "Yuanyuan Deng",
      "Ruichen Li",
      "Yannan Wu",
      "Jinming Zhao",
      "Fengsheng Qiao",
      "Chuanhe Liu",
      "Qin Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.13032"
  },
  {
    "id": "arXiv:2203.13052",
    "title": "Coarse-to-Fine Cascaded Networks with Smooth Predicting for Video Facial  Expression Recognition",
    "abstract": "Coarse-to-Fine Cascaded Networks with Smooth Predicting for Video Facial  Expression Recognition",
    "descriptor": "",
    "authors": [
      "Fanglei Xue",
      "Zichang Tan",
      "Yu Zhu",
      "Zhongsong Ma",
      "Guodong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13052"
  },
  {
    "id": "arXiv:2203.13055",
    "title": "Bailando: 3D Dance Generation by Actor-Critic GPT with Choreographic  Memory",
    "abstract": "Comments: Accepted by CVPR 2022. Code and video link: this https URL",
    "descriptor": "\nComments: Accepted by CVPR 2022. Code and video link: this https URL\n",
    "authors": [
      "Li Siyao",
      "Weijiang Yu",
      "Tianpei Gu",
      "Chunze Lin",
      "Quan Wang",
      "Chen Qian",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13055"
  },
  {
    "id": "arXiv:2203.13078",
    "title": "Universal algorithms for solving inverse spectral problems",
    "abstract": "Comments: 26 pages",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Jonathan Ben-Artzi",
      "Marco Marletta",
      "Frank R\u00f6sler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.13078"
  },
  {
    "id": "arXiv:2203.13093",
    "title": "A Preliminary Research on Space Situational Awareness Based on Event  Cameras",
    "abstract": "A Preliminary Research on Space Situational Awareness Based on Event  Cameras",
    "descriptor": "",
    "authors": [
      "Kun Xiao",
      "Pengju Li",
      "Guohui Wang",
      "Zhi Li",
      "Yi Chen",
      "Yongfeng Xie",
      "Yuqiang Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13093"
  },
  {
    "id": "arXiv:2203.13097",
    "title": "IA-FaceS: A Bidirectional Method for Semantic Face Editing",
    "abstract": "Comments: 68 pages, 33 figures",
    "descriptor": "\nComments: 68 pages, 33 figures\n",
    "authors": [
      "Wenjing Huang",
      "Shikui Tu",
      "Lei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13097"
  },
  {
    "id": "arXiv:2203.13108",
    "title": "Explainable Artificial Intelligence for Exhaust Gas Temperature of  Turbofan Engines",
    "abstract": "Comments: Main paper: 20 pages, 4 figures. Supplemental material: 18 pages, 30 figures. Published; Removed footnote on page 11 of the main article regarding a typo on formula (8) on the Journal version of this work. The Journal has corrected this typo since, therefore, there is no need for the footnote",
    "descriptor": "\nComments: Main paper: 20 pages, 4 figures. Supplemental material: 18 pages, 30 figures. Published; Removed footnote on page 11 of the main article regarding a typo on formula (8) on the Journal version of this work. The Journal has corrected this typo since, therefore, there is no need for the footnote\n",
    "authors": [
      "Marios Kefalas",
      "Juan de Santiago Rojo Jr.",
      "Asteris Apostolidis",
      "Dirk van den Herik",
      "Bas van Stein",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2203.13108"
  },
  {
    "id": "arXiv:2203.13129",
    "title": "Bi-level Optimization for hyperparameters in Nonnegative Matrix  Factorizations",
    "abstract": "Comments: 26 pages, 11 Figures",
    "descriptor": "\nComments: 26 pages, 11 Figures\n",
    "authors": [
      "Nicoletta Del Buono",
      "Flavia Esposito",
      "Laura Selicato",
      "Rafal Zdunek"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.13129"
  },
  {
    "id": "arXiv:2203.13181",
    "title": "The Cost-Accuracy Trade-Off In Operator Learning With Neural Networks",
    "abstract": "Comments: 25 pages, 15 figures",
    "descriptor": "\nComments: 25 pages, 15 figures\n",
    "authors": [
      "Maarten V. de Hoop",
      "Daniel Zhengyu Huang",
      "Elizabeth Qian",
      "Andrew M. Stuart"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.13181"
  }
]
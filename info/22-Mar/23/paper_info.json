[
  {
    "id": "arXiv:2203.11196",
    "title": "Performance of Deep Learning models with transfer learning for  multiple-step-ahead forecasts in monthly time series",
    "abstract": "Deep Learning and transfer learning models are being used to generate time\nseries forecasts; however, there is scarce evidence about their performance\nprediction that it is more evident for monthly time series. The purpose of this\npaper is to compare Deep Learning models with transfer learning and without\ntransfer learning and other traditional methods used for monthly forecasts to\nanswer three questions about the suitability of Deep Learning and Transfer\nLearning to generate predictions of time series. Time series of M4 and M3\ncompetitions were used for the experiments. The results suggest that deep\nlearning models based on TCN, LSTM, and CNN with transfer learning tend to\nsurpass the performance prediction of other traditional methods. On the other\nhand, TCN and LSTM, trained directly on the target time series, got similar or\nbetter performance than traditional methods for some forecast horizons.",
    "descriptor": "\nComments: 20 pages, 7 figures, 5 tables\n",
    "authors": [
      "Mart\u00edn Sol\u00eds",
      "Luis-Alexander Calvo-Valverde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11196"
  },
  {
    "id": "arXiv:2203.11197",
    "title": "Teachable Reinforcement Learning via Advice Distillation",
    "abstract": "Training automated agents to complete complex tasks in interactive\nenvironments is challenging: reinforcement learning requires careful\nhand-engineering of reward functions, imitation learning requires specialized\ninfrastructure and access to a human expert, and learning from intermediate\nforms of supervision (like binary preferences) is time-consuming and extracts\nlittle information from each human intervention. Can we overcome these\nchallenges by building agents that learn from rich, interactive feedback\ninstead? We propose a new supervision paradigm for interactive learning based\non \"teachable\" decision-making systems that learn from structured advice\nprovided by an external teacher. We begin by formalizing a class of\nhuman-in-the-loop decision making problems in which multiple forms of\nteacher-provided advice are available to a learner. We then describe a simple\nlearning algorithm for these problems that first learns to interpret advice,\nthen learns from advice to complete tasks even in the absence of human\nsupervision. In puzzle-solving, navigation, and locomotion domains, we show\nthat agents that learn from advice can acquire new skills with significantly\nless human supervision than standard reinforcement learning algorithms and\noften less than imitation learning.",
    "descriptor": "\nComments: Published at NeurIPS 2021\n",
    "authors": [
      "Olivia Watkins",
      "Trevor Darrell",
      "Pieter Abbeel",
      "Jacob Andreas",
      "Abhishek Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11197"
  },
  {
    "id": "arXiv:2203.11199",
    "title": "Distinguishing Non-natural from Natural Adversarial Samples for More  Robust Pre-trained Language Model",
    "abstract": "Recently, the problem of robustness of pre-trained language models (PrLMs)\nhas received increasing research interest. Latest studies on adversarial\nattacks achieve high attack success rates against PrLMs, claiming that PrLMs\nare not robust. However, we find that the adversarial samples that PrLMs fail\nare mostly non-natural and do not appear in reality. We question the validity\nof current evaluation of robustness of PrLMs based on these non-natural\nadversarial samples and propose an anomaly detector to evaluate the robustness\nof PrLMs with more natural adversarial samples. We also investigate two\napplications of the anomaly detector: (1) In data augmentation, we employ the\nanomaly detector to force generating augmented data that are distinguished as\nnon-natural, which brings larger gains to the accuracy of PrLMs. (2) We apply\nthe anomaly detector to a defense framework to enhance the robustness of PrLMs.\nIt can be used to defend all types of attacks and achieves higher accuracy on\nboth adversarial samples and compliant samples than other defense frameworks.",
    "descriptor": "\nComments: Accepted by findings of ACL 2022\n",
    "authors": [
      "Jiayi Wang",
      "Rongzhou Bao",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.11199"
  },
  {
    "id": "arXiv:2203.11200",
    "title": "Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with  Heterophily",
    "abstract": "Due to the homophily assumption of graph convolution networks, a common\nconsensus is that graph neural networks (GNNs) perform well on homophilic\ngraphs but may fail on the heterophilic graphs with many inter-class edges. In\nthis work, we re-examine the heterophily problem of GNNs and investigate the\nfeature aggregation of inter-class neighbors. To better evaluate whether the\nneighbor is helpful for the downstream tasks, we present the concept of the\nneighbor effect of each node and use the von Neumann entropy to measure the\nrandomness/identifiability of the neighbor distribution for each class.\nMoreover, we propose a Conv-Agnostic GNNs framework (CAGNNs) to enhance the\nperformance of GNNs on heterophily datasets by learning the neighbor effect for\neach node. Specifically, we first decouple the feature of each node into the\ndiscriminative feature for downstream tasks and the aggregation feature for\ngraph convolution. Then, we propose a shared mixer module for all layers to\nadaptively evaluate the neighbor effect of each node to incorporate the\nneighbor information. Experiments are performed on nine well-known benchmark\ndatasets for the node classification task. The results indicate that our\nframework is able to improve the average prediction performance by 9.81\\%,\n25.81\\%, and 20.61\\% for GIN, GAT, and GCN, respectively. Extensive ablation\nstudies and robustness analysis further verify the effectiveness, robustness,\nand interpretability of our framework.",
    "descriptor": "",
    "authors": [
      "Jie Chen",
      "Shouzhen Chen",
      "Zengfeng Huang",
      "Junping Zhang",
      "Jian Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11200"
  },
  {
    "id": "arXiv:2203.11201",
    "title": "Efficient Neural Network Analysis with Sum-of-Infeasibilities",
    "abstract": "Inspired by sum-of-infeasibilities methods in convex optimization, we propose\na novel procedure for analyzing verification queries on neural networks with\npiecewise-linear activation functions. Given a convex relaxation which\nover-approximates the non-convex activation functions, we encode the violations\nof activation functions as a cost function and optimize it with respect to the\nconvex relaxation. The cost function, referred to as the Sum-of-Infeasibilities\n(SoI), is designed so that its minimum is zero and achieved only if all the\nactivation functions are satisfied. We propose a stochastic procedure, DeepSoI,\nto efficiently minimize the SoI. An extension to a canonical\ncase-analysis-based complete search procedure can be achieved by replacing the\nconvex procedure executed at each search state with DeepSoI. Extending the\ncomplete search with DeepSoI achieves multiple simultaneous goals: 1) it guides\nthe search towards a counter-example; 2) it enables more informed branching\ndecisions; and 3) it creates additional opportunities for bound derivation. An\nextensive evaluation across different benchmarks and solvers demonstrates the\nbenefit of the proposed techniques. In particular, we demonstrate that SoI\nsignificantly improves the performance of an existing complete search\nprocedure. Moreover, the SoI-based implementation outperforms other\nstate-of-the-art complete verifiers. We also show that our technique can\nefficiently improve upon the perturbation bound derived by a recent adversarial\nattack algorithm.",
    "descriptor": "\nComments: TACAS'22\n",
    "authors": [
      "Haoze Wu",
      "Aleksandar Zelji\u0107",
      "Guy Katz",
      "Clark Barrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.11201"
  },
  {
    "id": "arXiv:2203.11203",
    "title": "Reinforcement learning for automatic quadrilateral mesh generation: a  soft actor-critic approach",
    "abstract": "This paper proposes, implements, and evaluates a Reinforcement Learning (RL)\nbased computational framework for automatic mesh generation. Mesh generation,\nas one of six basic research directions identified in NASA Vision 2030, is an\nimportant area in computational geometry and plays a fundamental role in\nnumerical simulations in the area of finite element analysis (FEA) and\ncomputational fluid dynamics (CFD). Existing mesh generation methods suffer\nfrom high computational complexity, low mesh quality in complex geometries, and\nspeed limitations. By formulating the mesh generation as a Markov decision\nprocess (MDP) problem, we are able to use soft actor-critic, a state-of-the-art\nRL algorithm, to learn the meshing agent's policy from trials automatically,\nand achieve a fully automatic mesh generation system without human intervention\nand any extra clean-up operations, which are typically needed in current\ncommercial software. In our experiments and comparison with a number of\nrepresentative commercial software, our system demonstrates promising\nperformance with respect to generalizability, robustness, and effectiveness.",
    "descriptor": "",
    "authors": [
      "Jie Pan",
      "Jingwei Huang",
      "Gengdong Cheng",
      "Yong Zeng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.11203"
  },
  {
    "id": "arXiv:2203.11207",
    "title": "Hybrid training of optical neural networks",
    "abstract": "Optical neural networks are emerging as a promising type of machine learning\nhardware capable of energy-efficient, parallel computation. Today's optical\nneural networks are mainly developed to perform optical inference after in\nsilico training on digital simulators. However, various physical imperfections\nthat cannot be accurately modelled may lead to the notorious reality gap\nbetween the digital simulator and the physical system. To address this\nchallenge, we demonstrate hybrid training of optical neural networks where the\nweight matrix is trained with neuron activation functions computed optically\nvia forward propagation through the network. We examine the efficacy of hybrid\ntraining with three different networks: an optical linear classifier, a hybrid\nopto-electronic network, and a complex-valued optical network. We perform a\ncomparative study to in silico training, and our results show that hybrid\ntraining is robust against different kinds of static noise. Our\nplatform-agnostic hybrid training scheme can be applied to a wide variety of\noptical neural networks, and this work paves the way towards advanced\nall-optical training in machine intelligence.",
    "descriptor": "",
    "authors": [
      "James Spall",
      "Xianxin Guo",
      "A. I. Lvovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2203.11207"
  },
  {
    "id": "arXiv:2203.11208",
    "title": "An efficient heuristic approach combining maximal itemsets and area  measure for compressing voluminous table constraints",
    "abstract": "Constraint Programming is a powerful paradigm to model and solve\ncombinatorial problems. While there are many kinds of constraints, the table\nconstraint is perhaps the most significant-being the most well-studied and has\nthe ability to encode any other constraints defined on finite variables.\nHowever, constraints can be very voluminous and their size can grow\nexponentially with their arity. To reduce space and the time complexity,\nresearchers have focused on various forms of compression. In this paper we\npropose a new approach based on maximal frequent itemsets technique and area\nmeasure for enumerating the maximal frequent itemsets relevant for compressing\ntable constraints. Our experimental results show the effectiveness and\nefficiency of this approach on compression and on solving compressed table\nconstraints.",
    "descriptor": "",
    "authors": [
      "Soufia Bennai",
      "Kamala Amroun",
      "Samir Loudni",
      "Abdelkader Ouali"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11208"
  },
  {
    "id": "arXiv:2203.11209",
    "title": "On the Effect of Pre-Processing and Model Complexity for Plastic  Analysis Using Short-Wave-Infrared Hyper-Spectral Imaging",
    "abstract": "The importance of plastic waste recycling is undeniable. In this respect,\ncomputer vision and deep learning enable solutions through the automated\nanalysis of short-wave-infrared hyper-spectral images of plastics. In this\npaper, we offer an exhaustive empirical study to show the importance of\nefficient model selection for resolving the task of hyper-spectral image\nsegmentation of various plastic flakes using deep learning. We assess the\ncomplexity level of generic and specialized models and infer their performance\ncapacity: generic models are often unnecessarily complex. We introduce two\nvariants of a specialized hyper-spectral architecture, PlasticNet, that\noutperforms several well-known segmentation architectures in both performance\nas well as computational complexity. In addition, we shed lights on the\nsignificance of signal pre-processing within the realm of hyper-spectral\nimaging. To complete our contribution, we introduce the largest, most versatile\nhyper-spectral dataset of plastic flakes of four primary polymer types.",
    "descriptor": "",
    "authors": [
      "Klaas Dijkstra",
      "Maya Aghaei",
      "Femke Jaarsma",
      "Martin Dijkstra",
      "Rudy Folkersma",
      "Jan Jager",
      "Jaap van de Loosdrecht"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.11209"
  },
  {
    "id": "arXiv:2203.11210",
    "title": "Disentangling Patterns and Transformations from One Sequence of Images  with Shape-invariant Lie Group Transformer",
    "abstract": "An effective way to model the complex real world is to view the world as a\ncomposition of basic components of objects and transformations. Although humans\nthrough development understand the compositionality of the real world, it is\nextremely difficult to equip robots with such a learning mechanism. In recent\nyears, there has been significant research on autonomously learning\nrepresentations of the world using the deep learning; however, most studies\nhave taken a statistical approach, which requires a large number of training\ndata. Contrary to such existing methods, we take a novel algebraic approach for\nrepresentation learning based on a simpler and more intuitive formulation that\nthe observed world is the combination of multiple independent patterns and\ntransformations that are invariant to the shape of patterns. Since the shape of\npatterns can be viewed as the invariant features against symmetric\ntransformations such as translation or rotation, we can expect that the\npatterns can naturally be extracted by expressing transformations with\nsymmetric Lie group transformers and attempting to reconstruct the scene with\nthem. Based on this idea, we propose a model that disentangles the scenes into\nthe minimum number of basic components of patterns and Lie transformations from\nonly one sequence of images, by introducing the learnable shape-invariant Lie\ngroup transformers as transformation components. Experiments show that given\none sequence of images in which two objects are moving independently, the\nproposed model can discover the hidden distinct objects and multiple\nshape-invariant transformations that constitute the scenes.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "T. Takada",
      "W. Shimaya",
      "Y. Ohmura",
      "Y. Kuniyoshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11210"
  },
  {
    "id": "arXiv:2203.11211",
    "title": "ReCCoVER: Detecting Causal Confusion for Explainable Reinforcement  Learning",
    "abstract": "Despite notable results in various fields over the recent years, deep\nreinforcement learning (DRL) algorithms lack transparency, affecting user trust\nand hindering their deployment to high-risk tasks. Causal confusion refers to a\nphenomenon where an agent learns spurious correlations between features which\nmight not hold across the entire state space, preventing safe deployment to\nreal tasks where such correlations might be broken. In this work, we examine\nwhether an agent relies on spurious correlations in critical states, and\npropose an alternative subset of features on which it should base its decisions\ninstead, to make it less susceptible to causal confusion. Our goal is to\nincrease transparency of DRL agents by exposing the influence of learned\nspurious correlations on its decisions, and offering advice to developers about\nfeature selection in different parts of state space, to avoid causal confusion.\nWe propose ReCCoVER, an algorithm which detects causal confusion in agent's\nreasoning before deployment, by executing its policy in alternative\nenvironments where certain correlations between features do not hold. We\ndemonstrate our approach in taxi and grid world environments, where ReCCoVER\ndetects states in which an agent relies on spurious correlations and offers a\nset of features that should be considered instead.",
    "descriptor": "\nComments: 18 pages, 4 tables, 4 figures\n",
    "authors": [
      "Jasmina Gajcin",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11211"
  },
  {
    "id": "arXiv:2203.11216",
    "title": "The Conceptual VAE",
    "abstract": "In this report we present a new model of concepts, based on the framework of\nvariational autoencoders, which is designed to have attractive properties such\nas factored conceptual domains, and at the same time be learnable from data.\nThe model is inspired by, and closely related to, the Beta-VAE model of\nconcepts, but is designed to be more closely connected with language, so that\nthe names of concepts form part of the graphical model. We provide evidence\nthat our model -- which we call the Conceptual VAE -- is able to learn\ninterpretable conceptual representations from simple images of coloured shapes\ntogether with the corresponding concept labels. We also show how the model can\nbe used as a concept classifier, and how it can be adapted to learn from fewer\nlabels per instance. Finally, we formally relate our model to Gardenfors'\ntheory of conceptual spaces, showing how the Gaussians we use to represent\nconcepts can be formalised in terms of \"fuzzy concepts\" in such a space.",
    "descriptor": "",
    "authors": [
      "Razin A. Shaikh",
      "Sara Sabrina Zemljic",
      "Sean Tull",
      "Stephen Clark"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11216"
  },
  {
    "id": "arXiv:2203.11239",
    "title": "DQ-BART: Efficient Sequence-to-Sequence Model via Joint Distillation and  Quantization",
    "abstract": "Large-scale pre-trained sequence-to-sequence models like BART and T5 achieve\nstate-of-the-art performance on many generative NLP tasks. However, such models\npose a great challenge in resource-constrained scenarios owing to their large\nmemory requirements and high latency. To alleviate this issue, we propose to\njointly distill and quantize the model, where knowledge is transferred from the\nfull-precision teacher model to the quantized and distilled low-precision\nstudent model. Empirical analyses show that, despite the challenging nature of\ngenerative tasks, we were able to achieve a 16.5x model footprint compression\nratio with little performance drop relative to the full-precision counterparts\non multiple summarization and QA datasets. We further pushed the limit of\ncompression ratio to 27.7x and presented the performance-efficiency trade-off\nfor generative tasks using pre-trained models. To the best of our knowledge,\nthis is the first work aiming to effectively distill and quantize\nsequence-to-sequence pre-trained models for language generation tasks.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Zheng Li",
      "Zijian Wang",
      "Ming Tan",
      "Ramesh Nallapati",
      "Parminder Bhatia",
      "Andrew Arnold",
      "Bing Xiang",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11239"
  },
  {
    "id": "arXiv:2203.11242",
    "title": "A survey on GANs for computer vision: Recent research, analysis and  taxonomy",
    "abstract": "In the last few years, there have been several revolutions in the field of\ndeep learning, mainly headlined by the large impact of Generative Adversarial\nNetworks (GANs). GANs not only provide an unique architecture when defining\ntheir models, but also generate incredible results which have had a direct\nimpact on society. Due to the significant improvements and new areas of\nresearch that GANs have brought, the community is constantly coming up with new\nresearches that make it almost impossible to keep up with the times. Our survey\naims to provide a general overview of GANs, showing the latest architectures,\noptimizations of the loss functions, validation metrics and application areas\nof the most widely recognized variants. The efficiency of the different\nvariants of the model architecture will be evaluated, as well as showing the\nbest application area; as a vital part of the process, the different metrics\nfor evaluating the performance of GANs and the frequently used loss functions\nwill be analyzed. The final objective of this survey is to provide a summary of\nthe evolution and performance of the GANs which are having better results to\nguide future researchers in the field.",
    "descriptor": "\nComments: 76 pages, 10 figures\n",
    "authors": [
      "Guillermo Iglesias",
      "Edgar Talavera",
      "Alberto D\u00edaz-\u00c1lvarez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11242"
  },
  {
    "id": "arXiv:2203.11258",
    "title": "Efficient Classification of Long Documents Using Transformers",
    "abstract": "Several methods have been proposed for classifying long textual documents\nusing Transformers. However, there is a lack of consensus on a benchmark to\nenable a fair comparison among different approaches. In this paper, we provide\na comprehensive evaluation of the relative efficacy measured against various\nbaselines and diverse datasets -- both in terms of accuracy as well as time and\nspace overheads. Our datasets cover binary, multi-class, and multi-label\nclassification tasks and represent various ways information is organized in a\nlong text (e.g. information that is critical to making the classification\ndecision is at the beginning or towards the end of the document). Our results\nshow that more complex models often fail to outperform simple baselines and\nyield inconsistent performance across datasets. These findings emphasize the\nneed for future studies to consider comprehensive baselines and datasets that\nbetter represent the task of long document classification to develop robust\nmodels.",
    "descriptor": "\nComments: Accepted to ACL 2022; 8 pages\n",
    "authors": [
      "Hyunji Hayley Park",
      "Yogarshi Vyas",
      "Kashif Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11258"
  },
  {
    "id": "arXiv:2203.11261",
    "title": "Healthy Twitter discussions? Time will tell",
    "abstract": "Studying misinformation and how to deal with unhealthy behaviours within\nonline discussions has recently become an important field of research within\nsocial studies. With the rapid development of social media, and the increasing\namount of available information and sources, rigorous manual analysis of such\ndiscourses has become unfeasible. Many approaches tackle the issue by studying\nthe semantic and syntactic properties of discussions following a supervised\napproach, for example using natural language processing on a dataset labeled\nfor abusive, fake or bot-generated content. Solutions based on the existence of\na ground truth are limited to those domains which may have ground truth.\nHowever, within the context of misinformation, it may be difficult or even\nimpossible to assign labels to instances. In this context, we consider the use\nof temporal dynamic patterns as an indicator of discussion health. Working in a\ndomain for which ground truth was unavailable at the time (early COVID-19\npandemic discussions) we explore the characterization of discussions based on\nthe the volume and time of contributions. First we explore the types of\ndiscussions in an unsupervised manner, and then characterize these types using\nthe concept of ephemerality, which we formalize. In the end, we discuss the\npotential use of our ephemerality definition for labeling online discourses\nbased on how desirable, healthy and constructive they are.",
    "descriptor": "\nComments: 15 pages. Related to the SoBigData++ project: this https URL\n",
    "authors": [
      "Dmitry Gnatyshak",
      "Dario Garcia-Gasulla",
      "Sergio Alvarez-Napagao",
      "Jamie Arjona",
      "Tommaso Venturini"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11261"
  },
  {
    "id": "arXiv:2203.11263",
    "title": "Assessing trade-offs among electrification and grid decarbonization in a  clean energy transition: Application to New York State",
    "abstract": "A modeling framework is presented to investigate trade-offs among\ndecarbonization from increased low-carbon electricity generation and\nelectrification of heating and vehicles. The model is broadly applicable but\nrelies on high-fidelity parameterization of existing infrastructure and\nanticipated electrified loads; this study applies it to New York State where\ndetailed data is available. Trade-offs are investigated between end use\nelectrification and renewable energy deployment in terms of supply costs,\ngeneration and storage capacities, renewable resource mix, and system\noperation. Results indicate that equivalent emissions reductions can be\nachieved at lower costs to the grid by prioritizing electrification with 40-70%\nlow-carbon electricity supply instead of aiming for complete grid\ndecarbonization. With 60% electrification and 50% low-carbon electricity,\napproximately 1/3 emissions reductions can be achieved at current supply costs;\nwith only 20% electrification, 90% low-carbon electricity is required to\nachieve the same emissions reductions, resulting in 43% higher grid costs. In\naddition, three primary cost drivers are identified for a system undergoing\ndecarbonization: (1) decreasing per-unit costs of existing infrastructure with\nincreasing electrified demand, (2) higher in-state generation costs from\nlow-carbon sources relative to gas-based and hydropower generation, and (3)\nincreasing integration costs at high percentages of low-carbon electricity.",
    "descriptor": "",
    "authors": [
      "Terence Conlon",
      "Michael Waite",
      "Yuezi Wu",
      "Vijay Modi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11263"
  },
  {
    "id": "arXiv:2203.11265",
    "title": "Curry and Howard Meet Borel",
    "abstract": "We show that an intuitionistic version of counting propositional logic\ncorresponds, in the sense of Curry and Howard, to an expressive type system for\nthe probabilistic event lambda-calculus, a vehicle calculus in which both\ncall-by-name and call-by-value evaluation of discrete randomized functional\nprograms can be simulated. Remarkably, proofs (respectively, types) do not only\nguarantee that validity (respectively, termination) holds, but also reveal the\nunderlying probability. We finally show that by endowing the type system with\nan intersection operator, one obtains a system precisely capturing the\nprobabilistic behavior of lambda-terms.",
    "descriptor": "",
    "authors": [
      "Melissa Antonelli",
      "Ugo Dal Lago",
      "Paolo Pistone"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.11265"
  },
  {
    "id": "arXiv:2203.11274",
    "title": "DefGraspSim: Physics-based simulation of grasp outcomes for 3D  deformable objects",
    "abstract": "Robotic grasping of 3D deformable objects (e.g., fruits/vegetables, internal\norgans, bottles/boxes) is critical for real-world applications such as food\nprocessing, robotic surgery, and household automation. However, developing\ngrasp strategies for such objects is uniquely challenging. Unlike rigid\nobjects, deformable objects have infinite degrees of freedom and require field\nquantities (e.g., deformation, stress) to fully define their state. As these\nquantities are not easily accessible in the real world, we propose studying\ninteraction with deformable objects through physics-based simulation. As such,\nwe simulate grasps on a wide range of 3D deformable objects using a GPU-based\nimplementation of the corotational finite element method (FEM). To facilitate\nfuture research, we open-source our simulated dataset (34 objects, 1e5 Pa\nelasticity range, 6800 grasp evaluations, 1.1M grasp measurements), as well as\na code repository that allows researchers to run our full FEM-based grasp\nevaluation pipeline on arbitrary 3D object models of their choice. Finally, we\ndemonstrate good correspondence between grasp outcomes on simulated objects and\ntheir real counterparts.",
    "descriptor": "\nComments: For associated web page, see \\url{this https URL}. To be published in the IEEE Robotics and Automation Letters (RA-L) special issue on Robotic Handling of Deformable Objects, 2022. arXiv admin note: substantial text overlap with arXiv:2107.05778\n",
    "authors": [
      "Isabella Huang",
      "Yashraj Narang",
      "Clemens Eppner",
      "Balakumar Sundaralingam",
      "Miles Macklin",
      "Ruzena Bajcsy",
      "Tucker Hermans",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.11274"
  },
  {
    "id": "arXiv:2203.11275",
    "title": "Liars are more influential: Effect of Deception in Influence  Maximization on Social Networks",
    "abstract": "Detecting influential users, called the influence maximization problem on\nsocial networks, is an important graph mining problem with many diverse\napplications such as information propagation, market advertising, and rumor\ncontrolling. There are many studies in the literature for influential users\ndetection problem in social networks. Although the current methods are\nsuccessfully used in many different applications, they assume that users are\nhonest with each other and ignore the role of deception on social networks. On\nthe other hand, deception appears to be surprisingly common among humans within\nsocial networks. In this paper, we study the effect of deception in influence\nmaximization on social networks. We first model deception in social networks.\nThen, we model the opinion dynamics on these networks taking the deception into\nconsideration thanks to a recent opinion dynamics model via sheaf Laplacian. We\nthen extend two influential node detection methods, namely Laplacian centrality\nand DFF centrality, for the sheaf Laplacian to measure the effect of deception\nin influence maximization. Our experimental results on synthetic and real-world\nnetworks suggest that liars are more influential than honest users in social\nnetworks.",
    "descriptor": "",
    "authors": [
      "Mehmet Emin Aktas",
      "Esra Akbas",
      "Ashley Hahn"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2203.11275"
  },
  {
    "id": "arXiv:2203.11283",
    "title": "NeRFusion: Fusing Radiance Fields for Large-Scale Scene Reconstruction",
    "abstract": "While NeRF has shown great success for neural reconstruction and rendering,\nits limited MLP capacity and long per-scene optimization times make it\nchallenging to model large-scale indoor scenes. In contrast, classical 3D\nreconstruction methods can handle large-scale scenes but do not produce\nrealistic renderings. We propose NeRFusion, a method that combines the\nadvantages of NeRF and TSDF-based fusion techniques to achieve efficient\nlarge-scale reconstruction and photo-realistic rendering. We process the input\nimage sequence to predict per-frame local radiance fields via direct network\ninference. These are then fused using a novel recurrent neural network that\nincrementally reconstructs a global, sparse scene representation in real-time\nat 22 fps. This global volume can be further fine-tuned to boost rendering\nquality. We demonstrate that NeRFusion achieves state-of-the-art quality on\nboth large-scale indoor and small-scale object scenes, with substantially\nfaster reconstruction than NeRF and other recent methods.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Xiaoshuai Zhang",
      "Sai Bi",
      "Kalyan Sunkavalli",
      "Hao Su",
      "Zexiang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.11283"
  },
  {
    "id": "arXiv:2203.11284",
    "title": "A Contrastive Objective for Learning Disentangled Representations",
    "abstract": "Learning representations of images that are invariant to sensitive or\nunwanted attributes is important for many tasks including bias removal and\ncross domain retrieval. Here, our objective is to learn representations that\nare invariant to the domain (sensitive attribute) for which labels are\nprovided, while being informative over all other image attributes, which are\nunlabeled. We present a new approach, proposing a new domain-wise contrastive\nobjective for ensuring invariant representations. This objective crucially\nrestricts negative image pairs to be drawn from the same domain, which enforces\ndomain invariance whereas the standard contrastive objective does not. This\ndomain-wise objective is insufficient on its own as it suffers from shortcut\nsolutions resulting in feature suppression. We overcome this issue by a\ncombination of a reconstruction constraint, image augmentations and\ninitialization with pre-trained weights. Our analysis shows that the choice of\naugmentations is important, and that a misguided choice of augmentations can\nharm the invariance and informativeness objectives. In an extensive evaluation,\nour method convincingly outperforms the state-of-the-art in terms of\nrepresentation invariance, representation informativeness, and training speed.\nFurthermore, we find that in some cases our method can achieve excellent\nresults even without the reconstruction constraint, leading to a much faster\nand resource efficient training.",
    "descriptor": "",
    "authors": [
      "Jonathan Kahana",
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11284"
  },
  {
    "id": "arXiv:2203.11287",
    "title": "PCA-RF: An Efficient Parkinson's Disease Prediction Model based on  Random Forest Classification",
    "abstract": "In this modern era of overpopulation disease prediction is a crucial step in\ndiagnosing various diseases at an early stage. With the advancement of various\nmachine learning algorithms, the prediction has become quite easy. However, the\ncomplex and the selection of an optimal machine learning technique for the\ngiven dataset greatly affects the accuracy of the model. A large amount of\ndatasets exists globally but there is no effective use of it due to its\nunstructured format. Hence, a lot of different techniques are available to\nextract something useful for the real world to implement. Therefore, accuracy\nbecomes a major metric in evaluating the model. In this paper, a disease\nprediction approach is proposed that implements a random forest classifier on\nParkinson's disease. We compared the accuracy of this model with the Principal\nComponent Analysis (PCA) applied Artificial Neural Network (ANN) model and\ncaptured a visible difference. The model secured a significant accuracy of up\nto 90%.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Ishu Gupta",
      "Vartika Sharma",
      "Sizman Kaur",
      "Ashutosh Kumar Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.11287"
  },
  {
    "id": "arXiv:2203.11294",
    "title": "Automated detection of foreground speech with wearable sensing in  everyday home environments: A transfer learning approach",
    "abstract": "Acoustic sensing has proved effective as a foundation for numerous\napplications in health and human behavior analysis. In this work, we focus on\nthe problem of detecting in-person social interactions in naturalistic settings\nfrom audio captured by a smartwatch. As a first step towards detecting social\ninteractions, it is critical to distinguish the speech of the individual\nwearing the watch from all other sounds nearby, such as speech from other\nindividuals and ambient sounds. This is very challenging in realistic settings,\nwhere interactions take place spontaneously and supervised models cannot be\ntrained apriori to recognize the full complexity of dynamic social\nenvironments. In this paper, we introduce a transfer learning-based approach to\ndetect foreground speech of users wearing a smartwatch. A highlight of the\nmethod is that it does not depend on the collection of voice samples to build\nuser-specific models. Instead, the approach is based on knowledge transfer from\ngeneral-purpose speaker representations derived from public datasets. Our\nexperiments demonstrate that our approach performs comparably to a fully\nsupervised model, with 80% F1 score. To evaluate the method, we collected a\ndataset of 31 hours of smartwatch-recorded audio in 18 homes with a total of 39\nparticipants performing various semi-controlled tasks.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Dawei Liang",
      "Zifan Xu",
      "Yinuo Chen",
      "Rebecca Adaimi",
      "David Harwath",
      "Edison Thomaz"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.11294"
  },
  {
    "id": "arXiv:2203.11295",
    "title": "Benchmarking Test-Time Unsupervised Deep Neural Network Adaptation on  Edge Devices",
    "abstract": "The prediction accuracy of the deep neural networks (DNNs) after deployment\nat the edge can suffer with time due to shifts in the distribution of the new\ndata. To improve robustness of DNNs, they must be able to update themselves to\nenhance their prediction accuracy. This adaptation at the resource-constrained\nedge is challenging as: (i) new labeled data may not be present; (ii)\nadaptation needs to be on device as connections to cloud may not be available;\nand (iii) the process must not only be fast but also memory- and\nenergy-efficient. Recently, lightweight prediction-time unsupervised DNN\nadaptation techniques have been introduced that improve prediction accuracy of\nthe models for noisy data by re-tuning the batch normalization (BN) parameters.\nThis paper, for the first time, performs a comprehensive measurement study of\nsuch techniques to quantify their performance and energy on various edge\ndevices as well as find bottlenecks and propose optimization opportunities. In\nparticular, this study considers CIFAR-10-C image classification dataset with\ncorruptions, three robust DNNs (ResNeXt, Wide-ResNet, ResNet-18), two BN\nadaptation algorithms (one that updates normalization statistics and the other\nthat also optimizes transformation parameters), and three edge devices (FPGA,\nRaspberry-Pi, and Nvidia Xavier NX). We find that the approach that only\nupdates the normalization parameters with Wide-ResNet, running on Xavier GPU,\nto be overall effective in terms of balancing multiple cost metrics. However,\nthe adaptation overhead can still be significant (around 213 ms). The results\nstrongly motivate the need for algorithm-hardware co-design for efficient\non-device DNN adaptation.",
    "descriptor": "\nComments: This paper was selected for poster presentation in International Symposium on Performance Analysis of Systems and Software (ISPASS), 2022\n",
    "authors": [
      "Kshitij Bhardwaj",
      "James Diffenderfer",
      "Bhavya Kailkhura",
      "Maya Gokhale"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.11295"
  },
  {
    "id": "arXiv:2203.11305",
    "title": "Generative Adversarial Network for Future Hand Segmentation from  Egocentric Video",
    "abstract": "We introduce the novel problem of anticipating a time series of future hand\nmasks from egocentric video. A key challenge is to model the stochasticity of\nfuture head motions, which globally impact the head-worn camera video analysis.\nTo this end, we propose a novel deep generative model -- EgoGAN, which uses a\n3D Fully Convolutional Network to learn a spatio-temporal video representation\nfor pixel-wise visual anticipation, generates future head motion using\nGenerative Adversarial Network (GAN), and then predicts the future hand masks\nbased on the video representation and the generated future head motion. We\nevaluate our method on both the EPIC-Kitchens and the EGTEA Gaze+ datasets. We\nconduct detailed ablation studies to validate the design choices of our\napproach. Furthermore, we compare our method with previous state-of-the-art\nmethods on future image segmentation and show that our method can more\naccurately predict future hand masks.",
    "descriptor": "",
    "authors": [
      "Wenqi Jia",
      "Miao Liu",
      "James M. Rehg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11305"
  },
  {
    "id": "arXiv:2203.11309",
    "title": "Fog Based Computation Offloading for Swarm of Drones",
    "abstract": "Due to the limited computing resources of swarm of drones, it is difficult to\nhandle computation-intensive tasks locally, hence the cloud based computation\noffloading is widely adopted. However, for the business which requires low\nlatency and high reliability, the cloud-based solution is not suitable, because\nof the slow response time caused by long distance data transmission. Therefore,\nto solve the problem mentioned above, in this paper, we introduce fog computing\ninto swarm of drones (FCSD). Focusing on the latency and reliability sensitive\nbusiness scenarios, the latency and reliability is constructed as the\nconstraints of the optimization problem. And in order to enhance the\npracticality of the FCSD system, we formulate the energy consumption of FCSD as\nthe optimization target function, to decrease the energy consumption as far as\npossible, under the premise of satisfying the latency and reliability\nrequirements of the task. Furthermore, a heuristic algorithm based on genetic\nalgorithm is designed to perform optimal task allocation in FCSD system. The\nsimulation results validate that the proposed fog based computation offloading\nwith the heuristic algorithm can complete the computing task effectively with\nthe minimal energy consumption under the requirements of latency and\nreliability.",
    "descriptor": "",
    "authors": [
      "Xiangwang Hou",
      "Zhiyuan Ren",
      "Wenchi Cheng",
      "Chen Chen",
      "Hailin Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.11309"
  },
  {
    "id": "arXiv:2203.11312",
    "title": "Toward RIS-Enhanced Integrated Terrestrial/Non-Terrestrial Connectivity  in 6G-Enabled IoE Era",
    "abstract": "The next generation of wireless systems will take the concept of\ncommunications and networking to another level and turn the vision of Internet\nof Everything (IoE) into reality. Everywhere connectivity through the\nintegration of terrestrial, aerial, satellite, maritime, and underwater\ncommunications is expected in 6G-enabled IoE systems, where various services\nwith satisfying performance are proffered in an uninterrupted universal manner.\nThe successful realization of this ambitious goal relies on the development of\npioneering solutions which can revolutionize the future of wireless\ntechnologies, while being secure, scalable, and reliable. Reconfigurable\nintelligent surface (RIS) is a novel paradigm which has recently been on the\nresearch spotlight and shown promising signs to expedite the evolution of\n6G-enabled integrated terrestrial/non-terrestrial (INTENT) IoE networks.\nMotivated by the unparalleled properties of this innovatory technology, we\nherein set forth the architecture of RIS-enhanced 6G-enabled INTENT IoE\nnetworks and clarify the decisive role of RIS in such an integrated\nenvironment. We also present the key challenges which need to be addressed for\nthe successful realization of RIS-enhanced 6G systems in all dimensions.",
    "descriptor": "",
    "authors": [
      "Parisa Ramezani",
      "Bin Lyu",
      "Abbas Jamalipour"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.11312"
  },
  {
    "id": "arXiv:2203.11313",
    "title": "Energy Harvesting Aware Multi-hop Routing Policy in Distributed IoT  System Based on Multi-agent Reinforcement Learning",
    "abstract": "Energy harvesting technologies offer a promising solution to sustainably\npower an ever-growing number of Internet of Things (IoT) devices. However, due\nto the weak and transient natures of energy harvesting, IoT devices have to\nwork intermittently rendering conventional routing policies and energy\nallocation strategies impractical. To this end, this paper, for the very first\ntime, developed a distributed multi-agent reinforcement algorithm known as\nglobal actor-critic policy (GAP) to address the problem of routing policy and\nenergy allocation together for the energy harvesting powered IoT system. At the\ntraining stage, each IoT device is treated as an agent and one universal model\nis trained for all agents to save computing resources. At the inference stage,\npacket delivery rate can be maximized. The experimental results show that the\nproposed GAP algorithm achieves around 1.28 times and 1.24 times data\ntransmission rate than that of the Q-table and ESDSRAA algorithm, respectively.",
    "descriptor": "",
    "authors": [
      "Wen Zhang",
      "Tao Liu",
      "Mimi Xie",
      "Longzhuang Li",
      "Dulal Kar",
      "Chen Pan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.11313"
  },
  {
    "id": "arXiv:2203.11315",
    "title": "Landscape Analysis for Surrogate Models in the Evolutionary Black-Box  Context",
    "abstract": "Surrogate modeling has become a valuable technique for black-box optimization\ntasks with expensive evaluation of the objective function. In this paper, we\ninvestigate the relationship between the predictive accuracy of surrogate\nmodels and features of the black-box function landscape. We also study\nproperties of features for landscape analysis in the context of different\ntransformations and ways of selecting the input data. We perform the landscape\nanalysis of a large set of data generated using runs of a surrogate-assisted\nversion of the Covariance Matrix Adaptation Evolution Strategy on the noiseless\npart of the Comparing Continuous Optimisers benchmark function testbed.",
    "descriptor": "\nComments: 35 pages, 3 figures, currently under review at Springer Machine Learning journal\n",
    "authors": [
      "Zbyn\u011bk Pitra",
      "Jan Koza",
      "Ji\u0159\u00ed Tumpach",
      "Martin Hole\u0148a"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.11315"
  },
  {
    "id": "arXiv:2203.11316",
    "title": "Random vector functional link network: recent developments,  applications, and future directions",
    "abstract": "Neural networks have been successfully employed in various domain such as\nclassification, regression and clustering, etc. Generally, the back propagation\n(BP) based iterative approaches are used to train the neural networks, however,\nit results in the issues of local minima, sensitivity to learning rate and slow\nconvergence. To overcome these issues, randomization based neural networks such\nas random vector functional link (RVFL) network have been proposed. RVFL model\nhas several characteristics such as fast training speed, simple architecture,\nand universal approximation capability, that make it a viable randomized neural\nnetwork. This article presents the comprehensive review of the development of\nRVFL model, which can serve as the extensive summary for the beginners as well\nas practitioners. We discuss the shallow RVFL, ensemble RVFL, deep RVFL and\nensemble deep RVFL models. The variations, improvements and applications of\nRVFL models are discussed in detail. Moreover, we discuss the different\nhyperparameter optimization techniques followed in the literature to improve\nthe generalization performance of the RVFL model. Finally, we give potential\nfuture research directions/opportunities that can inspire the researchers to\nimprove the RVFL architecture further.",
    "descriptor": "",
    "authors": [
      "A. K. Malik",
      "Ruobin Gao",
      "M.A. Ganaie",
      "M. Tanveer",
      "P.N. Suganthan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.11316"
  },
  {
    "id": "arXiv:2203.11317",
    "title": "The Change that Matters in Discourse Parsing: Estimating the Impact of  Domain Shift on Parser Error",
    "abstract": "Discourse analysis allows us to attain inferences of a text document that\nextend beyond the sentence-level. The current performance of discourse models\nis very low on texts outside of the training distribution's coverage,\ndiminishing the practical utility of existing models. There is need for a\nmeasure that can inform us to what extent our model generalizes from the\ntraining to the test sample when these samples may be drawn from distinct\ndistributions. While this can be estimated via distribution shift, we argue\nthat this does not directly correlate with change in the observed error of a\nclassifier (i.e. error-gap). Thus, we propose to use a statistic from the\ntheoretical domain adaptation literature which can be directly tied to\nerror-gap. We study the bias of this statistic as an estimator of error-gap\nboth theoretically and through a large-scale empirical study of over 2400\nexperiments on 6 discourse datasets from domains including, but not limited to:\nnews, biomedical texts, TED talks, Reddit posts, and fiction. Our results not\nonly motivate our proposal and help us to understand its limitations, but also\nprovide insight on the properties of discourse models and datasets which\nimprove performance in domain adaptation. For instance, we find that non-news\ndatasets are slightly easier to transfer to than news datasets when the\ntraining and test sets are very different. Our code and an associated Python\npackage are available to allow practitioners to make more informed model and\ndataset choices.",
    "descriptor": "",
    "authors": [
      "Katherine Atwell",
      "Anthony Sicilia",
      "Seong Jae Hwang",
      "Malihe Alikhani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11317"
  },
  {
    "id": "arXiv:2203.11321",
    "title": "Alarm-Based Root Cause Analysis in Industrial Processes Using Deep  Learning",
    "abstract": "Alarm management systems have become indispensable in modern industry. Alarms\ninform the operator of abnormal situations, particularly in the case of\nequipment failures. Due to the interconnections between various parts of the\nsystem, each fault can affect other sections of the system operating normally.\nAs a result, the fault propagates through faultless devices, increasing the\nnumber of alarms. Hence, the timely detection of the major fault that triggered\nthe alarm by the operator can prevent the following consequences. However, due\nto the complexity of the system, it is often impossible to find precise\nrelations between the underlying fault and the alarms. As a result, the\noperator needs support to make an appropriate decision immediately. Modeling\nalarms based on the historical alarm data can assist the operator in\ndetermining the root cause of the alarm. This research aims to model the\nrelations between industrial alarms using historical alarm data in the\ndatabase. Firstly, alarm data is collected, and alarm tags are sequenced. Then,\nthese sequences are converted to numerical vectors using word embedding. Next,\na self-attention-based BiLSTM-CNN classifier is used to learn the structure and\nrelevance between historical alarm data. After training the model, this model\nis used for online fault detection. Finally, as a case study, the proposed\nmodel is implemented in the well-known Tennessee Eastman process, and the\nresults are presented.",
    "descriptor": "",
    "authors": [
      "Negin Javanbakht",
      "Amir Neshastegaran",
      "Iman Izadi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11321"
  },
  {
    "id": "arXiv:2203.11323",
    "title": "Training Quantised Neural Networks with STE Variants: the Additive Noise  Annealing Algorithm",
    "abstract": "Training quantised neural networks (QNNs) is a non-differentiable\noptimisation problem since weights and features are output by piecewise\nconstant functions. The standard solution is to apply the straight-through\nestimator (STE), using different functions during the inference and gradient\ncomputation steps. Several STE variants have been proposed in the literature\naiming to maximise the task accuracy of the trained network. In this paper, we\nanalyse STE variants and study their impact on QNN training. We first observe\nthat most such variants can be modelled as stochastic regularisations of stair\nfunctions; although this intuitive interpretation is not new, our rigorous\ndiscussion generalises to further variants. Then, we analyse QNNs mixing\ndifferent regularisations, finding that some suitably synchronised smoothing of\neach layer map is required to guarantee pointwise compositional convergence to\nthe target discontinuous function. Based on these theoretical insights, we\npropose additive noise annealing (ANA), a new algorithm to train QNNs\nencompassing standard STE and its variants as special cases. When testing ANA\non the CIFAR-10 image classification benchmark, we find that the major impact\non task accuracy is not due to the qualitative shape of the regularisations but\nto the proper synchronisation of the different STE variants used in a network,\nin accordance with the theoretical results.",
    "descriptor": "",
    "authors": [
      "Matteo Spallanzani",
      "Gian Paolo Leonardi",
      "Luca Benini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11323"
  },
  {
    "id": "arXiv:2203.11324",
    "title": "Learning robot motor skills with mixed reality",
    "abstract": "Mixed Reality (MR) has recently shown great success as an intuitive interface\nfor enabling end-users to teach robots. Related works have used MR interfaces\nto communicate robot intents and beliefs to a co-located human, as well as\ndeveloped algorithms for taking multi-modal human input and learning complex\nmotor behaviors. Even with these successes, enabling end-users to teach robots\ncomplex motor tasks still poses a challenge because end-user communication is\nhighly task dependent and world knowledge is highly varied. We propose a\nlearning framework where end-users teach robots a) motion demonstrations, b)\ntask constraints, c) planning representations, and d) object information, all\nof which are integrated into a single motor skill learning framework based on\nDynamic Movement Primitives (DMPs). We hypothesize that conveying this world\nknowledge will be intuitive with an MR interface, and that a sample-efficient\nmotor skill learning framework which incorporates varied modalities of world\nknowledge will enable robots to effectively solve complex tasks.",
    "descriptor": "\nComments: VAM-HRI 2022\n",
    "authors": [
      "Eric Rosen",
      "Sreehari Rammohan",
      "Devesh Jha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11324"
  },
  {
    "id": "arXiv:2203.11325",
    "title": "Enhancing Speech Recognition Decoding via Layer Aggregation",
    "abstract": "Recently proposed speech recognition systems are designed to predict using\nrepresentations generated by their top layers, employing greedy decoding which\nisolates each timestep from the rest of the sequence. Aiming for improved\nperformance, a beam search algorithm is frequently utilized and a language\nmodel is incorporated to assist with ranking the top candidates. In this work,\nwe experiment with several speech recognition models and find that logits\npredicted using the top layers may hamper beam search from achieving optimal\nresults. Specifically, we show that fined-tuned Wav2Vec 2.0 and HuBERT yield\nhighly confident predictions, and hypothesize that the predictions are based on\nlocal information and may not take full advantage of the information encoded in\nintermediate layers. To this end, we perform a layer analysis to reveal and\nvisualize how predictions evolve throughout the inference flow. We then propose\na prediction method that aggregates the top M layers, potentially leveraging\nuseful information encoded in intermediate layers and relaxing model\nconfidence. We showcase the effectiveness of our approach via beam search\ndecoding, conducting our experiments on Librispeech test and dev sets and\nachieving WER, and CER reduction of up to 10% and 22%, respectively.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Tomer Wullach",
      "Shlomo E. Chazan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11325"
  },
  {
    "id": "arXiv:2203.11331",
    "title": "On The Robustness of Offensive Language Classifiers",
    "abstract": "Social media platforms are deploying machine learning based offensive\nlanguage classification systems to combat hateful, racist, and other forms of\noffensive speech at scale. However, despite their real-world deployment, we do\nnot yet comprehensively understand the extent to which offensive language\nclassifiers are robust against adversarial attacks. Prior work in this space is\nlimited to studying robustness of offensive language classifiers against\nprimitive attacks such as misspellings and extraneous spaces. To address this\ngap, we systematically analyze the robustness of state-of-the-art offensive\nlanguage classifiers against more crafty adversarial attacks that leverage\ngreedy- and attention-based word selection and context-aware embeddings for\nword replacement. Our results on multiple datasets show that these crafty\nadversarial attacks can degrade the accuracy of offensive language classifiers\nby more than 50% while also being able to preserve the readability and meaning\nof the modified text.",
    "descriptor": "\nComments: 9 pages, 2 figures, Accepted at ACL 2022\n",
    "authors": [
      "Jonathan Rusert",
      "Zubair Shafiq",
      "Padmini Srinivasan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11331"
  },
  {
    "id": "arXiv:2203.11335",
    "title": "Global Matching with Overlapping Attention for Optical Flow Estimation",
    "abstract": "Optical flow estimation is a fundamental task in computer vision. Recent\ndirect-regression methods using deep neural networks achieve remarkable\nperformance improvement. However, they do not explicitly capture long-term\nmotion correspondences and thus cannot handle large motions effectively. In\nthis paper, inspired by the traditional matching-optimization methods where\nmatching is introduced to handle large displacements before energy-based\noptimizations, we introduce a simple but effective global matching step before\nthe direct regression and develop a learning-based matching-optimization\nframework, namely GMFlowNet. In GMFlowNet, global matching is efficiently\ncalculated by applying argmax on 4D cost volumes. Additionally, to improve the\nmatching quality, we propose patch-based overlapping attention to extract large\ncontext features. Extensive experiments demonstrate that GMFlowNet outperforms\nRAFT, the most popular optimization-only method, by a large margin and achieves\nstate-of-the-art performance on standard benchmarks. Thanks to the matching and\noverlapping attention, GMFlowNet obtains major improvements on the predictions\nfor textureless regions and large motions. Our code is made publicly available\nat https://github.com/xiaofeng94/GMFlowNet",
    "descriptor": "\nComments: Accepted to CVPR 2022 (with additional figures)\n",
    "authors": [
      "Shiyu Zhao",
      "Long Zhao",
      "Zhixing Zhang",
      "Enyu Zhou",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11335"
  },
  {
    "id": "arXiv:2203.11338",
    "title": "Fast Toeplitz eigenvalue computations, joining  interpolation-extrapolation matrix-less algorithms and simple-loop  conjectures: the preconditioned setting",
    "abstract": "Under appropriate technical assumptions, the simple-loop theory allows to\ndeduce various types of asymptotic expansions for the eigenvalues of Toeplitz\nmatrices $T_{n}(f)$ generated by a function $f$, unfortunately, such a theory\nis not available in the preconditioning setting, that is for matrices of the\nform $T_{n}^{-1}(g)T_{n}(l)$ with $l,g$ real-valued, $g$ nonnnegative and not\nidentically zero almost everywhere. Independently and under the milder\nhypothesis that $f=\\frac{l}{g}$ is even and monotonic over $[0,\\pi]$,\nmatrix-less algorithms have been developed for the fast eigenvalue computation\nof large preconditioned matrices of the type above, within a linear complexity\nin the matrix order: behind the high efficiency of such algorithms there are\nthe expansions as in the case $g\\equiv 1$, combined with the extrapolation\nidea, and hence we conjecture that the simple-loop theory has to be extended in\nsuch a new setting, as the numerics strongly suggest.Here we focus our\nattention on a change of variable, followed by the asymptotic expansion of the\nnew variable, and we consider new matrix-less algorithms ad hoc for the current\ncase. Numerical experiments show a much higher precision till machine precision\nand the same linear computation cost, when compared with the matrix-less\nprocedures already proposed in the literature.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2201.02024\n",
    "authors": [
      "Manuel Bogoya",
      "Stefano Serra-Cappizano",
      "Paris Vassalos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11338"
  },
  {
    "id": "arXiv:2203.11341",
    "title": "Binary codes that do not preserve primitivity",
    "abstract": "A code $X$ is not primitivity preserving if there is a primitive list\n${\\mathbf w} \\in {\\tt lists} X$ whose concatenation is imprimitive. We\nformalize a full characterization of such codes in the binary case in the proof\nassistant Isabelle/HOL. Part of the formalization, interesting on its own, is a\ndescription of $\\{x,y\\}$-interpretations of the square $xx$ if $|y| \\leq |x|$.\nWe also provide a formalized parametric solution of the related equation\n$x^jy^k = z^\\ell$.",
    "descriptor": "",
    "authors": [
      "\u0160t\u011bp\u00e1n Holub",
      "Martin Ra\u0161ka",
      "\u0160t\u011bp\u00e1n Starosta"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2203.11341"
  },
  {
    "id": "arXiv:2203.11343",
    "title": "Using Evolutionary Coupling to Establish Relevance Links Between Tests  and Code Units. A case study on fault localization",
    "abstract": "Many software engineering techniques, such as fault localization, operate\nbased on relevance relationships between tests and code. These relationships\nare often inferred through the use of dynamic test execution information (test\nexecution traces) that approximate the link between relevant code units and\nasserted, by the tests, program behaviour. Unfortunately, in practice dynamic\ninformation is not always available due to the overheads introduced by the\ninstrumentation or the nature of the production environments. To deal with this\nissue, we propose CEMENT, a static technique that automatically infers such\ntest and code relationships given the projects' evolution. The key idea is that\ndevelopers make relevant changes on test and code units at the same period of\ntime, i.e., co-evolution of tests and code units reflects a probable link\nbetween them. We evaluate CEMENT on 15 open source projects and show that it\nindeed captures relevant links. Additionally, we perform a fault localization\ncase study where we compare CEMENT with an existing Information Retrieval-based\nFault Localization (IRFL) technique and show that it achieves comparable\nperformance. A further analysis of our results reveals a small overlap between\nthe faults successfully localized by the two approaches suggesting\ncomplementarity. In particular, out of the 39 successfully localized faults,\ntwo are common while CEMENT and IRFL localize 16 and 21. These results\ndemonstrate that test and code evolutionary coupling can effectively support\ntest and debugging activities.",
    "descriptor": "",
    "authors": [
      "Jeongju Sohn",
      "Mike Papadakis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.11343"
  },
  {
    "id": "arXiv:2203.11355",
    "title": "Origami in N dimensions: How feed-forward networks manufacture linear  separability",
    "abstract": "Neural networks can implement arbitrary functions. But, mechanistically, what\nare the tools at their disposal to construct the target? For classification\ntasks, the network must transform the data classes into a linearly separable\nrepresentation in the final hidden layer. We show that a feed-forward\narchitecture has one primary tool at hand to achieve this separability:\nprogressive folding of the data manifold in unoccupied higher dimensions. The\noperation of folding provides a useful intuition in low-dimensions that\ngeneralizes to high ones. We argue that an alternative method based on shear,\nrequiring very deep architectures, plays only a small role in real-world\nnetworks. The folding operation, however, is powerful as long as layers are\nwider than the data dimensionality, allowing efficient solutions by providing\naccess to arbitrary regions in the distribution, such as data points of one\nclass forming islands within the other classes. We argue that a link exists\nbetween the universal approximation property in ReLU networks and the\nfold-and-cut theorem (Demaine et al., 1998) dealing with physical paper\nfolding. Based on the mechanistic insight, we predict that the progressive\ngeneration of separability is necessarily accompanied by neurons showing mixed\nselectivity and bimodal tuning curves. This is validated in a network trained\non the poker hand task, showing the emergence of bimodal tuning curves during\ntraining. We hope that our intuitive picture of the data transformation in deep\nnetworks can help to provide interpretability, and discuss possible\napplications to the theory of convolutional networks, loss landscapes, and\ngeneralization.\nTL;DR: Shows that the internal processing of deep networks can be thought of\nas literal folding operations on the data distribution in the N-dimensional\nactivation space. A link to a well-known theorem in origami theory is provided.",
    "descriptor": "\nComments: preliminary version, comments are welcome\n",
    "authors": [
      "Christian Keup",
      "Moritz Helias"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.11355"
  },
  {
    "id": "arXiv:2203.11358",
    "title": "Segmenting Medical Instruments in Minimally Invasive Surgeries using  AttentionMask",
    "abstract": "Precisely locating and segmenting medical instruments in images of minimally\ninvasive surgeries, medical instrument segmentation, is an essential first step\nfor several tasks in medical image processing. However, image degradations,\nsmall instruments, and the generalization between different surgery types make\nmedical instrument segmentation challenging. To cope with these challenges, we\nadapt the object proposal generation system AttentionMask and propose a\ndedicated post-processing to select promising proposals. The results on the\nROBUST-MIS Challenge 2019 show that our adapted AttentionMask system is a\nstrong foundation for generating state-of-the-art performance. Our evaluation\nin an object proposal generation framework shows that our adapted AttentionMask\nsystem is robust to image degradations, generalizes well to unseen types of\nsurgeries, and copes well with small instruments.",
    "descriptor": "",
    "authors": [
      "Christian Wilms",
      "Alexander Michael Gerlach",
      "R\u00fcdiger Schmitz",
      "Simone Frintrop"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11358"
  },
  {
    "id": "arXiv:2203.11361",
    "title": "Complexity of limit cycles with block-sequential update schedules in  conjunctive networks",
    "abstract": "In this paper, we deal the following decision problem: given a conjunctive\nBoolean network defined by its interaction digraph, does it have a limit cycle\nof a given length k? We prove that this problem is NP-complete in general if k\nis a parameter of the problem and in P if the interaction digraph is strongly\nconnected. The case where $k$ is a constant, but the interaction digraph is not\nstrongly connected remains open. Furthermore, we study the variation of the\ndecision problem: given a conjunctive Boolean network, does there exist a\nblock-sequential (resp. sequential) update schedule such that there exists a\nlimit cycle of length k? We prove that this problem is NP-complete for any\nconstant k >= 2.",
    "descriptor": "",
    "authors": [
      "Julio Aracena",
      "Florian Bridoux",
      "Luis G\u00f3mez",
      "Lilian Salinas"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.11361"
  },
  {
    "id": "arXiv:2203.11364",
    "title": "An Information-theoretic Approach to Prompt Engineering Without Ground  Truth Labels",
    "abstract": "Pre-trained language models derive substantial linguistic and factual\nknowledge from the massive corpora on which they are trained, and prompt\nengineering seeks to align these models to specific tasks. Unfortunately,\nexisting prompt engineering methods require significant amounts of labeled\ndata, access to model parameters, or both. We introduce a new method for\nselecting prompt templates \\textit{without labeled examples} and\n\\textit{without direct access to the model}. Specifically, over a set of\ncandidate templates, we choose the template that maximizes the mutual\ninformation between the input and the corresponding model output. Across 8\ndatasets representing 7 distinct NLP tasks, we show that when a template has\nhigh mutual information, it also has high accuracy on the task. On the largest\nmodel, selecting prompts with our method gets 90\\% of the way from the average\nprompt accuracy to the best prompt accuracy and requires no ground truth\nlabels.",
    "descriptor": "",
    "authors": [
      "Taylor Sorensen",
      "Joshua Robinson",
      "Christopher Michael Rytting",
      "Alexander Glenn Shaw",
      "Kyle Jeffrey Rogers",
      "Alexia Pauline Delorey",
      "Mahmoud Khalil",
      "Nancy Fulda",
      "David Wingate"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11364"
  },
  {
    "id": "arXiv:2203.11365",
    "title": "Towards a Change Taxonomy for Machine Learning Systems",
    "abstract": "Machine Learning (ML) research publications commonly provide open-source\nimplementations on GitHub, allowing their audience to replicate, validate, or\neven extend machine learning algorithms, data sets, and metadata.\nHowever, thus far little is known about the degree of collaboration activity\nhappening on such ML research repositories, in particular regarding (1) the\ndegree to which such repositories receive contributions from forks, (2) the\nnature of such contributions (i.e., the types of changes), and (3) the nature\nof changes that are not contributed back to forks, which might represent missed\nopportunities. In this paper, we empirically study contributions to 1,346 ML\nresearch repositories and their 67,369 forks, both quantitatively and\nqualitatively (by building on Hindle et al.'s seminal taxonomy of code\nchanges). We found that while ML research repositories are heavily forked, only\n9% of the forks made modifications to the forked repository. 42% of the latter\nsent changes to the parent repositories, half of which (52%) were accepted by\nthe parent repositories. Our qualitative analysis on 539 contributed and 378\nlocal (fork-only) changes, extends Hindle et al.'s taxonomy with one new\ntop-level change category related to ML (Data), and 15 new sub-categories,\nincluding nine ML-specific ones (input data, output data, program data,\nsharing, change evaluation, parameter tuning, performance, pre-processing,\nmodel training). While the changes that are not contributed back by the forks\nmostly concern domain-specific customizations and local experimentation (e.g.,\nparameter tuning), the origin ML repositories do miss out on a non-negligible\n15.4% of Documentation changes, 13.6% of Feature changes and 11.4% of Bug fix\nchanges. The findings in this paper will be useful for practitioners,\nresearchers, toolsmiths, and educators.",
    "descriptor": "",
    "authors": [
      "Aaditya Bhatia",
      "Ellis E. Eghan",
      "Manel Grichi",
      "William G. Cavanagh",
      "Zhen Ming",
      "Jiang",
      "Bram Adams"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11365"
  },
  {
    "id": "arXiv:2203.11368",
    "title": "Audio visual character profiles for detecting background characters in  entertainment media",
    "abstract": "An essential goal of computational media intelligence is to support\nunderstanding how media stories -- be it news, commercial or entertainment\nmedia -- represent and reflect society and these portrayals are perceived.\nPeople are a central element of media stories. This paper focuses on\nunderstanding the representation and depiction of background characters in\nmedia depictions, primarily movies and TV shows. We define the background\ncharacters as those who do not participate vocally in any scene throughout the\nmovie and address the problem of localizing background characters in videos. We\nuse an active speaker localization system to extract high-confidence\nface-speech associations and generate audio-visual profiles for talking\ncharacters in a movie by automatically clustering them. Using a face\nverification system, we then prune all the face-tracks which match any of the\ngenerated character profiles and obtain the background character face-tracks.\nWe curate a background character dataset which provides annotations for\nbackground character for a set of TV shows, and use it to evaluate the\nperformance of the background character detection framework.",
    "descriptor": "\nComments: submitted to ICIP 2022\n",
    "authors": [
      "Rahul Sharma",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11368"
  },
  {
    "id": "arXiv:2203.11369",
    "title": "Temporal Abstractions-Augmented Temporally Contrastive Learning: An  Alternative to the Laplacian in RL",
    "abstract": "In reinforcement learning, the graph Laplacian has proved to be a valuable\ntool in the task-agnostic setting, with applications ranging from skill\ndiscovery to reward shaping. Recently, learning the Laplacian representation\nhas been framed as the optimization of a temporally-contrastive objective to\novercome its computational limitations in large (or continuous) state spaces.\nHowever, this approach requires uniform access to all states in the state\nspace, overlooking the exploration problem that emerges during the\nrepresentation learning process. In this work, we propose an alternative method\nthat is able to recover, in a non-uniform-prior setting, the expressiveness and\nthe desired properties of the Laplacian representation. We do so by combining\nthe representation learning with a skill-based covering policy, which provides\na better training distribution to extend and refine the representation. We also\nshow that a simple augmentation of the representation objective with the\nlearned temporal abstractions improves dynamics-awareness and helps\nexploration. We find that our method succeeds as an alternative to the\nLaplacian in the non-uniform setting and scales to challenging continuous\ncontrol environments. Finally, even if our method is not optimized for skill\ndiscovery, the learned skills can successfully solve difficult continuous\nnavigation tasks with sparse rewards, where standard skill discovery approaches\nare no so effective.",
    "descriptor": "",
    "authors": [
      "Akram Erraqabi",
      "Marlos C. Machado",
      "Mingde Zhao",
      "Sainbayar Sukhbaatar",
      "Alessandro Lazaric",
      "Ludovic Denoyer",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11369"
  },
  {
    "id": "arXiv:2203.11370",
    "title": "Language modeling via stochastic processes",
    "abstract": "Modern language models can generate high-quality short texts. However, they\noften meander or are incoherent when generating longer texts. These issues\narise from the next-token-only language modeling objective. To address these\nissues, we introduce Time Control (TC), a language model that implicitly plans\nvia a latent stochastic process. TC does this by learning a representation\nwhich maps the dynamics of how text changes in a document to the dynamics of a\nstochastic process of interest. Using this representation, the language model\ncan generate text by first implicitly generating a document plan via a\nstochastic process, and then generating text that is consistent with this\nlatent plan. Compared to domain-specific methods and fine-tuning GPT2 across a\nvariety of text domains, TC improves performance on text infilling and\ndiscourse coherence. On long text generation settings, TC preserves the text\nstructure both in terms of ordering (up to +40% better) and text length\nconsistency (up to +17% better). Human evaluators also prefer TC's output 28.6%\nmore than the baselines.",
    "descriptor": "\nComments: ICLR Oral 2022. Code: this https URL\n",
    "authors": [
      "Rose E Wang",
      "Esin Durmus",
      "Noah Goodman",
      "Tatsunori Hashimoto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11370"
  },
  {
    "id": "arXiv:2203.11372",
    "title": "Sensitivity of Single-Pulse Radar Detection to Radar State Uncertainty",
    "abstract": "Mission planners for aircraft operating under threat of detection from\nground-based radar systems are often concerned with the probability of\ndetection. Current approaches to path planning in such environments consider\nthe radar state (i.e. radar position and parameters) to be deterministic and\nknown. In practice, there is uncertainty in the radar state which induces\nuncertainty in the probability of detection. This paper presents a method to\nincorporate the uncertainty of the radar state in a single-pulse radar\ndetection model. The method linearizes the radar detection model with respect\nto the the radar state and uses the linearized models to estimate, to the first\norder, the variance of the probability of detection. The results in this paper\nvalidate the linearization using Monte Carlo analysis and illustrate the\nsensitivity of the probability of detection to radar state uncertainty.",
    "descriptor": "",
    "authors": [
      "Austin Costley",
      "Randall Christensen",
      "Robert C. Leishman",
      "Greg Droge"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11372"
  },
  {
    "id": "arXiv:2203.11373",
    "title": "Two methods for Jamming Identification in UAVs Networks using New  Synthetic Dataset",
    "abstract": "Unmanned aerial vehicle (UAV) systems are vulnerable to jamming from\nself-interested users who utilize radio devices for their benefits during UAV\ntransmissions. The vulnerability occurs due to the open nature of air-to-ground\n(A2G) wireless communication networks, which may enable network-wide attacks.\nThis paper presents two strategies to identify Jammers in UAV networks. The\nfirst strategy is based on time series approaches for anomaly detection where\nthe signal available in resource blocks are decomposed statistically to find\ntrend, seasonality, and residues, while the second is based on newly designed\ndeep networks. The joined technique is suitable for UAVs because the\nstatistical model does not require heavy computation processing but is limited\nin generalizing possible attack's identification. On the other hand, the deep\nnetwork can classify attacks accurately but requires more resources. The\nsimulation considers the location and power of the jamming attacks and the UAV\nposition related to the base station. The statistical method technique made it\nfeasible to identify 84.38 % of attacks when the attacker was at 30 m from the\nUAV. Furthermore, the Deep network's accuracy was approximately 99.99 % for\njamming powers greater than two and jammer distances less than 200 meters.",
    "descriptor": "\nComments: 7 pages, 9 figures, submitted to VTC conference\n",
    "authors": [
      "Joseanne Viana",
      "Hamed Farkhari",
      "Luis Miguel Campos",
      "Pedro Sebastiao",
      "Francisco Cercas",
      "Luis Bernardo",
      "Rui Dinis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.11373"
  },
  {
    "id": "arXiv:2203.11375",
    "title": "Robust Model Predictive Control with Polytopic Model Uncertainty through  System Level Synthesis",
    "abstract": "We propose a novel method for robust model predictive control (MPC) of\nuncertain systems subject to both polytopic model uncertainty and additive\ndisturbances. In our method, we over-approximate the actual uncertainty by a\nsurrogate additive disturbance which simplifies constraint tightening of the\nrobust optimal control problem. Using System Level Synthesis, we can optimize\nover a robust linear state feedback control policy and the uncertainty\nover-approximation parameters jointly and in a convex manner. The proposed\nmethod is demonstrated to achieve feasible domains close to the maximal robust\ncontrol invariant set for a wide range of uncertainty parameters and\nsignificant improvement in conservatism compared with tube-based MPC through\nnumerical examples.",
    "descriptor": "\nComments: Submitted to IEEE Control Systems Letters\n",
    "authors": [
      "Shaoru Chen",
      "Victor M. Preciado",
      "Manfred Morari",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.11375"
  },
  {
    "id": "arXiv:2203.11378",
    "title": "HyperShot: Few-Shot Learning by Kernel HyperNetworks",
    "abstract": "Few-shot models aim at making predictions using a minimal number of labeled\nexamples from a given task. The main challenge in this area is the one-shot\nsetting where only one element represents each class. We propose HyperShot -\nthe fusion of kernels and hypernetwork paradigm. Compared to reference\napproaches that apply a gradient-based adjustment of the parameters, our model\naims to switch the classification module parameters depending on the task's\nembedding. In practice, we utilize a hypernetwork, which takes the aggregated\ninformation from support data and returns the classifier's parameters\nhandcrafted for the considered problem. Moreover, we introduce the kernel-based\nrepresentation of the support examples delivered to hypernetwork to create the\nparameters of the classification module. Consequently, we rely on relations\nbetween embeddings of the support examples instead of direct feature values\nprovided by the backbone models. Thanks to this approach, our model can adapt\nto highly different tasks.",
    "descriptor": "",
    "authors": [
      "Marcin Sendera",
      "Marcin Przewi\u0119\u017alikowski",
      "Konrad Karanowski",
      "Maciej Zi\u0119ba",
      "Jacek Tabor",
      "Przemys\u0142aw Spurek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11378"
  },
  {
    "id": "arXiv:2203.11379",
    "title": "A Bayesian Deep Learning Technique for Multi-Step Ahead Solar Generation  Forecasting",
    "abstract": "In this paper, we propose an improved Bayesian bidirectional long-short term\nmemory (BiLSTM) neural networks for multi-step ahead (MSA) solar generation\nforecasting. The proposed technique applies alpha-beta divergence for a more\nappropriate consideration of outliers in the solar generation data and\nresulting variability of the weight parameter distribution in the neural\nnetwork. The proposed method is examined on highly granular solar generation\ndata from Ausgrid using probabilistic evaluation metrics such as Pinball loss\nand Winkler score. Moreover, a comparative analysis between MSA and the\nsingle-step ahead (SSA) forecasting is provided to test the effectiveness of\nthe proposed method on variable forecasting horizons. The numerical results\nclearly demonstrate that the proposed Bayesian BiLSTM with alpha-beta\ndivergence outperforms standard Bayesian BiLSTM and other benchmark methods for\nMSA forecasting in terms of error performance.",
    "descriptor": "",
    "authors": [
      "Devinder Kaur",
      "Shama Naz Islam",
      "Md. Apel Mahmud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11379"
  },
  {
    "id": "arXiv:2203.11380",
    "title": "Energy Efficient PON Backhaul Network for a VLC Based Fog Architecture",
    "abstract": "In this paper, an energy efficient passive optical network (PON) architecture\nis proposed for backhaul connectivity in indoor visible light communication\n(VLC) systems. The proposed network is used to support a fog computing\narchitecture allowing users with processing demands to access dedicated fog\nnodes and idle processing resources in other user devices within a building.\nThe fog resources within a building complement fog nodes at higher layers of\nthe access and metro networks and the central cloud data center. A mixed\ninteger linear programming (MILP) model is developed to minimize the total\npower consumption associated with serving demands over the proposed\narchitecture. The results show that the PON backhaul network improves the\nenergy efficiency of fog computing by 66% for networking and 12% for processing\ncompared to an architecture based on state-of-the-art Spine-and-Leaf\nconnectivity.",
    "descriptor": "",
    "authors": [
      "Wafaa B. M. Fadlelmula",
      "Sanaa H. Mohamed",
      "Taisir E. H. El-Gorashi",
      "Jaafar M. H. Elmirghani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.11380"
  },
  {
    "id": "arXiv:2203.11382",
    "title": "Preference Exploration for Efficient Bayesian Optimization with Multiple  Outcomes",
    "abstract": "We consider Bayesian optimization of expensive-to-evaluate experiments that\ngenerate vector-valued outcomes over which a decision-maker (DM) has\npreferences. These preferences are encoded by a utility function that is not\nknown in closed form but can be estimated by asking the DM to express\npreferences over pairs of outcome vectors. To address this problem, we develop\nBayesian optimization with preference exploration, a novel framework that\nalternates between interactive real-time preference learning with the DM via\npairwise comparisons between outcomes, and Bayesian optimization with a learned\ncompositional model of DM utility and outcomes. Within this framework, we\npropose preference exploration strategies specifically designed for this task,\nand demonstrate their performance via extensive simulation studies.",
    "descriptor": "",
    "authors": [
      "Zhiyuan Jerry Lin",
      "Raul Astudillo",
      "Peter I. Frazier",
      "Eytan Bakshy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.11382"
  },
  {
    "id": "arXiv:2203.11383",
    "title": "DIANES: A DEI Audit Toolkit for News Sources",
    "abstract": "Professional news media organizations have always touted the importance that\nthey give to multiple perspectives. However, in practice the traditional\napproach to all-sides has favored people in the dominant culture. Hence it has\ncome under ethical critique under the new norms of diversity, equity, and\ninclusion (DEI). When DEI is applied to journalism, it goes beyond conventional\nnotions of impartiality and bias and instead democratizes the journalistic\npractice of sourcing -- who is quoted or interviewed, who is not, how often,\nfrom which demographic group, gender, and so forth. There is currently no\nreal-time or on-demand tool in the hands of reporters to analyze the persons\nthey quote. In this paper, we present DIANES, a DEI Audit Toolkit for News\nSources. It consists of a natural language processing pipeline on the backend\nto extract quotes, speakers, titles, and organizations from news articles in\nreal time. On the frontend, DIANES offers the WordPress plugins, a Web monitor,\nand a DEI annotation API service, to help news media monitor their own quoting\npatterns and push themselves towards DEI norms.",
    "descriptor": "",
    "authors": [
      "Xiaoxiao Shang",
      "Zhiyuan Peng",
      "Qiming Yuan",
      "Sabiq Khan",
      "Lauren Xie",
      "Yi Fang",
      "Subramaniam Vincent"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11383"
  },
  {
    "id": "arXiv:2203.11386",
    "title": "Optimizing Binary Decision Diagrams with MaxSAT for classification",
    "abstract": "The growing interest in explainable artificial intelligence (XAI) for\ncritical decision making motivates the need for interpretable machine learning\n(ML) models. In fact, due to their structure (especially with small sizes),\nthese models are inherently understandable by humans. Recently, several exact\nmethods for computing such models are proposed to overcome weaknesses of\ntraditional heuristic methods by providing more compact models or better\nprediction quality.\nDespite their compressed representation of Boolean functions, Binary decision\ndiagrams (BDDs) did not gain enough interest as other interpretable ML models.\nIn this paper, we first propose SAT-based models for learning optimal BDDs (in\nterms of the number of features) that classify all input examples. Then, we\nlift the encoding to a MaxSAT model to learn optimal BDDs in limited depths,\nthat maximize the number of examples correctly classified. Finally, we tackle\nthe fragmentation problem by introducing a method to merge compatible subtrees\nfor the BDDs found via the MaxSAT model. Our empirical study shows clear\nbenefits of the proposed approach in terms of prediction quality and\nintrepretability (i.e., lighter size) compared to the state-of-the-art\napproaches.",
    "descriptor": "\nComments: This is the preprint version of the paper accepted in AAAI'22\n",
    "authors": [
      "Hao Hu",
      "Marie-Jos\u00e9 Huguet",
      "Mohamed Siala"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11386"
  },
  {
    "id": "arXiv:2203.11387",
    "title": "Privacy Rarely Considered: Exploring Considerations in the Adoption of  Third-Party Services by Websites",
    "abstract": "Modern websites frequently use and embed third-party services to facilitate\nweb development, connect to social media, or for monetization. This often\nintroduces privacy issues as the inclusion of third-party services on a website\ncan allow the third party to collect personal data about the website's\nvisitors. While the prevalence and mechanisms of third-party web tracking have\nbeen widely studied, little is known about the decision processes that lead to\nwebsites using third-party functionality and whether efforts are being made to\nprotect their visitors' privacy.\nWe report results from an online survey with 395 participants involved in the\ncreation and maintenance of websites. For ten common website functionalities we\ninvestigated if privacy has played a role in decisions about how the\nfunctionality is integrated, if specific efforts for privacy protection have\nbeen made during integration, and to what degree people are aware of data\ncollection through third parties. We find that ease of integration drives\nthird-party adoption but visitor privacy is considered if there are legal\nrequirements or respective guidelines. Awareness of data collection and privacy\nrisks is higher if the collection is directly associated with the purpose for\nwhich the third-party service is used.",
    "descriptor": "\nComments: 26 pages, 8 figures, 7 tables\n",
    "authors": [
      "Christine Utz",
      "Sabrina Amft",
      "Martin Degeling",
      "Thorsten Holz",
      "Sascha Fahl",
      "Florian Schaub"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.11387"
  },
  {
    "id": "arXiv:2203.11389",
    "title": "The VoiceMOS Challenge 2022",
    "abstract": "We present the first edition of the VoiceMOS Challenge, a scientific event\nthat aims to promote the study of automatic prediction of the mean opinion\nscore (MOS) of synthetic speech. This challenge drew 22 participating teams\nfrom academia and industry who tried a variety of approaches to tackle the\nproblem of predicting human ratings of synthesized speech. The listening test\ndata for the main track of the challenge consisted of samples from 187\ndifferent text-to-speech and voice conversion systems spanning over a decade of\nresearch, and the out-of-domain track consisted of data from more recent\nsystems rated in a separate listening test. Results of the challenge show the\neffectiveness of fine-tuning self-supervised speech models for the MOS\nprediction task, as well as the difficulty of predicting MOS ratings for unseen\nspeakers and listeners, and for unseen systems in the out-of-domain setting.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Wen-Chin Huang",
      "Erica Cooper",
      "Yu Tsao",
      "Hsin-Min Wang",
      "Tomoki Toda",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11389"
  },
  {
    "id": "arXiv:2203.11395",
    "title": "Multiple Convex Objects Image Segmentation via Proximal Alternating  Direction Method of Multipliers",
    "abstract": "This paper focuses on the issue of image segmentation with convex shape\nprior. Firstly, we use binary function to represent convex object(s). The\nconvex shape prior turns out to be a simple quadratic inequality constraint on\nthe binary indicator function associated with each object. An image\nsegmentation model incorporating convex shape prior into a probability-based\nmethod is proposed. Secondly, a new algorithm is designed to solve involved\noptimization problem, which is a challenging task because of the quadratic\ninequality constraint. To tackle this difficulty, we relax and linearize the\nquadratic inequality constraint to reduce it to solve a sequence of convex\nminimization problems. For each convex problem, an efficient proximal\nalternating direction method of multipliers is developed to solve it. The\nconvergence of the algorithm follows some existing results in the optimization\nliterature. Moreover, an interactive procedure is introduced to improve the\naccuracy of segmentation gradually. Numerical experiments on natural and\nmedical images demonstrate that the proposed method is superior to some\nexisting methods in terms of segmentation accuracy and computational time.",
    "descriptor": "",
    "authors": [
      "Shousheng Luo",
      "Jinfeng Chen",
      "Yunhai Xiao",
      "Xue-Cheng Tai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.11395"
  },
  {
    "id": "arXiv:2203.11396",
    "title": "Towards Textual Out-of-Domain Detection without In-Domain Labels",
    "abstract": "In many real-world settings, machine learning models need to identify user\ninputs that are out-of-domain (OOD) so as to avoid performing wrong actions.\nThis work focuses on a challenging case of OOD detection, where no labels for\nin-domain data are accessible (e.g., no intent labels for the intent\nclassification task). To this end, we first evaluate different language model\nbased approaches that predict likelihood for a sequence of tokens. Furthermore,\nwe propose a novel representation learning based method by combining\nunsupervised clustering and contrastive learning so that better data\nrepresentations for OOD detection can be learned. Through extensive\nexperiments, we demonstrate that this method can significantly outperform\nlikelihood-based methods and can be even competitive to the state-of-the-art\nsupervised approaches with label information.",
    "descriptor": "\nComments: Accepted by IEEE/ACM Transactions on Audio Speech and Language\n",
    "authors": [
      "Di Jin",
      "Shuyang Gao",
      "Seokhwan Kim",
      "Yang Liu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11396"
  },
  {
    "id": "arXiv:2203.11397",
    "title": "A Real World Dataset for Multi-view 3D Reconstruction",
    "abstract": "We present a dataset of 371 3D models of everyday tabletop objects along with\ntheir 320,000 real world RGB and depth images. Accurate annotations of camera\nposes and object poses for each image are performed in a semi-automated fashion\nto facilitate the use of the dataset for myriad 3D applications like shape\nreconstruction, object pose estimation, shape retrieval etc. We primarily focus\non learned multi-view 3D reconstruction due to the lack of appropriate real\nworld benchmark for the task and demonstrate that our dataset can fill that\ngap. The entire annotated dataset along with the source code for the annotation\ntools and evaluation baselines will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Rakesh Shrestha",
      "Siqi Hu",
      "Minghao Gou",
      "Ziyuan Liu",
      "Ping Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11397"
  },
  {
    "id": "arXiv:2203.11398",
    "title": "A Hybrid Lagrangian-Eulerian Model for the Structural Analysis of  Multifield Datasets",
    "abstract": "Multifields datasets are common in a large number of research and engineering\napplications of computational science. The effective visualization of the\ncorresponding datasets can facilitate their analysis by elucidating the complex\nand dynamic interactions that exist between the attributes that describe the\nphysics of the phenomenon. We present in this paper a new hybrid\nLagrangian-Eulerian model that extends existing Lagrangian visualization\ntechniques to the analysis of multifields problems. In particular, our approach\nfactors in the entire data space to reveal the structure of multifield\ndatasets, thereby combining both Eulerian and Lagrangian perspectives. We\nevaluate our technique in the context of several fluid dynamics applications.\nOur results indicate that our proposed approach is able to characterize\nimportant structural features that are missed by existing methods.",
    "descriptor": "",
    "authors": [
      "Zi'ang Ding",
      "Xavier Tricoche"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.11398"
  },
  {
    "id": "arXiv:2203.11399",
    "title": "Achieving Conversational Goals with Unsupervised Post-hoc Knowledge  Injection",
    "abstract": "A limitation of current neural dialog models is that they tend to suffer from\na lack of specificity and informativeness in generated responses, primarily due\nto dependence on training data that covers a limited variety of scenarios and\nconveys limited knowledge. One way to alleviate this issue is to extract\nrelevant knowledge from external sources at decoding time and incorporate it\ninto the dialog response. In this paper, we propose a post-hoc\nknowledge-injection technique where we first retrieve a diverse set of relevant\nknowledge snippets conditioned on both the dialog history and an initial\nresponse from an existing dialog model. We construct multiple candidate\nresponses, individually injecting each retrieved snippet into the initial\nresponse using a gradient-based decoding method, and then select the final\nresponse with an unsupervised ranking step. Our experiments in goal-oriented\nand knowledge-grounded dialog settings demonstrate that human annotators judge\nthe outputs from the proposed method to be more engaging and informative\ncompared to responses from prior dialog systems. We further show that\nknowledge-augmentation promotes success in achieving conversational goals in\nboth experimental settings.",
    "descriptor": "\nComments: Accepted at ACL 2022 main conference\n",
    "authors": [
      "Bodhisattwa Prasad Majumder",
      "Harsh Jhamtani",
      "Taylor Berg-Kirkpatrick",
      "Julian McAuley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11399"
  },
  {
    "id": "arXiv:2203.11400",
    "title": "VLSP 2021 Shared Task: Vietnamese Machine Reading Comprehension",
    "abstract": "One of the emerging research trends in natural language understanding is\nmachine reading comprehension (MRC) which is the task to find answers to human\nquestions based on textual data. Existing Vietnamese datasets for MRC research\nconcentrate solely on answerable questions. However, in reality, questions can\nbe unanswerable for which the correct answer is not stated in the given textual\ndata. To address the weakness, we provide the research community with a\nbenchmark dataset named UIT-ViQuAD 2.0 for evaluating the MRC task and question\nanswering systems for the Vietnamese language. We use UIT-ViQuAD 2.0 as a\nbenchmark dataset for the shared task on Vietnamese MRC at the Eighth Workshop\non Vietnamese Language and Speech Processing (VLSP 2021). This task attracted\n77 participant teams from 34 universities and other organizations. In this\narticle, we present details of the organization of the shared task, an overview\nof the methods employed by shared-task participants, and the results. The\nhighest performances are 77.24% EM and 67.43% F1-score on the private test set.\nThe Vietnamese MRC systems proposed by the top 3 teams use XLM-RoBERTa, a\npowerful pre-trained language model using the transformer architecture. The\nUIT-ViQuAD 2.0 dataset motivates more researchers to explore Vietnamese machine\nreading comprehension, question answering, and question generation.",
    "descriptor": "\nComments: VLSP 2021\n",
    "authors": [
      "Kiet Van Nguyen",
      "Son Quoc Tran",
      "Luan Thanh Nguyen",
      "Tin Van Huynh",
      "Son T. Luu",
      "Ngan Luu-Thuy Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11400"
  },
  {
    "id": "arXiv:2203.11401",
    "title": "Suum Cuique: Studying Bias in Taboo Detection with a Community  Perspective",
    "abstract": "Prior research has discussed and illustrated the need to consider linguistic\nnorms at the community level when studying taboo (hateful/offensive/toxic etc.)\nlanguage. However, a methodology for doing so, that is firmly founded on\ncommunity language norms is still largely absent. This can lead both to biases\nin taboo text classification and limitations in our understanding of the causes\nof bias. We propose a method to study bias in taboo classification and\nannotation where a community perspective is front and center. This is\naccomplished by using special classifiers tuned for each community's language.\nIn essence, these classifiers represent community level language norms. We use\nthese to study bias and find, for example, biases are largest against African\nAmericans (7/10 datasets and all 3 classifiers examined). In contrast to\nprevious papers we also study other communities and find, for example, strong\nbiases against South Asians. In a small scale user study we illustrate our key\nidea which is that common utterances, i.e., those with high alignment scores\nwith a community (community classifier confidence scores) are unlikely to be\nregarded taboo. Annotators who are community members contradict taboo\nclassification decisions and annotations in a majority of instances. This paper\nis a significant step toward reducing false positive taboo decisions that over\ntime harm minority communities.",
    "descriptor": "\nComments: 9 pages, 3 figures, Accepted to the Findings of ACL 2022\n",
    "authors": [
      "Osama Khalid",
      "Jonathan Rusert",
      "Padmini Srinivasan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11401"
  },
  {
    "id": "arXiv:2203.11405",
    "title": "Hindsight is 20/20: Leveraging Past Traversals to Aid 3D Perception",
    "abstract": "Self-driving cars must detect vehicles, pedestrians, and other traffic\nparticipants accurately to operate safely. Small, far-away, or highly occluded\nobjects are particularly challenging because there is limited information in\nthe LiDAR point clouds for detecting them. To address this challenge, we\nleverage valuable information from the past: in particular, data collected in\npast traversals of the same scene. We posit that these past data, which are\ntypically discarded, provide rich contextual information for disambiguating the\nabove-mentioned challenging cases. To this end, we propose a novel, end-to-end\ntrainable Hindsight framework to extract this contextual information from past\ntraversals and store it in an easy-to-query data structure, which can then be\nleveraged to aid future 3D object detection of the same scene. We show that\nthis framework is compatible with most modern 3D detection architectures and\ncan substantially improve their average precision on multiple autonomous\ndriving datasets, most notably by more than 300% on the challenging cases.",
    "descriptor": "\nComments: Accepted by ICLR 2022. Code is available at this https URL\n",
    "authors": [
      "Yurong You",
      "Katie Z Luo",
      "Xiangyu Chen",
      "Junan Chen",
      "Wei-Lun Chao",
      "Wen Sun",
      "Bharath Hariharan",
      "Mark Campbell",
      "Kilian Q. Weinberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11405"
  },
  {
    "id": "arXiv:2203.11407",
    "title": "Causal inference in time series in terms of R\u00e9nyi transfer entropy",
    "abstract": "Uncovering causal interdependencies from observational data is one of the\ngreat challenges of nonlinear time series analysis. In this paper, we discuss\nthis topic with the help of information-theoretic concept known as R\\'enyi\ninformation measure. In particular, we tackle the directional information flow\nbetween bivariate time series in terms of R\\'enyi transfer entropy. We show\nthat by choosing R\\'enyi $\\alpha$ parameter appropriately we can control\ninformation that is transferred only between selected parts of underlying\ndistributions. This, in turn, provides particularly potent tool for quantifying\ncausal interdependencies in time series, where the knowledge of \"black swan\"\nevents such as spikes or sudden jumps are of a key importance. In this\nconnection, we first prove that for Gaussian variables, Granger causality and\nR\\'enyi transfer entropy are entirely equivalent. Moreover, we also partially\nextend this results to heavy-tailed $\\alpha$-Gaussian variables. These results\nallow to establish connection between autoregressive and R\\'enyi entropy based\ninformation-theoretic approaches to data-driven causal inference. To aid our\nintuition we employ Leonenko et al. entropy estimator and analyze R\\'enyi\ninformation flow between bivariate time series generated from two\nunidirectionally coupled R\\\"ossler systems. Notably, we find that R\\'enyi\ntransfer entropy not only allowed us to detect a threshold of synchronization\nbut it also provided a non-trivial insight into the structure of a transient\nregime that exists between region of chaotic correlations and synchronization\nthreshold. In addition, from R\\'enyi transfer entropy we could reliably infer\nthe direction of coupling - and hence causality, only for coupling strengths\nsmaller that the onset value of transient regime, i.e. when two R\\\"ossler\nsystems were coupled, but have not yet entered a synchronization.",
    "descriptor": "",
    "authors": [
      "Petr Jizba",
      "Hynek Lavi\u010dka",
      "Zlata Tabachov\u00e1"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)",
      "Chaotic Dynamics (nlin.CD)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.11407"
  },
  {
    "id": "arXiv:2203.11408",
    "title": "Combined Optimal Routing and Coordination of Connected and Automated  Vehicles",
    "abstract": "In this letter, we consider a transportation network with a 100\\% penetration\nrate of connected and automated vehicles (CAVs), and present an optimal routing\napproach which takes into account the efficiency achieved in the network by\ncoordinating the CAVs at specific traffic scenarios, e.g., intersections,\nmerging roadways, roundabouts, etc. To derive the optimal route of a travel\nrequest, we use the information of the CAVs that have already received a\nrouting solution. This enables each CAV to consider the traffic conditions on\nthe roads. Given the trajectories of CAVs resulting by the routing solutions,\nthe solution of any new travel request determines the optimal travel time at\neach traffic scenario while satisfying all state, control, and safety\nconstraints. We validate the performance of our framework through numerical\nsimulations. To the best of our knowledge, this is the first attempt to\nconsider the coordination of CAVs in a routing problem.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Heeseung Bang",
      "Behdad Chalaki",
      "Andreas A. Malikopoulos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11408"
  },
  {
    "id": "arXiv:2203.11409",
    "title": "A Primer on Maximum Causal Entropy Inverse Reinforcement Learning",
    "abstract": "Inverse Reinforcement Learning (IRL) algorithms infer a reward function that\nexplains demonstrations provided by an expert acting in the environment.\nMaximum Causal Entropy (MCE) IRL is currently the most popular formulation of\nIRL, with numerous extensions. In this tutorial, we present a compressed\nderivation of MCE IRL and the key results from contemporary implementations of\nMCE IRL algorithms. We hope this will serve both as an introductory resource\nfor those new to the field, and as a concise reference for those already\nfamiliar with these topics.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Adam Gleave",
      "Sam Toyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11409"
  },
  {
    "id": "arXiv:2203.11410",
    "title": "Dazzle: Using Optimized Generative Adversarial Networks to Address  Security Data Class Imbalance Issue",
    "abstract": "Background: Machine learning techniques have been widely used and demonstrate\npromising performance in many software security tasks such as software\nvulnerability prediction. However, the class ratio within software\nvulnerability datasets is often highly imbalanced (since the percentage of\nobserved vulnerability is usually very low). Goal: To help security\npractitioners address software security data class imbalanced issues and\nfurther help build better prediction models with resampled datasets. Method: We\nintroduce an approach called Dazzle which is an optimized version of\nconditional Wasserstein Generative Adversarial Networks with gradient penalty\n(cWGAN-GP). Dazzle explores the architecture hyperparameters of cWGAN-GP with a\nnovel optimizer called Bayesian Optimization. We use Dazzle to generate\nminority class samples to resample the original imbalanced training dataset.\nResults: We evaluate Dazzle with three software security datasets, i.e., Moodle\nvulnerable files, Ambari bug reports, and JavaScript function code. We show\nthat Dazzle is practical to use and demonstrates promising improvement over\nexisting state-of-the-art oversampling techniques such as SMOTE (e.g., with an\naverage of about 60% improvement rate over SMOTE in recall among all datasets).\nConclusion: Based on this study, we would suggest the use of optimized GANs as\nan alternative method for security vulnerability data class imbalanced issues.",
    "descriptor": "",
    "authors": [
      "Rui Shu",
      "Tianpei Xia",
      "Laurie Williams",
      "Tim Menzies"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.11410"
  },
  {
    "id": "arXiv:2203.11412",
    "title": "Robust Pivoting: Exploiting Frictional Stability Using Bilevel  Optimization",
    "abstract": "Generalizable manipulation requires that robots be able to interact with\nnovel objects and environment. This requirement makes manipulation extremely\nchallenging as a robot has to reason about complex frictional interaction with\nuncertainty in physical properties of the object. In this paper, we study\nrobust optimization for control of pivoting manipulation in the presence of\nuncertainties. We present insights about how friction can be exploited to\ncompensate for the inaccuracies in the estimates of the physical properties\nduring manipulation. In particular, we derive analytical expressions for\nstability margin provided by friction during pivoting manipulation. This margin\nis then used in a bilevel trajectory optimization algorithm to design a\ncontroller that maximizes this stability margin to provide robustness against\nuncertainty in physical properties of the object. We demonstrate our proposed\nmethod using a 6 DoF manipulator for manipulating several different objects.",
    "descriptor": "\nComments: Accepted to the 2022 IEEE International Conference on Robotics and Automation (ICRA 2022)\n",
    "authors": [
      "Yuki Shirai",
      "Devesh K. Jha",
      "Arvind Raghunathan",
      "Diego Romeres"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11412"
  },
  {
    "id": "arXiv:2203.11413",
    "title": "Learning Confidence for Transformer-based Neural Machine Translation",
    "abstract": "Confidence estimation aims to quantify the confidence of the model\nprediction, providing an expectation of success. A well-calibrated confidence\nestimate enables accurate failure prediction and proper risk measurement when\ngiven noisy samples and out-of-distribution data in real-world settings.\nHowever, this task remains a severe challenge for neural machine translation\n(NMT), where probabilities from softmax distribution fail to describe when the\nmodel is probably mistaken. To address this problem, we propose an unsupervised\nconfidence estimate learning jointly with the training of the NMT model. We\nexplain confidence as how many hints the NMT model needs to make a correct\nprediction, and more hints indicate low confidence. Specifically, the NMT model\nis given the option to ask for hints to improve translation accuracy at the\ncost of some slight penalty. Then, we approximate their level of confidence by\ncounting the number of hints the model uses. We demonstrate that our learned\nconfidence estimate achieves high accuracy on extensive sentence/word-level\nquality estimation tasks. Analytical results verify that our confidence\nestimate can correctly assess underlying risk in two real-world scenarios: (1)\ndiscovering noisy samples and (2) detecting out-of-domain data. We further\npropose a novel confidence-based instance-specific label smoothing approach\nbased on our learned confidence estimate, which outperforms standard label\nsmoothing.",
    "descriptor": "",
    "authors": [
      "Yu Lu",
      "Jiali Zeng",
      "Jiajun Zhang",
      "Shuangzhi Wu",
      "Mu Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11413"
  },
  {
    "id": "arXiv:2203.11414",
    "title": "BESSIE: A Behavior and Epidemic Simulator for Use With Synthetic  Populations",
    "abstract": "In this paper, we present BESSIE (Behavior and Epidemic Simulator for\nSynthetic Information Environments), an open source, agent-based simulator for\nCOVID-type epidemics. BESSIE uses a synthetic population where each person has\ndemographic attributes, belong to a household, and has a base activity- and\nvisit schedule covering seven days. The simulated disease spreads through\ncontacts that arise from joint visits to the locations where activities take\nplace. The simulation model has a plugin-type programmable behavioral model\nwhere, based on the dynamics and observables tracked by the simulator, agents\ndecide on actions such as wearing a mask, engaging in social distancing, or\nrefraining from certain activity types by staying at home instead. The plugins\nare supplied as Python code. To the best of our knowledge, BESSIE is a unique\nsimulator supporting this feature set, and most certainly as open software.\nTo illustrate the use of BESSIE, we provide a COVID-relevant example\ndemonstrating some of its capabilities. The example uses a synthetic population\nfor the City of Charlottesville, Virginia. Both this population and the Python\nplugin modules used in the example are made available. The Python\nimplementation, which can run on anything from a laptop to a cluster, is made\navailable under the Apache 2.0 license\n(https://www.apache.org/licenses/LICENSE-2.0.html). The example population\naccompanying this publication is made available under the CC BY 4.0 license\n(https://creativecommons.org/licenses/by/4.0/).",
    "descriptor": "\nComments: 24 pages; the git repository and accompanying data will be made openly available upon final journal publication\n",
    "authors": [
      "Henning S Mortveit",
      "Stephen Adams",
      "Faraz Dadgostari",
      "Samarth Swarup",
      "Peter Beling"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.11414"
  },
  {
    "id": "arXiv:2203.11420",
    "title": "Consent as a Foundation for Responsible Autonomy",
    "abstract": "This paper focuses on a dynamic aspect of responsible autonomy, namely, to\nmake intelligent agents be responsible at run time. That is, it considers\nsettings where decision making by agents impinges upon the outcomes perceived\nby other agents. For an agent to act responsibly, it must accommodate the\ndesires and other attitudes of its users and, through other agents, of their\nusers.\nThe contribution of this paper is twofold. First, it provides a conceptual\nanalysis of consent, its benefits and misuses, and how understanding consent\ncan help achieve responsible autonomy. Second, it outlines challenges for AI\n(in particular, for agents and multiagent systems) that merit investigation to\nform as a basis for modeling consent in multiagent systems and applying consent\nto achieve responsible autonomy.",
    "descriptor": "\nComments: 6 pages; 1 table Proceedings of the 36th AAAI Conference on Artificial Intelligence (AAAI), Blue Sky Track\n",
    "authors": [
      "Munindar P. Singh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.11420"
  },
  {
    "id": "arXiv:2203.11421",
    "title": "Mobility Equity from a Game-Theoretic Perspective",
    "abstract": "In this letter, we consider a multi-modal mobility system of travelers, and\npropose a game-theoretic framework to efficiently assign each traveler to a\nmobility service (e.g., different modes of transportation). Our focus in this\nframework is to maximize the \"mobility equity\" in the sense of respecting the\nmobility budgets of the travelers. Each traveler seeks to travel using only one\nservice (e.g., car, bus, train, bike). The services are capacitated and can\nserve up to a fixed number of travelers at any instant of time. Thus, our\nproblem falls under the category of many-to-one assignment problems, where the\ngoal is to find the conditions that guarantee the stability of assignments. We\nformulate a linear program of maximizing the mobility equity of travelers and\nwe fully characterize the optimal solution. We also show that our framework\nunder the proposed pricing scheme induces truthfulness from the strategic\ntravelers, while they have incentives to voluntarily participate under\ninformational asymmetry.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2110.06403\n",
    "authors": [
      "Ioannis Vasileios Chremos",
      "Andreas Malikopoulos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11421"
  },
  {
    "id": "arXiv:2203.11423",
    "title": "RT-Bench: an Extensible Benchmark Framework for the Analysis and  Management of Real-Time Applications",
    "abstract": "Benchmarking is crucial for testing and validating any system, even more so\nin real-time systems. Typical real-time applications adhere to well-understood\nabstractions: they exhibit a periodic behavior, operate on a well-defined\nworking set, and strive for stable response time avoiding non-predicable\nfactors such as page faults. Unfortunately, available benchmark suites fail to\nreflect key characteristics of real-time applications. Practitioners and\nresearchers must resort to either benchmark heavily approximated real-time\nenvironments, or to re-engineer available benchmarks to add -- if possible --\nthe sought-after features. Additionally, the measuring and logging capabilities\nprovided by most benchmark suites are not tailored \"out-of-the-box\" to\nreal-time environments, and changing basic parameters such as the scheduling\npolicy often becomes a tiring and error-prone exercise.\nIn this paper, we present RT-bench, an open-source framework adding standard\nreal-time features to virtually any existing benchmark. Furthermore, RT-bench\nprovides an easy-to-use, unified command line interface to customize key\naspects of the real-time execution of a set of benchmarks. Our framework is\nguided by four main criteria: 1) cohesive interface, 2) support for periodic\napplication behavior and deadline semantics, 3) controllable memory footprint,\nand 4) extensibility and portability. We have integrated within the framework\napplications from the widely used SD-VBS and IsolBench suites. We showcase a\nset of use-cases that are representative of typical real-time system evaluation\nscenarios and that can be easily conducted via RT-Bench.",
    "descriptor": "\nComments: 11 pages, 12 figures; Submitted to RTNS 2022; code available at this https URL, documentation available at this https URL\n",
    "authors": [
      "Mattia Nicolella",
      "Shahin Roozkhosh",
      "Denis Hoornaert",
      "Andrea Bastoni",
      "Renato Mancuso"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Performance (cs.PF)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11423"
  },
  {
    "id": "arXiv:2203.11425",
    "title": "Towards Abstractive Grounded Summarization of Podcast Transcripts",
    "abstract": "Podcasts have recently shown a rapid rise in popularity. Summarization of\npodcast transcripts is of practical benefit to both content providers and\nconsumers. It helps consumers to quickly decide whether they will listen to the\npodcasts and reduces the cognitive load of content providers to write\nsummaries. Nevertheless, podcast summarization faces significant challenges\nincluding factual inconsistencies with respect to the inputs. The problem is\nexacerbated by speech disfluencies and recognition errors in transcripts of\nspoken language. In this paper, we explore a novel abstractive summarization\nmethod to alleviate these challenges. Specifically, our approach learns to\nproduce an abstractive summary while grounding summary segments in specific\nportions of the transcript to allow for full inspection of summary details. We\nconduct a series of analyses of the proposed approach on a large podcast\ndataset and show that the approach can achieve promising results. Grounded\nsummaries bring clear benefits in locating the summary and transcript segments\nthat contain inconsistent information, and hence significantly improve\nsummarization quality in both automatic and human evaluation metrics.",
    "descriptor": "",
    "authors": [
      "Kaiqiang Song",
      "Chen Li",
      "Xiaoyang Wang",
      "Dong Yu",
      "Fei Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11425"
  },
  {
    "id": "arXiv:2203.11427",
    "title": "Arithmetic crosscorrelation of pseudorandom binary sequences of coprime  periods",
    "abstract": "The (classical) crosscorrelation is an important measure of pseudorandomness\nof two binary sequences for applications in communications. The arithmetic\ncrosscorrelation is another figure of merit introduced by Goresky and Klapper\ngeneralizing Mandelbaum's arithmetic autocorrelation.\nFirst we observe that the arithmetic crosscorrelation is constant for two\nbinary sequences of coprime periods which complements the analogous result for\nthe classical crosscorrelation.\nThen we prove upper bounds for the constant arithmetic crosscorrelation of\ntwo Legendre sequences of different periods and of two binary $m$-sequences of\ncoprime periods, respectively.",
    "descriptor": "",
    "authors": [
      "Zhixiong Chen",
      "Zhihua Niu",
      "Arne Winterhof"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.11427"
  },
  {
    "id": "arXiv:2203.11431",
    "title": "Task-guided Disentangled Tuning for Pretrained Language Models",
    "abstract": "Pretrained language models (PLMs) trained on large-scale unlabeled corpus are\ntypically fine-tuned on task-specific downstream datasets, which have produced\nstate-of-the-art results on various NLP tasks. However, the data discrepancy\nissue in domain and scale makes fine-tuning fail to efficiently capture\ntask-specific patterns, especially in the low data regime. To address this\nissue, we propose Task-guided Disentangled Tuning (TDT) for PLMs, which\nenhances the generalization of representations by disentangling task-relevant\nsignals from the entangled representations. For a given task, we introduce a\nlearnable confidence model to detect indicative guidance from context, and\nfurther propose a disentangled regularization to mitigate the over-reliance\nproblem. Experimental results on GLUE and CLUE benchmarks show that TDT gives\nconsistently better results than fine-tuning with different PLMs, and extensive\nanalysis demonstrates the effectiveness and robustness of our method. Code is\navailable at https://github.com/lemon0830/TDT.",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Jiali Zeng",
      "Yufan Jiang",
      "Shuangzhi Wu",
      "Yongjing Yin",
      "Mu Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11431"
  },
  {
    "id": "arXiv:2203.11432",
    "title": "Gated Domain-Invariant Feature Disentanglement for Domain Generalizable  Object Detection",
    "abstract": "For Domain Generalizable Object Detection (DGOD), Disentangled Representation\nLearning (DRL) helps a lot by explicitly disentangling Domain-Invariant\nRepresentations (DIR) from Domain-Specific Representations (DSR). Considering\nthe domain category is an attribute of input data, it should be feasible for\nnetworks to fit a specific mapping which projects DSR into feature channels\nexclusive to domain-specific information, and thus much cleaner disentanglement\nof DIR from DSR can be achieved simply on channel dimension. Inspired by this\nidea, we propose a novel DRL method for DGOD, which is termed Gated\nDomain-Invariant Feature Disentanglement (GDIFD). In GDIFD, a Channel Gate\nModule (CGM) learns to output channel gate signals close to either 0 or 1,\nwhich can mask out the channels exclusive to domain-specific information\nhelpful for domain recognition. With the proposed GDIFD, the backbone in our\nframework can fit the desired mapping easily, which enables the channel-wise\ndisentanglement. In experiments, we demonstrate that our approach is highly\neffective and achieves state-of-the-art DGOD performance.",
    "descriptor": "",
    "authors": [
      "Haozhuo Zhang",
      "Huimin Yu",
      "Yuming Yan",
      "Runfa Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11432"
  },
  {
    "id": "arXiv:2203.11433",
    "title": "Making DeepFakes more spurious: evading deep face forgery detection via  trace removal attack",
    "abstract": "DeepFakes are raising significant social concerns. Although various DeepFake\ndetectors have been developed as forensic countermeasures, these detectors are\nstill vulnerable to attacks. Recently, a few attacks, principally adversarial\nattacks, have succeeded in cloaking DeepFake images to evade detection.\nHowever, these attacks have typical detector-specific designs, which require\nprior knowledge about the detector, leading to poor transferability. Moreover,\nthese attacks only consider simple security scenarios. Less is known about how\neffective they are in high-level scenarios where either the detectors or the\nattacker's knowledge varies. In this paper, we solve the above challenges with\npresenting a novel detector-agnostic trace removal attack for DeepFake\nanti-forensics. Instead of investigating the detector side, our attack looks\ninto the original DeepFake creation pipeline, attempting to remove all\ndetectable natural DeepFake traces to render the fake images more \"authentic\".\nTo implement this attack, first, we perform a DeepFake trace discovery,\nidentifying three discernible traces. Then a trace removal network (TR-Net) is\nproposed based on an adversarial learning framework involving one generator and\nmultiple discriminators. Each discriminator is responsible for one individual\ntrace representation to avoid cross-trace interference. These discriminators\nare arranged in parallel, which prompts the generator to remove various traces\nsimultaneously. To evaluate the attack efficacy, we crafted heterogeneous\nsecurity scenarios where the detectors were embedded with different levels of\ndefense and the attackers' background knowledge of data varies. The\nexperimental results show that the proposed attack can significantly compromise\nthe detection accuracy of six state-of-the-art DeepFake detectors while causing\nonly a negligible loss in visual quality to the original DeepFake samples.",
    "descriptor": "",
    "authors": [
      "Chi Liu",
      "Huajie Chen",
      "Tianqing Zhu",
      "Jun Zhang",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.11433"
  },
  {
    "id": "arXiv:2203.11434",
    "title": "Non-linear Embeddings in Hilbert Simplex Geometry",
    "abstract": "A key technique of machine learning and computer vision is to embed discrete\nweighted graphs into continuous spaces for further downstream processing.\nEmbedding discrete hierarchical structures in hyperbolic geometry has proven\nvery successful since it was shown that any weighted tree can be embedded in\nthat geometry with arbitrary low distortion. Various optimization methods for\nhyperbolic embeddings based on common models of hyperbolic geometry have been\nstudied. In this paper, we consider Hilbert geometry for the standard simplex\nwhich is isometric to a vector space equipped with the variation polytope norm.\nWe study the representation power of this Hilbert simplex geometry by embedding\ndistance matrices of graphs. Our findings demonstrate that Hilbert simplex\ngeometry is competitive to alternative geometries such as the Poincar\\'e\nhyperbolic ball or the Euclidean geometry for embedding tasks while being fast\nand numerically robust.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Frank Nielsen",
      "Ke Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11434"
  },
  {
    "id": "arXiv:2203.11437",
    "title": "Self-Supervised Representation Learning as Multimodal Variational  Inference",
    "abstract": "This paper proposes a probabilistic extension of SimSiam, a recent\nself-supervised learning (SSL) method. SimSiam trains a model by maximizing the\nsimilarity between image representations of different augmented views of the\nsame image. Although uncertainty-aware machine learning has been getting\ngeneral like deep variational inference, SimSiam and other SSL are\ninsufficiently uncertainty-aware, which could lead to limitations on its\npotential. The proposed extension is to make SimSiam uncertainty-aware based on\nvariational inference. Our main contributions are twofold: Firstly, we clarify\nthe theoretical relationship between non-contrastive SSL and multimodal\nvariational inference. Secondly, we introduce a novel SSL called variational\ninference SimSiam (VI-SimSiam), which incorporates the uncertainty by involving\nspherical posterior distributions. Our experiment shows that VI-SimSiam\noutperforms SimSiam in classification tasks in ImageNette and ImageWoof by\nsuccessfully estimating the representation uncertainty.",
    "descriptor": "\nComments: 4 pages, 4 figures, work in progress\n",
    "authors": [
      "Hiroki Nakamura",
      "Masashi Okada",
      "Tadahiro Taniguchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11437"
  },
  {
    "id": "arXiv:2203.11441",
    "title": "Multi-Modal Learning for AU Detection Based on Multi-Head Fused  Transformers",
    "abstract": "Multi-modal learning has been intensified in recent years, especially for\napplications in facial analysis and action unit detection whilst there still\nexist two main challenges in terms of 1) relevant feature learning for\nrepresentation and 2) efficient fusion for multi-modalities. Recently, there\nare a number of works have shown the effectiveness in utilizing the attention\nmechanism for AU detection, however, most of them are binding the region of\ninterest (ROI) with features but rarely apply attention between features of\neach AU. On the other hand, the transformer, which utilizes a more efficient\nself-attention mechanism, has been widely used in natural language processing\nand computer vision tasks but is not fully explored in AU detection tasks. In\nthis paper, we propose a novel end-to-end Multi-Head Fused Transformer (MFT)\nmethod for AU detection, which learns AU encoding features representation from\ndifferent modalities by transformer encoder and fuses modalities by another\nfusion transformer module. Multi-head fusion attention is designed in the\nfusion transformer module for the effective fusion of multiple modalities. Our\napproach is evaluated on two public multi-modal AU databases, BP4D, and BP4D+,\nand the results are superior to the state-of-the-art algorithms and baseline\nmodels. We further analyze the performance of AU detection from different\nmodalities.",
    "descriptor": "",
    "authors": [
      "Xiang Zhang",
      "Lijun Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11441"
  },
  {
    "id": "arXiv:2203.11442",
    "title": "Associating Objects with Scalable Transformers for Video Object  Segmentation",
    "abstract": "This paper investigates how to realize better and more efficient embedding\nlearning to tackle the semi-supervised video object segmentation under\nchallenging multi-object scenarios. The state-of-the-art methods learn to\ndecode features with a single positive object and thus have to match and\nsegment each target separately under multi-object scenarios, consuming multiple\ntimes computation resources. To solve the problem, we propose an Associating\nObjects with Transformers (AOT) approach to match and decode multiple objects\njointly and collaboratively. In detail, AOT employs an identification mechanism\nto associate multiple targets into the same high-dimensional embedding space.\nThus, we can simultaneously process multiple objects' matching and segmentation\ndecoding as efficiently as processing a single object. To sufficiently model\nmulti-object association, a Long Short-Term Transformer (LSTT) is devised to\nconstruct hierarchical matching and propagation. Based on AOT, we further\npropose a more flexible and robust framework, Associating Objects with Scalable\nTransformers (AOST), in which a scalable version of LSTT is designed to enable\nrun-time adaptation of accuracy-efficiency trade-offs. Besides, AOST introduces\na better layer-wise manner to couple identification and vision embeddings. We\nconduct extensive experiments on multi-object and single-object benchmarks to\nexamine AOT series frameworks. Compared to the state-of-the-art competitors,\nour methods can maintain times of run-time efficiency with superior\nperformance. Notably, we achieve new state-of-the-art performance on three\npopular benchmarks, i.e., YouTube-VOS (86.5%), DAVIS 2017 Val/Test\n(87.0%/84.7%), and DAVIS 2016 (93.0%). Project page:\nhttps://github.com/z-x-yang/AOT.",
    "descriptor": "\nComments: Extension of arXiv:2106.02638 (NeurIPS 2021)\n",
    "authors": [
      "Zongxin Yang",
      "Jiaxu Miao",
      "Xiaohan Wang",
      "Yunchao Wei",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11442"
  },
  {
    "id": "arXiv:2203.11443",
    "title": "Demo of the Linguistic Field Data Management and Analysis System -- LiFE",
    "abstract": "In the proposed demo, we will present a new software - Linguistic Field Data\nManagement and Analysis System - LiFE (https://github.com/kmi-linguistics/life)\n- an open-source, web-based linguistic data management and analysis application\nthat allows for systematic storage, management, sharing and usage of linguistic\ndata collected from the field. The application allows users to store lexical\nitems, sentences, paragraphs, audio-visual content with rich glossing /\nannotation; generate interactive and print dictionaries; and also train and use\nnatural language processing tools and models for various purposes using this\ndata. Since its a web-based application, it also allows for seamless\ncollaboration among multiple persons and sharing the data, models, etc with\neach other.\nThe system uses the Python-based Flask framework and MongoDB in the backend\nand HTML, CSS and Javascript at the frontend. The interface allows creation of\nmultiple projects that could be shared with the other users. At the backend,\nthe application stores the data in RDF format so as to allow its release as\nLinked Data over the web using semantic web technologies - as of now it makes\nuse of the OntoLex-Lemon for storing the lexical data and Ligt for storing the\ninterlinear glossed text and then internally linking it to the other linked\nlexicons and databases such as DBpedia and WordNet. Furthermore it provides\nsupport for training the NLP systems using scikit-learn and HuggingFace\nTransformers libraries as well as make use of any model trained using these\nlibraries - while the user interface itself provides limited options for tuning\nthe system, an externally-trained model could be easily incorporated within the\napplication; similarly the dataset itself could be easily exported into a\nstandard machine-readable format like JSON or CSV that could be consumed by\nother programs and pipelines.",
    "descriptor": "\nComments: Accepted in the 19th International Conference on Natural Language Processing (ICON-2021)\n",
    "authors": [
      "Siddharth Singh",
      "Ritesh Kumar",
      "Shyam Ratan",
      "Sonal Sinha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11443"
  },
  {
    "id": "arXiv:2203.11444",
    "title": "Root-aligned SMILES for Molecular Retrosynthesis Prediction",
    "abstract": "Retrosynthesis prediction is a fundamental problem in organic synthesis,\nwhere the task is to discover precursor molecules that can be used to\nsynthesize a target molecule. A popular paradigm of existing computational\nretrosynthesis methods formulate retrosynthesis prediction as a\nsequence-to-sequence translation problem, where the typical SMILES\nrepresentations are adopted for both reactants and products. However, the\ngeneral-purpose SMILES neglects the characteristics of retrosynthesis that 1)\nthe search space of the reactants is quite huge, and 2) the molecular graph\ntopology is largely unaltered from products to reactants, resulting in the\nsuboptimal performance of SMILES if straightforwardly applied. In this article,\nwe propose the root-aligned SMILES~(R-SMILES), which specifies a tightly\naligned one-to-one mapping between the product and the reactant SMILES, to\nnarrow the string representation discrepancy for more efficient retrosynthesis.\nAs the minimum edit distance between the input and the output is significantly\ndecreased with the proposed R-SMILES, the computational model is largely\nrelieved from learning the complex syntax and dedicated to learning the\nchemical knowledge for retrosynthesis. We compare the proposed R-SMILES with\nvarious state-of-the-art baselines on different benchmarks and show that it\nsignificantly outperforms them all, demonstrating the superiority of the\nproposed method.",
    "descriptor": "\nComments: Main paper: 15 pages, 5 figures, and 1 table; supplementary information: 4 pages, 2 figures and 3 tables\n",
    "authors": [
      "Zipeng Zhong",
      "Jie Song",
      "Zunlei Feng",
      "Tiantao Liu",
      "Lingxiang Jia",
      "Shaolun Liu",
      "Min Wu",
      "Tingjun Hou",
      "Mingli Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2203.11444"
  },
  {
    "id": "arXiv:2203.11447",
    "title": "Manipulating UAV Imagery for Satellite Model Training, Calibration and  Testing",
    "abstract": "Modern livestock farming is increasingly data driven and frequently relies on\nefficient remote sensing to gather data over wide areas. High resolution\nsatellite imagery is one such data source, which is becoming more accessible\nfor farmers as coverage increases and cost falls. Such images can be used to\ndetect and track animals, monitor pasture changes, and understand land use.\nMany of the data driven models being applied to these tasks require ground\ntruthing at resolutions higher than satellites can provide. Simultaneously,\nthere is a lack of available aerial imagery focused on farmland changes that\noccur over days or weeks, such as herd movement. With this goal in mind, we\npresent a new multi-temporal dataset of high resolution UAV imagery which is\nartificially degraded to match satellite data quality. An empirical blurring\nmetric is used to calibrate the degradation process against actual satellite\nimagery of the area. UAV surveys were flown repeatedly over several weeks, for\nspecific farm locations. This 5cm/pixel data is sufficiently high resolution to\naccurately ground truth cattle locations, and other factors such as grass\ncover. From 33 wide area UAV surveys, 1869 patches were extracted and\nartificially degraded using an accurate satellite optical model to simulate\nsatellite data. Geographic patches from multiple time periods are aligned and\npresented as sets, providing a multi-temporal dataset that can be used for\ndetecting changes on farms. The geo-referenced images and 27,853 manually\nannotated cattle labels are made publicly available.",
    "descriptor": "\nComments: 16 pages, 7 figures, 2 tables\n",
    "authors": [
      "Jasper Brown",
      "Cameron Clark",
      "Sabrina Lomax",
      "Khalid Rafique",
      "Salah Sukkarieh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11447"
  },
  {
    "id": "arXiv:2203.11449",
    "title": "Leveraging Textures in Zero-shot Understanding of Fine-Grained Domains",
    "abstract": "Textures can be used to describe the appearance of objects in a wide range of\nfine-grained domains. Textures are localized and one can often refer to their\nproperties in a manner that is independent of the object identity. Moreover,\nthere is a rich vocabulary to describe textures corresponding to properties\nsuch as their color, pattern, structure, periodicity, stochasticity, and\nothers. Motivated by this, we study the effectiveness of large-scale language\nand vision models (e.g., CLIP) at recognizing texture attributes in natural\nimages. We first conduct a systematic study of CLIP on texture datasets where\nwe find that it has good coverage for a wide range of texture terms. CLIP can\nalso handle compositional phrases that consist of color and pattern terms\n(e.g., red dots or yellow stripes). We then show how these attributes allow for\nzero-shot fine-grained categorization on existing datasets.",
    "descriptor": "",
    "authors": [
      "Chenyun Wu",
      "Subhransu Maji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11449"
  },
  {
    "id": "arXiv:2203.11453",
    "title": "DepthGAN: GAN-based Depth Generation of Indoor Scenes from Semantic  Layouts",
    "abstract": "Limited by the computational efficiency and accuracy, generating complex 3D\nscenes remains a challenging problem for existing generation networks. In this\nwork, we propose DepthGAN, a novel method of generating depth maps with only\nsemantic layouts as input. First, we introduce a well-designed cascade of\ntransformer blocks as our generator to capture the structural correlations in\ndepth maps, which makes a balance between global feature aggregation and local\nattention. Meanwhile, we propose a cross-attention fusion module to guide edge\npreservation efficiently in depth generation, which exploits additional\nappearance supervision information. Finally, we conduct extensive experiments\non the perspective views of the Structured3d panorama dataset and demonstrate\nthat our DepthGAN achieves superior performance both on quantitative results\nand visual effects in the depth generation task.Furthermore, 3D indoor scenes\ncan be reconstructed by our generated depth maps with reasonable structure and\nspatial coherency.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Yidi Li",
      "Yiqun Wang",
      "Zhengda Lu",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11453"
  },
  {
    "id": "arXiv:2203.11458",
    "title": "Hierarchical Graph Representation Learning for the Prediction of  Drug-Target Binding Affinity",
    "abstract": "The identification of drug-target binding affinity (DTA) has attracted\nincreasing attention in the drug discovery process due to the more specific\ninterpretation than binary interaction prediction. Recently, numerous deep\nlearning-based computational methods have been proposed to predict the binding\naffinities between drugs and targets benefiting from their satisfactory\nperformance. However, the previous works mainly focus on encoding biological\nfeatures and chemical structures of drugs and targets, with a lack of\nexploiting the essential topological information from the drug-target affinity\nnetwork. In this paper, we propose a novel hierarchical graph representation\nlearning model for the drug-target binding affinity prediction, namely\nHGRL-DTA. The main contribution of our model is to establish a hierarchical\ngraph learning architecture to incorporate the intrinsic properties of\ndrug/target molecules and the topological affinities of drug-target pairs. In\nthis architecture, we adopt a message broadcasting mechanism to integrate the\nhierarchical representations learned from the global-level affinity graph and\nthe local-level molecular graph. Besides, we design a similarity-based\nembedding map to solve the cold start problem of inferring representations for\nunseen drugs and targets. Comprehensive experimental results under different\nscenarios indicate that HGRL-DTA significantly outperforms the state-of-the-art\nmodels and shows better model generalization among all the scenarios.",
    "descriptor": "",
    "authors": [
      "Zhaoyang Chu",
      "Shichao Liu",
      "Wen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2203.11458"
  },
  {
    "id": "arXiv:2203.11463",
    "title": "Identity and Access Management Framework for Multi-tenant Resources in  Hybrid Cloud Computing",
    "abstract": "While more organizations have been trying to move their infrastructure to the\ncloud in recent years, there have been significant challenges in how identities\nand access are managed in a hybrid cloud setting. This paper showcases a novel\nidentity and access management framework for shared resources in a multi-tenant\nhybrid cloud environment. The paper demonstrates a method to implement the\n\"mirror\" identities of on-premise identities in the cloud. Following the best\nsecurity practices, the framework ensures that only rightful users can use\ntheir mirror identities in the cloud. Furthermore, the paper also proposes a\ntechnique in scaling the framework to accommodate large-scale enterprises. The\nframework exhibited in the paper provides a comprehensive and scalable solution\nfor enterprises to implement identity and access control in their hybrid cloud\ninfrastructure. Although the paper focuses on implementing the framework in\nGoogle Cloud Platform, it can be easily applied to any major public cloud\nplatform.",
    "descriptor": "\nComments: IEEE CLOUD 2022\n",
    "authors": [
      "Saurabh Deochake",
      "Vrushali Channapattan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.11463"
  },
  {
    "id": "arXiv:2203.11470",
    "title": "Safety of Sampled-Data Systems with Control Barrier Functions via  Approximate Discrete Time Models",
    "abstract": "Control Barrier Functions (CBFs) have been demonstrated to be a powerful tool\nfor safety-critical controller design for nonlinear systems. Existing design\nparadigms do not address the gap between theory (controller design with\ncontinuous time models) and practice (the discrete time sampled implementation\nof the resulting controllers); this can lead to poor performance and violations\nof safety for hardware instantiations. We propose an approach to close this gap\nby synthesizing sampled-data counterparts to these CBF-based controllers using\napproximate discrete time models and Sampled-Data Control Barrier Functions\n(SD-CBFs). Using properties of a system's continuous time model, we establish a\nrelationship between SD-CBFs and a notion of practical safety for sampled-data\nsystems. Furthermore, we construct convex optimization-based controllers that\nformally endow nonlinear systems with safety guarantees in practice. We\ndemonstrate the efficacy of these controllers in simulation.",
    "descriptor": "\nComments: 9 pages, 3 figures, submitted to Control Systems Letters (CSL) / 2022 Conference on Decision & Control (CDC)\n",
    "authors": [
      "Andrew J. Taylor",
      "Victor D. Dorobantu",
      "Ryan K. Cosner",
      "Yisong Yue",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.11470"
  },
  {
    "id": "arXiv:2203.11471",
    "title": "Ray3D: ray-based 3D human pose estimation for monocular absolute 3D  localization",
    "abstract": "In this paper, we propose a novel monocular ray-based 3D (Ray3D) absolute\nhuman pose estimation with calibrated camera. Accurate and generalizable\nabsolute 3D human pose estimation from monocular 2D pose input is an ill-posed\nproblem. To address this challenge, we convert the input from pixel space to 3D\nnormalized rays. This conversion makes our approach robust to camera intrinsic\nparameter changes. To deal with the in-the-wild camera extrinsic parameter\nvariations, Ray3D explicitly takes the camera extrinsic parameters as an input\nand jointly models the distribution between the 3D pose rays and camera\nextrinsic parameters. This novel network design is the key to the outstanding\ngeneralizability of Ray3D approach. To have a comprehensive understanding of\nhow the camera intrinsic and extrinsic parameter variations affect the accuracy\nof absolute 3D key-point localization, we conduct in-depth systematic\nexperiments on three single person 3D benchmarks as well as one synthetic\nbenchmark. These experiments demonstrate that our method significantly\noutperforms existing state-of-the-art models. Our code and the synthetic\ndataset are available at https://github.com/YxZhxn/Ray3D .",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Yu Zhan",
      "Fenghai Li",
      "Renliang Weng",
      "Wongun Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11471"
  },
  {
    "id": "arXiv:2203.11472",
    "title": "BigBird: Big Data Storage and Analytics at Scale in Hybrid Cloud",
    "abstract": "Implementing big data storage at scale is a complex and arduous task that\nrequires an advanced infrastructure. With the rise of public cloud computing,\nvarious big data management services can be readily leveraged. As a critical\npart of Twitter's \"Project Partly Cloudy\", the cold storage data and analytics\nsystems are being moved to the public cloud. This paper showcases our approach\nin designing a scalable big data storage and analytics management framework\nusing BigQuery in Google Cloud Platform while ensuring security, privacy, and\ndata protection. The paper also discusses the limitations on the public cloud\nresources and how they can be effectively overcome when designing a big data\nstorage and analytics solution at scale. Although the paper discusses the\nframework implementation in Google Cloud Platform, it can easily be applied to\nall major cloud providers.",
    "descriptor": "\nComments: Journal of Big Data\n",
    "authors": [
      "Saurabh Deochake",
      "Vrushali Channapattan",
      "Gary Steelman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.11472"
  },
  {
    "id": "arXiv:2203.11473",
    "title": "Federated Class-Incremental Learning",
    "abstract": "Federated learning (FL) has attracted growing attention via data-private\ncollaborative training on decentralized clients. However, most existing methods\nunrealistically assume object classes of the overall framework are fixed over\ntime. It makes the global model suffer from significant catastrophic forgetting\non old classes in real-world scenarios, where local clients often collect new\nclasses continuously and have very limited storage memory to store old classes.\nMoreover, new clients with unseen new classes may participate in the FL\ntraining, further aggravating the catastrophic forgetting of the global model.\nTo address these challenges, we develop a novel Global-Local Forgetting\nCompensation (GLFC) model, to learn a global class incremental model for\nalleviating the catastrophic forgetting from both local and global\nperspectives. Specifically, to address local forgetting caused by class\nimbalance at the local clients, we design a class-aware gradient compensation\nloss and a class-semantic relation distillation loss to balance the forgetting\nof old classes and distill consistent inter-class relations across tasks. To\ntackle the global forgetting brought by the non-i.i.d class imbalance across\nclients, we propose a proxy server that selects the best old global model to\nassist the local relation distillation. Moreover, a prototype gradient-based\ncommunication mechanism is developed to protect privacy. Our model outperforms\nstate-of-the-art methods by 4.4%-15.1% in terms of average accuracy on\nrepresentative benchmark datasets.",
    "descriptor": "\nComments: CVPR 2022, the first two authors contribute equally and they are ordered alphabetically\n",
    "authors": [
      "Jiahua Dong",
      "Lixu Wang",
      "Zhen Fang",
      "Gan Sun",
      "Shichao Xu",
      "Xiao Wang",
      "Qi Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11473"
  },
  {
    "id": "arXiv:2203.11474",
    "title": "Remember Intentions: Retrospective-Memory-based Trajectory Prediction",
    "abstract": "To realize trajectory prediction, most previous methods adopt the\nparameter-based approach, which encodes all the seen past-future instance pairs\ninto model parameters. However, in this way, the model parameters come from all\nseen instances, which means a huge amount of irrelevant seen instances might\nalso involve in predicting the current situation, disturbing the performance.\nTo provide a more explicit link between the current situation and the seen\ninstances, we imitate the mechanism of retrospective memory in neuropsychology\nand propose MemoNet, an instance-based approach that predicts the movement\nintentions of agents by looking for similar scenarios in the training data. In\nMemoNet, we design a pair of memory banks to explicitly store representative\ninstances in the training set, acting as prefrontal cortex in the neural\nsystem, and a trainable memory addresser to adaptively search a current\nsituation with similar instances in the memory bank, acting like basal ganglia.\nDuring prediction, MemoNet recalls previous memory by using the memory\naddresser to index related instances in the memory bank. We further propose a\ntwo-step trajectory prediction system, where the first step is to leverage\nMemoNet to predict the destination and the second step is to fulfill the whole\ntrajectory according to the predicted destinations. Experiments show that the\nproposed MemoNet improves the FDE by 20.3%/10.2%/28.3% from the previous best\nmethod on SDD/ETH-UCY/NBA datasets. Experiments also show that our MemoNet has\nthe ability to trace back to specific instances during prediction, promoting\nmore interpretability.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Chenxin Xu",
      "Weibo Mao",
      "Wenjun Zhang",
      "Siheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11474"
  },
  {
    "id": "arXiv:2203.11476",
    "title": "Modeling speech recognition and synthesis simultaneously: Encoding and  decoding lexical and sublexical semantic information into speech with no  direct access to speech data",
    "abstract": "Human speakers encode information into raw speech which is then decoded by\nthe listeners. This complex relationship between encoding (production) and\ndecoding (perception) is often modeled separately. Here, we test how decoding\nof lexical and sublexical semantic information can emerge automatically from\nraw speech in unsupervised generative deep convolutional networks that combine\nboth the production and perception principle. We introduce, to our knowledge,\nthe most challenging objective in unsupervised lexical learning: an\nunsupervised network that must learn to assign unique representations for\nlexical items with no direct access to training data. We train several models\n(ciwGAN and fiwGAN by [1]) and test how the networks classify raw acoustic\nlexical items in the unobserved test data. Strong evidence in favor of lexical\nlearning emerges. The architecture that combines the production and perception\nprinciples is thus able to learn to decode unique information from raw acoustic\ndata in an unsupervised manner without ever accessing real training data. We\npropose a technique to explore lexical and sublexical learned representations\nin the classifier network. The results bear implications for both unsupervised\nspeech synthesis and recognition as well as for unsupervised semantic modeling\nas language models increasingly bypass text and operate from raw acoustics.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Ga\u0161per Begu\u0161",
      "Alan Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11476"
  },
  {
    "id": "arXiv:2203.11479",
    "title": "How Interest-Driven Content Creation Shapes Opportunities for Informal  Learning in Scratch: A Case Study on Novices' Use of Data Structures",
    "abstract": "Through a mixed-method analysis of data from Scratch, we examine how novices\nlearn to program with simple data structures by using community-produced\nlearning resources. First, we present a qualitative study that describes how\ncommunity-produced learning resources create archetypes that shape exploration\nand may disadvantage some with less common interests. In a second quantitative\nstudy, we find broad support for this dynamic in several hypothesis tests. Our\nfindings identify a social feedback loop that we argue could limit sources of\ninspiration, pose barriers to broadening participation, and confine learners'\nunderstanding of general concepts. We conclude by suggesting several approaches\nthat may mitigate these dynamics.",
    "descriptor": "\nComments: Ruijia Cheng, Sayamindu Dasgupta, and Benjamin Mako Hill. 2022. How Interest-Driven Content Creation Shapes Opportunities for Informal Learning in Scratch: A Case Study on Novices' Use of Data Structures. In CHI Conference on Human Factors in Computing Systems (CHI '22), April 29-May 5, 2022, New Orleans, LA, USA. ACM, New York, NY, USA, 16 pages\n",
    "authors": [
      "Ruijia Cheng",
      "Sayamindu Dasgupta",
      "Benjamin Mako Hill"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.11479"
  },
  {
    "id": "arXiv:2203.11480",
    "title": "WuDaoMM: A large-scale Multi-Modal Dataset for Pre-training models",
    "abstract": "Compared with the domain-specific model, the vision-language pre-training\nmodels (VLPMs) have shown superior performance on downstream tasks with fast\nfine-tuning process. For example, ERNIE-ViL, Oscar and UNIMO trained VLPMs with\na uniform transformers stack architecture and large amounts of image-text\npaired data, achieving remarkable results on downstream tasks such as\nimage-text reference(IR and TR), vision question answering (VQA) and image\ncaptioning (IC) etc. During the training phase, VLPMs are always fed with a\ncombination of multiple public datasets to meet the demand of large-scare\ntraining data. However, due to the unevenness of data distribution including\nsize, task type and quality, using the mixture of multiple datasets for model\ntraining can be problematic. In this work, we introduce a large-scale\nmulti-modal corpora named WuDaoMM, totally containing more than 650M image-text\npairs. Specifically, about 600 million pairs of data are collected from\nmultiple webpages in which image and caption present weak correlation, and the\nother 50 million strong-related image-text pairs are collected from some\nhigh-quality graphic websites. We also release a base version of WuDaoMM with 5\nmillion strong-correlated image-text pairs, which is sufficient to support the\ncommon cross-modal model pre-training. Besides, we trained both an\nunderstanding and a generation vision-language (VL) model to test the dataset\neffectiveness. The results show that WuDaoMM can be applied as an efficient\ndataset for VLPMs, especially for the model in text-to-image generation task.\nThe data is released at https://data.wudaoai.cn",
    "descriptor": "\nComments: 7 pages, 2 tables, 4 figures\n",
    "authors": [
      "Sha Yuan",
      "Zhao Shuai",
      "Leng Jiahong",
      "Xue Zhao",
      "Zhao Hanyu",
      "Tang Jie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11480"
  },
  {
    "id": "arXiv:2203.11481",
    "title": "Mixed Differential Privacy in Computer Vision",
    "abstract": "We introduce AdaMix, an adaptive differentially private algorithm for\ntraining deep neural network classifiers using both private and public image\ndata. While pre-training language models on large public datasets has enabled\nstrong differential privacy (DP) guarantees with minor loss of accuracy, a\nsimilar practice yields punishing trade-offs in vision tasks. A few-shot or\neven zero-shot learning baseline that ignores private data can outperform\nfine-tuning on a large private dataset. AdaMix incorporates few-shot training,\nor cross-modal zero-shot learning, on public data prior to private fine-tuning,\nto improve the trade-off. AdaMix reduces the error increase from the\nnon-private upper bound from the 167-311\\% of the baseline, on average across 6\ndatasets, to 68-92\\% depending on the desired privacy level selected by the\nuser. AdaMix tackles the trade-off arising in visual classification, whereby\nthe most privacy sensitive data, corresponding to isolated points in\nrepresentation space, are also critical for high classification accuracy. In\naddition, AdaMix comes with strong theoretical privacy guarantees and\nconvergence analysis.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Aditya Golatkar",
      "Alessandro Achille",
      "Yu-Xiang Wang",
      "Aaron Roth",
      "Michael Kearns",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.11481"
  },
  {
    "id": "arXiv:2203.11483",
    "title": "Practical Stereo Matching via Cascaded Recurrent Network with Adaptive  Correlation",
    "abstract": "With the advent of convolutional neural networks, stereo matching algorithms\nhave recently gained tremendous progress. However, it remains a great challenge\nto accurately extract disparities from real-world image pairs taken by\nconsumer-level devices like smartphones, due to practical complicating factors\nsuch as thin structures, non-ideal rectification, camera module inconsistencies\nand various hard-case scenes. In this paper, we propose a set of innovative\ndesigns to tackle the problem of practical stereo matching: 1) to better\nrecover fine depth details, we design a hierarchical network with recurrent\nrefinement to update disparities in a coarse-to-fine manner, as well as a\nstacked cascaded architecture for inference; 2) we propose an adaptive group\ncorrelation layer to mitigate the impact of erroneous rectification; 3) we\nintroduce a new synthetic dataset with special attention to difficult cases for\nbetter generalizing to real-world scenes. Our results not only rank 1st on both\nMiddlebury and ETH3D benchmarks, outperforming existing state-of-the-art\nmethods by a notable margin, but also exhibit high-quality details for\nreal-life photos, which clearly demonstrates the efficacy of our contributions.",
    "descriptor": "\nComments: This work has been accepted to CVPR2022. The project link is this https URL\n",
    "authors": [
      "Jiankun Li",
      "Peisen Wang",
      "Pengfei Xiong",
      "Tao Cai",
      "Ziwei Yan",
      "Lei Yang",
      "Jiangyu Liu",
      "Haoqiang Fan",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11483"
  },
  {
    "id": "arXiv:2203.11484",
    "title": "A Virtual Point Light Generation Method in Close-Range Area",
    "abstract": "This paper proposes a new hybrid algorithm for sampling virtual point light\n(VPL). The indirect lighting calculation of the scene is used to distribute the\nVPL reasonably. In the process of generating VPL, we divide the scene into two\nparts according to the camera position and orientation. The close-range part:\nthe part that the camera pays attention to. The distant-range part: the part\nthat the camera does not pay attention to or rarely pays attention to. For the\nclose-range part, we use a patch-based vPL sampling method to distribute the\nVPL as evenly as possible on the patch in the near-field area; for the\ndistant-range part, we use sparse instant radiosity (IR) for sampling. It turns\nout that, in contrast to conventional multiple instant radiance Compared with\nthe VPL generation algorithm, the method proposed in this paper can greatly\nimprove the quality of the final result graph when the number of VPLs is the\nsame; Under the same rendering quality, the rendering speed can be greatly\nimproved.",
    "descriptor": "",
    "authors": [
      "Shihao Jin",
      "Rui Wang",
      "Wenting Zheng",
      "Wei Hua",
      "Yuchi Huo"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.11484"
  },
  {
    "id": "arXiv:2203.11486",
    "title": "Approaches for Improving the Performance of Fake News Detection in  Bangla: Imbalance Handling and Model Stacking",
    "abstract": "Imbalanced datasets can lead to biasedness into the detection of fake news.\nIn this work, we present several strategies for resolving the imbalance issue\nfor fake news detection in Bangla with a comparative assessment of proposed\nmethodologies. Additionally, we propose a technique for improving performance\neven when the dataset is imbalanced. We applied our proposed approaches to\nBanFakeNews, a dataset developed for the purpose of detecting fake news in\nBangla comprising of 50K instances but is significantly skewed, with 97% of\nmajority instances. We obtained a 93.1% F1-score using data manipulation\nmanipulation techniques such as SMOTE, and a 79.1% F1-score using without data\nmanipulation approaches such as Stacked Generalization. Without implementing\nthese techniques, the F1-score would have been 67.6% for baseline models. We\nsee this work as an important step towards paving the way of fake news\ndetection in Bangla. By implementing these strategies the obstacles of\nimbalanced dataset can be removed and improvement in the performance can be\nachieved.",
    "descriptor": "\nComments: 12 pages, 8 figures, To appear in the Proceedings of the International Conference on 4th Industrial Revolution and Beyond (IC4IR), 10-11 December 2021, Dhaka, Bangladesh\n",
    "authors": [
      "Md Muzakker Hossain",
      "Zahin Awosaf",
      "Md. Salman Hossan Prottoy",
      "Abu Saleh Muhammod Alvy",
      "Md. Kishor Morol"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11486"
  },
  {
    "id": "arXiv:2203.11487",
    "title": "Overview and Applications of GPGPU Based Parallel Ant Colony  Optimization",
    "abstract": "Ant Colony Optimization algorithm is a magnificent heuristics technique based\non the behavior of ants. Parallel computing is a means to achieve the desired\nresults in commensurable execution time. Parallelization of Ant Colony\nOptimization is utilized to solve large and complex problems. This paper\ndiscusses a review of different parallelization approaches for Ant Colony\nOptimization and its various applications. Parallel Ant Colony Optimization has\nproved to be a successful approach for highly constrained problems such as\nrouting, scheduling, timetabling, etc. Parallelization of Ant Colony\nOptimization reduces the execution time, increases the size of the problem,\netc.",
    "descriptor": "\nComments: International Conference on Advances in Computing and Information Technology (ICACIT 2014)\n",
    "authors": [
      "Sandeep U Mane",
      "Pooja S. Lokare",
      "Harsha R. Gaikwad"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.11487"
  },
  {
    "id": "arXiv:2203.11489",
    "title": "A Note on Target Q-learning For Solving Finite MDPs with A Generative  Oracle",
    "abstract": "Q-learning with function approximation could diverge in the off-policy\nsetting and the target network is a powerful technique to address this issue.\nIn this manuscript, we examine the sample complexity of the associated target\nQ-learning algorithm in the tabular case with a generative oracle. We point out\na misleading claim in [Lee and He, 2020] and establish a tight analysis. In\nparticular, we demonstrate that the sample complexity of the target Q-learning\nalgorithm in [Lee and He, 2020] is $\\widetilde{\\mathcal O}(|\\mathcal\nS|^2|\\mathcal A|^2 (1-\\gamma)^{-5}\\varepsilon^{-2})$. Furthermore, we show that\nthis sample complexity is improved to $\\widetilde{\\mathcal O}(|\\mathcal\nS||\\mathcal A| (1-\\gamma)^{-5}\\varepsilon^{-2})$ if we can sequentially update\nall state-action pairs and $\\widetilde{\\mathcal O}(|\\mathcal S||\\mathcal A|\n(1-\\gamma)^{-4}\\varepsilon^{-2})$ if $\\gamma$ is further in $(1/2, 1)$.\nCompared with the vanilla Q-learning, our results conclude that the\nintroduction of a periodically-frozen target Q-function does not sacrifice the\nsample complexity.",
    "descriptor": "",
    "authors": [
      "Ziniu Li",
      "Tian Xu",
      "Yang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.11489"
  },
  {
    "id": "arXiv:2203.11490",
    "title": "SSD-KD: A Self-supervised Diverse Knowledge Distillation Method for  Lightweight Skin Lesion Classification Using Dermoscopic Images",
    "abstract": "Skin cancer is one of the most common types of malignancy, affecting a large\npopulation and causing a heavy economic burden worldwide. Over the last few\nyears, computer-aided diagnosis has been rapidly developed and make great\nprogress in healthcare and medical practices due to the advances in artificial\nintelligence. However, most studies in skin cancer detection keep pursuing high\nprediction accuracies without considering the limitation of computing resources\non portable devices. In this case, knowledge distillation (KD) has been proven\nas an efficient tool to help improve the adaptability of lightweight models\nunder limited resources, meanwhile keeping a high-level representation\ncapability. To bridge the gap, this study specifically proposes a novel method,\ntermed SSD-KD, that unifies diverse knowledge into a generic KD framework for\nskin diseases classification. Our method models an intra-instance relational\nfeature representation and integrates it with existing KD research. A dual\nrelational knowledge distillation architecture is self-supervisedly trained\nwhile the weighted softened outputs are also exploited to enable the student\nmodel to capture richer knowledge from the teacher model. To demonstrate the\neffectiveness of our method, we conduct experiments on ISIC 2019, a large-scale\nopen-accessed benchmark of skin diseases dermoscopic images. Experiments show\nthat our distilled lightweight model can achieve an accuracy as high as 85% for\nthe classification tasks of 8 different skin diseases with minimal parameters\nand computing requirements. Ablation studies confirm the effectiveness of our\nintra- and inter-instance relational knowledge integration strategy. Compared\nwith state-of-the-art knowledge distillation techniques, the proposed method\ndemonstrates improved performances for multi-diseases classification on the\nlarge-scale dermoscopy database.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Yongwei Wang",
      "Yuheng Wang",
      "Tim K. Lee",
      "Chunyan Miao",
      "Z. Jane Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11490"
  },
  {
    "id": "arXiv:2203.11491",
    "title": "Making Recommender Systems Forget: Learning and Unlearning for Erasable  Recommendation",
    "abstract": "Privacy laws and regulations enforce data-driven systems, e.g., recommender\nsystems, to erase the data that concern individuals. As machine learning models\npotentially memorize the training data, data erasure should also unlearn the\ndata lineage in models, which raises increasing interest in the problem of\nMachine Unlearning (MU). However, existing MU methods cannot be directly\napplied into recommendation. The basic idea of most recommender systems is\ncollaborative filtering, but existing MU methods ignore the collaborative\ninformation across users and items. In this paper, we propose a general\nerasable recommendation framework, namely LASER, which consists of Group module\nand SeqTrain module. Firstly, Group module partitions users into balanced\ngroups based on their similarity of collaborative embedding learned via\nhypergraph. Then SeqTrain module trains the model sequentially on all groups\nwith curriculum learning. Both theoretical analysis and experiments on two\nreal-world datasets demonstrate that LASER can not only achieve efficient\nunlearning, but also outperform the state-of-the-art unlearning framework in\nterms of model utility.",
    "descriptor": "",
    "authors": [
      "Yuyuan Li",
      "Xiaolin Zheng",
      "Chaochao Chen",
      "Junlin Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11491"
  },
  {
    "id": "arXiv:2203.11492",
    "title": "Exploring High-Order Structure for Robust Graph Structure Learning",
    "abstract": "Recent studies show that Graph Neural Networks (GNNs) are vulnerable to\nadversarial attack, i.e., an imperceptible structure perturbation can fool GNNs\nto make wrong predictions. Some researches explore specific properties of clean\ngraphs such as the feature smoothness to defense the attack, but the analysis\nof it has not been well-studied. In this paper, we analyze the adversarial\nattack on graphs from the perspective of feature smoothness which further\ncontributes to an efficient new adversarial defensive algorithm for GNNs. We\ndiscover that the effect of the high-order graph structure is a smoother filter\nfor processing graph structures. Intuitively, the high-order graph structure\ndenotes the path number between nodes, where larger number indicates closer\nconnection, so it naturally contributes to defense the adversarial\nperturbation. Further, we propose a novel algorithm that incorporates the\nhigh-order structural information into the graph structure learning. We perform\nexperiments on three popular benchmark datasets, Cora, Citeseer and Polblogs.\nExtensive experiments demonstrate the effectiveness of our method for defending\nagainst graph adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Guangqian Yang",
      "Yibing Zhan",
      "Jinlong Li",
      "Baosheng Yu",
      "Liu Liu",
      "Fengxiang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11492"
  },
  {
    "id": "arXiv:2203.11493",
    "title": "FrameHopper: Selective Processing of Video Frames in Detection-driven  Real-Time Video Analytics",
    "abstract": "Detection-driven real-time video analytics require continuous detection of\nobjects contained in the video frames using deep learning models like YOLOV3,\nEfficientDet. However, running these detectors on each and every frame in\nresource-constrained edge devices is computationally intensive. By taking the\ntemporal correlation between consecutive video frames into account, we note\nthat detection outputs tend to be overlapping in successive frames. Elimination\nof similar consecutive frames will lead to a negligible drop in performance\nwhile offering significant performance benefits by reducing overall computation\nand communication costs. The key technical questions are, therefore, (a) how to\nidentify which frames to be processed by the object detector, and (b) how many\nsuccessive frames can be skipped (called skip-length) once a frame is selected\nto be processed. The overall goal of the process is to keep the error due to\nskipping frames as small as possible. We introduce a novel error vs processing\nrate optimization problem with respect to the object detection task that\nbalances between the error rate and the fraction of frames filtering.\nSubsequently, we propose an off-line Reinforcement Learning (RL)-based\nalgorithm to determine these skip-lengths as a state-action policy of the RL\nagent from a recorded video and then deploy the agent online for live video\nstreams. To this end, we develop FrameHopper, an edge-cloud collaborative video\nanalytics framework, that runs a lightweight trained RL agent on the camera and\npasses filtered frames to the server where the object detection model runs for\na set of applications. We have tested our approach on a number of live videos\ncaptured from real-life scenarios and show that FrameHopper processes only a\nhandful of frames but produces detection results closer to the oracle solution\nand outperforms recent state-of-the-art solutions in most cases.",
    "descriptor": "\nComments: Accepted in The 18th International Conference on Distributed Computing in Sensor Systems (DCOSS 2022)\n",
    "authors": [
      "Md Adnan Arefeen",
      "Sumaiya Tabassum Nimi",
      "Md Yusuf Sarwar Uddin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.11493"
  },
  {
    "id": "arXiv:2203.11496",
    "title": "TransFusion: Robust LiDAR-Camera Fusion for 3D Object Detection with  Transformers",
    "abstract": "LiDAR and camera are two important sensors for 3D object detection in\nautonomous driving. Despite the increasing popularity of sensor fusion in this\nfield, the robustness against inferior image conditions, e.g., bad illumination\nand sensor misalignment, is under-explored. Existing fusion methods are easily\naffected by such conditions, mainly due to a hard association of LiDAR points\nand image pixels, established by calibration matrices. We propose TransFusion,\na robust solution to LiDAR-camera fusion with a soft-association mechanism to\nhandle inferior image conditions. Specifically, our TransFusion consists of\nconvolutional backbones and a detection head based on a transformer decoder.\nThe first layer of the decoder predicts initial bounding boxes from a LiDAR\npoint cloud using a sparse set of object queries, and its second decoder layer\nadaptively fuses the object queries with useful image features, leveraging both\nspatial and contextual relationships. The attention mechanism of the\ntransformer enables our model to adaptively determine where and what\ninformation should be taken from the image, leading to a robust and effective\nfusion strategy. We additionally design an image-guided query initialization\nstrategy to deal with objects that are difficult to detect in point clouds.\nTransFusion achieves state-of-the-art performance on large-scale datasets. We\nprovide extensive experiments to demonstrate its robustness against degenerated\nimage quality and calibration errors. We also extend the proposed method to the\n3D tracking task and achieve the 1st place in the leaderboard of nuScenes\ntracking, showing its effectiveness and generalization capability.",
    "descriptor": "\nComments: Accepted to CVPR2022; Code at \\url{this https URL}; Based on this work, we achieve the 1st place in the leaderboard of nuScenes tracking\n",
    "authors": [
      "Xuyang Bai",
      "Zeyu Hu",
      "Xinge Zhu",
      "Qingqiu Huang",
      "Yilun Chen",
      "Hongbo Fu",
      "Chiew-Lan Tai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11496"
  },
  {
    "id": "arXiv:2203.11499",
    "title": "Residual-Guided Non-Intrusive Speech Quality Assessment",
    "abstract": "This paper proposes an approach to improve Non-Intrusive speech quality\nassessment(NI-SQA) based on the residuals between impaired speech and enhanced\nspeech. The difficulty in our task is particularly lack of information, for\nwhich the corresponding reference speech is absent. We generate an enhanced\nspeech on the impaired speech to compensate for the absence of the reference\naudio, then pair the information of residuals with the impaired speech.\nCompared to feeding the impaired speech directly into the model, residuals\ncould bring some extra helpful information from the contrast in enhancement.\nThe human ear is sensitive to certain noises but different to deep learning\nmodel. Causing the Mean Opinion Score(MOS) the model predicted is not enough to\nfit our subjective sensitive well and causes deviation. These residuals have a\nclose relationship to reference speech and then improve the ability of the deep\nlearning models to predict MOS. During the training phase, experimental results\ndemonstrate that paired with residuals can quickly obtain better evaluation\nindicators under the same conditions. Furthermore, our final results improved\n31.3 percent and 14.1 percent, respectively, in PLCC and RMSE.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Zhe Ye",
      "Jiahao Chen",
      "Diqun Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11499"
  },
  {
    "id": "arXiv:2203.11506",
    "title": "Rebalanced Siamese Contrastive Mining for Long-Tailed Recognition",
    "abstract": "Deep neural networks perform poorly on heavily class-imbalanced datasets.\nGiven the promising performance of contrastive learning, we propose\n$\\mathbf{Re}$balanced $\\mathbf{S}$iamese $\\mathbf{Co}$ntrastive\n$\\mathbf{m}$ining ( $\\mathbf{ResCom}$) to tackle imbalanced recognition. Based\non the mathematical analysis and simulation results, we claim that supervised\ncontrastive learning suffers a dual class-imbalance problem at both the\noriginal batch and Siamese batch levels, which is more serious than long-tailed\nclassification learning. In this paper, at the original batch level, we\nintroduce a class-balanced supervised contrastive loss to assign adaptive\nweights for different classes. At the Siamese batch level, we present a\nclass-balanced queue, which maintains the same number of keys for all classes.\nFurthermore, we note that the contrastive loss gradient with respect to the\ncontrastive logits can be decoupled into the positives and negatives, and easy\npositives and easy negatives will make the contrastive gradient vanish. We\npropose supervised hard positive and negative pairs mining to pick up\ninformative pairs for contrastive computation and improve representation\nlearning. Finally, to approximately maximize the mutual information between the\ntwo views, we propose Siamese Balanced Softmax and joint it with the\ncontrastive loss for one-stage training. ResCom outperforms the previous\nmethods by large margins on multiple long-tailed recognition benchmarks. Our\ncode will be made publicly available at:\nhttps://github.com/dvlab-research/ResCom.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Zhisheng Zhong",
      "Jiequan Cui",
      "Eric Lo",
      "Zeming Li",
      "Jian Sun",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11506"
  },
  {
    "id": "arXiv:2203.11509",
    "title": "Unsupervised Deraining: Where Contrastive Learning Meets Self-similarity",
    "abstract": "Image deraining is a typical low-level image restoration task, which aims at\ndecomposing the rainy image into two distinguishable layers: the clean image\nlayer and the rain layer. Most of the existing learning-based deraining methods\nare supervisedly trained on synthetic rainy-clean pairs. The domain gap between\nthe synthetic and real rains makes them less generalized to different real\nrainy scenes. Moreover, the existing methods mainly utilize the property of the\ntwo layers independently, while few of them have considered the mutually\nexclusive relationship between the two layers. In this work, we propose a novel\nnon-local contrastive learning (NLCL) method for unsupervised image deraining.\nConsequently, we not only utilize the intrinsic self-similarity property within\nsamples but also the mutually exclusive property between the two layers, so as\nto better differ the rain layer from the clean image. Specifically, the\nnon-local self-similarity image layer patches as the positives are pulled\ntogether and similar rain layer patches as the negatives are pushed away. Thus\nthe similar positive/negative samples that are close in the original space\nbenefit us to enrich more discriminative representation. Apart from the\nself-similarity sampling strategy, we analyze how to choose an appropriate\nfeature encoder in NLCL. Extensive experiments on different real rainy datasets\ndemonstrate that the proposed method obtains state-of-the-art performance in\nreal deraining.",
    "descriptor": "\nComments: 10 pages, 10 figures, accept to 2022CVPR\n",
    "authors": [
      "Ye Yuntong",
      "Yu Changfeng",
      "Chang Yi",
      "Zhu Lin",
      "Zhao Xile",
      "Yan Luxin",
      "Tian Yonghong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11509"
  },
  {
    "id": "arXiv:2203.11512",
    "title": "Gradient Vector Fields of Discrete Morse Functions are Minimum Spanning  Forests",
    "abstract": "In this paper, we prove that discrete Morse functions are equivalent to\nsimplicial stacks under reasonable constraints. We also show that, as in\nDiscrete Morse Theory, we can see the GVF of a simplicial stack (seen as a\ndiscrete Morse function) as the only relevant information we should consider.\nLast, but not least, we prove that the Minimum Spanning Forest on the dual\ngraph of a simplicial stack (or a discrete Morse function) is equal to the GVF\nof the initial function. In other words, the GVF of a discrete Morse function\nis related to a classic combinatorial minimization problem. This paper is the\nsequel of a sequence of papers showing that strong relations exist between\ndifferent domains: Topology, Discrete Morse Theory, Topological Data Analysis\nand Mathematical Morphology.",
    "descriptor": "",
    "authors": [
      "Nicolas Boutry",
      "Laurent Najman"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Algebraic Topology (math.AT)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.11512"
  },
  {
    "id": "arXiv:2203.11519",
    "title": "Comparing the expressiveness of the $\u03c0$-calculus and CCS",
    "abstract": "This paper shows that the $\\pi$-calculus with implicit matching is no more\nexpressive than CCS$\\gamma$, a variant of CCS in which the result of a\nsynchronisation of two actions is itself an action subject to relabelling or\nrestriction, rather than the silent action $\\tau$. This is done by exhibiting a\ncompositional translation from the $\\pi$-calculus with implicit matching to\nCCS$\\gamma$ that is valid up to strong barbed bisimilarity. The full\n$\\pi$-calculus can be similarly expressed in CCS$\\gamma$ enriched with the\ntriggering operation of Meije. I also show that these results cannot be\nrecreated with CCS in the role of CCS$\\gamma$, not even up to reduction\nequivalence, and not even for the asynchronous $\\pi$-calculus without\nrestriction or replication. Finally I observe that CCS cannot be encoded in the\n$\\pi$-calculus.",
    "descriptor": "\nComments: Extended abstract to appear in Proc. ESOP'22\n",
    "authors": [
      "Rob van Glabbeek"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.11519"
  },
  {
    "id": "arXiv:2203.11520",
    "title": "SoK: Preventing Transaction Reordering Manipulations in Decentralized  Finance",
    "abstract": "User transactions on Ethereum's peer-to-peer network are at risk of being\nattacked. The smart contracts building decentralized finance (DeFi) have\nintroduced a new transaction ordering dependency to the Ethereum blockchain. As\na result, attackers can profit from front- and back-running transactions.\nMultiple approaches to mitigate transaction reordering manipulations have\nsurfaced recently. However, the success of individual approaches in mitigating\nsuch attacks and their impact on the entire blockchain remains largely\nunstudied. In this systematization of knowledge (SoK), we categorize and\nanalyze state-of-the-art transaction reordering manipulation mitigation\nschemes. Instead of restricting our analysis to a scheme's success at\npreventing transaction reordering attacks, we evaluate its full impact on the\nblockchain. Therefore, we are able to provide a complete picture of the\nstrengths and weaknesses of current mitigation schemes. We find that currently\nno scheme fully meets all the demands of the blockchain ecosystem. In fact, all\napproaches demonstrate unsatisfactory performance in at least one area relevant\nto the blockchain ecosystem.",
    "descriptor": "",
    "authors": [
      "Lioba Heimbach",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.11520"
  },
  {
    "id": "arXiv:2203.11521",
    "title": "The neighbour sum distinguishing edge-weighting with local constraints",
    "abstract": "A $k$-edge-weighting of $G$ is a mapping $\\omega:E(G)\\longrightarrow\n\\{1,\\ldots,k\\}$. The edge-weighting naturally induces a vertex colouring\n$\\sigma_\\omega:V(G)\\longrightarrow \\mathbb{N}$ given by\n$\\sigma_{\\omega}(v)=\\sum_{u\\in N_G(v)}\\omega(vu)$ for every $v\\in V(G)$. The\nedge-weighting $\\omega$ is neighbour sum distinguishing if it yields a proper\nvertex colouring $\\sigma_{\\omega}$, i.e., $\\sigma_{\\omega}(u)\\neq\n\\sigma_{\\omega}(v)$ for every edge $uv$ of $G$.We investigate a neighbour sum\ndistinguishing edge-weighting with local constraints, namely, we assume that\nthe set of edges incident to a vertex of large degree is not monochromatic. The\ngraph is nice if it has no components isomorphic to $K_2$. We prove that every\nnice graph with maximum degree at most~5 admits a neighbour sum distinguishing\n$(\\Delta(G)+2)$-edge-weighting such that all the vertices of degree at least~2\nare incident with at least two edges of different weights. Furthermore, we\nprove that every nice graph admits a neighbour sum distinguishing\n$7$-edge-weighting such that all the vertices of degree at least~6 are incident\nwith at least two edges of different weights. Finally, we show that nice\nbipartite graphs admit a neighbour sum distinguishing $6$-edge-weighting such\nthat all the vertices of degree at least~2 are incident with at least two edges\nof different weights.",
    "descriptor": "",
    "authors": [
      "Antoine Dailly",
      "El\u017cbieta Sidorowicz"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.11521"
  },
  {
    "id": "arXiv:2203.11522",
    "title": "Early Adapting to Trends: Self-Stabilizing Information Spread using  Passive Communication",
    "abstract": "How to efficiently and reliably spread information in a system is one of the\nmost fundamental problems in distributed computing. Recently, inspired by\nbiological scenarios, several works focused on identifying the minimal\ncommunication resources necessary to spread information under faulty\nconditions. Here we study the self-stabilizing bit-dissemination problem,\nintroduced by Boczkowski, Korman, and Natale in [SODA 2017]. The problem\nconsiders a fully-connected network of n agents, with a binary world of\nopinions, one of which is called correct. At any given time, each agent holds\nan opinion bit as its public output. The population contains a source agent\nwhich knows which opinion is correct. This agent adopts the correct opinion and\nremains with it throughout the execution. We consider the basic PULL model of\ncommunication, in which each agent observes relatively few randomly chosen\nagents in each round. The goal of the non-source agents is to quickly converge\non the correct opinion, despite having an arbitrary initial configuration,\ni.e., in a self-stabilizing manner. Once the population converges on the\ncorrect opinion, it should remain with it forever. Motivated by biological\nscenarios in which animals observe and react to the behavior of others, we\nfocus on the extremely constrained model of passive communication, which\nassumes that when observing another agent the only information that can be\nextracted is the opinion bit of that agent. We prove that this problem can be\nsolved in a poly-logarithmic in n number of rounds with high probability, while\nsampling a logarithmic number of agents at each round. Previous works solved\nthis problem faster and using fewer samples, but they did that by decoupling\nthe messages sent by agents from their output opinion, and hence do not fit the\nframework of passive communication. Moreover, these works use complex recursive\nalgorithms with refined clocks that are unlikely to be used by biological\nentities. In contrast, our proposed algorithm has a natural appeal as it is\nbased on letting agents estimate the current tendency direction of the\ndynamics, and then adapt to the emerging trend.",
    "descriptor": "",
    "authors": [
      "Amos Korman",
      "Robin Vacus"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.11522"
  },
  {
    "id": "arXiv:2203.11526",
    "title": "Action Candidate Driven Clipped Double Q-learning for Discrete and  Continuous Action Tasks",
    "abstract": "Double Q-learning is a popular reinforcement learning algorithm in Markov\ndecision process (MDP) problems. Clipped Double Q-learning, as an effective\nvariant of Double Q-learning, employs the clipped double estimator to\napproximate the maximum expected action value. Due to the underestimation bias\nof the clipped double estimator, the performance of clipped Double Q-learning\nmay be degraded in some stochastic environments. In this paper, in order to\nreduce the underestimation bias, we propose an action candidate-based clipped\ndouble estimator for Double Q-learning. Specifically, we first select a set of\nelite action candidates with high action values from one set of estimators.\nThen, among these candidates, we choose the highest valued action from the\nother set of estimators. Finally, we use the maximum value in the second set of\nestimators to clip the action value of the chosen action in the first set of\nestimators and the clipped value is used for approximating the maximum expected\naction value. Theoretically, the underestimation bias in our clipped Double\nQ-learning decays monotonically as the number of action candidates decreases.\nMoreover, the number of action candidates controls the trade-off between the\noverestimation and underestimation biases. In addition, we also extend our\nclipped Double Q-learning to continuous action tasks via approximating the\nelite continuous action candidates. We empirically verify that our algorithm\ncan more accurately estimate the maximum expected action value on some toy\nenvironments and yield good performance on several benchmark problems.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2105.00704\n",
    "authors": [
      "Haobo Jiang",
      "Jin Xie",
      "Jian Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11526"
  },
  {
    "id": "arXiv:2203.11532",
    "title": "Quickstrom: Property Based Acceptance Testing with LTL Specifications",
    "abstract": "We present Quickstrom, a property-based testing system for acceptance testing\nof interactive applications. Using Quickstrom, programmers can specify the\nbehaviour of web applications as properties in our testing-oriented dialect of\nLinear Temporal Logic (LTL) called QuickLTL, and then automatically test their\napplication against the given specification with hundreds of automatically\ngenerated interactions. QuickLTL extends existing finite variants of LTL for\nthe testing use-case, determining likely outcomes from partial traces whose\nminimum length is itself determined by the LTL formula. This temporal logic is\nembedded in our specification language, Specstrom, which is designed to be\napproachable to web programmers, expressive for writing specifications, and\neasy to analyse. Because Quickstrom tests only user-facing behaviour, it is\nagnostic to the implementation language of the system under test. We therefore\nformally specify and test many implementations of the popular TodoMVC\nbenchmark, used for evaluation and comparison across various web frontend\nframeworks and languages. Our tests uncovered bugs in almost half of the\navailable implementations.",
    "descriptor": "\nComments: 13 pages, this is a technical report of a paper to appear at Programming Languages Design and Implementation (PLDI 2022)\n",
    "authors": [
      "Liam O'Connor",
      "Oskar Wickstr\u00f6m"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.11532"
  },
  {
    "id": "arXiv:2203.11534",
    "title": "Multiresolution-analysis for stochastic hyperbolic conservation laws",
    "abstract": "A multiresolution analysis for solving stochastic conservation laws is\nproposed. Using a novel adaptation strategy and a higher dimensional\ndeterministic problem, a discontinuous Galerkin (DG) solver is derived. A\nmultiresolution analysis of the DG spaces for the proposed adaptation strategy\nis presented. Numerical results show that in the case of general stochastic\ndistributions the performance of the DG solver is significantly improved by the\nnovel adaptive strategy. The gain in efficiency is validated in computational\nexperiments.",
    "descriptor": "",
    "authors": [
      "Michael Herty",
      "Adrian Kolb",
      "Siegfried M\u00fcller"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.11534"
  },
  {
    "id": "arXiv:2203.11537",
    "title": "Convolutional Neural Network-based Efficient Dense Point Cloud  Generation using Unsigned Distance Fields",
    "abstract": "Dense point cloud generation from a sparse or incomplete point cloud is a\ncrucial and challenging problem in 3D computer vision and computer graphics. So\nfar, the existing methods are either computationally too expensive, suffer from\nlimited resolution, or both. In addition, some methods are strictly limited to\nwatertight surfaces -- another major obstacle for a number of applications. To\naddress these issues, we propose a lightweight Convolutional Neural Network\nthat learns and predicts the unsigned distance field for arbitrary 3D shapes\nfor dense point cloud generation using the recently emerged concept of implicit\nfunction learning. Experiments demonstrate that the proposed architecture\nachieves slightly better quality results than the state of the art with 87%\nless model parameters and 40% less GPU memory usage.",
    "descriptor": "",
    "authors": [
      "Abol Basher",
      "Jani Boutellier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11537"
  },
  {
    "id": "arXiv:2203.11538",
    "title": "Isoparametric singularity extraction technique for 3D potential problems  in BEM",
    "abstract": "To solve boundary integral equations for potential problems using collocation\nBoundary Element Method (BEM) on smooth curved 3D geometries, an analytical\nsingularity extraction technique is employed. By adopting the isoparametric\napproach, curved geometries that are represented by mapped rectangles or\ntriangles from the parametric domain are considered. The singularity extraction\non the governing singular integrals can be performed either as an operation of\nsubtraction or division, each having some advantages. A particular series\nexpansion of a singular kernel about a source point is investigated. The series\nin the intrinsic coordinates consists of functions of a type $R^p x^q y^r$,\nwhere $R$ is a square root of a quadratic bivariate homogeneous polynomial,\ncorresponding to the first fundamental form of a smooth surface, and $p,q,r$\nare integers, satisfying $p\\leq -1$ and $q,r \\geq 0$. By extracting more terms\nfrom the series expansion of the singular kernel, the smoothness of the\nregularized kernel at the source point can be increased. Analytical formulae\nfor integrals of such terms are obtained from antiderivatives of $R^p x^q y^r$,\nusing recurrence formulae, and by evaluating them at the edges of rectangular\nor triangular parametric domains. Numerical tests demonstrate that the\nsingularity extraction technique can be a useful prerequisite for a numerical\nquadrature scheme to obtain accurate evaluations of the governing singular\nintegrals in 3D collocation BEM.",
    "descriptor": "",
    "authors": [
      "Tadej Kanduc"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11538"
  },
  {
    "id": "arXiv:2203.11540",
    "title": "Scale-out Systolic Arrays",
    "abstract": "Multi-pod systolic arrays are emerging as the architecture of choice in DNN\ninference accelerators. Despite their potential, designing multi-pod systolic\narrays to maximize effective throughput/Watt (i.e., throughput/Watt adjusted\nwhen accounting for array utilization) poses a unique set of challenges. In\nthis work, we study three key pillars in multi-pod systolic array designs,\nnamely array granularity, interconnect, and tiling. We identify optimal array\ngranularity across workloads and show that state-of-the-art commercial\naccelerators use suboptimal array sizes for single-tenancy workloads. We, then\nevaluate the bandwidth/latency trade-offs in interconnects and show that\nButterfly networks offer a scalable topology for accelerators with a large\nnumber of pods. Finally, we introduce a novel data tiling scheme with custom\npartition size to maximize utilization in optimally sized pods. We propose\nScale-out Systolic Arrays, a multi-pod inference accelerator for both single-\nand multi-tenancy based on these three pillars. We show that SOSA exhibits\nscaling of up to 600 TeraOps/s in effective throughput for state-of-the-art DNN\ninference workloads, and outperforms state-of-the-art multi-pod accelerators by\na factor of 1.5x.",
    "descriptor": "",
    "authors": [
      "Ahmet Caner Y\u00fcz\u00fcg\u00fcler",
      "Canberk S\u00f6nmez",
      "Mario Drumond",
      "Yunho Oh",
      "Babak Falsafi",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11540"
  },
  {
    "id": "arXiv:2203.11542",
    "title": "Mask Usage Recognition using Vision Transformer with Transfer Learning  and Data Augmentation",
    "abstract": "The COVID-19 pandemic has disrupted various levels of society. The use of\nmasks is essential in preventing the spread of COVID-19 by identifying an image\nof a person using a mask. Although only 23.1% of people use masks correctly,\nArtificial Neural Networks (ANN) can help classify the use of good masks to\nhelp slow the spread of the Covid-19 virus. However, it requires a large\ndataset to train an ANN that can classify the use of masks correctly.\nMaskedFace-Net is a suitable dataset consisting of 137016 digital images with 4\nclass labels, namely Mask, Mask Chin, Mask Mouth Chin, and Mask Nose Mouth.\nMask classification training utilizes Vision Transformers (ViT) architecture\nwith transfer learning method using pre-trained weights on ImageNet-21k, with\nrandom augmentation. In addition, the hyper-parameters of training of 20\nepochs, an Stochastic Gradient Descent (SGD) optimizer with a learning rate of\n0.03, a batch size of 64, a Gaussian Cumulative Distribution (GeLU) activation\nfunction, and a Cross-Entropy loss function are used to be applied on the\ntraining of three architectures of ViT, namely Base-16, Large-16, and Huge-14.\nFurthermore, comparisons of with and without augmentation and transfer learning\nare conducted. This study found that the best classification is transfer\nlearning and augmentation using ViT Huge-14. Using this method on\nMaskedFace-Net dataset, the research reaches an accuracy of 0.9601 on training\ndata, 0.9412 on validation data, and 0.9534 on test data. This research shows\nthat training the ViT model with data augmentation and transfer learning\nimproves classification of the mask usage, even better than convolutional-based\nResidual Network (ResNet).",
    "descriptor": "",
    "authors": [
      "Hensel Donato Jahja",
      "Novanto Yudistira",
      "Sutrisno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11542"
  },
  {
    "id": "arXiv:2203.11544",
    "title": "Visuo-Haptic Object Perception for Robots: An Overview",
    "abstract": "This article summarizes the current state of multimodal object perception for\nrobotic applications. It covers aspects of biological inspiration, sensor\ntechnologies, data sets, and sensory data processing for object recognition and\ngrasping. Firstly, the biological basis of multimodal object perception is\noutlined. Then the sensing technologies and data collection strategies are\ndiscussed. Next, an introduction to the main computational aspects is\npresented, highlighting a few representative articles for each main application\narea, including object recognition, object manipulation and grasping, texture\nrecognition, and transfer learning. Finally, informed by the current\nadvancements in each area, this article outlines promising new research\ndirections.",
    "descriptor": "\nComments: Submitted to \"Autonomous Robots\"\n",
    "authors": [
      "Nicol\u00e1s Navarro-Guerrero",
      "Sibel Toprak",
      "Josip Josifovski",
      "Lorenzo Jamone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11544"
  },
  {
    "id": "arXiv:2203.11547",
    "title": "Explainability in reinforcement learning: perspective and position",
    "abstract": "Artificial intelligence (AI) has been embedded into many aspects of people's\ndaily lives and it has become normal for people to have AI make decisions for\nthem. Reinforcement learning (RL) models increase the space of solvable\nproblems with respect to other machine learning paradigms. Some of the most\ninteresting applications are in situations with non-differentiable expected\nreward function, operating in unknown or underdefined environment, as well as\nfor algorithmic discovery that surpasses performance of any teacher, whereby\nagent learns from experimental experience through simple feedback. The range of\napplications and their social impact is vast, just to name a few: genomics,\ngame-playing (chess, Go, etc.), general optimization, financial investment,\ngovernmental policies, self-driving cars, recommendation systems, etc. It is\ntherefore essential to improve the trust and transparency of RL-based systems\nthrough explanations. Most articles dealing with explainability in artificial\nintelligence provide methods that concern supervised learning and there are\nvery few articles dealing with this in the area of RL. The reasons for this are\nthe credit assignment problem, delayed rewards, and the inability to assume\nthat data is independently and identically distributed (i.i.d.). This position\npaper attempts to give a systematic overview of existing methods in the\nexplainable RL area and propose a novel unified taxonomy, building and\nexpanding on the existing ones. The position section describes pragmatic\naspects of how explainability can be observed. The gap between the parties\nreceiving and generating the explanation is especially emphasized. To reduce\nthe gap and achieve honesty and truthfulness of explanations, we set up three\npillars: proactivity, risk attitudes, and epistemological constraints. To this\nend, we illustrate our proposal on simple variants of the shortest path\nproblem.",
    "descriptor": "\nComments: 18 pages, 4 figures, 76 references. keywords: explainable artificial intelligence, explainable reinforcement learning, XRL, XAI, risk attitudes, epistemic AI, proactivity\n",
    "authors": [
      "Agneza Krajna",
      "Mario Brcic",
      "Tomislav Lipic",
      "Juraj Doncevic"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.11547"
  },
  {
    "id": "arXiv:2203.11550",
    "title": "Running Time Analysis of the Non-dominated Sorting Genetic Algorithm II  (NSGA-II) using Binary or Stochastic Tournament Selection",
    "abstract": "Evolutionary algorithms (EAs) have been widely used to solve multi-objective\noptimization problems, and have become the most popular tool. However, the\ntheoretical foundation of multi-objective EAs (MOEAs), especially the essential\ntheoretical aspect, i.e., running time analysis, has been still largely\nunderdeveloped. The few existing theoretical works mainly considered simple\nMOEAs, while the non-dominated sorting genetic algorithm II (NSGA-II), probably\nthe most influential MOEA, has not been analyzed except for a very recent work\nconsidering a simplified variant without crossover. In this paper, we present a\nrunning time analysis of the standard NSGA-II for solving LOTZ, OneMinMax and\nCOCZ, the three commonly used bi-objective optimization problems. Specifically,\nwe prove that the expected running time (i.e., number of fitness evaluations)\nis $O(n^3)$ for LOTZ, and $O(n^2\\log n)$ for OneMinMax and COCZ, which is\nsurprisingly as same as that of the previously analyzed simple MOEAs, GSEMO and\nSEMO. Next, we introduce a new parent selection strategy, stochastic tournament\nselection (i.e., $k$ tournament selection where $k$ is uniformly sampled at\nrandom), to replace the binary tournament selection strategy of NSGA-II,\ndecreasing the required expected running time to $O(n^2)$ for all the three\nproblems. Experiments are also conducted, suggesting that the derived running\ntime upper bounds are tight for LOTZ, and almost tight for OneMinMax and COCZ.",
    "descriptor": "",
    "authors": [
      "Chao Bian",
      "Chao Qian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.11550"
  },
  {
    "id": "arXiv:2203.11552",
    "title": "Factual Consistency of Multilingual Pretrained Language Models",
    "abstract": "Pretrained language models can be queried for factual knowledge, with\npotential applications in knowledge base acquisition and tasks that require\ninference. However, for that, we need to know how reliable this knowledge is,\nand recent work has shown that monolingual English language models lack\nconsistency when predicting factual knowledge, that is, they fill-in-the-blank\ndifferently for paraphrases describing the same fact. In this paper, we extend\nthe analysis of consistency to a multilingual setting. We introduce a resource,\nmParaRel, and investigate (i) whether multilingual language models such as\nmBERT and XLM-R are more consistent than their monolingual counterparts; and\n(ii) if such models are equally consistent across languages. We find that mBERT\nis as inconsistent as English BERT in English paraphrases, but that both mBERT\nand XLM-R exhibit a high degree of inconsistency in English and even more so\nfor all the other 45 languages.",
    "descriptor": "",
    "authors": [
      "Constanza Fierro",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11552"
  },
  {
    "id": "arXiv:2203.11555",
    "title": "Gradient flows and randomised thresholding: sparse inversion and  classification",
    "abstract": "Sparse inversion and classification problems are ubiquitous in modern data\nscience and imaging. They are often formulated as non-smooth minimisation\nproblems. In sparse inversion, we minimise, e.g., the sum of a data fidelity\nterm and an L1/LASSO regulariser. In classification, we consider, e.g., the sum\nof a data fidelity term and a non-smooth Ginzburg--Landau energy. Standard\n(sub)gradient descent methods have shown to be inefficient when approaching\nsuch problems. Splitting techniques are much more useful: here, the target\nfunction is partitioned into a sum of two subtarget functions -- each of which\ncan be efficiently optimised. Splitting proceeds by performing optimisation\nsteps alternately with respect to each of the two subtarget functions.\nIn this work, we study splitting from a stochastic continuous-time\nperspective. Indeed, we define a differential inclusion that follows one of the\ntwo subtarget function's negative subgradient at each point in time. The choice\nof the subtarget function is controlled by a binary continuous-time Markov\nprocess. The resulting dynamical system is a stochastic approximation of the\nunderlying subgradient flow. We investigate this stochastic approximation for\nan L1-regularised sparse inversion flow and for a discrete Allen-Cahn equation\nminimising a Ginzburg--Landau energy. In both cases, we study the longtime\nbehaviour of the stochastic dynamical system and its ability to approximate the\nunderlying subgradient flow at any accuracy. We illustrate our theoretical\nfindings in a simple sparse estimation problem and also in a low-dimensional\nclassification problem.",
    "descriptor": "",
    "authors": [
      "Jonas Latz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.11555"
  },
  {
    "id": "arXiv:2203.11556",
    "title": "VQ-Flows: Vector Quantized Local Normalizing Flows",
    "abstract": "Normalizing flows provide an elegant approach to generative modeling that\nallows for efficient sampling and exact density evaluation of unknown data\ndistributions. However, current techniques have significant limitations in\ntheir expressivity when the data distribution is supported on a low-dimensional\nmanifold or has a non-trivial topology. We introduce a novel statistical\nframework for learning a mixture of local normalizing flows as \"chart maps\"\nover the data manifold. Our framework augments the expressivity of recent\napproaches while preserving the signature property of normalizing flows, that\nthey admit exact density evaluation. We learn a suitable atlas of charts for\nthe data manifold via a vector quantized auto-encoder (VQ-AE) and the\ndistributions over them using a conditional flow. We validate experimentally\nthat our probabilistic framework enables existing approaches to better model\ndata distributions over complex manifolds.",
    "descriptor": "",
    "authors": [
      "Sahil Sidheekh",
      "Chris B. Dock",
      "Tushar Jain",
      "Radu Balan",
      "Maneesh K. Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.11556"
  },
  {
    "id": "arXiv:2203.11559",
    "title": "Frugal Learning of Virtual Exemplars for Label-Efficient Satellite Image  Change Detection",
    "abstract": "In this paper, we devise a novel interactive satellite image change detection\nalgorithm based on active learning. The proposed framework is iterative and\nrelies on a question and answer model which asks the oracle (user) questions\nabout the most informative display (subset of critical images), and according\nto the user's responses, updates change detections. The contribution of our\nframework resides in a novel display model which selects the most\nrepresentative and diverse virtual exemplars that adversely challenge the\nlearned change detection functions, thereby leading to highly discriminating\nfunctions in the subsequent iterations of active learning. Extensive\nexperiments, conducted on the challenging task of interactive satellite image\nchange detection, show the superiority of the proposed virtual display model\nagainst the related work.",
    "descriptor": "",
    "authors": [
      "Hichem Sahbi",
      "Sebastien Deschamps"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11559"
  },
  {
    "id": "arXiv:2203.11561",
    "title": "Improved Differentially Private Euclidean Distance Approximation",
    "abstract": "This work shows how to privately and more accurately estimate Euclidean\ndistance between pairs of vectors. Input vectors $x$ and $y$ are mapped to\ndifferentially private sketches $x'$ and $y'$, from which one can estimate the\ndistance between $x$ and $y$. Our estimator relies on the Sparser\nJohnson-Lindenstrauss constructions by Kane \\& Nelson (Journal of the ACM\n2014), which for any $0<\\alpha,\\beta<1/2$ have optimal output dimension\n$k=\\Theta(\\alpha^{-2}\\log(1/\\beta))$ and sparsity\n$s=O(\\alpha^{-1}\\log(1/\\beta))$. We combine the constructions of Kane \\& Nelson\nwith either the Laplace or the Gaussian mechanism from the differential privacy\nliterature, depending on the privacy parameters $\\varepsilon$ and $\\delta$. We\nalso suggest a differentially private version of Fast Johnson-Lindenstrauss\nTransform (FJLT) by Ailon \\& Chazelle (SIAM Journal of Computing 2009) which\noffers a tradeoff in speed for variance for certain parameters. We answer an\nopen question by Kenthapadi et al.~(Journal of Privacy and Confidentiality\n2013) by analyzing the privacy and utility guarantees of an estimator for\nEuclidean distance, relying on Laplacian rather than Gaussian noise. We prove\nthat the Laplace mechanism yields lower variance than the Gaussian mechanism\nwhenever $\\delta<\\beta^{O(1/\\alpha)}$. Thus, our work poses an improvement over\nthe work of Kenthapadi et al.~by giving a more efficient estimator with lower\nvariance for sufficiently small $\\delta$. Our sketch also achieves \\emph{pure}\ndifferential privacy as a neat side-effect of the Laplace mechanism rather than\nthe \\emph{approximate} differential privacy guarantee of the Gaussian\nmechanism, which may not be sufficiently strong for some settings.",
    "descriptor": "",
    "authors": [
      "Nina Mesing Stausholm"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.11561"
  },
  {
    "id": "arXiv:2203.11562",
    "title": "A Text-to-Speech Pipeline, Evaluation Methodology, and Initial  Fine-Tuning Results for Child Speech Synthesis",
    "abstract": "Speech synthesis has come a long way as current text-to-speech (TTS) models\ncan now generate natural human-sounding speech. However, most of the TTS\nresearch focuses on using adult speech data and there has been very limited\nwork done on child speech synthesis. This study developed and validated a\ntraining pipeline for fine-tuning state-of-the-art (SOTA) neural TTS models\nusing child speech datasets. This approach adopts a multispeaker TTS retuning\nworkflow to provide a transfer-learning pipeline. A publicly available child\nspeech dataset was cleaned to provide a smaller subset of approximately 19\nhours, which formed the basis of our fine-tuning experiments. Both subjective\nand objective evaluations were performed using a pretrained MOSNet for\nobjective evaluation and a novel subjective framework for mean opinion score\n(MOS) evaluations. Subjective evaluations achieved the MOS of 3.92 for speech\nintelligibility, 3.85 for voice naturalness, and 3.96 for voice consistency.\nObjective evaluation using a pretrained MOSNet showed a strong correlation\nbetween real and synthetic child voices. The final trained model was able to\nsynthesize child-like speech from reference audio samples as short as 5\nseconds.",
    "descriptor": "\nComments: Submitted to IEEE ACCESS\n",
    "authors": [
      "Rishabh Jain",
      "Mariam Yiwere",
      "Dan Bigioi",
      "Peter Corcoran",
      "Horia Cucu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11562"
  },
  {
    "id": "arXiv:2203.11564",
    "title": "Reinforcement-based frugal learning for satellite image change detection",
    "abstract": "In this paper, we introduce a novel interactive satellite image change\ndetection algorithm based on active learning. The proposed approach is\niterative and asks the user (oracle) questions about the targeted changes and\naccording to the oracle's responses updates change detections. We consider a\nprobabilistic framework which assigns to each unlabeled sample a relevance\nmeasure modeling how critical is that sample when training change detection\nfunctions. These relevance measures are obtained by minimizing an objective\nfunction mixing diversity, representativity and uncertainty. These criteria\nwhen combined allow exploring different data modes and also refining change\ndetections. To further explore the potential of this objective function, we\nconsider a reinforcement learning approach that finds the best combination of\ndiversity, representativity and uncertainty, through active learning\niterations, leading to better generalization as corroborated through\nexperiments in interactive satellite image change detection.",
    "descriptor": "",
    "authors": [
      "Sebastien Deschamps",
      "Hichem Sahbi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11564"
  },
  {
    "id": "arXiv:2203.11567",
    "title": "The b-symbol weight distribution of irreducible cyclic codes and related  consequences",
    "abstract": "The $b$-symbol read channel is motivated by the limitations of the reading\nprocess in high density data storage systems. The corresponding new metric is a\ngeneralization of the Hamming metric known as the $b$-symbol weight metric and\nhas become an important object in coding theory. In this paper, the general\n$b$-symbol weight enumerator formula for irreducible cyclic codes is presented\nby using the Gaussian period and a new invariant $\\#U(b,j,N_1)$. The related\n$b$-symbol weight hierarchies $\\{d_1(\\C),d_2(\\C),\\ldots,d_K(\\C)\\}$\n($K=\\dim(\\C)$) are given for some cases. The shortened codes which are optimal\nfrom some classes of irreducible cyclic codes are given, where the shorten set\n$\\mathcal{T}$ is the complementary set of $b$-symbol support of some codeword\nwith the minimal $b$-symbol weight.",
    "descriptor": "",
    "authors": [
      "Hongwei Zhu",
      "Minjia Shi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.11567"
  },
  {
    "id": "arXiv:2203.11570",
    "title": "Conditional Generative Data Augmentation for Clinical Audio Datasets",
    "abstract": "In this work, we propose a novel data augmentation method for clinical audio\ndatasets based on a conditional Wasserstein Generative Adversarial Network with\nGradient Penalty (cWGAN-GP), operating on log-mel spectrograms. To validate our\nmethod, we created a clinical audio dataset which was recorded in a real-world\noperating room during Total Hip Arthroplasty (THA) procedures and contains\ntypical sounds which resemble the different phases of the intervention. We\ndemonstrate the capability of the proposed method to generate realistic\nclass-conditioned samples from the dataset distribution and show that training\nwith the generated augmented samples outperforms classical audio augmentation\nmethods in terms of classification accuracy. The performance was evaluated\nusing a ResNet-18 classifier which shows a mean per-class accuracy improvement\nof 1.51% in a 5-fold cross validation experiment using the proposed\naugmentation method. Because clinical data is often expensive to acquire, the\ndevelopment of realistic and high-quality data augmentation methods is crucial\nto improve the robustness and generalization capabilities of learning-based\nalgorithms which is especially important for safety-critical medical\napplications. Therefore, the proposed data augmentation method is an important\nstep towards improving the data bottleneck for clinical audio-based machine\nlearning systems. The code and dataset will be published upon acceptance.",
    "descriptor": "",
    "authors": [
      "Matthias Seibold",
      "Armando Hoch",
      "Mazda Farshad",
      "Nassir Navab",
      "Philipp F\u00fcrnstahl"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11570"
  },
  {
    "id": "arXiv:2203.11572",
    "title": "Fast Multi-view Clustering via Ensembles: Towards Scalability,  Superiority, and Simplicity",
    "abstract": "Despite significant progress, there remain three limitations to the previous\nmulti-view clustering algorithms. First, they often suffer from high\ncomputational complexity, restricting their feasibility for large-scale\ndatasets. Second, they typically fuse multi-view information via one-stage\nfusion, neglecting the possibilities in multi-stage fusions. Third,\ndataset-specific hyperparameter-tuning is frequently required, further\nundermining their practicability. In light of this, we propose a fast\nmulti-view clustering via ensembles (FastMICE) approach. Particularly, the\nconcept of random view groups is presented to capture the versatile view-wise\nrelationships, through which the hybrid early-late fusion strategy is designed\nto enable efficient multi-stage fusions. With multiple views extended to many\nview groups, three levels of diversity (w.r.t. features, anchors, and\nneighbors, respectively) are jointly leveraged for constructing the\nview-sharing bipartite graphs in the early-stage fusion. Then, a set of\ndiversified base clusterings for different view groups are obtained via fast\ngraph partitioning, which are further formulated into a unified bipartite graph\nfor final clustering in the late-stage fusion. Remarkably, FastMICE has almost\nlinear time and space complexity, and is free of dataset-specific tuning.\nExperiments on twenty multi-view datasets demonstrate its advantages in\nscalability (for extremely large datasets), superiority (in clustering\nperformance), and simplicity (to be applied) over the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Dong Huang",
      "Chang-Dong Wang",
      "Jian-Huang Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.11572"
  },
  {
    "id": "arXiv:2203.11573",
    "title": "CT-SAT: Contextual Transformer for Sequential Audio Tagging",
    "abstract": "Sequential audio event tagging can provide not only the type information of\naudio events, but also the order information between events and the number of\nevents that occur in an audio clip. Most previous works on audio event sequence\nanalysis rely on connectionist temporal classification (CTC). However, CTC's\nconditional independence assumption prevents it from effectively learning\ncorrelations between diverse audio events. This paper first attempts to\nintroduce Transformer into sequential audio tagging, since Transformers perform\nwell in sequence-related tasks. To better utilize contextual information of\naudio event sequences, we draw on the idea of bidirectional recurrent neural\nnetworks, and propose a contextual Transformer (cTransformer) with a\nbidirectional decoder that could exploit the forward and backward information\nof event sequences. Experiments on the real-life polyphonic audio dataset show\nthat, compared to CTC-based methods, the cTransformer can effectively combine\nthe fine-grained acoustic representations from the encoder and coarse-grained\naudio event cues to exploit contextual information to successfully recognize\nand predict audio event sequences.",
    "descriptor": "\nComments: Submitted to interspeech 2022\n",
    "authors": [
      "Yuanbo Hou",
      "Zhaoyi Liu",
      "Bo Kang",
      "Yun Wang",
      "Dick Botteldooren"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11573"
  },
  {
    "id": "arXiv:2203.11585",
    "title": "Collective motion emerging from evolving swarm controllers in different  environments using gradient following task",
    "abstract": "Designing controllers for robot swarms is challenging, because human\ndevelopers have typically no good understanding of the link between the details\nof a controller that governs individual robots and the swarm behaviour that is\nan indirect result of the interactions between swarm members and the\nenvironment. In this paper we investigate whether an evolutionary approach can\nmitigate this problem. We consider a very challenging task where robots with\nlimited sensing and communication abilities must follow the gradient of an\nenvironmental feature and use Differential Evolution to evolve a neural network\ncontroller for simulated Thymio II robots. We conduct a systematic study to\nmeasure the robustness and scalability of the method by varying the size of the\narena and number of robots in the swarm. The experiments confirm the\nfeasibility of our approach, the evolved robot controllers induced swarm\nbehaviour that solved the task. We found that solutions evolved under the\nharshest conditions (where the environmental clues were the weakest) were the\nmost robust and that there is a sweet spot regarding the swarm size.\nFurthermore, we observed collective motion of the swarm, showcasing truly\nemergent behavior that was not represented in- and selected for during\nevolution.",
    "descriptor": "\nComments: (1) Three authors contributed equally to this research\n",
    "authors": [
      "Fuda van Diggelen",
      "Jie Luo",
      "Tugay Alperen Karag\u00fczel",
      "Nicolas Cambier",
      "Eliseo Ferrante",
      "A.E. Eiben"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11585"
  },
  {
    "id": "arXiv:2203.11586",
    "title": "Privacy: An axiomatic approach",
    "abstract": "The increasing prevalence of large-scale data collection in modern society\nrepresents a potential threat to individual privacy. Addressing this threat,\nfor example through privacy-enhancing technologies (PETs), requires a rigorous\ndefinition of what exactly is being protected, that is, of privacy itself. In\nthis work, we formulate an axiomatic definition of privacy based on\nquantifiable and irreducible information flows. Our definition synthesizes\nprior work from the domain of social science with a contemporary understanding\nof PETs such as differential privacy (DP). Our work highlights the fact that\nthe inevitable difficulties of protecting privacy in practice are fundamentally\ninformation-theoretic. Moreover, it enables quantitative reasoning about PETs\nbased on what they are protecting, thus fostering objective policy discourse\nabout their societal implementation.",
    "descriptor": "",
    "authors": [
      "Alexander Ziller",
      "Tamara Mueller",
      "Rickmer Braren",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.11586"
  },
  {
    "id": "arXiv:2203.11587",
    "title": "Utterance Rewriting with Contrastive Learning in Multi-turn Dialogue",
    "abstract": "Context modeling plays a significant role in building multi-turn dialogue\nsystems. In order to make full use of context information, systems can use\nIncomplete Utterance Rewriting(IUR) methods to simplify the multi-turn dialogue\ninto single-turn by merging current utterance and context information into a\nself-contained utterance. However, previous approaches ignore the intent\nconsistency between the original query and rewritten query. The detection of\nomitted or coreferred locations in the original query can be further improved.\nIn this paper, we introduce contrastive learning and multi-task learning to\njointly model the problem. Our method benefits from carefully designed\nself-supervised objectives, which act as auxiliary tasks to capture semantics\nat both sentence-level and token-level. The experiments show that our proposed\nmodel achieves state-of-the-art performance on several public datasets.",
    "descriptor": "",
    "authors": [
      "Zhihao Wang",
      "Tangjian Duan",
      "Zihao Wang",
      "Minghui Yang",
      "Zujie Wen",
      "Yongliang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11587"
  },
  {
    "id": "arXiv:2203.11589",
    "title": "Adaptive Patch Exiting for Scalable Single Image Super-Resolution",
    "abstract": "Since the future of computing is heterogeneous, scalability is a crucial\nproblem for single image super-resolution. Recent works try to train one\nnetwork, which can be deployed on platforms with different capacities. However,\nthey rely on the pixel-wise sparse convolution, which is not hardware-friendly\nand achieves limited practical speedup. As image can be divided into patches,\nwhich have various restoration difficulties, we present a scalable method based\non Adaptive Patch Exiting (APE) to achieve more practical speedup.\nSpecifically, we propose to train a regressor to predict the incremental\ncapacity of each layer for the patch. Once the incremental capacity is below\nthe threshold, the patch can exit at the specific layer. Our method can easily\nadjust the trade-off between performance and efficiency by changing the\nthreshold of incremental capacity. Furthermore, we propose a novel strategy to\nenable the network training of our method. We conduct extensive experiments\nacross various backbones, datasets and scaling factors to demonstrate the\nadvantages of our method. Code will be released.",
    "descriptor": "",
    "authors": [
      "Shizun Wang",
      "Ming Lu",
      "Kaixin Chen",
      "Xiaoqi Li",
      "Jiaming Liu",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11589"
  },
  {
    "id": "arXiv:2203.11590",
    "title": "IDEA-Net: Dynamic 3D Point Cloud Interpolation via Deep Embedding  Alignment",
    "abstract": "This paper investigates the problem of temporally interpolating dynamic 3D\npoint clouds with large non-rigid deformation. We formulate the problem as\nestimation of point-wise trajectories (i.e., smooth curves) and further reason\nthat temporal irregularity and under-sampling are two major challenges. To\ntackle the challenges, we propose IDEA-Net, an end-to-end deep learning\nframework, which disentangles the problem under the assistance of the\nexplicitly learned temporal consistency. Specifically, we propose a temporal\nconsistency learning module to align two consecutive point cloud frames\npoint-wisely, based on which we can employ linear interpolation to obtain\ncoarse trajectories/in-between frames. To compensate the high-order nonlinear\ncomponents of trajectories, we apply aligned feature embeddings that encode\nlocal geometry properties to regress point-wise increments, which are combined\nwith the coarse estimations. We demonstrate the effectiveness of our method on\nvarious point cloud sequences and observe large improvement over\nstate-of-the-art methods both quantitatively and visually. Our framework can\nbring benefits to 3D motion data acquisition. The source code is publicly\navailable at https://github.com/ZENGYIMING-EAMON/IDEA-Net.git.",
    "descriptor": "\nComments: This paper was accepted by CVPR 2022\n",
    "authors": [
      "Yiming Zeng",
      "Yue Qian",
      "Qijian Zhang",
      "Junhui Hou",
      "Yixuan Yuan",
      "Ying He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11590"
  },
  {
    "id": "arXiv:2203.11591",
    "title": "HOP: History-and-Order Aware Pre-training for Vision-and-Language  Navigation",
    "abstract": "Pre-training has been adopted in a few of recent works for\nVision-and-Language Navigation (VLN). However, previous pre-training methods\nfor VLN either lack the ability to predict future actions or ignore the\ntrajectory contexts, which are essential for a greedy navigation process. In\nthis work, to promote the learning of spatio-temporal visual-textual\ncorrespondence as well as the agent's capability of decision making, we propose\na novel history-and-order aware pre-training paradigm (HOP) with VLN-specific\nobjectives that exploit the past observations and support future action\nprediction. Specifically, in addition to the commonly used Masked Language\nModeling (MLM) and Trajectory-Instruction Matching (TIM), we design two proxy\ntasks to model temporal order information: Trajectory Order Modeling (TOM) and\nGroup Order Modeling (GOM). Moreover, our navigation action prediction is also\nenhanced by introducing the task of Action Prediction with History (APH), which\ntakes into account the history visual perceptions. Extensive experimental\nresults on four downstream VLN tasks (R2R, REVERIE, NDH, RxR) demonstrate the\neffectiveness of our proposed method compared against several state-of-the-art\nagents.",
    "descriptor": "",
    "authors": [
      "Yanyuan Qiao",
      "Yuankai Qi",
      "Yicong Hong",
      "Zheng Yu",
      "Peng Wang",
      "Qi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11591"
  },
  {
    "id": "arXiv:2203.11592",
    "title": "Channel Hardening of IRS-Aided Multi-Antenna Systems: How Should IRSs  Scale?",
    "abstract": "Unlike active array antennas, intelligent reflecting surfaces (IRSs) are\nefficiently implemented at large dimensions. This allows for traceable\nrealizations of large-scale IRS-aided MIMO systems in which not necessarily the\narray antennas, but the passive IRSs are large. It is widely believed that\nlarge IRS-aided MIMO settings maintain the fundamental features of massive MIMO\nsystems, and hence they are the implementationally feasible technology for\nestablishing the performance of large-scale MIMO settings. This work gives a\nrigorous proof to this belief. We show that using a large passive IRS, the\nend-to-end MIMO channel between the transmitter and the receiver always\nhardens, even if the IRS elements are strongly correlated.\nFor the fading direct and reflection links between the transmitter and the\nreceiver, our derivations demonstrate that as the number of IRS elements grows\nlarge, the capacity of end-to-end channel converges in distribution to a\nreal-valued Gaussian random variable whose variance goes to zero. The order of\nthis drop depends on how the physical dimensions of the IRS grow. We derive\nthis order explicitly. Numerical experiments depict that the analytical\nasymptotic distribution almost perfectly matches the histogram of the capacity,\neven in practical scenarios.\nAs a sample application of the results, we use the asymptotic\ncharacterization to study the dimensional trade-off between the transmitter and\nthe IRS. The result is intuitive: For a given target performance, the larger\nthe IRS is, the less transmit antennas are required to achieve the target. For\nan arbitrary ergodic and outage performance, we characterize this trade-off\nanalytically. Our investigations demonstrate that using a practical IRS size,\nthe target performance can be achieved with significantly small end-to-end MIMO\ndimensions.",
    "descriptor": "\nComments: 17 pages, 11 figures\n",
    "authors": [
      "Ali Bereyhi",
      "Saba Asaad",
      "Chongjun Ouyang",
      "Ralf R. M\u00fcller",
      "Rafael F. Schaefer",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.11592"
  },
  {
    "id": "arXiv:2203.11593",
    "title": "Unified Negative Pair Generation toward Well-discriminative Feature  Space for Face Recognition",
    "abstract": "The goal of face recognition (FR) can be viewed as a pair similarity\noptimization problem, maximizing a similarity set $\\mathcal{S}^p$ over positive\npairs, while minimizing similarity set $\\mathcal{S}^n$ over negative pairs.\nIdeally, it is expected that FR models form a well-discriminative feature space\n(WDFS) that satisfies $\\inf{\\mathcal{S}^p} > \\sup{\\mathcal{S}^n}$. With regard\nto WDFS, the existing deep feature learning paradigms (i.e., metric and\nclassification losses) can be expressed as a unified perspective on different\npair generation (PG) strategies. Unfortunately, in the metric loss (ML), it is\ninfeasible to generate negative pairs taking all classes into account in each\niteration because of the limited mini-batch size. In contrast, in\nclassification loss (CL), it is difficult to generate extremely hard negative\npairs owing to the convergence of the class weight vectors to their center.\nThis leads to a mismatch between the two similarity distributions of the\nsampled pairs and all negative pairs. Thus, this paper proposes a unified\nnegative pair generation (UNPG) by combining two PG strategies (i.e., MLPG and\nCLPG) from a unified perspective to alleviate the mismatch. UNPG introduces\nuseful information about negative pairs using MLPG to overcome the CLPG\ndeficiency. Moreover, it includes filtering the similarities of noisy negative\npairs to guarantee reliable convergence and improved performance. Exhaustive\nexperiments show the superiority of UNPG by achieving state-of-the-art\nperformance across recent loss functions on public benchmark datasets. Our code\nand pretrained models are publicly available.",
    "descriptor": "",
    "authors": [
      "Junuk Jung",
      "Seonhoon Lee",
      "Heung-Seon Oh",
      "Yongjun Park",
      "Joochan Park",
      "Sungbin Son"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11593"
  },
  {
    "id": "arXiv:2203.11594",
    "title": "Budgeted Influence Maximization via Boost Simulated Annealing in Social  Networks",
    "abstract": "Due to much closer to real application scenarios,the budgeted influence\nmaximization (BIM) problem has attracted great attention among researchers. As\na variant of the influence maximization (IM) problem, the BIM problem aims at\nmining several nodes with different costs as seeds with limited budget to\nmaximize the influence as possible. By first activating these seed nodes and\nspreading influence under the given propagation model, the maximized spread of\ninfluence can be reached in the network.\nSeveral approaches have been proposed for BIM. Most of them are modified\nversions of the greedy algorithm, which work well on the IM but seems\ninefficient for the BIM because huge time consuming is inevitable. Recently,\nsome intelligence algorithms are proposed in order to reduce the running time,\nbut analysis shows that they cannot fully utilize the relationships between\nnodes in networks, which will result in influence loss.\nInspired by this, we propose an efficient method based on boosted simulated\nannealing (SA) algorithm in this paper. Three heuristic strategies are proposed\nto improve the performance and speed up the proposed algorithm. Experimental\nresults on both real world and synthetic networks demonstrate that the proposed\nboosted SA performs much better than existed algorithms on performance with\nalmost equal or less running time.",
    "descriptor": "",
    "authors": [
      "Jianshe Wu",
      "Junjun Gao",
      "Hongde Zhu",
      "Zulei Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.11594"
  },
  {
    "id": "arXiv:2203.11600",
    "title": "Distributed Vehicular Dynamic Spectrum Access for Platooning  Environments",
    "abstract": "In this paper, we propose a distributed Vehicular Dynamic Spectrum Access\n(VDSA) framework for vehicles operating in platoon formations. Given the\npotential for significant congestion in licensed frequency bands for vehicular\napplications such as 5.9 GHz. Our approach proposes to offload part of the\nintra-platoon data traffic to spectral white-spaces in order to enhance\nvehicular connectivity in support of on-road operations. To enable VDSA, a\nBumblebee-based decision making process is employed which is based on the\nbehavioral models of animals, is employed to provide a means of distributed\ntransmission band selection. Simulation results show the distributed VDSA\nframework improves the leader packets reception ratio by 5%, thus indicating\nits potential to increase in reliability of intra-platoon communications.",
    "descriptor": "",
    "authors": [
      "Pawe\u0142 Sroka",
      "Pawe\u0142 Kryszkiewicz",
      "Micha\u0142 Sybis",
      "Adrian Kliks",
      "Kuldeep S. Gill",
      "Alexander Wyglinski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.11600"
  },
  {
    "id": "arXiv:2203.11604",
    "title": "Radio Environment Maps for Dynamic Frequency Selection in V2X  Communications",
    "abstract": "In this paper, we investigate the concept of database supported Vehicular\nDynamic Spectrum Access (VDSA) for platooning. As various researchers show that\nthe 5.9 GHz band, devoted for Intelligent Transportation Systems, may suffer\nfrom congestion of the channel, we propose to offload part of this traffic to\nwhite-spaces with the guidance of the active database system. In our work, we\ndescribe our measurement campaign which delivered data for population of the\ndedicated radio environment map. Once the map is created, it was used in three\nproposed algorithms for VDSA: an optimal and two pragmatic approaches.",
    "descriptor": "",
    "authors": [
      "Pawe\u0142 Sroka",
      "Pawe\u0142 Kryszkiewicz",
      "Adrian Kliks"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.11604"
  },
  {
    "id": "arXiv:2203.11606",
    "title": "Analysis of Disfluencies for automatic detection of Mild Cognitive  Impartment: a deep learning approach",
    "abstract": "The so-called Mild Cognitive Impairment (MCI) or cognitive loss appears in a\nprevious stage before Alzheimer's Disease (AD), but it does not seem\nsufficiently severe to interfere in independent abilities of daily life, so it\nusually does not receive an appropriate diagnosis. Its detection is a\nchallenging issue to be addressed by medical specialists. This work presents a\nnovel proposal based on automatic analysis of speech and disfluencies aimed at\nsupporting MCI diagnosis. The approach includes deep learning by means of\nConvolutional Neural Networks (CNN) and non-linear multifeature modelling.\nMoreover, to select the most relevant features non-parametric Mann-Whitney\nU-testt and Support Vector Machine Attribute (SVM) evaluation are used.",
    "descriptor": "\nComments: 5 pages, published in 2017 International Conference and Workshop on Bioinspired Intelligence (IWOBI), 2017, pp. 1-4, 10-12 July Funchal (Portugal)\n",
    "authors": [
      "Karmele Lopez-de-Ipi\u00f1a",
      "Unai Martinez de Lizarduy",
      "Pilar Calvo",
      "Blanca Beita",
      "Joseba Garc\u00eda-Melero",
      "Miriam Ecay-Torres",
      "Ainara Estanga",
      "Marcos Faundez-Zanuy"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11606"
  },
  {
    "id": "arXiv:2203.11610",
    "title": "Diagnosis of Schizophrenia: A comprehensive evaluation",
    "abstract": "Machine learning models have been successfully employed in the diagnosis of\nSchizophrenia disease. The impact of classification models and the feature\nselection techniques on the diagnosis of Schizophrenia have not been evaluated.\nHere, we sought to access the performance of classification models along with\ndifferent feature selection approaches on the structural magnetic resonance\nimaging data. The data consist of 72 subjects with Schizophrenia and 74 healthy\ncontrol subjects. We evaluated different classification algorithms based on\nsupport vector machine (SVM), random forest, kernel ridge regression and\nrandomized neural networks. Moreover, we evaluated T-Test, Receiver Operator\nCharacteristics (ROC), Wilcoxon, entropy, Bhattacharyya, Minimum Redundancy\nMaximum Relevance (MRMR) and Neighbourhood Component Analysis (NCA) as the\nfeature selection techniques. Based on the evaluation, SVM based models with\nGaussian kernel proved better compared to other classification models and\nWilcoxon feature selection emerged as the best feature selection approach.\nMoreover, in terms of data modality the performance on integration of the grey\nmatter and white matter proved better compared to the performance on the grey\nand white matter individually. Our evaluation showed that classification\nalgorithms along with the feature selection approaches impact the diagnosis of\nSchizophrenia disease. This indicates that proper selection of the features and\nthe classification models can improve the diagnosis of Schizophrenia.",
    "descriptor": "",
    "authors": [
      "M. Tanveer",
      "Jatin Jangir",
      "M.A. Ganaie",
      "Iman Beheshti",
      "M. Tabish",
      "Nikunj Chhabra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11610"
  },
  {
    "id": "arXiv:2203.11611",
    "title": "Dense Residual Networks for Gaze Mapping on Indian Roads",
    "abstract": "In the recent past, greater accessibility to powerful computational resources\nhas enabled progress in the field of Deep Learning and Computer Vision to grow\nby leaps and bounds. This in consequence has lent progress to the domain of\nAutonomous Driving and Navigation Systems. Most of the present research work\nhas been focused on driving scenarios in the European or American roads. Our\npaper draws special attention to the Indian driving context. To this effect, we\npropose a novel architecture, DR-Gaze, which is used to map the driver's gaze\nonto the road. We compare our results with previous works and state-of-the-art\nresults on the DGAZE dataset. Our code will be made publicly available upon\nacceptance of our paper.",
    "descriptor": "",
    "authors": [
      "Chaitanya Kapoor",
      "Kshitij Kumar",
      "Soumya Vishnoi",
      "Sriram Ramanathan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11611"
  },
  {
    "id": "arXiv:2203.11612",
    "title": "Nonlinear prediction with neural nets in ADPCM",
    "abstract": "In the last years there has been a growing interest for nonlinear speech\nmodels. Several works have been published revealing the better performance of\nnonlinear techniques, but little attention has been dedicated to the\nimplementation of the nonlinear model into real applications. This work is\nfocused on the study of the behaviour of a nonlinear predictive model based on\nneural nets, in a speech waveform coder. Our novel scheme obtains an\nimprovement in SEGSNR between 1 and 2 dB for an adaptive quantization ranging\nfrom 2 to 5 bits.",
    "descriptor": "\nComments: 4 pages, published in Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181) Seattle, WA, USA. arXiv admin note: text overlap with arXiv:2203.01818\n",
    "authors": [
      "Marcos Faundez-Zanuy",
      "Francesc Vallverdu",
      "Enric Monte"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11612"
  },
  {
    "id": "arXiv:2203.11614",
    "title": "Speaker recognition with a MLP classifier and LPCC codebook",
    "abstract": "This paper improves the speaker recognition rates of a MLP classifier and\nLPCC codebook alone, using a linear combination between both methods. In\nsimulations we have obtained an improvement of 4.7% over a LPCC codebook of 32\nvectors and 1.5% for a codebook of 128 vectors (error rate drops from 3.68% to\n2.1%). Also we propose an efficient algorithm that reduces the computational\ncomplexity of the LPCC-VQ system by a factor of 4.",
    "descriptor": "\nComments: 4 pages, published in 1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.99CH36258) Phoenix, AZ, USA\n",
    "authors": [
      "Daniel Rodriguez-Porcheron",
      "Marcos Faundez-Zanuy"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11614"
  },
  {
    "id": "arXiv:2203.11618",
    "title": "Distributing Collaborative Multi-Robot Planning with Gaussian Belief  Propagation",
    "abstract": "Precise coordinated planning enables safe and highly efficient motion when\nmany robots must work together in tight spaces, but this would normally require\ncentralised control of all devices which is difficult to scale. We demonstrate\na new purely distributed technique based on Gaussian Belief Propagation on\nmulti-robot planning problems formulated by a generic factor graph defining\ndynamics and collision constraints. We show that our method allows extremely\nhigh performance collaborative planning in a simulated road traffic scenario,\nwhere vehicles are able to cross each other at a busy multi-lane junction while\nmaintaining much higher average speeds than alternative distributed planning\ntechniques. We encourage the reader to view the accompanying video\ndemonstration to this work at https://youtu.be/5d4LXbxgxaY.",
    "descriptor": "",
    "authors": [
      "Aalok Patwardhan",
      "Riku Murai",
      "Andrew J. Davison"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.11618"
  },
  {
    "id": "arXiv:2203.11624",
    "title": "High-resolution Iterative Feedback Network for Camouflaged Object  Detection",
    "abstract": "Spotting camouflaged objects that are visually assimilated into the\nbackground is tricky for both object detection algorithms and humans who are\nusually confused or cheated by the perfectly intrinsic similarities between the\nforeground objects and the background surroundings. To tackle this challenge,\nwe aim to extract the high-resolution texture details to avoid the detail\ndegradation that causes blurred vision in edges and boundaries. We introduce a\nnovel HitNet to refine the low-resolution representations by high-resolution\nfeatures in an iterative feedback manner, essentially a global loop-based\nconnection among the multi-scale resolutions. In addition, an iterative\nfeedback loss is proposed to impose more constraints on each feedback\nconnection. Extensive experiments on four challenging datasets demonstrate that\nour \\ourmodel~breaks the performance bottleneck and achieves significant\nimprovements compared with 29 state-of-the-art methods. To address the data\nscarcity in camouflaged scenarios, we provide an application example by\nemploying cross-domain learning to extract the features that can reflect the\ncamouflaged object properties and embed the features into salient objects,\nthereby generating more camouflaged training samples from the diverse salient\nobject datasets The code will be available at\nhttps://github.com/HUuxiaobin/HitNet.",
    "descriptor": "",
    "authors": [
      "Xiaobin Hu",
      "Deng-Ping Fan",
      "Xuebin Qin",
      "Hang Dai",
      "Wenqi Ren",
      "Ying Tai",
      "Chengjie Wang",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11624"
  },
  {
    "id": "arXiv:2203.11629",
    "title": "On Neural Network Equivalence Checking using SMT Solvers",
    "abstract": "Two pretrained neural networks are deemed equivalent if they yield similar\noutputs for the same inputs. Equivalence checking of neural networks is of\ngreat importance, due to its utility in replacing learning-enabled components\nwith equivalent ones, when there is need to fulfill additional requirements or\nto address security threats, as is the case for example when using knowledge\ndistillation, adversarial training etc. SMT solvers can potentially provide\nsolutions to the problem of neural network equivalence checking that will be\nsound and complete, but as it is expected any such solution is associated with\nsignificant limitations with respect to the size of neural networks to be\nchecked. This work presents a first SMT-based encoding of the equivalence\nchecking problem, explores its utility and limitations and proposes avenues for\nfuture research and improvements towards more scalable and practically\napplicable solutions. We present experimental results that shed light to the\naforementioned issues, for diverse types of neural network models (classifiers\nand regression networks) and equivalence criteria, towards a general and\napplication-independent equivalence checking approach.",
    "descriptor": "",
    "authors": [
      "Charis Eleftheriadis",
      "Nikolaos Kekatos",
      "Panagiotis Katsaros",
      "Stavros Tripakis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.11629"
  },
  {
    "id": "arXiv:2203.11632",
    "title": "QS-Craft: Learning to Quantize, Scrabble and Craft for Conditional Human  Motion Animation",
    "abstract": "This paper studies the task of conditional Human Motion Animation (cHMA).\nGiven a source image and a driving video, the model should animate the new\nframe sequence, in which the person in the source image should perform a\nsimilar motion as the pose sequence from the driving video. Despite the success\nof Generative Adversarial Network (GANs) methods in image and video synthesis,\nit is still very challenging to conduct cHMA due to the difficulty in\nefficiently utilizing the conditional guided information such as images or\nposes, and generating images of good visual quality. To this end, this paper\nproposes a novel model of learning to Quantize, Scrabble, and Craft (QS-Craft)\nfor conditional human motion animation. The key novelties come from the newly\nintroduced three key steps: quantize, scrabble and craft. Particularly, our\nQS-Craft employs transformer in its structure to utilize the attention\narchitectures. The guided information is represented as a pose coordinate\nsequence extracted from the driving videos. Extensive experiments on human\nmotion datasets validate the efficacy of our model.",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Yuxin Hong",
      "Xuelin Qian",
      "Simian Luo",
      "Xiangyang Xue",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11632"
  },
  {
    "id": "arXiv:2203.11633",
    "title": "Semi-Targeted Model Poisoning Attack on Federated Learning via Backward  Error Analysis",
    "abstract": "Model poisoning attacks on federated learning (FL) intrude in the entire\nsystem via compromising an edge model, resulting in malfunctioning of machine\nlearning models. Such compromised models are tampered with to perform\nadversary-desired behaviors. In particular, we considered a semi-targeted\nsituation where the source class is predetermined however the target class is\nnot. The goal is to cause the global classifier to misclassify data of the\nsource class. Though approaches such as label flipping have been adopted to\ninject poisoned parameters into FL, it has been shown that their performances\nare usually class-sensitive varying with different target classes applied.\nTypically, an attack can become less effective when shifting to a different\ntarget class. To overcome this challenge, we propose the Attacking\nDistance-aware Attack (ADA) to enhance a poisoning attack by finding the\noptimized target class in the feature space. Moreover, we studied a more\nchallenging situation where an adversary had limited prior knowledge about a\nclient's data. To tackle this problem, ADA deduces pair-wise distances between\ndifferent classes in the latent feature space from shared model parameters\nbased on the backward error analysis. We performed extensive empirical\nevaluations on ADA by varying the factor of attacking frequency in three\ndifferent image classification tasks. As a result, ADA succeeded in increasing\nthe attack performance by 1.8 times in the most challenging case with an\nattacking frequency of 0.01.",
    "descriptor": "",
    "authors": [
      "Yuwei Sun",
      "Hideya Ochiai",
      "Jun Sakuma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.11633"
  },
  {
    "id": "arXiv:2203.11635",
    "title": "Multi-Source Domain Adaptation Based on Federated Knowledge Alignment",
    "abstract": "Federated Learning (FL) facilitates distributed model learning to protect\nusers' privacy. In the absence of labels for a new user's data, the knowledge\ntransfer in FL allows a learned global model to adapt to the new samples\nquickly. The multi-source domain adaptation in FL aims to improve the model's\ngenerality in a target domain by learning domain-invariant features from\ndifferent clients. In this paper, we propose Federated Knowledge Alignment\n(FedKA) that aligns features from different clients and those of the target\ntask. We identify two types of negative transfer arising in multi-source domain\nadaptation of FL and demonstrate how FedKA can alleviate such negative\ntransfers with the help of a global features disentangler enhanced by embedding\nmatching. To further facilitate representation learning of the target task, we\ndevise a federated voting mechanism to provide labels for samples from the\ntarget domain via a consensus from querying local models and fine-tune the\nglobal model with these labeled samples. Extensive experiments, including an\nablation study, on an image classification task of Digit-Five and a text\nsentiment classification task of Amazon Review, show that FedKA could be\naugmented to existing FL algorithms to improve the generality of the learned\nmodel for tackling a new task.",
    "descriptor": "",
    "authors": [
      "Yuwei Sun",
      "Ng Chong",
      "Ochiai Hideya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11635"
  },
  {
    "id": "arXiv:2203.11636",
    "title": "A Method for Estimating Individual Socioeconomic Status of Twitter Users",
    "abstract": "The rise of social media and computational social science (CSS) has opened\ncountless opportunities to explore social science questions with new forms of\ndata and methods. However, CSS research on socioeconomic inequality, a\nfundamental problem in sociology, has been constrained due to the lack of\nindividual-level socioeconomic status (SES) measures in digital trace data. We\npropose a new approach to address this problem. Following Bourdieu, we argue\nthat the commercial and entertainment accounts that Twitter users follow\nreflect their economic and cultural capital and hence, we can use these\nfollowings to infer the users' SES. Inspired by political science approaches to\ninferring social media users' political ideology, we develop a method that uses\ncorrespondence analysis to project official Twitter accounts and their\nfollowers onto a linear SES scale. Using this method, we estimate the SES of\n3,482,657 Twitter users who follow the Twitter accounts of 339 supermarkets and\ndepartment stores, clothing and speciality retailers, chain restaurants,\nnewspapers and news channels, sports, and TV shows in the United States. We\nvalidate our estimates with data on audience composition from the Facebook\nMarketing API, self-reported job titles on users' Twitter profiles, and a small\nsurvey sample. The results show reasonable correlations between our SES\nestimates and the standard proxies for SES: education, occupational class, and\nincome at the aggregate level and weaker but still significant correlations at\nthe individual level. The proposed method opens new opportunities for\ninnovative social research on inequality on Twitter and similar online\nplatforms.",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Yuanmo He",
      "Milena Tsvetkova"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.11636"
  },
  {
    "id": "arXiv:2203.11637",
    "title": "Look for the Change: Learning Object States and State-Modifying Actions  from Untrimmed Web Videos",
    "abstract": "Human actions often induce changes of object states such as \"cutting an\napple\", \"cleaning shoes\" or \"pouring coffee\". In this paper, we seek to\ntemporally localize object states (e.g. \"empty\" and \"full\" cup) together with\nthe corresponding state-modifying actions (\"pouring coffee\") in long uncurated\nvideos with minimal supervision. The contributions of this work are threefold.\nFirst, we develop a self-supervised model for jointly learning state-modifying\nactions together with the corresponding object states from an uncurated set of\nvideos from the Internet. The model is self-supervised by the causal ordering\nsignal, i.e. initial object state $\\rightarrow$ manipulating action\n$\\rightarrow$ end state. Second, to cope with noisy uncurated training data,\nour model incorporates a noise adaptive weighting module supervised by a small\nnumber of annotated still images, that allows to efficiently filter out\nirrelevant videos during training. Third, we collect a new dataset with more\nthan 2600 hours of video and 34 thousand changes of object states, and manually\nannotate a part of this data to validate our approach. Our results demonstrate\nsubstantial improvements over prior work in both action and object\nstate-recognition in video.",
    "descriptor": "\nComments: To be published in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022\n",
    "authors": [
      "Tom\u00e1\u0161 Sou\u010dek",
      "Jean-Baptiste Alayrac",
      "Antoine Miech",
      "Ivan Laptev",
      "Josef Sivic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11637"
  },
  {
    "id": "arXiv:2203.11639",
    "title": "Learning Relation-Specific Representations for Few-shot Knowledge Graph  Completion",
    "abstract": "Recent years have witnessed increasing interest in few-shot knowledge graph\ncompletion (FKGC), which aims to infer unseen query triples for a few-shot\nrelation using a handful of reference triples of the relation. The primary\nfocus of existing FKGC methods lies in learning the relation representations\nthat can reflect the common information shared by the query and reference\ntriples. To this end, these methods learn the embeddings of entities with their\ndirect neighbors, and use the concatenation of the entity embeddings as the\nrelation representations. However, the entity embeddings learned only from\ndirect neighborhoods may have low expressiveness when the entity has sparse\nneighbors or shares a common local neighborhood with other entities. Moreover,\nthe embeddings of two entities are insufficient to represent the semantic\ninformation of their relationship, especially when they have multiple\nrelations. To address these issues, we propose a Relation-Specific Context\nLearning (RSCL) framework, which exploits graph contexts of triples to capture\nthe semantic information of relations and entities simultaneously.\nSpecifically, we first extract graph contexts for each triple, which can\nprovide long-term entity-relation dependencies. To model the graph contexts, we\nthen develop a hierarchical relation-specific learner to learn global and local\nrelation-specific representations for relations by capturing contextualized\ninformation of triples and incorporating local information of entities.\nFinally, we utilize the learned representations to predict the likelihood of\nthe query triples. Experimental results on two public datasets demonstrate that\nRSCL outperforms state-of-the-art FKGC methods.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Yuling Li",
      "Kui Yu",
      "Yuhong Zhang",
      "Xindong Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11639"
  },
  {
    "id": "arXiv:2203.11647",
    "title": "Semantic State Estimation in Cloth Manipulation Tasks",
    "abstract": "Understanding of deformable object manipulations such as textiles is a\nchallenge due to the complexity and high dimensionality of the problem.\nParticularly, the lack of a generic representation of semantic states (e.g.,\n\\textit{crumpled}, \\textit{diagonally folded}) during a continuous manipulation\nprocess introduces an obstacle to identify the manipulation type. In this\npaper, we aim to solve the problem of semantic state estimation in cloth\nmanipulation tasks. For this purpose, we introduce a new large-scale\nfully-annotated RGB image dataset showing various human demonstrations of\ndifferent complicated cloth manipulations. We provide a set of baseline deep\nnetworks and benchmark them on the problem of semantic state estimation using\nour proposed dataset. Furthermore, we investigate the scalability of our\nsemantic state estimation framework in robot monitoring tasks of long and\ncomplex cloth manipulations.",
    "descriptor": "",
    "authors": [
      "Georgies Tzelepis",
      "Eren Erdal Aksoy",
      "J\u00falia Borr\u00e0s",
      "Guillem Aleny\u00e0"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11647"
  },
  {
    "id": "arXiv:2203.11648",
    "title": "Learning Operators with Mesh-Informed Neural Networks",
    "abstract": "Thanks to their universal approximation properties and new efficient training\nstrategies, Deep Neural Networks are becoming a valuable tool for the\napproximation of mathematical operators. In the present work, we introduce\nMesh-Informed Neural Networks (MINNs), a class of architectures specifically\ntailored to handle mesh based functional data, and thus of particular interest\nfor reduced order modeling of parametrized Partial Differential Equations\n(PDEs). The driving idea behind MINNs is to embed hidden layers into discrete\nfunctional spaces of increasing complexity, obtained through a sequence of\nmeshes defined over the underlying spatial domain. The approach leads to a\nnatural pruning strategy which enables the design of sparse architectures that\nare able to learn general nonlinear operators. We assess this strategy through\nan extensive set of numerical experiments, ranging from nonlocal operators to\nnonlinear diffusion PDEs, where MINNs are compared to classical fully connected\nDeep Neural Networks. Our results show that MINNs can handle functional data\ndefined on general domains of any shape, while ensuring reduced training times,\nlower computational costs, and better generalization capabilities, thus making\nMINNs very well-suited for demanding applications such as Reduced Order\nModeling and Uncertainty Quantification for PDEs.",
    "descriptor": "",
    "authors": [
      "Nicola Rares Franco",
      "Andrea Manzoni",
      "Paolo Zunino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11648"
  },
  {
    "id": "arXiv:2203.11649",
    "title": "Performance Evaluation of Machine Learning-based Algorithm and Taguchi  Algorithm for the Determination of the Hardness Value of the Friction Stir  Welded AA 6262 Joints at a Nugget Zone",
    "abstract": "Nowadays, industry 4.0 plays a tremendous role in the manufacturing\nindustries for increasing the amount of data and accuracy in modern\nmanufacturing systems. Thanks to artificial intelligence, particularly machine\nlearning, big data analytics have dramatically amended, and manufacturers\neasily exploit organized and unorganized data. This study utilized hybrid\noptimization algorithms to find friction stir welding and optimal hardness\nvalue at the nugget zone. A similar AA 6262 material was used and welded in a\nbutt joint configuration. Tool rotational speed (RPM), tool traverse speed\n(mm/min), and the plane depth (mm) are used as controllable parameters and\noptimized using Taguchi L9, Random Forest, and XG Boost machine learning tools.\nAnalysis of variance was also conducted at a 95% confidence interval for\nidentifying the significant parameters. The result indicated that the\ncoefficient of determination from Taguchi L9 orthogonal array is 0.91 obtained\nwhile Random Forest and XG Boost algorithm imparted 0.62 and 0.65,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Akshansh Mishra",
      "Eyob Messele Sefene",
      "Gopikrishna Nidigonda",
      "Assefa Asmare Tsegaw"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11649"
  },
  {
    "id": "arXiv:2203.11650",
    "title": "Methodology for development of scientific software and test frameworks  in function of precision of the expected results",
    "abstract": "This dissertation focuses on the development process of scientific software.\nIt presents a methodology that has emerged over time during development of\nMonte Carlo tools for high energy physics experiments. A short description of\nthe physics background needed to understand the subjects presented in this\ndissertation is included and the different types of software created for the\nphysics experiments are outlined. Challenges related to the scientific software\ndevelopment are presented.\nThe development process of several projects is described. The development of\nsubsequent milestones of these projects follow the cycle of improving the\nphysics model, describing the model using mathematical formalism, implementing\nthe model with numerical approximations, creating the software framework,\ndocumenting and validating results. The relation between increased precision of\nthe results and increased complexity of tests and test frameworks is also\ndemonstrated based on these projects. The subject of scientific software\ntesting is addressed and the taxonomy of the scientific software tests is\npresented including testing techniques used in the development of this\nsoftware.\nAuthor of this dissertation co-authored tools presented in it. Some of these\ntools have been introduced into the HEP community. Some gained large user base\nand are in active use by the community. Some of them are part of analyses\nperformed by experiments around Large Hadron Collider. The analysis of the\ndevelopment process of these tools can help estimate the effort needed to\nimprove the design and precision of complex algorithms.",
    "descriptor": "\nComments: Dissertation submitted in partial fulfillment of the requirements for the doctorate of T. Przedzinski, 137 pages + 84 pages of appendices, 22MB pdf\n",
    "authors": [
      "T. Przedzinski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.11650"
  },
  {
    "id": "arXiv:2203.11652",
    "title": "Weakly-Supervised Salient Object Detection Using Point Supervison",
    "abstract": "Current state-of-the-art saliency detection models rely heavily on large\ndatasets of accurate pixel-wise annotations, but manually labeling pixels is\ntime-consuming and labor-intensive. There are some weakly supervised methods\ndeveloped for alleviating the problem, such as image label, bounding box label,\nand scribble label, while point label still has not been explored in this\nfield. In this paper, we propose a novel weakly-supervised salient object\ndetection method using point supervision. To infer the saliency map, we first\ndesign an adaptive masked flood filling algorithm to generate pseudo labels.\nThen we develop a transformer-based point-supervised saliency detection model\nto produce the first round of saliency maps. However, due to the sparseness of\nthe label, the weakly supervised model tends to degenerate into a general\nforeground detection model. To address this issue, we propose a Non-Salient\nSuppression (NSS) method to optimize the erroneous saliency maps generated in\nthe first round and leverage them for the second round of training. Moreover,\nwe build a new point-supervised dataset (P-DUTS) by relabeling the DUTS\ndataset. In P-DUTS, there is only one labeled point for each salient object.\nComprehensive experiments on five largest benchmark datasets demonstrate our\nmethod outperforms the previous state-of-the-art methods trained with the\nstronger supervision and even surpass several fully supervised state-of-the-art\nmodels. The code is available at: https://github.com/shuyonggao/PSOD.",
    "descriptor": "\nComments: accepted by AAAI2022\n",
    "authors": [
      "Shuyong Gao",
      "Wei Zhang",
      "Yan Wang",
      "Qianyu Guo",
      "Chenglong Zhang",
      "Yangji He",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11652"
  },
  {
    "id": "arXiv:2203.11653",
    "title": "Transferring Multi-Agent Reinforcement Learning Policies for Autonomous  Driving using Sim-to-Real",
    "abstract": "Autonomous Driving requires high levels of coordination and collaboration\nbetween agents. Achieving effective coordination in multi-agent systems is a\ndifficult task that remains largely unresolved. Multi-Agent Reinforcement\nLearning has arisen as a powerful method to accomplish this task because it\nconsiders the interaction between agents and also allows for decentralized\ntraining -- which makes it highly scalable. However, transferring policies from\nsimulation to the real world is a big challenge, even for single-agent\napplications. Multi-agent systems add additional complexities to the\nSim-to-Real gap due to agent collaboration and environment synchronization. In\nthis paper, we propose a method to transfer multi-agent autonomous driving\npolicies to the real world. For this, we create a multi-agent environment that\nimitates the dynamics of the Duckietown multi-robot testbed, and train\nmulti-agent policies using the MAPPO algorithm with different levels of domain\nrandomization. We then transfer the trained policies to the Duckietown testbed\nand compare the use of the MAPPO algorithm against a traditional rule-based\nmethod. We show that the rewards of the transferred policies with MAPPO and\ndomain randomization are, on average, 1.85 times superior to the rule-based\nmethod. Moreover, we show that different levels of parameter randomization have\na substantial impact on the Sim-to-Real gap.",
    "descriptor": "",
    "authors": [
      "Eduardo Candela",
      "Leandro Parada",
      "Luis Marques",
      "Tiberiu-Andrei Georgescu",
      "Yiannis Demiris",
      "Panagiotis Angeloudis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.11653"
  },
  {
    "id": "arXiv:2203.11654",
    "title": "Fine-Grained Scene Graph Generation with Data Transfer",
    "abstract": "Scene graph generation (SGG) aims to extract (subject, predicate, object)\ntriplets in images. Recent works have made a steady progress on SGG, and\nprovide useful tools for high-level vision and language understanding. However,\ndue to the data distribution problems including long-tail distribution and\nsemantic ambiguity, the predictions of current SGG models tend to collapse to\nseveral frequent but uninformative predicates (e.g., \\textit{on}, \\textit{at}),\nwhich limits practical application of these models in downstream tasks. To deal\nwith the problems above, we propose a novel Internal and External Data Transfer\n(IETrans) method, which can be applied in a play-and-plug fashion and expanded\nto large SGG with 1,807 predicate classes. Our IETrans tries to relieve the\ndata distribution problem by automatically creating an enhanced dataset that\nprovides more sufficient and coherent annotations for all predicates. By\ntraining on the transferred dataset, a Neural Motif model doubles the macro\nperformance while maintaining competitive micro performance. The data and code\nfor this paper are publicly available at\n\\url{https://github.com/waxnkw/IETrans-SGG.pytorch}",
    "descriptor": "\nComments: 15 pages, 10 figures, conference\n",
    "authors": [
      "Ao Zhang",
      "Yuan Yao",
      "Qianyu Chen",
      "Wei Ji",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11654"
  },
  {
    "id": "arXiv:2203.11656",
    "title": "Is Vanilla Policy Gradient Overlooked? Analyzing Deep Reinforcement  Learning for Hanabi",
    "abstract": "In pursuit of enhanced multi-agent collaboration, we analyze several\non-policy deep reinforcement learning algorithms in the recently published\nHanabi benchmark. Our research suggests a perhaps counter-intuitive finding,\nwhere Proximal Policy Optimization (PPO) is outperformed by Vanilla Policy\nGradient over multiple random seeds in a simplified environment of the\nmulti-agent cooperative card game. In our analysis of this behavior we look\ninto Hanabi-specific metrics and hypothesize a reason for PPO's plateau. In\naddition, we provide proofs for the maximum length of a perfect game (71 turns)\nand any game (89 turns). Our code can be found at:\nhttps://github.com/bramgrooten/DeepRL-for-Hanabi",
    "descriptor": "\nComments: Accepted at ALA 2022 (Adaptive and Learning Agents Workshop at AAMAS 2022)\n",
    "authors": [
      "Bram Grooten",
      "Jelle Wemmenhove",
      "Maurice Poot",
      "Jim Portegies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.11656"
  },
  {
    "id": "arXiv:2203.11658",
    "title": "A Decentralised Multi-Agent Reinforcement Learning Approach for the  Same-Day Delivery Problem",
    "abstract": "Same-Day Delivery services are becoming increasingly popular in recent years.\nThese have been usually modelled by previous studies as a certain class of\nDynamic Vehicle Routing Problem (DVRP) where goods must be delivered from a\ndepot to a set of customers in the same day that the orders were placed.\nAdaptive exact solution methods for DVRPs can become intractable even for small\nproblem instances. In this paper, we formulate the SDDP as a Markov Decision\nProcess (MDP) and solve it using a parameter-sharing Deep Q-Network, which\ncorresponds to a decentralised Multi-Agent Reinforcement Learning (MARL)\napproach. For this, we create a multi-agent grid-based SDD environment,\nconsisting of multiple vehicles, a central depot and dynamic order generation.\nIn addition, we introduce zone-specific order generation and reward\nprobabilities. We compare the performance of our proposed MARL approach against\na Mixed Inter Programming (MIP) solution. Results show that our proposed MARL\nframework performs on par with MIP-based policy when the number of orders is\nrelatively low. For problem instances with higher order arrival rates,\ncomputational results show that the MARL approach underperforms the MIP by up\nto 30%. The performance gap between both methods becomes smaller when\nzone-specific parameters are employed. The gap is reduced from 30% to 3% for a\n5x5 grid scenario with 30 orders. Execution time results indicate that the MARL\napproach is, on average, 65 times faster than the MIP-based policy, and\ntherefore may be more advantageous for real-time control, at least for\nsmall-sized instances.",
    "descriptor": "\nComments: Paper accepted for publication at the Transport Research Record (TRR) Journal\n",
    "authors": [
      "Elvin Ngu",
      "Leandro Parada",
      "Jose Javier Escribano Macias",
      "Panagiotis Angeloudis"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.11658"
  },
  {
    "id": "arXiv:2203.11660",
    "title": "Channel Self-Supervision for Online Knowledge Distillation",
    "abstract": "Recently, researchers have shown an increased interest in the online\nknowledge distillation. Adopting an one-stage and end-to-end training fashion,\nonline knowledge distillation uses aggregated intermediated predictions of\nmultiple peer models for training. However, the absence of a powerful teacher\nmodel may result in the homogeneity problem between group peers, affecting the\neffectiveness of group distillation adversely. In this paper, we propose a\nnovel online knowledge distillation method, \\textbf{C}hannel\n\\textbf{S}elf-\\textbf{S}upervision for Online Knowledge Distillation (CSS),\nwhich structures diversity in terms of input, target, and network to alleviate\nthe homogenization problem. Specifically, we construct a dual-network\nmulti-branch structure and enhance inter-branch diversity through\nself-supervised learning, adopting the feature-level transformation and\naugmenting the corresponding labels. Meanwhile, the dual network structure has\na larger space of independent parameters to resist the homogenization problem\nduring distillation. Extensive quantitative experiments on CIFAR-100 illustrate\nthat our method provides greater diversity than OKDDip and we also give pretty\nperformance improvement, even over the state-of-the-art such as PCL. The\nresults on three fine-grained datasets (StanfordDogs, StanfordCars,\nCUB-200-211) also show the significant generalization capability of our\napproach.",
    "descriptor": "",
    "authors": [
      "Shixiao Fan",
      "Xuan Cheng",
      "Xiaomin Wang",
      "Chun Yang",
      "Pan Deng",
      "Minghui Liu",
      "Jiali Deng",
      "Ming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11660"
  },
  {
    "id": "arXiv:2203.11667",
    "title": "TS-Reconfiguration of $k$-Path Vertex Covers in Caterpillars",
    "abstract": "A $k$-path vertex cover ($k$-PVC) of a graph $G$ is a vertex subset $I$ such\nthat each path on $k$ vertices in $G$ contains at least one member of $I$.\nImagine that a token is placed on each vertex of a $k$-PVC. Given two $k$-PVCs\n$I, J$ of a graph $G$, the $k$-Path Vertex Cover Reconfiguration ($k$-PVCR)\nunder Token Sliding ($\\mathsf{TS}$) problem asks if there is a sequence of\n$k$-PVCs between $I$ and $J$ where each intermediate member is obtained from\nits predecessor by sliding a token from some vertex to one of its unoccupied\nneighbors. This problem is known to be $\\mathtt{PSPACE}$-complete even for\nplanar graphs of maximum degree $3$ and bounded treewidth and can be solved in\npolynomial time for paths and cycles. Its complexity for trees remains unknown.\nIn this paper, for $k \\geq 4$, we present a polynomial-time algorithm that\nsolves $k$-PVCR under $\\mathsf{TS}$ for caterpillars (i.e., trees formed by\nattaching leaves to a path).",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Duc A. Hoang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.11667"
  },
  {
    "id": "arXiv:2203.11669",
    "title": "Are You Misinformed? A Study of Covid-Related Fake News in Bengali on  Facebook",
    "abstract": "Our opinions and views of life can be shaped by how we perceive the opinions\nof others on social media like Facebook. This dependence has increased during\nCOVID-19 periods when we have fewer means to connect with others. However, fake\nnews related to COVID-19 has become a significant problem on Facebook. Bengali\nis the seventh most spoken language worldwide, yet we are aware of no previous\nresearch that studied the prevalence of COVID-19 related fake news in Bengali\non Facebook. In this paper, we develop machine learning models to detect fake\nnews in Bengali automatically. The best performing model is BERT, with an\nF1-score of 0.97. We apply BERT on all Facebook Bengali posts related to\nCOVID-19. We find 10 topics in the COVID-19 Bengali fake news grouped into\nthree categories: System (e.g., medical system), belief (e.g., religious\nrituals), and social (e.g., scientific awareness).",
    "descriptor": "",
    "authors": [
      "Protik Bose Pranto",
      "Syed Zami-Ul-Haque Navid",
      "Protik Dey",
      "Gias Uddin",
      "Anindya Iqbal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.11669"
  },
  {
    "id": "arXiv:2203.11670",
    "title": "Improving Meta-learning for Low-resource Text Classification and  Generation via Memory Imitation",
    "abstract": "Building models of natural language processing (NLP) is challenging in\nlow-resource scenarios where only limited data are available.\nOptimization-based meta-learning algorithms achieve promising results in\nlow-resource scenarios by adapting a well-generalized model initialization to\nhandle new tasks. Nonetheless, these approaches suffer from the memorization\noverfitting issue, where the model tends to memorize the meta-training tasks\nwhile ignoring support sets when adapting to new tasks. To address this issue,\nwe propose a memory imitation meta-learning (MemIML) method that enhances the\nmodel's reliance on support sets for task adaptation. Specifically, we\nintroduce a task-specific memory module to store support set information and\nconstruct an imitation module to force query sets to imitate the behaviors of\nsome representative support-set samples stored in the memory. A theoretical\nanalysis is provided to prove the effectiveness of our method, and empirical\nresults also demonstrate that our method outperforms competitive baselines on\nboth text classification and generation tasks.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Yingxiu Zhao",
      "Zhiliang Tian",
      "Huaxiu Yao",
      "Yinhe Zheng",
      "Dongkyu Lee",
      "Yiping Song",
      "Jian Sun",
      "Nevin L. Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11670"
  },
  {
    "id": "arXiv:2203.11675",
    "title": "Final Revision Description of Dragonfly Algorithm, O(poly(n))",
    "abstract": "The strategy of the algorithm outlined in this paper is to reduce the\nNP-Complete problem 'exactly 1-in-3 SAT' to a problem of finding a polynomial\n$t(x)$ whose linear factors are a subset of a known set of linear factors with\nspecific roots and whose coefficients obey specific residues mod a set of small\nprimes. The algorithm uses a result that I derive relating to coprimality of\npolynomial derivatives of coprime polynomials (section 3), as well as a new\nmethod developed that will be referred to as the 'product-derivative' method\n(section 4). I provide in each section an overview of why the time complexity\nof that section's steps must be beneath some polynomial upper bound.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Rion Tolchin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.11675"
  },
  {
    "id": "arXiv:2203.11677",
    "title": "Robust Action Gap Increasing with Clipped Advantage Learning",
    "abstract": "Advantage Learning (AL) seeks to increase the action gap between the optimal\naction and its competitors, so as to improve the robustness to estimation\nerrors. However, the method becomes problematic when the optimal action induced\nby the approximated value function does not agree with the true optimal action.\nIn this paper, we present a novel method, named clipped Advantage Learning\n(clipped AL), to address this issue. The method is inspired by our observation\nthat increasing the action gap blindly for all given samples while not taking\ntheir necessities into account could accumulate more errors in the performance\nloss bound, leading to a slow value convergence, and to avoid that, we should\nadjust the advantage value adaptively. We show that our simple clipped AL\noperator not only enjoys fast convergence guarantee but also retains proper\naction gaps, hence achieving a good balance between the large action gap and\nthe fast convergence. The feasibility and effectiveness of the proposed method\nare verified empirically on several RL benchmarks with promising performance.",
    "descriptor": "",
    "authors": [
      "Zhe Zhang",
      "Yaozhong Gan",
      "Xiaoyang Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11677"
  },
  {
    "id": "arXiv:2203.11678",
    "title": "CNNs and Transformers Perceive Hybrid Images Similar to Humans",
    "abstract": "Hybrid images is a technique to generate images with two interpretations that\nchange as a function of viewing distance. It has been utilized to study\nmultiscale processing of images by the human visual system. Using 63,000 hybrid\nimages across 10 fruit categories, here we show that predictions of deep\nlearning vision models qualitatively matches with the human perception of these\nimages. Our results provide yet another evidence in support of the hypothesis\nthat Convolutional Neural Networks (CNNs) and Transformers are good at modeling\nthe feedforward sweep of information in the ventral stream of visual cortex.\nCode and data is available at https://github.com/aliborji/hybrid_images.git.",
    "descriptor": "",
    "authors": [
      "Ali Borji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11678"
  },
  {
    "id": "arXiv:2203.11683",
    "title": "Twin Weisfeiler-Lehman: High Expressive GNNs for Graph Classification",
    "abstract": "The expressive power of message passing GNNs is upper-bounded by\nWeisfeiler-Lehman (WL) test. To achieve high expressive GNNs beyond WL test, we\npropose a novel graph isomorphism test method, namely Twin-WL, which\nsimultaneously passes node labels and node identities rather than only passes\nnode label as WL. The identity-passing mechanism encodes complete structure\ninformation of rooted subgraph, and thus Twin-WL can offer extra power beyond\nWL at distinguishing graph structures. Based on Twin-WL, we implement two\nTwin-GNNs for graph classification via defining readout function over rooted\nsubgraph: one simply readouts the size of rooted subgraph and the other\nreadouts rich structure information of subgraph following a GNN-style. We prove\nthat the two Twin-GNNs both have higher expressive power than traditional\nmessage passing GNNs. Experiments also demonstrate the Twin-GNNs significantly\noutperform state-of-the-art methods at the task of graph classification.",
    "descriptor": "",
    "authors": [
      "Zhaohui Wang",
      "Qi Cao",
      "Huawei Shen",
      "Bingbing Xu",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11683"
  },
  {
    "id": "arXiv:2203.11684",
    "title": "Meta-attention for ViT-backed Continual Learning",
    "abstract": "Continual learning is a longstanding research topic due to its crucial role\nin tackling continually arriving tasks. Up to now, the study of continual\nlearning in computer vision is mainly restricted to convolutional neural\nnetworks (CNNs). However, recently there is a tendency that the newly emerging\nvision transformers (ViTs) are gradually dominating the field of computer\nvision, which leaves CNN-based continual learning lagging behind as they can\nsuffer from severe performance degradation if straightforwardly applied to\nViTs. In this paper, we study ViT-backed continual learning to strive for\nhigher performance riding on recent advances of ViTs. Inspired by mask-based\ncontinual learning methods in CNNs, where a mask is learned per task to adapt\nthe pre-trained ViT to the new task, we propose MEta-ATtention (MEAT), i.e.,\nattention to self-attention, to adapt a pre-trained ViT to new tasks without\nsacrificing performance on already learned tasks. Unlike prior mask-based\nmethods like Piggyback, where all parameters are associated with corresponding\nmasks, MEAT leverages the characteristics of ViTs and only masks a portion of\nits parameters. It renders MEAT more efficient and effective with less overhead\nand higher accuracy. Extensive experiments demonstrate that MEAT exhibits\nsignificant superiority to its state-of-the-art CNN counterparts, with 4.0~6.0%\nabsolute boosts in accuracy. Our code has been released at\nhttps://github.com/zju-vipa/MEAT-TIL.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Mengqi Xue",
      "Haofei Zhang",
      "Jie Song",
      "Mingli Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11684"
  },
  {
    "id": "arXiv:2203.11685",
    "title": "Piecewise Constant Parameters Identification Under Finite Excitation  Condition: Time Alertness Preservation, Exponential Convergence, Robustness  and Applications",
    "abstract": "The scope of this research is the identification of piecewise constant\nparameters of linear regression equations under the finite excitation\ncondition. Such an equation is considered as a switched system, which\nidentification usually consists of three main steps: a switching time instant\ndetection, choice of the most appropriate model from the known set or\ngeneration of a new one, online adjustment of the chosen model parameters.\nCompared to the known methods, to make the computational burden lower and\nsimplify the stability analysis, we use only one model to identify all\nswitching states of the regression. So, the proposed identification procedure\nincludes only two main approaches. The first one is a new estimation algorithm\nto detect switching time and preserve time alertness, which is based on a\nwell-known DREM procedure and ensures adjustable detection delay. Unlike\nexisting solutions, it does not involve an offline operation of data monitoring\nand stacking. The second one is the adaptive law, which provides element-wise\nmonotonous exponential convergence of the regression parameters to their true\nvalues over the time range between two consecutive switches. Its convergence\ncondition is that the regressor is finitely exciting somewhere inside such time\ninterval. The robustness of the proposed identification procedure to the\ninfluence of external disturbances is analytically proved. Its effectiveness is\ndemonstrated via numerical experiments, in which both abstract regressions and\na second-order plant model are used.",
    "descriptor": "\nComments: 26 pages, 10 figures\n",
    "authors": [
      "Anton Glushchenko",
      "Konstantin Lastochkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11685"
  },
  {
    "id": "arXiv:2203.11693",
    "title": "Optical Flow Based Motion Detection for Autonomous Driving",
    "abstract": "Motion detection is a fundamental but challenging task for autonomous\ndriving. In particular scenes like highway, remote objects have to be paid\nextra attention for better controlling decision. Aiming at distant vehicles, we\ntrain a neural network model to classify the motion status using optical flow\nfield information as the input. The experiments result in high accuracy,\nshowing that our idea is viable and promising. The trained model also achieves\nan acceptable performance for nearby vehicles. Our work is implemented in\nPyTorch. Open tools including nuScenes, FastFlowNet and RAFT are used.\nVisualization videos are available at\nhttps://www.youtube.com/playlist?list=PLVVrWgq4OrlBnRebmkGZO1iDHEksMHKGk .",
    "descriptor": "\nComments: This is an undergraduate research project\n",
    "authors": [
      "Ka Man Lo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11693"
  },
  {
    "id": "arXiv:2203.11695",
    "title": "Effective Communications for 6G: Challenges and Opportunities",
    "abstract": "This article studies effective communication, one of the three forms\nidentified by Weaver and Shannon, as an enabler for the upcoming 6G use cases.\nThe envisioned tactile, holographic, and multi-sensory communications require\nbandwidths in the order of terabits per second and latencies in the order of\nmicroseconds for an immersive experience. We argue that a theoretical framework\nfor transporting information tailored to end-users' goals is necessary to\nsupport such applications. Different from the recently emerging discussions\nfocusing on the meaning of exchanged messages, we focus on using these messages\nto take actions in the desired way. We highlight the essential characteristics\nof distributed knowledge accumulation as a facilitator for this upcoming\nparadigm, and discuss the challenges of making effective communications a\nreality and the potential opportunities for future research to address these\nchallenges. In a real-life use case, we showcase the potential reduction in the\nnumber of bits transferred owing to the transferred accumulated knowledge.",
    "descriptor": "",
    "authors": [
      "Ece Gelal Soyak",
      "Ozgur Ercetin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.11695"
  },
  {
    "id": "arXiv:2203.11696",
    "title": "Accelerating Extremum Seeking Convergence by Richardson Extrapolation  Methods",
    "abstract": "In this paper, we propose the concept of accelerated convergence that has\noriginally been developed to speed up the convergence of numerical methods for\nextremum seeking (ES) loops. We demonstrate how the dynamics of ES loops may be\nanalyzed to extract structural information about the generated output of the\nloop. This information is then used to distil the limit of the loop without\nhaving to wait for the system to converge to it.",
    "descriptor": "\nComments: 7 pages, 8 Figures, Submitted to CDC22\n",
    "authors": [
      "Jan-Henrik Metsch",
      "Jonathan Neuhauser",
      "Jerome Jouffroy",
      "Taous-Meriem Laleg-Kirati",
      "Johann Reger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.11696"
  },
  {
    "id": "arXiv:2203.11698",
    "title": "A Machine Learning Generative Method for Automating Antenna Design and  Optimization",
    "abstract": "To facilitate the antenna design with the aid of computer, one of the\npractices in consumer electronic industry is to model and optimize antenna\nperformances with a simplified antenna geometric scheme. Traditional antenna\nmodeling requires profound prior knowledge of electromagnetics in order to\nachieve a good design which satisfies the performance specifications from both\nantenna and product designs. The ease of handling multidimensional optimization\nproblems and the less dependence on domain knowledge and experience are the key\nto achieve the popularity of simulation driven antenna design and optimization\nfor the industry. In this paper, we introduce a flexible geometric scheme with\nthe concept of mesh network that can form any arbitrary shape by connecting\ndifferent nodes. For such problems with high dimensional parameters, we propose\na machine learning based generative method to assist the searching of optimal\nsolutions. It consists of discriminators and generators. The discriminators are\nused to predict the performance of geometric models, and the generators to\ncreate new candidates that will pass the discriminators. Moreover, an\nevolutionary criterion approach is proposed for further improving the\nefficiency of our method. Finally, not only optimal solutions can be found, but\nalso the well trained generators can be used to automate future antenna design\nand optimization. For a dual resonance antenna design with wide bandwidth, our\nproposed method is in par with Trust Region Framework and much better than the\nother mature machine learning algorithms including the widely used Genetic\nAlgorithm and Particle Swarm Optimization. When there is no wide bandwidth\nrequirement, it is better than Trust Region Framework.",
    "descriptor": "\nComments: 16 pages, 12 figures\n",
    "authors": [
      "Yang Zhong",
      "Peter Renner",
      "Weiping Dou",
      "Geng Ye",
      "Jiang Zhu",
      "Qing Huo Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.11698"
  },
  {
    "id": "arXiv:2203.11700",
    "title": "Exploring Linear Feature Disentanglement For Neural Networks",
    "abstract": "Non-linear activation functions, e.g., Sigmoid, ReLU, and Tanh, have achieved\ngreat success in neural networks (NNs). Due to the complex non-linear\ncharacteristic of samples, the objective of those activation functions is to\nproject samples from their original feature space to a linear separable feature\nspace. This phenomenon ignites our interest in exploring whether all features\nneed to be transformed by all non-linear functions in current typical NNs,\ni.e., whether there exists a part of features arriving at the linear separable\nfeature space in the intermediate layers, that does not require further\nnon-linear variation but an affine transformation instead. To validate the\nabove hypothesis, we explore the problem of linear feature disentanglement for\nneural networks in this paper. Specifically, we devise a learnable mask module\nto distinguish between linear and non-linear features. Through our designed\nexperiments we found that some features reach the linearly separable space\nearlier than the others and can be detached partly from the NNs. The explored\nmethod also provides a readily feasible pruning strategy which barely affects\nthe performance of the original model. We conduct our experiments on four\ndatasets and present promising results.",
    "descriptor": "",
    "authors": [
      "Tiantian He",
      "Zhibin Li",
      "Yongshun Gong",
      "Yazhou Yao",
      "Xiushan Nie",
      "Yilong Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11700"
  },
  {
    "id": "arXiv:2203.11702",
    "title": "BERT-ASC: Auxiliary-Sentence Construction for Implicit Aspect Learning  in Sentiment Analysis",
    "abstract": "Aspect-based sentiment analysis (ABSA) task aims to associate a piece of text\nwith a set of aspects and meanwhile infer their respective sentimental\npolarities. Up to now, the state-of-the-art approaches are built upon\nfine-tuning of various pre-trained language models. They commonly aim to learn\nthe aspect-specific representation in the corpus. Unfortunately, the aspect is\noften expressed implicitly through a set of representatives and thus renders\nimplicit mapping process unattainable unless sufficient labeled examples.\nIn this paper, we propose to jointly address aspect categorization and\naspect-based sentiment subtasks in a unified framework. Specifically, we first\nintroduce a simple but effective mechanism that collaborates the semantic and\nsyntactic information to construct auxiliary-sentences for the implicit aspect.\nThen, we encourage BERT to learn the aspect-specific representation in response\nto the automatically constructed auxiliary-sentence instead of the aspect\nitself. Finally, we empirically evaluate the performance of the proposed\nsolution by a comparative study on real benchmark datasets for both ABSA and\nTargeted-ABSA tasks. Our extensive experiments show that it consistently\nachieves state-of-the-art performance in terms of aspect categorization and\naspect-based sentiment across all datasets and the improvement margins are\nconsiderable.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Ahmed Murtadha",
      "Shengfeng Pan",
      "Bo Wen",
      "Jianlin Su",
      "Wenze Zhang",
      "Yunfeng Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11702"
  },
  {
    "id": "arXiv:2203.11705",
    "title": "Analysis and Petrov-Galerkin numerical approximation for variable  coefficient two-sided fractional diffusion, advection, reaction equations",
    "abstract": "In this paper we investigate the variable coefficient two-sided fractional\ndiffusion, advection, reaction equations on a bounded interval. It is known\nthat the fractional diffusion operator may lose coercivity due to the variable\ncoefficient, which makes both the mathematical and numerical analysis\nchallenging. To resolve this issue, we design appropriate test and trial\nfunctions to prove the inf-sup condition of the variable coefficient fractional\ndiffusion, advection, reaction operators in suitable function spaces. Based on\nthis property, we prove the well-posedness and regularity of the solutions, as\nwell as analyze the Petrov-Galerkin approximation scheme for the proposed\nmodel. Numerical experiments are presented to substantiate the theoretical\nfindings and to compare the behaviors of different models.",
    "descriptor": "",
    "authors": [
      "Xiangcheng Zheng",
      "V.J. Ervin",
      "Hong Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11705"
  },
  {
    "id": "arXiv:2203.11709",
    "title": "CP2: Copy-Paste Contrastive Pretraining for Semantic Segmentation",
    "abstract": "Recent advances in self-supervised contrastive learning yield good\nimage-level representation, which favors classification tasks but usually\nneglects pixel-level detailed information, leading to unsatisfactory transfer\nperformance to dense prediction tasks such as semantic segmentation. In this\nwork, we propose a pixel-wise contrastive learning method called CP2\n(Copy-Paste Contrastive Pretraining), which facilitates both image- and\npixel-level representation learning and therefore is more suitable for\ndownstream dense prediction tasks. In detail, we copy-paste a random crop from\nan image (the foreground) onto different background images and pretrain a\nsemantic segmentation model with the objective of 1) distinguishing the\nforeground pixels from the background pixels, and 2) identifying the composed\nimages that share the same foreground.Experiments show the strong performance\nof CP2 in downstream semantic segmentation: By finetuning CP2 pretrained models\non PASCAL VOC 2012, we obtain 78.6% mIoU with a ResNet-50 and 79.5% with a\nViT-S.",
    "descriptor": "",
    "authors": [
      "Feng Wang",
      "Huiyu Wang",
      "Chen Wei",
      "Alan Yuille",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11709"
  },
  {
    "id": "arXiv:2203.11718",
    "title": "Haar-type stochastic Galerkin formulations for hyperbolic systems with  Lipschitz continuous flux function",
    "abstract": "This work is devoted to the Galerkin projection of highly nonlinear random\nquantities. The dependency on a random input is described by Haar-type wavelet\nsystems. The classical Haar sequence has been used by Pettersson, Iaccarino,\nNordstroem (2014) for a hyperbolic stochastic Galerkin formulation of the\none-dimensional Euler equations. This work generalizes their approach to\nseveral multi-dimensional systems with Lipschitz continuous and non-polynomial\nflux functions. Theoretical results are illustrated numerically by a genuinely\nmultidimensional CWENO reconstruction.",
    "descriptor": "",
    "authors": [
      "Stephan Gerster",
      "Aleksey Sikstel",
      "Giuseppe Visconti"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.11718"
  },
  {
    "id": "arXiv:2203.11719",
    "title": "A Bayesian Approach for Shaft Centre Localisation in Journal Bearings",
    "abstract": "It has been shown that ultrasonic techniques work well for online measuring\nof circumferential oil film thickness profile in journal bearings;\nunfortunately, they can be limited by their measuring range and unable to\ncapture details of the film all around the bearing circumference. Attempts to\nmodel the film thickness over the full range of the bearing rely on\ndeterministic approaches, which assume the observations to be true with\nabsolute certainty. Unaccounted uncertainties of the film thickness may lead to\na cascade of inaccurate predictions for subsequent calculations of hydrodynamic\nparameters. In the present work, a probabilistic framework is proposed to model\nthe film thickness with Gaussian Processes. The results are then used to\nestimate the location of the bearing shaft under various operational\nconditions. A further step in the process involves using the newly-constructed\ndataset to generate likelihood maps displaying the probable location of the\nshaft centre, given the bearing rotational speed and applied static load. The\nresults offer the possibility to visualise the confidence of the predictions\nand allow the true location to be found within an area of high probability\nwithin the bearing's bore.",
    "descriptor": "",
    "authors": [
      "Christopher A. Lindley",
      "Scott Beamish",
      "Rob Dwyer-Joyce",
      "Nikolaos Dervilis",
      "Keith Worden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.11719"
  },
  {
    "id": "arXiv:2203.11720",
    "title": "Continuous Detection, Rapidly React: Unseen Rumors Detection based on  Continual Prompt-Tuning",
    "abstract": "Since open social platforms allow for a large and continuous flow of\nunverified information, rumors can emerge unexpectedly and spread quickly.\nHowever, existing rumor detection (RD) models often assume the same training\nand testing distributions and cannot cope with the continuously changing social\nnetwork environment. This paper proposes a Continual Prompt-Tuning RD (CPT-RD)\nframework, which avoids catastrophic forgetting of upstream tasks during\nsequential task learning and enables knowledge transfer between domain tasks.\nTo avoid forgetting, we optimize and store task-special soft-prompt for each\ndomain. Furthermore, we also propose several strategies to transfer knowledge\nof upstream tasks to deal with emergencies and a task-conditioned prompt-wise\nhypernetwork (TPHNet) to consolidate past domains, enabling bidirectional\nknowledge transfer. Finally, CPT-RD is evaluated on English and Chinese RD\ndatasets and is effective and efficient compared to state-of-the-art baselines,\nwithout data replay techniques and with only a few parameter tuning.",
    "descriptor": "\nComments: draft version, for submission\n",
    "authors": [
      "Yuhui Zuo",
      "Wei Zhu",
      "Guoyong Cai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11720"
  },
  {
    "id": "arXiv:2203.11724",
    "title": "Explainable Misinformation Detection Across Multiple Social Media  Platforms",
    "abstract": "In this work, the integration of two machine learning approaches, namely\ndomain adaptation and explainable AI, is proposed to address these two issues\nof generalized detection and explainability. Firstly the Domain Adversarial\nNeural Network (DANN) develops a generalized misinformation detector across\nmultiple social media platforms DANN is employed to generate the classification\nresults for test domains with relevant but unseen data. The DANN-based model, a\ntraditional black-box model, cannot justify its outcome, i.e., the labels for\nthe target domain. Hence a Local Interpretable Model-Agnostic Explanations\n(LIME) explainable AI model is applied to explain the outcome of the DANN mode.\nTo demonstrate these two approaches and their integration for effective\nexplainable generalized detection, COVID-19 misinformation is considered a case\nstudy. We experimented with two datasets, namely CoAID and MiSoVac, and\ncompared results with and without DANN implementation. DANN significantly\nimproves the accuracy measure F1 classification score and increases the\naccuracy and AUC performance. The results obtained show that the proposed\nframework performs well in the case of domain shift and can learn\ndomain-invariant features while explaining the target labels with LIME\nimplementation enabling trustworthy information processing and extraction to\ncombat misinformation effectively.",
    "descriptor": "\nComments: 28 pages,4 figures\n",
    "authors": [
      "Rahee Walambe",
      "Ananya Srivastava",
      "Bhargav Yagnik",
      "Mohammed Hasan",
      "Zainuddin Saiyed",
      "Gargi Joshi",
      "Ketan Kotecha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.11724"
  },
  {
    "id": "arXiv:2203.11728",
    "title": "Machine Learning based Data Driven Diagnostic and Prognostic Approach  for Laser Reliability Enhancement",
    "abstract": "In this paper, a data-driven diagnostic and prognostic approach based on\nmachine learning is proposed to detect laser failure modes and to predict the\nremaining useful life (RUL) of a laser during its operation. We present an\narchitecture of the proposed cognitive predictive maintenance framework and\ndemonstrate its effectiveness using synthetic data.",
    "descriptor": "\nComments: 2020 22nd International Conference on Transparent Optical Networks (ICTON)\n",
    "authors": [
      "khouloud Abdelli",
      "Helmut Griesser",
      "Stephan Pachnicke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11728"
  },
  {
    "id": "arXiv:2203.11729",
    "title": "Machine Learning based Laser Failure Mode Detection",
    "abstract": "Laser degradation analysis is a crucial process for the enhancement of laser\nreliability. Here, we propose a data-driven fault detection approach based on\nLong Short-Term Memory (LSTM) recurrent neural networks to detect the different\nlaser degradation modes based on synthetic historical failure data. In\ncomparison to typical threshold-based systems, attaining 24.41% classification\naccuracy, the LSTM-based model achieves 95.52% accuracy, and also outperforms\nclassical machine learning (ML) models namely Random Forest (RF), K-Nearest\nNeighbours (KNN) and Logistic Regression (LR).",
    "descriptor": "\nComments: 21st International Conference on Transparent Optical Networks (ICTON) 2019\n",
    "authors": [
      "khouloud Abdelli",
      "Danish Rafique",
      "Stephan Pachnicke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11729"
  },
  {
    "id": "arXiv:2203.11732",
    "title": "ProgressiveMotionSeg: Mutually Reinforced Framework for Event-Based  Motion Segmentation",
    "abstract": "Dynamic Vision Sensor (DVS) can asynchronously output the events reflecting\napparent motion of objects with microsecond resolution, and shows great\napplication potential in monitoring and other fields. However, the output event\nstream of existing DVS inevitably contains background activity noise (BA noise)\ndue to dark current and junction leakage current, which will affect the\ntemporal correlation of objects, resulting in deteriorated motion estimation\nperformance. Particularly, the existing filter-based denoising methods cannot\nbe directly applied to suppress the noise in event stream, since there is no\nspatial correlation. To address this issue, this paper presents a novel\nprogressive framework, in which a Motion Estimation (ME) module and an Event\nDenoising (ED) module are jointly optimized in a mutually reinforced manner.\nSpecifically, based on the maximum sharpness criterion, ME module divides the\ninput event into several segments by adaptive clustering in a motion\ncompensating warp field, and captures the temporal correlation of event stream\naccording to the clustered motion parameters. Taking temporal correlation as\nguidance, ED module calculates the confidence that each event belongs to real\nactivity events, and transmits it to ME module to update energy function of\nmotion segmentation for noise suppression. The two steps are iteratively\nupdated until stable motion segmentation results are obtained. Extensive\nexperimental results on both synthetic and real datasets demonstrate the\nsuperiority of our proposed approaches against the State-Of-The-Art (SOTA)\nmethods.",
    "descriptor": "\nComments: AAAI2022\n",
    "authors": [
      "Jinze Chen",
      "Yang Wang",
      "Yang Cao",
      "Feng Wu",
      "Zheng-Jun Zha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11732"
  },
  {
    "id": "arXiv:2203.11733",
    "title": "GBEM: Galerkin Boundary Element Method for 3-D Capacitance Extraction",
    "abstract": "For modern IC design, electromagnetic coupling among interconnect wires plays\nan increasingly important role in signoff analysis. The requirement of fast and\naccurate capacitance extraction is becoming more and more urgent.The critical\nstep of extracting capacitance among interconnect wires is solving electric\nfield. However, due to the high computational complexity, solving electric\nfield is extreme timing-consuming. To improve computational efficiency, we\npropose a Galerkin boundary element method (GBEM) to extract capacitance. The\nadvantage of this method is that it can greatly reduce the number of boundary\nelements on the premise of ensuring that the error is small enough. As a\nconsequence, the matrix order of the discretization equation will also\ndecrease. The experiments in this paper have proved this advantage of our\nalgorithm. Moreover, we have took advantage of some mathematical theorems in\nthis paper. Our attempt shows that there will be more connections between the\ncapacitance extraction and some mathematical conception so that we can use more\nmathematical tools to solve the problems of capacitance extraction.",
    "descriptor": "",
    "authors": [
      "Shengkun Wu",
      "Xingquan Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.11733"
  },
  {
    "id": "arXiv:2203.11735",
    "title": "A conservative multiscale method for stochastic highly heterogeneous  flow",
    "abstract": "In this paper, we propose a local model reduction approach for subsurface\nflow problems in stochastic and highly heterogeneous media. To guarantee the\nmass conservation, we consider the mixed formulation of the flow problem and\naim to solve the problem in a coarse grid to reduce the complexity of a\nlarge-scale system. We decompose the entire problem into a training and a\ntesting stage, namely the offline coarse-grid multiscale basis generation stage\nand online simulation stage with different parameters. In the training stage, a\nparameter-independent and small-dimensional multiscale basis function space is\nconstructed, which includes the media, source and boundary information. The key\npart of the basis generation stage is to solve some local problems defined\nspecially. With the parameter-independent basis space, one can efficiently\nsolve the concerned problems corresponding to different samples of permeability\nfield in a coarse grid without repeatedly constructing a multiscale space for\neach new sample. A rigorous analysis on convergence of the proposed method is\nproposed. In particular, we consider a generalization error, where bases\nconstructed with one source will be used to a different source. In the\nnumerical experiments, we apply the proposed method for both single-phase and\ntwophase flow problems. Simulation results for both 2D and 3D representative\nmodels demonstrate the high accuracy and impressive performance of the proposed\nmodel reduction techniques.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Yiran Wang",
      "Eric Chung",
      "Shubin Fu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11735"
  },
  {
    "id": "arXiv:2203.11740",
    "title": "Plasticity Neural Network Based on Astrocytic Influence at Critical  Periods, Synaptic Competition and Compensation by Current and Mnemonic Brain  Plasticity and Synapse Formation",
    "abstract": "Based on the RNN frame, we accomplished the model construction, formula\nderivation and algorithm testing for PNN. We elucidated the mechanism of PNN\nbased on the latest MIT research on synaptic compensation, and also grounded\nour study on the basis of findings of the Stanford research, which suggested\nthat synapse formation is important for competition in dendrite morphogenesis.\nThe influence of astrocytic impacts on brain plasticity and synapse formation\nis an important mechanism of our Neural Network at critical periods or the end\nof critical periods.In the model for critical periods, the hypothesis is that\nthe best brain plasticity so far affects current brain plasticity and the best\nsynapse formation so far affects current synapse formation.Furthermore, PNN\ntakes into account the mnemonic gradient informational synapse formation, and\nbrain plasticity and synapse formation change frame of NN is a new method of\nDeep Learning.The question we proposed is whether the promotion of neuroscience\nand brain cognition was achieved by model construction, formula derivation or\nalgorithm testing. We resorted to the Artificial Neural Network (ANN),\nevolutionary computation and other numerical methods for hypotheses, possible\nexplanations and rules, rather than only biological tests which include\ncutting-edge imaging and genetic tools.And it has no ethics of animal testing.",
    "descriptor": "",
    "authors": [
      "Jun-Bo Tao",
      "Bai-Qing Sun",
      "Wei-Dong Zhu",
      "Shi-You Qu",
      "Ling-Kun Chen",
      "Jia-Qiang Li",
      "Chong Wu",
      "Yu Xiong",
      "Jiaxuan Zhou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.11740"
  },
  {
    "id": "arXiv:2203.11743",
    "title": "The Stanford Drone Dataset is More Complex than We Think: An Analysis of  Key Characteristics",
    "abstract": "Several datasets exist which contain annotated information of individuals'\ntrajectories. Such datasets are vital for many real-world applications,\nincluding trajectory prediction and autonomous navigation. One prominent\ndataset currently in use is the Stanford Drone Dataset (SDD). Despite its\nprominence, discussion surrounding the characteristics of this dataset is\ninsufficient. We demonstrate how this insufficiency reduces the information\navailable to users and can impact performance. Our contributions include the\noutlining of key characteristics in the SDD, employment of an\ninformation-theoretic measure and custom metric to clearly visualize those\ncharacteristics, the implementation of the PECNet and Y-Net trajectory\nprediction models to demonstrate the outlined characteristics' impact on\npredictive performance, and lastly we provide a comparison between the SDD and\nIntersection Drone (inD) Dataset. Our analysis of the SDD's key characteristics\nis important because without adequate information about available datasets a\nuser's ability to select the most suitable dataset for their methods, to\nreproduce one another's results, and to interpret their own results are\nhindered. The observations we make through this analysis provide a readily\naccessible and interpretable source of information for those planning to use\nthe SDD. Our intention is to increase the performance and reproducibility of\nmethods applied to this dataset going forward, while also clearly detailing\nless obvious features of the dataset for new users.",
    "descriptor": "\nComments: 12 pages, 10 figures, 5 tables\n",
    "authors": [
      "Joshua Andle",
      "Nicholas Soucy",
      "Simon Socolow",
      "Salimeh Yasaei Sekeh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11743"
  },
  {
    "id": "arXiv:2203.11751",
    "title": "FedDC: Federated Learning with Non-IID Data via Local Drift Decoupling  and Correction",
    "abstract": "Federated learning (FL) allows multiple clients to collectively train a\nhigh-performance global model without sharing their private data. However, the\nkey challenge in federated learning is that the clients have significant\nstatistical heterogeneity among their local data distributions, which would\ncause inconsistent optimized local models on the client-side. To address this\nfundamental dilemma, we propose a novel federated learning algorithm with local\ndrift decoupling and correction (FedDC). Our FedDC only introduces lightweight\nmodifications in the local training phase, in which each client utilizes an\nauxiliary local drift variable to track the gap between the local model\nparameter and the global model parameters. The key idea of FedDC is to utilize\nthis learned local drift variable to bridge the gap, i.e., conducting\nconsistency in parameter-level. The experiment results and analysis demonstrate\nthat FedDC yields expediting convergence and better performance on various\nimage classification tasks, robust in partial participation settings, non-iid\ndata, and heterogeneous clients.",
    "descriptor": "\nComments: 28 pages, 13 figures, to be published in CVPR2022\n",
    "authors": [
      "Liang Gao",
      "Huazhu Fu",
      "Li Li",
      "Yingwen Chen",
      "Ming Xu",
      "Cheng-Zhong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11751"
  },
  {
    "id": "arXiv:2203.11752",
    "title": "COSTARICA estimator for rollback-less systems handling in iterative  co-simulation algorithms",
    "abstract": "Co-simulation is widely used in the industry due to the emergence of modular\ndynamical models made up of interconnected, black-boxed systems. Several\nco-simulation algorithms have been developed, each with different properties\nand different levels of accuracy and robustness. Among them, the most accurate\nand reliable ones are the iterative ones, although they have a main drawback in\ncommon: the involved systems are required to be capable of rollback. The latter\ndenotes the ability of a system to integrate over a co-simulation time step\nthat has already been simulated. Non-rollback-capable system can only go\nforward in time and every integrated step is definitive. In practice, the\nindustrial modelling and simulation platforms rarely produce rollback-capable\nsystems. This paper proposes a solution that slightly changes the co-simulation\nmethodology and that enables to use iterative co-simulation methods on a\nmodular model which contains non-rollback-capable systems in case the latter\nrepresent ordinary differential equations. The idea is to replace such a system\nby a simplified version, which is used to estimate the results of the\nintegrations instead of integrating the real system. Once the co-simulation\nmethod's surrogate iterations on these estimators predict the convergence on\nthe co-simulation step, the non-rollback-capable systems genuinely integrate\nthe step using the estimated solution on the other systems before moving\nforward, transforming the iterative co-simulation method into a non-iterative\none.",
    "descriptor": "",
    "authors": [
      "Yohan Eguillon",
      "Bruno Lacabanne",
      "Damien Tromeur-Dervout"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11752"
  },
  {
    "id": "arXiv:2203.11754",
    "title": "Exploring and Evaluating Image Restoration Potential in Dynamic Scenes",
    "abstract": "In dynamic scenes, images often suffer from dynamic blur due to superposition\nof motions or low signal-noise ratio resulted from quick shutter speed when\navoiding motions. Recovering sharp and clean results from the captured images\nheavily depends on the ability of restoration methods and the quality of the\ninput. Although existing research on image restoration focuses on developing\nmodels for obtaining better restored results, fewer have studied to evaluate\nhow and which input image leads to superior restored quality. In this paper, to\nbetter study an image's potential value that can be explored for restoration,\nwe propose a novel concept, referring to image restoration potential (IRP).\nSpecifically, We first establish a dynamic scene imaging dataset containing\ncomposite distortions and applied image restoration processes to validate the\nrationality of the existence to IRP. Based on this dataset, we investigate\nseveral properties of IRP and propose a novel deep model to accurately predict\nIRP values. By gradually distilling and selective fusing the degradation\nfeatures, the proposed model shows its superiority in IRP prediction. Thanks to\nthe proposed model, we are then able to validate how various image restoration\nrelated applications are benefited from IRP prediction. We show the potential\nusages of IRP as a filtering principle to select valuable frames, an auxiliary\nguidance to improve restoration models, and even an indicator to optimize\ncamera settings for capturing better images under dynamic scenarios.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Cheng Zhang",
      "Shaolin Su",
      "Yu Zhu",
      "Qingsen Yan",
      "Jinqiu Sun",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11754"
  },
  {
    "id": "arXiv:2203.11764",
    "title": "Listening to Affected Communities to Define Extreme Speech: Dataset and  Experiments",
    "abstract": "Building on current work on multilingual hate speech (e.g., Ousidhoum et al.\n(2019)) and hate speech reduction (e.g., Sap et al. (2020)), we present\nXTREMESPEECH, a new hate speech dataset containing 20,297 social media passages\nfrom Brazil, Germany, India and Kenya. The key novelty is that we directly\ninvolve the affected communities in collecting and annotating the data - as\nopposed to giving companies and governments control over defining and\ncombatting hate speech. This inclusive approach results in datasets more\nrepresentative of actually occurring online speech and is likely to facilitate\nthe removal of the social media content that marginalized communities view as\ncausing the most harm. Based on XTREMESPEECH, we establish novel tasks with\naccompanying baselines, provide evidence that cross-country training is\ngenerally not feasible due to cultural differences between countries and\nperform an interpretability analysis of BERT's predictions.",
    "descriptor": "\nComments: Accepted to ACL 2022 Findings\n",
    "authors": [
      "Antonis Maronikolakis",
      "Axel Wisiorek",
      "Leah Nann",
      "Haris Jabbar",
      "Sahana Udupa",
      "Hinrich Schuetze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11764"
  },
  {
    "id": "arXiv:2203.11766",
    "title": "Monitoring and mapping of crop fields with UAV swarms based on  information gain",
    "abstract": "Monitoring crop fields to map features like weeds can be efficiently\nperformed with unmanned aerial vehicles (UAVs) that can cover large areas in a\nshort time due to their privileged perspective and motion speed. However, the\nneed for high-resolution images for precise classification of features (e.g.,\ndetecting even the smallest weeds in the field) contrasts with the limited\npayload and ight time of current UAVs. Thus, it requires several flights to\ncover a large field uniformly. However, the assumption that the whole field\nmust be observed with the same precision is unnecessary when features are\nheterogeneously distributed, like weeds appearing in patches over the field. In\nthis case, an adaptive approach that focuses only on relevant areas can perform\nbetter, especially when multiple UAVs are employed simultaneously. Leveraging\non a swarm-robotics approach, we propose a monitoring and mapping strategy that\nadaptively chooses the target areas based on the expected information gain,\nwhich measures the potential for uncertainty reduction due to further\nobservations. The proposed strategy scales well with group size and leads to\nsmaller mapping errors than optimal pre-planned monitoring approaches.",
    "descriptor": "",
    "authors": [
      "Carlos Carbone",
      "Dario Albani",
      "Federico Magistri",
      "Dimitri Ognibene",
      "Cyrill Stachniss",
      "Gert Kootstra",
      "Daniele Nardi",
      "Vito Trianni"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.11766"
  },
  {
    "id": "arXiv:2203.11768",
    "title": "Inter- and Intra-Goal SDG Target Interactions in the Philippine Context:  A Two-Method Approach",
    "abstract": "In 2015, the United Nations developed 17 Sustainable Development Goals (SDGs)\nwith 169 targets for a more sustainable future by 2030. This study seeks to\nevaluate and analyze intra- and inter-goal SDG target interactions within the\nPhilippine context to determine what to mitigate and what to prioritize. To\nevaluate all 14196 target interactions, two methods are employed. First,\nexperts with over five years of SDG-related experience evaluated interactions\nusing the 7-point scale. Second, official indicator data is run through a\nSpearman rank correlation, with resulting coefficients serving as interaction\nscores. Interaction scores are then interpreted to be indivisible, cancelling,\nor consistent. Targets are modelled as nodes and interactions as edges. With\n1256 evaluated interactions under expert evaluation and 1914 under official\nindicator data, results were integrated to formulate recommendations for\nconcerned parties. This includes the mitigation of self-conflicting target\ninteractions under SDG 3 'Good Health and Well-Being' with an emphasis on\ntargets 3.6 'Halve traffic accident deaths' and 3.9 'Reduce pollution-related\ndeaths'. These targets as well as 8.2 'Economic productivity', and 16.1 'Reduce\nviolence' also have multiple negative interactions that need to be mitigated.\nTargets that reinforce their corresponding SDGs should be prioritized,\nincluding 1.1 'Eradicate extreme poverty', 1.2 'Halve poverty proportions', 3.2\n'End preventable deaths', 3.5 'Prevent substance abuse', 3.9 'Reduce\npollution-related deaths', 3.D 'EW risk reduction', 4.2 'Early education', 4.B\n'Higher education scholarships', and 6.2 'Sanitation and hygiene'. 'Beautiful'\ntargets (no negative interactions) should also be prioritized by score, namely,\n3.D 'Early warning systems for health risks', 8.A 'Trade support aid', 15.B\n'Sustainable forest management', and 17.1 'Domestic revenue collection'.",
    "descriptor": "",
    "authors": [
      "Vena Pearl Bongolan",
      "Spencer C. Soria",
      "Roselle Leah K. Rivera"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.11768"
  },
  {
    "id": "arXiv:2203.11774",
    "title": "Estimation of speaker age and height from speech signal using bi-encoder  transformer mixture model",
    "abstract": "The estimation of speaker characteristics such as age and height is a\nchallenging task, having numerous applications in voice forensic analysis. In\nthis work, we propose a bi-encoder transformer mixture model for speaker age\nand height estimation. Considering the wide differences in male and female\nvoice characteristics such as differences in formant and fundamental\nfrequencies, we propose the use of two separate transformer encoders for the\nextraction of specific voice features in the male and female gender, using\nwav2vec 2.0 as a common-level feature extractor. This architecture reduces the\ninterference effects during backpropagation and improves the generalizability\nof the model. We perform our experiments on the TIMIT dataset and significantly\noutperform the current state-of-the-art results on age estimation.\nSpecifically, we achieve root mean squared error (RMSE) of 5.54 years and 6.49\nyears for male and female age estimation, respectively. Further experiment to\nevaluate the relative importance of different phonetic types for our task\ndemonstrate that vowel sounds are the most distinguishing for age estimation.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Tarun Gupta",
      "Duc-Tuan Truong",
      "Tran The Anh",
      "Chng Eng Siong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11774"
  },
  {
    "id": "arXiv:2203.11777",
    "title": "Autonomous Bikebot Control for Crossing Obstacles with Assistive Leg  Impulsive Actuation",
    "abstract": "As a single-track mobile platform, bikebot (i.e., bicycle-based robot) has\nattractive navigation capability to pass through narrow, off-road terrain with\nhigh-speed and high-energy efficiency. However, running crossing step-like\nobstacles creates challenges for intrinsically unstable, underactuated\nbikebots. This paper presents a novel autonomous bikebot control with assistive\nleg actuation to navigate crossing obstacles. The proposed design integrates\nthe external/internal convertible-based control with leg-assisted impulse\ncontrol. The leg-terrain interaction generates assistive impulsive torques to\nhelp maintain the navigation and balance capability when running across\nobstacles. The control performance is analyzed and guaranteed. The experimental\nresults confirm that under the control design, the bikebot can smoothly run\ncrossing multiple step-like obstacles with height more than one third of the\nwheel radius. The comparison results demonstrate the superior performance than\nthose under only the velocity and steering control without leg assistive\nimpulsive actuation.",
    "descriptor": "",
    "authors": [
      "Feng Han",
      "Xinyan Huang",
      "Zenghao Wang",
      "Jingang Yi",
      "Tao Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11777"
  },
  {
    "id": "arXiv:2203.11779",
    "title": "Studying the scientific mobility and international collaboration funded  by the China Scholarship Council",
    "abstract": "Every year many scholars are funded by the China Scholarship Council (CSC).\nThe CSC is a funding agency established by the Chinese government with the main\ninitiative of training Chinese scholars to conduct research abroad and to\npromote international collaboration. In this study, we identified these\nCSC-funded scholars sponsored by the China Scholarship Council based on the\nacknowledgments text indexed by the Web of Science. Bibliometric data of their\npublications were collected to track their scientific mobility in different\nfields, and to evaluate the performance of the CSC scholarship in promoting\ninternational collaboration by sponsoring the mobility of scholars. Papers\nfunded by the China Scholarship Council are mainly from the fields of natural\nsciences and engineering sciences. There are few CSC-funded papers in the field\nof social sciences and humanities. CSC-funded scholars from mainland China have\nthe United States, Australia, Canada, and some European countries, such as\nGermany, the UK, and the Netherlands, as their preferential mobility\ndestinations across all fields of science. CSC-funded scholars published most\nof their papers with international collaboration during the mobility period,\nwith a decrease in the share of international collaboration after the support\nof the scholarship.",
    "descriptor": "\nComments: The 17th International Conference of the International Society for Scientometrics and Informetrics (ISSI 2019), Sep 2-5, Rome, Italy\n",
    "authors": [
      "Zhichao Fang",
      "Wout Lamers",
      "Rodrigo Costas"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2203.11779"
  },
  {
    "id": "arXiv:2203.11780",
    "title": "On the Modeling and Simulation of Portfolio Allocation Schemes: an  Approach based on Network Community Detection",
    "abstract": "We present a study on portfolio investments in financial applications. We\ndescribe a general modeling and simulation framework and study the impact on\nthe use of different metrics to measure the correlation among assets. In\nparticular, besides the traditional Pearson's correlation, we employ the\nDetrended Cross-Correlation Analysis (DCCA) and Detrended Partial\nCross-Correlation Analysis (DPCCA). Moreover, a novel portfolio allocation\nscheme is introduced that treats assets as a complex network and uses\nmodularity to detect communities of correlated assets. Weights of the\nallocation are then distributed among different communities for the sake of\ndiversification. Simulations compare this novel scheme against Critical Line\nAlgorithm (CLA), Inverse Variance Portfolio (IVP), the Hierarchical Risk Parity\n(HRP). Synthetic times series are generated using the Gaussian model, Geometric\nBrownian motion, GARCH, ARFIMA and modified ARFIMA models. Results show that\nthe proposed scheme outperforms state of the art approaches in many scenarios.\nWe also validate simulation results via backtesting, whose results confirm the\nviability of the proposal.",
    "descriptor": "",
    "authors": [
      "Stefano Ferretti"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Performance (cs.PF)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.11780"
  },
  {
    "id": "arXiv:2203.11782",
    "title": "On a workflow for efficient computation of the permeability of tight  sandstones",
    "abstract": "The paper presents a workflow for fast pore-scale simulation of single-phase\nflow in tight reservoirs typically characterized by low, multiscale porosity.\nMultiscale porosity implies that the computational domain contains porous\nvoxels (unresolved porosity) in addition to pure fluid voxels. In this case,\nthe Stokes-Brinkman equations govern the flow, with the Darcy term needed to\naccount for the flow in the porous voxels. As the central part of our workflow,\nrobust and efficient solvers for Stokes and Stokes-Brinkman equations are\npresented. The solvers are customized for low-porosity binary and multiclass\nimages, respectively. Another essential component of the workflow is a\npreprocessing module for classifying images with respect to the connectivity of\nthe multiscale pore space. Particularly, an approximation of the\nStokes-Brinkman problem, namely, the Darcy problem, is investigated for the\nimages that do not have pure fluid percolation paths. Thorough computational\nexperiments demonstrate efficiency and robustness of the workflow for\nsimulations on images from tight reservoirs. Raw files describing the used CT\nimages are provided as supplementary materials to enable other researchers to\nuse them.",
    "descriptor": "",
    "authors": [
      "Vladislav Pimanov",
      "Vladislav Lukoshkin",
      "Pavel Toktaliev",
      "Oleg Iliev",
      "Ekaterina Muravleva",
      "Denis Orlov",
      "Vladislav Krutko",
      "Alexander Avdonin",
      "Konrad Steiner",
      "Dmitry Koroteev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11782"
  },
  {
    "id": "arXiv:2203.11790",
    "title": "Learning Program Semantics with Code Representations: An Empirical Study",
    "abstract": "Program semantics learning is the core and fundamental for various code\nintelligent tasks e.g., vulnerability detection, clone detection. A\nconsiderable amount of existing works propose diverse approaches to learn the\nprogram semantics for different tasks and these works have achieved\nstate-of-the-art performance. However, currently, a comprehensive and\nsystematic study on evaluating different program representation techniques\nacross diverse tasks is still missed.\nFrom this starting point, in this paper, we conduct an empirical study to\nevaluate different program representation techniques. Specifically, we\ncategorize current mainstream code representation techniques into four\ncategories i.e., Feature-based, Sequence-based, Tree-based, and Graph-based\nprogram representation technique and evaluate its performance on three diverse\nand popular code intelligent tasks i.e., {Code Classification}, Vulnerability\nDetection, and Clone Detection on the public released benchmark. We further\ndesign three {research questions (RQs)} and conduct a comprehensive analysis to\ninvestigate the performance. By the extensive experimental results, we conclude\nthat (1) The graph-based representation is superior to the other selected\ntechniques across these tasks. (2) Compared with the node type information used\nin tree-based and graph-based representations, the node textual information is\nmore critical to learning the program semantics. (3) Different tasks require\nthe task-specific semantics to achieve their highest performance, however\ncombining various program semantics from different dimensions such as control\ndependency, data dependency can still produce promising results.",
    "descriptor": "\nComments: Accepted in 29th edition IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER 2022)\n",
    "authors": [
      "Jing Kai Siow",
      "Shangqing Liu",
      "Xiaofei Xie",
      "Guozhu Meng",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.11790"
  },
  {
    "id": "arXiv:2203.11793",
    "title": "A Perspective on Neural Capacity Estimation: Viability and Reliability",
    "abstract": "Recently, several methods have been proposed for estimating the mutual\ninformation from sample data using deep neural networks and without the\nknowledge of closed-form distribution of the data. This class of estimators is\nreferred to as neural mutual information estimators (NMIE). In this paper, we\ninvestigate the performance of different NMIE proposed in the literature when\napplied to the capacity estimation problem. In particular, we study the\nperformance of mutual information neural estimator (MINE), smoothed mutual\ninformation lower-bound estimator (SMILE), and directed information neural\nestimator (DINE). For the NMIE above, capacity estimation relies on two deep\nneural networks (DNN): (i) one DNN generates samples from a distribution that\nis learned, and (ii) a DNN to estimate the MI between the channel input and the\nchannel output. We benchmark these NMIE in three scenarios: (i) AWGN channel\ncapacity estimation and (ii) channels with unknown capacity and continuous\ninputs i.e., optical intensity and peak-power constrained AWGN channel (iii)\nchannels with unknown capacity and a discrete number of mass points i.e.,\nPoisson channel. Additionally, we also (iv) consider the extension to the MAC\ncapacity problem by considering the AWGN and optical MAC models.",
    "descriptor": "\nComments: 30 pages, 8 figures, submitted for possible journal publication. arXiv admin note: text overlap with arXiv:2111.07401\n",
    "authors": [
      "Farhad Mirkarimi",
      "Stefano Rini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.11793"
  },
  {
    "id": "arXiv:2203.11795",
    "title": "Minimizing communication in the multidimensional FFT",
    "abstract": "We present a parallel algorithm for the fast Fourier transform (FFT) in\nhigher dimensions. This algorithm generalizes the cyclic-to-cyclic\none-dimensional parallel algorithm to a cyclic-to-cyclic multidimensional\nparallel algorithm while retaining the property of needing only a single\nall-to-all communication step. This is under the constraint that we use at most\n$\\sqrt{N}$ processors for an FFT on an array with a total of $N$ elements,\nirrespective of the dimension $d$ or shape of the array. The only assumption we\nmake is that $N$ is sufficiently composite. Our algorithm starts and ends in\nthe same distribution.\nWe present our multidimensional implementation FFTU which utilizes the\nsequential FFTW program for its local FFTs, and which can handle any dimension\n$d$. We obtain experimental results for $d\\leq 5$ using MPI on up to 4096 cores\nof the supercomputer Snellius, comparing FFTU with the parallel FFTW program\nand with PFFT. These results show that FFTU is competitive with the\nstate-of-the-art and that it allows to use a larger number of processors, while\nkeeping communication limited to a single all-to-all operation. For arrays of\nsize $1024^3$ and $64^5$, FFTU achieves a speedup of a factor 149 and 176,\nrespectively, on 4096 processors.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Thomas Koopman",
      "Rob H. Bisseling"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11795"
  },
  {
    "id": "arXiv:2203.11797",
    "title": "A Novel Framework for Assessment of Learning-based Detectors in  Realistic Conditions with Application to Deepfake Detection",
    "abstract": "Deep convolutional neural networks have shown remarkable results on multiple\ndetection tasks. Despite the significant progress, the performance of such\ndetectors are often assessed in public benchmarks under non-realistic\nconditions. Specifically, impact of conventional distortions and processing\noperations such as compression, noise, and enhancement are not sufficiently\nstudied. This paper proposes a rigorous framework to assess performance of\nlearning-based detectors in more realistic situations. An illustrative example\nis shown under deepfake detection context. Inspired by the assessment results,\na data augmentation strategy based on natural image degradation process is\ndesigned, which significantly improves the generalization ability of two\ndeepfake detectors.",
    "descriptor": "",
    "authors": [
      "Yuhang Lu",
      "Ruizhi Luo",
      "Touradj Ebrahimi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.11797"
  },
  {
    "id": "arXiv:2203.11799",
    "title": "AP-BSN: Self-Supervised Denoising for Real-World Images via Asymmetric  PD and Blind-Spot Network",
    "abstract": "Blind-spot network (BSN) and its variants have made significant advances in\nself-supervised denoising. Nevertheless, they are still bound to synthetic\nnoisy inputs due to less practical assumptions like pixel-wise independent\nnoise. Hence, it is challenging to deal with spatially correlated real-world\nnoise using self-supervised BSN. Recently, pixel-shuffle downsampling (PD) has\nbeen proposed to remove the spatial correlation of real-world noise. However,\nit is not trivial to integrate PD and BSN directly, which prevents the fully\nself-supervised denoising model on real-world images. We propose an Asymmetric\nPD (AP) to address this issue, which introduces different PD stride factors for\ntraining and inference. We systematically demonstrate that the proposed AP can\nresolve inherent trade-offs caused by specific PD stride factors and make BSN\napplicable to practical scenarios. To this end, we develop AP-BSN, a\nstate-of-the-art self-supervised denoising method for real-world sRGB images.\nWe further propose random-replacing refinement, which significantly improves\nthe performance of our AP-BSN without any additional parameters. Extensive\nstudies demonstrate that our method outperforms the other self-supervised and\neven unpaired denoising methods by a large margin, without using any additional\nknowledge, e.g., noise level, regarding the underlying unknown noise.",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Wooseok Lee",
      "Sanghyun Son",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.11799"
  },
  {
    "id": "arXiv:2203.11804",
    "title": "Information-Theoretic Approaches to Differential Privacy",
    "abstract": "This tutorial studies relationships between differential privacy and various\ninformation-theoretic measures using several selective articles. In particular,\nwe present how these relationships can provide new interpretations for the\nprivacy guarantee in systems that deploy differential privacy in an\ninformation-theoretic framework. To this end, this work offers an extensive\nsummary on the existing literature that makes use of information-theoretic\nmeasures and tools such as mutual information, min entropy, Kullback-Leibler\ndivergence and rate-distortion function for quantifying differential privacy in\nvarious settings.",
    "descriptor": "",
    "authors": [
      "Ayse Unsal",
      "Melek Onen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.11804"
  },
  {
    "id": "arXiv:2203.11805",
    "title": "On Robust Classification using Contractive Hamiltonian Neural ODEs",
    "abstract": "Deep neural networks can be fragile and sensitive to small input\nperturbations that might cause a significant change in the output. In this\npaper, we employ contraction theory to improve the robustness of neural ODEs\n(NODEs). A dynamical system is contractive if all solutions with different\ninitial conditions converge to each other asymptotically. As a consequence,\nperturbations in initial conditions become less and less relevant over time.\nSince in NODEs, the input data corresponds to the initial condition of\ndynamical systems, we show contractivity can mitigate the effect of input\nperturbations. More precisely, inspired by NODEs with Hamiltonian dynamics, we\npropose a class of contractive Hamiltonian NODEs (CH-NODEs). By properly tuning\na scalar parameter, CH-NODEs ensure contractivity by design and can be trained\nusing standard backpropagation and gradient descent algorithms. Moreover,\nCH-NODEs enjoy built-in guarantees of non-exploding gradients, which ensures a\nwell-posed training process. Finally, we demonstrate the robustness of CH-NODEs\non the MNIST image classification problem with noisy test datasets.",
    "descriptor": "",
    "authors": [
      "Muhammad Zakwan",
      "Liang Xu",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11805"
  },
  {
    "id": "arXiv:2203.11807",
    "title": "A New Approach to Improve Learning-based Deepfake Detection in Realistic  Conditions",
    "abstract": "Deep convolutional neural networks have achieved exceptional results on\nmultiple detection and recognition tasks. However, the performance of such\ndetectors are often evaluated in public benchmarks under constrained and\nnon-realistic situations. The impact of conventional distortions and processing\noperations found in imaging workflows such as compression, noise, and\nenhancement are not sufficiently studied. Currently, only a few researches have\nbeen done to improve the detector robustness to unseen perturbations. This\npaper proposes a more effective data augmentation scheme based on real-world\nimage degradation process. This novel technique is deployed for deepfake\ndetection tasks and has been evaluated by a more realistic assessment\nframework. Extensive experiments show that the proposed data augmentation\nscheme improves generalization ability to unpredictable data distortions and\nunseen datasets.",
    "descriptor": "",
    "authors": [
      "Yuhang Lu",
      "Touradj Ebrahimi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.11807"
  },
  {
    "id": "arXiv:2203.11810",
    "title": "Analysis Method of Strapdown Inertial Navigation Error Distribution  Based on Covariance Matrix Decomposition",
    "abstract": "Error distribution analysis is an important assistant technology for the\nresearch of SINS(Strapdown Inertial Navigation System). Error distribution\nresult can provide the contribution of different errors to final navigation\nerror, which is helpful for modifying and optimizing SINS. To realize\ndecomposing the navigation error into parts that caused by each error source,\nthe SINS error state space model is established and covariance matrix is\ndecomposed according to error sources. The proposed error distribution analysis\nmethod based on 34-dimension SINS error model can quantitatively analyze the\ncontribution to the end navigation error of initial errors, IMU(Inertial\nMeasurement Unit) bias, IMU scale factor errors, mounting errors of gyroscopes\nand accelerometers, and IMU stochastic errors. The simulations in static\ncondition and single axis rotation condition indict that the distribution\nresult of proposed analysis method accords with the law of error propagation.\nAfter trajectory determined, the corresponding error distribution result will\nbe calculated with the proposed method. Compared with the Monte-Carlo method\nand other method based on covariance matrix, the proposed method uses more\ncomplete error model, considers the interaction effect of error sources and can\nbe easily realized with less computation.",
    "descriptor": "",
    "authors": [
      "Xiaokang Yang",
      "Gongmin Yan",
      "Fan Liu",
      "Bofan Guan",
      "Sihai Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11810"
  },
  {
    "id": "arXiv:2203.11812",
    "title": "Neural System Level Synthesis: Learning over All Stabilizing Policies  for Nonlinear Systems",
    "abstract": "We address the problem of designing stabilizing control policies for\nnonlinear systems in discrete-time, while minimizing an arbitrary cost\nfunction. When the system is linear and the cost is convex, the System Level\nSynthesis (SLS) approach offers an exact solution based on convex programming.\nBeyond this case, a globally optimal solution cannot be found in a tractable\nway, in general. In this paper, we develop a parametrization of all and only\nthe control policies stabilizing a given time-varying nonlinear system in terms\nof the combined effect of 1) a strongly stabilizing base controller and 2) a\nstable SLS operator to be freely designed. Based on this result, we propose a\nNeural SLS (Neur-SLS) approach guaranteeing closed-loop stability during and\nafter parameter optimization, without requiring any constraints to be\nsatisfied. We exploit recent Deep Neural Network (DNN) models based on\nRecurrent Equilibrium Networks (RENs) to learn over a rich class of nonlinear\nstable operators, and demonstrate the effectiveness of the proposed approach in\nnumerical examples.",
    "descriptor": "",
    "authors": [
      "Luca Furieri",
      "Clara Luc\u00eda Galimberti",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11812"
  },
  {
    "id": "arXiv:2203.11813",
    "title": "Weight distributions of two classes of linear codes based on Gaussian  period and Weil sums",
    "abstract": "In this paper, based on the theory of defining sets, two classes of at most\nsix-weight linear codes over $\\mathbb{F}_p$ are constructed. The weight\ndistributions of the linear codes are determined by means of Gaussian period\nand Weil sums. In some case, there is an almost optimal code with respect to\nGriesmer bound, which is also an optimal one according to the online code\ntable. The linear codes can also be employed to get secret sharing schemes.",
    "descriptor": "",
    "authors": [
      "Xina Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.11813"
  },
  {
    "id": "arXiv:2203.11815",
    "title": "Clustering units in neural networks: upstream vs downstream information",
    "abstract": "It has been hypothesized that some form of \"modular\" structure in artificial\nneural networks should be useful for learning, compositionality, and\ngeneralization. However, defining and quantifying modularity remains an open\nproblem. We cast the problem of detecting functional modules into the problem\nof detecting clusters of similar-functioning units. This begs the question of\nwhat makes two units functionally similar. For this, we consider two broad\nfamilies of methods: those that define similarity based on how units respond to\nstructured variations in inputs (\"upstream\"), and those based on how variations\nin hidden unit activations affect outputs (\"downstream\"). We conduct an\nempirical study quantifying modularity of hidden layer representations of\nsimple feedforward, fully connected networks, across a range of\nhyperparameters. For each model, we quantify pairwise associations between\nhidden units in each layer using a variety of both upstream and downstream\nmeasures, then cluster them by maximizing their \"modularity score\" using\nestablished tools from network science. We find two surprising results: first,\ndropout dramatically increased modularity, while other forms of weight\nregularization had more modest effects. Second, although we observe that there\nis usually good agreement about clusters within both upstream methods and\ndownstream methods, there is little agreement about the cluster assignments\nacross these two families of methods. This has important implications for\nrepresentation-learning, as it suggests that finding modular representations\nthat reflect structure in inputs (e.g. disentanglement) may be a distinct goal\nfrom learning modular representations that reflect structure in outputs (e.g.\ncompositionality).",
    "descriptor": "\nComments: 12 main text pages, 4 main figures, 5 supplemental figures. Will be submitted to TMLR\n",
    "authors": [
      "Richard D. Lange",
      "David S. Rolnick",
      "Konrad P. Kording"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.11815"
  },
  {
    "id": "arXiv:2203.11816",
    "title": "A Novel Exploration of Diffusion Process based on Multi-types  Galton-Watson Forests",
    "abstract": "Diffusion is a commonly used technique for spreading information from point\nto point on a graph. The rationale behind diffusion is not clear. And the\nmulti-types Galton-Watson forest is a random model of population growth without\nspace or any other resource constraints. In this paper, we use the degenerated\nmulti-types Galton-Watson forest (MGWF) to interpret the diffusion process and\nestablish an equivalent relationship between them. With the two-phase setting\nof the MGWF, one can interpret the diffusion process and the Google PageRank\nsystem explicitly. It also improves the convergence behaviour of the iterative\ndiffusion process and Google PageRank system. We validate the proposal by\nexperiment while providing new research directions.",
    "descriptor": "",
    "authors": [
      "Yanjiao Zhu",
      "Qilin Li",
      "Wanquan Liu",
      "Chuancun Yin",
      "Zhenlong Gao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11816"
  },
  {
    "id": "arXiv:2203.11817",
    "title": "Modeling Tie Duration in ERGM-Based Dynamic Network Models",
    "abstract": "Krivitsky and Handcock (2014) proposed a Separable Temporal ERGM (STERGM)\nframework for modeling social networks, which facilitates separable modeling of\nthe tie duration distributions and the structural dynamics of tie formation. In\nthis note, we explore the hazard structures achievable in this framework, with\nfirst- and higher-order Markov assumptions, and propose ways to model a variety\nof duration distributions in this framework.",
    "descriptor": "\nComments: Reposting of Penn State University Department of Statistics Technical Report 12-02 (April 2012), lost in a web site migration; 14 pages, 3 figures, 1 table. arXiv admin note: text overlap with arXiv:2203.06866\n",
    "authors": [
      "Pavel N. Krivitsky"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.11817"
  },
  {
    "id": "arXiv:2203.11819",
    "title": "A Broad Study of Pre-training for Domain Generalization and Adaptation",
    "abstract": "Deep models must learn robust and transferable representations in order to\nperform well on new domains. While domain transfer methods (e.g., domain\nadaptation, domain generalization) have been proposed to learn transferable\nrepresentations across domains, they are typically applied to ResNet backbones\npre-trained on ImageNet. Thus, existing works pay little attention to the\neffects of pre-training on domain transfer tasks. In this paper, we provide a\nbroad study and in-depth analysis of pre-training for domain adaptation and\ngeneralization, namely: network architectures, size, pre-training loss, and\ndatasets. We observe that simply using a state-of-the-art backbone outperforms\nexisting state-of-the-art domain adaptation baselines and set new baselines on\nOffice-Home and DomainNet improving by 10.7\\% and 5.5\\%. We hope that this work\ncan provide more insights for future domain transfer research.",
    "descriptor": "",
    "authors": [
      "Donghyun Kim",
      "Kaihong Wang",
      "Stan Sclaroff",
      "Kate Saenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11819"
  },
  {
    "id": "arXiv:2203.11824",
    "title": "Was that so hard? Estimating human classification difficulty",
    "abstract": "When doctors are trained to diagnose a specific disease, they learn faster\nwhen presented with cases in order of increasing difficulty. This creates the\nneed for automatically estimating how difficult it is for doctors to classify a\ngiven case. In this paper, we introduce methods for estimating how hard it is\nfor a doctor to diagnose a case represented by a medical image, both when\nground truth difficulties are available for training, and when they are not.\nOur methods are based on embeddings obtained with deep metric learning.\nAdditionally, we introduce a practical method for obtaining ground truth human\ndifficulty for each image case in a dataset using self-assessed certainty. We\napply our methods to two different medical datasets, achieving high Kendall\nrank correlation coefficients, showing that we outperform existing methods by a\nlarge margin on our problem and data.",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Morten Rieger Hannemose",
      "Josefine Vilsb\u00f8ll Sundgaard",
      "Niels Kvorning Ternov",
      "Rasmus R. Paulsen",
      "Anders Nymark Christensen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11824"
  },
  {
    "id": "arXiv:2203.11826",
    "title": "Reduction of Register Pushdown Systems with Freshness Property to  Pushdown Systems in LTL Model Checking",
    "abstract": "Pushdown systems (PDS) are known as an abstract model of recursive programs,\nand model checking methods for PDS have been studied. Register PDS (RPDS) are\nPDS augmented by registers to deal with data values from an infinite domain in\na restricted way. A linear temporal logic (LTL) model checking method for RPDS\nwith regular valuations has been proposed; however, the method requires the\nregister automata (RA) used for representing a regular valuation to be\nbackward-deterministic. This paper proposes another approach to the same\nproblem, in which the model checking problem for RPDS is reduced to that\nproblem for PDS by constructing a PDS bisimulation equivalent to a given RPDS.\nThe construction in the proposed method is simpler than the previous model\nchecking method and does not require RAs deterministic or\nbackward-deterministic, and the bisimulation equivalence clearly guarantees the\ncorrectness of this reduction. On the other hand, the proposed method requires\nevery RPDS (and RA) to have the freshness property, in which whenever the RPDS\nupdates a register with a data value not stored in any register or the stack\ntop, the value should be fresh. This paper also shows that this model checking\nproblem with regular valuations defined by general RA is undecidable, and thus\nthe freshness constraint is essential in the proposed method.",
    "descriptor": "\nComments: 9 pages, 2 figures, this is a longer version of a short paper submitted to IEICE Transactions on Information and Systems\n",
    "authors": [
      "Yoshiaki Takata",
      "Ryoma Senda",
      "Hiroyuki Seki"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.11826"
  },
  {
    "id": "arXiv:2203.11828",
    "title": "Explainable Landscape Analysis in Automated Algorithm Performance  Prediction",
    "abstract": "Predicting the performance of an optimization algorithm on a new problem\ninstance is crucial in order to select the most appropriate algorithm for\nsolving that problem instance. For this purpose, recent studies learn a\nsupervised machine learning (ML) model using a set of problem landscape\nfeatures linked to the performance achieved by the optimization algorithm.\nHowever, these models are black-box with the only goal of achieving good\npredictive performance, without providing explanations which landscape features\ncontribute the most to the prediction of the performance achieved by the\noptimization algorithm. In this study, we investigate the expressiveness of\nproblem landscape features utilized by different supervised ML models in\nautomated algorithm performance prediction. The experimental results point out\nthat the selection of the supervised ML method is crucial, since different\nsupervised ML regression models utilize the problem landscape features\ndifferently and there is no common pattern with regard to which landscape\nfeatures are the most informative.",
    "descriptor": "\nComments: To appear in International Conference on the Applications of Evolutionary Computation 2022 (Part of EvoStar 2022). arXiv admin note: text overlap with arXiv:2110.11633\n",
    "authors": [
      "Risto Trajanov",
      "Stefan Dimeski",
      "Martin Popovski",
      "Peter Koro\u0161ec",
      "Tome Eftimov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.11828"
  },
  {
    "id": "arXiv:2203.11832",
    "title": "Cross-View Panorama Image Synthesis",
    "abstract": "In this paper, we tackle the problem of synthesizing a ground-view panorama\nimage conditioned on a top-view aerial image, which is a challenging problem\ndue to the large gap between the two image domains with different view-points.\nInstead of learning cross-view mapping in a feedforward pass, we propose a\nnovel adversarial feedback GAN framework named PanoGAN with two key components:\nan adversarial feedback module and a dual branch discrimination strategy.\nFirst, the aerial image is fed into the generator to produce a target panorama\nimage and its associated segmentation map in favor of model training with\nlayout semantics. Second, the feature responses of the discriminator encoded by\nour adversarial feedback module are fed back to the generator to refine the\nintermediate representations, so that the generation performance is continually\nimproved through an iterative generation process. Third, to pursue\nhigh-fidelity and semantic consistency of the generated panorama image, we\npropose a pixel-segmentation alignment mechanism under the dual branch\ndiscrimiantion strategy to facilitate cooperation between the generator and the\ndiscriminator. Extensive experimental results on two challenging cross-view\nimage datasets show that PanoGAN enables high-quality panorama image generation\nwith more convincing details than state-of-the-art approaches. The source code\nand trained models are available at \\url{https://github.com/sswuai/PanoGAN}.",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Multimedia\n",
    "authors": [
      "Songsong Wu",
      "Hao Tang",
      "Xiao-Yuan Jing",
      "Haifeng Zhao",
      "Jianjun Qian",
      "Nicu Sebe",
      "Yan Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.11832"
  },
  {
    "id": "arXiv:2203.11834",
    "title": "Improving Generalization in Federated Learning by Seeking Flat Minima",
    "abstract": "Models trained in federated settings often suffer from degraded performances\nand fail at generalizing, especially when facing heterogeneous scenarios. In\nthis work, we investigate such behavior through the lens of geometry of the\nloss and Hessian eigenspectrum, linking the model's lack of generalization\ncapacity to the sharpness of the solution. Motivated by prior studies\nconnecting the sharpness of the loss surface and the generalization gap, we\nshow that i) training clients locally with Sharpness-Aware Minimization (SAM)\nor its adaptive version (ASAM) and ii) averaging stochastic weights (SWA) on\nthe server-side can substantially improve generalization in Federated Learning\nand help bridging the gap with centralized models. By seeking parameters in\nneighborhoods having uniform low loss, the model converges towards flatter\nminima and its generalization significantly improves in both homogeneous and\nheterogeneous scenarios. Empirical results demonstrate the effectiveness of\nthose optimizers across a variety of benchmark vision datasets (e.g.\nCIFAR10/100, Landmarks-User-160k, IDDA) and tasks (large scale classification,\nsemantic segmentation, domain generalization).",
    "descriptor": "",
    "authors": [
      "Debora Caldarola",
      "Barbara Caputo",
      "Marco Ciccone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11834"
  },
  {
    "id": "arXiv:2203.11835",
    "title": "Rendering Layered Materials with Diffuse Interfaces",
    "abstract": "In this work, we introduce a novel method to render, in real-time, Lambertian\nsurfaces with a rough dieletric coating. We show that the appearance of such\nconfigurations is faithfully represented with two microfacet lobes accounting\nfor direct and indirect interactions respectively. We numerically fit these\nlobes based on the first order directional statistics (energy, mean and\nvariance) of light transport using 5D tables and narrow them down to 2D + 1D\nwith analytical forms and dimension reduction. We demonstrate the quality of\nour method by efficiently rendering rough plastics and ceramics, closely\nmatching ground truth. In addition, we improve a state-of-the-art layered\nmaterial model to include Lambertian interfaces.",
    "descriptor": "",
    "authors": [
      "H\u00e9lo\u00efse de Dinechin",
      "Laurent Belcour"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.11835"
  },
  {
    "id": "arXiv:2203.11836",
    "title": "A Real-time Junk Food Recognition System based on Machine Learning",
    "abstract": "$ $As a result of bad eating habits, humanity may be destroyed. People are\nconstantly on the lookout for tasty foods, with junk foods being the most\ncommon source. As a consequence, our eating patterns are shifting, and we're\ngravitating toward junk food more than ever, which is bad for our health and\nincreases our risk of acquiring health problems. Machine learning principles\nare applied in every aspect of our lives, and one of them is object recognition\nvia image processing. However, because foods vary in nature, this procedure is\ncrucial, and traditional methods like ANN, SVM, KNN, PLS etc., will result in a\nlow accuracy rate. All of these issues were defeated by the Deep Neural\nNetwork. In this work, we created a fresh dataset of 10,000 data points from 20\njunk food classifications to try to recognize junk foods. All of the data in\nthe data set was gathered using the Google search engine, which is thought to\nbe one-of-a-kind in every way. The goal was achieved using Convolution Neural\nNetwork (CNN) technology, which is well-known for image processing. We achieved\na 98.05\\% accuracy rate throughout the research, which was satisfactory. In\naddition, we conducted a test based on a real-life event, and the outcome was\nextraordinary. Our goal is to advance this research to the next level, so that\nit may be applied to a future study. Our ultimate goal is to create a system\nthat would encourage people to avoid eating junk food and to be\nhealth-conscious. \\keywords{ Machine Learning \\and junk food \\and object\ndetection \\and YOLOv3 \\and custom food dataset.}",
    "descriptor": "\nComments: 15 pages, 7 figures, accepted in ICBBDB conference\n",
    "authors": [
      "Sirajum Munira Shifat",
      "Takitazwar Parthib",
      "Sabikunnahar Talukder Pyaasa",
      "Nila Maitra Chaity",
      "Niloy Kumar",
      "Md. Kishor Morol"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11836"
  },
  {
    "id": "arXiv:2203.11839",
    "title": "Piecewise discretization of monodromy operators of delay equations on  adapted meshes",
    "abstract": "Periodic solutions of delay equations are usually approximated as continuous\npiecewise polynomials on meshes adapted to the solutions' profile. In practical\ncomputations this affects the regularity of the (coefficients of the)\nlinearized system and, in turn, the effectiveness of assessing local stability\nby approximating the Floquet multipliers. To overcome this problem when\ncomputing multipliers by collocation, the discretization grid should include\nthe piecewise adapted mesh of the computed periodic solution. By introducing a\npiecewise version of existing pseudospectral techniques, we explain why and\nshow experimentally that this choice is essential in presence of either strong\nmesh adaptation or nontrivial multipliers whose eigenfunctions' profile is\nunrelated to that of the periodic solution.",
    "descriptor": "\nComments: This is a pre-copy-editing, author-produced PDF of an article accepted for publication in Journal of Computational Dynamics following peer review\n",
    "authors": [
      "Dimitri Breda",
      "Davide Liessi",
      "Rossana Vermiglio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11839"
  },
  {
    "id": "arXiv:2203.11841",
    "title": "SU-NLP at SemEval-2022 Task 11: Complex Named Entity Recognition with  Entity Linking",
    "abstract": "This paper describes the system proposed by Sabanc{\\i} University Natural\nLanguage Processing Group in the SemEval-2022 MultiCoNER task. We developed an\nunsupervised entity linking pipeline that detects potential entity mentions\nwith the help of Wikipedia and also uses the corresponding Wikipedia context to\nhelp the classifier in finding the named entity type of that mention. Our\nresults showed that our pipeline improved performance significantly, especially\nfor complex entities in low-context settings.",
    "descriptor": "",
    "authors": [
      "Buse \u00c7ar\u0131k",
      "Fatih Beyhan",
      "Reyyan Yeniterzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11841"
  },
  {
    "id": "arXiv:2203.11842",
    "title": "X-MEN: Guaranteed XOR-Maximum Entropy Constrained Inverse Reinforcement  Learning",
    "abstract": "Inverse Reinforcement Learning (IRL) is a powerful way of learning from\ndemonstrations. In this paper, we address IRL problems with the availability of\nprior knowledge that optimal policies will never violate certain constraints.\nConventional approaches ignoring these constraints need many demonstrations to\nconverge. We propose XOR-Maximum Entropy Constrained Inverse Reinforcement\nLearning (X-MEN), which is guaranteed to converge to the optimal policy in\nlinear rate w.r.t. the number of learning iterations. X-MEN embeds XOR-sampling\n-- a provable sampling approach that transforms the #P complete sampling\nproblem into queries to NP oracles -- into the framework of maximum entropy\nIRL. X-MEN also guarantees the learned policy will never generate trajectories\nthat violate constraints. Empirical results in navigation demonstrate that\nX-MEN converges faster to the optimal policies compared to baseline approaches\nand always generates trajectories that satisfy multi-state combinatorial\nconstraints.",
    "descriptor": "",
    "authors": [
      "Fan Ding",
      "Yeiang Xue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11842"
  },
  {
    "id": "arXiv:2203.11847",
    "title": "Spectral Algorithms Optimally Recover (Censored) Planted Dense Subgraphs",
    "abstract": "We study spectral algorithms for the planted dense subgraph problem (PDS), as\nwell as for a censored variant (CPDS) of PDS, where the edge statuses are\nmissing at random. More precisely, in the PDS model, we consider $n$ vertices\nand a random subset of vertices $S^{\\star}$ of size $\\Omega(n)$, such that two\nvertices share an edge with probability $p$ if both of them are in $S^{\\star}$,\nand all other edges are present with probability $q$, independently. The goal\nis to recover $S^{\\star}$ from one observation of the network. In the CPDS\nmodel, edge statuses are revealed with probability $\\frac{t \\log n}{n}$. For\nthe PDS model, we show that a simple spectral algorithm based on the top two\neigenvectors of the adjacency matrix can recover $S^{\\star}$ up to the\ninformation theoretic threshold. Prior work by Hajek, Wu and Xu required a less\nefficient SDP based algorithm to recover $S^{\\star}$ up to the information\ntheoretic threshold. For the CDPS model, we obtain the information theoretic\nlimit for the recovery problem, and further show that a spectral algorithm\nbased on a special matrix called the signed adjacency matrix recovers\n$S^{\\star}$ up to the information theoretic threshold.",
    "descriptor": "\nComments: 24 pages, 2 figures\n",
    "authors": [
      "Souvik Dhara",
      "Julia Gaudio",
      "Elchanan Mossel",
      "Colin Sandon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.11847"
  },
  {
    "id": "arXiv:2203.11849",
    "title": "A Girl Has A Name, And It's ... Adversarial Authorship Attribution for  Deobfuscation",
    "abstract": "Recent advances in natural language processing have enabled powerful\nprivacy-invasive authorship attribution. To counter authorship attribution,\nresearchers have proposed a variety of rule-based and learning-based text\nobfuscation approaches. However, existing authorship obfuscation approaches do\nnot consider the adversarial threat model. Specifically, they are not evaluated\nagainst adversarially trained authorship attributors that are aware of\npotential obfuscation. To fill this gap, we investigate the problem of\nadversarial authorship attribution for deobfuscation. We show that\nadversarially trained authorship attributors are able to degrade the\neffectiveness of existing obfuscators from 20-30% to 5-10%. We also evaluate\nthe effectiveness of adversarial training when the attributor makes incorrect\nassumptions about whether and which obfuscator was used. While there is a a\nclear degradation in attribution accuracy, it is noteworthy that this\ndegradation is still at or above the attribution accuracy of the attributor\nthat is not adversarially trained at all. Our results underline the need for\nstronger obfuscation approaches that are resistant to deobfuscation",
    "descriptor": "\nComments: 9 pages, 7 figures, 3 tables, ACL 2022\n",
    "authors": [
      "Wanyue Zhai",
      "Jonathan Rusert",
      "Zubair Shafiq",
      "Padmini Srinivasan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11849"
  },
  {
    "id": "arXiv:2203.11851",
    "title": "Cryptographic switching functions for multiplicative watermarking in  cyber-physical systems",
    "abstract": "In this paper we present a novel switching function for multiplicative\nwatermarking systems. The switching function is based on the algebraic\nstructure of elliptic curves over finite fields. The resulting function allows\nfor both watermarking generator and remover to define appropriate system\nparameters, sharing only limited information, namely a private key. Given the\ndefinition of the switching function, we prove that the resulting watermarking\nparameters lead to a stable watermarking scheme.",
    "descriptor": "\nComments: 8 pages, 3 figures, to be presented at: 11th IFAC Symposium on Fault Detection, Supervision and Safety for Technical Processes - SAFEPROCESS\n",
    "authors": [
      "Alexander J. Gallo",
      "Riccardo M. G. Ferrari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11851"
  },
  {
    "id": "arXiv:2203.11852",
    "title": "A Survey on Techniques for Identifying and Resolving Representation Bias  in Data",
    "abstract": "The grand goal of data-driven decision-making is to help humans make\ndecisions, not only easily and at scale but also wisely, accurately, and just.\nHowever, data-driven algorithms are only as good as the data they work with,\nwhile data sets, especially social data, often miss representing minorities.\nRepresentation Bias in data can happen due to various reasons ranging from\nhistorical discrimination to selection and sampling biases in the data\nacquisition and preparation methods. One cannot expect AI-based societal\nsolutions to have equitable outcomes without addressing the representation\nbias. This paper surveys the existing literature on representation bias in the\ndata. It presents a taxonomy to categorize the studied techniques based on\nmultiple design dimensions and provide a side-by-side comparison of their\nproperties. There is still a long way to fully address representation bias\nissues in data. The authors hope that this survey motivates researchers to\napproach these challenges in the future by observing existing work within their\nrespective domains.",
    "descriptor": "",
    "authors": [
      "Nima Shahbazi",
      "Yin Lin",
      "Abolfazl Asudeh",
      "H. V. Jagadish"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11852"
  },
  {
    "id": "arXiv:2203.11853",
    "title": "ImageNet Challenging Classification with the Raspberry Pi: An  Incremental Local Stochastic Gradient Descent Algorithm",
    "abstract": "With rising powerful, low-cost embedded devices, the edge computing has\nbecome an increasingly popular choice. In this paper, we propose a new\nincremental local stochastic gradient descent (SGD) tailored on the Raspberry\nPi to deal with large ImageNet dataset having 1,261,405 images with 1,000\nclasses. The local SGD splits the data block into $k$ partitions using $k$means\nalgorithm and then it learns in the parallel way SGD models in each data\npartition to classify the data locally. The incremental local SGD sequentially\nloads small data blocks of the training dataset to learn local SGD models. The\nnumerical test results on Imagenet dataset show that our incremental local SGD\nalgorithm with the Raspberry Pi 4 is faster and more accurate than the\nstate-of-the-art linear SVM run on a PC Intel(R) Core i7-4790 CPU, 3.6 GHz, 4\ncores.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Thanh-Nghi Do"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11853"
  },
  {
    "id": "arXiv:2203.11854",
    "title": "Sionna: An Open-Source Library for Next-Generation Physical Layer  Research",
    "abstract": "Sionna is a GPU-accelerated open-source library for link-level simulations\nbased on TensorFlow. It enables the rapid prototyping of complex communication\nsystem architectures and provides native support for the integration of neural\nnetworks. Sionna implements a wide breadth of carefully tested state-of-the-art\nalgorithms that can be used for benchmarking and end-to-end performance\nevaluation. This allows researchers to focus on their research, making it more\nimpactful and reproducible, while saving time implementing components outside\ntheir area of expertise. This white paper provides a brief introduction to\nSionna, explains its design principles and features, as well as future\nextensions, such as integrated ray tracing and custom CUDA kernels. We believe\nthat Sionna is a valuable tool for research on next-generation communication\nsystems, such as 6G, and we welcome contributions from our community.",
    "descriptor": "\nComments: 5 pages, 1 figure, 4 code listings\n",
    "authors": [
      "Jakob Hoydis",
      "Sebastian Cammerer",
      "Fay\u00e7al Ait Aoudia",
      "Avinash Vem",
      "Nikolaus Binder",
      "Guillermo Marcus",
      "Alexander Keller"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11854"
  },
  {
    "id": "arXiv:2203.11856",
    "title": "A Computational Approach to Understand Mental Health from Reddit:  Knowledge-aware Multitask Learning Framework",
    "abstract": "Analyzing gender is critical to study mental health (MH) support in CVD\n(cardiovascular disease). The existing studies on using social media for\nextracting MH symptoms consider symptom detection and tend to ignore user\ncontext, disease, or gender. The current study aims to design and evaluate a\nsystem to capture how MH symptoms associated with CVD are expressed differently\nwith the gender on social media. We observe that the reliable detection of MH\nsymptoms expressed by persons with heart disease in user posts is challenging\nbecause of the co-existence of (dis)similar MH symptoms in one post and due to\nvariation in the description of symptoms based on gender. We collect a corpus\nof $150k$ items (posts and comments) annotated using the subreddit labels and\ntransfer learning approaches. We propose GeM, a novel task-adaptive multi-task\nlearning approach to identify the MH symptoms in CVD patients based on gender.\nSpecifically, we adapt a knowledge-assisted RoBERTa based bi-encoder model to\ncapture CVD-related MH symptoms. Moreover, it enhances the reliability for\ndifferentiating the gender language in MH symptoms when compared to the\nstate-of-art language models. Our model achieves high (statistically\nsignificant) performance and predicts four labels of MH issues and two gender\nlabels, which outperforms RoBERTa, improving the recall by 2.14% on the symptom\nidentification task and by 2.55% on the gender identification task.",
    "descriptor": "",
    "authors": [
      "Usha Lokala",
      "Aseem Srivastava",
      "Triyasha Ghosh Dastidar",
      "Tanmoy Chakraborty",
      "Md Shad Akthar",
      "Maryam Panahiazar",
      "Amit Sheth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11856"
  },
  {
    "id": "arXiv:2203.11857",
    "title": "Optimal Slicing of Virtualised Passive Optical Networks to Support Dense  Deployment of Cloud-RAN and Multi-Access Edge Computing",
    "abstract": "The commercialization of Cloud-RAN, and Open-RAN in particular, is a key\nfactor to enable 5G cell densification, by providing lower cost and more agile\ndeployment of small cells. In addition, the adoption of MEC is important to\nsupport ultra-low latency and high reliability required by mission-critical\napplications, which constitute a milestone of the 5G and beyond vision of a\nfully connected society. However, connecting antenna site, C-RAN processing and\nMEC at low cost is challenging, as it requires high-capacity, low latency\nconnectivity delivered through a highly inter-connected topology. While PON is\nbeing considered as a solution for providing low-cost connectivity to C-RAN,\nthey only allow data transmission from the endpoints (for example hosting RU at\nthe antenna site) towards a central node (e.g., the central office, hosting\ncomputing equipment), thus cannot support traffic from RU towards MEC end nodes\nthat could host DU and possibly CU and network core. This led to research into\nthe evolution of PON architectures with the ability to provide direct\ncommunications between endpoints, thus supporting mesh traffic patterns\nrequired by MEC installations. In this context, virtualization plays a key role\nin enabling efficient resource allocation (i.e. optical transmission capacity)\nto endpoints, according to their communication patterns. In this article, we\naddress the challenge of dynamic allocation of virtual PON slices over mesh-PON\narchitectures to support C-RAN and MEC nodes. We make use of a mixed\nanalytical-iterative model to compute optimal virtual PON slice allocation,\nwith the objective of minimizing the use of MEC node resources, while meeting a\ntarget latency threshold (100 $\\mu s$ in our scenario). Our method is\nparticularly effective in reducing computation time, enabling virtual PON slice\nallocation in timescales compatible with real-time or near real-time\noperations.",
    "descriptor": "",
    "authors": [
      "Sandip Das",
      "Frank Slyne",
      "Marco Ruffini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.11857"
  },
  {
    "id": "arXiv:2203.11860",
    "title": "Practical tradeoffs between memory, compute, and performance in learned  optimizers",
    "abstract": "Optimization plays a costly and crucial role in developing machine learning\nsystems. In learned optimizers, the few hyperparameters of commonly used\nhand-designed optimizers, e.g. Adam or SGD, are replaced with flexible\nparametric functions. The parameters of these functions are then optimized so\nthat the resulting learned optimizer minimizes a target loss on a chosen class\nof models. Learned optimizers can both reduce the number of required training\nsteps and improve the final test loss. However, they can be expensive to train,\nand once trained can be expensive to use due to computational and memory\noverhead for the optimizer itself. In this work, we identify and quantify the\ndesign features governing the memory, compute, and performance trade-offs for\nmany learned and hand-designed optimizers. We further leverage our analysis to\nconstruct a learned optimizer that is both faster and more memory efficient\nthan previous work.",
    "descriptor": "",
    "authors": [
      "Luke Metz",
      "C. Daniel Freeman",
      "James Harrison",
      "Niru Maheswaranathan",
      "Jascha Sohl-Dickstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.11860"
  },
  {
    "id": "arXiv:2203.11862",
    "title": "Generating natural images with direct Patch Distributions Matching",
    "abstract": "Many traditional computer vision algorithms generate realistic images by\nrequiring that each patch in the generated image be similar to a patch in a\ntraining image and vice versa. Recently, this classical approach has been\nreplaced by adversarial training with a patch discriminator. The adversarial\napproach avoids the computational burden of finding nearest neighbors of\npatches but often requires very long training times and may fail to match the\ndistribution of patches. In this paper we leverage the recently developed\nSliced Wasserstein Distance and develop an algorithm that explicitly and\nefficiently minimizes the distance between patch distributions in two images.\nOur method is conceptually simple, requires no training and can be implemented\nin a few lines of codes. On a number of image generation tasks we show that our\nresults are often superior to single-image-GANs, require no training, and can\ngenerate high quality images in a few seconds. Our implementation is available\nat https://github.com/ariel415el/GPDM",
    "descriptor": "",
    "authors": [
      "Ariel Elnekave",
      "Yair Weiss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11862"
  },
  {
    "id": "arXiv:2203.11876",
    "title": "Open-Vocabulary DETR with Conditional Matching",
    "abstract": "Open-vocabulary object detection, which is concerned with the problem of\ndetecting novel objects guided by natural language, has gained increasing\nattention from the community. Ideally, we would like to extend an\nopen-vocabulary detector such that it can produce bounding box predictions\nbased on user inputs in form of either natural language or exemplar image. This\noffers great flexibility and user experience for human-computer interaction. To\nthis end, we propose a novel open-vocabulary detector based on DETR -- hence\nthe name OV-DETR -- which, once trained, can detect any object given its class\nname or an exemplar image. The biggest challenge of turning DETR into an\nopen-vocabulary detector is that it is impossible to calculate the\nclassification cost matrix of novel classes without access to their labeled\nimages. To overcome this challenge, we formulate the learning objective as a\nbinary matching one between input queries (class name or exemplar image) and\nthe corresponding objects, which learns useful correspondence to generalize to\nunseen queries during testing. For training, we choose to condition the\nTransformer decoder on the input embeddings obtained from a pre-trained\nvision-language model like CLIP, in order to enable matching for both text and\nimage queries. With extensive experiments on LVIS and COCO datasets, we\ndemonstrate that our OV-DETR -- the first end-to-end Transformer-based\nopen-vocabulary detector -- achieves non-trivial improvements over current\nstate of the arts.",
    "descriptor": "",
    "authors": [
      "Yuhang Zang",
      "Wei Li",
      "Kaiyang Zhou",
      "Chen Huang",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11876"
  },
  {
    "id": "arXiv:2203.11878",
    "title": "Under the Hood of Transformer Networks for Trajectory Forecasting",
    "abstract": "Transformer Networks have established themselves as the de-facto\nstate-of-the-art for trajectory forecasting but there is currently no\nsystematic study on their capability to model the motion patterns of people,\nwithout interactions with other individuals nor the social context. This paper\nproposes the first in-depth study of Transformer Networks (TF) and\nBidirectional Transformers (BERT) for the forecasting of the individual motion\nof people, without bells and whistles. We conduct an exhaustive evaluation of\ninput/output representations, problem formulations and sequence modeling,\nincluding a novel analysis of their capability to predict multi-modal futures.\nOut of comparative evaluation on the ETH+UCY benchmark, both TF and BERT are\ntop performers in predicting individual motions, definitely overcoming RNNs and\nLSTMs. Furthermore, they remain within a narrow margin wrt more complex\ntechniques, which include both social interactions and scene contexts. Source\ncode will be released for all conducted experiments.",
    "descriptor": "\nComments: Under review in Pattern Recognition journal\n",
    "authors": [
      "Luca Franco",
      "Leonardo Placidi",
      "Francesco Giuliari",
      "Irtiza Hasan",
      "Marco Cristani",
      "Fabio Galasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11878"
  },
  {
    "id": "arXiv:2203.11879",
    "title": "Exponential Convergence of $hp$-Time-Stepping in Space-Time  Discretizations of Parabolic PDEs",
    "abstract": "For linear parabolic initial-boundary value problems with self-adjoint,\ntime-homogeneous elliptic spatial operator in divergence form with\nLipschitz-continuous coefficients, and for incompatible, time-analytic forcing\nterm in polygonal/polyhedral domains $D$, we prove time-analyticity of\nsolutions. Temporal analyticity is quantified in terms of weighted, analytic\nfunction classes, for data with finite, low spatial regularity and without\nboundary compatibility. Leveraging this result, we prove exponential\nconvergence of a conforming, semi-discrete $hp$-time-stepping approach. We\ncombine this semi-discretization in time with first-order, so-called\n\"$h$-version\" Lagrangian Finite Elements with corner-refinements in space into\na tensor-product, conforming discretization of a space-time formulation. We\nprove that, under appropriate corner- and corner-edge mesh-refinement of $D$,\nerror vs. number of degrees of freedom in space-time behaves essentially (up to\nlogarithmic terms), to what standard FEM provide for one elliptic boundary\nvalue problem solve in $D$. We focus on two-dimensional spatial domains and\ncomment on the one- and the three-dimensional case.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Ilaria Perugia",
      "Christoph Schwab",
      "Marco Zank"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11879"
  },
  {
    "id": "arXiv:2203.11889",
    "title": "Insights From the NeurIPS 2021 NetHack Challenge",
    "abstract": "In this report, we summarize the takeaways from the first NeurIPS 2021\nNetHack Challenge. Participants were tasked with developing a program or agent\nthat can win (i.e., 'ascend' in) the popular dungeon-crawler game of NetHack by\ninteracting with the NetHack Learning Environment (NLE), a scalable,\nprocedurally generated, and challenging Gym environment for reinforcement\nlearning (RL). The challenge showcased community-driven progress in AI with\nmany diverse approaches significantly beating the previously best results on\nNetHack. Furthermore, it served as a direct comparison between neural (e.g.,\ndeep RL) and symbolic AI, as well as hybrid systems, demonstrating that on\nNetHack symbolic bots currently outperform deep RL by a large margin. Lastly,\nno agent got close to winning the game, illustrating NetHack's suitability as a\nlong-term benchmark for AI research.",
    "descriptor": "\nComments: Under review at PMLR for the NeuRIPS 2021 Competition Workshop Track, 10 pages + 10 in appendices\n",
    "authors": [
      "Eric Hambro",
      "Sharada Mohanty",
      "Dmitrii Babaev",
      "Minwoo Byeon",
      "Dipam Chakraborty",
      "Edward Grefenstette",
      "Minqi Jiang",
      "Daejin Jo",
      "Anssi Kanervisto",
      "Jongmin Kim",
      "Sungwoong Kim",
      "Robert Kirk",
      "Vitaly Kurin",
      "Heinrich K\u00fcttler",
      "Taehwon Kwon",
      "Donghoon Lee",
      "Vegard Mella",
      "Nantas Nardelli",
      "Ivan Nazarov",
      "Nikita Ovsov",
      "Jack Parker-Holder",
      "Roberta Raileanu",
      "Karolis Ramanauskas",
      "Tim Rockt\u00e4schel",
      "Danielle Rothermel",
      "Mikayel Samvelyan",
      "Dmitry Sorokin",
      "Maciej Sypetkowski",
      "Micha\u0142 Sypetkowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Symbolic Computation (cs.SC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.11889"
  },
  {
    "id": "arXiv:2203.11891",
    "title": "The biosphere computes evolution by autoencoding interacting organisms  into species and decoding species into ecosystems",
    "abstract": "Autoencoding is a machine-learning technique for extracting a compact\nrepresentation of the essential features of input data; this representation\nthen enables a variety of applications that rely on encoding and subsequent\nreconstruction based on decoding of the relevant data. Here, we document our\ndiscovery that the biosphere evolves by a natural process akin to autoencoding.\nWe establish the following points: (1) A species is defined by its species\ninteraction code. The species code consists of the fundamental, core\ninteractions of the species with its external and internal environments; core\ninteractions are encoded by multi-scale networks including\nmolecules-cells-organisms. Species interaction codes both map and construct the\nspecies' environment. (2) The survival of fitted species is computed by natural\nautoencoding: the fittedness of species interactions is proven by successful\ndecoding of evolving species into sustained ecosystems; survival of the fitted\nsupplants Darwinian struggle and domination of the \"fittest\" only. DNA is only\none element in natural autoencoding. (3) Natural autoencoding and artificial\nautoencoding techniques manifest defined similarities and differences.\nBiosphere autoencoding accounts for survival-of-the-fitted and sheds a new\nlight on the mechanism of evolution. Evolutionary autoencoding renders\nevolution amenable to new approaches to computer modeling.",
    "descriptor": "",
    "authors": [
      "Irun R. Cohen",
      "Assaf Marron"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.11891"
  },
  {
    "id": "arXiv:2203.11892",
    "title": "Multiple Models for Discrete-time Adaptive Iterative Learning Control",
    "abstract": "This article presents a complete framework for multiple estimation models in\nthe discrete-time Adaptive Iterative Learning Control (ILC) problem. The use of\nmultiple models improves transient response and error convergence in adaptive\nsystems and has not been previously explored in the context of Adaptive ILC. A\nnew control and identification scheme with a single estimation model is\npresented. This scheme enables the extension to multiple models, unlike\nexisting Adaptive ILC strategies. Next, the fundamentals of the Multiple\nModels, Switching and Tuning (MMST) methodology are used for multiple\nestimation models in Adaptive ILC. Two switching strategies are outlined, and\nconvergence is proved for all techniques using the properties of\nsquare-summable sequences. Simulation results demonstrate the efficacy of the\nproposed strategies, with improved convergence using multiple estimation\nmodels.",
    "descriptor": "\nComments: 21 pages, 5 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ram Padmanabhan",
      "Rajini Makam",
      "Koshy George"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11892"
  },
  {
    "id": "arXiv:2203.11894",
    "title": "GradViT: Gradient Inversion of Vision Transformers",
    "abstract": "In this work we demonstrate the vulnerability of vision transformers (ViTs)\nto gradient-based inversion attacks. During this attack, the original data\nbatch is reconstructed given model weights and the corresponding gradients. We\nintroduce a method, named GradViT, that optimizes random noise into naturally\nlooking images via an iterative process. The optimization objective consists of\n(i) a loss on matching the gradients, (ii) image prior in the form of distance\nto batch-normalization statistics of a pretrained CNN model, and (iii) a total\nvariation regularization on patches to guide correct recovery locations. We\npropose a unique loss scheduling function to overcome local minima during\noptimization. We evaluate GadViT on ImageNet1K and MS-Celeb-1M datasets, and\nobserve unprecedentedly high fidelity and closeness to the original (hidden)\ndata. During the analysis we find that vision transformers are significantly\nmore vulnerable than previously studied CNNs due to the presence of the\nattention mechanism. Our method demonstrates new state-of-the-art results for\ngradient inversion in both qualitative and quantitative metrics. Project page\nat https://gradvit.github.io/.",
    "descriptor": "\nComments: CVPR 2021 Accepted Paper\n",
    "authors": [
      "Ali Hatamizadeh",
      "Hongxu Yin",
      "Holger Roth",
      "Wenqi Li",
      "Jan Kautz",
      "Daguang Xu",
      "Pavlo Molchanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11894"
  },
  {
    "id": "arXiv:2203.11899",
    "title": "Transformer based ensemble for emotion detection",
    "abstract": "Detecting emotions in languages is important to accomplish a complete\ninteraction between humans and machines. This paper describes our contribution\nto the WASSA 2022 shared task which handles this crucial task of emotion\ndetection. We have to identify the following emotions: sadness, surprise,\nneutral, anger, fear, disgust, joy based on a given essay text. We are using an\nensemble of ELECTRA and BERT models to tackle this problem achieving an F1\nscore of 62.76%. Our codebase (https://bit.ly/WASSA_shared_task) and our WandB\nproject (https://wandb.ai/acl_wassa_pictxmanipal/acl_wassa) is available.",
    "descriptor": "",
    "authors": [
      "Aditya Kane",
      "Shantanu Patankar",
      "Sahil Khose",
      "Neeraja Kirtane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11899"
  },
  {
    "id": "arXiv:2203.11900",
    "title": "Detection, Recognition, and Tracking: A Survey",
    "abstract": "For humans, object detection, recognition, and tracking are innate. These\nprovide the ability for human to perceive their environment and objects within\ntheir environment. This ability however doesn't translate well in computers. In\nComputer Vision and Multimedia, it is becoming increasingly more important to\ndetect, recognize and track objects in images and/or videos. Many of these\napplications, such as facial recognition, surveillance, animation, are used for\ntracking features and/or people. However, these tasks prove challenging for\ncomputers to do effectively, as there is a significant amount of data to parse\nthrough. Therefore, many techniques and algorithms are needed and therefore\nresearched to try to achieve human like perception. In this literature review,\nwe focus on some novel techniques on object detection and recognition, and how\nto apply tracking algorithms to the detected features to track the objects'\nmovements.",
    "descriptor": "",
    "authors": [
      "Shiyao Chen",
      "Dale Chen-Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11900"
  },
  {
    "id": "arXiv:2203.11901",
    "title": "An Information-Theoretic View of Mixed-Delay Traffic in 5G and 6G",
    "abstract": "Fifth generation mobile communication systems (5G) have to accommodate both\nUltra-Reliable Low-Latency Communication (URLLC) and enhanced Mobile Broadband\n(eMBB) services. While, eMBB applications support high data rates, URLLC\nservices aim at guaranteeing low-latencies and high-reliabilities. eMBB and\nURLLC services are scheduled on the same frequency band, where the different\nlatency requirements of the communications render the coexistence challenging.\nIn this survey, we review, from an information theoretic perspective, coding\nschemes that simultaneously accommodate URLLC and eMBB transmissions and show\nthat they outperform traditional scheduling approaches. Various communication\nscenarios are considered, including point-to-point channels, broadcast\nchannels, interference networks, cellular models, and cloud radio access\nnetworks (C-RANs). The main focus is on the set of rate pairs that can\nsimultaneously be achieved for URLLC and eMBB messages, which well captures the\ntension between the two types of communications. We also discuss\nfinite-blocklength results where the measure of interest is the set of error\nprobability pairs that can simultaneously be achieved on the two communication\nregimes.",
    "descriptor": "",
    "authors": [
      "Homa Nikbakht",
      "Mich\u00e8le Wigger",
      "Malcolm Egan",
      "Shlomo Shamai",
      "Jean-Marie Gorce",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.11901"
  },
  {
    "id": "arXiv:2203.11903",
    "title": "Enabling faster and more reliable sonographic assessment of gestational  age through machine learning",
    "abstract": "Fetal ultrasounds are an essential part of prenatal care and can be used to\nestimate gestational age (GA). Accurate GA assessment is important for\nproviding appropriate prenatal care throughout pregnancy and identifying\ncomplications such as fetal growth disorders. Since derivation of GA from\nmanual fetal biometry measurements (head, abdomen, femur) are\noperator-dependent and time-consuming, there have been a number of research\nefforts focused on using artificial intelligence (AI) models to estimate GA\nusing standard biometry images, but there is still room to improve the accuracy\nand reliability of these AI systems for widescale adoption. To improve GA\nestimates, without significant change to provider workflows, we leverage AI to\ninterpret standard plane ultrasound images as well as 'fly-to' ultrasound\nvideos, which are 5-10s videos automatically recorded as part of the standard\nof care before the still image is captured. We developed and validated three AI\nmodels: an image model using standard plane images, a video model using fly-to\nvideos, and an ensemble model (combining both image and video). All three were\nstatistically superior to standard fetal biometry-based GA estimates derived by\nexpert sonographers, the ensemble model has the lowest mean absolute error\n(MAE) compared to the clinical standard fetal biometry (mean difference: -1.51\n$\\pm$ 3.96 days, 95% CI [-1.9, -1.1]) on a test set that consisted of 404\nparticipants. We showed that our models outperform standard biometry by a more\nsubstantial margin on fetuses that were small for GA. Our AI models have the\npotential to empower trained operators to estimate GA with higher accuracy\nwhile reducing the amount of time required and user variability in measurement\nacquisition.",
    "descriptor": "",
    "authors": [
      "Chace Lee",
      "Angelica Willis",
      "Christina Chen",
      "Marcin Sieniek",
      "Akib Uddin",
      "Jonny Wong",
      "Rory Pilgrim",
      "Katherine Chou",
      "Daniel Tse",
      "Shravya Shetty",
      "Ryan G. Gomes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.11903"
  },
  {
    "id": "arXiv:2203.11904",
    "title": "Bringing Linearly Transformed Cosines to Anisotropic GGX",
    "abstract": "Linearly Transformed Cosines (LTCs) are a family of distributions that are\nused for real-time area-light shading thanks to their analytic integration\nproperties. Modern game engines use an LTC approximation of the ubiquitous GGX\nmodel, but currently this approximation only exists for isotropic GGX and thus\nanisotropic GGX is not supported. While the higher dimensionality presents a\nchallenge in itself, we show that several additional problems arise when\nfitting, post-processing, storing, and interpolating LTCs in the anisotropic\ncase. Each of these operations must be done carefully to avoid rendering\nartifacts. We find robust solutions for each operation by introducing and\nexploiting invariance properties of LTCs. As a result, we obtain a small $8^4$\nlook-up table that provides a plausible and artifact-free LTC approximation to\nanisotropic GGX and brings it to real-time area-light shading.",
    "descriptor": "\nComments: ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D), 2022\n",
    "authors": [
      "Aakash KT",
      "Eric Heitz",
      "Jonathan Dupuy",
      "P. J. Narayanan"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.11904"
  },
  {
    "id": "arXiv:2203.11907",
    "title": "Bibliometric Profile of an Emerging Journal: Participatory Educational  Research",
    "abstract": "Participatory Educational Research journal is one of the journals that\ncontributes to the field of education and indexed in major international\ndatabases such as ERIC and Scopus.This study provides the bibliometric\ncharacteristic of the total 347 articles published in PER during the period of\n2014-2021 using bibliometric analysis. Publish or Perish software to collect\ncitation data from Google Scholar was used as an analysis instrument for the\nimpact of the articles.",
    "descriptor": "",
    "authors": [
      "Rumiye Arslan",
      "Keziban Orbay",
      "Metin Orbay"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Physics Education (physics.ed-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.11907"
  },
  {
    "id": "arXiv:2203.11910",
    "title": "Improving Neural Predictivity in the Visual Cortex with Gated Recurrent  Connections",
    "abstract": "Computational models of vision have traditionally been developed in a\nbottom-up fashion, by hierarchically composing a series of straightforward\noperations - i.e. convolution and pooling - with the aim of emulating simple\nand complex cells in the visual cortex, resulting in the introduction of deep\nconvolutional neural networks (CNNs). Nevertheless, data obtained with recent\nneuronal recording techniques support that the nature of the computations\ncarried out in the ventral visual stream is not completely captured by current\ndeep CNN models. To fill the gap between the ventral visual stream and deep\nmodels, several benchmarks have been designed and organized into the\nBrain-Score platform, granting a way to perform multi-layer (V1, V2, V4, IT)\nand behavioral comparisons between the two counterparts. In our work, we aim to\nshift the focus on architectures that take into account lateral recurrent\nconnections, a ubiquitous feature of the ventral visual stream, to devise\nadaptive receptive fields. Through recurrent connections, the input s\nlong-range spatial dependencies can be captured in a local multi-step fashion\nand, as introduced with Gated Recurrent CNNs (GRCNN), the unbounded expansion\nof the neuron s receptive fields can be modulated through the use of gates. In\norder to increase the robustness of our approach and the biological fidelity of\nthe activations, we employ specific data augmentation techniques in line with\nseveral of the scoring benchmarks. Enforcing some form of invariance, through\nheuristics, was found to be beneficial for better neural predictivity.",
    "descriptor": "\nComments: 6 pages, 1 figure, BrainScore Workshop 2022\n",
    "authors": [
      "Simone Azeglio",
      "Simone Poetto",
      "Luca Savant Aira",
      "Marco Nurisso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2203.11910"
  },
  {
    "id": "arXiv:2203.11912",
    "title": "What can we Learn Even From the Weakest? Learning Sketches for  Programmatic Strategies",
    "abstract": "In this paper we show that behavioral cloning can be used to learn effective\nsketches of programmatic strategies. We show that even the sketches learned by\ncloning the behavior of weak players can help the synthesis of programmatic\nstrategies. This is because even weak players can provide helpful information,\ne.g., that a player must choose an action in their turn of the game. If\nbehavioral cloning is not employed, the synthesizer needs to learn even the\nmost basic information by playing the game, which can be computationally\nexpensive. We demonstrate empirically the advantages of our sketch-learning\napproach with simulated annealing and UCT synthesizers. We evaluate our\nsynthesizers in the games of Can't Stop and MicroRTS. The sketch-based\nsynthesizers are able to learn stronger programmatic strategies than their\noriginal counterparts. Our synthesizers generate strategies of Can't Stop that\ndefeat a traditional programmatic strategy for the game. They also synthesize\nstrategies that defeat the best performing method from the latest MicroRTS\ncompetition.",
    "descriptor": "\nComments: Published at AAAI'22\n",
    "authors": [
      "Leandro C. Medeiros",
      "David S. Aleixo",
      "Levi H. S. Lelis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11912"
  },
  {
    "id": "arXiv:2203.11914",
    "title": "SPRITE: A Scalable Privacy-Preserving and Verifiable Collaborative  Learning for Industrial IoT",
    "abstract": "Recently collaborative learning is widely applied to model sensitive data\ngenerated in Industrial IoT (IIoT). It enables a large number of devices to\ncollectively train a global model by collaborating with a server while keeping\nthe datasets on their respective premises. However, existing approaches are\nlimited by high overheads and may also suffer from falsified aggregated results\nreturned by a malicious server. Hence, we propose a Scalable,\nPrivacy-preserving and veRIfiable collaboraTive lEarning (SPRITE) algorithm to\ntrain linear and logistic regression models for IIoT. We aim to reduce burden\nfrom resource-constrained IIoT devices and trust dependence on cloud by\nintroducing fog as a middleware. SPRITE employs threshold secret sharing to\nguarantee privacy-preservation and robustness to IIoT device dropout whereas\nverifiable additive homomorphic secret sharing to ensure verifiability during\nmodel aggregation. We prove the security of SPRITE in an honest-but-curious\nsetting where the cloud is untrustworthy. We validate SPRITE to be scalable and\nlightweight through theoretical overhead analysis and extensive testbed\nexperimentation on an IIoT use-case with two real-world industrial datasets.\nFor a large-scale industrial setup, SPRITE records 65% and 55% improved\nperformance over its competitor for linear and logistic regressions\nrespectively while reducing communication overhead for an IIoT device by 90%.",
    "descriptor": "\nComments: Accepted for publication at The 22nd IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGrid 2022). 5 figures and 6 tables\n",
    "authors": [
      "Jayasree Sengupta",
      "Sushmita Ruj",
      "Sipra Das Bit"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11914"
  },
  {
    "id": "arXiv:2203.11923",
    "title": "Super-resolution of generalized spikes and spectra of confluent  Vandermonde matrices",
    "abstract": "We study the problem of super-resolution of a linear combination of Dirac\ndistributions and their derivatives on a one-dimensional circle from noisy\nFourier measurements. Following numerous recent works on the subject, we\nconsider the geometric setting of \"partial clustering\", when some Diracs can be\nseparated much below the Rayleigh limit. Under this assumption, we prove sharp\nasymptotic bounds for the smallest singular value of a corresponding\nrectangular confluent Vandermonde matrix with nodes on the unit circle. As a\nconsequence, we derive matching lower and upper min-max error bounds for the\nabove super-resolution problem, under the additional assumption of nodes\nbelonging to a fixed grid.",
    "descriptor": "\nComments: 27 pages, 5 figures\n",
    "authors": [
      "Dmitry Batenkov",
      "Nuha Diab"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11923"
  },
  {
    "id": "arXiv:2203.11924",
    "title": "On Supervised Feature Selection from High Dimensional Feature Spaces",
    "abstract": "The application of machine learning to image and video data often yields a\nhigh dimensional feature space. Effective feature selection techniques identify\na discriminant feature subspace that lowers computational and modeling costs\nwith little performance degradation. A novel supervised feature selection\nmethodology is proposed for machine learning decisions in this work. The\nresulting tests are called the discriminant feature test (DFT) and the relevant\nfeature test (RFT) for the classification and regression problems,\nrespectively. The DFT and RFT procedures are described in detail. Furthermore,\nwe compare the effectiveness of DFT and RFT with several classic feature\nselection methods. To this end, we use deep features obtained by LeNet-5 for\nMNIST and Fashion-MNIST datasets as illustrative examples. It is shown by\nexperimental results that DFT and RFT can select a lower dimensional feature\nsubspace distinctly and robustly while maintaining high decision performance.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Yijing Yang",
      "Wei Wang",
      "Hongyu Fu",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11924"
  },
  {
    "id": "arXiv:2203.11926",
    "title": "Focal Modulation Networks",
    "abstract": "In this work, we propose focal modulation network (FocalNet in short), where\nself-attention (SA) is completely replaced by a focal modulation module that is\nmore effective and efficient for modeling token interactions. Focal modulation\ncomprises three components: $(i)$ hierarchical contextualization, implemented\nusing a stack of depth-wise convolutional layers, to encode visual contexts\nfrom short to long ranges at different granularity levels, $(ii)$ gated\naggregation to selectively aggregate context features for each visual token\n(query) based on its content, and $(iii)$ modulation or element-wise affine\ntransformation to fuse the aggregated features into the query vector. Extensive\nexperiments show that FocalNets outperform the state-of-the-art SA counterparts\n(e.g., Swin Transformers) with similar time and memory cost on the tasks of\nimage classification, object detection, and semantic segmentation.\nSpecifically, our FocalNets with tiny and base sizes achieve 82.3% and 83.9%\ntop-1 accuracy on ImageNet-1K. After pretrained on ImageNet-22K, it attains\n86.5% and 87.3% top-1 accuracy when finetuned with resolution 224$\\times$224\nand 384$\\times$384, respectively. FocalNets exhibit remarkable superiority when\ntransferred to downstream tasks. For object detection with Mask R-CNN, our\nFocalNet base trained with 1$\\times$ already surpasses Swin trained with\n3$\\times$ schedule (49.0 v.s. 48.5). For semantic segmentation with UperNet,\nFocalNet base evaluated at single-scale outperforms Swin evaluated at\nmulti-scale (50.5 v.s. 49.7). These results render focal modulation a favorable\nalternative to SA for effective and efficient visual modeling in real-world\napplications. Code is available at https://github.com/microsoft/FocalNet.",
    "descriptor": "\nComments: technical report\n",
    "authors": [
      "Jianwei Yang",
      "Chunyuan Li",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11926"
  },
  {
    "id": "arXiv:2203.11931",
    "title": "MetaMorph: Learning Universal Controllers with Transformers",
    "abstract": "Multiple domains like vision, natural language, and audio are witnessing\ntremendous progress by leveraging Transformers for large scale pre-training\nfollowed by task specific fine tuning. In contrast, in robotics we primarily\ntrain a single robot for a single task. However, modular robot systems now\nallow for the flexible combination of general-purpose building blocks into task\noptimized morphologies. However, given the exponentially large number of\npossible robot morphologies, training a controller for each new design is\nimpractical. In this work, we propose MetaMorph, a Transformer based approach\nto learn a universal controller over a modular robot design space. MetaMorph is\nbased on the insight that robot morphology is just another modality on which we\ncan condition the output of a Transformer. Through extensive experiments we\ndemonstrate that large scale pre-training on a variety of robot morphologies\nresults in policies with combinatorial generalization capabilities, including\nzero shot generalization to unseen robot morphologies. We further demonstrate\nthat our pre-trained policy can be used for sample-efficient transfer to\ncompletely new robot morphologies and tasks.",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Agrim Gupta",
      "Linxi Fan",
      "Surya Ganguli",
      "Li Fei-Fei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.11931"
  },
  {
    "id": "arXiv:2203.11932",
    "title": "Dataset Distillation by Matching Training Trajectories",
    "abstract": "Dataset distillation is the task of synthesizing a small dataset such that a\nmodel trained on the synthetic set will match the test accuracy of the model\ntrained on the full dataset. In this paper, we propose a new formulation that\noptimizes our distilled data to guide networks to a similar state as those\ntrained on real data across many training steps. Given a network, we train it\nfor several iterations on our distilled data and optimize the distilled data\nwith respect to the distance between the synthetically trained parameters and\nthe parameters trained on real data. To efficiently obtain the initial and\ntarget network parameters for large-scale datasets, we pre-compute and store\ntraining trajectories of expert networks trained on the real dataset. Our\nmethod handily outperforms existing methods and also allows us to distill\nhigher-resolution visual data.",
    "descriptor": "\nComments: CVPR 2022 website: this https URL code: this https URL\n",
    "authors": [
      "George Cazenavette",
      "Tongzhou Wang",
      "Antonio Torralba",
      "Alexei A. Efros",
      "Jun-Yan Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11932"
  },
  {
    "id": "arXiv:2203.11933",
    "title": "A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models  with Adversarial Learning",
    "abstract": "Vision-language models can encode societal biases and stereotypes, but there\nare challenges to measuring and mitigating these harms. Prior proposed bias\nmeasurements lack robustness and feature degradation occurs when mitigating\nbias without access to pretraining data. We address both of these challenges in\nthis paper: First, we evaluate different bias measures and propose the use of\nretrieval metrics to image-text representations via a bias measuring framework.\nSecond, we investigate debiasing methods and show that optimizing for\nadversarial loss via learnable token embeddings minimizes various bias measures\nwithout substantially degrading feature representations.",
    "descriptor": "\nComments: 24 pages, 10 figures. For code and trained token embeddings, see this https URL\n",
    "authors": [
      "Hugo Berg",
      "Siobhan Mackenzie Hall",
      "Yash Bhalgat",
      "Wonsuk Yang",
      "Hannah Rose Kirk",
      "Aleksandar Shtedritski",
      "Max Bain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.11933"
  },
  {
    "id": "arXiv:2203.11934",
    "title": "Learning from All Vehicles",
    "abstract": "In this paper, we present a system to train driving policies from experiences\ncollected not just from the ego-vehicle, but all vehicles that it observes.\nThis system uses the behaviors of other agents to create more diverse driving\nscenarios without collecting additional data. The main difficulty in learning\nfrom other vehicles is that there is no sensor information. We use a set of\nsupervisory tasks to learn an intermediate representation that is invariant to\nthe viewpoint of the controlling vehicle. This not only provides a richer\nsignal at training time but also allows more complex reasoning during\ninference. Learning how all vehicles drive helps predict their behavior at test\ntime and can avoid collisions. We evaluate this system in closed-loop driving\nsimulations. Our system outperforms all prior methods on the public CARLA\nLeaderboard by a wide margin, improving driving score by 25 and route\ncompletion rate by 24 points. Our method won the 2021 CARLA Autonomous Driving\nchallenge. Demo videos are available at https://dotchen.github.io/LAV/.",
    "descriptor": "\nComments: Paper accepted to CVPR 2022; Code and data available at this https URL\n",
    "authors": [
      "Dian Chen",
      "Philipp Kr\u00e4henb\u00fchl"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11934"
  },
  {
    "id": "arXiv:2203.11937",
    "title": "4D-OR: Semantic Scene Graphs for OR Domain Modeling",
    "abstract": "Surgical procedures are conducted in highly complex operating rooms (OR),\ncomprising different actors, devices, and interactions. To date, only medically\ntrained human experts are capable of understanding all the links and\ninteractions in such a demanding environment. This paper aims to bring the\ncommunity one step closer to automated, holistic and semantic understanding and\nmodeling of OR domain. Towards this goal, for the first time, we propose using\nsemantic scene graphs (SSG) to describe and summarize the surgical scene. The\nnodes of the scene graphs represent different actors and objects in the room,\nsuch as medical staff, patients, and medical equipment, whereas edges are the\nrelationships between them. To validate the possibilities of the proposed\nrepresentation, we create the first publicly available 4D surgical SSG dataset,\n4D-OR, containing ten simulated total knee replacement surgeries recorded with\nsix RGB-D sensors in a realistic OR simulation center. 4D-OR includes 6734\nframes and is richly annotated with SSGs, human and object poses, and clinical\nroles. We propose an end-to-end neural network-based SSG generation pipeline,\nwith a rate of success of 0.75 macro F1, indeed being able to infer semantic\nreasoning in the OR. We further demonstrate the representation power of our\nscene graphs by using it for the problem of clinical role prediction, where we\nachieve 0.85 macro F1. The code and dataset will be made available upon\nacceptance.",
    "descriptor": "\nComments: 11 pages, 3 figures, 3 tables\n",
    "authors": [
      "Ege \u00d6zsoy",
      "Evin P\u0131nar \u00d6rnek",
      "Ulrich Eck",
      "Tobias Czempiel",
      "Federico Tombari",
      "Nassir Navab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11937"
  },
  {
    "id": "arXiv:2203.11938",
    "title": "\u03c6-SfT: Shape-from-Template with a Physics-Based Deformation Model",
    "abstract": "Shape-from-Template (SfT) methods estimate 3D surface deformations from a\nsingle monocular RGB camera while assuming a 3D state known in advance (a\ntemplate). This is an important yet challenging problem due to the\nunder-constrained nature of the monocular setting. Existing SfT techniques\npredominantly use geometric and simplified deformation models, which often\nlimits their reconstruction abilities. In contrast to previous works, this\npaper proposes a new SfT approach explaining 2D observations through physical\nsimulations accounting for forces and material properties. Our differentiable\nphysics simulator regularises the surface evolution and optimises the material\nelastic properties such as bending coefficients, stretching stiffness and\ndensity. We use a differentiable renderer to minimise the dense reprojection\nerror between the estimated 3D states and the input images and recover the\ndeformation parameters using an adaptive gradient-based optimisation. For the\nevaluation, we record with an RGB-D camera challenging real surfaces exposed to\nphysical forces with various material properties and textures. Our approach\nsignificantly reduces the 3D reconstruction error compared to multiple\ncompeting methods. For the source code and data, see\nhttps://4dqv.mpi-inf.mpg.de/phi-SfT/.",
    "descriptor": "\nComments: 11 pages, 8 figures and one table; Computer Vision and Pattern Recognition (CVPR) 2022\n",
    "authors": [
      "Navami Kairanda",
      "Edith Tretschk",
      "Mohamed Elgharib",
      "Christian Theobalt",
      "Vladislav Golyanik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.11938"
  },
  {
    "id": "arXiv:2203.11205",
    "title": "VinDr-Mammo: A large-scale benchmark dataset for computer-aided  diagnosis in full-field digital mammography",
    "abstract": "Mammography, or breast X-ray, is the most widely used imaging modality to\ndetect cancer and other breast diseases. Recent studies have shown that deep\nlearning-based computer-assisted detection and diagnosis (CADe or CADx) tools\nhave been developed to support physicians and improve the accuracy of\ninterpreting mammography. However, most published datasets of mammography are\neither limited on sample size or digitalized from screen-film mammography\n(SFM), hindering the development of CADe and CADx tools which are developed\nbased on full-field digital mammography (FFDM). To overcome this challenge, we\nintroduce VinDr-Mammo - a new benchmark dataset of FFDM for detecting and\ndiagnosing breast cancer and other diseases in mammography. The dataset\nconsists of 5,000 mammography exams, each of which has four standard views and\nis double read with disagreement (if any) being resolved by arbitration. It is\ncreated for the assessment of Breast Imaging Reporting and Data System\n(BI-RADS) and density at the breast level. In addition, the dataset also\nprovides the category, location, and BI-RADS assessment of non-benign findings.\nWe make VinDr-Mammo publicly available on PhysioNet as a new imaging resource\nto promote advances in developing CADe and CADx tools for breast cancer\nscreening.",
    "descriptor": "\nComments: The manuscript is under review by Nature Scientific Data\n",
    "authors": [
      "Hieu T. Nguyen",
      "Ha Q. Nguyen",
      "Hieu H. Pham",
      "Khanh Lam",
      "Linh T. Le",
      "Minh Dao",
      "Van Vu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11205"
  },
  {
    "id": "arXiv:2203.11206",
    "title": "Phase Recognition in Contrast-Enhanced CT Scans based on Deep Learning  and Random Sampling",
    "abstract": "A fully automated system for interpreting abdominal computed tomography (CT)\nscans with multiple phases of contrast enhancement requires an accurate\nclassification of the phases. This work aims at developing and validating a\nprecise, fast multi-phase classifier to recognize three main types of contrast\nphases in abdominal CT scans. We propose in this study a novel method that uses\na random sampling mechanism on top of deep CNNs for the phase recognition of\nabdominal CT scans of four different phases: non-contrast, arterial, venous,\nand others. The CNNs work as a slice-wise phase prediction, while the random\nsampling selects input slices for the CNN models. Afterward, majority voting\nsynthesizes the slice-wise results of the CNNs, to provide the final prediction\nat scan level. Our classifier was trained on 271,426 slices from 830\nphase-annotated CT scans, and when combined with majority voting on 30% of\nslices randomly chosen from each scan, achieved a mean F1-score of 92.09% on\nour internal test set of 358 scans. The proposed method was also evaluated on 2\nexternal test sets: CTPAC-CCRCC (N = 242) and LiTS (N = 131), which were\nannotated by our experts. Although a drop in performance has been observed, the\nmodel performance remained at a high level of accuracy with a mean F1-score of\n76.79% and 86.94% on CTPAC-CCRCC and LiTS datasets, respectively. Our\nexperimental results also showed that the proposed method significantly\noutperformed the state-of-the-art 3D approaches while requiring less\ncomputation time for inference.",
    "descriptor": "\nComments: Accepted for publication by Medical Physics\n",
    "authors": [
      "Binh T. Dao",
      "Thang V. Nguyen",
      "Hieu H. Pham",
      "Ha Q. Nguyen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11206"
  },
  {
    "id": "arXiv:2203.11213",
    "title": "ME-Net: Multi-Encoder Net Framework for Brain Tumor Segmentation",
    "abstract": "Glioma is the most common and aggressive brain tumor. Magnetic resonance\nimaging (MRI) plays a vital role to evaluate tumors for the arrangement of\ntumor surgery and the treatment of subsequent procedures. However, the manual\nsegmentation of the MRI image is strenuous, which limits its clinical\napplication. With the development of deep learning, a large number of automatic\nsegmentation methods have been developed, but most of them stay in 2D images,\nwhich leads to subpar performance. Moreover, the serious voxel imbalance\nbetween the brain tumor and the background as well as the different sizes and\nlocations of the brain tumor makes the segmentation of 3D images a challenging\nproblem. Aiming at segmenting 3D MRI, we propose a model for brain tumor\nsegmentation with multiple encoders. The structure contains four encoders and\none decoder. The four encoders correspond to the four modalities of the MRI\nimage, perform one-to-one feature extraction, and then merge the feature maps\nof the four modalities into the decoder. This method reduces the difficulty of\nfeature extraction and greatly improves model performance. We also introduced a\nnew loss function named \"Categorical Dice\", and set different weights for\ndifferent segmented regions at the same time, which solved the problem of voxel\nimbalance. We evaluated our approach using the online BraTS 2020 Challenge\nverification. Our proposed method can achieve promising results in the\nvalidation set compared to the state-of-the-art approaches with Dice scores of\n0.70249, 0.88267, and 0.73864 for the intact tumor, tumor core, and enhanced\ntumor, respectively.",
    "descriptor": "\nComments: 28 pages, 8 figures, accepted by IMA journal\n",
    "authors": [
      "Wenbo Zhang",
      "Guang Yang",
      "He Huang",
      "Weiji Yang",
      "Xiaomei Xu",
      "Yongkai Liu",
      "Xiaobo Lai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11213"
  },
  {
    "id": "arXiv:2203.11268",
    "title": "Domain Knowledge Aids in Signal Disaggregation; the Example of the  Cumulative Water Heater",
    "abstract": "In this article we present an unsupervised low-frequency method aimed at\ndetecting and disaggregating the power used by Cumulative Water Heaters (CWH)\nin residential homes. Our model circumvents the inherent difficulty of\nunsupervised signal disaggregation by using both the shape of a power spike and\nits time of occurrence to identify the contribution of CWH reliably. Indeed,\nmany CHWs in France are configured to turn on automatically during off-peak\nhours only, and we are able to use this domain knowledge to aid peak\nidentification despite the low sampling frequency. In order to test our model,\nwe equipped a home with sensors to record the ground-truth consumption of a\nwater heater. We then apply the model to a larger dataset of energy consumption\nof Hello Watt users consisting of one month of consumption data for 5k homes at\n30-minute resolution. In this dataset we successfully identified CWHs in the\nmajority of cases where consumers declared using them. The remaining part is\nlikely due to possible misconfiguration of CWHs, since triggering them during\noff-peak hours requires specific wiring in the electrical panel of the house.\nOur model, despite its simplicity, offers promising applications: detection of\nmis-configured CWHs on off-peak contracts and slow performance degradation.",
    "descriptor": "\nComments: 16 pages, 12 figures, 2 tables\n",
    "authors": [
      "Alexander Belikov",
      "Guillaume Matheron",
      "Johan Sassi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.11268"
  },
  {
    "id": "arXiv:2203.11269",
    "title": "Contribution of Different Handwriting Modalities to Differential  Diagnosis of Parkinson's Disease",
    "abstract": "In this paper, we evaluate the contribution of different handwriting\nmodalities to the diagnosis of Parkinson's disease. We analyse on-surface\nmovement, in-air movement and pressure exerted on the tablet surface.\nEspecially in-air movement and pressure-based features have been rarely taken\ninto account in previous studies. We show that pressure and in-air movement\nalso possess information that is relevant for the diagnosis of Parkinson's\nDisease (PD) from handwriting. In addition to the conventional kinematic and\nspatio-temporal features, we present a group of the novel features based on\nentropy and empirical mode decomposition of the handwriting signal. The\npresented results indicate that handwriting can be used as biomarker for PD\nproviding classification performance around 89% area under the ROC curve (AUC)\nfor PD classification.",
    "descriptor": "\nComments: The work was published by IEEE\n",
    "authors": [
      "Peter Drot\u00e1r",
      "Ji\u0159\u00ed Mekyska",
      "Zden\u011bk Sm\u00e9kal",
      "Irena Rektorov\u00e1",
      "Lucia Masarov\u00e1",
      "Marcos Faundez-Zanuy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11269"
  },
  {
    "id": "arXiv:2203.11276",
    "title": "Model Comparison in Approximate Bayesian Computation",
    "abstract": "A common problem in natural sciences is the comparison of competing models in\nthe light of observed data. Bayesian model comparison provides a statistically\nsound framework for this comparison based on the evidence each model provides\nfor the data. However, this framework relies on the calculation of likelihood\nfunctions which are intractable for most models used in practice. Previous\napproaches in the field of Approximate Bayesian Computation (ABC) circumvent\nthe evaluation of the likelihood and estimate the model evidence based on\nrejection sampling, but they are typically computationally intense. Here, I\npropose a new efficient method to perform Bayesian model comparison in ABC.\nBased on recent advances in posterior density estimation, the method\napproximates the posterior over models in parametric form. In particular, I\ntrain a mixture-density network to map features of the observed data to the\nposterior probability of the models. The performance is assessed with two\nexamples. On a tractable model comparison problem, the underlying exact\nposterior probabilities are predicted accurately. In a use-case scenario from\ncomputational neuroscience -- the comparison between two ion channel models --\nthe underlying ground-truth model is reliably assigned a high posterior\nprobability. Overall, the method provides a new efficient way to perform\nBayesian model comparison on complex biophysical models independent of the\nmodel architecture.",
    "descriptor": "\nComments: Master thesis supervised by Henning Sprekeler and Jakob H. Macke\n",
    "authors": [
      "Jan Boelts"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11276"
  },
  {
    "id": "arXiv:2203.11278",
    "title": "One-Bit Compressive Sensing: Can We Go Deep and Blind?",
    "abstract": "One-bit compressive sensing is concerned with the accurate recovery of an\nunderlying sparse signal of interest from its one-bit noisy measurements. The\nconventional signal recovery approaches for this problem are mainly developed\nbased on the assumption that an exact knowledge of the sensing matrix is\navailable. In this work, however, we present a novel data-driven and\nmodel-based methodology that achieves blind recovery; i.e., signal recovery\nwithout requiring the knowledge of the sensing matrix. To this end, we make use\nof the deep unfolding technique and develop a model-driven deep neural\narchitecture which is designed for this specific task. The proposed deep\narchitecture is able to learn an alternative sensing matrix by taking advantage\nof the underlying unfolded algorithm such that the resulting learned recovery\nalgorithm can accurately and quickly (in terms of the number of iterations)\nrecover the underlying compressed signal of interest from its one-bit noisy\nmeasurements. In addition, due to the incorporation of the domain knowledge and\nthe mathematical model of the system into the proposed deep architecture, the\nresulting network benefits from enhanced interpretability, has a very small\nnumber of trainable parameters, and requires very small number of training\nsamples, as compared to the commonly used black-box deep neural network\nalternatives for the problem at hand.",
    "descriptor": "",
    "authors": [
      "Yiming Zeng",
      "Shahin Khobahi",
      "Mojtaba Soltanalian"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11278"
  },
  {
    "id": "arXiv:2203.11279",
    "title": "EEG based Emotion Recognition: A Tutorial and Review",
    "abstract": "Emotion recognition technology through analyzing the EEG signal is currently\nan essential concept in Artificial Intelligence and holds great potential in\nemotional health care, human-computer interaction, multimedia content\nrecommendation, etc. Though there have been several works devoted to reviewing\nEEG-based emotion recognition, the content of these reviews needs to be\nupdated. In addition, those works are either fragmented in content or only\nfocus on specific techniques adopted in this area but neglect the holistic\nperspective of the entire technical routes. Hence, in this paper, we review\nfrom the perspective of researchers who try to take the first step on this\ntopic. We review the recent representative works in the EEG-based emotion\nrecognition research and provide a tutorial to guide the researchers to start\nfrom the beginning. The scientific basis of EEG-based emotion recognition in\nthe psychological and physiological levels is introduced. Further, we\ncategorize these reviewed works into different technical routes and illustrate\nthe theoretical basis and the research motivation, which will help the readers\nbetter understand why those techniques are studied and employed. At last,\nexisting challenges and future investigations are also discussed in this paper,\nwhich guides the researchers to decide potential future research directions.",
    "descriptor": "",
    "authors": [
      "Xiang Li",
      "Yazhou Zhang",
      "Prayag Tiwari",
      "Dawei Song",
      "Bin Hu",
      "Meihong Yang",
      "Zhigang Zhao",
      "Neeraj Kumar",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11279"
  },
  {
    "id": "arXiv:2203.11280",
    "title": "The EL-X8 computer and the BOL detector Networking, programming,  time-sharing and data-handling in the Amsterdam nuclear research project  `BOL' A personal historical review",
    "abstract": "From 1967 to 1974, an Electrologica X8 computer was installed at the\nInstitute for Nuclear Research (IKO) in Amsterdam, primarily for online and\noffline evaluation of experimental data, an application quite different from\nits `brother's', X8's. During that time, the nuclear detection system `BOL' was\nin operation to study nuclear reactions. The BOL detector embodied a new and\nbold concept. It consisted of a large number of state-of-the-art detection\nunits, mounted in a spherical arrangement around a target in a beam of nuclear\nparticles. Two minicomputers performed data acquisition and control of the\nexperiment and supported online visual display of acquired data. The X8\ncomputer, networked with the minicomputers, allowed fast high-level data\nprocessing and analysis. Pioneering work in both experimental nuclear physics\nas well as in programming, turned out to be a surprisingly good combination.\nFor the network with the X8 and the minicomputers, advanced software layers\nwere developed to efficiently and flexibly program extensive data handling.",
    "descriptor": "\nComments: 19 pages, 10 figures\n",
    "authors": [
      "Ren\u00e9 van Dantzig"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2203.11280"
  },
  {
    "id": "arXiv:2203.11318",
    "title": "Deep Reinforcement Learning and Convex Mean-Variance Optimisation for  Portfolio Management",
    "abstract": "Traditional portfolio management methods can incorporate specific investor\npreferences but rely on accurate forecasts of asset returns and covariances.\nReinforcement learning (RL) methods do not rely on these explicit forecasts and\nare better suited for multi-stage decision processes. To address limitations of\nthe evaluated research, experiments were conducted on three markets in\ndifferent economies with different overall trends. By incorporating specific\ninvestor preferences into our RL models' reward functions, a more comprehensive\ncomparison could be made to traditional methods in risk-return space.\nTransaction costs were also modelled more realistically by including nonlinear\nchanges introduced by market volatility and trading volume. The results of this\nstudy suggest that there can be an advantage to using RL methods compared to\ntraditional convex mean-variance optimisation methods under certain market\nconditions. Our RL models could significantly outperform traditional\nsingle-period optimisation (SPO) and multi-period optimisation (MPO) models in\nupward trending markets, but only up to specific risk limits. In sideways\ntrending markets, the performance of SPO and MPO models can be closely matched\nby our RL models for the majority of the excess risk range tested. The specific\nmarket conditions under which these models could outperform each other\nhighlight the importance of a more comprehensive comparison of Pareto optimal\nfrontiers in risk-return space. These frontiers give investors a more granular\nview of which models might provide better performance for their specific risk\ntolerance or return targets.",
    "descriptor": "",
    "authors": [
      "Ruan Pretorius",
      "Terence van Zyl"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11318"
  },
  {
    "id": "arXiv:2203.11322",
    "title": "Probabilistically robust stabilizing allocations in uncertain  cooperative games",
    "abstract": "In this paper we consider multi-agent cooperative games with uncertain value\nfunctions for which we establish distribution-free guarantees on the\nprobability of allocation stability, i.e., agents do not have incentives to\ndefect the grand coalition to subcoalitions for unseen realizations of the\nuncertain parameter. In case the set of stable allocations, the so called core\nof the game, is empty, we propose a randomized relaxation of the core. We then\nshow that those allocations that belong to this relaxed set can be accompanied\nby stability guarantees in a probably approximately correct fashion. Finally,\nnumerical experiments corroborate our theoretical findings.",
    "descriptor": "",
    "authors": [
      "George Pantazis",
      "Filippo Fabiani",
      "Filiberto Fele",
      "Kostas Margellos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11322"
  },
  {
    "id": "arXiv:2203.11327",
    "title": "Online Joint Optimal Control-Estimation Architecture in Distribution  Networks",
    "abstract": "In this paper, we propose an optimal control-estimation architecture for\ndistribution networks, which jointly solves the optimal power flow (OPF)\nproblem and static state estimation (SE) problem through an online\ngradient-based feedback algorithm. The main objective is to enable a fast and\ntimely interaction between the optimal controllers and state estimators with\nlimited sensor measurements. First, convergence and optimality of the proposed\nalgorithm are analytically established. Then, the proposed gradient-based\nalgorithm is modified by introducing statistical information of the inherent\nestimation and linearization errors for an improved and robust performance of\nthe online control decisions. Overall, the proposed method eliminates the\ntraditional separation of control and operation, where control and estimation\nusually operate at distinct layers and different time-scales. Hence, it enables\na computationally affordable, efficient and robust online operational framework\nfor distribution networks under time-varying settings.",
    "descriptor": "",
    "authors": [
      "Yi Guo",
      "Xinyang Zhou",
      "Changhong Zhao",
      "Lijun Chen",
      "Gabriela Hug",
      "Tyler H. Summers"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11327"
  },
  {
    "id": "arXiv:2203.11363",
    "title": "PI-VAE: Physics-Informed Variational Auto-Encoder for stochastic  differential equations",
    "abstract": "We propose a new class of physics-informed neural networks, called\nphysics-informed Variational Autoencoder (PI-VAE), to solve stochastic\ndifferential equations (SDEs) or inverse problems involving SDEs. In these\nproblems the governing equations are known but only a limited number of\nmeasurements of system parameters are available. PI-VAE consists of a\nvariational autoencoder (VAE), which generates samples of system variables and\nparameters. This generative model is integrated with the governing equations.\nIn this integration, the derivatives of VAE outputs are readily calculated\nusing automatic differentiation, and used in the physics-based loss term. In\nthis work, the loss function is chosen to be the Maximum Mean Discrepancy (MMD)\nfor improved performance, and neural network parameters are updated iteratively\nusing the stochastic gradient descent algorithm. We first test the proposed\nmethod on approximating stochastic processes. Then we study three types of\nproblems related to SDEs: forward and inverse problems together with mixed\nproblems where system parameters and solutions are simultaneously calculated.\nThe satisfactory accuracy and efficiency of the proposed method are numerically\ndemonstrated in comparison with physics-informed generative adversarial network\n(PI-WGAN).",
    "descriptor": "",
    "authors": [
      "Weiheng Zhong",
      "Hadi Meidani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11363"
  },
  {
    "id": "arXiv:2203.11377",
    "title": "Sequential algorithmic modification with test data reuse",
    "abstract": "After initial release of a machine learning algorithm, the model can be\nfine-tuned by retraining on subsequently gathered data, adding newly discovered\nfeatures, or more. Each modification introduces a risk of deteriorating\nperformance and must be validated on a test dataset. It may not always be\npractical to assemble a new dataset for testing each modification, especially\nwhen most modifications are minor or are implemented in rapid succession.\nRecent works have shown how one can repeatedly test modifications on the same\ndataset and protect against overfitting by (i) discretizing test results along\na grid and (ii) applying a Bonferroni correction to adjust for the total number\nof modifications considered by an adaptive developer. However, the standard\nBonferroni correction is overly conservative when most modifications are\nbeneficial and/or highly correlated. This work investigates more powerful\napproaches using alpha-recycling and sequentially-rejective graphical\nprocedures (SRGPs). We introduce novel extensions that account for correlation\nbetween adaptively chosen algorithmic modifications. In empirical analyses, the\nSRGPs control the error rate of approving unacceptable modifications and\napprove a substantially higher number of beneficial modifications than previous\napproaches.",
    "descriptor": "",
    "authors": [
      "Jean Feng",
      "Gene Pennello",
      "Nicholas Petrick",
      "Berkman Sahiner",
      "Romain Pirracchio",
      "Alexej Gossmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.11377"
  },
  {
    "id": "arXiv:2203.11391",
    "title": "Survival Analysis for Idiopathic Pulmonary Fibrosis using CT Images and  Incomplete Clinical Data",
    "abstract": "Idiopathic Pulmonary Fibrosis (IPF) is an inexorably progressive fibrotic\nlung disease with a variable and unpredictable rate of progression. CT scans of\nthe lungs inform clinical assessment of IPF patients and contain pertinent\ninformation related to disease progression. In this work, we propose a\nmulti-modal method that uses neural networks and memory banks to predict the\nsurvival of IPF patients using clinical and imaging data. The majority of\nclinical IPF patient records have missing data (e.g. missing lung function\ntests). To this end, we propose a probabilistic model that captures the\ndependencies between the observed clinical variables and imputes missing ones.\nThis principled approach to missing data imputation can be naturally combined\nwith a deep survival analysis model. We show that the proposed framework yields\nsignificantly better survival analysis results than baselines in terms of\nconcordance index and integrated Brier score. Our work also provides insights\ninto novel image-based biomarkers that are linked to mortality.",
    "descriptor": "\nComments: Accepted as a full paper at the Medical Imaging with Deep Learning conference (MIDL 2022)\n",
    "authors": [
      "Ahmed H. Shahin",
      "Joseph Jacob",
      "Daniel C. Alexander",
      "David Barber"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11391"
  },
  {
    "id": "arXiv:2203.11404",
    "title": "Enhanced Preamble Based MAC Mechanism for IIoT-oriented PLC Network",
    "abstract": "In this paper, we propose an enhanced preamble based media access control\nmechanism (E-PMAC), which can be applied in power line communication (PLC)\nnetwork for Industrial Internet of Things (IIoT). We introduce detailed\ntechnologies used in E-PMAC, including delay calibration mechanism, preamble\ndesign, and slot allocation algorithm. With these technologies, E-PMAC is more\nrobust than existing preamble based MAC mechanism (P-MAC). Besides, we analyze\nthe disadvantage of P-MAC in multi-layer networking and design the networking\nprocess of E-PMAC to accelerate networking process. We analyze the complexity\nof networking process in P-MAC and E-PMAC and prove that E-PMAC has lower\ncomplexity than P-MAC. Finally, we simulate the single-layer networking and\nmulti-layer networking of E-PMAC, P-MAC, and existing PLC protocol, i.e. ,\nIEEE1901.1. The simulation results indicate that E-PMAC spends much less time\nin networking than IEEE1901.1 and P-MAC. Finally, with our work, a PLC network\nbased on E-PMAC mechanism can be realized.",
    "descriptor": "\nComments: 7 pages, 12 figures, to appeal in The 2022 IEEE 95th Vehicular Technology Conference (VTC2022-Spring)\n",
    "authors": [
      "Kai Song",
      "Biqian Feng",
      "Yongpeng Wu",
      "Wenjun Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.11404"
  },
  {
    "id": "arXiv:2203.11438",
    "title": "An Efficient Data-Driven Multiscale Stochastic Reduced Order Modeling  Framework for Complex Systems",
    "abstract": "Suitable reduced order models (ROMs) are computationally efficient tools in\ncharacterizing key dynamical and statistical features of nature. In this paper,\na systematic multiscale stochastic ROM framework is developed for complex\nsystems with strong chaotic or turbulent behavior. The new ROMs are\nfundamentally different from the traditional Galerkin ROM (G-ROM) or those\ndeterministic ROMs that aim at minimizing the path-wise errors and applying\nmainly to laminar systems. Here, the new ROM focuses on recovering the\nlarge-scale dynamics to the maximum extent while it also exploits cheap but\neffective conditional linear functions as the closure terms to capture the\nstatistical features of the medium-scale variables and its feedback to the\nlarge scales. In addition, physics constraints are incorporated into the new\nROM. One unique feature of the resulting ROM is that it facilitates an\nefficient and accurate scheme for nonlinear data assimilation, the solution of\nwhich is provided by closed analytic formulae. Such an analytic solvable data\nassimilation solution significantly accelerates the computational efficiency\nand allows the new ROM to avoid many potential numerical and sampling issues in\nrecovering the unobserved states from partial observations. The overall model\ncalibration is efficient and systematic via explicit mathematical formulae. The\nnew ROM framework is applied to complex nonlinear systems, in which the\nintrinsic turbulent behavior is either triggered by external random forcing or\ndeterministic nonlinearity. It is shown that the new ROM significantly\noutperforms the G-ROM in both scenarios in terms of reproducing the dynamical\nand statistical features as well as recovering unobserved states via the\nassociated efficient data assimilation scheme.",
    "descriptor": "",
    "authors": [
      "Changhong Mou",
      "Nan Chen",
      "Traian Iliescu"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.11438"
  },
  {
    "id": "arXiv:2203.11452",
    "title": "Improved characterization of Lagrangian coherent structures through  time-scale analysis",
    "abstract": "The computation of Lagrangian coherent structures (LCS) has established\nitself as a prominent means to reveal significant geometric structures in\ntime-dependent vector fields. Their characterization, however, requires the\nselection of a suitable time parameter for the construction of the flow map\nthat may not be known in advance. We present in this paper a continuous\ntime-scale framework for LCS extraction and visualization. Specifically, we\ntreat the time axis as a continuum from which a best temporal scale is\nautomatically determined at each spatial location for the extraction of LCS.\nBeyond its effectiveness with vector fields we show that this method can be\nsuccessfully applied to improve the characterization of salient structures in\ntensor fields and discrete maps. We present applications of our method to\nproblems spanning fluid dynamics, medical imaging, and orbital mechanics. The\nresults show that our approach can reveal important structural features that\nare missed by existing LCS extraction methods.",
    "descriptor": "",
    "authors": [
      "Zi'ang Ding",
      "Xavier Tricoche"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.11452"
  },
  {
    "id": "arXiv:2203.11500",
    "title": "Joint Noise Reduction and Listening Enhancement for Full-End Speech  Enhancement",
    "abstract": "Speech enhancement (SE) methods mainly focus on recovering clean speech from\nnoisy input. In real-world speech communication, however, noises often exist in\nnot only speaker but also listener environments. Although SE methods can\nsuppress the noise contained in the speaker's voice, they cannot deal with the\nnoise that is physically present in the listener side. To address such a\ncomplicated but common scenario, we investigate a deep learning-based joint\nframework integrating noise reduction (NR) with listening enhancement (LE), in\nwhich the NR module first suppresses noise and the LE module then modifies the\ndenoised speech, i.e., the output of the NR module, to further improve speech\nintelligibility. The enhanced speech can thus be less noisy and more\nintelligible for listeners. Experimental results show that our proposed method\nachieves promising results and significantly outperforms the disjoint\nprocessing methods in terms of various speech evaluation metrics.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Haoyu Li",
      "Yun Liu",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.11500"
  },
  {
    "id": "arXiv:2203.11510",
    "title": "Continuous Optimization for Control of Hybrid Systems with Hysteresis  via Time-Freezing",
    "abstract": "This article regards numerical optimal control of a class of hybrid systems\nwith hysteresis using solely techniques from nonlinear optimization, without\nany integer variables. Hysteresis is a rate independent memory effect which\noften results in severe nonsmoothness in the dynamics. These systems are not\nsimply Piecewise Smooth Systems (PSS); they are a more complicated form of\nhybrid systems. We introduce a time-freezing reformulation which transforms\nthese systems into a PSS. From the theoretical side, this reformulation opens\nthe door to study systems with hysteresis via the rich tools developed for\nFilippov systems. From the practical side, it enables the use of the recently\ndeveloped Finite Elements with Switch Detection [Nurkanovic et al., 2022],\nwhich makes high accuracy numerical optimal control of hybrid systems with\nhysteresis possible.",
    "descriptor": "\nComments: Submitted to the The IEEE Control Systems Letters and the IEEE Conference on Decision and Control\n",
    "authors": [
      "Armin Nurkanovi\u0107",
      "Moritz Diehl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11510"
  },
  {
    "id": "arXiv:2203.11516",
    "title": "NOS-NOC: A Software Package for Numerical Optimal Control of Nonsmooth  Systems",
    "abstract": "This letter introduces the open source software package for Nonsmooth\nNumerical Optimal Control (NOS-NOC). It is a modular tool based on CasADi\n[Andersson et al., 2019], IPOPT [W\\\"achter and Biegler, 2006] and MATLAB, for\nnumerically solving Optimal Control Problems (OCP) with piecewise smooth\nsystems (PSS). It relies on the recently introduced Finite Elements with Switch\nDetection [Nurkanovi\\'c et al., 2022] which enables high accuracy optimal\ncontrol and simulation of PSS. The time-freezing reformulation [Nurkanovi\\'c et\nal., 2021], which transforms several classes of systems with state jumps into\nPSS is supported as well. This enables the treatment of a broad class of\nnonsmooth systems in a unified way. The algorithms and reformulations yield\nmathematical programs with complementarity constraints (MPCC). They can be\nsolved with techniques of continuous optimization in a homotopy procedure,\nwithout the use of integer variables. The goal of the package is to automate\nall reformulations and to make nonsmooth optimal control problems practically\nsolvable, without deep expert knowledge.",
    "descriptor": "\nComments: Submitted to the The IEEE Control Systems Letters and the IEEE Conference on Decision and Control\n",
    "authors": [
      "Armin Nurkanovi\u0107",
      "Moritz Diehl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11516"
  },
  {
    "id": "arXiv:2203.11528",
    "title": "Out-of-distribution Generalization with Causal Invariant Transformations",
    "abstract": "In real-world applications, it is important and desirable to learn a model\nthat performs well on out-of-distribution (OOD) data. Recently, causality has\nbecome a powerful tool to tackle the OOD generalization problem, with the idea\nresting on the causal mechanism that is invariant across domains of interest.\nTo leverage the generally unknown causal mechanism, existing works assume a\nlinear form of causal feature or require sufficiently many and diverse training\ndomains, which are usually restrictive in practice. In this work, we obviate\nthese assumptions and tackle the OOD problem without explicitly recovering the\ncausal feature. Our approach is based on transformations that modify the\nnon-causal feature but leave the causal part unchanged, which can be either\nobtained from prior knowledge or learned from the training data in the\nmulti-domain scenario. Under the setting of invariant causal mechanism, we\ntheoretically show that if all such transformations are available, then we can\nlearn a minimax optimal model across the domains using only single domain data.\nNoticing that knowing a complete set of these causal invariant transformations\nmay be impractical, we further show that it suffices to know only a subset of\nthese transformations. Based on the theoretical findings, a regularized\ntraining procedure is proposed to improve the OOD generalization capability.\nExtensive experimental results on both synthetic and real datasets verify the\neffectiveness of the proposed algorithm, even with only a few causal invariant\ntransformations.",
    "descriptor": "",
    "authors": [
      "Ruoyu Wang",
      "Mingyang Yi",
      "Zhitang Chen",
      "Shengyu Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11528"
  },
  {
    "id": "arXiv:2203.11560",
    "title": "Modelling continual learning in humans with Hebbian context gating and  exponentially decaying task signals",
    "abstract": "Humans can learn several tasks in succession with minimal mutual interference\nbut perform more poorly when trained on multiple tasks at once. The opposite is\ntrue for standard deep neural networks. Here, we propose novel computational\nconstraints for artificial neural networks, inspired by earlier work on gating\nin the primate prefrontal cortex, that capture the cost of interleaved training\nand allow the network to learn two tasks in sequence without forgetting. We\naugment standard stochastic gradient descent with two algorithmic motifs,\nso-called \"sluggish\" task units and a Hebbian training step that strengthens\nconnections between task units and hidden units that encode task-relevant\ninformation. We found that the \"sluggish\" units introduce a switch-cost during\ntraining, which biases representations under interleaved training towards a\njoint representation that ignores the contextual cue, while the Hebbian step\npromotes the formation of a gating scheme from task units to the hidden layer\nthat produces orthogonal representations which are perfectly guarded against\ninterference. Validating the model on previously published human behavioural\ndata revealed that it matches performance of participants who had been trained\non blocked or interleaved curricula, and that these performance differences\nwere driven by misestimation of the true category boundary.",
    "descriptor": "\nComments: 29 pages, 7 figures\n",
    "authors": [
      "Timo Flesch",
      "David G. Nagy",
      "Andrew Saxe",
      "Christopher Summerfield"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11560"
  },
  {
    "id": "arXiv:2203.11565",
    "title": "Multi-layer Clustering-based Residual Sparsifying Transform for Low-dose  CT Image Reconstruction",
    "abstract": "The recently proposed sparsifying transform models incur low computational\ncost and have been applied to medical imaging. Meanwhile, deep models with\nnested network structure reveal great potential for learning features in\ndifferent layers. In this study, we propose a network-structured sparsifying\ntransform learning approach for X-ray computed tomography (CT), which we refer\nto as multi-layer clustering-based residual sparsifying transform (MCST)\nlearning. The proposed MCST scheme learns multiple different unitary transforms\nin each layer by dividing each layer's input into several classes. We apply the\nMCST model to low-dose CT (LDCT) reconstruction by deploying the learned MCST\nmodel into the regularizer in penalized weighted least squares (PWLS)\nreconstruction. We conducted LDCT reconstruction experiments on XCAT phantom\ndata and Mayo Clinic data and trained the MCST model with 2 (or 3) layers and\nwith 5 clusters in each layer. The learned transforms in the same layer showed\nrich features while additional information is extracted from representation\nresiduals. Our simulation results demonstrate that PWLS-MCST achieves better\nimage reconstruction quality than the conventional FBP method and PWLS with\nedge-preserving (EP) regularizer. It also outperformed recent advanced methods\nlike PWLS with a learned multi-layer residual sparsifying transform prior\n(MARS) and PWLS with a union of learned transforms (ULTRA), especially for\ndisplaying clear edges and preserving subtle details.",
    "descriptor": "\nComments: 19 pages, 12 figures, submitted to the Medical Physics\n",
    "authors": [
      "Xikai Yang",
      "Zhishen Huang",
      "Yong Long",
      "Saiprasad Ravishankar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11565"
  },
  {
    "id": "arXiv:2203.11579",
    "title": "Local Stochastic Factored Gradient Descent for Distributed Quantum State  Tomography",
    "abstract": "We propose a distributed Quantum State Tomography (QST) protocol, named Local\nStochastic Factored Gradient Descent (Local SFGD), to learn the low-rank factor\nof a density matrix over a set of local machines. QST is the canonical\nprocedure to characterize the state of a quantum system, which we formulate as\na stochastic nonconvex smooth optimization problem. Physically, the estimation\nof a low-rank density matrix helps characterizing the amount of noise\nintroduced by quantum computation. Theoretically, we prove the local\nconvergence of Local SFGD for a general class of restricted strongly\nconvex/smooth loss functions, i.e., Local SFGD converges locally to a small\nneighborhood of the global optimum at a linear rate with a constant step size,\nwhile it locally converges exactly at a sub-linear rate with diminishing step\nsizes. With a proper initialization, local convergence results imply global\nconvergence. We validate our theoretical findings with numerical simulations of\nQST on the Greenberger-Horne-Zeilinger (GHZ) state.",
    "descriptor": "",
    "authors": [
      "Junhyung Lyle Kim",
      "Mohammad Taha Toghani",
      "C\u00e9sar A. Uribe",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.11579"
  },
  {
    "id": "arXiv:2203.11643",
    "title": "Relation between spectra of Narain CFTs and properties of associated  boolean functions",
    "abstract": "Recently, the construction of Narain CFT from a certain class of quantum\nerror correcting codes has been discovered. In particular, the spectral gap of\nNarain CFT corresponds to the binary distance of the code, not the genuine\nHamming distance. In this paper, we show that the binary distance is identical\nto the so-called EPC distance of the boolean function uniquely associated with\nthe quantum code. Therefore, seeking Narain CFT with high spectral gap is\nequivalent to getting a boolean function with high EPC distance. Furthermore,\nthis problem can be addressed by finding lower Peak-to-Average Power ratio\n(PAR) with respect to the binary truth table of the boolean function. Though\nthis is neither sufficient nor necessary condition for high EPC distance, we\nconstruct some examples of relatively high EPC distances referring to the\nconstructions for lower PAR. We also see that codes with high distance are\nrelated to induced graphs with low independence numbers.",
    "descriptor": "\nComments: 27 pages, 1 figure\n",
    "authors": [
      "Yuma Furuta"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.11643"
  },
  {
    "id": "arXiv:2203.11686",
    "title": "End-to-End Learned Block-Based Image Compression with Block-Level Masked  Convolutions and Asymptotic Closed Loop Training",
    "abstract": "Learned image compression research has achieved state-of-the-art compression\nperformance with auto-encoder based neural network architectures, where the\nimage is mapped via convolutional neural networks (CNN) into a latent\nrepresentation that is quantized and processed again with CNN to obtain the\nreconstructed image. CNN operate on entire input images. On the other hand,\ntraditional state-of-the-art image and video compression methods process images\nwith a block-by-block processing approach for various reasons. Very recently,\nwork on learned image compression with block based approaches have also\nappeared, which use the auto-encoder architecture on large blocks of the input\nimage and introduce additional neural networks that perform intra/spatial\nprediction and deblocking/post-processing functions. This paper explores an\nalternative learned block-based image compression approach in which neither an\nexplicit intra prediction neural network nor an explicit deblocking neural\nnetwork is used. A single auto-encoder neural network with block-level masked\nconvolutions is used and the block size is much smaller (8x8). By using\nblock-level masked convolutions, each block is processed using reconstructed\nneighboring left and upper blocks both at the encoder and decoder. Hence, the\nmutual information between adjacent blocks is exploited during compression and\neach block is reconstructed using neighboring blocks, resolving the need for\nexplicit intra prediction and deblocking neural networks. Since the explored\nsystem is a closed loop system, a special optimization procedure, the\nasymptotic closed loop design, is used with standard stochastic gradient\ndescent based training. The experimental results indicate competitive image\ncompression performance.",
    "descriptor": "",
    "authors": [
      "Fatih Kamisli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.11686"
  },
  {
    "id": "arXiv:2203.11687",
    "title": "BEFANA: A Tool for Biodiversity-Ecosystem Functioning Assessment by  Network Analysis",
    "abstract": "BEFANA is a free and open-source software tool for ecological network\nanalysis and visualisation. It is adapted to ecologists' needs and allows them\nto study the topology and dynamics of ecological networks as well as apply\nselected machine learning algorithms. BEFANA is implemented in Python, and\nstructured as an ordered collection of interactive computational notebooks. It\nrelies on widely used open-source libraries, and aims to achieve simplicity,\ninteractivity, and extensibility. BEFANA provides methods and implementations\nfor data loading and preprocessing, network analysis and interactive\nvisualisation, modelling with experimental data, and predictive modelling with\nmachine learning. We showcase BEFANA through a concrete example of a detrital\nsoil food web of agricultural grasslands, and demonstrate all of its main\ncomponents and functionalities.",
    "descriptor": "",
    "authors": [
      "Martin Marzidov\u0161ek",
      "Vid Podpe\u010dan",
      "Erminia Conti",
      "Marko Debeljak",
      "Christian Mulder"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11687"
  },
  {
    "id": "arXiv:2203.11691",
    "title": "GAM(L)A: An econometric model for interpretable Machine Learning",
    "abstract": "Despite their high predictive performance, random forest and gradient\nboosting are often considered as black boxes or uninterpretable models which\nhas raised concerns from practitioners and regulators. As an alternative, we\npropose in this paper to use partial linear models that are inherently\ninterpretable. Specifically, this article introduces GAM-lasso (GAMLA) and\nGAM-autometrics (GAMA), denoted as GAM(L)A in short. GAM(L)A combines\nparametric and non-parametric functions to accurately capture linearities and\nnon-linearities prevailing between dependent and explanatory variables, and a\nvariable selection procedure to control for overfitting issues. Estimation\nrelies on a two-step procedure building upon the double residual method. We\nillustrate the predictive performance and interpretability of GAM(L)A on a\nregression and a classification problem. The results show that GAM(L)A\noutperforms parametric models augmented by quadratic, cubic and interaction\neffects. Moreover, the results also suggest that the performance of GAM(L)A is\nnot significantly different from that of random forest and gradient boosting.",
    "descriptor": "\nComments: 47 pages, 12 tables and 7 figures\n",
    "authors": [
      "Emmanuel Flachaire",
      "Gilles Hacheme",
      "Sullivan Hu\u00e9",
      "S\u00e9bastien Laurent"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2203.11691"
  },
  {
    "id": "arXiv:2203.11692",
    "title": "Panoptic segmentation with highly imbalanced semantic labels",
    "abstract": "This manuscript describes the panoptic segmentation method we devised for our\nsubmission to the CONIC challenge at ISBI 2022. Key features of our method are\na weighted loss that we specifically engineered for semantic segmentation of\nhighly imbalanced cell types, and an existing state-of-the art nuclei instance\nsegmentation model, which we combine in a Hovernet-like architecture.",
    "descriptor": "",
    "authors": [
      "Josef Lorenz Rumberger",
      "Elias Baumann",
      "Peter Hirsch",
      "Dagmar Kainmueller"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11692"
  },
  {
    "id": "arXiv:2203.11703",
    "title": "Switching transformations for control of opinion patterns in signed  networks: application to dynamic task allocation",
    "abstract": "We propose a new design method to control opinion patterns on signed networks\nof agents making decisions about two options and to switch the network from any\nopinion pattern to a new desired one. Our method relies on switching\ntransformations, which switch the sign of an agent's opinion at a stable\nequilibrium by flipping the sign of its local interactions with its neighbors.\nThe global dynamical behavior of the switched network can be predicted\nrigorously when the original, and thus the witched, networks are structurally\nbalanced. Structural balance ensures that the network dynamics are monotone,\nwhich makes the study of the basin of attraction of the various opinion\npatterns amenable to rigorous analysis through monotone systems theory. We\nillustrate the utility of the approach through scenarios motivated by\nmulti-robot coordination and dynamic task allocation.",
    "descriptor": "",
    "authors": [
      "Anastasia Bizyaeva",
      "Giovanna Amorim",
      "Maria Santos",
      "Alessio Franci",
      "Naomi Ehrich Leonard"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.11703"
  },
  {
    "id": "arXiv:2203.11708",
    "title": "Scale Fragilities in Localized Consensus Dynamics",
    "abstract": "We consider distributed consensus in networks where the agents have\nintegrator dynamics of order two or higher ($n\\ge 2$). We assume all feedback\nto be localized in the sense that each agent has a bounded number of neighbors\nand consider a scaling of the network through the addition of agents {in a\nmodular manner, i.e., without re-tuning controller gains upon addition}. We\nshow that standard consensus algorithms, {which rely on relative state\nfeedback, }are subject to what we term scale fragilities, meaning that\nstability is lost as the network scales. For high-order agents ($n\\ge 3$), we\nprove that no consensus algorithm with fixed gains can achieve consensus in\nnetworks of any size. That is, while a given algorithm may allow a small\nnetwork to converge, it causes instability if the network grows beyond a\ncertain finite size. This holds in families of network graphs whose algebraic\nconnectivity, that is, the smallest non-zero Laplacian eigenvalue, is\ndecreasing towards zero in network size (e.g. all planar graphs). For\nsecond-order consensus ($n = 2$) we prove that the same scale fragility applies\nto directed graphs that have a complex Laplacian eigenvalue approaching the\norigin (e.g. directed ring graphs). The proofs for both results rely on\nRouth-Hurwitz criteria for complex-valued polynomials and hold true for general\ndirected network graphs. We survey classes of graphs subject to these scale\nfragilities, discuss their scaling constants, and finally prove that a\nsub-linear scaling of nodal neighborhoods can suffice to overcome the issue.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1907.02465\n",
    "authors": [
      "Emma Tegling",
      "Bassam Bamieh",
      "Henrik Sandberg"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11708"
  },
  {
    "id": "arXiv:2203.11722",
    "title": "Convolutional Neural Network to Restore Low-Dose Digital Breast  Tomosynthesis Projections in a Variance Stabilization Domain",
    "abstract": "Digital breast tomosynthesis (DBT) exams should utilize the lowest possible\nradiation dose while maintaining sufficiently good image quality for accurate\nmedical diagnosis. In this work, we propose a convolution neural network (CNN)\nto restore low-dose (LD) DBT projections to achieve an image quality equivalent\nto a standard full-dose (FD) acquisition. The proposed network architecture\nbenefits from priors in terms of layers that were inspired by traditional\nmodel-based (MB) restoration methods, considering a model-based deep learning\napproach, where the network is trained to operate in the variance stabilization\ntransformation (VST) domain. To accurately control the network operation point,\nin terms of noise and blur of the restored image, we propose a loss function\nthat minimizes the bias and matches residual noise between the input and the\noutput. The training dataset was composed of clinical data acquired at the\nstandard FD and low-dose pairs obtained by the injection of quantum noise. The\nnetwork was tested using real DBT projections acquired with a physical\nanthropomorphic breast phantom. The proposed network achieved superior results\nin terms of the mean normalized squared error (MNSE), training time and noise\nspatial correlation compared with networks trained with traditional data-driven\nmethods. The proposed approach can be extended for other medical imaging\napplication that requires LD acquisitions.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Rodrigo de Barros Vimieiro",
      "Chuang Niu",
      "Hongming Shan",
      "Lucas Rodrigues Borges",
      "Ge Wang",
      "Marcelo Andrade da Costa Vieira"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11722"
  },
  {
    "id": "arXiv:2203.11725",
    "title": "Unsupervised Anomaly Detection in Medical Images with a Memory-augmented  Multi-level Cross-attentional Masked Autoencoder",
    "abstract": "Unsupervised anomaly detection (UAD) aims to find anomalous images by\noptimising a detector using a training set that contains only normal images.\nUAD approaches can be based on reconstruction methods, self-supervised\napproaches, and Imagenet pre-trained models. Reconstruction methods, which\ndetect anomalies from image reconstruction errors, are advantageous because\nthey do not rely on the design of problem-specific pretext tasks needed by\nself-supervised approaches, and on the unreliable translation of models\npre-trained from non-medical datasets. However, reconstruction methods may fail\nbecause they can have low reconstruction errors even for anomalous images. In\nthis paper, we introduce a new reconstruction-based UAD approach that addresses\nthis low-reconstruction error issue for anomalous images. Our UAD approach, the\nmemory-augmented multi-level cross-attentional masked autoencoder (MemMC-MAE),\nis a transformer-based approach, consisting of a novel memory-augmented\nself-attention operator for the encoder and a new multi-level cross-attention\noperator for the decoder. MemMC-MAE masks large parts of the input image during\nits reconstruction, reducing the risk that it will produce low reconstruction\nerrors because anomalies are likely to be masked and cannot be reconstructed.\nHowever, when the anomaly is not masked, then the normal patterns stored in the\nencoder's memory combined with the decoder's multi-level cross-attention will\nconstrain the accurate reconstruction of the anomaly. We show that our method\nachieves SOTA anomaly detection and localisation on colonoscopy and Covid-19\nChest X-ray datasets.",
    "descriptor": "\nComments: Technical report, 11 pages, 3 figures\n",
    "authors": [
      "Yu Tian",
      "Guansong Pang",
      "Yuyuan Liu",
      "Chong Wang",
      "Yuanhong Chen",
      "Fengbei Liu",
      "Rajvinder Singh",
      "Johan W Verjans",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11725"
  },
  {
    "id": "arXiv:2203.11726",
    "title": "AI-enabled Assessment of Cardiac Systolic and Diastolic Function from  Echocardiography",
    "abstract": "Left ventricular (LV) function is an important factor in terms of patient\nmanagement, outcome, and long-term survival of patients with heart disease. The\nmost recently published clinical guidelines for heart failure recognise that\nover reliance on only one measure of cardiac function (LV ejection fraction) as\na diagnostic and treatment stratification biomarker is suboptimal. Recent\nadvances in AI-based echocardiography analysis have shown excellent results on\nautomated estimation of LV volumes and LV ejection fraction. However, from\ntime-varying 2-D echocardiography acquisition, a richer description of cardiac\nfunction can be obtained by estimating functional biomarkers from the complete\ncardiac cycle. In this work we propose for the first time an AI approach for\nderiving advanced biomarkers of systolic and diastolic LV function from 2-D\nechocardiography based on segmentations of the full cardiac cycle. These\nbiomarkers will allow clinicians to obtain a much richer picture of the heart\nin health and disease. The AI model is based on the 'nn-Unet' framework and was\ntrained and tested using four different databases. Results show excellent\nagreement between manual and automated analysis and showcase the potential of\nthe advanced systolic and diastolic biomarkers for patient stratification.\nFinally, for a subset of 50 cases, we perform a correlation analysis between\nclinical biomarkers derived from echocardiography and CMR and we show excellent\nagreement between the two modalities.",
    "descriptor": "",
    "authors": [
      "Esther Puyol-Ant\u00f3n",
      "Bram Ruijsink",
      "Baldeep S. Sidhu",
      "Justin Gould",
      "Bradley Porter",
      "Mark K. Elliott",
      "Vishal Mehta",
      "Haotian Gu",
      "Miguel Xochicale",
      "Alberto Gomez",
      "Christopher A. Rinaldi",
      "Martin Cowie",
      "Phil Chowienczyk",
      "Reza Razavi",
      "Andrew P. King"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.11726"
  },
  {
    "id": "arXiv:2203.11727",
    "title": "Gated Recurrent Unit based Autoencoder for Optical Link Fault Diagnosis  in Passive Optical Networks",
    "abstract": "We propose a deep learning approach based on an autoencoder for identifying\nand localizing fiber faults in passive optical networks. The experimental\nresults show that the proposed method detects faults with 97% accuracy,\npinpoints them with an RMSE of 0.18 m and outperforms conventional techniques.",
    "descriptor": "\nComments: 2021 European Conference on Optical Communication (ECOC)\n",
    "authors": [
      "Khouloud Abdelli",
      "Florian Azendorf",
      "Helmut Griesser",
      "Carsten Tropschug",
      "Stephan Pachnicke"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11727"
  },
  {
    "id": "arXiv:2203.11758",
    "title": "Linear convergence of a policy gradient method for finite horizon  continuous time stochastic control problems",
    "abstract": "Despite its popularity in the reinforcement learning community, a provably\nconvergent policy gradient method for general continuous space-time stochastic\ncontrol problems has been elusive. This paper closes the gap by proposing a\nproximal gradient algorithm for feedback controls of finite-time horizon\nstochastic control problems. The state dynamics are continuous time nonlinear\ndiffusions with controlled drift and possibly degenerate noise, and the\nobjectives are nonconvex in the state and nonsmooth in the control. We prove\nunder suitable conditions that the algorithm converges linearly to a stationary\npoint of the control problem, and is stable with respect to policy updates by\napproximate gradient steps. The convergence result justifies the recent\nreinforcement learning heuristics that adding entropy regularization to the\noptimization objective accelerates the convergence of policy gradient methods.\nThe proof exploits careful regularity estimates of backward stochastic\ndifferential equations.",
    "descriptor": "",
    "authors": [
      "Christoph Reisinger",
      "Wolfgang Stockinger",
      "Yufei Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.11758"
  },
  {
    "id": "arXiv:2203.11769",
    "title": "Impact of counteracting vehicles on the characteristics of a smart city  transport system",
    "abstract": "The development of smart city transport systems, including self-driving cars,\nleads to an increase in the threat of hostile interference in the processes of\nvehicle control. This interference may disrupt the normal functioning of the\ntransport system, and, if is performed covertly, the system can be negatively\naffected for a long period of time. This paper develops a simulation stochastic\ncellular automata model of traffic on a circular two-lane road based on the\nSakai-Nishinari-Fukui-Schadschneider (S-NFS) rules. In the presented model, in\naddition to ordinary vehicles, there are covertly counteracting vehicles; their\ntask is to reduce the quantity indicators (such as traffic flux) of the\ntransport system using special rules of behavior. Three such rules are\nconsidered and compared: two lane-changing rules and one slow-down rule. It is\nshown that such counteracting vehicles can affect the traffic flow, mainly in\nthe region of the maximum of the fundamental diagram, that is, at average\nvalues of the vehicle density. In free-flowing traffic or in a traffic jam, the\ninfluence of the counteracting vehicle is negligible regardless of its rules of\nbehavior.",
    "descriptor": "",
    "authors": [
      "Nikita V. Bykov"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.11769"
  },
  {
    "id": "arXiv:2203.11783",
    "title": "The Combinatorial Multi-Round Ascending Auction",
    "abstract": "The Combinatorial Multi-Round Auction (CMRA) is a new auction format which\nhas already been used in several recent European spectrum auctions. We\ncharacterize equilibria in the CMRA that feature auction-specific forms of\ntruthful bidding, demand expansion, and demand reduction for settings in which\nbidders have either decreasing or non-decreasing marginal values. In\nparticular, we establish sufficient conditions for riskless collusion. Overall,\nour results suggest that the CMRA might be an attractive auction design in the\npresence of highly complementary goods on sale. We discuss to what extent our\ntheory is consistent with outcomes data in Danish spectrum auctions and how our\npredictions can be tested using bidding data.",
    "descriptor": "",
    "authors": [
      "Bernhard Kasberger",
      "Alexander Teytelboym"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.11783"
  },
  {
    "id": "arXiv:2203.11784",
    "title": "Controlling the average degree in random power-law networks",
    "abstract": "We describe a procedure that allows continuously tuning the average degree\n$\\langle k \\rangle$ of uncorrelated networks with power-law degree distribution\n$p(k)$. Inn order to do this, we modify the low-$k$ region of $p(k)$, while\npreserving the large-$k$ tail up to a cutoff. Then, we use the modified $p(k)$\nto obtain the degree sequence required to construct networks through the\nconfiguration model. We analyze the resulting nearest-neighbor degree and local\nclustering to verify the absence of $k$-dependencies. Finally, a further\nmodification is introduced to eliminate the sample fluctuations in the average\ndegree.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Allan Vieira",
      "Judson Moura",
      "Celia Anteneodo"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.11784"
  },
  {
    "id": "arXiv:2203.11829",
    "title": "Provable Constrained Stochastic Convex Optimization with XOR-Projected  Gradient Descent",
    "abstract": "Provably solving stochastic convex optimization problems with constraints is\nessential for various problems in science, business, and statistics. Recently\nproposed XOR-Stochastic Gradient Descent (XOR-SGD) provides a convergence rate\nguarantee solving the constraints-free version of the problem by leveraging\nXOR-Sampling. However, the task becomes more difficult when additional equality\nand inequality constraints are needed to be satisfied. Here we propose XOR-PGD,\na novel algorithm based on Projected Gradient Descent (PGD) coupled with the\nXOR sampler, which is guaranteed to solve the constrained stochastic convex\noptimization problem still in linear convergence rate by choosing proper step\nsize. We show on both synthetic stochastic inventory management and real-world\nroad network design problems that the rate of constraints satisfaction of the\nsolutions optimized by XOR-PGD is $10\\%$ more than the competing approaches in\na very large searching space. The improved XOR-PGD algorithm is demonstrated to\nbe more accurate and efficient than both XOR-SGD and SGD coupled with MCMC\nbased samplers. It is also shown to be more scalable with respect to the number\nof samples and processor cores via experiments with large dimensions.",
    "descriptor": "",
    "authors": [
      "Fan Ding",
      "Yijie Wang",
      "Jianzhu Ma",
      "Yexiang Xue"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11829"
  },
  {
    "id": "arXiv:2203.11837",
    "title": "Gain and phase type multipliers for structured feedback robustness",
    "abstract": "It is known that the stability of a feedback interconnection of two linear\ntime-invariant systems implies that the graphs of the open-loop systems are\nquadratically separated. This separation is defined by an object known as the\nmultiplier. The theory of integral quadratic constraints shows that the\nconverse also holds under certain conditions. This paper establishes that if\nthe feedback is robustly stable against certain structured uncertainty, then\nthere always exists a multiplier that takes a corresponding form. In\nparticular, if the feedback is robustly stable to certain gain-type\nuncertainty, then there exists a corresponding multiplier that is of\nphase-type, i.e., its diagonal blocks are zeros. These results build on the\nnotion of phases of matrices and systems, which was recently introduced in the\nfield of control. Similarly, if the feedback is robustly stable to certain\nphase-type uncertainty, then there exists a gain-type multiplier, i.e., its\noff-diagonal blocks are zeros. The results are meaningfully instructive in the\nsearch for a valid multiplier for establishing robust closed-loop stability,\nand cover the well-known small-gain and the recent small-phase theorems.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Axel Ringh",
      "Xin Mao",
      "Wei Chen",
      "Li Qiu",
      "Sei Zhen Khong"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11837"
  },
  {
    "id": "arXiv:2203.11864",
    "title": "On the (Non-)Robustness of Two-Layer Neural Networks in Different  Learning Regimes",
    "abstract": "Neural networks are known to be highly sensitive to adversarial examples.\nThese may arise due to different factors, such as random initialization, or\nspurious correlations in the learning problem. To better understand these\nfactors, we provide a precise study of robustness and generalization in\ndifferent scenarios, from initialization to the end of training in different\nregimes, as well as intermediate scenarios, where initialization still plays a\nrole due to \"lazy\" training. We consider over-parameterized networks in high\ndimensions with quadratic targets and infinite samples. Our analysis allows us\nto identify new trade-offs between generalization and robustness, whereby\nrobustness can only get worse when generalization improves, and vice versa. We\nalso show how linearized lazy training regimes can worsen robustness, due to\nimproperly scaled random initialization. Our theoretical results are\nillustrated with numerical experiments.",
    "descriptor": "",
    "authors": [
      "Elvis Dohmatob",
      "Alberto Bietti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11864"
  },
  {
    "id": "arXiv:2203.11869",
    "title": "An Optimal Transport Formulation of Bayes' Law for Nonlinear Filtering  Algorithms",
    "abstract": "This paper presents a variational representation of the Bayes' law using\noptimal transportation theory. The variational representation is in terms of\nthe optimal transportation between the joint distribution of the (state,\nobservation) and their independent coupling. By imposing certain structure on\nthe transport map, the solution to the variational problem is used to construct\na Brenier-type map that transports the prior distribution to the posterior\ndistribution for any value of the observation signal. The new formulation is\nused to derive the optimal transport form of the Ensemble Kalman filter (EnKF)\nfor the discrete-time filtering problem and propose a novel extension of EnKF\nto the non-Gaussian setting utilizing input convex neural networks. Finally,\nthe proposed methodology is used to derive the optimal transport form of the\nfeedback particle filler (FPF) in the continuous-time limit, which constitutes\nits first variational construction without explicitly using the nonlinear\nfiltering equation or Bayes' law.",
    "descriptor": "",
    "authors": [
      "Amirhossein Taghvaei",
      "Bamdad Hosseini"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.11869"
  },
  {
    "id": "arXiv:2203.11872",
    "title": "Performance of long short-term memory artificial neural networks in  nowcasting during the COVID-19 crisis",
    "abstract": "The COVID-19 pandemic has demonstrated the increasing need of policymakers\nfor timely estimates of macroeconomic variables. A prior UNCTAD research paper\nexamined the suitability of long short-term memory artificial neural networks\n(LSTM) for performing economic nowcasting of this nature. Here, the LSTM's\nperformance during the COVID-19 pandemic is compared and contrasted with that\nof the dynamic factor model (DFM), a commonly used methodology in the field.\nThree separate variables, global merchandise export values and volumes and\nglobal services exports, were nowcast with actual data vintages and performance\nevaluated for the second, third, and fourth quarters of 2020 and the first and\nsecond quarters of 2021. In terms of both mean absolute error and root mean\nsquare error, the LSTM obtained better performance in two-thirds of\nvariable/quarter combinations, as well as displayed more gradual forecast\nevolutions with more consistent narratives and smaller revisions. Additionally,\na methodology to introduce interpretability to LSTMs is introduced and made\navailable in the accompanying nowcast_lstm Python library, which is now also\navailable in R, MATLAB, and Julia.",
    "descriptor": "\nComments: 24 pages, 3 figures, 3 tables\n",
    "authors": [
      "Daniel Hopp"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2203.11872"
  },
  {
    "id": "arXiv:2203.11882",
    "title": "Linear-depth quantum circuits for multi-qubit controlled gates",
    "abstract": "Quantum circuit depth minimization is critical for practical applications of\ncircuit-based quantum computation. In this work, we present a systematic\nprocedure to decompose multi-qubit-controlled unitary gate, which is essential\nin many quantum algorithms, to controlled-NOT and single-qubit gates with which\nquantum circuit depth only increases linearly with the number of control\nqubits. Our algorithm does not require any ancillary qubits and achieves a\nquadratic reduction of the circuit depth against known methods. We demonstrate\nthe advantage of our algorithm with proof-of-principle experiments implemented\non the IBM quantum cloud platform.",
    "descriptor": "",
    "authors": [
      "Adenilton J. da Silva",
      "Daniel K. Park"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2203.11882"
  },
  {
    "id": "arXiv:1609.09656",
    "title": "Automated Enterprise Applications Generation from Requirements Model",
    "abstract": "Comments: update version from 2016",
    "descriptor": "\nComments: update version from 2016\n",
    "authors": [
      "Yilong Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/1609.09656"
  },
  {
    "id": "arXiv:1709.00944",
    "title": "Audio-Visual Speech Enhancement using Multimodal Deep Convolutional  Neural Network",
    "abstract": "Comments: This paper is the same as arXiv:1703.10893v2. Apologies for the inconvenience",
    "descriptor": "\nComments: This paper is the same as arXiv:1703.10893v2. Apologies for the inconvenience\n",
    "authors": [
      "Jen-Cheng Hou",
      "Syu-Siang Wang",
      "Ying-Hui Lai",
      "Yu Tsao",
      "Hsiu-Wen Chang",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1709.00944"
  },
  {
    "id": "arXiv:1906.05757",
    "title": "The rank of sparse random matrices",
    "abstract": "Comments: This article supersedes arXiv:1810.07390",
    "descriptor": "\nComments: This article supersedes arXiv:1810.07390\n",
    "authors": [
      "Amin Coja-Oghlan",
      "Alperen A. Erg\u00fcr",
      "Pu Gao",
      "Samuel Hetterich",
      "Maurice Rolvien"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1906.05757"
  },
  {
    "id": "arXiv:1909.07570",
    "title": "Nonnegative Canonical Tensor Decomposition with Linear Constraints:  nnCANDELINC",
    "abstract": "Comments: 29 pages, 6 figures",
    "descriptor": "\nComments: 29 pages, 6 figures\n",
    "authors": [
      "Boian Alexandrov",
      "Derek DeSantis",
      "Gianmarco Manzini",
      "Erik Skau"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1909.07570"
  },
  {
    "id": "arXiv:2004.04402",
    "title": "Reliable Time Prediction in the Markov Stochastic Block Model",
    "abstract": "Reliable Time Prediction in the Markov Stochastic Block Model",
    "descriptor": "",
    "authors": [
      "Quentin Duchemin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.04402"
  },
  {
    "id": "arXiv:2004.05909",
    "title": "kDecay: Just adding k-decay items on Learning-Rate Schedule to improve  Neural Networks",
    "abstract": "kDecay: Just adding k-decay items on Learning-Rate Schedule to improve  Neural Networks",
    "descriptor": "",
    "authors": [
      "Tao Zhang",
      "Wei Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2004.05909"
  },
  {
    "id": "arXiv:2006.04583",
    "title": "Vertex removal in biclique graphs",
    "abstract": "Vertex removal in biclique graphs",
    "descriptor": "",
    "authors": [
      "Leandro Montero"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2006.04583"
  },
  {
    "id": "arXiv:2007.04793",
    "title": "Statistical Shape Analysis of Brain Arterial Networks (BAN)",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2003.00287",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2003.00287\n",
    "authors": [
      "Xiaoyang Guo",
      "Aditi Basu Bal",
      "Tom Needham",
      "Anuj Srivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Differential Geometry (math.DG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2007.04793"
  },
  {
    "id": "arXiv:2007.10632",
    "title": "Rational homotopy type and computability",
    "abstract": "Comments: 26 pages. This is a major revision: The former Lemma 7.2 had been proven incorrectly and is now a conjecture, as is one direction of what was previously the main theorem. I have added proofs of a number of special cases as well as an explanation of why the general statement seems very difficult",
    "descriptor": "\nComments: 26 pages. This is a major revision: The former Lemma 7.2 had been proven incorrectly and is now a conjecture, as is one direction of what was previously the main theorem. I have added proofs of a number of special cases as well as an explanation of why the general statement seems very difficult\n",
    "authors": [
      "Fedor Manin"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2007.10632"
  },
  {
    "id": "arXiv:2008.07682",
    "title": "Residual Learning from Demonstration: Adapting DMPs for Contact-rich  Manipulation",
    "abstract": "Residual Learning from Demonstration: Adapting DMPs for Contact-rich  Manipulation",
    "descriptor": "",
    "authors": [
      "Todor Davchev",
      "Kevin Sebastian Luck",
      "Michael Burke",
      "Franziska Meier",
      "Stefan Schaal",
      "Subramanian Ramamoorthy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2008.07682"
  },
  {
    "id": "arXiv:2008.07912",
    "title": "Inductive logic programming at 30: a new introduction",
    "abstract": "Comments: Preprint of a paper accepted for JAIR",
    "descriptor": "\nComments: Preprint of a paper accepted for JAIR\n",
    "authors": [
      "Andrew Cropper",
      "Sebastijan Duman\u010di\u0107"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.07912"
  },
  {
    "id": "arXiv:2009.05208",
    "title": "Maximizing Convergence Time in Network Averaging Dynamics Subject to  Edge Removal",
    "abstract": "Maximizing Convergence Time in Network Averaging Dynamics Subject to  Edge Removal",
    "descriptor": "",
    "authors": [
      "S. Rasoul Etesami"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Complexity (cs.CC)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2009.05208"
  },
  {
    "id": "arXiv:2009.06412",
    "title": "Comprehensive Comparison of Deep Learning Models for Lung and COVID-19  Lesion Segmentation in CT scans",
    "abstract": "Comments: 10 pages, 8 figures, 2 tables",
    "descriptor": "\nComments: 10 pages, 8 figures, 2 tables\n",
    "authors": [
      "Paschalis Bizopoulos",
      "Nicholas Vretos",
      "Petros Daras"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.06412"
  },
  {
    "id": "arXiv:2010.05360",
    "title": "A range characterization of the single-quadrant ADRT",
    "abstract": "A range characterization of the single-quadrant ADRT",
    "descriptor": "",
    "authors": [
      "Weilin Li",
      "Kui Ren",
      "Donsub Rim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.05360"
  },
  {
    "id": "arXiv:2010.10805",
    "title": "SeqTrans: Automatic Vulnerability Fix via Sequence to Sequence Learning",
    "abstract": "Comments: 22 pages, 20 figures, 7 tables",
    "descriptor": "\nComments: 22 pages, 20 figures, 7 tables\n",
    "authors": [
      "Jianlei Chi",
      "Yu Qu",
      "Ting Liu",
      "Qinghua Zheng",
      "Heng Yin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2010.10805"
  },
  {
    "id": "arXiv:2011.03653",
    "title": "No-regret Learning in Price Competitions under Consumer Reference  Effects",
    "abstract": "Comments: Includes minor correction to statement of Theorem 5.1 and relevant assumptions in NeurIPS camera ready version",
    "descriptor": "\nComments: Includes minor correction to statement of Theorem 5.1 and relevant assumptions in NeurIPS camera ready version\n",
    "authors": [
      "Negin Golrezaei",
      "Patrick Jaillet",
      "Jason Cheuk Nam Liang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2011.03653"
  },
  {
    "id": "arXiv:2011.05260",
    "title": "ATCN: Resource-Efficient Processing of Time Series on Edge",
    "abstract": "Comments: Published in ACM Trans. Embed. Comput. Syst. (March 2022)",
    "descriptor": "\nComments: Published in ACM Trans. Embed. Comput. Syst. (March 2022)\n",
    "authors": [
      "Mohammadreza Baharani",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.05260"
  },
  {
    "id": "arXiv:2012.00620",
    "title": "Improved Bounds for $(b,k)$-hashing",
    "abstract": "Improved Bounds for $(b,k)$-hashing",
    "descriptor": "",
    "authors": [
      "Stefano Della Fiore",
      "Simone Costa",
      "Marco Dalai"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.00620"
  },
  {
    "id": "arXiv:2012.04087",
    "title": "Invertibility Conditions for the Admittance Matrices of Balanced Power  Systems",
    "abstract": "Comments: 10 pages, 2 figures, 1 table, submitted to IEEE Transactions on Power Systems",
    "descriptor": "\nComments: 10 pages, 2 figures, 1 table, submitted to IEEE Transactions on Power Systems\n",
    "authors": [
      "Daniel Turizo",
      "Daniel K. Molzahn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.04087"
  },
  {
    "id": "arXiv:2012.04886",
    "title": "DS-Net: Dynamic Spatiotemporal Network for Video Salient Object  Detection",
    "abstract": "Comments: The article has made some format changes",
    "descriptor": "\nComments: The article has made some format changes\n",
    "authors": [
      "Jing Liu",
      "Jiaxiang Wang",
      "Weikang Wang",
      "Yuting Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04886"
  },
  {
    "id": "arXiv:2012.09424",
    "title": "Predicting Events in MOBA Games: Prediction, Attribution, and Evaluation",
    "abstract": "Predicting Events in MOBA Games: Prediction, Attribution, and Evaluation",
    "descriptor": "",
    "authors": [
      "Zelong Yang",
      "Yan Wang",
      "Piji Li",
      "Shaobin Lin",
      "Shuming Shi",
      "Shao-Lun Huang",
      "Wei Bi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.09424"
  },
  {
    "id": "arXiv:2012.12298",
    "title": "Zeros of Gaussian Weyl-Heisenberg functions and hyperuniformity of  charge",
    "abstract": "Comments: 43 pages",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "Antti Haimi",
      "G\u00fcnther Koliander",
      "Jos\u00e9 Luis Romero"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.12298"
  },
  {
    "id": "arXiv:2101.01076",
    "title": "Unbox the Blackbox: Predict and Interpret YouTube Viewership Using Deep  Learning",
    "abstract": "Comments: WITS 2021 Best Paper Award",
    "descriptor": "\nComments: WITS 2021 Best Paper Award\n",
    "authors": [
      "Jiaheng Xie",
      "Xiao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.01076"
  },
  {
    "id": "arXiv:2101.03866",
    "title": "Register Automata with Extrema Constraints, and an Application to  Two-Variable Logic",
    "abstract": "Comments: The short version of this article appeared in the conference proceedings of LICS 2020",
    "descriptor": "\nComments: The short version of this article appeared in the conference proceedings of LICS 2020\n",
    "authors": [
      "Szymon Toru\u0144czyk",
      "Thomas Zeume"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2101.03866"
  },
  {
    "id": "arXiv:2102.03824",
    "title": "Neural Termination Analysis",
    "abstract": "Neural Termination Analysis",
    "descriptor": "",
    "authors": [
      "Mirco Giacobbe",
      "Daniel Kroening",
      "Julian Parsert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2102.03824"
  },
  {
    "id": "arXiv:2102.04152",
    "title": "EigenGame Unloaded: When playing games is better than optimizing",
    "abstract": "Comments: Published in ICLR '22",
    "descriptor": "\nComments: Published in ICLR '22\n",
    "authors": [
      "Ian Gemp",
      "Brian McWilliams",
      "Claire Vernade",
      "Thore Graepel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.04152"
  },
  {
    "id": "arXiv:2102.08804",
    "title": "LIRA-V: Lightweight Remote Attestation for Constrained RISC-V Devices",
    "abstract": "Comments: Published in the proceedings of the IEEE Security and Privacy Workshops, 2021",
    "descriptor": "\nComments: Published in the proceedings of the IEEE Security and Privacy Workshops, 2021\n",
    "authors": [
      "Carlton Shepherd",
      "Konstantinos Markantonakis",
      "Georges-Axel Jaloyan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.08804"
  },
  {
    "id": "arXiv:2102.11923",
    "title": "KAM Theory Meets Statistical Learning Theory: Hamiltonian Neural  Networks with Non-Zero Training Loss",
    "abstract": "Comments: Accepted to the thirty-sixth AAAI conference on artificial intelligence (AAAI-22) as an oral presentation",
    "descriptor": "\nComments: Accepted to the thirty-sixth AAAI conference on artificial intelligence (AAAI-22) as an oral presentation\n",
    "authors": [
      "Yuhan Chen",
      "Takashi Matsubara",
      "Takaharu Yaguchi"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.11923"
  },
  {
    "id": "arXiv:2102.12416",
    "title": "Accelerating Communication for Parallel Programming Models on GPU  Systems",
    "abstract": "Comments: 12 pages, 17 figures, submitted to Journal of Parallel Computing",
    "descriptor": "\nComments: 12 pages, 17 figures, submitted to Journal of Parallel Computing\n",
    "authors": [
      "Jaemin Choi",
      "Zane Fink",
      "Sam White",
      "Nitin Bhat",
      "David F. Richards",
      "Laxmikant V. Kale"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.12416"
  },
  {
    "id": "arXiv:2103.00293",
    "title": "N-Shot Learning for Augmenting Task-Oriented Dialogue State Tracking",
    "abstract": "Comments: Accepted by ACL 2022 Findings",
    "descriptor": "\nComments: Accepted by ACL 2022 Findings\n",
    "authors": [
      "Taha Aksu",
      "Zhengyuan Liu",
      "Min-Yen Kan",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.00293"
  },
  {
    "id": "arXiv:2103.00675",
    "title": "Bayesian filtering for nonlinear stochastic systems using holonomic  gradient method with integral transform",
    "abstract": "Comments: 7 pages, 4 figures, accepted for IEEE Conference on Decision and Control (CDC) 2021, Accepted version",
    "descriptor": "\nComments: 7 pages, 4 figures, accepted for IEEE Conference on Decision and Control (CDC) 2021, Accepted version\n",
    "authors": [
      "Tomoyuki Iori",
      "Toshiyuki Ohtsuka"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Symbolic Computation (cs.SC)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.00675"
  },
  {
    "id": "arXiv:2103.04941",
    "title": "InFillmore: Frame-Guided Language Generation with Bidirectional Context",
    "abstract": "Comments: Appearing in *SEM 2021",
    "descriptor": "\nComments: Appearing in *SEM 2021\n",
    "authors": [
      "Jiefu Ou",
      "Nathaniel Weir",
      "Anton Belyy",
      "Felix Yu",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.04941"
  },
  {
    "id": "arXiv:2103.06372",
    "title": "PANTHER: Perception-Aware Trajectory Planner in Dynamic Environments",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Jesus Tordesillas",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.06372"
  },
  {
    "id": "arXiv:2103.06376",
    "title": "Functional Collection Programming with Semi-Ring Dictionaries",
    "abstract": "Functional Collection Programming with Semi-Ring Dictionaries",
    "descriptor": "",
    "authors": [
      "Amir Shaikhha",
      "Mathieu Huot",
      "Jaclyn Smith",
      "Dan Olteanu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06376"
  },
  {
    "id": "arXiv:2103.10671",
    "title": "Wisecr: Secure Simultaneous Code Disseminationto Many Batteryless  Computational RFID Devices",
    "abstract": "Comments: 19 main pages, 6 Appendix. Under review at IEEE TDSC",
    "descriptor": "\nComments: 19 main pages, 6 Appendix. Under review at IEEE TDSC\n",
    "authors": [
      "Yang Su",
      "Michael Chesser",
      "Yansong Gao",
      "Alanson P. Sample",
      "Damith C. Ranasinghe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.10671"
  },
  {
    "id": "arXiv:2103.13138",
    "title": "SCHeMa: Scheduling Scientific Containers on a Cluster of Heterogeneous  Machines",
    "abstract": "SCHeMa: Scheduling Scientific Containers on a Cluster of Heterogeneous  Machines",
    "descriptor": "",
    "authors": [
      "Thanasis Vergoulis",
      "Konstantinos Zagganas",
      "Loukas Kavouras",
      "Martin Reczko",
      "Stelios Sartzetakis",
      "Theodore Dalamagas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2103.13138"
  },
  {
    "id": "arXiv:2104.04525",
    "title": "Coordinate descent heuristics for the irregular strip packing problem of  rasterized shapes",
    "abstract": "Coordinate descent heuristics for the irregular strip packing problem of  rasterized shapes",
    "descriptor": "",
    "authors": [
      "Shunji Umetani",
      "Shohei Murakami"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.04525"
  },
  {
    "id": "arXiv:2104.06723",
    "title": "Almost all classical theorems are intuitionistic",
    "abstract": "Almost all classical theorems are intuitionistic",
    "descriptor": "",
    "authors": [
      "Pierre Lescanne"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.06723"
  },
  {
    "id": "arXiv:2104.06951",
    "title": "Domain Adaptation and Multi-Domain Adaptation for Neural Machine  Translation: A Survey",
    "abstract": "Comments: 43 pages + references",
    "descriptor": "\nComments: 43 pages + references\n",
    "authors": [
      "Danielle Saunders"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.06951"
  },
  {
    "id": "arXiv:2104.08790",
    "title": "Misinfo Reaction Frames: Reasoning about Readers' Reactions to News  Headlines",
    "abstract": "Comments: ACL 2022 camera-ready",
    "descriptor": "\nComments: ACL 2022 camera-ready\n",
    "authors": [
      "Saadia Gabriel",
      "Skyler Hallinan",
      "Maarten Sap",
      "Pemi Nguyen",
      "Franziska Roesner",
      "Eunsol Choi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08790"
  },
  {
    "id": "arXiv:2104.11079",
    "title": "Randomized Algorithms for Scientific Computing (RASC)",
    "abstract": "Randomized Algorithms for Scientific Computing (RASC)",
    "descriptor": "",
    "authors": [
      "Aydin Buluc",
      "Tamara G. Kolda",
      "Stefan M. Wild",
      "Mihai Anitescu",
      "Anthony DeGennaro",
      "John Jakeman",
      "Chandrika Kamath",
      "Ramakrishnan Kannan",
      "Miles E. Lopes",
      "Per-Gunnar Martinsson",
      "Kary Myers",
      "Jelani Nelson",
      "Juan M. Restrepo",
      "C. Seshadhri",
      "Draguna Vrabie",
      "Brendt Wohlberg",
      "Stephen J. Wright",
      "Chao Yang",
      "Peter Zwart"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2104.11079"
  },
  {
    "id": "arXiv:2104.12576",
    "title": "A Splicing Approach to Best Subset of Groups Selection",
    "abstract": "Comments: 49 pages, 7 figures",
    "descriptor": "\nComments: 49 pages, 7 figures\n",
    "authors": [
      "Yanhang Zhang",
      "Junxian Zhu",
      "Jin Zhu",
      "Xueqin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.12576"
  },
  {
    "id": "arXiv:2104.13450",
    "title": "Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and  Extracting Them from 2D Renderings",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Innfarn Yoo",
      "Huiwen Chang",
      "Xiyang Luo",
      "Ondrej Stava",
      "Ce Liu",
      "Peyman Milanfar",
      "Feng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.13450"
  },
  {
    "id": "arXiv:2104.14445",
    "title": "Trakhtenbrot's Theorem in Coq: Finite Model Theory through the  Constructive Lens",
    "abstract": "Comments: 29 pages, extended version of the IJCAR 2020 paper. arXiv admin note: substantial text overlap with arXiv:2004.07390",
    "descriptor": "\nComments: 29 pages, extended version of the IJCAR 2020 paper. arXiv admin note: substantial text overlap with arXiv:2004.07390\n",
    "authors": [
      "Dominik Kirst",
      "Dominique Larchey-Wendling"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computation and Language (cs.CL)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.14445"
  },
  {
    "id": "arXiv:2105.03842",
    "title": "FastCorrect: Fast Error Correction with Edit Alignment for Automatic  Speech Recognition",
    "abstract": "Comments: NeurIPS 2021. Code URL: this https URL",
    "descriptor": "\nComments: NeurIPS 2021. Code URL: this https URL\n",
    "authors": [
      "Yichong Leng",
      "Xu Tan",
      "Linchen Zhu",
      "Jin Xu",
      "Renqian Luo",
      "Linquan Liu",
      "Tao Qin",
      "Xiang-Yang Li",
      "Ed Lin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.03842"
  },
  {
    "id": "arXiv:2105.05557",
    "title": "Supporting Land Reuse of Former Open Pit Mining Sites using Text  Classification and Active Learning",
    "abstract": "Supporting Land Reuse of Former Open Pit Mining Sites using Text  Classification and Active Learning",
    "descriptor": "",
    "authors": [
      "Christopher Schr\u00f6der",
      "Kim B\u00fcrgl",
      "Yves Annanias",
      "Andreas Niekler",
      "Lydia M\u00fcller",
      "Daniel Wiegreffe",
      "Christian Bender",
      "Christoph Mengs",
      "Gerik Scheuermann",
      "Gerhard Heyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.05557"
  },
  {
    "id": "arXiv:2105.11111",
    "title": "Oriented RepPoints for Aerial Object Detection",
    "abstract": "Comments: 10 pages, 4 figures, Accepted by CVPR2022",
    "descriptor": "\nComments: 10 pages, 4 figures, Accepted by CVPR2022\n",
    "authors": [
      "Wentong Li",
      "Yijie Chen",
      "Kaixuan Hu",
      "Jianke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11111"
  },
  {
    "id": "arXiv:2105.15093",
    "title": "Pho(SC)-CTC -- A Hybrid Approach Towards Zero-shot Word Image  Recognition",
    "abstract": "Comments: Under Review (International Journal on Document Analysis and Recognition). This paper is the extension of the paper titled \"Pho(SC)Net: An Approach Towards Zero-shot Word Image Recognition in Historical Documents\" published in ICDAR 2021",
    "descriptor": "\nComments: Under Review (International Journal on Document Analysis and Recognition). This paper is the extension of the paper titled \"Pho(SC)Net: An Approach Towards Zero-shot Word Image Recognition in Historical Documents\" published in ICDAR 2021\n",
    "authors": [
      "Ravi Bhatt",
      "Anuj Rai",
      "Narayanan C. Krishnan",
      "Sukalpa Chanda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.15093"
  },
  {
    "id": "arXiv:2106.05113",
    "title": "More Than Meets the Eye: Self-Supervised Depth Reconstruction From Brain  Activity",
    "abstract": "Comments: Code: this https URL",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Guy Gaziv",
      "Michal Irani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.05113"
  },
  {
    "id": "arXiv:2106.05470",
    "title": "Automated Self-Supervised Learning for Graphs",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Wei Jin",
      "Xiaorui Liu",
      "Xiangyu Zhao",
      "Yao Ma",
      "Neil Shah",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05470"
  },
  {
    "id": "arXiv:2106.08895",
    "title": "Masked Training of Neural Networks with Partial Gradients",
    "abstract": "Comments: Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS) 2022",
    "descriptor": "\nComments: Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS) 2022\n",
    "authors": [
      "Amirkeivan Mohtashami",
      "Martin Jaggi",
      "Sebastian U. Stich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08895"
  },
  {
    "id": "arXiv:2106.09563",
    "title": "On Anytime Learning at Macroscale",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Lucas Caccia",
      "Jing Xu",
      "Myle Ott",
      "Marc'Aurelio Ranzato",
      "Ludovic Denoyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09563"
  },
  {
    "id": "arXiv:2106.16163",
    "title": "The MultiBERTs: BERT Reproductions for Robustness Analysis",
    "abstract": "Comments: Accepted at ICLR'22. Checkpoints and example analyses: this http URL",
    "descriptor": "\nComments: Accepted at ICLR'22. Checkpoints and example analyses: this http URL\n",
    "authors": [
      "Thibault Sellam",
      "Steve Yadlowsky",
      "Jason Wei",
      "Naomi Saphra",
      "Alexander D'Amour",
      "Tal Linzen",
      "Jasmijn Bastings",
      "Iulia Turc",
      "Jacob Eisenstein",
      "Dipanjan Das",
      "Ian Tenney",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.16163"
  },
  {
    "id": "arXiv:2107.00327",
    "title": "Orthonormal Product Quantization Network for Scalable Face Image  Retrieval",
    "abstract": "Orthonormal Product Quantization Network for Scalable Face Image  Retrieval",
    "descriptor": "",
    "authors": [
      "Ming Zhang",
      "Xuefei Zhe",
      "Hong Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00327"
  },
  {
    "id": "arXiv:2107.02168",
    "title": "DPPIN: A Biological Repository of Dynamic Protein-Protein Interaction  Network Data",
    "abstract": "DPPIN: A Biological Repository of Dynamic Protein-Protein Interaction  Network Data",
    "descriptor": "",
    "authors": [
      "Dongqi Fu",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02168"
  },
  {
    "id": "arXiv:2107.04631",
    "title": "Ill-posed Surface Emissivity Retrieval from Multi-Geometry Hyperspectral  Images using a Hybrid Deep Neural Network",
    "abstract": "Ill-posed Surface Emissivity Retrieval from Multi-Geometry Hyperspectral  Images using a Hybrid Deep Neural Network",
    "descriptor": "",
    "authors": [
      "Fangcao Xu",
      "Jian Sun",
      "Guido Cervone",
      "Mark Salvador"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04631"
  },
  {
    "id": "arXiv:2107.05604",
    "title": "Direct speech-to-speech translation with discrete units",
    "abstract": "Comments: Accepted to ACL 2022 (long paper)",
    "descriptor": "\nComments: Accepted to ACL 2022 (long paper)\n",
    "authors": [
      "Ann Lee",
      "Peng-Jen Chen",
      "Changhan Wang",
      "Jiatao Gu",
      "Sravya Popuri",
      "Xutai Ma",
      "Adam Polyak",
      "Yossi Adi",
      "Qing He",
      "Yun Tang",
      "Juan Pino",
      "Wei-Ning Hsu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.05604"
  },
  {
    "id": "arXiv:2107.09783",
    "title": "Unsupervised Domain Adaptation in LiDAR Semantic Segmentation with  Self-Supervision and Gated Adapters",
    "abstract": "Comments: Accepted to the 2022 IEEE International Conference on Robotics and Automation (ICRA)",
    "descriptor": "\nComments: Accepted to the 2022 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Mrigank Rochan",
      "Shubhra Aich",
      "Eduardo R. Corral-Soto",
      "Amir Nabatchian",
      "Bingbing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.09783"
  },
  {
    "id": "arXiv:2107.11126",
    "title": "Combining the hybrid mimetic mixed method with the Scharfetter-Gummel  scheme for magnetised transport in plasmas",
    "abstract": "Combining the hybrid mimetic mixed method with the Scharfetter-Gummel  scheme for magnetised transport in plasmas",
    "descriptor": "",
    "authors": [
      "Hanz Martin Cheng",
      "Jan ten thije Boonkkamp",
      "Jesper Janssen",
      "Diana Mihailova",
      "Jan van Dijk"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.11126"
  },
  {
    "id": "arXiv:2107.11623",
    "title": "On relating one-way classical and quantum communication complexities",
    "abstract": "On relating one-way classical and quantum communication complexities",
    "descriptor": "",
    "authors": [
      "Naresh Goud Boddu",
      "Rahul Jain",
      "Han-Hsuan Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.11623"
  },
  {
    "id": "arXiv:2107.13242",
    "title": "Type theories in category theory",
    "abstract": "Comments: 45 pages",
    "descriptor": "\nComments: 45 pages\n",
    "authors": [
      "Tesla Zhang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.13242"
  },
  {
    "id": "arXiv:2108.02281",
    "title": "Context-Aware Environment Monitoring to Support LPWAN-based Battlefield  Applications",
    "abstract": "Context-Aware Environment Monitoring to Support LPWAN-based Battlefield  Applications",
    "descriptor": "",
    "authors": [
      "Guilherme Rotth Zibetti",
      "Juliano Araujo Wickboldt",
      "Edison Pignaton de Freitas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.02281"
  },
  {
    "id": "arXiv:2108.03718",
    "title": "Meta-Reinforcement Learning in Broad and Non-Parametric Environments",
    "abstract": "Meta-Reinforcement Learning in Broad and Non-Parametric Environments",
    "descriptor": "",
    "authors": [
      "Zhenshan Bing",
      "Lukas Knak",
      "Fabrice Oliver Robin",
      "Kai Huang",
      "Alois Knoll"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.03718"
  },
  {
    "id": "arXiv:2108.07917",
    "title": "Classification of Abnormal Hand Movement for Aiding in Autism Detection:  Machine Learning Study",
    "abstract": "Classification of Abnormal Hand Movement for Aiding in Autism Detection:  Machine Learning Study",
    "descriptor": "",
    "authors": [
      "Anish Lakkapragada",
      "Aaron Kline",
      "Onur Cezmi Mutlu",
      "Kelley Paskov",
      "Brianna Chrisman",
      "Nate Stockham",
      "Peter Washington",
      "Dennis Wall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.07917"
  },
  {
    "id": "arXiv:2108.11853",
    "title": "Lower bounds for integration and recovery in $L_2$",
    "abstract": "Lower bounds for integration and recovery in $L_2$",
    "descriptor": "",
    "authors": [
      "Aicke Hinrichs",
      "David Krieg",
      "Erich Novak",
      "Jan Vybiral"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.11853"
  },
  {
    "id": "arXiv:2109.01886",
    "title": "A well conditioned Method of Fundamental Solutions",
    "abstract": "A well conditioned Method of Fundamental Solutions",
    "descriptor": "",
    "authors": [
      "Pedro R. S. Antunes"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.01886"
  },
  {
    "id": "arXiv:2109.02748",
    "title": "Zero-Shot Out-of-Distribution Detection Based on the Pre-trained Model  CLIP",
    "abstract": "Zero-Shot Out-of-Distribution Detection Based on the Pre-trained Model  CLIP",
    "descriptor": "",
    "authors": [
      "Sepideh Esmaeilpour",
      "Bing Liu",
      "Eric Robertson",
      "Lei Shu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02748"
  },
  {
    "id": "arXiv:2109.03698",
    "title": "Towards Symbolic Pointers Reasoning in Dynamic Symbolic Execution",
    "abstract": "Towards Symbolic Pointers Reasoning in Dynamic Symbolic Execution",
    "descriptor": "",
    "authors": [
      "Daniil Kuts"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.03698"
  },
  {
    "id": "arXiv:2109.07143",
    "title": "Spline-PINN: Approaching PDEs without Data using Fast, Physics-Informed  Hermite-Spline CNNs",
    "abstract": "Comments: AAAI 2022 (Main Track)",
    "descriptor": "\nComments: AAAI 2022 (Main Track)\n",
    "authors": [
      "Nils Wandel",
      "Michael Weinmann",
      "Michael Neidlin",
      "Reinhard Klein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2109.07143"
  },
  {
    "id": "arXiv:2109.07368",
    "title": "Learning When to Translate for Streaming Speech",
    "abstract": "Comments: Accept to ACL 2022 main conference. 15 pages, 6 figures",
    "descriptor": "\nComments: Accept to ACL 2022 main conference. 15 pages, 6 figures\n",
    "authors": [
      "Qianqian Dong",
      "Yaoming Zhu",
      "Mingxuan Wang",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.07368"
  },
  {
    "id": "arXiv:2109.07931",
    "title": "DDS: A new device-degraded speech dataset for speech enhancement",
    "abstract": "Comments: Submitted to Interspeech 2022",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Haoyu Li",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.07931"
  },
  {
    "id": "arXiv:2109.09587",
    "title": "Recommender systems based on graph embedding techniques: A comprehensive  review",
    "abstract": "Recommender systems based on graph embedding techniques: A comprehensive  review",
    "descriptor": "",
    "authors": [
      "Yue Deng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.09587"
  },
  {
    "id": "arXiv:2109.09974",
    "title": "Adaptive Control of SE(3) Hamiltonian Dynamics with Learned Disturbance  Features",
    "abstract": "Comments: Project website: this https URL",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Thai Duong",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.09974"
  },
  {
    "id": "arXiv:2109.10274",
    "title": "The Trade-offs of Domain Adaptation for Neural Language Models",
    "abstract": "Comments: Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), 2022",
    "descriptor": "\nComments: Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), 2022\n",
    "authors": [
      "David Grangier",
      "Dan Iter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.10274"
  },
  {
    "id": "arXiv:2109.11694",
    "title": "Component-by-component construction of randomized rank-1 lattice rules  achieving almost the optimal randomized error rate",
    "abstract": "Comments: major revision, 29 pages, 3 figures",
    "descriptor": "\nComments: major revision, 29 pages, 3 figures\n",
    "authors": [
      "Josef Dick",
      "Takashi Goda",
      "Kosuke Suzuki"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.11694"
  },
  {
    "id": "arXiv:2109.12564",
    "title": "Vision Transformer Hashing for Image Retrieval",
    "abstract": "Comments: Accepted in IEEE International Conference on Multimedia and Expo (ICME), 2022",
    "descriptor": "\nComments: Accepted in IEEE International Conference on Multimedia and Expo (ICME), 2022\n",
    "authors": [
      "Shiv Ram Dubey",
      "Satish Kumar Singh",
      "Wei-Ta Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12564"
  },
  {
    "id": "arXiv:2109.13101",
    "title": "Half a Dozen Real-World Applications of Evolutionary Multitasking, and  More",
    "abstract": "Half a Dozen Real-World Applications of Evolutionary Multitasking, and  More",
    "descriptor": "",
    "authors": [
      "Abhishek Gupta",
      "Lei Zhou",
      "Yew-Soon Ong",
      "Zefeng Chen",
      "Yaqing Hou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2109.13101"
  },
  {
    "id": "arXiv:2110.00667",
    "title": "Data-Driven Detection and Identification of IoT-Enabled Load-Altering  Attacks in Power Grids",
    "abstract": "Data-Driven Detection and Identification of IoT-Enabled Load-Altering  Attacks in Power Grids",
    "descriptor": "",
    "authors": [
      "Subhash Lakshminarayana",
      "Saurav Sthapit",
      "Hamidreza Jahangir",
      "Carsten Maple",
      "H Vincent Poor"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.00667"
  },
  {
    "id": "arXiv:2110.04655",
    "title": "Disentangled Sequence to Sequence Learning for Compositional  Generalization",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Hao Zheng",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04655"
  },
  {
    "id": "arXiv:2110.05734",
    "title": "Learning Efficient Multi-Agent Cooperative Visual Exploration",
    "abstract": "Comments: First three authors share equal contribution",
    "descriptor": "\nComments: First three authors share equal contribution\n",
    "authors": [
      "Chao Yu",
      "Xinyi Yang",
      "Jiaxuan Gao",
      "Huazhong Yang",
      "Yu Wang",
      "Yi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05734"
  },
  {
    "id": "arXiv:2110.05894",
    "title": "Numerical analysis of 2D Navier--Stokes equations with additive  stochastic forcing",
    "abstract": "Numerical analysis of 2D Navier--Stokes equations with additive  stochastic forcing",
    "descriptor": "",
    "authors": [
      "Dominic Breit",
      "Andreas Prohl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.05894"
  },
  {
    "id": "arXiv:2110.06363",
    "title": "A Side-channel Analysis of Sensor Multiplexing for Covert Channels and  Application Fingerprinting on Mobile Devices",
    "abstract": "A Side-channel Analysis of Sensor Multiplexing for Covert Channels and  Application Fingerprinting on Mobile Devices",
    "descriptor": "",
    "authors": [
      "Carlton Shepherd",
      "Jan Kalbantner",
      "Benjamin Semal",
      "Konstantinos Markantonakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.06363"
  },
  {
    "id": "arXiv:2110.07476",
    "title": "Query and Extract: Refining Event Extraction as Type-oriented Binary  Decoding",
    "abstract": "Comments: 14pages, ACL'2022",
    "descriptor": "\nComments: 14pages, ACL'2022\n",
    "authors": [
      "Sijia Wang",
      "Mo Yu",
      "Shiyu Chang",
      "Lichao Sun",
      "Lifu Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.07476"
  },
  {
    "id": "arXiv:2110.07580",
    "title": "Graph Condensation for Graph Neural Networks",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Wei Jin",
      "Lingxiao Zhao",
      "Shichang Zhang",
      "Yozen Liu",
      "Jiliang Tang",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.07580"
  },
  {
    "id": "arXiv:2110.08173",
    "title": "Rewire-then-Probe: A Contrastive Recipe for Probing Biomedical Knowledge  of Pre-trained Language Models",
    "abstract": "Comments: ACL 2022; code and data are released at this https URL",
    "descriptor": "\nComments: ACL 2022; code and data are released at this https URL\n",
    "authors": [
      "Zaiqiao Meng",
      "Fangyu Liu",
      "Ehsan Shareghi",
      "Yixuan Su",
      "Charlotte Collins",
      "Nigel Collier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08173"
  },
  {
    "id": "arXiv:2110.10221",
    "title": "The CoRa Tensor Compiler: Compilation for Ragged Tensors with Minimal  Padding",
    "abstract": "Comments: 23 pages, 25 figures and 10 tables",
    "descriptor": "\nComments: 23 pages, 25 figures and 10 tables\n",
    "authors": [
      "Pratik Fegade",
      "Tianqi Chen",
      "Phillip B. Gibbons",
      "Todd C. Mowry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10221"
  },
  {
    "id": "arXiv:2110.10780",
    "title": "An Open Natural Language Processing Development Framework for EHR-based  Clinical Research: A case demonstration using the National COVID Cohort  Collaborative (N3C)",
    "abstract": "Comments: update on contents",
    "descriptor": "\nComments: update on contents\n",
    "authors": [
      "Sijia Liu",
      "Andrew Wen",
      "Liwei Wang",
      "Huan He",
      "Sunyang Fu",
      "Robert Miller",
      "Andrew Williams",
      "Daniel Harris",
      "Ramakanth Kavuluru",
      "Mei Liu",
      "Noor Abu-el-rub",
      "Dalton Schutte",
      "Rui Zhang",
      "Masoud Rouhizadeh",
      "John D. Osborne",
      "Yongqun He",
      "Umit Topaloglu",
      "Stephanie S Hong",
      "Joel H Saltz",
      "Thomas Schaffter",
      "Emily Pfaff",
      "Christopher G. Chute",
      "Tim Duong",
      "Melissa A. Haendel",
      "Rafael Fuentes",
      "Peter Szolovits",
      "Hua Xu",
      "Hongfang Liu",
      "National COVID Cohort Collaborative",
      "Natural Language Processing",
      "Subgroup",
      "National COVID Cohort Collaborative"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.10780"
  },
  {
    "id": "arXiv:2110.12576",
    "title": "Maximizing the Smallest Eigenvalue of Grounded Laplacian Matrix",
    "abstract": "Maximizing the Smallest Eigenvalue of Grounded Laplacian Matrix",
    "descriptor": "",
    "authors": [
      "Run Wang",
      "Xiaotian Zhou",
      "Wei Li",
      "Zhongzhi Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.12576"
  },
  {
    "id": "arXiv:2110.14747",
    "title": "Dynamic Review-based Recommenders",
    "abstract": "Comments: 6pages, Published at International Data Science Conference 2021 (iDSC21)",
    "descriptor": "\nComments: 6pages, Published at International Data Science Conference 2021 (iDSC21)\n",
    "authors": [
      "Kostadin Cvejoski",
      "Ramses J. Sanchez",
      "Christian Bauckhage",
      "Cesar Ojeda"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14747"
  },
  {
    "id": "arXiv:2110.15032",
    "title": "OneFlow: Redesign the Distributed Deep Learning Framework from Scratch",
    "abstract": "OneFlow: Redesign the Distributed Deep Learning Framework from Scratch",
    "descriptor": "",
    "authors": [
      "Jinhui Yuan",
      "Xinqi Li",
      "Cheng Cheng",
      "Juncheng Liu",
      "Ran Guo",
      "Shenghang Cai",
      "Chi Yao",
      "Fei Yang",
      "Xiaodong Yi",
      "Chuan Wu",
      "Haoran Zhang",
      "Jie Zhao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15032"
  },
  {
    "id": "arXiv:2111.02038",
    "title": "Fair-SSL: Building fair ML Software with less data",
    "abstract": "Fair-SSL: Building fair ML Software with less data",
    "descriptor": "",
    "authors": [
      "Joymallya Chakraborty",
      "Suvodeep Majumder",
      "Huy Tu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02038"
  },
  {
    "id": "arXiv:2111.03512",
    "title": "Data Selection for Efficient Model Update in Federated Learning",
    "abstract": "Data Selection for Efficient Model Update in Federated Learning",
    "descriptor": "",
    "authors": [
      "Hongrui Shi",
      "Valentin Radu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03512"
  },
  {
    "id": "arXiv:2111.03971",
    "title": "Towards noise robust trigger-word detection with contrastive learning  pre-task for fast on-boarding of new trigger-words",
    "abstract": "Comments: submitted to INTERSPEECH",
    "descriptor": "\nComments: submitted to INTERSPEECH\n",
    "authors": [
      "Sivakumar Balasubramanian",
      "Aditya Jajodia",
      "Gowtham Srinivasan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.03971"
  },
  {
    "id": "arXiv:2111.04060",
    "title": "Are we ready for a new paradigm shift? A Survey on Visual Deep MLP",
    "abstract": "Comments: With the development of MLP, the survey has been updated to the latest version in March",
    "descriptor": "\nComments: With the development of MLP, the survey has been updated to the latest version in March\n",
    "authors": [
      "Ruiyang Liu",
      "Yinghui Li",
      "Linmi Tao",
      "Dun Liang",
      "Shi-Min Hu",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.04060"
  },
  {
    "id": "arXiv:2111.04739",
    "title": "DR-VNet: Retinal Vessel Segmentation via Dense Residual UNet",
    "abstract": "Comments: Accepted to ICPRAI 2022 - 3rd International Conference on Pattern Recognition and Artificial Intelligence",
    "descriptor": "\nComments: Accepted to ICPRAI 2022 - 3rd International Conference on Pattern Recognition and Artificial Intelligence\n",
    "authors": [
      "Ali Karaali",
      "Rozenn Dahyot",
      "Donal J. Sexton"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.04739"
  },
  {
    "id": "arXiv:2111.04857",
    "title": "Model-assisted deep learning of rare extreme events from partial  observations",
    "abstract": "Comments: Accepted for publication in Chaos: An Interdisciplinary Journal of Nonlinear Science",
    "descriptor": "\nComments: Accepted for publication in Chaos: An Interdisciplinary Journal of Nonlinear Science\n",
    "authors": [
      "Anna Asch",
      "Ethan Brady",
      "Hugo Gallardo",
      "John Hood",
      "Bryan Chu",
      "Mohammad Farazmand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2111.04857"
  },
  {
    "id": "arXiv:2111.05770",
    "title": "Symbolic Security Predicates: Hunt Program Weaknesses",
    "abstract": "Symbolic Security Predicates: Hunt Program Weaknesses",
    "descriptor": "",
    "authors": [
      "Alexey Vishnyakov",
      "Vlada Logunova",
      "Eli Kobrin",
      "Daniil Kuts",
      "Darya Parygina",
      "Andrey Fedotov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.05770"
  },
  {
    "id": "arXiv:2111.05781",
    "title": "MAJORCA: Multi-Architecture JOP and ROP Chain Assembler",
    "abstract": "MAJORCA: Multi-Architecture JOP and ROP Chain Assembler",
    "descriptor": "",
    "authors": [
      "Alexey Nurmukhametov",
      "Alexey Vishnyakov",
      "Vlada Logunova",
      "Shamil Kurmangaleev"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.05781"
  },
  {
    "id": "arXiv:2111.06006",
    "title": "ConTesse: Accurate Occluding Contours for Smooth Surfaces",
    "abstract": "ConTesse: Accurate Occluding Contours for Smooth Surfaces",
    "descriptor": "",
    "authors": [
      "Chenxi Liu",
      "Pierre B\u00e9nard",
      "Aaron Hertzmann",
      "Shayan Hoshyari"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2111.06006"
  },
  {
    "id": "arXiv:2111.06967",
    "title": "On the complexity of SAT",
    "abstract": "On the complexity of SAT",
    "descriptor": "",
    "authors": [
      "Fabio Romano"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.06967"
  },
  {
    "id": "arXiv:2111.07513",
    "title": "A Comparative Study on Basic Elements of Deep Learning Models for  Spatial-Temporal Traffic Forecasting",
    "abstract": "Comments: 14 pages, 4 figures, 3 Tables, This paper is accepted for AAAI-22 Workshop: AI for Transportation",
    "descriptor": "\nComments: 14 pages, 4 figures, 3 Tables, This paper is accepted for AAAI-22 Workshop: AI for Transportation\n",
    "authors": [
      "Yuyol Shin",
      "Yoonjin Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.07513"
  },
  {
    "id": "arXiv:2111.08524",
    "title": "Non-separable Spatio-temporal Graph Kernels via SPDEs",
    "abstract": "Non-separable Spatio-temporal Graph Kernels via SPDEs",
    "descriptor": "",
    "authors": [
      "Alexander Nikitin",
      "ST John",
      "Arno Solin",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08524"
  },
  {
    "id": "arXiv:2111.08918",
    "title": "Local Texture Estimator for Implicit Representation Function",
    "abstract": "Comments: CVPR 2022 camera-ready version",
    "descriptor": "\nComments: CVPR 2022 camera-ready version\n",
    "authors": [
      "Jaewon Lee",
      "Kyong Hwan Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.08918"
  },
  {
    "id": "arXiv:2111.09383",
    "title": "DeepCurrents: Learning Implicit Representations of Shapes with  Boundaries",
    "abstract": "DeepCurrents: Learning Implicit Representations of Shapes with  Boundaries",
    "descriptor": "",
    "authors": [
      "David Palmer",
      "Dmitriy Smirnov",
      "Stephanie Wang",
      "Albert Chern",
      "Justin Solomon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.09383"
  },
  {
    "id": "arXiv:2111.10502",
    "title": "CamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and  Scene Flow Estimation",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Haisong Liu",
      "Tao Lu",
      "Yihui Xu",
      "Jia Liu",
      "Wenjie Li",
      "Lijun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10502"
  },
  {
    "id": "arXiv:2111.11176",
    "title": "Arithmetic Autocorrelation of Binary $m$-Sequences",
    "abstract": "Arithmetic Autocorrelation of Binary $m$-Sequences",
    "descriptor": "",
    "authors": [
      "Zhixiong Chen",
      "Zhihua Niu",
      "Yuqi Sang",
      "Chenhuang Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.11176"
  },
  {
    "id": "arXiv:2111.12229",
    "title": "Subspace Adversarial Training",
    "abstract": "Comments: CVPR2022",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Tao Li",
      "Yingwen Wu",
      "Sizhe Chen",
      "Kun Fang",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12229"
  },
  {
    "id": "arXiv:2111.12448",
    "title": "3D Shape Variational Autoencoder Latent Disentanglement via Mini-Batch  Feature Swapping for Bodies and Faces",
    "abstract": "Comments: Accepted for publication at CVPR2022",
    "descriptor": "\nComments: Accepted for publication at CVPR2022\n",
    "authors": [
      "Simone Foti",
      "Bongjin Koo",
      "Danail Stoyanov",
      "Matthew J. Clarkson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12448"
  },
  {
    "id": "arXiv:2111.12531",
    "title": "Non-Intrusive Binaural Speech Intelligibility Prediction from Discrete  Latent Representations",
    "abstract": "Comments: 4 pages + 1 refs; 1 figure; accepted at IEEE SPL (to appear)",
    "descriptor": "\nComments: 4 pages + 1 refs; 1 figure; accepted at IEEE SPL (to appear)\n",
    "authors": [
      "Alex F. McKinney",
      "Benjamin Cauchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.12531"
  },
  {
    "id": "arXiv:2111.12918",
    "title": "ACPL: Anti-curriculum Pseudo-labelling for Semi-supervised Medical Image  Classification",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Fengbei Liu",
      "Yu Tian",
      "Yuanhong Chen",
      "Yuyuan Liu",
      "Vasileios Belagiannis",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12918"
  },
  {
    "id": "arXiv:2111.13280",
    "title": "Efficient Self-Ensemble for Semantic Segmentation",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Walid Bousselham",
      "Guillaume Thibault",
      "Lucas Pagano",
      "Archana Machireddy",
      "Joe Gray",
      "Young Hwan Chang",
      "Xubo Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13280"
  },
  {
    "id": "arXiv:2111.13372",
    "title": "A deep learning based reduced order modeling for stochastic underground  flow problems",
    "abstract": "Comments: There are some mistakes as well as typos in the paper. Correction is needed",
    "descriptor": "\nComments: There are some mistakes as well as typos in the paper. Correction is needed\n",
    "authors": [
      "Yiran Wang",
      "Eric Chung",
      "Shubin Fu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.13372"
  },
  {
    "id": "arXiv:2111.13410",
    "title": "Modeling Annotator Preference and Stochastic Annotation Error for  Medical Image Segmentation",
    "abstract": "Modeling Annotator Preference and Stochastic Annotation Error for  Medical Image Segmentation",
    "descriptor": "",
    "authors": [
      "Zehui Liao",
      "Shishuai Hu",
      "Yutong Xie",
      "Yong Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13410"
  },
  {
    "id": "arXiv:2111.14358",
    "title": "IDR: Self-Supervised Image Denoising via Iterative Data Refinement",
    "abstract": "Comments: CVPR2022; code & dataset: this https URL",
    "descriptor": "\nComments: CVPR2022; code & dataset: this https URL\n",
    "authors": [
      "Yi Zhang",
      "Dasong Li",
      "Ka Lung Law",
      "Xiaogang Wang",
      "Hongwei Qin",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14358"
  },
  {
    "id": "arXiv:2112.00124",
    "title": "CryoCiM: Cryogenic Compute-in-Memory based on the Quantum Anomalous Hall  Effect",
    "abstract": "Comments: 13 pages, 6figures",
    "descriptor": "\nComments: 13 pages, 6figures\n",
    "authors": [
      "Shamiul Alam",
      "Md Mazharul Islam",
      "Md Shafayat Hossain",
      "Akhilesh Jaiswal",
      "Ahmedullah Aziz"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2112.00124"
  },
  {
    "id": "arXiv:2112.00597",
    "title": "Wish you were here: Hindsight Goal Selection for long-horizon dexterous  manipulation",
    "abstract": "Wish you were here: Hindsight Goal Selection for long-horizon dexterous  manipulation",
    "descriptor": "",
    "authors": [
      "Todor Davchev",
      "Oleg Sushkov",
      "Jean-Baptiste Regli",
      "Stefan Schaal",
      "Yusuf Aytar",
      "Markus Wulfmeier",
      "Jon Scholz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00597"
  },
  {
    "id": "arXiv:2112.01811",
    "title": "Multiscale simulation of injection-induced fracture slip and wing-crack  propagation in poroelastic media",
    "abstract": "Multiscale simulation of injection-induced fracture slip and wing-crack  propagation in poroelastic media",
    "descriptor": "",
    "authors": [
      "Hau Trung Dang",
      "Inga Berre",
      "Eirik Keilegavlen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.01811"
  },
  {
    "id": "arXiv:2112.02857",
    "title": "PTTR: Relational 3D Point Cloud Object Tracking with Transformer",
    "abstract": "PTTR: Relational 3D Point Cloud Object Tracking with Transformer",
    "descriptor": "",
    "authors": [
      "Changqing Zhou",
      "Zhipeng Luo",
      "Yueru Luo",
      "Tianrui Liu",
      "Liang Pan",
      "Zhongang Cai",
      "Haiyu Zhao",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02857"
  },
  {
    "id": "arXiv:2112.03596",
    "title": "E$^2$(GO)MOTION: Motion Augmented Event Stream for Egocentric Action  Recognition",
    "abstract": "Comments: Accepted at CVPR2022",
    "descriptor": "\nComments: Accepted at CVPR2022\n",
    "authors": [
      "Chiara Plizzari",
      "Mirco Planamente",
      "Gabriele Goletto",
      "Marco Cannici",
      "Emanuele Gusso",
      "Matteo Matteucci",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03596"
  },
  {
    "id": "arXiv:2112.04571",
    "title": "Ambiguous Dynamic Treatment Regimes: A Reinforcement Learning Approach",
    "abstract": "Ambiguous Dynamic Treatment Regimes: A Reinforcement Learning Approach",
    "descriptor": "",
    "authors": [
      "Soroush Saghafian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04571"
  },
  {
    "id": "arXiv:2112.05363",
    "title": "Mean-Square Stability and Stabilizability Analyses of LTI Systems Under  Spatially Correlated Multiplicative Perturbations",
    "abstract": "Mean-Square Stability and Stabilizability Analyses of LTI Systems Under  Spatially Correlated Multiplicative Perturbations",
    "descriptor": "",
    "authors": [
      "Jianqi Chen",
      "Tian Qi",
      "Jie Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.05363"
  },
  {
    "id": "arXiv:2112.06398",
    "title": "Shaping Visual Representations with Attributes for Few-Shot Learning",
    "abstract": "Shaping Visual Representations with Attributes for Few-Shot Learning",
    "descriptor": "",
    "authors": [
      "Haoxing Chen",
      "Huaxiong Li",
      "Yaohui Li",
      "Chunlin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06398"
  },
  {
    "id": "arXiv:2112.06781",
    "title": "Gromov Hyperbolicity, Geodesic Defect, and Apparent Pairs in  Vietoris-Rips Filtrations",
    "abstract": "Comments: 18 pages. Extended version of SoCG 2022 paper",
    "descriptor": "\nComments: 18 pages. Extended version of SoCG 2022 paper\n",
    "authors": [
      "Ulrich Bauer",
      "Fabian Roll"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.06781"
  },
  {
    "id": "arXiv:2112.08654",
    "title": "Learning to Prompt for Continual Learning",
    "abstract": "Comments: Published at CVPR 2022 as a conference paper",
    "descriptor": "\nComments: Published at CVPR 2022 as a conference paper\n",
    "authors": [
      "Zifeng Wang",
      "Zizhao Zhang",
      "Chen-Yu Lee",
      "Han Zhang",
      "Ruoxi Sun",
      "Xiaoqi Ren",
      "Guolong Su",
      "Vincent Perot",
      "Jennifer Dy",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08654"
  },
  {
    "id": "arXiv:2112.08812",
    "title": "Ditch the Gold Standard: Re-evaluating Conversational Question Answering",
    "abstract": "Comments: Accepted to ACL 2022; The dataset and code are available at this https URL",
    "descriptor": "\nComments: Accepted to ACL 2022; The dataset and code are available at this https URL\n",
    "authors": [
      "Huihan Li",
      "Tianyu Gao",
      "Manan Goenka",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08812"
  },
  {
    "id": "arXiv:2112.10354",
    "title": "Systematic Literature Review on Cyber Situational Awareness  Visualizations",
    "abstract": "Systematic Literature Review on Cyber Situational Awareness  Visualizations",
    "descriptor": "",
    "authors": [
      "Liuyue Jiang",
      "Asangi Jayatilaka",
      "Mehwish Nasim",
      "Marthie Grobler",
      "Mansooreh Zahedi",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.10354"
  },
  {
    "id": "arXiv:2112.11848",
    "title": "A Large-Scale Characterization of How Readers Browse Wikipedia",
    "abstract": "Comments: Single column - second revision",
    "descriptor": "\nComments: Single column - second revision\n",
    "authors": [
      "Tiziano Piccardi",
      "Martin Gerlach",
      "Akhil Arora",
      "Robert West"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.11848"
  },
  {
    "id": "arXiv:2112.12165",
    "title": "The Universal $\\ell^p$-Metric on Merge Trees",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Robert Cardona",
      "Justin Curry",
      "Tung Lam",
      "Michael Lesnick"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2112.12165"
  },
  {
    "id": "arXiv:2112.13181",
    "title": "DeepMTL Pro: Deep Learning Based MultipleTransmitter Localization and  Power Estimation",
    "abstract": "Comments: 38 pages, 27 figures. This is the final revision verison of a journal paper submitted to Pervasive and Mobile Computing (PMC). This is an extension of an accepted paper at IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM 2021)",
    "descriptor": "\nComments: 38 pages, 27 figures. This is the final revision verison of a journal paper submitted to Pervasive and Mobile Computing (PMC). This is an extension of an accepted paper at IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM 2021)\n",
    "authors": [
      "Caitao Zhan",
      "Mohammad Ghaderibaneh",
      "Pranjal Sahu",
      "Himanshu Gupta"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.13181"
  },
  {
    "id": "arXiv:2112.14012",
    "title": "Solving time dependent Fokker-Planck equations via temporal normalizing  flow",
    "abstract": "Comments: 16pages",
    "descriptor": "\nComments: 16pages\n",
    "authors": [
      "Xiaodong Feng",
      "Li Zeng",
      "Tao Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14012"
  },
  {
    "id": "arXiv:2201.02275",
    "title": "Well-Conditioned Linear Minimum Mean Square Error Estimation",
    "abstract": "Well-Conditioned Linear Minimum Mean Square Error Estimation",
    "descriptor": "",
    "authors": [
      "Edwin K. P. Chong"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.02275"
  },
  {
    "id": "arXiv:2201.04654",
    "title": "Towards Real-Time Monitoring and Control of Water Networks",
    "abstract": "Comments: Accepted for publication at the 2022 American Control Conference (ACC), Atlanta, GA, 2022",
    "descriptor": "\nComments: Accepted for publication at the 2022 American Control Conference (ACC), Atlanta, GA, 2022\n",
    "authors": [
      "Ahmed Elkhashap",
      "Daniel R\u00fcschen",
      "Dirk Abel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.04654"
  },
  {
    "id": "arXiv:2201.05451",
    "title": "A causal model of safety assurance for machine learning",
    "abstract": "A causal model of safety assurance for machine learning",
    "descriptor": "",
    "authors": [
      "Simon Burton"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.05451"
  },
  {
    "id": "arXiv:2201.06971",
    "title": "Identification for Accountability vs Privacy",
    "abstract": "Comments: 4 pages plus appendix, 9 pages total",
    "descriptor": "\nComments: 4 pages plus appendix, 9 pages total\n",
    "authors": [
      "Nick Pope",
      "Geoffrey Goodell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.06971"
  },
  {
    "id": "arXiv:2201.07462",
    "title": "Leaving Your Things Unattended is No Joke! Memory Bus Snooping and Open  Debug Interface Exploits",
    "abstract": "Comments: Published in IEEE PerCom Workshops 2022,978-1-6654-1647-4/22/$31.00 pp.643-648 Copyright 2022 IEEE",
    "descriptor": "\nComments: Published in IEEE PerCom Workshops 2022,978-1-6654-1647-4/22/$31.00 pp.643-648 Copyright 2022 IEEE\n",
    "authors": [
      "Yang Su",
      "Damith C.Ranasinghe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.07462"
  },
  {
    "id": "arXiv:2201.09447",
    "title": "Prescribed-Time Safety Design for a Chain of Integrators",
    "abstract": "Comments: Paper length shrunk to 6 pages to meet American Control Conference page limit restrictions",
    "descriptor": "\nComments: Paper length shrunk to 6 pages to meet American Control Conference page limit restrictions\n",
    "authors": [
      "Imoleayo Abel",
      "Drew Steeves",
      "Miroslav Krstic",
      "Mrdjan Jankovic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.09447"
  },
  {
    "id": "arXiv:2201.11627",
    "title": "Internal language model estimation through explicit context vector  learning for attention-based encoder-decoder ASR",
    "abstract": "Comments: submitted to INTERSPEECH",
    "descriptor": "\nComments: submitted to INTERSPEECH\n",
    "authors": [
      "Yufei Liu",
      "Rao Ma",
      "Haihua Xu",
      "Yi He",
      "Zejun Ma",
      "Weibin Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2201.11627"
  },
  {
    "id": "arXiv:2201.12329",
    "title": "DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR",
    "abstract": "Comments: Accepted to ICLR 2022",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "Shilong Liu",
      "Feng Li",
      "Hao Zhang",
      "Xiao Yang",
      "Xianbiao Qi",
      "Hang Su",
      "Jun Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12329"
  },
  {
    "id": "arXiv:2201.12845",
    "title": "Potential destination prediction for low predictability individuals  based on knowledge graph",
    "abstract": "Potential destination prediction for low predictability individuals  based on knowledge graph",
    "descriptor": "",
    "authors": [
      "Guilong Li",
      "Yixian Chen",
      "Qionghua Liao",
      "Zhaocheng He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12845"
  },
  {
    "id": "arXiv:2202.00455",
    "title": "HCSC: Hierarchical Contrastive Selective Coding",
    "abstract": "Comments: Accepted by CVPR 2022. arXiv v3: 800 epoch multi-crop model released; arXiv v2: more model weights released; arXiv v1: code & model weights released",
    "descriptor": "\nComments: Accepted by CVPR 2022. arXiv v3: 800 epoch multi-crop model released; arXiv v2: more model weights released; arXiv v1: code & model weights released\n",
    "authors": [
      "Yuanfan Guo",
      "Minghao Xu",
      "Jiawen Li",
      "Bingbing Ni",
      "Xuanyu Zhu",
      "Zhenbang Sun",
      "Yi Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00455"
  },
  {
    "id": "arXiv:2202.01566",
    "title": "Unified theory of atom-centered representations and message-passing  machine-learning schemes",
    "abstract": "Unified theory of atom-centered representations and message-passing  machine-learning schemes",
    "descriptor": "",
    "authors": [
      "Jigyasa Nigam",
      "Guillaume Fraux",
      "Michele Ceriotti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01566"
  },
  {
    "id": "arXiv:2202.02652",
    "title": "A Graph Neural Network Framework for Grid-Based Simulation",
    "abstract": "Comments: There are conflict of interests and I need to modify the paper before resubmitting",
    "descriptor": "\nComments: There are conflict of interests and I need to modify the paper before resubmitting\n",
    "authors": [
      "Haoyu Tang",
      "Wennan Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.02652"
  },
  {
    "id": "arXiv:2202.03086",
    "title": "Machine Translation from Signed to Spoken Languages: State of the Art  and Challenges",
    "abstract": "Machine Translation from Signed to Spoken Languages: State of the Art  and Challenges",
    "descriptor": "",
    "authors": [
      "Mathieu De Coster",
      "Dimitar Shterionov",
      "Mieke Van Herreweghe",
      "Joni Dambre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03086"
  },
  {
    "id": "arXiv:2202.05928",
    "title": "Benign Overfitting without Linearity: Neural Network Classifiers Trained  by Gradient Descent for Noisy Linear Data",
    "abstract": "Comments: 35 pages; fixed typos and clarified an assumption on the activation",
    "descriptor": "\nComments: 35 pages; fixed typos and clarified an assumption on the activation\n",
    "authors": [
      "Spencer Frei",
      "Niladri S. Chatterji",
      "Peter L. Bartlett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05928"
  },
  {
    "id": "arXiv:2202.06221",
    "title": "Supporting Serendipitous Discovery and Balanced Analysis of Online  Product Reviews with Interaction-Driven Metrics and Bias-Mitigating  Suggestions",
    "abstract": "Comments: Accepted for publication at CHI2022. Previous version is replace to account for additional comments, reviews, and changes",
    "descriptor": "\nComments: Accepted for publication at CHI2022. Previous version is replace to account for additional comments, reviews, and changes\n",
    "authors": [
      "Mahmood Jasim",
      "Christopher Collins",
      "Ali Sarvghad",
      "Narges Mahyar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.06221"
  },
  {
    "id": "arXiv:2202.06930",
    "title": "Tensor Moments of Gaussian Mixture Models: Theory and Applications",
    "abstract": "Tensor Moments of Gaussian Mixture Models: Theory and Applications",
    "descriptor": "",
    "authors": [
      "Jo\u00e3o M. Pereira",
      "Joe Kileel",
      "Tamara G. Kolda"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.06930"
  },
  {
    "id": "arXiv:2202.08510",
    "title": "A hybrid 2-stage vision transformer for artificial intelligence-assisted  5 class pathologic diagnosis of gastric endoscopic biopsies: a diagnostic  tool for guiding gastric cancer treatment",
    "abstract": "A hybrid 2-stage vision transformer for artificial intelligence-assisted  5 class pathologic diagnosis of gastric endoscopic biopsies: a diagnostic  tool for guiding gastric cancer treatment",
    "descriptor": "",
    "authors": [
      "Yujin Oh",
      "Go Eun Bae",
      "Kyung-Hee Kim",
      "Min-Kyung Yeo",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08510"
  },
  {
    "id": "arXiv:2202.09457",
    "title": "Merging Control Strategies of Connected and Autonomous Vehicles at  Freeway On-Ramps: A Comprehensive Review",
    "abstract": "Merging Control Strategies of Connected and Autonomous Vehicles at  Freeway On-Ramps: A Comprehensive Review",
    "descriptor": "",
    "authors": [
      "Jie Zhu",
      "Said Easa",
      "Kun Gao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09457"
  },
  {
    "id": "arXiv:2202.09950",
    "title": "CampNet: Context-Aware Mask Prediction for End-to-End Text-Based Speech  Editing",
    "abstract": "Comments: under review, 14 pages, 14 figures, demo page is available at this https URL",
    "descriptor": "\nComments: under review, 14 pages, 14 figures, demo page is available at this https URL\n",
    "authors": [
      "Tao Wang",
      "Jiangyan Yi",
      "Ruibo Fu",
      "Jianhua Tao",
      "Zhengqi Wen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.09950"
  },
  {
    "id": "arXiv:2202.11819",
    "title": "Improving Scalability with GPU-Aware Asynchronous Tasks",
    "abstract": "Comments: 10 pages, 9 figures, accepted at HIPS 2022 workshop",
    "descriptor": "\nComments: 10 pages, 9 figures, accepted at HIPS 2022 workshop\n",
    "authors": [
      "Jaemin Choi",
      "David F. Richards",
      "Laxmikant V. Kale"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.11819"
  },
  {
    "id": "arXiv:2202.12163",
    "title": "Attentive Temporal Pooling for Conformer-based Streaming Language  Identification in Long-form Speech",
    "abstract": "Attentive Temporal Pooling for Conformer-based Streaming Language  Identification in Long-form Speech",
    "descriptor": "",
    "authors": [
      "Quan Wang",
      "Yang Yu",
      "Jason Pelecanos",
      "Yiling Huang",
      "Ignacio Lopez Moreno"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12163"
  },
  {
    "id": "arXiv:2202.12524",
    "title": "MAMDR: A Model Agnostic Learning Method for Multi-Domain Recommendation",
    "abstract": "Comments: This paper has been submitted to KDD 2022 ADS Track",
    "descriptor": "\nComments: This paper has been submitted to KDD 2022 ADS Track\n",
    "authors": [
      "Linhao Luo",
      "Yumeng Li",
      "Buyu Gao",
      "Shuai Tang",
      "Sinan Wang",
      "Jiancheng Li",
      "Tanchao Zhu",
      "Jiancai Liu",
      "Zhao Li",
      "Binqiang Zhao",
      "Ziyang Zheng",
      "Shirui Pan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.12524"
  },
  {
    "id": "arXiv:2202.13747",
    "title": "A Blockchain Cloud Computing Middleware for Academic Manuscript  Submission",
    "abstract": "Comments: 11 pages, 5 figures, 51 references, This is an Accepted Manuscript of an article published by Wseas Transactions on Business and Economics on 2022, available online: this http URL",
    "descriptor": "\nComments: 11 pages, 5 figures, 51 references, This is an Accepted Manuscript of an article published by Wseas Transactions on Business and Economics on 2022, available online: this http URL\n",
    "authors": [
      "Alexandros Gazis",
      "Giwrgos Anagnostakis",
      "Stavros Kourmpetis",
      "Eleftheria Katsiri"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.13747"
  },
  {
    "id": "arXiv:2202.13900",
    "title": "Bounded-error constrained state estimation in presence of sporadic  measurements",
    "abstract": "Comments: 47 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2012.03267",
    "descriptor": "\nComments: 47 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2012.03267\n",
    "authors": [
      "Yasmina Becis-Aubry"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.13900"
  },
  {
    "id": "arXiv:2202.13981",
    "title": "\"If you could see me through my eyes\": Predicting Pedestrian Perception",
    "abstract": "\"If you could see me through my eyes\": Predicting Pedestrian Perception",
    "descriptor": "",
    "authors": [
      "Julian Petzold",
      "Mostafa Wahby",
      "Franek Stark",
      "Ulrich Behrje",
      "Heiko Hamann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.13981"
  },
  {
    "id": "arXiv:2203.01057",
    "title": "Colar: Effective and Efficient Online Action Detection by Consulting  Exemplars",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Le Yang",
      "Junwei Han",
      "Dingwen Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01057"
  },
  {
    "id": "arXiv:2203.01080",
    "title": "A Multi-Scale Time-Frequency Spectrogram Discriminator for GAN-based  Non-Autoregressive TTS",
    "abstract": "Comments: Submitted to INTERSPEECH 2022",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Haohan Guo",
      "Hui Lu",
      "Xixin Wu",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.01080"
  },
  {
    "id": "arXiv:2203.01429",
    "title": "SMTNet: Hierarchical cavitation intensity recognition based on sub-main  transfer network",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2203.01118; text overlap with arXiv:2202.13226",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2203.01118; text overlap with arXiv:2202.13226\n",
    "authors": [
      "Yu Sha",
      "Johannes Faber",
      "Shuiping Gou",
      "Bo Liu",
      "Wei Li",
      "Stefan Schramm",
      "Horst Stoecker",
      "Thomas Steckenreiter",
      "Domagoj Vnucec",
      "Nadine Wetzstein",
      "Andreas Widl",
      "Kai Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.01429"
  },
  {
    "id": "arXiv:2203.02916",
    "title": "PanFormer: a Transformer Based Model for Pan-sharpening",
    "abstract": "Comments: Accepted by ICME 2022",
    "descriptor": "\nComments: Accepted by ICME 2022\n",
    "authors": [
      "Huanyu Zhou",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02916"
  },
  {
    "id": "arXiv:2203.03043",
    "title": "High Speed Emulation in a Vehicle-in-the-Loop Driving Simulator",
    "abstract": "Comments: Manuscript accepted for publication in IEEE Transactions on Intelligent Vehicles. 11 pages, 10 figures, 2 tables",
    "descriptor": "\nComments: Manuscript accepted for publication in IEEE Transactions on Intelligent Vehicles. 11 pages, 10 figures, 2 tables\n",
    "authors": [
      "Elliot Weiss",
      "J. Christian Gerdes"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03043"
  },
  {
    "id": "arXiv:2203.03508",
    "title": "Prior-informed Uncertainty Modelling with Bayesian Polynomial  Approximations",
    "abstract": "Prior-informed Uncertainty Modelling with Bayesian Polynomial  Approximations",
    "descriptor": "",
    "authors": [
      "Chun Yui Wong",
      "Pranay Seshadri",
      "Andrew B. Duncan",
      "Ashley Scillitoe",
      "Geoffrey Parks"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.03508"
  },
  {
    "id": "arXiv:2203.03990",
    "title": "Audio-Visual MLP for Scoring Sport",
    "abstract": "Audio-Visual MLP for Scoring Sport",
    "descriptor": "",
    "authors": [
      "Jingfei Xia",
      "Mingchen Zhuge",
      "Tiantian Geng",
      "Shun Fan",
      "Yuantai Wei",
      "Zhenyu He",
      "Feng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03990"
  },
  {
    "id": "arXiv:2203.04041",
    "title": "Shape-invariant 3D Adversarial Point Clouds",
    "abstract": "Comments: Accepted at CVPR 2022",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Qidong Huang",
      "Xiaoyi Dong",
      "Dongdong Chen",
      "Hang Zhou",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04041"
  },
  {
    "id": "arXiv:2203.04042",
    "title": "Abandoning the Bayer-Filter to See in the Dark",
    "abstract": "Abandoning the Bayer-Filter to See in the Dark",
    "descriptor": "",
    "authors": [
      "Xingbo Dong",
      "Wanyan Xu",
      "Zhihui Miao",
      "Lan Ma",
      "Chao Zhang",
      "Jiewen Yang",
      "Zhe Jin",
      "Andrew Beng Jin Teoh",
      "Jiajun Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04042"
  },
  {
    "id": "arXiv:2203.04580",
    "title": "Equilibrium-Independent Stability Analysis for Distribution Systems with  Lossy Transmission Lines",
    "abstract": "Equilibrium-Independent Stability Analysis for Distribution Systems with  Lossy Transmission Lines",
    "descriptor": "",
    "authors": [
      "Wenqi Cui",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.04580"
  },
  {
    "id": "arXiv:2203.05662",
    "title": "Point Density-Aware Voxels for LiDAR 3D Object Detection",
    "abstract": "Comments: Accepted in CVPR 2022",
    "descriptor": "\nComments: Accepted in CVPR 2022\n",
    "authors": [
      "Jordan S. K. Hu",
      "Tianshu Kuai",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05662"
  },
  {
    "id": "arXiv:2203.06558",
    "title": "AutoGPart: Intermediate Supervision Search for Generalizable 3D Part  Segmentation",
    "abstract": "Comments: 11 pages, 6 figures, to be published in CVPR 2022",
    "descriptor": "\nComments: 11 pages, 6 figures, to be published in CVPR 2022\n",
    "authors": [
      "Xueyi Liu",
      "Xiaomeng Xu",
      "Anyi Rao",
      "Chuang Gan",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06558"
  },
  {
    "id": "arXiv:2203.07107",
    "title": "Memristor-based cryogenic programmable DC sources for scalable in-situ  quantum-dot control",
    "abstract": "Memristor-based cryogenic programmable DC sources for scalable in-situ  quantum-dot control",
    "descriptor": "",
    "authors": [
      "Pierre-Antoine Mouny",
      "Yann Beilliard",
      "S\u00e9bastien Graveline",
      "Marc-Antoine Roux",
      "Abdelouadoud El Mesoudy",
      "Rapha\u00ebl Dawant",
      "Pierre Gliech",
      "Serge Ecoffey",
      "Fabien Alibart",
      "Michel Pioro-Ladri\u00e8re",
      "Dominique Drouin"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.07107"
  },
  {
    "id": "arXiv:2203.07194",
    "title": "Strict stability of extension types",
    "abstract": "Comments: 16 pages. This text is essentially Chapter 6 from author's PhD thesis arXiv:2202.13132. Updated references. Submitted, but comments welcome!",
    "descriptor": "\nComments: 16 pages. This text is essentially Chapter 6 from author's PhD thesis arXiv:2202.13132. Updated references. Submitted, but comments welcome!\n",
    "authors": [
      "Jonathan Weinberger"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.07194"
  },
  {
    "id": "arXiv:2203.07836",
    "title": "Graph Pre-training for AMR Parsing and Generation",
    "abstract": "Comments: ACL2022 camera-ready version",
    "descriptor": "\nComments: ACL2022 camera-ready version\n",
    "authors": [
      "Xuefeng Bai",
      "Yulong Chen",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07836"
  },
  {
    "id": "arXiv:2203.08344",
    "title": "Domain Adaptive Hand Keypoint and Pixel Localization in the Wild",
    "abstract": "Domain Adaptive Hand Keypoint and Pixel Localization in the Wild",
    "descriptor": "",
    "authors": [
      "Takehiko Ohkawa",
      "Yu-Jhe Li",
      "Qichen Fu",
      "Ryosuke Furuta",
      "Kris M. Kitani",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08344"
  },
  {
    "id": "arXiv:2203.08481",
    "title": "Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding",
    "abstract": "Comments: Accepted by CVPR2022",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Haojun Jiang",
      "Yuanze Lin",
      "Dongchen Han",
      "Shiji Song",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08481"
  },
  {
    "id": "arXiv:2203.08652",
    "title": "Topology-Preserving Shape Reconstruction and Registration via Neural  Diffeomorphic Flow",
    "abstract": "Topology-Preserving Shape Reconstruction and Registration via Neural  Diffeomorphic Flow",
    "descriptor": "",
    "authors": [
      "Shanlin Sun",
      "Kun Han",
      "Deying Kong",
      "Hao Tang",
      "Xiangyi Yan",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08652"
  },
  {
    "id": "arXiv:2203.08657",
    "title": "Occlusion Fields: An Implicit Representation for Non-Line-of-Sight  Surface Reconstruction",
    "abstract": "Occlusion Fields: An Implicit Representation for Non-Line-of-Sight  Surface Reconstruction",
    "descriptor": "",
    "authors": [
      "Javier Grau",
      "Markus Plack",
      "Patrick Haehn",
      "Michael Weinmann",
      "Matthias Hullin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08657"
  },
  {
    "id": "arXiv:2203.08674",
    "title": "Know your sensORs -- A Modality Study For Surgical Action Classification",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Lennart Bastian",
      "Tobias Czempiel",
      "Christian Heiliger",
      "Konrad Karcz",
      "Ulrich Eck",
      "Benjamin Busam",
      "Nassir Navab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08674"
  },
  {
    "id": "arXiv:2203.08928",
    "title": "C-MORE: Pretraining to Answer Open-Domain Questions by Consulting  Millions of References",
    "abstract": "Comments: ACL 2022 Main Conference",
    "descriptor": "\nComments: ACL 2022 Main Conference\n",
    "authors": [
      "Xiang Yue",
      "Xiaoman Pan",
      "Wenlin Yao",
      "Dian Yu",
      "Dong Yu",
      "Jianshu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08928"
  },
  {
    "id": "arXiv:2203.08941",
    "title": "Translating Canonical SQL to Imperative Code in Coq",
    "abstract": "Comments: Version with appendix of a paper published at OOPSLA 2022",
    "descriptor": "\nComments: Version with appendix of a paper published at OOPSLA 2022\n",
    "authors": [
      "V\u00e9ronique Benzaken",
      "\u00c9velyne Contejean",
      "Mohammed Houssem Hachmaoui",
      "Chantal Keller",
      "Louis Mandel",
      "Avraham Shinnar",
      "J\u00e9r\u00f4me Sim\u00e9on"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.08941"
  },
  {
    "id": "arXiv:2203.09163",
    "title": "Modeling Dual Read/Write Paths for Simultaneous Machine Translation",
    "abstract": "Comments: Accept to ACL 2022 main conference. 19 pages, 12 figures, 8 tables",
    "descriptor": "\nComments: Accept to ACL 2022 main conference. 19 pages, 12 figures, 8 tables\n",
    "authors": [
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09163"
  },
  {
    "id": "arXiv:2203.09204",
    "title": "Investigation of Physics-Informed Deep Learning for the Prediction of  Parametric, Three-Dimensional Flow Based on Boundary Data",
    "abstract": "Comments: Reference to code and dataset are DOIs.The DOIs will be activated when article is reviewed. Until then please contact Philip Heger or Daniel Hilger if you wish for code and datasets",
    "descriptor": "\nComments: Reference to code and dataset are DOIs.The DOIs will be activated when article is reviewed. Until then please contact Philip Heger or Daniel Hilger if you wish for code and datasets\n",
    "authors": [
      "Philip Heger",
      "Markus Full",
      "Daniel Hilger",
      "Norbert Hosters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.09204"
  },
  {
    "id": "arXiv:2203.09416",
    "title": "Bi-directional Object-context Prioritization Learning for Saliency  Ranking",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Xin Tian",
      "Ke Xu",
      "Xin Yang",
      "Lin Du",
      "Baocai Yin",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09416"
  },
  {
    "id": "arXiv:2203.09481",
    "title": "Diffusion Probabilistic Modeling for Video Generation",
    "abstract": "Comments: This work has been submitted to the ECCV 2022 for possible publication",
    "descriptor": "\nComments: This work has been submitted to the ECCV 2022 for possible publication\n",
    "authors": [
      "Ruihan Yang",
      "Prakhar Srivastava",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09481"
  },
  {
    "id": "arXiv:2203.09501",
    "title": "A Coinductive Reformulation of Milner's Proof System for Regular  Expressions Modulo Bisimilarity",
    "abstract": "Comments: v2: 50 pages, added overview, text and proof sketches in Section 3, and improvements. arXiv admin note: substantial text overlap with arXiv:2108.13104",
    "descriptor": "\nComments: v2: 50 pages, added overview, text and proof sketches in Section 3, and improvements. arXiv admin note: substantial text overlap with arXiv:2108.13104\n",
    "authors": [
      "Clemens Grabmayer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.09501"
  },
  {
    "id": "arXiv:2203.09645",
    "title": "MatchFormer: Interleaving Attention in Transformers for Feature Matching",
    "abstract": "Comments: Code will be made publicly available at this https URL",
    "descriptor": "\nComments: Code will be made publicly available at this https URL\n",
    "authors": [
      "Qing Wang",
      "Jiaming Zhang",
      "Kailun Yang",
      "Kunyu Peng",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.09645"
  },
  {
    "id": "arXiv:2203.10161",
    "title": "Collaborative Computing Support for Analysis Facilities Exploiting  Software as Infrastructure Techniques",
    "abstract": "Comments: contribution to Snowmass 2021",
    "descriptor": "\nComments: contribution to Snowmass 2021\n",
    "authors": [
      "Maria Acosta Flechas",
      "Garhan Attebury",
      "Kenneth Bloom",
      "Brian Bockelman",
      "Lindsey Gray",
      "Burt Holzman",
      "Carl Lundstedt",
      "Oksana Shadura",
      "Nicholas Smith",
      "John Thiltges"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Software Engineering (cs.SE)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2203.10161"
  },
  {
    "id": "arXiv:2203.10289",
    "title": "METL -- a modern ETL pipeline with a dynamic mapping matrix",
    "abstract": "Comments: version 2: cleaned up references in abstract, improved explanation of block-scoped mapping process",
    "descriptor": "\nComments: version 2: cleaned up references in abstract, improved explanation of block-scoped mapping process\n",
    "authors": [
      "Christian Haase",
      "Timo R\u00f6seler",
      "Mattias Seidel"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.10289"
  },
  {
    "id": "arXiv:2203.10326",
    "title": "Pretraining with Artificial Language: Studying Transferable Knowledge in  Language Models",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Ryokan Ri",
      "Yoshimasa Tsuruoka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.10326"
  },
  {
    "id": "arXiv:2203.10430",
    "title": "g2pW: A Conditional Weighted Softmax BERT for Polyphone Disambiguation  in Mandarin",
    "abstract": "Comments: submitted to Insterspeech 2022",
    "descriptor": "\nComments: submitted to Insterspeech 2022\n",
    "authors": [
      "Yi-Chang Chen",
      "Yu-Chuan Chang",
      "Yen-Cheng Chang",
      "Yi-Ren Yeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.10430"
  },
  {
    "id": "arXiv:2203.10489",
    "title": "TVConv: Efficient Translation Variant Convolution for Layout-aware  Visual Processing",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Jierun Chen",
      "Tianlang He",
      "Weipeng Zhuo",
      "Li Ma",
      "Sangtae Ha",
      "S.-H. Gary Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10489"
  },
  {
    "id": "arXiv:2203.10492",
    "title": "SimAN: Exploring Self-Supervised Representation Learning of Scene Text  via Similarity-Aware Normalization",
    "abstract": "Comments: Accepted to appear in CVPR 2022",
    "descriptor": "\nComments: Accepted to appear in CVPR 2022\n",
    "authors": [
      "Canjie Luo",
      "Lianwen Jin",
      "Jingdong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10492"
  },
  {
    "id": "arXiv:2203.10531",
    "title": "Approximation and Interpolation of Singular Measures by Trigonometric  Polynomials",
    "abstract": "Comments: 26 pages",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Paul Catala",
      "Mathias Hockmann",
      "Stefan Kunis",
      "Markus Wageringel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.10531"
  },
  {
    "id": "arXiv:2203.10562",
    "title": "CRISPnet: Color Rendition ISP Net",
    "abstract": "CRISPnet: Color Rendition ISP Net",
    "descriptor": "",
    "authors": [
      "Matheus Souza",
      "Wolfgang Heidrich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.10562"
  },
  {
    "id": "arXiv:2203.10636",
    "title": "Transform your Smartphone into a DSLR Camera: Learning the ISP in the  Wild",
    "abstract": "Comments: 38 pages",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Ardhendu Shekhar Tripathi",
      "Martin Danelljan",
      "Samarth Shukla",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10636"
  },
  {
    "id": "arXiv:2203.10736",
    "title": "The activity-weight duality in feed forward neural networks: The  geometric determinants of generalization",
    "abstract": "The activity-weight duality in feed forward neural networks: The  geometric determinants of generalization",
    "descriptor": "",
    "authors": [
      "Yu Feng",
      "Yuhai Tu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.10736"
  },
  {
    "id": "arXiv:2203.10739",
    "title": "Tree Energy Loss: Towards Sparsely Annotated Semantic Segmentation",
    "abstract": "Comments: Accepted by CVPR2022",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Zhiyuan Liang",
      "Tiancai Wang",
      "Xiangyu Zhang",
      "Jian Sun",
      "Jianbing Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10739"
  },
  {
    "id": "arXiv:2203.10752",
    "title": "XTREME-S: Evaluating Cross-lingual Speech Representations",
    "abstract": "XTREME-S: Evaluating Cross-lingual Speech Representations",
    "descriptor": "",
    "authors": [
      "Alexis Conneau",
      "Ankur Bapna",
      "Yu Zhang",
      "Min Ma",
      "Patrick von Platen",
      "Anton Lozhkov",
      "Colin Cherry",
      "Ye Jia",
      "Clara Rivera",
      "Mihir Kale",
      "Daan Van Esch",
      "Vera Axelrod",
      "Simran Khanuja",
      "Jonathan H. Clark",
      "Orhan Firat",
      "Michael Auli",
      "Sebastian Ruder",
      "Jason Riesa",
      "Melvin Johnson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.10752"
  },
  {
    "id": "arXiv:2203.10765",
    "title": "Tiramisu: Layering Consensus Protocols for Scalable and Secure  Blockchains",
    "abstract": "Tiramisu: Layering Consensus Protocols for Scalable and Secure  Blockchains",
    "descriptor": "",
    "authors": [
      "Anurag Jain",
      "Sanidhay Arora",
      "Sankarshan Damle",
      "Sujit Gujar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.10765"
  },
  {
    "id": "arXiv:2203.10769",
    "title": "ASE: Anomaly Scoring Based Ensemble Learning for Imbalanced Datasets",
    "abstract": "ASE: Anomaly Scoring Based Ensemble Learning for Imbalanced Datasets",
    "descriptor": "",
    "authors": [
      "Xiayu Liang",
      "Ying Gao",
      "Shanrong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.10769"
  },
  {
    "id": "arXiv:2203.10774",
    "title": "Fictitious Play with Maximin Initialization",
    "abstract": "Fictitious Play with Maximin Initialization",
    "descriptor": "",
    "authors": [
      "Sam Ganzfried"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2203.10774"
  },
  {
    "id": "arXiv:2203.10833",
    "title": "Hyperbolic Vision Transformers: Combining Improvements in Metric  Learning",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Aleksandr Ermolov",
      "Leyla Mirvakhabova",
      "Valentin Khrulkov",
      "Nicu Sebe",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.10833"
  },
  {
    "id": "arXiv:2203.11007",
    "title": "Computational ergonomics for task delegation in Human-Robot  Collaboration: spatiotemporal adaptation of the robot to the human through  contactless gesture recognition",
    "abstract": "Comments: Under review in IEEE Robotics and Automation Letters",
    "descriptor": "\nComments: Under review in IEEE Robotics and Automation Letters\n",
    "authors": [
      "Brenda Elizabeth Olivas-Padilla",
      "Dimitris Papanagiotou",
      "Gavriela Senteri",
      "Sotiris Manitsaris",
      "Alina Glushkova"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.11007"
  },
  {
    "id": "arXiv:2203.11114",
    "title": "On the Parameterized Complexity of the Maximum Exposure Problem",
    "abstract": "On the Parameterized Complexity of the Maximum Exposure Problem",
    "descriptor": "",
    "authors": [
      "Remi Raman",
      "Shahin John J S",
      "R Subashini",
      "Subhasree Methirumangalath"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.11114"
  },
  {
    "id": "arXiv:2203.11156",
    "title": "Operator Sketching for Deep Unrolling Networks",
    "abstract": "Operator Sketching for Deep Unrolling Networks",
    "descriptor": "",
    "authors": [
      "Junqi Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.11156"
  },
  {
    "id": "arXiv:2203.11178",
    "title": "Physics-driven Synthetic Data Learning for Biomedical Magnetic Resonance",
    "abstract": "Physics-driven Synthetic Data Learning for Biomedical Magnetic Resonance",
    "descriptor": "",
    "authors": [
      "Qinqin Yang",
      "Zi Wang",
      "Kunyuan Guo",
      "Congbo Cai",
      "Xiaobo Qu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.11178"
  }
]
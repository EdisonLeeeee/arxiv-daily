[
  {
    "id": "arXiv:2203.03615",
    "title": "Academic mobility as an organizational mechanism of intercultural  interaction",
    "abstract": "The trends of academic mobility of students in the context of\ninternationalization are presented. The results of a study de-voted to the\nstudents' attitudes towards international education, cultural and educational\nexchange and academic mobility programs are presented. It is concluded that the\norganization of academic mobility, as a part of intercultural environment of\nthe university, is a necessary tool of motivation for the educational process\nand organizational mechanism for intercultural communication.",
    "descriptor": "\nComments: 3 page, 3 Figure\n",
    "authors": [
      "E.M. Pokrovskaya",
      "M.Y. Raitina"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.03615"
  },
  {
    "id": "arXiv:2203.03616",
    "title": "Responsible AI in Healthcare",
    "abstract": "This article discusses open problems, implemented solutions, and future\nresearch in the area of responsible AI in healthcare. In particular, we\nillustrate two main research themes related to the work of two laboratories\nwithin the Department of Informatics, Systems, and Communication at the\nUniversity of Milano-Bicocca. The problems addressed concern, in particular,\n{uncertainty in medical data and machine advice}, and the problem of online\nhealth information disorder.",
    "descriptor": "\nComments: 5 pages, 0 figures\n",
    "authors": [
      "Federico Cabitza",
      "Davide Ciucci",
      "Gabriella Pasi",
      "Marco Viviani"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03616"
  },
  {
    "id": "arXiv:2203.03620",
    "title": "Prediction of terrorism pattern accompanied by cyber-terrorism and the  development direction of corresponding legal systems",
    "abstract": "As the information and communication system has become an essential element\nfor national operation and people's lives, and the dependence on information\nand communication systems such as national infrastructure systems and\nfacilities increases, cyber terrorism is rapidly emerging as a serious threat\nto national security in peacetime. As terrorist groups' access to cyber-attack\nassets improves, the traditional form of terrorism is also expected to change\nto a form combined with cyber-terrorism. Nevertheless, from a national security\npoint of view, Korea lacks a legal system to prepare for and respond to cyber\nterrorism. In this paper, based on the development process of the modern\nmilitary operation concept, we predict the changes in the form of terrorism,\nanalyze the restrictions on the national response to cyber-terrorism based on\nthe current legal system, and propose the development directions.",
    "descriptor": "\nComments: in Korean language\n",
    "authors": [
      "Daegeon Kim"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.03620"
  },
  {
    "id": "arXiv:2203.03663",
    "title": "Towards Sub-Quadratic Diameter Computation in Geometric Intersection  Graphs",
    "abstract": "We initiate the study of diameter computation in geometric intersection\ngraphs from the fine-grained complexity perspective. A geometric intersection\ngraph is a graph whose vertices correspond to some shapes in $d$-dimensional\nEuclidean space, such as balls, segments, or hypercubes, and whose edges\ncorrespond to pairs of intersecting shapes. The diameter of a graph is the\nlargest distance realized by a pair of vertices in the graph.\nComputing the diameter in near-quadratic time is possible in several classes\nof intersection graphs [Chan and Skrepetos 2019], but it is not at all clear if\nthese algorithms are optimal, especially since in the related class of planar\ngraphs the diameter can be computed in $\\widetilde{\\mathcal{O}}(n^{5/3})$ time\n[Cabello 2019, Gawrychowski et al. 2021].\nIn this work we (conditionally) rule out sub-quadratic algorithms in several\nclasses of intersection graphs, i.e., algorithms of running time\n$\\mathcal{O}(n^{2-\\delta})$ for some $\\delta>0$. In particular, there are no\nsub-quadratic algorithms already for fat objects in small dimensions: unit\nballs in $\\mathbb{R}^3$ or congruent equilateral triangles in $\\mathbb{R}^2$.\nFor unit segments and congruent equilateral triangles, we can even rule out\nstrong sub-quadratic approximations already in $\\mathbb{R}^2$. It seems that\nthe hardness of approximation may also depend on dimensionality: for\naxis-parallel unit hypercubes in~$\\mathbb{R}^{12}$, distinguishing between\ndiameter 2 and 3 needs quadratic time (ruling out $(3/2-\\varepsilon)$-\napproximations), whereas for axis-parallel unit squares, we give an algorithm\nthat distinguishes between diameter $2$ and $3$ in near-linear time.\nNote that many of our lower bounds match the best known algorithms up to\nsub-polynomial factors.",
    "descriptor": "\nComments: Full version of SoCG '22 paper\n",
    "authors": [
      "Karl Bringmann",
      "S\u00e1ndor Kisfaludi-Bak",
      "Marvin K\u00fcnnemann",
      "Andr\u00e9 Nusser",
      "Zahra Parsaeian"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.03663"
  },
  {
    "id": "arXiv:2203.03664",
    "title": "Unsupervised Domain Adaptation with Contrastive Learning for OCT  Segmentation",
    "abstract": "Accurate segmentation of retinal fluids in 3D Optical Coherence Tomography\nimages is key for diagnosis and personalized treatment of eye diseases. While\ndeep learning has been successful at this task, trained supervised models often\nfail for images that do not resemble labeled examples, e.g. for images acquired\nusing different devices. We hereby propose a novel semi-supervised learning\nframework for segmentation of volumetric images from new unlabeled domains. We\njointly use supervised and contrastive learning, also introducing a contrastive\npairing scheme that leverages similarity between nearby slices in 3D. In\naddition, we propose channel-wise aggregation as an alternative to conventional\nspatial-pooling aggregation for contrastive feature map projection. We evaluate\nour methods for domain adaptation from a (labeled) source domain to an\n(unlabeled) target domain, each containing images acquired with different\nacquisition devices. In the target domain, our method achieves a Dice\ncoefficient 13.8% higher than SimCLR (a state-of-the-art contrastive\nframework), and leads to results comparable to an upper bound with supervised\ntraining in that domain. In the source domain, our model also improves the\nresults by 5.4% Dice, by successfully leveraging information from many\nunlabeled images.",
    "descriptor": "\nComments: Main: 10 pages, 4 figures, 1 table. Supplementary: 2 pages, 1 figure, 4 tables\n",
    "authors": [
      "Alvaro Gomariz",
      "Huanxiang Lu",
      "Yun Yvonna Li",
      "Thomas Albrecht",
      "Andreas Maunz",
      "Fethallah Benmansour",
      "Alessandra M.Valcarcel",
      "Jennifer Luu",
      "Daniela Ferrara",
      "Orcun Goksel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.03664"
  },
  {
    "id": "arXiv:2203.03665",
    "title": "Distributed Consensus of Stochastic Multi-agent Systems with Prescribed  Performance Constraints",
    "abstract": "This paper focuses on the problem of distributed consensus control of\nmulti-agent systems while considering two main practical concerns (i)\nstochastic noise in the agent dynamics and (ii) predefined performance\nconstraints over evolutions of multi-agent systems. In particular, we consider\nthat each agent is driven by a stochastic differential equation with\nstate-dependent noise which makes the considered problem more challenging\ncompared to non-stochastic agents. The work provides sufficient conditions\nunder which the proposed timevarying distributed control laws ensure consensus\nin expectation and almost sure consensus of stochastic multi-agent systems\nwhile satisfying prescribed performance constraints over evolutions of the\nsystems in the sense of the qth moment. Finally, we demonstrate the\neffectiveness of the proposed results with a numerical example.",
    "descriptor": "\nComments: 6 pages, 3 figures, published in 60th IEEE Conference on Decision and Control (CDC)\n",
    "authors": [
      "Pushpak Jagtap",
      "Dimos V. Dimarogonas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.03665"
  },
  {
    "id": "arXiv:2203.03668",
    "title": "A Typology to Explore and Guide Explanatory Interactive Machine Learning",
    "abstract": "Recently, more and more eXplanatory Interactive machine Learning (XIL)\nmethods have been proposed with the goal of extending a model's learning\nprocess by integrating human user supervision on the model's explanations.\nThese methods were often developed independently, provide different motivations\nand stem from different applications. Notably, up to now, there has not been a\ncomprehensive evaluation of these works. By identifying a common set of basic\nmodules and providing a thorough discussion of these modules, our work, for the\nfirst time, comes up with a unification of the various methods into a single\ntypology. This typology can thus be used to categorize existing and future XIL\nmethods based on the identified modules. Moreover, our work contributes by\nsurveying six existing XIL methods. In addition to benchmarking these methods\non their overall ability to revise a model, we perform additional benchmarks\nregarding wrong reason revision, interaction efficiency, robustness to feedback\nquality, and the ability to revise a strongly corrupted model. Apart from\nintroducing these novel benchmarking tasks, for improved quantitative\nevaluations, we further introduce a novel Wrong Reason (\\wrnospace) metric\nwhich measures the average wrong reason activation in a model's explanations to\ncomplement a qualitative inspection. In our evaluations, all methods prove to\nrevise a model successfully. However, we found significant differences between\nthe methods on individual benchmark tasks, revealing valuable\napplication-relevant aspects not only for comparing current methods but also to\nmotivate the necessity of incorporating these benchmarks in the development of\nfuture XIL methods.",
    "descriptor": "",
    "authors": [
      "Felix Friedrich",
      "Wolfgang Stammer",
      "Patrick Schramowski",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.03668"
  },
  {
    "id": "arXiv:2203.03677",
    "title": "Object-centric and memory-guided normality reconstruction for video  anomaly detection",
    "abstract": "This paper addresses video anomaly detection problem for videosurveillance.\nDue to the inherent rarity and heterogeneity of abnormal events, the problem is\nviewed as a normality modeling strategy, in which our model learns\nobject-centric normal patterns without seeing anomalous samples during\ntraining. The main contributions consist in coupling pretrained object-level\naction features prototypes with a cosine distance-based anomaly estimation\nfunction, therefore extending previous methods by introducing additional\nconstraints to the mainstream reconstruction-based strategy. Our framework\nleverages both appearance and motion information to learn object-level behavior\nand captures prototypical patterns within a memory module. Experiments on\nseveral well-known datasets demonstrate the effectiveness of our method as it\noutperforms current state-of-the-art on most relevant spatio-temporal\nevaluation metrics.",
    "descriptor": "",
    "authors": [
      "Khalil Bergaoui",
      "Yassine Naji",
      "Aleksandr Setkov",
      "Ang\u00e9lique Loesch",
      "Mich\u00e8le Gouiff\u00e8s",
      "Romaric Audigier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03677"
  },
  {
    "id": "arXiv:2203.03682",
    "title": "Monocular Robot Navigation with Self-Supervised Pretrained Vision  Transformers",
    "abstract": "In this work, we consider the problem of learning a perception model for\nmonocular robot navigation using few annotated images. Using a Vision\nTransformer (ViT) pretrained with a label-free self-supervised method, we\nsuccessfully train a coarse image segmentation model for the Duckietown\nenvironment using 70 training images. Our model performs coarse image\nsegmentation at the 8x8 patch level, and the inference resolution can be\nadjusted to balance prediction granularity and real-time perception\nconstraints. We study how best to adapt a ViT to our task and environment, and\nfind that some lightweight architectures can yield good single-image\nsegmentations at a usable frame rate, even on CPU. The resulting perception\nmodel is used as the backbone for a simple yet robust visual servoing agent,\nwhich we deploy on a differential drive mobile robot to perform two tasks: lane\nfollowing and obstacle avoidance.",
    "descriptor": "",
    "authors": [
      "Miguel Saavedra-Ruiz",
      "Sacha Morin",
      "Liam Paull"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03682"
  },
  {
    "id": "arXiv:2203.03684",
    "title": "Learn to Match with No Regret: Reinforcement Learning in Markov Matching  Markets",
    "abstract": "We study a Markov matching market involving a planner and a set of strategic\nagents on the two sides of the market. At each step, the agents are presented\nwith a dynamical context, where the contexts determine the utilities. The\nplanner controls the transition of the contexts to maximize the cumulative\nsocial welfare, while the agents aim to find a myopic stable matching at each\nstep. Such a setting captures a range of applications including ridesharing\nplatforms. We formalize the problem by proposing a reinforcement learning\nframework that integrates optimistic value iteration with maximum weight\nmatching. The proposed algorithm addresses the coupled challenges of sequential\nexploration, matching stability, and function approximation. We prove that the\nalgorithm achieves sublinear regret.",
    "descriptor": "\nComments: 40 pages\n",
    "authors": [
      "Yifei Min",
      "Tianhao Wang",
      "Ruitu Xu",
      "Zhaoran Wang",
      "Michael I. Jordan",
      "Zhuoran Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2203.03684"
  },
  {
    "id": "arXiv:2203.03689",
    "title": "WaveMix: Resource-efficient Token Mixing for Images",
    "abstract": "Although certain vision transformer (ViT) and CNN architectures generalize\nwell on vision tasks, it is often impractical to use them on green, edge, or\ndesktop computing due to their computational requirements for training and even\ntesting. We present WaveMix as an alternative neural architecture that uses a\nmulti-scale 2D discrete wavelet transform (DWT) for spatial token mixing.\nUnlike ViTs, WaveMix neither unrolls the image nor requires self-attention of\nquadratic complexity. Additionally, DWT introduces another inductive bias --\nbesides convolutional filtering -- to utilize the 2D structure of an image to\nimprove generalization. The multi-scale nature of the DWT also reduces the\nrequirement for a deeper architecture compared to the CNNs, as the latter\nrelies on pooling for partial spatial mixing. WaveMix models show\ngeneralization that is competitive with ViTs, CNNs, and token mixers on several\ndatasets while requiring lower GPU RAM (training and testing), number of\ncomputations, and storage. WaveMix have achieved State-of-the-art (SOTA)\nresults in EMNIST Byclass and EMNIST Balanced datasets.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Pranav Jeevan",
      "Amit Sethi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03689"
  },
  {
    "id": "arXiv:2203.03691",
    "title": "HyperMixer: An MLP-based Green AI Alternative to Transformers",
    "abstract": "Transformer-based architectures are the model of choice for natural language\nunderstanding, but they come at a significant cost, as they have quadratic\ncomplexity in the input length and can be difficult to tune. In the pursuit of\nGreen AI, we investigate simple MLP-based architectures. We find that existing\narchitectures such as MLPMixer, which achieves token mixing through a static\nMLP applied to each feature independently, are too detached from the inductive\nbiases required for natural language understanding. In this paper, we propose a\nsimple variant, HyperMixer, which forms the token mixing MLP dynamically using\nhypernetworks. Empirically, we demonstrate that our model performs better than\nalternative MLP-based models, and on par with Transformers. In contrast to\nTransformers, HyperMixer achieves these results at substantially lower costs in\nterms of processing time, training data, and hyperparameter tuning.",
    "descriptor": "",
    "authors": [
      "Florian Mai",
      "Arnaud Pannatier",
      "Fabio Fehr",
      "Haolin Chen",
      "Francois Marelli",
      "Francois Fleuret",
      "James Henderson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03691"
  },
  {
    "id": "arXiv:2203.03692",
    "title": "Low-Loss Subspace Compression for Clean Gains against Multi-Agent  Backdoor Attacks",
    "abstract": "Recent exploration of the multi-agent backdoor attack demonstrated the\nbackfiring effect, a natural defense against backdoor attacks where backdoored\ninputs are randomly classified. This yields a side-effect of low accuracy\nw.r.t. clean labels, which motivates this paper's work on the construction of\nmulti-agent backdoor defenses that maximize accuracy w.r.t. clean labels and\nminimize that of poison labels. Founded upon agent dynamics and low-loss\nsubspace construction, we contribute three defenses that yield improved\nmulti-agent backdoor robustness.",
    "descriptor": "",
    "authors": [
      "Siddhartha Datta",
      "Nigel Shadbolt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.03692"
  },
  {
    "id": "arXiv:2203.03695",
    "title": "Learning to Bound: A Generative Cram\u00e9r-Rao Bound",
    "abstract": "The Cram\\'er-Rao bound (CRB), a well-known lower bound on the performance of\nany unbiased parameter estimator, has been used to study a wide variety of\nproblems. However, to obtain the CRB, requires an analytical expression for the\nlikelihood of the measurements given the parameters, or equivalently a precise\nand explicit statistical model for the data. In many applications, such a model\nis not available. Instead, this work introduces a novel approach to approximate\nthe CRB using data-driven methods, which removes the requirement for an\nanalytical statistical model. This approach is based on the recent success of\ndeep generative models in modeling complex, high-dimensional distributions.\nUsing a learned normalizing flow model, we model the distribution of the\nmeasurements and obtain an approximation of the CRB, which we call Generative\nCram\\'er-Rao Bound (GCRB). Numerical experiments on simple problems validate\nthis approach, and experiments on two image processing tasks of image denoising\nand edge detection with a learned camera noise model demonstrate its power and\nbenefits.",
    "descriptor": "",
    "authors": [
      "Hai Victor Habi",
      "Hagit Messer",
      "Yoram Bresler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.03695"
  },
  {
    "id": "arXiv:2203.03697",
    "title": "Unit Perturbations in Budgeted Spanning Tree Problems",
    "abstract": "The minimum spanning tree of a graph is a well-studied structure that is the\nbasis of countless graph theoretic and optimization problem. We study the\nminimum spanning tree (MST) perturbation problem where the goal is to spend a\nfixed budget to increase the weight of edges in order to increase the weight of\nthe MST as much as possible. Two popular models of perturbation are bulk and\ncontinuous. In the bulk model, the weight of any edge can be increased exactly\nonce to some predetermined weight. In the continuous model, one can pay a\nfractional amount of cost to increase the weight of any edge by a proportional\namount. Frederickson and Solis-Oba \\cite{FS96} have studied these two models\nand showed that bulk perturbation for MST is as hard as the $k$-cut problem\nwhile the continuous perturbation model is solvable in poly-time. In this\npaper, we study an intermediate unit perturbation variation of this problem\nwhere the weight of each edge can be increased many times but at an integral\nunit amount every time. We provide an $(opt/2 -1)$-approximation in polynomial\ntime where $opt$ is the optimal increase in the weight. We also study the\nassociated dual targeted version of the problem where the goal is to increase\nthe weight of the MST by a target amount while minimizing the cost of\nperturbation. We provide a $2$-approximation for this variation. Furthermore we\nshow that assuming the Small Set Expansion Hypothesis, both problems are hard\nto approximate. We also point out an error in the proof provided by\nFrederickson and Solis-Oba in \\cite{FS96} with regard to their solution to the\ncontinuous perturbation model. Although their algorithm is correct, their\nanalysis is flawed. We provide a correct proof here.",
    "descriptor": "",
    "authors": [
      "Hassene Aissi",
      "Solal Attias",
      "Da Qi Chen",
      "R. Ravi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.03697"
  },
  {
    "id": "arXiv:2203.03702",
    "title": "On a Continuous-Time Version of Willems' Lemma",
    "abstract": "In this paper, a method to represent every input-output trajectory of a\ncontinuous-time linear system in terms of previously collected data is\npresented. This corresponds to a continuous-time version of the well-known\nWillems' lemma. The result is obtained by sampling the continuous signals at\nregular intervals, and constructing Hankel-like structures that closely\nresemble their discrete-time counterparts. Then, it is shown how to use\nmeasured persistently excited data to design a time-varying vector of\nparameters that allows the generation of arbitrary piecewise differentiable\ntrajectories. A class of input signals that satisfies the conditions for\npersistence of excitation is also provided.",
    "descriptor": "",
    "authors": [
      "Victor G. Lopez",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03702"
  },
  {
    "id": "arXiv:2203.03704",
    "title": "Mid-Air Helicopter Delivery at Mars Using a Jetpack",
    "abstract": "Mid-Air Helicopter Delivery (MAHD) is a new Entry, Descent and Landing (EDL)\narchitecture to enable in situ mobility for Mars science at lower cost than\nprevious missions. It uses a jetpack to slow down a Mars Science Helicopter\n(MSH) after separation from the backshell, and reach aerodynamic conditions\nsuitable for helicopter take-off in mid air. For given aeroshell dimensions,\nonly MAHD's lander-free approach leaves enough room in the aeroshell to\naccommodate the largest rotor option for MSH. This drastically improves flight\nperformance, notably allowing +150\\% increased science payload mass. Compared\nto heritage EDL approaches, the simpler MAHD architecture is also likely to\nreduce cost, and enables access to more hazardous and higher-elevation terrains\non Mars. This paper introduces a design for the MAHD system architecture and\noperations. We present a mechanical configuration that fits both MSH and the\njetpack within the 2.65-m Mars heritage aeroshell, and a jetpack control\narchitecture which fully leverages the available helicopter avionics. We\ndiscuss preliminary numerical models of the flow dynamics resulting from the\ninteraction between the jets, the rotors and the side winds. We define a\nforce-torque sensing architecture capable of handling the wind and trimming the\nrotors to prepare for safe take-off. Finally, we analyze the dynamic\nenvironment and closed-loop control simulation results to demonstrate the\npreliminary feasibility of MAHD.",
    "descriptor": "\nComments: Accepted in 2022 IEEE Aerospace Conference\n",
    "authors": [
      "Jeff Delaune",
      "Jacob Izraelevitz",
      "Samuel Sirlin",
      "David Sternberg",
      "Louis Giersch",
      "L. Phillipe Tosi",
      "Evgeniy Skliyanskiy",
      "Larry Young",
      "Michael Mischna",
      "Shannah Withrow-Maser",
      "Juergen Mueller",
      "Joshua Bowman",
      "Mark S Wallace",
      "Havard F. Grip",
      "Larry Matthies",
      "Wayne Johnson",
      "Matthew Keennon",
      "Benjamin Pipenberg",
      "Harsh Patel",
      "Christopher Lim",
      "Aaron Schutte",
      "Marcel Veismann",
      "Haley Cummings",
      "Sarah Conley",
      "Jonathan Bapst",
      "Theodore Tzanetos",
      "Roland Brockers",
      "Abhinandan Jain",
      "David Bayard",
      "Art Chmielewski",
      "Olivier Toupet",
      "Joel Burdick",
      "Morteza Gharib",
      "Balaram"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03704"
  },
  {
    "id": "arXiv:2203.03705",
    "title": "High-Dimensional Expanders from Chevalley Groups",
    "abstract": "Let $\\Phi$ be an irreducible root system (other than $G_2$) of rank at least\n$2$, let $\\mathbb{F}$ be a finite field with $p = \\operatorname{char}\n\\mathbb{F} > 3$, and let $\\mathrm{G}(\\Phi,\\mathbb{F})$ be the corresponding\nChevalley group. We describe a strongly explicit high-dimensional expander\n(HDX) family of dimension $\\mathrm{rank}(\\Phi)$, where\n$\\mathrm{G}(\\Phi,\\mathbb{F})$ acts simply transitively on the top-dimensional\nfaces; these are $\\lambda$-spectral HDXs with $\\lambda \\to 0$ as $p \\to\n\\infty$. This generalizes a construction of Kaufman and Oppenheim (STOC 2018),\nwhich corresponds to the case $\\Phi = A_d$. Our work gives three new families\nof spectral HDXs of any dimension $\\ge 2$, and four exceptional constructions\nof dimension $4$, $6$, $7$, and $8$.",
    "descriptor": "",
    "authors": [
      "Ryan O'Donnell",
      "Kevin Pratt"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.03705"
  },
  {
    "id": "arXiv:2203.03706",
    "title": "Detection of AI Synthesized Hindi Speech",
    "abstract": "The recent advancements in generative artificial speech models have made\npossible the generation of highly realistic speech signals. At first, it seems\nexciting to obtain these artificially synthesized signals such as speech clones\nor deep fakes but if left unchecked, it may lead us to digital dystopia. One of\nthe primary focus in audio forensics is validating the authenticity of a\nspeech. Though some solutions are proposed for English speeches but the\ndetection of synthetic Hindi speeches have not gained much attention. Here, we\npropose an approach for discrimination of AI synthesized Hindi speech from an\nactual human speech. We have exploited the Bicoherence Phase, Bicoherence\nMagnitude, Mel Frequency Cepstral Coefficient (MFCC), Delta Cepstral, and Delta\nSquare Cepstral as the discriminating features for machine learning models.\nAlso, we extend the study to using deep neural networks for extensive\nexperiments, specifically VGG16 and homemade CNN as the architecture models. We\nobtained an accuracy of 99.83% with VGG16 and 99.99% with homemade CNN models.",
    "descriptor": "\nComments: 5 Pages, 6 Figures, 4 Tables\n",
    "authors": [
      "Karan Bhatia",
      "Ansh Agrawal",
      "Priyanka Singh",
      "Arun Kumar Singh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.03706"
  },
  {
    "id": "arXiv:2203.03707",
    "title": "All one needs to know about shared micromobility simulation: a complete  survey",
    "abstract": "As the shared micromobility becomes a part of our daily life and environment,\nwe expect the number of low-speed modes for first-and-last mile trips to grow\nrapidly. The shared micomobility is expected to serve billions of humans,\nbringing us considerable advantages. With this growth, shared micromobility\nsimulation such as docked stations based shared bikes, dockless shared bikes\nand e-scooters, are regarded as promising solutions to deal with a large number\nof first-and-last mile trips. In this paper, we first provide a comprehensive\noverview of shared micromobility simulation and its related validation metrics.\nNext, we classify the research topics of shared micromobility simulation,\nsummarize, and classify the existing works. Finally, challenges and future\ndirections are provided for further research.",
    "descriptor": "",
    "authors": [
      "Yixuan Liu",
      "Yuhan Tang",
      "Yati Liu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.03707"
  },
  {
    "id": "arXiv:2203.03708",
    "title": "Biological, Family and Cultural Predictors of Personality Structure  analysis based on personality prediction models constructed by open data  source",
    "abstract": "Objective: This study takes further step on understanding personality\nstructure in order to cope with the mental health during the COVID-19 global\npandemic situation. Methods: Categorized the independent variables into\nbiological, family and cultural predictors according to the datasets of the\nBig-5 personality survey online. And established multiple regression prediction\nmodels and exhaustive CHAID decision tree model of each personality trait.\nResults: Females are different from males in personality. The personality\nchanges when growing. One-handed dominants are less agreeable and open than\nthose who use both hands. Different sexual orientation does have variety\npersonality. Native language used and education attainment is significantly\nrelated to personality accordingly. Marriage did help shaping personality to be\nmore extroverted, less neurotic or agreeable and more conscientious and open.\nPeople raised in urban are more agreeable and open. Neurotic and open people\noften come from small families. person participated in voting are more\nextroverted, conscientious and open but less neurotic and agreeable. Different\nreligions and races have different characteristics in each dimension of\npersonality and there is no clear pattern have been found. Conclusion:\nPersonality traits are indeed affected by multiple confounding factors. but the\nexploration on multiple cultures predictors still needed more details",
    "descriptor": "\nComments: 18 pages,7 figures\n",
    "authors": [
      "Cheng Hua",
      "Wang Dandan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.03708"
  },
  {
    "id": "arXiv:2203.03709",
    "title": "Impact of Critical and Auto Ticket: Analysis for Management and Workers  Productivity in using a Ticketing System",
    "abstract": "Ticketing system is common in Technical Support in Information Technology\nIndustry. At present time, even management is using it. It serves as a way to\nconnect the company and the client, end to end. The researchers conducted\nresearch where it aims to come up with a solution on how we are going to\nprevent, troubleshoot, and give insight for possible business impact to those\neveryday issues. Researchers used data collection to gather data from\nmanagement, support workers, and Service Now open-source ticketing system to\nvisualize the ticketing system application. Critical ticket gives a lot of\npressure to the resources as they needed to resolve the incident in accordance\nwith the service level agreement. Having knowledge management helps resource to\nfind references on how to deal with the incident. It helps them to execute\nworkaround quickly and think of a way on how to resolve it permanently. It is\nconcluded that critical and auto ticket affects the everyday productivity of\nthe worker especially teaching new employees despite ongoing critical\nincidents. Researchers provided solutions such as knowledge Management and\nDashboard to document all the solutions encountered and monitor the SLA and\nincoming tickets. It is recommended to have further research on how critical\nand auto ticket affects the mental health of resources and its direct impact to\nbusinesses. It is also recommended to have a study on how knowledge management\nwork and help resources to identify correct workaround despite of having a lot\nof troubleshooting guides.",
    "descriptor": "\nComments: Presented in National Research Conference in Computer Engineering and Technology\n",
    "authors": [
      "Kent Darryl Aglibar",
      "Nelson Rodelas"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.03709"
  },
  {
    "id": "arXiv:2203.03711",
    "title": "Algorithmic audits of algorithms, and the law",
    "abstract": "Algorithmic decision making is now widespread, ranging from health care\nallocation to more common actions such as recommendation or information\nranking. The aim to audit these algorithms has grown alongside. In this paper,\nwe focus on external audits that are conducted by interacting with the user\nside of the target algorithm, hence considered as a black box. Yet, the legal\nframework in which these audits take place is mostly ambiguous to researchers\ndeveloping them: on the one hand, the legal value of the audit outcome is\nuncertain; on the other hand the auditors' rights and obligations are unclear.\nThe contribution of this paper is to articulate two canonical audit forms to\nlaw, to shed light on these aspects: 1) the first audit form (we coin the Bobby\naudit form) checks a predicate against the algorithm, while the second\n(Sherlock) is more loose and opens up to multiple investigations. We find that:\nBobby audits are more amenable to prosecution, yet are delicate as operating on\nreal user data. This can lead to reject by a court (notion of admissibility).\nSherlock audits craft data for their operation, most notably to build\nsurrogates of the audited algorithm. It is mostly used for acts for\nwhistleblowing, as even if accepted as a proof, the evidential value will be\nlow in practice. 2) these two forms require the prior respect of a proper right\nto audit, granted by law or by the platform being audited; otherwise the\nauditor will be also prone to prosecutions regardless of the audit outcome.\nThis article thus highlights the relation of current audits with law, in order\nto structure the growing field of algorithm auditing.",
    "descriptor": "",
    "authors": [
      "Erwan Le Merrer",
      "Ronan Pons",
      "Gilles Tr\u00e9dan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03711"
  },
  {
    "id": "arXiv:2203.03712",
    "title": "Trusted Data Forever: Is AI the Answer?",
    "abstract": "Archival institutions and programs worldwide work to ensure that the records\nof governments, organizations, communities, and individuals are preserved for\nfuture generations as cultural heritage, as sources of rights, and as vehicles\nfor holding the past accountable and to inform the future. This commitment is\nguaranteed through the adoption of strategic and technical measures for the\nlong-term preservation of digital assets in any medium and form - textual,\nvisual, or aural. Public and private archives are the largest providers of data\nbig and small in the world and collectively host yottabytes of trusted data, to\nbe preserved forever. Several aspects of retention and preservation,\narrangement and description, management and administrations, and access and use\nare still open to improvement. In particular, recent advances in Artificial\nIntelligence (AI) open the discussion as to whether AI can support the ongoing\navailability and accessibility of trustworthy public records. This paper\npresents preliminary results of the InterPARES Trust AI (I Trust AI)\ninternational research partnership, which aims to (1) identify and develop\nspecific AI technologies to address critical records and archives challenges;\n(2) determine the benefits and risks of employing AI technologies on records\nand archives; (3) ensure that archival concepts and principles inform the\ndevelopment of responsible AI; and (4) validate outcomes through a conglomerate\nof case studies and demonstrations.",
    "descriptor": "",
    "authors": [
      "Emanuele Frontoni",
      "Marina Paolanti",
      "Tracey P. Lauriault",
      "Michael Stiber",
      "Luciana Duranti",
      "Abdul-Mageed Muhammad"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03712"
  },
  {
    "id": "arXiv:2203.03713",
    "title": "A Predictive Model for Student Performance in Classrooms Using Student  Interactions With an eTextbook",
    "abstract": "With the rise of online eTextbooks and Massive Open Online Courses (MOOCs), a\nhuge amount of data has been collected related to students' learning. With the\ncareful analysis of this data, educators can gain useful insights into the\nperformance of their students and their behavior in learning a particular\ntopic. This paper proposes a new model for predicting student performance based\non an analysis of how students interact with an interactive online eTextbook.\nBy being able to predict students' performance early in the course, educators\ncan easily identify students at risk and provide a suitable intervention. We\nconsidered two main issues the prediction of good/bad performance and the\nprediction of the final exam grade. To build the proposed model, we evaluated\nthe most popular classification and regression algorithms on data from a data\nstructures and algorithms course (CS2) offered in a large public research\nuniversity. Random Forest Regression and Multiple Linear Regression have been\napplied in Regression. While Logistic Regression, decision tree, Random Forest\nClassifier, K Nearest Neighbors, and Support Vector Machine have been applied\nin classification.",
    "descriptor": "\nComments: 21 pages,11 figures\n",
    "authors": [
      "Ahmed Abd Elrahman",
      "Taysir Hassan A Soliman",
      "Ahmed I. Taloba",
      "Mohammed F. Farghally"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03713"
  },
  {
    "id": "arXiv:2203.03714",
    "title": "Cloud Computing-based Higher Education Platforms during the COVID-19  Pandemic",
    "abstract": "Cloud computing has become the infrastructure that supports people's daily\nactivities, business operations, and education delivery around the world. Cloud\ncomputing-based education platforms have been widely applied to assist online\nteaching during the COVID-19 pandemic. This paper examines the impact and\nimportance of cloud computing in remote learning and education. This study\nconducted multiple-case analyses of 22 online platforms of higher education in\nChinese universities during the epidemic. A comparative analysis of the 22\nplatforms revealed that they applied different cloud computing models and tools\nbased on their unique requirements and needs. The study results provide\nstrategic insights to higher education institutions regarding effective\napproaches to applying cloud computing-based platforms for remote education,\nespecially during crisis situations.",
    "descriptor": "",
    "authors": [
      "Hui Han",
      "Silvana Trimi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.03714"
  },
  {
    "id": "arXiv:2203.03715",
    "title": "Needs and Artificial Intelligence",
    "abstract": "Throughout their history, homo sapiens have used technologies to better\nsatisfy their needs. The relation between needs and technology is so\nfundamental that the US National Research Council defined the distinguishing\ncharacteristic of technology as its goal \"to make modifications in the world to\nmeet human needs\". Artificial intelligence (AI) is one of the most promising\nemerging technologies of our time. Similar to other technologies, AI is\nexpected \"to meet [human] needs\". In this article, we reflect on the\nrelationship between needs and AI, and call for the realisation of needs-aware\nAI systems. We argue that re-thinking needs for, through, and by AI can be a\nvery useful means towards the development of realistic approaches for\nSustainable, Human-centric, Accountable, Lawful, and Ethical (HALE) AI systems.\nWe discuss some of the most critical gaps, barriers, enablers, and drivers of\nco-creating future AI-based socio-technical systems in which [human] needs are\nwell considered and met. Finally, we provide an overview of potential threats\nand HALE considerations that should be carefully taken into account, and call\nfor joint, immediate, and interdisciplinary efforts and collaborations.",
    "descriptor": "",
    "authors": [
      "Soheil Human",
      "Ryan Watkins"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03715"
  },
  {
    "id": "arXiv:2203.03716",
    "title": "Open-Ended Knowledge Tracing",
    "abstract": "Knowledge tracing refers to the problem of estimating each student's\nknowledge component/skill mastery level from their past responses to questions\nin educational applications. One direct benefit knowledge tracing methods\nprovide is the ability to predict each student's performance on the future\nquestions. However, one key limitation of most existing knowledge tracing\nmethods is that they treat student responses to questions as binary-valued,\ni.e., whether the responses are correct or incorrect. Response correctness\nanalysis/prediction is easy to navigate but loses important information,\nespecially for open-ended questions: the exact student responses can\npotentially provide much more information about their knowledge states than\nonly response correctness. In this paper, we present our first exploration into\nopen-ended knowledge tracing, i.e., the analysis and prediction of students'\nopen-ended responses to questions in the knowledge tracing setup. We first lay\nout a generic framework for open-ended knowledge tracing before detailing its\napplication to the domain of computer science education with programming\nquestions. We define a series of evaluation metrics in this domain and conduct\na series of quantitative and qualitative experiments to test the boundaries of\nopen-ended knowledge tracing methods on a real-world student code dataset.",
    "descriptor": "",
    "authors": [
      "Naiming Liu",
      "Zichao Wang",
      "Richard G. Baraniuk",
      "Andrew Lan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03716"
  },
  {
    "id": "arXiv:2203.03717",
    "title": "An Analysis of Energy Consumption and Carbon Footprints of  Cryptocurrencies and Possible Solutions",
    "abstract": "There is an urgent need to control global warming caused by humans to achieve\na sustainable future. $CO_2$ levels are rising steadily and while countries\nworldwide are actively moving toward the sustainability goals proposed during\nthe Paris Agreement in 2015, we are still a long way to go from achieving a\nsustainable mode of global operation. The increased popularity of\ncryptocurrencies since the introduction of Bitcoin in 2009 has been accompanied\nby an increasing trend in greenhouse gas emissions and high electrical energy\nconsumption. Popular energy tracking studies (e.g., Digiconomist and the\nCambridge Bitcoin Energy Consumption Index (CBECI)) have estimated energy\nconsumption ranges of 29.96 TWh to 135.12 TWh and 26.41 TWh to 176.98 TWh\nrespectively for Bitcoin as of July 2021, which are equivalent to the energy\nconsumption of countries such as Sweden and Thailand. The latest estimate by\nDigiconomist on carbon footprints shows a 64.18 Mt$CO_2$ emission by Bitcoin as\nof July 2021, close to the emissions by Greece and Oman. This review compiles\nestimates made by various studies from 2018 to 2021. We compare with the energy\nconsumption and carbon footprints of these cryptocurrencies with countries\naround the world, and centralized transaction methods such as Visa. We identify\nthe problems associated with cryptocurrencies, and propose solutions that can\nhelp reduce their energy usage and carbon footprints. Finally, we present case\nstudies on cryptocurrency networks namely, Ethereum 2.0 and Pi Network, with a\ndiscussion on how they solve some of the challenges we have identified.",
    "descriptor": "",
    "authors": [
      "Varun Kohli",
      "Sombuddha Chakravarty",
      "Vinay Chamola",
      "Kuldip Singh Sangwan",
      "Sherali Zeadally"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.03717"
  },
  {
    "id": "arXiv:2203.03718",
    "title": "Towards User-Centered Metrics for Trustworthy AI in Immersive Cyberspace",
    "abstract": "AI plays a key role in current cyberspace and future immersive ecosystems\nthat pinpoint user experiences. Thus, the trustworthiness of such AI systems is\nvital as failures in these systems can cause serious user harm. Although there\nare related works on exploring trustworthy AI (TAI) metrics in the current\ncyberspace, ecosystems towards user-centered services, such as the metaverse,\nare much more complicated in terms of system performance and user experience\nassessment, thus posing challenges for the applicability of existing\napproaches. Thus, we give an overlook on fairness, privacy and robustness,\nacross the historical path from existing approaches. Eventually, we propose a\nresearch agenda towards systematic yet user-centered TAI in immersive\necosystems.",
    "descriptor": "",
    "authors": [
      "Pengyuan Zhou",
      "Benjamin Finley",
      "Lik-Hang Lee",
      "Yong Liao",
      "Haiyong Xie",
      "Pan Hui"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03718"
  },
  {
    "id": "arXiv:2203.03719",
    "title": "Biometric recognition: why not massively adopted yet?",
    "abstract": "Although there has been a dramatically reduction on the prices of capturing\ndevices and an increase on computing power in the last decade, it seems that\nbiometric systems are still far from massive adoption for civilian\napplications. This paper deals with the causes of this phenomenon, as well as\nsome misconceptions regarding biometric identification.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Marcos Faundez-Zanuy"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03719"
  },
  {
    "id": "arXiv:2203.03720",
    "title": "Exploring Fairness in District-based Multi-party Elections under  different Voting Rules using Stochastic Simulations",
    "abstract": "Many democratic societies use district-based elections, where the region\nunder consideration is geographically divided into districts and a\nrepresentative is chosen for each district based on the preferences of the\nelectors who reside there. These representatives belong to political parties,\nand the executive powers are acquired by that party which has a majority of the\nelected district representatives. In most systems, each elector can express\npreference for one candidate, though they may have a complete or partial\nranking of the candidates/parties. We show that this can lead to situations\nwhere many electors are dissatisfied with the election results, which is not\ndesirable in a democracy. The results may be biased towards the supporters of a\nparticular party, and against others. Inspired by current literature on\nfairness of Machine Learning algorithms, we define measures of fairness to\nquantify the satisfaction of electors, irrespective of their political choices.\nWe also consider alternative election policies using concepts of voting rules\nand rank aggregation, to enable voters to express their detailed preferences\nwithout making the electoral process cumbersome or opaque. We then evaluate\nthese policies using the aforementioned fairness measures with the help of\nMonte Carlo simulations. Such simulations are obtained using a proposed\nstochastic model for election simulation, that takes into account community\nidentities of electors and its role in influencing their residence and\npolitical preferences. We show that this model can simulate actual multi-party\nelections in India. Through extensive simulations, we find that allowing voters\nto provide 2 preferences reduces the disparity between supporters of different\nparties in terms of the election result.",
    "descriptor": "",
    "authors": [
      "Adway Mitra"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.03720"
  },
  {
    "id": "arXiv:2203.03722",
    "title": "Cognitive Diagnosis with Explicit Student Vector Estimation and  Unsupervised Question Matrix Learning",
    "abstract": "Cognitive diagnosis is an essential task in many educational applications.\nMany solutions have been designed in the literature. The deterministic input,\nnoisy \"and\" gate (DINA) model is a classical cognitive diagnosis model and can\nprovide interpretable cognitive parameters, e.g., student vectors. However, the\nassumption of the probabilistic part of DINA is too strong, because it assumes\nthat the slip and guess rates of questions are student-independent. Besides,\nthe question matrix (i.e., Q-matrix) recording the skill distribution of the\nquestions in the cognitive diagnosis domain often requires precise labels given\nby domain experts. Thus, we propose an explicit student vector estimation\n(ESVE) method to estimate the student vectors of DINA with a local\nself-consistent test, which does not rely on any assumptions for the\nprobabilistic part of DINA. Then, based on the estimated student vectors, the\nprobabilistic part of DINA can be modified to a student dependent model that\nthe slip and guess rates are related to student vectors. Furthermore, we\npropose an unsupervised method called heuristic bidirectional calibration\nalgorithm (HBCA) to label the Q-matrix automatically, which connects the\nquestion difficulty relation and the answer results for initialization and uses\nthe fault tolerance of ESVE-DINA for calibration. The experimental results on\ntwo real-world datasets show that ESVE-DINA outperforms the DINA model on\naccuracy and that the Q-matrix labeled automatically by HBCA can achieve\nperformance comparable to that obtained with the manually labeled Q-matrix when\nusing the same model structure.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Lu Dong",
      "Zhenhua Ling",
      "Qiang Ling",
      "Zefeng Lai"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.03722"
  },
  {
    "id": "arXiv:2203.03723",
    "title": "Judging the algorithm: A case study on the risk assessment tool for  gender-based violence implemented in the Basque country",
    "abstract": "Since 2010, the output of a risk assessment tool that predicts how likely an\nindividual is to commit severe violence against their partner has been\nintegrated within the Basque country courtrooms. The EPV-R, the tool developed\nto assist police officers during the assessment of gender-based violence cases,\nwas also incorporated to assist the decision-making of judges. With\ninsufficient training, judges are exposed to an algorithmic output that\ninfluences the human decision of adopting measures in cases of gender-based\nviolence.\nIn this paper, we examine the risks, harms and limits of algorithmic\ngovernance within the context of gender-based violence. Through the lens of an\nSpanish judge exposed to this tool, we analyse how the EPV-R is impacting on\nthe justice system. Moving beyond the risks of unfair and biased algorithmic\noutputs, we examine legal, social and technical pitfalls such as opaque\nimplementation, efficiency's paradox and feedback loop, that could led to\nunintended consequences on women who suffer gender-based violence. Our\ninterdisciplinary framework highlights the importance of understanding the\nimpact and influence of risk assessment tools within judicial decision-making\nand increase awareness about its implementation in this context.",
    "descriptor": "\nComments: 18 pages, 5 figures, 1 table\n",
    "authors": [
      "Valdivia Ana",
      "Hyde-Vaamonde Cari",
      "Garc\u00eda-Marcos Juli\u00e1n"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.03723"
  },
  {
    "id": "arXiv:2203.03724",
    "title": "A New Era: Intelligent Tutoring Systems Will Transform Online Learning  for Millions",
    "abstract": "Despite artificial intelligence (AI) having transformed major aspects of our\nsociety, less than a fraction of its potential has been explored, let alone\ndeployed, for education. AI-powered learning can provide millions of learners\nwith a highly personalized, active and practical learning experience, which is\nkey to successful learning. This is especially relevant in the context of\nonline learning platforms. In this paper, we present the results of a\ncomparative head-to-head study on learning outcomes for two popular online\nlearning platforms (n=199 participants): A MOOC platform following a\ntraditional model delivering content using lecture videos and multiple-choice\nquizzes, and the Korbit learning platform providing a highly personalized,\nactive and practical learning experience. We observe a huge and statistically\nsignificant increase in the learning outcomes, with students on the Korbit\nplatform providing full feedback resulting in higher course completion rates\nand achieving learning gains 2 to 2.5 times higher than both students on the\nMOOC platform and students in a control group who don't receive personalized\nfeedback on the Korbit platform. The results demonstrate the tremendous impact\nthat can be achieved with a personalized, active learning AI-powered system.\nMaking this technology and learning experience available to millions of\nlearners around the world will represent a significant leap forward towards the\ndemocratization of education.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Francois St-Hilaire",
      "Dung Do Vu",
      "Antoine Frau",
      "Nathan Burns",
      "Farid Faraji",
      "Joseph Potochny",
      "Stephane Robert",
      "Arnaud Roussel",
      "Selene Zheng",
      "Taylor Glazier",
      "Junfel Vincent Romano",
      "Robert Belfer",
      "Muhammad Shayan",
      "Ariella Smofsky",
      "Tommy Delarosbil",
      "Seulmin Ahn",
      "Simon Eden-Walker",
      "Kritika Sony",
      "Ansona Onyi Ching",
      "Sabina Elkins",
      "Anush Stepanyan",
      "Adela Matajova",
      "Victor Chen",
      "Hossein Sahraei",
      "Robert Larson",
      "Nadia Markova",
      "Andrew Barkett",
      "Laurent Charlin",
      "Yoshua Bengio",
      "Iulian Vlad Serban",
      "Ekaterina Kochmar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03724"
  },
  {
    "id": "arXiv:2203.03726",
    "title": "The Braess Paradox in Dynamic Traffic",
    "abstract": "The Braess's Paradox (BP) is the observation that adding one or more roads to\nthe existing road network will counter-intuitively increase traffic congestion\nand slow down the overall traffic flow. Previously, the existence of the BP is\nmodeled using the static traffic assignment model, which solves for the user\nequilibrium subject to network flow conservation to find the equilibrium state\nand distributes all vehicles instantaneously. Such approach neglects the\ndynamic nature of real-world traffic, including vehicle behaviors and the\ninteraction between vehicles and the infrastructure. As such, this article\nproposes a dynamic traffic network model and empirically validates the\nexistence of the BP under dynamic traffic. In particular, we use\nmicrosimulation environment to study the impacts of an added path on a grid\nnetwork. We explore how the network flow, vehicle travel time, and network\ncapacity respond, as well as when the BP will occur.",
    "descriptor": "\nComments: Submitted to 2022 IEEE Intelligent Transportation Systems Conference (ITSC)\n",
    "authors": [
      "Dingyi Zhuang",
      "Yuzhu Huang",
      "Vindula Jayawardana",
      "Jinhua Zhao",
      "Dajiang Suo",
      "Cathy Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computers and Society (cs.CY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03726"
  },
  {
    "id": "arXiv:2203.03727",
    "title": "Barlow constrained optimization for Visual Question Answering",
    "abstract": "Visual question answering is a vision-and-language multimodal task, that aims\nat predicting answers given samples from the question and image modalities.\nMost recent methods focus on learning a good joint embedding space of images\nand questions, either by improving the interaction between these two\nmodalities, or by making it a more discriminant space. However, how informative\nthis joint space is, has not been well explored. In this paper, we propose a\nnovel regularization for VQA models, Constrained Optimization using Barlow's\ntheory (COB), that improves the information content of the joint space by\nminimizing the redundancy. It reduces the correlation between the learned\nfeature components and thereby disentangles semantic concepts. Our model also\naligns the joint space with the answer embedding space, where we consider the\nanswer and image+question as two different `views' of what in essence is the\nsame semantic information. We propose a constrained optimization policy to\nbalance the categorical and redundancy minimization forces. When built on the\nstate-of-the-art GGE model, the resulting model improves VQA accuracy by 1.4%\nand 4% on the VQA-CP v2 and VQA v2 datasets respectively. The model also\nexhibits better interpretability.",
    "descriptor": "",
    "authors": [
      "Abhishek Jha",
      "Badri N. Patro",
      "Luc Van Gool",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03727"
  },
  {
    "id": "arXiv:2203.03729",
    "title": "Robustness and Usefulness in AI Explanation Methods",
    "abstract": "Explainability in machine learning has become incredibly important as machine\nlearning-powered systems become ubiquitous and both regulation and public\nsentiment begin to demand an understanding of how these systems make decisions.\nAs a result, a number of explanation methods have begun to receive widespread\nadoption. This work summarizes, compares, and contrasts three popular\nexplanation methods: LIME, SmoothGrad, and SHAP. We evaluate these methods with\nrespect to: robustness, in the sense of sample complexity and stability;\nunderstandability, in the sense that provided explanations are consistent with\nuser expectations; and usability, in the sense that the explanations allow for\nthe model to be modified based on the output. This work concludes that current\nexplanation methods are insufficient; that putting faith in and adopting these\nmethods may actually be worse than simply not using them.",
    "descriptor": "",
    "authors": [
      "Erick Galinkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03729"
  },
  {
    "id": "arXiv:2203.03730",
    "title": "Provably Accurate and Scalable Linear Classifiers in Hyperbolic Spaces",
    "abstract": "Many high-dimensional practical data sets have hierarchical structures\ninduced by graphs or time series. Such data sets are hard to process in\nEuclidean spaces and one often seeks low-dimensional embeddings in other space\nforms to perform the required learning tasks. For hierarchical data, the space\nof choice is a hyperbolic space because it guarantees low-distortion embeddings\nfor tree-like structures. The geometry of hyperbolic spaces has properties not\nencountered in Euclidean spaces that pose challenges when trying to rigorously\nanalyze algorithmic solutions. We propose a unified framework for learning\nscalable and simple hyperbolic linear classifiers with provable performance\nguarantees. The gist of our approach is to focus on Poincar\\'e ball models and\nformulate the classification problems using tangent space formalisms. Our\nresults include a new hyperbolic perceptron algorithm as well as an efficient\nand highly accurate convex optimization setup for hyperbolic support vector\nmachine classifiers. Furthermore, we adapt our approach to accommodate\nsecond-order perceptrons, where data is preprocessed based on second-order\ninformation (correlation) to accelerate convergence, and strategic perceptrons,\nwhere potentially manipulated data arrives in an online manner and decisions\nare made sequentially. The excellent performance of the Poincar\\'e second-order\nand strategic perceptrons shows that the proposed framework can be extended to\ngeneral machine learning problems in hyperbolic spaces. Our experimental\nresults, pertaining to synthetic, single-cell RNA-seq expression measurements,\nCIFAR10, Fashion-MNIST and mini-ImageNet, establish that all algorithms\nprovably converge and have complexity comparable to those of their Euclidean\ncounterparts. Accompanying codes can be found at:\nhttps://github.com/thupchnsky/PoincareLinearClassification.",
    "descriptor": "",
    "authors": [
      "Chao Pan",
      "Eli Chien",
      "Puoya Tabaghi",
      "Jianhao Peng",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03730"
  },
  {
    "id": "arXiv:2203.03732",
    "title": "A Push-Relabel Based Additive Approximation for Optimal Transport",
    "abstract": "Optimal Transport is a popular distance metric for measuring similarity\nbetween distributions. Exact algorithms for computing Optimal Transport can be\nslow, which has motivated the development of approximate numerical solvers\n(e.g. Sinkhorn method). We introduce a new and very simple combinatorial\napproach to find an $\\varepsilon$-approximation of the OT distance. Our\nalgorithm achieves a near-optimal execution time of $O(n^2/\\varepsilon^2)$ for\ncomputing OT distance and, for the special case of the assignment problem, the\nexecution time improves to $O(n^2/\\varepsilon)$. Our algorithm is based on the\npush-relabel framework for min-cost flow problems.\nUnlike the other combinatorial approach (Lahn, Mulchandani and Raghvendra,\nNeurIPS 2019) which does not have a fast parallel implementation, our algorithm\nhas a parallel execution time of $O(\\log n/\\varepsilon^2)$. Interestingly,\nunlike the Sinkhorn algorithm, our method also readily provides a compact\ntransport plan as well as a solution to an approximate version of the dual\nformulation of the OT problem, both of which have numerous applications in\nMachine Learning. For the assignment problem, we provide both a CPU\nimplementation as well as an implementation that exploits GPU parallelism.\nExperiments suggest that our algorithm is faster than the Sinkhorn algorithm,\nboth in terms of CPU and GPU implementations, especially while computing\nmatchings with a high accuracy.",
    "descriptor": "",
    "authors": [
      "Nathaniel Lahn",
      "Sharath Raghvendra",
      "Kaiyi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.03732"
  },
  {
    "id": "arXiv:2203.03737",
    "title": "Battery Cloud with Advanced Algorithms",
    "abstract": "A Battery Cloud or cloud battery management system leverages the cloud\ncomputational power and data storage to improve battery safety, performance,\nand economy. This work will present the Battery Cloud that collects measured\nbattery data from electric vehicles and energy storage systems. Advanced\nalgorithms are applied to improve battery performance. Using remote vehicle\ndata, we train and validate an artificial neural network to estimate pack SOC\nduring vehicle charging. The strategy is then tested on vehicles. Furthermore,\nhigh accuracy and onboard battery state of health estimation methods for\nelectric vehicles are developed based on the differential voltage (DVA) and\nincremental capacity analysis (ICA). Using cycling data from battery cells at\nvarious temperatures, we extract the charging cycles and calculate the DVA and\nICA curves, from which multiple features are extracted, analyzed, and\neventually used to estimate the state of health. For battery safety, a\ndata-driven thermal anomaly detection method is developed. The method can\ndetect unforeseen anomalies such as thermal runaways at the very early stage.\nWith the further development of the internet of things, more and more battery\ndata will be available. Potential applications of battery cloud also include\nareas such as battery manufacture, recycling, and electric vehicle battery\nswap.",
    "descriptor": "",
    "authors": [
      "Xiaojun Li",
      "David Jauernig",
      "Mengzhu Gao",
      "Trevor Jones"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03737"
  },
  {
    "id": "arXiv:2203.03749",
    "title": "Direct LiDAR-Inertial Odometry",
    "abstract": "This paper proposes a new LiDAR-inertial odometry framework that generates\naccurate state estimates and detailed maps in real-time on resource-constrained\nmobile robots. Our Direct LiDAR-Inertial Odometry (DLIO) algorithm utilizes a\nhybrid architecture that combines the benefits of loosely-coupled and\ntightly-coupled IMU integration to enhance reliability and real-time\nperformance while improving accuracy. The proposed architecture has two key\nelements. The first is a fast keyframe-based LiDAR scan-matcher that builds an\ninternal map by registering dense point clouds to a local submap with a\ntranslational and rotational prior generated by a nonlinear motion model. The\nsecond is a factor graph and high-rate propagator that fuses the output of the\nscan-matcher with preintegrated IMU measurements for up-to-date pose, velocity,\nand bias estimates. These estimates enable us to accurately deskew the next\npoint cloud using a nonlinear kinematic model for precise motion correction, in\naddition to initializing the next scan-to-map optimization prior. We\ndemonstrate DLIO's superior localization accuracy, map quality, and lower\ncomputational overhead by comparing it to the state-of-the-art using multiple\nbenchmark, public, and self-collected datasets on both consumer and hobby-grade\nhardware.",
    "descriptor": "",
    "authors": [
      "Kenny Chen",
      "Ryan Nemiroff",
      "Brett T. Lopez"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03749"
  },
  {
    "id": "arXiv:2203.03751",
    "title": "Class Fairness in Online Matching",
    "abstract": "In the classical version of online bipartite matching, there is a given set\nof offline vertices (aka agents) and another set of vertices (aka items) that\narrive online. When each item arrives, its incident edges -- the agents who\nlike the item -- are revealed and the algorithm must irrevocably match the item\nto such agents. We initiate the study of class fairness in this setting, where\nagents are partitioned into a set of classes and the matching is required to be\nfair with respect to the classes. We adopt popular fairness notions from the\nfair division literature such as envy-freeness (up to one item),\nproportionality, and maximin share fairness to our setting. Our class versions\nof these notions demand that all classes, regardless of their sizes, receive a\nfair treatment. We study deterministic and randomized algorithms for matching\nindivisible items (leading to integral matchings) and for matching divisible\nitems (leading to fractional matchings). We design and analyze three novel\nalgorithms. For matching indivisible items, we propose an\nadaptive-priority-based algorithm, MATCH-AND-SHIFT, prove that it achieves\n1/2-approximation of both class envy-freeness up to one item and class maximin\nshare fairness, and show that each guarantee is tight. For matching divisible\nitems, we design a water-filling-based algorithm, EQUAL-FILLING, that achieves\n(1-1/e)-approximation of class envy-freeness and class proportionality; we\nprove (1-1/e) to be tight for class proportionality and establish a 3/4 upper\nbound on class envy-freeness. Finally, we build upon EQUAL-FILLING to design a\nrandomized algorithm for matching indivisible items, EQAUL-FILLING-OCS, which\nachieves 0.593-approximation of class proportionality. The algorithm and its\nanalysis crucially leverage the recently introduced technique of online\ncorrelated selection (OCS) [Fahrbach et al., 2020].",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Hadi Hosseini",
      "Zhiyi Huang",
      "Ayumi Igarashi",
      "Nisarg Shah"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2203.03751"
  },
  {
    "id": "arXiv:2203.03756",
    "title": "Flat minima generalize for low-rank matrix recovery",
    "abstract": "Empirical evidence suggests that for a variety of overparameterized nonlinear\nmodels, most notably in neural network training, the growth of the loss around\na minimizer strongly impacts its performance. Flat minima -- those around which\nthe loss grows slowly -- appear to generalize well. This work takes a step\ntowards understanding this phenomenon by focusing on the simplest class of\noverparameterized nonlinear models: those arising in low-rank matrix recovery.\nWe analyze overparameterized matrix and bilinear sensing, robust PCA,\ncovariance matrix estimation, and single hidden layer neural networks with\nquadratic activation functions. In all cases, we show that flat minima,\nmeasured by the trace of the Hessian, exactly recover the ground truth under\nstandard statistical assumptions. For matrix completion, we establish weak\nrecovery, although empirical evidence suggests exact recovery holds here as\nwell. We complete the paper with synthetic experiments that illustrate our\nfindings.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Lijun Ding",
      "Dmitriy Drusvyatskiy",
      "Maryam Fazel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.03756"
  },
  {
    "id": "arXiv:2203.03759",
    "title": "IT5: Large-scale Text-to-text Pretraining for Italian Language  Understanding and Generation",
    "abstract": "The T5 model and its unified text-to-text paradigm contributed in advancing\nthe state-of-the-art for many natural language processing tasks. While some\nmultilingual variants of the T5 model have recently been introduced, their\nperformances were found to provide suboptimal performances for languages other\nthan English if compared to monolingual variants. We are motivated by these\nfindings to introduce IT5, the first family of encoder-decoder transformer\nmodels pretrained specifically on Italian. We perform a thorough cleaning of a\nweb-crawled Italian corpus including more than 40 billion words and use it to\npretrain three IT5 models of different sizes. The performance of IT5 models and\ntheir multilingual counterparts is then evaluated on a broad range of natural\nlanguage understanding and generation benchmarks for Italian. We find the\nmonolingual IT5 models to provide the best scale-to-performance ratio across\ntested models, consistently outperforming their multilingual counterparts and\nsetting a new state-of-the-art for most Italian conditional language generation\ntasks.",
    "descriptor": "\nComments: 13 pages, 7 tables, 1 figure. Code and checkpoints available: this https URL\n",
    "authors": [
      "Gabriele Sarti",
      "Malvina Nissim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03759"
  },
  {
    "id": "arXiv:2203.03761",
    "title": "The Fundamental Price of Secure Aggregation in Differentially Private  Federated Learning",
    "abstract": "We consider the problem of training a $d$ dimensional model with distributed\ndifferential privacy (DP) where secure aggregation (SecAgg) is used to ensure\nthat the server only sees the noisy sum of $n$ model updates in every training\nround. Taking into account the constraints imposed by SecAgg, we characterize\nthe fundamental communication cost required to obtain the best accuracy\nachievable under $\\varepsilon$ central DP (i.e. under a fully trusted server\nand no communication constraints). Our results show that $\\tilde{O}\\left(\n\\min(n^2\\varepsilon^2, d) \\right)$ bits per client are both sufficient and\nnecessary, and this fundamental limit can be achieved by a linear scheme based\non sparse random projections. This provides a significant improvement relative\nto state-of-the-art SecAgg distributed DP schemes which use\n$\\tilde{O}(d\\log(d/\\varepsilon^2))$ bits per client.\nEmpirically, we evaluate our proposed scheme on real-world federated learning\ntasks. We find that our theoretical analysis is well matched in practice. In\nparticular, we show that we can reduce the communication cost significantly to\nunder $1.2$ bits per parameter in realistic privacy settings without decreasing\ntest-time performance. Our work hence theoretically and empirically specifies\nthe fundamental price of using SecAgg.",
    "descriptor": "",
    "authors": [
      "Wei-Ning Chen",
      "Christopher A. Choquette-Choo",
      "Peter Kairouz",
      "Ananda Theertha Suresh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.03761"
  },
  {
    "id": "arXiv:2203.03762",
    "title": "Defending Graph Convolutional Networks against Dynamic Graph  Perturbations via Bayesian Self-supervision",
    "abstract": "In recent years, plentiful evidence illustrates that Graph Convolutional\nNetworks (GCNs) achieve extraordinary accomplishments on the node\nclassification task. However, GCNs may be vulnerable to adversarial attacks on\nlabel-scarce dynamic graphs. Many existing works aim to strengthen the\nrobustness of GCNs; for instance, adversarial training is used to shield GCNs\nagainst malicious perturbations. However, these works fail on dynamic graphs\nfor which label scarcity is a pressing issue. To overcome label scarcity,\nself-training attempts to iteratively assign pseudo-labels to highly confident\nunlabeled nodes but such attempts may suffer serious degradation under dynamic\ngraph perturbations. In this paper, we generalize noisy supervision as a kind\nof self-supervised learning method and then propose a novel Bayesian\nself-supervision model, namely GraphSS, to address the issue. Extensive\nexperiments demonstrate that GraphSS can not only affirmatively alert the\nperturbations on dynamic graphs but also effectively recover the prediction of\na node classifier when the graph is under such perturbations. These two\nadvantages prove to be generalized over three classic GCNs across five public\ngraph datasets.",
    "descriptor": "\nComments: The paper is accepted by AAAI 2022\n",
    "authors": [
      "Jun Zhuang",
      "Mohammad Al Hasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03762"
  },
  {
    "id": "arXiv:2203.03764",
    "title": "Towards Flexible Anonymous Networks",
    "abstract": "Anonymous Communication designs such as Tor build their security upon\ndistributing the trust in many volunteers running relays in many locations\nglobally. These volunteers run the Tor code upon various operating systems,\neach potentially having different software packaging policies. In practice, it\nleads to a heterogeneous network in which many versions of the same Tor\nsoftware exist, with a different set of protocol features. Because of the\nheterogeneous aspect of the network, the maintainers had to come up with\nforward-compatible protocol design strategies. Their role is to guarantee that\ndifferent versions of the Tor software interact without unrecoverable errors.\nIn this work, we cast the protocol tolerance enabled with forward-compatible\nprotocol considerations as a double-edged sword. Despite being beneficial for\nthe developers, we argue that protocol tolerance is the systemic cause behind\nmany strong attacks against Tor in the past fifteen years.\nTo address this issue, we propose FAN for Flexible Anonymous Network, a new\nsoftware architecture for volunteer-based distributed networks that shifts the\ndependence away from protocol tolerance without losing the ability for the\ndevelopers to ensure the continuous evolution of their software. We realize an\nimplementation, evaluate the overheads and, experiment with several of FAN's\nbenefits to defend against a severe attack still applicable to Tor today.",
    "descriptor": "\nComments: 17 pages, including bibliography and appendices. Note: This version of the paper does not yet address the most recent comments received (March 4, 2022) from its IEEE S&P submission\n",
    "authors": [
      "Florentin Rochet",
      "Tariq Elahi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.03764"
  },
  {
    "id": "arXiv:2203.03768",
    "title": "CrowdFormer: Weakly-supervised Crowd counting with Improved  Generalizability",
    "abstract": "Convolutional neural networks (CNNs) have dominated the field of computer\nvision for nearly a decade due to their strong ability to learn local features.\nHowever, due to their limited receptive field, CNNs fail to model the global\ncontext. On the other hand, transformer, an attention-based architecture can\nmodel the global context easily. Despite this, there are limited studies that\ninvestigate the effectiveness of transformers in crowd counting. In addition,\nthe majority of the existing crowd counting methods are based on the regression\nof density maps which requires point-level annotation of each person present in\nthe scene. This annotation task is laborious and also error-prone. This has led\nto increased focus on weakly-supervised crowd counting methods which require\nonly the count-level annotations. In this paper, we propose a weakly-supervised\nmethod for crowd counting using a pyramid vision transformer. We have conducted\nextensive evaluations to validate the effectiveness of the proposed method. Our\nmethod is comparable to the state-of-the-art on the benchmark crowd datasets.\nMore importantly, it shows remarkable generalizability.",
    "descriptor": "",
    "authors": [
      "Siddharth Singh Savner",
      "Vivek Kanhangad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03768"
  },
  {
    "id": "arXiv:2203.03771",
    "title": "Static Prediction of Runtime Errors by Learning to Execute Programs with  External Resource Descriptions",
    "abstract": "The execution behavior of a program often depends on external resources, such\nas program inputs or file contents, and so cannot be run in isolation.\nNevertheless, software developers benefit from fast iteration loops where\nautomated tools identify errors as early as possible, even before programs can\nbe compiled and run. This presents an interesting machine learning challenge:\ncan we predict runtime errors in a \"static\" setting, where program execution is\nnot possible? Here, we introduce a real-world dataset and task for predicting\nruntime errors, which we show is difficult for generic models like\nTransformers. We approach this task by developing an interpreter-inspired\narchitecture with an inductive bias towards mimicking program executions, which\nmodels exception handling and \"learns to execute\" descriptions of the contents\nof external resources. Surprisingly, we show that the model can also predict\nthe location of the error, despite being trained only on labels indicating the\npresence/absence and kind of error. In total, we present a practical and\ndifficult-yet-approachable challenge problem related to learning program\nexecution and we demonstrate promising new capabilities of interpreter-inspired\nmachine learning models for code.",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "David Bieber",
      "Rishab Goel",
      "Daniel Zheng",
      "Hugo Larochelle",
      "Daniel Tarlow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03771"
  },
  {
    "id": "arXiv:2203.03774",
    "title": "Exploring Physical-Based Constraints in Short-Term Load Forecasting: A  Defense Mechanism Against Cyberattack",
    "abstract": "Short-term load forecasting is an essential task that supports utilities to\nschedule generating sufficient power for balancing supply and demand, and can\nbecome an attractive target for cyber attacks. It has been shown that the power\nsystem state estimation is vulnerable to false data injection attacks.\nSimilarly, false data injection on input variables can result in large forecast\nerrors. The load forecasting system should have a protective mechanism to\nmitigate such attacks. One approach is to model physical system constraints\nthat would identify anomalies. This study investigates possible constraints\nassociated with a load forecasting application. Looking at regional forecasted\nloads, we analyze the relation between each zone through similarity measures\nused in time series in order to identify constraints. Comprehensive results for\nhistorical ERCOT load data indicate variation in the measures recognizing the\nexistence of malicious action. Still, these static measures can not be\nconsidered an efficient index across different scenarios.",
    "descriptor": "\nComments: 2022 IEEE Power and Energy Society General Meeting,17-21 July 2022, Denver, Colorado, USA\n",
    "authors": [
      "Mojtaba Dezvarei",
      "Kevin Tomsovic",
      "Jinyuan Stella Sun",
      "Seddik M. Djouadi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03774"
  },
  {
    "id": "arXiv:2203.03776",
    "title": "Zero-delay Consistent and Smooth Trainable Interpolation",
    "abstract": "The question of how to produce a smooth interpolating curve from a stream of\ndata points is addressed in this paper. To this end, we formalize the concept\nof real-time interpolator (RTI): a trainable unit that recovers smooth signals\nthat are consistent with the received input samples in an online manner.\nSpecifically, an RTI works under the requirement of producing a function\nsection immediately after a sample is received (zero delay), without changing\nthe reconstructed signal in past time sections. This work formulates the design\nof spline-based RTIs as a bi-level optimization problem. Their training\nconsists in minimizing the average curvature of the interpolated signals over a\nset of example sequences. The latter are representative of the nature of the\ndata sequence to be interpolated, allowing to tailor the RTI to a specific\nsignal source. Our overall design allows for different possible schemes. In\nthis work, we present two approaches, namely, the parametrized RTI and the\nrecurrent neural network (RNN)-based RTI, including their architecture and\nproperties. Experimental results show that the two proposed RTIs can be trained\nin a data-driven fashion to achieve improved performance (in terms of the\ncurvature loss metric) with respect to a myopic-type RTI that only exploits the\nlocal information at each time sample, while maintaining smooth, zero-delay,\nand consistency requirements.",
    "descriptor": "\nComments: 12 pages, 7 figures, submitted to IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Emilio Ruiz-Moreno",
      "Luis Miguel L\u00f3pez-Ramos",
      "Baltasar Beferull-Lozano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.03776"
  },
  {
    "id": "arXiv:2203.03778",
    "title": "A DG/CR discretization for the variational phase-field approach to  fracture",
    "abstract": "Variational phase-field models of fracture are widely used to simulate\nnucleation and propagation of cracks in brittle materials. They are based on\nthe approximation of the solutions of free-discontinuity fracture energy by two\nsmooth function: a displacement and a damage field. Their numerical\nimplementation is typically based on the discretization of both fields by nodal\nP^1 Lagrange finite elements. In this article, we propose a nonconforming\napproximation by discontinuous elements for the displacement and nonconforming\nelements, whose gradient is more isotropic, for the damage. The handling of the\nnonconformity is derived from that of heterogeneous diffusion problems. We\nillustrate the robustness and versatility of the proposed method through series\nof numerical examples.",
    "descriptor": "",
    "authors": [
      "Frederic Marazzato",
      "Blaise Bourdin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.03778"
  },
  {
    "id": "arXiv:2203.03781",
    "title": "Double-Sided Beamforming in OWC Systems Using Omni-Digital  Reconfigurable Intelligent Surfaces",
    "abstract": "In this paper, we introduce a variant of reconfigurable intelligent surfaces\n(RISs) called omni-digital-RISs (DRISs), which allow multiple physical\nprocesses, with application to optical wireless communications systems. The\nproposed omni-DRIS contains both reflectors and refractive elements, as well as\nelements that perform both simultaneously. We describe and explain the concept\nof omni-DRIS, suggest and analyze an omni-DRIS coding structure, discuss\nmetamaterials to be used, and provide a design example. Furthermore, we\ndemonstrate that the achievable rate of an omni-DRIS system depends on the\nnumber of omni-DRIS elements, bits per phase shift, and the number of unused\nelements. In addition, we show that the achievable rate upper bound is related\nto the number of omni-DRIS elements, and conclude by discussing future research\ndirections.",
    "descriptor": "",
    "authors": [
      "Alain R. Ndjiongue",
      "Telex M. N. Ngatched",
      "Octavia A. Dobre",
      "Harald Haas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.03781"
  },
  {
    "id": "arXiv:2203.03792",
    "title": "Aggregate Queries on Knowledge Graphs: Fast Approximation with  Semantic-aware Sampling",
    "abstract": "A knowledge graph (KG) manages large-scale and real-world facts as a big\ngraph in a schema-flexible manner. Aggregate query is a fundamental query over\nKGs, e.g., \"what is the average price of cars produced in Germany?\". Despite\nits importance, answering aggregate queries on KGs has received little\nattention in the literature. Aggregate queries can be supported based on\nfactoid queries, e.g., \"find all cars produced in Germany\", by applying an\nadditional aggregate operation on factoid queries' answers. However, this\nstraightforward method is challenging because both the accuracy and efficiency\nof factoid query processing will seriously impact the performance of aggregate\nqueries. In this paper, we propose a \"sampling-estimation\" model to answer\naggregate queries over KGs, which is the first work to provide an approximate\naggregate result with an effective accuracy guarantee, and without relying on\nfactoid queries. Specifically, we first present a semantic-aware sampling to\ncollect a high-quality random sample through a random walk based on knowledge\ngraph embedding. Then, we propose unbiased estimators for COUNT, SUM, and a\nconsistent estimator for AVG to compute the approximate aggregate results based\non the random sample, with an accuracy guarantee in the form of confidence\ninterval. We extend our approach to support iterative improvement of accuracy,\nand more complex queries with filter, GROUP-BY, and different graph shapes,\ne.g., chain, cycle, star, flower. Extensive experiments over real-world KGs\ndemonstrate the effectiveness and efficiency of our approach.",
    "descriptor": "\nComments: 16 pages, 6 figures, 13 tables\n",
    "authors": [
      "Yuxiang Wang",
      "Arijit Khan",
      "Xiaoliang Xu",
      "Jiahui Jin",
      "Qifan Hong",
      "Tao Fu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.03792"
  },
  {
    "id": "arXiv:2203.03794",
    "title": "YONO: Modeling Multiple Heterogeneous Neural Networks on  Microcontrollers",
    "abstract": "With the advancement of Deep Neural Networks (DNN) and large amounts of\nsensor data from Internet of Things (IoT) systems, the research community has\nworked to reduce the computational and resource demands of DNN to compute on\nlow-resourced microcontrollers (MCUs). However, most of the current work in\nembedded deep learning focuses on solving a single task efficiently, while the\nmulti-tasking nature and applications of IoT devices demand systems that can\nhandle a diverse range of tasks (activity, voice, and context recognition) with\ninput from a variety of sensors, simultaneously.\nIn this paper, we propose YONO, a product quantization (PQ) based approach\nthat compresses multiple heterogeneous models and enables in-memory model\nexecution and switching for dissimilar multi-task learning on MCUs. We first\nadopt PQ to learn codebooks that store weights of different models. Also, we\npropose a novel network optimization and heuristics to maximize the compression\nrate and minimize the accuracy loss. Then, we develop an online component of\nYONO for efficient model execution and switching between multiple tasks on an\nMCU at run time without relying on an external storage device.\nYONO shows remarkable performance as it can compress multiple heterogeneous\nmodels with negligible or no loss of accuracy up to 12.37$\\times$. Besides,\nYONO's online component enables an efficient execution (latency of 16-159 ms\nper operation) and reduces model loading/switching latency and energy\nconsumption by 93.3-94.5% and 93.9-95.0%, respectively, compared to external\nstorage access. Interestingly, YONO can compress various architectures trained\nwith datasets that were not shown during YONO's offline codebook learning phase\nshowing the generalizability of our method. To summarize, YONO shows great\npotential and opens further doors to enable multi-task learning systems on\nextremely resource-constrained devices.",
    "descriptor": "\nComments: Accepted for publication at IPSN 2022\n",
    "authors": [
      "Young D. Kwon",
      "Jagmohan Chauhan",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03794"
  },
  {
    "id": "arXiv:2203.03795",
    "title": "Semantic-Preserving Linguistic Steganography by Pivot Translation and  Semantic-Aware Bins Coding",
    "abstract": "Linguistic steganography (LS) aims to embed secret information into a highly\nencoded text for covert communication. It can be roughly divided to two main\ncategories, i.e., modification based LS (MLS) and generation based LS (GLS).\nUnlike MLS that hides secret data by slightly modifying a given text without\nimpairing the meaning of the text, GLS uses a trained language model to\ndirectly generate a text carrying secret data. A common disadvantage for MLS\nmethods is that the embedding payload is very low, whose return is well\npreserving the semantic quality of the text. In contrast, GLS allows the data\nhider to embed a high payload, which has to pay the high price of\nuncontrollable semantics. In this paper, we propose a novel LS method to modify\na given text by pivoting it between two different languages and embed secret\ndata by applying a GLS-like information encoding strategy. Our purpose is to\nalter the expression of the given text, enabling a high payload to be embedded\nwhile keeping the semantic information unchanged. Experimental results have\nshown that the proposed work not only achieves a high embedding payload, but\nalso shows superior performance in maintaining the semantic consistency and\nresisting linguistic steganalysis.",
    "descriptor": "",
    "authors": [
      "Tianyu Yang",
      "Hanzhou Wu",
      "Biao Yi",
      "Guorui Feng",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03795"
  },
  {
    "id": "arXiv:2203.03796",
    "title": "PAMI-AD: An Activity Detector Exploiting Part-attention and Motion  Information in Surveillance Videos",
    "abstract": "Activity detection in surveillance videos is a challenging task caused by\nsmall objects, complex activity categories, its untrimmed nature, etc. In this\nwork, we propose an effective activity detection system for person-only and\nvehicle-only activities in untrimmed surveillance videos, named PAMI-AD. It\nconsists of four modules, i.e., multi-object tracking, background modeling,\nactivity classifier and post-processing. In particular, we propose a novel\npart-attention mechanism for person-only activities and a simple but strong\nmotion information encoding method for vehicle-only activities. Our proposed\nsystem achieves the best results on the VIRAT dataset. Furthermore, our team\nwon the 1st place in the TRECVID 2021 ActEV challenge.",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Yunhao Du",
      "Zhihang Tong",
      "Junfeng Wan",
      "Binyu Zhang",
      "Yanyun Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03796"
  },
  {
    "id": "arXiv:2203.03797",
    "title": "Learning Sensorimotor Primitives of Sequential Manipulation Tasks from  Visual Demonstrations",
    "abstract": "This work aims to learn how to perform complex robot manipulation tasks that\nare composed of several, consecutively executed low-level sub-tasks, given as\ninput a few visual demonstrations of the tasks performed by a person. The\nsub-tasks consist of moving the robot's end-effector until it reaches a\nsub-goal region in the task space, performing an action, and triggering the\nnext sub-task when a pre-condition is met. Most prior work in this domain has\nbeen concerned with learning only low-level tasks, such as hitting a ball or\nreaching an object and grasping it. This paper describes a new neural\nnetwork-based framework for learning simultaneously low-level policies as well\nas high-level policies, such as deciding which object to pick next or where to\nplace it relative to other objects in the scene. A key feature of the proposed\napproach is that the policies are learned directly from raw videos of task\ndemonstrations, without any manual annotation or post-processing of the data.\nEmpirical results on object manipulation tasks with a robotic arm show that the\nproposed network can efficiently learn from real visual demonstrations to\nperform the tasks, and outperforms popular imitation learning algorithms.",
    "descriptor": "",
    "authors": [
      "Junchi Liang",
      "Bowen Wen",
      "Kostas Bekris",
      "Abdeslam Boularias"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03797"
  },
  {
    "id": "arXiv:2203.03798",
    "title": "New Insights on Reducing Abrupt Representation Change in Online  Continual Learning",
    "abstract": "In the online continual learning paradigm, agents must learn from a changing\ndistribution while respecting memory and compute constraints. Experience Replay\n(ER), where a small subset of past data is stored and replayed alongside new\ndata, has emerged as a simple and effective learning strategy. In this work, we\nfocus on the change in representations of observed data that arises when\npreviously unobserved classes appear in the incoming data stream, and new\nclasses must be distinguished from previous ones. We shed new light on this\nquestion by showing that applying ER causes the newly added classes'\nrepresentations to overlap significantly with the previous classes, leading to\nhighly disruptive parameter updates. Based on this empirical analysis, we\npropose a new method which mitigates this issue by shielding the learned\nrepresentations from drastic adaptation to accommodate new classes. We show\nthat using an asymmetric update rule pushes new classes to adapt to the older\nones (rather than the reverse), which is more effective especially at task\nboundaries, where much of the forgetting typically occurs. Empirical results\nshow significant gains over strong baselines on standard continual learning\nbenchmarks",
    "descriptor": "\nComments: Accepted at ICLR 2022. Code Available at this https URL\n",
    "authors": [
      "Lucas Caccia",
      "Rahaf Aljundi",
      "Nader Asadi",
      "Tinne Tuytelaars",
      "Joelle Pineau",
      "Eugene Belilovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03798"
  },
  {
    "id": "arXiv:2203.03800",
    "title": "Unknown-Aware Object Detection: Learning What You Don't Know from Videos  in the Wild",
    "abstract": "Building reliable object detectors that can detect out-of-distribution (OOD)\nobjects is critical yet underexplored. One of the key challenges is that models\nlack supervision signals from unknown data, producing overconfident predictions\non OOD objects. We propose a new unknown-aware object detection framework\nthrough Spatial-Temporal Unknown Distillation (STUD), which distills unknown\nobjects from videos in the wild and meaningfully regularizes the model's\ndecision boundary. STUD first identifies the unknown candidate object proposals\nin the spatial dimension, and then aggregates the candidates across multiple\nvideo frames to form a diverse set of unknown objects near the decision\nboundary. Alongside, we employ an energy-based uncertainty regularization loss,\nwhich contrastively shapes the uncertainty space between the in-distribution\nand distilled unknown objects. STUD establishes the state-of-the-art\nperformance on OOD detection tasks for object detection, reducing the FPR95\nscore by over 10% compared to the previous best method. Code is available at\nhttps://github.com/deeplearning-wisc/stud.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Xuefeng Du",
      "Xin Wang",
      "Gabriel Gozum",
      "Yixuan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03800"
  },
  {
    "id": "arXiv:2203.03802",
    "title": "Understanding Iterative Revision from Human-Written Text",
    "abstract": "Writing is, by nature, a strategic, adaptive, and more importantly, an\niterative process. A crucial part of writing is editing and revising the text.\nPrevious works on text revision have focused on defining edit intention\ntaxonomies within a single domain or developing computational models with a\nsingle level of edit granularity, such as sentence-level edits, which differ\nfrom human's revision cycles. This work describes IteraTeR: the first\nlarge-scale, multi-domain, edit-intention annotated corpus of iteratively\nrevised text. In particular, IteraTeR is collected based on a new framework to\ncomprehensively model the iterative text revisions that generalize to various\ndomains of formal writing, edit intentions, revision depths, and granularities.\nWhen we incorporate our annotated edit intentions, both generative and\nedit-based text revision models significantly improve automatic evaluations.\nThrough our work, we better understand the text revision process, making vital\nconnections between edit intentions and writing quality, enabling the creation\nof diverse corpora to support computational modeling of iterative text\nrevisions.",
    "descriptor": "\nComments: To appear in ACL2022\n",
    "authors": [
      "Wanyu Du",
      "Vipul Raheja",
      "Dhruv Kumar",
      "Zae Myung Kim",
      "Melissa Lopez",
      "Dongyeop Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.03802"
  },
  {
    "id": "arXiv:2203.03805",
    "title": "Discrete Robust Control of Robot Manipulators using an Uncertainty and  Disturbance Estimator",
    "abstract": "This article presents the design of a robust observer based on the\ndiscrete-time formulation of Uncertainty and Disturbance Estimator (UDE), a\nwell-known robust control technique, for the purpose of controlling robot\nmanipulators. The design results in a complete closed-loop, robust,\ncontroller--observer structure. The observer incorporates the estimate of the\noverall uncertainty associated with the plant, in order to mimic its dynamics,\nand the control law is generated using an auxiliary error instead of state\ntracking error. A detailed qualitative and quantitative stability analysis is\nprovided, and simulations are performed on the two-link robot manipulator\nsystem. Further, a comparative study with well-known control strategies for\nrobot manipulators is presented. The results demonstrate the efficacy of the\nproposed technique, with better tracking performance and lower control energy\ncompared to other strategies.",
    "descriptor": "\nComments: 20 pages, 7 figures, Submitted to ASME Journal of Dynamic Systems, Measurement and Control\n",
    "authors": [
      "Ram Padmanabhan",
      "Maithili Shetty",
      "T. S. Chandar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03805"
  },
  {
    "id": "arXiv:2203.03806",
    "title": "Panoramic Human Activity Recognition",
    "abstract": "To obtain a more comprehensive activity understanding for a crowded scene, in\nthis paper, we propose a new problem of panoramic human activity recognition\n(PAR), which aims to simultaneous achieve the individual action, social group\nactivity, and global activity recognition. This is a challenging yet practical\nproblem in real-world applications. For this problem, we develop a novel\nhierarchical graph neural network to progressively represent and model the\nmulti-granularity human activities and mutual social relations for a crowd of\npeople. We further build a benchmark to evaluate the proposed method and other\nexisting related methods. Experimental results verify the rationality of the\nproposed PAR problem, the effectiveness of our method and the usefulness of the\nbenchmark. We will release the source code and benchmark to the public for\npromoting the study on this problem.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Ruize Han",
      "Haomin Yan",
      "Jiacheng Li",
      "Songmiao Wang",
      "Wei Feng",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03806"
  },
  {
    "id": "arXiv:2203.03809",
    "title": "Image Search with Text Feedback by Additive Attention Compositional  Learning",
    "abstract": "Effective image retrieval with text feedback stands to impact a range of\nreal-world applications, such as e-commerce. Given a source image and text\nfeedback that describes the desired modifications to that image, the goal is to\nretrieve the target images that resemble the source yet satisfy the given\nmodifications by composing a multi-modal (image-text) query. We propose a novel\nsolution to this problem, Additive Attention Compositional Learning (AACL),\nthat uses a multi-modal transformer-based architecture and effectively models\nthe image-text contexts. Specifically, we propose a novel image-text\ncomposition module based on additive attention that can be seamlessly plugged\ninto deep neural networks. We also introduce a new challenging benchmark\nderived from the Shopping100k dataset. AACL is evaluated on three large-scale\ndatasets (FashionIQ, Fashion200k, and Shopping100k), each with strong\nbaselines. Extensive experiments show that AACL achieves new state-of-the-art\nresults on all three datasets.",
    "descriptor": "",
    "authors": [
      "Yuxin Tian",
      "Shawn Newsam",
      "Kofi Boakye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03809"
  },
  {
    "id": "arXiv:2203.03810",
    "title": "Towards Efficient Data-Centric Robust Machine Learning with Noise-based  Augmentation",
    "abstract": "The data-centric machine learning aims to find effective ways to build\nappropriate datasets which can improve the performance of AI models. In this\npaper, we mainly focus on designing an efficient data-centric scheme to improve\nrobustness for models towards unforeseen malicious inputs in the black-box test\nsettings. Specifically, we introduce a noised-based data augmentation method\nwhich is composed of Gaussian Noise, Salt-and-Pepper noise, and the PGD\nadversarial perturbations. The proposed method is built on lightweight\nalgorithms and proved highly effective based on comprehensive evaluations,\nshowing good efficiency on computation cost and robustness enhancement. In\naddition, we share our insights about the data-centric robust machine learning\ngained from our experiments.",
    "descriptor": "\nComments: Competition paper of AAAI2022:Data-Centric Robust Learning on ML Models. Published in Workshop on Adversarial Machine Learning and Beyond at AAAI2022\n",
    "authors": [
      "Xiaogeng Liu",
      "Haoyu Wang",
      "Yechao Zhang",
      "Fangzhou Wu",
      "Shengshan Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.03810"
  },
  {
    "id": "arXiv:2203.03812",
    "title": "SpeechFormer: A Hierarchical Efficient Framework Incorporating the  Characteristics of Speech",
    "abstract": "Transformer has obtained promising result on cognitive speech signal\nprocessing field, which is of interest in various applications ranging from\nemotion to neurocognitive disorder analysis. However, most works treat speech\nsignal as a whole, leading to the neglect of the pronunciation structure that\nis unique to speech and reflects the cognitive process. Meanwhile, Transformer\nhas heavy computational burden due to its full attention. In this paper, a\nhierarchical efficient framework that considers the structural characteristics\nof speech, called SpeechFormer, is proposed to serve as a general-purpose\nbackbone for cognitive speech signal processing. SpeechFormer consists of\nframe, phoneme, word and utterance stages in succession to imitate the\nstructural pattern of speech. Moreover, a modified attention is applied in each\nstage to learn a stage-specific feature. This hierarchical architecture models\nspeech signal by its nature and greatly reduces the computational complexity as\nwell. SpeechFormer is evaluated on speech emotion recognition (IEMOCAP & MELD)\nand neurocognitive disorder detection (Pitt & DAIC-WOZ) tasks, and the results\nshow that SpeechFormer outperforms the Transformer-based framework while\nassuring high computational efficiency. Furthermore, our SpeechFormer achieves\ncomparable results to state-of-the-art approaches.",
    "descriptor": "\nComments: 5 pages, 4figures\n",
    "authors": [
      "Weidong Chen",
      "Xiaofen Xing",
      "Xiangmin Xu",
      "Jianxin Pang",
      "Lan Du"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.03812"
  },
  {
    "id": "arXiv:2203.03815",
    "title": "UWB-based Target Localization using Adaptive Belief Propagation in the  HMM Framework",
    "abstract": "This paper proposes a novel adaptive sample space-based Viterbi algorithm for\nultra-wideband (UWB) based target localization in an online manner. As the\ndiscretized area of interest is defined as a finite number of hidden states,\nthe most probable trajectory of the unspecified agent is computed efficiently\nvia dynamic programming in a Hidden Markov Model (HMM) framework. Furthermore,\nthe approach has no requirements about Gaussian assumption and linearization\nfor Bayesian calculation. However, the issue of computational complexity\nbecomes very critical as the number of hidden states increases for estimation\naccuracy and large space. Previous localization works, based on discrete-state\nHMM, handle a small number of hidden variables, which represent specific paths\nor places. Inspired by the k-d Tree algorithm (e.g., quadtree) that is commonly\nused in the computer vision field, we propose a belief propagation in the most\nprobable belief space with a low to high-resolution sequentially, thus reducing\nthe required resources significantly. Our method has three advantages for\nlocalization: (a) no Gaussian assumptions and linearization, (b) handling the\nwhole area of interest, not specific or small map representations, (c) reducing\ncomputation time and required memory size. Experimental tests demonstrate our\nresults.",
    "descriptor": "",
    "authors": [
      "Minwon Seo",
      "Solmaz S. Kia"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03815"
  },
  {
    "id": "arXiv:2203.03818",
    "title": "Shadows can be Dangerous: Stealthy and Effective Physical-world  Adversarial Attack by Natural Phenomenon",
    "abstract": "Estimating the risk level of adversarial examples is essential for safely\ndeploying machine learning models in the real world. One popular approach for\nphysical-world attacks is to adopt the \"sticker-pasting\" strategy, which\nhowever suffers from some limitations, including difficulties in access to the\ntarget or printing by valid colors. A new type of non-invasive attacks emerged\nrecently, which attempt to cast perturbation onto the target by optics based\ntools, such as laser beam and projector. However, the added optical patterns\nare artificial but not natural. Thus, they are still conspicuous and\nattention-grabbed, and can be easily noticed by humans. In this paper, we study\na new type of optical adversarial examples, in which the perturbations are\ngenerated by a very common natural phenomenon, shadow, to achieve naturalistic\nand stealthy physical-world adversarial attack under the black-box setting. We\nextensively evaluate the effectiveness of this new attack on both simulated and\nreal-world environments. Experimental results on traffic sign recognition\ndemonstrate that our algorithm can generate adversarial examples effectively,\nreaching 98.23% and 90.47% success rates on LISA and GTSRB test sets\nrespectively, while continuously misleading a moving camera over 95% of the\ntime in real-world scenarios. We also offer discussions about the limitations\nand the defense mechanism of this attack.",
    "descriptor": "\nComments: This paper has been accepted by CVPR2022\n",
    "authors": [
      "Yiqi Zhong",
      "Xianming Liu",
      "Deming Zhai",
      "Junjun Jiang",
      "Xiangyang Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03818"
  },
  {
    "id": "arXiv:2203.03819",
    "title": "Table Structure Recognition with Conditional Attention",
    "abstract": "Tabular data in digital documents is widely used to express compact and\nimportant information for readers. However, it is challenging to parse tables\nfrom unstructured digital documents, such as PDFs and images, into\nmachine-readable format because of the complexity of table structures and the\nmissing of meta-information. Table Structure Recognition (TSR) problem aims to\nrecognize the structure of a table and transform the unstructured tables into a\nstructured and machine-readable format so that the tabular data can be further\nanalysed by the down-stream tasks, such as semantic modeling and information\nretrieval. In this study, we hypothesize that a complicated table structure can\nbe represented by a graph whose vertices and edges represent the cells and\nassociation between cells, respectively. Then we define the table structure\nrecognition problem as a cell association classification problem and propose a\nconditional attention network (CATT-Net). The experimental results demonstrate\nthe superiority of our proposed method over the state-of-the-art methods on\nvarious datasets. Besides, we investigate whether the alignment of a cell\nbounding box or a text-focused approach has more impact on the model\nperformance. Due to the lack of public dataset annotations based on these two\napproaches, we further annotate the ICDAR2013 dataset providing both types of\nbounding boxes, which can be a new benchmark dataset for evaluating the methods\nin this field. Experimental results show that the alignment of a cell bounding\nbox can help improve the Micro-averaged F1 score from 0.915 to 0.963, and the\nMacro-average F1 score from 0.787 to 0.923.",
    "descriptor": "\nComments: IJDAR under review\n",
    "authors": [
      "Bin Xiao",
      "Murat Simsek",
      "Burak Kantarci",
      "Ala Abu Alkheir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.03819"
  },
  {
    "id": "arXiv:2203.03820",
    "title": "A Variational Hierarchical Model for Neural Cross-Lingual Summarization",
    "abstract": "The goal of the cross-lingual summarization (CLS) is to convert a document in\none language (e.g., English) to a summary in another one (e.g., Chinese).\nEssentially, the CLS task is the combination of machine translation (MT) and\nmonolingual summarization (MS), and thus there exists the hierarchical\nrelationship between MT\\&MS and CLS. Existing studies on CLS mainly focus on\nutilizing pipeline methods or jointly training an end-to-end model through an\nauxiliary MT or MS objective. However, it is very challenging for the model to\ndirectly conduct CLS as it requires both the abilities to translate and\nsummarize. To address this issue, we propose a hierarchical model for the CLS\ntask, based on the conditional variational auto-encoder. The hierarchical model\ncontains two kinds of latent variables at the local and global levels,\nrespectively. At the local level, there are two latent variables, one for\ntranslation and the other for summarization. As for the global level, there is\nanother latent variable for cross-lingual summarization conditioned on the two\nlocal-level variables. Experiments on two language directions (English-Chinese)\nverify the effectiveness and superiority of the proposed approach. In addition,\nwe show that our model is able to generate better cross-lingual summaries than\ncomparison models in the few-shot setting.",
    "descriptor": "\nComments: Accepted at ACL 2022 as a long paper of main conference. Code: this https URL\n",
    "authors": [
      "Yunlong Liang",
      "Fandong Meng",
      "Chulun Zhou",
      "Jinan Xu",
      "Yufeng Chen",
      "Jinsong Su",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03820"
  },
  {
    "id": "arXiv:2203.03821",
    "title": "Coarse-to-Fine Vision Transformer",
    "abstract": "Vision Transformers (ViT) have made many breakthroughs in computer vision\ntasks. However, considerable redundancy arises in the spatial dimension of an\ninput image, leading to massive computational costs. Therefore, We propose a\ncoarse-to-fine vision transformer (CF-ViT) to relieve computational burden\nwhile retaining performance in this paper. Our proposed CF-ViT is motivated by\ntwo important observations in modern ViT models: (1) The coarse-grained patch\nsplitting can locate informative regions of an input image. (2) Most images can\nbe well recognized by a ViT model in a small-length token sequence. Therefore,\nour CF-ViT implements network inference in a two-stage manner. At coarse\ninference stage, an input image is split into a small-length patch sequence for\na computationally economical classification. If not well recognized, the\ninformative patches are identified and further re-split in a fine-grained\ngranularity. Extensive experiments demonstrate the efficacy of our CF-ViT. For\nexample, without any compromise on performance, CF-ViT reduces 53% FLOPs of\nLV-ViT, and also achieves 2.01x throughput.",
    "descriptor": "",
    "authors": [
      "Mengzhao Chen",
      "Mingbao Lin",
      "Ke Li",
      "Yunhang Shen",
      "Yongjian Wu",
      "Fei Chao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03821"
  },
  {
    "id": "arXiv:2203.03822",
    "title": "Virtual Displacement based Discontinuity Layout Optimization",
    "abstract": "Discontinuity layout optimization (DLO) is a relatively new upper bound limit\nanalysis method. Compared to classic topology optimization methods, aimed at\nobtaining the optimum design of a structure by considering its self-weight,\nbuilding cost or bearing capacity, DLO optimizes the failure pattern of the\nstructure under specific loading conditions and constraints by minimizing the\ndissipation energy. In this work, we present a modified DLO algorithm that\ncontains all of the advantages of DLO. It is referred to virtual\ndisplacement-based discontinuity layout optimization (VDLO). VDLO takes the\nstress state of a loaded structure as a snapshot and correspondingly provides\nthe optimum failure pattern, which greatly extends the application potential of\nDLO. Numerical examples indicate the effectiveness and flexibility of VDLO. It\nis regarded as a highly promising supplemental tool for other numerical methods\nin element-/node-based frameworks.",
    "descriptor": "",
    "authors": [
      "Yiming Zhang",
      "Xueya Wang",
      "Xinquan Wang",
      "Herbert Mang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.03822"
  },
  {
    "id": "arXiv:2203.03823",
    "title": "A Unified Framework of Medical Information Annotation and Extraction for  Chinese Clinical Text",
    "abstract": "Medical information extraction consists of a group of natural language\nprocessing (NLP) tasks, which collaboratively convert clinical text to\npre-defined structured formats. Current state-of-the-art (SOTA) NLP models are\nhighly integrated with deep learning techniques and thus require massive\nannotated linguistic data. This study presents an engineering framework of\nmedical entity recognition, relation extraction and attribute extraction, which\nare unified in annotation, modeling and evaluation. Specifically, the\nannotation scheme is comprehensive, and compatible between tasks, especially\nfor the medical relations. The resulted annotated corpus includes 1,200 full\nmedical records (or 18,039 broken-down documents), and achieves inter-annotator\nagreements (IAAs) of 94.53%, 73.73% and 91.98% F 1 scores for the three tasks.\nThree task-specific neural network models are developed within a shared\nstructure, and enhanced by SOTA NLP techniques, i.e., pre-trained language\nmodels. Experimental results show that the system can retrieve medical\nentities, relations and attributes with F 1 scores of 93.47%, 67.14% and\n90.89%, respectively. This study, in addition to our publicly released\nannotation scheme and code, provides solid and practical engineering experience\nof developing an integrated medical information extraction system.",
    "descriptor": "\nComments: 31 pages, 5 figures\n",
    "authors": [
      "Enwei Zhu",
      "Qilin Sheng",
      "Huanwan Yang",
      "Jinpeng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03823"
  },
  {
    "id": "arXiv:2203.03825",
    "title": "Incorporating Hierarchy into Text Encoder: a Contrastive Learning  Approach for Hierarchical Text Classification",
    "abstract": "Hierarchical text classification is a challenging subtask of multi-label\nclassification due to its complex label hierarchy. Existing methods encode text\nand label hierarchy separately and mix their representations for\nclassification, where the hierarchy remains unchanged for all input text.\nInstead of modeling them separately, in this work, we propose Hierarchy-guided\nContrastive Learning (HGCLR) to directly embed the hierarchy into a text\nencoder. During training, HGCLR constructs positive samples for input text\nunder the guidance of the label hierarchy. By pulling together the input text\nand its positive sample, the text encoder can learn to generate the\nhierarchy-aware text representation independently. Therefore, after training,\nthe HGCLR enhanced text encoder can dispense with the redundant hierarchy.\nExtensive experiments on three benchmark datasets verify the effectiveness of\nHGCLR.",
    "descriptor": "\nComments: ACL 2022 main conference\n",
    "authors": [
      "Zihan Wang",
      "Peiyi Wang",
      "Lianzhe Huang",
      "Xin Sun",
      "Houfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03825"
  },
  {
    "id": "arXiv:2203.03827",
    "title": "GANSpiration: Balancing Targeted and Serendipitous Inspiration in User  Interface Design with Style-Based Generative Adversarial Network",
    "abstract": "Inspiration from design examples plays a crucial role in the creative process\nof user interface design. However, current tools and techniques that support\ninspiration usually only focus on example browsing with limited user control or\nsimilarity-based example retrieval, leading to undesirable design outcomes such\nas focus drift and design fixation. To address these issues, we propose the\nGANSpiration approach that suggests design examples for both targeted and\nserendipitous inspiration, leveraging a style-based Generative Adversarial\nNetwork. A quantitative evaluation revealed that the outputs of\nGANSpiration-based example suggestion approaches are relevant to the input\ndesign, and at the same time include diverse instances. A user study with\nprofessional UI/UX practitioners showed that the examples suggested by our\napproach serve as viable sources of inspiration for overall design concepts and\nspecific design elements. Overall, our work paves the road of using advanced\ngenerative machine learning techniques in supporting the creative design\npractice.",
    "descriptor": "\nComments: 15 pages, 9 figures, CHI Conference on Human Factors in Computing Systems (CHI '22)\n",
    "authors": [
      "Mohammad Amin Mozaffari",
      "Xinyuan Zhang",
      "Jinghui Cheng",
      "Jin L.C. Guo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.03827"
  },
  {
    "id": "arXiv:2203.03828",
    "title": "Informative Planning for Worst-Case Error Minimisation in Sparse  Gaussian Process Regression",
    "abstract": "We present a planning framework for minimising the deterministic worst-case\nerror in sparse Gaussian process (GP) regression. We first derive a universal\nworst-case error bound for sparse GP regression with bounded noise using\ninterpolation theory on reproducing kernel Hilbert spaces (RKHSs). By\nexploiting the conditional independence (CI) assumption central to sparse GP\nregression, we show that the worst-case error minimisation can be achieved by\nsolving a posterior entropy minimisation problem. In turn, the posterior\nentropy minimisation problem is solved using a Gaussian belief space planning\nalgorithm. We corroborate the proposed worst-case error bound in a simple 1D\nexample, and test the planning framework in simulation for a 2D vehicle in a\ncomplex flow field. Our results demonstrate that the proposed posterior entropy\nminimisation approach is effective in minimising deterministic error, and\noutperforms the conventional measurement entropy maximisation formulation when\nthe inducing points are fixed.",
    "descriptor": "\nComments: 7 pages, 6 figures, accepted to Proc. of ICRA 2022\n",
    "authors": [
      "Jennifer Wakulicz",
      "Ki Myung Brian Lee",
      "Chanyeol Yoo",
      "Teresa Vidal-Calleja",
      "Robert Fitch"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03828"
  },
  {
    "id": "arXiv:2203.03831",
    "title": "Deep Rectangling for Image Stitching: A Learning Baseline",
    "abstract": "Stitched images provide a wide field-of-view (FoV) but suffer from unpleasant\nirregular boundaries. To deal with this problem, existing image rectangling\nmethods devote to searching an initial mesh and optimizing a target mesh to\nform the mesh deformation in two stages. Then rectangular images can be\ngenerated by warping stitched images. However, these solutions only work for\nimages with rich linear structures, leading to noticeable distortions for\nportraits and landscapes with non-linear objects. In this paper, we address\nthese issues by proposing the first deep learning solution to image\nrectangling. Concretely, we predefine a rigid target mesh and only estimate an\ninitial mesh to form the mesh deformation, contributing to a compact one-stage\nsolution. The initial mesh is predicted using a fully convolutional network\nwith a residual progressive regression strategy. To obtain results with high\ncontent fidelity, a comprehensive objective function is proposed to\nsimultaneously encourage the boundary rectangular, mesh shape-preserving, and\ncontent perceptually natural. Besides, we build the first image stitching\nrectangling dataset with a large diversity in irregular boundaries and scenes.\nExperiments demonstrate our superiority over traditional methods both\nquantitatively and qualitatively.",
    "descriptor": "\nComments: Accepted by CVPR2022; Codes and dataset: this https URL\n",
    "authors": [
      "Lang Nie",
      "Chunyu Lin",
      "Kang Liao",
      "Shuaicheng Liu",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03831"
  },
  {
    "id": "arXiv:2203.03833",
    "title": "Quasi-Balanced Self-Training on Noise-Aware Synthesis of Object Point  Clouds for Closing Domain Gap",
    "abstract": "Semantic analyses of object point clouds are largely driven by releasing of\nbenchmarking datasets, including synthetic ones whose instances are sampled\nfrom object CAD models. However, learning from synthetic data may not\ngeneralize to practical scenarios, where point clouds are typically incomplete,\nnon-uniformly distributed, and noisy. Such a challenge of Simulation-to-Real\n(Sim2Real) domain gap could be mitigated via learning algorithms of domain\nadaptation; however, we argue that generation of synthetic point clouds via\nmore physically realistic rendering is a powerful alternative, as systematic\nnon-uniform noise patterns can be captured. To this end, we propose an\nintegrated scheme consisting of physically realistic synthesis of object point\nclouds via rendering stereo images via projection of speckle patterns onto CAD\nmodels and a novel quasi-balanced self-training designed for more balanced data\ndistribution by sparsity-driven selection of pseudo labeled samples for long\ntailed classes. Experiment results can verify the effectiveness of our method\nas well as both of its modules for unsupervised domain adaptation on point\ncloud classification, achieving the state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Yongwei Chen",
      "Zihao Wang",
      "Longkun Zou",
      "Ke Chen",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03833"
  },
  {
    "id": "arXiv:2203.03835",
    "title": "Towards Building an Open-Domain Dialogue System Incorporated with  Internet Memes",
    "abstract": "In recent years, Internet memes have been widely used in online chatting.\nCompared with text-based communication, conversations become more expressive\nand attractive when Internet memes are incorporated. This paper presents our\nsolutions for the Meme incorporated Open-domain Dialogue (MOD) Challenge of\nDSTC10, where three tasks are involved: text response modeling, meme retrieval,\nand meme emotion classification. Firstly, we leverage a large-scale pre-trained\ndialogue model for coherent and informative response generation. Secondly,\nbased on interaction-based text-matching, our approach can retrieve appropriate\nmemes with good generalization ability. Thirdly, we propose to model the\nemotion flow (EF) in conversations and introduce an auxiliary task of emotion\ndescription prediction (EDP) to boost the performance of meme emotion\nclassification. Experimental results on the MOD dataset demonstrate that our\nmethods can incorporate Internet memes into dialogue systems effectively.",
    "descriptor": "\nComments: First two authors contributed equally to this work\n",
    "authors": [
      "Hua Lu",
      "Zhen Guo",
      "Chanjuan Li",
      "Yunyi Yang",
      "Huang He",
      "Siqi Bao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03835"
  },
  {
    "id": "arXiv:2203.03836",
    "title": "An Efficient Two-Stage SPARC Decoder for Massive MIMO Unsourced Random  Access",
    "abstract": "In this paper, we study a concatenate coding scheme based on sparse\nregression code (SPARC) and tree code for unsourced random access in massive\nmultiple-input and multiple-output (MIMO) systems. Our focus is concentrated on\nefficient decoding for the inner SPARC with practical concerns. A two-stage\nmethod is proposed to achieve near-optimal performance while maintaining low\ncomputational complexity. Specifically, an one-step thresholding-based\nalgorithm is first used for reducing large dimensions of the SPARC decoding,\nafter which an relaxed maximum-likelihood estimator is employed for refinement.\nAdequate simulation results are provided to validate the near-optimal\nperformance and the low computational complexity. Besides, for covariance-based\nsparse recovery method, theoretical analyses are given to characterize the\nupper bound of the number of active users supported when convex relaxation is\nconsidered, and the probability of successful dimension reduction by the\none-step thresholding-based algorithm.",
    "descriptor": "",
    "authors": [
      "Juntao You",
      "Wenjie Wang",
      "Shansuo Liang",
      "Wei Han",
      "Bo Bai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.03836"
  },
  {
    "id": "arXiv:2203.03838",
    "title": "Multi-Scale Self-Contrastive Learning with Hard Negative Mining for  Weakly-Supervised Query-based Video Grounding",
    "abstract": "Query-based video grounding is an important yet challenging task in video\nunderstanding, which aims to localize the target segment in an untrimmed video\naccording to a sentence query. Most previous works achieve significant progress\nby addressing this task in a fully-supervised manner with segment-level labels,\nwhich require high labeling cost. Although some recent efforts develop\nweakly-supervised methods that only need the video-level knowledge, they\ngenerally match multiple pre-defined segment proposals with query and select\nthe best one, which lacks fine-grained frame-level details for distinguishing\nframes with high repeatability and similarity within the entire video. To\nalleviate the above limitations, we propose a self-contrastive learning\nframework to address the query-based video grounding task under a\nweakly-supervised setting. Firstly, instead of utilizing redundant segment\nproposals, we propose a new grounding scheme that learns frame-wise matching\nscores referring to the query semantic to predict the possible foreground\nframes by only using the video-level annotations. Secondly, since some\npredicted frames (i.e., boundary frames) are relatively coarse and exhibit\nsimilar appearance to their adjacent frames, we propose a coarse-to-fine\ncontrastive learning paradigm to learn more discriminative frame-wise\nrepresentations for distinguishing the false positive frames. In particular, we\niteratively explore multi-scale hard negative samples that are close to\npositive samples in the representation space for distinguishing fine-grained\nframe-wise details, thus enforcing more accurate segment grounding. Extensive\nexperiments on two challenging benchmarks demonstrate the superiority of our\nproposed method compared with the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Shentong Mo",
      "Daizong Liu",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.03838"
  },
  {
    "id": "arXiv:2203.03839",
    "title": "Hermite spectral method for multi-species Boltzmann equation",
    "abstract": "We introduce a numerical scheme for the full multi-species Boltzmann equation\nbased on Hermite spectral method. With the proper choice of expansion centers\nfor different species, a practical algorithm is derived to evaluate the\ncomplicated multi-species binary collision operator. New collision models are\nbuilt by combining the quadratic collision model and the simple BGK collision\nmodel under the framework of the Hermite spectral method, which enables us to\nbalance the computational cost and accuracy. Several numerical experiments are\nimplemented to validate the dramatic efficiency of this new Hermite spectral\nmethod. Moreover, we can handle the problems with as many as 100 species, which\nis far beyond the capability of the state-of-art algorithms.",
    "descriptor": "",
    "authors": [
      "Ruo Li",
      "Yixiao Lu",
      "Yanli Wang",
      "Haoxuan Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.03839"
  },
  {
    "id": "arXiv:2203.03843",
    "title": "Self-supervised Social Relation Representation for Human Group Detection",
    "abstract": "Human group detection, which splits crowd of people into groups, is an\nimportant step for video-based human social activity analysis. The core of\nhuman group detection is the human social relation representation and\ndivision.In this paper, we propose a new two-stage multi-head framework for\nhuman group detection. In the first stage, we propose a human behavior\nsimulator head to learn the social relation feature embedding, which is\nself-supervisely trained by leveraging the socially grounded multi-person\nbehavior relationship. In the second stage, based on the social relation\nembedding, we develop a self-attention inspired network for human group\ndetection. Remarkable performance on two state-of-the-art large-scale\nbenchmarks, i.e., PANDA and JRDB-Group, verifies the effectiveness of the\nproposed framework. Benefiting from the self-supervised social relation\nembedding, our method can provide promising results with very few (labeled)\ntraining data. We will release the source code to the public.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Jiacheng Li",
      "Ruize Han",
      "Haomin Yan",
      "Zekun Qian",
      "Wei Feng",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03843"
  },
  {
    "id": "arXiv:2203.03847",
    "title": "Trust in AI and Implications for the AEC Research: A Literature Analysis",
    "abstract": "Engendering trust in technically acceptable and psychologically embraceable\nsystems requires domain-specific research to capture unique characteristics of\nthe field of application. The architecture, engineering, and construction (AEC)\nresearch community has been recently harnessing advanced solutions offered by\nartificial intelligence (AI) to improve project workflows. Despite the unique\ncharacteristics of work, workers, and workplaces in the AEC industry, the\nconcept of trust in AI has received very little attention in the literature.\nThis paper presents a comprehensive analysis of the academic literature in two\nmain areas of trust in AI and AI in the AEC, to explore the interplay between\nAEC projects unique aspects and the sociotechnical concepts that lead to trust\nin AI. A total of 490 peer-reviewed scholarly articles are analyzed in this\nstudy. The main constituents of human trust in AI are identified from the\nliterature and are characterized within the AEC project types, processes, and\ntechnologies.",
    "descriptor": "\nComments: 2021 ASCE International Conference on Computing in Civil Engineering (i3CE2021)\n",
    "authors": [
      "Newsha Emaminejad",
      "Alexa Maria North",
      "Reza Akhavian"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03847"
  },
  {
    "id": "arXiv:2203.03850",
    "title": "UniXcoder: Unified Cross-Modal Pre-training for Code Representation",
    "abstract": "Pre-trained models for programming languages have recently demonstrated great\nsuccess on code intelligence. To support both code-related understanding and\ngeneration tasks, recent works attempt to pre-train unified encoder-decoder\nmodels. However, such encoder-decoder framework is sub-optimal for\nauto-regressive tasks, especially code completion that requires a decoder-only\nmanner for efficient inference. In this paper, we present UniXcoder, a unified\ncross-modal pre-trained model for programming language. The model utilizes mask\nattention matrices with prefix adapters to control the behavior of the model\nand leverages cross-modal contents like AST and code comment to enhance code\nrepresentation. To encode AST that is represented as a tree in parallel, we\npropose a one-to-one mapping method to transform AST in a sequence structure\nthat retains all structural information from the tree. Furthermore, we propose\nto utilize multi-modal contents to learn representation of code fragment with\ncontrastive learning, and then align representations among programming\nlanguages using a cross-modal generation task. We evaluate UniXcoder on five\ncode-related tasks over nine datasets. To further evaluate the performance of\ncode fragment representation, we also construct a dataset for a new task,\ncalled zero-shot code-to-code search. Results show that our model achieves\nstate-of-the-art performance on most tasks and analysis reveals that comment\nand AST can both enhance UniXcoder.",
    "descriptor": "\nComments: Published in ACL 2022\n",
    "authors": [
      "Daya Guo",
      "Shuai Lu",
      "Nan Duan",
      "Yanlin Wang",
      "Ming Zhou",
      "Jian Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.03850"
  },
  {
    "id": "arXiv:2203.03853",
    "title": "Where Does the Performance Improvement Come From? - A Reproducibility  Concern about Image-Text Retrieval",
    "abstract": "This paper seeks to provide the information retrieval community with some\nreflections on the current improvements of retrieval learning through the\nanalysis of the reproducibility aspects of image-text retrieval models. For the\nlatter part of the past decade, image-text retrieval has gradually become a\nmajor research direction in the field of information retrieval because of the\ngrowth of multi-modal data. Many researchers use benchmark datasets like\nMS-COCO and Flickr30k to train and assess the performance of image-text\nretrieval algorithms. Research in the past has mostly focused on performance,\nwith several state-of-the-art methods being proposed in various ways. According\nto their claims, these approaches achieve better modal interactions and thus\nbetter multimodal representations with greater precision. In contrast to those\nprevious works, we focus on the repeatability of the approaches and the overall\nexamination of the elements that lead to improved performance by pretrained and\nnonpretrained models in retrieving images and text. To be more specific, we\nfirst examine the related reproducibility concerns and why the focus is on\nimage-text retrieval tasks, and then we systematically summarize the current\nparadigm of image-text retrieval models and the stated contributions of those\napproaches. Second, we analyze various aspects of the reproduction of\npretrained and nonpretrained retrieval models. Based on this, we conducted\nablation experiments and obtained some influencing factors that affect\nretrieval recall more than the improvement claimed in the original paper.\nFinally, we also present some reflections and issues that should be considered\nby the retrieval community in the future. Our code is freely available at\nhttps://github.com/WangFei-2019/Image-text-Retrieval.",
    "descriptor": "\nComments: submitted to SIGIR 2022 (reproducibility track)\n",
    "authors": [
      "Jun Rao",
      "Fei Wang",
      "Liang Ding",
      "Shuhan Qi",
      "Yibing Zhan",
      "Weifeng Liu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03853"
  },
  {
    "id": "arXiv:2203.03854",
    "title": "Metaverse: Security and Privacy Concerns",
    "abstract": "The term \"metaverse\", a three-dimensional virtual universe similar to the\nreal realm, has always been full of imagination since it was put forward in the\n1990s. Recently, it is possible to realize the metaverse with the continuous\nemergence and progress of various technologies, and thus it has attracted\nextensive attention again. It may bring a lot of benefits to human society such\nas reducing discrimination, eliminating individual differences, and\nsocializing. However, everything has security and privacy concerns, which is no\nexception for the metaverse. In this article, we firstly analyze the concept of\nthe metaverse and propose that it is a super virtual-reality (VR) ecosystem\ncompared with other VR technologies. Then, we carefully analyze and elaborate\non possible security and privacy concerns from four perspectives: user\ninformation, communication, scenario, and goods, and immediately, the potential\nsolutions are correspondingly put forward. Meanwhile, we propose the need to\ntake advantage of the new buckets effect to comprehensively address security\nand privacy concerns from a philosophical perspective, which hopefully will\nbring some progress to the metaverse community.",
    "descriptor": "",
    "authors": [
      "Ruoyu Zhao",
      "Yushu Zhang",
      "Youwen Zhu",
      "Rushi Lan",
      "Zhongyun Hua"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.03854"
  },
  {
    "id": "arXiv:2203.03856",
    "title": "DARER: Dual-task Temporal Relational Recurrent Reasoning Network for  Joint Dialog Sentiment Classification and Act Recognition",
    "abstract": "The task of joint dialog sentiment classification (DSC) and act recognition\n(DAR) aims to simultaneously predict the sentiment label and act label for each\nutterance in a dialog. In this paper, we put forward a new framework which\nmodels the explicit dependencies via integrating \\textit{prediction-level\ninteractions} other than semantics-level interactions, more consistent with\nhuman intuition. Besides, we propose a speaker-aware temporal graph (SATG) and\na dual-task relational temporal graph (DRTG) to introduce \\textit{temporal\nrelations} into dialog understanding and dual-task reasoning. To implement our\nframework, we propose a novel model dubbed DARER, which first generates the\ncontext-, speaker- and temporal-sensitive utterance representations via\nmodeling SATG, then conducts recurrent dual-task relational reasoning on DRTG,\nin which process the estimated label distributions act as key clues in\nprediction-level interactions. Experiment results show that DARER outperforms\nexisting models by large margins while requiring much less computation resource\nand costing less training time. Remarkably, on DSC task in Mastodon, DARER\ngains a relative improvement of about 25% over previous best model in terms of\nF1, with less than 50% parameters and about only 60% required GPU memory.",
    "descriptor": "\nComments: Long paper; ACL 2022 (Findings)\n",
    "authors": [
      "Bowen Xing",
      "Ivor W. Tsang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03856"
  },
  {
    "id": "arXiv:2203.03859",
    "title": "A New 27 Class Sign Language Dataset Collected from 173 Individuals",
    "abstract": "After the interviews, it has been comprehended that speech-impaired\nindividuals who use sign languages have difficulty communicating with other\npeople who do not know sign language. Due to the communication problems, the\nsense of independence of speech-impaired individuals could be damaged and lead\nthem to socialize less with society. To contribute to the development of\ntechnologies, that can reduce the communication problems of speech-impaired\npersons, a new dataset was presented with this paper. The dataset was created\nby processing American Sign Language-based photographs collected from 173\nvolunteers, published as 27 Class Sign Language Dataset on the Kaggle Datasets\nweb page.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Arda Mavi",
      "Zeynep Dikle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03859"
  },
  {
    "id": "arXiv:2203.03860",
    "title": "Weakly Supervised Semantic Segmentation using Out-of-Distribution Data",
    "abstract": "Weakly supervised semantic segmentation (WSSS) methods are often built on\npixel-level localization maps obtained from a classifier. However, training on\nclass labels only, classifiers suffer from the spurious correlation between\nforeground and background cues (e.g. train and rail), fundamentally bounding\nthe performance of WSSS. There have been previous endeavors to address this\nissue with additional supervision. We propose a novel source of information to\ndistinguish foreground from the background: Out-of-Distribution (OoD) data, or\nimages devoid of foreground object classes. In particular, we utilize the hard\nOoDs that the classifier is likely to make false-positive predictions. These\nsamples typically carry key visual features on the background (e.g. rail) that\nthe classifiers often confuse as foreground (e.g. train), so these cues let\nclassifiers correctly suppress spurious background cues. Acquiring such hard\nOoDs does not require an extensive amount of annotation efforts; it only incurs\na few additional image-level labeling costs on top of the original efforts to\ncollect class labels. We propose a method, W-OoD, for utilizing the hard OoDs.\nW-OoD achieves state-of-the-art performance on Pascal VOC 2012.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Jungbeom Lee",
      "Seong Joon Oh",
      "Sangdoo Yun",
      "Junsuk Choe",
      "Eunji Kim",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03860"
  },
  {
    "id": "arXiv:2203.03865",
    "title": "A Cauchy-type Hamilton-Jacobi Successive Approximation Scheme For  Reachable Sets Computation",
    "abstract": "Motivated by the scalability limitations of Eulerian methods for variational\nHamilton-Jacobi-Isaacs (HJI) formulations that provide a least restrictive\ncontroller in problems that involve state or input constraints under a\nworst-possible disturbance, we introduce a second-order, successive sweep\nalgorithm for computing the zero sublevel sets of a popular reachability value\nfunctional. Under sufficient HJI partial differential equation regularity and\ncontinuity assumption throughout the state space, we show that with state\nfeedback control under the worst-possible disturbance, we can compute the state\nset that are reachable within a prescribed verification time bound.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Olalekan Ogunmolu",
      "Ian Abraham",
      "Sylvia Herbert"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03865"
  },
  {
    "id": "arXiv:2203.03867",
    "title": "Featured Trajectory Generation for TrackPuzzle",
    "abstract": "Indoor route graph learning is critically important for autonomous indoor\nnavigation. A key problem for crowd-sourcing indoor route graph learning is\nfeatured trajectory generation. In this paper, a system is provided to generate\nfeatured trajectories by crowd-sourcing smartphone data. Firstly, we propose a\nmore accurate PDR algorithm for the generation of trajectory motion data. This\nalgorithm uses ADAPTIV as the step counting method and uses the step estimation\nalgorithm o make the trajectory more accurate in length. Next, the barometer is\nused to segment the tracks of different floors, and the track floors are\nobtained by WiFi feature clustering. Finally, by finding the turning point as\nthe feature point of the trajectory, the vertices and edges of the trajectory\nare extracted to reduce the noise of the long straight trajectory.",
    "descriptor": "",
    "authors": [
      "Wanting Li",
      "Yongcai Wang",
      "Deying Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.03867"
  },
  {
    "id": "arXiv:2203.03870",
    "title": "Morphological Anti-Aliasing Method for Boundary Slope Prediction",
    "abstract": "Image pixel aliasing caused by insufficient sampling is a long-standing\nproblem in the field of computer graphics. It has always been the goal of\nresearchers to seek anti-aliasing algorithms with high speed and good effect.\nDue to the deficiencies in local detection and reconstruction of sloping line\nboundaries, a morphological anti-aliasing method for boundary slope prediction\nis proposed. This method uses the information of the local line boundary slope\nto predict and test the end positions of the line boundary in the global scope,\nthereby reconstructing The boundary information more consistent with the actual\nboundary is obtained, and a more accurate linear boundary shape is obtained\nwith only a small increase in the amount of calculation. Compared with the\nprevious morphological anti-aliasing algorithm, the proposed method is based on\nthe global morphological boundary. , can reconstruct the straight line boundary\nmore accurately, and apply it to the anti-aliasing calculation, which can\nfurther improve the color transition of the straight line boundary, make the\ninclined straight line boundary have higher continuity, and obtain a better\nanti-aliasing effect.",
    "descriptor": "",
    "authors": [
      "Yuchen Zhong",
      "Yuchi Huo",
      "Rui Wang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.03870"
  },
  {
    "id": "arXiv:2203.03871",
    "title": "Discriminability-Transferability Trade-Off: An Information-Theoretic  Perspective",
    "abstract": "This work simultaneously considers the discriminability and transferability\nproperties of deep representations in the typical supervised learning task,\ni.e., image classification. By a comprehensive temporal analysis, we observe a\ntrade-off between these two properties. The discriminability keeps increasing\nwith the training progressing while the transferability intensely diminishes in\nthe later training period.\nFrom the perspective of information-bottleneck theory, we reveal that the\nincompatibility between discriminability and transferability is attributed to\nthe over-compression of input information. More importantly, we investigate why\nand how the InfoNCE loss can alleviate the over-compression, and further\npresent a learning framework, named contrastive temporal coding~(CTC), to\ncounteract the over-compression and alleviate the incompatibility. Extensive\nexperiments validate that CTC successfully mitigates the incompatibility,\nyielding discriminative and transferable representations. Noticeable\nimprovements are achieved on the image classification task and challenging\ntransfer learning tasks. We hope that this work will raise the significance of\nthe transferability property in the conventional supervised learning setting.\nCode will be publicly available.",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Quan Cui",
      "Bingchen Zhao",
      "Zhao-Min Chen",
      "Borui Zhao",
      "Renjie Song",
      "Jiajun Liang",
      "Boyan Zhou",
      "Osamu Yoshie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03871"
  },
  {
    "id": "arXiv:2203.03872",
    "title": "Visual anomaly detection in video by variational autoencoder",
    "abstract": "Video anomalies detection is the intersection of anomaly detection and visual\nintelligence. It has commercial applications in surveillance, security,\nself-driving cars and crop monitoring. Videos can capture a variety of\nanomalies. Due to efforts needed to label training data, unsupervised\napproaches to train anomaly detection models for videos is more practical An\nautoencoder is a neural network that is trained to recreate its input using\nlatent representation of input also called a bottleneck layer. Variational\nautoencoder uses distribution (mean and variance) as compared to latent vector\nas bottleneck layer and can have better regularization effect. In this paper we\nhave demonstrated comparison between performance of convolutional LSTM versus a\nvariation convolutional LSTM autoencoder",
    "descriptor": "",
    "authors": [
      "Faraz Waseem",
      "Rafael Perez Martinez",
      "Chris Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03872"
  },
  {
    "id": "arXiv:2203.03875",
    "title": "Occupancy Flow Fields for Motion Forecasting in Autonomous Driving",
    "abstract": "We propose Occupancy Flow Fields, a new representation for motion forecasting\nof multiple agents, an important task in autonomous driving. Our representation\nis a spatio-temporal grid with each grid cell containing both the probability\nof the cell being occupied by any agent, and a two-dimensional flow vector\nrepresenting the direction and magnitude of the motion in that cell. Our method\nsuccessfully mitigates shortcomings of the two most commonly-used\nrepresentations for motion forecasting: trajectory sets and occupancy grids.\nAlthough occupancy grids efficiently represent the probabilistic location of\nmany agents jointly, they do not capture agent motion and lose the agent\nidentities. To this end, we propose a deep learning architecture that generates\nOccupancy Flow Fields with the help of a new flow trace loss that establishes\nconsistency between the occupancy and flow predictions. We demonstrate the\neffectiveness of our approach using three metrics on occupancy prediction,\nmotion estimation, and agent ID recovery. In addition, we introduce the problem\nof predicting speculative agents, which are currently-occluded agents that may\nappear in the future through dis-occlusion or by entering the field of view. We\nreport experimental results on a large in-house autonomous driving dataset and\nthe public INTERACTION dataset, and show that our model outperforms\nstate-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Reza Mahjourian",
      "Jinkyu Kim",
      "Yuning Chai",
      "Mingxing Tan",
      "Ben Sapp",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03875"
  },
  {
    "id": "arXiv:2203.03876",
    "title": "High-order Order Proximity-Incorporated, Symmetry and Graph-Regularized  Nonnegative Matrix Factorization for Community Detection",
    "abstract": "Community describes the functional mechanism of a network, making community\ndetection serve as a fundamental graph tool for various real applications like\ndiscovery of social circle. To date, a Symmetric and Non-negative Matrix\nFactorization (SNMF) model has been frequently adopted to address this issue\nowing to its high interpretability and scalability. However, most existing\nSNMF-based community detection methods neglect the high-order connection\npatterns in a network. Motivated by this discovery, in this paper, we propose a\nHigh-Order Proximity (HOP)-incorporated, Symmetry and Graph-regularized NMF\n(HSGN) model that adopts the following three-fold ideas: a) adopting a weighted\npointwise mutual information (PMI)-based approach to measure the HOP indices\namong nodes in a network; b) leveraging an iterative reconstruction scheme to\nencode the captured HOP into the network; and c) introducing a symmetry and\ngraph-regularized NMF algorithm to detect communities accurately. Extensive\nempirical studies on eight real-world networks demonstrate that an HSGN-based\ncommunity detector significantly outperforms both benchmark and\nstate-of-the-art community detectors in providing highly-accurate community\ndetection results.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Zhigang Liu",
      "Xin Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03876"
  },
  {
    "id": "arXiv:2203.03878",
    "title": "HyperPELT: Unified Parameter-Efficient Language Model Tuning for Both  Language and Vision-and-Language Tasks",
    "abstract": "The workflow of pretraining and fine-tuning has emerged as a popular paradigm\nfor solving various NLP and V&L (Vision-and-Language) downstream tasks. With\nthe capacity of pretrained models growing rapidly, how to perform\nparameter-efficient fine-tuning has become fairly important for quick transfer\nlearning and deployment. In this paper, we design a novel unified\nparameter-efficient transfer learning framework that works effectively on both\npure language and V&L tasks. In particular, we use a shared hypernetwork that\ntakes trainable hyper-embeddings as input, and outputs weights for fine-tuning\ndifferent small modules in a pretrained language model, such as tuning the\nparameters inserted into multi-head attention blocks (i.e., prefix-tuning) and\nfeed-forward blocks (i.e., adapter-tuning). We define a set of embeddings\n(e.g., layer, block, task and visual embeddings) as the key components to\ncalculate hyper-embeddings, which thus can support both pure language and V&L\ntasks. Our proposed framework adds fewer trainable parameters in multi-task\nlearning while achieving superior performances and transfer ability compared to\nstate-of-the-art methods. Empirical results on the GLUE benchmark and multiple\nV&L tasks confirm the effectiveness of our framework on both textual and visual\nmodalities.",
    "descriptor": "",
    "authors": [
      "Zhengkun Zhang",
      "Wenya Guo",
      "Xiaojun Meng",
      "Yasheng Wang",
      "Yadao Wang",
      "Xin Jiang",
      "Qun Liu",
      "Zhenglu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03878"
  },
  {
    "id": "arXiv:2203.03883",
    "title": "Online Dynamic Parameter Estimation of an Alkaline Electrolysis System  Based on Bayesian Inference",
    "abstract": "When directly coupled with fluctuating energy sources such as wind and\nphotovoltage power, the alkaline electrolysis (AEL) in a power-to-hydrogen\n(P2H) system is required to operate flexibly by dynamically adjusting its\nhydrogen production rate. The flex-ibility characteristics, e.g., loading range\nand ramping rate, of an AEL system are significantly influenced by some\nparameters re-lated to the dynamic processes of the AEL system. These\nparame-ters are usually difficult to measure directly and may even change with\ntime. To accurately evaluate the flexibility of an AEL system in online\noperation, this paper presents a Bayesian Inference-based Markov Chain Monte\nCarlo (MCMC) method to estimate these parameters. Meanwhile, posterior joint\nprobability distribu-tions of the estimated parameters are obtained as a\nbyproduct, which provides valuable physical insight into the AEL systems.\nExperiments on a 25 kW electrolyzer validate the proposed pa-rameter estimation\nmethod.",
    "descriptor": "\nComments: Accepted by 2022 IEEE 5th International Electrical and Energy Conference\n",
    "authors": [
      "Xiaoyan Qiu",
      "Hang Zhang",
      "Yiwei Qiu",
      "Buxiang Zhou",
      "Tianlei Zang",
      "Ruomei Qi",
      "Jin Lin",
      "Jiepeng Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.03883"
  },
  {
    "id": "arXiv:2203.03884",
    "title": "Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels",
    "abstract": "The crux of semi-supervised semantic segmentation is to assign adequate\npseudo-labels to the pixels of unlabeled images. A common practice is to select\nthe highly confident predictions as the pseudo ground-truth, but it leads to a\nproblem that most pixels may be left unused due to their unreliability. We\nargue that every pixel matters to the model training, even its prediction is\nambiguous. Intuitively, an unreliable prediction may get confused among the top\nclasses (i.e., those with the highest probabilities), however, it should be\nconfident about the pixel not belonging to the remaining classes. Hence, such a\npixel can be convincingly treated as a negative sample to those most unlikely\ncategories. Based on this insight, we develop an effective pipeline to make\nsufficient use of unlabeled data. Concretely, we separate reliable and\nunreliable pixels via the entropy of predictions, push each unreliable pixel to\na category-wise queue that consists of negative samples, and manage to train\nthe model with all candidate pixels. Considering the training evolution, where\nthe prediction becomes more and more accurate, we adaptively adjust the\nthreshold for the reliable-unreliable partition. Experimental results on\nvarious benchmarks and training settings demonstrate the superiority of our\napproach over the state-of-the-art alternatives.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Yuchao Wang",
      "Haochen Wang",
      "Yujun Shen",
      "Jingjing Fei",
      "Wei Li",
      "Guoqiang Jin",
      "Liwei Wu",
      "Rui Zhao",
      "Xinyi Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03884"
  },
  {
    "id": "arXiv:2203.03885",
    "title": "Incentivizing Data Contribution in Cross-Silo Federated Learning",
    "abstract": "In cross-silo federated learning, clients (e.g., organizations) collectively\ntrain a global model using their local data. However, due to business\ncompetitions and privacy concerns, the clients tend to free-ride (i.e., not\ncontribute enough data points) during training.\nTo address this issue, we propose a framework where the profit/benefit\nobtained from the global model can be properly allocated to clients to\nincentivize data contribution.\nMore specifically, we study the game-theoretical interactions among the\nclients under three widely used profit allocation mechanisms, i.e., linearly\nproportional (LP), leave-one-out (LOO), and Shapley value (SV). We consider two\ntypes of equilibrium structures: symmetric and asymmetric equilibria. We show\nthat the three mechanisms admit an identical symmetric equilibrium structure.\nHowever, at asymmetric equilibrium, LP outperforms SV and LOO in incentivizing\nthe clients' average data contribution. We further discuss the impact of\nvarious parameters on the clients' free-riding behaviors.",
    "descriptor": "",
    "authors": [
      "Chao Huang",
      "Huanle Zhang",
      "Xin Liu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.03885"
  },
  {
    "id": "arXiv:2203.03886",
    "title": "Boosting Mask R-CNN Performance for Long, Thin Forensic Traces with  Pre-Segmentation and IoU Region Merging",
    "abstract": "Mask R-CNN has recently achieved great success in the field of instance\nsegmentation. However, weaknesses of the algorithm have been repeatedly pointed\nout as well, especially in the segmentation of long, sparse objects whose\norientation is not exclusively horizontal or vertical. We present here an\napproach that significantly improves the performance of the algorithm by first\npre-segmenting the images with a PSPNet algorithm. To further improve its\nprediction, we have developed our own cost functions and heuristics in the form\nof training strategies, which can prevent so-called (early) overfitting and\nachieve a more targeted convergence. Furthermore, due to the high variance of\nthe images, especially for PSPNet, we aimed to develop strategies for a high\nrobustness and generalization, which are also presented here.",
    "descriptor": "\nComments: 9 Pages, 19 Figures\n",
    "authors": [
      "Moritz Zink",
      "Martin Schiele",
      "Pengcheng Fan",
      "Stephan Gasterst\u00e4dt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03886"
  },
  {
    "id": "arXiv:2203.03888",
    "title": "ART-Point: Improving Rotation Robustness of Point Cloud Classifiers via  Adversarial Rotation",
    "abstract": "Point cloud classifiers with rotation robustness have been widely discussed\nin the 3D deep learning community. Most proposed methods either use rotation\ninvariant descriptors as inputs or try to design rotation equivariant networks.\nHowever, robust models generated by these methods have limited performance\nunder clean aligned datasets due to modifications on the original classifiers\nor input space. In this study, for the first time, we show that the rotation\nrobustness of point cloud classifiers can also be acquired via adversarial\ntraining with better performance on both rotated and clean datasets.\nSpecifically, our proposed framework named ART-Point regards the rotation of\nthe point cloud as an attack and improves rotation robustness by training the\nclassifier on inputs with Adversarial RoTations. We contribute an axis-wise\nrotation attack that uses back-propagated gradients of the pre-trained model to\neffectively find the adversarial rotations. To avoid model over-fitting on\nadversarial inputs, we construct rotation pools that leverage the\ntransferability of adversarial rotations among samples to increase the\ndiversity of training data. Moreover, we propose a fast one-step optimization\nto efficiently reach the final robust model. Experiments show that our proposed\nrotation attack achieves a high success rate and ART-Point can be used on most\nexisting classifiers to improve the rotation robustness while showing better\nperformance on clean datasets than state-of-the-art methods.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Robin Wang",
      "Yibo Yang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03888"
  },
  {
    "id": "arXiv:2203.03890",
    "title": "ClearPose: Large-scale Transparent Object Dataset and Benchmark",
    "abstract": "Transparent objects are ubiquitous in household settings and pose distinct\nchallenges for visual sensing and perception systems. The optical properties of\ntransparent objects leave conventional 3D sensors alone unreliable for object\ndepth and pose estimation. These challenges are highlighted by the shortage of\nlarge-scale RGB-Depth datasets focusing on transparent objects in real-world\nsettings. In this work, we contribute a large-scale real-world RGB-Depth\ntransparent object dataset named ClearPose to serve as a benchmark dataset for\nsegmentation, scene-level depth completion and object-centric pose estimation\ntasks. The ClearPose dataset contains over 350K labeled real-world RGB-Depth\nframes and 4M instance annotations covering 63 household objects. The dataset\nincludes object categories commonly used in daily life under various lighting\nand occluding conditions as well as challenging test scenarios such as cases of\nocclusion by opaque or translucent objects, non-planar orientations, presence\nof liquids, etc. We benchmark several state-of-the-art depth completion and\nobject pose estimation deep neural networks on ClearPose.",
    "descriptor": "",
    "authors": [
      "Xiaotong Chen",
      "Huijie Zhang",
      "Zeren Yu",
      "Anthony Opipari",
      "Odest Chadwicke Jenkins"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03890"
  },
  {
    "id": "arXiv:2203.03893",
    "title": "Towards Large-Scale Relative Localization in Multi-Robot Systems with  Dynamic UWB Role Allocation",
    "abstract": "Ultra-wideband (UWB) ranging has emerged as a key radio technology for robot\npositioning and relative localization in multi-robot systems. Multiple works\nare now advancing towards more scalable systems, but challenges still remain.\nThis paper proposes a novel approach to relative localization in multi-robot\nsystems where the roles of the UWB nodes are dynamically allocated between\nactive nodes (using time-of-flight for ranging estimation to other active\nnodes) and passive nodes (using time-difference-of-arrival for estimating range\ndifferences with respect to pairs of active nodes). We adaptively update UWB\nroles based on the location of the robots with respect to the convex envelope\ndefined by active nodes, and introducing constraints in the form of\nlocalization frequency and accuracy requirements. We demonstrate the\napplicability of the proposed approach and show that the localization errors\nremain comparable to fixed-role systems. Then, we show how the navigation of an\nautonomous drone is affected by the changes in the localization system,\nobtaining significantly better trajectory tracking accuracy than when relying\nin passive localization only. Our results pave the way for UWB-based\nlocalization in large-scale multi-robot deployments, for either relative\npositioning or for applications in GNSS-denied environments.",
    "descriptor": "\nComments: 8 pages, 7 Figures\n",
    "authors": [
      "Paola Torrico Mor\u00f3n",
      "Jorge Pe\u00f1a Queralta",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03893"
  },
  {
    "id": "arXiv:2203.03897",
    "title": "Multi-Modal Mixup for Robust Fine-tuning",
    "abstract": "Pre-trained large-scale models provide a transferable embedding, and they\nshow comparable performance on the diverse downstream task. However, the\ntransferability of multi-modal learning is restricted, and the analysis of\nlearned embedding has not been explored well. This paper provides a perspective\nto understand the multi-modal embedding in terms of uniformity and alignment.\nWe newly find that the representation learned by multi-modal learning models\nsuch as CLIP has a two separated representation space for each heterogeneous\ndataset with less alignment. Besides, there are unexplored large intermediate\nareas between two modalities with less uniformity. Less robust embedding might\nrestrict the transferability of the representation for the downstream task.\nThis paper provides a new end-to-end fine-tuning method for robust\nrepresentation that encourages better uniformity and alignment score. First, we\npropose a multi-modal Mixup, $m^{2}$-Mix that mixes the representation of image\nand text to generate the hard negative samples. Second, we fine-tune the\nmulti-modal model on a hard negative sample as well as normal negative and\npositive samples with contrastive learning. Our multi-modal Mixup provides a\nrobust representation, and we validate our methods on classification,\nretrieval, and structure-awareness task.",
    "descriptor": "",
    "authors": [
      "Junhyuk So",
      "Changdae Oh",
      "Minchul Shin",
      "Kyungwoo Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03897"
  },
  {
    "id": "arXiv:2203.03898",
    "title": "Yet another DE-Sinc indefinite integration formula",
    "abstract": "Based on the Sinc approximation combined with the tanh transformation, Haber\nderived an approximation formula for numerical indefinite integration over the\nfinite interval (-1, 1). The formula, (SE1) uses a special function for the\nbasis functions. In contrast, Stenger derived another formula (SE2), which does\nnot use any special function but does include a double sum. Subsequently,\nMuhammad and Mori proposed the formula (DE1), which replaces the tanh\ntransformation with the double-exponential transformation in the formula (SE1).\nAlmost simultaneously, Tanaka et al. proposed the formula (DE2), which was\nbased on the same replacement in (SE2). As they reported, the replacement\ndrastically improves the convergence rate of (SE1) and (SE2). In addition to\nthe formulas above, Stenger derived yet another indefinite integration formula\n(SE3) based on the Sinc approximation combined with the tanh transformation,\nwhich has an elegant matrix-vector form. In this paper, we propose the\nreplacement of the tanh transformation with the double-exponential\ntransformation in the formula (SE3). We provide a theoretical analysis as well\nas a numerical comparison.",
    "descriptor": "",
    "authors": [
      "Tomoaki Okayama",
      "Ken'ichiro Tanaka"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.03898"
  },
  {
    "id": "arXiv:2203.03903",
    "title": "InstructionNER: A Multi-Task Instruction-Based Generative Framework for  Few-shot NER",
    "abstract": "Recently, prompt-based methods have achieved significant performance in\nfew-shot learning scenarios by bridging the gap between language model\npre-training and fine-tuning for downstream tasks. However, existing prompt\ntemplates are mostly designed for sentence-level tasks and are inappropriate\nfor sequence labeling objectives. To address the above issue, we propose a\nmulti-task instruction-based generative framework, named InstructionNER, for\nlow-resource named entity recognition. Specifically, we reformulate the NER\ntask as a generation problem, which enriches source sentences with\ntask-specific instructions and answer options, then inferences the entities and\ntypes in natural language. We further propose two auxiliary tasks, including\nentity extraction and entity typing, which enable the model to capture more\nboundary information of entities and deepen the understanding of entity type\nsemantics, respectively. Experimental results show that our method consistently\noutperforms other baselines on five datasets in few-shot settings.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Liwen Wang",
      "Rumei Li",
      "Yang Yan",
      "Yuanmeng Yan",
      "Sirui Wang",
      "Wei Wu",
      "Weiran Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03903"
  },
  {
    "id": "arXiv:2203.03905",
    "title": "End-to-end system for object detection from sub-sampled radar data",
    "abstract": "Robust and accurate sensing is of critical importance for advancing\nautonomous automotive systems. The need to acquire situational awareness in\ncomplex urban conditions using sensors such as radar has motivated research on\npower and latency-efficient signal acquisition methods. In this paper, we\npresent an end-to-end signal processing pipeline, capable of operating in\nextreme weather conditions, that relies on sub-sampled radar data to perform\nobject detection in vehicular settings. The results of the object detection are\nfurther utilized to sub-sample forthcoming radar data, which stands in contrast\nto prior work where the sub-sampling relies on image information. We show\nrobust detection based on radar data reconstructed using 20% of samples under\nextreme weather conditions such as snow or fog, and on low-illuminated nights.\nAdditionally, we generate 20% sampled radar data in a fine-tuning set and show\n1.1% gain in AP50 across scenes and 3% AP50 gain in motorway condition.",
    "descriptor": "\nComments: Submitted to EUSIPCO 2022\n",
    "authors": [
      "Madhumitha Sakthi",
      "Ahmed Tewfik",
      "Marius Arvinte",
      "Haris Vikalo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03905"
  },
  {
    "id": "arXiv:2203.03906",
    "title": "Graph Reinforcement Learning for Predictive Power Allocation to Mobile  Users",
    "abstract": "Allocating resources with future channels can save resource to ensure\nquality-of-service of video streaming. In this paper, we optimize predictive\npower allocation to minimize the energy consumed at distributed units (DUs) by\nusing deep deterministic policy gradient (DDPG) to find optimal policy and\npredict average channel gains. To improve training efficiency, we resort to\ngraph DDPG for exploiting two kinds of relational priors: (a) permutation\nequivariant (PE) and permutation invariant (PI) properties of policy function\nand action-value function, (b) topology relation among users and DUs. To design\ngraph DDPG framework more systematically in harnessing the priors, we first\ndemonstrate how to transform matrix-based DDPG into graph-based DDPG. Then, we\nrespectively design the actor and critic networks to satisfy the permutation\nproperties when graph neural networks are used in embedding and end to-end\nmanners. To avoid destroying the PE/PI properties of the actor and critic\nnetworks, we conceive a batch normalization method. Finally, we show the impact\nof leveraging each prior. Simulation results show that the learned predictive\npolicy performs close to the optimal solution with perfect future information,\nand the graph DDPG algorithms converge much faster than existing DDPG\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Jianyu Zhao",
      "Chenyang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03906"
  },
  {
    "id": "arXiv:2203.03907",
    "title": "On a Simple Connection Between $\u0394$-modular ILP and LP, and a New  Bound on the Number of Integer Vertices",
    "abstract": "Let $A \\in Z^{m \\times n}$, $rank(A) = n$, $b \\in Z^m$, and $P$ be an\n$n$-dimensional polyhedron, induced by the system $A x \\leq b$.\nIt is a known fact that if $F$ is a $k$-face of $P$, then there exist at\nleast $n-k$ linearly independent inequalities of the system $A x \\leq b$ that\nbecome equalities on $F$. In other words, there exists a set of indices $J$,\nsuch that $|J| = n-k$, $rank(A_{JC}) = n-k$, and\n$$\nA_{J} x - b_{J} = 0,\\quad \\text{for any $x \\in F$}.\n$$\nWe show that a similar fact holds for the integer polyhedron\n$$\nP_{I} = conv\\bigl(P \\cap Z^n\\bigr)$$ if we additionally suppose that $P$ is\n$\\Delta$-modular, for some $\\Delta \\in \\{1,2,\\dots\\}$. More precisely, if $F$\nis a $k$-face of $P_{I}$, then there exists a set of indices $J$, such that\n$|J| = n-k$, $rank(A_{J}) = n-k$, and\n$$\n\\|A_{J} x - b_{J}\\|_{\\infty} < \\Delta,\\quad \\text{for any $x \\in F \\cap\nZ^n$.}\n$$ In other words, there exist at least $n-k$ linearly independent\ninequalities of the system $A x \\leq b$ that almost become equalities on $F\n\\cap Z^n$. When we say almost, we mean that the slacks are at most $\\Delta-1$\nin the absolute value. Using this fact, we prove the inequality\n$$\n|vert(P_I)| \\leq 2 \\cdot \\binom{m}{n} \\cdot \\Delta^{n-1},\n$$ for the number of vertices of $P_I$, which is better, than the state of\nthe art bound for $\\Delta = O(n^2)$.",
    "descriptor": "",
    "authors": [
      "D. V. Gribanov",
      "D. S. Malyshev",
      "I. A. Shumilov"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.03907"
  },
  {
    "id": "arXiv:2203.03910",
    "title": "Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced  Training for Neural Machine Translation",
    "abstract": "Neural networks tend to gradually forget the previously learned knowledge\nwhen learning multiple tasks sequentially from dynamic data distributions. This\nproblem is called \\textit{catastrophic forgetting}, which is a fundamental\nchallenge in the continual learning of neural networks. In this work, we\nobserve that catastrophic forgetting not only occurs in continual learning but\nalso affects the traditional static training. Neural networks, especially\nneural machine translation models, suffer from catastrophic forgetting even if\nthey learn from a static training set. To be specific, the final model pays\nimbalanced attention to training samples, where recently exposed samples\nattract more attention than earlier samples. The underlying cause is that\ntraining samples do not get balanced training in each model update, so we name\nthis problem \\textit{imbalanced training}. To alleviate this problem, we\npropose Complementary Online Knowledge Distillation (COKD), which uses\ndynamically updated teacher models trained on specific data orders to\niteratively provide complementary knowledge to the student model. Experimental\nresults on multiple machine translation tasks show that our method successfully\nalleviates the problem of imbalanced training and achieves substantial\nimprovements over strong baseline systems.",
    "descriptor": "\nComments: ACL 2022 main conference\n",
    "authors": [
      "Chenze Shao",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03910"
  },
  {
    "id": "arXiv:2203.03911",
    "title": "Language Matters: A Weakly Supervised Pre-training Approach for Scene  Text Detection and Spotting",
    "abstract": "Recently, Vision-Language Pre-training (VLP) techniques have greatly\nbenefited various vision-language tasks by jointly learning visual and textual\nrepresentations, which intuitively helps in Optical Character Recognition (OCR)\ntasks due to the rich visual and textual information in scene text images.\nHowever, these methods cannot well cope with OCR tasks because of the\ndifficulty in both instance-level text encoding and image-text pair acquisition\n(i.e. images and captured texts in them). This paper presents a weakly\nsupervised pre-training method that can acquire effective scene text\nrepresentations by jointly learning and aligning visual and textual\ninformation. Our network consists of an image encoder and a character-aware\ntext encoder that extract visual and textual features, respectively, as well as\na visual-textual decoder that models the interaction among textual and visual\nfeatures for learning effective scene text representations. With the learning\nof textual features, the pre-trained model can attend texts in images well with\ncharacter awareness. Besides, these designs enable the learning from weakly\nannotated texts (i.e. partial texts in images without text bounding boxes)\nwhich mitigates the data annotation constraint greatly. Experiments over the\nweakly annotated images in ICDAR2019-LSVT show that our pre-trained model\nimproves F-score by +2.5% and +4.8% while transferring its weights to other\ntext detection and spotting networks, respectively. In addition, the proposed\nmethod outperforms existing pre-training techniques consistently across\nmultiple public datasets (e.g., +3.2% and +1.3% for Total-Text and CTW1500).",
    "descriptor": "",
    "authors": [
      "Chuhui Xue",
      "Yu Hao",
      "Shijian Lu",
      "Philip Torr",
      "Song Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03911"
  },
  {
    "id": "arXiv:2203.03914",
    "title": "Globally-Optimal Event Camera Motion Estimation",
    "abstract": "Event cameras are bio-inspired sensors that perform well in HDR conditions\nand have high temporal resolution. However, different from traditional\nframe-based cameras, event cameras measure asynchronous pixel-level brightness\nchanges and return them in a highly discretised format, hence new algorithms\nare needed. The present paper looks at fronto-parallel motion estimation of an\nevent camera. The flow of the events is modeled by a general homographic\nwarping in a space-time volume, and the objective is formulated as a\nmaximisation of contrast within the image of unwarped events. However, in stark\ncontrast to prior art, we derive a globally optimal solution to this generally\nnon-convex problem, and thus remove the dependency on a good initial guess. Our\nalgorithm relies on branch-and-bound optimisation for which we derive novel,\nrecursive upper and lower bounds for six different contrast estimation\nfunctions. The practical validity of our approach is supported by a highly\nsuccessful application to AGV motion estimation with a downward facing event\ncamera, a challenging scenario in which the sensor experiences fronto-parallel\nmotion in front of noisy, fast moving textures.",
    "descriptor": "",
    "authors": [
      "Xin Peng",
      "Yifu Wang",
      "Ling Gao",
      "Laurent Kneip"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03914"
  },
  {
    "id": "arXiv:2203.03917",
    "title": "An Analysis of Measure-Valued Derivatives for Policy Gradients",
    "abstract": "Reinforcement learning methods for robotics are increasingly successful due\nto the constant development of better policy gradient techniques. A precise\n(low variance) and accurate (low bias) gradient estimator is crucial to face\nincreasingly complex tasks. Traditional policy gradient algorithms use the\nlikelihood-ratio trick, which is known to produce unbiased but high variance\nestimates. More modern approaches exploit the reparametrization trick, which\ngives lower variance gradient estimates but requires differentiable value\nfunction approximators. In this work, we study a different type of stochastic\ngradient estimator - the Measure-Valued Derivative. This estimator is unbiased,\nhas low variance, and can be used with differentiable and non-differentiable\nfunction approximators. We empirically evaluate this estimator in the\nactor-critic policy gradient setting and show that it can reach comparable\nperformance with methods based on the likelihood-ratio or reparametrization\ntricks, both in low and high-dimensional action spaces. With this work, we want\nto show that the Measure-Valued Derivative estimator can be a useful\nalternative to other policy gradient estimators.",
    "descriptor": "",
    "authors": [
      "Joao Carvalho",
      "Jan Peters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03917"
  },
  {
    "id": "arXiv:2203.03918",
    "title": "Residual Robot Learning for Object-Centric Probabilistic Movement  Primitives",
    "abstract": "It is desirable for future robots to quickly learn new tasks and adapt\nlearned skills to constantly changing environments. To this end, Probabilistic\nMovement Primitives (ProMPs) have shown to be a promising framework to learn\ngeneralizable trajectory generators from distributions over demonstrated\ntrajectories. However, in practical applications that require high precision in\nthe manipulation of objects, the accuracy of ProMPs is often insufficient, in\nparticular when they are learned in cartesian space from external observations\nand executed with limited controller gains. Therefore, we propose to combine\nProMPs with recently introduced Residual Reinforcement Learning (RRL), to\naccount for both, corrections in position and orientation during task\nexecution. In particular, we learn a residual on top of a nominal ProMP\ntrajectory with Soft-Actor Critic and incorporate the variability in the\ndemonstrations as a decision variable to reduce the search space for RRL. As a\nproof of concept, we evaluate our proposed method on a 3D block insertion task\nwith a 7-DoF Franka Emika Panda robot. Experimental results show that the robot\nsuccessfully learns to complete the insertion which was not possible before\nwith using basic ProMPs.",
    "descriptor": "",
    "authors": [
      "Joao Carvalho",
      "Dorothea Koert",
      "Marek Daniv",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03918"
  },
  {
    "id": "arXiv:2203.03919",
    "title": "A Hierarchical Approach to Active Pose Estimation",
    "abstract": "Creating mobile robots which are able to find and manipulate objects in large\nenvironments is an active topic of research. These robots not only need to be\ncapable of searching for specific objects but also to estimate their poses\noften relying on environment observations, which is even more difficult in the\npresence of occlusions. Therefore, to tackle this problem we propose a simple\nhierarchical approach to estimate the pose of a desired object. An Active\nVisual Search module operating with RGB images first obtains a rough estimation\nof the object 2D pose, followed by a more computationally expensive Active Pose\nEstimation module using point cloud data. We empirically show that processing\nimage features to obtain a richer observation speeds up the search and pose\nestimation computations, in comparison to a binary decision that indicates\nwhether the object is or not in the current image.",
    "descriptor": "",
    "authors": [
      "Jascha Hellwig",
      "Mark Baierl",
      "Joao Carvalho",
      "Julen Urain",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03919"
  },
  {
    "id": "arXiv:2203.03923",
    "title": "ROLL: Long-Term Robust LiDAR-based Localization With Temporary Mapping  in Changing Environments",
    "abstract": "Long-term scene changes present challenges to localization systems using a\npre-built map. This paper presents a LiDAR-based system that can provide robust\nlocalization against those challenges. Our method starts with activation of a\nmapping process temporarily when global matching towards the pre-built map is\nunreliable. The temporary map will be merged onto the pre-built map for later\nlocalization runs once reliable matching is obtained again. We further\nintegrate a LiDAR inertial odometry (LIO) to provide motion-compensated LiDAR\nscans and a reliable initial pose guess for the global matching module. To\ngenerate a smooth real-time trajectory for navigation purposes, we fuse poses\nfrom odometry and global matching by solving a pose graph optimization problem.\nWe evaluate our localization system with extensive experiments on the NCLT\ndataset including a variety of changing indoor and outdoor environments, and\nthe results demonstrate a robust and accurate localization performance for over\na year. The implementations are open sourced on GitHub.",
    "descriptor": "",
    "authors": [
      "Bin Peng",
      "Hongle Xie",
      "Weidong Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03923"
  },
  {
    "id": "arXiv:2203.03926",
    "title": "Numerical simulation of sound propagation in and around ducts using thin  boundary elements",
    "abstract": "Investigating the sound field in and around ducts is an important topic in\nacoustics, e.g. when simulating musical instruments or the human vocal tract.\nIn this paper a method that is based on the boundary element method in 3D\ncombined with a formulation for infinitely thin elements is presented. The\nboundary integral equations for these elements are presented, and numerical\nexperiments are used to illustrate the behavior of the thin elements. Using the\nexample of a closed benchmark duct, boundary element solutions for thin\nelements and surface elements are compared with the analytic solution, and the\naccuracy of the boundary element method as function of element size is\ninvestigated. As already shown for surface elements in the literature, an\naccumulation of the error along the duct can also be found for thin elements,\nbut in contrast to surface elements this effect is not as big and a damping of\nthe amplitude cannot be seen. In a second experiment, the impedance at the open\nend of a half open duct is compared with formulas for the radiation impedance\nof an unflanged tube, and a good agreement is shown. Finally, resonance\nfrequencies of a tube open at both ends are calculated and compared with\nmeasured spectra. For sufficiently small element sizes frequencies for lower\nharmonics agree very well, for higher frequencies a difference of a few Hertz\ncan be observed, which may be explained by the fact that the method does not\nconsider dampening effects near the duct walls. The numerical experiments also\nsuggest, that for duct simulations the usual six to eight elements per\nwavelength rule is not enough for accurate results.",
    "descriptor": "\nComments: 38 pages, 19 figures, submitted to Journal of Sound and Vibration\n",
    "authors": [
      "Wolfgang Kreuzer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.03926"
  },
  {
    "id": "arXiv:2203.03927",
    "title": "Quadruped Guidance Robot for the Visually Impaired: A Comfort-Based  Approach",
    "abstract": "A quadrupedal guidance robot that can guide people and avoid various\nobstacles, could potentially be owned by more visually impaired people at a\nfairly low cost. In this paper, we propose a novel guidance robot system with a\ncomfort-based concept. We design a leash containing an elastic rope and a thin\nstring, and use a motor to adjust the length of the string to ensure comfort.\nWe use the force-based human motion model to plan the forces experienced by the\nhuman. Afterward, the direction and magnitude of the force are controlled by\nthe motion of the robot, and the rotation of the motor, respectively. This\nallows humans to be guided safely and more comfortably to the target position\nin complex environments. The system has been deployed on Unitree Laikago\nquadrupedal platform and validated in real-world scenarios.",
    "descriptor": "\nComments: Submitted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022\n",
    "authors": [
      "Yanbo Chen",
      "Zhengzhe Xu",
      "Zhuozhu Jian",
      "Gengpan Tang",
      "Yunong Yangli",
      "Anxing Xiao",
      "Xueqian Wang",
      "Bin Liang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03927"
  },
  {
    "id": "arXiv:2203.03929",
    "title": "Quantifying Privacy Risks of Masked Language Models Using Membership  Inference Attacks",
    "abstract": "The wide adoption and application of Masked language models~(MLMs) on\nsensitive data (from legal to medical) necessitates a thorough quantitative\ninvestigation into their privacy vulnerabilities -- to what extent do MLMs leak\ninformation about their training data? Prior attempts at measuring leakage of\nMLMs via membership inference attacks have been inconclusive, implying the\npotential robustness of MLMs to privacy attacks. In this work, we posit that\nprior attempts were inconclusive because they based their attack solely on the\nMLM's model score. We devise a stronger membership inference attack based on\nlikelihood ratio hypothesis testing that involves an additional reference MLM\nto more accurately quantify the privacy risks of memorization in MLMs. We show\nthat masked language models are extremely susceptible to likelihood ratio\nmembership inference attacks: Our empirical results, on models trained on\nmedical notes, show that our attack improves the AUC of prior membership\ninference attacks from 0.66 to an alarmingly high 0.90 level, with a\nsignificant improvement in the low-error region: at 1% false positive rate, our\nattack is 51X more powerful than prior work.",
    "descriptor": "",
    "authors": [
      "Fatemehsadat Mireshghallah",
      "Kartik Goyal",
      "Archit Uniyal",
      "Taylor Berg-Kirkpatrick",
      "Reza Shokri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.03929"
  },
  {
    "id": "arXiv:2203.03930",
    "title": "Integral representations for higher-order Fr\u00e9chet derivatives of  matrix functions: Quadrature algorithms and new results on the level-2  condition number",
    "abstract": "We propose an integral representation for the higher-order Fr\\'echet\nderivative of analytic matrix functions $f(A)$ which unifies known results for\nthe first-order Fr\\'echet derivative of general analytic matrix functions and\nfor higher-order Fr\\'echet derivatives of $A^{-1}$. We highlight two\napplications of this integral representation: On the one hand, it allows to\nfind the exact value of the level-2 condition number (i.e., the condition\nnumber of the condition number) of $f(A)$ for a large class of functions $f$\nwhen $A$ is Hermitian. On the other hand, it also allows to use numerical\nquadrature methods to approximate higher-order Fr\\'echet derivatives. We\ndemonstrate that in certain situations -- in particular when the derivative\norder $k$ is moderate and the direction terms in the derivative have low-rank\nstructure -- the resulting algorithm can outperform established methods from\nthe literature by a large margin.",
    "descriptor": "",
    "authors": [
      "Marcel Schweitzer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.03930"
  },
  {
    "id": "arXiv:2203.03931",
    "title": "Part-Aware Self-Supervised Pre-Training for Person Re-Identification",
    "abstract": "In person re-identification (ReID), very recent researches have validated\npre-training the models on unlabelled person images is much better than on\nImageNet. However, these researches directly apply the existing self-supervised\nlearning (SSL) methods designed for image classification to ReID without any\nadaption in the framework. These SSL methods match the outputs of local views\n(e.g., red T-shirt, blue shorts) to those of the global views at the same time,\nlosing lots of details. In this paper, we propose a ReID-specific pre-training\nmethod, Part-Aware Self-Supervised pre-training (PASS), which can generate\npart-level features to offer fine-grained information and is more suitable for\nReID. PASS divides the images into several local areas, and the local views\nrandomly cropped from each area are assigned with a specific learnable [PART]\ntoken. On the other hand, the [PART]s of all local areas are also appended to\nthe global views. PASS learns to match the output of the local views and global\nviews on the same [PART]. That is, the learned [PART] of the local views from a\nlocal area is only matched with the corresponding [PART] learned from the\nglobal views. As a result, each [PART] can focus on a specific local area of\nthe image and extracts fine-grained information of this area. Experiments show\nPASS sets the new state-of-the-art performances on Market1501 and MSMT17 on\nvarious ReID tasks, e.g., vanilla ViT-S/16 pre-trained by PASS achieves\n92.2\\%/90.2\\%/88.5\\% mAP accuracy on Market1501 for supervised/UDA/USL ReID.\nOur codes are available at https://github.com/CASIA-IVA-Lab/PASS-reID.",
    "descriptor": "",
    "authors": [
      "Kuan Zhu",
      "Haiyun Guo",
      "Tianyi Yan",
      "Yousong Zhu",
      "Jinqiao Wang",
      "Ming Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03931"
  },
  {
    "id": "arXiv:2203.03932",
    "title": "Digital Speech Algorithms for Speaker De-Identification",
    "abstract": "The present work is based on the COST Action IC1206 for De-identification in\nmultimedia content. It was performed to test four algorithms of voice\nmodifications on a speech gender recognizer to find the degree of modification\nof pitch when the speech recognizer have the probability of success equal to\nthe probability of failure. The purpose of this analysis is to assess the\nintensity of the speech tone modification, the quality, the reversibility and\nnot-reversibility of the changes made.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Stefano Marinozzi",
      "Marcos Faundez-Zanuy"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.03932"
  },
  {
    "id": "arXiv:2203.03933",
    "title": "A Preliminary Study on Aging Examining Online Handwriting",
    "abstract": "In order to develop infocommunications devices so that the capabilities of\nthe human brain may interact with the capabilities of any artificially\ncognitive system a deeper knowledge of aging is necessary. Especially if\nsociety does not want to exclude elder people and wants to develop automatic\nsystems able to help and improve the quality of life of this group of\npopulation, healthy individuals as well as those with cognitive decline or\nother pathologies. This paper tries to establish the variations in handwriting\ntasks with the goal to obtain a better knowledge about aging. We present the\ncorrelation results between several parameters extracted from online\nhandwriting and the age of the writers. It is based on BIOSECURID database,\nwhich consists of 400 people that provided several biometric traits, including\nonline handwriting. The main idea is to identify those parameters that are more\nstable and those more age dependent. One challenging topic for disease diagnose\nis the differentiation between healthy and pathological aging. For this\npurpose, it is necessary to be aware of handwriting parameters that are, in\ngeneral, not affected by aging and those who experiment changes, increase or\ndecrease their values, because of it. This paper contributes to this research\nline analyzing a selected set of online handwriting parameters provided by a\nhealthy group of population aged from 18 to 70 years. Preliminary results show\nthat these parameters are not affected by aging and therefore, changes in their\nvalues can only be attributed to motor or cognitive disorders.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Marcos Faundez-Zanuy",
      "Enric Sesa-Nogueras",
      "Josep Roure-Alcob\u00e9",
      "Anna Esposito",
      "Jiri Mekyska",
      "Karmele L\u00f3pez-de-Ipi\u00f1a"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03933"
  },
  {
    "id": "arXiv:2203.03934",
    "title": "Nonlinear Isometric Manifold Learning for Injective Normalizing Flows",
    "abstract": "To model manifold data using normalizing flows, we propose to employ the\nisometric autoencoder to design nonlinear encodings with explicit inverses. The\nisometry allows us to separate manifold learning and density estimation and\ntrain both parts to high accuracy. Applied to the MNIST data set, the combined\napproach generates high-quality images.",
    "descriptor": "\nComments: 10 pages, 5 figures, 3 tables\n",
    "authors": [
      "Eike Cramer",
      "Felix Rauh",
      "Alexander Mitsos",
      "Ra\u00fal Tempone",
      "Manuel Dahmen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03934"
  },
  {
    "id": "arXiv:2203.03937",
    "title": "Dynamic Group Transformer: A General Vision Transformer Backbone with  Dynamic Group Attention",
    "abstract": "Recently, Transformers have shown promising performance in various vision\ntasks. To reduce the quadratic computation complexity caused by each query\nattending to all keys/values, various methods have constrained the range of\nattention within local regions, where each query only attends to keys/values\nwithin a hand-crafted window. However, these hand-crafted window partition\nmechanisms are data-agnostic and ignore their input content, so it is likely\nthat one query maybe attends to irrelevant keys/values. To address this issue,\nwe propose a Dynamic Group Attention (DG-Attention), which dynamically divides\nall queries into multiple groups and selects the most relevant keys/values for\neach group. Our DG-Attention can flexibly model more relevant dependencies\nwithout any spatial constraint that is used in hand-crafted window based\nattention. Built on the DG-Attention, we develop a general vision transformer\nbackbone named Dynamic Group Transformer (DGT). Extensive experiments show that\nour models can outperform the state-of-the-art methods on multiple common\nvision tasks, including image classification, semantic segmentation, object\ndetection, and instance segmentation.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Kai Liu",
      "Tianyi Wu",
      "Cong Liu",
      "Guodong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03937"
  },
  {
    "id": "arXiv:2203.03938",
    "title": "Drivers and challenges of internet of things diffusion in smart stores:  A field exploration",
    "abstract": "The digitally disruptive environment has evolved rapidly due to the\nintroduction of new advancements within the field of smart applications.\nApplications of one of the most prominent technologies, Internet of Things\n(IoT), often appear in the retail sector, where smart services have transformed\nthe customer experience holistically. Presented in this paper are the findings\nfrom an exploratory field study in the retail service sector, which drew on the\nviews of experienced practitioners about the smart store experience and the\nassociated changes. The paper presents an overview of the drivers of smart\nretail service diffusion and the relevant challenges, such as the business\nexpectations and the heterogeneity of devices. The arising themes indicate that\nIoT security is a major challenge for businesses installing IoT devices in\ntheir journey towards smart store transformation. The paper highlights the\nimportance of a secure data-sharing IoT environment that respects customer\nprivacy as the smart experience in-store offers data-driven insights and\nservices. Implications for research and practice are discussed in terms of the\ncustomer experience relevant to the identified challenges.",
    "descriptor": "",
    "authors": [
      "Michael Roe",
      "Konstantina Spanaki",
      "Athina Ioannou",
      "Efpraxia Zamani",
      "Mihalis Giannakis"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.03938"
  },
  {
    "id": "arXiv:2203.03943",
    "title": "mwp-Analysis Improvement and Implementation: Realizing Implicit  Computational Complexity",
    "abstract": "Implicit Computational Complexity (ICC) drives better understanding of\ncomplexity classes, but it also guides the development of resources-aware\nlanguages and static source code analyzers. Among the methods developed, the\nmwp-flow analysis certifies polynomial bounds on the size of the values\nmanipulated by an imperative program. This result is obtained by bounding the\ntransitions between states instead of focusing on states in isolation, as most\nstatic analyzers do, and is not concerned with termination or tight bounds on\nvalues. Those differences, along with its built-in compositionality, make the\nmwp-flow analysis a good target for determining how ICC-inspired techniques\ndiverge compared with more traditional static analysis methods. This paper's\ncontributions are threefold: we fine-tune the internal machinery of the\noriginal analysis to make it tractable in practice; we extend the analysis to\nfunction calls and leverage its machinery to compute the result of the analysis\nefficiently; and we implement the resulting analysis as a lightweight tool to\nautomatically perform data-size analysis of C programs. This documented effort\nprepares and enables the development of certified complexity analysis, by\ntransforming a costly analysis into a tractable program, that furthermore\ndecorrelates the problem of deciding if a bound exist with the problem of\ncomputing it.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Aubert",
      "Thomas Rubiano",
      "Neea Rusch",
      "Thomas Seiller"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.03943"
  },
  {
    "id": "arXiv:2203.03944",
    "title": "An Online Semantic Mapping System for Extending and Enhancing Visual  SLAM",
    "abstract": "We present a real-time semantic mapping approach for mobile vision systems\nwith a 2D to 3D object detection pipeline and rapid data association for\ngenerated landmarks. Besides the semantic map enrichment the associated\ndetections are further introduced as semantic constraints into a simultaneous\nlocalization and mapping (SLAM) system for pose correction purposes. This way,\nwe are able generate additional meaningful information that allows to achieve\nhigher-level tasks, while simultaneously leveraging the view-invariance of\nobject detections to improve the accuracy and the robustness of the odometry\nestimation. We propose tracklets of locally associated object observations to\nhandle ambiguous and false predictions and an uncertainty-based greedy\nassociation scheme for an accelerated processing time. Our system reaches\nreal-time capabilities with an average iteration duration of 65~ms and is able\nto improve the pose estimation of a state-of-the-art SLAM by up to 68% on a\npublic dataset. Additionally, we implemented our approach as a modular ROS\npackage that makes it straightforward for integration in arbitrary graph-based\nSLAM methods.",
    "descriptor": "\nComments: Accepted by Engineering Applications of Artificial Intelligence, Elsevier, 7 Mar 2022\n",
    "authors": [
      "Thorsten Hempel",
      "Ayoub Al-Hamadi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03944"
  },
  {
    "id": "arXiv:2203.03947",
    "title": "Combinatorial expression of Hopf polynomial invariants",
    "abstract": "In 2017 Aguiar and Ardila provided a generic way to construct polynomial\ninvariants of combinatorial objects using the notions of Hopf monoids and\ncharacters of Hopf monoids. They show that it is possible to find a\ncombinatorial interpretation of these polynomials over negative integers using\nthe antipode and give a cancellation-free grouping-free formula for the\nantipode on generalized permutahedra. In this work, we give a combinatorial\ninterpretation of these polynomials over both positive integers and negative\nintegers for the Hopf monoids of generalized permutahedra and hypergraphs and\nfor every character on these two Hopf monoids. In the case of hypergraphs, we\npresent two different proofs for the interpretation on negative integers. We\nthen deduce similar results on other combinatorial objects including graphs,\nsimplicial complexes and building sets.",
    "descriptor": "",
    "authors": [
      "Th\u00e9o Karaboghossian"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.03947"
  },
  {
    "id": "arXiv:2203.03949",
    "title": "RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering",
    "abstract": "Finding accurate correspondences among different views is the Achilles' heel\nof unsupervised Multi-View Stereo (MVS). Existing methods are built upon the\nassumption that corresponding pixels share similar photometric features.\nHowever, multi-view images in real scenarios observe non-Lambertian surfaces\nand experience occlusions. In this work, we propose a novel approach with\nneural rendering (RC-MVSNet) to solve such ambiguity issues of correspondences\namong views. Specifically, we impose a depth rendering consistency loss to\nconstrain the geometry features close to the object surface to alleviate\nocclusions. Concurrently, we introduce a reference view synthesis loss to\ngenerate consistent supervision, even for non-Lambertian surfaces. Extensive\nexperiments on DTU and Tanks\\&Temples benchmarks demonstrate that our RC-MVSNet\napproach achieves state-of-the-art performance over unsupervised MVS frameworks\nand competitive performance to many supervised methods.The trained models and\ncode will be released at https://github.com/Boese0601/RC-MVSNet.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Di Chang",
      "Alja\u017e Bo\u017ei\u010d",
      "Tong Zhang",
      "Qingsong Yan",
      "Yingcong Chen",
      "Sabine S\u00fcsstrunk",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03949"
  },
  {
    "id": "arXiv:2203.03951",
    "title": "Efficient and Accurate Hyperspectral Pansharpening Using 3D VolumeNet  and 2.5D Texture Transfer",
    "abstract": "Recently, convolutional neural networks (CNN) have obtained promising results\nin single-image SR for hyperspectral pansharpening. However, enhancing CNNs'\nrepresentation ability with fewer parameters and a shorter prediction time is a\nchallenging and critical task. In this paper, we propose a novel multi-spectral\nimage fusion method using a combination of the previously proposed 3D CNN model\nVolumeNet and 2.5D texture transfer method using other modality high resolution\n(HR) images. Since a multi-spectral (MS) image consists of several bands and\neach band is a 2D image slice, MS images can be seen as 3D data. Thus, we use\nthe previously proposed VolumeNet to fuse HR panchromatic (PAN) images and\nbicubic interpolated MS images. Because the proposed 3D VolumeNet can\neffectively improve the accuracy by expanding the receptive field of the model,\nand due to its lightweight structure, we can achieve better performance against\nthe existing method without purchasing a large number of remote sensing images\nfor training. In addition, VolumeNet can restore the high-frequency information\nlost in the HR MR image as much as possible, reducing the difficulty of feature\nextraction in the following step: 2.5D texture transfer. As one of the latest\ntechnologies, deep learning-based texture transfer has been demonstrated to\neffectively and efficiently improve the visual performance and quality\nevaluation indicators of image reconstruction. Different from the texture\ntransfer processing of RGB image, we use HR PAN images as the reference images\nand perform texture transfer for each frequency band of MS images, which is\nnamed 2.5D texture transfer. The experimental results show that the proposed\nmethod outperforms the existing methods in terms of objective accuracy\nassessment, method efficiency, and visual subjective evaluation.",
    "descriptor": "",
    "authors": [
      "Yinao Li",
      "Yutaro Iwamoto",
      "Ryousuke Nakamura",
      "Lanfen Lin",
      "Ruofeng Tong",
      "Yen-Wei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03951"
  },
  {
    "id": "arXiv:2203.03952",
    "title": "EdgeFormer: Improving Light-weight ConvNets by Learning from Vision  Transformers",
    "abstract": "Recently, vision transformers started to show impressive results which\noutperform large convolution based models significantly. However, in the area\nof small models for mobile or resource constrained devices, ConvNet still has\nits own advantages in both performance and model complexity. We propose\nEdgeFormer, a pure ConvNet based backbone model that further strengthens these\nadvantages by fusing the merits of vision transformers into ConvNets.\nSpecifically, we propose global circular convolution (GCC) with position\nembeddings, a light-weight convolution op which boasts a global receptive field\nwhile producing location sensitive features as in local convolutions. We\ncombine the GCCs and squeeze-exictation ops to form a meta-former like model\nblock, which further has the attention mechanism like transformers. The\naforementioned block can be used in plug-and-play manner to replace relevant\nblocks in ConvNets or transformers. Experiment results show that the proposed\nEdgeFormer achieves better performance than popular light-weight ConvNets and\nvision transformer based models in common vision tasks and datasets, while\nhaving fewer parameters and faster inference speed. For classification on\nImageNet-1k, EdgeFormer achieves 78.6% top-1 accuracy with about 5.0 million\nparameters, saving 11% parameters and 13% computational cost but gaining 0.2%\nhigher accuracy and 23% faster inference speed (on ARM based Rockchip RK3288)\ncompared with MobileViT, and uses only 0.5 times parameters but gaining 2.7%\naccuracy compared with DeIT. On MS-COCO object detection and PASCAL VOC\nsegmentation tasks, EdgeFormer also shows better performance.",
    "descriptor": "\nComments: 14 pages, 7 figures and 4 tables\n",
    "authors": [
      "Haokui Zhang",
      "Wenze Hu",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03952"
  },
  {
    "id": "arXiv:2203.03957",
    "title": "The Internet of Things enabling communication technologies, applications  and challenges: a survey",
    "abstract": "Recently, the IoT has gained great importance, which results in the evolution\nof communication technologies to meet the needs of different IoT applications.\nIn addition, several domains integrate the IoT technologies in several\napplications of our professional life and daily activities. However, the IoT\nstill presents many challenges and issues. This article describes in details\nthe emerging communication technologies used in the IoT networks and enumerates\nthe common domains of their application. It also describes the main challenges\nof the IoT and its use in order to exploit its advantages at most.",
    "descriptor": "",
    "authors": [
      "Sihem Tlili",
      "Sami Mnasri",
      "Thierry Val"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.03957"
  },
  {
    "id": "arXiv:2203.03958",
    "title": "Betweenness Approximation for Hypernetwork Dismantling with Hypergraph  Neural Network",
    "abstract": "The purpose of Network Dismantling (ND) is to find an optimal set of nodes\nand removing these nodes can greatly decrease the network connectivity.\nHowever, current dismantling methods are mainly focus on traditional simple\nnetwork which only consider the pairwise interaction between two nodes, while\nthe hypernetwork, which can model higher order groupwise relation among\narbitrary nodes, is more suitable for modeling real world. Due to the\nstructural difference between simple network and hypernetwork, current\ndismantling methods cannot be directly applied to hypernetwork dismantling.\nAlthough some centrality measures in hypernetwork can be used for hypernetwork\ndismantling, they face the problem of banlancing effect and efficiency.\nTherefore, in this paper, we propose a novel HyperNetwork Dismantling methods\nbased on hypergraph neural network, called HND. Specifically, our method first\ngenerates plenty of node ranking samples with the help of synthetic\nhypernetwork generator. Then, a node betweenness approximation model in\nhypernetwork is built based on hypergraph neural network. And this model is\ntrained on those ranking samples generated in previous step until convergence.\nFinally, the well-trained model is utilized to approximate the nodes'\nbetweenness in real world hypernetworks and further used for dismantling. To\nconfirm the effectiveness of our method, we conduct extensive experiments on\nfive real world hypernetworks. The experimental results demostrate that the HND\noutperforms various baselines.",
    "descriptor": "",
    "authors": [
      "Dengcheng Yan",
      "Wenxin Xie",
      "Yiwen Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.03958"
  },
  {
    "id": "arXiv:2203.03959",
    "title": "Enhancing Door Detection for Autonomous Mobile Robots with  Environment-Specific Data Collection",
    "abstract": "Door detection represents a fundamental capability for autonomous mobile\nrobots employed in tasks involving indoor navigation. Recognizing the presence\nof a door and its status (open or closed) can induce a remarkable impact on the\nnavigation performance, especially for dynamic settings where doors can enable\nor disable passages, hence changing the actual topology of the map. In this\nwork, we address the problem of building a door detector module for an\nautonomous mobile robot deployed in a long-term scenario, namely operating in\nthe same environment for a long time, thus observing the same set of doors from\ndifferent points of view. First, we show how the mainstream approach for door\ndetection, based on object recognition, falls short in considering the\nconstrained perception setup typical of a mobile robot. Hence, we devise a\nmethod to build a dataset of images taken from a robot's perspective and we\nexploit it to obtain a door detector based on an established deep-learning\nobject-recognition method. We then exploit the long-term assumption of our\nscenario to qualify the model on the robot working environment via fine-tuning\nwith additional images acquired in the deployment environment. Our experimental\nanalysis shows how this method can achieve good performance and highlights a\ntrade-off between costs and benefits of the fine-tuning approach.",
    "descriptor": "\nComments: Preprint submitted for revision at IROS 2022\n",
    "authors": [
      "Michele Antonazzi",
      "Matteo Luperto",
      "Nicola Basilico",
      "N. Alberto Borghese"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03959"
  },
  {
    "id": "arXiv:2203.03961",
    "title": "Computing roadmaps in unbounded smooth real algebraic sets I:  connectivity results",
    "abstract": "Answering connectivity queries in real algebraic sets is a fundamental\nproblem in effective real algebraic geometry that finds many applications in\ne.g. robotics where motion planning issues are topical. This computational\nproblem is tackled through the computation of so-called roadmaps which are real\nalgebraic subsets of the set V under study, of dimension at most one, and which\nhave a connected intersection with all semi-algebraically connected components\nof V. Algorithms for computing roadmaps rely on statements establishing\nconnectivity properties of some well-chosen subsets of V , assuming that V is\nbounded. In this paper, we extend such connectivity statements by dropping the\nboundedness assumption on V. This exploits properties of so-called generalized\npolar varieties, which are critical loci of V for some well-chosen polynomial\nmaps.",
    "descriptor": "",
    "authors": [
      "R\u00e9mi Pr\u00e9bet",
      "Mohab Safey El Din",
      "\u00c9ric Schost"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2203.03961"
  },
  {
    "id": "arXiv:2203.03962",
    "title": "Generative Cooperative Learning for Unsupervised Video Anomaly Detection",
    "abstract": "Video anomaly detection is well investigated in weakly-supervised and\none-class classification (OCC) settings. However, unsupervised video anomaly\ndetection methods are quite sparse, likely because anomalies are less frequent\nin occurrence and usually not well-defined, which when coupled with the absence\nof ground truth supervision, could adversely affect the performance of the\nlearning algorithms. This problem is challenging yet rewarding as it can\ncompletely eradicate the costs of obtaining laborious annotations and enable\nsuch systems to be deployed without human intervention. To this end, we propose\na novel unsupervised Generative Cooperative Learning (GCL) approach for video\nanomaly detection that exploits the low frequency of anomalies towards building\na cross-supervision between a generator and a discriminator. In essence, both\nnetworks get trained in a cooperative fashion, thereby allowing unsupervised\nlearning. We conduct extensive experiments on two large-scale video anomaly\ndetection datasets, UCF crime, and ShanghaiTech. Consistent improvement over\nthe existing state-of-the-art unsupervised and OCC methods corroborate the\neffectiveness of our approach.",
    "descriptor": "\nComments: Accepted to the Conference on Computer Vision and Pattern Recognition CVPR 2022\n",
    "authors": [
      "Muhammad Zaigham Zaheer",
      "Arif Mahmood",
      "Muhammad Haris Khan",
      "Mattia Segu",
      "Fisher Yu",
      "Seung-Ik Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03962"
  },
  {
    "id": "arXiv:2203.03963",
    "title": "Reaching Efficient Byzantine Agreements in Bipartite Networks",
    "abstract": "For reaching efficient deterministic synchronous Byzantine agreement upon\npartially connected networks, the traditional broadcast primitive is extended\nand integrated with a general framework. With this, the Byzantine agreement is\nextended to fully connected bipartite networks and some bipartite\nbounded-degree networks. The complexity of the Byzantine agreement is lowered\nand optimized with the so-called Byzantine-levers under a general system\nstructure. Some bipartite simulation of the butterfly networks and some finer\nproperties of bipartite bounded-degree networks are also provided for building\nefficient incomplete Byzantine agreement under the same system structure. It\nshows that efficient real-world Byzantine agreement systems can be built with\nthe provided algorithms with sufficiently high system assumption coverage.\nMeanwhile, the proposed bipartite solutions can improve the dependability of\nthe systems in some open, heterogeneous, and even antagonistic environments.",
    "descriptor": "\nComments: 24 pages, 5 figures\n",
    "authors": [
      "Shaolin Yu",
      "Jihong Zhu",
      "Jiali Yang",
      "Wei Lu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.03963"
  },
  {
    "id": "arXiv:2203.03965",
    "title": "Few-Shot Traffic Prediction with Graph Networks using Locale as  Relational Inductive Biases",
    "abstract": "Accurate short-term traffic prediction plays a pivotal role in various smart\nmobility operation and management systems. Currently, most of the\nstate-of-the-art prediction models are based on graph neural networks (GNNs),\nand the required training samples are proportional to the size of the traffic\nnetwork. In many cities, the available amount of traffic data is substantially\nbelow the minimum requirement due to the data collection expense. It is still\nan open question to develop traffic prediction models with a small size of\ntraining data on large-scale networks. We notice that the traffic states of a\nnode for the near future only depend on the traffic states of its localized\nneighborhoods, which can be represented using the graph relational inductive\nbiases. In view of this, this paper develops a graph network (GN)-based deep\nlearning model LocaleGn that depicts the traffic dynamics using localized data\naggregating and updating functions, as well as the node-wise recurrent neural\nnetworks. LocaleGn is a light-weighted model designed for training on few\nsamples without over-fitting, and hence it can solve the problem of few-shot\ntraffic prediction. The proposed model is examined on predicting both traffic\nspeed and flow with six datasets, and the experimental results demonstrate that\nLocaleGn outperforms existing state-of-the-art baseline models. It is also\ndemonstrated that the learned knowledge from LocaleGn can be transferred across\ncities. The research outcomes can help to develop light-weighted traffic\nprediction systems, especially for cities lacking in historically archived\ntraffic data.",
    "descriptor": "",
    "authors": [
      "Mingxi Li",
      "Yihong Tang",
      "Wei Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.03965"
  },
  {
    "id": "arXiv:2203.03966",
    "title": "GaitStrip: Gait Recognition via Effective Strip-based Feature  Representations and Multi-Level Framework",
    "abstract": "Many gait recognition methods first partition the human gait into N-parts and\nthen combine them to establish part-based feature representations. Their gait\nrecognition performance is often affected by partitioning strategies, which are\nempirically chosen in different datasets. However, we observe that strips as\nthe basic component of parts are agnostic against different partitioning\nstrategies. Motivated by this observation, we present a strip-based multi-level\ngait recognition network, named GaitStrip, to extract comprehensive gait\ninformation at different levels. To be specific, our high-level branch explores\nthe context of gait sequences and our low-level one focuses on detailed posture\nchanges. We introduce a novel StriP-Based feature extractor (SPB) to learn the\nstrip-based feature representations by directly taking each strip of the human\nbody as the basic unit. Moreover, we propose a novel multi-branch structure,\ncalled Enhanced Convolution Module (ECM), to extract different representations\nof gaits. ECM consists of the Spatial-Temporal feature extractor (ST), the\nFrame-Level feature extractor (FL) and SPB, and has two obvious advantages:\nFirst, each branch focuses on a specific representation, which can be used to\nimprove the robustness of the network. Specifically, ST aims to extract\nspatial-temporal features of gait sequences, while FL is used to generate the\nfeature representation of each frame. Second, the parameters of the ECM can be\nreduced in test by introducing a structural re-parameterization technique.\nExtensive experimental results demonstrate that our GaitStrip achieves\nstate-of-the-art performance in both normal walking and complex conditions.",
    "descriptor": "",
    "authors": [
      "Ming Wang",
      "Beibei Lin",
      "Xianda Guo",
      "Lincheng Li",
      "Zheng Zhu",
      "Jiande Sun",
      "Shunli Zhang",
      "Xin Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03966"
  },
  {
    "id": "arXiv:2203.03967",
    "title": "Comparing lifetime learning methods for morphologically evolving robots",
    "abstract": "Evolving morphologies and controllers of robots simultaneously leads to a\nproblem: Even if the parents have well-matching bodies and brains, the\nstochastic recombination can break this match and cause a body-brain mismatch\nin their offspring. We argue that this can be mitigated by having newborn\nrobots perform a learning process that optimizes their inherited brain quickly\nafter birth. We compare three different algorithms for doing this. To this end,\nwe consider three algorithmic properties, efficiency, efficacy, and the\nsensitivity to differences in the morphologies of the robots that run the\nlearning process.",
    "descriptor": "\nComments: Associated code: this https URL\n",
    "authors": [
      "Fuda van Diggelen",
      "Eliseo Ferrante",
      "A.E. Eiben"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.03967"
  },
  {
    "id": "arXiv:2203.03969",
    "title": "A Dynamic Hierarchical Framework for IoT-assisted Metaverse  Synchronization",
    "abstract": "Metaverse has recently attracted much attention from both academia and\nindustry. Virtual services, ranging from virtual driver training to online\nroute optimization for smart good delivery, are emerging in the Metaverse. To\nmake the human experience of virtual life real, digital twins (DTs), namely\ndigital replications of physical objects in life, are the key enablers.\nHowever, the status of DTs is not always reliable because their physical\ncounterparties can be moving objects or subject to changes as time passes. As\nsuch, it is necessary to synchronize DTs with their physical objects to make\nDTs status reliable for virtual businesses in the Metaverse. In this paper, we\npropose a dynamic hierarchical framework in, which a group of IoTs devices\nassists virtual service providers (VSPs) in synchronizing DTs: the devices\nsense and collect physical objects' status information collectively in return\nfor incentives. Based on the collected sync data and the value decay rate of\nthe DTs, the VSPs can determine a sync intensity to maximize their payoffs. We\nadopt a dynamic hierarchical framework in which the lower-level evolutionary\ngame captures the VSPs selection by the population of IoT devices, and the\nupper-level (Stackelberg) differential game captures the VSPs payoffs affected\nby the sync strategy, UAVs selection shares, and the DTs value status. We\ntheoretically and experimentally prove the equilibrium to the lower-level game\nexists and is evolutionarily robust, and provide the sensitivity analysis w.r.t\nvarious system parameters. Experiment shows that the dynamic Stackelberg\ndifferential game gives higher accumulated payoffs compared to the static\nStackelberg game and the simultaneous differential game.",
    "descriptor": "",
    "authors": [
      "Yue Han",
      "Dusit Niyato",
      "Cyril Leung",
      "Dong In Kim",
      "Kun Zhu",
      "Shaohan Feng",
      "Xuemin",
      "Shen",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03969"
  },
  {
    "id": "arXiv:2203.03970",
    "title": "On Generalizing Beyond Domains in Cross-Domain Continual Learning",
    "abstract": "Humans have the ability to accumulate knowledge of new tasks in varying\nconditions, but deep neural networks often suffer from catastrophic forgetting\nof previously learned knowledge after learning a new task. Many recent methods\nfocus on preventing catastrophic forgetting under the assumption of train and\ntest data following similar distributions. In this work, we consider a more\nrealistic scenario of continual learning under domain shifts where the model\nmust generalize its inference to an unseen domain. To this end, we encourage\nlearning semantically meaningful features by equipping the classifier with\nclass similarity metrics as learning parameters which are obtained through\nMahalanobis similarity computations. Learning of the backbone representation\nalong with these extra parameters is done seamlessly in an end-to-end manner.\nIn addition, we propose an approach based on the exponential moving average of\nthe parameters for better knowledge distillation. We demonstrate that, to a\ngreat extent, existing continual learning algorithms fail to handle the\nforgetting issue under multiple distributions, while our proposed approach\nlearns new tasks under domain shift with accuracy boosts up to 10% on\nchallenging datasets such as DomainNet and OfficeHome.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Christian Simon",
      "Masoud Faraki",
      "Yi-Hsuan Tsai",
      "Xiang Yu",
      "Samuel Schulter",
      "Yumin Suh",
      "Mehrtash Harandi",
      "Manmohan Chandraker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03970"
  },
  {
    "id": "arXiv:2203.03971",
    "title": "Universal Prototype Transport for Zero-Shot Action Recognition and  Localization",
    "abstract": "This work addresses the problem of recognizing action categories in videos\nfor which no training examples are available. The current state-of-the-art\nenables such a zero-shot recognition by learning universal mappings from videos\nto a shared semantic space, either trained on large-scale seen actions or on\nobjects. While effective, we find that universal action and object mappings are\nbiased to their seen categories. Such biases are further amplified due to\nbiases between seen and unseen categories in the semantic space. The\ncompounding biases result in many unseen action categories simply never being\nselected during inference, hampering zero-shot progress. We seek to address\nthis limitation and introduce universal prototype transport for zero-shot\naction recognition. The main idea is to re-position the semantic prototypes of\nunseen actions through transduction, i.e. by using the distribution of the\nunlabelled test set. For universal action models, we first seek to find a\nhyperspherical optimal transport mapping from unseen action prototypes to the\nset of all projected test videos. We then define a target prototype for each\nunseen action as the weighted Fr\\'echet mean over the transport couplings.\nEquipped with a target prototype, we propose to re-position unseen action\nprototypes along the geodesic spanned by the original and target prototypes,\nacting as a form of semantic regularization. For universal object models, we\noutline a variant that defines target prototypes based on an optimal transport\nbetween unseen action prototypes and semantic object prototypes. Empirically,\nwe show that universal prototype transport diminishes the biased selection of\nunseen action prototypes and boosts both universal action and object models,\nresulting in state-of-the-art performance for zero-shot classification and\nspatio-temporal localization.",
    "descriptor": "",
    "authors": [
      "Pascal Mettes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03971"
  },
  {
    "id": "arXiv:2203.03972",
    "title": "GaitEdge: Beyond Plain End-to-end Gait Recognition for Better  Practicality",
    "abstract": "Gait is one of the most promising biometrics to identify individuals at a\nlong distance. Although most previous methods have focused on recognizing the\nsilhouettes, several end-to-end methods that extract gait features directly\nfrom RGB images perform better. However, we argue that these end-to-end methods\ninevitably suffer from the gait-unrelated noises, i.e., low-level texture and\ncolorful information. Experimentally, we design both the cross-domain\nevaluation and visualization to stand for this view. In this work, we propose a\nnovel end-to-end framework named GaitEdge which can effectively block\ngait-unrelated information and release end-to-end training potential.\nSpecifically, GaitEdge synthesizes the output of the pedestrian segmentation\nnetwork and then feeds it to the subsequent recognition network, where the\nsynthetic silhouettes consist of trainable edges of bodies and fixed interiors\nto limit the information that the recognition network receives. Besides,\nGaitAlign for aligning silhouettes is embedded into the GaitEdge without loss\nof differentiability. Experimental results on CASIA-B and our newly built\nTTG-200 indicate that GaitEdge significantly outperforms the previous methods\nand provides a more practical end-to-end paradigm for blocking RGB noises\neffectively. All the source code will be released.",
    "descriptor": "",
    "authors": [
      "Junhao Liang",
      "Chao Fan",
      "Saihui Hou",
      "Chuanfu Shen",
      "Yongzhen Huang",
      "Shiqi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03972"
  },
  {
    "id": "arXiv:2203.03975",
    "title": "Computational Benchmarks with Optimal Multilevel Argyris FEM",
    "abstract": "The main drawback for the application of the conforming Argyris FEM is the\nlabourious implementation on the one hand and the low convergence rates on the\nother. If no appropriate adaptive meshes are utilised, only the convergence\nrate caused by corner singularities [Blum and Rannacher, 1980], far below the\napproximation order for smooth functions, can be achieved. The fine\napproximation with the Argyris FEM produces high-dimensional linear systems and\nfor a long time an optimal preconditioned scheme was not available for\nunstructured grids. This paper presents numerical benchmarks to confirm that\nthe adaptive multilevel solver for the hierarchical Argyris FEM from\n[Carstensen and Hu, 2021] is in fact highly efficient and of linear time\ncomplexity. Moreover, the very first display of optimal convergence rates in\npractically relevant benchmarks with corner singularities and general boundary\nconditions lead to the rehabilitation of the Argyris finite element from the\ncomputational perspective.",
    "descriptor": "",
    "authors": [
      "Benedikt Gr\u00e4\u00dfle"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.03975"
  },
  {
    "id": "arXiv:2203.03978",
    "title": "Contrastive Conditional Neural Processes",
    "abstract": "Conditional Neural Processes~(CNPs) bridge neural networks with probabilistic\ninference to approximate functions of Stochastic Processes under meta-learning\nsettings. Given a batch of non-{\\it i.i.d} function instantiations, CNPs are\njointly optimized for in-instantiation observation prediction and\ncross-instantiation meta-representation adaptation within a generative\nreconstruction pipeline. There can be a challenge in tying together such two\ntargets when the distribution of function observations scales to\nhigh-dimensional and noisy spaces. Instead, noise contrastive estimation might\nbe able to provide more robust representations by learning distributional\nmatching objectives to combat such inherent limitation of generative models. In\nlight of this, we propose to equip CNPs by 1) aligning prediction with encoded\nground-truth observation, and 2) decoupling meta-representation adaptation from\ngenerative reconstruction. Specifically, two auxiliary contrastive branches are\nset up hierarchically, namely in-instantiation temporal contrastive\nlearning~({\\tt TCL}) and cross-instantiation function contrastive\nlearning~({\\tt FCL}), to facilitate local predictive alignment and global\nfunction consistency, respectively. We empirically show that {\\tt TCL} captures\nhigh-level abstraction of observations, whereas {\\tt FCL} helps identify\nunderlying functions, which in turn provides more efficient representations.\nOur model outperforms other CNPs variants when evaluating function distribution\nreconstruction and parameter identification across 1D, 2D and high-dimensional\ntime-series.",
    "descriptor": "\nComments: 8 pages, 7 figures, accepted to CVPR2022\n",
    "authors": [
      "Zesheng Ye",
      "Lina Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.03978"
  },
  {
    "id": "arXiv:2203.03981",
    "title": "End-to-end Multiple Instance Learning with Gradient Accumulation",
    "abstract": "Being able to learn on weakly labeled data, and provide interpretability, are\ntwo of the main reasons why attention-based deep multiple instance learning\n(ABMIL) methods have become particularly popular for classification of\nhistopathological images. Such image data usually come in the form of\ngigapixel-sized whole-slide-images (WSI) that are cropped into smaller patches\n(instances). However, the sheer size of the data makes training of ABMIL models\nchallenging. All the instances from one WSI cannot be processed at once by\nconventional GPUs. Existing solutions compromise training by relying on\npre-trained models, strategic sampling or selection of instances, or\nself-supervised learning. We propose a training strategy based on gradient\naccumulation that enables direct end-to-end training of ABMIL models without\nbeing limited by GPU memory. We conduct experiments on both QMNIST and\nImagenette to investigate the performance and training time, and compare with\nthe conventional memory-expensive baseline and a recent sampled-based approach.\nThis memory-efficient approach, although slower, reaches performance\nindistinguishable from the memory-expensive baseline.",
    "descriptor": "",
    "authors": [
      "Axel Andersson",
      "Nadezhda Koriakina",
      "Nata\u0161a Sladoje",
      "Joakim Lindblad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03981"
  },
  {
    "id": "arXiv:2203.03982",
    "title": "Predictive and Contrastive: Dual-Auxiliary Learning for Recommendation",
    "abstract": "Self-supervised learning (SSL) recently has achieved outstanding success on\nrecommendation. By setting up an auxiliary task (either predictive or\ncontrastive), SSL can discover supervisory signals from the raw data without\nhuman annotation, which greatly mitigates the problem of sparse user-item\ninteractions. However, most SSL-based recommendation models rely on\ngeneral-purpose auxiliary tasks, e.g., maximizing correspondence between node\nrepresentations learned from the original and perturbed interaction graphs,\nwhich are explicitly irrelevant to the recommendation task. Accordingly, the\nrich semantics reflected by social relationships and item categories, which lie\nin the recommendation data-based heterogeneous graphs, are not fully exploited.\nTo explore recommendation-specific auxiliary tasks, we first quantitatively\nanalyze the heterogeneous interaction data and find a strong positive\ncorrelation between the interactions and the number of user-item paths induced\nby meta-paths. Based on the finding, we design two auxiliary tasks that are\ntightly coupled with the target task (one is predictive and the other one is\ncontrastive) towards connecting recommendation with the self-supervision\nsignals hiding in the positive correlation. Finally, a model-agnostic\nDUal-Auxiliary Learning (DUAL) framework which unifies the SSL and\nrecommendation tasks is developed. The extensive experiments conducted on three\nreal-world datasets demonstrate that DUAL can significantly improve\nrecommendation, reaching the state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Yinghui Tao",
      "Min Gao",
      "Junliang Yu",
      "Zongwei Wang",
      "Qingyu Xiong",
      "Xu Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.03982"
  },
  {
    "id": "arXiv:2203.03984",
    "title": "Attention-Based Lip Audio-Visual Synthesis for Talking Face Generation  in the Wild",
    "abstract": "Talking face generation with great practical significance has attracted more\nattention in recent audio-visual studies. How to achieve accurate lip\nsynchronization is a long-standing challenge to be further investigated.\nMotivated by xxx, in this paper, an AttnWav2Lip model is proposed by\nincorporating spatial attention module and channel attention module into\nlip-syncing strategy. Rather than focusing on the unimportant regions of the\nface image, the proposed AttnWav2Lip model is able to pay more attention on the\nlip region reconstruction. To our limited knowledge, this is the first attempt\nto introduce attention mechanism to the scheme of talking face generation. An\nextensive experiments have been conducted to evaluate the effectiveness of the\nproposed model. Compared to the baseline measured by LSE-D and LSE-C metrics, a\nsuperior performance has been demonstrated on the benchmark lip synthesis\ndatasets, including LRW, LRS2 and LRS3.",
    "descriptor": "",
    "authors": [
      "Ganglai Wang",
      "Peng Zhang",
      "Lei Xie",
      "Wei Huang",
      "Yufei Zha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.03984"
  },
  {
    "id": "arXiv:2203.03985",
    "title": "SimpleTrack: Rethinking and Improving the JDE Approach for Multi-Object  Tracking",
    "abstract": "Joint detection and embedding (JDE) based methods usually estimate bounding\nboxes and embedding features of objects with a single network in Multi-Object\nTracking (MOT). In the tracking stage, JDE-based methods fuse the target motion\ninformation and appearance information by applying the same rule, which could\nfail when the target is briefly lost or blocked. To overcome this problem, we\npropose a new association matrix, the Embedding and Giou matrix, which combines\nembedding cosine distance and Giou distance of objects. To further improve the\nperformance of data association, we develop a simple, effective tracker named\nSimpleTrack, which designs a bottom-up fusion method for Re-identity and\nproposes a new tracking strategy based on our EG matrix. The experimental\nresults indicate that SimpleTrack has powerful data association capability,\ne.g., 61.6 HOTA and 76.3 IDF1 on MOT17. In addition, we apply the EG matrix to\n5 different state-of-the-art JDE-based methods and achieve significant\nimprovements in IDF1, HOTA and IDsw metrics, and increase the tracking speed of\nthese methods by about 20%.",
    "descriptor": "",
    "authors": [
      "Jiaxin Li",
      "Yan Ding",
      "Hualiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03985"
  },
  {
    "id": "arXiv:2203.03986",
    "title": "Leveraging Randomized Smoothing for Optimal Control of Nonsmooth  Dynamical Systems",
    "abstract": "Optimal control (OC) algorithms such as Differential Dynamic Programming\n(DDP) take advantage of the derivatives of the dynamics to efficiently control\nphysical systems. Yet, in the presence of nonsmooth dynamical systems, such\nclass of algorithms are likely to fail due, for instance, to the presence of\ndiscontinuities in the dynamics derivatives or because of non-informative\ngradient. On the contrary, reinforcement learning (RL) algorithms have shown\nbetter empirical results in scenarios exhibiting non-smooth effects (contacts,\nfrictions, etc). Our approach leverages recent works on randomized smoothing\n(RS) to tackle non-smoothness issues commonly encountered in optimal control,\nand provides key insights on the interplay between RL and OC through the prism\nof RS methods. This naturally leads us to introduce the randomized Differential\nDynamic Programming (R-DDP) algorithm accounting for deterministic but\nnon-smooth dynamics in a very sample-efficient way. The experiments demonstrate\nthat our method is able to solve classic robotic problems with dry friction and\nfrictional contacts, where classical OC algorithms are likely to fail and RL\nalgorithms require in practice a prohibitive number of samples to find an\noptimal solution.",
    "descriptor": "",
    "authors": [
      "Quentin Le Lidec",
      "Louis Montaut",
      "Cordelia Schmid",
      "Ivan Laptev",
      "Justin Carpentier"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.03986"
  },
  {
    "id": "arXiv:2203.03989",
    "title": "Adapt$\\mathcal{O}$r: Objective-Centric Adaptation Framework for Language  Models",
    "abstract": "Progress in natural language processing research is catalyzed by the\npossibilities given by the widespread software frameworks. This paper\nintroduces Adaptor library that transposes the traditional model-centric\napproach composed of pre-training + fine-tuning steps to objective-centric\napproach, composing the training process by applications of selected\nobjectives. We survey research directions that can benefit from enhanced\nobjective-centric experimentation in multitask training, custom objectives\ndevelopment, dynamic training curricula, or domain adaptation. Adaptor aims to\nease reproducibility of these research directions in practice. Finally, we\ndemonstrate the practical applicability of Adaptor in selected unsupervised\ndomain adaptation scenarios.",
    "descriptor": "\nComments: 60th Annual Meeting of the ACL (ACL 2022): System Demonstrations paper\n",
    "authors": [
      "Michal \u0160tef\u00e1nik",
      "V\u00edt Novotn\u00fd",
      "Nikola Groverov\u00e1",
      "Petr Sojka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03989"
  },
  {
    "id": "arXiv:2203.03990",
    "title": "Skating-Mixer: Multimodal MLP for Scoring Figure Skating",
    "abstract": "Figure skating scoring is a challenging task because it requires judging\nplayers' technical moves as well as coordination with the background music.\nPrior learning-based work cannot solve it well for two reasons: 1) each move in\nfigure skating changes quickly, hence simply applying traditional frame\nsampling will lose a lot of valuable information, especially in a 3-5 minutes\nlasting video, so an extremely long-range representation learning is necessary;\n2) prior methods rarely considered the critical audio-visual relationship in\ntheir models. Thus, we introduce a multimodal MLP architecture, named\nSkating-Mixer. It extends the MLP-Mixer-based framework into a multimodal\nfashion and effectively learns long-term representations through our designed\nmemory recurrent unit (MRU). Aside from the model, we also collected a\nhigh-quality audio-visual FS1000 dataset, which contains over 1000 videos on 8\ntypes of programs with 7 different rating metrics, overtaking other datasets in\nboth quantity and diversity. Experiments show the proposed method outperforms\nSOTAs over all major metrics on the public Fis-V and our FS1000 dataset. In\naddition, we include an analysis applying our method to recent competitions\nthat occurred in Beijing 2022 Winter Olympic Games, proving our method has\nstrong robustness.",
    "descriptor": "",
    "authors": [
      "Jingfei Xia",
      "Mingchen Zhuge",
      "Tiantian Geng",
      "Shun Fan",
      "Yuantai Wei",
      "Zhenyu He",
      "Feng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03990"
  },
  {
    "id": "arXiv:2203.03991",
    "title": "Sparsification and Filtering for Spatial-temporal GNN in Multivariate  Time-series",
    "abstract": "We propose an end-to-end architecture for multivariate time-series prediction\nthat integrates a spatial-temporal graph neural network with a matrix filtering\nmodule. This module generates filtered (inverse) correlation graphs from\nmultivariate time series before inputting them into a GNN. In contrast with\nexisting sparsification methods adopted in graph neural network, our model\nexplicitly leverage time-series filtering to overcome the low signal-to-noise\nratio typical of complex systems data. We present a set of experiments, where\nwe predict future sales from a synthetic time-series sales dataset. The\nproposed spatial-temporal graph neural network displays superior performances\nwith respect to baseline approaches, with no graphical information, and with\nfully connected, disconnected graphs and unfiltered graphs.",
    "descriptor": "\nComments: 7 pages, 1 figure, 3tables\n",
    "authors": [
      "Yuanrong Wang",
      "Tomaso Aste"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2203.03991"
  },
  {
    "id": "arXiv:2203.03992",
    "title": "Semi-Integrated-Sensing-and-Communication (Semi-ISaC) Networks Assisted  by NOMA",
    "abstract": "This paper investigates non-orthogonal multiple access (NOMA) assisted\nintegrated sensing and communication (ISaC) networks. Compared to the\nconventional ISaC networks, where the total bandwidth is used for both the\nradar detection and wireless communications, the proposed Semi-ISaC networks\nallow that a portion of bandwidth is used for ISaC and the rest of the\nbandwidth is only utilized for wireless communications. We first derive the\nanalytical expressions of the outage probability for the communication signals,\nincluding the signals for the radar target and the communication transmitter.\nAdditionally, we derive the analytical expressions of the ergodic radar\nestimation information rate (REIR) for the radar echoes. The simulation results\nshow that 1) NOMA ISaC has better spectrum efficiency than the conventional\nISaC; and 2) The REIR is enhanced when we enlarge the density of pulses.",
    "descriptor": "\nComments: Accepted by ICC 2022\n",
    "authors": [
      "Chao Zhang",
      "Wenqiang Yi",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.03992"
  },
  {
    "id": "arXiv:2203.03996",
    "title": "DeltaCNN: End-to-End CNN Inference of Sparse Frame Differences in Videos",
    "abstract": "Convolutional neural network inference on video data requires powerful\nhardware for real-time processing. Given the inherent coherence across\nconsecutive frames, large parts of a video typically change little. By skipping\nidentical image regions and truncating insignificant pixel updates,\ncomputational redundancy can in theory be reduced significantly. However, these\ntheoretical savings have been difficult to translate into practice, as sparse\nupdates hamper computational consistency and memory access coherence; which are\nkey for efficiency on real hardware. With DeltaCNN, we present a sparse\nconvolutional neural network framework that enables sparse frame-by-frame\nupdates to accelerate video inference in practice. We provide sparse\nimplementations for all typical CNN layers and propagate sparse feature updates\nend-to-end - without accumulating errors over time. DeltaCNN is applicable to\nall convolutional neural networks without retraining. To the best of our\nknowledge, we are the first to significantly outperform the dense reference,\ncuDNN, in practical settings, achieving speedups of up to 7x with only marginal\ndifferences in accuracy.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Mathias Parger",
      "Chengcheng Tang",
      "Christopher D. Twigg",
      "Cem Keskin",
      "Robert Wang",
      "Markus Steinberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03996"
  },
  {
    "id": "arXiv:2203.04002",
    "title": "Semi-Random Sparse Recovery in Nearly-Linear Time",
    "abstract": "Sparse recovery is one of the most fundamental and well-studied inverse\nproblems. Standard statistical formulations of the problem are provably solved\nby general convex programming techniques and more practical, fast\n(nearly-linear time) iterative methods. However, these latter \"fast algorithms\"\nhave previously been observed to be brittle in various real-world settings.\nWe investigate the brittleness of fast sparse recovery algorithms to\ngenerative model changes through the lens of studying their robustness to a\n\"helpful\" semi-random adversary, a framework which tests whether an algorithm\noverfits to input assumptions. We consider the following basic model: let\n$\\mathbf{A} \\in \\mathbb{R}^{n \\times d}$ be a measurement matrix which contains\nan unknown subset of rows $\\mathbf{G} \\in \\mathbb{R}^{m \\times d}$ which are\nbounded and satisfy the restricted isometry property (RIP), but is otherwise\narbitrary. Letting $x^\\star \\in \\mathbb{R}^d$ be $s$-sparse, and given either\nexact measurements $b = \\mathbf{A} x^\\star$ or noisy measurements $b =\n\\mathbf{A} x^\\star + \\xi$, we design algorithms recovering $x^\\star$\ninformation-theoretically optimally in nearly-linear time. We extend our\nalgorithm to hold for weaker generative models relaxing our planted RIP\nassumption to a natural weighted variant, and show that our method's guarantees\nnaturally interpolate the quality of the measurement matrix to, in some\nparameter regimes, run in sublinear time.\nOur approach differs from prior fast iterative methods with provable\nguarantees under semi-random generative models: natural conditions on a\nsubmatrix which make sparse recovery tractable are NP-hard to verify. We design\na new iterative method tailored to the geometry of sparse recovery which is\nprovably robust to our semi-random model. We hope our approach opens the door\nto new robust, efficient algorithms for natural statistical inverse problems.",
    "descriptor": "\nComments: 42 pages, comments welcome!\n",
    "authors": [
      "Jonathan A. Kelner",
      "Jerry Li",
      "Allen Liu",
      "Aaron Sidford",
      "Kevin Tian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.04002"
  },
  {
    "id": "arXiv:2203.04006",
    "title": "Visual-Language Navigation Pretraining via Prompt-based Environmental  Self-exploration",
    "abstract": "Vision-language navigation (VLN) is a challenging task due to its large\nsearching space in the environment. To address this problem, previous works\nhave proposed some methods of fine-tuning a large model that pretrained on\nlarge-scale datasets. However, the conventional fine-tuning methods require\nextra human-labeled navigation data and lack self-exploration capabilities in\nenvironments, which hinders their generalization of unseen scenes. To improve\nthe ability of fast cross-domain adaptation, we propose Prompt-based\nEnvironmental Self-exploration (ProbES), which can self-explore the\nenvironments by sampling trajectories and automatically generates structured\ninstructions via a large-scale cross-modal pretrained model (CLIP). Our method\nfully utilizes the knowledge learned from CLIP to build an in-domain dataset by\nself-exploration without human labeling. Unlike the conventional approach of\nfine-tuning, we introduce prompt-based learning to achieve fast adaptation for\nlanguage embeddings, which substantially improves the learning efficiency by\nleveraging prior knowledge. By automatically synthesizing\ntrajectory-instruction pairs in any environment without human supervision and\nefficient prompt-based learning, our model can adapt to diverse vision-language\nnavigation tasks, including VLN and REVERIE. Both qualitative and quantitative\nresults show that our ProbES significantly improves the generalization ability\nof the navigation model.",
    "descriptor": "\nComments: Accepted by ACL 2022\n",
    "authors": [
      "Xiwen Liang",
      "Fengda Zhu",
      "Lingling Li",
      "Hang Xu",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.04006"
  },
  {
    "id": "arXiv:2203.04007",
    "title": "DuMLP-Pin: A Dual-MLP-dot-product Permutation-invariant Network for Set  Feature Extraction",
    "abstract": "Existing permutation-invariant methods can be divided into two categories\naccording to the aggregation scope, i.e. global aggregation and local one.\nAlthough the global aggregation methods, e. g., PointNet and Deep Sets, get\ninvolved in simpler structures, their performance is poorer than the local\naggregation ones like PointNet++ and Point Transformer. It remains an open\nproblem whether there exists a global aggregation method with a simple\nstructure, competitive performance, and even much fewer parameters. In this\npaper, we propose a novel global aggregation permutation-invariant network\nbased on dual MLP dot-product, called DuMLP-Pin, which is capable of being\nemployed to extract features for set inputs, including unordered or\nunstructured pixel, attribute, and point cloud data sets. We strictly prove\nthat any permutation-invariant function implemented by DuMLP-Pin can be\ndecomposed into two or more permutation-equivariant ones in a dot-product way\nas the cardinality of the given input set is greater than a threshold. We also\nshow that the DuMLP-Pin can be viewed as Deep Sets with strong constraints\nunder certain conditions. The performance of DuMLP-Pin is evaluated on several\ndifferent tasks with diverse data sets. The experimental results demonstrate\nthat our DuMLP-Pin achieves the best results on the two classification problems\nfor pixel sets and attribute sets. On both the point cloud classification and\nthe part segmentation, the accuracy of DuMLP-Pin is very close to the so-far\nbest-performing local aggregation method with only a 1-2% difference, while the\nnumber of required parameters is significantly reduced by more than 85% in\nclassification and 69% in segmentation, respectively. The code is publicly\navailable on https://github.com/JaronTHU/DuMLP-Pin.",
    "descriptor": "\nComments: 16 pages, accepted by AAAI 2022, with technical appendix\n",
    "authors": [
      "Jiajun Fei",
      "Ziyu Zhu",
      "Wenlei Liu",
      "Zhidong Deng",
      "Mingyang Li",
      "Huanjun Deng",
      "Shuo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.04007"
  },
  {
    "id": "arXiv:2203.04011",
    "title": "Evolutionary Neural Cascade Search across Supernetworks",
    "abstract": "To achieve excellent performance with modern neural networks, having the\nright network architecture is important. Neural Architecture Search (NAS)\nconcerns the automatic discovery of task-specific network architectures. Modern\nNAS approaches leverage supernetworks whose subnetworks encode candidate neural\nnetwork architectures. These subnetworks can be trained simultaneously,\nremoving the need to train each network from scratch, thereby increasing the\nefficiency of NAS. A recent method called Neural Architecture Transfer (NAT)\nfurther improves the efficiency of NAS for computer vision tasks by using a\nmulti-objective evolutionary algorithm to find high-quality subnetworks of a\nsupernetwork pretrained on ImageNet. Building upon NAT, we introduce ENCAS -\nEvolutionary Neural Cascade Search. ENCAS can be used to search over multiple\npretrained supernetworks to achieve a trade-off front of cascades of different\nneural network architectures, maximizing accuracy while minimizing FLOPS count.\nWe test ENCAS on common computer vision benchmarks (CIFAR-10, CIFAR-100,\nImageNet) and achieve Pareto dominance over previous state-of-the-art NAS\nmodels up to 1.5 GFLOPS. Additionally, applying ENCAS to a pool of 518 publicly\navailable ImageNet classifiers leads to Pareto dominance in all computation\nregimes and to increasing the maximum accuracy from 88.6% to 89.0%, accompanied\nby an 18\\% decrease in computation effort from 362 to 296 GFLOPS. Our code is\navailable at https://github.com/AwesomeLemon/ENCAS",
    "descriptor": "\nComments: 13 pages, 13 figures\n",
    "authors": [
      "Alexander Chebykin",
      "Tanja Alderliesten",
      "Peter A. N. Bosman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.04011"
  },
  {
    "id": "arXiv:2203.04015",
    "title": "A Compilation Flow for the Generation of CNN Inference Accelerators on  FPGAs",
    "abstract": "We present a compilation flow for the generation of CNN inference\naccelerators on FPGAs. The flow translates a frozen model into OpenCL kernels\nwith the TVM compiler and uses the Intel OpenCL SDK to compile to an FPGA\nbitstream. We improve the quality of the generated hardware with optimizations\napplied to the base OpenCL kernels generated by TVM. These optimizations\nincrease parallelism, reduce memory access latency, increase concurrency and\nsave on-chip resources. We automate these optimizations in TVM and evaluate\nthem by generating accelerators for LeNet-5, MobileNetV1 and ResNet-34 on an\nIntel Stratix~10SX. We show that the optimizations improve the performance of\nthe generated accelerators by up to 846X over the base accelerators. The\nperformance of the optimized accelerators is up to 4.57X better than TensorFlow\non CPU, 3.83X better than single-threaded TVM and is only 0.34X compared to TVM\nwith 56 threads. Our optimized kernels also outperform ones generated by a\nsimilar approach (that also uses high-level synthesis) while providing more\nfunctionality and flexibility. However, it underperforms an approach that\nutilizes hand-optimized designs. Thus, we view our approach as useful in\npre-production environments that benefit from increased performance and fast\nprototyping, realizing the benefits of FPGAs without hardware design expertise.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Seung-Hun Chung",
      "Tarek S. Abdelrahman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04015"
  },
  {
    "id": "arXiv:2203.04021",
    "title": "EXOSMOOTH: Test of Innovative EXOskeleton Control for SMOOTH Assistance,  With and Without Ankle Actuation",
    "abstract": "This work presents a description of the EXOSMOOTH project, oriented to the\nbenchmarking of lower limb exoskeletons performance. In the field of assisted\nwalking by powered lower limb exoskeletons, the EXOSMOOTH project proposes an\nexperiment that targets two scientific questions. The first question is related\nto the effectiveness of a novel control strategy for smooth assistance. Current\nassist strategies are based on controllers that switch the assistance level\nbased on the gait segmentation provided by a finite state machine. The proposed\nstrategy aims at managing phase transitions to provide a smoother assistance to\nthe user, thus increasing the device transparency and comfort for the user. The\nsecond question is the role of the actuation at the ankle joint in assisted\nwalking. Many novel exoskeletons devised for industrial applications do not\nfeature an actuated ankle joint. In the EXOSMOOTH project, the ankle joint\nactuation will be one experimental factor to have a direct assessment of the\nrole of an actuated joint in assisted walking. Preliminary results of 15\nhealthy subjects walking at different speeds while wearing a lower limb\nexoskeleton supported the rationale behind this question: having an actuated\nankle joint could potentially reduce the torques applied by the user by a\nmaximum value of 85 Nm. The two aforementioned questions will be investigated\nin a protocol that includes walking on a treadmill and on flat ground, with or\nwithout slope, and with a load applied on the back. In addition, the\ninteraction forces measured at the exoskeleton harnesses will be used to assess\nthe comfort of the user and the effectiveness of the control strategy to\nimprove transparency.",
    "descriptor": "",
    "authors": [
      "Vittorio Lippi",
      "Alessandro Filippeschi",
      "Cristian Camardella",
      "Francesco Porcini",
      "Christoph Maurer",
      "Lucia Lencioni"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.04021"
  },
  {
    "id": "arXiv:2203.04024",
    "title": "Metal Wire Manipulation Planning for 3D Curving -- How a Low Payload  Robot Can Use a Bending Machine to Bend Stiff Metal Wire",
    "abstract": "This paper presents a combined task and motion planner for a robot arm to\ncarry out 3D metal wire curving tasks by collaborating with a bending machine.\nWe assume a collaborative robot that is safe to work in a human environment but\nhas a weak payload to bend objects with large stiffness, and developed a\ncombined planner for the robot to use a bending machine. Our method converts a\n3D curve to a bending set and generates the feasible bending sequence, machine\nusage, robotic grasp poses, and pick-and-place arm motion considering the\ncombined task and motion level constraints. Compared with previous deformable\nlinear object shaping work that relied on forces provided by robotic arms, the\nproposed method is suitable for the material with high stiffness. We evaluate\nthe system using different tasks. The results show that the proposed system is\nflexible and robust to generate robotic motion to corporate with the designed\nbending machine.",
    "descriptor": "",
    "authors": [
      "Ruishuang Liu",
      "Weiwei Wan",
      "Emiko Isomura",
      "Kensuke Harada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.04024"
  },
  {
    "id": "arXiv:2203.04026",
    "title": "Toward Understanding Deep Learning Framework Bugs",
    "abstract": "DL frameworks are the basis of constructing all DL programs and models, and\nthus their bugs could lead to the unexpected behaviors of any DL program or\nmodel relying on them. Such wide effect demonstrates the necessity and\nimportance of guaranteeing DL frameworks' quality. Understanding the\ncharacteristics of DL framework bugs is a fundamental step for this quality\nassurance task, facilitating to design effective bug detection and debugging\napproaches. Hence, in this work we conduct the most large-scale study on 800\nbugs from four popular and diverse DL frameworks (i.e., TensorFlow, PyTorch,\nMXNet, and DL4J). By analyzing the root causes and symptoms of DL framework\nbugs associated with 5 components decomposed from DL frameworks, as well as\nmeasuring test coverage achieved by three state-of-the-art testing techniques\nand developers' efforts on fixing those bugs, we obtain 14 major findings for\nthe comprehensive understanding of DL framework bugs and the current status of\nexisting DL framework testing and debugging practice, and then provide a series\nof actionable guidelines for better DL framework bug detection and debugging.",
    "descriptor": "",
    "authors": [
      "Junjie Chen",
      "Yihua Liang",
      "Qingchao Shen",
      "Jiajun Jiang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.04026"
  },
  {
    "id": "arXiv:2203.04027",
    "title": "Data augmentation with mixtures of max-entropy transformations for  filling-level classification",
    "abstract": "We address the problem of distribution shifts in test-time data with a\nprincipled data augmentation scheme for the task of content-level\nclassification. In such a task, properties such as shape or transparency of\ntest-time containers (cup or drinking glass) may differ from those represented\nin the training data. Dealing with such distribution shifts using standard\naugmentation schemes is challenging and transforming the training images to\ncover the properties of the test-time instances requires sophisticated image\nmanipulations. We therefore generate diverse augmentations using a family of\nmax-entropy transformations that create samples with new shapes, colors and\nspectral characteristics. We show that such a principled augmentation scheme,\nalone, can replace current approaches that use transfer learning or can be used\nin combination with transfer learning to improve its performance.",
    "descriptor": "",
    "authors": [
      "Apostolos Modas",
      "Andrea Cavallaro",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.04027"
  },
  {
    "id": "arXiv:2203.04031",
    "title": "Stage-Aware Feature Alignment Network for Real-Time Semantic  Segmentation of Street Scenes",
    "abstract": "Over the past few years, deep convolutional neural network-based methods have\nmade great progress in semantic segmentation of street scenes. Some recent\nmethods align feature maps to alleviate the semantic gap between them and\nachieve high segmentation accuracy. However, they usually adopt the feature\nalignment modules with the same network configuration in the decoder and thus\nignore the different roles of stages of the decoder during feature aggregation,\nleading to a complex decoder structure. Such a manner greatly affects the\ninference speed. In this paper, we present a novel Stage-aware Feature\nAlignment Network (SFANet) based on the encoder-decoder structure for real-time\nsemantic segmentation of street scenes. Specifically, a Stage-aware Feature\nAlignment module (SFA) is proposed to align and aggregate two adjacent levels\nof feature maps effectively. In the SFA, by taking into account the unique role\nof each stage in the decoder, a novel stage-aware Feature Enhancement Block\n(FEB) is designed to enhance spatial details and contextual information of\nfeature maps from the encoder. In this way, we are able to address the\nmisalignment problem with a very simple and efficient multi-branch decoder\nstructure. Moreover, an auxiliary training strategy is developed to explicitly\nalleviate the multi-scale object problem without bringing additional\ncomputational costs during the inference phase. Experimental results show that\nthe proposed SFANet exhibits a good balance between accuracy and speed for\nreal-time semantic segmentation of street scenes. In particular, based on\nResNet-18, SFANet respectively obtains 78.1% and 74.7% mean of class-wise\nIntersection-over-Union (mIoU) at inference speeds of 37 FPS and 96 FPS on the\nchallenging Cityscapes and CamVid test datasets by using only a single GTX\n1080Ti GPU.",
    "descriptor": "",
    "authors": [
      "Xi Weng",
      "Yan Yan",
      "Si Chen",
      "Jing-Hao Xue",
      "Hanzi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04031"
  },
  {
    "id": "arXiv:2203.04032",
    "title": "Bayesian Optimisation-Assisted Neural Network Training Technique for  Radio Localisation",
    "abstract": "Radio signal-based (indoor) localisation technique is important for IoT\napplications such as smart factory and warehouse. Through machine learning,\nespecially neural networks methods, more accurate mapping from signal features\nto target positions can be achieved. However, different radio protocols, such\nas WiFi, Bluetooth, etc., have different features in the transmitted signals\nthat can be exploited for localisation purposes. Also, neural networks methods\noften rely on carefully configured models and extensive training processes to\nobtain satisfactory performance in individual localisation scenarios. The above\nposes a major challenge in the process of determining neural network model\nstructure, or hyperparameters, as well as the selection of training features\nfrom the available data. This paper proposes a neural network model\nhyperparameter tuning and training method based on Bayesian optimisation.\nAdaptive selection of model hyperparameters and training features can be\nrealised with minimal need for manual model training design. With the proposed\ntechnique, the training process is optimised in a more automatic and efficient\nway, enhancing the applicability of neural networks in localisation.",
    "descriptor": "\nComments: 5 pages, 4 figures. This paper has been accepted for presentation at the VTC2022-Spring\n",
    "authors": [
      "Xingchi Liu",
      "Peizheng Li",
      "Ziming Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.04032"
  },
  {
    "id": "arXiv:2203.04036",
    "title": "StyleHEAT: One-Shot High-Resolution Editable Talking Face Generation via  Pretrained StyleGAN",
    "abstract": "One-shot talking face generation aims at synthesizing a high-quality talking\nface video from an arbitrary portrait image, driven by a video or an audio\nsegment. One challenging quality factor is the resolution of the output video:\nhigher resolution conveys more details. In this work, we investigate the latent\nfeature space of a pre-trained StyleGAN and discover some excellent spatial\ntransformation properties. Upon the observation, we explore the possibility of\nusing a pre-trained StyleGAN to break through the resolution limit of training\ndatasets. We propose a novel unified framework based on a pre-trained StyleGAN\nthat enables a set of powerful functionalities, i.e., high-resolution video\ngeneration, disentangled control by driving video or audio, and flexible face\nediting. Our framework elevates the resolution of the synthesized talking face\nto 1024*1024 for the first time, even though the training dataset has a lower\nresolution. We design a video-based motion generation module and an audio-based\none, which can be plugged into the framework either individually or jointly to\ndrive the video generation. The predicted motion is used to transform the\nlatent features of StyleGAN for visual animation. To compensate for the\ntransformation distortion, we propose a calibration network as well as a domain\nloss to refine the features. Moreover, our framework allows two types of facial\nediting, i.e., global editing via GAN inversion and intuitive editing based on\n3D morphable models. Comprehensive experiments show superior video quality,\nflexible controllability, and editability over state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Fei Yin",
      "Yong Zhang",
      "Xiaodong Cun",
      "Mingdeng Cao",
      "Yanbo Fan",
      "Xuan Wang",
      "Qingyan Bai",
      "Baoyuan Wu",
      "Jue Wang",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04036"
  },
  {
    "id": "arXiv:2203.04037",
    "title": "Deep Multi-Branch Aggregation Network for Real-Time Semantic  Segmentation in Street Scenes",
    "abstract": "Real-time semantic segmentation, which aims to achieve high segmentation\naccuracy at real-time inference speed, has received substantial attention over\nthe past few years. However, many state-of-the-art real-time semantic\nsegmentation methods tend to sacrifice some spatial details or contextual\ninformation for fast inference, thus leading to degradation in segmentation\nquality. In this paper, we propose a novel Deep Multi-branch Aggregation\nNetwork (called DMA-Net) based on the encoder-decoder structure to perform\nreal-time semantic segmentation in street scenes. Specifically, we first adopt\nResNet-18 as the encoder to efficiently generate various levels of feature maps\nfrom different stages of convolutions. Then, we develop a Multi-branch\nAggregation Network (MAN) as the decoder to effectively aggregate different\nlevels of feature maps and capture the multi-scale information. In MAN, a\nlattice enhanced residual block is designed to enhance feature representations\nof the network by taking advantage of the lattice structure. Meanwhile, a\nfeature transformation block is introduced to explicitly transform the feature\nmap from the neighboring branch before feature aggregation. Moreover, a global\ncontext block is used to exploit the global contextual information. These key\ncomponents are tightly combined and jointly optimized in a unified network.\nExtensive experimental results on the challenging Cityscapes and CamVid\ndatasets demonstrate that our proposed DMA-Net respectively obtains 77.0% and\n73.6% mean Intersection over Union (mIoU) at the inference speed of 46.7 FPS\nand 119.8 FPS by only using a single NVIDIA GTX 1080Ti GPU. This shows that\nDMA-Net provides a good tradeoff between segmentation quality and speed for\nsemantic segmentation in street scenes.",
    "descriptor": "",
    "authors": [
      "Xi Weng",
      "Yan Yan",
      "Genshun Dong",
      "Chang Shu",
      "Biao Wang",
      "Hanzi Wang",
      "Ji Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04037"
  },
  {
    "id": "arXiv:2203.04038",
    "title": "Gait Recognition with Mask-based Regularization",
    "abstract": "Most gait recognition methods exploit spatial-temporal representations from\nstatic appearances and dynamic walking patterns. However, we observe that many\npart-based methods neglect representations at boundaries. In addition, the\nphenomenon of overfitting on training data is relatively common in gait\nrecognition, which is perhaps due to insufficient data and low-informative gait\nsilhouettes. Motivated by these observations, we propose a novel mask-based\nregularization method named ReverseMask. By injecting perturbation on the\nfeature map, the proposed regularization method helps convolutional\narchitecture learn the discriminative representations and enhances\ngeneralization. Also, we design an Inception-like ReverseMask Block, which has\nthree branches composed of a global branch, a feature dropping branch, and a\nfeature scaling branch. Precisely, the dropping branch can extract fine-grained\nrepresentations when partial activations are zero-outed. Meanwhile, the scaling\nbranch randomly scales the feature map, keeping structural information of\nactivations and preventing overfitting. The plug-and-play Inception-like\nReverseMask block is simple and effective to generalize networks, and it also\nimproves the performance of many state-of-the-art methods. Extensive\nexperiments demonstrate that the ReverseMask regularization help baseline\nachieves higher accuracy and better generalization. Moreover, the baseline with\nInception-like Block significantly outperforms state-of-the-art methods on the\ntwo most popular datasets, CASIA-B and OUMVLP. The source code will be\nreleased.",
    "descriptor": "\nComments: 14 pages,4 figues\n",
    "authors": [
      "Chuanfu Shen",
      "Beibei Lin",
      "Shunli Zhang",
      "George Q. Huang",
      "Shiqi Yu",
      "Xin Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04038"
  },
  {
    "id": "arXiv:2203.04041",
    "title": "Shape-invariant 3D Adversarial Point Clouds",
    "abstract": "Adversary and invisibility are two fundamental but conflict characters of\nadversarial perturbations. Previous adversarial attacks on 3D point cloud\nrecognition have often been criticized for their noticeable point outliers,\nsince they just involve an \"implicit constrain\" like global distance loss in\nthe time-consuming optimization to limit the generated noise. While point cloud\nis a highly structured data format, it is hard to metric and constrain its\nperturbation with a simple loss properly. In this paper, we propose a novel\nPoint-Cloud Sensitivity Map to boost both the efficiency and imperceptibility\nof point perturbations. This map reveals the vulnerability of point cloud\nrecognition models when encountering shape-invariant adversarial noises. These\nnoises are designed along the shape surface with an \"explicit constrain\"\ninstead of extra distance loss. Specifically, we first apply a reversible\ncoordinate transformation on each point of the point cloud input, to reduce one\ndegree of point freedom and limit its movement on the tangent plane. Then we\ncalculate the best attacking direction with the gradients of the transformed\npoint cloud obtained on the white-box model. Finally we assign each point with\na non-negative score to construct the sensitivity map, which benefits both\nwhite-box adversarial invisibility and black-box query-efficiency extended in\nour work. Extensive evaluations prove that our method can achieve the superior\nperformance on various point cloud recognition models, with its satisfying\nadversarial imperceptibility and strong resistance to different point cloud\ndefense settings. Our code is available at: https://github.com/shikiw/SI-Adv.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Qidong Huang",
      "Xiaoyi Dong",
      "Dongdong Chen",
      "Hang Zhou",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04041"
  },
  {
    "id": "arXiv:2203.04045",
    "title": "Towards Generalized Models for Task-oriented Dialogue Modeling on Spoken  Conversations",
    "abstract": "Building robust and general dialogue models for spoken conversations is\nchallenging due to the gap in distributions of spoken and written data. This\npaper presents our approach to build generalized models for the\nKnowledge-grounded Task-oriented Dialogue Modeling on Spoken Conversations\nChallenge of DSTC-10. In order to mitigate the discrepancies between spoken and\nwritten text, we mainly employ extensive data augmentation strategies on\nwritten data, including artificial error injection and round-trip text-speech\ntransformation. To train robust models for spoken conversations, we improve\npre-trained language models, and apply ensemble algorithms for each sub-task.\nTypically, for the detection task, we fine-tune \\roberta and ELECTRA, and run\nan error-fixing ensemble algorithm. For the selection task, we adopt a\ntwo-stage framework that consists of entity tracking and knowledge ranking, and\npropose a multi-task learning method to learn multi-level semantic information\nby domain classification and entity selection. For the generation task, we\nadopt a cross-validation data process to improve pre-trained generative\nlanguage models, followed by a consensus decoding algorithm, which can add\narbitrary features like relative \\rouge metric, and tune associated feature\nweights toward \\bleu directly. Our approach ranks third on the objective\nevaluation and second on the final official human evaluation.",
    "descriptor": "",
    "authors": [
      "Ruijie Yan",
      "Shuang Peng",
      "Haitao Mi",
      "Liang Jiang",
      "Shihui Yang",
      "Yuchi Zhang",
      "Jiajun Li",
      "Liangrui Peng",
      "Yongliang Wang",
      "Zujie Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.04045"
  },
  {
    "id": "arXiv:2203.04049",
    "title": "Graph Attention Transformer Network for Multi-Label Image Classification",
    "abstract": "Multi-label classification aims to recognize multiple objects or attributes\nfrom images. However, it is challenging to learn from proper label graphs to\neffectively characterize such inter-label correlations or dependencies. Current\nmethods often use the co-occurrence probability of labels based on the training\nset as the adjacency matrix to model this correlation, which is greatly limited\nby the dataset and affects the model's generalization ability. In this paper,\nwe propose a Graph Attention Transformer Network (GATN), a general framework\nfor multi-label image classification that can effectively mine complex\ninter-label relationships. First, we use the cosine similarity based on the\nlabel word embedding as the initial correlation matrix, which can represent\nrich semantic information. Subsequently, we design the graph attention\ntransformer layer to transfer this adjacency matrix to adapt to the current\ndomain. Our extensive experiments have demonstrated that our proposed methods\ncan achieve state-of-the-art performance on three datasets.",
    "descriptor": "",
    "authors": [
      "Jin Yuan",
      "Shikai Chen",
      "Yao Zhang",
      "Zhongchao Shi",
      "Xin Geng",
      "Jianping Fan",
      "Yong Rui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04049"
  },
  {
    "id": "arXiv:2203.04050",
    "title": "BEVSegFormer: Bird's Eye View Semantic Segmentation From Arbitrary  Camera Rigs",
    "abstract": "Semantic segmentation in bird's eye view (BEV) is an important task for\nautonomous driving. Though this task has attracted a large amount of research\nefforts, it is still challenging to flexibly cope with arbitrary (single or\nmultiple) camera sensors equipped on the autonomous vehicle. In this paper, we\npresent BEVSegFormer, an effective transformer-based method for BEV semantic\nsegmentation from arbitrary camera rigs. Specifically, our method first encodes\nimage features from arbitrary cameras with a shared backbone. These image\nfeatures are then enhanced by a deformable transformer-based encoder. Moreover,\nwe introduce a BEV transformer decoder module to parse BEV semantic\nsegmentation results. An efficient multi-camera deformable attention unit is\ndesigned to carry out the BEV-to-image view transformation. Finally, the\nqueries are reshaped according the layout of grids in the BEV, and upsampled to\nproduce the semantic segmentation result in a supervised manner. We evaluate\nthe proposed algorithm on the public nuScenes dataset and a self-collected\ndataset. Experimental results show that our method achieves promising\nperformance on BEV semantic segmentation from arbitrary camera rigs. We also\ndemonstrate the effectiveness of each component via ablation study.",
    "descriptor": "",
    "authors": [
      "Lang Peng",
      "Zhirong Chen",
      "Zhangjie Fu",
      "Pengpeng Liang",
      "Erkang Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04050"
  },
  {
    "id": "arXiv:2203.04051",
    "title": "Robot Learning of Mobile Manipulation with Reachability Behavior Priors",
    "abstract": "Mobile Manipulation (MM) systems are ideal candidates for taking up the role\nof a personal assistant in unstructured real-world environments. Among other\nchallenges, MM requires effective coordination of the robot's embodiments for\nexecuting tasks that require both mobility and manipulation. Reinforcement\nLearning (RL) holds the promise of endowing robots with adaptive behaviors, but\nmost methods require prohibitively large amounts of data for learning a useful\ncontrol policy. In this work, we study the integration of robotic reachability\npriors in actor-critic RL methods for accelerating the learning of MM for\nreaching and fetching tasks. Namely, we consider the problem of optimal base\nplacement and the subsequent decision of whether to activate the arm for\nreaching a 6D target. For this, we devise a novel Hybrid RL method that handles\ndiscrete and continuous actions jointly, resorting to the Gumbel-Softmax\nreparameterization. Next, we train a reachability prior using data from the\noperational robot workspace, inspired by classical methods. Subsequently, we\nderive Boosted Hybrid RL (BHyRL), a novel algorithm for learning Q-functions by\nmodeling them as a sum of residual approximators. Every time a new task needs\nto be learned, we can transfer our learned residuals and learn the component of\nthe Q-function that is task-specific, hence, maintaining the task structure\nfrom prior behaviors. Moreover, we find that regularizing the target policy\nwith a prior policy yields more expressive behaviors. We evaluate our method in\nsimulation in reaching and fetching tasks of increasing difficulty, and we show\nthe superior performance of BHyRL against baseline methods. Finally, we\nzero-transfer our learned 6D fetching policy with BHyRL to our MM robot\nTIAGo++. For more details and code release, please refer to our project site:\nirosalab.com/rlmmbp",
    "descriptor": "\nComments: Submitted to RAL-IROS 2022\n",
    "authors": [
      "Snehal Jauhri",
      "Jan Peters",
      "Georgia Chalvatzaki"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04051"
  },
  {
    "id": "arXiv:2203.04052",
    "title": "Towards Safe and Efficient Swarm-Human Collaboration: A Hierarchical  Multi-Agent Pickup and Delivery framework",
    "abstract": "The multi-Agent Pickup and Delivery (MAPD) problem is crucial in the realm of\nIntelligent Storage Systems (ISSs), where multiple robots are assigned with\ntime-varying, heterogeneous, and potentially uncertain tasks. When it comes to\nHuman-Swarm Hybrid System ((HS)$_2$), robots and human workers will accomplish\nthe MAPD tasks in collaboration. Herein, we propose a Human-Swarm Hybrid System\nPickup and Delivery ((HS)$_2$PD) framework, which is predominant in future\nISSs. A two-layer decision framework based on the prediction horizon window is\nestablished in light of the unpredictability of human behavior and the dynamic\nchanges of tasks. The first layer is a two-level programming problem to solve\nthe problems of mode assignment and TA. The second layer is devoted to the\nexact path of each agent via solving mixed-integer programming (MIP) problems.\nAn integrated algorithm for the (HS)$_2$PD problem is summarized. The\npracticality and validity of the above algorithm are illustrated via a\nnumerical simulation example towards (HS)$_2$PD tasks.",
    "descriptor": "",
    "authors": [
      "Xin Gong",
      "Tieniu Wang",
      "Yukang Cui",
      "Tingwen Huang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.04052"
  },
  {
    "id": "arXiv:2203.04058",
    "title": "A Fast Hardware Pseudorandom Number Generator Based on the xoroshiro128  LFSR",
    "abstract": "The Graphcore Intelligent Processing Unit (IPU) contains an original\npseudorandom number generator (PRNG) called xoroshiro128aox that is based on\nthe xoroshiro128 LFSR. It is designed to be cheap to implement in hardware and\nprovide a high quality of statistical randomness. In this paper, we present a\nrigorous assessment of the quality of our new PRNG using standard statistical\ntest suites and compare the results with the fast contemporary PRNGs\nxoroshiro128+, pcg64 and philox4x32. As a baseline for the analysis, we include\nthe widely-used Mersenne Twister PRNG. In our experiments, we show that\nxoroshiro128aox mitigates the known weakness in the lower order bits of\nxoroshiro128+ with our new AOX output function by passing the BigCrush and\nPractRand test suites. We extend our testing with the Gjrand test suite and a\nHamming-Weight dependency test to highlight the linear weaknesses of both\nxoroshiro128 PRNGs, but conclude that these linearities are hard to detect, and\nthe xoroshiro128aox PRNG otherwise provides an excellent trade off between\nstatistical quality and hardware implementation cost.",
    "descriptor": "\nComments: Under review for IEEE Transactions on Computers\n",
    "authors": [
      "James Hanlon",
      "Diya Rajan",
      "Stephen Felix"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.04058"
  },
  {
    "id": "arXiv:2203.04061",
    "title": "Counting with Adaptive Auxiliary Learning",
    "abstract": "This paper proposes an adaptive auxiliary task learning based approach for\nobject counting problems. Unlike existing auxiliary task learning based\nmethods, we develop an attention-enhanced adaptively shared backbone network to\nenable both task-shared and task-tailored features learning in an end-to-end\nmanner. The network seamlessly combines standard Convolution Neural Network\n(CNN) and Graph Convolution Network (GCN) for feature extraction and feature\nreasoning among different domains of tasks. Our approach gains enriched\ncontextual information by iteratively and hierarchically fusing the features\nacross different task branches of the adaptive CNN backbone. The whole\nframework pays special attention to the objects' spatial locations and varied\ndensity levels, informed by object (or crowd) segmentation and density level\nsegmentation auxiliary tasks. In particular, thanks to the proposed dilated\ncontrastive density loss function, our network benefits from individual and\nregional context supervision in terms of pixel-independent and pixel-dependent\nfeature learning mechanisms, along with strengthened robustness. Experiments on\nseven challenging multi-domain datasets demonstrate that our method achieves\nsuperior performance to the state-of-the-art auxiliary task learning based\ncounting methods. Our code is made publicly available at:\nhttps://github.com/smallmax00/Counting_With_Adaptive_Auxiliary",
    "descriptor": "",
    "authors": [
      "Yanda Meng",
      "Joshua Bridge",
      "Meng Wei",
      "Yitian Zhao",
      "Yihong Qiao",
      "Xiaoyun Yang",
      "Xiaowei Huang",
      "Yalin Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04061"
  },
  {
    "id": "arXiv:2203.04064",
    "title": "Analyzing General-Purpose Deep-Learning Detection and Segmentation  Models with Images from a Lidar as a Camera Sensor",
    "abstract": "Over the last decade, robotic perception algorithms have significantly\nbenefited from the rapid advances in deep learning (DL). Indeed, a significant\namount of the autonomy stack of different commercial and research platforms\nrelies on DL for situational awareness, especially vision sensors. This work\nexplores the potential of general-purpose DL perception algorithms,\nspecifically detection and segmentation neural networks, for processing\nimage-like outputs of advanced lidar sensors. Rather than processing the\nthree-dimensional point cloud data, this is, to the best of our knowledge, the\nfirst work to focus on low-resolution images with 360\\textdegree field of view\nobtained with lidar sensors by encoding either depth, reflectivity, or\nnear-infrared light in the image pixels. We show that with adequate\npreprocessing, general-purpose DL models can process these images, opening the\ndoor to their usage in environmental conditions where vision sensors present\ninherent limitations. We provide both a qualitative and quantitative analysis\nof the performance of a variety of neural network architectures. We believe\nthat using DL models built for visual cameras offers significant advantages due\nto the much wider availability and maturity compared to point cloud-based\nperception.",
    "descriptor": "",
    "authors": [
      "Yu Xianjia",
      "Sahar Salimpour",
      "Jorge Pe\u00f1a Queralta",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04064"
  },
  {
    "id": "arXiv:2203.04067",
    "title": "Lane Detection with Versatile AtrousFormer and Local Semantic Guidance",
    "abstract": "Lane detection is one of the core functions in autonomous driving and has\naroused widespread attention recently. The networks to segment lane instances,\nespecially with bad appearance, must be able to explore lane distribution\nproperties. Most existing methods tend to resort to CNN-based techniques. A few\nhave a try on incorporating the recent adorable, the seq2seq Transformer\n\\cite{transformer}. However, their innate drawbacks of weak global information\ncollection ability and exorbitant computation overhead prohibit a wide range of\nthe further applications. In this work, we propose Atrous Transformer\n(AtrousFormer) to solve the problem. Its variant local AtrousFormer is\ninterleaved into feature extractor to enhance extraction. Their collecting\ninformation first by rows and then by columns in a dedicated manner finally\nequips our network with stronger information gleaning ability and better\ncomputation efficiency. To further improve the performance, we also propose a\nlocal semantic guided decoder to delineate the identities and shapes of lanes\nmore accurately, in which the predicted Gaussian map of the starting point of\neach lane serves to guide the process. Extensive results on three challenging\nbenchmarks (CULane, TuSimple, and BDD100K) show that our network performs\nfavorably against the state of the arts.",
    "descriptor": "",
    "authors": [
      "Jiaxing Yang",
      "Lihe Zhang",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.04067"
  },
  {
    "id": "arXiv:2203.04071",
    "title": "AdaPT: Fast Emulation of Approximate DNN Accelerators in PyTorch",
    "abstract": "Current state-of-the-art employs approximate multipliers to address the\nhighly increased power demands of DNN accelerators. However, evaluating the\naccuracy of approximate DNNs is cumbersome due to the lack of adequate support\nfor approximate arithmetic in DNN frameworks. We address this inefficiency by\npresenting AdaPT, a fast emulation framework that extends PyTorch to support\napproximate inference as well as approximation-aware retraining. AdaPT can be\nseamlessly deployed and is compatible with the most DNNs. We evaluate the\nframework on several DNN models and application fields including CNNs, LSTMs,\nand GANs for a number of approximate multipliers with distinct bitwidth values.\nThe results show substantial error recovery from approximate re-training and\nreduced inference time up to 53.9x with respect to the baseline approximate\nimplementation.",
    "descriptor": "",
    "authors": [
      "Dimitrios Danopoulos",
      "Georgios Zervakis",
      "Kostas Siozios",
      "Dimitrios Soudris",
      "J\u00f6rg Henkel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.04071"
  },
  {
    "id": "arXiv:2203.04072",
    "title": "Guidelines for cyber risk management in shipboard operational technology  systems",
    "abstract": "Over the past few years, we have seen several cyber incidents being reported,\nwhere some of the primary causes were the lack of proper security controls\nonboard the ship and crew awareness on cybersecurity. In response to the\ngrowing cyber threat landscape in the maritime sector, we have developed a set\nof guidelines for maritime cyber risk management, focusing on four major\nshipboard Operational Technology (OT) systems that are crucial for the\nday-to-day operation of ships. These four OT systems are: Communication\nSystems, Propulsion, Machinery and Power Control Systems, Navigation Systems\nand Cargo Management Systems. The guidelines identify the cyber risks in each\nof the OT systems and recommend the necessary actions that can be taken to\nmanage risks in each shipboard OT system. In this paper, we introduce the new\nguidelines, which include cyber risks, mitigation measures, cyber risk\nassessment, and a checklist to help shipowners and maritime authorities assess\nand enhance cyber hygiene of their vessels. Our guidelines have been\ndisseminated by the Maritime and Port Authority of Singapore (MPA) to owners\nand operators of the Singapore Registry of Ships for their reference and use.",
    "descriptor": "",
    "authors": [
      "Priyanga Rajaram",
      "Mark Goh",
      "Jianying Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.04072"
  },
  {
    "id": "arXiv:2203.04074",
    "title": "E2EC: An End-to-End Contour-based Method for High-Quality High-Speed  Instance Segmentation",
    "abstract": "Contour-based instance segmentation methods have developed rapidly recently\nbut feature rough and hand-crafted front-end contour initialization, which\nrestricts the model performance, and an empirical and fixed backend\npredicted-label vertex pairing, which contributes to the learning difficulty.\nIn this paper, we introduce a novel contour-based method, named E2EC, for\nhigh-quality instance segmentation. Firstly, E2EC applies a novel learnable\ncontour initialization architecture instead of hand-crafted contour\ninitialization. This consists of a contour initialization module for\nconstructing more explicit learning goals and a global contour deformation\nmodule for taking advantage of all of the vertices' features better. Secondly,\nwe propose a novel label sampling scheme, named multi-direction alignment, to\nreduce the learning difficulty. Thirdly, to improve the quality of the boundary\ndetails, we dynamically match the most appropriate predicted-ground truth\nvertex pairs and propose the corresponding loss function named dynamic matching\nloss. The experiments showed that E2EC can achieve a state-of-the-art\nperformance on the KITTI INStance (KINS) dataset, the Semantic Boundaries\nDataset (SBD), the Cityscapes and the COCO dataset. E2EC is also efficient for\nuse in real-time applications, with an inference speed of 36 fps for 512*512\nimages on an NVIDIA A6000 GPU. Code will be released at\nhttps://github.com/zhang-tao-whu/e2ec.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Tao Zhang",
      "Shiqing Wei",
      "Shunping Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.04074"
  },
  {
    "id": "arXiv:2203.04075",
    "title": "Obstacle Aware Sampling for Path Planning",
    "abstract": "Many path planning algorithms are based on sampling the state space. While\nthis approach is very simple, it can become costly when the obstacles are\nunknown, since samples hitting these obstacles are wasted. The goal of this\npaper is to efficiently identify obstacles in a map and remove them from the\nsampling space. To this end, we propose a pre-processing algorithm for space\nexploration that enables more efficient sampling. We show that it can boost the\nperformance of other space sampling methods and path planners.\nOur approach is based on the fact that a convex obstacle can be approximated\nprovably well by its minimum volume enclosing ellipsoid (MVEE), and a\nnon-convex obstacle may be partitioned into convex shapes. Our main\ncontribution is an algorithm that strategically finds a small sample, called\nthe \\emph{active-coreset}, that adaptively samples the space via\nmembership-oracle such that the MVEE of the coreset approximates the MVEE of\nthe obstacle. Experimental results confirm the effectiveness of our approach\nacross multiple planners based on Rapidly-exploring random trees, showing\nsignificant improvement in terms of time and path length.",
    "descriptor": "",
    "authors": [
      "Murad Tukan",
      "Alaa Maalouf",
      "Dan Feldman",
      "Roi Poranne"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04075"
  },
  {
    "id": "arXiv:2203.04076",
    "title": "Semantic Distillation Guided Salient Object Detection",
    "abstract": "Most existing CNN-based salient object detection methods can identify local\nsegmentation details like hair and animal fur, but often misinterpret the real\nsaliency due to the lack of global contextual information caused by the\nsubjectiveness of the SOD task and the locality of convolution layers.\nMoreover, due to the unrealistically expensive labeling costs, the current\nexisting SOD datasets are insufficient to cover the real data distribution. The\nlimitation and bias of the training data add additional difficulty to fully\nexploring the semantic association between object-to-object and\nobject-to-environment in a given image. In this paper, we propose a semantic\ndistillation guided SOD (SDG-SOD) method that produces accurate results by\nfusing semantically distilled knowledge from generated image captioning into\nthe Vision-Transformer-based SOD framework. SDG-SOD can better uncover\ninter-objects and object-to-environment saliency and cover the gap between the\nsubjective nature of SOD and its expensive labeling. Comprehensive experiments\non five benchmark datasets demonstrate that the SDG-SOD outperforms the\nstate-of-the-art approaches on four evaluation metrics, and largely improves\nthe model performance on DUTS, ECSSD, DUT, HKU-IS, and PASCAL-S datasets.",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Bo Xu",
      "Guanze Liu",
      "Han Huang",
      "Cheng Lu",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.04076"
  },
  {
    "id": "arXiv:2203.04079",
    "title": "A New Fault-Tolerant Synchronization Scheme with Anonymous Pulses",
    "abstract": "Robust pulse synchronization is fundamental in constructing reliable\nsynchronous applications in wired and wireless distributed systems. In wired\nsystems, self-stabilizing Byzantine pulse synchronization aims for\nsynchronizing fault-prone distributed components with arbitrary initial states\nin bounded-delay message-passing systems. In wireless systems, fault-tolerant\nsynchronization of pulse-coupled oscillators is also built for a similar goal\nbut often works under specific system restrictions, such as low computation\npower, low message complexity, and anonymous physical pulses whose senders\ncannot be identified by the receivers. These restrictions often prevent us from\nconstructing high-reliable wireless synchronous applications. This paper tries\nto break barriers between bounded-delay message-passing systems and classical\npulse-coupled oscillators by introducing a new fault-tolerant synchronization\nscheme for the so-called anonymous bounded-delay pulsing systems in the\npresence of indeterministic communication delays and inconsistent faults. For\nlow computation power and low message complexity, instead of involving in\nconsensus-based primitives, the proposed synchronization scheme integrates the\nso-called discrete mean-fields, planar random walks, and some additional easy\noperations in utilizing only sparsely generated anonymous pulses. For\nfault-tolerance, we show that a square-root number of faulty oscillators can be\ntolerated by utilizing planar random walks in anonymous pulse synchronization.\nFor self-stabilization, we show that the stabilization can be reached in an\nexpected constant number of observing windows in anonymous bounded-delay\npulsing systems with the pulsing-frequency restriction.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Shaolin Yu",
      "Jihong Zhu",
      "Jiali Yang",
      "Wei Lu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.04079"
  },
  {
    "id": "arXiv:2203.04085",
    "title": "Urban Vehicle Mobility Characteristic Mining and Trip Generation Based  on Knowledge Graph",
    "abstract": "The operation of urban transportation produces massive traffic data, which\ncontains abundant information and is of great significance for the study of\nintelligent transportation systems. In particular, with the improvement of\nperception technology, it has become possible to obtain trip data in\nindividual-level of vehicles. It has finer granularity and greater research\npotential, but at the same time requires higher requirements in terms of data\norganization and analysis. More importantly it cannot be made public due to\nprivacy issues. To handle individual-level urban vehicle trip big data better,\nwe introduce the knowledge graph for the study. For organization of individual\nlevel trip data, we designed and constructed an individual-level trip knowledge\ngraph which greatly improves the efficiency of obtaining data. Then we used the\ntrip knowledge graph as the data engine and designed logical rules to mine the\ntrip characteristics of vehicles by combining the transportation domain\nknowledge. Finally, we further propose an individual-level trip synthesis\nmethod based on knowledge graph generation to address the privacy issue of\nindividual-level traffic data. The experiment shows that the final generated\ntrip data are similar to the historical one in mobility patterns and vehicle\nassociations, and have high spatial continuity.",
    "descriptor": "",
    "authors": [
      "Guilong Li",
      "Yixian Chen",
      "Jun Xie",
      "Qinghai Lin",
      "Zhaocheng He"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.04085"
  },
  {
    "id": "arXiv:2203.04086",
    "title": "The infinity norm bounds and characteristic polynomial for high order RK  matrices",
    "abstract": "This paper shows that $t_m \\leq \\|\\mathbf{A}\\|_\\infty \\leq \\sqrt{t_m}$ holds,\nwhen $\\mathbf{A} \\in \\mathbb{R}^{m \\times m}$ is a Runge-Kutta matrix which\nnodes originating from the Gaussian quadrature that integrates polynomials of\ndegree $2m-2$ exactly. It can be shown that this is also true for the\nGauss-Lobatto quadrature. Additionally, the characteristic polynomial of\n$\\mathbf{A}$, when the matrix is nonsingular, is $p_A(\\lambda) = m!t^m +\n(m-1)!a_{m-1}t^{m-1} + \\dots + a_0$, where the coefficients $a_i$ are the\ncoefficients of the polynomial of nodes $\\omega(t) = (t - t_1) \\dots (t - t_m)\n= t^m + a_{m-1}t^{m-1} + \\dots + a_0$.",
    "descriptor": "",
    "authors": [
      "Gayatri Caklovic"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.04086"
  },
  {
    "id": "arXiv:2203.04088",
    "title": "The role of alcohol outlet visits derived from mobile phone location  data in enhancing domestic violence prediction at the neighborhood level",
    "abstract": "Domestic violence (DV) is a serious public health issue, with 1 in 3 women\nand 1 in 4 men experiencing some form of partner-related violence every year.\nExisting research has shown a strong association between alcohol use and DV at\nthe individual level. Accordingly, alcohol use could also be a predictor for DV\nat the neighborhood level, helping identify the neighborhoods where DV is more\nlikely to happen. However, it is difficult and costly to collect data that can\nrepresent neighborhood-level alcohol use especially for a large geographic\narea. In this study, we propose to derive information about the alcohol outlet\nvisits of the residents of different neighborhoods from anonymized mobile phone\nlocation data, and investigate whether the derived visits can help better\npredict DV at the neighborhood level. We use mobile phone data from the company\nSafeGraph, which is freely available to researchers and which contains\ninformation about how people visit various points-of-interest including alcohol\noutlets. In such data, a visit to an alcohol outlet is identified based on the\nGPS point location of the mobile phone and the building footprint (a polygon)\nof the alcohol outlet. We present our method for deriving neighborhood-level\nalcohol outlet visits, and experiment with four different statistical and\nmachine learning models to investigate the role of the derived visits in\nenhancing DV prediction based on an empirical dataset about DV in Chicago. Our\nresults reveal the effectiveness of the derived alcohol outlets visits in\nhelping identify neighborhoods that are more likely to suffer from DV, and can\ninform policies related to DV intervention and alcohol outlet licensing.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Ting Chang",
      "Yingjie Hu",
      "Dane Taylor",
      "Brian M. Quigley"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04088"
  },
  {
    "id": "arXiv:2203.04089",
    "title": "Associating eHealth Policies and National Data Privacy Regulations",
    "abstract": "As electronic data becomes the lifeline of modern society, privacy concerns\nincrease. These concerns are reflected by the European Union's enactment of the\nGeneral Data Protection Regulation (GDPR), one of the most comprehensive and\nrobust privacy regulations globally. This project aims to evaluate and\nhighlight associations between eHealth systems' policies and personal data\nprivacy regulations. Using bias-corrected Cramer's V and Thiel's U tests, we\nfound weak and zero associations between e-health systems' rules and\nprotections for data privacy. A simple decision tree model is trained, which\nvalidates the association scores obtained",
    "descriptor": "",
    "authors": [
      "Saurav K. Aryal",
      "Peter A. Keiller"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.04089"
  },
  {
    "id": "arXiv:2203.04090",
    "title": "Foundations for Grassroots Democratic Metaverse",
    "abstract": "While the physical lives of many of us are in democracies (one person, one\nvote - e.g., the EU and the US), our digital lives are mostly in autocracies\n(one person, all votes - e.g., Facebook). Cryptocurrencies promise liberation\nbut stop short, at plutocracy (one coin, one vote). What would it take for us\nto live in a digital democracy? This paper offers a vision, a theoretical\nframework, and an architecture for a grassroots network of autonomous,\npeople-owned, people-operated, and people-governed digital communities, namely\na grassroots democratic metaverse. It also charts a roadmap towards realizing\nit, and identifies unexplored territory for MAS research.",
    "descriptor": "",
    "authors": [
      "Nimrod Talmon",
      "Ehud Shapiro"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.04090"
  },
  {
    "id": "arXiv:2203.04095",
    "title": "Contrastive Enhancement Using Latent Prototype for Few-Shot Segmentation",
    "abstract": "Few-shot segmentation enables the model to recognize unseen classes with few\nannotated examples. Most existing methods adopt prototype learning\narchitecture, where support prototype vectors are expanded and concatenated\nwith query features to perform conditional segmentation. However, such\nframework potentially focuses more on query features while may neglect the\nsimilarity between support and query features. This paper proposes a\ncontrastive enhancement approach using latent prototypes to leverage latent\nclasses and raise the utilization of similarity information between prototype\nand query features. Specifically, a latent prototype sampling module is\nproposed to generate pseudo-mask and novel prototypes based on features\nsimilarity. The module conveniently conducts end-to-end learning and has no\nstrong dependence on clustering numbers like cluster-based method. Besides, a\ncontrastive enhancement module is developed to drive models to provide\ndifferent predictions with the same query features. Our method can be used as\nan auxiliary module to flexibly integrate into other baselines for a better\nsegmentation performance. Extensive experiments show our approach remarkably\nimproves the performance of state-of-the-art methods for 1-shot and 5-shot\nsegmentation, especially outperforming baseline by 5.9% and 7.3% for 5-shot\ntask on Pascal-5^i and COCO-20^i. Source code is available at\nhttps://github.com/zhaoxiaoyu1995/CELP-Pytorch",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Xiaoyu Zhao",
      "Xiaoqian Chen",
      "Zhiqiang Gong",
      "Wen Yao",
      "Yunyang Zhang",
      "Xiaohu Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.04095"
  },
  {
    "id": "arXiv:2203.04098",
    "title": "COLA: Consistent Learning with Opponent-Learning Awareness",
    "abstract": "Learning in general-sum games can be unstable and often leads to socially\nundesirable, Pareto-dominated outcomes. To mitigate this, Learning with\nOpponent-Learning Awareness (LOLA) introduced opponent shaping to this setting,\nby accounting for the agent's influence on the anticipated learning steps of\nother agents. However, the original LOLA formulation (and follow-up work) is\ninconsistent because LOLA models other agents as naive learners rather than\nLOLA agents. In previous work, this inconsistency was suggested as a cause of\nLOLA's failure to preserve stable fixed points (SFPs). First, we formalize\nconsistency and show that higher-order LOLA (HOLA) solves LOLA's inconsistency\nproblem if it converges. Second, we correct a claim made in the literature, by\nproving that, contrary to Sch\\\"afer and Anandkumar (2019), Competitive Gradient\nDescent (CGD) does not recover HOLA as a series expansion. Hence, CGD also does\nnot solve the consistency problem. Third, we propose a new method called\nConsistent LOLA (COLA), which learns update functions that are consistent under\nmutual opponent shaping. It requires no more than second-order derivatives and\nlearns consistent update functions even when HOLA fails to converge. However,\nwe also prove that even consistent update functions do not preserve SFPs,\ncontradicting the hypothesis that this shortcoming is caused by LOLA's\ninconsistency. Finally, in an empirical evaluation on a set of general-sum\ngames, we find that COLA finds prosocial solutions and that it converges under\na wider range of learning rates than HOLA and LOLA. We support the latter\nfinding with a theoretical result for a simple game.",
    "descriptor": "",
    "authors": [
      "Timon Willi",
      "Johannes Treutlein",
      "Alistair Letcher",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.04098"
  },
  {
    "id": "arXiv:2203.04099",
    "title": "VoViT: Low Latency Graph-based Audio-Visual Voice Separation Transformer",
    "abstract": "This paper presents an audio-visual approach for voice separation which\noutperforms state-of-the-art methods at a low latency in two scenarios: speech\nand singing voice. The model is based on a two-stage network. Motion cues are\nobtained with a lightweight graph convolutional network that processes face\nlandmarks. Then, both audio and motion features are fed to an audio-visual\ntransformer which produces a fairly good estimation of the isolated target\nsource. In a second stage, the predominant voice is enhanced with an audio-only\nnetwork. We present different ablation studies and comparison to\nstate-of-the-art methods. Finally, we explore the transferability of models\ntrained for speech separation in the task of singing voice separation. The\ndemos, code, and weights will be made publicly available at\nhttps://ipcv.github.io/VoViT/",
    "descriptor": "",
    "authors": [
      "Juan F. Montesinos",
      "Venkatesh S. Kadandale",
      "Gloria Haro"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.04099"
  },
  {
    "id": "arXiv:2203.04100",
    "title": "Low-rank approximation of continuous functions in Sobolev spaces with  dominating mixed smoothness",
    "abstract": "Let $\\Omega_i\\subset\\mathbb{R}^{n_i}$, $i=1,\\ldots,m$, be given domains. In\nthis article, we study the low-rank approximation with respect to\n$L^2(\\Omega_1\\times\\dots\\times\\Omega_m)$ of functions from Sobolev spaces with\ndominating mixed smoothness. To this end, we first estimate the rank of a\nbivariate approximation, i.e., the rank of the continuous singular value\ndecomposition. In comparison to the case of functions from Sobolev spaces with\nisotropic smoothness, compare \\cite{GH14,GH19}, we obtain improved results due\nto the additional mixed smoothness. This convergence result is then used to\nstudy the tensor train decomposition as a method to construct multivariate\nlow-rank approximations of functions from Sobolev spaces with dominating mixed\nsmoothness. We show that this approach is able to beat the curse of dimension.",
    "descriptor": "",
    "authors": [
      "Michael Griebel",
      "Helmut Harbrecht",
      "Reinhold Schneider"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.04100"
  },
  {
    "id": "arXiv:2203.04109",
    "title": "Explaining Classifiers by Constructing Familiar Concepts",
    "abstract": "Interpreting a large number of neurons in deep learning is difficult. Our\nproposed `CLAssifier-DECoder' architecture (ClaDec) facilitates the\nunderstanding of the output of an arbitrary layer of neurons or subsets\nthereof. It uses a decoder that transforms the incomprehensible representation\nof the given neurons to a representation that is more similar to the domain a\nhuman is familiar with. In an image recognition problem, one can recognize what\ninformation (or concepts) a layer maintains by contrasting reconstructed images\nof ClaDec with those of a conventional auto-encoder(AE) serving as reference.\nAn extension of ClaDec allows trading comprehensibility and fidelity. We\nevaluate our approach for image classification using convolutional neural\nnetworks. We show that reconstructed visualizations using encodings from a\nclassifier capture more relevant classification information than conventional\nAEs. This holds although AEs contain more information on the original input.\nOur user study highlights that even non-experts can identify a diverse set of\nconcepts contained in images that are relevant (or irrelevant) for the\nclassifier. We also compare against saliency based methods that focus on pixel\nrelevance rather than concepts. We show that ClaDec tends to highlight more\nrelevant input areas to classification though outcomes depend on classifier\narchitecture. Code is at \\url{https://github.com/JohnTailor/ClaDec}",
    "descriptor": "\nComments: This paper is a journal version of the conference paper arXiv:2005.13630 . It adds about 60% new material. It was accepted at Machine Learning (Springer Journal) in March 2022\n",
    "authors": [
      "Johannes Schneider",
      "Michail Vlachos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04109"
  },
  {
    "id": "arXiv:2203.04111",
    "title": "Plumeria at SemEval-2022 Task 6: Robust Approaches for Sarcasm Detection  for English and Arabic Using Transformers and Data Augmentation",
    "abstract": "This paper describes our submission to SemEval-2022 Task 6 on sarcasm\ndetection and its five subtasks for English and Arabic. Sarcasm conveys a\nmeaning which contradicts the literal meaning, and it is mainly found on social\nnetworks. It has a significant role in understanding the intention of the user.\nFor detecting sarcasm, we used deep learning techniques based on transformers\ndue to its success in the field of Natural Language Processing (NLP) without\nthe need for feature engineering. The datasets were taken from tweets. We\ncreated new datasets by augmenting with external data or by using word\nembeddings and repetition of instances. Experiments were done on the datasets\nwith different types of preprocessing because it is crucial in this task. The\nrank of our team was consistent across four subtasks (fourth rank in three\nsubtasks and sixth rank in one subtask); whereas other teams might be in the\ntop ranks for some subtasks but rank drastically less in other subtasks. This\nimplies the robustness and stability of the models and the techniques we used.",
    "descriptor": "\nComments: SemEval-2022 workshop paper, submitted in NAACL-2022 conference. 8 figures and 29 tables. 8 main pages, 4 appendix pages\n",
    "authors": [
      "Shubham Kumar Nigam",
      "Mosab Shaheen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04111"
  },
  {
    "id": "arXiv:2203.04113",
    "title": "Quantification of Occlusion Handling Capability of a 3D Human Pose  Estimation Framework",
    "abstract": "3D human pose estimation using monocular images is an important yet\nchallenging task. Existing 3D pose detection methods exhibit excellent\nperformance under normal conditions however their performance may degrade due\nto occlusion. Recently some occlusion aware methods have also been proposed,\nhowever, the occlusion handling capability of these networks has not yet been\nthoroughly investigated. In the current work, we propose an occlusion-guided 3D\nhuman pose estimation framework and quantify its occlusion handling capability\nby using different protocols. The proposed method estimates more accurate 3D\nhuman poses using 2D skeletons with missing joints as input. Missing joints are\nhandled by introducing occlusion guidance that provides extra information about\nthe absence or presence of a joint. Temporal information has also been\nexploited to better estimate the missing joints. A large number of experiments\nare performed for the quantification of occlusion handling capability of the\nproposed method on three publicly available datasets in various settings\nincluding random missing joints, fixed body parts missing, and complete frames\nmissing, using mean per joint position error criterion. In addition to that,\nthe quality of the predicted 3D poses is also evaluated using action\nclassification performance as a criterion. 3D poses estimated by the proposed\nmethod achieved significantly improved action recognition performance in the\npresence of missing joints. Our experiments demonstrate the effectiveness of\nthe proposed framework for handling the missing joints as well as\nquantification of the occlusion handling capability of the deep neural\nnetworks.",
    "descriptor": "\nComments: Accepted for publication in IEEE Transaction Multimedia, 2022\n",
    "authors": [
      "Mehwish Ghafoor",
      "Arif Mahmood"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04113"
  },
  {
    "id": "arXiv:2203.04114",
    "title": "A study on joint modeling and data augmentation of multi-modalities for  audio-visual scene classification",
    "abstract": "In this paper, we propose two techniques, namely joint modeling and data\naugmentation, to improve system performances for audio-visual scene\nclassification (AVSC). We employ pre-trained networks trained only on image\ndata sets to extract video embedding; whereas for audio embedding models, we\ndecide to train them from scratch. We explore different neural network\narchitectures for joint modeling to effectively combine the video and audio\nmodalities. Moreover, data augmentation strategies are investigated to increase\naudio-visual training set size. For the video modality the effectiveness of\nseveral operations in RandAugment is verified. An audio-video joint mixup\nscheme is proposed to further improve AVSC performances. Evaluated on the\ndevelopment set of TAU Urban Audio Visual Scenes 2021, our final system can\nachieve the best accuracy of 94.2% among all single AVSC systems submitted to\nDCASE 2021 Task 1b.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Qing Wang",
      "Jun Du",
      "Siyuan Zheng",
      "Yunqing Li",
      "Yajian Wang",
      "Yuzhong Wu",
      "Hu Hu",
      "Chao-Han Huck Yang",
      "Sabato Marco Siniscalchi",
      "Yannan Wang",
      "Chin-Hui Lee"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.04114"
  },
  {
    "id": "arXiv:2203.04117",
    "title": "xTag: Mitigating Use-After-Free Vulnerabilities via Software-Based  Pointer Tagging on Intel x86-64",
    "abstract": "Memory safety in complex applications implemented in unsafe programming\nlanguages such as C/C++ is still an unresolved problem in practice. Many\ndifferent types of defenses have been proposed in the past to mitigate this\nproblem. The most promising next step is a tighter integration of the hardware\nand software level: modern mitigation techniques are either accelerated using\nhardware extensions or implemented in the hardware by extensions of the ISA. In\nparticular, memory tagging, as proposed by ARM or SPARC, promises to solve many\nissues for practical memory safety. Unfortunately, Intel x86-64, which\nrepresents the most important ISA for both the desktop and server domain, lacks\nsupport for hardware-accelerated memory tagging, so memory tagging is not\nconsidered practical for this platform.\nIn this paper, we present the design and implementation of an efficient,\nsoftware-only pointer tagging scheme for Intel x86-64 based on a novel metadata\nembedding scheme. The basic idea is to alias multiple virtual pages to one\nphysical page so that we can efficiently embed tag bits into a pointer.\nFurthermore, we introduce several optimizations that significantly reduce the\nperformance impact of this approach to memory tagging. Based on this scheme, we\npropose a novel use-after-free mitigation scheme, called xTag, that offers\nbetter performance and strong security properties compared to state-of-the-art\nmethods. We also show how double-free vulnerabilities can be mitigated. Our\napproach is highly compatible, allowing pointers to be passed back and forth\nbetween instrumented and non-instrumented code without losing metadata, and it\nis even compatible with inline assembly. We conclude that building exploit\nmitigation mechanisms on top of our memory tagging scheme is feasible on Intel\nx86-64, as demonstrated by the effective prevention of use-after-free bugs in\nthe Firefox web browser.",
    "descriptor": "",
    "authors": [
      "Lukas Bernhard",
      "Michael Rodler",
      "Thorsten Holz",
      "Lucas Davi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.04117"
  },
  {
    "id": "arXiv:2203.04120",
    "title": "Graph-based Reinforcement Learning meets Mixed Integer Programs: An  application to 3D robot assembly discovery",
    "abstract": "Robot assembly discovery is a challenging problem that lives at the\nintersection of resource allocation and motion planning. The goal is to combine\na predefined set of objects to form something new while considering task\nexecution with the robot-in-the-loop. In this work, we tackle the problem of\nbuilding arbitrary, predefined target structures entirely from scratch using a\nset of Tetris-like building blocks and a robotic manipulator. Our novel\nhierarchical approach aims at efficiently decomposing the overall task into\nthree feasible levels that benefit mutually from each other. On the high level,\nwe run a classical mixed-integer program for global optimization of block-type\nselection and the blocks' final poses to recreate the desired shape. Its output\nis then exploited to efficiently guide the exploration of an underlying\nreinforcement learning (RL) policy. This RL policy draws its generalization\nproperties from a flexible graph-based representation that is learned through\nQ-learning and can be refined with search. Moreover, it accounts for the\nnecessary conditions of structural stability and robotic feasibility that\ncannot be effectively reflected in the previous layer. Lastly, a grasp and\nmotion planner transforms the desired assembly commands into robot joint\nmovements. We demonstrate the performance of the proposed method on a set of\ncompetitive simulated robot assembly discovery environments and report\nperformance and robustness gains compared to an unstructured end-to-end\napproach. Videos are available at https://sites.google.com/view/rl-meets-milp .",
    "descriptor": "",
    "authors": [
      "Niklas Funk",
      "Svenja Menzenbach",
      "Georgia Chalvatzaki",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04120"
  },
  {
    "id": "arXiv:2203.04121",
    "title": "Few Shot Generative Model Adaption via Relaxed Spatial Structural  Alignment",
    "abstract": "Training a generative adversarial network (GAN) with limited data has been a\nchallenging task. A feasible solution is to start with a GAN well-trained on a\nlarge scale source domain and adapt it to the target domain with a few samples,\ntermed as few shot generative model adaption. However, existing methods are\nprone to model overfitting and collapse in extremely few shot setting (less\nthan 10). To solve this problem, we propose a relaxed spatial structural\nalignment method to calibrate the target generative models during the adaption.\nWe design a cross-domain spatial structural consistency loss comprising the\nself-correlation and disturbance correlation consistency loss. It helps align\nthe spatial structural information between the synthesis image pairs of the\nsource and target domains. To relax the cross-domain alignment, we compress the\noriginal latent space of generative models to a subspace. Image pairs generated\nfrom the subspace are pulled closer. Qualitative and quantitative experiments\nshow that our method consistently surpasses the state-of-the-art methods in few\nshot setting.",
    "descriptor": "",
    "authors": [
      "Jiayu Xiao",
      "Liang Li",
      "Chaofei Wang",
      "Zheng-Jun Zha",
      "Qingming Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04121"
  },
  {
    "id": "arXiv:2203.04123",
    "title": "On the complexity of invariant polynomials under the action of finite  reflection groups",
    "abstract": "Let $G$ be a finite reflection group and $\\mathbb{K}[x_1, \\dots, x_n]$ be a\nmultivariate polynomial ring over a field $\\mathbb{K}$. Let $\\mathbb{K}[x_1,\n\\dots, x_n]^G$ be a set containing all invariant polynomials under the action\nof $G$. Then the Chevalley-Shephard-Todd theorem states that there exists a\nsequence of homogeneous polynomials $\\eta_1, \\dots, \\eta_n$ such that for any\npolynomial $f$ in $\\mathbb{K}[x_1, \\dots, x_n]^G$, there exists a unique\npolynomial $f_{\\rm new}$ in $\\mathbb{K}[e_1, \\dots, e_n]$, where $e_1, \\dots,\ne_n$ are new variables, such that $f_{\\mathrm{new}}(\\eta_1, \\dots, \\eta_n) =\nf(x_1, \\dots, x_n)$. In this paper, we study the arithmetic complexity to\ncompute $f_{\\mathrm{new}}$ knowing $f$ and $(\\eta_1, \\dots, \\eta_n)$. Our\nalgorithm works for any finite reflection group $G$ and any set of generators\n$(\\eta_1, \\dots, \\eta_n)$. Previously such a result was only known for $G$ a\nsymmetric group or a directed product of symmetric groups and $\\eta_1, \\dots,\n\\eta_n$ elementary symmetric functions.",
    "descriptor": "",
    "authors": [
      "Thi Xuan Vu"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2203.04123"
  },
  {
    "id": "arXiv:2203.04129",
    "title": "YouTube-GDD: A challenging gun detection dataset with rich contextual  information",
    "abstract": "An automatic gun detection system can detect potential gun-related violence\nat an early stage that is of paramount importance for citizens security. In the\nwhole system, object detection algorithm is the key to perceive the environment\nso that the system can detect dangerous objects such as pistols and rifles.\nHowever, mainstream deep learning-based object detection algorithms depend\nheavily on large-scale high-quality annotated samples, and the existing gun\ndatasets are characterized by low resolution, little contextual information and\nlittle data volume. To promote the development of security, this work presents\na new challenging dataset called YouTube Gun Detection Dataset (YouTube-GDD).\nOur dataset is collected from 343 high-definition YouTube videos and contains\n5000 well-chosen images, in which 16064 instances of gun and 9046 instances of\nperson are annotated. Compared to other datasets, YouTube-GDD is \"dynamic\",\ncontaining rich contextual information and recording shape changes of the gun\nduring shooting. To build a baseline for gun detection, we evaluate YOLOv5 on\nYouTube-GDD and analyze the influence of additional related annotated\ninformation on gun detection. YouTube-GDD and subsequent updates will be\nreleased at https://github.com/UCAS-GYX/YouTube-GDD.",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Yongxiang Gu",
      "Xingbin Liao",
      "Xiaolin Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.04129"
  },
  {
    "id": "arXiv:2203.04130",
    "title": "NeReF: Neural Refractive Field for Fluid Surface Reconstruction and  Implicit Representation",
    "abstract": "Existing neural reconstruction schemes such as Neural Radiance Field (NeRF)\nare largely focused on modeling opaque objects. We present a novel neural\nrefractive field(NeReF) to recover wavefront of transparent fluids by\nsimultaneously estimating the surface position and normal of the fluid front.\nUnlike prior arts that treat the reconstruction target as a single layer of the\nsurface, NeReF is specifically formulated to recover a volumetric normal field\nwith its corresponding density field. A query ray will be refracted by NeReF\naccording to its accumulated refractive point and normal, and we employ the\ncorrespondences and uniqueness of refracted ray for NeReF optimization. We show\nNeReF, as a global optimization scheme, can more robustly tackle refraction\ndistortions detrimental to traditional methods for correspondence matching.\nFurthermore, the continuous NeReF representation of wavefront enables view\nsynthesis as well as normal integration. We validate our approach on both\nsynthetic and real data and show it is particularly suitable for sparse\nmulti-view acquisition. We hence build a small light field array and experiment\non various surface shapes to demonstrate high fidelity NeReF reconstruction.",
    "descriptor": "",
    "authors": [
      "Ziyu Wang",
      "Wei Yang",
      "Junming Cao",
      "Lan Xu",
      "Junqing Yu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04130"
  },
  {
    "id": "arXiv:2203.04132",
    "title": "Motron: Multimodal Probabilistic Human Motion Forecasting",
    "abstract": "Autonomous systems and humans are increasingly sharing the same space. Robots\nwork side by side or even hand in hand with humans to balance each other's\nlimitations. Such cooperative interactions are ever more sophisticated. Thus,\nthe ability to reason not just about a human's center of gravity position, but\nalso its granular motion is an important prerequisite for human-robot\ninteraction. Though, many algorithms ignore the multimodal nature of humans or\nneglect uncertainty in their motion forecasts. We present Motron, a multimodal,\nprobabilistic, graph-structured model, that captures human's multimodality\nusing probabilistic methods while being able to output deterministic motions\nand corresponding confidence values for each mode. Our model aims to be tightly\nintegrated with the robotic planning-control-interaction loop; outputting\nphysically feasible human motions and being computationally efficient. We\ndemonstrate the performance of our model on several challenging real-world\nmotion forecasting datasets, outperforming a wide array of generative methods\nwhile providing state-of-the-art deterministic motions if required. Both using\nsignificantly less computational power than state-of-the art algorithms.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Tim Salzmann",
      "Marco Pavone",
      "Markus Ryll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.04132"
  },
  {
    "id": "arXiv:2203.04135",
    "title": "Bots don't Vote, but They Surely Bother! A Study of Anomalous Accounts  in a National Referendum",
    "abstract": "The Web contains several social media platforms for discussion, exchange of\nideas, and content publishing. These platforms are used by people, but also by\ndistributed agents known as bots. Although bots have existed for decades, with\nmany of them being benevolent, their influence in propagating and generating\ndeceptive information in the last years has increased. Here we present a\ncharacterization of the discussion on Twitter about the 2020 Chilean\nconstitutional referendum. The characterization uses a profile-oriented\nanalysis that enables the isolation of anomalous content using machine\nlearning. As result, we obtain a characterization that matches national vote\nturnout, and we measure how anomalous accounts (some of which are automated\nbots) produce content and interact promoting (false) information.",
    "descriptor": "\nComments: 5 pages, 9 figures\n",
    "authors": [
      "Eduardo Graells-Garrido",
      "Ricardo Baeza-Yates"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.04135"
  },
  {
    "id": "arXiv:2203.04136",
    "title": "Cybersecurity Playbook Sharing with STIX 2.1",
    "abstract": "Understanding that interoperable machine-readable security playbooks will\nbecome a fundamental component of defenders' arsenal to decrease attack\ndetection and response times, it is time to consider their position in sharing\nefforts. This report documents the process of extending Structured Threat\nInformation eXpression (STIX) version 2.1, using the available extension\ndefinition mechanism, to enable sharing machine-readable security playbooks\nand, in particular, Collaborative Automated Course of Action Operations (CACAO)\nplaybooks.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2110.10540\n",
    "authors": [
      "Vasileios Mavroeidis",
      "Mateusz Zych"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.04136"
  },
  {
    "id": "arXiv:2203.04138",
    "title": "A Jacobian Free Deterministic Method for Solving Inverse Problems",
    "abstract": "An effective numerical method is presented for optimizing model parameters\nthat can be applied to any type of system of non-linear equations and any\nnumber of data-points, which does not require explicit formulation of the\nobjective function or its partial derivatives. The numerics are reduced to\nsolving a non-linear least squares problem, which uses the Levenberg-Marquardt\nalgorithm and the Jacobian is approximated by applying rank-one updates using\nBroyden's method. An advantage of this methodology over conventional approaches\nis that the partial derivatives of the objective function do not have to be\nanalytically calculated. For instance, there may be situations where one cannot\nformulate the partial derivatives, such as cases involving an objective\nfunction that itself contains a nested optimization problem. Moreover, a line\nsearch algorithm is also described that ensures that the Armijo conditions are\nsatisfied and that convergence is assured, which makes the success of the\napproach insensitive to the initial estimates of the model parameters. The\nforegoing numerical methods are described with respect to the development of\nthe Optima software to solve inverse problems, which are reduced to non-linear\nleast squares problems. This computational approach has proven to be\nparticularly useful at solving inverse problems of very complex physical models\nthat cannot be optimized directly in a practical way.",
    "descriptor": "",
    "authors": [
      "M.H.A. Piro",
      "J.S. Bell",
      "M. Poschmann",
      "A. Prudil",
      "P. Chan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2203.04138"
  },
  {
    "id": "arXiv:2203.04142",
    "title": "A Reply to \"On Salum's Algorithm for X3SAT\"",
    "abstract": "This paper is a reply to \"On Salum's Algorithm for X3SAT\" (arXiv:2104.02886)",
    "descriptor": "",
    "authors": [
      "Latif Salum"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.04142"
  },
  {
    "id": "arXiv:2203.04146",
    "title": "Runtime Enforcement of Hyperproperties",
    "abstract": "An enforcement mechanism monitors a reactive system for undesired behavior at\nruntime and corrects the system's output in case it violates the given\nspecification. In this paper, we study the enforcement problem for\nhyperproperties, i.e., properties that relate multiple computation traces to\neach other. We elaborate the notion of sound and transparent enforcement\nmechanisms for hyperproperties in two trace input models: 1) the parallel trace\ninput model, where the number of traces is known a-priori and all traces are\nproduced and processed in parallel and 2) the sequential trace input model,\nwhere traces are processed sequentially and no a-priori bound on the number of\ntraces is known. For both models, we study enforcement algorithms for\nspecifications given as formulas in universally quantified HyperLTL, a temporal\nlogic for hyperproperties. For the parallel model, we describe an enforcement\nmechanism based on parity games. For the sequential model, we show that\nenforcement is in general undecidable and present algorithms for reasonable\nsimplifications of the problem (partial guarantees or the restriction to safety\nproperties). Furthermore, we report on experimental results of our prototype\nimplementation for the parallel model.",
    "descriptor": "",
    "authors": [
      "Norine Coenen",
      "Bernd Finkbeiner",
      "Christopher Hahn",
      "Jana Hofmann",
      "Yannick Schillo"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.04146"
  },
  {
    "id": "arXiv:2203.04147",
    "title": "Mu-synthesis PID Control of Full-Car with Parallel Active Link  Suspension Under Variable Payload",
    "abstract": "This paper presents a combined mu-synthesis PID control scheme, employing a\nfrequency separation paradigm, for a recently proposed novel active suspension,\nthe Parallel Active Link Suspension (PALS). The developed mu-synthesis control\nscheme is superior to the conventional H-infinity control, previously designed\nfor the PALS, in terms of ride comfort and road holding (higher frequency\ndynamics), with important realistic uncertainties, such as in vehicle payload,\ntaken into account. The developed PID control method is applied to guarantee\ngood chassis attitude control capabilities and minimization of pitch and roll\nmotions (low frequency dynamics). A multi-objective control method, which\nmerges the aforementioned PID and mu-synthesis-based controls is further\nintroduced to achieve simultaneously the low frequency mitigation of attitude\nmotions and the high frequency vibration suppression of the vehicle. A\nseven-degree-of-freedom Sport Utility Vehicle (SUV) full car model with PALS,\nis employed in this work to test the synthesized controller by nonlinear\nsimulations with different ISO-defined road events and variable vehicle\npayload. The results demonstrate the control scheme's significant robustness\nand performance, as compared to the conventional passive suspension as well as\nthe actively controlled PALS by conventional H-infinity control, achieved for a\nwide range of vehicle payload considered in the investigation.",
    "descriptor": "\nComments: 13 pages, 24 figures\n",
    "authors": [
      "Zilin Feng",
      "Min Yu",
      "Simos A. Evangelou",
      "Imad M Jaimoukha",
      "Daniele Dini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.04147"
  },
  {
    "id": "arXiv:2203.04153",
    "title": "Easy Ensemble: Simple Deep Ensemble Learning for Sensor-Based Human  Activity Recognition",
    "abstract": "Sensor-based human activity recognition (HAR) is a paramount technology in\nthe Internet of Things services. HAR using representation learning, which\nautomatically learns a feature representation from raw data, is the mainstream\nmethod because it is difficult to interpret relevant information from raw\nsensor data to design meaningful features. Ensemble learning is a robust\napproach to improve generalization performance; however, deep ensemble learning\nrequires various procedures, such as data partitioning and training multiple\nmodels, which are time-consuming and computationally expensive. In this study,\nwe propose Easy Ensemble (EE) for HAR, which enables the easy implementation of\ndeep ensemble learning in a single model. In addition, we propose input masking\nas a method for diversifying the input for EE. Experiments on a benchmark\ndataset for HAR demonstrated the effectiveness of EE and input masking and\ntheir characteristics compared with conventional ensemble learning methods.",
    "descriptor": "\nComments: 15 pages, 11 figures, this paper is a pre-print to submit to IEEE Internet of Things journal\n",
    "authors": [
      "Tatsuhito Hasegawa",
      "Kazuma Kondo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04153"
  },
  {
    "id": "arXiv:2203.04156",
    "title": "Robust Local Preserving and Global Aligning Network for Adversarial  Domain Adaptation",
    "abstract": "Unsupervised domain adaptation (UDA) requires source domain samples with\nclean ground truth labels during training. Accurately labeling a large number\nof source domain samples is time-consuming and laborious. An alternative is to\nutilize samples with noisy labels for training. However, training with noisy\nlabels can greatly reduce the performance of UDA. In this paper, we address the\nproblem that learning UDA models only with access to noisy labels and propose a\nnovel method called robust local preserving and global aligning network\n(RLPGA). RLPGA improves the robustness of the label noise from two aspects. One\nis learning a classifier by a robust informative-theoretic-based loss function.\nThe other is constructing two adjacency weight matrices and two negative weight\nmatrices by the proposed local preserving module to preserve the local topology\nstructures of input data. We conduct theoretical analysis on the robustness of\nthe proposed RLPGA and prove that the robust informative-theoretic-based loss\nand the local preserving module are beneficial to reduce the empirical risk of\nthe target domain. A series of empirical studies show the effectiveness of our\nproposed RLPGA.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Knowledge and Data Engineering (TKDE) 2022; Refer to this https URL\n",
    "authors": [
      "Wenwen Qiang",
      "Jiangmeng Li",
      "Changwen Zheng",
      "Bing Su",
      "Hui Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04156"
  },
  {
    "id": "arXiv:2203.04159",
    "title": "AI for Next Generation Computing: Emerging Trends and Future Directions",
    "abstract": "Autonomic computing investigates how systems can achieve (user) specified\ncontrol outcomes on their own, without the intervention of a human operator.\nAutonomic computing fundamentals have been substantially influenced by those of\ncontrol theory for closed and open-loop systems. In practice, complex systems\nmay exhibit a number of concurrent and inter-dependent control loops. Despite\nresearch into autonomic models for managing computer resources, ranging from\nindividual resources (e.g., web servers) to a resource ensemble (e.g., multiple\nresources within a data center), research into integrating Artificial\nIntelligence (AI) and Machine Learning (ML) to improve resource autonomy and\nperformance at scale continues to be a fundamental challenge. The integration\nof AI/ML to achieve such autonomic and self-management of systems can be\nachieved at different levels of granularity, from full to human-in-the-loop\nautomation. In this article, leading academics, researchers, practitioners,\nengineers, and scientists in the fields of cloud computing, AI/ML, and quantum\ncomputing join to discuss current research and potential future directions for\nthese fields. Further, we discuss challenges and opportunities for leveraging\nAI and ML in next generation computing for emerging computing paradigms,\nincluding cloud, fog, edge, serverless and quantum computing environments.",
    "descriptor": "\nComments: Accepted for Publication in Elsevier IoT Journal, 2022\n",
    "authors": [
      "Sukhpal Singh Gill",
      "Minxian Xu",
      "Carlo Ottaviani",
      "Panos Patros",
      "Rami Bahsoon",
      "Arash Shaghaghi",
      "Muhammed Golec",
      "Vlado Stankovski",
      "Huaming Wu",
      "Ajith Abraham",
      "Manmeet Singh",
      "Harshit Mehta",
      "Soumya K. Ghosh",
      "Thar Baker",
      "Ajith Kumar Parlikad",
      "Hanan Lutfiyya",
      "Salil S. Kanhere",
      "Rizos Sakellariou",
      "Schahram Dustdar",
      "Omer Rana",
      "Ivona Brandic",
      "Steve Uhlig"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.04159"
  },
  {
    "id": "arXiv:2203.04160",
    "title": "Robustly-reliable learners under poisoning attacks",
    "abstract": "Data poisoning attacks, in which an adversary corrupts a training set with\nthe goal of inducing specific desired mistakes, have raised substantial\nconcern: even just the possibility of such an attack can make a user no longer\ntrust the results of a learning system. In this work, we show how to achieve\nstrong robustness guarantees in the face of such attacks across multiple axes.\nWe provide robustly-reliable predictions, in which the predicted label is\nguaranteed to be correct so long as the adversary has not exceeded a given\ncorruption budget, even in the presence of instance targeted attacks, where the\nadversary knows the test example in advance and aims to cause a specific\nfailure on that example. Our guarantees are substantially stronger than those\nin prior approaches, which were only able to provide certificates that the\nprediction of the learning algorithm does not change, as opposed to certifying\nthat the prediction is correct, as we are able to achieve in our work.\nRemarkably, we provide a complete characterization of learnability in this\nsetting, in particular, nearly-tight matching upper and lower bounds on the\nregion that can be certified, as well as efficient algorithms for computing\nthis region given an ERM oracle. Moreover, for the case of linear separators\nover logconcave distributions, we provide efficient truly polynomial time\nalgorithms (i.e., non-oracle algorithms) for such robustly-reliable\npredictions.\nWe also extend these results to the active setting where the algorithm\nadaptively asks for labels of specific informative examples, and the difficulty\nis that the adversary might even be adaptive to this interaction, as well as to\nthe agnostic learning setting where there is no perfect classifier even over\nthe uncorrupted data.",
    "descriptor": "",
    "authors": [
      "Maria-Florina Balcan",
      "Avrim Blum",
      "Steve Hanneke",
      "Dravyansh Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.04160"
  },
  {
    "id": "arXiv:2203.04162",
    "title": "Feedforward PID Control of Full-Car with Parallel Active Link Suspension  for Improved Chassis Attitude Stabilization",
    "abstract": "PID control is commonly utilized in an active suspension system to achieve\ndesirable chassis attitude, where, due to delays, feedback information has much\ndifficulty regulating the roll and pitch behavior, and stabilizing the chassis\nattitude, which may result in roll over when the vehicle steers at a large\nlongitudinal velocity. To address the problem of the feedback delays in chassis\nattitude stabilization, in this paper, a feedforward control strategy is\nproposed to combine with a previously developed PID control scheme in the\nrecently introduced Parallel Active Link Suspension (PALS). Numerical\nsimulations with a nonlinear multi-body vehicle model are performed, where a\nset of ISO driving maneuvers are tested. Results demonstrate the\nfeedforward-based control scheme has improved suspension performance as\ncompared to the conventional PID control, with faster speed of convergence in\nbrake in a turn and step steer maneuvers, and surviving the fishhook maneuver\n(although displaying two-wheel lift-off) with 50 mph maneuver entrance speed at\nwhich conventional PID control rolls over.",
    "descriptor": "\nComments: 8 pages, 17 figures, CCTA conference\n",
    "authors": [
      "Zilin Feng",
      "Min Yu",
      "Simos A. Evangelou",
      "Imad M Jaimoukha",
      "Daniele Dini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.04162"
  },
  {
    "id": "arXiv:2203.04166",
    "title": "Curriculum-based Reinforcement Learning for Distribution System Critical  Load Restoration",
    "abstract": "This paper focuses on the critical load restoration problem in distribution\nsystems following major outages. To provide fast online response and optimal\nsequential decision-making support, a reinforcement learning (RL) based\napproach is proposed to optimize the restoration. Due to the complexities\nstemming from the large policy search space, renewable uncertainty, and\nnonlinearity in a complex grid control problem, directly applying RL algorithms\nto train a satisfactory policy requires extensive tuning to be successful. To\naddress this challenge, this paper leverages the curriculum learning (CL)\ntechnique to design a training curriculum involving a simpler steppingstone\nproblem that guides the RL agent to learn to solve the original hard problem in\na progressive and more efficient manner. We demonstrate that compared with\ndirect learning, CL facilitates controller training to achieve better\nperformance. In the experiments, to study realistic scenarios where renewable\nforecasts used for decision-making are in general imperfect, the trained RL\ncontrollers are compared with two model predictive controllers (MPCs) using\nrenewable forecasts with different error levels and observe how these\ncontrollers can hedge against the uncertainty. Results show that RL controllers\nare less susceptible to forecast errors than the baseline MPCs and can provide\na more reliable restoration process.",
    "descriptor": "",
    "authors": [
      "Xiangyu Zhang",
      "Abinet Tesfaye Eseye",
      "Bernard Knueven",
      "Weijia Liu",
      "Matthew Reynolds",
      "Wesley Jones"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.04166"
  },
  {
    "id": "arXiv:2203.04172",
    "title": "Distributed Control using Reinforcement Learning with  Temporal-Logic-Based Reward Shaping",
    "abstract": "We present a computational framework for synthesis of distributed control\nstrategies for a heterogeneous team of robots in a partially observable\nenvironment. The goal is to cooperatively satisfy specifications given as\nTruncated Linear Temporal Logic (TLTL) formulas. Our approach formulates the\nsynthesis problem as a stochastic game and employs a policy graph method to\nfind a control strategy with memory for each agent. We construct the stochastic\ngame on the product between the team transition system and a finite state\nautomaton (FSA) that tracks the satisfaction of the TLTL formula. We use the\nquantitative semantics of TLTL as the reward of the game, and further reshape\nit using the FSA to guide and accelerate the learning process. Simulation\nresults demonstrate the efficacy of the proposed solution under demanding task\nspecifications and the effectiveness of reward shaping in significantly\naccelerating the speed of learning.",
    "descriptor": "\nComments: 12 pages, 4 figures, accepted by L4DC 2022\n",
    "authors": [
      "Ningyuan Zhang",
      "Wenliang Liu",
      "Calin Belta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.04172"
  },
  {
    "id": "arXiv:2203.04177",
    "title": "Occupancy Map Prediction for Improved Indoor Robot Navigation",
    "abstract": "In the typical path planning pipeline for a ground robot, we build a map\n(e.g., an occupancy grid) of the environment as the robot moves around. While\nnavigating indoors, a ground robot's knowledge about the environment may be\nlimited by the occlusions in its surroundings. Therefore, the map will have\nmany as-yet-unknown regions that may need to be avoided by a conservative\nplanner. Instead, if a robot is able to correctly infer what its surroundings\nand occluded regions look like, the navigation can be further optimized. In\nthis work, we propose an approach using pix2pix and UNet to infer the occupancy\ngrid in unseen areas near the robot as an image-to-image translation task. Our\napproach simplifies the task of occupancy map prediction for the deep learning\nnetwork and reduces the amount of data required compared to similar existing\nmethods. We show that the predicted map improves the navigation time in\nsimulations over the existing approaches.",
    "descriptor": "",
    "authors": [
      "Vishnu Dutt Sharma",
      "Jingxi Chen",
      "Abhinav Shrivastava",
      "Pratap Tokekar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.04177"
  },
  {
    "id": "arXiv:2203.04179",
    "title": "Understanding person identification via gait",
    "abstract": "Gait recognition is the process of identifying humans from their bipedal\nlocomotion such as walking or running. As such gait data is privacy sensitive\ninformation and should be anonymized. With the rise of more and higher quality\ngait recording techniques, such as depth cameras or motion capture suits, an\nincreasing amount of high-quality gait data becomes available which requires\nanonymization. As a first step towards developing anonymization techniques for\nhigh-quality gait data, we study different aspects of movement data to quantify\ntheir contribution to the gait recognition process. We first extract categories\nof features from the literature on human gait perception and then design\ncomputational experiments for each of the categories which we run against a\ngait recognition system. Our results show that gait anonymization is a\nchallenging process as the data is highly redundant and interdependent.",
    "descriptor": "",
    "authors": [
      "Simon Hanisch",
      "Evelyn Muschter",
      "Adamantini Chatzipanagioti",
      "Shu-Chen Li",
      "Thorsten Strufe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04179"
  },
  {
    "id": "arXiv:2203.04180",
    "title": "Tuning-free multi-coil compressed sensing MRI with Parallel Variable  Density Approximate Message Passing (P-VDAMP)",
    "abstract": "Purpose: To develop a tuning-free method for multi-coil compressed sensing\nMRI that performs competitively with algorithms with an optimally tuned sparse\nparameter.\nTheory: The Parallel Variable Density Approximate Message Passing (P-VDAMP)\nalgorithm is proposed. For Bernoulli random variable density sampling, P-VDAMP\nobeys a \"state evolution\", where the intermediate per-iteration image estimate\nis distributed according to the ground truth corrupted by a Gaussian vector\nwith approximately known covariance. State evolution is leveraged to\nautomatically tune sparse parameters on-the-fly with Stein's Unbiased Risk\nEstimate (SURE).\nMethods: P-VDAMP is evaluated on brain, knee and angiogram datasets at\nacceleration factors 5 and 10 and compared with four variants of the Fast\nIterative Shrinkage-Thresholding algorithm (FISTA), including two tuning-free\nvariants from the literature.\nResults: The proposed method is found to have a similar reconstruction\nquality and time to convergence as FISTA with an optimally tuned sparse\nweighting.\nConclusions: P-VDAMP is an efficient, robust and principled method for\non-the-fly parameter tuning that is competitive with optimally tuned FISTA and\noffers substantial robustness and reconstruction quality improvements over\ncompeting tuning-free methods.",
    "descriptor": "\nComments: 24 pages, 10 figures. Submitted to Magnetic Resonance in Medicine on 8th March 2022\n",
    "authors": [
      "Charles Millard",
      "Mark Chiew",
      "Jared Tanner",
      "Aaron T. Hess",
      "Boris Mailhe"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.04180"
  },
  {
    "id": "arXiv:2203.04181",
    "title": "Selective-Supervised Contrastive Learning with Noisy Labels",
    "abstract": "Deep networks have strong capacities of embedding data into latent\nrepresentations and finishing following tasks. However, the capacities largely\ncome from high-quality annotated labels, which are expensive to collect. Noisy\nlabels are more affordable, but result in corrupted representations, leading to\npoor generalization performance. To learn robust representations and handle\nnoisy labels, we propose selective-supervised contrastive learning (Sel-CL) in\nthis paper. Specifically, Sel-CL extend supervised contrastive learning\n(Sup-CL), which is powerful in representation learning, but is degraded when\nthere are noisy labels. Sel-CL tackles the direct cause of the problem of\nSup-CL. That is, as Sup-CL works in a \\textit{pair-wise} manner, noisy pairs\nbuilt by noisy labels mislead representation learning. To alleviate the issue,\nwe select confident pairs out of noisy ones for Sup-CL without knowing noise\nrates. In the selection process, by measuring the agreement between learned\nrepresentations and given labels, we first identify confident examples that are\nexploited to build confident pairs. Then, the representation similarity\ndistribution in the built confident pairs is exploited to identify more\nconfident pairs out of noisy pairs. All obtained confident pairs are finally\nused for Sup-CL to enhance representations. Experiments on multiple noisy\ndatasets demonstrate the robustness of the learned representations by our\nmethod, following the state-of-the-art performance. Source codes are available\nat https://github.com/ShikunLi/Sel-CL",
    "descriptor": "\nComments: Accepted to CVPR 2022. 12 pages, 5 figure, and 10 tables\n",
    "authors": [
      "Shikun Li",
      "Xiaobo Xia",
      "Shiming Ge",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04181"
  },
  {
    "id": "arXiv:2203.04183",
    "title": "Enhancing Mechanical Metamodels with a Generative Model-Based Augmented  Training Dataset",
    "abstract": "Modeling biological soft tissue is complex in part due to material\nheterogeneity. Microstructural patterns, which play a major role in defining\nthe mechanical behavior of these tissues, are both challenging to characterize,\nand difficult to simulate. Recently, machine learning-based methods to predict\nthe mechanical behavior of heterogeneous materials have made it possible to\nmore thoroughly explore the massive input parameter space associated with\nheterogeneous blocks of material. Specifically, we can train machine learning\n(ML) models to closely approximate computationally expensive heterogeneous\nmaterial simulations where the ML model is trained on a dataset of simulations\nthat capture the range of spatial heterogeneity present in the material of\ninterest. However, when it comes to applying these techniques to biological\ntissue more broadly, there is a major limitation: the relevant microstructural\npatterns are both challenging to obtain and difficult to analyze. Consequently,\nthe number of useful examples available to characterize the input domain under\nstudy is limited. In this work, we investigate the efficacy of ML-based\ngenerative models as a tool for augmenting limited input pattern datasets. We\nfind that a Style-based Generative Adversarial Network with an adaptive\ndiscriminator augmentation mechanism is able to successfully leverage just\n1,000 example patterns to create meaningful generated patterns that can be used\nas inputs to finite element simulations to augment the training dataset. To\nenable this methodological contribution, we have created an open access dataset\nof Finite Element Analysis simulations based on Cahn-Hilliard patterns. We\nanticipate that future researchers will be able to leverage this dataset and\nbuild on the work presented here.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Hiba Kobeissi",
      "Saeed Mohammadzadeh",
      "Emma Lejeune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2203.04183"
  },
  {
    "id": "arXiv:2203.04187",
    "title": "MLSeg: Image and Video Segmentation as Multi-Label Classification and  Selected-Label Pixel Classification",
    "abstract": "For a long period of time, research studies on segmentation have typically\nformulated the task as pixel classification that predicts a class for each\npixel from a set of predefined, fixed number of semantic categories. Yet\nstandard architectures following this formulation will inevitably encounter\nvarious challenges under more realistic settings where the total number of\nsemantic categories scales up (e.g., beyond $1\\rm{k}$ classes). On the other\nhand, a standard image or video usually contains only a small number of\nsemantic categories from the entire label set. Motivated by this intuition, in\nthis paper, we propose to decompose segmentation into two sub-problems: (i)\nimage-level or video-level multi-label classification and (ii) pixel-level\nselected-label classification. Given an input image or video, our framework\nfirst conducts multi-label classification over the large complete label set and\nselects a small set of labels according to the class confidence scores. Then\nthe follow-up pixel-wise classification is only performed among the selected\nsubset of labels. Our approach is conceptually general and can be applied to\nvarious existing segmentation frameworks by simply adding a lightweight\nmulti-label classification branch. We demonstrate the effectiveness of our\nframework with competitive experimental results across four tasks including\nimage semantic segmentation, image panoptic segmentation, video instance\nsegmentation, and video semantic segmentation. Especially, with our MLSeg,\nMask$2$Former gains +$0.8\\%$/+$0.7\\%$/+$0.7\\%$ on ADE$20$K panoptic\nsegmentation/YouTubeVIS $2019$ video instance segmentation/VSPW video semantic\nsegmentation benchmarks respectively. Code will be available\nat:https://github.com/openseg-group/MLSeg",
    "descriptor": "",
    "authors": [
      "Haodi He",
      "Yuhui Yuan",
      "Xiangyu Yue",
      "Han Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04187"
  },
  {
    "id": "arXiv:2203.04192",
    "title": "Neural Contextual Bandits via Reward-Biased Maximum Likelihood  Estimation",
    "abstract": "Reward-biased maximum likelihood estimation (RBMLE) is a classic principle in\nthe adaptive control literature for tackling explore-exploit trade-offs. This\npaper studies the stochastic contextual bandit problem with general bounded\nreward functions and proposes NeuralRBMLE, which adapts the RBMLE principle by\nadding a bias term to the log-likelihood to enforce exploration. NeuralRBMLE\nleverages the representation power of neural networks and directly encodes\nexploratory behavior in the parameter space, without constructing confidence\nintervals of the estimated rewards. We propose two variants of NeuralRBMLE\nalgorithms: The first variant directly obtains the RBMLE estimator by gradient\nascent, and the second variant simplifies RBMLE to a simple index policy\nthrough an approximation. We show that both algorithms achieve\n$\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret. Through extensive experiments, we\ndemonstrate that the NeuralRBMLE algorithms achieve comparable or better\nempirical regrets than the state-of-the-art methods on real-world datasets with\nnon-linear reward functions.",
    "descriptor": "",
    "authors": [
      "Yu-Heng Hung",
      "Ping-Chun Hsieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.04192"
  },
  {
    "id": "arXiv:2203.04195",
    "title": "A Gating Model for Bias Calibration in Generalized Zero-shot Learning",
    "abstract": "Generalized zero-shot learning (GZSL) aims at training a model that can\ngeneralize to unseen class data by only using auxiliary information. One of the\nmain challenges in GZSL is a biased model prediction toward seen classes caused\nby overfitting on only available seen class data during training. To overcome\nthis issue, we propose a two-stream autoencoder-based gating model for GZSL.\nOur gating model predicts whether the query data is from seen classes or unseen\nclasses, and utilizes separate seen and unseen experts to predict the class\nindependently from each other. This framework avoids comparing the biased\nprediction scores for seen classes with the prediction scores for unseen\nclasses. In particular, we measure the distance between visual and attribute\nrepresentations in the latent space and the cross-reconstruction space of the\nautoencoder. These distances are utilized as complementary features to\ncharacterize unseen classes at different levels of data abstraction. Also, the\ntwo-stream autoencoder works as a unified framework for the gating model and\nthe unseen expert, which makes the proposed method computationally efficient.\nWe validate our proposed method in four benchmark image recognition datasets.\nIn comparison with other state-of-the-art methods, we achieve the best harmonic\nmean accuracy in SUN and AWA2, and the second best in CUB and AWA1.\nFurthermore, our base model requires at least 20% less number of model\nparameters than state-of-the-art methods relying on generative models.",
    "descriptor": "\nComments: IEEE Transactions on Image Processing, 2022. Code is available at this https URL\n",
    "authors": [
      "Gukyeong Kwon",
      "Ghassan AlRegib"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04195"
  },
  {
    "id": "arXiv:2203.04199",
    "title": "Trustable Co-label Learning from Multiple Noisy Annotators",
    "abstract": "Supervised deep learning depends on massive accurately annotated examples,\nwhich is usually impractical in many real-world scenarios. A typical\nalternative is learning from multiple noisy annotators. Numerous earlier works\nassume that all labels are noisy, while it is usually the case that a few\ntrusted samples with clean labels are available. This raises the following\nimportant question: how can we effectively use a small amount of trusted data\nto facilitate robust classifier learning from multiple annotators? This paper\nproposes a data-efficient approach, called \\emph{Trustable Co-label Learning}\n(TCL), to learn deep classifiers from multiple noisy annotators when a small\nset of trusted data is available. This approach follows the coupled-view\nlearning manner, which jointly learns the data classifier and the label\naggregator. It effectively uses trusted data as a guide to generate trustable\nsoft labels (termed co-labels). A co-label learning can then be performed by\nalternately reannotating the pseudo labels and refining the classifiers. In\naddition, we further improve TCL for a special complete data case, where each\ninstance is labeled by all annotators and the label aggregator is represented\nby multilayer neural networks to enhance model capacity. Extensive experiments\non synthetic and real datasets clearly demonstrate the effectiveness and\nrobustness of the proposed approach. Source code is available at\nhttps://github.com/ShikunLi/TCL",
    "descriptor": "\nComments: Accepted by IEEE TMM. 13 pages, 9 figures and 6 tables\n",
    "authors": [
      "Shikun Li",
      "Tongliang Liu",
      "Jiyong Tan",
      "Dan Zeng",
      "Shiming Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04199"
  },
  {
    "id": "arXiv:2203.04203",
    "title": "AssistQ: Affordance-centric Question-driven Task Completion for  Egocentric Assistant",
    "abstract": "A long-standing goal of intelligent assistants such as AR glasses/robots has\nbeen to assist users in affordance-centric real-world scenarios, such as \"how\ncan I run the microwave for 1 minute?\". However, there is still no clear task\ndefinition and suitable benchmarks. In this paper, we define a new task called\nAffordance-centric Question-driven Task Completion, where the AI assistant\nshould learn from instructional videos and scripts to guide the user\nstep-by-step. To support the task, we constructed AssistQ, a new dataset\ncomprising 529 question-answer samples derived from 100 newly filmed\nfirst-person videos. Each question should be completed with multi-step\nguidances by inferring from visual details (e.g., buttons' position) and\ntextural details (e.g., actions like press/turn). To address this unique task,\nwe developed a Question-to-Actions (Q2A) model that significantly outperforms\nseveral baseline methods while still having large room for improvement. We\nexpect our task and dataset to advance Egocentric AI Assistant's development.\nOur project page is available at: https://showlab.github.io/assistq",
    "descriptor": "",
    "authors": [
      "Benita Wong",
      "Joya Chen",
      "You Wu",
      "Stan Weixian Lei",
      "Dongxing Mao",
      "Difei Gao",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04203"
  },
  {
    "id": "arXiv:2203.04206",
    "title": "Lightweight Monocular Depth Estimation through Guided Decoding",
    "abstract": "We present a lightweight encoder-decoder archi- tecture for monocular depth\nestimation, specifically designed for embedded platforms. Our main contribution\nis the Guided Upsampling Block (GUB) for building the decoder of our model.\nMotivated by the concept of guided image filtering, GUB relies on the image to\nguide the decoder on upsampling the feature representation and the depth map\nreconstruction, achieving high resolution results with fine-grained details.\nBased on multiple GUBs, our model outperforms the related methods on the NYU\nDepth V2 dataset in terms of accuracy while delivering up to 35.1 fps on the\nNVIDIA Jetson Nano and up to 144.5 fps on the NVIDIA Xavier NX. Similarly, on\nthe KITTI dataset, inference is possible with up to 23.7 fps on the Jetson Nano\nand 102.9 fps on the Xavier NX. Our code and models are made publicly\navailable.",
    "descriptor": "\nComments: Accepted to ICRA 2022\n",
    "authors": [
      "Michael Rudolph",
      "Youssef Dawoud",
      "Ronja G\u00fcldenring",
      "Lazaros Nalpantidis",
      "Vasileios Belagiannis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.04206"
  },
  {
    "id": "arXiv:2203.04211",
    "title": "The CAT Effect: Exploring the Impact of Casual Affective Triggers on  Online Surveys' Response Rates",
    "abstract": "We explore the impact of Casual Affective Triggers (CAT) on response rates of\nonline surveys. As CAT, we refer to objects that can be included in survey\nparticipation invitations and trigger participants' affect. The hypothesis is\nthat participants who receive CAT-enriched invitations are more likely to\nrespond to a survey. We conducted a study where the control condition received\ninvitations without affective triggers, and the experimental condition received\nCAT-enriched invitations. We differentiated the triggers within the\nexperimental condition: one-third of the population received a personalized\ninvitation, one-third received a picture of the surveyor's cat, and one-third\nreceived both. We followed up with a survey to validate our findings. Our\nresults suggest that CATs have a positive impact on response rates. We did not\nfind CATs to induce response bias.",
    "descriptor": "\nComments: Accepted in Proceedings of the ACM CHI Conference on Human Factors in Computing Systems (CHI '22)\n",
    "authors": [
      "Irene-Angelica Chounta",
      "Alexander Nolte"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.04211"
  },
  {
    "id": "arXiv:2203.04212",
    "title": "Measuring the Mixing of Contextual Information in the Transformer",
    "abstract": "The Transformer architecture aggregates input information through the\nself-attention mechanism, but there is no clear understanding of how this\ninformation is mixed across the entire model. Additionally, recent works have\ndemonstrated that attention weights alone are not enough to describe the flow\nof information. In this paper, we consider the whole attention block\n--multi-head attention, residual connection, and layer normalization-- and\ndefine a metric to measure token-to-token interactions within each layer,\nconsidering the characteristics of the representation space. Then, we aggregate\nlayer-wise interpretations to provide input attribution scores for model\npredictions. Experimentally, we show that our method, ALTI (Aggregation of\nLayer-wise Token-to-token Interactions), provides faithful explanations and\noutperforms similar aggregation methods.",
    "descriptor": "",
    "authors": [
      "Javier Ferrando",
      "Gerard I. G\u00e1llego",
      "Marta R. Costa-juss\u00e0"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.04212"
  },
  {
    "id": "arXiv:2203.04214",
    "title": "BYOTee: Towards Building Your Own Trusted Execution Environments Using  FPGA",
    "abstract": "In recent years, we have witnessed unprecedented growth in using\nhardware-assisted Trusted Execution Environments (TEE) or enclaves to protect\nsensitive code and data on commodity devices thanks to new hardware security\nfeatures, such as Intel SGX and Arm TrustZone. Even though the proprietary TEEs\nbring many benefits, they have been criticized for lack of transparency,\nvulnerabilities, and various restrictions. For example, existing TEEs only\nprovide a static and fixed hardware Trusted Computing Base (TCB), which cannot\nbe customized for different applications. Existing TEEs time-share a processor\ncore with the Rich Execution Environment (REE), making execution less efficient\nand vulnerable to cache side-channel attacks. Moreover, TrustZone lacks\nhardware support for multiple TEEs, remote attestation, and memory encryption.\nIn this paper, we present BYOTee (Build Your Own Trusted Execution\nEnvironments), which is an easy-to-use infrastructure for building multiple\nequally secure enclaves by utilizing commodity Field Programmable Gate Arrays\n(FPGA) devices. BYOTee creates enclaves with customized hardware TCBs, which\ninclude softcore CPUs, block RAMs, and peripheral connections, in FPGA on\ndemand. Additionally, BYOTee provides mechanisms to attest the integrity of the\ncustomized enclaves' hardware and software stacks, including bitstream,\nfirmware, and the Security-Sensitive Applications (SSA) along with their inputs\nand outputs to remote verifiers. We implement a BYOTee system for the Xilinx\nSystem-on-Chip (SoC) FPGA. The evaluations on the low-end Zynq-7000 system for\nfour SSAs and 12 benchmark applications demonstrate the usage, security,\neffectiveness, and performance of the BYOTee framework.",
    "descriptor": "",
    "authors": [
      "Md Armanuzzaman",
      "Ziming Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.04214"
  },
  {
    "id": "arXiv:2203.04215",
    "title": "Multi-agent consensus over time-invariant and time-varying signed  digraphs via eventual positivity",
    "abstract": "Laplacian dynamics on signed digraphs have a richer behavior than those on\nnonnegative digraphs. In particular, for the so-called \"repelling\" signed\nLaplacians, the marginal stability property (needed to achieve consensus) is\nnot guaranteed a priori and, even when it holds, it does not automatically lead\nto consensus, as these signed Laplacians may loose rank even in strongly\nconnected digraphs. Furthermore, in the time-varying case, instability can\noccur even when switching in a family of systems each of which corresponds to a\nmarginally stable signed Laplacian with the correct corank. In this paper we\npresent conditions guaranteeing consensus of these signed Laplacians based on\nthe property of eventual positivity, a Perron-Frobenius type of property for\nsigned matrices. The conditions cover both time-invariant and time-varying\ncases. A particularly simple sufficient condition valid in both cases is that\nthe Laplacians are normal matrices. Such condition can be relaxed in several\nways. For instance in the time-invariant case it is enough that the Laplacian\nhas this Perron-Frobenius property on the right but not on the left side (i.e.,\non the transpose). For the time-varying case, convergence to consensus can be\nguaranteed by the existence of a common Lyapunov function for all the signed\nLaplacians. All conditions can be easily extended to bipartite consensus.",
    "descriptor": "\nComments: 16 pages, 1 figure\n",
    "authors": [
      "Angela Fontan",
      "Lingfei Wang",
      "Yiguang Hong",
      "Guodong Shi",
      "Claudio Altafini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.04215"
  },
  {
    "id": "arXiv:2203.04218",
    "title": "Learning Bidirectional Translation between Descriptions and Actions with  Small Paired Data",
    "abstract": "This study achieved bidirectional translation between descriptions and\nactions using small paired data. The ability to mutually generate descriptions\nand actions is essential for robots to collaborate with humans in their daily\nlives. The robot is required to associate real-world objects with linguistic\nexpressions, and large-scale paired data are required for machine learning\napproaches. However, a paired dataset is expensive to construct and difficult\nto collect. This study proposes a two-stage training method for bidirectional\ntranslation. In the proposed method, we train recurrent autoencoders (RAEs) for\ndescriptions and actions with a large amount of non-paired data. Then, we\nfine-tune the entire model to bind their intermediate representations using\nsmall paired data. Because the data used for pre-training do not require\npairing, behavior-only data or a large language corpus can be used. We\nexperimentally evaluated our method using a paired dataset consisting of\nmotion-captured actions and descriptions. The results showed that our method\nperformed well, even when the amount of paired data to train was small. The\nvisualization of the intermediate representations of each RAE showed that\nsimilar actions were encoded in a clustered position and the corresponding\nfeature vectors well aligned.",
    "descriptor": "\nComments: 8 pages, 7 figures. Submitted to RA-L (IEEE Robotics and Automation Letters) with IROS 2022 Option. An accompanying video is available at this https URL\n",
    "authors": [
      "Minori Toyoda",
      "Kanata Suzuki",
      "Yoshihiko Hayashi",
      "Tetsuya Ogata"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04218"
  },
  {
    "id": "arXiv:2203.04221",
    "title": "Towards Universal Texture Synthesis by Combining Texton Broadcasting  with Noise Injection in StyleGAN-2",
    "abstract": "We present a new approach for universal texture synthesis by incorporating a\nmulti-scale texton broadcasting module in the StyleGAN-2 framework. The texton\nbroadcasting module introduces an inductive bias, enabling generation of\nbroader range of textures, from those with regular structures to completely\nstochastic ones. To train and evaluate the proposed approach, we construct a\ncomprehensive high-resolution dataset that captures the diversity of natural\ntextures as well as stochastic variations within each perceptually uniform\ntexture. Experimental results demonstrate that the proposed approach yields\nsignificantly better quality textures than the state of the art. The ultimate\ngoal of this work is a comprehensive understanding of texture space.",
    "descriptor": "",
    "authors": [
      "Jue Lin",
      "Gaurav Sharma",
      "Thrasyvoulos N. Pappas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04221"
  },
  {
    "id": "arXiv:2203.04225",
    "title": "Olfaction-inspired MCs: Molecule Mixture Shift Keying and Cross-Reactive  Receptor Arrays",
    "abstract": "In this paper, we propose a novel concept for engineered molecular\ncommunication (MC) systems inspired by animal olfaction. We focus on a\nmulti-user scenario where several transmitters wish to communicate with a\ncentral receiver. We assume that each transmitter employs a unique mixture of\ndifferent types of signaling molecules to represent its message and the\nreceiver is equipped with an array comprising $R$ different types of receptors\nin order to detect the emitted molecule mixtures. The design of an MC system\nbased on \\textit{orthogonal} molecule-receptor pairs implies that the hardware\ncomplexity of the receiver linearly scales with the number of signaling\nmolecule types $Q$ (i.e., $R=Q$). Natural olfaction systems avoid such high\ncomplexity by employing arrays of \\textit{cross-reactive} receptors, where each\ntype of molecule activates multiple types of receptors and each type of\nreceptor is predominantly activated by multiple types of molecules albeit with\ndifferent activation strengths. For instance, the human olfactory system is\nbelieved to discriminate several thousands of chemicals using only a few\nhundred receptor types, i.e., $Q\\gg R$. Motivated by this observation, we first\ndevelop an end-to-end MC channel model that accounts for the key properties of\nolfaction. Subsequently, we present the proposed transmitter and receiver\ndesigns. In particular, given a set of signaling molecules, we develop\nalgorithms that allocate molecules to different transmitters and optimize the\nmixture alphabet for communication. Moreover, we formulate the molecule mixture\nrecovery as a convex compressive sensing problem which can be efficiently\nsolved via available numerical solvers.",
    "descriptor": "",
    "authors": [
      "Vahid Jamali",
      "Helene M. Loos",
      "Andrea Buettner",
      "Robert Schober",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.04225"
  },
  {
    "id": "arXiv:2203.04226",
    "title": "Extending Life of Lithium-ion Battery Packs by Taming Heterogeneities  via an Optimal Control-based Active Balancing Strategy",
    "abstract": "This paper develops a multi-objective fast charging-minimum degradation\noptimal control problem (OCP) for lithium-ion battery modules, made of\nseries-connected cells, subject to heterogeneity induced by manufacturing\ndefects and non uniform operating conditions, realized via an active balancing\ncircuitry. Each cell is expressed via a coupled nonlinear electrochemical,\nthermal, and aging model and the direct collocation approach is employed to\ntranscribe the OCP into a nonlinear programming problem (NLP). The proposed OCP\nis formulated under two different schemes of charging operation: (i)\nsame-charging-time (OCP-SCT) and (ii) different-charging-time (OCP-DCT). The\nformer assumes simultaneous charging of all cells irrespective of their initial\nconditions, whereas the latter allows for different charging times of the cells\nto account for heterogeneous initial conditions. Simulations on an illustrative\ncase study -- a battery module with two series-connected cells -- are carried\nout in the presence of intrinsic heterogeneity among the cells in terms of\nstate of charge and state of health. Results show that the OCP-DCT scheme\nprovides more flexibility to deal with heterogeneity, boasting of lower\ntemperature increase, charging current amplitudes, and degradation. Finally,\ncomparison with the common practice of constant current (CC) charging over a\nlong-term cycling operation shows that promising savings, in terms of retained\ncapacity, are attainable under the new control.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Vahid Azimi",
      "Anirudh Allam",
      "Simona Onori"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.04226"
  },
  {
    "id": "arXiv:2203.04227",
    "title": "Learning based Age of Information Minimization in UAV-relayed IoT  Networks",
    "abstract": "Unmanned Aerial Vehicles (UAVs) are used as aerial base-stations to relay\ntime-sensitive packets from IoT devices to the nearby terrestrial base-station\n(TBS). Scheduling of packets in such UAV-relayed IoT-networks to ensure fresh\n(or up-to-date) IoT devices' packets at the TBS is a challenging problem as it\ninvolves two simultaneous steps of (i) sampling of packets generated at IoT\ndevices by the UAVs [hop-1] and (ii) updating of sampled packets from UAVs to\nthe TBS [hop-2]. To address this, we propose Age-of-Information (AoI)\nscheduling algorithms for two-hop UAV-relayed IoT-networks. First, we propose a\nlow-complexity AoI scheduler, termed, MAF-MAD that employs Maximum AoI First\n(MAF) policy for sampling of IoT devices at UAV (hop-1) and Maximum AoI\nDifference (MAD) policy for updating sampled packets from UAV to the TBS\n(hop-2). We prove that MAF-MAD is the optimal AoI scheduler under ideal\nconditions (lossless wireless channels and generate-at-will traffic-generation\nat IoT devices). On the contrary, for general conditions (lossy channel\nconditions and varying periodic traffic-generation at IoT devices), a deep\nreinforcement learning algorithm, namely, Proximal Policy Optimization\n(PPO)-based scheduler is proposed. Simulation results show that the proposed\nPPO-based scheduler outperforms other schedulers like MAF-MAD, MAF, and\nround-robin in all considered general scenarios.",
    "descriptor": "",
    "authors": [
      "Biplav Choudhury",
      "Prasenjit Karmakar",
      "Vijay K. Shah",
      "Jeffrey H. Reed"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04227"
  },
  {
    "id": "arXiv:2203.04228",
    "title": "Twitter Engagement with Retracted Articles: Who, When, and How?",
    "abstract": "Retracted research discussed on social media can spread misinformation, yet\nwe lack an understanding of how retracted articles are mentioned by academic\nand non-academic users. This is especially relevant on Twitter due to the\nplatform's prominent role in science communication. Here, we analyze the pre\nand post retraction differences in Twitter engagement metrics and content of\nmentions for over 3,800 retracted English-language articles alongside\ncomparable non-retracted articles. We subset these findings according to the\nfive user types detected by our supervised learning classifier: members of the\npublic, scientists, bots, practitioners, and science communicators. We find\nthat retracted articles receive greater overall engagement than non-retracted\narticles, especially among members of the public and bot users, the majority of\nengagement happening prior to retraction. Our results highlight non-scientists'\ninvolvement in retracted article discussions and suggest an opportunity for\nTwitter to include a retraction notice feature.",
    "descriptor": "",
    "authors": [
      "Rod Abhari",
      "Nicholas Vincent",
      "Henry K. Dambanemuya",
      "Herminio Bodon",
      "Em\u0151ke-\u00c1gnes Horv\u00e1t"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.04228"
  },
  {
    "id": "arXiv:2203.04229",
    "title": "Neural Face Identification in a 2D Wireframe Projection of a Manifold  Object",
    "abstract": "In computer-aided design (CAD) systems, 2D line drawings are commonly used to\nillustrate 3D object designs. To reconstruct the 3D models depicted by a single\n2D line drawing, an important key is finding the edge loops in the line drawing\nwhich correspond to the actual faces of the 3D object. In this paper, we\napproach the classical problem of face identification from a novel data-driven\npoint of view. We cast it as a sequence generation problem: starting from an\narbitrary edge, we adopt a variant of the popular Transformer model to predict\nthe edges associated with the same face in a natural order. This allows us to\navoid searching the space of all possible edge loops with various hand-crafted\nrules and heuristics as most existing methods do, deal with challenging cases\nsuch as curved surfaces and nested edge loops, and leverage additional cues\nsuch as face types. We further discuss how possibly imperfect predictions can\nbe used for 3D object reconstruction.",
    "descriptor": "\nComments: To Appear in CVPR 2022. The project page is at this https URL\n",
    "authors": [
      "Kehan Wang",
      "Jia Zheng",
      "Zihan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04229"
  },
  {
    "id": "arXiv:2203.04232",
    "title": "A Lightweight and Detector-free 3D Single Object Tracker on Point Clouds",
    "abstract": "Recent works on 3D single object tracking treat the tracking as a\ntarget-specific 3D detection task, where an off-the-shelf 3D detector is\ncommonly employed for tracking. However, it is non-trivial to perform accurate\ntarget-specific detection since the point cloud of objects in raw LiDAR scans\nis usually sparse and incomplete. In this paper, we address this issue by\nexplicitly leveraging temporal motion cues and propose DMT, a Detector-free\nMotion prediction based 3D Tracking network that totally removes the usage of\ncomplicated 3D detectors, which is lighter, faster, and more accurate than\nprevious trackers. Specifically, the motion prediction module is firstly\nintroduced to estimate a potential target center of the current frame in a\npoint-cloud free way. Then, an explicit voting module is proposed to directly\nregress the 3D box from the estimated target center. Extensive experiments on\nKITTI and NuScenes datasets demonstrate that our DMT, without applying any\ncomplicated 3D detectors, can still achieve better performance (~10%\nimprovement on the NuScenes dataset) and faster tracking speed (i.e., 72 FPS)\nthan state-of-the-art approaches. Our codes will be released publicly.",
    "descriptor": "\nComments: 12 pages, 5 figures, 6 tables\n",
    "authors": [
      "Yan Xia",
      "Qiangqiang Wu",
      "Tianyu Yang",
      "Wei Li",
      "Antoni B. Chan",
      "Uwe Stilla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04232"
  },
  {
    "id": "arXiv:2203.04234",
    "title": "Adaptative Perturbation Patterns: Realistic Adversarial Learning for  Robust NIDS",
    "abstract": "Adversarial attacks pose a major threat to machine learning and to the\nsystems that rely on it. Nonetheless, adversarial examples cannot be freely\ngenerated for domains with tabular data, such as cybersecurity. This work\nestablishes the fundamental constraint levels required to achieve realism and\nintroduces the Adaptative Perturbation Pattern Method (A2PM) to fulfill these\nconstraints in a gray-box setting. A2PM relies on pattern sequences that are\nindependently adapted to the characteristics of each class to create valid and\ncoherent data perturbations. The developed method was evaluated in a\ncybersecurity case study with two scenarios: Enterprise and Internet of Things\n(IoT) networks. Multilayer Perceptron (MLP) and Random Forest (RF) classifiers\nwere created with regular and adversarial training, using the CIC-IDS2017 and\nIoT-23 datasets. In each scenario, targeted and untargeted attacks were\nperformed against the classifiers, and the generated examples were compared\nwith the original network traffic flows to assess their realism. The obtained\nresults demonstrate that A2PM provides a time efficient generation of realistic\nadversarial examples, which can be advantageous for both adversarial training\nand attacks.",
    "descriptor": "\nComments: 16 pages, 6 tables, 8 figures, Future Internet journal\n",
    "authors": [
      "Jo\u00e3o Vitorino",
      "Nuno Oliveira",
      "Isabel Pra\u00e7a"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.04234"
  },
  {
    "id": "arXiv:2203.04236",
    "title": "A Sharp Characterization of Linear Estimators for Offline Policy  Evaluation",
    "abstract": "Offline policy evaluation is a fundamental statistical problem in\nreinforcement learning that involves estimating the value function of some\ndecision-making policy given data collected by a potentially different policy.\nIn order to tackle problems with complex, high-dimensional observations, there\nhas been significant interest from theoreticians and practitioners alike in\nunderstanding the possibility of function approximation in reinforcement\nlearning. Despite significant study, a sharp characterization of when we might\nexpect offline policy evaluation to be tractable, even in the simplest setting\nof linear function approximation, has so far remained elusive, with a\nsurprising number of strong negative results recently appearing in the\nliterature.\nIn this work, we identify simple control-theoretic and linear-algebraic\nconditions that are necessary and sufficient for classical methods, in\nparticular Fitted Q-iteration (FQI) and least squares temporal difference\nlearning (LSTD), to succeed at offline policy evaluation. Using this\ncharacterization, we establish a precise hierarchy of regimes under which these\nestimators succeed. We prove that LSTD works under strictly weaker conditions\nthan FQI. Furthermore, we establish that if a problem is not solvable via LSTD,\nthen it cannot be solved by a broad class of linear estimators, even in the\nlimit of infinite data. Taken together, our results provide a complete picture\nof the behavior of linear estimators for offline policy evaluation (OPE), unify\npreviously disparate analyses of canonical algorithms, and provide\nsignificantly sharper notions of the underlying statistical complexity of OPE.",
    "descriptor": "",
    "authors": [
      "Juan C. Perdomo",
      "Akshay Krishnamurthy",
      "Peter Bartlett",
      "Sham Kakade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.04236"
  },
  {
    "id": "arXiv:2203.04243",
    "title": "Lower Bounds for the Reachability Problem in Fixed Dimensional VASSes",
    "abstract": "We study the complexity of the reachability problem for Vector Addition\nSystems with States (VASSes) in fixed dimensions. We provide four lower bounds\nimproving the currently known state-of-the-art: 1) \\np-hardness for unary flat\n$4$-VASSes (VASSes in dimension 4), 2) \\pspace-hardness for unary $5$-VASSes,\n3) \\expspace-hardness for binary $6$-VASSes and 4) \\tower-hardness for unary\n$8$-VASSes.",
    "descriptor": "",
    "authors": [
      "Wojciech Czerwi\u0144ski",
      "\u0141ukasz Orlikowski"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.04243"
  },
  {
    "id": "arXiv:2203.04248",
    "title": "Dual Lottery Ticket Hypothesis",
    "abstract": "Fully exploiting the learning capacity of neural networks requires\noverparameterized dense networks. On the other side, directly training sparse\nneural networks typically results in unsatisfactory performance. Lottery Ticket\nHypothesis (LTH) provides a novel view to investigate sparse network training\nand maintain its capacity. Concretely, it claims there exist winning tickets\nfrom a randomly initialized network found by iterative magnitude pruning and\npreserving promising trainability (or we say being in trainable condition). In\nthis work, we regard the winning ticket from LTH as the subnetwork which is in\ntrainable condition and its performance as our benchmark, then go from a\ncomplementary direction to articulate the Dual Lottery Ticket Hypothesis\n(DLTH): Randomly selected subnetworks from a randomly initialized dense network\ncan be transformed into a trainable condition and achieve admirable performance\ncompared with LTH -- random tickets in a given lottery pool can be transformed\ninto winning tickets. Specifically, by using uniform-randomly selected\nsubnetworks to represent the general cases, we propose a simple sparse network\ntraining strategy, Random Sparse Network Transformation (RST), to substantiate\nour DLTH. Concretely, we introduce a regularization term to borrow learning\ncapacity and realize information extrusion from the weights which will be\nmasked. After finishing the transformation for the randomly selected\nsubnetworks, we conduct the regular finetuning to evaluate the model using fair\ncomparisons with LTH and other strong baselines. Extensive experiments on\nseveral public datasets and comparisons with competitive approaches validate\nour DLTH as well as the effectiveness of the proposed model RST. Our work is\nexpected to pave a way for inspiring new research directions of sparse network\ntraining in the future. Our code is available at\nhttps://github.com/yueb17/DLTH.",
    "descriptor": "",
    "authors": [
      "Yue Bai",
      "Huan Wang",
      "Zhiqiang Tao",
      "Kunpeng Li",
      "Yun Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04248"
  },
  {
    "id": "arXiv:2203.04249",
    "title": "Second-life Lithium-ion batteries: A chemistry-agnostic and scalable  health estimation algorithm",
    "abstract": "Battery state of health is an essential metric for diagnosing battery\ndegradation during testing and operation. While many unique measurements are\npossible in the design phase, for practical applications often only\ntemperature, voltage and current sensing are accessible. This paper presents a\nnovel combination of machine learning techniques to produce accurate\npredictions significantly faster than standard Gaussian processes. The\ndata-driven approach uses feature generation with simple mathematics, feature\nfiltering, and bagging, which is validated with publicly available aging\ndatasets of more than 200 cells with slow and fast charging, across different\ncathode chemistries, and for various operating conditions. Based on multiple\ntraining-test partitions, average and median state of health prediction root\nmean square error (RMSE) is found to be less than 1.48% and 1.27%,\nrespectively, with a limited amount of input data, showing the capability of\nthe approach even when input data and time are limiting factors. The process\ndeveloped in this paper has direct applicability to today's incumbent open\nchallenge of assessing retired batteries on the basis of their residual health,\nand therefore nominal remaining useful life, to allow fast classification for\nsecond-life reutilization.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Aki Takahashi",
      "Anirudh Allam",
      "Simona Onori"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04249"
  },
  {
    "id": "arXiv:2203.04250",
    "title": "Edge Intersection Graphs of Paths on a Triangular Grid",
    "abstract": "We introduce a new class of intersection graphs, the edge intersection graphs\nof paths on a triangular grid, called EPGt graphs. We show similarities and\ndifferences from this new class to the well-known class of EPG graphs. A turn\nof a path at a grid point is called a bend. An EPGt representation in which\nevery path has at most $k$ bends is called a B$_k$-EPGt representation and the\ncorresponding graphs are called B$_k$-EPGt graphs. We provide examples of\nB$_{2}$-EPG graphs that are B$_{1}$-EPGt. We characterize the representation of\ncliques with three vertices and chordless 4-cycles in B$_{1}$-EPGt\nrepresentations. We also prove that B$_{1}$-EPGt graphs have Strong Helly\nnumber $3$. Furthermore, we prove that B$_{1}$-EPGt graphs are $7$-clique\ncolorable.",
    "descriptor": "\nComments: 19 pages, 12 figures\n",
    "authors": [
      "Vitor T. F. de Luca",
      "Mar\u00eda P\u00eda Mazzoleni",
      "Fabiano S. Oliveira",
      "Tanilson D. Santos",
      "Jayme L. Szwarcfiter"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.04250"
  },
  {
    "id": "arXiv:2203.04251",
    "title": "End-to-End Semi-Supervised Learning for Video Action Detection",
    "abstract": "In this work, we focus on semi-supervised learning for video action detection\nwhich utilizes both labeled as well as unlabeled data. We propose a simple\nend-to-end consistency based approach which effectively utilizes the unlabeled\ndata. Video action detection requires both, action class prediction as well as\na spatio-temporal localization of actions. Therefore, we investigate two types\nof constraints, classification consistency, and spatio-temporal consistency.\nThe presence of predominant background and static regions in a video makes it\nchallenging to utilize spatio-temporal consistency for action detection. To\naddress this, we propose two novel regularization constraints for\nspatio-temporal consistency; 1) temporal coherency, and 2) gradient smoothness.\nBoth these aspects exploit the temporal continuity of action in videos and are\nfound to be effective for utilizing unlabeled videos for action detection. We\ndemonstrate the effectiveness of the proposed approach on two different action\ndetection benchmark datasets, UCF101-24 and JHMDB-21. In addition, we also show\nthe effectiveness of the proposed approach for video object segmentation on the\nYoutube-VOS dataset which demonstrates its generalization capability to other\ntasks. The proposed approach achieves competitive performance by using merely\n20% of annotations on UCF101-24 when compared with recent fully supervised\nmethods. On UCF101-24, it improves the score by +8.9% and +11% at 0.5 f-mAP and\nv-mAP respectively, compared to supervised approach.",
    "descriptor": "\nComments: CVPR'22\n",
    "authors": [
      "Akash Kumar",
      "Yogesh Singh Rawat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04251"
  },
  {
    "id": "arXiv:2203.04253",
    "title": "Oriented Diameter of Planar Triangulations",
    "abstract": "The diameter of an undirected or a directed graph is defined to be the\nmaximum shortest path distance over all pairs of vertices in the graph. Given\nan undirected graph $G$, we examine the problem of assigning directions to each\nedge of $G$ such that the diameter of the resulting oriented graph is\nminimized. The minimum diameter over all strongly connected orientations is\ncalled the oriented diameter of $G$. The problem of determining the oriented\ndiameter of a graph is known to be NP-hard, but the time-complexity question is\nopen for planar graphs. In this paper we compute the exact value of the\noriented diameter for triangular grid graphs. We then prove an $n/3$ lower\nbound and an $n/2+O(\\sqrt{n})$ upper bound on the oriented diameter of planar\ntriangulations. It is known that given a planar graph $G$ with bounded\ntreewidth and a fixed positive integer $k$, one can determine in linear time\nwhether the oriented diameter of $G$ is at most $k$. In contrast, we consider a\nweighted version of the oriented diameter problem and show it to be is weakly\nNP-complete for planar graphs with bounded pathwidth.",
    "descriptor": "",
    "authors": [
      "Debajyoti Mondal",
      "N. Parthiban",
      "Indra Rajasingh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.04253"
  },
  {
    "id": "arXiv:2203.04258",
    "title": "RAPTEE: Leveraging trusted execution environments for Byzantine-tolerant  peer sampling services",
    "abstract": "Peer sampling is a first-class abstraction used in distributed systems for\noverlay management and information dissemination. The goal of peer sampling is\nto continuously build and refresh a partial and local view of the full\nmembership of a dynamic, large-scale distributed system. Malicious nodes under\nthe control of an adversary may aim at being over-represented in the views of\ncorrect nodes, increasing their impact on the proper operation of protocols\nbuilt over peer sampling. State-of-the-art Byzantine resilient peer sampling\nprotocols reduce this bias as long as Byzantines are not overly present. This\npaper studies the benefits brought to the resilience of peer sampling services\nwhen considering that a small portion of trusted nodes can run code whose\nauthenticity and integrity can be assessed within a trusted execution\nenvironment, and specifically Intel's software guard extensions technology\n(SGX). We present RAPTEE, a protocol that builds and leverages trusted\ngossip-based communications to hamper an adversary's ability to increase its\nsystem-wide representation in the views of all nodes. We apply RAPTEE to\nBRAHMS, the most resilient peer sampling protocol to date. Experiments with\n10,000 nodes show that with only 1% of SGX-capable devices, RAPTEE can reduce\nthe proportion of Byzantine IDs in the view of honest nodes by up to 17% when\nthe system contains 10% of Byzantine nodes. In addition, the security\nguarantees of RAPTEE hold even in the presence of a powerful attacker\nattempting to identify trusted nodes and injecting view-poisoned trusted nodes.",
    "descriptor": "",
    "authors": [
      "Matthieu Pigaglio",
      "Joachim Bruneau-Queyreix",
      "David Bromberg",
      "Davide Frey",
      "Etienne Rivi\u00e8re",
      "Laurent R\u00e9veill\u00e8re"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.04258"
  },
  {
    "id": "arXiv:2203.04264",
    "title": "A Survey on Privacy for B5G/6G: New Privacy Goals, Challenges, and  Research Directions",
    "abstract": "Massive progress of mobile wireless telecommunication networks was achieved\nin the previous decades, with privacy enhancement in each. At present, mobile\nusers are getting familiar with the latest 5G networks, and the discussion for\nthe next generation of Beyond 5G (B5G)/6G networks has already been initiated.\nIt is expected that B5G/6G will push the existing network capabilities to the\nnext level, with higher speeds, enhanced reliability, and seamless\nconnectivity. To make these expectations a reality, research is progressing on\nnew technologies, architectures, and intelligence-based decision-making\nprocesses related to B5G/6G. Privacy considerations are a crucial aspect that\nneeds further attention in such developments, as billions of people and devices\nwill be transmitting their data through the upcoming network. This paper\nprovides a comprehensive survey on privacy-related aspects for B5G/6G networks.\nFirst, it discusses a taxonomy of different privacy perspectives. Based on the\ntaxonomy, the paper then conceptualizes a set of privacy goals for the B5G/6G\nand the challenges that appear as barriers to reaching these goals. Next, this\nwork provides a set of solutions applicable to the proposed architecture of\nB5G/6G networks to mitigate the challenges. Additionally, this paper discusses\nthe emerging field of non-personal data privacy. It also provides an overview\nof standardization initiatives for privacy preservation. Finally, it concludes\nwith a roadmap of future directions and upcoming trends containing\nprivacy-related topics, which will be an arena for new research towards\nprivacy-enhanced B5G/6G networks. This work provides a basis for privacy\naspects that will significantly impact peoples' daily lives with future\nnetworks.",
    "descriptor": "\nComments: Survey paper, 49 Pages, 15 figures\n",
    "authors": [
      "Chamara Sandeepa",
      "Bartlomiej Siniarski",
      "Nicolas Kourtellis",
      "Shen Wang",
      "Madhusanka Liyanage"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.04264"
  },
  {
    "id": "arXiv:2203.04272",
    "title": "Policy-Based Bayesian Experimental Design for Non-Differentiable  Implicit Models",
    "abstract": "For applications in healthcare, physics, energy, robotics, and many other\nfields, designing maximally informative experiments is valuable, particularly\nwhen experiments are expensive, time-consuming, or pose safety hazards. While\nexisting approaches can sequentially design experiments based on prior\nobservation history, many of these methods do not extend to implicit models,\nwhere simulation is possible but computing the likelihood is intractable.\nFurthermore, they often require either significant online computation during\ndeployment or a differentiable simulation system. We introduce Reinforcement\nLearning for Deep Adaptive Design (RL-DAD), a method for simulation-based\noptimal experimental design for non-differentiable implicit models. RL-DAD\nextends prior work in policy-based Bayesian Optimal Experimental Design (BOED)\nby reformulating it as a Markov Decision Process with a reward function based\non likelihood-free information lower bounds, which is used to learn a policy\nvia deep reinforcement learning. The learned design policy maps prior histories\nto experiment designs offline and can be quickly deployed during online\nexecution. We evaluate RL-DAD and find that it performs competitively with\nbaselines on three benchmarks.",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Vincent Lim",
      "Ellen Novoseller",
      "Jeffrey Ichnowski",
      "Huang Huang",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.04272"
  },
  {
    "id": "arXiv:2203.04274",
    "title": "Leveraging Initial Hints for Free in Stochastic Linear Bandits",
    "abstract": "We study the setting of optimizing with bandit feedback with additional prior\nknowledge provided to the learner in the form of an initial hint of the optimal\naction. We present a novel algorithm for stochastic linear bandits that uses\nthis hint to improve its regret to $\\tilde O(\\sqrt{T})$ when the hint is\naccurate, while maintaining a minimax-optimal $\\tilde O(d\\sqrt{T})$ regret\nindependent of the quality of the hint. Furthermore, we provide a Pareto\nfrontier of tight tradeoffs between best-case and worst-case regret, with\nmatching lower bounds. Perhaps surprisingly, our work shows that leveraging a\nhint shows provable gains without sacrificing worst-case performance, implying\nthat our algorithm adapts to the quality of the hint for free. We also provide\nan extension of our algorithm to the case of $m$ initial hints, showing that we\ncan achieve a $\\tilde O(m^{2/3}\\sqrt{T})$ regret.",
    "descriptor": "\nComments: ALT 2022\n",
    "authors": [
      "Ashok Cutkosky",
      "Chris Dann",
      "Abhimanyu Das",
      "Qiuyi",
      "Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.04274"
  },
  {
    "id": "arXiv:2203.04275",
    "title": "Robust Multi-Task Learning and Online Refinement for Spacecraft Pose  Estimation across Domain Gap",
    "abstract": "This work presents Spacecraft Pose Network v2 (SPNv2), a Convolutional Neural\nNetwork (CNN) for pose estimation of noncooperative spacecraft across domain\ngap. SPNv2 is a multi-scale, multi-task CNN which consists of a shared\nmulti-scale feature encoder and multiple prediction heads that perform\ndifferent tasks on a shared feature output. These tasks are all related to\ndetection and pose estimation of a target spacecraft from an image, such as\nprediction of pre-defined satellite keypoints, direct pose regression, and\nbinary segmentation of the satellite foreground. It is shown that by jointly\ntraining on different yet related tasks with extensive data augmentations on\nsynthetic images only, the shared encoder learns features that are common\nacross image domains that have fundamentally different visual characteristics\ncompared to synthetic images. This work also introduces Online Domain\nRefinement (ODR) which refines the parameters of the normalization layers of\nSPNv2 on the target domain images online at deployment. Specifically, ODR\nperforms self-supervised entropy minimization of the predicted satellite\nforeground, thereby improving the CNN's performance on the target domain images\nwithout their pose labels and with minimal computational efforts. The GitHub\nrepository for SPNv2 will be made available in the near future.",
    "descriptor": "",
    "authors": [
      "Tae Ha Park",
      "Simone D'Amico"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04275"
  },
  {
    "id": "arXiv:2203.04277",
    "title": "You Cannot Always Win the Race: Analyzing the LFENCE/JMP Mitigation for  Branch Target Injection",
    "abstract": "LFENCE/JMP is an existing software mitigation option for Branch Target\nInjection (BTI) and similar transient execution attacks stemming from indirect\nbranch predictions, which is commonly used on AMD processors. However, the\neffectiveness of this mitigation can be compromised by the inherent race\ncondition between the speculative execution of the predicted target and the\narchitectural resolution of the intended target, since this can create a window\nin which code can still be transiently executed.\nThis work investigates the potential sources of latency that may contribute\nto such a speculation window. We show that an attacker can \"win the race\", and\nthus that this window can still be sufficient to allow exploitation of\nBTI-style attacks on a variety of different x86 CPUs, despite the presence of\nthe LFENCE/JMP mitigation.",
    "descriptor": "\nComments: 11 pages, 1 figure\n",
    "authors": [
      "Alyssa Milburn",
      "Ke Sun",
      "Henrique Kawakami"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.04277"
  },
  {
    "id": "arXiv:2203.04279",
    "title": "Probabilistic Warp Consistency for Weakly-Supervised Semantic  Correspondences",
    "abstract": "We propose Probabilistic Warp Consistency, a weakly-supervised learning\nobjective for semantic matching. Our approach directly supervises the dense\nmatching scores predicted by the network, encoded as a conditional probability\ndistribution. We first construct an image triplet by applying a known warp to\none of the images in a pair depicting different instances of the same object\nclass. Our probabilistic learning objectives are then derived using the\nconstraints arising from the resulting image triplet. We further account for\nocclusion and background clutter present in real image pairs by extending our\nprobabilistic output space with a learnable unmatched state. To supervise it,\nwe design an objective between image pairs depicting different object classes.\nWe validate our method by applying it to four recent semantic matching\narchitectures. Our weakly-supervised approach sets a new state-of-the-art on\nfour challenging semantic matching benchmarks. Lastly, we demonstrate that our\nobjective also brings substantial improvements in the strongly-supervised\nregime, when combined with keypoint annotations.",
    "descriptor": "\nComments: Accepted at CVPR 2022 code: this https URL\n",
    "authors": [
      "Prune Truong",
      "Martin Danelljan",
      "Fisher Yu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04279"
  },
  {
    "id": "arXiv:2203.04282",
    "title": "From the Lab to People's Home: Lessons from Accessing Blind  Participants' Interactions via Smart Glasses in Remote Studies",
    "abstract": "Researchers have adopted remote methods, such as online surveys and video\nconferencing, to overcome challenges in conducting in-person usability testing,\nsuch as participation, user representation, and safety. However, remote user\nevaluation on hardware testbeds is limited, especially for blind participants,\nas such methods restrict access to observations of user interactions. We employ\nsmart glasses in usability testing with blind people and share our lessons from\na case study conducted in blind participants' homes (N=12), where the\nexperimenter can access participants' activities via dual video conferencing: a\nthird-person view via a laptop camera and a first-person view via smart glasses\nworn by the participant. We show that smart glasses hold potential for\nobserving participants' interactions with smartphone testbeds remotely; on\naverage 58.7% of the interactions were fully captured via the first-person view\ncompared to 3.7% via the third-person. However, this gain is not uniform across\nparticipants as it is susceptible to head movements orienting the ear towards a\nsound source, which highlights the need for a more inclusive camera form\nfactor. We also share our lessons learned when it comes to dealing with lack of\nscreen reader support in smart glasses, a rapidly draining battery, and\nInternet connectivity in remote studies with blind participants.",
    "descriptor": "\nComments: to be published in the proceedings of the 19th International Web for All Conference (Web4All 2022)\n",
    "authors": [
      "Kyungjun Lee",
      "Jonggi Hong",
      "Ebrima Jarjue",
      "Ernest Essuah Mensah",
      "Hernisa Kacorri"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.04282"
  },
  {
    "id": "arXiv:2203.04286",
    "title": "Proximal PanNet: A Model-Based Deep Network for Pansharpening",
    "abstract": "Recently, deep learning techniques have been extensively studied for\npansharpening, which aims to generate a high resolution multispectral (HRMS)\nimage by fusing a low resolution multispectral (LRMS) image with a high\nresolution panchromatic (PAN) image. However, existing deep learning-based\npansharpening methods directly learn the mapping from LRMS and PAN to HRMS.\nThese network architectures always lack sufficient interpretability, which\nlimits further performance improvements. To alleviate this issue, we propose a\nnovel deep network for pansharpening by combining the model-based methodology\nwith the deep learning method. Firstly, we build an observation model for\npansharpening using the convolutional sparse coding (CSC) technique and design\na proximal gradient algorithm to solve this model. Secondly, we unfold the\niterative algorithm into a deep network, dubbed as Proximal PanNet, by learning\nthe proximal operators using convolutional neural networks. Finally, all the\nlearnable modules can be automatically learned in an end-to-end manner.\nExperimental results on some benchmark datasets show that our network performs\nbetter than other advanced methods both quantitatively and qualitatively.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Xiangyong Cao",
      "Yang Chen",
      "Wenfei Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04286"
  },
  {
    "id": "arXiv:2203.04287",
    "title": "A Simple Multi-Modality Transfer Learning Baseline for Sign Language  Translation",
    "abstract": "This paper proposes a simple transfer learning baseline for sign language\ntranslation. Existing sign language datasets (e.g. PHOENIX-2014T, CSL-Daily)\ncontain only about 10K-20K pairs of sign videos, gloss annotations and texts,\nwhich are an order of magnitude smaller than typical parallel data for training\nspoken language translation models. Data is thus a bottleneck for training\neffective sign language translation models. To mitigate this problem, we\npropose to progressively pretrain the model from general-domain datasets that\ninclude a large amount of external supervision to within-domain datasets.\nConcretely, we pretrain the sign-to-gloss visual network on the general domain\nof human actions and the within-domain of a sign-to-gloss dataset, and pretrain\nthe gloss-to-text translation network on the general domain of a multilingual\ncorpus and the within-domain of a gloss-to-text corpus. The joint model is\nfine-tuned with an additional module named the visual-language mapper that\nconnects the two networks. This simple baseline surpasses the previous\nstate-of-the-art results on two sign language translation benchmarks,\ndemonstrating the effectiveness of transfer learning. With its simplicity and\nstrong performance, this approach can serve as a solid baseline for future\nresearch.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Yutong Chen",
      "Fangyun Wei",
      "Xiao Sun",
      "Zhirong Wu",
      "Stephen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04287"
  },
  {
    "id": "arXiv:2203.02090",
    "title": "Bayesian community detection for networks with covariates",
    "abstract": "The increasing prevalence of network data in a vast variety of fields and the\nneed to extract useful information out of them have spurred fast developments\nin related models and algorithms. Among the various learning tasks with network\ndata, community detection, the discovery of node clusters or \"communities,\" has\narguably received the most attention in the scientific community. In many\nreal-world applications, the network data often come with additional\ninformation in the form of node or edge covariates that should ideally be\nleveraged for inference. In this paper, we add to a limited literature on\ncommunity detection for networks with covariates by proposing a Bayesian\nstochastic block model with a covariate-dependent random partition prior. Under\nour prior, the covariates are explicitly expressed in specifying the prior\ndistribution on the cluster membership. Our model has the flexibility of\nmodeling uncertainties of all the parameter estimates including the community\nmembership. Importantly, and unlike the majority of existing methods, our model\nhas the ability to learn the number of the communities via posterior inference\nwithout having to assume it to be known. Our model can be applied to community\ndetection in both dense and sparse networks, with both categorical and\ncontinuous covariates, and our MCMC algorithm is very efficient with good\nmixing properties. We demonstrate the superior performance of our model over\nexisting models in a comprehensive simulation study and an application to two\nreal datasets.",
    "descriptor": "",
    "authors": [
      "Luyi Shen",
      "Arash Amini",
      "Nathaniel Josephs",
      "Lizhen Lin"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.02090"
  },
  {
    "id": "arXiv:2203.03618",
    "title": "Mammograms Classification: A Review",
    "abstract": "An advanced reliable low-cost form of screening method, Digital mammography\nhas been used as an effective imaging method for breast cancer detection. With\nan increased focus on technologies to aid healthcare, Mammogram images have\nbeen utilized in developing computer-aided diagnosis systems that will\npotentially help in clinical diagnosis. Researchers have proved that artificial\nintelligence with its emerging technologies can be used in the early detection\nof the disease and improve radiologists' performance in assessing breast\ncancer. In this paper, we review the methods developed for mammogram mass\nclassification in two categories. The first one is classifying manually\nprovided cropped region of interests (ROI) as either malignant or benign, and\nthe second one is the classification of automatically segmented ROIs as either\nmalignant or benign. We also provide an overview of datasets and evaluation\nmetrics used in the classification task. Finally, we compare and discuss the\ndeep learning approach to classical image processing and learning approach in\nthis domain.",
    "descriptor": "",
    "authors": [
      "Marawan Elbatel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03618"
  },
  {
    "id": "arXiv:2203.03619",
    "title": "Adaptive Cross-Layer Attention for Image Restoration",
    "abstract": "Non-local attention module has been proven to be crucial for image\nrestoration. Conventional non-local attention processes features of each layer\nseparately, so it risks missing correlation between features among different\nlayers. To address this problem, we propose Cross-Layer Attention (CLA) module\nin this paper. Instead of finding correlated key pixels within the same layer,\neach query pixel can attend to key pixels at previous layers of the network. In\norder to further enhance the learning capability and reduce the inference cost\nof CLA, we further propose Adaptive CLA, or ACLA, as an improved CLA. Two\nadaptive designs are proposed for ACLA: 1) adaptively selecting the keys for\nnon-local attention at each layer; 2) automatically searching for the insertion\nlocations for ACLA modules. By these two adaptive designs, ACLA dynamically\nselects the number of keys to be aggregated for non-local attention at layer.\nIn addition, ACLA searches for the optimal insert positions of ACLA modules by\na neural architecture search method to render a compact neural network with\ncompelling performance. Extensive experiments on image restoration tasks,\nincluding single image super-resolution, image denoising, image demosaicing,\nand image compression artifacts reduction, validate the effectiveness and\nefficiency of ACLA.",
    "descriptor": "",
    "authors": [
      "Yancheng Wang",
      "Ning Xu",
      "Chong Chen",
      "Yingzhen Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03619"
  },
  {
    "id": "arXiv:2203.03621",
    "title": "Triple Motion Estimation and Frame Interpolation based on Adaptive  Threshold for Frame Rate Up-Conversion",
    "abstract": "In this paper, we propose a novel motion-compensated frame rate up-conversion\n(MC-FRUC) algorithm. The proposed algorithm creates interpolated frames by\nfirst estimating motion vectors using unilateral (jointing forward and\nbackward) and bilateral motion estimation. Then motion vectors are combined\nbased on adaptive threshold, in order to creates high-quality interpolated\nframes and reduce block artifacts. Since motion-compensated frame interpolation\nalong unilateral motion trajectories yields holes, a new algorithm is\nintroduced to resolve this problem. The experimental results show that the\nquality of the interpolated frames using the proposed algorithm is much higher\nthan the existing algorithms.",
    "descriptor": "\nComments: Frame rate up-conversion, frame interpolation, motion estimation, motion compensation\n",
    "authors": [
      "Hanieh Naderi",
      "Mohammad Rahmati"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.03621"
  },
  {
    "id": "arXiv:2203.03622",
    "title": "Deep-ASPECTS: A Segmentation-Assisted Model for Stroke Severity  Measurement",
    "abstract": "A stroke occurs when an artery in the brain ruptures and bleeds or when the\nblood supply to the brain is cut off. Blood and oxygen cannot reach the brain's\ntissues due to the rupture or obstruction resulting in tissue death. The Middle\ncerebral artery (MCA) is the largest cerebral artery and the most commonly\ndamaged vessel in stroke. The quick onset of a focused neurological deficit\ncaused by interruption of blood flow in the territory supplied by the MCA is\nknown as an MCA stroke. Alberta stroke programme early CT score (ASPECTS) is\nused to estimate the extent of early ischemic changes in patients with MCA\nstroke. This study proposes a deep learning-based method to score the CT scan\nfor ASPECTS. Our work has three highlights. First, we propose a novel method\nfor medical image segmentation for stroke detection. Second, we show the\neffectiveness of AI solution for fully-automated ASPECT scoring with reduced\ndiagnosis time for a given non-contrast CT (NCCT) Scan. Our algorithms show a\ndice similarity coefficient of 0.64 for the MCA anatomy segmentation and 0.72\nfor the infarcts segmentation. Lastly, we show that our model's performance is\ninline with inter-reader variability between radiologists.",
    "descriptor": "",
    "authors": [
      "Ujjwal Upadhyay",
      "Mukul Ranjan",
      "Satish Golla",
      "Swetha Tanamala",
      "Preetham Sreenivas",
      "Sasank Chilamkurthy",
      "Jeyaraj Pandian",
      "Jason Tarpley"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.03622"
  },
  {
    "id": "arXiv:2203.03623",
    "title": "Measurement-conditioned Denoising Diffusion Probabilistic Model for  Under-sampled Medical Image Reconstruction",
    "abstract": "We propose a novel and unified method, measurement-conditioned denoising\ndiffusion probabilistic model (MC-DDPM), for under-sampled medical image\nreconstruction based on DDPM. Different from previous works, MC-DDPM is defined\nin measurement domain (e.g. k-space in MRI reconstruction) and conditioned on\nunder-sampling mask. We apply this method to accelerate MRI reconstruction and\nthe experimental results show excellent performance, outperforming full\nsupervision baseline and the state-of-the-art score-based reconstruction\nmethod. Due to its generative nature, MC-DDPM can also quantify the uncertainty\nof reconstruction. Our code is available on github.",
    "descriptor": "",
    "authors": [
      "Yutong Xie",
      "Quanzheng Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03623"
  },
  {
    "id": "arXiv:2203.03624",
    "title": "Fusion-Correction Network for Single-Exposure Correction and  Multi-Exposure Fusion",
    "abstract": "The photographs captured by digital cameras usually suffer from over-exposure\nor under-exposure problems. The Single-Exposure Correction (SEC) and\nMulti-Exposure Fusion (MEF) are two widely studied image processing tasks for\nimage exposure enhancement. However, current SEC and MEF methods ignore the\ninternal correlation between SEC and MEF, and are proposed under distinct\nframeworks. What's more, most MEF methods usually fail at processing a sequence\ncontaining only under-exposed or over-exposed images. To alleviate these\nproblems, in this paper, we develop an integrated framework to simultaneously\ntackle the SEC and MEF tasks. Built upon the Laplacian Pyramid (LP)\ndecomposition, we propose a novel Fusion-Correction Network (FCNet) to fuse and\ncorrect an image sequence sequentially in a multi-level scheme. In each LP\nlevel, the image sequence is feed into a Fusion block and a Correction block\nfor consecutive image fusion and exposure correction. The corrected image is\nupsampled and re-composed with the high-frequency detail components in\nnext-level, producing the base sequence for the next-level blocks. Experiments\non the benchmark dataset demonstrate that our FCNet is effective on both the\nSEC and MEF tasks.",
    "descriptor": "",
    "authors": [
      "Jin Liang",
      "Anran Zhang",
      "Jun Xu",
      "Hui Li",
      "Xiantong Zhen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03624"
  },
  {
    "id": "arXiv:2203.03626",
    "title": "Coordinate Translator for Learning Deformable Medical Image Registration",
    "abstract": "The majority of deep learning (DL) based deformable image registration\nmethods use convolutional neural networks (CNNs) to estimate displacement\nfields from pairs of moving and fixed images. This, however, requires the\nconvolutional kernels in the CNN to not only extract intensity features from\nthe inputs but also understand image coordinate systems. We argue that the\nlatter task is challenging for traditional CNNs, limiting their performance in\nregistration tasks. To tackle this problem, we first introduce Coordinate\nTranslator (CoTr), a differentiable module that identifies matched features\nbetween the fixed and moving image and outputs their coordinate correspondences\nwithout the need for training. It unloads the burden of understanding image\ncoordinate systems for CNNs, allowing them to focus on feature extraction. We\nthen propose a novel deformable registration network, im2grid, that uses\nmultiple CoTr's with the hierarchical features extracted from a CNN encoder and\noutputs a deformation field in a coarse-to-fine fashion. We compared im2grid\nwith the state-of-the-art DL and non-DL methods for unsupervised 3D magnetic\nresonance image registration. Our experiments show that im2grid outperforms\nthese methods both qualitatively and quantitatively.",
    "descriptor": "",
    "authors": [
      "Yihao Liu",
      "Lianrui Zuo",
      "Shuo Han",
      "Jerry L. Prince",
      "Aaron Carass"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03626"
  },
  {
    "id": "arXiv:2203.03627",
    "title": "Multi-channel deep convolutional neural networks for multi-classifying  thyroid disease",
    "abstract": "Thyroid disease instances have been continuously increasing since the 1990s,\nand thyroid cancer has become the most rapidly rising disease among all the\nmalignancies in recent years. Most existing studies focused on applying deep\nconvolutional neural networks for detecting thyroid cancer. Despite their\nsatisfactory performance on binary classification tasks, limited studies have\nexplored multi-class classification of thyroid disease types; much less is\nknown of the diagnosis of co-existence situation for different types of thyroid\ndiseases. Therefore, this study proposed a novel multi-channel convolutional\nneural network (CNN) architecture to address the multi-class classification\ntask of thyroid disease. The multi-channel CNN merits from computed tomography\nto drive a comprehensive diagnostic decision for the overall thyroid gland,\nemphasizing the disease co-existence circumstance. Moreover, this study also\nexamined alternative strategies to enhance the diagnostic accuracy of CNN\nmodels through concatenation of different scales of feature maps. Benchmarking\nexperiments demonstrate the improved performance of the proposed multi-channel\nCNN architecture compared with the standard single-channel CNN architecture.\nMore specifically, the multi-channel CNN achieved an accuracy of 0.909,\nprecision of 0.944, recall of 0.896, specificity of 0.994, and F1 of 0.917, in\ncontrast to the single-channel CNN, which obtained 0.902, 0.892, 0.909, 0.993,\n0.898, respectively. In addition, the proposed model was evaluated in different\ngender groups; it reached a diagnostic accuracy of 0.908 for the female group\nand 0.901 for the male group. Collectively, the results highlight that the\nproposed multi-channel CNN has excellent generalization and has the potential\nto be deployed to provide computational decision support in clinical settings.",
    "descriptor": "",
    "authors": [
      "Xinyu Zhang",
      "Vincent CS. Lee",
      "Jia Rong",
      "James C. Lee",
      "Jiangning Song",
      "Feng Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03627"
  },
  {
    "id": "arXiv:2203.03631",
    "title": "Student Become Decathlon Master in Retinal Vessel Segmentation via  Dual-teacher Multi-target Domain Adaptation",
    "abstract": "Unsupervised domain adaptation has been proposed recently to tackle the\nso-called domain shift between training data and test data with different\ndistributions. However, most of them only focus on single-target domain\nadaptation and cannot be applied to the scenario with multiple target domains.\nIn this paper, we propose RVms, a novel unsupervised multi-target domain\nadaptation approach to segment retinal vessels (RVs) from multimodal and\nmulticenter retinal images. RVms mainly consists of a style augmentation and\ntransfer (SAT) module and a dual-teacher knowledge distillation (DTKD) module.\nSAT augments and clusters images into source-similar domains and\nsource-dissimilar domains via B\\'ezier and Fourier transformations. DTKD\nutilizes the augmented and transformed data to train two teachers, one for\nsource-similar domains and the other for source-dissimilar domains. Afterwards,\nknowledge distillation is performed to iteratively distill different domain\nknowledge from teachers to a generic student. The local relative intensity\ntransformation is employed to characterize RVs in a domain invariant manner and\npromote the generalizability of teachers and student models. Moreover, we\nconstruct a new multimodal and multicenter vascular segmentation dataset from\nexisting publicly-available datasets, which can be used to benchmark various\ndomain adaptation and domain generalization methods. Through extensive\nexperiments, RVms is found to be very close to the target-trained Oracle in\nterms of segmenting the RVs, largely outperforming other state-of-the-art\nmethods.",
    "descriptor": "\nComments: Submitted in MICCAI 2022\n",
    "authors": [
      "Linkai Peng",
      "Li Lin",
      "Pujin Cheng",
      "Huaqing He",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03631"
  },
  {
    "id": "arXiv:2203.03634",
    "title": "InsightNet: non-contact blood pressure measuring network based on face  video",
    "abstract": "Blood pressure indicates cardiac function and peripheral vascular resistance\nand is critical for disease diagnosis. Traditionally, blood pressure data are\nmainly acquired through contact sensors, which require high maintenance and may\nbe inconvenient and unfriendly to some people (e.g., burn patients). In this\npaper, an efficient non-contact blood pressure measurement network based on\nface videos is proposed for the first time. An innovative oversampling training\nstrategy is proposed to handle the unbalanced data distribution. The input\nvideo sequences are first normalized and converted to our proposed YUVT color\nspace. Then, the Spatio-temporal slicer encodes it into a multi-domain\nSpatio-temporal mapping. Finally, the neural network computation module, used\nfor high-dimensional feature extraction of the multi-domain spatial feature\nmapping, after which the extracted high-dimensional features are used to\nenhance the time-domain feature association using LSTM, is computed by the\nblood pressure classifier to obtain the blood pressure measurement intervals.\nCombining the output of feature extraction and the result after classification,\nthe blood pressure calculator, calculates the blood pressure measurement\nvalues. The solution uses a blood pressure classifier to calculate blood\npressure intervals, which can help the neural network distinguish between the\nhigh-dimensional features of different blood pressure intervals and alleviate\nthe overfitting phenomenon. It can also locate the blood pressure intervals,\ncorrect the final blood pressure values and improve the network performance.\nExperimental results on two datasets show that the network outperforms existing\nstate-of-the-art methods.",
    "descriptor": "\nComments: 23 pages, 7 figures\n",
    "authors": [
      "Jialiang Zhuang",
      "Bin Li",
      "Yun Zhang",
      "Xiujuan Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.03634"
  },
  {
    "id": "arXiv:2203.03635",
    "title": "Stepwise Feature Fusion: Local Guides Global",
    "abstract": "Colonoscopy, currently the most efficient and recognized colon polyp\ndetection technology, is necessary for early screening and prevention of\ncolorectal cancer. However, due to the varying size and complex morphological\nfeatures of colonic polyps as well as the indistinct boundary between polyps\nand mucosa, accurate segmentation of polyps is still challenging. Deep learning\nhas become popular for accurate polyp segmentation tasks with excellent\nresults. However, due to the structure of polyps image and the varying shapes\nof polyps, it easy for existing deep learning models to overfitting the current\ndataset. As a result, the model may not process unseen colonoscopy data. To\naddress this, we propose a new State-Of-The-Art model for medical image\nsegmentation, the SSFormer, which uses a pyramid Transformer encoder to improve\nthe generalization ability of models. Specifically, our proposed Progressive\nLocality Decoder can be adapted to the pyramid Transformer backbone to\nemphasize local features and restrict attention dispersion. The SSFormer\nachieves statet-of-the-art performance in both learning and generalization\nassessment.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Jinfeng Wang",
      "Qiming Huang",
      "Feilong Tang",
      "Jia Meng",
      "Jionglong Su",
      "Sifan Song"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03635"
  },
  {
    "id": "arXiv:2203.03636",
    "title": "Clustering and classification of low-dimensional data in explicit  feature map domain: intraoperative pixel-wise diagnosis of adenocarcinoma of  a colon in a liver",
    "abstract": "Application of artificial intelligence in medicine brings in highly accurate\npredictions achieved by complex models, the reasoning of which is hard to\ninterpret. Their generalization ability can be reduced because of the lack of\npixel wise annotated images that occurs in frozen section tissue analysis. To\npartially overcome this gap, this paper explores the approximate explicit\nfeature map (aEFM) transform of low-dimensional data into a low-dimensional\nsubspace in Hilbert space. There, with a modest increase in computational\ncomplexity, linear algorithms yield improved performance and keep\ninterpretability. They remain amenable to incremental learning that is not a\ntrivial issue for some nonlinear algorithms. We demonstrate proposed\nmethodology on a very large-scale problem related to intraoperative pixel-wise\nsemantic segmentation and clustering of adenocarcinoma of a colon in a liver.\nCompared to the results in the input space, logistic classifier achieved\nstatistically significant performance improvements in micro balanced accuracy\nand F1 score in the amounts of 12.04% and 12.58%, respectively. Support vector\nmachine classifier yielded the increase of 8.04% and 9.41%. For clustering,\nincreases of 0.79% and 0.85% are obtained with ultra large-scale spectral\nclustering algorithm. Results are supported by a discussion of interpretability\nusing Shapely additive explanation values for predictions of linear classifier\nin input space and aEFM induced space.",
    "descriptor": "\nComments: 18 pages, 4 figures, 6 tables, appendix\n",
    "authors": [
      "Dario Sitnik",
      "Ivica Kopriva"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03636"
  },
  {
    "id": "arXiv:2203.03638",
    "title": "Unsupervised Image Registration Towards Enhancing Performance and  Explainability in Cardiac And Brain Image Analysis",
    "abstract": "Magnetic Resonance Imaging (MRI) typically recruits multiple sequences\n(defined here as \"modalities\"). As each modality is designed to offer different\nanatomical and functional clinical information, there are evident disparities\nin the imaging content across modalities. Inter- and intra-modality affine and\nnon-rigid image registration is an essential medical image analysis process in\nclinical imaging, as for example before imaging biomarkers need to be derived\nand clinically evaluated across different MRI modalities, time phases and\nslices. Although commonly needed in real clinical scenarios, affine and\nnon-rigid image registration is not extensively investigated using a single\nunsupervised model architecture. In our work, we present an un-supervised deep\nlearning registration methodology which can accurately model affine and\nnon-rigid trans-formations, simultaneously. Moreover, inverse-consistency is a\nfundamental inter-modality registration property that is not considered in deep\nlearning registration algorithms. To address inverse-consistency, our\nmethodology performs bi-directional cross-modality image synthesis to learn\nmodality-invariant latent rep-resentations, while involves two factorised\ntransformation networks and an inverse-consistency loss to learn\ntopology-preserving anatomical transformations. Overall, our model (named\n\"FIRE\") shows improved performances against the reference standard baseline\nmethod on multi-modality brain 2D and 3D MRI and intra-modality cardiac 4D MRI\ndata experiments.",
    "descriptor": "\nComments: 38 pages, 7 figures, will be published in Sensors journal by MDPI\n",
    "authors": [
      "Chengjia Wang",
      "Guang Yang",
      "Giorgos Papanastasiou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03638"
  },
  {
    "id": "arXiv:2203.03640",
    "title": "Conquering Data Variations in Resolution: A Slice-Aware Multi-Branch  Decoder Network",
    "abstract": "Fully convolutional neural networks have made promising progress in joint\nliver and liver tumor segmentation. Instead of following the debates over 2D\nversus 3D networks (for example, pursuing the balance between large-scale 2D\npretraining and 3D context), in this paper, we novelly identify the wide\nvariation in the ratio between intra- and inter-slice resolutions as a crucial\nobstacle to the performance. To tackle the mismatch between the intra- and\ninter-slice information, we propose a slice-aware 2.5D network that emphasizes\nextracting discriminative features utilizing not only in-plane semantics but\nalso out-of-plane coherence for each separate slice. Specifically, we present a\nslice-wise multi-input multi-output architecture to instantiate such a design\nparadigm, which contains a Multi-Branch Decoder (MD) with a Slice-centric\nAttention Block (SAB) for learning slice-specific features and a Densely\nConnected Dice (DCD) loss to regularize the inter-slice predictions to be\ncoherent and continuous. Based on the aforementioned innovations, we achieve\nstate-of-the-art results on the MICCAI 2017 Liver Tumor Segmentation (LiTS)\ndataset. Besides, we also test our model on the ISBI 2019 Segmentation of\nTHoracic Organs at Risk (SegTHOR) dataset, and the result proves the robustness\nand generalizability of the proposed method in other segmentation tasks.",
    "descriptor": "\nComments: Published by IEEE TMI\n",
    "authors": [
      "Shuxin Wang",
      "Shilei Cao",
      "Zhizhong Chai",
      "Dong Wei",
      "Kai Ma",
      "Liansheng Wang",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03640"
  },
  {
    "id": "arXiv:2203.03673",
    "title": "AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment  of Implicit Graph Generators",
    "abstract": "We propose and analyse a novel statistical procedure, coined AgraSSt, to\nassess the quality of graph generators that may not be available in explicit\nform. In particular, AgraSSt can be used to determine whether a learnt graph\ngenerating process is capable of generating graphs that resemble a given input\ngraph. Inspired by Stein operators for random graphs, the key idea of AgraSSt\nis the construction of a kernel discrepancy based on an operator obtained from\nthe graph generator. AgraSSt can provide interpretable criticisms for a graph\ngenerator training procedure and help identify reliable sample batches for\ndownstream tasks. Using Stein`s method we give theoretical guarantees for a\nbroad class of random graph models. We provide empirical results on both\nsynthetic input graphs with known graph generation procedures, and real-world\ninput graphs that the state-of-the-art (deep) generative models for graphs are\ntrained on.",
    "descriptor": "",
    "authors": [
      "Wenkai Xu",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03673"
  },
  {
    "id": "arXiv:2203.03690",
    "title": "Robust Design of Rate-Splitting Multiple Access With Imperfect CSI for  Cell-Free MIMO Systems",
    "abstract": "Rate-Splitting Multiple Access (RSMA) for multi-user downlink operates by\nsplitting the message for each user equipment (UE) into a private message and a\nset of common messages, which are simultaneously transmitted by means of\nsuperposition coding. The RSMA scheme can enhance throughput and connectivity\nas compared to conventional multiple access techniques by optimizing the\nrate-splitting ratios along with the corresponding downlink beamforming\nvectors. This work examines the impact of erroneous channel state information\n(CSI) on the performance of RSMA in cell-free multiple-input multiple-output\n(MIMO) systems. An efficient robust optimization algorithm is proposed by using\nclosed-form lower bound expressions on the expected data rates. Extensive\nnumerical results show the importance of robust design in the presence of CSI\nerrors and how the performance gain of RSMA over conventional schemes is\naffected by CSI imperfection.",
    "descriptor": "\nComments: To be presented at IEEE ICC 2022 6th Workshop on Rate-Splitting Multiple Access for 6G\n",
    "authors": [
      "Daesung Yu",
      "Seok-Hwan Park",
      "Osvaldo Simeone",
      "Shlomo Shamai"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.03690"
  },
  {
    "id": "arXiv:2203.03744",
    "title": "Identifying the Deviator",
    "abstract": "A group of players are supposed to follow a prescribed profile of strategies.\nIf they follow this profile, they will reach a given target. We show that if\nthe target is not reached because some player deviates, then an outside\nobserver can identify the deviator. We also construct identification methods in\ntwo nontrivial cases.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Noga Alon",
      "Benjamin Gunby",
      "Xiaoyu He",
      "Eran Shmaya",
      "Eilon Solan"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.03744"
  },
  {
    "id": "arXiv:2203.03745",
    "title": "Self-restricting Noise and Quantum Relative Entropy Decay",
    "abstract": "Open quantum systems as modeled by quantum channels and quantum Markov\nsemigroups usually decay to subspaces that are invariant under environmental\ninteractions. It is known that finite-dimensional semigroups with detailed\nbalance decay exponentially under modified logarithmic-Sobolev inequalities\n(MLSIs). Here we analyze discrete and continuous processes that include unitary\ncomponents, breaking the detailed balance assumption. We find counter-examples\nto analogs of MLSIs for these systems. The generalized quantum Zeno effect\nappears for many Lindbladians that combine a decay process with unitary drift.\nAs incompatible long-time and Zeno limits compete, strong noise often protects\nsubsystems and subspaces from its own spread. We observe this interplay between\ndecay and Zeno-like effects experimentally on superconducting qubits using IBM\nQ devices. Nonetheless, by combining MLSIs for effective self-adjoint decay\nprocesses across different times, we obtain eventual exponential decay. We\nsimilarly obtain decay rate lower bounds for discrete compositions of quantum\nchannels.",
    "descriptor": "\nComments: 46 pages, 7 figures\n",
    "authors": [
      "Nicholas LaRacuente"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.03745"
  },
  {
    "id": "arXiv:2203.03791",
    "title": "Data adaptive RKHS Tikhonov regularization for learning kernels in  operators",
    "abstract": "We present DARTR: a Data Adaptive RKHS Tikhonov Regularization method for the\nlinear inverse problem of nonparametric learning of function parameters in\noperators. A key ingredient is a system intrinsic data-adaptive (SIDA) RKHS,\nwhose norm restricts the learning to take place in the function space of\nidentifiability. DARTR utilizes this norm and selects the regularization\nparameter by the L-curve method. We illustrate its performance in examples\nincluding integral operators, nonlinear operators and nonlocal operators with\ndiscrete synthetic data. Numerical results show that DARTR leads to an accurate\nestimator robust to both numerical error due to discrete data and noise in\ndata, and the estimator converges at a consistent rate as the data mesh refines\nunder different levels of noises, outperforming two baseline regularizers using\n$l^2$ and $L^2$ norms.",
    "descriptor": "",
    "authors": [
      "Fei Lu",
      "Quanjun Lang",
      "Qingci An"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03791"
  },
  {
    "id": "arXiv:2203.03808",
    "title": "A Fast Scale-Invariant Algorithm for Non-negative Least Squares with  Non-negative Data",
    "abstract": "Nonnegative (linear) least square problems are a fundamental class of\nproblems that is well-studied in statistical learning and for which solvers\nhave been implemented in many of the standard programming languages used within\nthe machine learning community. The existing off-the-shelf solvers view the\nnon-negativity constraint in these problems as an obstacle and, compared to\nunconstrained least squares, perform additional effort to address it. However,\nin many of the typical applications, the data itself is nonnegative as well,\nand we show that the nonnegativity in this case makes the problem easier. In\nparticular, while the oracle complexity of unconstrained least squares problems\nnecessarily scales with one of the data matrix constants (typically the\nspectral norm) and these problems are solved to additive error, we show that\nnonnegative least squares problems with nonnegative data are solvable to\nmultiplicative error and with complexity that is independent of any matrix\nconstants. The algorithm we introduce is accelerated and based on a primal-dual\nperspective. We further show how to provably obtain linear convergence using\nadaptive restart coupled with our method and demonstrate its effectiveness on\nlarge-scale data via numerical experiments.",
    "descriptor": "",
    "authors": [
      "Jelena Diakonikolas",
      "Chenghui Li",
      "Swati Padmanabhan",
      "Chaobing Song"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.03808"
  },
  {
    "id": "arXiv:2203.03814",
    "title": "Generating 3D Bio-Printable Patches Using Wound Segmentation and  Reconstruction to Treat Diabetic Foot Ulcers",
    "abstract": "We introduce AiD Regen, a novel system that generates 3D wound models\ncombining 2D semantic segmentation with 3D reconstruction so that they can be\nprinted via 3D bio-printers during the surgery to treat diabetic foot ulcers\n(DFUs). AiD Regen seamlessly binds the full pipeline, which includes RGB-D\nimage capturing, semantic segmentation, boundary-guided point-cloud processing,\n3D model reconstruction, and 3D printable G-code generation, into a single\nsystem that can be used out of the box. We developed a multi-stage data\npreprocessing method to handle small and unbalanced DFU image datasets. AiD\nRegen's human-in-the-loop machine learning interface enables clinicians to not\nonly create 3D regenerative patches with just a few touch interactions but also\ncustomize and confirm wound boundaries. As evidenced by our experiments, our\nmodel outperforms prior wound segmentation models and our reconstruction\nalgorithm is capable of generating 3D wound models with compelling accuracy. We\nfurther conducted a case study on a real DFU patient and demonstrated the\neffectiveness of AiD Regen in treating DFU wounds.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Han Joo Chae",
      "Seunghwan Lee",
      "Hyewon Son",
      "Seungyeob Han",
      "Taebin Lim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03814"
  },
  {
    "id": "arXiv:2203.03816",
    "title": "Quantum Volume in Practice: What Users Can Expect from NISQ Devices",
    "abstract": "Quantum volume (QV) has become the de-facto standard benchmark to quantify\nthe capability of Noisy Intermediate-Scale Quantum (NISQ) devices. While QV\nvalues are often reported by NISQ providers for their systems, we perform our\nown series of QV calculations on more than 20 NISQ devices currently\n(2021/2022) offered by IBM Q, IonQ, Rigetti, Oxford Quantum Circuits, and\nHoneywell/Quantinuum. Our approach characterizes the performances that an\nadvanced user of these NISQ devices can expect to achieve with a reasonable\namount of optimization, but without white-box access to the device. In\nparticular, we compile QV circuits to standard gate sets of the vendor using\ncompiler optimization routines where available, and we perform experiments\nacross different initial qubit mappings. We find that running QV tests requires\nvery significant compilation cycles, QV values achieved in our tests typically\nlag behind officially reported results and also depend significantly on the\nclassical compilation effort invested.",
    "descriptor": "",
    "authors": [
      "Elijah Pelofske",
      "Andreas B\u00e4rtschi",
      "Stephan Eidenbenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2203.03816"
  },
  {
    "id": "arXiv:2203.03844",
    "title": "Dynamic Dual Trainable Bounds for Ultra-low Precision Super-Resolution  Networks",
    "abstract": "Light-weight super-resolution (SR) models have received considerable\nattention for their serviceability in mobile devices. Many efforts employ\nnetwork quantization to compress SR models. However, these methods suffer from\nsevere performance degradation when quantizing the SR models to ultra-low\nprecision (e.g., 2-bit and 3-bit) with the low-cost layer-wise quantizer. In\nthis paper, we identify that the performance drop comes from the contradiction\nbetween the layer-wise symmetric quantizer and the highly asymmetric activation\ndistribution in SR models. This discrepancy leads to either a waste on the\nquantization levels or detail loss in reconstructed images. Therefore, we\npropose a novel activation quantizer, referred to as Dynamic Dual Trainable\nBounds (DDTB), to accommodate the asymmetry of the activations. Specifically,\nDDTB innovates in: 1) A layer-wise quantizer with trainable upper and lower\nbounds to tackle the highly asymmetric activations. 2) A dynamic gate\ncontroller to adaptively adjust the upper and lower bounds at runtime to\novercome the drastically varying activation ranges over different samples.To\nreduce the extra overhead, the dynamic gate controller is quantized to 2-bit\nand applied to only part of the SR networks according to the introduced dynamic\nintensity. Extensive experiments demonstrate that our DDTB exhibits significant\nperformance improvements in ultra-low precision. For example, our DDTB achieves\na 0.70dB PSNR increase on Urban100 benchmark when quantizing EDSR to 2-bit and\nscaling up output images to x4. Code is at\n\\url{https://github.com/zysxmu/DDTB}.",
    "descriptor": "",
    "authors": [
      "Yunshan Zhong",
      "Mingbao Lin",
      "Xunchao Li",
      "Ke Li",
      "Yunhang Shen",
      "Fei Chao",
      "Yongjian Wu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03844"
  },
  {
    "id": "arXiv:2203.03858",
    "title": "Dimension reduction for maximum matchings and the Fastest Mixing Markov  Chain",
    "abstract": "Let $G = (V,E)$ be an undirected graph with maximum degree $\\Delta$ and\nvertex conductance $\\Psi^*(G)$. We show that there exists a symmetric,\nstochastic matrix $P$, with off-diagonal entries supported on $E$, whose\nspectral gap $\\gamma^*(P)$ satisfies \\[\\Psi^*(G)^{2}/\\log\\Delta \\lesssim\n\\gamma^*(P) \\lesssim \\Psi^*(G).\\] Our bound is optimal under the Small Set\nExpansion Hypothesis, and answers a question of Olesker-Taylor and Zanetti, who\nobtained such a result with $\\log\\Delta$ replaced by $\\log|V|$.\nIn order to obtain our result, we show how to embed a negative-type\nsemi-metric $d$ defined on $V$ into a negative-type semi-metric $d'$ supported\nin $\\mathbb{R}^{O(\\log\\Delta)}$, such that the (fractional) matching number of\nthe weighted graph $(V,E,d)$ is approximately equal to that of $(V,E,d')$.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Vishesh Jain",
      "Huy Tuan Pham",
      "Thuy-Duong Vuong"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.03858"
  },
  {
    "id": "arXiv:2203.03899",
    "title": "Noisy Low-rank Matrix Optimization: Geometry of Local Minima and  Convergence Rate",
    "abstract": "This paper is concerned with low-rank matrix optimization, which has found a\nwide range of applications in machine learning. This problem in the special\ncase of matrix sense has been studied extensively through the notion of\nRestricted Isometry Property (RIP), leading to a wealth of results on the\ngeometric landscape of the problem and the convergence rate of common\nalgorithms. However, the existing results are not able to handle the problem\nwith a general objective function subject to noisy data. In this paper, we\naddress this problem by developing a mathematical framework that can deal with\nrandom corruptions to general objective functions, where the noise model is\narbitrary. We prove that as long as the RIP constant of the noiseless objective\nis less than $1/3$, any spurious local solution of the noisy optimization\nproblem must be close to the ground truth solution. By working through the\nstrict saddle property, we also show that an approximate solution can be found\nin polynomial time. We characterize the geometry of the spurious local minima\nof the problem in a local region around the ground truth in the case when the\nRIP constant is greater than $1/3$. This paper offers the first set of results\non the global and local optimization landscapes of general low-rank\noptimization problems under arbitrary random corruptions.",
    "descriptor": "",
    "authors": [
      "Ziye Ma",
      "Somayeh Sojoudi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.03899"
  },
  {
    "id": "arXiv:2203.03916",
    "title": "Estimating the average causal effect of intervention in continuous  variables using machine learning",
    "abstract": "The most widely discussed methods for estimating the Average Causal Effect /\nAverage Treatment Effect are those for intervention in discrete binary\nvariables whose value represents the intervention / non-intervention groups. On\nthe other hand, methods for intervening in continuous variables independent of\nthe data generating model has not been developed. In this study, we give a\nmethod for estimating the average causal effect for intervention in continuous\nvariables that can be applied to data of any generating model as long as the\ncausal effect is identifiable. The proposing method is independent of machine\nlearning algorithms and preserves the identifiability of the data.",
    "descriptor": "",
    "authors": [
      "Yoshiaki Kitazawa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03916"
  },
  {
    "id": "arXiv:2203.03976",
    "title": "Adaptations to a geomagnetic field interpolation method in Southern  Africa",
    "abstract": "Space weather and its impact on infrastructure presents a clear risk in the\nmodern era, as evidenced by the adverse effects of geomagnetically induced\ncurrents (GICs) in power networks. To model GICs, ground-based geomagnetic\nfield (B-field) measurements are critical and need to be available in the\nregion of interest. A challenge globally lies in the sparse distribution of\nmagnetometer arrays, which are seldom located near critical power network\nnodes. Interpolation of the geomagnetic field (B-field) is often needed, with\nthe spherical elementary current system (SECS) approach developed for\nhigh-latitude regions favoured. We adapt this interpolation scheme to include\nlow-cost variometers to interpolate dB/dt directly and increase interpolation\naccuracy. A further adaptation to the scheme is to physically represent the\nmid-latitude context where most power networks and pipelines lie. The driving\ncurrent systems in these regions differ from their high-latitude counterparts.\nUsing a physics-consistent mid-latitude version of SECS, we show why previous\nimplementations in Southern Africa are incorrect but still result in useful\ninterpolation. The scope of these adaptations not only has direct application\nto research in general, but also to utilities, where effective low-cost\ninstrumentation can be used to improve GIC modelling accuracy.",
    "descriptor": "\nComments: 10 pages, 8 figures, submitted to Advances in Space Research\n",
    "authors": [
      "M. J. Heyns",
      "S. I. Lotz",
      "P. J. Cilliers",
      "C. T. Gaunt"
    ],
    "subjectives": [
      "Space Physics (physics.space-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03976"
  },
  {
    "id": "arXiv:2203.03979",
    "title": "Online Weak-form Sparse Identification of Partial Differential Equations",
    "abstract": "This paper presents an online algorithm for identification of partial\ndifferential equations (PDEs) based on the weak-form sparse identification of\nnonlinear dynamics algorithm (WSINDy). The algorithm is online in a sense that\nif performs the identification task by processing solution snapshots that\narrive sequentially. The core of the method combines a weak-form discretization\nof candidate PDEs with an online proximal gradient descent approach to the\nsparse regression problem. In particular, we do not regularize the\n$\\ell_0$-pseudo-norm, instead finding that directly applying its proximal\noperator (which corresponds to a hard thresholding) leads to efficient online\nsystem identification from noisy data. We demonstrate the success of the method\non the Kuramoto-Sivashinsky equation, the nonlinear wave equation with\ntime-varying wavespeed, and the linear wave equation, in one, two, and three\nspatial dimensions, respectively. In particular, our examples show that the\nmethod is capable of identifying and tracking systems with coefficients that\nvary abruptly in time, and offers a streaming alternative to problems in higher\ndimensions.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Daniel A. Messenger",
      "Emiliano Dall'Anese",
      "David M. Bortz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.03979"
  },
  {
    "id": "arXiv:2203.04010",
    "title": "A nonlinear bending theory for nematic LCE plates",
    "abstract": "In this paper, we study an elastic bilayer plate composed of a nematic liquid\ncrystal elastomer in the top layer and a nonlinearly elastic material in the\nbottom layer. While the bottom layer is assumed to be stress-free in the flat\nreference configuration, the top layer features an eigenstrain that depends on\nthe local liquid crystal orientation. As a consequence, the plate shows\nnon-flat deformations in equilibrium with a geometry that non-trivially depends\non the relative thickness and shape of the plate, material parameters, boundary\nconditions for the deformation, and anchorings of the liquid crystal\norientation. We focus on thin plates in the bending regime and derive a\ntwo-dimensional bending model that combines a nonlinear bending energy for the\ndeformation, with a surface Oseen-Frank energy for the director field that\ndescribes the local orientation of the liquid crystal elastomer. Both energies\nare nonlinearly coupled by means of a spontaneous curvature term that\neffectively describes the nematic-elastic coupling. We rigorously derive this\nmodel as a {\\Gamma}-limit from three-dimensional, nonlinear elasticity. We also\ndevise a new numerical algorithm to compute stationary points of the\ntwo-dimensional model. We conduct numerical experiments and present simulation\nresults that illustrate the practical properties of the proposed scheme as well\nas the rich mechanical behavior of the system.",
    "descriptor": "\nComments: 61 pages, 7 Figures\n",
    "authors": [
      "S\u00f6ren Bartels",
      "Max Griehl",
      "Stefan Neukamm",
      "David Padilla-Garza",
      "Christian Palus"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.04010"
  },
  {
    "id": "arXiv:2203.04013",
    "title": "Mutual Contrastive Learning to Disentangle Whole Slide Image  Representations for Glioma Grading",
    "abstract": "Whole slide images (WSI) provide valuable phenotypic information for\nhistological assessment and malignancy grading of tumors. The WSI-based\ncomputational pathology promises to provide rapid diagnostic support and\nfacilitate digital health. The most commonly used WSI are derived from\nformalin-fixed paraffin-embedded (FFPE) and frozen sections. Currently, the\nmajority of automatic tumor grading models are developed based on FFPE\nsections, which could be affected by the artifacts introduced by tissue\nprocessing. Here we propose a mutual contrastive learning scheme to integrate\nFFPE and frozen sections and disentangle cross-modality representations for\nglioma grading. We first design a mutual learning scheme to jointly optimize\nthe model training based on FFPE and frozen sections. Further, we develop a\nmulti-modality domain alignment mechanism to ensure semantic consistency in the\nbackbone model training. We finally design a sphere normalized\ntemperature-scaled cross-entropy loss (NT-Xent), which could promote\ncross-modality representation disentangling of FFPE and frozen sections. Our\nexperiments show that the proposed scheme achieves better performance than the\nmodel trained based on each single modality or mixed modalities. The sphere\nNT-Xent loss outperforms other typical metrics loss functions.",
    "descriptor": "\nComments: 11 pages, 4 figures, 2 tables\n",
    "authors": [
      "Lipei Zhang",
      "Yiran Wei",
      "Ying Fu",
      "Stephen Price",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Chao Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04013"
  },
  {
    "id": "arXiv:2203.04020",
    "title": "Mini-batch stochastic three-operator splitting for distributed  optimization",
    "abstract": "We consider a network of agents, each with its own private cost consisting of\na sum of two possibly nonsmooth convex functions, one of which is composed with\na linear operator. At every iteration each agent performs local calculations\nand can only communicate with its neighbors. The challenging aspect of our\nstudy is that the smooth part of the private cost function is given as an\nexpected value and agents only have access to this part of the problem\nformulation via a heavy-tailed stochastic oracle. To tackle such sampling-based\noptimization problems, we propose a stochastic extension of the triangular\npre-conditioned primal-dual algorithm. We demonstrate almost sure convergence\nof the scheme and validate the performance of the method via numerical\nexperiments.",
    "descriptor": "",
    "authors": [
      "Barbara Franci",
      "Mathias Staudigl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.04020"
  },
  {
    "id": "arXiv:2203.04042",
    "title": "Learning to Erase the Bayer-Filter to See in the Dark",
    "abstract": "Low-light image enhancement - a pervasive but challenging problem, plays a\ncentral role in enhancing the visibility of an image captured in a poor\nillumination environment. Due to the fact that not all photons can pass the\nBayer-Filter on the sensor of the color camera, in this work, we first present\na De-Bayer-Filter simulator based on deep neural networks to generate a\nmonochrome raw image from the colored raw image. Next, a fully convolutional\nnetwork is proposed to achieve the low-light image enhancement by fusing\ncolored raw data with synthesized monochrome raw data. Channel-wise attention\nis also introduced to the fusion process to establish a complementary\ninteraction between features from colored and monochrome raw images. To train\nthe convolutional networks, we propose a dataset with monochrome and color raw\npairs named Mono-Colored Raw paired dataset (MCR) collected by using a\nmonochrome camera without Bayer-Filter and a color camera with Bayer-Filter.\nThe proposed pipeline take advantages of the fusion of the virtual monochrome\nand the color raw images and our extensive experiments indicate that\nsignificant improvement can be achieved by leveraging raw sensor data and\ndata-driven learning.",
    "descriptor": "",
    "authors": [
      "Xingbo Dong",
      "Wanyan Xu",
      "Zhihui Miao",
      "Lan Ma",
      "Chao Zhang",
      "Jiewen Yang",
      "Zhe Jin",
      "Andrew Beng Jin Teoh",
      "Jiajun Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04042"
  },
  {
    "id": "arXiv:2203.04044",
    "title": "Single-trajectory map equation",
    "abstract": "Community detection is an effective approach in studies of network data. The\nmap equation is a particularly popular framework and several extensions of this\nmethod have been proposed. Herein, we revisit the original formulation of the\nmap equation and consider its \"raw form,\" which we refer to as the\nsingle-trajectory map equation. The map equation requires a network as the\ninput and considers the flow of the random walk on the network, whereas the\nsingle-trajectory map equation requires a set of trajectories that walkers have\ntraveled along. We study how these formulations are related and show that the\nsingle-trajectory map equation is a community detection method that provides\ncoarser-resolution partitions, implying that it prevents the issue of\nexcessively high resolution in the map equation.",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Tatsuro Kawamoto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.04044"
  },
  {
    "id": "arXiv:2203.04093",
    "title": "Exploration of Various Deep Learning Models for Increased Accuracy in  Automatic Polyp Detection",
    "abstract": "This paper is created to explore deep learning models and algorithms that\nresults in highest accuracy in detecting polyp on colonoscopy images. Previous\nstudies implemented deep learning using convolution neural network (CNN)\nalgorithm in detecting polyp and non-polyp. Other studies used dropout, and\ndata augmentation algorithm but mostly not checking the overfitting, thus,\ninclude more than four-layer modelss. Rulei Yu et.al from the Institute of\nSoftware, Chinese Academy of Sciences said that transfer learning is better\ntalking about performance or improving the previous used algorithm. Most\nespecially in applying the transfer learning in feature extraction. Series of\nexperiments were conducted with only a minimum of 4 CNN layers applying\nprevious used models and identified the model that produce the highest\npercentage accuracy of 98% among the other models that apply transfer learning.\nFurther studies could use different optimizer to a different CNN modelsto\nincrease accuracy.",
    "descriptor": "",
    "authors": [
      "Ariel E. Isidro",
      "Arnel C. Fajardo",
      "Alexander A. Hernandez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.04093"
  },
  {
    "id": "arXiv:2203.04107",
    "title": "Comparing representations of biological data learned with different AI  paradigms, augmenting and cropping strategies",
    "abstract": "Recent advances in computer vision and robotics enabled automated large-scale\nbiological image analysis. Various machine learning approaches have been\nsuccessfully applied to phenotypic profiling. However, it remains unclear how\nthey compare in terms of biological feature extraction. In this study, we\npropose a simple CNN architecture and implement 4 different representation\nlearning approaches. We train 16 deep learning setups on the 770k cancer cell\nimages dataset under identical conditions, using different augmenting and\ncropping strategies. We compare the learned representations by evaluating\nmultiple metrics for each of three downstream tasks: i) distance-based\nsimilarity analysis of known drugs, ii) classification of drugs versus\ncontrols, iii) clustering within cell lines. We also compare training times and\nmemory usage. Among all tested setups, multi-crops and random augmentations\ngenerally improved performance across tasks, as expected. Strikingly,\nself-supervised (implicit contrastive learning) models showed competitive\nperformance being up to 11 times faster to train. Self-supervised regularized\nlearning required the most of memory and computation to deliver arguably the\nmost informative features. We observe that no single combination of augmenting\nand cropping strategies consistently results in top performance across tasks\nand recommend prospective research directions.",
    "descriptor": "\nComments: Accepted to MIDL 2022 conference. 17 pages, 8 figures, 4 tables\n",
    "authors": [
      "Andrei Dmitrenko",
      "Mauro M. Masiero",
      "Nicola Zamboni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2203.04107"
  },
  {
    "id": "arXiv:2203.04115",
    "title": "Biological Sequence Design with GFlowNets",
    "abstract": "Design of de novo biological sequences with desired properties, like protein\nand DNA sequences, often involves an active loop with several rounds of\nmolecule ideation and expensive wet-lab evaluations. These experiments can\nconsist of multiple stages, with increasing levels of precision and cost of\nevaluation, where candidates are filtered. This makes the diversity of proposed\ncandidates a key consideration in the ideation phase. In this work, we propose\nan active learning algorithm leveraging epistemic uncertainty estimation and\nthe recently proposed GFlowNets as a generator of diverse candidate solutions,\nwith the objective to obtain a diverse batch of useful (as defined by some\nutility function, for example, the predicted anti-microbial activity of a\npeptide) and informative candidates after each round. We also propose a scheme\nto incorporate existing labeled datasets of candidates, in addition to a reward\nfunction, to speed up learning in GFlowNets. We present empirical results on\nseveral biological sequence design tasks, and we find that our method generates\nmore diverse and novel batches with high scoring candidates compared to\nexisting approaches.",
    "descriptor": "\nComments: 15 pages, 3 figures. Code available at: this https URL\n",
    "authors": [
      "Moksh Jain",
      "Emmanuel Bengio",
      "Alex-Hernandez Garcia",
      "Jarrid Rector-Brooks",
      "Bonaventure F. P. Dossou",
      "Chanakya Ekbote",
      "Jie Fu",
      "Tianyu Zhang",
      "Micheal Kilgour",
      "Dinghuai Zhang",
      "Lena Simine",
      "Payel Das",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04115"
  },
  {
    "id": "arXiv:2203.04118",
    "title": "An Efficient Polyp Segmentation Network",
    "abstract": "Cancer is a disease that occurs as a result of uncontrolled division and\nproliferation of cells. The number of cancer cases has been on the rise over\nthe recent years.. Colon cancer is one of the most common types of cancer in\nthe world. Polyps that can be seen in the large intestine can cause cancer if\nnot removed with early intervention. Deep learning and image segmentation\ntechniques are used to minimize the number of polyps that goes unnoticed by the\nexperts during the diagnosis. Although these techniques give good results, they\nrequire too many parameters. We propose a new model to solve this problem. Our\nproposed model includes less parameters as well as outperforming the success of\nthe state of the art models. In the proposed model, a partial decoder is used\nto reduce the number of parameters while maintaning success. EfficientNetB0,\nwhich gives successfull results as well as requiring few parameters, is used in\nthe encoder part. Since polyps have variable aspect and aspect ratios, an\nasymetric convolution block was used instead of using classic convolution\nblock. Kvasir and CVC-ClinicDB datasets were seperated as training, validation\nand testing, and CVC-ColonDB, ETIS and Endoscene datasets were used for\ntesting. According to the dice metric, our model had the best results with\n%71.8 in the ColonDB test dataset, %89.3 in the EndoScene test dataset and\n%74.8 in the ETIS test dataset. Our model requires a total of 2.626.337\nparameters. When we compare it in the literature, according to similar studies,\nthe model that requires the least parameters is U-Net++ with 9.042.177\nparameters.",
    "descriptor": "\nComments: 4 pages, in Turkish language, 2 figures, 2 tables\n",
    "authors": [
      "Tugberk Erol",
      "Duygu Sarikaya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04118"
  },
  {
    "id": "arXiv:2203.04148",
    "title": "Numerical solution of optimal control of atherosclerosis using direct  and indirect methods with shooting/collocation approach",
    "abstract": "We present a direct numerical method for the solution of an optimal control\nproblem controlling the growth of LDL, HDL and plaque. The optimal control\nproblem is constrained with a system of coupled nonlinear free and mixed\nboundary partial differential equations consisting of three parabolics one\nelliptic and one ordinary differential equations. In the first step, the\noriginal problem is transformed from a free boundary problem into a fixed one\nand from the mixed boundary condition to a Neumann one. Then, employing a fixed\npoint-collocation method, we solve the optimal control problem. In each step of\nthe fixed point iteration, the problem is changed to a linear one and then, the\nequations are solved using the collocation method bringing about an NLP which\nis solved using sequential quadratic programming. Then, the obtained solution\nis verified using indirect methods originating from the first-order optimality\nconditions. Numerical results are considered to illustrate the efficiency of\nmethods.",
    "descriptor": "",
    "authors": [
      "F. Nasresfahani",
      "M. R. Eslahchi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.04148"
  },
  {
    "id": "arXiv:2203.04163",
    "title": "Localization Schemes: A Framework for Proving Mixing Bounds for Markov  Chains",
    "abstract": "Two recent and seemingly-unrelated techniques for proving mixing bounds for\nMarkov chains are: (i) the framework of Spectral Independence, introduced by\nAnari, Liu and Oveis Gharan, and its numerous extensions, which have given rise\nto several breakthroughs in the analysis of mixing times of discrete Markov\nchains and (ii) the Stochastic Localization technique which has proven useful\nin establishing mixing and expansion bounds for both log-concave measures and\nfor measures on the discrete hypercube. In this paper, we introduce a framework\nwhich connects ideas from both techniques. Our framework unifies, simplifies\nand extends those two techniques. In its center is the concept of a\nlocalization scheme which, to every probability measure, assigns a martingale\nof probability measures which localize in space as time evolves. As it turns\nout, to every such scheme corresponds a Markov chain, and many chains of\ninterest appear naturally in this framework. This viewpoint provides tools for\nderiving mixing bounds for the dynamics through the analysis of the\ncorresponding localization process. Generalizations of concepts of Spectral\nIndependence and Entropic Independence naturally arise from our definitions,\nand in particular we recover the main theorems in the spectral and entropic\nindependence frameworks via simple martingale arguments (completely bypassing\nthe need to use the theory of high-dimensional expanders). We demonstrate the\nstrength of our proposed machinery by giving short and (arguably) simpler\nproofs to many mixing bounds in the recent literature, including giving the\nfirst $O(n \\log n)$ bound for the mixing time of Glauber dynamics on the\nhardcore-model (of arbitrary degree) in the tree-uniqueness regime.",
    "descriptor": "\nComments: 59 pages, 1 figure\n",
    "authors": [
      "Yuansi Chen",
      "Ronen Eldan"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.04163"
  },
  {
    "id": "arXiv:2203.04176",
    "title": "Variational methods for simulation-based inference",
    "abstract": "We present Sequential Neural Variational Inference (SNVI), an approach to\nperform Bayesian inference in models with intractable likelihoods. SNVI\ncombines likelihood-estimation (or likelihood-ratio-estimation) with\nvariational inference to achieve a scalable simulation-based inference\napproach. SNVI maintains the flexibility of likelihood(-ratio) estimation to\nallow arbitrary proposals for simulations, while simultaneously providing a\nfunctional estimate of the posterior distribution without requiring MCMC\nsampling. We present several variants of SNVI and demonstrate that they are\nsubstantially more computationally efficient than previous algorithms, without\nloss of accuracy on benchmark tasks. We apply SNVI to a neuroscience model of\nthe pyloric network in the crab and demonstrate that it can infer the posterior\ndistribution with one order of magnitude fewer simulations than previously\nreported. SNVI vastly reduces the computational cost of simulation-based\ninference while maintaining accuracy and flexibility, making it possible to\ntackle problems that were previously inaccessible.",
    "descriptor": "",
    "authors": [
      "Manuel Gl\u00f6ckler",
      "Michael Deistler",
      "Jakob H. Macke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04176"
  },
  {
    "id": "arXiv:2203.04197",
    "title": "Locate This, Not That: Class-Conditioned Sound Event DOA Estimation",
    "abstract": "Existing systems for sound event localization and detection (SELD) typically\noperate by estimating a source location for all classes at every time instant.\nIn this paper, we propose an alternative class-conditioned SELD model for\nsituations where we may not be interested in localizing all classes all of the\ntime. This class-conditioned SELD model takes as input the spatial and spectral\nfeatures from the sound file, and also a one-hot vector indicating the class we\nare currently interested in localizing. We inject the conditioning information\nat several points in our model using feature-wise linear modulation (FiLM)\nlayers. Through experiments on the DCASE 2020 Task 3 dataset, we show that the\nproposed class-conditioned SELD model performs better in terms of common SELD\nmetrics than the baseline model that locates all classes simultaneously, and\nalso outperforms specialist models that are trained to locate only a single\nclass of interest. We also evaluate performance on the DCASE 2021 Task 3\ndataset, which includes directional interference (sound events from classes we\nare not interested in localizing) and notice especially strong improvement from\nthe class-conditioned model.",
    "descriptor": "\nComments: Accepted for publication at ICASSP 2022\n",
    "authors": [
      "Olga Slizovskaia",
      "Gordon Wichern",
      "Zhong-Qiu Wang",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.04197"
  },
  {
    "id": "arXiv:2203.04201",
    "title": "Follow the Water: Finding Water, Snow and Clouds on Terrestrial  Exoplanets with Photometry and Machine Learning",
    "abstract": "All life on Earth needs water. NASA's quest to follow the water links water\nto the search for life in the cosmos. Telescopes like JWST and mission concepts\nlike HabEx, LUVOIR and Origins are designed to characterise rocky exoplanets\nspectroscopically. However, spectroscopy remains time-intensive and therefore,\ninitial characterisation is critical to prioritisation of targets.\nHere, we study machine learning as a tool to assess water's existence through\nbroadband-filter reflected photometric flux on Earth-like exoplanets in three\nforms: seawater, water-clouds and snow; based on 53,130 spectra of cold,\nEarth-like planets with 6 major surfaces. XGBoost, a well-known machine\nlearning algorithm, achieves over 90\\% balanced accuracy in detecting the\nexistence of snow or clouds for S/N$\\gtrsim 20$, and 70\\% for liquid seawater\nfor S/N $\\gtrsim 30$. Finally, we perform mock Bayesian analysis with\nMarkov-chain Monte Carlo with five filters identified to derive exact surface\ncompositions to test for retrieval feasibility.\nThe results show that the use of machine learning to identify water on the\nsurface of exoplanets from broadband-filter photometry provides a promising\ninitial characterisation tool of water in different forms. Planned small and\nlarge telescope missions could use this to aid their prioritisation of targets\nfor time-intense follow-up observations.",
    "descriptor": "\nComments: 6 pages, 5 figures. Accepted for publications in MNRAS Letters\n",
    "authors": [
      "Dang Pham",
      "Lisa Kaltenegger"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04201"
  },
  {
    "id": "arXiv:2203.04216",
    "title": "Determination of a class of permutation quadrinomials",
    "abstract": "We determine all permutation polynomials over F_{q^2} of the form X^r\nA(X^{q-1}) where, for some Q which is a power of the characteristic of F_q, the\ninteger r is congruent to Q+1 (mod q+1) and all terms of A(X) have degrees in\n{0, 1, Q, Q+1}. We then use this classification to resolve eight conjectures\nand open problems from the literature, and we show that the simplest special\ncases of our result imply 58 recent results from the literature. Our proof\nmakes a novel use of geometric techniques in a situation where they previously\ndid not seem applicable, namely to understand the arithmetic of high-degree\nrational functions over small finite fields, despite the fact that in this\nsituation the Weil bounds do not provide useful information.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Zhiguo Ding",
      "Michael E. Zieve"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.04216"
  },
  {
    "id": "arXiv:2203.04262",
    "title": "Diagonal distance of quantum codes and hardness of the minimum distance  problem",
    "abstract": "The diagonal distance or graph distance is an important parameter of a\nquantum error-correcting code that characterizes whether the code is degenerate\nor not. Degeneracy is a property unique to quantum codes, which allows quantum\ncodes, unlike their classical counterparts, to correct more errors than they\ncan uniquely identify. In the CWS framework introduced by Cross, Smith, Smolin\nand Zeng (2009), a quantum code is constructed using a classical code and a\ngraph. It is known that the diagonal distance of such a code is upper bounded\nby $\\delta+1$, where $\\delta$ is the minimum degree of the associated graph. In\nthis paper, we give sufficient conditions on a graph such that a CWS code\nconstructed from it has diagonal distance at least $\\delta$, and in fact most\nof the graphs in our sufficient class achieve the upper bound of $\\delta+1$.\nUsing this result, first we give necessary conditions for a CWS code to be\ndegenerate. Secondly, we prove hardness results for the problem of finding the\ndistance of a CWS code. We construct a CWS code from a given classical code,\nwith the distance of the CWS code being equal to the distance of the classical\ncode. This allows us to translate well-known hardness results for computing the\nminimum distance in classical codes to quantum codes. Specifically, we show\nthat exactly computing the distance of a CWS code is NP-complete, and\nmultiplicatively or additively approximating it is NP-hard under\npolynomial-time randomized reductions. Our reduction from the classical\nproblems to the quantum problems results in a non-degenerate quantum code,\nhence our result implies that the quantum problems remain NP-hard even with the\npromise that the code is non-degenerate. Moreover, using a mapping from\nstabilizer codes to CSS codes due to Bravyi, Terhal and Leemhuis (2010), we are\nable to show that the hardness results hold for CSS codes as well.",
    "descriptor": "\nComments: Contains results previously included in arXiv:2107.11286\n",
    "authors": [
      "Upendra Kapshikar",
      "Srijita Kundu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.04262"
  },
  {
    "id": "arXiv:2203.04285",
    "title": "Bayesian Persuasion with Mediators",
    "abstract": "A sender communicates with a receiver through a sequence of mediators. The\nsender is the only informed agent and the receiver is the only one taking an\naction. All the agents have their own utility functions, which depend on the\nreceiver's action and the state.\nFor any number of mediators, the sender's optimal value is characterized. For\none mediator, the characterization has a clear geometric meaning of constrained\nconcavification of the sender's utility, optimal persuasion requires the same\nnumber of signals as without mediators, and the presence of the mediator is\nnever profitable for the sender. Surprisingly, the second mediator may improve\nthe sender's utility; however, optimal persuasion with several mediators may\nrequire more signals.",
    "descriptor": "",
    "authors": [
      "Itai Arieli",
      "Yakov Babichenko",
      "Fedor Sandomirskiy"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.04285"
  },
  {
    "id": "arXiv:1907.01696",
    "title": "A Semi-Supervised Framework for Automatic Pixel-Wise Breast Cancer  Grading of Histological Images",
    "abstract": "Comments: The author list and contents of this paper is not complete. Other authors request to withdraw this paper",
    "descriptor": "\nComments: The author list and contents of this paper is not complete. Other authors request to withdraw this paper\n",
    "authors": [
      "Yanyuet Man",
      "Xiangyun Ding",
      "Xingcheng Yao",
      "Han Bao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1907.01696"
  },
  {
    "id": "arXiv:1907.04377",
    "title": "Convergence Rates for Gaussian Mixtures of Experts",
    "abstract": "Comments: 81 pages",
    "descriptor": "\nComments: 81 pages\n",
    "authors": [
      "Nhat Ho",
      "Chiao-Yu Yang",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1907.04377"
  },
  {
    "id": "arXiv:1907.04826",
    "title": "Approximately counting and sampling small witnesses using a colourful  decision oracle",
    "abstract": "Approximately counting and sampling small witnesses using a colourful  decision oracle",
    "descriptor": "",
    "authors": [
      "Holger Dell",
      "John Lapinskas",
      "Kitty Meeks"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/1907.04826"
  },
  {
    "id": "arXiv:2001.03884",
    "title": "Compressibility Measures for Affinely Singular Random Vectors",
    "abstract": "Compressibility Measures for Affinely Singular Random Vectors",
    "descriptor": "",
    "authors": [
      "Mohammad-Amin Charusaie",
      "Arash Amini",
      "Stefano Rini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2001.03884"
  },
  {
    "id": "arXiv:2003.13153",
    "title": "Nonconvex Matrix Completion with Linearly Parameterized Factors",
    "abstract": "Comments: 34 pages, 2 figures",
    "descriptor": "\nComments: 34 pages, 2 figures\n",
    "authors": [
      "Ji Chen",
      "Xiaodong Li",
      "Zongming Ma"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.13153"
  },
  {
    "id": "arXiv:2007.01852",
    "title": "Language-agnostic BERT Sentence Embedding",
    "abstract": "Comments: To be presented at ACL 2022",
    "descriptor": "\nComments: To be presented at ACL 2022\n",
    "authors": [
      "Fangxiaoyu Feng",
      "Yinfei Yang",
      "Daniel Cer",
      "Naveen Arivazhagan",
      "Wei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2007.01852"
  },
  {
    "id": "arXiv:2008.00155",
    "title": "Adaptive integration of nonlinear evolution equations on tensor  manifolds",
    "abstract": "Comments: 26 pages, 10 figures",
    "descriptor": "\nComments: 26 pages, 10 figures\n",
    "authors": [
      "Abram Rodgers",
      "Alec Dektor",
      "Daniele Venturi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2008.00155"
  },
  {
    "id": "arXiv:2009.12517",
    "title": "QuatRE: Relation-Aware Quaternions for Knowledge Graph Embeddings",
    "abstract": "Comments: Accepted to The ACM Web Conference 2022 (WWW '22) (Poster and Demo Track)",
    "descriptor": "\nComments: Accepted to The ACM Web Conference 2022 (WWW '22) (Poster and Demo Track)\n",
    "authors": [
      "Dai Quoc Nguyen",
      "Thanh Vu",
      "Tu Dinh Nguyen",
      "Dinh Phung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.12517"
  },
  {
    "id": "arXiv:2009.13236",
    "title": "Acoustic scattering by impedance screens/cracks with fractal boundary:  well-posedness analysis and boundary element approximation",
    "abstract": "Acoustic scattering by impedance screens/cracks with fractal boundary:  well-posedness analysis and boundary element approximation",
    "descriptor": "",
    "authors": [
      "J. Bannister",
      "A. Gibbs",
      "D. P. Hewett"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2009.13236"
  },
  {
    "id": "arXiv:2010.03172",
    "title": "Improving Sequential Latent Variable Models with Autoregressive Flows",
    "abstract": "Comments: Published at Machine Learning Journal",
    "descriptor": "\nComments: Published at Machine Learning Journal\n",
    "authors": [
      "Joseph Marino",
      "Lei Chen",
      "Jiawei He",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.03172"
  },
  {
    "id": "arXiv:2010.07393",
    "title": "FAR: A General Framework for Attributional Robustness",
    "abstract": "FAR: A General Framework for Attributional Robustness",
    "descriptor": "",
    "authors": [
      "Adam Ivankay",
      "Ivan Girardi",
      "Chiara Marchiori",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.07393"
  },
  {
    "id": "arXiv:2010.09055",
    "title": "Large-Scale Maintenance and Unit Commitment: A Decentralized Subgradient  Approach",
    "abstract": "Large-Scale Maintenance and Unit Commitment: A Decentralized Subgradient  Approach",
    "descriptor": "",
    "authors": [
      "Paritosh Ramanan",
      "Murat Yildirim",
      "Nagi Gebraeel",
      "Edmond Chow"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2010.09055"
  },
  {
    "id": "arXiv:2011.15079",
    "title": "Forecasting Characteristic 3D Poses of Human Actions",
    "abstract": "Comments: CVPR 2022; Project Page: this https URL; Paper Video: this https URL",
    "descriptor": "\nComments: CVPR 2022; Project Page: this https URL; Paper Video: this https URL\n",
    "authors": [
      "Christian Diller",
      "Thomas Funkhouser",
      "Angela Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.15079"
  },
  {
    "id": "arXiv:2012.04372",
    "title": "Freeform shape optimization of a compact DC photo-electron gun using  isogeometric analysis",
    "abstract": "Freeform shape optimization of a compact DC photo-electron gun using  isogeometric analysis",
    "descriptor": "",
    "authors": [
      "Peter F\u00f6rster",
      "Sebastian Sch\u00f6ps",
      "Joachim Enders",
      "Maximilian Herbert",
      "Abele Simona"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Accelerator Physics (physics.acc-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.04372"
  },
  {
    "id": "arXiv:2012.04543",
    "title": "Efficient model selection in switching linear dynamic systems by graph  clustering",
    "abstract": "Efficient model selection in switching linear dynamic systems by graph  clustering",
    "descriptor": "",
    "authors": [
      "Parisa Karimi",
      "Mark Butala",
      "Zhizhen Zhao",
      "Farzad Kamalabadi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.04543"
  },
  {
    "id": "arXiv:2101.06757",
    "title": "Higher Order Automatic Differentiation of Higher Order Functions",
    "abstract": "Comments: 34 pages, 5 figures, submitted at LMCS 2020. arXiv admin note: substantial text overlap with arXiv:2001.02209",
    "descriptor": "\nComments: 34 pages, 5 figures, submitted at LMCS 2020. arXiv admin note: substantial text overlap with arXiv:2001.02209\n",
    "authors": [
      "Mathieu Huot",
      "Sam Staton",
      "Matthijs V\u00e1k\u00e1r"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.06757"
  },
  {
    "id": "arXiv:2102.02959",
    "title": "Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text  Reports Using Deep Learning",
    "abstract": "Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text  Reports Using Deep Learning",
    "descriptor": "",
    "authors": [
      "Vincent M. D'Anniballe",
      "Fakrul Islam Tushar",
      "Khrystyna Faryna",
      "Songyue Han",
      "Maciej A. Mazurowski",
      "Geoffrey D. Rubin",
      "Joseph Y. Lo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02959"
  },
  {
    "id": "arXiv:2102.05375",
    "title": "Strength of Minibatch Noise in SGD",
    "abstract": "Comments: ICLR 2022 spotlight",
    "descriptor": "\nComments: ICLR 2022 spotlight\n",
    "authors": [
      "Liu Ziyin",
      "Kangqiao Liu",
      "Takashi Mori",
      "Masahito Ueda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.05375"
  },
  {
    "id": "arXiv:2102.10351",
    "title": "Nonlinear dimension reduction for surrogate modeling using gradient  information",
    "abstract": "Nonlinear dimension reduction for surrogate modeling using gradient  information",
    "descriptor": "",
    "authors": [
      "Daniele Bigoni",
      "Youssef Marzouk",
      "Cl\u00e9mentine Prieur",
      "Olivier Zahm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.10351"
  },
  {
    "id": "arXiv:2102.10743",
    "title": "Mobility-Aware Routing and Caching: A Federated Learning Assisted  Approach",
    "abstract": "Mobility-Aware Routing and Caching: A Federated Learning Assisted  Approach",
    "descriptor": "",
    "authors": [
      "Yuwen Cao",
      "Setareh Maghsudi",
      "Tomoaki Ohtsuki"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.10743"
  },
  {
    "id": "arXiv:2102.11644",
    "title": "Higher order phase averaging for highly oscillatory systems",
    "abstract": "Higher order phase averaging for highly oscillatory systems",
    "descriptor": "",
    "authors": [
      "Werner Bauer",
      "Colin J. Cotter",
      "Beth Wingate"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.11644"
  },
  {
    "id": "arXiv:2103.00284",
    "title": "On the Initialization for Convex-Concave Min-max Problems",
    "abstract": "Comments: Accepted by ALT 2022",
    "descriptor": "\nComments: Accepted by ALT 2022\n",
    "authors": [
      "Mingrui Liu",
      "Francesco Orabona"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00284"
  },
  {
    "id": "arXiv:2103.05134",
    "title": "Constrained Learning with Non-Convex Losses",
    "abstract": "Constrained Learning with Non-Convex Losses",
    "descriptor": "",
    "authors": [
      "Luiz F. O. Chamon",
      "Santiago Paternain",
      "Miguel Calvo-Fullana",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.05134"
  },
  {
    "id": "arXiv:2103.06109",
    "title": "Session-based Social and Dependency-aware Software Recommendation",
    "abstract": "Session-based Social and Dependency-aware Software Recommendation",
    "descriptor": "",
    "authors": [
      "Dengcheng Yan",
      "Tianyi Tang",
      "Wenxin Xie",
      "Yiwen Zhang",
      "Qiang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2103.06109"
  },
  {
    "id": "arXiv:2103.06560",
    "title": "Heterogeneous Information Network-based Interest Composition with Graph  Neural Network for Recommendation",
    "abstract": "Heterogeneous Information Network-based Interest Composition with Graph  Neural Network for Recommendation",
    "descriptor": "",
    "authors": [
      "Dengcheng Yan",
      "Wenxin Xie",
      "Yiwen Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2103.06560"
  },
  {
    "id": "arXiv:2103.11730",
    "title": "Reduced basis methods for numerical room acoustic simulations with  parametrized boundaries",
    "abstract": "Comments: 10 figures and 2 tables",
    "descriptor": "\nComments: 10 figures and 2 tables\n",
    "authors": [
      "Hermes Sampedro Llopis",
      "Allan P. Engsig-Karup",
      "Cheol-Ho Jeong",
      "Finnur Pind",
      "Jan S. Hesthaven"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2103.11730"
  },
  {
    "id": "arXiv:2104.00165",
    "title": "Encoding Event-Based Data With a Hybrid SNN Guided Variational  Auto-encoder in Neuromorphic Hardware",
    "abstract": "Comments: Published in NICE 2022",
    "descriptor": "\nComments: Published in NICE 2022\n",
    "authors": [
      "Kenneth Stewart",
      "Andreea Danielescu",
      "Timothy Shea",
      "Emre Neftci"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.00165"
  },
  {
    "id": "arXiv:2104.01714",
    "title": "Accounting for uncertainty of non-linear regression models by divisive  data resorting",
    "abstract": "Accounting for uncertainty of non-linear regression models by divisive  data resorting",
    "descriptor": "",
    "authors": [
      "Andrew Polar",
      "Michael Poluektov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.01714"
  },
  {
    "id": "arXiv:2104.02395",
    "title": "Ensemble deep learning: A review",
    "abstract": "Ensemble deep learning: A review",
    "descriptor": "",
    "authors": [
      "M.A. Ganaie",
      "Minghui Hu",
      "A.K. Malik",
      "M. Tanveer",
      "P.N. Suganthan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.02395"
  },
  {
    "id": "arXiv:2104.14332",
    "title": "Hypernetwork Dismantling via Deep Reinforcement Learning",
    "abstract": "Hypernetwork Dismantling via Deep Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Dengcheng Yan",
      "Wenxin Xie",
      "Yiwen Zhang",
      "Qiang He",
      "Yun Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.14332"
  },
  {
    "id": "arXiv:2105.13116",
    "title": "IA-CCF: Individual Accountability for Permissioned Ledgers",
    "abstract": "IA-CCF: Individual Accountability for Permissioned Ledgers",
    "descriptor": "",
    "authors": [
      "Alex Shamis",
      "Peter Pietzuch",
      "Miguel Castro",
      "C\u00e9dric Fournet",
      "Edward Ashton",
      "Amaury Chamayou",
      "Sylvan Clebsch",
      "Antoine Delignat-Lavaud",
      "Matthew Kerner",
      "Julien Maffre",
      "Manuel Costa",
      "Mark Russinovich"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13116"
  },
  {
    "id": "arXiv:2105.13569",
    "title": "Superfloe Parameterization with Physics Constraints for Uncertainty  Quantification of Sea Ice Floes",
    "abstract": "Superfloe Parameterization with Physics Constraints for Uncertainty  Quantification of Sea Ice Floes",
    "descriptor": "",
    "authors": [
      "Nan Chen",
      "Quanling Deng",
      "Samuel N. Stechmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2105.13569"
  },
  {
    "id": "arXiv:2105.13626",
    "title": "ByT5: Towards a token-free future with pre-trained byte-to-byte models",
    "abstract": "Comments: To be published in TACL 2022",
    "descriptor": "\nComments: To be published in TACL 2022\n",
    "authors": [
      "Linting Xue",
      "Aditya Barua",
      "Noah Constant",
      "Rami Al-Rfou",
      "Sharan Narang",
      "Mihir Kale",
      "Adam Roberts",
      "Colin Raffel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13626"
  },
  {
    "id": "arXiv:2106.01216",
    "title": "Evidential Turing Processes",
    "abstract": "Comments: accepted at ICLR2022; camera ready version",
    "descriptor": "\nComments: accepted at ICLR2022; camera ready version\n",
    "authors": [
      "Melih Kandemir",
      "Abdullah Akg\u00fcl",
      "Manuel Haussmann",
      "Gozde Unal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01216"
  },
  {
    "id": "arXiv:2106.02320",
    "title": "Few-Shot Segmentation via Cycle-Consistent Transformer",
    "abstract": "Comments: Advances in Neural Information Processing Systems (NeurIPS), 2021. Project: this https URL",
    "descriptor": "\nComments: Advances in Neural Information Processing Systems (NeurIPS), 2021. Project: this https URL\n",
    "authors": [
      "Gengwei Zhang",
      "Guoliang Kang",
      "Yi Yang",
      "Yunchao Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02320"
  },
  {
    "id": "arXiv:2106.03579",
    "title": "Forward Looking Best-Response Multiplicative Weights Update Methods for  Bilinear Zero-sum Games",
    "abstract": "Forward Looking Best-Response Multiplicative Weights Update Methods for  Bilinear Zero-sum Games",
    "descriptor": "",
    "authors": [
      "Michail Fasoulakis",
      "Evangelos Markakis",
      "Yannis Pantazis",
      "Constantinos Varsos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03579"
  },
  {
    "id": "arXiv:2106.03915",
    "title": "A Graphical Representation of Membrane Filtration",
    "abstract": "A Graphical Representation of Membrane Filtration",
    "descriptor": "",
    "authors": [
      "Binan Gu",
      "Lou Kondic",
      "Linda J. Cummings"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.03915"
  },
  {
    "id": "arXiv:2106.04590",
    "title": "PEARL: Data Synthesis via Private Embeddings and Adversarial  Reconstruction Learning",
    "abstract": "Comments: 22 pages, 10 figures, accepted to ICLR 2022",
    "descriptor": "\nComments: 22 pages, 10 figures, accepted to ICLR 2022\n",
    "authors": [
      "Seng Pei Liew",
      "Tsubasa Takahashi",
      "Michihiko Ueno"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.04590"
  },
  {
    "id": "arXiv:2106.04823",
    "title": "Taxonomy of Machine Learning Safety: A Survey and Primer",
    "abstract": "Taxonomy of Machine Learning Safety: A Survey and Primer",
    "descriptor": "",
    "authors": [
      "Sina Mohseni",
      "Haotao Wang",
      "Zhiding Yu",
      "Chaowei Xiao",
      "Zhangyang Wang",
      "Jay Yadawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.04823"
  },
  {
    "id": "arXiv:2106.07349",
    "title": "Using Integrated Gradients and Constituency Parse Trees to explain  Linguistic Acceptability learnt by BERT",
    "abstract": "Comments: Accepted at International Conference on Natural Language Processing (ICON) 2021. 6 pages, 3 figures",
    "descriptor": "\nComments: Accepted at International Conference on Natural Language Processing (ICON) 2021. 6 pages, 3 figures\n",
    "authors": [
      "Anmol Nayak",
      "Hari Prasad Timmapathini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07349"
  },
  {
    "id": "arXiv:2106.07617",
    "title": "Delving Deep into the Generalization of Vision Transformers under  Distribution Shifts",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Chongzhi Zhang",
      "Mingyuan Zhang",
      "Shanghang Zhang",
      "Daisheng Jin",
      "Qiang Zhou",
      "Zhongang Cai",
      "Haiyu Zhao",
      "Xianglong Liu",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07617"
  },
  {
    "id": "arXiv:2106.08074",
    "title": "On Star Expressions and Coalgebraic Completeness Theorems",
    "abstract": "Comments: In Proceedings MFPS 2021, arXiv:2112.13746",
    "descriptor": "\nComments: In Proceedings MFPS 2021, arXiv:2112.13746\n",
    "authors": [
      "Todd Schmid",
      "Jurriaan Rot",
      "Alexandra Silva"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.08074"
  },
  {
    "id": "arXiv:2106.08217",
    "title": "RFpredInterval: An R Package for Prediction Intervals with Random  Forests and Boosted Forests",
    "abstract": "Comments: 36 pages, 14 figures, 5 tables",
    "descriptor": "\nComments: 36 pages, 14 figures, 5 tables\n",
    "authors": [
      "Cansu Alakus",
      "Denis Larocque",
      "Aurelie Labbe"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08217"
  },
  {
    "id": "arXiv:2106.09215",
    "title": "Optimum-statistical Collaboration Towards General and Efficient  Black-box Optimization",
    "abstract": "Optimum-statistical Collaboration Towards General and Efficient  Black-box Optimization",
    "descriptor": "",
    "authors": [
      "Wenjie Li",
      "Chi-Hua Wang",
      "Qifan Song",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09215"
  },
  {
    "id": "arXiv:2106.10541",
    "title": "Checking whether a word is Hamming-isometric in linear time",
    "abstract": "Comments: A second algorithm for checking whether a word is Hamming-isometric is added using the result given in reference [5]",
    "descriptor": "\nComments: A second algorithm for checking whether a word is Hamming-isometric is added using the result given in reference [5]\n",
    "authors": [
      "Marie-Pierre B\u00e9al",
      "Maxime Crochemore"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.10541"
  },
  {
    "id": "arXiv:2106.12248",
    "title": "ADAVI: Automatic Dual Amortized Variational Inference Applied To  Pyramidal Bayesian Models",
    "abstract": "ADAVI: Automatic Dual Amortized Variational Inference Applied To  Pyramidal Bayesian Models",
    "descriptor": "",
    "authors": [
      "Louis Rouillard",
      "Demian Wassermann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.12248"
  },
  {
    "id": "arXiv:2106.12271",
    "title": "Unsupervised Speech Enhancement using Dynamical Variational  Auto-Encoders",
    "abstract": "Unsupervised Speech Enhancement using Dynamical Variational  Auto-Encoders",
    "descriptor": "",
    "authors": [
      "Xiaoyu Bie",
      "Simon Leglaive",
      "Xavier Alameda-Pineda",
      "Laurent Girin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.12271"
  },
  {
    "id": "arXiv:2106.13264",
    "title": "You are AllSet: A Multiset Function Framework for Hypergraph Neural  Networks",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Eli Chien",
      "Chao Pan",
      "Jianhao Peng",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13264"
  },
  {
    "id": "arXiv:2107.00363",
    "title": "Valid prediction intervals for regression problems",
    "abstract": "Comments: submitted to AI Review",
    "descriptor": "\nComments: submitted to AI Review\n",
    "authors": [
      "Nicolas Dewolf",
      "Bernard De Baets",
      "Willem Waegeman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00363"
  },
  {
    "id": "arXiv:2107.01294",
    "title": "Is GPT-3 Text Indistinguishable from Human Text? Scarecrow: A Framework  for Scrutinizing Machine Text",
    "abstract": "Comments: The project webpage is at this https URL",
    "descriptor": "\nComments: The project webpage is at this https URL\n",
    "authors": [
      "Yao Dou",
      "Maxwell Forbes",
      "Rik Koncel-Kedziorski",
      "Noah A. Smith",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01294"
  },
  {
    "id": "arXiv:2107.08286",
    "title": "Large-Scale Estimation of Dominant Poles of a Transfer Function by an  Interpolatory Framework",
    "abstract": "Comments: 24 pages, 3 figures",
    "descriptor": "\nComments: 24 pages, 3 figures\n",
    "authors": [
      "Emre Mengi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.08286"
  },
  {
    "id": "arXiv:2107.10648",
    "title": "DEAP-FAKED: Knowledge Graph based Approach for Fake News Detection",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Mohit Mayank",
      "Shakshi Sharma",
      "Rajesh Sharma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.10648"
  },
  {
    "id": "arXiv:2107.14415",
    "title": "Connecting Compression Spaces with Transformer for Approximate Nearest  Neighbor Search",
    "abstract": "Comments: 13 pages, 3 figures and 5 tables",
    "descriptor": "\nComments: 13 pages, 3 figures and 5 tables\n",
    "authors": [
      "Haokui Zhang",
      "Buzhou Tang",
      "Wenze Hu",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.14415"
  },
  {
    "id": "arXiv:2108.01950",
    "title": "On origami-like quasi-mechanisms with an antiprismatic skeleton",
    "abstract": "Comments: 12 pages, 9 figures",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Georg Nawratil"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2108.01950"
  },
  {
    "id": "arXiv:2108.02741",
    "title": "GIFAIR-FL: A Framework for Group and Individual Fairness in Federated  Learning",
    "abstract": "GIFAIR-FL: A Framework for Group and Individual Fairness in Federated  Learning",
    "descriptor": "",
    "authors": [
      "Xubo Yue",
      "Maher Nouiehed",
      "Raed Al Kontar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.02741"
  },
  {
    "id": "arXiv:2108.04314",
    "title": "Malware-on-the-Brain: Illuminating Malware Byte Codes with Images for  Malware Classification",
    "abstract": "Malware-on-the-Brain: Illuminating Malware Byte Codes with Images for  Malware Classification",
    "descriptor": "",
    "authors": [
      "Fangtian Zhong",
      "Zekai Chen",
      "Minghui Xu",
      "Guoming Zhang",
      "Dongxiao Yu",
      "Xiuzhen Cheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.04314"
  },
  {
    "id": "arXiv:2108.05828",
    "title": "A general class of surrogate functions for stable and efficient  reinforcement learning",
    "abstract": "Comments: AISTATS 2022",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Sharan Vaswani",
      "Olivier Bachem",
      "Simone Totaro",
      "Robert Mueller",
      "Shivam Garg",
      "Matthieu Geist",
      "Marlos C. Machado",
      "Pablo Samuel Castro",
      "Nicolas Le Roux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.05828"
  },
  {
    "id": "arXiv:2108.12790",
    "title": "RPR-Net: A Point Cloud-based Rotation-aware Large Scale Place  Recognition Network",
    "abstract": "RPR-Net: A Point Cloud-based Rotation-aware Large Scale Place  Recognition Network",
    "descriptor": "",
    "authors": [
      "Zhaoxin Fan",
      "Zhenbo Song",
      "Wenping Zhang",
      "Hongyan Liu",
      "Jun He",
      "Xiaoyong Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.12790"
  },
  {
    "id": "arXiv:2109.01359",
    "title": "CAM-loss: Towards Learning Spatially Discriminative Feature  Representations",
    "abstract": "Comments: Accepted by ICCV2021",
    "descriptor": "\nComments: Accepted by ICCV2021\n",
    "authors": [
      "Chaofei Wang",
      "Jiayu Xiao",
      "Yizeng Han",
      "Qisen Yang",
      "Shiji Song",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.01359"
  },
  {
    "id": "arXiv:2109.05021",
    "title": "A Deep Learning-Based Unified Framework for Red Lesions Detection on  Retinal Fundus Images",
    "abstract": "A Deep Learning-Based Unified Framework for Red Lesions Detection on  Retinal Fundus Images",
    "descriptor": "",
    "authors": [
      "Norah Asiri",
      "Muhammad Hussain",
      "Fadwa Al Adel",
      "Hatim Aboalsamh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05021"
  },
  {
    "id": "arXiv:2109.05205",
    "title": "Contrastive Quantization with Code Memory for Unsupervised Image  Retrieval",
    "abstract": "Comments: Accepted for AAAI'22 (Oral). 9 pages, 4 figures, 3 tables",
    "descriptor": "\nComments: Accepted for AAAI'22 (Oral). 9 pages, 4 figures, 3 tables\n",
    "authors": [
      "Jinpeng Wang",
      "Ziyun Zeng",
      "Bin Chen",
      "Tao Dai",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.05205"
  },
  {
    "id": "arXiv:2109.05565",
    "title": "SphereFace Revived: Unifying Hyperspherical Face Recognition",
    "abstract": "Comments: Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Weiyang Liu",
      "Yandong Wen",
      "Bhiksha Raj",
      "Rita Singh",
      "Adrian Weller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05565"
  },
  {
    "id": "arXiv:2109.08549",
    "title": "Measuring Fairness under Unawareness of Sensitive Attributes: A  Quantification-Based Approach",
    "abstract": "Measuring Fairness under Unawareness of Sensitive Attributes: A  Quantification-Based Approach",
    "descriptor": "",
    "authors": [
      "Alessandro Fabris",
      "Andrea Esuli",
      "Alejandro Moreo",
      "Fabrizio Sebastiani"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.08549"
  },
  {
    "id": "arXiv:2109.10294",
    "title": "DeepSTL - From English Requirements to Signal Temporal Logic",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Jie He",
      "Ezio Bartocci",
      "Dejan Ni\u010dkovi\u0107",
      "Haris Isakovic",
      "Radu Grosu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.10294"
  },
  {
    "id": "arXiv:2109.11200",
    "title": "Secure PAC Bayesian Regression via Real Shamir Secret Sharing",
    "abstract": "Secure PAC Bayesian Regression via Real Shamir Secret Sharing",
    "descriptor": "",
    "authors": [
      "Jaron Skovsted Gundersen",
      "Bulut Kuskonmaz",
      "Rafael Wisniewski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.11200"
  },
  {
    "id": "arXiv:2109.12147",
    "title": "Trajectory Distribution Control for Model Predictive Path Integral  Control using Covariance Steering",
    "abstract": "Comments: \"For associated video, see this https URL\"",
    "descriptor": "\nComments: \"For associated video, see this https URL\"\n",
    "authors": [
      "Ji Yin",
      "Zhiyuan Zhang",
      "Evangelos Theodorou",
      "Panagiotis Tsiotras"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.12147"
  },
  {
    "id": "arXiv:2109.14960",
    "title": "Prune Your Model Before Distill It",
    "abstract": "Prune Your Model Before Distill It",
    "descriptor": "",
    "authors": [
      "Jinhyuk Park",
      "Albert No"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.14960"
  },
  {
    "id": "arXiv:2110.00717",
    "title": "Mobile Manipulation Leveraging Multiple Views",
    "abstract": "Comments: 6 pages, 2 pages of references, 5 figures, 5 tables",
    "descriptor": "\nComments: 6 pages, 2 pages of references, 5 figures, 5 tables\n",
    "authors": [
      "David Watkins-Valls",
      "Peter K Allen",
      "Henrique Maia",
      "Madhavan Seshadri",
      "Jonathan Sanabria",
      "Nicholas Waytowich",
      "Jacob Varley"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.00717"
  },
  {
    "id": "arXiv:2110.01515",
    "title": "A Review of the Gumbel-max Trick and its Extensions for Discrete  Stochasticity in Machine Learning",
    "abstract": "Comments: Accepted as a survey article in IEEE TPAMI",
    "descriptor": "\nComments: Accepted as a survey article in IEEE TPAMI\n",
    "authors": [
      "Iris A. M. Huijben",
      "Wouter Kool",
      "Max B. Paulus",
      "Ruud J. G. van Sloun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.01515"
  },
  {
    "id": "arXiv:2110.01775",
    "title": "Deep Instance Segmentation with High-Resolution Automotive Radar",
    "abstract": "Deep Instance Segmentation with High-Resolution Automotive Radar",
    "descriptor": "",
    "authors": [
      "Jianan Liu",
      "Weiyi Xiong",
      "Liping Bai",
      "Yuxuan Xia",
      "Tao Huang",
      "Wanli Ouyang",
      "Bing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.01775"
  },
  {
    "id": "arXiv:2110.02369",
    "title": "EntQA: Entity Linking as Question Answering",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Wenzheng Zhang",
      "Wenyue Hua",
      "Karl Stratos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02369"
  },
  {
    "id": "arXiv:2110.02792",
    "title": "Hierarchical Potential-based Reward Shaping from Task Specifications",
    "abstract": "Comments: 7 pages main, 3 pages appendix - improved task specification language and experiments",
    "descriptor": "\nComments: 7 pages main, 3 pages appendix - improved task specification language and experiments\n",
    "authors": [
      "Luigi Berducci",
      "Edgar A. Aguilar",
      "Dejan Ni\u010dkovi\u0107",
      "Radu Grosu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02792"
  },
  {
    "id": "arXiv:2110.03040",
    "title": "Approximate Quantiles for Stochastic Optimal Control of LTI Systems with  Arbitrary Disturbances",
    "abstract": "Comments: Accepted to American Control Conference (ACC) 2022. Final submission",
    "descriptor": "\nComments: Accepted to American Control Conference (ACC) 2022. Final submission\n",
    "authors": [
      "Shawn Priore",
      "Christopher Petersen",
      "Meeko Oishi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.03040"
  },
  {
    "id": "arXiv:2110.03272",
    "title": "A Novel Blind Source Separation Framework Towards Maximum  Signal-To-Interference Ratio",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Jianju Gu",
      "Longbiao Cheng",
      "Dingding Yao",
      "Junfeng Li",
      "Yonghong Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03272"
  },
  {
    "id": "arXiv:2110.04971",
    "title": "A Deep Generative Model for Reordering Adjacency Matrices",
    "abstract": "Comments: IEEE Transactions on Visualization and Computer Graphics",
    "descriptor": "\nComments: IEEE Transactions on Visualization and Computer Graphics\n",
    "authors": [
      "Oh-Hyun Kwon",
      "Chiun-How Kao",
      "Chun-houh Chen",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.04971"
  },
  {
    "id": "arXiv:2110.05145",
    "title": "Sim2Air - Synthetic aerial dataset for UAV monitoring",
    "abstract": "Sim2Air - Synthetic aerial dataset for UAV monitoring",
    "descriptor": "",
    "authors": [
      "Antonella Barisic",
      "Frano Petric",
      "Stjepan Bogdan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05145"
  },
  {
    "id": "arXiv:2110.05794",
    "title": "Information Theoretic Structured Generative Modeling",
    "abstract": "Information Theoretic Structured Generative Modeling",
    "descriptor": "",
    "authors": [
      "Bo Hu",
      "Shujian Yu",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05794"
  },
  {
    "id": "arXiv:2110.08300",
    "title": "When Combating Hype, Proceed with Caution",
    "abstract": "Comments: Proceedings of ACL 2022",
    "descriptor": "\nComments: Proceedings of ACL 2022\n",
    "authors": [
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08300"
  },
  {
    "id": "arXiv:2110.10380",
    "title": "Learning to Remember Patterns: Pattern Matching Memory Networks for  Traffic Forecasting",
    "abstract": "Comments: 15 pages, Accepted as poster to ICLR 2022",
    "descriptor": "\nComments: 15 pages, Accepted as poster to ICLR 2022\n",
    "authors": [
      "Hyunwook Lee",
      "Seungmin Jin",
      "Hyeshin Chu",
      "Hongkyu Lim",
      "Sungahn Ko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.10380"
  },
  {
    "id": "arXiv:2110.10572",
    "title": "Estimation & Recognition under Perspective of Random-Fuzzy Dual  Interpretation of Unknown Quantity: with Demonstration of IMM Filter",
    "abstract": "Comments: 15 pages, 11 figures, code available",
    "descriptor": "\nComments: 15 pages, 11 figures, code available\n",
    "authors": [
      "Wei Mei",
      "Yunfeng Xu",
      "Limin Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Probability (math.PR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.10572"
  },
  {
    "id": "arXiv:2110.11485",
    "title": "Soft Lattice Modules that Behave Independently and Collectively",
    "abstract": "Comments: 8 pages, 15 figures, accepted by IEEE RA-L & RoboSoft 2022",
    "descriptor": "\nComments: 8 pages, 15 figures, accepted by IEEE RA-L & RoboSoft 2022\n",
    "authors": [
      "Luyang Zhao",
      "Yijia Wu",
      "Julien Blanchet",
      "Maxine Perroni-Scharf",
      "Xiaonan Huang",
      "Joran Booth",
      "Rebecca Kramer-Bottiglio",
      "Devin Balkcom"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11485"
  },
  {
    "id": "arXiv:2110.12388",
    "title": "An adaptive model hierarchy for data-augmented training of kernel models  for reactive flow",
    "abstract": "Comments: New version contains fixed typos and an updated reference",
    "descriptor": "\nComments: New version contains fixed typos and an updated reference\n",
    "authors": [
      "Bernard Haasdonk",
      "Mario Ohlberger",
      "Felix Schindler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.12388"
  },
  {
    "id": "arXiv:2110.14163",
    "title": "Does the Data Induce Capacity Control in Deep Learning?",
    "abstract": "Does the Data Induce Capacity Control in Deep Learning?",
    "descriptor": "",
    "authors": [
      "Rubing Yang",
      "Jialin Mao",
      "Pratik Chaudhari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14163"
  },
  {
    "id": "arXiv:2110.14434",
    "title": "Nonnegative Tucker Decomposition with Beta-divergence for Music  Structure Analysis of audio signals",
    "abstract": "Comments: 4 pages, 2 figures, 1 table, 1 algorithm. Rejected from ICASSP 2022, but the algorithm is available at this https URL",
    "descriptor": "\nComments: 4 pages, 2 figures, 1 table, 1 algorithm. Rejected from ICASSP 2022, but the algorithm is available at this https URL\n",
    "authors": [
      "Axel Marmoret",
      "Florian Voorwinden",
      "Valentin Leplat",
      "J\u00e9r\u00e9my E. Cohen",
      "Fr\u00e9d\u00e9ric Bimbot"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.14434"
  },
  {
    "id": "arXiv:2110.14437",
    "title": "Exploring single-song autoencoding schemes for audio-based music  structure analysis",
    "abstract": "Comments: 4 pages, 4 figures, 2 tables. Rejected from ICASSP 2022, an extended version is available at arXiv:2202.04981",
    "descriptor": "\nComments: 4 pages, 4 figures, 2 tables. Rejected from ICASSP 2022, an extended version is available at arXiv:2202.04981\n",
    "authors": [
      "Axel Marmoret",
      "J\u00e9r\u00e9my E. Cohen",
      "Fr\u00e9d\u00e9ric Bimbot"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.14437"
  },
  {
    "id": "arXiv:2111.00161",
    "title": "Pseudo-Labeling for Massively Multilingual Speech Recognition",
    "abstract": "Comments: Accepted to ICASSP 2022. New version has links to code/models + more training curves for larger model. (Fixed code link.)",
    "descriptor": "\nComments: Accepted to ICASSP 2022. New version has links to code/models + more training curves for larger model. (Fixed code link.)\n",
    "authors": [
      "Loren Lugosch",
      "Tatiana Likhomanenko",
      "Gabriel Synnaeve",
      "Ronan Collobert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.00161"
  },
  {
    "id": "arXiv:2111.01827",
    "title": "Equivalent Versions of Total Flow Analysis",
    "abstract": "Equivalent Versions of Total Flow Analysis",
    "descriptor": "",
    "authors": [
      "St\u00e9phan Plassart",
      "Jean-Yves Le Boudec"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.01827"
  },
  {
    "id": "arXiv:2111.02274",
    "title": "Manipulation of granular materials by learning particle interactions",
    "abstract": "Comments: 8 pages, 5 figures. Accepted to IEEE Robotics and Automation Letters",
    "descriptor": "\nComments: 8 pages, 5 figures. Accepted to IEEE Robotics and Automation Letters\n",
    "authors": [
      "Neea Tuomainen",
      "David Blanco-Mulero",
      "Ville Kyrki"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02274"
  },
  {
    "id": "arXiv:2111.02280",
    "title": "A reduced order Schwarz method for nonlinear multiscale elliptic  equations based on two-layer neural networks",
    "abstract": "A reduced order Schwarz method for nonlinear multiscale elliptic  equations based on two-layer neural networks",
    "descriptor": "",
    "authors": [
      "Shi Chen",
      "Zhiyan Ding",
      "Qin Li",
      "Stephen J. Wright"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.02280"
  },
  {
    "id": "arXiv:2111.02630",
    "title": "Network Structure and Feature Learning from Noisy Data",
    "abstract": "Network Structure and Feature Learning from Noisy Data",
    "descriptor": "",
    "authors": [
      "Junyao Kuang",
      "Caterina Scoglio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.02630"
  },
  {
    "id": "arXiv:2111.05987",
    "title": "Tight bounds for minimum l1-norm interpolation of noisy data",
    "abstract": "Comments: 33 pages, 1 figure; accepted to AISTATS 2022",
    "descriptor": "\nComments: 33 pages, 1 figure; accepted to AISTATS 2022\n",
    "authors": [
      "Guillaume Wang",
      "Konstantin Donhauser",
      "Fanny Yang"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.05987"
  },
  {
    "id": "arXiv:2111.06021",
    "title": "Probabilistic Contrastive Learning for Domain Adaptation",
    "abstract": "Comments: 12 pages,4 figures",
    "descriptor": "\nComments: 12 pages,4 figures\n",
    "authors": [
      "Junjie Li",
      "Yixin Zhang",
      "Zilei Wang",
      "Keyu Tu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06021"
  },
  {
    "id": "arXiv:2111.06824",
    "title": "SOCP-based disjunctive cuts for a class of integer nonlinear bilevel  programs",
    "abstract": "SOCP-based disjunctive cuts for a class of integer nonlinear bilevel  programs",
    "descriptor": "",
    "authors": [
      "Elisabeth Gaar",
      "Jon Lee",
      "Ivana Ljubi\u0107",
      "Markus Sinnl",
      "K\u00fcbra Tan\u0131nm\u0131\u015f"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.06824"
  },
  {
    "id": "arXiv:2111.09136",
    "title": "IntraQ: Learning Synthetic Images with Intra-Class Heterogeneity for  Zero-Shot Network Quantization",
    "abstract": "Comments: CVPR2022",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Yunshan Zhong",
      "Mingbao Lin",
      "Gongrui Nan",
      "Jianzhuang Liu",
      "Baochang Zhang",
      "Yonghong Tian",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09136"
  },
  {
    "id": "arXiv:2111.09452",
    "title": "Open Vocabulary Object Detection with Pseudo Bounding-Box Labels",
    "abstract": "Open Vocabulary Object Detection with Pseudo Bounding-Box Labels",
    "descriptor": "",
    "authors": [
      "Mingfei Gao",
      "Chen Xing",
      "Juan Carlos Niebles",
      "Junnan Li",
      "Ran Xu",
      "Wenhao Liu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09452"
  },
  {
    "id": "arXiv:2111.10144",
    "title": "Positional Encoder Graph Neural Networks for Geographic Data",
    "abstract": "Positional Encoder Graph Neural Networks for Geographic Data",
    "descriptor": "",
    "authors": [
      "Konstantin Klemmer",
      "Nathan Safir",
      "Daniel B Neill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10144"
  },
  {
    "id": "arXiv:2111.12904",
    "title": "Low-rank approximation for multiscale PDEs",
    "abstract": "Low-rank approximation for multiscale PDEs",
    "descriptor": "",
    "authors": [
      "Ke Chen",
      "Shi Chen",
      "Qin Li",
      "Jianfeng Lu",
      "Stephen J. Wright"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12904"
  },
  {
    "id": "arXiv:2111.13445",
    "title": "How Well Do Sparse Imagenet Models Transfer?",
    "abstract": "Comments: Accepted to CVPR'22 20 pages, 8 figures (including appendix)",
    "descriptor": "\nComments: Accepted to CVPR'22 20 pages, 8 figures (including appendix)\n",
    "authors": [
      "Eugenia Iofinova",
      "Alexandra Peste",
      "Mark Kurtz",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13445"
  },
  {
    "id": "arXiv:2111.14833",
    "title": "Adversarial Attacks in Cooperative AI",
    "abstract": "Adversarial Attacks in Cooperative AI",
    "descriptor": "",
    "authors": [
      "Ted Fujimoto",
      "Arthur Paul Pedersen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.14833"
  },
  {
    "id": "arXiv:2111.15418",
    "title": "A structure preserving front tracking finite element method for the  Mullins--Sekerka problem",
    "abstract": "Comments: 24 pages, 9 figures",
    "descriptor": "\nComments: 24 pages, 9 figures\n",
    "authors": [
      "Robert N\u00fcrnberg"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.15418"
  },
  {
    "id": "arXiv:2112.01740",
    "title": "AirDet: Few-Shot Detection without Fine-tuning for Autonomous  Exploration",
    "abstract": "Comments: 23 pages, 9 figures",
    "descriptor": "\nComments: 23 pages, 9 figures\n",
    "authors": [
      "Bowen Li",
      "Chen Wang",
      "Pranay Reddy",
      "Seungchan Kim",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01740"
  },
  {
    "id": "arXiv:2112.02891",
    "title": "Seeing BDD100K in dark: Single-Stage Night-time Object Detection via  Continual Fourier Contrastive Learning",
    "abstract": "Seeing BDD100K in dark: Single-Stage Night-time Object Detection via  Continual Fourier Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Ujjal Kr Dutta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02891"
  },
  {
    "id": "arXiv:2112.04585",
    "title": "MASTAF: A Model-Agnostic Spatio-Temporal Attention Fusion Network for  Few-shot Video Classification",
    "abstract": "MASTAF: A Model-Agnostic Spatio-Temporal Attention Fusion Network for  Few-shot Video Classification",
    "descriptor": "",
    "authors": [
      "Rex Liu",
      "Huanle Zhang",
      "Hamed Pirsiavash",
      "Xin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04585"
  },
  {
    "id": "arXiv:2112.04906",
    "title": "Enhancing Column Generation by a Machine-Learning-Based Pricing  Heuristic for Graph Coloring",
    "abstract": "Comments: Machine learning for column generation and branch-and-price; accepted to AAAI 2022",
    "descriptor": "\nComments: Machine learning for column generation and branch-and-price; accepted to AAAI 2022\n",
    "authors": [
      "Yunzhuang Shen",
      "Yuan Sun",
      "Xiaodong Li",
      "Andrew Eberhard",
      "Andreas Ernst"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04906"
  },
  {
    "id": "arXiv:2112.06101",
    "title": "Confidence intervals for the random forest generalization error",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Paulo C. Marques F."
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06101"
  },
  {
    "id": "arXiv:2112.06318",
    "title": "Contextualized Scene Imagination for Generative Commonsense Reasoning",
    "abstract": "Comments: Accepted by ICLR 2022",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "PeiFeng Wang",
      "Jonathan Zamora",
      "Junfeng Liu",
      "Filip Ilievski",
      "Muhao Chen",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.06318"
  },
  {
    "id": "arXiv:2112.06374",
    "title": "Learning Generalizable Vision-Tactile Robotic Grasping Strategy for  Deformable Objects via Transformer",
    "abstract": "Comments: This paper is submitted to RA-L",
    "descriptor": "\nComments: This paper is submitted to RA-L\n",
    "authors": [
      "Yunhai Han",
      "Rahul Batra",
      "Nathan Boyd",
      "Tuo Zhao",
      "Yu She",
      "Seth Hutchinson",
      "Ye Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.06374"
  },
  {
    "id": "arXiv:2112.09075",
    "title": "A minimalistic stochastic dynamics model of cluttered obstacle traversal",
    "abstract": "A minimalistic stochastic dynamics model of cluttered obstacle traversal",
    "descriptor": "",
    "authors": [
      "Bokun Zheng",
      "Qihan Xuan",
      "Chen Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.09075"
  },
  {
    "id": "arXiv:2112.10741",
    "title": "GLIDE: Towards Photorealistic Image Generation and Editing with  Text-Guided Diffusion Models",
    "abstract": "Comments: 20 pages, 18 figures",
    "descriptor": "\nComments: 20 pages, 18 figures\n",
    "authors": [
      "Alex Nichol",
      "Prafulla Dhariwal",
      "Aditya Ramesh",
      "Pranav Shyam",
      "Pamela Mishkin",
      "Bob McGrew",
      "Ilya Sutskever",
      "Mark Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.10741"
  },
  {
    "id": "arXiv:2112.12601",
    "title": "Hermite--Pad\u00e9 approximations with Pfaffian structures: Novikov  peakon equation and integrable lattices",
    "abstract": "Comments: 37 pages; to appear in Advances in Mathematics",
    "descriptor": "\nComments: 37 pages; to appear in Advances in Mathematics\n",
    "authors": [
      "Xiang-Ke Chang"
    ],
    "subjectives": [
      "Exactly Solvable and Integrable Systems (nlin.SI)",
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12601"
  },
  {
    "id": "arXiv:2112.13257",
    "title": "A Fast Row-Stochastic Decentralized Optimization Method Over Directed  Graphs",
    "abstract": "A Fast Row-Stochastic Decentralized Optimization Method Over Directed  Graphs",
    "descriptor": "",
    "authors": [
      "Diyako Ghaderyan",
      "Necdet Serhat Aybat",
      "A. Pedro Aguiar",
      "Fernando Lobo Pereira"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.13257"
  },
  {
    "id": "arXiv:2112.15272",
    "title": "ViNMT: Neural Machine Translation Toolkit",
    "abstract": "ViNMT: Neural Machine Translation Toolkit",
    "descriptor": "",
    "authors": [
      "Nguyen Hoang Quan",
      "Nguyen Thanh Dat",
      "Nguyen Hoang Minh Cong",
      "Nguyen Van Vinh",
      "Ngo Thi Vinh",
      "Nguyen Phuong Thai",
      "Tran Hong Viet"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15272"
  },
  {
    "id": "arXiv:2201.01113",
    "title": "Noisy Sensor Scheduling in Wireless Networked Control Systems: Freshness  or Precision",
    "abstract": "Comments: Accepted by IEEE Wireless Communications Letters",
    "descriptor": "\nComments: Accepted by IEEE Wireless Communications Letters\n",
    "authors": [
      "He Ma",
      "Shidong Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.01113"
  },
  {
    "id": "arXiv:2201.03331",
    "title": "Fiuncho: a program for any-order epistasis detection in CPU clusters",
    "abstract": "Comments: Submitted to The Journal of Supercomputing. Source code available at this https URL",
    "descriptor": "\nComments: Submitted to The Journal of Supercomputing. Source code available at this https URL\n",
    "authors": [
      "Christian Ponte-Fern\u00e1ndez",
      "Jorge Gonz\u00e1lez-Dom\u00ednguez",
      "Mar\u00eda J. Mart\u00edn"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.03331"
  },
  {
    "id": "arXiv:2201.04756",
    "title": "Roadside Lidar Vehicle Detection and Tracking Using Range And Intensity  Background Subtraction",
    "abstract": "Roadside Lidar Vehicle Detection and Tracking Using Range And Intensity  Background Subtraction",
    "descriptor": "",
    "authors": [
      "Tianya Zhang",
      "Peter J. Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.04756"
  },
  {
    "id": "arXiv:2201.04788",
    "title": "AI Singapore Trusted Media Challenge Dataset",
    "abstract": "AI Singapore Trusted Media Challenge Dataset",
    "descriptor": "",
    "authors": [
      "Weiling Chen",
      "Benjamin Chua",
      "Stefan Winkler",
      "See Kiong Ng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.04788"
  },
  {
    "id": "arXiv:2201.04898",
    "title": "Flexible Style Image Super-Resolution using Conditional Objective",
    "abstract": "Comments: Will be presented in IEEE ACCESS. Code and trained models will be available at this https URL",
    "descriptor": "\nComments: Will be presented in IEEE ACCESS. Code and trained models will be available at this https URL\n",
    "authors": [
      "Seung Ho Park",
      "Young Su Moon",
      "Nam Ik Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.04898"
  },
  {
    "id": "arXiv:2201.06126",
    "title": "Solving Inventory Management Problems with Inventory-dynamics-informed  Neural Networks",
    "abstract": "Comments: 35 pages, 5 figures",
    "descriptor": "\nComments: 35 pages, 5 figures\n",
    "authors": [
      "Lucas B\u00f6ttcher",
      "Thomas Asikis",
      "Ioannis Fragkos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.06126"
  },
  {
    "id": "arXiv:2201.06532",
    "title": "A New Look at Dynamic Regret for Non-Stationary Stochastic Bandits",
    "abstract": "A New Look at Dynamic Regret for Non-Stationary Stochastic Bandits",
    "descriptor": "",
    "authors": [
      "Yasin Abbasi-Yadkori",
      "Andras Gyorgy",
      "Nevena Lazic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.06532"
  },
  {
    "id": "arXiv:2201.07207",
    "title": "Language Models as Zero-Shot Planners: Extracting Actionable Knowledge  for Embodied Agents",
    "abstract": "Comments: Project website at this https URL",
    "descriptor": "\nComments: Project website at this https URL\n",
    "authors": [
      "Wenlong Huang",
      "Pieter Abbeel",
      "Deepak Pathak",
      "Igor Mordatch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.07207"
  },
  {
    "id": "arXiv:2201.08845",
    "title": "Point-NeRF: Point-based Neural Radiance Fields",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Qiangeng Xu",
      "Zexiang Xu",
      "Julien Philip",
      "Sai Bi",
      "Zhixin Shu",
      "Kalyan Sunkavalli",
      "Ulrich Neumann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08845"
  },
  {
    "id": "arXiv:2201.08959",
    "title": "Few-shot Object Counting with Similarity-Aware Feature Enhancement",
    "abstract": "Few-shot Object Counting with Similarity-Aware Feature Enhancement",
    "descriptor": "",
    "authors": [
      "Zhiyuan You",
      "Yujun Shen",
      "Kai Yang",
      "Wenhan Luo",
      "Xin Lu",
      "Lei Cui",
      "Xinyi Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08959"
  },
  {
    "id": "arXiv:2201.10460",
    "title": "Conditional entropy minimization principle for learning domain invariant  representation features",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Thuan Nguyen",
      "Boyang Lyu",
      "Prakash Ishwar",
      "Matthias Scheutz",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.10460"
  },
  {
    "id": "arXiv:2201.10633",
    "title": "Informative Path Planning to Estimate Quantiles for Environmental  Analysis",
    "abstract": "Comments: 8 pages, 7 figures",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Isabel M. Rayas Fern\u00e1ndez",
      "Christopher E. Denniston",
      "David A. Caron",
      "Gaurav S. Sukhatme"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.10633"
  },
  {
    "id": "arXiv:2201.10665",
    "title": "Writer Recognition Using Off-line Handwritten Single Block Characters",
    "abstract": "Comments: Accepted for publication at IEEE International Workshop on Biometrics and Forensics IWBF 2022",
    "descriptor": "\nComments: Accepted for publication at IEEE International Workshop on Biometrics and Forensics IWBF 2022\n",
    "authors": [
      "Adrian Leo Hagstr\u00f6m",
      "Rustam Stanikzai",
      "Josef Bigun",
      "Fernando Alonso-Fernandez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.10665"
  },
  {
    "id": "arXiv:2201.10705",
    "title": "Learning to Recommend Method Names with Global Context",
    "abstract": "Comments: Accepted for publication at ICSE 2022",
    "descriptor": "\nComments: Accepted for publication at ICSE 2022\n",
    "authors": [
      "Fang Liu",
      "Ge Li",
      "Zhiyi Fu",
      "Shuai Lu",
      "Yiyang Hao",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.10705"
  },
  {
    "id": "arXiv:2201.10865",
    "title": "On the Issues of TrueDepth Sensor Data for Computer Vision Tasks Across  Different iPad Generations",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Steffen Urban",
      "Thomas Lindemeier",
      "David Dobbelstein",
      "Matthias Haenel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.10865"
  },
  {
    "id": "arXiv:2201.12414",
    "title": "Any Variational Autoencoder Can Do Arbitrary Conditioning",
    "abstract": "Any Variational Autoencoder Can Do Arbitrary Conditioning",
    "descriptor": "",
    "authors": [
      "Ryan R. Strauss",
      "Junier B. Oliva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12414"
  },
  {
    "id": "arXiv:2201.12769",
    "title": "MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale  Point Clouds",
    "abstract": "MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale  Point Clouds",
    "descriptor": "",
    "authors": [
      "Chuanyu Luo",
      "Xiaohan Li",
      "Nuo Cheng",
      "Han Li",
      "Shengguang Lei",
      "Pu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12769"
  },
  {
    "id": "arXiv:2202.01332",
    "title": "Training a Bidirectional GAN-based One-Class Classifier for Network  Intrusion Detection",
    "abstract": "Comments: 16 pages, 8 figures",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Wen Xu",
      "Julian Jang-Jaccard",
      "Tong Liu",
      "Fariza Sabrina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01332"
  },
  {
    "id": "arXiv:2202.01426",
    "title": "Interleaving Monte Carlo Tree Search and Self-Supervised Learning for  Object Retrieval in Clutter",
    "abstract": "Comments: Accepted for ICRA 2022",
    "descriptor": "\nComments: Accepted for ICRA 2022\n",
    "authors": [
      "Baichuan Huang",
      "Teng Guo",
      "Abdeslam Boularias",
      "Jingjin Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01426"
  },
  {
    "id": "arXiv:2202.01694",
    "title": "Variational Nearest Neighbor Gaussian Processes",
    "abstract": "Variational Nearest Neighbor Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Luhuan Wu",
      "Geoff Pleiss",
      "John Cunningham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01694"
  },
  {
    "id": "arXiv:2202.01862",
    "title": "Practical Imitation Learning in the Real World via Task Consistency Loss",
    "abstract": "Practical Imitation Learning in the Real World via Task Consistency Loss",
    "descriptor": "",
    "authors": [
      "Mohi Khansari",
      "Daniel Ho",
      "Yuqing Du",
      "Armando Fuentes",
      "Matthew Bennice",
      "Nicolas Sievers",
      "Sean Kirmani",
      "Yunfei Bai",
      "Eric Jang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01862"
  },
  {
    "id": "arXiv:2202.02149",
    "title": "Edge-Selective Feature Weaving for Point Cloud Matching",
    "abstract": "Edge-Selective Feature Weaving for Point Cloud Matching",
    "descriptor": "",
    "authors": [
      "Rintaro Yanagi",
      "Atsushi Hashimoto",
      "Shusaku Sone",
      "Naoya Chiba",
      "Jiaxin Ma",
      "Yoshitaka Ushiku"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02149"
  },
  {
    "id": "arXiv:2202.02397",
    "title": "Textured Mesh Quality Assessment: Large-Scale Dataset and Deep  Learning-based Quality Metric",
    "abstract": "Textured Mesh Quality Assessment: Large-Scale Dataset and Deep  Learning-based Quality Metric",
    "descriptor": "",
    "authors": [
      "Yana Nehm\u00e9",
      "Florent Dupont",
      "Jean-Philippe Farrugia",
      "Patrick Le Callet",
      "Guillaume Lavou\u00e9"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.02397"
  },
  {
    "id": "arXiv:2202.04129",
    "title": "Independent Policy Gradient for Large-Scale Markov Potential Games:  Sharper Rates, Function Approximation, and Game-Agnostic Convergence",
    "abstract": "Comments: 72 pages, 6 figures; Theorem 1 and Theorem 2 are improved by using $\\tilde{\\kappa}_\\mu$, a minimax variant of distribution mismatch coefficient $\\kappa_\\mu$; the existence of an algorithm that enjoys finite-time best-iterate convergence in both competitive and cooperative Markov games is answered in Theorem 6",
    "descriptor": "\nComments: 72 pages, 6 figures; Theorem 1 and Theorem 2 are improved by using $\\tilde{\\kappa}_\\mu$, a minimax variant of distribution mismatch coefficient $\\kappa_\\mu$; the existence of an algorithm that enjoys finite-time best-iterate convergence in both competitive and cooperative Markov games is answered in Theorem 6\n",
    "authors": [
      "Dongsheng Ding",
      "Chen-Yu Wei",
      "Kaiqing Zhang",
      "Mihailo R. Jovanovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04129"
  },
  {
    "id": "arXiv:2202.06449",
    "title": "Notes on BIM and BFM Optimal Power Flow With Parallel Lines and Total  Current Limits",
    "abstract": "Comments: 5 pages; to be published in 2022 IEEE Power and Energy Society General Meeting Proceedings",
    "descriptor": "\nComments: 5 pages; to be published in 2022 IEEE Power and Energy Society General Meeting Proceedings\n",
    "authors": [
      "Frederik Geth",
      "Bin Liu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.06449"
  },
  {
    "id": "arXiv:2202.08549",
    "title": "Oracle-Efficient Online Learning for Beyond Worst-Case Adversaries",
    "abstract": "Comments: Under submission",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Nika Haghtalab",
      "Yanjun Han",
      "Abhishek Shetty",
      "Kunhe Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08549"
  },
  {
    "id": "arXiv:2202.09741",
    "title": "Visual Attention Network",
    "abstract": "Comments: Code is available at this https URL",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Meng-Hao Guo",
      "Cheng-Ze Lu",
      "Zheng-Ning Liu",
      "Ming-Ming Cheng",
      "Shi-Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09741"
  },
  {
    "id": "arXiv:2202.11042",
    "title": "FASURA: A Scheme for Quasi-Static Massive MIMO Unsourced Random Access  Channels",
    "abstract": "FASURA: A Scheme for Quasi-Static Massive MIMO Unsourced Random Access  Channels",
    "descriptor": "",
    "authors": [
      "Michail Gkagkos",
      "Krishna R. Narayanan",
      "Jean-Francois Chamberland",
      "Costas N. Georghiades"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.11042"
  },
  {
    "id": "arXiv:2202.11684",
    "title": "MuMiN: A Large-Scale Multilingual Multimodal Fact-Checked Misinformation  Social Network Dataset",
    "abstract": "Comments: 9+3 pages",
    "descriptor": "\nComments: 9+3 pages\n",
    "authors": [
      "Dan Saattrup Nielsen",
      "Ryan McConville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.11684"
  },
  {
    "id": "arXiv:2202.12154",
    "title": "Towards Effective and Robust Neural Trojan Defenses via Input Filtering",
    "abstract": "Towards Effective and Robust Neural Trojan Defenses via Input Filtering",
    "descriptor": "",
    "authors": [
      "Kien Do",
      "Haripriya Harikumar",
      "Hung Le",
      "Dung Nguyen",
      "Truyen Tran",
      "Santu Rana",
      "Dang Nguyen",
      "Willy Susilo",
      "Svetha Venkatesh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12154"
  },
  {
    "id": "arXiv:2202.12403",
    "title": "Learning Transferable Reward for Query Object Localization with Policy  Adaptation",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Tingfeng Li",
      "Shaobo Han",
      "Martin Renqiang Min",
      "Dimitris N. Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12403"
  },
  {
    "id": "arXiv:2202.12498",
    "title": "Diffeomorphic Image Registration with Neural Velocity Field",
    "abstract": "Diffeomorphic Image Registration with Neural Velocity Field",
    "descriptor": "",
    "authors": [
      "Kun Han",
      "Shanlin Sun",
      "Hao Tang",
      "Deying Kong",
      "Xiangyi Yan",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12498"
  },
  {
    "id": "arXiv:2202.12535",
    "title": "Break Up the Pipeline Structure to Reach a Nearly Optimal End-to-End  Latency",
    "abstract": "Break Up the Pipeline Structure to Reach a Nearly Optimal End-to-End  Latency",
    "descriptor": "",
    "authors": [
      "Junyi Zhao",
      "Yihan Gao"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.12535"
  },
  {
    "id": "arXiv:2202.12986",
    "title": "Extracting Effective Subnetworks with Gumebel-Softmax",
    "abstract": "Comments: 5 pages, 1 table",
    "descriptor": "\nComments: 5 pages, 1 table\n",
    "authors": [
      "Robin Dupont",
      "Mohammed Amine Alaoui",
      "Hichem Sahbi",
      "Alice Lebois"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12986"
  },
  {
    "id": "arXiv:2202.13785",
    "title": "CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge  Graph Completion",
    "abstract": "Comments: The full version of a long paper accepted to ACL 2022 main conference",
    "descriptor": "\nComments: The full version of a long paper accepted to ACL 2022 main conference\n",
    "authors": [
      "Guanglin Niu",
      "Bo Li",
      "Yongfei Zhang",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.13785"
  },
  {
    "id": "arXiv:2203.00193",
    "title": "EPPAC: Entity Pre-typing Relation Classification with Prompt  AnswerCentralizing",
    "abstract": "Comments: There are errors in experimental results",
    "descriptor": "\nComments: There are errors in experimental results\n",
    "authors": [
      "Jiejun Tan",
      "Wenbin Hu",
      "WeiWei Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.00193"
  },
  {
    "id": "arXiv:2203.00812",
    "title": "Efficient Dynamic Clustering: Capturing Patterns from Historical Cluster  Evolution",
    "abstract": "Efficient Dynamic Clustering: Capturing Patterns from Historical Cluster  Evolution",
    "descriptor": "",
    "authors": [
      "Binbin Gu",
      "Saeed Kargar",
      "Faisal Nawab"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.00812"
  },
  {
    "id": "arXiv:2203.00829",
    "title": "Personalized Federated Learning With Structure",
    "abstract": "Personalized Federated Learning With Structure",
    "descriptor": "",
    "authors": [
      "Fengwen Chen",
      "Guodong Long",
      "Zonghan Wu",
      "Tianyi Zhou",
      "Jing Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.00829"
  },
  {
    "id": "arXiv:2203.00911",
    "title": "Towards Bidirectional Arbitrary Image Rescaling: Joint Optimization and  Cycle Idempotence",
    "abstract": "Comments: To appear at CVPR 2022",
    "descriptor": "\nComments: To appear at CVPR 2022\n",
    "authors": [
      "Zhihong Pan",
      "Baopu Li",
      "Dongliang He",
      "Mingde Yao",
      "Wenhao Wu",
      "Tianwei Lin",
      "Xin Li",
      "Errui Ding"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.00911"
  },
  {
    "id": "arXiv:2203.01063",
    "title": "Discontinuous Constituency and BERT: A Case Study of Dutch",
    "abstract": "Comments: 8 pages plus references. To appear in Findings of the Association for Computational Linguistics 2022",
    "descriptor": "\nComments: 8 pages plus references. To appear in Findings of the Association for Computational Linguistics 2022\n",
    "authors": [
      "Konstantinos Kogkalidis",
      "Gijs Wijnholds"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01063"
  },
  {
    "id": "arXiv:2203.01300",
    "title": "BGG sequences with weak regularity and applications",
    "abstract": "Comments: 26 pages, comments welcome",
    "descriptor": "\nComments: 26 pages, comments welcome\n",
    "authors": [
      "Andreas \u010cap",
      "Kaibo Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Differential Geometry (math.DG)",
      "Functional Analysis (math.FA)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2203.01300"
  },
  {
    "id": "arXiv:2203.01302",
    "title": "Evolving Curricula with Regret-Based Environment Design",
    "abstract": "Comments: First two authors contributed equally",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Jack Parker-Holder",
      "Minqi Jiang",
      "Michael Dennis",
      "Mikayel Samvelyan",
      "Jakob Foerster",
      "Edward Grefenstette",
      "Tim Rockt\u00e4schel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01302"
  },
  {
    "id": "arXiv:2203.01426",
    "title": "SPICEprop: Backpropagating Errors Through Memristive Spiking Neural  Networks",
    "abstract": "SPICEprop: Backpropagating Errors Through Memristive Spiking Neural  Networks",
    "descriptor": "",
    "authors": [
      "Peng Zhou",
      "Jason K. Eshraghian",
      "Dong-Uk Choi",
      "Sung-Mo Kang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2203.01426"
  },
  {
    "id": "arXiv:2203.01786",
    "title": "Generative Modeling for Low Dimensional Speech Attributes with Neural  Spline Flows",
    "abstract": "Comments: 22 pages, 11 figures, 3 tables",
    "descriptor": "\nComments: 22 pages, 11 figures, 3 tables\n",
    "authors": [
      "Kevin J. Shih",
      "Rafael Valle",
      "Rohan Badlani",
      "Jo\u00e3o Felipe Santos",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.01786"
  },
  {
    "id": "arXiv:2203.01870",
    "title": "KamNet: An Integrated Spatiotemporal Deep Neural Network for Rare Event  Search in KamLAND-Zen",
    "abstract": "Comments: 12 pages, dual submission with upcoming KamLAND-Zen 800 main result",
    "descriptor": "\nComments: 12 pages, dual submission with upcoming KamLAND-Zen 800 main result\n",
    "authors": [
      "A. Li",
      "Z. Fu",
      "L. Winslow",
      "C. Grant",
      "H. Song",
      "H. Ozaki",
      "I. Shimizu",
      "A. Takeuchi"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01870"
  },
  {
    "id": "arXiv:2203.01923",
    "title": "Recovering 3D Human Mesh from Monocular Images: A Survey",
    "abstract": "Comments: Survey paper on monocular 3D human mesh recovery, Project page: this https URL",
    "descriptor": "\nComments: Survey paper on monocular 3D human mesh recovery, Project page: this https URL\n",
    "authors": [
      "Yating Tian",
      "Hongwen Zhang",
      "Yebin Liu",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.01923"
  },
  {
    "id": "arXiv:2203.02471",
    "title": "Graph clustering with Boltzmann machines",
    "abstract": "Graph clustering with Boltzmann machines",
    "descriptor": "",
    "authors": [
      "Pierre Miasnikof",
      "Mohammad Bagherbeik",
      "Ali Sheikholeslami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.02471"
  },
  {
    "id": "arXiv:2203.02591",
    "title": "A Small Gain Analysis of Single Timescale Actor Critic",
    "abstract": "A Small Gain Analysis of Single Timescale Actor Critic",
    "descriptor": "",
    "authors": [
      "Alex Olshevsky",
      "Bahman Gharesifard"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.02591"
  },
  {
    "id": "arXiv:2203.02689",
    "title": "Federated and Generalized Person Re-identification through Domain and  Feature Hallucinating",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Fengxiang Yang",
      "Zhun Zhong",
      "Zhiming Luo",
      "Shaozi Li",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02689"
  },
  {
    "id": "arXiv:2203.02704",
    "title": "Reconfigurable Intelligent Surface-Aided Joint Radar and Covert  Communications: Fundamentals, Optimization, and Challenges",
    "abstract": "Reconfigurable Intelligent Surface-Aided Joint Radar and Covert  Communications: Fundamentals, Optimization, and Challenges",
    "descriptor": "",
    "authors": [
      "Hongyang Du",
      "Jiawen Kang",
      "Dusit Niyato",
      "Jiayi Zhang",
      "Dong In Kim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.02704"
  },
  {
    "id": "arXiv:2203.02925",
    "title": "Weakly Supervised Temporal Action Localization via Representative  Snippet Knowledge Propagation",
    "abstract": "Comments: Accepted by CVPR 2022. Code is available at this https URL",
    "descriptor": "\nComments: Accepted by CVPR 2022. Code is available at this https URL\n",
    "authors": [
      "Linjiang Huang",
      "Liang Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02925"
  },
  {
    "id": "arXiv:2203.02932",
    "title": "Doctor Recommendation in Online Health Forums via Expertise Learning",
    "abstract": "Comments: Accepted to ACL 2022 main conference",
    "descriptor": "\nComments: Accepted to ACL 2022 main conference\n",
    "authors": [
      "Xiaoxin Lu",
      "Yubo Zhang",
      "Jing Li",
      "Shi Zong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.02932"
  },
  {
    "id": "arXiv:2203.03185",
    "title": "Covariate-Balancing-Aware Interpretable Deep Learning models for  Treatment Effect Estimation",
    "abstract": "Comments: 27 pages, 2 figures",
    "descriptor": "\nComments: 27 pages, 2 figures\n",
    "authors": [
      "Kan Chen",
      "Qishuo Yin",
      "Qi Long"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03185"
  },
  {
    "id": "arXiv:2203.03373",
    "title": "Adversarial Texture for Fooling Person Detectors in the Physical World",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Zhanhao Hu",
      "Siyuan Huang",
      "Xiaopei Zhu",
      "Xiaolin Hu",
      "Fuchun Sun",
      "Bo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03373"
  },
  {
    "id": "arXiv:2203.03426",
    "title": "Towards Managing Industrial Robot Fleets with Hyperledger Fabric  Blockchain and ROS 2",
    "abstract": "Comments: 8 Pages, 8 figures",
    "descriptor": "\nComments: 8 Pages, 8 figures\n",
    "authors": [
      "Salma Salimi",
      "Jorge Pe\u00f1a Queralta",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03426"
  },
  {
    "id": "arXiv:2203.03457",
    "title": "Graph Neural Networks for Image Classification and Reinforcement  Learning using Graph representations",
    "abstract": "Comments: The work was done as a project for Neural Networks and Deep Learning course, Fall 2021 offering by Prof. Richard Zemel at Columbia University",
    "descriptor": "\nComments: The work was done as a project for Neural Networks and Deep Learning course, Fall 2021 offering by Prof. Richard Zemel at Columbia University\n",
    "authors": [
      "Naman Goyal",
      "David Steiner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03457"
  },
  {
    "id": "arXiv:2203.03564",
    "title": "TIGGER: Scalable Generative Modelling for Temporal Interaction Graphs",
    "abstract": "Comments: To be published in AAAI-2022, additionally contains technical appendices/supplementary material",
    "descriptor": "\nComments: To be published in AAAI-2022, additionally contains technical appendices/supplementary material\n",
    "authors": [
      "Shubham Gupta",
      "Sahil Manchanda",
      "Srikanta Bedathur",
      "Sayan Ranu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.03564"
  }
]
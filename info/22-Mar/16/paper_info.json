[
  {
    "id": "arXiv:2203.07372",
    "title": "Enhancing crowd flow prediction in various spatial and temporal  granularities",
    "abstract": "Thanks to the diffusion of the Internet of Things, nowadays it is possible to\nsense human mobility almost in real time using unconventional methods (e.g.,\nnumber of bikes in a bike station). Due to the diffusion of such technologies,\nthe last years have witnessed a significant growth of human mobility studies,\nmotivated by their importance in a wide range of applications, from traffic\nmanagement to public security and computational epidemiology. A mobility task\nthat is becoming prominent is crowd flow prediction, i.e., forecasting\naggregated incoming and outgoing flows in the locations of a geographic region.\nAlthough several deep learning approaches have been proposed to solve this\nproblem, their usage is limited to specific types of spatial tessellations and\ncannot provide sufficient explanations of their predictions. We propose\nCrowdNet, a solution to crowd flow prediction based on graph convolutional\nnetworks. Compared with state-of-the-art solutions, CrowdNet can be used with\nregions of irregular shapes and provide meaningful explanations of the\npredicted crowd flows. We conduct experiments on public data varying the\nspatio-temporal granularity of crowd flows to show the superiority of our model\nwith respect to existing methods, and we investigate CrowdNet's reliability to\nmissing or noisy input data. Our model is a step forward in the design of\nreliable deep learning models to predict and explain human displacements in\nurban environments.",
    "descriptor": "",
    "authors": [
      "Marco Cardia",
      "Massimiliano Luca",
      "Luca Pappalardo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07372"
  },
  {
    "id": "arXiv:2203.07374",
    "title": "Automated fault tree learning from continuous-valued sensor data: a case  study on domestic heaters",
    "abstract": "Many industrial sectors have been collecting big sensor data. With recent\ntechnologies for processing big data, companies can exploit this for automatic\nfailure detection and prevention. We propose the first completely automated\nmethod for failure analysis, machine-learning fault trees from raw\nobservational data with continuous variables. Our method scales well and is\ntested on a real-world, five-year dataset of domestic heater operations in The\nNetherlands, with 31 million unique heater-day readings, each containing 27\nsensor and 11 failure variables. Our method builds on two previous procedures:\nthe C4.5 decision-tree learning algorithm, and the LIFT fault tree learning\nalgorithm from Boolean data. C4.5 pre-processes each continuous variable: it\nlearns an optimal numerical threshold which distinguishes between faulty and\nnormal operation of the top-level system. These thresholds discretise the\nvariables, thus allowing LIFT to learn fault trees which model the root failure\nmechanisms of the system and are explainable. We obtain fault trees for the 11\nfailure variables, and evaluate them in two ways: quantitatively, with a\nsignificance score, and qualitatively, with domain specialists. Some of the\nfault trees learnt have almost maximum significance (above 0.95), while others\nhave medium-to-low significance (around 0.30), reflecting the difficulty of\nlearning from big, noisy, real-world sensor data. The domain specialists\nconfirm that the fault trees model meaningful relationships among the\nvariables.",
    "descriptor": "\nComments: Preprint submitted to the International Journal of Prognostics and Health Management - March 2022\n",
    "authors": [
      "Bart Verkuil",
      "Carlos E. Budde",
      "Doina Bucur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07374"
  },
  {
    "id": "arXiv:2203.07375",
    "title": "From Big to Small: Adaptive Learning to Partial-Set Domains",
    "abstract": "Domain adaptation targets at knowledge acquisition and dissemination from a\nlabeled source domain to an unlabeled target domain under distribution shift.\nStill, the common requirement of identical class space shared across domains\nhinders applications of domain adaptation to partial-set domains. Recent\nadvances show that deep pre-trained models of large scale endow rich knowledge\nto tackle diverse downstream tasks of small scale. Thus, there is a strong\nincentive to adapt models from large-scale domains to small-scale domains. This\npaper introduces Partial Domain Adaptation (PDA), a learning paradigm that\nrelaxes the identical class space assumption to that the source class space\nsubsumes the target class space. First, we present a theoretical analysis of\npartial domain adaptation, which uncovers the importance of estimating the\ntransferable probability of each class and each instance across domains. Then,\nwe propose Selective Adversarial Network (SAN and SAN++) with a bi-level\nselection strategy and an adversarial adaptation mechanism. The bi-level\nselection strategy up-weighs each class and each instance simultaneously for\nsource supervised training, target self-training, and source-target adversarial\nadaptation through the transferable probability estimated alternately by the\nmodel. Experiments on standard partial-set datasets and more challenging tasks\nwith superclasses show that SAN++ outperforms several domain adaptation\nmethods.",
    "descriptor": "\nComments: accepted to TPAMI in 2022\n",
    "authors": [
      "Zhangjie Cao",
      "Kaichao You",
      "Ziyang Zhang",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07375"
  },
  {
    "id": "arXiv:2203.07376",
    "title": "HIE-SQL: History Information Enhanced Network for Context-Dependent  Text-to-SQL Semantic Parsing",
    "abstract": "Recently, context-dependent text-to-SQL semantic parsing which translates\nnatural language into SQL in an interaction process has attracted a lot of\nattention. Previous works leverage context-dependence information either from\ninteraction history utterances or the previous predicted SQL queries but fail\nin taking advantage of both since of the mismatch between natural language and\nlogic-form SQL. In this work, we propose a History Information Enhanced\ntext-to-SQL model (HIE-SQL) to exploit context-dependence information from both\nhistory utterances and the last predicted SQL query. In view of the mismatch,\nwe treat natural language and SQL as two modalities and propose a bimodal\npre-trained model to bridge the gap between them. Besides, we design a\nschema-linking graph to enhance connections from utterances and the SQL query\nto the database schema. We show our history information enhanced methods\nimprove the performance of HIE-SQL by a significant margin, which achieves new\nstate-of-the-art results on the two context-dependent text-to-SQL benchmarks,\nthe SparC and CoSQL datasets, at the writing time.",
    "descriptor": "",
    "authors": [
      "Yanzhao Zheng",
      "Haibin Wang",
      "Baohua Dong",
      "Xingjun Wang",
      "Changshan Li"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07376"
  },
  {
    "id": "arXiv:2203.07379",
    "title": "Quantitative Gaussian Approximation of Randomly Initialized Deep Neural  Networks",
    "abstract": "Given any deep fully connected neural network, initialized with random\nGaussian parameters, we bound from above the quadratic Wasserstein distance\nbetween its output distribution and a suitable Gaussian process. Our explicit\ninequalities indicate how the hidden and output layers sizes affect the\nGaussian behaviour of the network and quantitatively recover the distributional\nconvergence results in the wide limit, i.e., if all the hidden layers sizes\nbecome large.",
    "descriptor": "",
    "authors": [
      "Andrea Basteri",
      "Dario Trevisan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.07379"
  },
  {
    "id": "arXiv:2203.07390",
    "title": "There's no difference: Convolutional Neural Networks for transient  detection without template subtraction",
    "abstract": "We present a Convolutional Neural Network (CNN) model for the separation of\nastrophysical transients from image artifacts, a task known as \"real-bogus\"\nclassification, that does not rely on Difference Image Analysis (DIA) which is\na computationally expensive process involving image matching on small spatial\nscales in large volumes of data. We explore the use of CNNs to (1) automate the\n\"real-bogus\" classification, (2) reduce the computational costs of transient\ndiscovery. We compare the efficiency of two CNNs with similar architectures,\none that uses \"image triplets\" (templates, search, and the corresponding\ndifference image) and one that adopts a similar architecture but takes as input\nthe template and search only. Without substantially changing the model\narchitecture or retuning the hyperparameters to the new input, we observe only\na small decrease in model efficiency (97% to 92% accuracy). We further\ninvestigate how the model that does not receive the difference image learns the\nrequired information from the template and search by exploring the saliency\nmaps. Our work demonstrates that (1) CNNs are excellent models for \"real-bogus\"\nclassification that rely exclusively on the imaging data and require no feature\nengineering task; (2) high-accuracy models can be built without the need to\nconstruct difference images. Since once trained, neural networks can generate\npredictions at minimal computational costs, we argue that future\nimplementations of this methodology could dramatically reduce the computational\ncosts in the detection of genuine transients in synoptic surveys like Rubin\nObservatory's Legacy Survey of Space and Time by bypassing the DIA step\nentirely.",
    "descriptor": "",
    "authors": [
      "Tatiana Acero-Cuellar",
      "Federica Bianco",
      "Gregory Dobler",
      "Masao Sako",
      "Helen Qu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2203.07390"
  },
  {
    "id": "arXiv:2203.07401",
    "title": "Multi-Parameter Analysis of Finding Minors and Subgraphs in Edge  Periodic Temporal Graphs",
    "abstract": "We study the computational complexity of determining structural properties of\nedge periodic temporal graphs (EPGs). EPGs are time-varying graphs that\ncompactly represent periodic behavior of components of a dynamic network, for\nexample, train schedules on a rail network. In EPGs, for each edge $e$ of the\ngraph, a binary string $s_e$ determines in which time steps the edge is\npresent, namely $e$ is present in time step $t$ if and only if $s_e$ contains a\n$1$ at position $t \\mod |s_e|$. Due to this periodicity, EPGs serve as very\ncompact representations of complex periodic systems and can even be\nexponentially smaller than classic temporal graphs representing one period of\nthe same system, as the latter contain the whole sequence of graphs explicitly.\nIn this paper, we study the computational complexity of fundamental questions\nof the new concept of EPGs such as what is the shortest traversal time between\ntwo vertices; is there a time step in which the graph (1) is minor-free; (2)\ncontains a minor; (3) is subgraph-free; (4) contains a subgraph; with respect\nto a given minor or subgraph. We give a detailed parameterized analysis for\nmultiple combinations of parameters for the problems stated above including\nseveral parameterized algorithms.",
    "descriptor": "",
    "authors": [
      "Emmanuel Arrighi",
      "Niels Gr\u00fcttemeier",
      "Nils Morawietz",
      "Frank Sommer",
      "Petra Wolf"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.07401"
  },
  {
    "id": "arXiv:2203.07402",
    "title": "Revisiting the Compositional Generalization Abilities of Neural Sequence  Models",
    "abstract": "Compositional generalization is a fundamental trait in humans, allowing us to\neffortlessly combine known phrases to form novel sentences. Recent works have\nclaimed that standard seq-to-seq models severely lack the ability to\ncompositionally generalize. In this paper, we focus on one-shot primitive\ngeneralization as introduced by the popular SCAN benchmark. We demonstrate that\nmodifying the training distribution in simple and intuitive ways enables\nstandard seq-to-seq models to achieve near-perfect generalization performance,\nthereby showing that their compositional generalization abilities were\npreviously underestimated. We perform detailed empirical analysis of this\nphenomenon. Our results indicate that the generalization performance of models\nis highly sensitive to the characteristics of the training data which should be\ncarefully considered while designing such benchmarks in future.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Arkil Patel",
      "Satwik Bhattamishra",
      "Phil Blunsom",
      "Navin Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07402"
  },
  {
    "id": "arXiv:2203.07404",
    "title": "Respecting causality is all you need for training physics-informed  neural networks",
    "abstract": "While the popularity of physics-informed neural networks (PINNs) is steadily\nrising, to this date PINNs have not been successful in simulating dynamical\nsystems whose solution exhibits multi-scale, chaotic or turbulent behavior. In\nthis work we attribute this shortcoming to the inability of existing PINNs\nformulations to respect the spatio-temporal causal structure that is inherent\nto the evolution of physical systems. We argue that this is a fundamental\nlimitation and a key source of error that can ultimately steer PINN models to\nconverge towards erroneous solutions. We address this pathology by proposing a\nsimple re-formulation of PINNs loss functions that can explicitly account for\nphysical causality during model training. We demonstrate that this simple\nmodification alone is enough to introduce significant accuracy improvements, as\nwell as a practical quantitative mechanism for assessing the convergence of a\nPINNs model. We provide state-of-the-art numerical results across a series of\nbenchmarks for which existing PINNs formulations fail, including the chaotic\nLorenz system, the Kuramoto-Sivashinsky equation in the chaotic regime, and the\nNavier-Stokes equations in the turbulent regime. To the best of our knowledge,\nthis is the first time that PINNs have been successful in simulating such\nsystems, introducing new opportunities for their applicability to problems of\nindustrial complexity.",
    "descriptor": "\nComments: 35 pages, 27 figures, 4 tables\n",
    "authors": [
      "Sifan Wang",
      "Shyam Sankaran",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Chaotic Dynamics (nlin.CD)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.07404"
  },
  {
    "id": "arXiv:2203.07407",
    "title": "Computational Complexity of Multi-Player Evolutionarily Stable  Strategies",
    "abstract": "In this paper we study the computational complexity of computing an\nevolutionary stable strategy (ESS) in multi-player symmetric games. For\ntwo-player games, deciding existence of an ESS is complete for {\\Sigma} 2 , the\nsecond level of the polynomial time hierarchy. We show that deciding existence\nof an ESS of a multi-player game is closely connected to the second level of\nthe real polynomial time hierarchy. Namely, we show that the problem is hard\nfor a complexity class we denote as \\exists D . \\forall R and is a member of\n\\exists\\forall R, where the former class restrict the latter by having the\nexistentially quantified variables be Boolean rather then real-valued. As a\nspecial case of our results it follows that deciding whether a given strategy\nis an ESS is complete for \\forall R. A concept strongly related to ESS is that\nof a locally superior strategy (LSS). We extend our results about ESS and show\nthat deciding existence of an LSS of a multiplayer game is likewise hard for\n\\exists D \\forall R and a member of \\exists\\forall R, and as a special case\nthat deciding whether a given strategy is an LSS is complete for \\forall R.",
    "descriptor": "",
    "authors": [
      "Manon Blanc",
      "Kristoffer Arnsfelt Hansen"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.07407"
  },
  {
    "id": "arXiv:2203.07411",
    "title": "On Connecting Deep Trigonometric Networks with Deep Gaussian Processes:  Covariance, Expressivity, and Neural Tangent Kernel",
    "abstract": "Deep Gaussian Process as a Bayesian learning model is promising because it is\nexpressive and capable of uncertainty estimation. With Bochner's theorem, we\ncan view the deep Gaussian process with squared exponential kernels as a deep\ntrigonometric network consisting of the random feature layers, sine and cosine\nactivation units, and random weight layers. Focusing on this particular class\nof models allows us to obtain analytical results. We shall show that the weight\nspace view yields the same effective covariance functions which were obtained\npreviously in function space. The heavy statistical tails can be studied with\nmultivariate characteristic function. In addition, the trig networks are\nflexible and expressive as one can freely adopt different prior distributions\nover the parameters in weight and feature layers. Lastly, the deep\ntrigonometric network representation of deep Gaussian process allows the\nderivation of its neural tangent kernel, which can reveal the mean of\npredictive distribution from the intractable inference.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Chi-Ken Lu",
      "Patrick Shafto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.07411"
  },
  {
    "id": "arXiv:2203.07413",
    "title": "Switch Trajectory Transformer with Distributional Value Approximation  for Multi-Task Reinforcement Learning",
    "abstract": "We propose SwitchTT, a multi-task extension to Trajectory Transformer but\nenhanced with two striking features: (i) exploiting a sparsely activated model\nto reduce computation cost in multi-task offline model learning and (ii)\nadopting a distributional trajectory value estimator that improves policy\nperformance, especially in sparse reward settings. These two enhancements make\nSwitchTT suitable for solving multi-task offline reinforcement learning\nproblems, where model capacity is critical for absorbing the vast quantities of\nknowledge available in the multi-task dataset. More specifically, SwitchTT\nexploits switch transformer model architecture for multi-task policy learning,\nallowing us to improve model capacity without proportional computation cost.\nAlso, SwitchTT approximates the distribution rather than the expectation of\ntrajectory value, mitigating the effects of the Monte-Carlo Value estimator\nsuffering from poor sample complexity, especially in the sparse-reward setting.\nWe evaluate our method using the suite of ten sparse-reward tasks from the\ngym-mini-grid environment.We show an improvement of 10% over Trajectory\nTransformer across 10-task learning and obtain up to 90% increase in offline\nmodel training speed. Our results also demonstrate the advantage of the switch\ntransformer model for absorbing expert knowledge and the importance of value\ndistribution in evaluating the trajectory.",
    "descriptor": "",
    "authors": [
      "Qinjie Lin",
      "Han Liu",
      "Biswa Sengupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07413"
  },
  {
    "id": "arXiv:2203.07416",
    "title": "Refined Hardness of Distance-Optimal Multi-Agent Path Finding",
    "abstract": "We study the computational complexity of multi-agent path finding (MAPF).\nGiven a graph $G$ and a set of agents, each having a start and target vertex,\nthe goal is to find collision-free paths minimizing the total distance\ntraveled. To better understand the source of difficulty of the problem, we aim\nto study the simplest and least constrained graph class for which it remains\nhard. To this end, we restrict $G$ to be a 2D grid, which is a ubiquitous\nabstraction, as it conveniently allows for modeling well-structured\nenvironments (e.g., warehouses). Previous hardness results considered highly\nconstrained 2D grids having only one vertex unoccupied by an agent, while the\nmost restricted hardness result that allowed multiple empty vertices was for\n(non-grid) planar graphs. We therefore refine previous results by\nsimultaneously considering both 2D grids and multiple empty vertices. We show\nthat even in this case distance-optimal MAPF remains NP-hard, which settles an\nopen problem posed by Banfi et al. (2017). We present a reduction directly from\n3-SAT using simple gadgets, making our proof arguably more informative than\nprevious work in terms of potential progress towards positive results.\nFurthermore, our reduction is the first linear one for the case where $G$ is\nplanar, appearing nearly four decades after the first related result. This\nallows us to go a step further and exploit the Exponential Time Hypothesis\n(ETH) to obtain an exponential lower bound for the running time of the problem.\nFinally, as a stepping stone towards our main results, we prove the NP-hardness\nof the monotone case, in which agents move one by one with no intermediate\nstops.",
    "descriptor": "\nComments: Accepted to Autonomous Agents and Multi-Agent Systems (AAMAS 2022)\n",
    "authors": [
      "Tzvika Geft",
      "Dan Halperin"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computational Geometry (cs.CG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07416"
  },
  {
    "id": "arXiv:2203.07422",
    "title": "Bayesian-EUCLID: discovering hyperelastic material laws with  uncertainties",
    "abstract": "Within the scope of our recent approach for Efficient Unsupervised\nConstitutive Law Identification and Discovery (EUCLID), we propose an\nunsupervised Bayesian learning framework for discovery of parsimonious and\ninterpretable constitutive laws with quantifiable uncertainties. As in\ndeterministic EUCLID, we do not resort to stress data, but only to\nrealistically measurable full-field displacement and global reaction force\ndata; as opposed to calibration of an a priori assumed model, we start with a\nconstitutive model ansatz based on a large catalog of candidate functional\nfeatures; we leverage domain knowledge by including features based on existing,\nboth physics-based and phenomenological, constitutive models. In the new\nBayesian-EUCLID approach, we use a hierarchical Bayesian model with\nsparsity-promoting priors and Monte Carlo sampling to efficiently solve the\nparsimonious model selection task and discover physically consistent\nconstitutive equations in the form of multivariate multi-modal probabilistic\ndistributions. We demonstrate the ability to accurately and efficiently recover\nisotropic and anisotropic hyperelastic models like the Neo-Hookean, Isihara,\nGent-Thomas, Arruda-Boyce, Ogden, and Holzapfel models in both elastostatics\nand elastodynamics. The discovered constitutive models are reliable under both\nepistemic uncertainties - i.e. uncertainties on the true features of the\nconstitutive catalog - and aleatoric uncertainties - which arise from the noise\nin the displacement field data, and are automatically estimated by the\nhierarchical Bayesian model.",
    "descriptor": "\nComments: 36 pages, 17 figures\n",
    "authors": [
      "Akshay Joshi",
      "Prakash Thakolkaran",
      "Yiwen Zheng",
      "Maxime Escande",
      "Moritz Flaschel",
      "Laura De Lorenzis",
      "Siddhant Kumar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.07422"
  },
  {
    "id": "arXiv:2203.07424",
    "title": "Hercules: Heterogeneity-Aware Inference Serving for At-Scale  Personalized Recommendation",
    "abstract": "Personalized recommendation is an important class of deep-learning\napplications that powers a large collection of internet services and consumes a\nconsiderable amount of datacenter resources. As the scale of production-grade\nrecommendation systems continues to grow, optimizing their serving performance\nand efficiency in a heterogeneous datacenter is important and can translate\ninto infrastructure capacity saving. In this paper, we propose Hercules, an\noptimized framework for personalized recommendation inference serving that\ntargets diverse industry-representative models and cloud-scale heterogeneous\nsystems. Hercules performs a two-stage optimization procedure - offline\nprofiling and online serving. The first stage searches the large under-explored\ntask scheduling space with a gradient-based search algorithm achieving up to\n9.0x latency-bounded throughput improvement on individual servers; it also\nidentifies the optimal heterogeneous server architecture for each\nrecommendation workload. The second stage performs heterogeneity-aware cluster\nprovisioning to optimize resource mapping and allocation in response to\nfluctuating diurnal loads. The proposed cluster scheduler in Hercules achieves\n47.7% cluster capacity saving and reduces the provisioned power by 23.7% over a\nstate-of-the-art greedy scheduler.",
    "descriptor": "",
    "authors": [
      "Liu Ke",
      "Udit Gupta",
      "Mark Hempstead",
      "Carole-Jean Wu",
      "Hsien-Hsin S. Lee",
      "Xuan Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.07424"
  },
  {
    "id": "arXiv:2203.07425",
    "title": "Computational Perspective of the Fog Node",
    "abstract": "Fog computing is a recent computational paradigm that was proposed to solve\nsome weaknesses in cloud-based systems. For this reason, this technology has\nbeen extensively studied by several technology areas. It is still in a maturing\nstage, so there is no consensus in academia about its concepts and definitions,\nand each area adopts the ones that are convenient for each use case. This\narticle proposes a definition and a classification relying on a computational\nperspective for the fog node, which is a fundamental element in a fog computing\nenvironment. In addition, the main challenges related to the fog node are also\npresented.",
    "descriptor": "\nComments: Paper presented in the conference '2021 World Congress in Computer Science, Computer Engineering, & Applied Computing' (CSCE'21)\n",
    "authors": [
      "Jo\u00e3o Bachiega Jr",
      "Breno Costa",
      "Aleteia P. F. Araujo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.07425"
  },
  {
    "id": "arXiv:2203.07426",
    "title": "Sememe Prediction for BabelNet Synsets using Multilingual and Multimodal  Information",
    "abstract": "In linguistics, a sememe is defined as the minimum semantic unit of\nlanguages. Sememe knowledge bases (KBs), which are built by manually annotating\nwords with sememes, have been successfully applied to various NLP tasks.\nHowever, existing sememe KBs only cover a few languages, which hinders the wide\nutilization of sememes. To address this issue, the task of sememe prediction\nfor BabelNet synsets (SPBS) is presented, aiming to build a multilingual sememe\nKB based on BabelNet, a multilingual encyclopedia dictionary. By automatically\npredicting sememes for a BabelNet synset, the words in many languages in the\nsynset would obtain sememe annotations simultaneously. However, previous SPBS\nmethods have not taken full advantage of the abundant information in BabelNet.\nIn this paper, we utilize the multilingual synonyms, multilingual glosses and\nimages in BabelNet for SPBS. We design a multimodal information fusion model to\nencode and combine this information for sememe prediction. Experimental results\nshow the substantial outperformance of our model over previous methods (about\n10 MAP and F1 scores). All the code and data of this paper can be obtained at\nhttps://github.com/thunlp/MSGI.",
    "descriptor": "\nComments: Accepted by Findings of ACL 2022 as a long paper. Camera-ready version\n",
    "authors": [
      "Fanchao Qi",
      "Chuancheng Lv",
      "Zhiyuan Liu",
      "Xiaojun Meng",
      "Maosong Sun",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07426"
  },
  {
    "id": "arXiv:2203.07429",
    "title": "Bipedal Locomotion with Nonlinear Model Predictive Control: Online Gait  Generation using Whole-Body Dynamics",
    "abstract": "The ability to generate dynamic walking in real-time for bipedal robots with\ncompliance and underactuation has the potential to enable locomotion in complex\nand unstructured environments. Yet, the high-dimensional nature of bipedal\nrobots has limited the use of full-order rigid body dynamics to gaits which are\nsynthesized offline and then tracked online, e.g., via whole-body controllers.\nIn this work we develop an online nonlinear model predictive control approach\nthat leverages the full-order dynamics to realize diverse walking behaviors.\nAdditionally, this approach can be coupled with gaits synthesized offline via a\nterminal cost that enables a shorter prediction horizon; this makes rapid\nonline re-planning feasible and bridges the gap between online reactive control\nand offline gait planning. We demonstrate the proposed method on the planar\nrobot AMBER-3M, both in simulation and on hardware.",
    "descriptor": "\nComments: 8 pages, 6 figures, submitted to IROS 2022\n",
    "authors": [
      "Manuel Y. Galliker",
      "Noel Csomay-Shanklin",
      "Ruben Grandia",
      "Andrew J. Taylor",
      "Farbod Farshidian",
      "Marco Hutter",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07429"
  },
  {
    "id": "arXiv:2203.07430",
    "title": "$\\mathcal{H}_{\\infty}$-optimal Interval Observer Synthesis for Uncertain  Nonlinear Dynamical Systems via Mixed-Monotone Decompositions",
    "abstract": "This paper introduces a novel $\\mathcal{H}_{\\infty}$-optimal interval\nobserver synthesis for bounded-error/uncertain locally Lipschitz nonlinear\ncontinuous-time (CT) and discrete-time (DT) systems with noisy nonlinear\nobservations. Specifically, using mixed-monotone decompositions, the proposed\nobserver is correct by construction, i.e., the interval estimates readily frame\nthe true states without additional constraints or procedures. In addition, we\nprovide sufficient conditions for input-to-state (ISS) stability of the\nproposed observer and for minimizing the $\\mathcal{H}_{\\infty}$ gain of the\nframer error system in the form of semi-definite programs (SDPs) with Linear\nMatrix Inequalities (LMIs) constraints. Finally, we compare the performance of\nthe proposed $\\mathcal{H}_{\\infty}$-optimal interval observers with some\nbenchmark CT and DT interval observers.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Mohammad Khajenejad",
      "Sze Zheng Yong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.07430"
  },
  {
    "id": "arXiv:2203.07431",
    "title": "Conditional Contextual Refinement (CCR)",
    "abstract": "Contextual refinement (CR) is one of the standard notions of specifying open\nprograms. CR has two main advantages: (i) (horizontal and vertical)\ncompositionality that allows us to decompose a large contextual refinement into\nmany smaller ones enabling modular and incremental verification, and (ii) no\nrestriction on programming features thereby allowing, e.g., mutually recursive,\npointer-value passing, and higher-order functions. However, CR has a downside\nthat it cannot impose conditions on the context since it quantifies over all\ncontexts, which indeed plays a key role in support of full compositionality and\nprogramming features.\nIn this paper, we address the problem of finding a notion of refinement that\nsatisfies all three requirements: support of full compositionality, full\n(sequential) programming features, and rich conditions on the context. As a\nsolution, we propose a new theory of refinement, called CCR (Conditional\nContextual Refinement), and develop a verification framework based on it, which\nallows us to modularly and incrementally verify a concrete module against an\nabstract module under separation-logic-style pre and post conditions about\nexternal modules. It is fully formalized in Coq and provides a proof mode that\ncombines (i) simulation reasoning about preservation of sideffects such as IO\nevents and termination and (ii) propositional reasoning about pre and post\nconditions. Also, the verification results are combined with CompCert, so that\nwe formally establish behavioral refinement from top-level abstract programs,\nall the way down to their assembly code.",
    "descriptor": "",
    "authors": [
      "Youngju Song",
      "Minki Cho",
      "Dongjae Lee",
      "Chung-Kil Hur"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.07431"
  },
  {
    "id": "arXiv:2203.07433",
    "title": "Characterizing Reddit Participation of Users Who Engage in the QAnon  Conspiracy Theories",
    "abstract": "Widespread conspiracy theories may significantly impact our society. This\npaper focuses on the QAnon conspiracy theory, a consequential conspiracy theory\nthat started on and disseminated successfully through social media. Our work\ncharacterizes how Reddit users who have participated in QAnon-focused\nsubreddits engage in activities on the platform, especially outside their own\ncommunities. Using a large-scale Reddit moderation nation against QAnon-related\nactivities in 2018 as the source, we identified 13,000 users active in the\nearly QAnon communities. We collected the 2.1 million submissions and 10.8\nmillion comments posted by these users across all of Reddit from October 2016\nto January 2021. The majority of these users were only active after the\nemergence of the QAnon Conspiracy theory and decreased in activity after\nReddit's 2018 QAnon ban. A qualitative analysis of a sample of 915 subreddits\nwhere the \"QAnon-enthusiastic\" users were especially active shows that they\nparticipated in a diverse range of subreddits, often of unrelated topics to\nQAnon. However, most of the users' submissions were concentrated in subreddits\nthat have sympathetic attitudes towards the conspiracy theory, characterized by\ndiscussions that were pro-Trump, or emphasized unconstricted behavior (often\nanti-establishment and anti-interventionist). Further study of a sample of\n1,571 of these submissions indicates that most consist of links from\nlow-quality sources, bringing potential harm to the broader Reddit community.\nThese results point to the likelihood that the activities of early QAnon users\non Reddit were dedicated and committed to the conspiracy, providing\nimplications on both platform moderation design and future research.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Kristen Engel",
      "Yiqing Hua",
      "Taixiang Zeng",
      "Mor Naaman"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.07433"
  },
  {
    "id": "arXiv:2203.07436",
    "title": "Panoptic animal pose estimators are zero-shot performers",
    "abstract": "Animal pose estimation is critical in applications ranging from life science\nresearch, agriculture, to veterinary medicine. Compared to human pose\nestimation, the performance of animal pose estimation is limited by the size of\navailable datasets and the generalization of a model across datasets. Typically\ndifferent keypoints are labeled regardless of whether the species are the same\nor not, leaving animal pose datasets to have disjoint or partially overlapping\nkeypoints. As a consequence, a model cannot be used as a plug-and-play solution\nacross datasets. This reality motivates us to develop panoptic animal pose\nestimation models that are able to predict keypoints defined in all datasets.\nIn this work we propose a simple yet effective way to merge differentially\nlabeled datasets to obtain the largest quadruped and lab mouse pose dataset.\nUsing a gradient masking technique, so called SuperAnimal-models are able to\npredict keypoints that are distributed across datasets and exhibit strong\nzero-shot performance. The models can be further improved by (pseudo) labeled\nfine-tuning. These models outperform ImageNet-initialized models.",
    "descriptor": "",
    "authors": [
      "Shaokai Ye",
      "Alexander Mathis",
      "Mackenzie Weygandt Mathis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2203.07436"
  },
  {
    "id": "arXiv:2203.07437",
    "title": "Unsupervised Clustering of Roman Potsherds via Variational Autoencoders",
    "abstract": "In this paper we propose an artificial intelligence imaging solution to\nsupport archaeologists in the classification task of Roman commonware\npotsherds. Usually, each potsherd is represented by its sectional profile as a\ntwo dimensional black-white image and printed in archaeological books related\nto specific archaeological excavations. The partiality and handcrafted variance\nof the fragments make their matching a challenging problem: we propose to pair\nsimilar profiles via the unsupervised hierarchical clustering of non-linear\nfeatures learned in the latent space of a deep convolutional Variational\nAutoencoder (VAE) network. Our contribution also include the creation of a\nROman COmmonware POTtery (ROCOPOT) database, with more than 4000 potsherds\nprofiles extracted from 25 Roman pottery corpora, and a MATLAB GUI software for\nthe easy inspection of shape similarities. Results are commented both from a\nmathematical and archaeological perspective so as to unlock new research\ndirections in both communities.",
    "descriptor": "\nComments: 16 pages, 11 figures\n",
    "authors": [
      "Simone Parisotto",
      "Ninetta Leone",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Alessandro Launaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07437"
  },
  {
    "id": "arXiv:2203.07444",
    "title": "Minimum Partition into Plane Subgraphs: The CG:SHOP Challenge 2022",
    "abstract": "We give an overview of the 2022 Computational Geometry Challenge targeting\nthe problem Minimum Partition into Plane Subsets, which consists of\npartitioning a given set of line segments into a minimum number of non-crossing\nsubsets.",
    "descriptor": "\nComments: 13 pages, 5 figures, 1 table\n",
    "authors": [
      "S\u00e1ndor P. Fekete",
      "Phillip Keldenich",
      "Dominik Krupke",
      "Stefan Schirra"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.07444"
  },
  {
    "id": "arXiv:2203.07450",
    "title": "A Neural Pairwise Ranking Model for Readability Assessment",
    "abstract": "Automatic Readability Assessment (ARA), the task of assigning a reading level\nto a text, is traditionally treated as a classification problem in NLP\nresearch. In this paper, we propose the first neural, pairwise ranking approach\nto ARA and compare it with existing classification, regression, and\n(non-neural) ranking methods. We establish the performance of our model by\nconducting experiments with three English, one French and one Spanish datasets.\nWe demonstrate that our approach performs well in monolingual single/cross\ncorpus testing scenarios and achieves a zero-shot cross-lingual ranking\naccuracy of over 80% for both French and Spanish when trained on English data.\nAdditionally, we also release a new parallel bilingual readability dataset in\nEnglish and French. To our knowledge, this paper proposes the first neural\npairwise ranking model for ARA, and shows the first results of cross-lingual,\nzero-shot evaluation of ARA with neural models.",
    "descriptor": "\nComments: to appear in Findings of ACL 2022\n",
    "authors": [
      "Justin Lee",
      "Sowmya Vajjala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07450"
  },
  {
    "id": "arXiv:2203.07454",
    "title": "L2Explorer: A Lifelong Reinforcement Learning Assessment Environment",
    "abstract": "Despite groundbreaking progress in reinforcement learning for robotics,\ngameplay, and other complex domains, major challenges remain in applying\nreinforcement learning to the evolving, open-world problems often found in\ncritical application spaces. Reinforcement learning solutions tend to\ngeneralize poorly when exposed to new tasks outside of the data distribution\nthey are trained on, prompting an interest in continual learning algorithms. In\ntandem with research on continual learning algorithms, there is a need for\nchallenge environments, carefully designed experiments, and metrics to assess\nresearch progress. We address the latter need by introducing a framework for\ncontinual reinforcement-learning development and assessment using Lifelong\nLearning Explorer (L2Explorer), a new, Unity-based, first-person 3D exploration\nenvironment that can be continuously reconfigured to generate a range of tasks\nand task variants structured into complex and evolving evaluation curricula. In\ncontrast to procedurally generated worlds with randomized components, we have\ndeveloped a systematic approach to defining curricula in response to controlled\nchanges with accompanying metrics to assess transfer, performance recovery, and\ndata efficiency. Taken together, the L2Explorer environment and evaluation\napproach provides a framework for developing future evaluation methodologies in\nopen-world settings and rigorously evaluating approaches to lifelong learning.",
    "descriptor": "\nComments: 10 Pages submitted to AAAI AI for Open Worlds Symposium 2022\n",
    "authors": [
      "Erik C. Johnson",
      "Eric Q. Nguyen",
      "Blake Schreurs",
      "Chigozie S. Ewulum",
      "Chace Ashcraft",
      "Neil M. Fendley",
      "Megan M. Baker",
      "Alexander New",
      "Gautam K. Vallabha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07454"
  },
  {
    "id": "arXiv:2203.07456",
    "title": "Designing Underactuated Graspers with Dynamically Variable Geometry  Using Potential Energy Map Based Analysis",
    "abstract": "In this paper we present a potential energy map based approach that provides\na framework for the design and control of a robotic grasper. Unlike other\npotential energy map approaches, our framework is able to consider friction for\na more realistic perspective on grasper performance. Our analysis establishes\nthe importance of including variable geometry in a grasper design, namely with\nregards to palm width, link lengths, and transmission ratio. We demonstrate the\nuse of this method specifically for a two-phalanx tendon-pulley underactuated\ngrasper, and show how various design parameters - palm width, link lengths, and\ntransmission ratios - impact the grasping and manipulation performance of a\nspecific design across a range of object sizes and friction coefficients.\nOptimal grasping designs have palms that scale with object size, and\ntransmission ratios that scale with the coefficient of friction. Using a custom\nmanipulation metric we compared a grasper that only dynamically varied its\ngeometry to a grasper with a variable palm and distinct actuation commands. The\nanalysis revealed the advantage of the compliant reconfiguration ability\nintrinsic to underactuated mechanisms; by varying only the geometry of the\ngrasper, manipulation of a wide range of objects could be performed.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Connor L. Yako",
      "Shenli Yuan",
      "J. Kenneth Salisbury"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07456"
  },
  {
    "id": "arXiv:2203.07463",
    "title": "Simultaneous Learning of the Inputs and Parameters in Neural  Collaborative Filtering",
    "abstract": "Neural network-based collaborative filtering systems focus on designing\nnetwork architectures to learn better representations while fixing the input to\nthe user/item interaction vectors and/or ID. In this paper, we first show that\nthe non-zero elements of the inputs are learnable parameters that determine the\nweights in combining the user/item embeddings, and fixing them limits the power\nof the models in learning the representations. Then, we propose to learn the\nvalue of the non-zero elements of the inputs jointly with the neural network\nparameters. We analyze the model complexity and the empirical risk of our\napproach and prove that learning the input leads to a better generalization\nbound. Our experiments on several real-world datasets show that our method\noutperforms the state-of-the-art methods, even using shallow network structures\nwith a smaller number of layers and parameters.",
    "descriptor": "",
    "authors": [
      "Ramin Raziperchikolaei",
      "Young-joo Chung"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07463"
  },
  {
    "id": "arXiv:2203.07469",
    "title": "Quantum Information Elicitation",
    "abstract": "In the classic scoring rule setting, a principal incentivizes an agent to\ntruthfully report their probabilistic belief about some future outcome. This\npaper addresses the situation when this private belief, rather than a classical\nprobability distribution, is instead a quantum mixed state. In the resulting\nquantum scoring rule setting, the principal chooses both a scoring function and\na measurement function, and the agent responds with their reported density\nmatrix. Several characterizations of quantum scoring rules are presented, which\nreveal a familiar structure based on convex analysis. Spectral scores, where\nthe measurement function is given by the spectral decomposition of the reported\ndensity matrix, have particularly elegant structure and connect to quantum\ninformation theory. Turning to property elicitation, eigenvectors of the belief\nare elicitable, whereas eigenvalues and entropy have maximal elicitation\ncomplexity. The paper concludes with a discussion of other quantum information\nelicitation settings and connections to the literature.",
    "descriptor": "",
    "authors": [
      "Rafael Frongillo"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.07469"
  },
  {
    "id": "arXiv:2203.07471",
    "title": "Robust Dynamic Walking for a 3D Dual-SLIP Model under One-Step  Unilateral Stiffness Perturbations: Towards Bipedal Locomotion over Compliant  Terrain",
    "abstract": "Bipedal walking is one of the most important hallmarks of human that robots\nhave been trying to mimic for many decades. Although previous control\nmethodologies have achieved robot walking on some terrains, there is a need for\na framework allowing stable and robust locomotion over a wide range of\ncompliant surfaces. This work proposes a novel biomechanics-inspired controller\nthat adjusts the stiffness of the legs in support for robust and dynamic\nbipedal locomotion over compliant terrains. First, the 3D Dual-SLIP model is\nextended to support for the first time locomotion over compliant surfaces with\nvariable stiffness and damping parameters. Then, the proposed controller is\ncompared to a Linear-Quadratic Regulator (LQR) controller, in terms of\nrobustness on stepping on soft terrain. The LQR controller is shown to be\nrobust only up to a moderate ground stiffness level of 174 kN/m, while it fails\nin lower stiffness levels. On the contrary, the proposed controller can produce\nstable gait in stiffness levels as low as 30 kN/m, which results in a vertical\nground penetration of the leg that is deeper than 10% of its rest length. The\nproposed framework could advance the field of bipedal walking, by generating\nstable walking trajectories for a wide range of compliant terrains useful for\nthe control of bipeds and humanoids, as well as by improving controllers for\nprosthetic devices with tunable stiffness.",
    "descriptor": "\nComments: This work has been submitted to the 30th Mediterranean Conference on Control and Automation, MED'22 for publication\n",
    "authors": [
      "Chrysostomos Karakasis",
      "Ioannis Poulakakis",
      "Panagiotis Artemiadis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.07471"
  },
  {
    "id": "arXiv:2203.07472",
    "title": "Uncertainty Estimation for Language Reward Models",
    "abstract": "Language models can learn a range of capabilities from unsupervised training\non text corpora. However, to solve a particular problem (such as text\nsummarization) it is typically necessary to fine-tune them on a task-specific\ndataset. It is often easier for humans to choose between options than to\nprovide labeled data, and prior work has achieved state-of-the-art performance\nby training a reward model from such preference comparisons. However,\ncollecting a large preference comparison dataset is still expensive -- and the\nlearned reward models are unreliable out-of-distribution. We seek to address\nthese problems via uncertainty estimation, which can improve sample efficiency\nand robustness using active learning and risk-averse reinforcement learning\n(RL). Specifically, we use bootstrap aggregating (bagging) to train an ensemble\nof reward models differing in the initialization of their final layer.\nEnsembles have proved successful in prior applications of active learning, but\nwe find that in our setting ensemble active learning does not outperform random\nsampling. Further experiments show that while the aggregate predictions are\nwell-calibrated, the ensemble's estimated epistemic uncertainty is only weakly\ncorrelated with model error. We suspect this is because the ensemble members\nare fine-tuned from a single model and so are similar to one another. This\nsuggests current pre-training methods will need to be modified to support\nuncertainty estimation, e.g. by training multiple language models.",
    "descriptor": "\nComments: 8 pages main paper, 17 pages total\n",
    "authors": [
      "Adam Gleave",
      "Geoffrey Irving"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07472"
  },
  {
    "id": "arXiv:2203.07473",
    "title": "The Unexplored Treasure Trove of Phabricator Code Review",
    "abstract": "Phabricator is a modern code collaboration tool used by popular projects like\nFreeBSD and Mozilla. However, unlike the other well-known code review\nenvironments, such as Gerrit or GitHub, there is no readily accessible public\ncode review dataset for Phabricator. This paper describes our experience mining\ncode reviews from five different projects that use Phabricator (Blender,\nFreeBSD, KDE, LLVM, and Mozilla). We discuss the challenges associated with the\ndata retrieval process and our solutions, resulting in a dataset with details\nregarding 317,476 Phabricator code reviews. Our dataset is available in both\nJSON and MySQL database dump formats. The dataset enables analyses of the\nhistory of code reviews at a more granular level than other platforms. In\naddition, given that the projects we mined are publicly accessible via the\nConduit API, our dataset can be used as a foundation to fetch additional\ndetails and insights.",
    "descriptor": "\nComments: 5 pages. To be published in Proceedings of MSR '22: Proceedings of the 19th International Conference on Mining Software Repositories (MSR 2022). ACM, New York, NY, USA\n",
    "authors": [
      "Gunnar Kudrjavets",
      "Nachiappan Nagappan",
      "Ayushi Rastogi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.07473"
  },
  {
    "id": "arXiv:2203.07474",
    "title": "Distributed On-Sensor Compute System for AR/VR Devices: A  Semi-Analytical Simulation Framework for Power Estimation",
    "abstract": "Augmented Reality/Virtual Reality (AR/VR) glasses are widely foreseen as the\nnext generation computing platform. AR/VR glasses are a complex \"system of\nsystems\" which must satisfy stringent form factor, computing-, power- and\nthermal- requirements. In this paper, we will show that a novel distributed\non-sensor compute architecture, coupled with new semiconductor technologies\n(such as dense 3D-IC interconnects and Spin-Transfer Torque Magneto Random\nAccess Memory, STT-MRAM) and, most importantly, a full hardware-software\nco-optimization are the solutions to achieve attractive and socially acceptable\nAR/VR glasses. To this end, we developed a semi-analytical simulation framework\nto estimate the power consumption of novel AR/VR distributed on-sensor\ncomputing architectures. The model allows the optimization of the main\ntechnological features of the system modules, as well as the computer-vision\nalgorithm partition strategy across the distributed compute architecture. We\nshow that, in the case of the compute-intensive machine learning based Hand\nTracking algorithm, the distributed on-sensor compute architecture can reduce\nthe system power consumption compared to a centralized system, with the\nadditional benefits in terms of latency and privacy.",
    "descriptor": "\nComments: 6 pages, 5 figures, TinyML Research Symposium\n",
    "authors": [
      "Jorge Gomez",
      "Saavan Patel",
      "Syed Shakib Sarwar",
      "Ziyun Li",
      "Raffaele Capoccia",
      "Zhao Wang",
      "Reid Pinkham",
      "Andrew Berkovich",
      "Tsung-Hsun Tsai",
      "Barbara De Salvo",
      "Chiao Liu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07474"
  },
  {
    "id": "arXiv:2203.07475",
    "title": "Invariance in Policy Optimisation and Partial Identifiability in Reward  Learning",
    "abstract": "It's challenging to design reward functions for complex, real-world tasks.\nReward learning lets one instead infer reward functions from data. However,\nmultiple reward functions often fit the data equally well, even in the\ninfinite-data limit. Prior work often considers reward functions to be uniquely\nrecoverable, by imposing additional assumptions on data sources. By contrast,\nwe formally characterise the partial identifiability of popular data sources,\nincluding demonstrations and trajectory preferences, under multiple common sets\nof assumptions. We analyse the impact of this partial identifiability on\ndownstream tasks such as policy optimisation, including under changes in\nenvironment dynamics. We unify our results in a framework for comparing data\nsources and downstream tasks by their invariances, with implications for the\ndesign and selection of data sources for reward learning.",
    "descriptor": "\nComments: 8 pages main paper, 24 pages total, 1 figure\n",
    "authors": [
      "Joar Skalse",
      "Matthew Farrugia-Roberts",
      "Stuart Russell",
      "Alessandro Abate",
      "Adam Gleave"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.07475"
  },
  {
    "id": "arXiv:2203.07478",
    "title": "Synergistic Scheduling of Learning and Allocation of Tasks in  Human-Robot Teams",
    "abstract": "We consider the problem of completing a set of $n$ tasks with a human-robot\nteam using minimum effort. In many domains, teaching a robot to be fully\nautonomous can be counterproductive if there are finitely many tasks to be\ndone. Rather, the optimal strategy is to weigh the cost of teaching a robot and\nits benefit -- how many new tasks it allows the robot to solve autonomously. We\nformulate this as a planning problem where the goal is to decide what tasks the\nrobot should do autonomously (act), what tasks should be delegated to a human\n(delegate) and what tasks the robot should be taught (learn) so as to complete\nall the given tasks with minimum effort. This planning problem results in a\nsearch tree that grows exponentially with $n$ -- making standard graph search\nalgorithms intractable. We address this by converting the problem into a mixed\ninteger program that can be solved efficiently using off-the-shelf solvers with\nbounds on solution quality. To predict the benefit of learning, we use an\napproximate simulation model of the tasks to train a precondition model that is\nparameterized by the training task. Finally, we evaluate our approach on peg\ninsertion and Lego stacking tasks -- both in simulation and real-world, showing\nsubstantial savings in human effort.",
    "descriptor": "\nComments: Accepted at ICRA, 2022\n",
    "authors": [
      "Shivam Vats",
      "Oliver Kroemer",
      "Maxim Likhachev"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07478"
  },
  {
    "id": "arXiv:2203.07482",
    "title": "Audiovisual Affect Assessment and Autonomous Automobiles: Applications",
    "abstract": "Emotion and a broader range of affective driver states can be a life decisive\nfactor on the road. While this aspect has been investigated repeatedly, the\nadvent of autonomous automobiles puts a new perspective on the role of\ncomputer-based emotion recognition in the car -- the passenger's one. This\nincludes amongst others the monitoring of wellbeing during the commute such as\nto adjust the driving style or to adapt the info- and entertainment. This\ncontribution aims to foresee according challenges and provide potential avenues\ntowards affect modelling in a multimodal \"audiovisual plus x\" on the road\ncontext. From the technical end, this concerns holistic passenger modelling and\nreliable diarisation of the individuals in a vehicle. In conclusion, automated\naffect analysis has just matured to the point of applicability in autonomous\nvehicles in first selected use-cases, which will be discussed towards the end.",
    "descriptor": "\nComments: Originally peer-reviewed and accepted for Machines with Emotion, Workshop in conjunction with IROS, MwE 2019 - no proceedings were, however, published\n",
    "authors": [
      "Bj\u00f6rn W. Schuller",
      "Dagmar M. Schuller"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07482"
  },
  {
    "id": "arXiv:2203.07483",
    "title": "Bilinear Systems Induced by Proper Lie Group Actions",
    "abstract": "In the study of induced bilinear systems, the classical Lie algebra rank\ncondition (LARC) is known to be impractical since it requires computing the\nrank everywhere. On the other hand, the transitive Lie algebra condition, while\nmore commonly used, relies on the classification of transitive Lie algebras,\nwhich is elusive except for few simple geometric objects such as spheres. We\nprove in this note that for bilinear systems induced by proper Lie group\nactions, the underlying Lie algebra is closely related to the orbits of the\ngroup action. Knowing the pattern of the Lie algebra rank over the manifold, we\nshow that the LARC can be relaxed so that it suffices to check the rank at an\narbitrary single point. Moreover, it removes the necessity for classifying\ntransitive Lie algebras. Finally, this relaxed rank condition also leads to a\ncharacterization of controllable submanifolds by orbits.",
    "descriptor": "",
    "authors": [
      "Gong Cheng",
      "Wei Zhang",
      "Jr-Shin Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.07483"
  },
  {
    "id": "arXiv:2203.07485",
    "title": "Simplicial Attention Networks",
    "abstract": "The aim of this work is to introduce simplicial attention networks (SANs),\ni.e., novel neural architectures that operate on data defined on simplicial\ncomplexes leveraging masked self-attentional layers. Hinging on formal\narguments from topological signal processing, we introduce a proper\nself-attention mechanism able to process data components at different layers\n(e.g., nodes, edges, triangles, and so on), while learning how to weight both\nupper and lower neighborhoods of the given topological domain in a totally\ntask-oriented fashion. The proposed SANs generalize most of the current\narchitectures available for processing data defined on simplicial complexes.\nThe proposed approach compares favorably with other methods when applied to\ndifferent (inductive and transductive) tasks such as trajectory prediction and\nmissing data imputations in citation complexes.",
    "descriptor": "\nComments: Submitted to Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "L. Giusti",
      "C. Battiloro",
      "P. Di Lorenzo",
      "S. Sardellitti",
      "S. Barbarossa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.07485"
  },
  {
    "id": "arXiv:2203.07486",
    "title": "Constrained Precision Tuning",
    "abstract": "Precision tuning or customized precision number representations is emerging,\nin these recent years, as one of the most promising techniques that has a\npositive impact on the footprint of programs concerning energy consumption,\nbandwidth usage and computation time of numerical programs. In contrast to the\nuniform precision, mixed precision tuning assigns different finite-precision\ntypes to each variable and arithmetic operation of a program and offers many\nadditional optimization opportunities. However, this technique introduces new\nchallenge related to the cost of operations or type conversions which can\noverload the program execution after tuning. In this article, we extend our\ntool POP (Precision OPtimizer), with efficient ways to limit the number of\ndrawbacks of mixed precision and to achieve best compromise between performance\nand memory consumption. On a popular set of tests from the FPBench suite, we\ndiscuss the results obtained by POP.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Dorra Ben Khalifa",
      "Matthieu Martel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.07486"
  },
  {
    "id": "arXiv:2203.07488",
    "title": "Tweets in Time of Conflict: A Public Dataset Tracking the Twitter  Discourse on the War Between Ukraine and Russia",
    "abstract": "On February 24, 2022, Russia invaded Ukraine. In the days that followed,\nreports kept flooding in from layman to news anchors of a conflict quickly\nescalating into war. Russia faced immediate backlash and condemnation from the\nworld at large. While the war continues to contribute to an ongoing\nhumanitarian and refugee crisis in Ukraine, a second battlefield has emerged in\nthe online space, both in the use of social media to garner support for both\nsides of the conflict and also in the context of information warfare. In this\npaper, we present a collection of over 63 million tweets, from February 22,\n2022 through March 8, 2022 that we are publishing for the wider research\ncommunity to use. This dataset can be found at\nhttps://github.com/echen102/ukraine-russia and will be maintained and regularly\nupdated as the war continues to unfold. Our preliminary analysis already shows\nevidence of public engagement with Russian state sponsored media and other\ndomains that are known to push unreliable information; the former saw a spike\nin activity on the day of the Russian invasion. Our hope is that this public\ndataset can help the research community to further understand the ever evolving\nrole that social media plays in information dissemination, influence campaigns,\ngrassroots mobilization, and much more, during a time of conflict.",
    "descriptor": "\nComments: Dataset at this https URL\n",
    "authors": [
      "Emily Chen",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2203.07488"
  },
  {
    "id": "arXiv:2203.07490",
    "title": "Achieving Downstream Fairness with Geometric Repair",
    "abstract": "Consider a scenario where some upstream model developer must train a fair\nmodel, but is unaware of the fairness requirements of a downstream model user\nor stakeholder. In the context of fair classification, we present a technique\nthat specifically addresses this setting, by post-processing a regressor's\nscores such they yield fair classifications for any downstream choice in\ndecision threshold. To begin, we leverage ideas from optimal transport to show\nhow this can be achieved for binary protected groups across a broad class of\nfairness metrics. Then, we extend our approach to address the setting where a\nprotected attribute takes on multiple values, by re-recasting our technique as\na convex optimization problem that leverages lexicographic fairness.",
    "descriptor": "",
    "authors": [
      "Kweku Kwegyir-Aggrey",
      "Jessica Dai",
      "John Dickerson",
      "Keegan Hines"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.07490"
  },
  {
    "id": "arXiv:2203.07493",
    "title": "Approaching Massive MIMO Performance with Reconfigurable Intelligent  Surfaces: We Do Not Need Many Antennas",
    "abstract": "This paper considers an antenna structure where a (non-large) array of\nradiating elements is placed at short distance in front of a reconfigurable\nintelligent surface (RIS). This structure is analyzed as a possible emulator of\na traditional MIMO antenna with a large number of active antenna elements and\nRF chains. Focusing on both the cases of active and passive RIS, we tackle the\nissues of channel estimation, downlink signal processing, power control, and\nRIS configuration optimization. With regard to the last point, an optimization\nproblem is formulated and solved, both for the cases of active and passive RIS,\naimed at minimizing the channel signatures cross-correlations and thereby\nreducing the interference. Downlink spectral efficiency (SE) formulas are also\nderived by using the popular hardening lower-bound. Numerical results,\nrepresented with reference to max-fairness power control, show that the\nproposed structure is capable of outperforming conventional non-RIS aided MIMO\nsystems even when the MIMO system has a considerably larger number of antennas\nand RF chains. The proposed antenna structure is thus shown to be able to\napproach massive MIMO performance levels in a cost-effective way with reduced\nhardware resources.",
    "descriptor": "\nComments: Paper submitted to IEEE for possible publication\n",
    "authors": [
      "Stefano Buzzi",
      "Carmen D'Andrea",
      "Giovanni Interdonato"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.07493"
  },
  {
    "id": "arXiv:2203.07500",
    "title": "Reinforcement Learning for Optimal Control of a District Cooling Energy  Plant",
    "abstract": "District cooling energy plants (DCEPs) consisting of chillers, cooling\ntowers, and thermal energy storage (TES) systems consume a considerable amount\nof electricity. Optimizing the scheduling of the TES and chillers to take\nadvantage of time-varying electricity price is a challenging optimal control\nproblem. The classical method, model predictive control (MPC), requires solving\na high dimensional mixed-integer nonlinear program (MINLP) because of the\non/off actuation of the chillers and charging/discharging of TES, which are\ncomputationally challenging. RL is an attractive alternative to MPC: the real\ntime control computation is a low-dimensional optimization problem that can be\neasily solved. However, the performance of an RL controller depends on many\ndesign choices. In this paper, we propose a Q-learning based reinforcement\nlearning (RL) controller for this problem. Numerical simulation results show\nthat the proposed RL controller is able to reduce energy cost over a rule-based\nbaseline controller by approximately 8%, comparable to savings reported in the\nliterature with MPC for similar DCEPs. We describe the design choices in the RL\ncontroller, including basis functions, reward function shaping, and learning\nalgorithm parameters. Compared to existing work on RL for DCEPs, the proposed\ncontroller is designed for continuous state and actions spaces.",
    "descriptor": "\nComments: 10 pages, extended ACC2022 version\n",
    "authors": [
      "Zhong Guo",
      "Austin R. Coffman",
      "Prabir Barooah"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.07500"
  },
  {
    "id": "arXiv:2203.07503",
    "title": "BR2 discontinuous Galerkin methods for finite hyperelastic deformations",
    "abstract": "In this work we introduce a dG framework for nonlinear elasticity based on a\nBassi-Rebay (BR2) formulation. The framework encompasses compressible and\nincompressible hyperelastic materials and is capable of dealing with large\ndeformations. In order to achieve stability, we combine higher-order lifting\noperators for the BR2 stabilization term with an adaptive stabilization\nstrategy which relies on the BR2 Laplace operator stabilization and a penalty\nparameter based on the spectrum of the fourth-order elasticity tensor.\nDirichlet boundary conditions for the displacement can be imposed by means of\nLagrange multipliers and Nitsche method. Efficiency of the solution strategy is\nachieved by means of state-of-the-art agglomeration based $h$-multigrid\npreconditioners and the code implementation supports distributed memory\nexecution on modern parallel architectures. Several benchmark test cases are\nproposed in order to investigate some relevant computational aspects, namely\nthe performance of the $h$-multigrid iterative solver varying the stabilization\nparameters and the influence of Dirichlet boundary conditions on Newton's\nmethod globalisation strategy.",
    "descriptor": "",
    "authors": [
      "Botti Lorenzo",
      "Luca Verzeroli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.07503"
  },
  {
    "id": "arXiv:2203.07504",
    "title": "VAST: The Valence-Assessing Semantics Test for Contextualizing Language  Models",
    "abstract": "VAST, the Valence-Assessing Semantics Test, is a novel intrinsic evaluation\ntask for contextualized word embeddings (CWEs). VAST uses valence, the\nassociation of a word with pleasantness, to measure the correspondence of\nword-level LM semantics with widely used human judgments, and examines the\neffects of contextualization, tokenization, and LM-specific geometry. Because\nprior research has found that CWEs from GPT-2 perform poorly on other intrinsic\nevaluations, we select GPT-2 as our primary subject, and include results\nshowing that VAST is useful for 7 other LMs, and can be used in 7 languages.\nGPT-2 results show that the semantics of a word incorporate the semantics of\ncontext in layers closer to model output, such that VAST scores diverge between\nour contextual settings, ranging from Pearson's rho of .55 to .77 in layer 11.\nWe also show that multiply tokenized words are not semantically encoded until\nlayer 8, where they achieve Pearson's rho of .46, indicating the presence of an\nencoding process for multiply tokenized words which differs from that of singly\ntokenized words, for which rho is highest in layer 0. We find that a few\nneurons with values having greater magnitude than the rest mask word-level\nsemantics in GPT-2's top layer, but that word-level semantics can be recovered\nby nullifying non-semantic principal components: Pearson's rho in the top layer\nimproves from .32 to .76. After isolating semantics, we show the utility of\nVAST for understanding LM semantics via improvements over related work on four\nword similarity tasks, with a score of .50 on SimLex-999, better than the\nprevious best of .45 for GPT-2. Finally, we show that 8 of 10 WEAT bias tests,\nwhich compare differences in word embedding associations between groups of\nwords, exhibit more stereotype-congruent biases after isolating semantics,\nindicating that non-semantic structures in LMs also mask biases.",
    "descriptor": "\nComments: To be published in AAAI 2022\n",
    "authors": [
      "Robert Wolfe",
      "Aylin Caliskan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07504"
  },
  {
    "id": "arXiv:2203.07505",
    "title": "Closing the Loop: A Framework for Trustworthy Machine Learning in Power  Systems",
    "abstract": "Deep decarbonization of the energy sector will require massive penetration of\nstochastic renewable energy resources and an enormous amount of grid asset\ncoordination; this represents a challenging paradigm for the power system\noperators who are tasked with maintaining grid stability and security in the\nface of such changes. With its ability to learn from complex datasets and\nprovide predictive solutions on fast timescales, machine learning (ML) is\nwell-posed to help overcome these challenges as power systems transform in the\ncoming decades. In this work, we outline five key challenges (dataset\ngeneration, data pre-processing, model training, model assessment, and model\nembedding) associated with building trustworthy ML models which learn from\nphysics-based simulation data. We then demonstrate how linking together\nindividual modules, each of which overcomes a respective challenge, at\nsequential stages in the machine learning pipeline can help enhance the overall\nperformance of the training process. In particular, we implement methods that\nconnect different elements of the learning pipeline through feedback, thus\n\"closing the loop\" between model training, performance assessments, and\nre-training. We demonstrate the effectiveness of this framework, its\nconstituent modules, and its feedback connections by learning the N-1\nsmall-signal stability margin associated with a detailed model of a proposed\nNorth Sea Wind Power Hub system.",
    "descriptor": "\nComments: 20 pages, 12 figures, 3 tables, submitted to \"11th Bulk Power Systems Dynamics and Control Symposium, July 25-30, 2022, Banff, Canada\"\n",
    "authors": [
      "Jochen Stiasny",
      "Samuel Chevalier",
      "Rahul Nellikkath",
      "Brynjar S\u00e6varsson",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07505"
  },
  {
    "id": "arXiv:2203.07507",
    "title": "Conformance Checking Over Stochastically Known Logs",
    "abstract": "With the growing number of devices, sensors and digital systems, data logs\nmay become uncertain due to, e.g., sensor reading inaccuracies or incorrect\ninterpretation of readings by processing programs. At times, such uncertainties\ncan be captured stochastically, especially when using probabilistic data\nclassification models. In this work we focus on conformance checking, which\ncompares a process model with an event log, when event logs are stochastically\nknown. Building on existing alignment-based conformance checking fundamentals,\nwe mathematically define a stochastic trace model, a stochastic synchronous\nproduct, and a cost function that reflects the uncertainty of events in a log.\nThen, we search for an optimal alignment over the reachability graph of the\nstochastic synchronous product for finding an optimal alignment between a model\nand a stochastic process observation. Via structured experiments with two\nwell-known process mining benchmarks, we explore the behavior of the suggested\nstochastic conformance checking approach and compare it to a standard\nalignment-based approach as well as to an approach that creates a lower bound\non performance. We envision the proposed stochastic conformance checking\napproach as a viable process mining component for future analysis of stochastic\nevent logs.",
    "descriptor": "",
    "authors": [
      "Eli Bogdanov",
      "Izack Cohen",
      "Avigdor Gal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07507"
  },
  {
    "id": "arXiv:2203.07511",
    "title": "Contrastive Visual Semantic Pretraining Magnifies the Semantics of  Natural Language Representations",
    "abstract": "We examine the effects of contrastive visual semantic pretraining by\ncomparing the geometry and semantic properties of contextualized English\nlanguage representations formed by GPT-2 and CLIP, a zero-shot multimodal image\nclassifier which adapts the GPT-2 architecture to encode image captions. We\nfind that contrastive visual semantic pretraining significantly mitigates the\nanisotropy found in contextualized word embeddings from GPT-2, such that the\nintra-layer self-similarity (mean pairwise cosine similarity) of CLIP word\nembeddings is under .25 in all layers, compared to greater than .95 in the top\nlayer of GPT-2. CLIP word embeddings outperform GPT-2 on word-level semantic\nintrinsic evaluation tasks, and achieve a new corpus-based state of the art for\nthe RG65 evaluation, at .88. CLIP also forms fine-grained semantic\nrepresentations of sentences, and obtains Spearman's rho = .73 on the\nSemEval-2017 Semantic Textual Similarity Benchmark with no fine-tuning,\ncompared to no greater than rho = .45 in any layer of GPT-2. Finally,\nintra-layer self-similarity of CLIP sentence embeddings decreases as the layer\nindex increases, finishing at .25 in the top layer, while the self-similarity\nof GPT-2 sentence embeddings formed using the EOS token increases\nlayer-over-layer and never falls below .97. Our results indicate that high\nanisotropy is not an inevitable consequence of contextualization, and that\nvisual semantic pretraining is beneficial not only for ordering visual\nrepresentations, but also for encoding useful semantic representations of\nlanguage, both on the word level and the sentence level.",
    "descriptor": "\nComments: To be published in ACL 2022\n",
    "authors": [
      "Robert Wolfe",
      "Aylin Caliskan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07511"
  },
  {
    "id": "arXiv:2203.07513",
    "title": "Multi Stage Screening: Enforcing Fairness and Maximizing Efficiency in a  Pre-Existing Pipeline",
    "abstract": "Consider an actor making selection decisions using a series of classifiers,\nwhich we term a sequential screening process. The early stages filter out some\napplicants, and in the final stage an expensive but accurate test is applied to\nthe individuals that make it to the final stage. Since the final stage is\nexpensive, if there are multiple groups with different fractions of positives\nat the penultimate stage (even if a slight gap), then the firm may naturally\nonly choose to the apply the final (interview) stage solely to the highest\nprecision group which would be clearly unfair to the other groups. Even if the\nfirm is required to interview all of those who pass the final round, the tests\nthemselves could have the property that qualified individuals from some groups\npass more easily than qualified individuals from others. Thus, we consider\nrequiring Equality of Opportunity (qualified individuals from each each group\nhave the same chance of reaching the final stage and being interviewed). We\nthen examine the goal of maximizing quantities of interest to the decision\nmaker subject to this constraint, via modification of the probabilities of\npromotion through the screening process at each stage based on performance at\nthe previous stage. We exhibit algorithms for satisfying Equal Opportunity over\nthe selection process and maximizing precision (the fraction of interview that\nyield qualified candidates) as well as linear combinations of precision and\nrecall (recall determines the number of applicants needed per hire) at the end\nof the final stage. We also present examples showing that the solution space is\nnon-convex, which motivate our exact and (FPTAS) approximation algorithms for\nmaximizing the linear combination of precision and recall. Finally, we discuss\nthe `price of' adding additional restrictions, such as not allowing the\ndecision maker to use group membership in its decision process.",
    "descriptor": "",
    "authors": [
      "Avrim Blum",
      "Kevin Stangl",
      "Ali Vakilian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07513"
  },
  {
    "id": "arXiv:2203.07516",
    "title": "Skydiver: A Spiking Neural Network Accelerator Exploiting  Spatio-Temporal Workload Balance",
    "abstract": "Spiking Neural Networks (SNNs) are developed as a promising alternative to\nArtificial Neural networks (ANNs) due to their more realistic brain-inspired\ncomputing models. SNNs have sparse neuron firing over time, i.e.,\nspatio-temporal sparsity; thus, they are useful to enable energy-efficient\nhardware inference. However, exploiting spatio-temporal sparsity of SNNs in\nhardware leads to unpredictable and unbalanced workloads, degrading the energy\nefficiency. In this work, we propose an FPGA-based convolutional SNN\naccelerator called Skydiver that exploits spatio-temporal workload balance. We\npropose the Approximate Proportional Relation Construction (APRC) method that\ncan predict the relative workload channel-wisely and a Channel-Balanced\nWorkload Schedule (CBWS) method to increase the hardware workload balance ratio\nto over 90%. Skydiver was implemented on a Xilinx XC7Z045 FPGA and verified on\nimage segmentation and MNIST classification tasks. Results show improved\nthroughput by 1.4X and 1.2X for the two tasks. Skydiver achieved 22.6 KFPS\nthroughput, and 42.4 uJ/Image prediction energy on the classification task with\n98.5% accuracy.",
    "descriptor": "\nComments: Accepted to be published in the IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2022\n",
    "authors": [
      "Qinyu Chen",
      "Chang Gao",
      "Xinyuan Fang",
      "Haitao Luan"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.07516"
  },
  {
    "id": "arXiv:2203.07519",
    "title": "Leveraging Visual Knowledge in Language Tasks: An Empirical Study on  Intermediate Pre-training for Cross-modal Knowledge Transfer",
    "abstract": "Pre-trained language models are still far from human performance in tasks\nthat need understanding of properties (e.g. appearance, measurable quantity)\nand affordances of everyday objects in the real world since the text lacks such\ninformation due to reporting bias. In this work, we study whether integrating\nvisual knowledge into a language model can fill the gap. We investigate two\ntypes of knowledge transfer: (1) text knowledge transfer using image captions\nthat may contain enriched visual knowledge and (2) cross-modal knowledge\ntransfer using both images and captions with vision-language training\nobjectives. On 5 downstream tasks that may need visual knowledge to solve the\nproblem, we perform extensive empirical comparisons over the presented\nobjectives. Our experiments show that visual knowledge transfer can improve\nperformance in both low-resource and fully supervised settings.",
    "descriptor": "\nComments: Accepted to ACL 2022, 13 pages, 4 figures\n",
    "authors": [
      "Woojeong Jin",
      "Dong-Ho Lee",
      "Chenguang Zhu",
      "Jay Pujara",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07519"
  },
  {
    "id": "arXiv:2203.07521",
    "title": "Automatic lane change scenario extraction and generation of scenarios in  OpenX format from real-world data",
    "abstract": "Autonomous Vehicles (AV)'s wide-scale deployment appears imminent despite\nmany safety challenges yet to be resolved. The modern autonomous vehicles will\nundoubtedly include machine learning and probabilistic techniques that add\nsignificant complexity to the traditional verification and validation methods.\nRoad testing is essential before the deployment, but scenarios are repeatable,\nand it's hard to collect challenging events. Exploring numerous, diverse and\ncrucial scenarios is a time-consuming and expensive approach. The research\ncommunity and industry have widely accepted scenario-based testing in the last\nfew years. As it is focused directly on the relevant critical road situations,\nit can reduce the effort required in testing. The scenario-based testing in\nsimulation requires the realistic behaviour of the traffic participants to\nassess the System Under Test (SUT). It is essential to capture the scenarios\nfrom the real world to encode the behaviour of actual traffic participants.\nThis paper proposes a novel scenario extraction method to capture the lane\nchange scenarios using point-cloud data and object tracking information. This\nmethod enables fully automatic scenario extraction compared to similar\napproaches in this area. The generated scenarios are represented in OpenX\nformat to reuse them in the SUT evaluation easily. The motivation of this\nframework is to build a validation dataset to generate many critical concrete\nscenarios. The code is available online at\nhttps://github.com/dkarunakaran/scenario_extraction_framework.",
    "descriptor": "\nComments: Submitted to IEEE IV 22 conference\n",
    "authors": [
      "Dhanoop Karunakaran",
      "Julie Stephany Berrio",
      "Stewart Worrall",
      "Eduardo Nebot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07521"
  },
  {
    "id": "arXiv:2203.07522",
    "title": "Choose Your QA Model Wisely: A Systematic Study of Generative and  Extractive Readers for Question Answering",
    "abstract": "While both extractive and generative readers have been successfully applied\nto the Question Answering (QA) task, little attention has been paid toward the\nsystematic comparison of them. Characterizing the strengths and weaknesses of\nthe two readers is crucial not only for making a more informed reader selection\nin practice but also for developing a deeper understanding to foster further\nresearch on improving readers in a principled manner. Motivated by this goal,\nwe make the first attempt to systematically study the comparison of extractive\nand generative readers for question answering. To be aligned with the\nstate-of-the-art, we explore nine transformer-based large pre-trained language\nmodels (PrLMs) as backbone architectures. Furthermore, we organize our findings\nunder two main categories: (1) keeping the architecture invariant, and (2)\nvarying the underlying PrLMs. Among several interesting findings, it is\nimportant to highlight that (1) the generative readers perform better in long\ncontext QA, (2) the extractive readers perform better in short context while\nalso showing better out-of-domain generalization, and (3) the encoder of\nencoder-decoder PrLMs (e.g., T5) turns out to be a strong extractive reader and\noutperforms the standard choice of encoder-only PrLMs (e.g., RoBERTa). We also\nstudy the effect of multi-task learning on the two types of readers varying the\nunderlying PrLMs and perform qualitative and quantitative diagnosis to provide\nfurther insights into future directions in modeling better readers.",
    "descriptor": "",
    "authors": [
      "Man Luo",
      "Kazuma Hashimoto",
      "Semih Yavuz",
      "Zhiwei Liu",
      "Chitta Baral",
      "Yingbo Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07522"
  },
  {
    "id": "arXiv:2203.07523",
    "title": "Sense Embeddings are also Biased--Evaluating Social Biases in Static and  Contextualised Sense Embeddings",
    "abstract": "Sense embedding learning methods learn different embeddings for the different\nsenses of an ambiguous word. One sense of an ambiguous word might be socially\nbiased while its other senses remain unbiased. In comparison to the numerous\nprior work evaluating the social biases in pretrained word embeddings, the\nbiases in sense embeddings have been relatively understudied. We create a\nbenchmark dataset for evaluating the social biases in sense embeddings and\npropose novel sense-specific bias evaluation measures. We conduct an extensive\nevaluation of multiple static and contextualised sense embeddings for various\ntypes of social biases using the proposed measures. Our experimental results\nshow that even in cases where no biases are found at word-level, there still\nexist worrying levels of social biases at sense-level, which are often ignored\nby the word-level bias evaluation measures.",
    "descriptor": "\nComments: Accepted to ACL 2022\n",
    "authors": [
      "Yi Zhou",
      "Masahiro Kaneko",
      "Danushka Bollegala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07523"
  },
  {
    "id": "arXiv:2203.07524",
    "title": "Convolutional-Recurrent Neural Network Proxy for Robust Optimization and  Closed-Loop Reservoir Management",
    "abstract": "Production optimization under geological uncertainty is computationally\nexpensive, as a large number of well control schedules must be evaluated over\nmultiple geological realizations. In this work, a convolutional-recurrent\nneural network (CNN-RNN) proxy model is developed to predict well-by-well oil\nand water rates, for given time-varying well bottom-hole pressure (BHP)\nschedules, for each realization in an ensemble. This capability enables the\nestimation of the objective function and nonlinear constraint values required\nfor robust optimization. The proxy model represents an extension of a recently\ndeveloped long short-term memory (LSTM) RNN proxy designed to predict well\nrates for a single geomodel. A CNN is introduced here to processes permeability\nrealizations, and this provides the initial states for the RNN. The CNN-RNN\nproxy is trained using simulation results for 300 different sets of BHP\nschedules and permeability realizations. We demonstrate proxy accuracy for\noil-water flow through multiple realizations of 3D multi-Gaussian permeability\nmodels. The proxy is then incorporated into a closed-loop reservoir management\n(CLRM) workflow, where it is used with particle swarm optimization and a\nfilter-based method for nonlinear constraint satisfaction. History matching is\nachieved using an adjoint-gradient-based procedure. The proxy model is shown to\nperform well in this setting for five different (synthetic) `true' models.\nImproved net present value along with constraint satisfaction and uncertainty\nreduction are observed with CLRM. For the robust production optimization steps,\nthe proxy provides O(100) runtime speedup over simulation-based optimization.",
    "descriptor": "",
    "authors": [
      "Yong Do Kim",
      "Louis J. Durlofsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07524"
  },
  {
    "id": "arXiv:2203.07527",
    "title": "A Linearly Convergent Douglas-Rachford Splitting Solver for Markovian  Information-Theoretic Optimization Problems",
    "abstract": "In this work, we propose solving the Information bottleneck (IB) and Privacy\nFunnel (PF) problems with Douglas-Rachford Splitting methods (DRS). We study a\ngeneral Markovian information-theoretic Lagrangian that formulates the IB and\nPF problems into a convex-weakly convex pair of functions in a unified\nframework. Exploiting the recent non-convex convergence analysis for splitting\nmethods, we prove the linear convergence of the proposed algorithms using the\nKurdyka-{\\L}ojasiewicz inequality. Moreover, our analysis is beyond IB and PF\nand applies to any convex-weakly convex pair objectives. Based on the results,\nwe develop two types of IB solvers, with one improves the performance of\nconvergence over existing solvers while the other is linearly convergent\nindependent to the relevance-compression trade-off, and a class of PF solvers\nthat can handle both random and deterministic mappings. Empirically, we\nevaluate the proposed DRS solvers for both the IB and PF problems with our\ngradient-descent-based implementation. For IB, the proposed solvers result in\nsolutions that are comparable to those obtained through the\nBlahut-Arimoto-based benchmark and is convergent for a wider range of the\npenalty coefficient than existing solvers. For PF, our non-greedy solvers can\nexplore the information plane better than the clustering-based greedy solvers.",
    "descriptor": "",
    "authors": [
      "Teng-Hui Huang",
      "Aly El Gamal",
      "Hesham El Gamal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.07527"
  },
  {
    "id": "arXiv:2203.07530",
    "title": "Fast Active Monocular Distance Estimation from Time-to-Contact",
    "abstract": "Distance estimation is fundamental for a variety of robotic applications\nincluding navigation, manipulation and planning. Inspired by the mammal's\nvisual system, which gazes at specific objects (active fixation), and estimates\nwhen the object will reach it (time-to-contact), we develop a novel constraint\nbetween time-to-contact, acceleration, and distance that we call the\n$\\tau$-constraint. It allows an active monocular camera to estimate depth using\ntime-to-contact and inertial measurements (linear accelerations and angular\nvelocities) within a window of time.\nOur work differs from other approaches by focusing on patches instead of\nfeature points. This is, because the change in the patch area determines the\ntime-to-contact directly. The result enables efficient estimation of distance\nwhile using only a small portion of the image, leading to a large speedup.\nWe successfully validate the proposed $\\tau$-constraint in the application of\nestimating camera position with a monocular grayscale camera and an Inertial\nMeasurement Unit (IMU). Specifically, we test our method on different\nreal-world planar objects over trajectories 8-40 seconds in duration and 7-35\nmeters long. Our method achieves 8.5 cm Average Trajectory Error (ATE) while\nthe popular Visual-Inertial Odometry methods VINS-Mono and ROVIO achieve 12.2\nand 16.9 cm ATE respectively. Additionally, our implementation runs 27$\\times$\nfaster than VINS-Mono's and 6.8$\\times$ faster than ROVIO's. We believe these\nresults indicate the $\\tau$-constraints potential to be the basis of robust,\nsophisticated algorithms for a multitude of applications involving an active\ncamera and an IMU.",
    "descriptor": "\nComments: 23 pages, 25 figures, 2 tables\n",
    "authors": [
      "Levi Burner",
      "Nitin J. Sanket",
      "Cornelia Ferm\u00fcller",
      "Yiannis Aloimonos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07530"
  },
  {
    "id": "arXiv:2203.07538",
    "title": "Autistic Children's Mental Model of an Humanoid Robot",
    "abstract": "This position paper introduces the results of an initial card sorting\nexperiment based on the reactions and questions of a group of children with\nautism working with a humanoid robot in a therapeutic laboratory on autonomy.",
    "descriptor": "",
    "authors": [
      "Cristina Gena",
      "Claudio Mattutino",
      "Andrea Maieli",
      "Elisabetta Miraglio",
      "Giulia Ricciardiello",
      "Rossana Damiano",
      "Alessandro Mazzei"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07538"
  },
  {
    "id": "arXiv:2203.07540",
    "title": "ScienceWorld: Is your Agent Smarter than a 5th Grader?",
    "abstract": "This paper presents a new benchmark, ScienceWorld, to test agents' scientific\nreasoning abilities in a new interactive text environment at the level of a\nstandard elementary school science curriculum. Despite the recent\ntransformer-based progress seen in adjacent fields such as question-answering,\nscientific text processing, and the wider area of natural language processing,\nwe find that current state-of-the-art models are unable to reason about or\nexplain learned science concepts in novel contexts. For instance, models can\neasily answer what the conductivity of a previously seen material is but\nstruggle when asked how they would conduct an experiment in a grounded,\ninteractive environment to find the conductivity of an unknown material. This\nbegs the question of whether current models are simply retrieving answers by\nway of seeing a large number of similar input examples or if they have learned\nto reason about concepts in a reusable manner. We hypothesize that agents need\nto be grounded in interactive environments to achieve such reasoning\ncapabilities. Our experiments provide empirical evidence supporting this\nhypothesis -- showing that a 1.5 million parameter agent trained interactively\nfor 100k steps outperforms a 11 billion parameter model statically trained for\nscientific question-answering and reasoning via millions of expert\ndemonstrations.",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Ruoyao Wang",
      "Peter Jansen",
      "Marc-Alexandre C\u00f4t\u00e9",
      "Prithviraj Ammanabrolu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07540"
  },
  {
    "id": "arXiv:2203.07543",
    "title": "Sugar, Salt & Pepper -- Humanoid robotics for autism",
    "abstract": "This paper introduces an experimental trial that will take place from\nFebruary to June 2021, and which will see the use of the Pepper robot in a\ntherapeutic laboratory on autonomies that will promote functional acquisitions\nin children diagnosed with high functioning autism/Asperger's syndrome.",
    "descriptor": "\nComments: IUI Workshops 2021\n",
    "authors": [
      "Cristina Gena",
      "Claudio Mattutino",
      "Stefania Brighenti",
      "Andrea Meirone",
      "Francesco Petriglia",
      "Loredana Mazzotta",
      "Federica Liscio",
      "Matteo Nazzario",
      "Valeria Ricci",
      "Camilla Quarato",
      "Cesare Pecone",
      "Giuseppe Piccinni"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07543"
  },
  {
    "id": "arXiv:2203.07544",
    "title": "A Unified Framework for Rank-based Evaluation Metrics for Link  Prediction in Knowledge Graphs",
    "abstract": "The link prediction task on knowledge graphs without explicit negative\ntriples in the training data motivates the usage of rank-based metrics. Here,\nwe review existing rank-based metrics and propose desiderata for improved\nmetrics to address lack of interpretability and comparability of existing\nmetrics to datasets of different sizes and properties. We introduce a simple\ntheoretical framework for rank-based metrics upon which we investigate two\navenues for improvements to existing metrics via alternative aggregation\nfunctions and concepts from probability theory. We finally propose several new\nrank-based metrics that are more easily interpreted and compared accompanied by\na demonstration of their usage in a benchmarking of knowledge graph embedding\nmodels.",
    "descriptor": "",
    "authors": [
      "Charles Tapley Hoyt",
      "Max Berrendorf",
      "Mikhail Gaklin",
      "Volker Tresp",
      "Benjamin M. Gyori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07544"
  },
  {
    "id": "arXiv:2203.07547",
    "title": "On the Violation of Honesty in Mobile Apps: Automated Detection and  Categories",
    "abstract": "Human values such as integrity, privacy, curiosity, security, and honesty are\nguiding principles for what people consider important in life. Such human\nvalues may be violated by mobile software applications (apps), and the negative\neffects of such human value violations can be seen in various ways in society.\nIn this work, we focus on the human value of honesty. We present a model to\nsupport the automatic identification of violations of the value of honesty from\napp reviews from an end-user perspective. Beyond the automatic detection of\nhonesty violations by apps, we also aim to better understand different\ncategories of honesty violations expressed by users in their app reviews. The\nresult of our manual analysis of our honesty violations dataset shows that\nhonesty violations can be characterised into ten categories: unfair\ncancellation and refund policies; false advertisements; delusive subscriptions;\ncheating systems; inaccurate information; unfair fees; no service; deletion of\nreviews; impersonation; and fraudulent-looking apps. Based on these results, we\nargue for a conscious effort in developing more honest software artefacts\nincluding mobile apps, and the promotion of honesty as a key value in software\ndevelopment practices. Furthermore, we discuss the role of app distribution\nplatforms as enforcers of ethical systems supporting human values, and\nhighlight some proposed next steps for human values in software engineering\n(SE) research.",
    "descriptor": "\nComments: 12 pages, Accepted for publication in 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)\n",
    "authors": [
      "Humphrey O. Obie",
      "Idowu Ilekura",
      "Hung Du",
      "Mojtaba Shahin",
      "John Grundy",
      "Li Li",
      "Jon Whittle",
      "Burak Turhan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.07547"
  },
  {
    "id": "arXiv:2203.07548",
    "title": "Physical Neural Cellular Automata for 2D Shape Classification",
    "abstract": "Materials with the ability to self-classify their own shape have the\npotential to advance a wide range of engineering applications and industries.\nBiological systems possess the ability not only to self-reconfigure but also to\nself-classify themselves to determine a general shape and function. Previous\nwork into modular robotics systems have only enabled self-recognition and\nself-reconfiguration into a specific target shape, missing the inherent\nrobustness present in nature to self-classify. In this paper we therefore take\nadvantage of recent advances in deep learning and neural cellular automata, and\npresent a simple modular 2D robotic system that can infer its own class of\nshape through the local communication of its components. Furthermore, we show\nthat our system can be successfully transferred to hardware which thus opens\nopportunities for future self-classifying machines.",
    "descriptor": "",
    "authors": [
      "Kathryn Walker",
      "Rasmus Berg Palm",
      "Rodrigo Moreno Garcia",
      "Andres Faina",
      "Kasper Stoy",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07548"
  },
  {
    "id": "arXiv:2203.07549",
    "title": "Cell-Free Massive MIMO with OTFS Modulation: Power Control and Resource  Allocation",
    "abstract": "We consider the downlink of cell-free massive multiple-input multiple-output\n(MIMO) systems with orthogonal time frequency space (OTFS) modulation. Two\npilot-based channel estimation schemes, namely superimposed pilot-based\n(SP-CHE) and embedded pilot-based channel estimation (EP-CHE), are applied to\nestimate the channels at the access points (APs). The SP-CHE scheme\nsuperimposes low power pilots onto the data symbols in the delay-Doppler domain\nto avoid the spectral efficiency (SE) loss due to null guard intervals used in\nthe EP-CHE scheme. In the case of SP-CHE scheme, we consider a max-min fairness\noptimization problem to jointly optimize the peruser pilot/data power\nallocation coefficients and per-AP power control coefficients. The complicated\nnon-convex problem is then iteratively solved through two decoupled\nsub-problems. Moreover, a max-min fairness problem is cast for the EP-CHE\nscheme, where the optimization variables are the per-AP power control\ncoefficients. Numerical results show that the proposed resource allocation\napproaches provide at most 42 and 5-fold increase in the 95%-likely per-user SE\nfor the SP-CHE and EP-CHE scheme, respectively, compared with the uniform power\ncontrol and in correlated shadowing fading channels.",
    "descriptor": "\nComments: Accepted in ICC 2022 Workshop on OTFS and Delay-Doppler Signal Processing for 6G and Future High-mobility Communications\n",
    "authors": [
      "Mohammadali Mohammadi",
      "Hien Quoc Ngo",
      "Michail Matthaiou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.07549"
  },
  {
    "id": "arXiv:2203.07552",
    "title": "The Spherical Cap Discrepancy of HEALPix Points",
    "abstract": "In this paper we show that the spherical cap discrepancy of the point set\ngiven by centers of pixels in the HEALPix tessellation (short for Hierarchical,\nEqual Area and iso-Latitude Pixelation) of unit $2$-sphere is lower and upper\nbounded by order square root of the number of points, and compute explicit\nconstants. This adds to the known collection of explicitly constructed sets\nwhose discrepancy converges with order $N^{-1/2}$, matching the asymptotic\norder for i.i.d. random point sets. We describe the HEALPix framework in more\ndetail and give explicit formulas for the boundaries and pixel centers. We then\nintroduce the notion of an $n$-convex curve and prove an upper bound on how\nmany fundamental domains are intersected by such curves, and in particular we\nshow that boundaries of spherical caps have this property. Lastly, we mention\nbriefly that a jittered sampling technique works in the HEALPix framework as\nwell.",
    "descriptor": "",
    "authors": [
      "Damir Ferizovi\u0107",
      "Julian Hofstadler",
      "Michelle Mastrianni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2203.07552"
  },
  {
    "id": "arXiv:2203.07553",
    "title": "VPFusion: Joint 3D Volume and Pixel-Aligned Feature Fusion for Single  and Multi-view 3D Reconstruction",
    "abstract": "We introduce a unified single and multi-view neural implicit 3D\nreconstruction framework VPFusion. VPFusion~attains high-quality reconstruction\nusing both - 3D feature volume to capture 3D-structure-aware context, and\npixel-aligned image features to capture fine local detail. Existing approaches\nuse RNN, feature pooling, or attention computed independently in each view for\nmulti-view fusion. RNNs suffer from long-term memory loss and permutation\nvariance, while feature pooling or independently computed attention leads to\nrepresentation in each view being unaware of other views before the final\npooling step. In contrast, we show improved multi-view feature fusion by\nestablishing transformer-based pairwise view association. In particular, we\npropose a novel interleaved 3D reasoning and pairwise view association\narchitecture for feature volume fusion across different views. Using this\nstructure-aware and multi-view-aware feature volume, we show improved 3D\nreconstruction performance compared to existing methods. VPFusion improves the\nreconstruction quality further by also incorporating pixel-aligned local image\nfeatures to capture fine detail. We verify the effectiveness of VPFusion~on the\nShapeNet and ModelNet datasets, where we outperform or perform on-par the\nstate-of-the-art single and multi-view 3D shape reconstruction methods.",
    "descriptor": "\nComments: 14 pages, 6 figures, 3 tables\n",
    "authors": [
      "Jisan Mahmud",
      "Jan-Michael Frahm"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07553"
  },
  {
    "id": "arXiv:2203.07554",
    "title": "Agile Maneuvers in Legged Robots: a Predictive Control Approach",
    "abstract": "Achieving agile maneuvers through multiple contact phases has been a\nlongstanding challenge in legged robotics. It requires to derive motion plans\nand local control feedback policies in real-time to handle the nonholonomy of\nthe kinetic momenta. While a few recent predictive control approaches based on\ncentroidal momentum have been able to generate dynamic motions, they assume\nunlimited actuation capabilities. This assumption is quite restrictive and does\nnot hold for agile maneuvers on most robots. In this work, we present a\ncontact-phase predictive and state-feedback controllers that enables legged\nrobots to plan and perform agile locomotion skills. Our predictive controller\nmodels the contact phases using a hybrid paradigm that considers the robot's\nactuation limits and full dynamics. We demonstrate the benefits of our approach\non agile maneuvers on ANYmal robots in realistic scenarios. To the best of our\nknowledge, our work is the first to show that predictive control can handle\nactuation limits, generate agile locomotion maneuvers and execute locally\noptimal feedback policies on hardware without the use of a separate whole-body\ncontroller.",
    "descriptor": "\nComments: 19 pages, 16 figures\n",
    "authors": [
      "Carlos Mastalli",
      "Wolfgang Merkt",
      "Guiyang Xin",
      "Jaehyun Shim",
      "Michael Mistry",
      "Ioannis Havoutis",
      "Sethu Vijayakumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.07554"
  },
  {
    "id": "arXiv:2203.07557",
    "title": "Fast Regression for Structured Inputs",
    "abstract": "We study the $\\ell_p$ regression problem, which requires finding\n$\\mathbf{x}\\in\\mathbb R^{d}$ that minimizes\n$\\|\\mathbf{A}\\mathbf{x}-\\mathbf{b}\\|_p$ for a matrix $\\mathbf{A}\\in\\mathbb R^{n\n\\times d}$ and response vector $\\mathbf{b}\\in\\mathbb R^{n}$. There has been\nrecent interest in developing subsampling methods for this problem that can\noutperform standard techniques when $n$ is very large. However, all known\nsubsampling approaches have run time that depends exponentially on $p$,\ntypically, $d^{\\mathcal{O}(p)}$, which can be prohibitively expensive. We\nimprove on this work by showing that for a large class of common\n\\emph{structured matrices}, such as combinations of low-rank matrices, sparse\nmatrices, and Vandermonde matrices, there are subsampling based methods for\n$\\ell_p$ regression that depend polynomially on $p$. For example, we give an\nalgorithm for $\\ell_p$ regression on Vandermonde matrices that runs in time\n$\\mathcal{O}(n\\log^3 n+(dp^2)^{0.5+\\omega}\\cdot\\text{polylog}\\,n)$, where\n$\\omega$ is the exponent of matrix multiplication. The polynomial dependence on\n$p$ crucially allows our algorithms to extend naturally to efficient algorithms\nfor $\\ell_\\infty$ regression, via approximation of $\\ell_\\infty$ by\n$\\ell_{\\mathcal{O}(\\log n)}$. Of practical interest, we also develop a new\nsubsampling algorithm for $\\ell_p$ regression for arbitrary matrices, which is\nsimpler than previous approaches for $p \\ge 4$.",
    "descriptor": "",
    "authors": [
      "Raphael A. Meyer",
      "Cameron Musco",
      "Christopher Musco",
      "David P. Woodruff",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.07557"
  },
  {
    "id": "arXiv:2203.07558",
    "title": "Learning for Robot Decision Making under Distribution Shift: A Survey",
    "abstract": "With the recent advances in the field of deep learning, learning-based\nmethods are widely being implemented in various robotic systems that help\nrobots understand their environment and make informed decisions to achieve a\nwide variety of tasks or goals. However, learning-based methods have repeatedly\nbeen shown to have poor generalization when they are presented with inputs that\nare different from those during training leading to the problem of distribution\nshift. Any robotic system that employs learning-based methods is prone to\ndistribution shift which might lead the agents to make decisions that lead to\ndegraded performance or even catastrophic failure. In this paper, we discuss\nvarious techniques that have been proposed in the literature to aid or improve\ndecision making under distribution shift for robotic systems. We present a\ntaxonomy of existing literature and present a survey of existing approaches in\nthe area based on this taxonomy. Finally, we also identify a few open problems\nin the area that could serve as future directions for research.",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Abhishek Paudel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07558"
  },
  {
    "id": "arXiv:2203.07559",
    "title": "On the Calibration of Pre-trained Language Models using Mixup Guided by  Area Under the Margin and Saliency",
    "abstract": "A well-calibrated neural model produces confidence (probability outputs)\nclosely approximated by the expected accuracy. While prior studies have shown\nthat mixup training as a data augmentation technique can improve model\ncalibration on image classification tasks, little is known about using mixup\nfor model calibration on natural language understanding (NLU) tasks. In this\npaper, we explore mixup for model calibration on several NLU tasks and propose\na novel mixup strategy for pre-trained language models that improves model\ncalibration further. Our proposed mixup is guided by both the Area Under the\nMargin (AUM) statistic (Pleiss et al., 2020) and the saliency map of each\nsample (Simonyan et al.,2013). Moreover, we combine our mixup strategy with\nmodel miscalibration correction techniques (i.e., label smoothing and\ntemperature scaling) and provide detailed analyses of their impact on our\nproposed mixup. We focus on systematically designing experiments on three NLU\ntasks: natural language inference, paraphrase detection, and commonsense\nreasoning. Our method achieves the lowest expected calibration error compared\nto strong baselines on both in-domain and out-of-domain test samples while\nmaintaining competitive accuracy.",
    "descriptor": "\nComments: Accepted at ACL 2022 main conference\n",
    "authors": [
      "Seo Yeon Park",
      "Cornelia Caragea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07559"
  },
  {
    "id": "arXiv:2203.07561",
    "title": "Toward the Detection of Polyglot Files",
    "abstract": "Standardized file formats play a key role in the development and use of\ncomputer software. However, it is possible to abuse standardized file formats\nby creating a file that is valid in multiple file formats. The resulting\npolyglot (many languages) file can confound file format identification,\nallowing elements of the file to evade analysis.This is especially problematic\nfor malware detection systems that rely on file format identification for\nfeature extraction. File format identification processes that depend on file\nsignatures can be easily evaded thanks to flexibility in the format\nspecifications of certain file formats. Although work has been done to identify\nfile formats using more comprehensive methods than file signatures, accurate\nidentification of polyglot files remains an open problem. Since malware\ndetection systems routinely perform file format-specific feature extraction,\npolyglot files need to be filtered out prior to ingestion by these systems.\nOtherwise, malicious content could pass through undetected. To address the\nproblem of polyglot detection we assembled a data set using the mitra tool. We\nthen evaluated the performance of the most commonly used file identification\ntool, file. Finally, we demonstrated the accuracy, precision, recall and F1\nscore of a range of machine and deep learning models. Malconv2 and Catboost\ndemonstrated the highest recall on our data set with 95.16% and 95.34%,\nrespectively. These models can be incorporated into a malware detector's file\nprocessing pipeline to filter out potentially malicious polyglots before file\nformat-dependent feature extraction takes place.",
    "descriptor": "",
    "authors": [
      "Luke Koch",
      "Sean Oesch",
      "Mary Adkisson",
      "Sam Erwin",
      "Brian Weber",
      "Amul Chaulagain"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07561"
  },
  {
    "id": "arXiv:2203.07562",
    "title": "Safe adaptation in multiagent competition",
    "abstract": "Achieving the capability of adapting to ever-changing environments is a\ncritical step towards building fully autonomous robots that operate safely in\ncomplicated scenarios. In multiagent competitive scenarios, agents may have to\nadapt to new opponents with previously unseen behaviors by learning from the\ninteraction experiences between the ego-agent and the opponent. However, this\nadaptation is susceptible to opponent exploitation. As the ego-agent updates\nits own behavior to exploit the opponent, its own behavior could become more\nexploitable as a result of overfitting to this specific opponent's behavior. To\novercome this difficulty, we developed a safe adaptation approach in which the\nego-agent is trained against a regularized opponent model, which effectively\navoids overfitting and consequently improves the robustness of the ego-agent's\npolicy. We evaluated our approach in the Mujoco domain with two competing\nagents. The experiment results suggest that our approach effectively achieves\nboth adaptation to the specific opponent that the ego-agent is interacting with\nand maintaining low exploitability to other possible opponent exploitation.",
    "descriptor": "",
    "authors": [
      "Macheng Shen",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.07562"
  },
  {
    "id": "arXiv:2203.07565",
    "title": "An asymptotically compatible coupling formulation for nonlocal interface  problems with jumps",
    "abstract": "We introduce a mathematically rigorous formulation for a nonlocal interface\nproblem with jumps and propose an asymptotically compatible finite element\ndiscretization for the weak form of the interface problem. After proving the\nwell-posedness of the weak form, we demonstrate that solutions to the nonlocal\ninterface problem converge to the corresponding local counterpart when the\nnonlocal data are appropriately prescribed. Several numerical tests in one and\ntwo dimensions show the applicability of our technique, its numerical\nconvergence to exact nonlocal solutions, its convergence to the local limit\nwhen the horizons vanish, and its robustness with respect to the patch test.",
    "descriptor": "",
    "authors": [
      "Christian Glusa",
      "Marta D'Elia",
      "Giacomo Capodaglio",
      "Max Gunzburger",
      "Pavel B. Bochev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.07565"
  },
  {
    "id": "arXiv:2203.07566",
    "title": "ETH-tight algorithms for finding surfaces in simplicial complexes of  bounded treewidth",
    "abstract": "Given a simplicial complex with $n$ simplices, we consider the Connected\nSubsurface Recognition (c-SR) problem of finding a subcomplex that is\nhomeomorphic to a given connected surface with a fixed boundary. We also study\nthe related Sum-of-Genus Subsurface Recognition (SoG) problem, where we instead\nsearch for a surface whose boundary, number of connected components, and total\ngenus are given.\nFor both of these problems, we give parameterized algorithms with respect to\nthe treewidth $k$ of the Hasse diagram that run in $2^{O(k \\log k)}n^{O(1)}$\ntime. For the SoG problem, we also prove that our algorithm is optimal assuming\nthe exponential-time hypothesis. In fact, we prove the stronger result that our\nalgorithm is ETH-tight even without restriction on the total genus.",
    "descriptor": "\nComments: This paper contains some material that previously appeared at arXiv:2107.10339. The split into two papers reflects new material and a change in authorship in this version. Accepted to SoCG 2022\n",
    "authors": [
      "Mitchell Black",
      "Nello Blaser",
      "Amir Nayyeri",
      "Erlend Raa V\u00e5gset"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.07566"
  },
  {
    "id": "arXiv:2203.07567",
    "title": "Testing a Drop of Liquid Using Smartphone LiDAR",
    "abstract": "We present the first system to determine fluid properties using the LiDAR\nsensors present on modern smartphones. Traditional methods of measuring\nproperties like viscosity require expensive laboratory equipment or a\nrelatively large amount of fluid. In contrast, our smartphone-based method is\naccessible, contactless and works with just a single drop of liquid. Our design\nworks by targeting a coherent LiDAR beam from the phone onto the liquid. Using\nthe phone's camera, we capture the characteristic laser speckle pattern that is\nformed by the interference of light reflecting from light-scattering particles.\nBy correlating the fluctuations in speckle intensity over time, we can\ncharacterize the Brownian motion within the liquid which is correlated with its\nviscosity. The speckle pattern can be captured on a range of phone cameras and\ndoes not require external magnifiers. Our results show that we can distinguish\nbetween different fat contents as well as identify adulterated milk. Further,\nalgorithms can classify between ten different liquids using the smartphone\nLiDAR speckle patterns. Finally, we conducted a clinical study with whole blood\nsamples across 30 patients showing that our approach can distinguish between\ncoagulated and uncoagulated blood using a single drop of blood.",
    "descriptor": "\nComments: 27 pages, 15 figures, accepted at IMWUT\n",
    "authors": [
      "Justin Chan",
      "Ananditha Raghunath",
      "Kelly E. Michaelsen",
      "Shyamnath Gollakota"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2203.07567"
  },
  {
    "id": "arXiv:2203.07577",
    "title": "Efficient and Optimal Fixed-Time Regret with Two Experts",
    "abstract": "Prediction with expert advice is a foundational problem in online learning.\nIn instances with $T$ rounds and $n$ experts, the classical Multiplicative\nWeights Update method suffers at most $\\sqrt{(T/2)\\ln n}$ regret when $T$ is\nknown beforehand. Moreover, this is asymptotically optimal when both $T$ and\n$n$ grow to infinity. However, when the number of experts $n$ is small/fixed,\nalgorithms with better regret guarantees exist. Cover showed in 1967 a dynamic\nprogramming algorithm for the two-experts problem restricted to $\\{0,1\\}$ costs\nthat suffers at most $\\sqrt{T/2\\pi} + O(1)$ regret with $O(T^2)$ pre-processing\ntime. In this work, we propose an optimal algorithm for prediction with two\nexperts' advice that works even for costs in $[0,1]$ and with $O(1)$ processing\ntime per turn. Our algorithm builds up on recent work on the experts problem\nbased on techniques and tools from stochastic calculus.",
    "descriptor": "\nComments: 29 pages, 13 pages of main text, published in ALT 2022 (PMLR vol. 167)\n",
    "authors": [
      "Laura Greenstreet",
      "Nicholas J. A. Harvey",
      "Victor Sanches Portella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.07577"
  },
  {
    "id": "arXiv:2203.07580",
    "title": "TSM: Measuring the Enticement of Honeyfiles with Natural Language  Processing",
    "abstract": "Honeyfile deployment is a useful breach detection method in cyber deception\nthat can also inform defenders about the intent and interests of intruders and\nmalicious insiders. A key property of a honeyfile, enticement, is the extent to\nwhich the file can attract an intruder to interact with it. We introduce a\nnovel metric, Topic Semantic Matching (TSM), which uses topic modelling to\nrepresent files in the repository and semantic matching in an embedding vector\nspace to compare honeyfile text and topic words robustly. We also present a\nhoneyfile corpus created with different Natural Language Processing (NLP)\nmethods. Experiments show that TSM is effective in inter-corpus comparisons and\nis a promising tool to measure the enticement of honeyfiles. TSM is the first\nmeasure to use NLP techniques to quantify the enticement of honeyfile content\nthat compares the essential topical content of local contexts to honeyfiles and\nis robust to paraphrasing.",
    "descriptor": "",
    "authors": [
      "Roelien C. Timmer",
      "David Liebowitz",
      "Surya Nepal",
      "Salil Kanhere"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07580"
  },
  {
    "id": "arXiv:2203.07583",
    "title": "Distributed Coded Modulation Schemes for Multiple Access Relay Channels",
    "abstract": "In this paper, we investigate network nest coded modulation schemes for\nmultiple access relay channels. The performance of the distributed systems\nwhich are based on distributed convolutional codes with network coded\nmodulation is presented. An analytical upper bound on bit error probability\nperformance for the studied distributed systems with Maximum Likelihood\nSequence Detection (MLSD) is derived. The constructured bounds for the\ninvestigated systems are shown to be asymptotically tight for increasing\nchannel Signal-to-Noise Ratio (SNR) values",
    "descriptor": "",
    "authors": [
      "Zihuai Lin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.07583"
  },
  {
    "id": "arXiv:2203.07584",
    "title": "Chains, Koch Chains, and Point Sets with many Triangulations",
    "abstract": "We introduce the abstract notion of a chain, which is a sequence of $n$\npoints in the plane, ordered by $x$-coordinates, so that the edge between any\ntwo consecutive points is unavoidable as far as triangulations are concerned. A\ngeneral theory of the structural properties of chains is developed, alongside a\ngeneral understanding of their number of triangulations.\nWe also describe an intriguing new and concrete configuration, which we call\nthe Koch chain due to its similarities to the Koch curve. A specific\nconstruction based on Koch chains is then shown to have $\\Omega(9.08^n)$\ntriangulations. This is a significant improvement over the previous and\nlong-standing lower bound of $\\Omega(8.65^n)$ for the maximum number of\ntriangulations of planar point sets.",
    "descriptor": "",
    "authors": [
      "Daniel Rutschmann",
      "Manuel Wettstein"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.07584"
  },
  {
    "id": "arXiv:2203.07585",
    "title": "Accelerating Stochastic Probabilistic Inference",
    "abstract": "Recently, Stochastic Variational Inference (SVI) has been increasingly\nattractive thanks to its ability to find good posterior approximations of\nprobabilistic models. It optimizes the variational objective with stochastic\noptimization, following noisy estimates of the natural gradient. However,\nalmost all the state-of-the-art SVI algorithms are based on first-order\noptimization algorithm and often suffer from poor convergence rate. In this\npaper, we bridge the gap between second-order methods and stochastic\nvariational inference by proposing a second-order based stochastic variational\ninference approach. In particular, firstly we derive the Hessian matrix of the\nvariational objective. Then we devise two numerical schemes to implement\nsecond-order SVI efficiently. Thorough empirical evaluations are investigated\non both synthetic and real dataset to backup both the effectiveness and\nefficiency of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Minta Liu",
      "Suliang Bu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.07585"
  },
  {
    "id": "arXiv:2203.07586",
    "title": "Long Document Summarization with Top-down and Bottom-up Inference",
    "abstract": "Text summarization aims to condense long documents and retain key\ninformation. Critical to the success of a summarization model is the faithful\ninference of latent representations of words or tokens in the source documents.\nMost recent models infer the latent representations with a transformer encoder,\nwhich is purely bottom-up. Also, self-attention-based inference models face the\nchallenge of quadratic complexity with respect to sequence length. We propose a\nprincipled inference framework to improve summarization models on these two\naspects. Our framework assumes a hierarchical latent structure of a document\nwhere the top-level captures the long range dependency at a coarser time scale\nand the bottom token level preserves the details. Critically, this hierarchical\nstructure enables token representations to be updated in both a bottom-up and\ntop-down manner. In the bottom-up pass, token representations are inferred with\nlocal self-attention to leverage its efficiency. Top-down correction is then\napplied to allow tokens to capture long-range dependency. We demonstrate the\neffectiveness of the proposed framework on a diverse set of summarization\ndatasets, including narrative, conversational, scientific documents and news.\nOur model achieves (1) competitive or better performance on short documents\nwith higher memory and compute efficiency, compared to full attention\ntransformers, and (2) state-of-the-art performance on a wide range of long\ndocument summarization benchmarks, compared to recent efficient transformers.\nWe also show that our model can summarize an entire book and achieve\ncompetitive performance using $0.27\\%$ parameters (464M vs. 175B) and much less\ntraining data, compared to a recent GPT-3-based model. These results indicate\nthe general applicability and benefits of the proposed framework.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Bo Pang",
      "Erik Nijkamp",
      "Wojciech Kry\u015bci\u0144ski",
      "Silvio Savarese",
      "Yingbo Zhou",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07586"
  },
  {
    "id": "arXiv:2203.07588",
    "title": "When Cell-Free Massive MIMO Meets OTFS Modulation: The Downlink Case",
    "abstract": "We provide a performance evaluation of orthogonal time frequency space (OTFS)\nmodulation in cell-free massive MIMO (multiple-input multiple-output) systems.\nBy leveraging the inherent sparsity of the delay-Doppler (DD) representation of\ntime-varying channels, we apply the embedded pilot-aided channel estimation\nmethod with reduced guard intervals and derive the minimum mean-square error\nestimate of the channel gains from received uplink pilots at the access points\n(APs). Each AP applies conjugate beamforming to transmit data to the users. We\nderive a closed-form expression for the individual user downlink throughput as\na function of the numbers of APs, users and DD channel estimate parameters. We\ncompare the OTFS performance with that of orthogonal frequency division\nmultiplexing (OFDM) at high-mobility conditions. Our findings reveal that with\nuncorrelated shadowing, cell-free massive MIMO with OTFS modulation achieves up\nto 35% gain in 95%-likely per-user throughput, compared with the OFDM\ncounterpart. Finally, the increase in the per user throughput is more\npronounced at the median rates over the correlated shadowing scenarios.",
    "descriptor": "\nComments: 6 pages, 2 figures, accepted by IEEE ICC 2022\n",
    "authors": [
      "Mohammadali Mohammadi",
      "Hien Quoc Ngo",
      "Michail Matthaiou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.07588"
  },
  {
    "id": "arXiv:2203.07589",
    "title": "Sim-to-Real Learning of Footstep-Constrained Bipedal Dynamic Walking",
    "abstract": "Recently, work on reinforcement learning (RL) for bipedal robots has\nsuccessfully learned controllers for a variety of dynamic gaits with robust\nsim-to-real demonstrations. In order to maintain balance, the learned\ncontrollers have full freedom of where to place the feet, resulting in highly\nrobust gaits. In the real world however, the environment will often impose\nconstraints on the feasible footstep locations, typically identified by\nperception systems. Unfortunately, most demonstrated RL controllers on bipedal\nrobots do not allow for specifying and responding to such constraints. This\nmissing control interface greatly limits the real-world application of current\nRL controllers. In this paper, we aim to maintain the robust and dynamic nature\nof learned gaits while also respecting footstep constraints imposed externally.\nWe develop an RL formulation for training dynamic gait controllers that can\nrespond to specified touchdown locations. We then successfully demonstrate\nsimulation and sim-to-real performance on the bipedal robot Cassie. In\naddition, we use supervised learning to induce a transition model for\naccurately predicting the next touchdown locations that the controller can\nachieve given the robot's proprioceptive observations. This model paves the way\nfor integrating the learned controller into a full-order robot locomotion\nplanner that robustly satisfies both balance and environmental constraints.",
    "descriptor": "\nComments: Accepted at ICRA 2022. Video will be uploaded later\n",
    "authors": [
      "Helei Duan",
      "Ashish Malik",
      "Jeremy Dao",
      "Aseem Saxena",
      "Kevin Green",
      "Jonah Siekmann",
      "Alan Fern",
      "Jonathan Hurst"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07589"
  },
  {
    "id": "arXiv:2203.07593",
    "title": "Distraction is All You Need for Fairness",
    "abstract": "With the recent growth in artificial intelligence models and its expanding\nrole in automated decision making, ensuring that these models are not biased is\nof vital importance. There is an abundance of evidence suggesting that these\nmodels could contain or even amplify the bias present in the data on which they\nare trained, inherent to their objective function and learning algorithms. In\nthis paper, we propose a novel classification algorithm that improves fairness,\nwhile maintaining accuracy of the predictions. Utilizing the embedding layer of\na pre-trained classifier for the protected attributes, the network uses an\nattention layer to distract the classification from depending on the protected\nattribute in its predictions. We compare our model with six state-of-the-art\nmethodologies proposed in fairness literature, and show that the model is\nsuperior to those methods in terms of minimizing bias while maintaining\naccuracy.",
    "descriptor": "",
    "authors": [
      "Mehdi Yazdani-Jahromi",
      "AmirArsalan Rajabi",
      "Aida Tayebi",
      "Ozlem Ozmen Garibay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07593"
  },
  {
    "id": "arXiv:2203.07596",
    "title": "Task-Agnostic Robust Representation Learning",
    "abstract": "It has been reported that deep learning models are extremely vulnerable to\nsmall but intentionally chosen perturbations of its input. In particular, a\ndeep network, despite its near-optimal accuracy on the clean images, often\nmis-classifies an image with a worst-case but humanly imperceptible\nperturbation (so-called adversarial examples). To tackle this problem, a great\namount of research has been done to study the training procedure of a network\nto improve its robustness. However, most of the research so far has focused on\nthe case of supervised learning. With the increasing popularity of\nself-supervised learning methods, it is also important to study and improve the\nrobustness of their resulting representation on the downstream tasks. In this\npaper, we study the problem of robust representation learning with unlabeled\ndata in a task-agnostic manner. Specifically, we first derive an upper bound on\nthe adversarial loss of a prediction model (which is based on the learned\nrepresentation) on any downstream task, using its loss on the clean data and a\nrobustness regularizer. Moreover, the regularizer is task-independent, thus we\npropose to minimize it directly during the representation learning phase to\nmake the downstream prediction model more robust. Extensive experiments show\nthat our method achieves preferable adversarial performance compared to\nrelevant baselines.",
    "descriptor": "",
    "authors": [
      "A. Tuan Nguyen",
      "Ser Nam Lim",
      "Philip Torr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07596"
  },
  {
    "id": "arXiv:2203.07597",
    "title": "Quantum Finite Automata and Quiver Algebras",
    "abstract": "We find an application in quantum finite automata for the ideas and results\nof [JL21] and [JL22]. We reformulate quantum finite automata with multiple-time\nmeasurements using the algebraic notion of near-ring. This gives a unified\nunderstanding towards quantum computing and deep learning. When the near-ring\ncomes from a quiver, we have a nice moduli space of computing machines with\nmetric that can be optimized by gradient descent.",
    "descriptor": "",
    "authors": [
      "George Jeffreys",
      "Siu-Cheong Lau"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)",
      "Algebraic Geometry (math.AG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.07597"
  },
  {
    "id": "arXiv:2203.07600",
    "title": "Procedural Text Understanding via Scene-Wise Evolution",
    "abstract": "Procedural text understanding requires machines to reason about entity states\nwithin the dynamical narratives. Current procedural text understanding\napproaches are commonly \\textbf{entity-wise}, which separately track each\nentity and independently predict different states of each entity. Such an\nentity-wise paradigm does not consider the interaction between entities and\ntheir states. In this paper, we propose a new \\textbf{scene-wise} paradigm for\nprocedural text understanding, which jointly tracks states of all entities in a\nscene-by-scene manner. Based on this paradigm, we propose \\textbf{S}cene\n\\textbf{G}raph \\textbf{R}easoner (\\textbf{SGR}), which introduces a series of\ndynamically evolving scene graphs to jointly formulate the evolution of\nentities, states and their associations throughout the narrative. In this way,\nthe deep interactions between all entities and states can be jointly captured\nand simultaneously derived from scene graphs. Experiments show that SGR not\nonly achieves the new state-of-the-art performance but also significantly\naccelerates the speed of reasoning.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Jialong Tang",
      "Hongyu Lin",
      "Meng Liao",
      "Yaojie Lu",
      "Xianpei Han",
      "Le Sun",
      "Weijian Xie",
      "Jin Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07600"
  },
  {
    "id": "arXiv:2203.07601",
    "title": "Automatic HFL(Z) Validity Checking for Program Verification",
    "abstract": "We propose an automated method for checking the validity of a formula of\nHFL(Z), a higher-order logic with fixpoint operators and integers. Combined\nwith Kobayashi et al.'s reduction from higher-order program verification to\nHFL(Z) validity checking, our method yields a fully automated verification\nmethod for temporal properties of higher-order functional programs. We have\nimplemented our method and obtained promising experimental results.",
    "descriptor": "",
    "authors": [
      "Kento Tanahashi",
      "Naoki Kobayashi",
      "Ryosuke Sato"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.07601"
  },
  {
    "id": "arXiv:2203.07603",
    "title": "SmartValidator: A Framework for Automatic Identification and  Classification of Cyber Threat Data",
    "abstract": "A wide variety of Cyber Threat Information (CTI) is used by Security\nOperation Centres (SOCs) to perform validation of security incidents and\nalerts. Security experts manually define different types of rules and scripts\nbased on CTI to perform validation tasks. These rules and scripts need to be\nupdated continuously due to evolving threats, changing SOCs' requirements and\ndynamic nature of CTI. The manual process of updating rules and scripts delays\nthe response to attacks. To reduce the burden of human experts and accelerate\nresponse, we propose a novel Artificial Intelligence (AI) based framework,\nSmartValidator. SmartValidator leverages Machine Learning (ML) techniques to\nenable automated validation of alerts. It consists of three layers to perform\nthe tasks of data collection, model building and alert validation. It projects\nthe validation task as a classification problem. Instead of building and saving\nmodels for all possible requirements, we propose to automatically construct the\nvalidation models based on SOC's requirements and CTI. We built a Proof of\nConcept (PoC) system with eight ML algorithms, two feature engineering\ntechniques and 18 requirements to investigate the effectiveness and efficiency\nof SmartValidator. The evaluation results showed that when prediction models\nwere built automatically for classifying cyber threat data, the F1-score of\n75\\% of the models were above 0.8, which indicates adequate performance of the\nPoC for use in a real-world organization. The results further showed that\ndynamic construction of prediction models required 99\\% less models to be built\nthan pre-building models for all possible requirements. The framework can be\nfollowed by various industries to accelerate and automate the validation of\nalerts and incidents based on their CTI and SOC's preferences.",
    "descriptor": "",
    "authors": [
      "Chadni Islam",
      "M. Ali Babar",
      "Roland Croft",
      "Helge Janicke"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.07603"
  },
  {
    "id": "arXiv:2203.07605",
    "title": "Online Task Assignment Problems with Reusable Resources",
    "abstract": "We study online task assignment problem with reusable resources, motivated by\npractical applications such as ridesharing, crowdsourcing and job hiring. In\nthe problem, we are given a set of offline vertices (agents), and, at each\ntime, an online vertex (task) arrives randomly according to a known\ntime-dependent distribution. Upon arrival, we assign the task to agents\nimmediately and irrevocably. The goal of the problem is to maximize the\nexpected total profit produced by completed tasks. The key features of our\nproblem are (1) an agent is reusable, i.e., an agent comes back to the market\nafter completing the assigned task, (2) an agent may reject the assigned task\nto stay the market, and (3) a task may accommodate multiple agents. The setting\ngeneralizes that of existing work in which an online task is assigned to one\nagent under (1).\nIn this paper, we propose an online algorithm that is $1/2$-competitive for\nthe above setting, which is tight. Moreover, when each agent can reject\nassigned tasks at most $\\Delta$ times, the algorithm is shown to have the\ncompetitive ratio $\\Delta/(3\\Delta-1)\\geq 1/3$. We also evaluate our proposed\nalgorithm with numerical experiments.",
    "descriptor": "\nComments: Appeared in AAAI-22\n",
    "authors": [
      "Hanna Sumita",
      "Shinji Ito",
      "Kei Takemura",
      "Daisuke Hatano",
      "Takuro Fukunaga",
      "Naonori Kakimura",
      "Ken-ichi Kawarabayashi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07605"
  },
  {
    "id": "arXiv:2203.07613",
    "title": "CARETS: A Consistency And Robustness Evaluative Test Suite for VQA",
    "abstract": "We introduce CARETS, a systematic test suite to measure consistency and\nrobustness of modern VQA models through a series of six fine-grained capability\ntests. In contrast to existing VQA test sets, CARETS features balanced question\ngeneration to create pairs of instances to test models, with each pair focusing\non a specific capability such as rephrasing, logical symmetry or image\nobfuscation. We evaluate six modern VQA systems on CARETS and identify several\nactionable weaknesses in model comprehension, especially with concepts such as\nnegation, disjunction, or hypernym invariance. Interestingly, even the most\nsophisticated models are sensitive to aspects such as swapping the order of\nterms in a conjunction or varying the number of answer choices mentioned in the\nquestion. We release CARETS to be used as an extensible tool for evaluating\nmulti-modal model robustness.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Carlos E. Jimenez",
      "Olga Russakovsky",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07613"
  },
  {
    "id": "arXiv:2203.07615",
    "title": "Learning What Not to Segment: A New Perspective on Few-Shot Segmentation",
    "abstract": "Recently few-shot segmentation (FSS) has been extensively developed. Most\nprevious works strive to achieve generalization through the meta-learning\nframework derived from classification tasks; however, the trained models are\nbiased towards the seen classes instead of being ideally class-agnostic, thus\nhindering the recognition of new concepts. This paper proposes a fresh and\nstraightforward insight to alleviate the problem. Specifically, we apply an\nadditional branch (base learner) to the conventional FSS model (meta learner)\nto explicitly identify the targets of base classes, i.e., the regions that do\nnot need to be segmented. Then, the coarse results output by these two learners\nin parallel are adaptively integrated to yield precise segmentation prediction.\nConsidering the sensitivity of meta learner, we further introduce an adjustment\nfactor to estimate the scene differences between the input image pairs for\nfacilitating the model ensemble forecasting. The substantial performance gains\non PASCAL-5i and COCO-20i verify the effectiveness, and surprisingly, our\nversatile scheme sets a new state-of-the-art even with two plain learners.\nMoreover, in light of the unique nature of the proposed approach, we also\nextend it to a more realistic but challenging setting, i.e., generalized FSS,\nwhere the pixels of both base and novel classes are required to be determined.\nThe source code is available at github.com/chunbolang/BAM.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Chunbo Lang",
      "Gong Cheng",
      "Binfei Tu",
      "Junwei Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07615"
  },
  {
    "id": "arXiv:2203.07616",
    "title": "Visualization in virtual reality: a systematic review",
    "abstract": "Rapidly growing virtual reality (VR) technologies and techniques have gained\nimportance over the past few years, and academics and practitioners have been\nsearching for efficient visualizations in VR. To date, emphasis has been on the\nemployment of game technologies. Despite the growing interest and discussion,\nvisualization studies have lacked a common baseline in the transition period of\n2D visualizations to immersive ones. To this end, the presented study aims to\nprovide a systematic literature review that explains the state-of-the-art\nresearch and future trends on visualization in virtual reality. The research\nframework is grounded in empirical and theoretical works of visualization. We\ncharacterize the reviewed literature based on three dimensions: (a) Connection\nwith visualization background and theory, (b) Evaluation and design\nconsiderations for virtual reality visualization, and (c) Empirical studies.\nThe results from this systematic review suggest that: (1) There are only a few\nstudies that focus on creating standard guidelines for virtual reality, and\neach study individually provides a framework or employs previous studies on\ntraditional 2D visualizations; (2) With the myriad of advantages provided for\nvisualization and virtual reality, most of the studies prefer to use game\nengines; (3) Although game engines are extensively used, they are not\nconvenient for critical scientific studies; and (4) 3D versions of traditional\nstatistical visualization techniques, such as bar plots and scatter plots, are\nstill commonly used in the data visualization context. This systematic review\nattempts to add to the literature a clear picture of the emerging contexts,\ndifferent elements, and their interdependencies.",
    "descriptor": "",
    "authors": [
      "Elif Hilal Korkut",
      "Elif Surer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.07616"
  },
  {
    "id": "arXiv:2203.07618",
    "title": "Do Language Models Plagiarize?",
    "abstract": "Past literature has illustrated that language models do not fully understand\nthe context and sensitivity of text and can sometimes memorize phrases or\nsentences present in their training sets. In this paper, we investigate whether\nthey not only memorize but also plagiarize training samples when generating\nartificial texts. Our findings support that they, especially GPT-2, reuse\nparticular pieces of texts from the training corpus with or without\nobfuscation. We have four main results: 1) language models with more capacity\nplagiarize more; 2) fine-tuned language models demonstrate differing patterns\nof plagiarism based on characteristics of auxiliary data; 3) sampling from\ntruncated language modeling distributions tends to heighten the degree of\nplagiarism as opposed to temperature sampling, and 4) plagiarism in language\nmodels can have serious privacy consequences. Overall, our work implies that\nfuture research on neural language models should take precautions to avoid\nmodels plagiarizing their training datasets.",
    "descriptor": "",
    "authors": [
      "Jooyoung Lee",
      "Thai Le",
      "Jinghui Chen",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07618"
  },
  {
    "id": "arXiv:2203.07621",
    "title": "Practical Detectability for Persistent Lock-Free Data Structures",
    "abstract": "Persistent memory (PM) is an emerging class of storage technology that\ncombines the benefits of DRAM and SSD. This characteristic inspires research on\npersistent objects in PM with fine-grained concurrency control. Among such\nobjects, persistent lock-free data structures (DSs) are particularly\ninteresting thanks to their efficiency and scalability. One of the most widely\nused correctness criteria for persistent lock-free DSs is durable\nlinearizability (Izraelevitz et. al., DISC 2016). However, durable\nlinearizability is insufficient to use persistent DSs for fault-tolerant\nsystems requiring exactly-once semantics for storage systems, because we may\nnot be able to detect whether an operation is performed when a crash occurs.\nWe present a practical programming framework for persistent lock-free DSs\nwith detectability. In contrast to the prior work on such DSs, our framework\nsupports (1) primitive detectable operations such as space-efficient\ncompare-and-swap, insertion, and deletion; (2) systematic transformation of\nlock-free DSs in DRAM into those in PM requiring modest efforts; (3) comparable\nperformance with non-detectable DSs by DRAM scratchpad optimization; and (4)\nrecovery from both full system and thread crashes. The key idea is memento\nobjects serving as a lightweight, precise, and per-thread checkpoints in PM. As\na case study, we implement lock-free and combining queues and hash tables with\ndetectability that outperform (and perform comparably) the state-of-the-art DSs\nwith (and without, respectively) detectability.",
    "descriptor": "",
    "authors": [
      "Kyeongmin Cho",
      "Seungmin Jeon",
      "Jeehoon Kang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.07621"
  },
  {
    "id": "arXiv:2203.07627",
    "title": "Multilingual Mix: Example Interpolation Improves Multilingual Neural  Machine Translation",
    "abstract": "Multilingual neural machine translation models are trained to maximize the\nlikelihood of a mix of examples drawn from multiple language pairs. The\ndominant inductive bias applied to these models is a shared vocabulary and a\nshared set of parameters across languages; the inputs and labels corresponding\nto examples drawn from different language pairs might still reside in distinct\nsub-spaces. In this paper, we introduce multilingual crossover encoder-decoder\n(mXEncDec) to fuse language pairs at an instance level. Our approach\ninterpolates instances from different language pairs into joint `crossover\nexamples' in order to encourage sharing input and output spaces across\nlanguages. To ensure better fusion of examples in multilingual settings, we\npropose several techniques to improve example interpolation across dissimilar\nlanguages under heavy data imbalance. Experiments on a large-scale WMT\nmultilingual dataset demonstrate that our approach significantly improves\nquality on English-to-Many, Many-to-English and zero-shot translation tasks\n(from +0.5 BLEU up to +5.5 BLEU points). Results on code-switching sets\ndemonstrate the capability of our approach to improve model generalization to\nout-of-distribution multilingual examples. We also conduct qualitative and\nquantitative representation comparisons to analyze the advantages of our\napproach at the representation level.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Yong Cheng",
      "Ankur Bapna",
      "Orhan Firat",
      "Yuan Cao",
      "Pidong Wang",
      "Wolfgang Macherey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07627"
  },
  {
    "id": "arXiv:2203.07628",
    "title": "P-STMO: Pre-Trained Spatial Temporal Many-to-One Model for 3D Human Pose  Estimation",
    "abstract": "This paper introduces a novel Pre-trained Spatial Temporal Many-to-One\n(P-STMO) model for 2D-to-3D human pose estimation task. To reduce the\ndifficulty of capturing spatial and temporal information, we divide this task\ninto two stages: pre-training (Stage I) and fine-tuning (Stage II). In Stage I,\na self-supervised pre-training sub-task, termed masked pose modeling, is\nproposed. The human joints in the input sequence are randomly masked in both\nspatial and temporal domains. A general form of denoising auto-encoder is\nexploited to recover the original 2D poses and the encoder is capable of\ncapturing spatial and temporal dependencies in this way. In Stage II, the\npre-trained encoder is loaded to STMO model and fine-tuned. The encoder is\nfollowed by a many-to-one frame aggregator to predict the 3D pose in the\ncurrent frame. Especially, an MLP block is utilized as the spatial feature\nextractor in STMO, which yields better performance than other methods. In\naddition, a temporal downsampling strategy is proposed to diminish data\nredundancy. Extensive experiments on two benchmarks show that our method\noutperforms state-of-the-art methods with fewer parameters and less\ncomputational overhead. For example, our P-STMO model achieves 42.1mm MPJPE on\nHuman3.6M dataset when using 2D poses from CPN as inputs. Meanwhile, it brings\na 1.5-7.1 times speedup to state-of-the-art methods. Code is available at\nhttps://github.com/paTRICK-swk/P-STMO.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Wenkang Shan",
      "Zhenhua Liu",
      "Xinfeng Zhang",
      "Shanshe Wang",
      "Siwei Ma",
      "Wen Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07628"
  },
  {
    "id": "arXiv:2203.07632",
    "title": "Graph Representation Learning for Popularity Prediction Problem: A  Survey",
    "abstract": "The online social platforms, like Twitter, Facebook, LinkedIn and WeChat,\nhave grown really fast in last decade and have been one of the most effective\nplatforms for people to communicate and share information with each other. Due\nto the \"word of mouth\" effects, information usually can spread rapidly on these\nsocial media platforms. Therefore, it is important to study the mechanisms\ndriving the information diffusion and quantify the consequence of information\nspread. A lot of efforts have been focused on this problem to help us better\nunderstand and achieve higher performance in viral marketing and advertising.\nOn the other hand, the development of neural networks has blossomed in the last\nfew years, leading to a large number of graph representation learning (GRL)\nmodels. Compared to traditional models, GRL methods are often shown to be more\neffective. In this paper, we present a comprehensive review for existing works\nusing GRL methods for popularity prediction problem, and categorize related\nliteratures into two big classes, according to their mainly used model and\ntechniques: embedding-based methods and deep learning methods. Deep learning\nmethod is further classified into six small classes: convolutional neural\nnetworks, graph convolutional networks, graph attention networks, graph neural\nnetworks, recurrent neural networks, and reinforcement learning. We compare the\nperformance of these different models and discuss their strengths and\nlimitations. Finally, we outline the challenges and future chances for\npopularity prediction problem.",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Tiantian Chen",
      "Jianxiong Guo",
      "Weili Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07632"
  },
  {
    "id": "arXiv:2203.07633",
    "title": "Improving Event Representation via Simultaneous Weakly Supervised  Contrastive Learning and Clustering",
    "abstract": "Representations of events described in text are important for various tasks.\nIn this work, we present SWCC: a Simultaneous Weakly supervised Contrastive\nlearning and Clustering framework for event representation learning. SWCC\nlearns event representations by making better use of co-occurrence information\nof events. Specifically, we introduce a weakly supervised contrastive learning\nmethod that allows us to consider multiple positives and multiple negatives,\nand a prototype-based clustering method that avoids semantically related events\nbeing pulled apart. For model training, SWCC learns representations by\nsimultaneously performing weakly supervised contrastive learning and\nprototype-based clustering. Experimental results show that SWCC outperforms\nother baselines on Hard Similarity and Transitive Sentence Similarity tasks. In\naddition, a thorough analysis of the prototype-based clustering method\ndemonstrates that the learned prototype vectors are able to implicitly capture\nvarious relations between events.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Jun Gao",
      "Wei Wang",
      "Changlong Yu",
      "Huan Zhao",
      "Wilfred Ng",
      "Ruifeng Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07633"
  },
  {
    "id": "arXiv:2203.07637",
    "title": "Lifelong Matrix Completion with Sparsity-Number",
    "abstract": "Matrix completion problem has been previously studied under various adaptive\nand passive settings. Previously, researchers have proposed passive, two-phase\nand single-phase algorithms using coherence parameter, and multi phase\nalgorithm using sparsity-number. It has been shown that the method using\nsparsity-number reaching to theoretical lower bounds in many conditions.\nHowever, the aforementioned method is running in many phases through the matrix\ncompletion process, therefore it makes much more informative decision at each\nstage. Hence, it is natural that the method outperforms previous algorithms. In\nthis paper, we are using the idea of sparsity-number and propose and\nsingle-phase column space recovery algorithm which can be extended to two-phase\nexact matrix completion algorithm. Moreover, we show that these methods are as\nefficient as multi-phase matrix recovery algorithm. We provide experimental\nevidence to illustrate the performance of our algorithm.",
    "descriptor": "",
    "authors": [
      "Ilqar Ramazanli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07637"
  },
  {
    "id": "arXiv:2203.07640",
    "title": "Unsupervised Keyphrase Extraction via Interpretable Neural Networks",
    "abstract": "Keyphrase extraction aims at automatically extracting a list of \"important\"\nphrases which represent the key concepts in a document. Prior approaches for\nunsupervised keyphrase extraction resort to heuristic notions of phrase\nimportance via embedding similarities or graph centrality, requiring extensive\ndomain expertise to develop them. Our work proposes an alternative operational\ndefinition: phrases that are most useful for predicting the topic of a text are\nimportant keyphrases. To this end, we propose INSPECT -- a self-explaining\nneural framework for identifying influential keyphrases by measuring the\npredictive impact of input phrases on the downstream task of topic\nclassification. We show that this novel approach not only alleviates the need\nfor ad-hoc heuristics but also achieves state-of-the-art results in\nunsupervised keyphrase extraction across four diverse datasets in two domains:\nscientific publications and news articles. Ultimately, our study suggests a new\nusage of interpretable neural networks as an intrinsic component in NLP\nsystems, and not only as a tool for explaining model predictions to humans.",
    "descriptor": "",
    "authors": [
      "Rishabh Joshi",
      "Vidhisha Balachandran",
      "Emily Saldanha",
      "Maria Glenski",
      "Svitlana Volkova",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07640"
  },
  {
    "id": "arXiv:2203.07643",
    "title": "Can Synthetic Translations Improve Bitext Quality?",
    "abstract": "Synthetic translations have been used for a wide range of NLP tasks primarily\nas a means of data augmentation. This work explores, instead, how synthetic\ntranslations can be used to revise potentially imperfect reference translations\nin mined bitext. We find that synthetic samples can improve bitext quality\nwithout any additional bilingual supervision when they replace the originals\nbased on a semantic equivalence classifier that helps mitigate NMT noise. The\nimproved quality of the revised bitext is confirmed intrinsically via human\nevaluation and extrinsically through bilingual induction and MT tasks.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Eleftheria Briakou",
      "Marine Carpuat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07643"
  },
  {
    "id": "arXiv:2203.07644",
    "title": "Efficient Long Sequence Encoding via Synchronization",
    "abstract": "Pre-trained Transformer models have achieved successes in a wide range of NLP\ntasks, but are inefficient when dealing with long input sequences. Existing\nstudies try to overcome this challenge via segmenting the long sequence\nfollowed by hierarchical encoding or post-hoc aggregation. We propose a\nsynchronization mechanism for hierarchical encoding. Our approach first\nidentifies anchor tokens across segments and groups them by their roles in the\noriginal input sequence. Then inside Transformer layer, anchor embeddings are\nsynchronized within their group via a self-attention module. Our approach is a\ngeneral framework with sufficient flexibility -- when adapted to a new task, it\nis easy to be enhanced with the task-specific anchor definitions. Experiments\non two representative tasks with different types of long input texts,\nNarrativeQA summary setting and wild multi-hop reasoning from HotpotQA,\ndemonstrate that our approach is able to improve the global information\nexchange among segments while maintaining efficiency.",
    "descriptor": "\nComments: 5 pages, short paper\n",
    "authors": [
      "Xiangyang Mou",
      "Mo Yu",
      "Bingsheng Yao",
      "Lifu Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07644"
  },
  {
    "id": "arXiv:2203.07648",
    "title": "InfoDCL: A Distantly Supervised Contrastive Learning Framework for  Social Meaning",
    "abstract": "Existing supervised contrastive learning frameworks suffer from two major\ndrawbacks: (i) they depend on labeled data, which is limited for the majority\nof tasks in real-world, and (ii) they incorporate inter-class relationships\nbased on instance-level information, while ignoring corpus-level information,\nfor weighting negative samples. To mitigate these challenges, we propose an\neffective distantly supervised contrastive learning framework (InfoDCL) that\nmakes use of naturally occurring surrogate labels in the context of contrastive\nlearning and employs pointwise mutual information to leverage corpus-level\ninformation. Our framework outperforms an extensive set of existing contrastive\nlearning methods (self-supervised, supervised, and weakly supervised) on a wide\nrange of social meaning tasks (in-domain and out-of-domain), in both the\ngeneral and few-shot settings. Our method is also language-agnostic, as we\ndemonstrate on three languages in addition to English.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Chiyu Zhang",
      "Muhammad Abdul-Mageed",
      "Ganesh Jawahar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07648"
  },
  {
    "id": "arXiv:2203.07653",
    "title": "Generalized but not Robust? Comparing the Effects of Data Modification  Methods on Out-of-Domain Generalization and Adversarial Robustness",
    "abstract": "Data modification, either via additional training datasets, data\naugmentation, debiasing, and dataset filtering, has been proposed as an\neffective solution for generalizing to out-of-domain (OOD) inputs, in both\nnatural language processing and computer vision literature. However, the effect\nof data modification on adversarial robustness remains unclear. In this work,\nwe conduct a comprehensive study of common data modification strategies and\nevaluate not only their in-domain and OOD performance, but also their\nadversarial robustness (AR). We also present results on a two-dimensional\nsynthetic dataset to visualize the effect of each method on the training\ndistribution. This work serves as an empirical study towards understanding the\nrelationship between generalizing to unseen domains and defending against\nadversarial perturbations. Our findings suggest that more data (either via\nadditional datasets or data augmentation) benefits both OOD accuracy and AR.\nHowever, data filtering (previously shown to improve OOD accuracy on natural\nlanguage inference) hurts OOD accuracy on other tasks such as question\nanswering and image classification. We provide insights from our experiments to\ninform future work in this direction.",
    "descriptor": "\nComments: ACL 2022 Findings\n",
    "authors": [
      "Tejas Gokhale",
      "Swaroop Mishra",
      "Man Luo",
      "Bhavdeep Singh Sachdeva",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07653"
  },
  {
    "id": "arXiv:2203.07656",
    "title": "Wave-SAN: Wavelet based Style Augmentation Network for Cross-Domain  Few-Shot Learning",
    "abstract": "Previous few-shot learning (FSL) works mostly are limited to natural images\nof general concepts and categories. These works assume very high visual\nsimilarity between the source and target classes. In contrast, the recently\nproposed cross-domain few-shot learning (CD-FSL) aims at transferring knowledge\nfrom general nature images of many labeled examples to novel domain-specific\ntarget categories of only a few labeled examples. The key challenge of CD-FSL\nlies in the huge data shift between source and target domains, which is\ntypically in the form of totally different visual styles. This makes it very\nnontrivial to directly extend the classical FSL methods to address the CD-FSL\ntask. To this end, this paper studies the problem of CD-FSL by spanning the\nstyle distributions of the source dataset. Particularly, wavelet transform is\nintroduced to enable the decomposition of visual representations into\nlow-frequency components such as shape and style and high-frequency components\ne.g., texture. To make our model robust to visual styles, the source images are\naugmented by swapping the styles of their low-frequency components with each\nother. We propose a novel Style Augmentation (StyleAug) module to implement\nthis idea. Furthermore, we present a Self-Supervised Learning (SSL) module to\nensure the predictions of style-augmented images are semantically similar to\nthe unchanged ones. This avoids the potential semantic drift problem in\nexchanging the styles. Extensive experiments on two CD-FSL benchmarks show the\neffectiveness of our method. Our codes and models will be released.",
    "descriptor": "",
    "authors": [
      "Yuqian Fu",
      "Yu Xie",
      "Yanwei Fu",
      "Jingjing Chen",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07656"
  },
  {
    "id": "arXiv:2203.07657",
    "title": "Seamlessly Integrating Factual Information and Social Content with  Persuasive Dialogue",
    "abstract": "Effective human-chatbot conversations need to achieve both coherence and\nefficiency. Complex conversation settings such as persuasion involve\ncommunicating changes in attitude or behavior, so users' perspectives need to\nbe carefully considered and addressed, even when not directly related to the\ntopic. In this work, we contribute a novel modular dialogue system framework\nthat seamlessly integrates factual information and social content into\npersuasive dialogue. Our framework is generalizable to any dialogue tasks that\nhave mixed social and task contents. We conducted a study that compared user\nevaluations of our framework versus a baseline end-to-end generation model. We\nfound our model was evaluated to be more favorable in all dimensions including\ncompetence and friendliness compared to the baseline model which does not\nexplicitly handle social content or factual questions.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Maximillian Chen",
      "Weiyan Shi",
      "Feifan Yan",
      "Ryan Hou",
      "Jingwen Zhang",
      "Saurav Sahay",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.07657"
  },
  {
    "id": "arXiv:2203.07658",
    "title": "Neural Radiance Projection",
    "abstract": "The proposed method, Neural Radiance Projection (NeRP), addresses the three\nmost fundamental shortages of training such a convolutional neural network on\nX-ray image segmentation: dealing with missing/limited human-annotated\ndatasets; ambiguity on the per-pixel label; and the imbalance across positive-\nand negative- classes distribution. By harnessing a generative adversarial\nnetwork, we can synthesize a massive amount of physics-based X-ray images,\nso-called Variationally Reconstructed Radiographs (VRRs), alongside their\nsegmentation from more accurate labeled 3D Computed Tomography data. As a\nresult, VRRs present more faithfully than other projection methods in terms of\nphoto-realistic metrics. Adding outputs from NeRP also surpasses the vanilla\nUNet models trained on the same pairs of X-ray images.",
    "descriptor": "\nComments: Accepted to IEEE ISBI 2022\n",
    "authors": [
      "Pham Ngoc Huy",
      "Tran Minh Quan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.07658"
  },
  {
    "id": "arXiv:2203.07662",
    "title": "What's in the Black Box? The False Negative Mechanisms Inside Object  Detectors",
    "abstract": "In object detection, false negatives arise when a detector fails to detect a\ntarget object. To understand why object detectors produce false negatives, we\nidentify five 'false negative mechanisms', where each mechanism describes how a\nspecific component inside the detector architecture failed. Focusing on\ntwo-stage and one-stage anchor-box object detector architectures, we introduce\na framework for quantifying these false negative mechanisms. Using this\nframework, we investigate why Faster R-CNN and RetinaNet fail to detect objects\nin benchmark vision datasets and robotics datasets. We show that a detector's\nfalse negative mechanisms differ significantly between computer vision\nbenchmark datasets and robotics deployment scenarios. This has implications for\nthe translation of object detectors developed for benchmark datasets to\nrobotics applications.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Dimity Miller",
      "Peyman Moghadam",
      "Mark Cox",
      "Matt Wildie",
      "Raja Jurdak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07662"
  },
  {
    "id": "arXiv:2203.07664",
    "title": "Can you even tell left from right? Presenting a new challenge for VQA",
    "abstract": "Visual Question Answering (VQA) needs a means of evaluating the strengths and\nweaknesses of models. One aspect of such an evaluation is the evaluation of\ncompositional generalisation, or the ability of a model to answer well on\nscenes whose scene-setups are different from the training set. Therefore, for\nthis purpose, we need datasets whose train and test sets differ significantly\nin composition. In this work, we present several quantitative measures of\ncompositional separation and find that popular datasets for VQA are not good\nevaluators. To solve this, we present Uncommon Objects in Unseen Configurations\n(UOUC), a synthetic dataset for VQA. UOUC is at once fairly complex while also\nbeing well-separated, compositionally. The object-class of UOUC consists of 380\nclasess taken from 528 characters from the Dungeons and Dragons game. The train\nset of UOUC consists of 200,000 scenes; whereas the test set consists of 30,000\nscenes. In order to study compositional generalisation, simple reasoning and\nmemorisation, each scene of UOUC is annotated with up to 10 novel questions.\nThese deal with spatial relationships, hypothetical changes to scenes,\ncounting, comparison, memorisation and memory-based reasoning. In total, UOUC\npresents over 2 million questions. UOUC also finds itself as a strong challenge\nto well-performing models for VQA. Our evaluation of recent models for VQA\nshows poor compositional generalisation, and comparatively lower ability\ntowards simple reasoning. These results suggest that UOUC could lead to\nadvances in research by being a strong benchmark for VQA.",
    "descriptor": "",
    "authors": [
      "Sai Raam Venkatraman",
      "Rishi Rao",
      "S. Balasubramanian",
      "Chandra Sekhar Vorugunti",
      "R. Raghunatha Sarma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07664"
  },
  {
    "id": "arXiv:2203.07665",
    "title": "One Agent To Rule Them All: Towards Multi-agent Conversational AI",
    "abstract": "The increasing volume of commercially available conversational agents (CAs)\non the market has resulted in users being burdened with learning and adopting\nmultiple agents to accomplish their tasks. Though prior work has explored\nsupporting a multitude of domains within the design of a single agent, the\ninteraction experience suffers due to the large action space of desired\ncapabilities. To address these problems, we introduce a new task BBAI:\nBlack-Box Agent Integration, focusing on combining the capabilities of multiple\nblack-box CAs at scale. We explore two techniques: question agent pairing and\nquestion response pairing aimed at resolving this task. Leveraging these\ntechniques, we design One For All (OFA), a scalable system that provides a\nunified interface to interact with multiple CAs. Additionally, we introduce\nMARS: Multi-Agent Response Selection, a new encoder model for question response\npairing that jointly encodes user question and agent response pairs. We\ndemonstrate that OFA is able to automatically and accurately integrate an\nensemble of commercially available CAs spanning disparate domains.\nSpecifically, using the MARS encoder we achieve the highest accuracy on our\nBBAI task, outperforming strong baselines.",
    "descriptor": "",
    "authors": [
      "Christopher Clarke",
      "Joseph Joshua Peper",
      "Karthik Krishnamurthy",
      "Walter Talamonti",
      "Kevin Leach",
      "Walter Lasecki",
      "Yiping Kang",
      "Lingjia Tang",
      "Jason Mars"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.07665"
  },
  {
    "id": "arXiv:2203.07667",
    "title": "SATS: Self-Attention Transfer for Continual Semantic Segmentation",
    "abstract": "Continually learning to segment more and more types of image regions is a\ndesired capability for many intelligent systems. However, such continual\nsemantic segmentation suffers from the same catastrophic forgetting issue as in\ncontinual classification learning. While multiple knowledge distillation\nstrategies originally for continual classification have been well adapted to\ncontinual semantic segmentation, they only consider transferring old knowledge\nbased on the outputs from one or more layers of deep fully convolutional\nnetworks. Different from existing solutions, this study proposes to transfer a\nnew type of information relevant to knowledge, i.e. the relationships between\nelements (Eg. pixels or small local regions) within each image which can\ncapture both within-class and between-class knowledge. The relationship\ninformation can be effectively obtained from the self-attention maps in a\nTransformer-style segmentation model. Considering that pixels belonging to the\nsame class in each image often share similar visual properties, a\nclass-specific region pooling is applied to provide more efficient relationship\ninformation for knowledge transfer. Extensive evaluations on multiple public\nbenchmarks support that the proposed self-attention transfer method can further\neffectively alleviate the catastrophic forgetting issue, and its flexible\ncombination with one or more widely adopted strategies significantly\noutperforms state-of-the-art solu",
    "descriptor": "",
    "authors": [
      "Yiqiao Qiu",
      "Yixing Shen",
      "Zhuohao Sun",
      "Yanchong Zheng",
      "Xiaobin Chang",
      "Weishi Zheng",
      "Ruixuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07667"
  },
  {
    "id": "arXiv:2203.07669",
    "title": "Progressive End-to-End Object Detection in Crowded Scenes",
    "abstract": "In this paper, we propose a new query-based detection framework for crowd\ndetection. Previous query-based detectors suffer from two drawbacks: first,\nmultiple predictions will be inferred for a single object, typically in crowded\nscenes; second, the performance saturates as the depth of the decoding stage\nincreases. Benefiting from the nature of the one-to-one label assignment rule,\nwe propose a progressive predicting method to address the above issues.\nSpecifically, we first select accepted queries prone to generate true positive\npredictions, then refine the rest noisy queries according to the previously\naccepted predictions. Experiments show that our method can significantly boost\nthe performance of query-based detectors in crowded scenes. Equipped with our\napproach, Sparse RCNN achieves 92.0\\% $\\text{AP}$, 41.4\\% $\\text{MR}^{-2}$ and\n83.2\\% $\\text{JI}$ on the challenging CrowdHuman \\cite{shao2018crowdhuman}\ndataset, outperforming the box-based method MIP \\cite{chu2020detection} that\nspecifies in handling crowded scenarios. Moreover, the proposed method, robust\nto crowdedness, can still obtain consistent improvements on moderately and\nslightly crowded datasets like CityPersons \\cite{zhang2017citypersons} and COCO\n\\cite{lin2014microsoft}. Code will be made publicly available at\nhttps://github.com/megvii-model/Iter-E2EDET.",
    "descriptor": "",
    "authors": [
      "Anlin Zheng",
      "Yuang Zhang",
      "Xiangyu Zhang",
      "Xiaojuan Qi",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07669"
  },
  {
    "id": "arXiv:2203.07670",
    "title": "Towards Adversarial Control Loops in Sensor Attacks: A Case Study to  Control the Kinematics and Actuation of Embedded Systems",
    "abstract": "Recent works investigated attacks on sensors by influencing analog sensor\ncomponents with acoustic, light, and electromagnetic signals. Such attacks can\nhave extensive security, reliability, and safety implications since many types\nof the targeted sensors are also widely used in critical process control,\nrobotics, automation, and industrial control systems. While existing works\nadvanced our understanding of the physical-level risks that are hidden from a\ndigital-domain perspective, gaps exist in how the attack can be guided to\nachieve system-level control in real-time, continuous processes. This paper\nproposes an adversarial control loop-based approach for real-time attacks on\ncontrol systems relying on sensors. We study how to utilize the system feedback\nextracted from physical-domain signals to guide the attacks. In the attack\nprocess, injection signals are adjusted in real time based on the extracted\nfeedback to exert targeted influence on a victim control system that is\ncontinuously affected by the injected perturbations and applying changes to the\nphysical environment. In our case study, we investigate how an external\nadversarial control system can be constructed over sensor-actuator systems and\ndemonstrate the attacks with program-controlled processes to manipulate the\nvictim system without accessing its internal statuses.",
    "descriptor": "",
    "authors": [
      "Yazhou Tu",
      "Sara Rampazzi",
      "Xiali Hei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.07670"
  },
  {
    "id": "arXiv:2203.07671",
    "title": "Safe Neurosymbolic Learning with Differentiable Symbolic Execution",
    "abstract": "We study the problem of learning worst-case-safe parameters for programs that\nuse neural networks as well as symbolic, human-written code. Such neurosymbolic\nprograms arise in many safety-critical domains. However, because they can use\nnondifferentiable operations, it is hard to learn their parameters using\nexisting gradient-based approaches to safe learning. Our approach to this\nproblem, Differentiable Symbolic Execution (DSE), samples control flow paths in\na program, symbolically constructs worst-case \"safety losses\" along these\npaths, and backpropagates the gradients of these losses through program\noperations using a generalization of the REINFORCE estimator. We evaluate the\nmethod on a mix of synthetic tasks and real-world benchmarks. Our experiments\nshow that DSE significantly outperforms the state-of-the-art DiffAI method on\nthese tasks.",
    "descriptor": "\nComments: Accepted as a poster at ICLR 2022\n",
    "authors": [
      "Chenxi Yang",
      "Swarat Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.07671"
  },
  {
    "id": "arXiv:2203.07673",
    "title": "Distributed-Memory Sparse Kernels for Machine Learning",
    "abstract": "Sampled Dense Times Dense Matrix Multiplication (SDDMM) and Sparse Times\nDense Matrix Multiplication (SpMM) appear in diverse settings, such as\ncollaborative filtering, document clustering, and graph embedding. Frequently,\nthe SDDMM output becomes the input sparse matrix for a subsequent SpMM\noperation. Existing work has focused on shared memory parallelization of these\nprimitives. While there has been extensive analysis of communication-minimizing\ndistributed 1.5D algorithms for SpMM, no such analysis exists for SDDMM or the\nback-to-back sequence of SDDMM and SpMM, termed FusedMM. We show that\ndistributed memory 1.5D and 2.5D algorithms for SpMM can be converted to\nalgorithms for SDDMM with identical communication costs and input / output data\nlayouts. Further, we give two communication-eliding strategies to reduce costs\nfurther for FusedMM kernels: either reusing the replication of an input dense\nmatrix for the SDDMM and SpMM in sequence, or fusing the local SDDMM and SpMM\nkernels.\nWe benchmark FusedMM algorithms on Cori, a Cray XC40 at LBNL, using\nErdos-Renyi random matrices and large real-world sparse matrices. On 256 nodes\nwith 68 cores each, 1.5D FusedMM algorithms using either communication eliding\napproach can save at least 30% of time spent exclusively in communication\ncompared to executing a distributed-memory SpMM and SDDMM kernel in sequence.\nOn real-world matrices with hundreds of millions of edges, all of our\nalgorithms exhibit at least a 10x speedup over the SpMM algorithm in PETSc. On\nthese matrices, our communication-eliding techniques exhibit runtimes up to 1.6\ntimes faster than an unoptimized sequence of SDDMM and SpMM. We embed and test\nthe scaling of our algorithms in real-world applications, including\ncollaborative filtering via alternating-least-squares and inference for\nattention-based graph neural networks.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Vivek Bharadwaj",
      "Aydin Bulu\u00e7",
      "James Demmel"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.07673"
  },
  {
    "id": "arXiv:2203.07676",
    "title": "An Introduction to Multi-Agent Reinforcement Learning and Review of its  Application to Autonomous Mobility",
    "abstract": "Many scenarios in mobility and traffic involve multiple different agents that\nneed to cooperate to find a joint solution. Recent advances in behavioral\nplanning use Reinforcement Learning to find effective and performant behavior\nstrategies. However, as autonomous vehicles and vehicle-to-X communications\nbecome more mature, solutions that only utilize single, independent agents\nleave potential performance gains on the road. Multi-Agent Reinforcement\nLearning (MARL) is a research field that aims to find optimal solutions for\nmultiple agents that interact with each other. This work aims to give an\noverview of the field to researchers in autonomous mobility. We first explain\nMARL and introduce important concepts. Then, we discuss the central paradigms\nthat underlie MARL algorithms, and give an overview of state-of-the-art methods\nand ideas in each paradigm. With this background, we survey applications of\nMARL in autonomous mobility scenarios and give an overview of existing\nscenarios and implementations.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Lukas M. Schmidt",
      "Johanna Brosig",
      "Axel Plinge",
      "Bjoern M. Eskofier",
      "Christopher Mutschler"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.07676"
  },
  {
    "id": "arXiv:2203.07678",
    "title": "Incorporating Heterophily into Graph Neural Networks for Graph  Classification",
    "abstract": "Graph neural networks (GNNs) often assume strong homophily in graphs, seldom\nconsidering heterophily which means connected nodes tend to have different\nclass labels and dissimilar features. In real-world scenarios, graphs may have\nnodes that exhibit both homophily and heterophily. Failing to generalize to\nthis setting makes many GNNs underperform in graph classification. In this\npaper, we address this limitation by identifying two useful designs and develop\na novel GNN architecture called IHGNN (Incorporating Heterophily into Graph\nNeural Networks). These designs include integration and separation of the ego-\nand neighbor-embeddings of nodes; and concatenation of all the node embeddings\nas the final graph-level readout function. In the first design, integration is\ncombined with separation by an injective function which is the composition of\nthe MLP and the concatenation function. The second design enables the\ngraph-level readout function to differentiate between different node\nembeddings. As the functions used in both the designs are injective, IHGNN,\nwhile being simple, has an expressiveness as powerful as the 1-WL. We\nempirically validate IHGNN on various graph datasets and demonstrate that it\nachieves state-of-the-art performance on the graph classification task.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Wei Ye",
      "Jiayi Yang",
      "Sourav Medya",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.07678"
  },
  {
    "id": "arXiv:2203.07679",
    "title": "Energy-efficient Dense DNN Acceleration with Signed Bit-slice  Architecture",
    "abstract": "As the number of deep neural networks (DNNs) to be executed on a mobile\nsystem-on-chip (SoC) increases, the mobile SoC suffers from the real-time DNN\nacceleration within its limited hardware resources and power budget. Although\nthe previous mobile neural processing units (NPUs) take advantage of low-bit\ncomputing and exploitation of the sparsity, it is incapable of accelerating\nhigh-precision and dense DNNs. This paper proposes energy-efficient signed\nbit-slice architecture which accelerates both high-precision and dense DNNs by\nexploiting a large number of zero values of signed bit-slices. Proposed signed\nbit-slice representation (SBR) changes signed $1111_{2}$ bit-slice to\n$0000_{2}$ by borrowing a $1$ value from its lower order of bit-slice. As a\nresult, it generates a large number of zero bit-slices even in dense DNNs.\nMoreover, it balances the positive and negative values of 2's complement data,\nallowing bit-slice based output speculation which pre-computes high order of\nbit-slices and skips the remaining dense low order of bit-slices. The signed\nbit-slice architecture compresses and skips the zero input signed bit-slices,\nand the zero skipping unit also supports the output skipping by masking the\nspeculated inputs as zero. Additionally, the heterogeneous network-on-chip\n(NoC) benefits the exploitation of data reusability and reduction of\ntransmission bandwidth. The paper introduces a specialized instruction set\narchitecture (ISA) and a hierarchical instruction decoder for the control of\nthe signed bit-slice architecture. Finally, the signed bit-slice architecture\noutperforms the previous bit-slice accelerator, Bit-fusion, over $\\times3.65$\nhigher area-efficiency, $\\times3.88$ higher energy-efficiency, and $\\times5.35$\nhigher throughput.",
    "descriptor": "",
    "authors": [
      "Dongseok Im",
      "Gwangtae Park",
      "Zhiyong Li",
      "Junha Ryu",
      "Hoi-Jun Yoo"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07679"
  },
  {
    "id": "arXiv:2203.07680",
    "title": "Optimal error estimates of a Crank--Nicolson finite element projection  method for magnetohydrodynamic equations",
    "abstract": "In this paper, we propose and analyze a fully discrete finite element\nprojection method for the magnetohydrodynamic (MHD) equations. A modified\nCrank--Nicolson method and the Galerkin finite element method are used to\ndiscretize the model in time and space, respectively, and appropriate\nsemi-implicit treatments are applied to the fluid convection term and two\ncoupling terms. These semi-implicit approximations result in a linear system\nwith variable coefficients for which the unique solvability can be proved\ntheoretically. In addition, we use a second-order decoupling projection method\nof the Van Kan type \\cite{vankan1986} in the Stokes solver, which computes the\nintermediate velocity field based on the gradient of the pressure from the\nprevious time level, and enforces the incompressibility constraint via the\nHelmholtz decomposition of the intermediate velocity field. The energy\nstability of the scheme is theoretically proved, in which the decoupled Stokes\nsolver needs to be analyzed in details. Error estimates are proved in the\ndiscrete $L^\\infty(0,T;L^2)$ norm for the proposed decoupled finite element\nprojection scheme. Numerical examples are provided to illustrate the\ntheoretical results.",
    "descriptor": "",
    "authors": [
      "Cheng Wang",
      "Jilu Wang",
      "Zeyu Xia",
      "Liwei Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.07680"
  },
  {
    "id": "arXiv:2203.07681",
    "title": "DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting",
    "abstract": "Periodic time series (PTS) forecasting plays a crucial role in a variety of\nindustries to foster critical tasks, such as early warning, pre-planning,\nresource scheduling, etc. However, the complicated dependencies of the PTS\nsignal on its inherent periodicity as well as the sophisticated composition of\nvarious periods hinder the performance of PTS forecasting. In this paper, we\nintroduce a deep expansion learning framework, DEPTS, for PTS forecasting.\nDEPTS starts with a decoupled formulation by introducing the periodic state as\na hidden variable, which stimulates us to make two dedicated modules to tackle\nthe aforementioned two challenges. First, we develop an expansion module on top\nof residual learning to perform a layer-by-layer expansion of those complicated\ndependencies. Second, we introduce a periodicity module with a parameterized\nperiodic function that holds sufficient capacity to capture diversified\nperiods. Moreover, our two customized modules also have certain interpretable\ncapabilities, such as attributing the forecasts to either local momenta or\nglobal periodicity and characterizing certain core periodic properties, e.g.,\namplitudes and frequencies. Extensive experiments on both synthetic data and\nreal-world data demonstrate the effectiveness of DEPTS on handling PTS. In most\ncases, DEPTS achieves significant improvements over the best baseline.\nSpecifically, the error reduction can even reach up to 20% for a few cases.\nFinally, all codes are publicly available.",
    "descriptor": "\nComments: ICLR22 Spotlight\n",
    "authors": [
      "Wei Fan",
      "Shun Zheng",
      "Xiaohan Yi",
      "Wei Cao",
      "Yanjie Fu",
      "Jiang Bian",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.07681"
  },
  {
    "id": "arXiv:2203.07682",
    "title": "Rich CNN-Transformer Feature Aggregation Networks for Super-Resolution",
    "abstract": "Recent vision transformers along with self-attention have achieved promising\nresults on various computer vision tasks. In particular, a pure\ntransformer-based image restoration architecture surpasses the existing\nCNN-based methods using multi-task pre-training with a large number of\ntrainable parameters. In this paper, we introduce an effective hybrid\narchitecture for super-resolution (SR) tasks, which leverages local features\nfrom CNNs and long-range dependencies captured by transformers to further\nimprove the SR results. Specifically, our architecture comprises of transformer\nand convolution branches, and we substantially elevate the performance by\nmutually fusing two branches to complement each representation. Furthermore, we\npropose a cross-scale token attention module, which allows the transformer to\nefficiently exploit the informative relationships among tokens across different\nscales. Our proposed method achieves state-of-the-art SR results on numerous\nbenchmark datasets.",
    "descriptor": "\nComments: 19 pages, 11 figures, preprint\n",
    "authors": [
      "Jinsu Yoo",
      "Taehoon Kim",
      "Sihaeng Lee",
      "Seung Hwan Kim",
      "Honglak Lee",
      "Tae Hyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07682"
  },
  {
    "id": "arXiv:2203.07686",
    "title": "On Comparable Box Dimension",
    "abstract": "Two boxes in $\\mathbb{R}^d$ are comparable if one of them is a subset of a\ntranslation of the other one. The comparable box dimension of a graph $G$ is\nthe minimum integer $d$ such that $G$ can be represented as a touching graph of\ncomparable axis-aligned boxes in $\\mathbb{R}^d$. We show that proper\nminor-closed classes have bounded comparable box dimensions and explore further\nproperties of this notion.",
    "descriptor": "\nComments: 23 pages, 1 figure, accepted for presentation at SoCG 2022\n",
    "authors": [
      "Zdenek Dvor\u00e1k",
      "Daniel Goncalves",
      "Abhiruk Lahiri",
      "Jane Tan",
      "Torsten Ueckerdt"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.07686"
  },
  {
    "id": "arXiv:2203.07687",
    "title": "Compressing Sentence Representation for Semantic Retrieval via  Homomorphic Projective Distillation",
    "abstract": "How to learn highly compact yet effective sentence representation?\nPre-trained language models have been effective in many NLP tasks. However,\nthese models are often huge and produce large sentence embeddings. Moreover,\nthere is a big performance gap between large and small models. In this paper,\nwe propose Homomorphic Projective Distillation (HPD) to learn compressed\nsentence embeddings. Our method augments a small Transformer encoder model with\nlearnable projection layers to produce compact representations while mimicking\na large pre-trained language model to retain the sentence representation\nquality. We evaluate our method with different model sizes on both semantic\ntextual similarity (STS) and semantic retrieval (SR) tasks. Experiments show\nthat our method achieves 2.7-4.5 points performance gain on STS tasks compared\nwith previous best representations of the same size. In SR tasks, our method\nimproves retrieval speed (8.2$\\times$) and memory usage (8.0$\\times$) compared\nwith state-of-the-art large models.",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Xuandong Zhao",
      "Zhiguo Yu",
      "Ming Wu",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.07687"
  },
  {
    "id": "arXiv:2203.07688",
    "title": "InsCon:Instance Consistency Feature Representation via Self-Supervised  Learning",
    "abstract": "Feature representation via self-supervised learning has reached remarkable\nsuccess in image-level contrastive learning, which brings impressive\nperformances on image classification tasks. While image-level feature\nrepresentation mainly focuses on contrastive learning in single instance, it\nignores the objective differences between pretext and downstream prediction\ntasks such as object detection and instance segmentation. In order to fully\nunleash the power of feature representation on downstream prediction tasks, we\npropose a new end-to-end self-supervised framework called InsCon, which is\ndevoted to capturing multi-instance information and extracting cell-instance\nfeatures for object recognition and localization. On the one hand, InsCon\nbuilds a targeted learning paradigm that applies multi-instance images as\ninput, aligning the learned feature between corresponding instance views, which\nmakes it more appropriate for multi-instance recognition tasks. On the other\nhand, InsCon introduces the pull and push of cell-instance, which utilizes cell\nconsistency to enhance fine-grained feature representation for precise boundary\nlocalization. As a result, InsCon learns multi-instance consistency on semantic\nfeature representation and cell-instance consistency on spatial feature\nrepresentation. Experiments demonstrate the method we proposed surpasses MoCo\nv2 by 1.1% AP^{bb} on COCO object detection and 1.0% AP^{mk} on COCO instance\nsegmentation using Mask R-CNN R50-FPN network structure with 90k iterations,\n2.1% APbb on PASCAL VOC objection detection using Faster R-CNN R50-C4 network\nstructure with 24k iterations.",
    "descriptor": "\nComments: 16 pages, 3 figures, 9 tables\n",
    "authors": [
      "Junwei Yang",
      "Ke Zhang",
      "Zhaolin Cui",
      "Jinming Su",
      "Junfeng Luo",
      "Xiaolin Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07688"
  },
  {
    "id": "arXiv:2203.07691",
    "title": "Supervised Contrastive Learning with Structure Inference for Graph  Classification",
    "abstract": "Advanced graph neural networks have shown great potentials in graph\nclassification tasks recently. Different from node classification where node\nembeddings aggregated from local neighbors can be directly used to learn node\nlabels, graph classification requires a hierarchical accumulation of different\nlevels of topological information to generate discriminative graph embeddings.\nStill, how to fully explore graph structures and formulate an effective graph\nclassification pipeline remains rudimentary. In this paper, we propose a novel\ngraph neural network based on supervised contrastive learning with structure\ninference for graph classification. First, we propose a data-driven graph\naugmentation strategy that can discover additional connections to enhance the\nexisting edge set. Concretely, we resort to a structure inference stage based\non diffusion cascades to recover possible connections with high node\nsimilarities. Second, to improve the contrastive power of graph neural\nnetworks, we propose to use a supervised contrastive loss for graph\nclassification. With the integration of label information, the one-vs-many\ncontrastive learning can be extended to a many-vs-many setting, so that the\ngraph-level embeddings with higher topological similarities will be pulled\ncloser. The supervised contrastive loss and structure inference can be\nnaturally incorporated within the hierarchical graph neural networks where the\ntopological patterns can be fully explored to produce discriminative graph\nembeddings. Experiment results show the effectiveness of the proposed method\ncompared with recent state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Hao Jia",
      "Junzhong Ji",
      "Minglong Lei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07691"
  },
  {
    "id": "arXiv:2203.07694",
    "title": "Implicit field supervision for robust non-rigid shape matching",
    "abstract": "Establishing a correspondence between two non-rigidly deforming shapes is one\nof the most fundamental problems in visual computing. Existing methods often\nshow weak resilience when presented with challenges innate to real-world data\nsuch as noise, outliers, self-occlusion etc. On the other hand, auto-decoders\nhave demonstrated strong expressive power in learning geometrically meaningful\nlatent embeddings. However, their use in \\emph{shape analysis} and especially\nin non-rigid shape correspondence has been limited. In this paper, we introduce\nan approach based on auto-decoder framework, that learns a continuous\nshape-wise deformation field over a fixed template. By supervising the\ndeformation field for points on-surface and regularising for points off-surface\nthrough a novel \\emph{Signed Distance Regularisation} (SDR), we learn an\nalignment between the template and shape \\emph{volumes}. Unlike classical\ncorrespondence techniques, our method is remarkably robust in the presence of\nstrong artefacts and can be generalised to arbitrary shape categories. Trained\non clean water-tight meshes, \\emph{without} any data-augmentation, we\ndemonstrate compelling performance on compromised data and real-world scans.",
    "descriptor": "",
    "authors": [
      "Ramana Sundararaman",
      "Gautam Pai",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07694"
  },
  {
    "id": "arXiv:2203.07697",
    "title": "Distribution-Aware Single-Stage Models for Multi-Person 3D Pose  Estimation",
    "abstract": "In this paper, we present a novel Distribution-Aware Single-stage (DAS) model\nfor tackling the challenging multi-person 3D pose estimation problem. Different\nfrom existing top-down and bottom-up methods, the proposed DAS model\nsimultaneously localizes person positions and their corresponding body joints\nin the 3D camera space in a one-pass manner. This leads to a simplified\npipeline with enhanced efficiency. In addition, DAS learns the true\ndistribution of body joints for the regression of their positions, rather than\nmaking a simple Laplacian or Gaussian assumption as previous works. This\nprovides valuable priors for model prediction and thus boosts the\nregression-based scheme to achieve competitive performance with volumetric-base\nones. Moreover, DAS exploits a recursive update strategy for progressively\napproaching to regression target, alleviating the optimization difficulty and\nfurther lifting the regression performance. DAS is implemented with a fully\nConvolutional Neural Network and end-to-end learnable. Comprehensive\nexperiments on benchmarks CMU Panoptic and MuPoTS-3D demonstrate the superior\nefficiency of the proposed DAS model, specifically 1.5x speedup over previous\nbest model, and its stat-of-the-art accuracy for multi-person 3D pose\nestimation.",
    "descriptor": "",
    "authors": [
      "Zitian Wang",
      "Xuecheng Nie",
      "Xiaochao Qu",
      "Yunpeng Chen",
      "Si Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07697"
  },
  {
    "id": "arXiv:2203.07703",
    "title": "Benchmarking and Interpreting End-to-end Learning of MIMO and Multi-User  Communication",
    "abstract": "End-to-end autoencoder (AE) learning has the potential of exceeding the\nperformance of human-engineered transceivers and encoding schemes, without a\npriori knowledge of communication-theoretic principles. In this work, we aim to\nunderstand to what extent and for which scenarios this claim holds true when\ncomparing with fair benchmarks. Our particular focus is on memoryless\nmultiple-input multiple-output (MIMO) and multi-user (MU) systems. Four case\nstudies are considered: two point-to-point (closed-loop and open-loop MIMO) and\ntwo MU scenarios (MIMO broadcast and interference channels). For the\npoint-to-point scenarios, we explain some of the performance gains observed in\nprior work through the selection of improved baseline schemes that include\ngeometric shaping as well as bit and power allocation. For the MIMO broadcast\nchannel, we demonstrate the feasibility of a novel AE method with centralized\nlearning and decentralized execution. Interestingly, the learned scheme\nperforms close to nonlinear vector-perturbation precoding and significantly\noutperforms conventional zero-forcing. Lastly, we highlight potential pitfalls\nwhen interpreting learned communication schemes. In particular, we show that\nthe AE for the considered interference channel learns to avoid interference,\nalbeit in a rotated reference frame. After de-rotating the learned signal\nconstellation of each user, the resulting scheme corresponds to conventional\ntime sharing with geometric shaping.",
    "descriptor": "\nComments: Accepted to Transaction on Wireless Communications\n",
    "authors": [
      "Jinxiang Song",
      "Christian H\u00e4ger",
      "Jochen Schr\u00f6der",
      "Timothy J. O'Shea",
      "Erik Agrell",
      "Henk Wymeersch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.07703"
  },
  {
    "id": "arXiv:2203.07705",
    "title": "APRNet: Attention-based Pixel-wise Rendering Network for Photo-Realistic  Text Image Generation",
    "abstract": "Style-guided text image generation tries to synthesize text image by\nimitating reference image's appearance while keeping text content unaltered.\nThe text image appearance includes many aspects. In this paper, we focus on\ntransferring style image's background and foreground color patterns to the\ncontent image to generate photo-realistic text image. To achieve this goal, we\npropose 1) a content-style cross attention based pixel sampling approach to\nroughly mimicking the style text image's background; 2) a pixel-wise style\nmodulation technique to transfer varying color patterns of the style image to\nthe content image spatial-adaptively; 3) a cross attention based multi-scale\nstyle fusion approach to solving text foreground misalignment issue between\nstyle and content images; 4) an image patch shuffling strategy to create style,\ncontent and ground truth image tuples for training. Experimental results on\nChinese handwriting text image synthesis with SCUT-HCCDoc and CASIA-OLHWDB\ndatasets demonstrate that the proposed method can improve the quality of\nsynthetic text images and make them more photo-realistic.",
    "descriptor": "",
    "authors": [
      "Yangming Shi",
      "Haisong Ding",
      "Kai Chen",
      "Qiang Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07705"
  },
  {
    "id": "arXiv:2203.07706",
    "title": "ActFormer: A GAN Transformer Framework towards General  Action-Conditioned 3D Human Motion Generation",
    "abstract": "We present a GAN Transformer framework for general action-conditioned 3D\nhuman motion generation, including not only single-person actions but also\nmulti-person interactive actions. Our approach consists of a powerful\nAction-conditioned motion transFormer (ActFormer) under a GAN training scheme,\nequipped with a Gaussian Process latent prior. Such a design combines the\nstrong spatio-temporal representation capacity of Transformer, superiority in\ngenerative modeling of GAN, and inherent temporal correlations from latent\nprior. Furthermore, ActFormer can be naturally extended to multi-person motions\nby alternately modeling temporal correlations and human interactions with\nTransformer encoders. We validate our approach by comparison with other methods\non larger-scale benchmarks, including NTU RGB+D 120 and BABEL. We also\nintroduce a new synthetic dataset of complex multi-person combat behaviors to\nfacilitate research on multi-person motion generation. Our method demonstrates\nadaptability to various human motion representations and achieves leading\nperformance over SOTA methods on both single-person and multi-person motion\ngeneration tasks, indicating a hopeful step towards a universal human motion\ngenerator.",
    "descriptor": "",
    "authors": [
      "Ziyang Song",
      "Dongliang Wang",
      "Nan Jiang",
      "Zhicheng Fang",
      "Chenjing Ding",
      "Weihao Gan",
      "Wei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.07706"
  },
  {
    "id": "arXiv:2203.07709",
    "title": "Adaptive Environment Modeling Based Reinforcement Learning for Collision  Avoidance in Complex Scenes",
    "abstract": "The major challenges of collision avoidance for robot navigation in crowded\nscenes lie in accurate environment modeling, fast perceptions, and trustworthy\nmotion planning policies. This paper presents a novel adaptive environment\nmodel based collision avoidance reinforcement learning (i.e., AEMCARL)\nframework for an unmanned robot to achieve collision-free motions in\nchallenging navigation scenarios. The novelty of this work is threefold: (1)\ndeveloping a hierarchical network of gated-recurrent-unit (GRU) for environment\nmodeling; (2) developing an adaptive perception mechanism with an attention\nmodule; (3) developing an adaptive reward function for the reinforcement\nlearning (RL) framework to jointly train the environment model, perception\nfunction and motion planning policy. The proposed method is tested with the\nGym-Gazebo simulator and a group of robots (Husky and Turtlebot) under various\ncrowded scenes. Both simulation and experimental results have demonstrated the\nsuperior performance of the proposed method over baseline methods.",
    "descriptor": "",
    "authors": [
      "Shuaijun Wang",
      "Rui Gao",
      "Ruihua Han",
      "Shengduo Chen",
      "Chengyang Li",
      "Qi Hao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07709"
  },
  {
    "id": "arXiv:2203.07711",
    "title": "Maximizing Modular plus Non-monotone Submodular Functions",
    "abstract": "We study the problem of maximizing the sum of the extensions of a submodular\nfunction and a modular function subject to a down-monotone polytope, where the\nunderlying set function of the multilinear is submodular but not necessary\nmonotone. We present an algorithm called \\text{Measured Continuous Greedy with\nAdaptive Weights} with $F(\\mathbf{x})+L(\\mathbf{x})\\geq\n(1/e-\\epsilon)f(OPT)+\\ell(OPT)$ guarantee, where $\\mathbf{x}$ is a feasible\npoint in the polytope of the given constraint, $f$, $\\ell$ are the submodular\nfunction and modular function respectively, $F$, $L$ denote the extensions of\nthe given functions, and $OPT$ is the optimal integral solution for the\nproblem. Moreover, we show that our algorithm also works for the monotone\nsetting and it can achieve $F(\\mathbf{x})+L(\\mathbf{x})\\geq\n(1-1/e)f(OPT)+\\ell(OPT)$-approximation. Besides, we present an\ninapproximability analysis for the problem we consider. We provide a hardness\nresult that there exists no polynomial algorithm whose output $S$ satisfies\n$f(S)+\\ell(S)\\geq0.478\\cdot f(OPT)+\\ell(OPT)$.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Xin Sun",
      "Dachuan Xu",
      "Yang Zhou",
      "Chenchen Wu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.07711"
  },
  {
    "id": "arXiv:2203.07712",
    "title": "Multi-Use Trust in Crowdsourced IoT Services",
    "abstract": "We introduce the concept of adaptive trust in crowdsourced IoT services. It\nis a customized fine-grained trust tailored for specific IoT consumers. Usage\npatterns of IoT consumers are exploited to provide an accurate trust value for\nservice providers. A novel adaptive trust management framework is proposed to\nassess the dynamic trust of IoT services. The framework leverages a novel\ndetection algorithm to obtain trust indicators that are likely to influence the\ntrust level of a specific IoT service type. Detected trust indicators are then\nused to build service-to-indicator model to evaluate a service's trust at each\nindicator. Similarly, a usage-to-indicator model is built to obtain the\nimportance of each trust indicator for a particular usage scenario. The\nper-indicator trust and the importance of each trust indicator are utilized to\nobtain an overall value of a given service for a specific consumer. We conduct\na set of experiments on a real dataset to show the effectiveness of the\nproposed framework.",
    "descriptor": "\nComments: 14 pages, accepted and to appear in IEEE Ttransactions on Services Computing\n",
    "authors": [
      "Mohammed Bahutair",
      "Athman Bouguettaya",
      "Azadeh Ghari Neiat"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.07712"
  },
  {
    "id": "arXiv:2203.07713",
    "title": "LDP: Learnable Dynamic Precision for Efficient Deep Neural Network  Training and Inference",
    "abstract": "Low precision deep neural network (DNN) training is one of the most effective\ntechniques for boosting DNNs' training efficiency, as it trims down the\ntraining cost from the finest bit level. While existing works mostly fix the\nmodel precision during the whole training process, a few pioneering works have\nshown that dynamic precision schedules help DNNs converge to a better accuracy\nwhile leading to a lower training cost than their static precision training\ncounterparts. However, existing dynamic low precision training methods rely on\nmanually designed precision schedules to achieve advantageous efficiency and\naccuracy trade-offs, limiting their more comprehensive practical applications\nand achievable performance. To this end, we propose LDP, a Learnable Dynamic\nPrecision DNN training framework that can automatically learn a temporally and\nspatially dynamic precision schedule during training towards optimal accuracy\nand efficiency trade-offs. It is worth noting that LDP-trained DNNs are by\nnature efficient during inference. Furthermore, we visualize the resulting\ntemporal and spatial precision schedule and distribution of LDP trained DNNs on\ndifferent tasks to better understand the corresponding DNNs' characteristics at\ndifferent training stages and DNN layers both during and after training,\ndrawing insights for promoting further innovations. Extensive experiments and\nablation studies (seven networks, five datasets, and three tasks) show that the\nproposed LDP consistently outperforms state-of-the-art (SOTA) low precision DNN\ntraining techniques in terms of training efficiency and achieved accuracy\ntrade-offs. For example, in addition to having the advantage of being\nautomated, our LDP achieves a 0.31\\% higher accuracy with a 39.1\\% lower\ncomputational cost when training ResNet-20 on CIFAR-10 as compared with the\nbest SOTA method.",
    "descriptor": "",
    "authors": [
      "Zhongzhi Yu",
      "Yonggan Fu",
      "Shang Wu",
      "Mengquan Li",
      "Haoran You",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07713"
  },
  {
    "id": "arXiv:2203.07716",
    "title": "Zero Trust Architecture for 6G Security",
    "abstract": "The upcoming sixth generation (6G) network is envisioned to be more open and\nheterogeneous than earlier generations. This challenges conventional security\narchitectures, which typically rely on the construction of a security perimeter\nat network boundaries. In this article, we propose a software-defined zero\ntrust architecture (ZTA) for 6G networks, which is promising for establishing\nan elastic and scalable security regime. This architecture achieves secure\naccess control through adaptive collaborations among the involved control\ndomains, and can effectively prevent malicious access behaviors such as\ndistributed denial of service (DDoS) attacks, malware spread, and zero-day\nexploits. We also introduce key design aspects of this architecture and show\nthe simulation results of a case study, which shows the effectiveness and\nrobustness of ZTA for 6G. Furthermore, we discuss open issues to further\npromote this new architecture.",
    "descriptor": "",
    "authors": [
      "Xu Chen",
      "Wei Feng",
      "Ning Ge",
      "Yan Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.07716"
  },
  {
    "id": "arXiv:2203.07717",
    "title": "Modern Lower Bound Techniques in Database Theory and Constraint  Satisfaction",
    "abstract": "Conditional lower bounds based on $P\\neq NP$, the Exponential-Time Hypothesis\n(ETH), or similar complexity assumptions can provide very useful information\nabout what type of algorithms are likely to be possible. Ideally, such lower\nbounds would be able to demonstrate that the best known algorithms are\nessentially optimal and cannot be improved further. In this tutorial, we\noverview different types of lower bounds, and see how they can be applied to\nproblems in database theory and constraint satisfaction.",
    "descriptor": "\nComments: PODS 2021 Tutorial\n",
    "authors": [
      "D\u00e1niel Marx"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.07717"
  },
  {
    "id": "arXiv:2203.07718",
    "title": "Bio-inspired Multi-robot Autonomy",
    "abstract": "Increasingly, high value industrial markets are driving trends for improved\nfunctionality and resilience from resident autonomous systems. This led to an\nincrease in multi-robot fleets that aim to leverage the complementary\nattributes of the diverse platforms. In this paper we introduce a novel\nbio-inspired Symbiotic System of Systems Approach (SSOSA) for designing the\noperational governance of a multi-robot fleet consisting of ground-based\nquadruped and wheeled platforms. SSOSA couples the MR-fleet to the resident\ninfrastructure monitoring systems into one collaborative digital commons. The\nhyper visibility of the integrated distributed systems, achieved through a\nlatency bidirectional communication network, supports collaboration,\ncoordination and corroboration (3C) across the integrated systems. In our\nexperiment, we demonstrate how an operator can activate a pre-determined\nautonomous mission and utilize SSOSA to overcome intrinsic and external risks\nto the autonomous missions. We demonstrate how resilience can be enhanced by\nlocal collaboration between SPOT and Husky wherein we detect a replacement\nbattery, and utilize the manipulator arm of SPOT to support a Clearpath Husky\nA200 wheeled robotic platform. This allows for increased resilience of an\nautonomous mission as robots can collaborate to ensure the battery state of the\nHusky robot. Overall, these initial results demonstrate the value of a SSOSA\napproach in addressing a key operational barrier to scalable autonomy, the\nresilience.",
    "descriptor": "\nComments: A preprint submit to IROS 2022\n",
    "authors": [
      "Shivoh Chirayil Nandakumar",
      "Samuel Harper",
      "Daniel Mitchell",
      "Jamie Blanche",
      "Theodore Lim",
      "Ikuo Yamamoto",
      "David Flynn"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.07718"
  },
  {
    "id": "arXiv:2203.07720",
    "title": "Revitalize Region Feature for Democratizing Video-Language Pre-training",
    "abstract": "Recent dominant methods for video-language pre-training (VLP) learn\ntransferable representations from the raw pixels in an end-to-end manner to\nachieve advanced performance on downstream video-language tasks. Despite the\nimpressive results, VLP research becomes extremely expensive with the need for\nmassive data and a long training time, preventing further explorations. In this\nwork, we revitalize region features of sparsely sampled video clips to\nsignificantly reduce both spatial and temporal visual redundancy towards\ndemocratizing VLP research at the same time achieving state-of-the-art results.\nSpecifically, to fully explore the potential of region features, we introduce a\nnovel bidirectional region-word alignment regularization that properly\noptimizes the fine-grained relations between regions and certain words in\nsentences, eliminating the domain/modality disconnections between pre-extracted\nregion features and text. Extensive results of downstream text-to-video\nretrieval and video question answering tasks on seven datasets demonstrate the\nsuperiority of our method on both effectiveness and efficiency, e.g., our\nmethod achieves competing results with 80\\% fewer data and 85\\% less\npre-training time compared to the most efficient VLP method so far. The code\nwill be available at \\url{https://github.com/CuthbertCai/DemoVLP}.",
    "descriptor": "",
    "authors": [
      "Guanyu Cai",
      "Yixiao Ge",
      "Alex Jinpeng Wang",
      "Rui Yan",
      "Xudong Lin",
      "Ying Shan",
      "Lianghua He",
      "Xiaohu Qie",
      "Jianping Wu",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07720"
  },
  {
    "id": "arXiv:2203.07722",
    "title": "ReACC: A Retrieval-Augmented Code Completion Framework",
    "abstract": "Code completion, which aims to predict the following code token(s) according\nto the code context, can improve the productivity of software development.\nRecent work has proved that statistical language modeling with transformers can\ngreatly improve the performance in the code completion task via learning from\nlarge-scale source code datasets. However, current approaches focus only on\ncode context within the file or project, i.e. internal context. Our distinction\nis utilizing \"external\" context, inspired by human behaviors of copying from\nthe related code snippets when writing code. Specifically, we propose a\nretrieval-augmented code completion framework, leveraging both lexical copying\nand referring to code with similar semantics by retrieval. We adopt a\nstage-wise training approach that combines a source code retriever and an\nauto-regressive language model for programming language. We evaluate our\napproach in the code completion task in Python and Java programming languages,\nachieving a state-of-the-art performance on CodeXGLUE benchmark.",
    "descriptor": "\nComments: Published in ACL 2022\n",
    "authors": [
      "Shuai Lu",
      "Nan Duan",
      "Hojae Han",
      "Daya Guo",
      "Seung-won Hwang",
      "Alexey Svyatkovskiy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07722"
  },
  {
    "id": "arXiv:2203.07724",
    "title": "CODA: A Real-World Road Corner Case Dataset for Object Detection in  Autonomous Driving",
    "abstract": "Contemporary deep-learning object detection methods for autonomous driving\nusually assume prefixed categories of common traffic participants, such as\npedestrians and cars. Most existing detectors are unable to detect uncommon\nobjects and corner cases (e.g., a dog crossing a street), which may lead to\nsevere accidents in some situations, making the timeline for the real-world\napplication of reliable autonomous driving uncertain. One main reason that\nimpedes the development of truly reliably self-driving systems is the lack of\npublic datasets for evaluating the performance of object detectors on corner\ncases. Hence, we introduce a challenging dataset named CODA that exposes this\ncritical problem of vision-based detectors. The dataset consists of 1500\ncarefully selected real-world driving scenes, each containing four object-level\ncorner cases (on average), spanning 30+ object categories. On CODA, the\nperformance of standard object detectors trained on large-scale autonomous\ndriving datasets significantly drops to no more than 12.8% in mAR. Moreover, we\nexperiment with the state-of-the-art open-world object detector and find that\nit also fails to reliably identify the novel objects in CODA, suggesting that a\nrobust perception system for autonomous driving is probably still far from\nreach. We expect our CODA dataset to facilitate further research in reliable\ndetection for real-world autonomous driving. Our dataset will be released at\nhttps://coda-dataset.github.io.",
    "descriptor": "",
    "authors": [
      "Kaican Li",
      "Kai Chen",
      "Haoyu Wang",
      "Lanqing Hong",
      "Chaoqiang Ye",
      "Jianhua Han",
      "Yukuai Chen",
      "Wei Zhang",
      "Chunjing Xu",
      "Dit-Yan Yeung",
      "Xiaodan Liang",
      "Zhenguo Li",
      "Hang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07724"
  },
  {
    "id": "arXiv:2203.07725",
    "title": "Meta Ordinal Regression Forest for Medical Image Classification with  Ordinal Labels",
    "abstract": "The performance of medical image classification has been enhanced by deep\nconvolutional neural networks (CNNs), which are typically trained with\ncross-entropy (CE) loss. However, when the label presents an intrinsic ordinal\nproperty in nature, e.g., the development from benign to malignant tumor, CE\nloss cannot take into account such ordinal information to allow for better\ngeneralization. To improve model generalization with ordinal information, we\npropose a novel meta ordinal regression forest (MORF) method for medical image\nclassification with ordinal labels, which learns the ordinal relationship\nthrough the combination of convolutional neural network and differential forest\nin a meta-learning framework. The merits of the proposed MORF come from the\nfollowing two components: a tree-wise weighting net (TWW-Net) and a grouped\nfeature selection (GFS) module. First, the TWW-Net assigns each tree in the\nforest with a specific weight that is mapped from the classification loss of\nthe corresponding tree. Hence, all the trees possess varying weights, which is\nhelpful for alleviating the tree-wise prediction variance. Second, the GFS\nmodule enables a dynamic forest rather than a fixed one that was previously\nused, allowing for random feature perturbation. During training, we\nalternatively optimize the parameters of the CNN backbone and TWW-Net in the\nmeta-learning framework through calculating the Hessian matrix. Experimental\nresults on two medical image classification datasets with ordinal labels, i.e.,\nLIDC-IDRI and Breast Ultrasound Dataset, demonstrate the superior performances\nof our MORF method over existing state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yiming Lei",
      "Haiping Zhu",
      "Junping Zhang",
      "Hongming Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07725"
  },
  {
    "id": "arXiv:2203.07731",
    "title": "Evaluating BERT-based Pre-training Language Models for Detecting  Misinformation",
    "abstract": "It is challenging to control the quality of online information due to the\nlack of supervision over all the information posted online. Manual checking is\nalmost impossible given the vast number of posts made on online media and how\nquickly they spread. Therefore, there is a need for automated rumour detection\ntechniques to limit the adverse effects of spreading misinformation. Previous\nstudies mainly focused on finding and extracting the significant features of\ntext data. However, extracting features is time-consuming and not a highly\neffective process. This study proposes the BERT- based pre-trained language\nmodels to encode text data into vectors and utilise neural network models to\nclassify these vectors to detect misinformation. Furthermore, different\nlanguage models (LM) ' performance with different trainable parameters was\ncompared. The proposed technique is tested on different short and long text\ndatasets. The result of the proposed technique has been compared with the\nstate-of-the-art techniques on the same datasets. The results show that the\nproposed technique performs better than the state-of-the-art techniques. We\nalso tested the proposed technique by combining the datasets. The results\ndemonstrated that the large data training and testing size considerably\nimproves the technique's performance.",
    "descriptor": "\nComments: 17 pages, 2 figures, 10 tables\n",
    "authors": [
      "Rini Anggrainingsih",
      "Ghulam Mubashar Hassan",
      "Amitava Datta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07731"
  },
  {
    "id": "arXiv:2203.07732",
    "title": "S2F2: Self-Supervised High Fidelity Face Reconstruction from Monocular  Image",
    "abstract": "We present a novel face reconstruction method capable of reconstructing\ndetailed face geometry, spatially varying face reflectance from a single\nmonocular image. We build our work upon the recent advances of DNN-based\nauto-encoders with differentiable ray tracing image formation, trained in\nself-supervised manner. While providing the advantage of learning-based\napproaches and real-time reconstruction, the latter methods lacked fidelity. In\nthis work, we achieve, for the first time, high fidelity face reconstruction\nusing self-supervised learning only. Our novel coarse-to-fine deep architecture\nallows us to solve the challenging problem of decoupling face reflectance from\ngeometry using a single image, at high computational speed. Compared to\nstate-of-the-art methods, our method achieves more visually appealing\nreconstruction.",
    "descriptor": "\nComments: 24 Pages, 22 Figures\n",
    "authors": [
      "Abdallah Dib",
      "Junghyun Ahn",
      "Cedric Thebault",
      "Philippe-Henri Gosselin",
      "Louis Chevallier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07732"
  },
  {
    "id": "arXiv:2203.07735",
    "title": "Augmenting Document Representations for Dense Retrieval with  Interpolation and Perturbation",
    "abstract": "Dense retrieval models, which aim at retrieving the most relevant document\nfor an input query on a dense representation space, have gained considerable\nattention for their remarkable success. Yet, dense models require a vast amount\nof labeled training data for notable performance, whereas it is often\nchallenging to acquire query-document pairs annotated by humans. To tackle this\nproblem, we propose a simple but effective Document Augmentation for dense\nRetrieval (DAR) framework, which augments the representations of documents with\ntheir interpolation and perturbation. We validate the performance of DAR on\nretrieval tasks with two benchmark datasets, showing that the proposed DAR\nsignificantly outperforms relevant baselines on the dense retrieval of both the\nlabeled and unlabeled documents.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Soyeong Jeong",
      "Jinheon Baek",
      "Sukmin Cho",
      "Sung Ju Hwang",
      "Jong C. Park"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07735"
  },
  {
    "id": "arXiv:2203.07736",
    "title": "CSRS: Code Search with Relevance Matching and Semantic Matching",
    "abstract": "Developers often search and reuse existing code snippets in the process of\nsoftware development. Code search aims to retrieve relevant code snippets from\na codebase according to natural language queries entered by the developer. Up\nto now, researchers have already proposed information retrieval (IR) based\nmethods and deep learning (DL) based methods. The IR-based methods focus on\nkeyword matching, that is to rank codes by relevance between queries and code\nsnippets, while DL-based methods focus on capturing the semantic correlations.\nHowever, the existing methods rarely consider capturing two matching signals\nsimultaneously. Therefore, in this paper, we propose CSRS, a code search model\nwith relevance matching and semantic matching. CSRS comprises (1) an embedding\nmodule containing convolution kernels of different sizes which can extract\nn-gram embeddings of queries and codes, (2) a relevance matching module that\nmeasures lexical matching signals, and (3) a co-attention based semantic\nmatching module to capture the semantic correlation. We train and evaluate CSRS\non a dataset with 18.22M and 10k code snippets. The experimental results\ndemonstrate that CSRS achieves an MRR of 0.614, which outperforms two\nstate-of-the-art models DeepCS and CARLCS-CNN by 33.77% and 18.53%\nrespectively. In addition, we also conducted several experiments to prove the\neffectiveness of each component of CSRS.",
    "descriptor": "",
    "authors": [
      "Yi Cheng",
      "Li Kuang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.07736"
  },
  {
    "id": "arXiv:2203.07737",
    "title": "An Annotation-free Restoration Network for Cataractous Fundus Images",
    "abstract": "Cataracts are the leading cause of vision loss worldwide. Restoration\nalgorithms are developed to improve the readability of cataract fundus images\nin order to increase the certainty in diagnosis and treatment for cataract\npatients. Unfortunately, the requirement of annotation limits the application\nof these algorithms in clinics. This paper proposes a network to\nannotation-freely restore cataractous fundus images (ArcNet) so as to boost the\nclinical practicability of restoration. Annotations are unnecessary in ArcNet,\nwhere the high-frequency component is extracted from fundus images to replace\nsegmentation in the preservation of retinal structures. The restoration model\nis learned from the synthesized images and adapted to real cataract images.\nExtensive experiments are implemented to verify the performance and\neffectiveness of ArcNet. Favorable performance is achieved using ArcNet against\nstate-of-the-art algorithms, and the diagnosis of ocular fundus diseases in\ncataract patients is promoted by ArcNet. The capability of properly restoring\ncataractous images in the absence of annotated data promises the proposed\nalgorithm outstanding clinical practicability.",
    "descriptor": "\nComments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Heng Li",
      "Haofeng Liu",
      "Yan Hu",
      "Huazhu Fu",
      "Yitian Zhao",
      "Hanpei Miao",
      "Jiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07737"
  },
  {
    "id": "arXiv:2203.07738",
    "title": "CSN: Component-Supervised Network for Few-Shot Classification",
    "abstract": "The few-shot classification (FSC) task has been a hot research topic in\nrecent years. It aims to address the classification problem with insufficient\nlabeled data on a cross-category basis. Typically, researchers pre-train a\nfeature extractor with base data, then use it to extract the features of novel\ndata and recognize them. Notably, the novel set only has a few annotated\nsamples and has entirely different categories from the base set, which leads to\nthat the pre-trained feature extractor can not adapt to the novel data\nflawlessly. We dub this problem as Feature-Extractor-Maladaptive (FEM) problem.\nStarting from the root cause of this problem, this paper presents a new scheme,\nComponent-Supervised Network (CSN), to improve the performance of FSC. We\nbelieve that although the categories of base and novel sets are different, the\ncomposition of the sample's components is similar. For example, both cat and\ndog contain leg and head components. Actually, such entity components are\nintra-class stable. They have fine cross-category versatility and new category\ngeneralization. Therefore, we refer to WordNet, a dictionary commonly used in\nnatural language processing, to collect component information of samples and\nconstruct a component-based auxiliary task to improve the adaptability of the\nfeature extractor. We conduct experiments on two benchmark datasets\n(mini-ImageNet and tiered-ImageNet), the improvements of $0.9\\%$-$5.8\\%$\ncompared with state-of-the-arts have evaluated the efficiency of our CSN.",
    "descriptor": "",
    "authors": [
      "Shuai Shao",
      "Baodi Liu",
      "Lei Xing",
      "Lifei Zhao",
      "Yanjiang Wang",
      "Weifeng Liu",
      "Yicong Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07738"
  },
  {
    "id": "arXiv:2203.07740",
    "title": "Exact Feature Distribution Matching for Arbitrary Style Transfer and  Domain Generalization",
    "abstract": "Arbitrary style transfer (AST) and domain generalization (DG) are important\nyet challenging visual learning tasks, which can be cast as a feature\ndistribution matching problem. With the assumption of Gaussian feature\ndistribution, conventional feature distribution matching methods usually match\nthe mean and standard deviation of features. However, the feature distributions\nof real-world data are usually much more complicated than Gaussian, which\ncannot be accurately matched by using only the first-order and second-order\nstatistics, while it is computationally prohibitive to use high-order\nstatistics for distribution matching. In this work, we, for the first time to\nour best knowledge, propose to perform Exact Feature Distribution Matching\n(EFDM) by exactly matching the empirical Cumulative Distribution Functions\n(eCDFs) of image features, which could be implemented by applying the Exact\nHistogram Matching (EHM) in the image feature space. Particularly, a fast EHM\nalgorithm, named Sort-Matching, is employed to perform EFDM in a plug-and-play\nmanner with minimal cost. The effectiveness of our proposed EFDM method is\nverified on a variety of AST and DG tasks, demonstrating new state-of-the-art\nresults. Codes are available at https://github.com/YBZh/EFDM.",
    "descriptor": "\nComments: To appear in CVPR2022; codes and supplementary material are available at: this https URL\n",
    "authors": [
      "Yabin Zhang",
      "Minghan Li",
      "Ruihuang Li",
      "Kui Jia",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07740"
  },
  {
    "id": "arXiv:2203.07742",
    "title": "ViWOZ: A Multi-Domain Task-Oriented Dialogue Systems Dataset For  Low-resource Language",
    "abstract": "Most of the current task-oriented dialogue systems (ToD), despite having\ninteresting results, are designed for a handful of languages like Chinese and\nEnglish. Therefore, their performance in low-resource languages is still a\nsignificant problem due to the absence of a standard dataset and evaluation\npolicy. To address this problem, we proposed ViWOZ, a fully-annotated\nVietnamese task-oriented dialogue dataset. ViWOZ is the first multi-turn,\nmulti-domain tasked oriented dataset in Vietnamese, a low-resource language.\nThe dataset consists of a total of 5,000 dialogues, including 60,946 fully\nannotated utterances. Furthermore, we provide a comprehensive benchmark of both\nmodular and end-to-end models in low-resource language scenarios. With those\ncharacteristics, the ViWOZ dataset enables future studies on creating a\nmultilingual task-oriented dialogue system.",
    "descriptor": "",
    "authors": [
      "Phi Nguyen Van",
      "Tung Cao Hoang",
      "Dung Nguyen Manh",
      "Quan Nguyen Minh",
      "Long Tran Quoc"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07742"
  },
  {
    "id": "arXiv:2203.07747",
    "title": "Neural-MPC: Deep Learning Model Predictive Control for Quadrotors and  Agile Robotic Platforms",
    "abstract": "Model Predictive Control (MPC) has become a popular framework in embedded\ncontrol for high-performance autonomous systems. However, to achieve good\ncontrol performance using MPC, an accurate dynamics model is key. To maintain\nreal-time operation, the dynamics models used on embedded systems have been\nlimited to simple first-principle models, which substantially limits their\nrepresentative power. In contrast, neural networks can model complex effects\npurely from data. In contrast to such simple models, machine learning\napproaches such as neural networks have been shown to accurately model even\ncomplex dynamic effects, but their large computational complexity hindered\ncombination with fast real-time iteration loops. With this work, we present\nNeural-MPC, a framework to efficiently integrate large, complex neural network\narchitectures as dynamics models within a model-predictive control pipeline.\nOur experiments, performed in simulation and the real world on a highly agile\nquadrotor platform, demonstrate up to 83% reduction in positional tracking\nerror when compared to state-of-the-art MPC approaches without neural network\ndynamics.",
    "descriptor": "\nComments: submitted to RA-L\n",
    "authors": [
      "Tim Salzmann",
      "Elia Kaufmann",
      "Marco Pavone",
      "Davide Scaramuzza",
      "Markus Ryll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.07747"
  },
  {
    "id": "arXiv:2203.07750",
    "title": "Development of a multi-timescale method for classifying hybrid energy  storage systems in grid applications",
    "abstract": "An extended use of renewable energies and a trend towards increasing energy\nconsumption lead to challenges such as temporal and spatial decoupling of\nenergy generation and consumption. This work evaluates the possible\napplications and advantages of hybrid energy storage systems compared to\nconventional, single energy storage applications. In a mathematical approach,\nevaluation criteria such as frequency, probability of power transients, as well\nas absolute power peaks are combined to identify suitable thresholds for energy\nmanagement systems on a multi-timescale basis. With experimental load profiles\nfrom a municipal application, an airport, and an industrial application, four\ncategories, clustering similar roles of the VRFB and the SC, are developed.",
    "descriptor": "",
    "authors": [
      "C. Zugschwert",
      "S. G\u00f6schl",
      "F. Martin Ibanez",
      "K. Pettinger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.07750"
  },
  {
    "id": "arXiv:2203.07756",
    "title": "Multi-Curve Translator for Real-Time High-Resolution Image-to-Image  Translation",
    "abstract": "The dominant image-to-image translation methods are based on fully\nconvolutional networks, which extract and translate an image's features and\nthen reconstruct the image. However, they have unacceptable computational costs\nwhen working with high-resolution images. To this end, we present the\nMulti-Curve Translator (MCT), which not only predicts the translated pixels for\nthe corresponding input pixels but also for their neighboring pixels. And if a\nhigh-resolution image is downsampled to its low-resolution version, the lost\npixels are the remaining pixels' neighboring pixels. So MCT makes it possible\nto feed the network only the downsampled image to perform the mapping for the\nfull-resolution image, which can dramatically lower the computational cost.\nBesides, MCT is a plug-in approach that utilizes existing base models and\nrequires only replacing their output layers. Experiments demonstrate that the\nMCT variants can process 4K images in real-time and achieve comparable or even\nbetter performance than the base models on various image-to-image translation\ntasks.",
    "descriptor": "",
    "authors": [
      "Yuda Song",
      "Hui Qian",
      "Xin Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07756"
  },
  {
    "id": "arXiv:2203.07761",
    "title": "Reactive Motion Generation on Learned Riemannian Manifolds",
    "abstract": "In recent decades, advancements in motion learning have enabled robots to\nacquire new skills and adapt to unseen conditions in both structured and\nunstructured environments. In practice, motion learning methods capture\nrelevant patterns and adjust them to new conditions such as dynamic obstacle\navoidance or variable targets. In this paper, we investigate the robot motion\nlearning paradigm from a Riemannian manifold perspective. We argue that\nRiemannian manifolds may be learned via human demonstrations in which geodesics\nare natural motion skills. The geodesics are generated using a learned\nRiemannian metric produced by our novel variational autoencoder (VAE), which is\nespecially intended to recover full-pose end-effector states and joint space\nconfigurations. In addition, we propose a technique for facilitating on-the-fly\nend-effector/multiple-limb obstacle avoidance by reshaping the learned manifold\nusing an obstacle-aware ambient metric. The motion generated using these\ngeodesics may naturally result in multiple-solution tasks that have not been\nexplicitly demonstrated previously. We extensively tested our approach in task\nspace and joint space scenarios using a 7-DoF robotic manipulator. We\ndemonstrate that our method is capable of learning and generating motion skills\nbased on complicated motion patterns demonstrated by a human operator.\nAdditionally, we assess several obstacle avoidance strategies and generate\ntrajectories in multiple-mode settings.",
    "descriptor": "",
    "authors": [
      "Hadi Beik-Mohammadi",
      "S\u00f8ren Hauberg",
      "Georgios Arvanitidis",
      "Gerhard Neumann",
      "Leonel Rozo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07761"
  },
  {
    "id": "arXiv:2203.07765",
    "title": "Optimal selection and tracking of generalized Nash equilibria in  monotone games",
    "abstract": "A fundamental open problem in monotone game theory is the computation of a\nspecific generalized Nash equilibrium (GNE) among all the available ones, e.g.\nthe optimal equilibrium with respect to a system-level objective. The existing\nGNE seeking algorithms have in fact convergence guarantees toward an arbitrary,\npossibly inefficient, equilibrium. In this paper, we solve this open problem by\nleveraging results from fixed-point selection theory and in turn derive\ndistributed algorithms for the computation of an optimal GNE in monotone games.\nWe then extend the technical results to the time-varying setting and propose an\nalgorithm that tracks the sequence of optimal equilibria up to an asymptotic\nerror, whose bound depends on the local computational capabilities of the\nagents.",
    "descriptor": "",
    "authors": [
      "Emilio Benenati",
      "Wicak Ananduta",
      "Sergio Grammatico"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.07765"
  },
  {
    "id": "arXiv:2203.07769",
    "title": "Inverse Problems: A Deterministic Approach using Physics-Based Reduced  Models",
    "abstract": "These lecture notes summarize various summer schools that I have given on the\ntopic of solving inverse problems (state and parameter estimation) by combining\noptimally measurement observations and parametrized PDE models. After defining\na notion of optimal performance in terms of the smallest reconstruction error\nthat any reconstruction algorithm can achieve, the notes present practical\nnumerical algorithms based on nonlinear reduced models for which one can prove\nthat they can deliver a performance close to optimal. We also discuss\nalgorithms for sensor placement with the approach. The proposed concepts may be\nviewed as exploring alternatives to Bayesian inversion in favor of more\ndeterministic notions of accuracy quantification.",
    "descriptor": "",
    "authors": [
      "Olga Mula"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.07769"
  },
  {
    "id": "arXiv:2203.07774",
    "title": "An Empirical Study of Market Inefficiencies in Uniswap and SushiSwap",
    "abstract": "Decentralized exchanges are revolutionizing finance. With their ever-growing\nincrease in popularity, a natural question that begs to be asked is: how\nefficient are these new markets?\nWe find that nearly 30% of analyzed trades are executed at an unfavorable\nrate. Additionally, we observe that, especially during the DeFi summer in 2020,\nprice inaccuracies across the market plagued DEXes. Uniswap and SushiSwap,\nhowever, quickly adapt to their increased volumes. We see an increase in market\nefficiency with time during the observation period. Nonetheless, the DEXes\nstill struggle to track the reference market when cryptocurrency prices are\nhighly volatile. During such periods of high volatility, we observe the market\nbecoming less efficient - manifested by an increased prevalence in cyclic\narbitrage opportunities.",
    "descriptor": "",
    "authors": [
      "Jan Arvid Berg",
      "Robin Fritsch",
      "Lioba Heimbach",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2203.07774"
  },
  {
    "id": "arXiv:2203.07777",
    "title": "Social Choice Around the Block: On the Computational Social Choice of  Blockchain",
    "abstract": "One of the most innovative aspects of blockchain technology consists in the\nintroduction of an incentive layer to regulate the behavior of distributed\nprotocols. The designer of a blockchain system faces therefore issues that are\nakin to those relevant for the design of economic mechanisms, and faces them in\na computational setting. From this perspective the present paper argues for the\nimportance of computational social choice in blockchain research. It identifies\na few challenges at the interface of the two fields that illustrate the strong\npotential for cross-fertilization between them.",
    "descriptor": "\nComments: Paper appears in the proceedings of AAMAS'22, Blue Sky Ideas track\n",
    "authors": [
      "Davide Grossi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07777"
  },
  {
    "id": "arXiv:2203.07781",
    "title": "UniSAr: A Unified Structure-Aware Autoregressive Language Model for  Text-to-SQL",
    "abstract": "Existing text-to-SQL semantic parsers are typically designed for particular\nsettings such as handling queries that span multiple tables, domains or turns\nwhich makes them ineffective when applied to different settings. We present\nUniSAr (Unified Structure-Aware Autoregressive Language Model), which benefits\nfrom directly using an off-the-shelf language model architecture and\ndemonstrates consistently high performance under different settings.\nSpecifically, UniSAr extends existing autoregressive language models to\nincorporate three non-invasive extensions to make them structure-aware: (1)\nadding structure mark to encode database schema, conversation context, and\ntheir relationships; (2) constrained decoding to decode well structured SQL for\na given database schema; and (3) SQL completion to complete potential missing\nJOIN relationships in SQL based on database schema. On seven well-known\ntext-to-SQL datasets covering multi-domain, multi-table and multi-turn, UniSAr\ndemonstrates highly comparable or better performance to the most advanced\nspecifically-designed text-to-SQL models. Importantly, our UniSAr is\nnon-invasive, such that other core model advances in text-to-SQL can also adopt\nour extensions to further enhance performance.",
    "descriptor": "\nComments: Codes and checkpoints are available at this https URL\n",
    "authors": [
      "Longxu Dou",
      "Yan Gao",
      "Mingyang Pan",
      "Dingzirui Wang",
      "Jian-Guang Lou",
      "Wanxiang Che",
      "Dechen Zhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.07781"
  },
  {
    "id": "arXiv:2203.07782",
    "title": "Complex Evolutional Pattern Learning for Temporal Knowledge Graph  Reasoning",
    "abstract": "A Temporal Knowledge Graph (TKG) is a sequence of KGs corresponding to\ndifferent timestamps. TKG reasoning aims to predict potential facts in the\nfuture given the historical KG sequences. One key of this task is to mine and\nunderstand evolutional patterns of facts from these sequences. The evolutional\npatterns are complex in two aspects, length-diversity and time-variability.\nExisting models for TKG reasoning focus on modeling fact sequences of a fixed\nlength, which cannot discover complex evolutional patterns that vary in length.\nFurthermore, these models are all trained offline, which cannot well adapt to\nthe changes of evolutional patterns from then on. Thus, we propose a new model,\ncalled Complex Evolutional Network (CEN), which uses a length-aware\nConvolutional Neural Network (CNN) to handle evolutional patterns of different\nlengths via an easy-to-difficult curriculum learning strategy. Besides, we\npropose to learn the model under the online setting so that it can adapt to the\nchanges of evolutional patterns over time. Extensive experiments demonstrate\nthat CEN obtains substantial performance improvement under both the traditional\noffline and the proposed online settings.",
    "descriptor": "\nComments: ACL 2022 main conference\n",
    "authors": [
      "Zixuan Li",
      "Saiping Guan",
      "Xiaolong Jin",
      "Weihua Peng",
      "Yajuan Lyu",
      "Yong Zhu",
      "Long Bai",
      "Wei Li",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07782"
  },
  {
    "id": "arXiv:2203.07785",
    "title": "The Ghost in the Machine has an American accent: value conflict in GPT-3",
    "abstract": "The alignment problem in the context of large language models must consider\nthe plurality of human values in our world. Whilst there are many resonant and\noverlapping values amongst the world's cultures, there are also many\nconflicting, yet equally valid, values. It is important to observe which\ncultural values a model exhibits, particularly when there is a value conflict\nbetween input prompts and generated outputs. We discuss how the co-creation of\nlanguage and cultural value impacts large language models (LLMs). We explore\nthe constitution of the training data for GPT-3 and compare that to the world's\nlanguage and internet access demographics, as well as to reported statistical\nprofiles of dominant values in some Nation-states. We stress tested GPT-3 with\na range of value-rich texts representing several languages and nations;\nincluding some with values orthogonal to dominant US public opinion as reported\nby the World Values Survey. We observed when values embedded in the input text\nwere mutated in the generated outputs and noted when these conflicting values\nwere more aligned with reported dominant US values. Our discussion of these\nresults uses a moral value pluralism (MVP) lens to better understand these\nvalue mutations. Finally, we provide recommendations for how our work may\ncontribute to other current work in the field.",
    "descriptor": "\nComments: There are a total of 15 pages of the PDF including 8 pages of the main manuscript, 3 pages of references, and 4 pages of appendices. The paper is currently under review by a conference\n",
    "authors": [
      "Rebecca L Johnson",
      "Giada Pistilli",
      "Natalia Men\u00e9dez-Gonz\u00e1lez",
      "Leslye Denisse Dias Duran",
      "Enrico Panai",
      "Julija Kalpokiene",
      "Donald Jay Bertulfo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07785"
  },
  {
    "id": "arXiv:2203.07788",
    "title": "Scalable Penalized Regression for Noise Detection in Learning with Noisy  Labels",
    "abstract": "Noisy training set usually leads to the degradation of generalization and\nrobustness of neural networks. In this paper, we propose using a theoretically\nguaranteed noisy label detection framework to detect and remove noisy data for\nLearning with Noisy Labels (LNL). Specifically, we design a penalized\nregression to model the linear relation between network features and one-hot\nlabels, where the noisy data are identified by the non-zero mean shift\nparameters solved in the regression model. To make the framework scalable to\ndatasets that contain a large number of categories and training data, we\npropose a split algorithm to divide the whole training set into small pieces\nthat can be solved by the penalized regression in parallel, leading to the\nScalable Penalized Regression (SPR) framework. We provide the non-asymptotic\nprobabilistic condition for SPR to correctly identify the noisy data. While SPR\ncan be regarded as a sample selection module for standard supervised training\npipeline, we further combine it with semi-supervised algorithm to further\nexploit the support of noisy data as unlabeled data. Experimental results on\nseveral benchmark datasets and real-world noisy datasets show the effectiveness\nof our framework. Our code and pretrained models are released at\nhttps://github.com/Yikai-Wang/SPR-LNL.",
    "descriptor": "\nComments: To appear in CVPR2022. Code and pretrained models will be released after going through necessary procedures\n",
    "authors": [
      "Yikai Wang",
      "Xinwei Sun",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07788"
  },
  {
    "id": "arXiv:2203.07789",
    "title": "Engineering data-driven solutions for future mobility: perspectives and  challenges",
    "abstract": "The automotive industry is currently undergoing major changes. These include\na general shift towards decarbonised mode of transportation, the implementation\nof mobility as an end-to-end service, and the transition to vehicles that\nincreasingly rely on software and digital tools to function. Digitalisation is\nexpected to play a key role in shaping the future of mobility ecosystems by\nfostering the integration of traditionally independent system domains in the\nenergy, transportation and information sectors. This report discusses\nopportunities and challenges for engineering data-driven solutions that support\nthe requirements of future digitalised mobility systems based on three use\ncases for electric vehicle public charging infrastructures, services and\nsecurity.",
    "descriptor": "",
    "authors": [
      "Daphne Tuncer",
      "Oytun Babacan",
      "Raoul Guiazon",
      "Halima Abu Ali",
      "Josephine Conway",
      "Sebastian Kern",
      "Ana Teresa Moreno",
      "Max Peel",
      "Arthur Pereira",
      "Nadia Assad",
      "Giulia Franceschini",
      "Margrethe Gjerull",
      "Anna Hardisty",
      "Imran Marwa",
      "Blanca Alvarez Lopez",
      "Ariella Shalev",
      "Christopher D' Cruz Tambua",
      "Hapsari Damayanti",
      "Paul Frapart",
      "Sacha Lepoutre",
      "Peer Novak"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.07789"
  },
  {
    "id": "arXiv:2203.07792",
    "title": "Parking Analytics Framework using Deep Learning",
    "abstract": "With the number of vehicles continuously increasing, parking monitoring and\nanalysis are becoming a substantial feature of modern cities. In this study, we\npresent a methodology to monitor car parking areas and to analyze their\noccupancy in real-time. The solution is based on a combination between image\nanalysis and deep learning techniques. It incorporates four building blocks put\ninside a pipeline: vehicle detection, vehicle tracking, manual annotation of\nparking slots, and occupancy estimation using the Ray Tracing algorithm. The\naim of this methodology is to optimize the use of parking areas and to reduce\nthe time wasted by daily drivers to find the right parking slot for their cars.\nAlso, it helps to better manage the space of the parking areas and to discover\nmisuse cases. A demonstration of the provided solution is shown in the\nfollowing video link: https://www.youtube.com/watch?v=KbAt8zT14Tc.",
    "descriptor": "",
    "authors": [
      "Bilel Benjdira",
      "Anis Koubaa",
      "Wadii Boulila",
      "Adel Ammar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07792"
  },
  {
    "id": "arXiv:2203.07796",
    "title": "Multi-Unit Diffusion Auctions with Intermediaries",
    "abstract": "This paper studies multi-unit auctions powered by intermediaries, where each\nintermediary owns a private set of unit-demand buyers and all intermediaries\nare networked with each other. Our goal is to incentivize the intermediaries to\ndiffuse the auction information to individuals they can reach, including their\nprivate buyers and neighboring intermediaries, so that more potential buyers\nare able to participate in the auction. To this end, we build a diffusion-based\nauction framework which incorporates the strategic interaction of\nintermediaries. It is showed that the classic Vickrey-Clarke-Groves (VCG)\nmechanism within the framework can achieve the maximum social welfare, but it\nmay decrease the seller's revenue or even lead to a deficit. To overcome the\nrevenue issue, we propose a novel auction, called critical neighborhood\nauction, which not only maximizes the social welfare, but also improves the\nseller's revenue comparing to the VCG mechanism with/without intermediaries.",
    "descriptor": "",
    "authors": [
      "Bin Li",
      "Dong Hao",
      "Dengji Zhao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07796"
  },
  {
    "id": "arXiv:2203.07802",
    "title": "A Framework for Verifiable and Auditable Federated Anomaly Detection",
    "abstract": "Federated Leaning is an emerging approach to manage cooperation between a\ngroup of agents for the solution of Machine Learning tasks, with the goal of\nimproving each agent's performance without disclosing any data. In this paper\nwe present a novel algorithmic architecture that tackle this problem in the\nparticular case of Anomaly Detection (or classification or rare events), a\nsetting where typical applications often comprise data with sensible\ninformation, but where the scarcity of anomalous examples encourages\ncollaboration. We show how Random Forests can be used as a tool for the\ndevelopment of accurate classifiers with an effective insight-sharing mechanism\nthat does not break the data integrity. Moreover, we explain how the new\narchitecture can be readily integrated in a blockchain infrastructure to ensure\nthe verifiable and auditable execution of the algorithm. Furthermore, we\ndiscuss how this work may set the basis for a more general approach for the\ndesign of federated ensemble-learning methods beyond the specific task and\narchitecture discussed in this paper.",
    "descriptor": "",
    "authors": [
      "Gabriele Santin",
      "Inna Skarbovsky",
      "Fabiana Fournier",
      "Bruno Lepri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.07802"
  },
  {
    "id": "arXiv:2203.07805",
    "title": "On the focusing of thermal images",
    "abstract": "In this paper we present a new thermographic image database suitable for the\nanalysis of automatic focus measures. This database consists of 8 different\nsets of scenes, where each scene contains one image for 96 different focus\npositions. Using this database we evaluate the usefulness of six focus measures\nwith the goal to determine the optimal focus position. Experimental results\nreveal that an accurate automatic detection of optimal focus position is\npossible, even with a low computational burden. We also present an acquisition\ntool able to help the acquisition of thermal images. To the best of our\nknowledge, this is the first study about automatic focus of thermal images.",
    "descriptor": "\nComments: 11 pages, published in Pattern Recognition Letters, Volume 32, Issue 11, 2011, Pages 1548-1557\n",
    "authors": [
      "Marcos Faundez-Zanuy",
      "Ji\u0159\u00ed Mekyska",
      "Virginia Espinosa-Duro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07805"
  },
  {
    "id": "arXiv:2203.07806",
    "title": "This is not the padding you are looking for! On the ineffectiveness of  QUIC PADDING against website fingerprinting",
    "abstract": "Website fingerprinting (WF) is a well-know threat to users' web privacy. New\ninternet standards, such as QUIC, include padding to support defenses against\nWF. We study whether network-layer padding can indeed be used to construct\neffective WF defenses. We confirm previous claims that network-layer padding\ncannot provide good protection against powerful adversaries capable of\nobserving all traffic traces. In contrast to prior work, we also demonstrate\nthat such padding is ineffective even against adversaries with partial view of\nthe traffic. Network-layer padding without application input is ineffective\nbecause it fails to hide information unique across different applications. We\nshow that application-layer padding solutions need to be deployed by both first\nand third parties, and that they can only thwart traffic analysis in limited\nsituations. We identify challenges to deploy effective WF defenses and provide\nrecommendations to reduce these hurdles.",
    "descriptor": "",
    "authors": [
      "Ludovic Barman",
      "Sandra Siby",
      "Christopher Wood",
      "Marwan Fayed",
      "Nick Sullivan",
      "Carmela Troncoso"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.07806"
  },
  {
    "id": "arXiv:2203.07807",
    "title": "End-to-end P300 BCI using Bayesian accumulation of Riemannian  probabilities",
    "abstract": "In brain-computer interfaces (BCI), most of the approaches based on\nevent-related potential (ERP) focus on the detection of P300, aiming for single\ntrial classification for a speller task. While this is an important objective,\nexisting P300 BCI still require several repetitions to achieve a correct\nclassification accuracy. Signal processing and machine learning advances in\nP300 BCI mostly revolve around the P300 detection part, leaving the character\nclassification out of the scope. To reduce the number of repetitions while\nmaintaining a good character classification, it is critical to embrace the full\nclassification problem. We introduce an end-to-end pipeline, starting from\nfeature extraction, and is composed of an ERP-level classification using\nprobabilistic Riemannian MDM which feeds a character-level classification using\nBayesian accumulation of confidence across trials. Whereas existing approaches\nonly increase the confidence of a character when it is flashed, our new\npipeline, called Bayesian accumulation of Riemannian probabilities (ASAP),\nupdate the confidence of each character after each flash. We provide the proper\nderivation and theoretical reformulation of this Bayesian approach for a\nseamless processing of information from signal to BCI characters. We\ndemonstrate that our approach performs significantly better than standard\nmethods on public P300 datasets.",
    "descriptor": "\nComments: 9 pages, 7 figures, 1 table\n",
    "authors": [
      "Quentin Barth\u00e9lemy",
      "Sylvain Chevallier",
      "Rapha\u00eblle Bertrand-Lalo",
      "Pierre Clisson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.07807"
  },
  {
    "id": "arXiv:2203.07808",
    "title": "Interspace Pruning: Using Adaptive Filter Representations to Improve  Training of Sparse CNNs",
    "abstract": "Unstructured pruning is well suited to reduce the memory footprint of\nconvolutional neural networks (CNNs), both at training and inference time. CNNs\ncontain parameters arranged in $K \\times K$ filters. Standard unstructured\npruning (SP) reduces the memory footprint of CNNs by setting filter elements to\nzero, thereby specifying a fixed subspace that constrains the filter.\nEspecially if pruning is applied before or during training, this induces a\nstrong bias. To overcome this, we introduce interspace pruning (IP), a general\ntool to improve existing pruning methods. It uses filters represented in a\ndynamic interspace by linear combinations of an underlying adaptive filter\nbasis (FB). For IP, FB coefficients are set to zero while un-pruned\ncoefficients and FBs are trained jointly. In this work, we provide mathematical\nevidence for IP's superior performance and demonstrate that IP outperforms SP\non all tested state-of-the-art unstructured pruning methods. Especially in\nchallenging situations, like pruning for ImageNet or pruning to high sparsity,\nIP greatly exceeds SP with equal runtime and parameter costs. Finally, we show\nthat advances of IP are due to improved trainability and superior\ngeneralization ability.",
    "descriptor": "\nComments: Accepted as conference paper for CVPR 2022\n",
    "authors": [
      "Paul Wimmer",
      "Jens Mehnert",
      "Alexandru Paul Condurache"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07808"
  },
  {
    "id": "arXiv:2203.07814",
    "title": "Competition-Level Code Generation with AlphaCode",
    "abstract": "Programming is a powerful and ubiquitous problem-solving tool. Developing\nsystems that can assist programmers or even generate programs independently\ncould make programming more productive and accessible, yet so far incorporating\ninnovations in AI has proven challenging. Recent large-scale language models\nhave demonstrated an impressive ability to generate code, and are now able to\ncomplete simple programming tasks. However, these models still perform poorly\nwhen evaluated on more complex, unseen problems that require problem-solving\nskills beyond simply translating instructions into code. For example,\ncompetitive programming problems which require an understanding of algorithms\nand complex natural language remain extremely challenging. To address this gap,\nwe introduce AlphaCode, a system for code generation that can create novel\nsolutions to these problems that require deeper reasoning. In simulated\nevaluations on recent programming competitions on the Codeforces platform,\nAlphaCode achieved on average a ranking of top 54.3% in competitions with more\nthan 5,000 participants. We found that three key components were critical to\nachieve good and reliable performance: (1) an extensive and clean competitive\nprogramming dataset for training and evaluation, (2) large and\nefficient-to-sample transformer-based architectures, and (3) large-scale model\nsampling to explore the search space, followed by filtering based on program\nbehavior to a small set of submissions.",
    "descriptor": "\nComments: 74 pages\n",
    "authors": [
      "Yujia Li",
      "David Choi",
      "Junyoung Chung",
      "Nate Kushman",
      "Julian Schrittwieser",
      "R\u00e9mi Leblond",
      "Tom Eccles",
      "James Keeling",
      "Felix Gimeno",
      "Agustin Dal Lago",
      "Thomas Hubert",
      "Peter Choy",
      "Cyprien de Masson d'Autume",
      "Igor Babuschkin",
      "Xinyun Chen",
      "Po-Sen Huang",
      "Johannes Welbl",
      "Sven Gowal",
      "Alexey Cherepanov",
      "James Molloy",
      "Daniel J. Mankowitz",
      "Esme Sutherland Robson",
      "Pushmeet Kohli",
      "Nando de Freitas",
      "Koray Kavukcuoglu",
      "Oriol Vinyals"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07814"
  },
  {
    "id": "arXiv:2203.07815",
    "title": "Adversarial Counterfactual Augmentation: Application in Alzheimer's  Disease Classification",
    "abstract": "Data augmentation has been widely used in deep learning to reduce\nover-fitting and improve the robustness of models. However, traditional data\naugmentation techniques, e.g., rotation, cropping, flipping, etc., do not\nconsider \\textit{semantic} transformations, e.g., changing the age of a brain\nimage. Previous works tried to achieve semantic augmentation by generating\n\\textit{counterfactuals}, but they focused on how to train deep generative\nmodels and randomly created counterfactuals with the generative models without\nconsidering which counterfactuals are most \\textit{effective} for improving\ndownstream training. Different from these approaches, in this work, we propose\na novel adversarial counterfactual augmentation scheme that aims to find the\nmost \\textit{effective} counterfactuals to improve downstream tasks with a\npre-trained generative model. Specifically, we construct an adversarial game\nwhere we update the input \\textit{conditional factor} of the generator and the\ndownstream \\textit{classifier} with gradient backpropagation alternatively and\niteratively. The key idea is to find conditional factors that can result in\n\\textit{hard} counterfactuals for the classifier. This can be viewed as finding\nthe `\\textit{weakness}' of the classifier and purposely forcing it to\n\\textit{overcome} its weakness via the generative model. To demonstrate the\neffectiveness of the proposed approach, we validate the method with the\nclassification of Alzheimer's Disease (AD) as the downstream task based on a\npre-trained brain ageing synthesis model. We show the proposed approach\nimproves test accuracy and can alleviate spurious correlations. Code will be\nreleased upon acceptance.",
    "descriptor": "",
    "authors": [
      "Tian Xia",
      "Pedro Sanchez",
      "Chen Qin",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07815"
  },
  {
    "id": "arXiv:2203.07824",
    "title": "SISL:Self-Supervised Image Signature Learning for Splicing Detection and  Localization",
    "abstract": "Recent algorithms for image manipulation detection almost exclusively use\ndeep network models. These approaches require either dense pixelwise\ngroundtruth masks, camera ids, or image metadata to train the networks. On one\nhand, constructing a training set to represent the countless tampering\npossibilities is impractical. On the other hand, social media platforms or\ncommercial applications are often constrained to remove camera ids as well as\nmetadata from images. A self-supervised algorithm for training manipulation\ndetection models without dense groundtruth or camera/image metadata would be\nextremely useful for many forensics applications. In this paper, we propose\nself-supervised approach for training splicing detection/localization models\nfrom frequency transforms of images. To identify the spliced regions, our deep\nnetwork learns a representation to capture an image specific signature by\nenforcing (image) self consistency . We experimentally demonstrate that our\nproposed model can yield similar or better performances of multiple existing\nmethods on standard datasets without relying on labels or metadata.",
    "descriptor": "",
    "authors": [
      "Susmit Agrawal",
      "Prabhat Kumar",
      "Siddharth Seth",
      "Toufiq Parag",
      "Maneesh Singh",
      "Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07824"
  },
  {
    "id": "arXiv:2203.07825",
    "title": "SPA-VAE: Similar-Parts-Assignment for Unsupervised 3D Point Cloud  Generation",
    "abstract": "This paper addresses the problem of unsupervised parts-aware point cloud\ngeneration with learned parts-based self-similarity. Our SPA-VAE infers a set\nof latent canonical candidate shapes for any given object, along with a set of\nrigid body transformations for each such candidate shape to one or more\nlocations within the assembled object. In this way, noisy samples on the\nsurface of, say, each leg of a table, are effectively combined to estimate a\nsingle leg prototype. When parts-based self-similarity exists in the raw data,\nsharing data among parts in this way confers numerous advantages: modeling\naccuracy, appropriately self-similar generative outputs, precise in-filling of\nocclusions, and model parsimony. SPA-VAE is trained end-to-end using a\nvariational Bayesian approach which uses the Gumbel-softmax trick for the\nshared part assignments, along with various novel losses to provide appropriate\ninductive biases. Quantitative and qualitative analyses on ShapeNet demonstrate\nthe advantage of SPA-VAE.",
    "descriptor": "",
    "authors": [
      "Shidi Li",
      "Christian Walder",
      "Miaomiao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07825"
  },
  {
    "id": "arXiv:2203.07828",
    "title": "Do BERTs Learn to Use Browser User Interface? Exploring Multi-Step Tasks  with Unified Vision-and-Language BERTs",
    "abstract": "Pre-trained Transformers are good foundations for unified multi-task models\nowing to their task-agnostic representation. Pre-trained Transformers are often\ncombined with text-to-text framework to execute multiple tasks by a single\nmodel. Performing a task through a graphical user interface (GUI) is another\ncandidate to accommodate various tasks, including multi-step tasks with vision\nand language inputs. However, few papers combine pre-trained Transformers with\nperforming through GUI. To fill this gap, we explore a framework in which a\nmodel performs a task by manipulating the GUI implemented with web pages in\nmultiple steps. We develop task pages with and without page transitions and\npropose a BERT extension for the framework. We jointly trained our BERT\nextension with those task pages, and made the following observations. (1) The\nmodel learned to use both task pages with and without page transition. (2) In\nfour out of five tasks without page transitions, the model performs greater\nthan 75% of the performance of the original BERT, which does not use browsers.\n(3) The model did not generalize effectively on unseen tasks. These results\nsuggest that we can fine-tune BERTs to multi-step tasks through GUIs, and there\nis room for improvement in their generalizability. Code will be available\nonline.",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Taichi Iki",
      "Akiko Aizawa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07828"
  },
  {
    "id": "arXiv:2203.07830",
    "title": "A Survey of fault models and fault tolerance methods for 2D bus-based  multi-core systems and TSV based 3D NOC many-core systems",
    "abstract": "Reliability has taken centre stage in the development of high-performance\ncomputing processors. A Surge of interest is noticeable in recent times in\nformulating fault and failure models, understanding failure mechanism and\nstrategizing fault mitigation methods for improving the reliability of the\nsystem. The article presents a congregation of concepts illustrated one after\nthe other for a better understanding of damages caused by radiation, relevant\nfault models, and effects of faults. We examine the state of art fault\nmitigation techniques at the logical layer for digital CMOS based design and\nSRAM based FPGA. CMOS SRAM structure is the same for both digital CMOS and\nFPGA. Understanding of resilient SRAM based FPGA is necessary for developing\nresilient prototypes and it facilitates a faster integration of digital CMOS\ndesigns. At the micro-architectural and architectural layer, error detection\nand recovery methods are discussed for bus-based multi-core systems. The\nThrough silicon via based 3D Network on chip is the prospective solution for\nintegrating many cores on single die. A suitable interconnection approach for\npetascale computing on many-core systems. The article presents an elaborate\ndiscussion on fault models, failure mechanisms, resilient 3D routers, defect\ntolerance methods for the TSV based 3D NOC many-core systems. Core redundancy,\nself-diagnosis and distributed diagnosis at the hardware level are examined for\nmany-core systems. The article presents a gamut of fault tolerance solutions\nfrom logic level to processor core level in a multi-core and many-core\nscenario.",
    "descriptor": "\nComments: An Elaborate survey on fault models and fault tolerant designs for multi-core and many-core systems\n",
    "authors": [
      "Shashikiran Venkatesha",
      "Ranjani Parthasarathi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.07830"
  },
  {
    "id": "arXiv:2203.07832",
    "title": "Learning to Infer Belief Embedded Communication",
    "abstract": "In multi-agent collaboration problems with communication, an agent's ability\nto encode their intention and interpret other agents' strategies is critical\nfor planning their future actions. This paper introduces a novel algorithm\ncalled Intention Embedded Communication (IEC) to mimic an agent's language\nlearning ability. IEC contains a perception module for decoding other agents'\nintentions in response to their past actions. It also includes a language\ngeneration module for learning implicit grammar during communication with two\nor more agents. Such grammar, by construction, should be compact for efficient\ncommunication. Both modules undergo conjoint evolution - similar to an infant's\nbabbling that enables it to learn a language of choice by trial and error. We\nutilised three multi-agent environments, namely predator/prey, traffic junction\nand level-based foraging and illustrate that such a co-evolution enables us to\nlearn much quicker (50%) than state-of-the-art algorithms like MADDPG. Ablation\nstudies further show that disabling the inferring belief module, communication\nmodule, and the hidden states reduces the model performance by 38%, 60% and\n30%, respectively. Hence, we suggest that modelling other agents' behaviour\naccelerates another agent to learn grammar and develop a language to\ncommunicate efficiently. We evaluate our method on a set of cooperative\nscenarios and show its superior performance to other multi-agent baselines. We\nalso demonstrate that it is essential for agents to reason about others' states\nand learn this ability by continuous communication.",
    "descriptor": "",
    "authors": [
      "Guo Ye",
      "Han Liu",
      "Biswa Sengupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.07832"
  },
  {
    "id": "arXiv:2203.07835",
    "title": "Trustworthy Deep Learning via Proper Calibration Errors: A Unifying  Approach for Quantifying the Reliability of Predictive Uncertainty",
    "abstract": "With model trustworthiness being crucial for sensitive real-world\napplications, practitioners are putting more and more focus on evaluating deep\nneural networks in terms of uncertainty calibration. Calibration errors are\ndesigned to quantify the reliability of probabilistic predictions but their\nestimators are usually biased and inconsistent. In this work, we introduce the\nframework of proper calibration errors, which relates every calibration error\nto a proper score and provides a respective upper bound with optimal estimation\nproperties. This upper bound allows us to reliably estimate the calibration\nimprovement of any injective recalibration method in an unbiased manner. We\ndemonstrate that, in contrast to our approach, the most commonly used\nestimators are substantially biased with respect to the true improvement of\nrecalibration methods.",
    "descriptor": "",
    "authors": [
      "Sebastian Gruber",
      "Florian Buettner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.07835"
  },
  {
    "id": "arXiv:2203.07836",
    "title": "Graph Pre-training for AMR Parsing and Generation",
    "abstract": "Abstract meaning representation (AMR) highlights the core semantic\ninformation of text in a graph structure. Recently, pre-trained language models\n(PLMs) have advanced tasks of AMR parsing and AMR-to-text generation,\nrespectively. However, PLMs are typically pre-trained on textual data, thus are\nsub-optimal for modeling structural knowledge. To this end, we investigate\ngraph self-supervised training to improve the structure awareness of PLMs over\nAMR graphs. In particular, we introduce two graph auto-encoding strategies for\ngraph-to-graph pre-training and four tasks to integrate text and graph\ninformation during pre-training. We further design a unified framework to\nbridge the gap between pre-training and fine-tuning tasks. Experiments on both\nAMR parsing and AMR-to-text generation show the superiority of our model. To\nour knowledge, we are the first to consider pre-training on semantic graphs.",
    "descriptor": "\nComments: to appear in ACL2022 main conference\n",
    "authors": [
      "Xuefeng Bai",
      "Yulong Chen",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07836"
  },
  {
    "id": "arXiv:2203.07837",
    "title": "Pose-MUM : Reinforcing Key Points Relationship for Semi-Supervised Human  Pose Estimation",
    "abstract": "A well-designed strong-weak augmentation strategy and the stable teacher to\ngenerate reliable pseudo labels are essential in the teacher-student framework\nof semi-supervised learning (SSL). Considering these in mind, to suit the\nsemi-supervised human pose estimation (SSHPE) task, we propose a novel approach\nreferred to as Pose-MUM that modifies Mix/UnMix (MUM) augmentation. Like MUM in\nthe dense prediction task, the proposed Pose-MUM makes strong-weak augmentation\nfor pose estimation and leads the network to learn the relationship between\neach human key point much better than the conventional methods by adding the\nmixing process in intermediate layers in a stochastic manner. In addition, we\nemploy the exponential-moving-average-normalization (EMAN) teacher, which is\nstable and well-suited to the SSL framework and furthermore boosts the\nperformance. Extensive experiments on MS-COCO dataset show the superiority of\nour proposed method by consistently improving the performance over the previous\nmethods following SSHPE benchmark.",
    "descriptor": "",
    "authors": [
      "JongMok Kim",
      "Hwijun Lee",
      "Jaeseung Lim",
      "Jongkeun Na",
      "Nojun Kwak",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07837"
  },
  {
    "id": "arXiv:2203.07840",
    "title": "Optimizing microservices with hyperparameter optimization",
    "abstract": "In the last few years, the cloudification of applications requires new\nconcepts and techniques to fully reap the benefits of the new computing\nparadigm. Among them, the microservices architectural style, which is inspired\nby service-oriented architectures, has gained attention from both industry and\nacademia. However, decomposing a monolith into multiple microservices also\ncreates several challenges across the application's lifecycle. In this work, we\nfocus on the operation aspect of microservices, and present our novel proposal\nto enable self-optimizing microservices systems based on grid search and random\nsearch techniques. The initial results show our approach is able to optimize\nthe latency performance of microservices to up to 10.56\\%.",
    "descriptor": "",
    "authors": [
      "Hai Dinh-Tuan",
      "Katerina Katsarou",
      "Patrick Herbke"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.07840"
  },
  {
    "id": "arXiv:2203.07843",
    "title": "Locally refined quad meshing for linear elasticity problems based on  convolutional neural networks",
    "abstract": "In this paper we propose a method to generate suitably refined finite element\nmeshes using neural networks. As a model problem we consider a linear\nelasticity problem on a planar domain (possibly with holes) having a polygonal\nboundary. We impose boundary conditions by fixing the position of a part of the\nboundary and applying a force on another part of the boundary. The resulting\ndisplacement and distribution of stresses depend on the geometry of the domain\nand on the boundary conditions. When applying a standard Galerkin\ndiscretization using quadrilateral finite elements, one usually has to perform\nadaptive refinement to properly resolve maxima of the stress distribution. Such\nan adaptive scheme requires a local error estimator and a corresponding local\nrefinement strategy. The overall costs of such a strategy are high. We propose\nto reduce the costs of obtaining a suitable discretization by training a neural\nnetwork whose evaluation replaces this adaptive refinement procedure. We set up\na single network for a large class of possible domains and boundary conditions\nand not on a single domain of interest. The computational domain and boundary\nconditions are interpreted as images, which are suitable inputs for convolution\nneural networks. We use the U-net architecture and we devise training\nstrategies by dividing the possible inputs into different categories based on\ntheir overall geometric complexity. Thus, we compare different training\nstrategies based on varying geometric complexity. One of the advantages of the\nproposed approach is the interpretation of input and output as images, which do\nnot depend on the underlying discretization scheme. Another is the\ngeneralizability and geometric flexibility. The network can be applied to\npreviously unseen geometries, even with different topology and level of detail.\nThus, training can easily be extended to other classes of geometries.",
    "descriptor": "",
    "authors": [
      "Chiu Ling Chan",
      "Felix Scholz",
      "Thomas Takacs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.07843"
  },
  {
    "id": "arXiv:2203.07844",
    "title": "What is the best RNN-cell structure for forecasting each time series  behavior?",
    "abstract": "It is unquestionable that time series forecasting is of paramount importance\nin many fields. The most used machine learning models to address time series\nforecasting tasks are Recurrent Neural Networks (RNNs). Typically, those models\nare built using one of the three most popular cells, ELMAN, Long-Short Term\nMemory (LSTM), or Gated Recurrent Unit (GRU) cells, each cell has a different\nstructure and implies a different computational cost. However, it is not clear\nwhy and when to use each RNN-cell structure. Actually, there is no\ncomprehensive characterization of all the possible time series behaviors and no\nguidance on what RNN cell structure is the most suitable for each behavior. The\nobjective of this study is two-fold: it presents a comprehensive taxonomy of\nall-time series behaviors (deterministic, random-walk, nonlinear, long-memory,\nand chaotic), and provides insights into the best RNN cell structure for each\ntime series behavior. We conducted two experiments: (1) The first experiment\nevaluates and analyzes the role of each component in the LSTM-Vanilla cell by\ncreating 11 variants based on one alteration in its basic architecture\n(removing, adding, or substituting one cell component). (2) The second\nexperiment evaluates and analyzes the performance of 20 possible RNN-cell\nstructures. Our results showed that the MGU-SLIM3 cell is the most recommended\nfor deterministic and nonlinear behaviors, the MGU-SLIM2 cell is the most\nsuitable for random-walk behavior, FB1 cell is advocated for long-memory\nbehavior, and LSTM-SLIM1 for chaotic behavior.",
    "descriptor": "",
    "authors": [
      "Rohaifa Khaldi",
      "Abdellatif El Afia",
      "Raddouane Chiheb",
      "Siham Tabik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07844"
  },
  {
    "id": "arXiv:2203.07845",
    "title": "Bamboo: Building Mega-Scale Vision Dataset Continually with  Human-Machine Synergy",
    "abstract": "Large-scale datasets play a vital role in computer vision. Existing datasets\nare either collected according to heuristic label systems or annotated blindly\nwithout differentiation to samples, making them inefficient and unscalable. How\nto systematically collect, annotate and build a mega-scale dataset remains an\nopen question. In this work, we advocate building a high-quality vision dataset\nactively and continually on a comprehensive label system. Specifically, we\ncontribute Bamboo Dataset, a mega-scale and information-dense dataset for both\nclassification and detection. Bamboo aims to populate the comprehensive\ncategories with 69M image classification annotations and 170,586 object\nbounding box annotations. Compared to ImageNet22K and Objects365, models\npre-trained on Bamboo achieve superior performance among various downstream\ntasks (6.2% gains on classification and 2.1% gains on detection). In addition,\nwe provide valuable observations regarding large-scale pre-training from over\n1,000 experiments. Due to its scalable nature on both label system and\nannotation pipeline, Bamboo will continue to grow and benefit from the\ncollective efforts of the community, which we hope would pave the way for more\ngeneral vision models.",
    "descriptor": "\nComments: Bamboo is available at this https URL\n",
    "authors": [
      "Yuanhan Zhang",
      "Qinghong Sun",
      "Yichun Zhou",
      "Zexin He",
      "Zhenfei Yin",
      "Kun Wang",
      "Lu Sheng",
      "Yu Qiao",
      "Jing Shao",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07845"
  },
  {
    "id": "arXiv:2203.07847",
    "title": "SCD: Self-Contrastive Decorrelation for Sentence Embeddings",
    "abstract": "In this paper, we propose Self-Contrastive Decorrelation (SCD), a\nself-supervised approach. Given an input sentence, it optimizes a joint\nself-contrastive and decorrelation objective. Learning a representation is\nfacilitated by leveraging the contrast arising from the instantiation of\nstandard dropout at different rates. The proposed method is conceptually simple\nyet empirically powerful. It achieves comparable results with state-of-the-art\nmethods on multiple benchmarks without using contrastive pairs. This study\nopens up avenues for efficient self-supervised learning methods that are more\nrobust than current contrastive methods.",
    "descriptor": "\nComments: To appear at ACL 2022\n",
    "authors": [
      "Tassilo Klein",
      "Moin Nabi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07847"
  },
  {
    "id": "arXiv:2203.07852",
    "title": "Block-Recurrent Transformers",
    "abstract": "We introduce the Block-Recurrent Transformer, which applies a transformer\nlayer in a recurrent fashion along a sequence, and has linear complexity with\nrespect to sequence length. Our recurrent cell operates on blocks of tokens\nrather than single tokens, and leverages parallel computation within a block in\norder to make efficient use of accelerator hardware. The cell itself is\nstrikingly simple. It is merely a transformer layer: it uses self-attention and\ncross-attention to efficiently compute a recurrent function over a large set of\nstate vectors and tokens. Our design was inspired in part by LSTM cells, and it\nuses LSTM-style gates, but it scales the typical LSTM cell up by several orders\nof magnitude.\nOur implementation of recurrence has the same cost in both computation time\nand parameter count as a conventional transformer layer, but offers\ndramatically improved perplexity in language modeling tasks over very long\nsequences. Our model out-performs a long-range Transformer XL baseline by a\nwide margin, while running twice as fast. We demonstrate its effectiveness on\nPG19 (books), arXiv papers, and GitHub source code.",
    "descriptor": "",
    "authors": [
      "DeLesley Hutchins",
      "Imanol Schlag",
      "Yuhuai Wu",
      "Ethan Dyer",
      "Behnam Neyshabur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.07852"
  },
  {
    "id": "arXiv:2203.07853",
    "title": "Concentration Properties of Random Codes",
    "abstract": "This paper studies the concentration properties of random codes.\nSpecifically, we show that, for discrete memoryless channels, the error\nexponent of a randomly generated code with pairwise-independent codewords\nconverges in probability to its expectation -- the typical error exponent. For\nhigh rates, the result is a consequence of the fact that the random-coding\nerror exponent and the sphere-packing error exponent coincide. For low rates,\ninstead, the convergence is based on the fact that the union bound accurately\ncharacterizes the probability of error. The paper also zooms into the behavior\nat asymptotically low rates and shows that the error exponent converges in\ndistribution to a Gaussian-like distribution. Finally, we present several\nresults on the convergence of the error probability and error exponent for\ngeneric ensembles and channels.",
    "descriptor": "\nComments: 98 pages\n",
    "authors": [
      "Lan V. Truong",
      "Giuseppe Cocco",
      "Josep Font-Segura",
      "Albert Guill\u00e9n i F\u00e0bregas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2203.07853"
  },
  {
    "id": "arXiv:2203.07856",
    "title": "Improved Multi-label Classification under Temporal Concept Drift:  Rethinking Group-Robust Algorithms in a Label-Wise Setting",
    "abstract": "In document classification for, e.g., legal and biomedical text, we often\ndeal with hundreds of classes, including very infrequent ones, as well as\ntemporal concept drift caused by the influence of real world events, e.g.,\npolicy changes, conflicts, or pandemics. Class imbalance and drift can\nsometimes be mitigated by resampling the training data to simulate (or\ncompensate for) a known target distribution, but what if the target\ndistribution is determined by unknown future events? Instead of simply\nresampling uniformly to hedge our bets, we focus on the underlying optimization\nalgorithms used to train such document classifiers and evaluate several\ngroup-robust optimization algorithms, initially proposed to mitigate\ngroup-level disparities. Reframing group-robust algorithms as adaptation\nalgorithms under concept drift, we find that Invariant Risk Minimization and\nSpectral Decoupling outperform sampling-based approaches to class imbalance and\nconcept drift, and lead to much better performance on minority classes. The\neffect is more pronounced the larger the label set.",
    "descriptor": "\nComments: 9 pages, long paper at ACL 2022 Findings\n",
    "authors": [
      "Ilias Chalkidis",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07856"
  },
  {
    "id": "arXiv:2203.07858",
    "title": "A Survey of Non-Rigid 3D Registration",
    "abstract": "Non-rigid registration computes an alignment between a source surface with a\ntarget surface in a non-rigid manner. In the past decade, with the advances in\n3D sensing technologies that can measure time-varying surfaces, non-rigid\nregistration has been applied for the acquisition of deformable shapes and has\na wide range of applications. This survey presents a comprehensive review of\nnon-rigid registration methods for 3D shapes, focusing on techniques related to\ndynamic shape acquisition and reconstruction. In particular, we review\ndifferent approaches for representing the deformation field, and the methods\nfor computing the desired deformation. Both optimization-based and\nlearning-based methods are covered. We also review benchmarks and datasets for\nevaluating non-rigid registration methods, and discuss potential future\nresearch directions.",
    "descriptor": "\nComments: Accepted to Eurographics 2022 State-of-the-Art Reports\n",
    "authors": [
      "Bailin Deng",
      "Yuxin Yao",
      "Roberto M. Dyke",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07858"
  },
  {
    "id": "arXiv:2203.07860",
    "title": "Imputing Out-of-Vocabulary Embeddings with LOVE Makes Language Models  Robust with Little Cost",
    "abstract": "State-of-the-art NLP systems represent inputs with word embeddings, but these\nare brittle when faced with Out-of-Vocabulary (OOV) words. To address this\nissue, we follow the principle of mimick-like models to generate vectors for\nunseen words, by learning the behavior of pre-trained embeddings using only the\nsurface form of words. We present a simple contrastive learning framework,\nLOVE, which extends the word representation of an existing pre-trained language\nmodel (such as BERT), and makes it robust to OOV with few additional\nparameters. Extensive evaluations demonstrate that our lightweight model\nachieves similar or even better performances than prior competitors, both on\noriginal datasets and on corrupted variants. Moreover, it can be used in a\nplug-and-play fashion with FastText and BERT, where it significantly improves\ntheir robustness.",
    "descriptor": "",
    "authors": [
      "Lihu Chen",
      "Ga\u00ebl Varoquaux",
      "Fabian M. Suchanek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07860"
  },
  {
    "id": "arXiv:2203.07861",
    "title": "Don't Get Me Wrong: How to apply Deep Visual Interpretations to Time  Series",
    "abstract": "The correct interpretation and understanding of deep learning models is\nessential in many applications. Explanatory visual interpretation approaches\nfor image and natural language processing allow domain experts to validate and\nunderstand almost any deep learning model. However, they fall short when\ngeneralizing to arbitrary time series data that is less intuitive and more\ndiverse. Whether a visualization explains the true reasoning or captures the\nreal features is difficult to judge. Hence, instead of blind trust we need an\nobjective evaluation to obtain reliable quality metrics. We propose a framework\nof six orthogonal metrics for gradient- or perturbation-based post-hoc visual\ninterpretation methods designed for time series classification and segmentation\ntasks. An experimental study includes popular neural network architectures for\ntime series and nine visual interpretation methods. We evaluate the visual\ninterpretation methods with diverse datasets from the UCR repository and a\ncomplex real-world dataset, and study the influence of common regularization\ntechniques during training. We show that none of the methods consistently\noutperforms any of the others on all metrics while some are ahead at times. Our\ninsights and recommendations allow experts to make informed choices of suitable\nvisualization techniques for the model and task at hand.",
    "descriptor": "\nComments: 32 pages, 13 figues\n",
    "authors": [
      "Christoffer Loeffler",
      "Wei-Cheng Lai",
      "Bjoern Eskofier",
      "Dario Zanca",
      "Lukas Schmidt",
      "Christopher Mutschler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07861"
  },
  {
    "id": "arXiv:2203.07875",
    "title": "Regret Bounds for Expected Improvement Algorithms in Gaussian Process  Bandit Optimization",
    "abstract": "The expected improvement (EI) algorithm is one of the most popular strategies\nfor optimization under uncertainty due to its simplicity and efficiency.\nDespite its popularity, the theoretical aspects of this algorithm have not been\nproperly analyzed. In particular, whether in the noisy setting, the EI strategy\nwith a standard incumbent converges is still an open question of the Gaussian\nprocess bandit optimization problem. We aim to answer this question by\nproposing a variant of EI with a standard incumbent defined via the GP\npredictive mean. We prove that our algorithm converges, and achieves a\ncumulative regret bound of $\\mathcal O(\\gamma_T\\sqrt{T})$, where $\\gamma_T$ is\nthe maximum information gain between $T$ observations and the Gaussian process\nmodel. Based on this variant of EI, we further propose an algorithm called\nImproved GP-EI that converges faster than previous counterparts. In particular,\nour proposed variants of EI do not require the knowledge of the RKHS norm and\nthe noise's sub-Gaussianity parameter as in previous works. Empirical\nvalidation in our paper demonstrates the effectiveness of our algorithms\ncompared to several baselines.",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Hung Tran-The",
      "Sunil Gupta",
      "Santu Rana",
      "Svetha Venkatesh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.07875"
  },
  {
    "id": "arXiv:2203.07881",
    "title": "LiP-Flow: Learning Inference-time Priors for Codec Avatars via  Normalizing Flows in Latent Space",
    "abstract": "Neural face avatars that are trained from multi-view data captured in camera\ndomes can produce photo-realistic 3D reconstructions. However, at inference\ntime, they must be driven by limited inputs such as partial views recorded by\nheadset-mounted cameras or a front-facing camera, and sparse facial landmarks.\nTo mitigate this asymmetry, we introduce a prior model that is conditioned on\nthe runtime inputs and tie this prior space to the 3D face model via a\nnormalizing flow in the latent space. Our proposed model, LiP-Flow, consists of\ntwo encoders that learn representations from the rich training-time and\nimpoverished inference-time observations. A normalizing flow bridges the two\nrepresentation spaces and transforms latent samples from one domain to another,\nallowing us to define a latent likelihood objective. We trained our model\nend-to-end to maximize the similarity of both representation spaces and the\nreconstruction quality, making the 3D face model aware of the limited driving\nsignals. We conduct extensive evaluations where the latent codes are optimized\nto reconstruct 3D avatars from partial or sparse observations. We show that our\napproach leads to an expressive and effective prior, capturing facial dynamics\nand subtle expressions better.",
    "descriptor": "",
    "authors": [
      "Emre Aksan",
      "Shugao Ma",
      "Akin Caliskan",
      "Stanislav Pidhorskyi",
      "Alexander Richard",
      "Shih-En Wei",
      "Jason Saragih",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07881"
  },
  {
    "id": "arXiv:2203.07890",
    "title": "K-VQG: Knowledge-aware Visual Question Generation for Common-sense  Acquisition",
    "abstract": "Visual Question Generation (VQG) is a task to generate questions from images.\nWhen humans ask questions about an image, their goal is often to acquire some\nnew knowledge. However, existing studies on VQG have mainly addressed question\ngeneration from answers or question categories, overlooking the objectives of\nknowledge acquisition. To introduce a knowledge acquisition perspective into\nVQG, we constructed a novel knowledge-aware VQG dataset called K-VQG. This is\nthe first large, humanly annotated dataset in which questions regarding images\nare tied to structured knowledge. We also developed a new VQG model that can\nencode and use knowledge as the target for a question. The experiment results\nshow that our model outperforms existing models on the K-VQG dataset.",
    "descriptor": "",
    "authors": [
      "Kohei Uehara",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07890"
  },
  {
    "id": "arXiv:2203.07893",
    "title": "Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear  Guarded Attribute Information",
    "abstract": "We describe a simple and effective method (Spectral Attribute removaL; SAL)\nto remove guarded information from neural representations. Our method uses\nsingular value decomposition and eigenvalue decomposition to project the input\nrepresentations into directions with reduced covariance with the guarded\ninformation rather than maximal covariance as normally these factorization\nmethods are used. We begin with linear information removal and proceed to\ngeneralize our algorithm to the case of nonlinear information removal through\nthe use of kernels. Our experiments demonstrate that our algorithm retains\nbetter main task performance after removing the guarded information compared to\nprevious methods. In addition, our experiments demonstrate that we need a\nrelatively small amount of guarded attribute data to remove information about\nthese attributes, which lowers the exposure to such possibly sensitive data and\nfits better low-resource scenarios.",
    "descriptor": "",
    "authors": [
      "Shun Shao",
      "Yftah Ziser",
      "Shay B. Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07893"
  },
  {
    "id": "arXiv:2203.07895",
    "title": "Simulating Liquids with Graph Networks",
    "abstract": "Simulating complex dynamics like fluids with traditional simulators is\ncomputationally challenging. Deep learning models have been proposed as an\nefficient alternative, extending or replacing parts of traditional simulators.\nWe investigate graph neural networks (GNNs) for learning fluid dynamics and\nfind that their generalization capability is more limited than previous works\nwould suggest. We also challenge the current practice of adding random noise to\nthe network inputs in order to improve its generalization capability and\nsimulation stability. We find that inserting the real data distribution, e.g.\nby unrolling multiple simulation steps, improves accuracy and that hiding all\ndomain-specific features from the learning model improves generalization. Our\nresults indicate that learning models, such as GNNs, fail to learn the exact\nunderlying dynamics unless the training set is devoid of any other\nproblem-specific correlations that could be used as shortcuts.",
    "descriptor": "\nComments: This work will not be published. 11 pages, 9 figures, 2 tables\n",
    "authors": [
      "Jonathan Klimesch",
      "Philipp Holl",
      "Nils Thuerey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2203.07895"
  },
  {
    "id": "arXiv:2203.07897",
    "title": "Magnetic Field Prediction Using Generative Adversarial Networks",
    "abstract": "Plenty of scientific and real-world applications are built on magnetic fields\nand their characteristics. To retrieve the valuable magnetic field information\nin high resolution, extensive field measurements are required, which are either\ntime-consuming to conduct or even not feasible due to physical constraints. To\nalleviate this problem, we predict magnetic field values at a random point in\nspace from a few point measurements by using a generative adversarial network\n(GAN) structure. The deep learning (DL) architecture consists of two neural\nnetworks: a generator, which predicts missing field values of a given magnetic\nfield, and a critic, which is trained to calculate the statistical distance\nbetween real and generated magnetic field distributions. By minimizing this\nstatistical distance, a reconstruction loss as well as physical losses, our\ntrained generator has learned to predict the missing field values with a median\nreconstruction test error of 5.14%, when a single coherent region of field\npoints is missing, and 5.86%, when only a few point measurements in space are\navailable and the field measurements around are predicted. We verify the\nresults on an experimentally validated field.",
    "descriptor": "\nComments: 10 pages, 12 figures\n",
    "authors": [
      "Stefan Pollok",
      "Nataniel Olden-J\u00f8rgensen",
      "Peter Stanley J\u00f8rgensen",
      "Rasmus Bj\u00f8rk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.07897"
  },
  {
    "id": "arXiv:2203.07898",
    "title": "Dynamic Time Warping Under Translation: Approximation Guided by  Space-Filling Curves",
    "abstract": "The Dynamic Time Warping (DTW) distance is a popular measure of similarity\nfor a variety of sequence data. For comparing polygonal curves $\\pi, \\sigma$ in\n$\\mathbb{R}^d$, it provides a robust, outlier-insensitive alternative to the\nFr\\'echet distance. However, like the Fr\\'echet distance, the DTW distance is\nnot invariant under translations. Can we efficiently optimize the DTW distance\nof $\\pi$ and $\\sigma$ under arbitrary translations, to compare the curves'\nshape irrespective of their absolute location?\nThere are surprisingly few works in this direction, which may be due to its\ncomputational intricacy: For the Euclidean norm, this problem contains as a\nspecial case the geometric median problem, which is known not to have an exact\nalgebraic algorithm (that is, an algorithm using only addition, multiplication,\nand $k$-th roots). We thus investigate exact algorithms for non-Euclidean norms\nas well as approximation algorithms for the Euclidean norm:\n- For the $L_1$ norm in $\\mathbb{R}^d$, we provide an $O(n^{2(d+1)})$-time\nalgorithm, i.e., an exact polynomial-time algorithm for constant $d$. Here and\nbelow, $n$ bounds the curves' complexities.\n- For the Euclidean norm in $\\mathbb{R}^2$, we show that a simple\nproblem-specific insight leads to a $(1+\\epsilon)$-approximation in time\n$O(n^3/\\epsilon^2)$. We then show how to obtain a subcubic $\\tilde\nO(n^{8/3}/\\epsilon^2)$ time algorithm with significant new ideas; this time\ncomes close to the well-known quadratic time barrier for computing DTW for\nfixed translations. Technically, the algorithm is obtained by speeding up\nrepeated DTW distance estimations using a dynamic data structure for\nmaintaining shortest paths in weighted planar digraphs. Crucially, we show how\nto traverse a candidate set of translations using space-filling curves in a way\nthat incurs only few updates to the data structure.",
    "descriptor": "\nComments: Full version of SoCG '22 paper\n",
    "authors": [
      "Karl Bringmann",
      "S\u00e1ndor Kisfaludi-Bak",
      "Marvin K\u00fcnnemann",
      "D\u00e1niel Marx",
      "Andr\u00e9 Nusser"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.07898"
  },
  {
    "id": "arXiv:2203.07902",
    "title": "Generalized Rectifier Wavelet Covariance Models For Texture Synthesis",
    "abstract": "State-of-the-art maximum entropy models for texture synthesis are built from\nstatistics relying on image representations defined by convolutional neural\nnetworks (CNN). Such representations capture rich structures in texture images,\noutperforming wavelet-based representations in this regard. However, conversely\nto neural networks, wavelets offer meaningful representations, as they are\nknown to detect structures at multiple scales (e.g. edges) in images. In this\nwork, we propose a family of statistics built upon non-linear wavelet based\nrepresentations, that can be viewed as a particular instance of a one-layer\nCNN, using a generalized rectifier non-linearity. These statistics\nsignificantly improve the visual quality of previous classical wavelet-based\nmodels, and allow one to produce syntheses of similar quality to\nstate-of-the-art models, on both gray-scale and color textures.",
    "descriptor": "\nComments: To be published as a conference paper at the International Conference on Learning Representations (ICLR) 2022\n",
    "authors": [
      "Antoine Brochard",
      "Sixin Zhang",
      "St\u00e9phane Mallat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.07902"
  },
  {
    "id": "arXiv:2203.07904",
    "title": "Unsupervised Learning Based Focal Stack Camera Depth Estimation",
    "abstract": "We propose an unsupervised deep learning based method to estimate depth from\nfocal stack camera images. On the NYU-v2 dataset, our method achieves much\nbetter depth estimation accuracy compared to single-image based methods.",
    "descriptor": "",
    "authors": [
      "Zhengyu Huang",
      "Weizhi Du",
      "Theodore B. Norris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07904"
  },
  {
    "id": "arXiv:2203.07908",
    "title": "Panoptic SwiftNet: Pyramidal Fusion for Real-time Panoptic Segmentation",
    "abstract": "Dense panoptic prediction is a key ingredient in many existing applications\nsuch as autonomous driving, automated warehouses or agri-robotics. However,\nmost of these applications leverage the recovered dense semantics as an input\nto visual closed-loop control. Hence, practical deployments require real-time\ninference over large input resolutions on embedded hardware. These requirements\ncall for computationally efficient approaches which deliver high accuracy with\nlimited computational resources. We propose to achieve this goal by trading-off\nbackbone capacity for multi-scale feature extraction. In comparison with\ncontemporaneous approaches to panoptic segmentation, the main novelties of our\nmethod are scale-equivariant feature extraction and cross-scale upsampling\nthrough pyramidal fusion. Our best model achieves 55.9% PQ on Cityscapes val at\n60 FPS on full resolution 2MPx images and RTX3090 with FP16 Tensor RT\noptimization.",
    "descriptor": "\nComments: Submitted to Pattern Recognition Letters. Code available at: this https URL\n",
    "authors": [
      "Josip \u0160ari\u0107",
      "Marin Or\u0161i\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07908"
  },
  {
    "id": "arXiv:2203.07910",
    "title": "Deep Transfer Learning with Graph Neural Network for Sensor-Based Human  Activity Recognition",
    "abstract": "The sensor-based human activity recognition (HAR) in mobile application\nscenarios is often confronted with sensor modalities variation and annotated\ndata deficiency. Given this observation, we devised a graph-inspired deep\nlearning approach toward the sensor-based HAR tasks, which was further used to\nbuild a deep transfer learning model toward giving a tentative solution for\nthese two challenging problems. Specifically, we present a multi-layer residual\nstructure involved graph convolutional neural network (ResGCNN) toward the\nsensor-based HAR tasks, namely the HAR-ResGCNN approach. Experimental results\non the PAMAP2 and mHealth data sets demonstrate that our ResGCNN is effective\nat capturing the characteristics of actions with comparable results compared to\nother sensor-based HAR models (with an average accuracy of 98.18% and 99.07%,\nrespectively). More importantly, the deep transfer learning experiments using\nthe ResGCNN model show excellent transferability and few-shot learning\nperformance. The graph-based framework shows good meta-learning ability and is\nsupposed to be a promising solution in sensor-based HAR tasks.",
    "descriptor": "",
    "authors": [
      "Yan Yan",
      "Tianzheng Liao",
      "Jinjin Zhao",
      "Jiahong Wang",
      "Liang Ma",
      "Wei Lv",
      "Jing Xiong",
      "Lei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07910"
  },
  {
    "id": "arXiv:2203.07911",
    "title": "Signal in Noise: Exploring Meaning Encoded in Random Character Sequences  with Character-Aware Language Models",
    "abstract": "Natural language processing models learn word representations based on the\ndistributional hypothesis, which asserts that word context (e.g.,\nco-occurrence) correlates with meaning. We propose that $n$-grams composed of\nrandom character sequences, or $garble$, provide a novel context for studying\nword meaning both within and beyond extant language. In particular, randomly\ngenerated character $n$-grams lack meaning but contain primitive information\nbased on the distribution of characters they contain. By studying the\nembeddings of a large corpus of garble, extant language, and pseudowords using\nCharacterBERT, we identify an axis in the model's high-dimensional embedding\nspace that separates these classes of $n$-grams. Furthermore, we show that this\naxis relates to structure within extant language, including word\npart-of-speech, morphology, and concept concreteness. Thus, in contrast to\nstudies that are mainly limited to extant language, our work reveals that\nmeaning and primitive information are intrinsically linked.",
    "descriptor": "",
    "authors": [
      "Mark Chu",
      "Bhargav Srinivasa Desikan",
      "Ethan O. Nadler",
      "Ruggerio L. Sardo",
      "Elise Darragh-Ford",
      "Douglas Guilbeault"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07911"
  },
  {
    "id": "arXiv:2203.07915",
    "title": "On the Application of Total Traction Equilibrium in Topology  Optimization of Fluid-Structure Interactions",
    "abstract": "This work investigates the different techniques of enforcing traction\nequilibrium in topology optimization of fluid-structure interaction problems.\nIn literature, force coupling between the solid and the fluid domains is\nusually achieved using internal volume integrals of hydrostatic stresses. In\nthis work, we extend the traction equilibrium condition to include the viscous\nstress components as well as the hydrostatic components in what is termed the\ntotal stress formulation. We also investigate the different force calculation\ntechniques, and how the mixed finite element formulation results in two\nconflicting approaches; external surface vs. internal volume integrals. Lastly,\na numerical experiment reveals the effects of the different force coupling\ntechniques on the optimized designs with commentary on complexity of\nimplementation and convergence behaviour.",
    "descriptor": "",
    "authors": [
      "Mohamed Abdelhamid",
      "Aleksander Czekanski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2203.07915"
  },
  {
    "id": "arXiv:2203.07918",
    "title": "GPV-Pose: Category-level Object Pose Estimation via Geometry-guided  Point-wise Voting",
    "abstract": "While 6D object pose estimation has recently made a huge leap forward, most\nmethods can still only handle a single or a handful of different objects, which\nlimits their applications. To circumvent this problem, category-level object\npose estimation has recently been revamped, which aims at predicting the 6D\npose as well as the 3D metric size for previously unseen instances from a given\nset of object classes. This is, however, a much more challenging task due to\nsevere intra-class shape variations. To address this issue, we propose\nGPV-Pose, a novel framework for robust category-level pose estimation,\nharnessing geometric insights to enhance the learning of category-level\npose-sensitive features. First, we introduce a decoupled confidence-driven\nrotation representation, which allows geometry-aware recovery of the associated\nrotation matrix. Second, we propose a novel geometry-guided point-wise voting\nparadigm for robust retrieval of the 3D object bounding box. Finally,\nleveraging these different output streams, we can enforce several geometric\nconsistency terms, further increasing performance, especially for non-symmetric\ncategories. GPV-Pose produces superior results to state-of-the-art competitors\non common public benchmarks, whilst almost achieving real-time inference speed\nat 20 FPS.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Yan Di",
      "Ruida Zhang",
      "Zhiqiang Lou",
      "Fabian Manhardt",
      "Xiangyang Ji",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07918"
  },
  {
    "id": "arXiv:2203.07920",
    "title": "Cost-effective BlackWater Raft on Highly Unreliable Nodes at Scale Out",
    "abstract": "The Raft algorithm maintains strong consistency across data replicas in\nCloud. This algorithm divides nodes into leaders and followers, to satisfy\nread/write requests spanning geo-diverse sites. With the increase of workload,\nRaft shall provide scale-out performance in proportion. However, traditional\nscale-out techniques encounter bottlenecks in Raft, and when the provisioned\nsites exhaust local resources, the performance loss will grow exponentially. To\nprovide scalability in Raft, this paper proposes a cost-effective mechanism for\nelastic auto-scaling in Raft, called BlackWater-Raft or BW-Raft. BW-Raft\nextends the original Raft with the following abstractions: (1) secretary nodes\nthat take over expensive log synchronization operations from the leader,\nrelaxing the performance constraints on locks. (2) massive low cost observer\nnodes that handle reads only, improving throughput for typical data intensive\nservices. These abstractions are stateless, allowing elastic scale-out on\nunreliable yet cheap spot instances. In theory, we demonstrate that BW-Raft can\nmaintain Raft's strong consistency guarantees when scaling out, processing a\n50X increase in the number of nodes compared to the original Raft. We have\nprototyped the BW-Raft on key-value services and evaluated it with many\nstate-of-the-arts on Amazon EC2 and Alibaba Cloud. Our results show that within\nthe same budget, BW-Raft's resource footprint increments are 5-7X smaller than\nMulti-Raft, and 2X better than original Raft. Using spot instances, BW-Raft can\nreduces costs by 84.5\\% compared to Multi-Raft. In the real world experiments,\nBW-Raft improves goodput of the 95th-percentile SLO by 9.4X, thus serving as an\nalternative for services scaling out with strong consistency.",
    "descriptor": "\nComments: 18 pages, 26 figures, We are already revising the Camera Ready version of IEEE Transaction on Cloud Computing\n",
    "authors": [
      "Zichen Xu",
      "Yunxiao Du",
      "Kanqi Zhang",
      "Jiacheng Huang",
      "Jie Liu",
      "Jingxiong Gao",
      "Christopher Stewart"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.07920"
  },
  {
    "id": "arXiv:2203.07921",
    "title": "Unsupervised Extractive Opinion Summarization Using Sparse Coding",
    "abstract": "Opinion summarization is the task of automatically generating summaries that\nencapsulate information from multiple user reviews. We present Semantic\nAutoencoder (SemAE) to perform extractive opinion summarization in an\nunsupervised manner. SemAE uses dictionary learning to implicitly capture\nsemantic information from the review and learns a latent representation of each\nsentence over semantic units. A semantic unit is supposed to capture an\nabstract semantic concept. Our extractive summarization algorithm leverages the\nrepresentations to identify representative opinions among hundreds of reviews.\nSemAE is also able to perform controllable summarization to generate\naspect-specific summaries. We report strong performance on SPACE and AMAZON\ndatasets, and perform experiments to investigate the functioning of our model.\nOur code is publicly available at https://github.com/brcsomnath/SemAE.",
    "descriptor": "\nComments: Accepted at ACL 2022\n",
    "authors": [
      "Somnath Basu Roy Chowdhury",
      "Chao Zhao",
      "Snigdha Chaturvedi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07921"
  },
  {
    "id": "arXiv:2203.07922",
    "title": "How informative is the Order Book Beyond the Best Levels? Machine  Learning Perspective",
    "abstract": "Research on limit order book markets has been rapidly growing and nowadays\nhigh-frequency full order book data is widely available for researchers and\npractitioners. However, it is common that research papers use the best level\ndata only, which motivates us to ask whether the exclusion of the quotes deeper\nin the book over multiple price levels causes performance degradation. In this\npaper, we address this question by using modern Machine Learning (ML)\ntechniques to predict mid-price movements without assuming that limit order\nbook markets represent a linear system. We provide a number of results that are\nrobust across ML prediction models, feature selection algorithms, data sets,\nand prediction horizons. We find that the best bid and ask levels are\nsystematically identified not only as the most informative levels in the order\nbooks, but also to carry most of the information needed for good prediction\nperformance. On the other hand, even if the top-of-the-book levels contain most\nof the relevant information, to maximize models' performance one should use all\ndata across all the levels. Additionally, the informativeness of the order book\nlevels clearly decreases from the first to the fourth level while the rest of\nthe levels are approximately equally important.",
    "descriptor": "\nComments: NeurIPS 2021 Workshop on Machine Learning meets Econometrics (MLECON2021)\n",
    "authors": [
      "Dat Thanh Tran",
      "Juho Kanniainen",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.07922"
  },
  {
    "id": "arXiv:2203.07929",
    "title": "Dynamical Modeling and Control of Soft Robots with Non-constant  Curvature Deformation",
    "abstract": "The Piecewise Constant Curvature (PCC) model is the most widely used soft\nrobotic modeling and control. However, the PCC fails to accurately describe the\ndeformation of the soft robots when executing dynamic tasks or interacting with\nthe environment. This paper presents a simple threedimensional (3D) modeling\nmethod for a multi-segment soft robotic manipulator with non-constant curvature\ndeformation. We devise kinematic and dynamical models for soft manipulators by\nmodeling each segment of the manipulator as two stretchable links connected by\na universal joint. Based on that, we present two controllers for dynamic\ntrajectory tracking in confguration space and pose control in task space,\nrespectively. Model accuracy is demonstrated with simulations and experimental\ndata. The controllers are implemented on a four-segment soft robotic\nmanipulator and validated in dynamic motions and pose control with unknown\nloads. The experimental results show that the dynamic controller enables a\nstable reference trajectory tracking at speeds up to 7m/s.",
    "descriptor": "\nComments: 16 pages, 16 figures\n",
    "authors": [
      "Zhanchi Wang",
      "Gaotian Wang",
      "Xiaoping Chen",
      "Nikolaos M. Freris"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07929"
  },
  {
    "id": "arXiv:2203.07930",
    "title": "Relative Pose from SIFT Features",
    "abstract": "This paper proposes the geometric relationship of epipolar geometry and\norientation- and scale-covariant, e.g., SIFT, features. We derive a new linear\nconstraint relating the unknown elements of the fundamental matrix and the\norientation and scale. This equation can be used together with the well-known\nepipolar constraint to, e.g., estimate the fundamental matrix from four SIFT\ncorrespondences, essential matrix from three, and to solve the semi-calibrated\ncase from three correspondences. Requiring fewer correspondences than the\nwell-known point-based approaches (e.g., 5PT, 6PT and 7PT solvers) for epipolar\ngeometry estimation makes RANSAC-like randomized robust estimation\nsignificantly faster. The proposed constraint is tested on a number of problems\nin a synthetic environment and on publicly available real-world datasets on\nmore than 80000 image pairs. It is superior to the state-of-the-art in terms of\nprocessing time while often leading to more accurate results.",
    "descriptor": "",
    "authors": [
      "Daniel Barath",
      "Zuzana Kukelova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07930"
  },
  {
    "id": "arXiv:2203.07931",
    "title": "DialogueNeRF: Towards Realistic Avatar Face-to-face Conversation Video  Generation",
    "abstract": "Conversation is an essential component of virtual avatar activities in the\nmetaverse. With the development of natural language processing, textual and\nvocal conversation generation has achieved a significant breakthrough.\nFace-to-face conversations account for the vast majority of daily\nconversations. However, this task has not acquired enough attention. In this\npaper, we propose a novel task that aims to generate a realistic human avatar\nface-to-face conversation process and present a new dataset to explore this\ntarget. To tackle this novel task, we propose a new framework that utilizes a\nseries of conversation signals, e.g. audio, head pose, and expression, to\nsynthesize face-to-face conversation videos between human avatars, with all the\ninterlocutors modeled within the same network. Our method is evaluated by\nquantitative and qualitative experiments in different aspects, e.g. image\nquality, pose sequence trend, and naturalness of the rendering videos. All the\ncode, data, and models will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Zanwei Zhou",
      "Zi Wang",
      "Shunyu Yao",
      "Yichao Yan",
      "Chen Yang",
      "Guangtao Zhai",
      "Junchi Yan",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07931"
  },
  {
    "id": "arXiv:2203.07932",
    "title": "Style Transformer for Image Inversion and Editing",
    "abstract": "Existing GAN inversion methods fail to provide latent codes for reliable\nreconstruction and flexible editing simultaneously. This paper presents a\ntransformer-based image inversion and editing model for pretrained StyleGAN\nwhich is not only with less distortions, but also of high quality and\nflexibility for editing. The proposed model employs a CNN encoder to provide\nmulti-scale image features as keys and values. Meanwhile it regards the style\ncode to be determined for different layers of the generator as queries. It\nfirst initializes query tokens as learnable parameters and maps them into W+\nspace. Then the multi-stage alternate self- and cross-attention are utilized,\nupdating queries with the purpose of inverting the input by the generator.\nMoreover, based on the inverted code, we investigate the reference- and\nlabel-based attribute editing through a pretrained latent classifier, and\nachieve flexible image-to-image translation with high quality results.\nExtensive experiments are carried out, showing better performances on both\ninversion and editing tasks within StyleGAN.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Xueqi Hu",
      "Qiusheng Huang",
      "Zhengyi Shi",
      "Siyuan Li",
      "Changxin Gao",
      "Li Sun",
      "Qingli Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07932"
  },
  {
    "id": "arXiv:2203.07933",
    "title": "Threat Detection for General Social Engineering Attack Using Machine  Learning Techniques",
    "abstract": "This paper explores the threat detection for general social engineering (SE)\nattack using machine learning (ML) techniques, rather than focusing on or\nlimited to a specific SE attack type, e.g. email phishing. Firstly, this paper\nprocesses and obtains more SE threat data from the previous knowledge graph,\nand then extracts different threat features and generates new datasets\ncorresponding with three different feature combinations. Finally, 9 types of ML\nmodels are created and trained using the three datasets, respectively, and\ntheir performance are compared and analyzed with 27 threat\ndetectors/classifiers and 270 experiments. The experimental results and\nanalysis show that: 1) the ML techniques is feasible in detecting general SE\nattack threat and some ML models are quite effective; ML-based SE threat\ndetection is complementary with knowledge graph-based approaches; 2) the\ngenerated datasets are usable; the SE domain ontology proposed in previous work\ncan dissect SE attacks and deliver the SE threat features, allowing it to be\nused as a data model for future research. Besides, many conclusions and\nanalyses about the characteristics of different ML models and the datasets are\ndiscussed.",
    "descriptor": "",
    "authors": [
      "Zuoguang Wang",
      "Yimo Ren",
      "Hongsong Zhu",
      "Limin Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07933"
  },
  {
    "id": "arXiv:2203.07934",
    "title": "Towards Distributed Coordination for Fog Platforms",
    "abstract": "Distributed fog and edge applications communicate over unreliable networks\nand are subject to high communication delays. This makes using existing\ndistributed coordination technologies from cloud applications infeasible, as\nthey are built on the assumption of a highly reliable, low-latency datacenter\nnetwork to achieve strict consistency with low overheads. To help implement\nconfiguration and state management for fog platforms and applications, we\npropose a novel decentralized approach that lets systems specify coordination\nstrategies and membership for different sets of coordination data.",
    "descriptor": "\nComments: Accepted for publication at the 22nd IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGrid 2022) Poster Track\n",
    "authors": [
      "Tobias Pfandzelter",
      "Trever Schirmer",
      "David Bermbach"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.07934"
  },
  {
    "id": "arXiv:2203.07937",
    "title": "Edge-based Local Push for Personalized PageRank",
    "abstract": "Personalized PageRank (PPR) is a popular node proximity metric in graph\nmining and network research. Given a graph G=(V,E) and a source node $s \\in V$,\na single-source PPR (SSPPR) query asks for the PPR value $\\vpi(u)$ with respect\nto s, which represents the relative importance of node u in the context of the\nsource node s. Among existing algorithms for SSPPR queries, LocalPush is a\nfundamental method which serves as a cornerstone for subsequent algorithms. In\nLocalPush, a push operation is a crucial primitive operation, which distributes\nthe probability at a node u to ALL u's neighbors via the corresponding edges.\nAlthough this push operation works well on unweighted graphs, unfortunately, it\ncan be rather inefficient on weighted graphs. In particular, on unbalanced\nweighted graphs where only a few of these edges take the majority of the total\nweight among them, the push operation would have to distribute insignificant\nprobabilities along those edges which just take the minor weights, resulting in\nexpensive overhead.\nTo resolve this issue, we propose the EdgePush algorithm, a novel method for\ncomputing SSPPR queries on weighted graphs. EdgePush decomposes the\naforementioned push operations in edge-based push, allowing the algorithm to\noperate at the edge level granularity. Hence, it can flexibly distribute the\nprobabilities according to edge weights. Furthermore, our EdgePush allows a\nfine-grained termination threshold for each individual edge, leading to a\nsuperior complexity over LocalPush. Notably, we prove that EdgePush improves\nthe theoretical query cost of LocalPush by an order of up to O(n) when the\ngraph's weights are unbalanced, both in terms of $\\ell_1$-error and normalized\nadditive error. Our experimental results demonstrate that EdgePush\nsignificantly outperforms state-of-the-art baselines in terms of query\nefficiency on large motif-based and real-world weighted graphs.",
    "descriptor": "\nComments: VLDB 2022, volume 15, issue 7\n",
    "authors": [
      "Hanzhi Wang",
      "Zhewei Wei",
      "Junhao Gan",
      "Ye Yuan",
      "Xiaoyong Du",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.07937"
  },
  {
    "id": "arXiv:2203.07939",
    "title": "Strategic Thinking for Sustainable Practice-Centered Computing",
    "abstract": "This book was a trigger for me to reflect on all the projects we have\nconducted at the local, regional, national, and European levels around\nhealthcare, addressing the social isolation of elderlies, the social support\namong caregivers, and the coordination issues of professionals willing to take\ncare for patients at their home. Since Ina Wagner interviewed me in Paris, the\nsituation evolved in France as a new healthcare law was voted that emphasizes\nthe importance of cooperation among healthcare practitioners, the need for IT\nsupport, and the key role of local territories (which is not obvious in France,\nthat is a very centralized country). The reflection that started with this book\ndefinitely helped me to make decisions in this evolving context, and I am\ngrateful to Claudia M{\\\"u}ller who, through an interview, facilitated me to\nrealize what are, from my experience, the main issues that have to be dealt\nwith when aiming at ensuring a sustainable practice-based computing approach.\nIn this epilogue, I briefly list and illustrate these main issues, hoping they\ncould support other sustainable experiences.",
    "descriptor": "",
    "authors": [
      "Myriam Lewkowicz"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.07939"
  },
  {
    "id": "arXiv:2203.07941",
    "title": "Reachability In Simple Neural Networks",
    "abstract": "We investigate the complexity of the reachability problem for (deep) neural\nnetworks: does it compute valid output given some valid input? It was recently\nclaimed that the problem is NP-complete for general neural networks and\nspecifications over the input/output dimension given by conjunctions of linear\ninequalities. We recapitulate the proof and repair some flaws in the original\nupper and lower bound proofs. Motivated by the general result, we show that\nNP-hardness already holds for restricted classes of simple specifications and\nneural networks. Allowing for a single hidden layer and an output dimension of\none as well as neural networks with just one negative, zero and one positive\nweight or bias is sufficient to ensure NP-hardness. Additionally, we give a\nthorough discussion and outlook of possible extensions for this direction of\nresearch on neural network verification.",
    "descriptor": "",
    "authors": [
      "Marco S\u00e4lzer",
      "Martin Lange"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07941"
  },
  {
    "id": "arXiv:2203.07947",
    "title": "NINNs: Nudging Induced Neural Networks",
    "abstract": "New algorithms called nudging induced neural networks (NINNs), to control and\nimprove the accuracy of deep neural networks (DNNs), are introduced. The NINNs\nframework can be applied to almost all pre-existing DNNs, with forward\npropagation, with costs comparable to existing DNNs. NINNs work by adding a\nfeedback control term to the forward propagation of the network. The feedback\nterm nudges the neural network towards a desired quantity of interest. NINNs\noffer multiple advantages, for instance, they lead to higher accuracy when\ncompared with existing data assimilation algorithms such as nudging. Rigorous\nconvergence analysis is established for NINNs. The algorithmic and theoretical\nfindings are illustrated on examples from data assimilation and chemically\nreacting flows.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Harbir Antil",
      "Rainald L\u00f6hner",
      "Randy Price"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.07947"
  },
  {
    "id": "arXiv:2203.07948",
    "title": "An Ultra-Compact Single FeFET Binary and Multi-Bit Associative Search  Engine",
    "abstract": "Content addressable memory (CAM) is widely used in associative search tasks\nfor its highly parallel pattern matching capability. To accommodate the\nincreasingly complex and data-intensive pattern matching tasks, it is critical\nto keep improving the CAM density to enhance the performance and area\nefficiency. In this work, we demonstrate: i) a novel ultra-compact 1FeFET CAM\ndesign that enables parallel associative search and in-memory hamming distance\ncalculation; ii) a multi-bit CAM for exact search using the same CAM cell; iii)\ncompact device designs that integrate the series resistor current limiter into\nthe intrinsic FeFET structure to turn the 1FeFET1R into an effective 1FeFET\ncell; iv) a successful 2-step search operation and a sufficient sensing margin\nof the proposed binary and multi-bit 1FeFET1R CAM array with sizes of practical\ninterests in both experiments and simulations, given the existing unoptimized\nFeFET device variation; v) 89.9x speedup and 66.5x energy efficiency\nimprovement over the state-of-the art alignment tools on GPU in accelerating\ngenome pattern matching applications through the hyperdimensional computing\nparadigm.",
    "descriptor": "\nComments: 20 pages, 14 figures\n",
    "authors": [
      "Xunzhao Yin",
      "Franz M\u00fcller",
      "Qingrong Huang",
      "Chao Li",
      "Mohsen Imani",
      "Zeyu Yang",
      "Jiahao Cai",
      "Maximilian Lederer",
      "Ricardo Olivo",
      "Nellie Laleni",
      "Shan Deng",
      "Zijian Zhao",
      "Cheng Zhuo",
      "Thomas K\u00e4mpfe",
      "Kai Ni"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.07948"
  },
  {
    "id": "arXiv:2203.07949",
    "title": "Generating Privacy-Preserving Process Data with Deep Generative Models",
    "abstract": "Process data with confidential information cannot be shared directly in\npublic, which hinders the research in process data mining and analytics. Data\nencryption methods have been studied to protect the data, but they still may be\ndecrypted, which leads to individual identification. We experimented with\ndifferent models of representation learning and used the learned model to\ngenerate synthetic process data. We introduced an adversarial generative\nnetwork for process data generation (ProcessGAN) with two Transformer networks\nfor the generator and the discriminator. We evaluated ProcessGAN and\ntraditional models on six real-world datasets, of which two are public and four\nare collected in medical domains. We used statistical metrics and supervised\nlearning scores to evaluate the synthetic data. We also used process mining to\ndiscover workflows for the authentic and synthetic datasets and had medical\nexperts evaluate the clinical applicability of the synthetic workflows. We\nfound that ProcessGAN outperformed traditional sequential models when trained\non small authentic datasets of complex processes. ProcessGAN better represented\nthe long-range dependencies between the activities, which is important for\ncomplicated processes such as the medical processes. Traditional sequential\nmodels performed better when trained on large data of simple processes. We\nconclude that ProcessGAN can generate a large amount of sharable synthetic\nprocess data indistinguishable from authentic data.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Keyi Li",
      "Sen Yang",
      "Travis M. Sullivan",
      "Randall S. Burd",
      "Ivan Marsic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.07949"
  },
  {
    "id": "arXiv:2203.07953",
    "title": "Reproducibility and Performance: Why Choose?",
    "abstract": "Research processes often rely on high-performance computing (HPC), but HPC is\noften seen as antithetical to \"reproducibility\": one would have to choose\nbetween software that achieves high performance, and software that can be\ndeployed in a reproducible fashion. However, by giving up on reproducibility we\nwould give up on verifiability, a foundation of the scientific process. How can\nwe conciliate performance and reproducibility? This article looks at two\nperformance-critical aspects in HPC: message passing (MPI) and CPU\nmicro-architecture tuning. Engineering work that has gone into performance\nportability has already proved fruitful, but some areas remain unaddressed when\nit comes to CPU tuning. We propose package multi-versioning, a technique\ndeveloped for GNU Guix, a tool for reproducible software deployment, and show\nthat it allows us to implement CPU tuning without compromising on\nreproducibility and provenance tracking.",
    "descriptor": "",
    "authors": [
      "Ludovic Court\u00e8s"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.07953"
  },
  {
    "id": "arXiv:2203.07961",
    "title": "Amortised inference of fractional Brownian motion with linear  computational complexity",
    "abstract": "We introduce a simulation-based, amortised Bayesian inference scheme to infer\nthe parameters of random walks. Our approach learns the posterior distribution\nof the walks' parameters with a likelihood-free method. In the first step a\ngraph neural network is trained on simulated data to learn optimized\nlow-dimensional summary statistics of the random walk. In the second step an\ninvertible neural network generates the posterior distribution of the\nparameters from the learnt summary statistics using variational inference. We\napply our method to infer the parameters of the fractional Brownian motion\nmodel from single trajectories. The computational complexity of the amortized\ninference procedure scales linearly with trajectory length, and its precision\nscales similarly to the Cram{\\'e}r-Rao bound over a wide range of lengths. The\napproach is robust to positional noise, and generalizes well to trajectories\nlonger than those seen during training. Finally, we adapt this scheme to show\nthat a finite decorrelation time in the environment can furthermore be inferred\nfrom individual trajectories.",
    "descriptor": "",
    "authors": [
      "Fran\u00e7ois Laurent",
      "Christian Vestergaard",
      "Jean-Baptiste Masson",
      "Alhassan Cass\u00e9",
      "Hippolyte Verdier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2203.07961"
  },
  {
    "id": "arXiv:2203.07962",
    "title": "Automated Design Approximation to Overcome Circuit Aging",
    "abstract": "Transistor aging phenomena manifest themselves as degradations in the main\nelectrical characteristics of transistors. Over time, they result in a\nsignificant increase of cell propagation delay, leading to errors due to timing\nviolations, since the operating frequency becomes unsustainable as the circuit\nages. Conventional techniques employ timing guardbands to mitigate\naging-induced delay increase, which leads to considerable performance losses\nfrom the beginning of the circuit's lifetime. Leveraging the inherent error\nresilience of a vast number of application domains, approximate computing was\nrecently introduced as an aging mitigation mechanism. In this work, we present\nthe first automated framework for generating aging-aware approximate circuits.\nOur framework, by applying directed gate-level netlist approximation, induces a\nsmall functional error and recovers the delay degradation due to aging. As a\nresult, our optimized circuits eliminate aging-induced timing errors.\nExperimental evaluation over a variety of arithmetic circuits and image\nprocessing benchmarks demonstrates that for an average error of merely\n$5\\times10^{-3}$, our framework completely eliminates aging-induced timing\nguardbands. Compared to the respective baseline circuits without timing\nguardbands (i.e., iso-performance evaluation), the error of the circuits\ngenerated by our framework is $1208$x smaller.",
    "descriptor": "",
    "authors": [
      "Konstantinos Balaskas",
      "Georgios Zervakis",
      "Hussam Amrouch",
      "Joerg Henkel",
      "Kostas Siozios"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.07962"
  },
  {
    "id": "arXiv:2203.07967",
    "title": "Intrinsic Neural Fields: Learning Functions on Manifolds",
    "abstract": "Neural fields have gained significant attention in the computer vision\ncommunity due to their excellent performance in novel view synthesis, geometry\nreconstruction, and generative modeling. Some of their advantages are a sound\ntheoretic foundation and an easy implementation in current deep learning\nframeworks. While neural fields have been applied to signals on manifolds,\ne.g., for texture reconstruction, their representation has been limited to\nextrinsically embedding the shape into Euclidean space. The extrinsic embedding\nignores known intrinsic manifold properties and is inflexible wrt. transfer of\nthe learned function. To overcome these limitations, this work introduces\nintrinsic neural fields, a novel and versatile representation for neural fields\non manifolds. Intrinsic neural fields combine the advantages of neural fields\nwith the spectral properties of the Laplace-Beltrami operator. We show\ntheoretically that intrinsic neural fields inherit many desirable properties of\nthe extrinsic neural field framework but exhibit additional intrinsic\nqualities, like isometry invariance. In experiments, we show intrinsic neural\nfields can reconstruct high-fidelity textures from images with state-of-the-art\nquality and are robust to the discretization of the underlying manifold. We\ndemonstrate the versatility of intrinsic neural fields by tackling various\napplications: texture transfer between deformed shapes & different shapes,\ntexture reconstruction from real-world images with view dependence, and\ndiscretization-agnostic learning on meshes and point clouds.",
    "descriptor": "",
    "authors": [
      "Lukas Koestler",
      "Daniel Grittner",
      "Michael Moeller",
      "Daniel Cremers",
      "Zorah L\u00e4hner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07967"
  },
  {
    "id": "arXiv:2203.07969",
    "title": "PDNS-Net: A Large Heterogeneous Graph Benchmark Dataset of Network  Resolutions for Graph Learning",
    "abstract": "In order to advance the state of the art in graph learning algorithms, it is\nnecessary to construct large real-world datasets. While there are many\nbenchmark datasets for homogeneous graphs, only a few of them are available for\nheterogeneous graphs. Furthermore, the latter graphs are small in size\nrendering them insufficient to understand how graph learning algorithms perform\nin terms of classification metrics and computational resource utilization. We\nintroduce, PDNS-Net, the largest public heterogeneous graph dataset containing\n447K nodes and 897K edges for the malicious domain classification task.\nCompared to the popular heterogeneous datasets IMDB and DBLP, PDNS-Net is 38\nand 17 times bigger respectively. We provide a detailed analysis of PDNS-Net\nincluding the data collection methodology, heterogeneous graph construction,\ndescriptive statistics and preliminary graph classification performance. The\ndataset is publicly available at https://github.com/qcri/PDNS-Net. Our\npreliminary evaluation of both popular homogeneous and heterogeneous graph\nneural networks on PDNS-Net reveals that further research is required to\nimprove the performance of these models on large heterogeneous graphs.",
    "descriptor": "\nComments: Workshop on Graph Learning Benchmark 2022\n",
    "authors": [
      "Udesh Kumarasinghe",
      "Fatih Deniz",
      "Mohamed Nabeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.07969"
  },
  {
    "id": "arXiv:2203.07973",
    "title": "MOBDrone: a Drone Video Dataset for Man OverBoard Rescue",
    "abstract": "Modern Unmanned Aerial Vehicles (UAV) equipped with cameras can play an\nessential role in speeding up the identification and rescue of people who have\nfallen overboard, i.e., man overboard (MOB). To this end, Artificial\nIntelligence techniques can be leveraged for the automatic understanding of\nvisual data acquired from drones. However, detecting people at sea in aerial\nimagery is challenging primarily due to the lack of specialized annotated\ndatasets for training and testing detectors for this task. To fill this gap, we\nintroduce and publicly release the MOBDrone benchmark, a collection of more\nthan 125K drone-view images in a marine environment under several conditions,\nsuch as different altitudes, camera shooting angles, and illumination. We\nmanually annotated more than 180K objects, of which about 113K man overboard,\nprecisely localizing them with bounding boxes. Moreover, we conduct a thorough\nperformance analysis of several state-of-the-art object detectors on the\nMOBDrone data, serving as baselines for further research.",
    "descriptor": "\nComments: Accepted at ICIAP 2021\n",
    "authors": [
      "Donato Cafarelli",
      "Luca Ciampi",
      "Lucia Vadicamo",
      "Claudio Gennaro",
      "Andrea Berton",
      "Marco Paterni",
      "Chiara Benvenuti",
      "Mirko Passera",
      "Fabrizio Falchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07973"
  },
  {
    "id": "arXiv:2203.07975",
    "title": "Categorical Representation Learning and RG flow operators for  algorithmic classifiers",
    "abstract": "Following the earlier formalism of the categorical representation learning\n(arXiv:2103.14770) by the first two authors, we discuss the construction of the\n\"RG-flow based categorifier\". Borrowing ideas from theory of renormalization\ngroup flows (RG) in quantum field theory, holographic duality, and hyperbolic\ngeometry, and mixing them with neural ODE's, we construct a new algorithmic\nnatural language processing (NLP) architecture, called the RG-flow categorifier\nor for short the RG categorifier, which is capable of data classification and\ngeneration in all layers. We apply our algorithmic platform to biomedical data\nsets and show its performance in the field of sequence-to-function mapping. In\nparticular we apply the RG categorifier to particular genomic sequences of flu\nviruses and show how our technology is capable of extracting the information\nfrom given genomic sequences, find their hidden symmetries and dominant\nfeatures, classify them and use the trained data to make stochastic prediction\nof new plausible generated sequences associated with new set of viruses which\ncould avoid the human immune system. The content of the current article is part\nof the recent US patent application submitted by first two authors (U.S. Patent\nApplication No.: 63/313.504).",
    "descriptor": "\nComments: 31 pages, comments are very welcome\n",
    "authors": [
      "Artan Sheshmani",
      "Yizhuang You",
      "Wenbo Fu",
      "Ahmadreza Azizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Algebraic Geometry (math.AG)",
      "Category Theory (math.CT)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2203.07975"
  },
  {
    "id": "arXiv:2203.07976",
    "title": "On the Pitfalls of Batch Normalization for End-to-End Video Learning: A  Study on Surgical Workflow Analysis",
    "abstract": "Batch Normalization's (BN) unique property of depending on other samples in a\nbatch is known to cause problems in several tasks, including sequential\nmodeling, and has led to the use of alternatives in these fields. In video\nlearning, however, these problems are less studied, despite the ubiquitous use\nof BN in CNNs for visual feature extraction. We argue that BN's properties\ncreate major obstacles for training CNNs and temporal models end to end in\nvideo tasks. Yet, end-to-end learning seems preferable in specialized domains\nsuch as surgical workflow analysis, which lack well-pretrained feature\nextractors. While previous work in surgical workflow analysis has avoided\nBN-related issues through complex, multi-stage learning procedures, we show\nthat even simple, end-to-end CNN-LSTMs can outperform the state of the art when\nCNNs without BN are used. Moreover, we analyze in detail when BN-related issues\noccur, including a \"cheating\" phenomenon in surgical anticipation tasks. We\nhope that a deeper understanding of BN's limitations and a reconsideration of\nend-to-end approaches can be beneficial for future research in surgical\nworkflow analysis and general video learning.",
    "descriptor": "",
    "authors": [
      "Dominik Rivoir",
      "Isabel Funke",
      "Stefanie Speidel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07976"
  },
  {
    "id": "arXiv:2203.07977",
    "title": "OcclusionFusion: Occlusion-aware Motion Estimation for Real-time Dynamic  3D Reconstruction",
    "abstract": "RGBD-based real-time dynamic 3D reconstruction suffers from inaccurate\ninter-frame motion estimation as errors may accumulate with online tracking.\nThis problem is even more severe for single-view-based systems due to strong\nocclusions. Based on these observations, we propose OcclusionFusion, a novel\nmethod to calculate occlusion-aware 3D motion to guide the reconstruction. In\nour technique, the motion of visible regions is first estimated and combined\nwith temporal information to infer the motion of the occluded regions through\nan LSTM-involved graph neural network. Furthermore, our method computes the\nconfidence of the estimated motion by modeling the network output with a\nprobabilistic model, which alleviates untrustworthy motions and enables robust\ntracking. Experimental results on public datasets and our own recorded data\nshow that our technique outperforms existing single-view-based real-time\nmethods by a large margin. With the reduction of the motion errors, the\nproposed technique can handle long and challenging motion sequences. Please\ncheck out the project page for sequence results:\nhttps://wenbin-lin.github.io/OcclusionFusion.",
    "descriptor": "\nComments: Accepted by CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Wenbin Lin",
      "Chengwei Zheng",
      "Jun-Hai Yong",
      "Feng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07977"
  },
  {
    "id": "arXiv:2203.07978",
    "title": "Control Barrier Functions for Systems with Multiple Control Inputs",
    "abstract": "Control Barrier Functions (CBFs) are becoming popular tools in guaranteeing\nsafety for nonlinear systems and constraints, and they can reduce a constrained\noptimal control problem into a sequence of Quadratic Programs (QPs) for affine\ncontrol systems. The recently proposed High Order Control Barrier Functions\n(HOCBFs) work for arbitrary relative degree constraints. One of the challenges\nin a HOCBF is to address the relative degree problem when a system has multiple\ncontrol inputs, i.e., the relative degree could be defined with respect to\ndifferent components of the control vector. This paper proposes two methods for\nHOCBFs to deal with systems with multiple control inputs: a general integral\ncontrol method and a method which is simpler but limited to specific classes of\nphysical systems. When control bounds are involved, the feasibility of the\nabove mentioned QPs can also be significantly improved with the proposed\nmethods. We illustrate our approaches on a unicyle model with two control\ninputs, and compare the two proposed methods to demonstrate their effectiveness\nand performance.",
    "descriptor": "\nComments: To appear in ACC2022\n",
    "authors": [
      "Wei Xiao",
      "Christos G. Cassandras",
      "Calin A. Belta",
      "Daniela Rus"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07978"
  },
  {
    "id": "arXiv:2203.07980",
    "title": "Object Detection as Probabilistic Set Prediction",
    "abstract": "Accurate uncertainty estimates are essential for deploying deep object\ndetectors in safety-critical systems. The development and evaluation of\nprobabilistic object detectors have been hindered by shortcomings in existing\nperformance measures, which tend to involve arbitrary thresholds or limit the\ndetector's choice of distributions. In this work, we propose to view object\ndetection as a set prediction task where detectors predict the distribution\nover the set of objects. Using the negative log-likelihood for random finite\nsets, we present a proper scoring rule for evaluating and training\nprobabilistic object detectors. The proposed method can be applied to existing\nprobabilistic detectors, is free from thresholds, and enables fair comparison\nbetween architectures. Three different types of detectors are evaluated on the\nCOCO dataset. Our results indicate that the training of existing detectors is\noptimized toward non-probabilistic metrics. We hope to encourage the\ndevelopment of new object detectors that can accurately estimate their own\nuncertainty. Code will be released.",
    "descriptor": "",
    "authors": [
      "Georg Hess",
      "Christoffer Petersson",
      "Lennart Svensson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07980"
  },
  {
    "id": "arXiv:2203.07982",
    "title": "Linear-Time Verification of Data-Aware Dynamic Systems with Arithmetic",
    "abstract": "Combined modeling and verification of dynamic systems and the data they\noperate on has gained momentum in AI and in several application domains. We\ninvestigate the expressive yet concise framework of data-aware dynamic systems\n(DDS), extending it with linear arithmetic, and provide the following\ncontributions. First, we introduce a new, semantic property of \"finite\nsummary\", which guarantees the existence of a faithful finite-state\nabstraction. We rely on this to show that checking whether a witness exists for\na linear-time, finite-trace property is decidable for DDSs with finite summary.\nSecond, we demonstrate that several decidability conditions studied in formal\nmethods and database theory can be seen as concrete, checkable instances of\nthis property. This also gives rise to new decidability results. Third, we show\nhow the abstract, uniform property of finite summary leads to modularity\nresults: a system enjoys finite summary if it can be partitioned appropriately\ninto smaller systems that possess the property. Our results allow us to analyze\nsystems that were out of reach in earlier approaches. Finally, we demonstrate\nthe feasibility of our approach in a prototype implementation.",
    "descriptor": "",
    "authors": [
      "Paolo Felli",
      "Marco Montali",
      "Sarah Winkler"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07982"
  },
  {
    "id": "arXiv:2203.07983",
    "title": "Adversarial Robustness of Neural-Statistical Features in Detection of  Generative Transformers",
    "abstract": "The detection of computer-generated text is an area of rapidly increasing\nsignificance as nascent generative models allow for efficient creation of\ncompelling human-like text, which may be abused for the purposes of spam,\ndisinformation, phishing, or online influence campaigns. Past work has studied\ndetection of current state-of-the-art models, but despite a developing threat\nlandscape, there has been minimal analysis of the robustness of detection\nmethods to adversarial attacks. To this end, we evaluate neural and non-neural\napproaches on their ability to detect computer-generated text, their robustness\nagainst text adversarial attacks, and the impact that successful adversarial\nattacks have on human judgement of text quality. We find that while statistical\nfeatures underperform neural features, statistical features provide additional\nadversarial robustness that can be leveraged in ensemble detection models. In\nthe process, we find that previously effective complex phrasal features for\ndetection of computer-generated text hold little predictive power against\ncontemporary generative models, and identify promising statistical features to\nuse instead. Finally, we pioneer the usage of $\\Delta$MAUVE as a proxy measure\nfor human judgement of adversarial text quality.",
    "descriptor": "",
    "authors": [
      "Evan Crothers",
      "Nathalie Japkowicz",
      "Herna Viktor",
      "Paula Branco"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07983"
  },
  {
    "id": "arXiv:2203.07986",
    "title": "Distributed Pinning Set Stabilization of Large-Scale Boolean Networks",
    "abstract": "In this article, we design the distributed pinning controllers to globally\nstabilize a Boolean network (BN), specially a sparsely connected large-scale\none, towards a preassigned subset of state space through the node-to-node\nmessage exchange. Given an appointed state set, system nodes are partitioned\ninto two disjoint parts, which respectively gather the nodes whose states are\nfixed or arbitrary with respect to the given state set. With such node\ndivision, three parts of pinned nodes are selected and the state feedback\ncontrollers are accordingly designed such that the resulting BN satisfies three\nconditions: the states of the other nodes cannot affect the nodal dynamics of\nfixed-state nodes, the subgraph of network structure induced by the fixed-state\nnodes is acyclic, and the steady state of the subnetwork induced by the\nfixed-state nodes lies in the state set given beforehand. If the BN after\ncontrol is acyclic, the stabilizing time is revealed to be no more than the\nlength of the longest path in the current network structure plus one. This\nenables us to further design the pinning controllers with the constraint of\nstabilizing time. Noting that the overall procedure runs in an exponentially\nincreasing time with respect to the largest number of functional variables in\nthe dynamics of pinned nodes, the sparsely-connected large-scale BNs can be\nwell addressed in a reasonable amount of time. Finally, we demonstrate the\napplications of our theoretical results in a T-LGL survival signal network with\n$29$ nodes and T-cell receptor signaling network with $90$ nodes.",
    "descriptor": "",
    "authors": [
      "Shiyong Zhu",
      "Jianquan Lu",
      "Liangjie Sun",
      "Jinde Cao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.07986"
  },
  {
    "id": "arXiv:2203.07988",
    "title": "Smoothing Matters: Momentum Transformer for Domain Adaptive Semantic  Segmentation",
    "abstract": "After the great success of Vision Transformer variants (ViTs) in computer\nvision, it has also demonstrated great potential in domain adaptive semantic\nsegmentation. Unfortunately, straightforwardly applying local ViTs in domain\nadaptive semantic segmentation does not bring in expected improvement. We find\nthat the pitfall of local ViTs is due to the severe high-frequency components\ngenerated during both the pseudo-label construction and features alignment for\ntarget domains. These high-frequency components make the training of local ViTs\nvery unsmooth and hurt their transferability. In this paper, we introduce a\nlow-pass filtering mechanism, momentum network, to smooth the learning dynamics\nof target domain features and pseudo labels. Furthermore, we propose a dynamic\nof discrepancy measurement to align the distributions in the source and target\ndomains via dynamic weights to evaluate the importance of the samples. After\ntackling the above issues, extensive experiments on sim2real benchmarks show\nthat the proposed method outperforms the state-of-the-art methods. Our codes\nare available at https://github.com/alpc91/TransDA",
    "descriptor": "",
    "authors": [
      "Runfa Chen",
      "Yu Rong",
      "Shangmin Guo",
      "Jiaqi Han",
      "Fuchun Sun",
      "Tingyang Xu",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07988"
  },
  {
    "id": "arXiv:2203.07989",
    "title": "Approximability and Generalisation",
    "abstract": "Approximate learning machines have become popular in the era of small\ndevices, including quantised, factorised, hashed, or otherwise compressed\npredictors, and the quest to explain and guarantee good generalisation\nabilities for such methods has just begun. In this paper we study the role of\napproximability in learning, both in the full precision and the approximated\nsettings of the predictor that is learned from the data, through a notion of\nsensitivity of predictors to the action of the approximation operator at hand.\nWe prove upper bounds on the generalisation of such predictors, yielding the\nfollowing main findings, for any PAC-learnable class and any given\napproximation operator. 1) We show that under mild conditions, approximable\ntarget concepts are learnable from a smaller labelled sample, provided\nsufficient unlabelled data. 2) We give algorithms that guarantee a good\npredictor whose approximation also enjoys the same generalisation guarantees.\n3) We highlight natural examples of structure in the class of sensitivities,\nwhich reduce, and possibly even eliminate the otherwise abundant requirement of\nadditional unlabelled data, and henceforth shed new light onto what makes one\nproblem instance easier to learn than another. These results embed the scope of\nmodern model compression approaches into the general goal of statistical\nlearning theory, which in return suggests appropriate algorithms through\nminimising uniform bounds.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Andrew J. Turner",
      "Ata Kab\u00e1n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.07989"
  },
  {
    "id": "arXiv:2203.07990",
    "title": "UofA-Truth at Factify 2022 : Transformer And Transfer Learning Based  Multi-Modal Fact-Checking",
    "abstract": "Identifying fake news is a very difficult task, especially when considering\nthe multiple modes of conveying information through text, image, video and/or\naudio. We attempted to tackle the problem of automated\nmisinformation/disinformation detection in multi-modal news sources (including\ntext and images) through our simple, yet effective, approach in the FACTIFY\nshared task at De-Factify@AAAI2022. Our model produced an F1-weighted score of\n74.807%, which was the fourth best out of all the submissions. In this paper we\nwill explain our approach to undertake the shared task.",
    "descriptor": "",
    "authors": [
      "Abhishek Dhankar",
      "Osmar R. Za\u00efane",
      "Francois Bolduc"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07990"
  },
  {
    "id": "arXiv:2203.07993",
    "title": "RotateQVS: Representing Temporal Information as Rotations in Quaternion  Vector Space for Temporal Knowledge Graph Completion",
    "abstract": "Temporal factors are tied to the growth of facts in realistic applications,\nsuch as the progress of diseases and the development of political situation,\ntherefore, research on Temporal Knowledge Graph (TKG) attracks much attention.\nIn TKG, relation patterns inherent with temporality are required to be studied\nfor representation learning and reasoning across temporal facts. However,\nexisting methods can hardly model temporal relation patterns, nor can capture\nthe intrinsic connections between relations when evolving over time, lacking of\ninterpretability. In this paper, we propose a novel temporal modeling method\nwhich represents temporal entities as Rotations in Quaternion Vector Space\n(RotateQVS) and relations as complex vectors in Hamilton's quaternion space. We\ndemonstrate our method can model key patterns of relations in TKG, such as\nsymmetry, asymmetry, inverse, and can further capture time-evolved relations by\ntheory. Empirically, we show that our method can boost the performance of link\nprediction tasks over four temporal knowledge graph benchmarks.",
    "descriptor": "",
    "authors": [
      "Kai Chen",
      "Ye Wang",
      "Yitong Li",
      "Aiping Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07993"
  },
  {
    "id": "arXiv:2203.07996",
    "title": "Leveraging Uni-Modal Self-Supervised Learning for Multimodal  Audio-Visual Speech Recognition",
    "abstract": "Training Transformer-based models demands a large amount of data, while\nobtaining parallel aligned and labelled data in multimodality is rather\ncost-demanding, especially for audio-visual speech recognition (AVSR). Thus it\nmakes a lot of sense to make use of unlabelled uni-modal data. On the other\nside, although the effectiveness of large-scale self-supervised learning is\nwell established in both audio and visual modalities, how to integrate those\npre-trained models into a multimodal scenario remains underexplored. In this\nwork, we successfully leverage uni-modal self-supervised learning to promote\nthe multimodal AVSR. In particular, we first train audio and visual encoders on\na large-scale uni-modal dataset, then we integrate components of both encoders\ninto a larger multimodal framework which learns to recognize paired\naudio-visual data into characters through a combination of CTC and seq2seq\ndecoding. We show that both components inherited from uni-modal self-supervised\nlearning cooperate well, resulting in that the multimodal framework yields\ncompetitive results through fine-tuning. Our model is experimentally validated\non both word-level and sentence-level AVSR tasks. Especially, even without an\nexternal language model, our proposed model raises the state-of-the-art\nperformances on the widely accepted Lip Reading Sentences 2 (LRS2) dataset by a\nlarge margin, with a relative improvement of 30%.",
    "descriptor": "\nComments: 8 pages (main), 2 pages (appendix) and to be appeared in ACL2022\n",
    "authors": [
      "Xichen Pan",
      "Peiyu Chen",
      "Yichen Gong",
      "Helong Zhou",
      "Xinbing Wang",
      "Zhouhan Lin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.07996"
  },
  {
    "id": "arXiv:2203.07997",
    "title": "Inverted Pyramid Multi-task Transformer for Dense Scene Understanding",
    "abstract": "Multi-task dense scene understanding is a thriving research domain that\nrequires simultaneous perception and reasoning on a series of correlated tasks\nwith pixel-wise prediction. Most existing works encounter a severe limitation\nof modeling in the locality due to heavy utilization of convolution operations,\nwhile learning interactions and inference in a global spatial-position and\nmulti-task context is critical for this problem. In this paper, we propose a\nnovel end-to-end Inverted Pyramid multi-task (InvPT) Transformer to perform\nsimultaneous modeling of spatial positions and multiple tasks in a unified\nframework. To the best of our knowledge, this is the first work that explores\ndesigning a transformer structure for multi-task dense prediction for scene\nunderstanding. Besides, it is widely demonstrated that a higher spatial\nresolution is remarkably beneficial for dense predictions, while it is very\nchallenging for existing transformers to go deeper with higher resolutions due\nto huge complexity to large spatial size. InvPT presents an efficient\nUP-Transformer block to learn multi-task feature interaction at gradually\nincreased resolutions, which also incorporates effective self-attention message\npassing and multi-scale feature aggregation to produce task-specific prediction\nat a high resolution. Our method achieves superior multi-task performance on\nNYUD-v2 and PASCAL-Context datasets respectively, and significantly outperforms\nprevious state-of-the-arts. Code and trained models will be publicly available.",
    "descriptor": "\nComments: technical report\n",
    "authors": [
      "Hanrong Ye",
      "Dan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07997"
  },
  {
    "id": "arXiv:2203.07998",
    "title": "Reinforcement Learning Framework for Server Placement and Workload  Allocation in Multi-Access Edge Computing",
    "abstract": "Cloud computing is a reliable solution to provide distributed computation\npower. However, real-time response is still challenging regarding the enormous\namount of data generated by the IoT devices in 5G and 6G networks. Thus,\nmulti-access edge computing (MEC), which consists of distributing the edge\nservers in the proximity of end-users to have low latency besides the higher\nprocessing power, is increasingly becoming a vital factor for the success of\nmodern applications. This paper addresses the problem of minimizing both, the\nnetwork delay, which is the main objective of MEC, and the number of edge\nservers to provide a MEC design with minimum cost. This MEC design consists of\nedge servers placement and base stations allocation, which makes it a joint\ncombinatorial optimization problem (COP). Recently, reinforcement learning (RL)\nhas shown promising results for COPs. However, modeling real-world problems\nusing RL when the state and action spaces are large still needs investigation.\nWe propose a novel RL framework with an efficient representation and modeling\nof the state space, action space and the penalty function in the design of the\nunderlying Markov Decision Process (MDP) for solving our problem.",
    "descriptor": "",
    "authors": [
      "Anahita Mazloomi",
      "Hani Sami",
      "Jamal Bentahar",
      "Hadi Otrok",
      "Azzam Mourad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07998"
  },
  {
    "id": "arXiv:2203.07999",
    "title": "MSCET: A Multi-Scenario Offloading Schedule for Biomedical Data  Processing and Analysis in Cloud-Edge-Terminal Collaborative Vehicular  Networks",
    "abstract": "With the rapid development of Artificial Intelligence (AI) and Internet of\nThings (IoTs), an increasing number of computation intensive or delay sensitive\nbiomedical data processing and analysis tasks are produced in vehicles,\nbringing more and more challenges to the biometric monitoring of drivers. Edge\ncomputing is a new paradigm to solve these challenges by offloading tasks from\nthe resource-limited vehicles to Edge Servers (ESs) in Road Side Units (RSUs).\nHowever, most of the traditional offloading schedules for vehicular networks\nconcentrate on the edge, while some tasks may be too complex for ESs to\nprocess. To this end, we consider a collaborative vehicular network in which\nthe cloud, edge and terminal can cooperate with each other to accomplish the\ntasks. The vehicles can offload the computation intensive tasks to the cloud to\nsave the resource of edge. We further construct the virtual resource pool which\ncan integrate the resource of multiple ESs since some regions may be covered by\nmultiple RSUs. In this paper, we propose a Multi-Scenario offloading schedule\nfor biomedical data processing and analysis in Cloud-Edge-Terminal\ncollaborative vehicular networks called MSCET. The parameters of the proposed\nMSCET are optimized to maximize the system utility. We also conduct extensive\nsimulations to evaluate the proposed MSCET and the results illustrate that\nMSCET outperforms other existing schedules.",
    "descriptor": "",
    "authors": [
      "Zhichen Ni",
      "Honglong Chen",
      "Zhe Li",
      "Xiaomeng Wang",
      "Na Yan",
      "Weifeng Liu",
      "Feng Xia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07999"
  },
  {
    "id": "arXiv:2203.08007",
    "title": "Data Smells in Public Datasets",
    "abstract": "The adoption of Artificial Intelligence (AI) in high-stakes domains such as\nhealthcare, wildlife preservation, autonomous driving and criminal justice\nsystem calls for a data-centric approach to AI. Data scientists spend the\nmajority of their time studying and wrangling the data, yet tools to aid them\nwith data analysis are lacking. This study identifies the recurrent data\nquality issues in public datasets. Analogous to code smells, we introduce a\nnovel catalogue of data smells that can be used to indicate early signs of\nproblems or technical debt in machine learning systems. To understand the\nprevalence of data quality issues in datasets, we analyse 25 public datasets\nand identify 14 data smells.",
    "descriptor": "",
    "authors": [
      "Arumoy Shome",
      "Luis Cruz",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08007"
  },
  {
    "id": "arXiv:2203.08008",
    "title": "Beyond Explaining: Opportunities and Challenges of XAI-Based Model  Improvement",
    "abstract": "Explainable Artificial Intelligence (XAI) is an emerging research field\nbringing transparency to highly complex and opaque machine learning (ML)\nmodels. Despite the development of a multitude of methods to explain the\ndecisions of black-box classifiers in recent years, these tools are seldomly\nused beyond visualization purposes. Only recently, researchers have started to\nemploy explanations in practice to actually improve models. This paper offers a\ncomprehensive overview over techniques that apply XAI practically for improving\nvarious properties of ML models, and systematically categorizes these\napproaches, comparing their respective strengths and weaknesses. We provide a\ntheoretical perspective on these methods, and show empirically through\nexperiments on toy and realistic settings how explanations can help improve\nproperties such as model generalization ability or reasoning, among others. We\nfurther discuss potential caveats and drawbacks of these methods. We conclude\nthat while model improvement based on XAI can have significant beneficial\neffects even on complex and not easily quantifyable model properties, these\nmethods need to be applied carefully, since their success can vary depending on\na multitude of factors, such as the model and dataset used, or the employed\nexplanation method.",
    "descriptor": "",
    "authors": [
      "Leander Weber",
      "Sebastian Lapuschkin",
      "Alexander Binder",
      "Wojciech Samek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08008"
  },
  {
    "id": "arXiv:2203.08011",
    "title": "Approximate Decision Trees For Machine Learning Classification on Tiny  Printed Circuits",
    "abstract": "Although Printed Electronics (PE) cannot compete with silicon-based systems\nin conventional evaluation metrics, e.g., integration density, area and\nperformance, PE offers attractive properties such as on-demand ultra-low-cost\nfabrication, flexibility and non-toxicity. As a result, it targets application\ndomains that are untouchable by lithography-based silicon electronics and thus\nhave not yet seen much proliferation of computing. However, despite the\nattractive characteristics of PE, the large feature sizes in PE prohibit the\nrealization of complex printed circuits, such as Machine Learning (ML)\nclassifiers. In this work, we exploit the hardware-friendly nature of Decision\nTrees for machine learning classification and leverage the hardware-efficiency\nof the approximate design in order to generate approximate ML classifiers that\nare suitable for tiny, ultra-resource constrained, and battery-powered printed\napplications.",
    "descriptor": "\nComments: Accepted at the 23rd International Symposium on Quality Electronic Design (ISQED'22), April 6-7, 2022 (Virtual Conference)\n",
    "authors": [
      "Konstantinos Balaskas",
      "Georgios Zervakis",
      "Kostas Siozios",
      "Mehdi B. Tahoori",
      "Joerg Henkel"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08011"
  },
  {
    "id": "arXiv:2203.08013",
    "title": "End-to-End Modeling via Information Tree for One-Shot Natural Language  Spatial Video Grounding",
    "abstract": "Natural language spatial video grounding aims to detect the relevant objects\nin video frames with descriptive sentences as the query. In spite of the great\nadvances, most existing methods rely on dense video frame annotations, which\nrequire a tremendous amount of human effort. To achieve effective grounding\nunder a limited annotation budget, we investigate one-shot video grounding, and\nlearn to ground natural language in all video frames with solely one frame\nlabeled, in an end-to-end manner. One major challenge of end-to-end one-shot\nvideo grounding is the existence of videos frames that are either irrelevant to\nthe language query or the labeled frames. Another challenge relates to the\nlimited supervision, which might result in ineffective representation learning.\nTo address these challenges, we designed an end-to-end model via Information\nTree for One-Shot video grounding (IT-OS). Its key module, the information\ntree, can eliminate the interference of irrelevant frames based on branch\nsearch and branch cropping techniques. In addition, several self-supervised\ntasks are proposed based on the information tree to improve the representation\nlearning under insufficient labeling. Experiments on the benchmark dataset\ndemonstrate the effectiveness of our model.",
    "descriptor": "",
    "authors": [
      "Mengze Li",
      "Tianbao Wang",
      "Haoyu Zhang",
      "Shengyu Zhang",
      "Zhou Zhao",
      "Jiaxu Miao",
      "Wenqiao Zhang",
      "Wenming Tan",
      "Jin Wang",
      "Peng Wang",
      "Shiliang Pu",
      "Fei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08013"
  },
  {
    "id": "arXiv:2203.08015",
    "title": "On-the-fly Strategy Adaptation for ad-hoc Agent Coordination",
    "abstract": "Training agents in cooperative settings offers the promise of AI agents able\nto interact effectively with humans (and other agents) in the real world.\nMulti-agent reinforcement learning (MARL) has the potential to achieve this\ngoal, demonstrating success in a series of challenging problems. However,\nwhilst these advances are significant, the vast majority of focus has been on\nthe self-play paradigm. This often results in a coordination problem, caused by\nagents learning to make use of arbitrary conventions when playing with\nthemselves. This means that even the strongest self-play agents may have very\nlow cross-play with other agents, including other initializations of the same\nalgorithm. In this paper we propose to solve this problem by adapting agent\nstrategies on the fly, using a posterior belief over the other agents'\nstrategy. Concretely, we consider the problem of selecting a strategy from a\nfinite set of previously trained agents, to play with an unknown partner. We\npropose an extension of the classic statistical technique, Gibbs sampling, to\nupdate beliefs about other agents and obtain close to optimal ad-hoc\nperformance. Despite its simplicity, our method is able to achieve strong\ncross-play with unseen partners in the challenging card game of Hanabi,\nachieving successful ad-hoc coordination without knowledge of the partner's\nstrategy a priori.",
    "descriptor": "\nComments: Extended abstract published in AAMAS 2022\n",
    "authors": [
      "Jaleh Zand",
      "Jack Parker-Holder",
      "Stephen J. Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08015"
  },
  {
    "id": "arXiv:2203.08016",
    "title": "Formalising Decentralised Exchanges in Coq",
    "abstract": "The number of attacks and accidents leading to significant losses of\ncrypto-assets is growing. According to Chainalysis, in 2021, approx. $14\nbillion has been lost due to various incidents, and this number is dominated by\nDecentralized Finance (DeFi) applications. In order to address these issues,\none can use a collection of tools ranging from auditing to formal methods. We\nuse formal verification and provide the first formalisation of a DeFi contract\nin a foundational proof assistant capturing contract interactions. We focus on\nDexter2, a decentralized, non-custodial exchange for the Tezos network similar\nto Uniswap on Ethereum. The Dexter implementation consists of several smart\ncontracts. This poses unique challenges for formalisation due to the complex\ncontract interactions. Our formalisation includes proofs of functional\ncorrectness with respect to an informal specification for the contracts\ninvolved in Dexter's implementation. Moreover, our formalisation is the first\nto feature proofs of safety properties of the interacting smart contracts of a\ndecentralized exchange. We have extracted our contract from Coq into CameLIGO\ncode, so it can be deployed on the Tezos blockchain. Uniswap and Dexter are\nparadigmatic for a collection of similar contracts. Our methodology thus allows\nus to implement and verify DeFi applications featuring similar interaction\npatterns.",
    "descriptor": "",
    "authors": [
      "Eske Hoy Nielsen",
      "Danil Annenkov",
      "Bas Spitters"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08016"
  },
  {
    "id": "arXiv:2203.08019",
    "title": "Optimal Admission Control for Multiclass Queues with Time-Varying  Arrival Rates via State Abstraction",
    "abstract": "We consider a novel queuing problem where the decision-maker must choose to\naccept or reject randomly arriving tasks into a no buffer queue which are\nprocessed by $N$ identical servers. Each task has a price, which is a positive\nreal number, and a class. Each class of task has a different price distribution\nand service rate, and arrives according to an inhomogenous Poisson process. The\nobjective is to decide which tasks to accept so that the total price of tasks\nprocessed is maximised over a finite horizon. We formulate the problem as a\ndiscrete time Markov Decision Process (MDP) with a hybrid state space. We show\nthat the optimal value function has a specific structure, which enables us to\nsolve the hybrid MDP exactly. Moreover, we prove that as the time step is\nreduced, the discrete time solution approaches the optimal solution to the\noriginal continuous time problem. To improve the scalability of our approach to\na greater number of task classes, we present an approximation based on state\nabstraction. We validate our approach on synthetic data, as well as a real\nfinancial fraud data set, which is the motivating application for this work.",
    "descriptor": "\nComments: 7+1 pages main text, 16 pages supplementary material, accepted to AAAI 2022\n",
    "authors": [
      "Marc Rigter",
      "Danial Dervovic",
      "Parisa Hassanzadeh",
      "Jason Long",
      "Parisa Zehtabi",
      "Daniele Magazzeni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.08019"
  },
  {
    "id": "arXiv:2203.08020",
    "title": "Geometric reconstructions of density based clusterings",
    "abstract": "DBSCAN* and HDBSCAN* are well established density based clustering\nalgorithms. However, obtaining the clusters of very large datasets is\ninfeasible, limiting their use in real world applications.\nBy exploiting the geometry of Euclidean space, we prove that it is possible\nto systematically construct the DBSCAN* and HDBSCAN* clusters of a finite\n$X\\subset \\mathbb{R}^n$ from specific subsets of $X$. We are able to control\nthe size of these subsets and therefore our results make it possible to cluster\nvery large datasets.\nTo illustrate our theory, we cluster the Microsoft Building Footprint\nDatabase of the US, which is not possible using the standard implementations.",
    "descriptor": "",
    "authors": [
      "A.L. Garcia-Pulido",
      "K.P. Samardzhiev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08020"
  },
  {
    "id": "arXiv:2203.08027",
    "title": "Natural Hierarchical Cluster Analysis by Nearest Neighbors with  Near-Linear Time Complexity",
    "abstract": "We propose a nearest neighbor based clustering algorithm that results in a\nnaturally defined hierarchy of clusters. In contrast to the agglomerative and\ndivisive hierarchical clustering algorithms, our approach is not dependent on\nthe iterative working of the algorithm, in the sense that the partitions of the\nhierarchical clusters are purely defined in accordance with the input dataset.\nOur method is a universal hierarchical clustering approach since it can be\nimplemented as bottom up or top down versions, both of which result in the same\nclustering. We show that for certain types of datasets, our algorithm has\nnear-linear time and space complexity.",
    "descriptor": "",
    "authors": [
      "Kaan Gokcesu",
      "Hakan Gokcesu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08027"
  },
  {
    "id": "arXiv:2203.08029",
    "title": "Optimal dispatch schedule for a fast EV charging station with account to  supplementary battery health degradation",
    "abstract": "This paper investigates the usage of battery storage systems in a fast\ncharging station (FCS) for participation in energy markets and charging\nelectrical vehicles (EVs) simultaneously. In particular, we focus on optimizing\nthe scheduling strategies to reduce the overall operational cost of the system\nover its lifetime by combining the model of battery degradation and energy\narbitrage. We implement the battery degradation as a penalty term within an\nenergy arbitrage model and show that the battery degradation plays an important\nrole in the optimal energy dispatch scheduling of the FCS system. In this case\nstudy, with different penalty coefficients for the battery degradation penalty\nterm, it is found that including the penalty of battery usage in the scheduling\nmodel will reduce the number of small charging/discharging cycles, thereby\nprolonging the battery lifetime, while maintaining near optimal revenue from\ngrid services.",
    "descriptor": "\nComments: To be published at ITEC+EATS, 2022\n",
    "authors": [
      "Yihao Wan",
      "Daniel Gebbran",
      "Tomislav Dragi\u010devi\u0107"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.08029"
  },
  {
    "id": "arXiv:2203.08031",
    "title": "Data-Efficient Graph Grammar Learning for Molecular Generation",
    "abstract": "The problem of molecular generation has received significant attention\nrecently. Existing methods are typically based on deep neural networks and\nrequire training on large datasets with tens of thousands of samples. In\npractice, however, the size of class-specific chemical datasets is usually\nlimited (e.g., dozens of samples) due to labor-intensive experimentation and\ndata collection. This presents a considerable challenge for the deep learning\ngenerative models to comprehensively describe the molecular design space.\nAnother major challenge is to generate only physically synthesizable molecules.\nThis is a non-trivial task for neural network-based generative models since the\nrelevant chemical knowledge can only be extracted and generalized from the\nlimited training data. In this work, we propose a data-efficient generative\nmodel that can be learned from datasets with orders of magnitude smaller sizes\nthan common benchmarks. At the heart of this method is a learnable graph\ngrammar that generates molecules from a sequence of production rules. Without\nany human assistance, these production rules are automatically constructed from\ntraining data. Furthermore, additional chemical knowledge can be incorporated\nin the model by further grammar optimization. Our learned graph grammar yields\nstate-of-the-art results on generating high-quality molecules for three monomer\ndatasets that contain only ${\\sim}20$ samples each. Our approach also achieves\nremarkable performance in a challenging polymer generation task with only $117$\ntraining samples and is competitive against existing methods using $81$k data\npoints. Code is available at https://github.com/gmh14/data_efficient_grammar.",
    "descriptor": "\nComments: ICLR 2022 oral\n",
    "authors": [
      "Minghao Guo",
      "Veronika Thost",
      "Beichen Li",
      "Payel Das",
      "Jie Chen",
      "Wojciech Matusik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2203.08031"
  },
  {
    "id": "arXiv:2203.08036",
    "title": "Sensor Object Plausibilization with Boids Flocking Algorithm",
    "abstract": "Driver assistance systems are increasingly becoming part of the standard\nequipment of vehicles and thus contribute to road safety. However, as they\nbecome more widespread, the requirements for cost efficiency are also\nincreasing, and so few and inexpensive sensors are used in these systems.\nEspecially in challenging situations, this leads to the fact that target\ndiscrimination cannot be ensured which in turn leads to a false reaction of the\ndriver assistance system. Typically, the interaction between moving traffic\nparticipants is not modeled directly in the environmental model so that tracked\nobjects can split, merge or disappear. The Boids flocking algorithm is used to\nmodel the interaction between road users on already tracked objects by applying\nthe movement rules (separation, cohesion, alignment) on the boids. This\nfacilitates the creation of semantic neighborhood information between road\nusers. We show in a comprehensive simulation that with only 7 boids per traffic\nparticipant, the estimated median separatation between objects can improve from\n2.4 m to 3 m for a ground truth of 3.7 m. The bottom percentile improves from\n1.85 m to 2.8 m.",
    "descriptor": "",
    "authors": [
      "Christopher Knievel",
      "Lars Krueger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08036"
  },
  {
    "id": "arXiv:2203.08037",
    "title": "Interactive Robotic Grasping with Attribute-Guided Disambiguation",
    "abstract": "Interactive robotic grasping using natural language is one of the most\nfundamental tasks in human-robot interaction. However, language can be a source\nof ambiguity, particularly when there are ambiguous visual or linguistic\ncontents. This paper investigates the use of object attributes in\ndisambiguation and develops an interactive grasping system capable of\neffectively resolving ambiguities via dialogues. Our approach first predicts\ntarget scores and attribute scores through vision-and-language grounding. To\nhandle ambiguous objects and commands, we propose an attribute-guided\nformulation of the partially observable Markov decision process (Attr-POMDP)\nfor disambiguation. The Attr-POMDP utilizes target and attribute scores as the\nobservation model to calculate the expected return of an attribute-based (e.g.,\n\"what is the color of the target, red or green?\") or a pointing-based (e.g.,\n\"do you mean this one?\") question. Our disambiguation module runs in real time\non a real robot, and the interactive grasping system achieves a 91.43\\%\nselection accuracy in the real-robot experiments, outperforming several\nbaselines by large margins.",
    "descriptor": "\nComments: Accepted to the IEEE International Conference on Robotics and Automation (ICRA 2022). Project page: this https URL\n",
    "authors": [
      "Yang Yang",
      "Xibai Lou",
      "Changhyun Choi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08037"
  },
  {
    "id": "arXiv:2203.08038",
    "title": "Deep learning for radar data exploitation of autonomous vehicle",
    "abstract": "Autonomous driving requires a detailed understanding of complex driving\nscenes. The redundancy and complementarity of the vehicle's sensors provide an\naccurate and robust comprehension of the environment, thereby increasing the\nlevel of performance and safety. This thesis focuses the on automotive RADAR,\nwhich is a low-cost active sensor measuring properties of surrounding objects,\nincluding their relative speed, and has the key advantage of not being impacted\nby adverse weather conditions. With the rapid progress of deep learning and the\navailability of public driving datasets, the perception ability of vision-based\ndriving systems has considerably improved. The RADAR sensor is seldom used for\nscene understanding due to its poor angular resolution, the size, noise, and\ncomplexity of RADAR raw data as well as the lack of available datasets. This\nthesis proposes an extensive study of RADAR scene understanding, from the\nconstruction of an annotated dataset to the conception of adapted deep learning\narchitectures. First, this thesis details approaches to tackle the current lack\nof data. A simple simulation as well as generative methods for creating\nannotated data will be presented. It will also describe the CARRADA dataset,\ncomposed of synchronised camera and RADAR data with a semi-automatic annotation\nmethod. This thesis then present a proposed set of deep learning architectures\nwith their associated loss functions for RADAR semantic segmentation. It also\nintroduces a method to open up research into the fusion of LiDAR and RADAR\nsensors for scene understanding. Finally, this thesis exposes a collaborative\ncontribution, the RADIal dataset with synchronised High-Definition (HD) RADAR,\nLiDAR and camera. A deep learning architecture is also proposed to estimate the\nRADAR signal processing pipeline while performing multitask learning for object\ndetection and free driving space segmentation.",
    "descriptor": "\nComments: PhD Thesis (194 pages); several papers are included in the manuscript; may overlap with: arXiv:2005.01456, arXiv:2103.16214 and arXiv:2112.10646\n",
    "authors": [
      "Arthur Ouaknine"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08038"
  },
  {
    "id": "arXiv:2203.08040",
    "title": "Simultaneous Localisation and Mapping with Quadric Surfaces",
    "abstract": "There are many possibilities for how to represent the map in simultaneous\nlocalisation and mapping (SLAM). While sparse, keypoint-based SLAM systems have\nachieved impressive levels of accuracy and robustness, their maps may not be\nsuitable for many robotic tasks. Dense SLAM systems are capable of producing\ndense reconstructions, but can be computationally expensive and, like sparse\nsystems, lack higher-level information about the structure of a scene.\nHuman-made environments contain a lot of structure, and we seek to take\nadvantage of this by enabling the use of quadric surfaces as features in SLAM\nsystems. We introduce a minimal representation for quadric surfaces and show\nhow this can be included in a least-squares formulation. We also show how our\nrepresentation can be easily extended to include additional constraints on\nquadrics such as those found in quadrics of revolution. Finally, we introduce a\nproof-of-concept SLAM system using our representation, and provide some\nexperimental results using an RGB-D dataset.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Tristan Laidlow",
      "Andrew J. Davison"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08040"
  },
  {
    "id": "arXiv:2203.08041",
    "title": "A multi-organ point cloud registration algorithm for abdominal CT  registration",
    "abstract": "Registering CT images of the chest is a crucial step for several tasks such\nas disease progression tracking or surgical planning. It is also a challenging\nstep because of the heterogeneous content of the human abdomen which implies\ncomplex deformations. In this work, we focus on accurately registering a subset\nof organs of interest. We register organ surface point clouds, as may typically\nbe extracted from an automatic segmentation pipeline, by expanding the Bayesian\nCoherent Point Drift algorithm (BCPD). We introduce MO-BCPD, a multi-organ\nversion of the BCPD algorithm which explicitly models three important aspects\nof this task: organ individual elastic properties, inter-organ motion coherence\nand segmentation inaccuracy. This model also provides an interpolation\nframework to estimate the deformation of the entire volume. We demonstrate the\nefficiency of our method by registering different patients from the LITS\nchallenge dataset. The target registration error on anatomical landmarks is\nalmost twice as small for MO-BCPD compared to standard BCPD while imposing the\nsame constraints on individual organs deformation.",
    "descriptor": "\nComments: Accepted at WBIR 2022\n",
    "authors": [
      "Samuel Joutard",
      "Thomas Pheiffer",
      "Chloe Audigier",
      "Patrick Wohlfahrt",
      "Reuben Dorent",
      "Sebastien Piat",
      "Tom Vercauteren",
      "Marc Modat",
      "Tommaso Mansi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08041"
  },
  {
    "id": "arXiv:2203.08046",
    "title": "Intelligent Reconfigurable Surfaces vs. Decode-and-Forward: What is the  Impact of Electromagnetic Interference?",
    "abstract": "This paper considers the use of an intelligent reconfigurable surface (IRS)\nto aid wireless communication systems. The main goal is to compare this\nemerging technology with conventional decode-and-forward (DF) relaying. Unlike\nprior comparisons, we assume that electromagnetic interference (EMI),\nconsisting of incoming waves from external sources, is present at the location\nwhere the IRS or DF relay are placed. The analysis, in terms of minimizing the\ntotal transmit power, shows that EMI has a strong impact on DF relay-assisted\ncommunications, even when the relaying protocol is optimized against EMI. It\nturns out that IRS-aided communications is more resilient to EMI. To beat an\nIRS, we show that the DF relay must use multiple antennas and actively suppress\nthe EMI by beamforming.",
    "descriptor": "\nComments: 5 pages, 9 figures, submitted to the 23rd IEEE International Workshop on Signal Processing Advances in Wireless Communications (SPAWC2022)\n",
    "authors": [
      "Andrea De Jesus Torres",
      "Luca Sanguinetti",
      "Emil Bj\u00f6rnson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.08046"
  },
  {
    "id": "arXiv:2203.08047",
    "title": "Mobility, traffic and radio channel prediction: 5G and beyond  applications",
    "abstract": "Machine learning (ML) is an important component for enabling automation in\nRadio Access Networks (RANs). The work on applying ML for RAN has been under\ndevelopment for many years and is now also drawing attention in 3GPP and\nOpen-RAN standardization fora. A key component of multiple features, also\nhighlighted in the recent 3GPP specification work, is the use of mobility,\ntraffic and radio channel prediction. These types of predictions form the\nintelligence enablers to leverage the potentials for ML for RAN, both for\ncurrent and future wireless networks. This paper provides an overview with\nevaluation results of current applications that utilize such intelligence\nenablers, we then discuss how those enablers likely will be a cornerstone for\nemerging 6G use cases such as wireless energy transmission.",
    "descriptor": "\nComments: 6 pages, submitted to IEEE conference\n",
    "authors": [
      "Henrik Ryd\u00e9n",
      "Alex Palaios",
      "L\u00e1szl\u00f3 H\u00e9vizi",
      "David Sandberg",
      "Tor Kvernvik",
      "Hamed Farhadi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.08047"
  },
  {
    "id": "arXiv:2203.08049",
    "title": "On Hyperbolic Embeddings in 2D Object Detection",
    "abstract": "Object detection, for the most part, has been formulated in the euclidean\nspace, where euclidean or spherical geodesic distances measure the similarity\nof an image region to an object class prototype. In this work, we study whether\na hyperbolic geometry better matches the underlying structure of the object\nclassification space. We incorporate a hyperbolic classifier in two-stage,\nkeypoint-based, and transformer-based object detection architectures and\nevaluate them on large-scale, long-tailed, and zero-shot object detection\nbenchmarks. In our extensive experimental evaluations, we observe categorical\nclass hierarchies emerging in the structure of the classification space,\nresulting in lower classification errors and boosting the overall object\ndetection performance.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Christopher Lang",
      "Alexander Braun",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08049"
  },
  {
    "id": "arXiv:2203.08055",
    "title": "Modular and Parameter-Efficient Multimodal Fusion with Prompting",
    "abstract": "Recent research has made impressive progress in large-scale multimodal\npre-training. In the context of the rapid growth of model size, it is necessary\nto seek efficient and flexible methods other than finetuning. In this paper, we\npropose to use prompt vectors to align the modalities. Our method achieves\ncomparable performance to several other multimodal fusion methods in\nlow-resource settings. We further show that our method is modular and\nparameter-efficient for processing tasks involving two or more data modalities.",
    "descriptor": "\nComments: Accepted to Findings of ACL 2022\n",
    "authors": [
      "Sheng Liang",
      "Mengjie Zhao",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08055"
  },
  {
    "id": "arXiv:2203.08057",
    "title": "POETREE: Interpretable Policy Learning with Adaptive Decision Trees",
    "abstract": "Building models of human decision-making from observed behaviour is critical\nto better understand, diagnose and support real-world policies such as clinical\ncare. As established policy learning approaches remain focused on imitation\nperformance, they fall short of explaining the demonstrated decision-making\nprocess. Policy Extraction through decision Trees (POETREE) is a novel\nframework for interpretable policy learning, compatible with fully-offline and\npartially-observable clinical decision environments -- and builds probabilistic\ntree policies determining physician actions based on patients' observations and\nmedical history. Fully-differentiable tree architectures are grown\nincrementally during optimization to adapt their complexity to the modelling\ntask, and learn a representation of patient history through recurrence,\nresulting in decision tree policies that adapt over time with patient\ninformation. This policy learning method outperforms the state-of-the-art on\nreal and synthetic medical datasets, both in terms of understanding,\nquantifying and evaluating observed behaviour as well as in accurately\nreplicating it -- with potential to improve future decision support systems.",
    "descriptor": "",
    "authors": [
      "Aliz\u00e9e Pace",
      "Alex J. Chan",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08057"
  },
  {
    "id": "arXiv:2203.08060",
    "title": "Seeking Commonness and Inconsistencies: A Jointly Smoothed Approach to  Multi-view Subspace Clustering",
    "abstract": "Multi-view subspace clustering aims to discover the hidden subspace\nstructures from multiple views for robust clustering, and has been attracting\nconsiderable attention in recent years. Despite significant progress, most of\nthe previous multi-view subspace clustering algorithms are still faced with two\nlimitations. First, they usually focus on the consistency (or commonness) of\nmultiple views, yet often lack the ability to capture the cross-view\ninconsistencies in subspace representations. Second, many of them overlook the\nlocal structures of multiple views and cannot jointly leverage multiple local\nstructures to enhance the subspace representation learning. To address these\ntwo limitations, in this paper, we propose a jointly smoothed multi-view\nsubspace clustering (JSMC) approach. Specifically, we simultaneously\nincorporate the cross-view commonness and inconsistencies into the subspace\nrepresentation learning. The view-consensus grouping effect is presented to\njointly exploit the local structures of multiple views to regularize the\nview-commonness representation, which is further associated with the low-rank\nconstraint via the nuclear norm to strengthen its cluster structure. Thus the\ncross-view commonness and inconsistencies, the view-consensus grouping effect,\nand the low-rank representation are seamlessly incorporated into a unified\nobjective function, upon which an alternating optimization algorithm is\nperformed to achieve a robust subspace representation for clustering.\nExperimental results on a variety of real-world multi-view datasets have\nconfirmed the superiority of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Xiaosha Cai",
      "Dong Huang",
      "Guang-Yu Zhang",
      "Chang-Dong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08060"
  },
  {
    "id": "arXiv:2203.08061",
    "title": "A novel sampler for Gauss-Hermite determinantal point processes with  application to Monte Carlo integration",
    "abstract": "Determinantal points processes are a promising but relatively under-developed\ntool in machine learning and statistical modelling, being the canonical\nstatistical example of distributions with repulsion. While their mathematical\nformulation is elegant and appealing, their practical use, such as simply\nsampling from them, is far from straightforward.Recent work has shown how a\nparticular type of determinantal point process defined on the compact\nmultidimensional space $[-1, 1]^d$ can be practically sampled and further shown\nhow such samples can be used to improve Monte Carlo integration.This work\nextends those results to a new determinantal point process on $\\mathbb{R}^d$ by\nconstructing a novel sampling scheme. Samples from this new process are shown\nto be useful in Monte Carlo integration against Gaussian measure, which is\nparticularly relevant in machine learning applications.",
    "descriptor": "\nComments: 12 pages, 11 figures\n",
    "authors": [
      "Nicholas P Baskerville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.08061"
  },
  {
    "id": "arXiv:2203.08063",
    "title": "MotionCLIP: Exposing Human Motion Generation to CLIP Space",
    "abstract": "We introduce MotionCLIP, a 3D human motion auto-encoder featuring a latent\nembedding that is disentangled, well behaved, and supports highly semantic\ntextual descriptions. MotionCLIP gains its unique power by aligning its latent\nspace with that of the Contrastive Language-Image Pre-training (CLIP) model.\nAligning the human motion manifold to CLIP space implicitly infuses the\nextremely rich semantic knowledge of CLIP into the manifold. In particular, it\nhelps continuity by placing semantically similar motions close to one another,\nand disentanglement, which is inherited from the CLIP-space structure.\nMotionCLIP comprises a transformer-based motion auto-encoder, trained to\nreconstruct motion while being aligned to its text label's position in\nCLIP-space. We further leverage CLIP's unique visual understanding and inject\nan even stronger signal through aligning motion to rendered frames in a\nself-supervised manner. We show that although CLIP has never seen the motion\ndomain, MotionCLIP offers unprecedented text-to-motion abilities, allowing\nout-of-domain actions, disentangled editing, and abstract language\nspecification. For example, the text prompt \"couch\" is decoded into a sitting\ndown motion, due to lingual similarity, and the prompt \"Spiderman\" results in a\nweb-swinging-like solution that is far from seen during training. In addition,\nwe show how the introduced latent space can be leveraged for motion\ninterpolation, editing and recognition.",
    "descriptor": "",
    "authors": [
      "Guy Tevet",
      "Brian Gordon",
      "Amir Hertz",
      "Amit H. Bermano",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.08063"
  },
  {
    "id": "arXiv:2203.08065",
    "title": "Surrogate Gap Minimization Improves Sharpness-Aware Training",
    "abstract": "The recently proposed Sharpness-Aware Minimization (SAM) improves\ngeneralization by minimizing a \\textit{perturbed loss} defined as the maximum\nloss within a neighborhood in the parameter space. However, we show that both\nsharp and flat minima can have a low perturbed loss, implying that SAM does not\nalways prefer flat minima. Instead, we define a \\textit{surrogate gap}, a\nmeasure equivalent to the dominant eigenvalue of Hessian at a local minimum\nwhen the radius of the neighborhood (to derive the perturbed loss) is small.\nThe surrogate gap is easy to compute and feasible for direct minimization\nduring training. Based on the above observations, we propose Surrogate\n\\textbf{G}ap Guided \\textbf{S}harpness-\\textbf{A}ware \\textbf{M}inimization\n(GSAM), a novel improvement over SAM with negligible computation overhead.\nConceptually, GSAM consists of two steps: 1) a gradient descent like SAM to\nminimize the perturbed loss, and 2) an \\textit{ascent} step in the\n\\textit{orthogonal} direction (after gradient decomposition) to minimize the\nsurrogate gap and yet not affect the perturbed loss. GSAM seeks a region with\nboth small loss (by step 1) and low sharpness (by step 2), giving rise to a\nmodel with high generalization capabilities. Theoretically, we show the\nconvergence of GSAM and provably better generalization than SAM. Empirically,\nGSAM consistently improves generalization (e.g., +3.2\\% over SAM and +5.4\\%\nover AdamW on ImageNet top-1 accuracy for ViT-B/32). Code is released at \\url{\nhttps://sites.google.com/view/gsam-iclr22/home}.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Juntang Zhuang",
      "Boqing Gong",
      "Liangzhe Yuan",
      "Yin Cui",
      "Hartwig Adam",
      "Nicha Dvornek",
      "Sekhar Tatikonda",
      "James Duncan",
      "Ting Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08065"
  },
  {
    "id": "arXiv:2203.08067",
    "title": "Practical data monitoring in the internet-services domain",
    "abstract": "Large-scale automated monitoring, anomaly detection, and root cause analysis\nof metrics is an essential requirement of the internet-services industry. To\naddress the need to continuously monitor millions of metrics, many anomaly\ndetection approaches are being used on a daily basis by large internet-based\ncompanies. However, in spite of the significant progress made to accurately and\nefficiently detect anomalies in metrics, the sheer scale of the number of\nmetrics has meant there are still a large number of false alarms that need to\nbe investigated. This paper presents a framework for reliable large-scale\nanomaly detection. It is significantly more accurate than existing approaches\nand allows for easy interpretation of models, thus enabling practical data\nmonitoring in the internet-services domain.",
    "descriptor": "",
    "authors": [
      "Nikhil Galagali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.08067"
  },
  {
    "id": "arXiv:2203.08069",
    "title": "DISTAL: The Distributed Tensor Algebra Compiler",
    "abstract": "We introduce DISTAL, a compiler for dense tensor algebra that targets modern\ndistributed and heterogeneous systems. DISTAL lets users independently describe\nhow tensors and computation map onto target machines through separate format\nand scheduling languages. The combination of choices for data and computation\ndistribution creates a large design space that includes many algorithms from\nboth the past (e.g., Cannon's algorithm) and the present (e.g., COSMA). DISTAL\ncompiles a tensor algebra domain specific language to a distributed task-based\nruntime system and supports both nodes with multi-core CPUs and multiple GPUs.\nCode generated by DISTAL is competitive with optimized codes for matrix\nmultiply on 256 nodes of the Lassen supercomputer and outperforms existing\nsystems by between 1.8x to 3.7x (with a 45.7x outlier) on higher order tensor\noperations.",
    "descriptor": "",
    "authors": [
      "Rohan Yadav",
      "Alex Aiken",
      "Fredrik Kjolstad"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.08069"
  },
  {
    "id": "arXiv:2203.08073",
    "title": "Can A Neural Network Hear the Shape of A Drum?",
    "abstract": "We have developed a deep neural network that reconstructs the shape of a\npolygonal domain given the first hundred of its Laplacian (or Schrodinger)\neigenvalues. Having an encoder-decoder structure, the network maps input\nspectra to a latent space and then predicts the discretized image of the domain\non a square grid. We tested this network on randomly generated pentagons. The\nprediction accuracy is high and the predictions obey the Laplacian scaling\nrule. The network recovers the continuous rotational degree of freedom beyond\nthe symmetry of the grid. The variation of the latent variables under the\nscaling transformation shows they are strongly correlated with Weyl' s\nparameters (area, perimeter, and a certain function of the angles) of the test\npolygons.",
    "descriptor": "",
    "authors": [
      "Yueqi Zhao",
      "Michael M. Fogler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2203.08073"
  },
  {
    "id": "arXiv:2203.08075",
    "title": "Things not Written in Text: Exploring Spatial Commonsense from Visual  Signals",
    "abstract": "Spatial commonsense, the knowledge about spatial position and relationship\nbetween objects (like the relative size of a lion and a girl, and the position\nof a boy relative to a bicycle when cycling), is an important part of\ncommonsense knowledge. Although pretrained language models (PLMs) succeed in\nmany NLP tasks, they are shown to be ineffective in spatial commonsense\nreasoning. Starting from the observation that images are more likely to exhibit\nspatial commonsense than texts, we explore whether models with visual signals\nlearn more spatial commonsense than text-based PLMs. We propose a spatial\ncommonsense benchmark that focuses on the relative scales of objects, and the\npositional relationship between people and objects under different actions. We\nprobe PLMs and models with visual signals, including vision-language pretrained\nmodels and image synthesis models, on this benchmark, and find that image\nsynthesis models are more capable of learning accurate and consistent spatial\nknowledge than other models. The spatial knowledge from image synthesis models\nalso helps in natural language understanding tasks that require spatial\ncommonsense.",
    "descriptor": "\nComments: Accepted by ACL 2022 main conference\n",
    "authors": [
      "Xiao Liu",
      "Da Yin",
      "Yansong Feng",
      "Dongyan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08075"
  },
  {
    "id": "arXiv:2203.08080",
    "title": "Implicit Feature Decoupling with Depthwise Quantization",
    "abstract": "Quantization has been applied to multiple domains in Deep Neural Networks\n(DNNs). We propose Depthwise Quantization (DQ) where $\\textit{quantization}$ is\napplied to a decomposed sub-tensor along the $\\textit{feature axis}$ of weak\nstatistical dependence. The feature decomposition leads to an exponential\nincrease in $\\textit{representation capacity}$ with a linear increase in memory\nand parameter cost. In addition, DQ can be directly applied to existing\nencoder-decoder frameworks without modification of the DNN architecture. We use\nDQ in the context of Hierarchical Auto-Encoder and train end-to-end on an image\nfeature representation. We provide an analysis on cross-correlation between\nspatial and channel features and we propose a decomposition of the image\nfeature representation along the channel axis. The improved performance of the\ndepthwise operator is due to the increased representation capacity from\nimplicit feature decoupling. We evaluate DQ on the likelihood estimation task,\nwhere it outperforms the previous state-of-the-art on CIFAR-10, ImageNet-32 and\nImageNet-64. We progressively train with increasing image size a single\nhierarchical model that uses 69% less parameters and has a faster convergence\nthan the previous works.",
    "descriptor": "\nComments: to be published in CVPR-2022\n",
    "authors": [
      "Iordanis Fostiropoulos",
      "Barry Boehm"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08080"
  },
  {
    "id": "arXiv:2203.08082",
    "title": "Regenerative Particle Thompson Sampling",
    "abstract": "This paper proposes regenerative particle Thompson sampling (RPTS), a\nflexible variation of Thompson sampling. Thompson sampling itself is a Bayesian\nheuristic for solving stochastic bandit problems, but it is hard to implement\nin practice due to the intractability of maintaining a continuous posterior\ndistribution. Particle Thompson sampling (PTS) is an approximation of Thompson\nsampling obtained by simply replacing the continuous distribution by a discrete\ndistribution supported at a set of weighted static particles. We observe that\nin PTS, the weights of all but a few fit particles converge to zero. RPTS is\nbased on the heuristic: delete the decaying unfit particles and regenerate new\nparticles in the vicinity of fit surviving particles. Empirical evidence shows\nuniform improvement from PTS to RPTS and flexibility and efficacy of RPTS\nacross a set of representative bandit problems, including an application to 5G\nnetwork slicing.",
    "descriptor": "\nComments: Mainbody 14 pages, appendix 32 pages, 16 figures\n",
    "authors": [
      "Zeyu Zhou",
      "Bruce Hajek",
      "Nakjung Choi",
      "Anwar Walid"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.08082"
  },
  {
    "id": "arXiv:2203.08085",
    "title": "Measuring the Impact of (Psycho-)Linguistic and Readability Features and  Their Spill Over Effects on the Prediction of Eye Movement Patterns",
    "abstract": "There is a growing interest in the combined use of NLP and machine learning\nmethods to predict gaze patterns during naturalistic reading. While promising\nresults have been obtained through the use of transformer-based language\nmodels, little work has been undertaken to relate the performance of such\nmodels to general text characteristics. In this paper we report on experiments\nwith two eye-tracking corpora of naturalistic reading and two language models\n(BERT and GPT-2). In all experiments, we test effects of a broad spectrum of\nfeatures for predicting human reading behavior that fall into five categories\n(syntactic complexity, lexical richness, register-based multiword combinations,\nreadability and psycholinguistic word properties). Our experiments show that\nboth the features included and the architecture of the transformer-based\nlanguage models play a role in predicting multiple eye-tracking measures during\nnaturalistic reading. We also report the results of experiments aimed at\ndetermining the relative importance of features from different groups using\nSP-LIME.",
    "descriptor": "\nComments: accepted at ACL 2022\n",
    "authors": [
      "Daniel Wiechmann",
      "Yu Qiao",
      "Elma Kerz",
      "Justus Mattern"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08085"
  },
  {
    "id": "arXiv:2203.08089",
    "title": "On Suspicious Coincidences and Pointwise Mutual Information",
    "abstract": "Barlow (1985) hypothesized that the co-occurrence of two events $A$ and $B$\nis \"suspicious\" if $P(A,B) \\gg P(A) P(B)$. We first review classical measures\nof association for $2 \\times 2$ contingency tables, including Yule's $Y$ (Yule,\n1912), which depends only on the odds ratio $\\lambda$, and is independent of\nthe marginal probabilities of the table. We then discuss the mutual information\n(MI) and pointwise mutual information (PMI), which depend on the ratio\n$P(A,B)/P(A)P(B)$, as measures of association. We show that, once the effect of\nthe marginals is removed, MI and PMI behave similarly to $Y$ as functions of\n$\\lambda$. The pointwise mutual information is used extensively in some\nresearch communities for flagging suspicious coincidences, but it is important\nto bear in mind the sensitivity of the PMI to the marginals, with increased\nscores for sparser events.",
    "descriptor": "\nComments: 7 pages, 1 figure\n",
    "authors": [
      "Christopher K. I. Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.08089"
  },
  {
    "id": "arXiv:2203.08098",
    "title": "RB2: Robotic Manipulation Benchmarking with a Twist",
    "abstract": "Benchmarks offer a scientific way to compare algorithms using objective\nperformance metrics. Good benchmarks have two features: (a) they should be\nwidely useful for many research groups; (b) and they should produce\nreproducible findings. In robotic manipulation research, there is a trade-off\nbetween reproducibility and broad accessibility. If the benchmark is kept\nrestrictive (fixed hardware, objects), the numbers are reproducible but the\nsetup becomes less general. On the other hand, a benchmark could be a loose set\nof protocols (e.g. object sets) but the underlying variation in setups make the\nresults non-reproducible. In this paper, we re-imagine benchmarking for robotic\nmanipulation as state-of-the-art algorithmic implementations, alongside the\nusual set of tasks and experimental protocols. The added baseline\nimplementations will provide a way to easily recreate SOTA numbers in a new\nlocal robotic setup, thus providing credible relative rankings between existing\napproaches and new work. However, these local rankings could vary between\ndifferent setups. To resolve this issue, we build a mechanism for pooling\nexperimental data between labs, and thus we establish a single global ranking\nfor existing (and proposed) SOTA algorithms. Our benchmark, called\nRanking-Based Robotics Benchmark (RB2), is evaluated on tasks that are inspired\nfrom clinically validated Southampton Hand Assessment Procedures. Our benchmark\nwas run across two different labs and reveals several surprising findings. For\nexample, extremely simple baselines like open-loop behavior cloning, outperform\nmore complicated models (e.g. closed loop, RNN, Offline-RL, etc.) that are\npreferred by the field. We hope our fellow researchers will use RB2 to improve\ntheir research's quality and rigor.",
    "descriptor": "\nComments: accepted at the NeurIPS 2021 Datasets and Benchmarks Track\n",
    "authors": [
      "Sudeep Dasari",
      "Jianren Wang",
      "Joyce Hong",
      "Shikhar Bahl",
      "Yixin Lin",
      "Austin Wang",
      "Abitha Thankaraj",
      "Karanbir Chahal",
      "Berk Calli",
      "Saurabh Gupta",
      "David Held",
      "Lerrel Pinto",
      "Deepak Pathak",
      "Vikash Kumar",
      "Abhinav Gupta"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08098"
  },
  {
    "id": "arXiv:2203.08101",
    "title": "ARTEMIS: Attention-based Retrieval with Text-Explicit Matching and  Implicit Similarity",
    "abstract": "An intuitive way to search for images is to use queries composed of an\nexample image and a complementary text. While the first provides rich and\nimplicit context for the search, the latter explicitly calls for new traits, or\nspecifies how some elements of the example image should be changed to retrieve\nthe desired target image. Current approaches typically combine the features of\neach of the two elements of the query into a single representation, which can\nthen be compared to the ones of the potential target images. Our work aims at\nshedding new light on the task by looking at it through the prism of two\nfamiliar and related frameworks: text-to-image and image-to-image retrieval.\nTaking inspiration from them, we exploit the specific relation of each query\nelement with the targeted image and derive light-weight attention mechanisms\nwhich enable to mediate between the two complementary modalities. We validate\nour approach on several retrieval benchmarks, querying with images and their\nassociated free-form text modifiers. Our method obtains state-of-the-art\nresults without resorting to side information, multi-level features, heavy\npre-training nor large architectures as in previous works.",
    "descriptor": "\nComments: Published in ICLR 2022\n",
    "authors": [
      "Ginger Delmas",
      "Rafael Sampaio de Rezende",
      "Gabriela Csurka",
      "Diane Larlus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.08101"
  },
  {
    "id": "arXiv:2203.08110",
    "title": "Topology optimization including a model of the layer by layer additive  manufacturing process",
    "abstract": "A topology optimization formulation including a model of the layer-by-layer\nadditive manufacturing (AM) process is considered. Defined as a multi-objective\nminimization problem, the formulation accounts for the performance and cost of\nboth the final and partially manufactured designs and allows for considering\nAM-related issues such as overhang and residual stresses in the optimization.\nThe formulation is exemplified by stiffness optimization in which the overhang\nis limited by adding mechanical or thermal compliance as a measure of the cost\nof partially manufactured designs. Convergence of the model as the approximate\nlayer-by-layer model is refined is shown theoretically, and an extensive\nnumerical study indicates that this convergence can be fast, thus making it a\ncomputationally viable approach useful for including AM-related issues into\ntopology optimization. The examples also show that drips and sharp corners\nassociated with some geometry-based formulations for overhang limitation can be\navoided. The codes used in this article are written in Python using only open\nsources libraries and are available for reference.",
    "descriptor": "",
    "authors": [
      "G.A. Haveroth",
      "C-J. Thore",
      "M.R. Correa",
      "R.F. Ausas",
      "S. Jakobsson",
      "J.A. Cuminato",
      "A. Klarbring"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08110"
  },
  {
    "id": "arXiv:2203.08111",
    "title": "Does Corpus Quality Really Matter for Low-Resource Languages?",
    "abstract": "The vast majority of non-English corpora are derived from automatically\nfiltered versions of CommonCrawl. While prior work has identified major issues\non the quality of these datasets (Kreutzer et al., 2021), it is not clear how\nthis impacts downstream performance. Taking Basque as a case study, we explore\ntailored crawling (manually identifying and scraping websites with high-quality\ncontent) as an alternative to filtering CommonCrawl. Our new corpus, called\nEusCrawl, is similar in size to the Basque portion of popular multilingual\ncorpora like CC100 and mC4, yet it has a much higher quality according to\nnative annotators. For instance, 66% of documents are rated as high-quality for\nEusCrawl, in contrast with <33% for both mC4 and CC100. Nevertheless, we obtain\nsimilar results on downstream tasks regardless of the corpus used for\npre-training. Our work suggests that NLU performance in low-resource languages\nis primarily constrained by the quantity rather than the quality of the data,\nprompting for methods to exploit more diverse data sources.",
    "descriptor": "",
    "authors": [
      "Mikel Artetxe",
      "Itziar Aldabe",
      "Rodrigo Agerri",
      "Olatz Perez-de-Vi\u00f1aspre",
      "Aitor Soroa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08111"
  },
  {
    "id": "arXiv:2203.08118",
    "title": "Representation Learning for Resource-Constrained Keyphrase Generation",
    "abstract": "State-of-the-art keyphrase generation methods generally depend on large\nannotated datasets, limiting their performance in domains with constrained\nresources. To overcome this challenge, we investigate strategies to learn an\nintermediate representation suitable for the keyphrase generation task. We\nintroduce salient span recovery and salient span prediction as guided denoising\nlanguage modeling objectives that condense the domain-specific knowledge\nessential for keyphrase generation. Through experiments on multiple scientific\nkeyphrase generation benchmarks, we show the effectiveness of the proposed\napproach for facilitating low-resource and zero-shot keyphrase generation.\nFurthermore, we observe that our method especially benefits the generation of\nabsent keyphrases, approaching the performance of SOTA methods trained with\nlarge training sets.",
    "descriptor": "",
    "authors": [
      "Di Wu",
      "Wasi Uddin Ahmad",
      "Sunipa Dev",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08118"
  },
  {
    "id": "arXiv:2203.08120",
    "title": "Deep Learning without Shortcuts: Shaping the Kernel with Tailored  Rectifiers",
    "abstract": "Training very deep neural networks is still an extremely challenging task.\nThe common solution is to use shortcut connections and normalization layers,\nwhich are both crucial ingredients in the popular ResNet architecture. However,\nthere is strong evidence to suggest that ResNets behave more like ensembles of\nshallower networks than truly deep ones. Recently, it was shown that deep\nvanilla networks (i.e. networks without normalization layers or shortcut\nconnections) can be trained as fast as ResNets by applying certain\ntransformations to their activation functions. However, this method (called\nDeep Kernel Shaping) isn't fully compatible with ReLUs, and produces networks\nthat overfit significantly more than ResNets on ImageNet. In this work, we\nrectify this situation by developing a new type of transformation that is fully\ncompatible with a variant of ReLUs -- Leaky ReLUs. We show in experiments that\nour method, which introduces negligible extra computational cost, achieves\nvalidation accuracies with deep vanilla networks that are competitive with\nResNets (of the same width/depth), and significantly higher than those obtained\nwith the Edge of Chaos (EOC) method. And unlike with EOC, the validation\naccuracies we obtain do not get worse with depth.",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Guodong Zhang",
      "Aleksandar Botev",
      "James Martens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08120"
  },
  {
    "id": "arXiv:2203.08122",
    "title": "From 2D to 3D: Re-thinking Benchmarking of Monocular Depth Prediction",
    "abstract": "There have been numerous recently proposed methods for monocular depth\nprediction (MDP) coupled with the equally rapid evolution of benchmarking\ntools. However, we argue that MDP is currently witnessing benchmark\nover-fitting and relying on metrics that are only partially helpful to gauge\nthe usefulness of the predictions for 3D applications. This limits the design\nand development of novel methods that are truly aware of - and improving\ntowards estimating - the 3D structure of the scene rather than optimizing\n2D-based distances. In this work, we aim to bring structural awareness to MDP,\nan inherently 3D task, by exhibiting the limits of evaluation metrics towards\nassessing the quality of the 3D geometry. We propose a set of metrics well\nsuited to evaluate the 3D geometry of MDP approaches and a novel indoor\nbenchmark, RIO-D3D, crucial for the proposed evaluation methodology. Our\nbenchmark is based on a real-world dataset featuring high-quality rendered\ndepth maps obtained from RGB-D reconstructions. We further demonstrate this to\nhelp benchmark the closely-tied task of 3D scene completion.",
    "descriptor": "",
    "authors": [
      "Evin P\u0131nar \u00d6rnek",
      "Shristi Mudgal",
      "Johanna Wald",
      "Yida Wang",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08122"
  },
  {
    "id": "arXiv:2203.08124",
    "title": "Can Neural Nets Learn the Same Model Twice? Investigating  Reproducibility and Double Descent from the Decision Boundary Perspective",
    "abstract": "We discuss methods for visualizing neural network decision boundaries and\ndecision regions. We use these visualizations to investigate issues related to\nreproducibility and generalization in neural network training. We observe that\nchanges in model architecture (and its associate inductive bias) cause visible\nchanges in decision boundaries, while multiple runs with the same architecture\nyield results with strong similarities, especially in the case of wide\narchitectures. We also use decision boundary methods to visualize double\ndescent phenomena. We see that decision boundary reproducibility depends\nstrongly on model width. Near the threshold of interpolation, neural network\ndecision boundaries become fragmented into many small decision regions, and\nthese regions are non-reproducible. Meanwhile, very narrows and very wide\nnetworks have high levels of reproducibility in their decision boundaries with\nrelatively few decision regions. We discuss how our observations relate to the\ntheory of double descent phenomena in convex models. Code is available at\nhttps://github.com/somepago/dbViz",
    "descriptor": "\nComments: To appear in CVPR 2022\n",
    "authors": [
      "Gowthami Somepalli",
      "Liam Fowl",
      "Arpit Bansal",
      "Ping Yeh-Chiang",
      "Yehuda Dar",
      "Richard Baraniuk",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08124"
  },
  {
    "id": "arXiv:2203.08130",
    "title": "One Network Doesn't Rule Them All: Moving Beyond Handcrafted  Architectures in Self-Supervised Learning",
    "abstract": "The current literature on self-supervised learning (SSL) focuses on\ndeveloping learning objectives to train neural networks more effectively on\nunlabeled data. The typical development process involves taking\nwell-established architectures, e.g., ResNet demonstrated on ImageNet, and\nusing them to evaluate newly developed objectives on downstream scenarios.\nWhile convenient, this does not take into account the role of architectures\nwhich has been shown to be crucial in the supervised learning literature. In\nthis work, we establish extensive empirical evidence showing that a network\narchitecture plays a significant role in SSL. We conduct a large-scale study\nwith over 100 variants of ResNet and MobileNet architectures and evaluate them\nacross 11 downstream scenarios in the SSL setting. We show that there is no one\nnetwork that performs consistently well across the scenarios. Based on this, we\npropose to learn not only network weights but also architecture topologies in\nthe SSL regime. We show that \"self-supervised architectures\" outperform popular\nhandcrafted architectures (ResNet18 and MobileNetV2) while performing\ncompetitively with the larger and computationally heavy ResNet50 on major image\nclassification benchmarks (ImageNet-1K, iNat2021, and more). Our results\nsuggest that it is time to consider moving beyond handcrafted architectures in\nSSL and start thinking about incorporating architecture search into\nself-supervised learning objectives.",
    "descriptor": "",
    "authors": [
      "Sharath Girish",
      "Debadeepta Dey",
      "Neel Joshi",
      "Vibhav Vineet",
      "Shital Shah",
      "Caio Cesar Teodoro Mendes",
      "Abhinav Shrivastava",
      "Yale Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08130"
  },
  {
    "id": "arXiv:2203.08133",
    "title": "Animatable Neural Implicit Surfaces for Creating Avatars from Videos",
    "abstract": "This paper aims to reconstruct an animatable human model from a video of very\nsparse camera views. Some recent works represent human geometry and appearance\nwith neural radiance fields and utilize parametric human models to produce\ndeformation fields for animation, which enables them to recover detailed 3D\nhuman models from videos. However, their reconstruction results tend to be\nnoisy due to the lack of surface constraints on radiance fields. Moreover, as\nthey generate the human appearance in 3D space, their rendering quality heavily\ndepends on the accuracy of deformation fields. To solve these problems, we\npropose Animatable Neural Implicit Surface (AniSDF), which models the human\ngeometry with a signed distance field and defers the appearance generation to\nthe 2D image space with a 2D neural renderer. The signed distance field\nnaturally regularizes the learned geometry, enabling the high-quality\nreconstruction of human bodies, which can be further used to improve the\nrendering speed. Moreover, the 2D neural renderer can be learned to compensate\nfor geometric errors, making the rendering more robust to inaccurate\ndeformations. Experiments on several datasets show that the proposed approach\noutperforms recent human reconstruction and synthesis methods by a large\nmargin.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Sida Peng",
      "Shangzhan Zhang",
      "Zhen Xu",
      "Chen Geng",
      "Boyi Jiang",
      "Hujun Bao",
      "Xiaowei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08133"
  },
  {
    "id": "arXiv:2203.08134",
    "title": "Privacy-Aware Compression for Federated Data Analysis",
    "abstract": "Federated data analytics is a framework for distributed data analysis where a\nserver compiles noisy responses from a group of distributed low-bandwidth user\ndevices to estimate aggregate statistics. Two major challenges in this\nframework are privacy, since user data is often sensitive, and compression,\nsince the user devices have low network bandwidth. Prior work has addressed\nthese challenges separately by combining standard compression algorithms with\nknown privacy mechanisms. In this work, we take a holistic look at the problem\nand design a family of privacy-aware compression mechanisms that work for any\ngiven communication budget. We first propose a mechanism for transmitting a\nsingle real number that has optimal variance under certain conditions. We then\nshow how to extend it to metric differential privacy for location privacy\nuse-cases, as well as vectors, for application to federated learning. Our\nexperiments illustrate that our mechanism can lead to better utility vs.\ncompression trade-offs for the same privacy loss in a number of settings.",
    "descriptor": "",
    "authors": [
      "Kamalika Chaudhuri",
      "Chuan Guo",
      "Mike Rabbat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08134"
  },
  {
    "id": "arXiv:2203.08138",
    "title": "CryoAI: Amortized Inference of Poses for Ab Initio Reconstruction of 3D  Molecular Volumes from Real Cryo-EM Images",
    "abstract": "Cryo-electron microscopy (cryo-EM) has become a tool of fundamental\nimportance in structural biology, helping us understand the basic building\nblocks of life. The algorithmic challenge of cryo-EM is to jointly estimate the\nunknown 3D poses and the 3D electron scattering potential of a biomolecule from\nmillions of extremely noisy 2D images. Existing reconstruction algorithms,\nhowever, cannot easily keep pace with the rapidly growing size of cryo-EM\ndatasets due to their high computational and memory cost. We introduce cryoAI,\nan ab initio reconstruction algorithm for homogeneous conformations that uses\ndirect gradient-based optimization of particle poses and the electron\nscattering potential from single-particle cryo-EM data. CryoAI combines a\nlearned encoder that predicts the poses of each particle image with a\nphysics-based decoder to aggregate each particle image into an implicit\nrepresentation of the scattering potential volume. This volume is stored in the\nFourier domain for computational efficiency and leverages a modern coordinate\nnetwork architecture for memory efficiency. Combined with a symmetrized loss\nfunction, this framework achieves results of a quality on par with\nstate-of-the-art cryo-EM solvers for both simulated and experimental data, one\norder of magnitude faster for large datasets and with significantly lower\nmemory requirements than existing methods.",
    "descriptor": "\nComments: 31 pages, 16 figures\n",
    "authors": [
      "Axel Levy",
      "Fr\u00e9d\u00e9ric Poitevin",
      "Julien Martel",
      "Youssef Nashed",
      "Ariana Peck",
      "Nina Miolane",
      "Daniel Ratner",
      "Mike Dunne",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2203.08138"
  },
  {
    "id": "arXiv:2203.08140",
    "title": "Learning Spatio-Temporal Downsampling for Effective Video Upscaling",
    "abstract": "Downsampling is one of the most basic image processing operations. Improper\nspatio-temporal downsampling applied on videos can cause aliasing issues such\nas moir\\'e patterns in space and the wagon-wheel effect in time. Consequently,\nthe inverse task of upscaling a low-resolution, low frame-rate video in space\nand time becomes a challenging ill-posed problem due to information loss and\naliasing artifacts. In this paper, we aim to solve the space-time aliasing\nproblem by learning a spatio-temporal downsampler. Towards this goal, we\npropose a neural network framework that jointly learns spatio-temporal\ndownsampling and upsampling. It enables the downsampler to retain the key\npatterns of the original video and maximizes the reconstruction performance of\nthe upsampler. To make the downsamping results compatible with popular image\nand video storage formats, the downsampling results are encoded to uint8 with a\ndifferentiable quantization layer. To fully utilize the space-time\ncorrespondences, we propose two novel modules for explicit temporal propagation\nand space-time feature rearrangement. Experimental results show that our\nproposed method significantly boosts the space-time reconstruction quality by\npreserving spatial textures and motion patterns in both downsampling and\nupscaling. Moreover, our framework enables a variety of applications, including\narbitrary video resampling, blurry frame reconstruction, and efficient video\nstorage.",
    "descriptor": "\nComments: Main paper: 13 pages, 8 figures; appendix: 8 pages, 10 figures\n",
    "authors": [
      "Xiaoyu Xiang",
      "Yapeng Tian",
      "Vijay Rengarajan",
      "Lucas Young",
      "Bo Zhu",
      "Rakesh Ranjan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.08140"
  },
  {
    "id": "arXiv:2203.08141",
    "title": "Object Manipulation via Visual Target Localization",
    "abstract": "Object manipulation is a critical skill required for Embodied AI agents\ninteracting with the world around them. Training agents to manipulate objects,\nposes many challenges. These include occlusion of the target object by the\nagent's arm, noisy object detection and localization, and the target frequently\ngoing out of view as the agent moves around in the scene. We propose\nManipulation via Visual Object Location Estimation (m-VOLE), an approach that\nexplores the environment in search for target objects, computes their 3D\ncoordinates once they are located, and then continues to estimate their 3D\nlocations even when the objects are not visible, thus robustly aiding the task\nof manipulating these objects throughout the episode. Our evaluations show a\nmassive 3x improvement in success rate over a model that has access to the same\nsensory suite but is trained without the object location estimator, and our\nanalysis shows that our agent is robust to noise in depth perception and agent\nlocalization. Importantly, our proposed approach relaxes several assumptions\nabout idealized localization and perception that are commonly employed by\nrecent works in embodied AI -- an important step towards training agents for\nobject manipulation in the real world.",
    "descriptor": "",
    "authors": [
      "Kiana Ehsani",
      "Ali Farhadi",
      "Aniruddha Kembhavi",
      "Roozbeh Mottaghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08141"
  },
  {
    "id": "arXiv:2007.02820",
    "title": "Predicting Porosity, Permeability, and Tortuosity of Porous Media from  Images by Deep Learning",
    "abstract": "Convolutional neural networks (CNN) are utilized to encode the relation\nbetween initial configurations of obstacles and three fundamental quantities in\nporous media: porosity ($\\varphi$), permeability $k$, and tortuosity ($T$). The\ntwo-dimensional systems with obstacles are considered. The fluid flow through a\nporous medium is simulated with the lattice Boltzmann method. It is\ndemonstrated that the CNNs are able to predict the porosity, permeability, and\ntortuosity with good accuracy. With the usage of the CNN models, the relation\nbetween $T$ and $\\varphi$ has been reproduced and compared with the empirical\nestimate. The analysis has been performed for the systems with $\\varphi \\in\n(0.37,0.99)$ which covers five orders of magnitude span for permeability $k \\in\n(0.78, 2.1\\times 10^5)$ and tortuosity $T \\in (1.03,2.74)$.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Krzysztof M. Graczyk",
      "Maciej Matyka"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.02820"
  },
  {
    "id": "arXiv:2203.06725",
    "title": "Network Bandwidth Allocation Problem For Cloud Computing",
    "abstract": "Cloud computing enables ubiquitous, convenient, and on-demand network access\nto a shared pool of computing resources. Cloud computing technologies create\ntremendous commercial values in various areas, while many scientific challenges\nhave arisen accordingly. The process of transmitting data through networks is\ncharacterized by some distinctive characteristics such as nonlinear, nonconvex\nand even noncontinuous cost functions generated by pricing schemes,\nperiodically updated network topology, as well as replicable data within\nnetwork nodes. Because of these characteristics, data transfer scheduling is a\nvery challenging problem both engineeringly and scientifically. On the other\nhand, the cost for bandwidth is a major component of the operating cost for\ncloud providers, and thus how to save bandwidth cost is extremely important for\nthem to supply service with minimized cost. We propose the Network Bandwidth\nAllocation (NBA) problem for cloud computing and formulate it as an integer\nprogramming model on a high level, with which more comprehensive and rigorous\nscientific studies become possible. We also show that the NBA problem captures\nsome of the major cloud computing scenarios including the content delivery\nnetwork (CDN), the live video delivery network (LVDN), the real-time\ncommunication network (RTCN), and the cloud wide area network (Cloud-WAN).",
    "descriptor": "\nComments: 28 pages, 4 figures\n",
    "authors": [
      "Changpeng Yang",
      "Jintao You",
      "Xiaoming Yuan",
      "Pengxiang Zhao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.06725"
  },
  {
    "id": "arXiv:2203.07373",
    "title": "SATr: Slice Attention with Transformer for Universal Lesion Detection",
    "abstract": "Universal Lesion Detection (ULD) in computed tomography plays an essential\nrole in computer-aided diagnosis. Promising ULD results have been reported by\nmulti-slice-input detection approaches which model 3D context from multiple\nadjacent CT slices, but such methods still experience difficulty in obtaining a\nglobal representation among different slices and within each individual slice\nsince they only use convolution-based fusion operations. In this paper, we\npropose a novel Slice Attention Transformer (SATr) block which can be easily\nplugged into convolution-based ULD backbones to form hybrid network structures.\nSuch newly formed hybrid backbones can better model long-distance feature\ndependency via the cascaded self-attention modules in the Transformer block\nwhile still holding a strong power of modeling local features with the\nconvolutional operations in the original backbone. Experiments with five\nstate-of-the-art methods show that the proposed SATr block can provide an\nalmost free boost to lesion detection accuracy without extra hyperparameters or\nspecial network designs.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Han Li",
      "Long Chen",
      "Hu Han",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07373"
  },
  {
    "id": "arXiv:2203.07378",
    "title": "Dawn of the transformer era in speech emotion recognition: closing the  valence gap",
    "abstract": "Recent advances in transformer-based architectures which are pre-trained in\nself-supervised manner have shown great promise in several machine learning\ntasks. In the audio domain, such architectures have also been successfully\nutilised in the field of speech emotion recognition (SER). However, existing\nworks have not evaluated the influence of model size and pre-training data on\ndownstream performance, and have shown limited attention to generalisation,\nrobustness, fairness, and efficiency. The present contribution conducts a\nthorough analysis of these aspects on several pre-trained variants of wav2vec\n2.0 and HuBERT that we fine-tuned on the dimensions arousal, dominance, and\nvalence of MSP-Podcast, while additionally using IEMOCAP and MOSI to test\ncross-corpus generalisation. To the best of our knowledge, we obtain the top\nperformance for valence prediction without use of explicit linguistic\ninformation, with a concordance correlation coefficient (CCC) of .638 on\nMSP-Podcast. Furthermore, our investigations reveal that transformer-based\narchitectures are more robust to small perturbations compared to a CNN-based\nbaseline and fair with respect to biological sex groups, but not towards\nindividual speakers. Finally, we are the first to show that their extraordinary\nsuccess on valence is based on implicit linguistic information learnt during\nfine-tuning of the transformer layers, which explains why they perform on-par\nwith recent multimodal approaches that explicitly utilise textual information.\nOur findings collectively paint the following picture: transformer-based\narchitectures constitute the new state-of-the-art in SER, but further advances\nare needed to mitigate remaining robustness and individual speaker issues. To\nmake our findings reproducible, we release the best performing model to the\ncommunity.",
    "descriptor": "",
    "authors": [
      "Johannes Wagner",
      "Andreas Triantafyllopoulos",
      "Hagen Wierstorf",
      "Maximilian Schmitt",
      "Florian Eyben",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.07378"
  },
  {
    "id": "arXiv:2203.07452",
    "title": "A deep learning pipeline for breast cancer ki-67 proliferation index  scoring",
    "abstract": "The Ki-67 proliferation index is an essential biomarker that helps\npathologists to diagnose and select appropriate treatments. However, automatic\nevaluation of Ki-67 is difficult due to nuclei overlapping and complex\nvariations in their properties. This paper proposes an integrated pipeline for\naccurate automatic counting of Ki-67, where the impact of nuclei separation\ntechniques is highlighted. First, semantic segmentation is performed by\ncombining the Squeez and Excitation Resnet and Unet algorithms to extract\nnuclei from the background. The extracted nuclei are then divided into\noverlapped and non-overlapped regions based on eight geometric and statistical\nfeatures. A marker-based Watershed algorithm is subsequently proposed and\napplied only to the overlapped regions to separate nuclei. Finally, deep\nfeatures are extracted from each nucleus patch using Resnet18 and classified\ninto positive or negative by a random forest classifier. The proposed\npipeline's performance is validated on a dataset from the Department of\nPathology at H\\^opital Nord Franche-Comt\\'e hospital.",
    "descriptor": "",
    "authors": [
      "Khaled Benaggoune",
      "Zeina Al Masry",
      "Jian Ma",
      "Christine Devalland",
      "L.H Mouss",
      "Noureddine Zerhouni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07452"
  },
  {
    "id": "arXiv:2203.07512",
    "title": "Don't fear the unlabelled: safe deep semi-supervised learning via simple  debiaising",
    "abstract": "Semi supervised learning (SSL) provides an effective means of leveraging\nunlabelled data to improve a model's performance. Even though the domain has\nreceived a considerable amount of attention in the past years, most methods\npresent the common drawback of being unsafe. By safeness we mean the quality of\nnot degrading a fully supervised model when including unlabelled data. Our\nstarting point is to notice that the estimate of the risk that most\ndiscriminative SSL methods minimise is biased, even asymptotically. This bias\nmakes these techniques untrustable without a proper validation set, but we\npropose a simple way of removing the bias. Our debiasing approach is\nstraightforward to implement, and applicable to most deep SSL methods. We\nprovide simple theoretical guarantees on the safeness of these modified\nmethods, without having to rely on the strong assumptions on the data\ndistribution that SSL theory usually requires. We evaluate debiased versions of\ndifferent existing SSL methods and show that debiasing can compete with classic\ndeep SSL techniques in various classic settings and even performs well when\ntraditional SSL fails.",
    "descriptor": "",
    "authors": [
      "Hugo Schmutz",
      "Olivier Humbert",
      "Pierre-Alexandre Mattei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.07512"
  },
  {
    "id": "arXiv:2203.07518",
    "title": "Erd\u0151s--Szekeres-type problems in the real projective plane",
    "abstract": "We consider point sets in the real projective plane $\\mathbb{R}\\mathcal{P}^2$\nand explore variants of classical extremal problems about planar point sets in\nthis setting, with a main focus on Erd\\H{o}s--Szekeres-type problems.\nWe provide asymptotically tight bounds for a variant of the\nErd\\H{o}s--Szekeres theorem about point sets in convex position in\n$\\mathbb{R}\\mathcal{P}^2$, which was initiated by Harborth and M\\\"oller in\n1994. The notion of convex position in $\\mathbb{R}\\mathcal{P}^2$ agrees with\nthe definition of convex sets introduced by Steinitz in 1913.\nFor $k \\geq 3$, an (affine) $k$-hole in a finite set $S \\subseteq\n\\mathbb{R}^2$ is a set of $k$ points from $S$ in convex position with no point\nof $S$ in the interior of their convex hull. After introducing a new notion of\n$k$-holes for points sets from $\\mathbb{R}\\mathcal{P}^2$, called projective\n$k$-holes, we find arbitrarily large finite sets of points from\n$\\mathbb{R}\\mathcal{P}^2$ with no projective 8-holes, providing an analogue of\na classical result by Horton from 1983. We also prove that they contain only\nquadratically many projective $k$-holes for $k \\leq 7$. On the other hand, we\nshow that the number of $k$-holes can be substantially larger in\n$\\mathbb{R}\\mathcal{P}^2$ than in $\\mathbb{R}^2$ by constructing, for every $k\n\\in \\{3,\\dots,6\\}$, sets of $n$ points from $\\mathbb{R}^2 \\subset\n\\mathbb{R}\\mathcal{P}^2$ with $\\Omega(n^{3-3/5k})$ projective $k$-holes and\nonly $O(n^2)$ affine $k$-holes. Last but not least, we prove several other\nresults, for example about projective holes in random point sets in\n$\\mathbb{R}\\mathcal{P}^2$ and about some algorithmic aspects.\nThe study of extremal problems about point sets in $\\mathbb{R}\\mathcal{P}^2$\nopens a new area of research, which we support by posing several open problems.",
    "descriptor": "\nComments: To appear at the 38th International Symposium on Computational Geometry (SoCG 2022)\n",
    "authors": [
      "Martin Balko",
      "Manfred Scheucher",
      "Pavel Valtr"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.07518"
  },
  {
    "id": "arXiv:2203.07537",
    "title": "Denoising and feature extraction in photoemission spectra with  variational auto-encoder neural networks",
    "abstract": "In recent years, distinct machine learning (ML) models have been separately\nused for feature extraction and noise reduction from energy-momentum dispersion\nintensity maps obtained from raw angle-resolved photoemission spectroscopy\n(ARPES) data. In this work, we employ a shallow variational auto-encoder (VAE)\nneural network to demonstrate the prospect of using ML for both denoising of as\nwell as feature extraction from ARPES dispersion maps.",
    "descriptor": "\nComments: Submitted to Review of Scientific Instruments\n",
    "authors": [
      "Francisco Restrepo",
      "Junjing Zhao",
      "Utpal Chatterjee"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07537"
  },
  {
    "id": "arXiv:2203.07542",
    "title": "Neural Network Solver for Coherent Synchrotron Radiation Wakefield  Calculations in Accelerator-based Charged Particle Beams",
    "abstract": "Particle accelerators support a wide array of scientific, industrial, and\nmedical applications. To meet the needs of these applications, accelerator\nphysicists rely heavily on detailed simulations of the complicated particle\nbeam dynamics through the accelerator. One of the most computationally\nexpensive and difficult-to-model effects is the impact of Coherent Synchrotron\nRadiation (CSR). As a beam travels through a curved trajectory (e.g. due to a\nbending magnet), it emits radiation that in turn interacts with the rest of the\nbeam. At each step through the trajectory, the electromagnetic field introduced\nby CSR (called the CSR wakefield) needs to computed and used when calculating\nthe updates to the positions and momenta of every particle in the beam. CSR is\none of the major drivers of growth in the beam emittance, which is a key metric\nof beam quality that is critical in many applications. The CSR wakefield is\nvery computationally intensive to compute with traditional electromagnetic\nsolvers, and this is a major limitation in accurately simulating accelerators.\nHere, we demonstrate a new approach for the CSR wakefield computation using a\nneural network solver structured in a way that is readily generalizable to new\nsetups. We validate its performance by adding it to a standard beam tracking\ntest problem and show a ten-fold speedup along with high accuracy.",
    "descriptor": "",
    "authors": [
      "Auralee Edelen",
      "Christopher Mayes"
    ],
    "subjectives": [
      "Accelerator Physics (physics.acc-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.07542"
  },
  {
    "id": "arXiv:2203.07546",
    "title": "Permutation Invariant Representations with Applications to Graph Deep  Learning",
    "abstract": "This paper presents primarily two Euclidean embeddings of the quotient space\ngenerated by matrices that are identified modulo arbitrary row permutations.\nThe original application is in deep learning on graphs where the learning task\nis invariant to node relabeling. Two embedding schemes are introduced, one\nbased on sorting and the other based on algebras of multivariate polynomials.\nWhile both embeddings exhibit a computational complexity exponential in problem\nsize, the sorting based embedding is globally bi-Lipschitz and admits a low\ndimensional target space. Additionally, an almost everywhere injective scheme\ncan be implemented with minimal redundancy and low computational cost. In turn,\nthis proves that almost any classifier can be implemented with an arbitrary\nsmall loss of performance. Numerical experiments are carried out on two data\nsets, a chemical compound data set (QM9) and a proteins data set (PROTEINS).",
    "descriptor": "\nComments: 43 pages, 13 figures, 16 tables\n",
    "authors": [
      "Radu Balan",
      "Naveed Haghani",
      "Maneesh Singh"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07546"
  },
  {
    "id": "arXiv:2203.07555",
    "title": "Resilience of Input Metering in Dynamic Flow Networks",
    "abstract": "In this paper, we study robustness of input metering policies in dynamic flow\nnetworks in the presence of transient disturbances and attacks. We consider a\ncompartmental model for dynamic flow networks with a First-In-First-Out (FIFO)\nrouting rule as found in, e.g., transportation networks. We model the effect of\nthe transient disturbance as an abrupt change to the state of the network and\nuse the notion of the region of attraction to measure the resilience of the\nnetwork to these changes. For constant and periodic input metering, we\nintroduce the notion of monotone-invariant points to establish inner-estimates\nfor the regions of attraction of free-flow equilibrium points and free-flow\nperiodic orbits using monotone systems theory. These results are applicable to,\ne.g., networks with cycles, which have not been considered in prior literature\non dynamic flow networks with FIFO routing. Finally, we propose two approaches\nfor finding suitable monotone-invariant points in the flow networks with FIFO\nrules.",
    "descriptor": "",
    "authors": [
      "Saber Jafarpour",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.07555"
  },
  {
    "id": "arXiv:2203.07573",
    "title": "Thermodynamic engine powered by anisotropic fluctuations",
    "abstract": "The purpose of this work is to present the concept of an autonomous\nStirling-like engine powered by anisotropy of thermodynamic fluctuations.\nSpecifically, simultaneous contact of a thermodynamic system with two heat\nbaths along coupled degrees of freedom generates torque and circulatory\ncurrents -- an arrangement referred to as a Brownian gyrator. The embodiment\nthat constitutes the engine includes an inertial wheel to sustain rotary motion\nand average out the generated fluctuating torque, ultimately delivering power\nto an external load. We detail an electrical model for such an engine that\nconsists of two resistors in different temperatures and three reactive elements\nin the form of variable capacitors. The resistors generate Johnson-Nyquist\ncurrent fluctuations that power the engine, while the capacitors generate\ndriving forces via a coupling of their dielectric material with the inertial\nwheel. A proof-of-concept is established via stability analysis to ensure the\nexistence of a stable periodic orbit generating sustained power output. We\nconclude by drawing a connection to the dynamics of a damped pendulum with\nconstant torque and to those of a macroscopic Stirling engine. The sought\ninsights aim at nano-engines and biological processes that are similarly\npowered by anisotropy in temperature and chemical potentials.",
    "descriptor": "\nComments: 6 pages, 6 figures, 1 table\n",
    "authors": [
      "Olga Movilla Miangolarra",
      "Amirhossein Taghvaei",
      "Yongxin Chen",
      "Tryphon T. Georgiou"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Systems and Control (eess.SY)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.07573"
  },
  {
    "id": "arXiv:2203.07574",
    "title": "Time-series image denoising of pressure-sensitive paint data by  projected multivariate singular spectrum analysis",
    "abstract": "Time-series data, such as unsteady pressure-sensitive paint (PSP) measurement\ndata, may contain a significant amount of random noise. Thus, in this study, we\ninvestigated a noise-reduction method that combines multivariate singular\nspectrum analysis (MSSA) with low-dimensional data representation. MSSA is a\nstate-space reconstruction technique that utilizes time-delay embedding, and\nthe low-dimensional representation is achieved by projecting data onto the\nsingular value decomposition (SVD) basis. The noise-reduction performance of\nthe proposed method for unsteady PSP data, i.e., the projected MSSA, is\ncompared with that of the truncated SVD method, one of the most employed\nnoise-reduction methods. The result shows that the projected MSSA exhibits\nbetter performance in reducing random noise than the truncated SVD method.\nAdditionally, in contrast to that of the truncated SVD method, the performance\nof the projected MSSA is less sensitive to the truncation rank. Furthermore,\nthe projected MSSA achieves denoising effectively by extracting smooth\ntrajectories in a state space from noisy input data. Expectedly, the projected\nMSSA will be effective for reducing random noise in not only PSP measurement\ndata, but also various high-dimensional time-series data.",
    "descriptor": "\nComments: 15 pages, 12 figures\n",
    "authors": [
      "Yuya Ohmichi",
      "Kohmi Takahashi",
      "Kazuyuki Nakakita"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2203.07574"
  },
  {
    "id": "arXiv:2203.07620",
    "title": "Innovations in trigger and data acquisition systems for next-generation  physics facilities",
    "abstract": "Data-intensive physics facilities are increasingly reliant on heterogeneous\nand large-scale data processing and computational systems in order to collect,\ndistribute, process, filter, and analyze the ever increasing huge volumes of\ndata being collected. Moreover, these tasks are often performed in hard\nreal-time or quasi real-time processing pipelines that place extreme\nconstraints on various parameters and design choices for those systems.\nConsequently, a large number and variety of challenges are faced to design,\nconstruct, and operate such facilities. This is especially true at the energy\nand intensity frontiers of particle physics where bandwidths of raw data can\nexceed 100 Tb/s of heterogeneous, high-dimensional data sourced from >300M\nindividual sensors. Data filtering and compression algorithms deployed at these\nfacilities often operate at the level of 1 part in $10^5$, and once executed,\nthese algorithms drive the data curation process, further highlighting the\ncritical roles that these systems have in the physics impact of those\nendeavors. This White Paper aims to highlight the challenges that these\nfacilities face in the design of the trigger and data acquisition\ninstrumentation and systems, as well as in their installation, commissioning,\nintegration and operation, and in building the domain knowledge and technical\nexpertise required to do so.",
    "descriptor": "\nComments: Contribution to Snowmass 2021\n",
    "authors": [
      "Rainer Bartoldus",
      "Catrin Bernius",
      "David W. Miller"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2203.07620"
  },
  {
    "id": "arXiv:2203.07639",
    "title": "Fast and Accurate Linear Fitting for Incompletely Sampled Gaussian  Function With a Long Tail",
    "abstract": "Fitting experiment data onto a curve is a common signal processing technique\nto extract data features and establish the relationship between variables.\nOften, we expect the curve to comply with some analytical function and then\nturn data fitting into estimating the unknown parameters of a function. Among\nanalytical functions for data fitting, Gaussian function is the most widely\nused one due to its extensive applications in numerous science and engineering\nfields. To name just a few, Gaussian function is highly popular in statistical\nsignal processing and analysis, thanks to the central limit theorem [1];\nGaussian function frequently appears in the quantum harmonic oscillator,\nquantum field theory, optics, lasers, and many other theories and models in\nPhysics [2]; moreover, Gaussian function is widely applied in chemistry for\ndepicting molecular orbitals, in computer science for imaging processing and in\nartificial intelligence for defining neural networks.",
    "descriptor": "\nComments: 7 pages; 3 figures; 2 tabkes; submitted to IEEE journal for possible publiacation. Simulation codes can be downloaded from the link provided in the paper. Should you use the codes in any way, please cite this work. Thanks for your interest\n",
    "authors": [
      "Kai Wu",
      "J. Andrew Zhang",
      "Y. Jay Guo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2203.07639"
  },
  {
    "id": "arXiv:2203.07655",
    "title": "Joint Time-Vertex Fractional Fourier Transform",
    "abstract": "Graphs signal processing successfully captures high-dimensional data on\nnon-Euclidean domains by using graph signals defined on graph vertices.\nHowever, data sources on each vertex can also continually provide time-series\nsignals such that graph signals on each vertex are now time-series signals.\nJoint time-vertex Fourier transform (JFT) and the associated framework of\ntime-vertex signal processing enable us to study such signals defined on joint\ntime-vertex domains by providing spectral analysis. Just as the fractional\nFourier transform (FRT) generalizes the ordinary Fourier transform (FT), we\npropose the joint time-vertex fractional Fourier transform (JFRT) as a\ngeneralization to the JFT. JFRT provides an additional fractional analysis tool\nfor joint time-vertex processing by extending both temporal and vertex domain\nFourier analysis to fractional orders. We theoretically show that the proposed\nJFRT generalizes the JFT and satisfies the properties of index additivity,\nreversibility, reduction to identity, and unitarity (for certain graph\ntopologies). We provide theoretical derivations for JFRT-based denoising as\nwell as computational cost analysis. Results of numerical experiments are also\npresented to demonstrate the benefits of JFRT.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "B\u00fcnyamin Kartal",
      "Eray \u00d6zg\u00fcnay",
      "Aykut Ko\u00e7"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.07655"
  },
  {
    "id": "arXiv:2203.07659",
    "title": "Breast Cancer Molecular Subtypes Prediction on Pathological Images with  Discriminative Patch Selecting and Multi-Instance Learning",
    "abstract": "Molecular subtypes of breast cancer are important references to personalized\nclinical treatment. For cost and labor savings, only one of the patient's\nparaffin blocks is usually selected for subsequent immunohistochemistry (IHC)\nto obtain molecular subtypes. Inevitable sampling error is risky due to tumor\nheterogeneity and could result in a delay in treatment. Molecular subtype\nprediction from conventional H&E pathological whole slide images (WSI) using AI\nmethod is useful and critical to assist pathologists pre-screen proper paraffin\nblock for IHC. It's a challenging task since only WSI level labels of molecular\nsubtypes can be obtained from IHC. Gigapixel WSIs are divided into a huge\nnumber of patches to be computationally feasible for deep learning. While with\ncoarse slide-level labels, patch-based methods may suffer from abundant noise\npatches, such as folds, overstained regions, or non-tumor tissues. A weakly\nsupervised learning framework based on discriminative patch selecting and\nmulti-instance learning was proposed for breast cancer molecular subtype\nprediction from H&E WSIs. Firstly, co-teaching strategy was adopted to learn\nmolecular subtype representations and filter out noise patches. Then, a\nbalanced sampling strategy was used to handle the imbalance in subtypes in the\ndataset. In addition, a noise patch filtering algorithm that used local outlier\nfactor based on cluster centers was proposed to further select discriminative\npatches. Finally, a loss function integrating patch with slide constraint\ninformation was used to finetune MIL framework on obtained discriminative\npatches and further improve the performance of molecular subtyping. The\nexperimental results confirmed the effectiveness of the proposed method and our\nmodels outperformed even senior pathologists, with potential to assist\npathologists to pre-screen paraffin blocks for IHC in clinic.",
    "descriptor": "",
    "authors": [
      "Hong Liu",
      "Wen-Dong Xu",
      "Zi-Hao Shang",
      "Xiang-Dong Wang",
      "Hai-Yan Zhou",
      "Ke-Wen Ma",
      "Huan Zhou",
      "Jia-Lin Qi",
      "Jia-Rui Jiang",
      "Li-Lan Tan",
      "Hui-Min Zeng",
      "Hui-Juan Cai",
      "Kuan-Song Wang",
      "Yue-Liang Qian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07659"
  },
  {
    "id": "arXiv:2203.07672",
    "title": "On the Advances and Challenges of Adaptive Online Testing",
    "abstract": "In recent years, the interest in developing adaptive solutions for online\ntesting has grown significantly in the industry. While the advances related to\nthis relative new technology have been developed in multiple domains, it lacks\nin the literature a systematic and complete treatment of the procedure that\ninvolves exploration, inference, and analysis. This short paper aims to develop\na comprehensive understanding of adaptive online testing, including various\nbuilding blocks and analytical results. We also address the latest\ndevelopments, research directions, and challenges that have been less mentioned\nin the literature.",
    "descriptor": "",
    "authors": [
      "Da Xu",
      "Bo Yang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.07672"
  },
  {
    "id": "arXiv:2203.07677",
    "title": "Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning",
    "abstract": "We present an effective unpaired learning based image dehazing network from\nan unpaired set of clear and hazy images. This paper provides a new perspective\nto treat image dehazing as a two-class separated factor disentanglement task,\ni.e, the task-relevant factor of clear image reconstruction and the\ntask-irrelevant factor of haze-relevant distribution. To achieve the\ndisentanglement of these two-class factors in deep feature space, contrastive\nlearning is introduced into a CycleGAN framework to learn disentangled\nrepresentations by guiding the generated images to be associated with latent\nfactors. With such formulation, the proposed contrastive disentangled dehazing\nmethod (CDD-GAN) first develops negative generators to cooperate with the\nencoder network to update alternately, so as to produce a queue of challenging\nnegative adversaries. Then these negative adversaries are trained end-to-end\ntogether with the backbone representation network to enhance the discriminative\ninformation and promote factor disentanglement performance by maximizing the\nadversarial contrastive loss. During the training, we further show that hard\nnegative examples can suppress the task-irrelevant factors and unpaired clear\nexemples can enhance the task-relevant factors, in order to better facilitate\nhaze removal and help image restoration. Extensive experiments on both\nsynthetic and real-world datasets demonstrate that our method performs\nfavorably against existing state-of-the-art unpaired dehazing approaches.",
    "descriptor": "",
    "authors": [
      "Xiang Chen",
      "Zhentao Fan",
      "Zhuoran Zheng",
      "Yufeng Li",
      "Yufeng Huang",
      "Longgang Dai",
      "Caihua Kong",
      "Pengpeng Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07677"
  },
  {
    "id": "arXiv:2203.07707",
    "title": "Magnification Prior: A Self-Supervised Method for Learning  Representations on Breast Cancer Histopathological Images",
    "abstract": "This work presents a novel self-supervised pre-training method to learn\nefficient representations without labels on histopathology medical images\nutilizing magnification factors. Other state-of-theart works mainly focus on\nfully supervised learning approaches that rely heavily on human annotations.\nHowever, the scarcity of labeled and unlabeled data is a long-standing\nchallenge in histopathology. Currently, representation learning without labels\nremains unexplored for the histopathology domain. The proposed method,\nMagnification Prior Contrastive Similarity (MPCS), enables self-supervised\nlearning of representations without labels on small-scale breast cancer dataset\nBreakHis by exploiting magnification factor, inductive transfer, and reducing\nhuman prior. The proposed method matches fully supervised learning\nstate-of-the-art performance in malignancy classification when only 20% of\nlabels are used in fine-tuning and outperform previous works in fully\nsupervised learning settings. It formulates a hypothesis and provides empirical\nevidence to support that reducing human-prior leads to efficient representation\nlearning in self-supervision. The implementation of this work is available\nonline on GitHub -\nhttps://github.com/prakashchhipa/Magnification-Prior-Self-Supervised-Method",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Prakash Chandra Chhipa",
      "Richa Upadhyay",
      "Gustav Grund Pihlgren",
      "Rajkumar Saini",
      "Seiichi Uchida",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07707"
  },
  {
    "id": "arXiv:2203.07728",
    "title": "Securing the Classification of COVID-19 in Chest X-ray Images: A  Privacy-Preserving Deep Learning Approach",
    "abstract": "Deep learning (DL) is being increasingly utilized in healthcare-related\nfields due to its outstanding efficiency. However, we have to keep the\nindividual health data used by DL models private and secure. Protecting data\nand preserving the privacy of individuals has become an increasingly prevalent\nissue. The gap between the DL and privacy communities must be bridged. In this\npaper, we propose privacy-preserving deep learning (PPDL)-based approach to\nsecure the classification of Chest X-ray images. This study aims to use Chest\nX-ray images to their fullest potential without compromising the privacy of the\ndata that it contains. The proposed approach is based on two steps: encrypting\nthe dataset using partially homomorphic encryption and training/testing the DL\nalgorithm over the encrypted images. Experimental results on the COVID-19\nRadiography database show that the MobileNetV2 model achieves an accuracy of\n94.2% over the plain data and 93.3% over the encrypted data.",
    "descriptor": "",
    "authors": [
      "Wadii Boulila",
      "Adel Ammar",
      "Bilel Benjdira",
      "Anis Koubaa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07728"
  },
  {
    "id": "arXiv:2203.07746",
    "title": "Stress-testing the Resilience of the Austrian Healthcare System Using  Agent-Based Simulation",
    "abstract": "Patients do not access physicians at random but rather via naturally emerging\nnetworks of patient flows between them. As retirements, mass quarantines and\nabsence due to sickness during pandemics, or other shocks thin out these\nnetworks, the system might be pushed closer to a tipping point where it loses\nits ability to deliver care to the population. Here we propose a data-driven\nframework to quantify the regional resilience to such shocks of primary and\nsecondary care in Austria via an agent-based model. For each region and medical\nspecialty we construct detailed patient-sharing networks from administrative\ndata and stress-test these networks by removing increasing numbers of\nphysicians from the system. This allows us to measure regional resilience\nindicators describing how many physicians can be removed from a certain area\nbefore individual patients won't be treated anymore. We find that such tipping\npoints do indeed exist and that regions and medical specialties differ\nsubstantially in their resilience. These systemic differences can be related to\nindicators for individual physicians by quantifying how much their hypothetical\nremoval would stress the system (risk score) or how much of the stress from the\nremoval of other physicians they would be able to absorb (benefit score). Our\nstress-testing framework could enable health authorities to rapidly identify\nbottlenecks in access to care as well as to inspect these naturally emerging\nphysician networks and how potential absences would impact them.",
    "descriptor": "\nComments: See also the dashboard under this https URL\n",
    "authors": [
      "Michaela Kaleta",
      "Jana Lasser",
      "Elma Dervic",
      "Liuhuaying Yang",
      "Johannes Sorger",
      "Ruggiero Lo Sardo",
      "Stefan Thurner",
      "Alexandra Kautzky-Willer",
      "Peter Klimek"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.07746"
  },
  {
    "id": "arXiv:2203.07752",
    "title": "Optimal denoising of rotationally invariant rectangular matrices",
    "abstract": "In this manuscript we consider denoising of large rectangular matrices: given\na noisy observation of a signal matrix, what is the best way of recovering the\nsignal matrix itself? For Gaussian noise and rotationally-invariant signal\npriors, we completely characterize the optimal denoiser and its performance in\nthe high-dimensional limit, in which the size of the signal matrix goes to\ninfinity with fixed aspects ratio, and under the Bayes optimal setting, that is\nwhen the statistician knows how the signal and the observations were generated.\nOur results generalise previous works that considered only symmetric matrices\nto the more general case of non-symmetric and rectangular ones. We explore\nanalytically and numerically a particular choice of factorized signal prior\nthat models cross-covariance matrices and the matrix factorization problem. As\na byproduct of our analysis, we provide an explicit asymptotic evaluation of\nthe rectangular Harish-Chandra-Itzykson-Zuber integral in a special case.",
    "descriptor": "",
    "authors": [
      "Emanuele Troiani",
      "Vittorio Erba",
      "Florent Krzakala",
      "Antoine Maillard",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.07752"
  },
  {
    "id": "arXiv:2203.07755",
    "title": "Generative models and Bayesian inversion using Laplace approximation",
    "abstract": "The Bayesian approach to solving inverse problems relies on the choice of a\nprior. This critical ingredient allows the formulation of expert knowledge or\nphysical constraints in a probabilistic fashion and plays an important role for\nthe success of the inference. Recently, Bayesian inverse problems were solved\nusing generative models as highly informative priors. Generative models are a\npopular tool in machine learning to generate data whose properties closely\nresemble those of a given database. Typically, the generated distribution of\ndata is embedded in a low-dimensional manifold. For the inverse problem, a\ngenerative model is trained on a database that reflects the properties of the\nsought solution, such as typical structures of the tissue in the human brain in\nmagnetic resonance (MR) imaging. The inference is carried out in the\nlow-dimensional manifold determined by the generative model which strongly\nreduces the dimensionality of the inverse problem. However, this proceeding\nproduces a posterior that admits no Lebesgue density in the actual variables\nand the accuracy reached can strongly depend on the quality of the generative\nmodel. For linear Gaussian models we explore an alternative Bayesian inference\nbased on probabilistic generative models which is carried out in the original\nhigh-dimensional space. A Laplace approximation is employed to analytically\nderive the required prior probability density function induced by the\ngenerative model. Properties of the resulting inference are investigated.\nSpecifically, we show that derived Bayes estimates are consistent, in contrast\nto the approach employing the low-dimensional manifold of the generative model.\nThe MNIST data set is used to construct numerical experiments which confirm our\ntheoretical findings.",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Manuel Marschall",
      "Gerd W\u00fcbbeler",
      "Franko Schm\u00e4hling",
      "Clemens Elster"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2203.07755"
  },
  {
    "id": "arXiv:2203.07771",
    "title": "Optimal mixing for two-state anti-ferromagnetic spin systems",
    "abstract": "We prove an optimal $\\Omega(n^{-1})$ lower bound for modified log-Sobolev\n(MLS) constant of the Glauber dynamics for anti-ferromagnetic two-spin systems\nwith $n$ vertices in the tree uniqueness regime. Specifically, this optimal MLS\nbound holds for the following classes of two-spin systems in the tree\nuniqueness regime:\n$\\bullet$ all strictly anti-ferromagnetic two-spin systems (where both edge\nparameters $\\beta,\\gamma<1$), which cover the hardcore models and the\nanti-ferromagnetic Ising models;\n$\\bullet$ general anti-ferromagnetic two-spin systems on regular graphs.\nConsequently, an optimal $O(n\\log n)$ mixing time holds for these\nanti-ferromagnetic two-spin systems when the uniqueness condition is satisfied.\nThese MLS and mixing time bounds hold for any bounded or unbounded maximum\ndegree, and the constant factors in the bounds depend only on the gap to the\nuniqueness threshold. We prove this by showing a boosting theorem for MLS\nconstant for distributions satisfying certain spectral independence and\nmarginal stability properties.",
    "descriptor": "",
    "authors": [
      "Xiaoyu Chen",
      "Weiming Feng",
      "Yitong Yin",
      "Xinyuan Zhang"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.07771"
  },
  {
    "id": "arXiv:2203.07772",
    "title": "Fast Autofocusing using Tiny Networks for Digital Holographic Microscopy",
    "abstract": "The numerical wavefront backpropagation principle of digital holography\nconfers unique extended focus capabilities, without mechanical displacements\nalong z-axis. However, the determination of the correct focusing distance is a\nnon-trivial and time consuming issue. A deep learning (DL) solution is proposed\nto cast the autofocusing as a regression problem and tested over both\nexperimental and simulated holograms. Single wavelength digital holograms were\nrecorded by a Digital Holographic Microscope (DHM) with a 10$\\mathrm{x}$\nmicroscope objective from a patterned target moving in 3D over an axial range\nof 92 $\\mu$m. Tiny DL models are proposed and compared such as a tiny Vision\nTransformer (TViT), tiny VGG16 (TVGG) and a tiny Swin-Transfomer (TSwinT). The\nexperiments show that the predicted focusing distance $Z_R^{\\mathrm{Pred}}$ is\naccurately inferred with an accuracy of 1.2 $\\mu$m in average in comparison\nwith the DHM depth of field of 15 $\\mu$m. Numerical simulations show that all\ntiny models give the $Z_R^{\\mathrm{Pred}}$ with an error below 0.3 $\\mu$m. Such\na prospect would significantly improve the current capabilities of computer\nvision position sensing in applications such as 3D microscopy for life sciences\nor micro-robotics. Moreover, all models reach state of the art inference time\non CPU, less than 25 ms per inference.",
    "descriptor": "",
    "authors": [
      "St\u00e9phane Cuenat",
      "Louis Andr\u00e9oli",
      "Antoine N. Andr\u00e9",
      "Patrick Sandoz",
      "Guillaume J. Laurent",
      "Rapha\u00ebl Couturier",
      "Maxime Jacquot"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2203.07772"
  },
  {
    "id": "arXiv:2203.07798",
    "title": "Igeood: An Information Geometry Approach to Out-of-Distribution  Detection",
    "abstract": "Reliable out-of-distribution (OOD) detection is fundamental to implementing\nsafer modern machine learning (ML) systems. In this paper, we introduce Igeood,\nan effective method for detecting OOD samples. Igeood applies to any\npre-trained neural network, works under various degrees of access to the ML\nmodel, does not require OOD samples or assumptions on the OOD data but can also\nbenefit (if available) from OOD samples. By building on the geodesic\n(Fisher-Rao) distance between the underlying data distributions, our\ndiscriminator can combine confidence scores from the logits outputs and the\nlearned features of a deep neural network. Empirically, we show that Igeood\noutperforms competing state-of-the-art methods on a variety of network\narchitectures and datasets.",
    "descriptor": "\nComments: Accepted in ICLR 2022\n",
    "authors": [
      "Eduardo Dadalto Camara Gomes",
      "Florence Alberge",
      "Pierre Duhamel",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07798"
  },
  {
    "id": "arXiv:2203.07803",
    "title": "A negative binomial approximation in group testing",
    "abstract": "We consider the problem of group testing (pooled testing), first introduced\nby Dorfman. For non-adaptive testing strategies, we refer to a non-defective\nitem as `intruding' if it only appears in positive tests. Such items cause\nmis-classification errors in the well-known COMP algorithm, and can make other\nalgorithms produce an error. It is therefore of interest to understand the\ndistribution of the number of intruding items. We show that, under Bernoulli\nmatrix designs, this distribution is well approximated in a variety of senses\nby a negative binomial distribution, allowing us to understand the performance\nof the two-stage conservative group testing algorithm of Aldridge.",
    "descriptor": "",
    "authors": [
      "Letian Yu",
      "Fraser Daly",
      "Oliver Johnson"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2203.07803"
  },
  {
    "id": "arXiv:2203.07809",
    "title": "Image Quality Assessment for Magnetic Resonance Imaging",
    "abstract": "Image quality assessment (IQA) algorithms aim to reproduce the human's\nperception of the image quality. The growing popularity of image enhancement,\ngeneration, and recovery models instigated the development of many methods to\nassess their performance. However, most IQA solutions are designed to predict\nimage quality in the general domain, with the applicability to specific areas,\nsuch as medical imaging, remaining questionable. Moreover, the selection of\nthese IQA metrics for a specific task typically involves intentionally induced\ndistortions, such as manually added noise or artificial blurring; yet, the\nchosen metrics are then used to judge the output of real-life computer vision\nmodels. In this work, we aspire to fill these gaps by carrying out the most\nextensive IQA evaluation study for Magnetic Resonance Imaging (MRI) to date\n(14,700 subjective scores). We use outputs of neural network models trained to\nsolve problems relevant to MRI, including image reconstruction in the scan\nacceleration, motion correction, and denoising. Seven trained radiologists\nassess these distorted images, with their verdicts then correlated with 35\ndifferent image quality metrics (full-reference, no-reference, and\ndistribution-based metrics considered). Our emphasis is on reflecting the\nradiologist's perception of the reconstructed images, gauging the most\ndiagnostically influential criteria for the quality of MRI scans:\nsignal-to-noise ratio, contrast-to-noise ratio, and the presence of artifacts.",
    "descriptor": "\nComments: 10 pages, 7 figures, under review in IEEE TMI\n",
    "authors": [
      "Segrey Kastryulin",
      "Jamil Zakirov",
      "Nicola Pezzotti",
      "Dmitry V. Dylov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07809"
  },
  {
    "id": "arXiv:2203.07826",
    "title": "Discrete approximations to Dirac operators and norm resolvent  convergence",
    "abstract": "We consider continuous Dirac operators defined on $\\mathbf{R}^d$,\n$d\\in\\{1,2,3\\}$, together with various discrete versions of them. Both\nforward-backward and symmetric finite differences are used as approximations to\npartial derivatives. We also allow a bounded, H\\\"older continuous, and\nself-adjoint matrix-valued potential, which in the discrete setting is\nevaluated on the mesh.\nOur main goal is to investigate whether the proposed discrete models converge\nin norm resolvent sense to their continuous counterparts, as the mesh size\ntends to zero and up to a natural embedding of the discrete space into the\ncontinuous one. In dimension one we show that forward-backward differences lead\nto norm resolvent convergence, while in dimension two and three they do\n\\textit{not}. The same negative result holds in all dimensions when symmetric\ndifferences are used. On the other hand, strong resolvent convergence holds in\nall these cases. Nevertheless, and quite remarkably, a rather simple but\nnon-standard modification to the discrete models, involving the mass term,\nensures norm resolvent convergence in general.",
    "descriptor": "",
    "authors": [
      "Horia D. Cornean",
      "Henrik Garde",
      "Arne Jensen"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.07826"
  },
  {
    "id": "arXiv:2203.07831",
    "title": "Graph Neural Network Sensitivity Under Probabilistic Error Model",
    "abstract": "Graph convolutional networks (GCNs) can successfully learn the graph signal\nrepresentation by graph convolution. The graph convolution depends on the graph\nfilter, which contains the topological dependency of data and propagates data\nfeatures. However, the estimation errors in the propagation matrix (e.g., the\nadjacency matrix) can have a significant impact on graph filters and GCNs. In\nthis paper, we study the effect of a probabilistic graph error model on the\nperformance of the GCNs. We prove that the adjacency matrix under the error\nmodel is bounded by a function of graph size and error probability. We further\nanalytically specify the upper bound of a normalized adjacency matrix with\nself-loop added. Finally, we illustrate the error bounds by running experiments\non a synthetic dataset and study the sensitivity of a simple GCN under this\nprobabilistic error model on accuracy.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Xinjue Wang",
      "Esa Ollila",
      "Sergiy A. Vorobyov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07831"
  },
  {
    "id": "arXiv:2203.07846",
    "title": "Recursive 3D Segmentation of Shoulder Joint with Coarse-scanned MR Image",
    "abstract": "For diagnosis of shoulder illness, it is essential to look at the morphology\ndeviation of scapula and humerus from the medical images that are acquired from\nMagnetic Resonance (MR) imaging. However, taking high-resolution MR images is\ntime-consuming and costly because the reduction of the physical distance\nbetween image slices causes prolonged scanning time. Moreover, due to the lack\nof training images, images from various sources must be utilized, which creates\nthe issue of high variance across the dataset. Also, there are human errors\namong the images due to the fact that it is hard to take the spatial\nrelationship into consideration when labeling the 3D image in low resolution.\nIn order to combat all obstacles stated above, we develop a fully automated\nalgorithm for segmenting the humerus and scapula bone from coarsely scanned and\nlow-resolution MR images and a recursive learning framework that iterative\nutilize the generated labels for reducing the errors among segmentations and\nincrease our dataset set for training the next round network. In this study, 50\nMR images are collected from several institutions and divided into five\nmutually exclusive sets for carrying five-fold cross-validation. Contours that\nare generated by the proposed method demonstrated a high level of accuracy when\ncompared with ground truth and the traditional method. The proposed neural\nnetwork and the recursive learning scheme improve the overall quality of the\nsegmentation on humerus and scapula on the low-resolution dataset and reduced\nincorrect segmentation in the ground truth, which could have a positive impact\non finding the cause of shoulder pain and patient's early relief.",
    "descriptor": "",
    "authors": [
      "Xiaoxiao He",
      "Chaowei Tan",
      "Virak Tan",
      "Kang Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07846"
  },
  {
    "id": "arXiv:2203.07869",
    "title": "Finding Many Sparse Cuts Using Entropy Maximization",
    "abstract": "A randomized algorithm for finding sparse cuts is given which is based on\nconstructing a dual markov chain called multiscale rings process(MRP) and a new\nconcept of entropy. It is shown how the time to absorption of the dual process\nmeasures the connectedness of the graph and mixing of the corresponding markov\nprocess which is then utilized to do clustering. The second algorithm uses the\nentropy which provides a new methodology and a set of tools to think about\nsparse cuts as well as sparsification of a graph.",
    "descriptor": "\nComments: 2 figures\n",
    "authors": [
      "Farshad Noravesh"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.07869"
  },
  {
    "id": "arXiv:2203.07879",
    "title": "Superconducting qubits as musical synthesizers for live performance",
    "abstract": "In the frame of a year-long artistic residency at the Yale Quantum Institute\nin 2019, artist and technologist Spencer Topel and quantum physicists Kyle\nSerniak and Luke Burkhart collaborated to create Quantum Sound, the first-ever\nmusic created and performed directly from measurements of superconducting\nquantum devices. Using analog- and digital-signal-processing sonification\ntechniques, the team transformed GHz-frequency signals from experiments inside\ndilution refrigerators into audible sounds. The project was performed live at\nthe International Festival of Arts and Ideas in New Haven, Connecticut on June\n14, 2019 as a structured improvisation using the synthesis methods described in\nthis chapter. At the interface between research and art, Quantum Sound\nrepresents an earnest attempt to produce a sonic reflection of the quantum\nrealm.",
    "descriptor": "\nComments: Unedited pre-publication version of a chapter which will appear in the book \"Quantum Computer Music\", Miranda, E. R. (Editor)\n",
    "authors": [
      "Spencer Topel",
      "Kyle Serniak",
      "Luke Burkhart",
      "Florian Carle"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.07879"
  },
  {
    "id": "arXiv:2203.07884",
    "title": "Efficient Training of the Memristive Deep Belief Net Immune to  Non-Idealities of the Synaptic Devices",
    "abstract": "The tunability of conductance states of various emerging non-volatile\nmemristive devices emulates the plasticity of biological synapses, making it\npromising in the hardware realization of large-scale neuromorphic systems. The\ninference of the neural network can be greatly accelerated by the vector-matrix\nmultiplication (VMM) performed within a crossbar array of memristive devices in\none step. Nevertheless, the implementation of the VMM needs complex peripheral\ncircuits and the complexity further increases since non-idealities of\nmemristive devices prevent precise conductance tuning (especially for the\nonline training) and largely degrade the performance of the deep neural\nnetworks (DNNs). Here, we present an efficient online training method of the\nmemristive deep belief net (DBN). The proposed memristive DBN uses\nstochastically binarized activations, reducing the complexity of peripheral\ncircuits, and uses the contrastive divergence (CD) based gradient descent\nlearning algorithm. The analog VMM and digital CD are performed separately in a\nmixed-signal hardware arrangement, making the memristive DBN high immune to\nnon-idealities of synaptic devices. The number of write operations on\nmemristive devices is reduced by two orders of magnitude. The recognition\naccuracy of 95%~97% can be achieved for the MNIST dataset using pulsed synaptic\nbehaviors of various memristive synaptic devices.",
    "descriptor": "",
    "authors": [
      "Wei Wang",
      "Barak Hoffer",
      "Tzofnat Greenberg-Toledo",
      "Yang Li",
      "Minhui Zou",
      "Eric Herbelin",
      "Ronny Ronen",
      "Xiaoxin Xu",
      "Yulin Zhao",
      "Jianguo Yang",
      "Shahar Kvatinsky"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.07884"
  },
  {
    "id": "arXiv:2203.07889",
    "title": "Comparing two samples through stochastic dominance: a graphical approach",
    "abstract": "Non-deterministic measurements are common in real-world scenarios: the\nperformance of a stochastic optimization algorithm or the total reward of a\nreinforcement learning agent in a chaotic environment are just two examples in\nwhich unpredictable outcomes are common. These measures can be modeled as\nrandom variables and compared among each other via their expected values or\nmore sophisticated tools such as null hypothesis statistical tests. In this\npaper, we propose an alternative framework to visually compare two samples\naccording to their estimated cumulative distribution functions. First, we\nintroduce a dominance measure for two random variables that quantifies the\nproportion in which the cumulative distribution function of one of the random\nvariables scholastically dominates the other one. Then, we present a graphical\nmethod that decomposes in quantiles i) the proposed dominance measure and ii)\nthe probability that one of the random variables takes lower values than the\nother. With illustrative purposes, we re-evaluate the experimentation of an\nalready published work with the proposed methodology and we show that\nadditional conclusions (missed by the rest of the methods) can be inferred.\nAdditionally, the software package RVCompare was created as a convenient way of\napplying and experimenting with the proposed framework.",
    "descriptor": "",
    "authors": [
      "Etor Arza",
      "Josu Ceberio",
      "Ekhi\u00f1e Irurozki",
      "Aritz P\u00e9rez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.07889"
  },
  {
    "id": "arXiv:2203.07912",
    "title": "Scalable Bigraphical Lasso: Two-way Sparse Network Inference for Count  Data",
    "abstract": "Classically, statistical datasets have a larger number of data points than\nfeatures ($n > p$). The standard model of classical statistics caters for the\ncase where data points are considered conditionally independent given the\nparameters. However, for $n\\approx p$ or $p > n$ such models are poorly\ndetermined. Kalaitzis et al. (2013) introduced the Bigraphical Lasso, an\nestimator for sparse precision matrices based on the Cartesian product of\ngraphs. Unfortunately, the original Bigraphical Lasso algorithm is not\napplicable in case of large p and n due to memory requirements. We exploit\neigenvalue decomposition of the Cartesian product graph to present a more\nefficient version of the algorithm which reduces memory requirements from\n$O(n^2p^2)$ to $O(n^2 + p^2)$. Many datasets in different application fields,\nsuch as biology, medicine and social science, come with count data, for which\nGaussian based models are not applicable. Our multi-way network inference\napproach can be used for discrete data. Our methodology accounts for the\ndependencies across both instances and features, reduces the computational\ncomplexity for high dimensional data and enables to deal with both discrete and\ncontinuous data. Numerical studies on both synthetic and real datasets are\npresented to showcase the performance of our method.",
    "descriptor": "",
    "authors": [
      "Sijia Li",
      "Mart\u00edn L\u00f3pez-Garc\u00eda",
      "Neil D. Lawrence",
      "Luisa Cutillo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.07912"
  },
  {
    "id": "arXiv:2203.07966",
    "title": "Learning Expanding Graphs for Signal Interpolation",
    "abstract": "Performing signal processing over graphs requires knowledge of the underlying\nfixed topology. However, graphs often grow in size with new nodes appearing\nover time, whose connectivity is typically unknown; hence, making more\nchallenging the downstream tasks in applications like cold start\nrecommendation. We address such a challenge for signal interpolation at the\nincoming nodes blind to the topological connectivity of the specific node.\nSpecifically, we propose a stochastic attachment model for incoming nodes\nparameterized by the attachment probabilities and edge weights. We estimate\nthese parameters in a data-driven fashion by relying only on the attachment\nbehaviour of earlier incoming nodes with the goal of interpolating the signal\nvalue. We study the non-convexity of the problem at hand, derive conditions\nwhen it can be marginally convexified, and propose an alternating projected\ndescent approach between estimating the attachment probabilities and the edge\nweights. Numerical experiments with synthetic and real data dealing in cold\nstart collaborative filtering corroborate our findings.",
    "descriptor": "",
    "authors": [
      "Bishwadeep Das",
      "Elvin Isufi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07966"
  },
  {
    "id": "arXiv:2203.08002",
    "title": "Quantum Parameterized Complexity",
    "abstract": "Parameterized complexity theory was developed in the 1990s to enrich the\ncomplexity-theoretic analysis of problems that depend on a range of parameters.\nIn this paper we establish a quantum equivalent of classical parameterized\ncomplexity theory, motivated by the need for new tools for the classifications\nof the complexity of real-world problems. We introduce the quantum analogues of\na range of parameterized complexity classes and examine the relationship\nbetween these classes, their classical counterparts, and well-studied problems.\nThis framework exposes a rich classification of the complexity of parameterized\nversions of QMA-hard problems, demonstrating, for example, a clear separation\nbetween the Quantum Circuit Satisfiability problem and the Local Hamiltonian\nproblem.",
    "descriptor": "\nComments: 23 pages, 1 figure\n",
    "authors": [
      "Michael J. Bremner",
      "Zhengfeng Ji",
      "Ryan L. Mann",
      "Luke Mathieson",
      "Mauro E.S. Morales",
      "Alexis T.E. Shaw"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.08002"
  },
  {
    "id": "arXiv:2203.08009",
    "title": "Text-free non-parallel many-to-many voice conversion using normalising  flows",
    "abstract": "Non-parallel voice conversion (VC) is typically achieved using lossy\nrepresentations of the source speech. However, ensuring only speaker identity\ninformation is dropped whilst all other information from the source speech is\nretained is a large challenge. This is particularly challenging in the scenario\nwhere at inference-time we have no knowledge of the text being read, i.e.,\ntext-free VC. To mitigate this, we investigate information-preserving VC\napproaches.\nNormalising flows have gained attention for text-to-speech synthesis, however\nhave been under-explored for VC. Flows utilize invertible functions to learn\nthe likelihood of the data, thus provide a lossless encoding of speech. We\ninvestigate normalising flows for VC in both text-conditioned and text-free\nscenarios. Furthermore, for text-free VC we compare pre-trained and\njointly-learnt priors. Flow-based VC evaluations show no degradation between\ntext-free and text-conditioned VC, resulting in improvements over the\nstate-of-the-art. Also, joint-training of the prior is found to negatively\nimpact text-free VC quality.",
    "descriptor": "",
    "authors": [
      "Thomas Merritt",
      "Abdelhamid Ezzerg",
      "Piotr Bili\u0144ski",
      "Magdalena Proszewska",
      "Kamil Pokora",
      "Roberto Barra-Chicote",
      "Daniel Korzekwa"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.08009"
  },
  {
    "id": "arXiv:2203.08021",
    "title": "Interpretable machine learning in Physics",
    "abstract": "Adding interpretability to multivariate methods creates a powerful synergy\nfor exploring complex physical systems with higher order correlations while\nbringing about a degree of clarity in the underlying dynamics of the system.",
    "descriptor": "\nComments: Submitted version of invited Comment Article for Nature Reviews Physics\n",
    "authors": [
      "Christophe Grojean",
      "Ayan Paul",
      "Zhuoni Qian",
      "Inga Str\u00fcmke"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08021"
  },
  {
    "id": "arXiv:2203.08034",
    "title": "A Noise-level-aware Framework for PET Image Denoising",
    "abstract": "In PET, the amount of relative (signal-dependent) noise present in different\nbody regions can be significantly different and is inherently related to the\nnumber of counts present in that region. The number of counts in a region\ndepends, in principle and among other factors, on the total administered\nactivity, scanner sensitivity, image acquisition duration, radiopharmaceutical\ntracer uptake in the region, and patient local body morphometry surrounding the\nregion. In theory, less amount of denoising operations is needed to denoise a\nhigh-count (low relative noise) image than images a low-count (high relative\nnoise) image, and vice versa. The current deep-learning-based methods for PET\nimage denoising are predominantly trained on image appearance only and have no\nspecial treatment for images of different noise levels. Our hypothesis is that\nby explicitly providing the local relative noise level of the input image to a\ndeep convolutional neural network (DCNN), the DCNN can outperform itself\ntrained on image appearance only. To this end, we propose a noise-level-aware\nframework denoising framework that allows embedding of local noise level into a\nDCNN. The proposed is trained and tested on 30 and 15 patient PET images\nacquired on a GE Discovery MI PET/CT system. Our experiments showed that the\nincreases in both PSNR and SSIM from our backbone network with relative noise\nlevel embedding (NLE) versus the same network without NLE were statistically\nsignificant with p<0.001, and the proposed method significantly outperformed a\nstrong baseline method by a large margin.",
    "descriptor": "",
    "authors": [
      "Ye Li",
      "Jianan Cui",
      "Junyu Chen",
      "Guodong Zeng",
      "Scott Wollenweber",
      "Floris Jansen",
      "Se-In Jang",
      "Kyungsang Kim",
      "Kuang Gong",
      "Quanzheng Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.08034"
  },
  {
    "id": "arXiv:2203.08056",
    "title": "Machine Learning and Cosmology",
    "abstract": "Methods based on machine learning have recently made substantial inroads in\nmany corners of cosmology. Through this process, new computational tools, new\nperspectives on data collection, model development, analysis, and discovery, as\nwell as new communities and educational pathways have emerged. Despite rapid\nprogress, substantial potential at the intersection of cosmology and machine\nlearning remains untapped. In this white paper, we summarize current and\nongoing developments relating to the application of machine learning within\ncosmology and provide a set of recommendations aimed at maximizing the\nscientific impact of these burgeoning tools over the coming decade through both\ntechnical development as well as the fostering of emerging communities.",
    "descriptor": "\nComments: Contribution to Snowmass 2021. 32 pages\n",
    "authors": [
      "Cora Dvorkin",
      "Siddharth Mishra-Sharma",
      "Brian Nord",
      "V. Ashley Villar",
      "Camille Avestruz",
      "Keith Bechtol",
      "Aleksandra \u0106iprijanovi\u0107",
      "Andrew J. Connolly",
      "Lehman H. Garrison",
      "Gautham Narayan",
      "Francisco Villaescusa-Navarro"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08056"
  },
  {
    "id": "arXiv:2203.08058",
    "title": "Graph filtering over expanding graphs",
    "abstract": "Our capacity to learn representations from data is related to our ability to\ndesign filters that can leverage their coupling with the underlying domain.\nGraph filters are one such tool for network data and have been used in a myriad\nof applications. But graph filters work only with a fixed number of nodes\ndespite the expanding nature of practical networks. Learning filters in this\nsetting is challenging not only because of the increased dimensions but also\nbecause the connectivity is known only up to an attachment model. We propose a\nfilter learning scheme for data over expanding graphs by relying only on such a\nmodel. By characterizing the filter stochastically, we develop an empirical\nrisk minimization framework inspired by multi-kernel learning to balance the\ninformation inflow and outflow at the incoming nodes. We particularize the\napproach for denoising and semi-supervised learning (SSL) over expanding graphs\nand show near-optimal performance compared with baselines relying on the exact\ntopology. For SSL, the proposed scheme uses the incoming node information to\nimprove the task on the existing ones. These findings lay the foundation for\nlearning representations over expanding graphs by relying only on the\nstochastic connectivity model.",
    "descriptor": "",
    "authors": [
      "Bishwadeep Das",
      "Elvin Isufi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08058"
  },
  {
    "id": "arXiv:2203.08072",
    "title": "Neural Solvers for Fast and Accurate Numerical Optimal Control",
    "abstract": "Synthesizing optimal controllers for dynamical systems often involves solving\noptimization problems with hard real-time constraints. These constraints\ndetermine the class of numerical methods that can be applied: computationally\nexpensive but accurate numerical routines are replaced by fast and inaccurate\nmethods, trading inference time for solution accuracy. This paper provides\ntechniques to improve the quality of optimized control policies given a fixed\ncomputational budget. We achieve the above via a hypersolvers approach, which\nhybridizes a differential equation solver and a neural network. The performance\nis evaluated in direct and receding-horizon optimal control tasks in both low\nand high dimensions, where the proposed approach shows consistent Pareto\nimprovements in solution accuracy and control performance.",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Federico Berto",
      "Stefano Massaroli",
      "Michael Poli",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08072"
  },
  {
    "id": "arXiv:2203.08074",
    "title": "Combining AI/ML and PHY Layer Rule Based Inference -- Some First Results",
    "abstract": "In 3GPP New Radio (NR) Release 18 we see the first study item starting in May\n2022, which will evaluate the potential of AI/ML methods for Radio Access\nNetwork (RAN) 1, i.e., for mobile radio PHY and MAC layer applications. We use\nthe profiling method for accurate iterative estimation of multipath component\nparameters for PHY layer reference, as it promises a large channel prediction\nhorizon. We investigate options to partly or fully replace some functionalities\nof this rule based PHY layer method by AI/ML inferences, with the goal to\nachieve either a higher performance, lower latency, or, reduced processing\ncomplexity. We provide first results for noise reduction, then a combined\nscheme for model order selection, compare options to infer multipath component\nstart parameters, and, provide an outlook on a possible channel prediction\nframework.",
    "descriptor": "\nComments: submitted to SPAWC 2022\n",
    "authors": [
      "Brenda Vilas Boas",
      "Wolfgang Zirwas",
      "Martin Haardt"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08074"
  },
  {
    "id": "arXiv:2203.08115",
    "title": "Temporal interaction-driven contagion model of Covid-19 variants reveals  surprising competition conditions",
    "abstract": "The temporal dynamics of social interactions were shown to influence the\nspread of disease. Here, we model the progression and competition conditions of\na number of pathogens with various levels of cross-immunity over temporal\nnetworks. We use our interaction-driven contagion model of Covid-19 and model\nsome of its variants. Our results, obtained on both temporal random networks\nand real-world interaction data, demonstrate that temporal dynamics are crucial\nto the competition conditions. We consider two and three competing pathogens\nand show that there are conditions under which a slower pathogen will remain\nactive and create a second wave in which it infects the majority of the\npopulation. We then show that when the duration of the encounters is\nconsidered, the spreading dynamics change significantly. Our results indicate\nthat when considering airborne diseases, it might be crucial to take into\naccount the duration of temporal meetings to model the spread of pathogens in a\npopulation.",
    "descriptor": "",
    "authors": [
      "Alex Abbey",
      "Yuval Shahar",
      "Osnat Mokryn"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.08115"
  },
  {
    "id": "arXiv:1811.07644",
    "title": "Coinduction in Uniform: Foundations for Corecursive Proof Search with  Horn Clauses",
    "abstract": "Coinduction in Uniform: Foundations for Corecursive Proof Search with  Horn Clauses",
    "descriptor": "",
    "authors": [
      "Henning Basold",
      "Ekaterina Komendantskaya",
      "Yue Li"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1811.07644"
  },
  {
    "id": "arXiv:1903.02240",
    "title": "Efficient Deep Neural Network for Photo-realistic Image Super-Resolution",
    "abstract": "Comments: Pattern Recognition",
    "descriptor": "\nComments: Pattern Recognition\n",
    "authors": [
      "Namhyuk Ahn",
      "Byungkon Kang",
      "Kyung-Ah Sohn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1903.02240"
  },
  {
    "id": "arXiv:1903.04668",
    "title": "Synthesizing Invariant Clusters for Polynomial Programs by Semidefinite  Programming",
    "abstract": "Synthesizing Invariant Clusters for Polynomial Programs by Semidefinite  Programming",
    "descriptor": "",
    "authors": [
      "Qiuye Wang",
      "Lihong Zhi",
      "Naijun Zhan",
      "Bai Xue",
      "Zhi-hong Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1903.04668"
  },
  {
    "id": "arXiv:1911.08109",
    "title": "2D Eigenvalue Problem I: Existence and Number of Solutions",
    "abstract": "Comments: 21 pages, 9 figures",
    "descriptor": "\nComments: 21 pages, 9 figures\n",
    "authors": [
      "Yangfeng Su",
      "Tianyi Lu",
      "Zhaojun Bai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1911.08109"
  },
  {
    "id": "arXiv:2001.07488",
    "title": "Profunctor Optics, a Categorical Update",
    "abstract": "Comments: 45 pages, 11 figures, minor fixes, new code and reformatting",
    "descriptor": "\nComments: 45 pages, 11 figures, minor fixes, new code and reformatting\n",
    "authors": [
      "Bryce Clarke",
      "Derek Elkins",
      "Jeremy Gibbons",
      "Fosco Loregian",
      "Bartosz Milewski",
      "Emily Pillmore",
      "Mario Rom\u00e1n"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2001.07488"
  },
  {
    "id": "arXiv:2004.04348",
    "title": "On the sparsity of LASSO minimizers in sparse data recovery",
    "abstract": "On the sparsity of LASSO minimizers in sparse data recovery",
    "descriptor": "",
    "authors": [
      "Simon Foucart",
      "Eitan Tadmor",
      "Ming Zhong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2004.04348"
  },
  {
    "id": "arXiv:2005.06674",
    "title": "On the Convergence of Overlapping Schwarz Decomposition for Nonlinear  Optimal Control",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Sen Na",
      "Sungho Shin",
      "Mihai Anitescu",
      "Victor M. Zavala"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2005.06674"
  },
  {
    "id": "arXiv:2006.02495",
    "title": "Balanced Truncation Model Reduction with A Priori Error Bounds for LTI  Systems with Nonzero Initial Value",
    "abstract": "Comments: 20 pages, 5 figures",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Christian Schr\u00f6der",
      "Matthias Voigt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.02495"
  },
  {
    "id": "arXiv:2006.14892",
    "title": "Well-posedness and numerical schemes for one-dimensional McKean-Vlasov  equations and interacting particle systems with discontinuous drift",
    "abstract": "Comments: 33 pages, 4 figures",
    "descriptor": "\nComments: 33 pages, 4 figures\n",
    "authors": [
      "Gunther Leobacher",
      "Christoph Reisinger",
      "Wolfgang Stockinger"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.14892"
  },
  {
    "id": "arXiv:2007.01409",
    "title": "A (Slightly) Improved Approximation Algorithm for Metric TSP",
    "abstract": "A (Slightly) Improved Approximation Algorithm for Metric TSP",
    "descriptor": "",
    "authors": [
      "Anna R. Karlin",
      "Nathan Klein",
      "Shayan Oveis Gharan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2007.01409"
  },
  {
    "id": "arXiv:2007.08386",
    "title": "MTP: Multi-Task Pruning for Efficient Semantic Segmentation Networks",
    "abstract": "MTP: Multi-Task Pruning for Efficient Semantic Segmentation Networks",
    "descriptor": "",
    "authors": [
      "Xinghao Chen",
      "Yiman Zhang",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2007.08386"
  },
  {
    "id": "arXiv:2007.12350",
    "title": "Improving the dilation of a metric graph by adding edges",
    "abstract": "Comments: Journal version, TALG 2022",
    "descriptor": "\nComments: Journal version, TALG 2022\n",
    "authors": [
      "Joachim Gudmundsson",
      "Sampson Wong"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2007.12350"
  },
  {
    "id": "arXiv:2008.12083",
    "title": "Kernel-based Active Subspaces with application to CFD parametric  problems using Discontinuous Galerkin method",
    "abstract": "Kernel-based Active Subspaces with application to CFD parametric  problems using Discontinuous Galerkin method",
    "descriptor": "",
    "authors": [
      "Francesco Romor",
      "Marco Tezzele",
      "Andrea Lario",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.12083"
  },
  {
    "id": "arXiv:2009.00171",
    "title": "Precoding and Scheduling for AoI Minimization in MIMO Broadcast Channels",
    "abstract": "Precoding and Scheduling for AoI Minimization in MIMO Broadcast Channels",
    "descriptor": "",
    "authors": [
      "Songtao Feng",
      "Jing Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2009.00171"
  },
  {
    "id": "arXiv:2009.07398",
    "title": "A Sensitivity-based Data Augmentation Framework for Model Predictive  Control Policy Approximation",
    "abstract": "Comments: Accepted for publication at IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: Accepted for publication at IEEE Transactions on Automatic Control\n",
    "authors": [
      "Dinesh Krishnamoorthy"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.07398"
  },
  {
    "id": "arXiv:2009.09778",
    "title": "Computation of Parameter Dependent Robust Invariant Sets for LPV Models  with Guaranteed Performance",
    "abstract": "Comments: 17 pages, 6 figures, preprint submitted to Automatica",
    "descriptor": "\nComments: 17 pages, 6 figures, preprint submitted to Automatica\n",
    "authors": [
      "Ankit Gupta",
      "Manas Mejari",
      "Paolo Falcone",
      "Dario Piga"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2009.09778"
  },
  {
    "id": "arXiv:2010.06975",
    "title": "Medical Code Assignment with Gated Convolution and Note-Code Interaction",
    "abstract": "Comments: Findings of ACL-IJCNLP 2021",
    "descriptor": "\nComments: Findings of ACL-IJCNLP 2021\n",
    "authors": [
      "Shaoxiong Ji",
      "Shirui Pan",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2010.06975"
  },
  {
    "id": "arXiv:2010.08382",
    "title": "Enumerating Answers to First-Order Queries over Databases of Low Degree",
    "abstract": "Enumerating Answers to First-Order Queries over Databases of Low Degree",
    "descriptor": "",
    "authors": [
      "Arnaud Durand",
      "Nicole Schweikardt",
      "Luc Segoufin"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2010.08382"
  },
  {
    "id": "arXiv:2010.15030",
    "title": "Actris 2.0: Asynchronous Session-Type Based Reasoning in Separation  Logic",
    "abstract": "Comments: 60 pages, 24 figures",
    "descriptor": "\nComments: 60 pages, 24 figures\n",
    "authors": [
      "Jonas Kastberg Hinrichsen",
      "Jesper Bengtson",
      "Robbert Krebbers"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2010.15030"
  },
  {
    "id": "arXiv:2011.03183",
    "title": "Learning Object-Based State Estimators for Household Robots",
    "abstract": "Comments: Website at: this https URL",
    "descriptor": "\nComments: Website at: this https URL\n",
    "authors": [
      "Yilun Du",
      "Tomas Lozano-Perez",
      "Leslie Kaelbling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.03183"
  },
  {
    "id": "arXiv:2011.08340",
    "title": "Automatically Repairing Programs Using Both Tests and Bug Reports",
    "abstract": "Comments: working paper",
    "descriptor": "\nComments: working paper\n",
    "authors": [
      "Manish Motwani",
      "Yuriy Brun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2011.08340"
  },
  {
    "id": "arXiv:2011.13737",
    "title": "Limitations of Mean-Based Algorithms for Trace Reconstruction at Small  Distance",
    "abstract": "Comments: In this version, we improve Theorem 7 due to a technical lemma by Sima and Bruck, whose proof we simplify further in Lemma 4. We explain the differences between the proofs in Section 1.2 after Theorem 7. We also strenghthen and simplify Theorem 1,3,5 and Lemma 6, and answer the open questions we raised in our previous version with the new Theorem 4. We suggest new open problems in Section 7",
    "descriptor": "\nComments: In this version, we improve Theorem 7 due to a technical lemma by Sima and Bruck, whose proof we simplify further in Lemma 4. We explain the differences between the proofs in Section 1.2 after Theorem 7. We also strenghthen and simplify Theorem 1,3,5 and Lemma 6, and answer the open questions we raised in our previous version with the new Theorem 4. We suggest new open problems in Section 7\n",
    "authors": [
      "Elena Grigorescu",
      "Madhu Sudan",
      "Minshen Zhu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2011.13737"
  },
  {
    "id": "arXiv:2012.09047",
    "title": "Continuous Positional Payoffs",
    "abstract": "Continuous Positional Payoffs",
    "descriptor": "",
    "authors": [
      "Alexander Kozachinskiy"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2012.09047"
  },
  {
    "id": "arXiv:2101.02201",
    "title": "Experimental System for Molecular Communication in Pipe Flow With  Magnetic Nanoparticles",
    "abstract": "Comments: \\c{opyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\c{opyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Wayan Wicke",
      "Harald Unterweger",
      "Jens Kirchner",
      "Lukas Brand",
      "Arman Ahmadzadeh",
      "Doaa Ahmed",
      "Vahid Jamali",
      "Christoph Alexiou",
      "Georg Fischer",
      "Robert Schober"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2101.02201"
  },
  {
    "id": "arXiv:2101.04431",
    "title": "Automatic Extrinsic Calibration Method for LiDAR and Camera Sensor  Setups",
    "abstract": "Comments: Published on IEEE Transactions on Intelligent Transportation Systems",
    "descriptor": "\nComments: Published on IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Jorge Beltr\u00e1n",
      "Carlos Guindel",
      "Arturo de la Escalera",
      "Fernando Garc\u00eda"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.04431"
  },
  {
    "id": "arXiv:2101.06536",
    "title": "Deep Cox Mixtures for Survival Regression",
    "abstract": "Comments: Machine Learning for Healthcare Conference, 2021",
    "descriptor": "\nComments: Machine Learning for Healthcare Conference, 2021\n",
    "authors": [
      "Chirag Nagpal",
      "Steve Yadlowsky",
      "Negar Rostamzadeh",
      "Katherine Heller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.06536"
  },
  {
    "id": "arXiv:2101.11500",
    "title": "A Deterministic Algorithm for the Discrete Logarithm Problem in a  Semigroup",
    "abstract": "A Deterministic Algorithm for the Discrete Logarithm Problem in a  Semigroup",
    "descriptor": "",
    "authors": [
      "Simran Tinani",
      "Joachim Rosenthal"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2101.11500"
  },
  {
    "id": "arXiv:2101.11659",
    "title": "Optimal Utilization Strategy of the LiFePO$_4$ Battery Storage",
    "abstract": "Comments: 35 pages, 12 figures",
    "descriptor": "\nComments: 35 pages, 12 figures\n",
    "authors": [
      "T. Sayfutdinov",
      "P. Vorobev"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.11659"
  },
  {
    "id": "arXiv:2102.01066",
    "title": "Evaluating Large-Vocabulary Object Detectors: The Devil is in the  Details",
    "abstract": "Evaluating Large-Vocabulary Object Detectors: The Devil is in the  Details",
    "descriptor": "",
    "authors": [
      "Achal Dave",
      "Piotr Doll\u00e1r",
      "Deva Ramanan",
      "Alexander Kirillov",
      "Ross Girshick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.01066"
  },
  {
    "id": "arXiv:2102.03690",
    "title": "WiSleep: Inferring Sleep Duration at Scale Using Passive WiFi Sensing",
    "abstract": "Comments: 14 pages, 17 figures",
    "descriptor": "\nComments: 14 pages, 17 figures\n",
    "authors": [
      "Priyanka Mary Mammen",
      "Camellia Zakaria",
      "Tergel Molom-Ochir",
      "Amee Trivedi",
      "Prashant Shenoy",
      "Rajesh Balan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.03690"
  },
  {
    "id": "arXiv:2102.10303",
    "title": "Towards Building A Group-based Unsupervised Representation  Disentanglement Framework",
    "abstract": "Comments: Accepted by ICLR 2022",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Tao Yang",
      "Xuanchi Ren",
      "Yuwang Wang",
      "Wenjun Zeng",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.10303"
  },
  {
    "id": "arXiv:2103.00683",
    "title": "Decision Making in Monopoly using a Hybrid Deep Reinforcement Learning  Approach",
    "abstract": "Decision Making in Monopoly using a Hybrid Deep Reinforcement Learning  Approach",
    "descriptor": "",
    "authors": [
      "Trevor Bonjour",
      "Marina Haliem",
      "Aala Alsalem",
      "Shilpa Thomas",
      "Hongyu Li",
      "Vaneet Aggarwal",
      "Mayank Kejriwal",
      "Bharat Bhargava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.00683"
  },
  {
    "id": "arXiv:2103.01528",
    "title": "Nested Vehicle Routing Problem: Optimizing Drone-Truck Surveillance  Operations",
    "abstract": "Comments: 40 pages, 20 figures",
    "descriptor": "\nComments: 40 pages, 20 figures\n",
    "authors": [
      "Fanruiqi Zeng",
      "Zaiwei Chen",
      "John-Paul Clarke",
      "David Goldsman"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.01528"
  },
  {
    "id": "arXiv:2103.06676",
    "title": "Inference for Generative Capsule Models",
    "abstract": "Inference for Generative Capsule Models",
    "descriptor": "",
    "authors": [
      "Alfredo Nazabal",
      "Nikolaos Tsagkas",
      "Christopher K.I. Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06676"
  },
  {
    "id": "arXiv:2103.11919",
    "title": "Machine Learning Emulation of 3D Cloud Radiative Effects",
    "abstract": "Comments: Published version",
    "descriptor": "\nComments: Published version\n",
    "authors": [
      "David Meyer",
      "Robin J. Hogan",
      "Peter D. Dueben",
      "Shannon L. Mason"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2103.11919"
  },
  {
    "id": "arXiv:2103.13027",
    "title": "Unveiling the Power of Mixup for Stronger Classifiers",
    "abstract": "Comments: The fourth version of AutoMix. The source code is available at this https URL",
    "descriptor": "\nComments: The fourth version of AutoMix. The source code is available at this https URL\n",
    "authors": [
      "Zicheng Liu",
      "Siyuan Li",
      "Di Wu",
      "Zihan Liu",
      "Zhiyuan Chen",
      "Lirong Wu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.13027"
  },
  {
    "id": "arXiv:2103.17151",
    "title": "Divide and Rule: Effective Pre-Training for Context-Aware Multi-Encoder  Translation Models",
    "abstract": "Comments: ACL 2022 (camera ready)",
    "descriptor": "\nComments: ACL 2022 (camera ready)\n",
    "authors": [
      "Lorenzo Lupo",
      "Marco Dinarelli",
      "Laurent Besacier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.17151"
  },
  {
    "id": "arXiv:2104.04532",
    "title": "Neural RGB-D Surface Reconstruction",
    "abstract": "Comments: CVPR'22; Project page: this https URL Video: this https URL",
    "descriptor": "\nComments: CVPR'22; Project page: this https URL Video: this https URL\n",
    "authors": [
      "Dejan Azinovi\u0107",
      "Ricardo Martin-Brualla",
      "Dan B Goldman",
      "Matthias Nie\u00dfner",
      "Justus Thies"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.04532"
  },
  {
    "id": "arXiv:2104.08678",
    "title": "Improving Question Answering Model Robustness with Synthetic Adversarial  Data Generation",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Max Bartolo",
      "Tristan Thrush",
      "Robin Jia",
      "Sebastian Riedel",
      "Pontus Stenetorp",
      "Douwe Kiela"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08678"
  },
  {
    "id": "arXiv:2104.09627",
    "title": "Inference of Upcoming Human Grasp Using EMG During Reach-to-Grasp  Movement",
    "abstract": "Inference of Upcoming Human Grasp Using EMG During Reach-to-Grasp  Movement",
    "descriptor": "",
    "authors": [
      "Mo Han",
      "Mehrshad Zandigohar",
      "Sezen Yagmur Gunay",
      "Gunar Schirner",
      "Deniz Erdogmus"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.09627"
  },
  {
    "id": "arXiv:2104.09684",
    "title": "Suppressing simulation bias using multi-modal data",
    "abstract": "Suppressing simulation bias using multi-modal data",
    "descriptor": "",
    "authors": [
      "Bogdan Kustowski",
      "Jim A. Gaffney",
      "Brian K. Spears",
      "Gemma J. Anderson",
      "Rushil Anirudh",
      "Peer-Timo Bremer",
      "Jayaraman J. Thiagarajan",
      "Michael K. G. Kruse",
      "Ryan C. Nora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09684"
  },
  {
    "id": "arXiv:2104.13450",
    "title": "Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and  Extracting Them from 2D Renderings",
    "abstract": "Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and  Extracting Them from 2D Renderings",
    "descriptor": "",
    "authors": [
      "Innfarn Yoo",
      "Huiwen Chang",
      "Xiyang Luo",
      "Ondrej Stava",
      "Ce Liu",
      "Peyman Milanfar",
      "Feng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.13450"
  },
  {
    "id": "arXiv:2105.00828",
    "title": "Memorisation versus Generalisation in Pre-trained Language Models",
    "abstract": "Comments: 15 pages, 25 figures. To be published in ACL2022",
    "descriptor": "\nComments: 15 pages, 25 figures. To be published in ACL2022\n",
    "authors": [
      "Michael T\u00e4nzer",
      "Sebastian Ruder",
      "Marek Rei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00828"
  },
  {
    "id": "arXiv:2105.07654",
    "title": "Dependency Parsing as MRC-based Span-Span Prediction",
    "abstract": "Comments: Accepted by ACL 2022 main conference",
    "descriptor": "\nComments: Accepted by ACL 2022 main conference\n",
    "authors": [
      "Leilei Gan",
      "Yuxian Meng",
      "Kun Kuang",
      "Xiaofei Sun",
      "Chun Fan",
      "Fei Wu",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.07654"
  },
  {
    "id": "arXiv:2105.09871",
    "title": "Tuza's Conjecture for Threshold Graphs",
    "abstract": "Comments: 12 pages, 11 figures, Accepted to European Conference on Combinatorics, Graph Theory and Applications (EUROCOMB) 2021",
    "descriptor": "\nComments: 12 pages, 11 figures, Accepted to European Conference on Combinatorics, Graph Theory and Applications (EUROCOMB) 2021\n",
    "authors": [
      "Marthe Bonamy",
      "\u0141ukasz Bo\u017cyk",
      "Andrzej Grzesik",
      "Meike Hatzel",
      "Tom\u00e1\u0161 Masa\u0159\u00edk",
      "Jana Novotn\u00e1",
      "Karolina Okrasa"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.09871"
  },
  {
    "id": "arXiv:2105.15164",
    "title": "DISSECT: Disentangled Simultaneous Explanations via Concept Traversals",
    "abstract": "Comments: Accepted for publication at ICLR 2022",
    "descriptor": "\nComments: Accepted for publication at ICLR 2022\n",
    "authors": [
      "Asma Ghandeharioun",
      "Been Kim",
      "Chun-Liang Li",
      "Brendan Jou",
      "Brian Eoff",
      "Rosalind W. Picard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.15164"
  },
  {
    "id": "arXiv:2106.02713",
    "title": "Learning Curves for SGD on Structured Features",
    "abstract": "Comments: Camera Ready for ICLR 2022: this https URL",
    "descriptor": "\nComments: Camera Ready for ICLR 2022: this https URL\n",
    "authors": [
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02713"
  },
  {
    "id": "arXiv:2106.02736",
    "title": "Exposing the Implicit Energy Networks behind Masked Language Models via  Metropolis--Hastings",
    "abstract": "Comments: ICLR 2022 - camera ready",
    "descriptor": "\nComments: ICLR 2022 - camera ready\n",
    "authors": [
      "Kartik Goyal",
      "Chris Dyer",
      "Taylor Berg-Kirkpatrick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02736"
  },
  {
    "id": "arXiv:2106.02940",
    "title": "Same State, Different Task: Continual Reinforcement Learning without  Interference",
    "abstract": "Comments: Accepted as an oral at AAAI 2022. 17 pages and 12 figures",
    "descriptor": "\nComments: Accepted as an oral at AAAI 2022. 17 pages and 12 figures\n",
    "authors": [
      "Samuel Kessler",
      "Jack Parker-Holder",
      "Philip Ball",
      "Stefan Zohren",
      "Stephen J. Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02940"
  },
  {
    "id": "arXiv:2106.03489",
    "title": "Conditionally Exponential Prior in Focal Near- and Far-Field EEG Source  Localization via Randomized Multiresolution Scanning (RAMUS)",
    "abstract": "Comments: 23 pages, 16 figures, submitted to Journal of Mathematical Imaging and Vision",
    "descriptor": "\nComments: 23 pages, 16 figures, submitted to Journal of Mathematical Imaging and Vision\n",
    "authors": [
      "Joonas Lahtinen",
      "Alexandra Koulouri",
      "Atena Rezaei",
      "Sampsa Pursiainen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.03489"
  },
  {
    "id": "arXiv:2106.04263",
    "title": "On the Connection between Local Attention and Dynamic Depth-wise  Convolution",
    "abstract": "Comments: ICLR 2022 Spotlight",
    "descriptor": "\nComments: ICLR 2022 Spotlight\n",
    "authors": [
      "Qi Han",
      "Zejia Fan",
      "Qi Dai",
      "Lei Sun",
      "Ming-Ming Cheng",
      "Jiaying Liu",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04263"
  },
  {
    "id": "arXiv:2106.04732",
    "title": "AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain  Adaptation",
    "abstract": "Comments: Accepted to ICLR 2022",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "David Berthelot",
      "Rebecca Roelofs",
      "Kihyuk Sohn",
      "Nicholas Carlini",
      "Alex Kurakin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04732"
  },
  {
    "id": "arXiv:2106.05126",
    "title": "Efficient Active Search for Combinatorial Optimization Problems",
    "abstract": "Comments: Accepted at ICLR 2022",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Andr\u00e9 Hottung",
      "Yeong-Dae Kwon",
      "Kevin Tierney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.05126"
  },
  {
    "id": "arXiv:2106.05258",
    "title": "Generative Models as a Data Source for Multiview Representation Learning",
    "abstract": "Generative Models as a Data Source for Multiview Representation Learning",
    "descriptor": "",
    "authors": [
      "Ali Jahanian",
      "Xavier Puig",
      "Yonglong Tian",
      "Phillip Isola"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05258"
  },
  {
    "id": "arXiv:2106.06235",
    "title": "Knowledge Enhanced Machine Learning Pipeline against Diverse Adversarial  Attacks",
    "abstract": "Comments: International Conference on Machine Learning 2021, 37 pages, 8 figures, 9 tables",
    "descriptor": "\nComments: International Conference on Machine Learning 2021, 37 pages, 8 figures, 9 tables\n",
    "authors": [
      "Nezihe Merve G\u00fcrel",
      "Xiangyu Qi",
      "Luka Rimanic",
      "Ce Zhang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06235"
  },
  {
    "id": "arXiv:2106.07967",
    "title": "Incorporating Word Sense Disambiguation in Neural Language Models",
    "abstract": "Incorporating Word Sense Disambiguation in Neural Language Models",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Norman Meuschke",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07967"
  },
  {
    "id": "arXiv:2106.07971",
    "title": "Simple GNN Regularisation for 3D Molecular Property Prediction & Beyond",
    "abstract": "Comments: ICLR 2022 Camera Ready",
    "descriptor": "\nComments: ICLR 2022 Camera Ready\n",
    "authors": [
      "Jonathan Godwin",
      "Michael Schaarschmidt",
      "Alexander Gaunt",
      "Alvaro Sanchez-Gonzalez",
      "Yulia Rubanova",
      "Petar Veli\u010dkovi\u0107",
      "James Kirkpatrick",
      "Peter Battaglia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07971"
  },
  {
    "id": "arXiv:2106.08290",
    "title": "PolyDot Coded Privacy Preserving Multi-Party Computation at the Edge",
    "abstract": "Comments: 23 pages, 5 figures",
    "descriptor": "\nComments: 23 pages, 5 figures\n",
    "authors": [
      "Elahe Vedadi",
      "Yasaman Keshtkarjahromi",
      "Hulya Seferoglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.08290"
  },
  {
    "id": "arXiv:2106.11071",
    "title": "Making Sense of Moodle Log Data",
    "abstract": "Making Sense of Moodle Log Data",
    "descriptor": "",
    "authors": [
      "Daniela Rotelli",
      "Anna Monreale"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11071"
  },
  {
    "id": "arXiv:2106.12534",
    "title": "Coarse-to-Fine Q-attention: Efficient Learning for Visual Robotic  Manipulation via Discretisation",
    "abstract": "Comments: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022). Videos and code: this https URL",
    "descriptor": "\nComments: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022). Videos and code: this https URL\n",
    "authors": [
      "Stephen James",
      "Kentaro Wada",
      "Tristan Laidlow",
      "Andrew J. Davison"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12534"
  },
  {
    "id": "arXiv:2106.14282",
    "title": "A Closer Look at How Fine-tuning Changes BERT",
    "abstract": "Comments: Camera ready for ACL 2022",
    "descriptor": "\nComments: Camera ready for ACL 2022\n",
    "authors": [
      "Yichu Zhou",
      "Vivek Srikumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.14282"
  },
  {
    "id": "arXiv:2107.00394",
    "title": "Global sensitivity analysis using derivative-based sparse Poincar\u00e9  chaos expansions",
    "abstract": "Global sensitivity analysis using derivative-based sparse Poincar\u00e9  chaos expansions",
    "descriptor": "",
    "authors": [
      "Nora L\u00fcthen",
      "Olivier Roustant",
      "Fabrice Gamboa",
      "Bertrand Iooss",
      "Stefano Marelli",
      "Bruno Sudret"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.00394"
  },
  {
    "id": "arXiv:2107.02153",
    "title": "FaVIQ: FAct Verification from Information-seeking Questions",
    "abstract": "Comments: ACL 2022(long). Data & Code available at this https URL",
    "descriptor": "\nComments: ACL 2022(long). Data & Code available at this https URL\n",
    "authors": [
      "Jungsoo Park",
      "Sewon Min",
      "Jaewoo Kang",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02153"
  },
  {
    "id": "arXiv:2107.02398",
    "title": "From General to Specific: Online Updating for Blind Super-Resolution",
    "abstract": "Comments: Accepted by Pattern Recognition",
    "descriptor": "\nComments: Accepted by Pattern Recognition\n",
    "authors": [
      "Shang Li",
      "Guixuan Zhang",
      "Zhengxiong Luo",
      "Jie Liu",
      "Zhi Zeng",
      "Shuwu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02398"
  },
  {
    "id": "arXiv:2107.02729",
    "title": "AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning",
    "abstract": "AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Biwei Huang",
      "Fan Feng",
      "Chaochao Lu",
      "Sara Magliacane",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.02729"
  },
  {
    "id": "arXiv:2107.08712",
    "title": "Exploring Set Similarity for Dense Self-supervised Representation  Learning",
    "abstract": "Comments: 10 pages, 4 figures, Accepted by CVPR2022",
    "descriptor": "\nComments: 10 pages, 4 figures, Accepted by CVPR2022\n",
    "authors": [
      "Zhaoqing Wang",
      "Qiang Li",
      "Guoxin Zhang",
      "Pengfei Wan",
      "Wen Zheng",
      "Nannan Wang",
      "Mingming Gong",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.08712"
  },
  {
    "id": "arXiv:2107.11214",
    "title": "Human Pose Estimation from Sparse Inertial Measurements through  Recurrent Graph Convolution",
    "abstract": "Comments: Preprint, in submission",
    "descriptor": "\nComments: Preprint, in submission\n",
    "authors": [
      "Patrik Puchert",
      "Timo Ropinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.11214"
  },
  {
    "id": "arXiv:2107.13862",
    "title": "Subsequent embedding in targeted image steganalysis: Theoretical  framework and practical applications",
    "abstract": "Subsequent embedding in targeted image steganalysis: Theoretical  framework and practical applications",
    "descriptor": "",
    "authors": [
      "David Meg\u00edas",
      "Daniel Lerch-Hostalot"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.13862"
  },
  {
    "id": "arXiv:2107.14226",
    "title": "Learning more skills through optimistic exploration",
    "abstract": "Comments: Accepted at ICLR 2022 (spotlight)",
    "descriptor": "\nComments: Accepted at ICLR 2022 (spotlight)\n",
    "authors": [
      "DJ Strouse",
      "Kate Baumli",
      "David Warde-Farley",
      "Vlad Mnih",
      "Steven Hansen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.14226"
  },
  {
    "id": "arXiv:2108.00785",
    "title": "Towards Reliable and Efficient AI for 6G: Bayesian Active Meta-Learning  for Few Pilot Demodulation and Equalization",
    "abstract": "Comments: Submitted for a journal review",
    "descriptor": "\nComments: Submitted for a journal review\n",
    "authors": [
      "Kfir M. Cohen",
      "Sangwoo Park",
      "Osvaldo Simeone",
      "Shlomo Shamai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.00785"
  },
  {
    "id": "arXiv:2108.00981",
    "title": "PSA-GAN: Progressive Self Attention GANs for Synthetic Time Series",
    "abstract": "PSA-GAN: Progressive Self Attention GANs for Synthetic Time Series",
    "descriptor": "",
    "authors": [
      "Jeha Paul",
      "Bohlke-Schneider Michael",
      "Mercado Pedro",
      "Singh Nirwan Rajbir",
      "Kapoor Shubham",
      "Flunkert Valentin",
      "Gasthaus Jan",
      "Januschowski Tim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.00981"
  },
  {
    "id": "arXiv:2108.04106",
    "title": "Noisy Channel Language Model Prompting for Few-Shot Text Classification",
    "abstract": "Comments: 15 pages, 6 figures. Published as a conference paper at ACL 2022 (long). Code available at this https URL",
    "descriptor": "\nComments: 15 pages, 6 figures. Published as a conference paper at ACL 2022 (long). Code available at this https URL\n",
    "authors": [
      "Sewon Min",
      "Mike Lewis",
      "Hannaneh Hajishirzi",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.04106"
  },
  {
    "id": "arXiv:2108.04763",
    "title": "Imitation Learning by Reinforcement Learning",
    "abstract": "Comments: Published in ICLR 2022",
    "descriptor": "\nComments: Published in ICLR 2022\n",
    "authors": [
      "Kamil Ciosek"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04763"
  },
  {
    "id": "arXiv:2108.05018",
    "title": "Are Neural Ranking Models Robust?",
    "abstract": "Are Neural Ranking Models Robust?",
    "descriptor": "",
    "authors": [
      "Chen Wu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Yixing Fan",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.05018"
  },
  {
    "id": "arXiv:2108.05439",
    "title": "Gap-Dependent Unsupervised Exploration for Reinforcement Learning",
    "abstract": "Comments: AISTATS 2022 camera ready version",
    "descriptor": "\nComments: AISTATS 2022 camera ready version\n",
    "authors": [
      "Jingfeng Wu",
      "Vladimir Braverman",
      "Lin F. Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.05439"
  },
  {
    "id": "arXiv:2108.06332",
    "title": "FlipDA: Effective and Robust Data Augmentation for Few-Shot Learning",
    "abstract": "FlipDA: Effective and Robust Data Augmentation for Few-Shot Learning",
    "descriptor": "",
    "authors": [
      "Jing Zhou",
      "Yanan Zheng",
      "Jie Tang",
      "Jian Li",
      "Zhilin Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.06332"
  },
  {
    "id": "arXiv:2108.11269",
    "title": "Domain Adversarial RetinaNet as a Reference Algorithm for the MItosis  DOmain Generalization Challenge",
    "abstract": "Comments: This is the long version of the original pre-print. Due to a bug in our automatic threshold computation the detection threshold of our model changed from 0.62 to 0.64. This value was not optimized on any other images but the validation split of the MIDOG training set. 9 pages, 4 figures, 1 table",
    "descriptor": "\nComments: This is the long version of the original pre-print. Due to a bug in our automatic threshold computation the detection threshold of our model changed from 0.62 to 0.64. This value was not optimized on any other images but the validation split of the MIDOG training set. 9 pages, 4 figures, 1 table\n",
    "authors": [
      "Frauke Wilm",
      "Christian Marzahl",
      "Katharina Breininger",
      "Marc Aubreville"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11269"
  },
  {
    "id": "arXiv:2108.11792",
    "title": "A Statutory Article Retrieval Dataset in French",
    "abstract": "Comments: ACL 2022. Code and dataset are available at this https URL",
    "descriptor": "\nComments: ACL 2022. Code and dataset are available at this https URL\n",
    "authors": [
      "Antoine Louis",
      "Gerasimos Spanakis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.11792"
  },
  {
    "id": "arXiv:2108.13458",
    "title": "The Application of Convolutional Neural Networks for Tomographic  Reconstruction of Hyperspectral Images",
    "abstract": "Comments: 31 pages, 18 figures and 4 tables. v2: clarifications and references added, analyses and network diagrams updated",
    "descriptor": "\nComments: 31 pages, 18 figures and 4 tables. v2: clarifications and references added, analyses and network diagrams updated\n",
    "authors": [
      "Wei-Chih Huang",
      "Mads Svanborg Peters",
      "Mads Juul Ahlebaek",
      "Mads Toudal Frandsen",
      "Ren\u00e9 Lynge Eriksen",
      "Bjarke J\u00f8rgensen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13458"
  },
  {
    "id": "arXiv:2108.13968",
    "title": "Absent Subsequences in Words",
    "abstract": "Comments: An extended abstract appeared in the proceedings of the 15th International Conference on Reachability Problems RP2021",
    "descriptor": "\nComments: An extended abstract appeared in the proceedings of the 15th International Conference on Reachability Problems RP2021\n",
    "authors": [
      "Maria Kosche",
      "Tore Ko\u00df",
      "Florin Manea",
      "Stefan Siemer"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.13968"
  },
  {
    "id": "arXiv:2109.01036",
    "title": "MrSQM: Fast Time Series Classification with Symbolic Representations",
    "abstract": "MrSQM: Fast Time Series Classification with Symbolic Representations",
    "descriptor": "",
    "authors": [
      "Thach Le Nguyen",
      "Georgiana Ifrim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01036"
  },
  {
    "id": "arXiv:2109.03490",
    "title": "Spelling provides a precise (but sometimes misplaced) phonological  target. Orthography and acoustic variability in second language word learning",
    "abstract": "Spelling provides a precise (but sometimes misplaced) phonological  target. Orthography and acoustic variability in second language word learning",
    "descriptor": "",
    "authors": [
      "Pauline Welby",
      "Elsa Spinelli",
      "Audrey B\u00fcrki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2109.03490"
  },
  {
    "id": "arXiv:2109.05113",
    "title": "Natural Multicontact Walking for Robotic Assistive Devices via  Musculoskeletal Models and Hybrid Zero Dynamics",
    "abstract": "Comments: 8 pages, 7 figures",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Kejun Li",
      "Maegan Tucker",
      "Rachel Gehlhar",
      "Yisong Yue",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.05113"
  },
  {
    "id": "arXiv:2109.05791",
    "title": "Unified Kinematic and Dynamical Modeling of a Soft Robotic Arm by a  Piecewise Universal Joint Model",
    "abstract": "Comments: The paper will be merged into a new one",
    "descriptor": "\nComments: The paper will be merged into a new one\n",
    "authors": [
      "Zhanchi Wang",
      "Gaotian Wang",
      "Nikolaos M. Freris"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.05791"
  },
  {
    "id": "arXiv:2109.05948",
    "title": "A deep learning guided memetic framework for graph coloring problems",
    "abstract": "A deep learning guided memetic framework for graph coloring problems",
    "descriptor": "",
    "authors": [
      "Olivier Goudet",
      "Cyril Grelier",
      "Jin-Kao Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.05948"
  },
  {
    "id": "arXiv:2109.07977",
    "title": "Convex strategies for trajectory optimisation: application to the  Polytope Traversal Problem",
    "abstract": "Convex strategies for trajectory optimisation: application to the  Polytope Traversal Problem",
    "descriptor": "",
    "authors": [
      "Steve Tonneau"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07977"
  },
  {
    "id": "arXiv:2109.09033",
    "title": "Joint Distribution Alignment via Adversarial Learning for Domain  Adaptive Object Detection",
    "abstract": "Comments: Accepted by IEEE T-MM, 2021, the code is available at this https URL",
    "descriptor": "\nComments: Accepted by IEEE T-MM, 2021, the code is available at this https URL\n",
    "authors": [
      "Bo Zhang",
      "Tao Chen",
      "Bin Wang",
      "Ruoyao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.09033"
  },
  {
    "id": "arXiv:2109.10115",
    "title": "StereOBJ-1M: Large-scale Stereo Image Dataset for 6D Object Pose  Estimation",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Xingyu Liu",
      "Shun Iwase",
      "Kris M. Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.10115"
  },
  {
    "id": "arXiv:2109.10392",
    "title": "Multi-Modal Model Predictive Control through Batch Non-Holonomic  Trajectory Optimization: Application to Highway Driving",
    "abstract": "Comments: Published IEEE Robotics and Automation Letters (RA-L)",
    "descriptor": "\nComments: Published IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Vivek K. Adajania",
      "Aditya Sharma",
      "Anish Gupta",
      "Houman Masnavi",
      "K Madhava Krishna",
      "Arun K.Singh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.10392"
  },
  {
    "id": "arXiv:2109.12068",
    "title": "AraT5: Text-to-Text Transformers for Arabic Language Generation",
    "abstract": "Comments: Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL 2022). All authors contributed equally",
    "descriptor": "\nComments: Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL 2022). All authors contributed equally\n",
    "authors": [
      "El Moatez Billah Nagoudi",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.12068"
  },
  {
    "id": "arXiv:2109.12544",
    "title": "DAMix: A Density-Aware Mixup Augmentation for Single Image Dehazing  under Domain Shift",
    "abstract": "DAMix: A Density-Aware Mixup Augmentation for Single Image Dehazing  under Domain Shift",
    "descriptor": "",
    "authors": [
      "Chia-Ming Chang",
      "Tsung-Nan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12544"
  },
  {
    "id": "arXiv:2109.12663",
    "title": "The Finite-Skip Method for Multiserver Analysis",
    "abstract": "Comments: 29 pages. Under submission",
    "descriptor": "\nComments: 29 pages. Under submission\n",
    "authors": [
      "Isaac Grosof",
      "Mor Harchol-Balter",
      "Alan Scheller-Wolf"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2109.12663"
  },
  {
    "id": "arXiv:2109.12742",
    "title": "FewNLU: Benchmarking State-of-the-Art Methods for Few-Shot Natural  Language Understanding",
    "abstract": "FewNLU: Benchmarking State-of-the-Art Methods for Few-Shot Natural  Language Understanding",
    "descriptor": "",
    "authors": [
      "Yanan Zheng",
      "Jing Zhou",
      "Yujie Qian",
      "Ming Ding",
      "Chonghua Liao",
      "Jian Li",
      "Ruslan Salakhutdinov",
      "Jie Tang",
      "Sebastian Ruder",
      "Zhilin Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.12742"
  },
  {
    "id": "arXiv:2109.13930",
    "title": "All-Around Real Label Supervision: Cyclic Prototype Consistency Learning  for Semi-supervised Medical Image Segmentation",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Zhe Xu",
      "Yixin Wang",
      "Donghuan Lu",
      "Lequan Yu",
      "Jiangpeng Yan",
      "Jie Luo",
      "Kai Ma",
      "Yefeng Zheng",
      "Raymond Kai-yu Tong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.13930"
  },
  {
    "id": "arXiv:2109.15134",
    "title": "Variational Marginal Particle Filters",
    "abstract": "Comments: Accepted to AISTATS 2022",
    "descriptor": "\nComments: Accepted to AISTATS 2022\n",
    "authors": [
      "Jinlin Lai",
      "Justin Domke",
      "Daniel Sheldon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.15134"
  },
  {
    "id": "arXiv:2110.03484",
    "title": "Creating Training Sets via Weak Indirect Supervision",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Jieyu Zhang",
      "Bohan Wang",
      "Xiangchen Song",
      "Yujing Wang",
      "Yaming Yang",
      "Jing Bai",
      "Alexander Ratner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03484"
  },
  {
    "id": "arXiv:2110.04124",
    "title": "Ensemble Neural Representation Networks",
    "abstract": "Comments: IEEE Signal Processing Letters submitted, 5 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: IEEE Signal Processing Letters submitted, 5 pages, 6 figures, 2 tables\n",
    "authors": [
      "Milad Soltany Kadarvish",
      "Hesam Mojtahedi",
      "Hossein Entezari Zarch",
      "Amirhossein Kazerouni",
      "Alireza Morsali",
      "Azra Abtahi",
      "Farokh Marvasti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04124"
  },
  {
    "id": "arXiv:2110.05169",
    "title": "Learning a subspace of policies for online adaptation in Reinforcement  Learning",
    "abstract": "Learning a subspace of policies for online adaptation in Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "Jean-Baptiste Gaya",
      "Laure Soulier",
      "Ludovic Denoyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05169"
  },
  {
    "id": "arXiv:2110.05922",
    "title": "Trivial or impossible -- dichotomous data difficulty masks model  differences (on ImageNet and beyond)",
    "abstract": "Comments: Published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Kristof Meding",
      "Luca M. Schulze Buschoff",
      "Robert Geirhos",
      "Felix A. Wichmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.05922"
  },
  {
    "id": "arXiv:2110.06177",
    "title": "Tracking the risk of a deployed model and detecting harmful distribution  shifts",
    "abstract": "Comments: Accepted as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Accepted as a conference paper at ICLR 2022\n",
    "authors": [
      "Aleksandr Podkopaev",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06177"
  },
  {
    "id": "arXiv:2110.06850",
    "title": "Boosting the Certified Robustness of L-infinity Distance Nets",
    "abstract": "Comments: Accepted for ICLR 2022; 21 pages",
    "descriptor": "\nComments: Accepted for ICLR 2022; 21 pages\n",
    "authors": [
      "Bohang Zhang",
      "Du Jiang",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06850"
  },
  {
    "id": "arXiv:2110.07165",
    "title": "Semantically Distributed Robust Optimization for Vision-and-Language  Inference",
    "abstract": "Comments: Findings of ACL 2022; code available at this https URL",
    "descriptor": "\nComments: Findings of ACL 2022; code available at this https URL\n",
    "authors": [
      "Tejas Gokhale",
      "Abhishek Chaudhary",
      "Pratyay Banerjee",
      "Chitta Baral",
      "Yezhou Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.07165"
  },
  {
    "id": "arXiv:2110.07398",
    "title": "The Time Domain Linear Sampling Method for determining the shape of  multiple scatterers using electromagnetic waves",
    "abstract": "The Time Domain Linear Sampling Method for determining the shape of  multiple scatterers using electromagnetic waves",
    "descriptor": "",
    "authors": [
      "Timo L\u00e4hivaara",
      "Peter Monk",
      "Virginia Selgas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.07398"
  },
  {
    "id": "arXiv:2110.07586",
    "title": "Can Explanations Be Useful for Calibrating Black Box Models?",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Xi Ye",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.07586"
  },
  {
    "id": "arXiv:2110.07905",
    "title": "Towards Better Plasticity-Stability Trade-off in Incremental Learning: A  Simple Linear Connector",
    "abstract": "Towards Better Plasticity-Stability Trade-off in Incremental Learning: A  Simple Linear Connector",
    "descriptor": "",
    "authors": [
      "Guoliang Lin",
      "Hanlu Chu",
      "Hanjiang Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.07905"
  },
  {
    "id": "arXiv:2110.08018",
    "title": "Structural Characterization for Dialogue Disentanglement",
    "abstract": "Comments: Accepted by ACL2022",
    "descriptor": "\nComments: Accepted by ACL2022\n",
    "authors": [
      "Xinbei Ma",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08018"
  },
  {
    "id": "arXiv:2110.08243",
    "title": "Neural Dubber: Dubbing for Videos According to Scripts",
    "abstract": "Comments: Accepted by NeurIPS 2021; Project page at this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS 2021; Project page at this https URL\n",
    "authors": [
      "Chenxu Hu",
      "Qiao Tian",
      "Tingle Li",
      "Yuping Wang",
      "Yuxuan Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.08243"
  },
  {
    "id": "arXiv:2110.08296",
    "title": "ASPECTNEWS: Aspect-Oriented Summarization of News Documents",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Ojas Ahuja",
      "Jiacheng Xu",
      "Akshay Gupta",
      "Kevin Horecka",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08296"
  },
  {
    "id": "arXiv:2110.08303",
    "title": "Minimum Viable Device Drivers for ARM TrustZone",
    "abstract": "Comments: Eurosys 2022",
    "descriptor": "\nComments: Eurosys 2022\n",
    "authors": [
      "Liwei Guo",
      "Felix Xiaozhu Lin"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08303"
  },
  {
    "id": "arXiv:2110.08370",
    "title": "Training Dynamics for Text Summarization Models",
    "abstract": "Comments: ACL 2022 Findings",
    "descriptor": "\nComments: ACL 2022 Findings\n",
    "authors": [
      "Tanya Goyal",
      "Jiacheng Xu",
      "Junyi Jessy Li",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08370"
  },
  {
    "id": "arXiv:2110.08414",
    "title": "Graph-Theoretic Approach to Quantum Error Correction",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Robert Vandermolen",
      "Duncan Wright"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.08414"
  },
  {
    "id": "arXiv:2110.08415",
    "title": "Multilingual unsupervised sequence segmentation transfers to extremely  low-resource languages",
    "abstract": "Comments: ACL 2022 camera-ready",
    "descriptor": "\nComments: ACL 2022 camera-ready\n",
    "authors": [
      "C.M. Downey",
      "Shannon Drizin",
      "Levon Haroutunian",
      "Shivin Thukral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08415"
  },
  {
    "id": "arXiv:2110.08438",
    "title": "Unsupervised Natural Language Inference Using PHL Triplet Generation",
    "abstract": "Comments: ACL 2022 Findings",
    "descriptor": "\nComments: ACL 2022 Findings\n",
    "authors": [
      "Neeraj Varshney",
      "Pratyay Banerjee",
      "Tejas Gokhale",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08438"
  },
  {
    "id": "arXiv:2110.08484",
    "title": "A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based  Learning for Vision-Language Models",
    "abstract": "Comments: Accepted to ACL 2022",
    "descriptor": "\nComments: Accepted to ACL 2022\n",
    "authors": [
      "Woojeong Jin",
      "Yu Cheng",
      "Yelong Shen",
      "Weizhu Chen",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08484"
  },
  {
    "id": "arXiv:2110.09437",
    "title": "Ctrl-Shift: How Privacy Sentiment Changed from 2019 to 2021",
    "abstract": "Ctrl-Shift: How Privacy Sentiment Changed from 2019 to 2021",
    "descriptor": "",
    "authors": [
      "Angelica Goetzen",
      "Samuel Dooley",
      "Elissa M. Redmiles"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.09437"
  },
  {
    "id": "arXiv:2110.09759",
    "title": "A Regularization Method to Improve Adversarial Robustness of Neural  Networks for ECG Signal Classification",
    "abstract": "Comments: This paper has been published by Computers in Biology and Medicine",
    "descriptor": "\nComments: This paper has been published by Computers in Biology and Medicine\n",
    "authors": [
      "Linhai Ma",
      "Liang Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.09759"
  },
  {
    "id": "arXiv:2110.11405",
    "title": "Illiterate DALL-E Learns to Compose",
    "abstract": "Comments: Published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Gautam Singh",
      "Fei Deng",
      "Sungjin Ahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11405"
  },
  {
    "id": "arXiv:2110.12914",
    "title": "SILT: Self-supervised Lighting Transfer Using Implicit Image  Decomposition",
    "abstract": "Comments: Accepted to BMVC 2021. The code and pre-trained models can be found at this https URL",
    "descriptor": "\nComments: Accepted to BMVC 2021. The code and pre-trained models can be found at this https URL\n",
    "authors": [
      "Nikolina Kubiak",
      "Armin Mustafa",
      "Graeme Phillipson",
      "Stephen Jolly",
      "Simon Hadfield"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.12914"
  },
  {
    "id": "arXiv:2110.13409",
    "title": "Task-Aware Meta Learning-based Siamese Neural Network for Classifying  Obfuscated Malware",
    "abstract": "Task-Aware Meta Learning-based Siamese Neural Network for Classifying  Obfuscated Malware",
    "descriptor": "",
    "authors": [
      "Jinting Zhu",
      "Julian Jang-Jaccard",
      "Amardeep Singh",
      "Paul A. Watters",
      "Seyit Camtepe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13409"
  },
  {
    "id": "arXiv:2110.14583",
    "title": "Deep learning via message passing algorithms based on belief propagation",
    "abstract": "Deep learning via message passing algorithms based on belief propagation",
    "descriptor": "",
    "authors": [
      "Carlo Lucibello",
      "Fabrizio Pittorino",
      "Gabriele Perugini",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14583"
  },
  {
    "id": "arXiv:2111.00899",
    "title": "Equivariant Contrastive Learning",
    "abstract": "Comments: Camera Ready Revision. ICLR 2022. Discussion: this https URL Code: this https URL",
    "descriptor": "\nComments: Camera Ready Revision. ICLR 2022. Discussion: this https URL Code: this https URL\n",
    "authors": [
      "Rumen Dangovski",
      "Li Jing",
      "Charlotte Loh",
      "Seungwook Han",
      "Akash Srivastava",
      "Brian Cheung",
      "Pulkit Agrawal",
      "Marin Solja\u010di\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.00899"
  },
  {
    "id": "arXiv:2111.03017",
    "title": "MT3: Multi-Task Multitrack Music Transcription",
    "abstract": "Comments: ICLR 2022 camera-ready version",
    "descriptor": "\nComments: ICLR 2022 camera-ready version\n",
    "authors": [
      "Josh Gardner",
      "Ian Simon",
      "Ethan Manilow",
      "Curtis Hawthorne",
      "Jesse Engel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.03017"
  },
  {
    "id": "arXiv:2111.03390",
    "title": "Stress-informed Control of Medium- and High-head Hydropower Plants to  Reduce Penstock Fatigue",
    "abstract": "Stress-informed Control of Medium- and High-head Hydropower Plants to  Reduce Penstock Fatigue",
    "descriptor": "",
    "authors": [
      "Stefano Cassano",
      "Fabrizio Sossan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.03390"
  },
  {
    "id": "arXiv:2111.05806",
    "title": "On the efficiency of a general attack against the MOBS cryptosystem",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Christopher Battarbee",
      "Delaram Kahrobaei",
      "Dylan Tailor",
      "Siamak F. Shahandashti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.05806"
  },
  {
    "id": "arXiv:2111.07786",
    "title": "Independent SE(3)-Equivariant Models for End-to-End Rigid Protein  Docking",
    "abstract": "Independent SE(3)-Equivariant Models for End-to-End Rigid Protein  Docking",
    "descriptor": "",
    "authors": [
      "Octavian-Eugen Ganea",
      "Xinyuan Huang",
      "Charlotte Bunne",
      "Yatao Bian",
      "Regina Barzilay",
      "Tommi Jaakkola",
      "Andreas Krause"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.07786"
  },
  {
    "id": "arXiv:2111.08389",
    "title": "Analysis of Model-Free Reinforcement Learning Control Schemes on  self-balancing Wheeled Extendible System",
    "abstract": "Analysis of Model-Free Reinforcement Learning Control Schemes on  self-balancing Wheeled Extendible System",
    "descriptor": "",
    "authors": [
      "Kanishk .",
      "Rushil Kumar",
      "Vikas Rastogi",
      "Ajeet Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.08389"
  },
  {
    "id": "arXiv:2111.08712",
    "title": "Automatic Semantic Segmentation of the Lumbar Spine: Clinical  Applicability in a Multi-parametric and Multi-centre Study on Magnetic  Resonance Images",
    "abstract": "Comments: 18 pages, 9 Figures, 7 Tables; Supplementary Material: 6 pages, 8 Tables",
    "descriptor": "\nComments: 18 pages, 9 Figures, 7 Tables; Supplementary Material: 6 pages, 8 Tables\n",
    "authors": [
      "Jhon Jairo Saenz-Gamboa",
      "Julio Domenech",
      "Antonio Alonso-Manjarr\u00e9s",
      "Jon A. G\u00f3mez",
      "Maria de la Iglesia-Vay\u00e1"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08712"
  },
  {
    "id": "arXiv:2111.08862",
    "title": "Max-Min Grouped Bandits",
    "abstract": "Comments: AAAI 2022 paper + technical appendix (supplementary material), single-column format",
    "descriptor": "\nComments: AAAI 2022 paper + technical appendix (supplementary material), single-column format\n",
    "authors": [
      "Zhenlin Wang",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08862"
  },
  {
    "id": "arXiv:2111.09515",
    "title": "RAANet: Range-Aware Attention Network for LiDAR-based 3D Object  Detection with Auxiliary Density Level Estimation",
    "abstract": "RAANet: Range-Aware Attention Network for LiDAR-based 3D Object  Detection with Auxiliary Density Level Estimation",
    "descriptor": "",
    "authors": [
      "Yantao Lu",
      "Xuetao Hao",
      "Shiqi Sun",
      "Weiheng Chai",
      "Yu Ding",
      "Muchenxuan Tong",
      "Senem Velipasalar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09515"
  },
  {
    "id": "arXiv:2111.09789",
    "title": "Multi-Channel Bayesian Persuasion",
    "abstract": "Multi-Channel Bayesian Persuasion",
    "descriptor": "",
    "authors": [
      "Yakov Babichenko",
      "Inbal Talgam-Cohen",
      "Haifeng Xu",
      "Konstantin Zabarnyi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.09789"
  },
  {
    "id": "arXiv:2111.10958",
    "title": "MUM : Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object  Detection",
    "abstract": "Comments: Accept to CVPR2022",
    "descriptor": "\nComments: Accept to CVPR2022\n",
    "authors": [
      "JongMok Kim",
      "Jooyoung Jang",
      "Seunghyeon Seo",
      "Jisoo Jeong",
      "Jongkeun Na",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.10958"
  },
  {
    "id": "arXiv:2111.11187",
    "title": "PointMixer: MLP-Mixer for Point Cloud Understanding",
    "abstract": "PointMixer: MLP-Mixer for Point Cloud Understanding",
    "descriptor": "",
    "authors": [
      "Jaesung Choe",
      "Chunghyun Park",
      "Francois Rameau",
      "Jaesik Park",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11187"
  },
  {
    "id": "arXiv:2111.11223",
    "title": "Transfer Learning with Gaussian Processes for Bayesian Optimization",
    "abstract": "Transfer Learning with Gaussian Processes for Bayesian Optimization",
    "descriptor": "",
    "authors": [
      "Petru Tighineanu",
      "Kathrin Skubch",
      "Paul Baireuther",
      "Attila Reiss",
      "Felix Berkenkamp",
      "Julia Vinogradska"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11223"
  },
  {
    "id": "arXiv:2111.11704",
    "title": "Deep Point Cloud Reconstruction",
    "abstract": "Comments: ICLR 2022 accepted",
    "descriptor": "\nComments: ICLR 2022 accepted\n",
    "authors": [
      "Jaesung Choe",
      "Byeongin Joung",
      "Francois Rameau",
      "Jaesik Park",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11704"
  },
  {
    "id": "arXiv:2111.12594",
    "title": "Conditional Object-Centric Learning from Video",
    "abstract": "Comments: Published at ICLR 2022. Project page at this https URL",
    "descriptor": "\nComments: Published at ICLR 2022. Project page at this https URL\n",
    "authors": [
      "Thomas Kipf",
      "Gamaleldin F. Elsayed",
      "Aravindh Mahendran",
      "Austin Stone",
      "Sara Sabour",
      "Georg Heigold",
      "Rico Jonschkowski",
      "Alexey Dosovitskiy",
      "Klaus Greff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12594"
  },
  {
    "id": "arXiv:2111.13069",
    "title": "Continual Active Learning Using Pseudo-Domains for Limited Labelling  Resources and Changing Acquisition Characteristics",
    "abstract": "Comments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL",
    "descriptor": "\nComments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL\n",
    "authors": [
      "Matthias Perkonigg",
      "Johannes Hofmanninger",
      "Christian Herold",
      "Helmut Prosch",
      "Georg Langs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13069"
  },
  {
    "id": "arXiv:2111.13420",
    "title": "Confounder Identification-free Causal Visual Feature Learning",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Xin Li",
      "Zhizheng Zhang",
      "Guoqiang Wei",
      "Cuiling Lan",
      "Wenjun Zeng",
      "Xin Jin",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13420"
  },
  {
    "id": "arXiv:2111.13875",
    "title": "Topology optimization of stiff structures under self-weight for given  volume using a smooth Heaviside function",
    "abstract": "Comments: Accepted",
    "descriptor": "\nComments: Accepted\n",
    "authors": [
      "Prabhat Kumar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.13875"
  },
  {
    "id": "arXiv:2111.14173",
    "title": "CDGNet: Class Distribution Guided Network for Human Parsing",
    "abstract": "Comments: Accepted at CVPR 2022",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Kunliang Liu",
      "Ouk Choi",
      "Jianming Wang",
      "Wonjun Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14173"
  },
  {
    "id": "arXiv:2111.14549",
    "title": "MeshUDF: Fast and Differentiable Meshing of Unsigned Distance Field  Networks",
    "abstract": "MeshUDF: Fast and Differentiable Meshing of Unsigned Distance Field  Networks",
    "descriptor": "",
    "authors": [
      "Benoit Guillard",
      "Federico Stella",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14549"
  },
  {
    "id": "arXiv:2111.15174",
    "title": "CRIS: CLIP-Driven Referring Image Segmentation",
    "abstract": "Comments: 10 pages, 5 figures, Accepted by CVPR2022",
    "descriptor": "\nComments: 10 pages, 5 figures, Accepted by CVPR2022\n",
    "authors": [
      "Zhaoqing Wang",
      "Yu Lu",
      "Qiang Li",
      "Xunqiang Tao",
      "Yandong Guo",
      "Mingming Gong",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15174"
  },
  {
    "id": "arXiv:2112.00351",
    "title": "Energy Management of a Multi-Battery System for Renewable-Based High  Power EV Charging",
    "abstract": "Comments: Preprint submitted to Elsevier eTransportation",
    "descriptor": "\nComments: Preprint submitted to Elsevier eTransportation\n",
    "authors": [
      "Jan Engelhardt",
      "Jan Martin Zepter",
      "Tatiana Gabderakhmanova",
      "Mattia Marinelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.00351"
  },
  {
    "id": "arXiv:2112.02268",
    "title": "Bridging Pre-trained Models and Downstream Tasks for Source Code  Understanding",
    "abstract": "Comments: Accepted to the 44th International Conference on Software Engineering (ICSE 2022)",
    "descriptor": "\nComments: Accepted to the 44th International Conference on Software Engineering (ICSE 2022)\n",
    "authors": [
      "Deze Wang",
      "Zhouyang Jia",
      "Shanshan Li",
      "Yue Yu",
      "Yun Xiong",
      "Wei Dong",
      "Xiangke Liao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.02268"
  },
  {
    "id": "arXiv:2112.02932",
    "title": "Indian Kidney Exchange Program: A Game Theoretic Perspective",
    "abstract": "Comments: 43 pages, 52 figures, 9 tables",
    "descriptor": "\nComments: 43 pages, 52 figures, 9 tables\n",
    "authors": [
      "Arghya Bandyopadhyay",
      "Sajal Mukhopadhyay"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.02932"
  },
  {
    "id": "arXiv:2112.04011",
    "title": "Auxiliary Learning for Self-Supervised Video Representation via  Similarity-based Knowledge Distillation",
    "abstract": "Auxiliary Learning for Self-Supervised Video Representation via  Similarity-based Knowledge Distillation",
    "descriptor": "",
    "authors": [
      "Amirhossein Dadashzadeh",
      "Alan Whone",
      "Majid Mirmehdi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04011"
  },
  {
    "id": "arXiv:2112.04035",
    "title": "Relating transformers to models and neural representations of the  hippocampal formation",
    "abstract": "Relating transformers to models and neural representations of the  hippocampal formation",
    "descriptor": "",
    "authors": [
      "James C.R. Whittington",
      "Joseph Warren",
      "Timothy E.J. Behrens"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2112.04035"
  },
  {
    "id": "arXiv:2112.05244",
    "title": "An Experimental Design Perspective on Model-Based Reinforcement Learning",
    "abstract": "Comments: Conference paper at ICLR 2022",
    "descriptor": "\nComments: Conference paper at ICLR 2022\n",
    "authors": [
      "Viraj Mehta",
      "Biswajit Paria",
      "Jeff Schneider",
      "Stefano Ermon",
      "Willie Neiswanger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.05244"
  },
  {
    "id": "arXiv:2112.07342",
    "title": "Learning to Guide and to Be Guided in the Architect-Builder Problem",
    "abstract": "Learning to Guide and to Be Guided in the Architect-Builder Problem",
    "descriptor": "",
    "authors": [
      "Paul Barde",
      "Tristan Karch",
      "Derek Nowrouzezahrai",
      "Cl\u00e9ment Moulin-Frier",
      "Christopher Pal",
      "Pierre-Yves Oudeyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.07342"
  },
  {
    "id": "arXiv:2112.08544",
    "title": "NewsClaims: A New Benchmark for Claim Detection from News with  Background Knowledge",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Revanth Gangi Reddy",
      "Sai Chinthakindi",
      "Zhenhailong Wang",
      "Yi R. Fung",
      "Kathryn S. Conger",
      "Ahmed S. Elsayed",
      "Martha Palmer",
      "Preslav Nakov",
      "Eduard Hovy",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08544"
  },
  {
    "id": "arXiv:2112.09266",
    "title": "Incomplete Knowledge Graph Alignment",
    "abstract": "Incomplete Knowledge Graph Alignment",
    "descriptor": "",
    "authors": [
      "Vinh Van Tong",
      "Thanh Trung Huynh",
      "Thanh Tam Nguyen",
      "Hongzhi Yin",
      "Quoc Viet Hung Nguyen",
      "Quyet Thang Huynh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09266"
  },
  {
    "id": "arXiv:2112.10020",
    "title": "Cryptography from Pseudorandom Quantum States",
    "abstract": "Comments: 50 pages, 1 figure. Differences from v1: Expanded introduction; Corrected the ideal experiment in Definition 6.1; Expanded the implications to secure computations and other applications; General improvements",
    "descriptor": "\nComments: 50 pages, 1 figure. Differences from v1: Expanded introduction; Corrected the ideal experiment in Definition 6.1; Expanded the implications to secure computations and other applications; General improvements\n",
    "authors": [
      "Prabhanjan Ananth",
      "Luowen Qian",
      "Henry Yuen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.10020"
  },
  {
    "id": "arXiv:2112.11429",
    "title": "Machine Learning Emulation of Urban Land Surface Processes",
    "abstract": "Comments: Published version",
    "descriptor": "\nComments: Published version\n",
    "authors": [
      "David Meyer",
      "Sue Grimmond",
      "Peter Dueben",
      "Robin Hogan",
      "Maarten van Reeuwijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.11429"
  },
  {
    "id": "arXiv:2112.13548",
    "title": "Responsive Listening Head Generation: A Benchmark Dataset and Baseline",
    "abstract": "Comments: 14 pages, 11 figures",
    "descriptor": "\nComments: 14 pages, 11 figures\n",
    "authors": [
      "Mohan Zhou",
      "Yalong Bai",
      "Wei Zhang",
      "Ting Yao",
      "Tiejun Zhao",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.13548"
  },
  {
    "id": "arXiv:2112.15025",
    "title": "Constructing a Good Behavior Basis for Transfer using Generalized Policy  Updates",
    "abstract": "Comments: Published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Safa Alver",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15025"
  },
  {
    "id": "arXiv:2201.00057",
    "title": "Optimal Representations for Covariate Shift",
    "abstract": "Comments: Accepted at ICLR 2022",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Yangjun Ruan",
      "Yann Dubois",
      "Chris J. Maddison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.00057"
  },
  {
    "id": "arXiv:2201.01228",
    "title": "Exponentially Convergent Direct Adaptive Pole Placement Control of  Plants with Unmatched Uncertainty under FE Condition",
    "abstract": "Comments: 6 pages, 2 figures",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Anton Glushchenko",
      "Konstantin Lastochkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.01228"
  },
  {
    "id": "arXiv:2201.01427",
    "title": "Attention-based Dual Supervised Decoder for RGBD Semantic Segmentation",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Yang Zhang",
      "Yang Yang",
      "Chenyun Xiong",
      "Guodong Sun",
      "Yanwen Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.01427"
  },
  {
    "id": "arXiv:2201.01480",
    "title": "Control of a Soft Robotic Arm Using a Piecewise Universal Joint Model",
    "abstract": "Comments: The paper will be merged into a new one",
    "descriptor": "\nComments: The paper will be merged into a new one\n",
    "authors": [
      "Zhanchi Wang",
      "Gaotian Wang",
      "Xiaoping Chen",
      "Nikolaos M. Freris"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.01480"
  },
  {
    "id": "arXiv:2201.02410",
    "title": "Auction-Based Ex-Post-Payment Incentive Mechanism Design for Horizontal  Federated Learning with Reputation and Contribution Measurement",
    "abstract": "Auction-Based Ex-Post-Payment Incentive Mechanism Design for Horizontal  Federated Learning with Reputation and Contribution Measurement",
    "descriptor": "",
    "authors": [
      "Jingwen Zhang",
      "Yuezhou Wu",
      "Rong Pan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2201.02410"
  },
  {
    "id": "arXiv:2201.02664",
    "title": "Optimizing the Communication-Accuracy Trade-off in Federated Learning  with Rate-Distortion Theory",
    "abstract": "Optimizing the Communication-Accuracy Trade-off in Federated Learning  with Rate-Distortion Theory",
    "descriptor": "",
    "authors": [
      "Nicole Mitchell",
      "Johannes Ball\u00e9",
      "Zachary Charles",
      "Jakub Kone\u010dn\u00fd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.02664"
  },
  {
    "id": "arXiv:2201.05348",
    "title": "Software Engineering User Study Recruitment on Prolific: An Experience  Report",
    "abstract": "Comments: To appear at RoPES 2022",
    "descriptor": "\nComments: To appear at RoPES 2022\n",
    "authors": [
      "Brittany Reid",
      "Markus Wagner",
      "Marcelo d'Amorim",
      "Christoph Treude"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.05348"
  },
  {
    "id": "arXiv:2201.05869",
    "title": "Prototype Guided Network for Anomaly Segmentation",
    "abstract": "Comments: Need for edit,and improve the method for better performance",
    "descriptor": "\nComments: Need for edit,and improve the method for better performance\n",
    "authors": [
      "Yiqing Hao",
      "Yi Jin",
      "Gaoyun An"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05869"
  },
  {
    "id": "arXiv:2201.06354",
    "title": "Improving the Security of the IEEE 802.15.6 Standard for Medical BANs",
    "abstract": "Improving the Security of the IEEE 802.15.6 Standard for Medical BANs",
    "descriptor": "",
    "authors": [
      "Muhammad Ali Siddiqi",
      "Georg Hahn",
      "Said Hamdioui",
      "Wouter A. Serdijn",
      "Christos Strydis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.06354"
  },
  {
    "id": "arXiv:2201.08714",
    "title": "Equivalent Distance Geometry Error for Molecular Conformation Comparison",
    "abstract": "Equivalent Distance Geometry Error for Molecular Conformation Comparison",
    "descriptor": "",
    "authors": [
      "Shuwen Yang",
      "Tianyu Wen",
      "Ziyao Li",
      "Guojie Song"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.08714"
  },
  {
    "id": "arXiv:2201.08959",
    "title": "Few-shot Object Counting with Similarity-Aware Feature Enhancement",
    "abstract": "Few-shot Object Counting with Similarity-Aware Feature Enhancement",
    "descriptor": "",
    "authors": [
      "Zhiyuan You",
      "Yujun Shen",
      "Kai Yang",
      "Wenhan Luo",
      "Xin Lu",
      "Lei Cui",
      "Xinyi Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08959"
  },
  {
    "id": "arXiv:2201.09047",
    "title": "Online Auction-Based Incentive Mechanism Design for Horizontal Federated  Learning with Budget Constraint",
    "abstract": "Online Auction-Based Incentive Mechanism Design for Horizontal Federated  Learning with Budget Constraint",
    "descriptor": "",
    "authors": [
      "Jingwen Zhang",
      "Yuezhou Wu",
      "Rong Pan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.09047"
  },
  {
    "id": "arXiv:2201.10248",
    "title": "HoneyTop90: A 90-line MATLAB code for topology optimization using  honeycomb tessellation",
    "abstract": "Comments: In press",
    "descriptor": "\nComments: In press\n",
    "authors": [
      "Prabhat Kumar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.10248"
  },
  {
    "id": "arXiv:2201.10471",
    "title": "GIU-GANs: Global Information Utilization for Generative Adversarial  Networks",
    "abstract": "GIU-GANs: Global Information Utilization for Generative Adversarial  Networks",
    "descriptor": "",
    "authors": [
      "Yongqi Tian",
      "Xueyuan Gong",
      "Jialin Tang",
      "Binghua Su",
      "Xiaoxiang Liu",
      "Xinyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10471"
  },
  {
    "id": "arXiv:2201.10630",
    "title": "Game-Theoretic Energy Source Allocation Mechanism in Smart-Grids",
    "abstract": "Game-Theoretic Energy Source Allocation Mechanism in Smart-Grids",
    "descriptor": "",
    "authors": [
      "Eleni Stai",
      "Evangelia Kokolaki",
      "Lesia Mitridati",
      "Petros Tatoulis",
      "Ioannis Stavrakakis",
      "Gabriela Hug"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.10630"
  },
  {
    "id": "arXiv:2201.11701",
    "title": "Model Agnostic Interpretability for Multiple Instance Learning",
    "abstract": "Comments: 25 pages (9 content, 2 acknowledgement + references, 14 appendix). 16 figures (3 main content, 13 appendix). Submitted and accepted to ICLR 22, see this http URL Revisions: v2) Added additional acknowledgements v3) Updated to ICLR camera ready version",
    "descriptor": "\nComments: 25 pages (9 content, 2 acknowledgement + references, 14 appendix). 16 figures (3 main content, 13 appendix). Submitted and accepted to ICLR 22, see this http URL Revisions: v2) Added additional acknowledgements v3) Updated to ICLR camera ready version\n",
    "authors": [
      "Joseph Early",
      "Christine Evers",
      "Sarvapali Ramchurn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11701"
  },
  {
    "id": "arXiv:2202.02521",
    "title": "Comparative study of 3D object detection frameworks based on LiDAR data  and sensor fusion techniques",
    "abstract": "Comments: 2021 International Conference on Industrial Automation, Robotics and Control Engineering (IARCE 2021)",
    "descriptor": "\nComments: 2021 International Conference on Industrial Automation, Robotics and Control Engineering (IARCE 2021)\n",
    "authors": [
      "Sreenivasa Hikkal Venugopala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02521"
  },
  {
    "id": "arXiv:2202.03086",
    "title": "Machine Translation from Signed to Spoken Languages: State of the Art  and Challenges",
    "abstract": "Machine Translation from Signed to Spoken Languages: State of the Art  and Challenges",
    "descriptor": "",
    "authors": [
      "Mathieu De Coster",
      "Dimitar Shterionov",
      "Mieke Van Herreweghe",
      "Joni Dambre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03086"
  },
  {
    "id": "arXiv:2202.03672",
    "title": "APPFL: Open-Source Software Framework for Privacy-Preserving Federated  Learning",
    "abstract": "Comments: 9 pages, 4 figures, 1 table",
    "descriptor": "\nComments: 9 pages, 4 figures, 1 table\n",
    "authors": [
      "Minseok Ryu",
      "Youngdae Kim",
      "Kibaek Kim",
      "Ravi K. Madduri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03672"
  },
  {
    "id": "arXiv:2202.04303",
    "title": "TinyM$^2$Net: A Flexible System Algorithm Co-designed Multimodal  Learning Framework for Tiny Devices",
    "abstract": "Comments: tinyML Research Symposium 2022",
    "descriptor": "\nComments: tinyML Research Symposium 2022\n",
    "authors": [
      "Hasib-Al Rashid",
      "Pretom Roy Ovi",
      "Carl Busart",
      "Aryya Gangopadhyay",
      "Tinoosh Mohsenin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04303"
  },
  {
    "id": "arXiv:2202.04647",
    "title": "Multi-modal unsupervised brain image registration using edge maps",
    "abstract": "Comments: Accepted to IEEE International Symposium on Biomedical Imaging (ISBI) 2022",
    "descriptor": "\nComments: Accepted to IEEE International Symposium on Biomedical Imaging (ISBI) 2022\n",
    "authors": [
      "Vasiliki Sideri-Lampretsa",
      "Georgios Kaissis",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04647"
  },
  {
    "id": "arXiv:2202.05458",
    "title": "Conditional Contrastive Learning with Kernel",
    "abstract": "Conditional Contrastive Learning with Kernel",
    "descriptor": "",
    "authors": [
      "Yao-Hung Hubert Tsai",
      "Tianqin Li",
      "Martin Q. Ma",
      "Han Zhao",
      "Kun Zhang",
      "Louis-Philippe Morency",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05458"
  },
  {
    "id": "arXiv:2202.05735",
    "title": "SleepPPG-Net: a deep learning algorithm for robust sleep staging from  continuous photoplethysmography",
    "abstract": "Comments: 23 pages, 10 figures",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Kevin Kotzen",
      "Peter H. Charlton",
      "Sharon Salabi",
      "Lea Amar",
      "Amir Landesberg",
      "Joachim A. Behar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05735"
  },
  {
    "id": "arXiv:2202.06205",
    "title": "StoryBuddy: A Human-AI Collaborative Chatbot for Parent-Child  Interactive Storytelling with Flexible Parental Involvement",
    "abstract": "Comments: Published at CHI 2022",
    "descriptor": "\nComments: Published at CHI 2022\n",
    "authors": [
      "Zheng Zhang",
      "Ying Xu",
      "Yanhao Wang",
      "Bingsheng Yao",
      "Daniel Ritchie",
      "Tongshuang Wu",
      "Mo Yu",
      "Dakuo Wang",
      "Toby Jia-Jun Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06205"
  },
  {
    "id": "arXiv:2202.07506",
    "title": "Confidence Threshold Neural Diving",
    "abstract": "Comments: Published on the NeurIPS 2021 ML4CO Competition Proceedings section, see this https URL",
    "descriptor": "\nComments: Published on the NeurIPS 2021 ML4CO Competition Proceedings section, see this https URL\n",
    "authors": [
      "Taehyun Yoon"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.07506"
  },
  {
    "id": "arXiv:2202.08900",
    "title": "Attributable-Watermarking of Speech Generative Models",
    "abstract": "Comments: Accepted to International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2022",
    "descriptor": "\nComments: Accepted to International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2022\n",
    "authors": [
      "Yongbaek Cho",
      "Changhoon Kim",
      "Yezhou Yang",
      "Yi Ren"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.08900"
  },
  {
    "id": "arXiv:2202.08901",
    "title": "The Effects of Interactive AI Design on User Behavior: An Eye-tracking  Study of Fact-checking COVID-19 Claims",
    "abstract": "The Effects of Interactive AI Design on User Behavior: An Eye-tracking  Study of Fact-checking COVID-19 Claims",
    "descriptor": "",
    "authors": [
      "Li Shi",
      "Nilavra Bhattacharya",
      "Anubrata Das",
      "Matthew Lease",
      "Jacek Gwidzka"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.08901"
  },
  {
    "id": "arXiv:2202.10094",
    "title": "Point Cloud Denoising via Momentum Ascent in Gradient Fields",
    "abstract": "Comments: 5 pages, 5 figures",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Yaping Zhao",
      "Haitian Zheng",
      "Zhongrui Wang",
      "Jiebo Luo",
      "Edmund Y. Lam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.10094"
  },
  {
    "id": "arXiv:2202.10240",
    "title": "Rethinking the Zigzag Flattening for Image Reading",
    "abstract": "Rethinking the Zigzag Flattening for Image Reading",
    "descriptor": "",
    "authors": [
      "Qingsong Zhao",
      "Zhipeng Zhou",
      "Shuguang Dou",
      "Yangguang Li",
      "Rui Lu",
      "Yin Wang",
      "Cairong Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.10240"
  },
  {
    "id": "arXiv:2202.10972",
    "title": "Estimation of Looming from LiDAR",
    "abstract": "Estimation of Looming from LiDAR",
    "descriptor": "",
    "authors": [
      "Juan D. Yepes",
      "Daniel Raviv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.10972"
  },
  {
    "id": "arXiv:2202.12012",
    "title": "Strict universes for Grothendieck topoi",
    "abstract": "Comments: Added acknowledgments and citations, generalized section 3.3, fixed typographic errors",
    "descriptor": "\nComments: Added acknowledgments and citations, generalized section 3.3, fixed typographic errors\n",
    "authors": [
      "Daniel Gratzer",
      "Michael Shulman",
      "Jonathan Sterling"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.12012"
  },
  {
    "id": "arXiv:2202.12163",
    "title": "Attentive Temporal Pooling for Conformer-based Streaming Language  Identification in Long-form Speech",
    "abstract": "Attentive Temporal Pooling for Conformer-based Streaming Language  Identification in Long-form Speech",
    "descriptor": "",
    "authors": [
      "Quan Wang",
      "Yang Yu",
      "Jason Pelecanos",
      "Yiling Huang",
      "Ignacio Lopez Moreno"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12163"
  },
  {
    "id": "arXiv:2202.12403",
    "title": "Learning Transferable Reward for Query Object Localization with Policy  Adaptation",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Tingfeng Li",
      "Shaobo Han",
      "Martin Renqiang Min",
      "Dimitris N. Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12403"
  },
  {
    "id": "arXiv:2202.13100",
    "title": "Semantic Supervision: Enabling Generalization over Output Spaces",
    "abstract": "Semantic Supervision: Enabling Generalization over Output Spaces",
    "descriptor": "",
    "authors": [
      "Austin W. Hanjie",
      "Ameet Deshpande",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.13100"
  },
  {
    "id": "arXiv:2202.13305",
    "title": "Private Location Sharing for Decentralized Routing services",
    "abstract": "Private Location Sharing for Decentralized Routing services",
    "descriptor": "",
    "authors": [
      "Matthew Tsao",
      "Kaidi Yang",
      "Karthik Gopalakrishnan",
      "Marco Pavone"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.13305"
  },
  {
    "id": "arXiv:2202.13363",
    "title": "Variational Autoencoder with Disentanglement Priors for Low-Resource  Task-Specific Natural Language Generation",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Zhuang Li",
      "Lizhen Qu",
      "Qiongkai Xu",
      "Tongtong Wu",
      "Tianyang Zhan",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.13363"
  },
  {
    "id": "arXiv:2202.13404",
    "title": "Improving Candidate Retrieval with Entity Profile Generation for  Wikidata Entity Linking",
    "abstract": "Comments: ACL 2022 (Findings)",
    "descriptor": "\nComments: ACL 2022 (Findings)\n",
    "authors": [
      "Tuan Manh Lai",
      "Heng Ji",
      "ChengXiang Zhai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.13404"
  },
  {
    "id": "arXiv:2202.13961",
    "title": "A Spatio-Causal Growth Model Explains the Pareto Principle",
    "abstract": "A Spatio-Causal Growth Model Explains the Pareto Principle",
    "descriptor": "",
    "authors": [
      "Andre F. Ribeiro"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.13961"
  },
  {
    "id": "arXiv:2203.00113",
    "title": "Understanding Digits in Identifier Names: An Exploratory Study",
    "abstract": "Comments: This study has been accepted for publication at: The 1st International Workshop on Natural Language-based Software Engineering (NLBSE 2022)",
    "descriptor": "\nComments: This study has been accepted for publication at: The 1st International Workshop on Natural Language-based Software Engineering (NLBSE 2022)\n",
    "authors": [
      "Anthony Peruma",
      "Christian D. Newman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.00113"
  },
  {
    "id": "arXiv:2203.00120",
    "title": "Neural Ordinary Differential Equations for Nonlinear System  Identification",
    "abstract": "Neural Ordinary Differential Equations for Nonlinear System  Identification",
    "descriptor": "",
    "authors": [
      "Aowabin Rahman",
      "J\u00e1n Drgo\u0148a",
      "Aaron Tuor",
      "Jan Strube"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.00120"
  },
  {
    "id": "arXiv:2203.00162",
    "title": "Do Transformers use variable binding?",
    "abstract": "Comments: We noticed an implementation error in the experiment code, due to which the experiments need to be redone",
    "descriptor": "\nComments: We noticed an implementation error in the experiment code, due to which the experiments need to be redone\n",
    "authors": [
      "Tommi Gr\u00f6ndahl",
      "N. Asokan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.00162"
  },
  {
    "id": "arXiv:2203.01570",
    "title": "Representing Mixtures of Word Embeddings with Mixtures of Topic  Embeddings",
    "abstract": "Comments: Proceedings of ICLR, 2022",
    "descriptor": "\nComments: Proceedings of ICLR, 2022\n",
    "authors": [
      "Dongsheng Wang",
      "Dandan Guo",
      "He Zhao",
      "Huangjie Zheng",
      "Korawat Tanwisuth",
      "Bo Chen",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.01570"
  },
  {
    "id": "arXiv:2203.02763",
    "title": "Online List Labeling: Breaking the $\\log^2n$ Barrier",
    "abstract": "Online List Labeling: Breaking the $\\log^2n$ Barrier",
    "descriptor": "",
    "authors": [
      "Michael A. Bender",
      "Alexander Conway",
      "Mart\u00edn Farach-Colton",
      "Hanna Koml\u00f3s",
      "William Kuszmaul",
      "Nicole Wein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.02763"
  },
  {
    "id": "arXiv:2203.02861",
    "title": "Optimally scheduling public safety power shutoffs",
    "abstract": "Optimally scheduling public safety power shutoffs",
    "descriptor": "",
    "authors": [
      "Antoine Lesage-Landry",
      "F\u00e9lix Pellerin",
      "Joshua A. Taylor",
      "Duncan S. Callaway"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.02861"
  },
  {
    "id": "arXiv:2203.03079",
    "title": "GlideNet: Global, Local and Intrinsic based Dense Embedding NETwork for  Multi-category Attributes Prediction",
    "abstract": "Comments: CVPR 2022, 16 pages (including supplementary), CAR Dataset, VAW Dataset, this http URL",
    "descriptor": "\nComments: CVPR 2022, 16 pages (including supplementary), CAR Dataset, VAW Dataset, this http URL\n",
    "authors": [
      "Kareem Metwaly",
      "Aerin Kim",
      "Elliot Branson",
      "Vishal Monga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03079"
  },
  {
    "id": "arXiv:2203.03099",
    "title": "Singular Value Perturbation and Deep Network Optimization",
    "abstract": "Singular Value Perturbation and Deep Network Optimization",
    "descriptor": "",
    "authors": [
      "Rudolf H. Riedi",
      "Randall Balestriero",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.03099"
  },
  {
    "id": "arXiv:2203.03377",
    "title": "A Random Access Protocol for RIS-Aided Wireless Communications",
    "abstract": "Comments: 5 pages, 2 figures, conference version",
    "descriptor": "\nComments: 5 pages, 2 figures, conference version\n",
    "authors": [
      "Victor Croisfelt",
      "Fabio Saggese",
      "Israel Leyva-Mayorga",
      "Radoslaw Kotaba",
      "Gabriele Gradoni",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.03377"
  },
  {
    "id": "arXiv:2203.03949",
    "title": "RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering",
    "abstract": "Comments: 17 pages, 10 figures",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "Di Chang",
      "Alja\u017e Bo\u017ei\u010d",
      "Tong Zhang",
      "Qingsong Yan",
      "Yingcong Chen",
      "Sabine S\u00fcsstrunk",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03949"
  },
  {
    "id": "arXiv:2203.03952",
    "title": "EdgeFormer: Improving Light-weight ConvNets by Learning from Vision  Transformers",
    "abstract": "Comments: 14 pages, 7 figures and 4 tables. Code is available at this https URL",
    "descriptor": "\nComments: 14 pages, 7 figures and 4 tables. Code is available at this https URL\n",
    "authors": [
      "Haokui Zhang",
      "Wenze Hu",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03952"
  },
  {
    "id": "arXiv:2203.04176",
    "title": "Variational methods for simulation-based inference",
    "abstract": "Variational methods for simulation-based inference",
    "descriptor": "",
    "authors": [
      "Manuel Gl\u00f6ckler",
      "Michael Deistler",
      "Jakob H. Macke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04176"
  },
  {
    "id": "arXiv:2203.04304",
    "title": "Dynamic Dual-Output Diffusion Models",
    "abstract": "Comments: To be presented at CVPR 2022",
    "descriptor": "\nComments: To be presented at CVPR 2022\n",
    "authors": [
      "Yaniv Benny",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.04304"
  },
  {
    "id": "arXiv:2203.04530",
    "title": "Design of Detectors at the Electron Ion Collider with Artificial  Intelligence",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Cristiano Fanelli"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.04530"
  },
  {
    "id": "arXiv:2203.04771",
    "title": "Multiscale Convolutional Transformer with Center Mask Pretraining for  Hyperspectral Image Classificationtion",
    "abstract": "Comments: 8 pages, 26 figures, conference paper",
    "descriptor": "\nComments: 8 pages, 26 figures, conference paper\n",
    "authors": [
      "Yifan Wang",
      "Sen Jia",
      "Zhongfan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04771"
  },
  {
    "id": "arXiv:2203.05118",
    "title": "Semi-supervision semantic segmentation with uncertainty-guided self  cross supervision",
    "abstract": "Semi-supervision semantic segmentation with uncertainty-guided self  cross supervision",
    "descriptor": "",
    "authors": [
      "Yunyang Zhang",
      "Zhiqiang Gong",
      "Xiaohu Zheng",
      "Xiaoyu Zhao",
      "Wen Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05118"
  },
  {
    "id": "arXiv:2203.05140",
    "title": "Speciesist Language and Nonhuman Animal Bias in English Masked Language  Models",
    "abstract": "Comments: Anonymous previous version of this paper is accessible at (this https URL). Our code will be available at (this https URL)",
    "descriptor": "\nComments: Anonymous previous version of this paper is accessible at (this https URL). Our code will be available at (this https URL)\n",
    "authors": [
      "Masashi Takeshita",
      "Rafal Rzepka",
      "Kenji Araki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05140"
  },
  {
    "id": "arXiv:2203.05151",
    "title": "Frequency-driven Imperceptible Adversarial Attack on Semantic Similarity",
    "abstract": "Comments: 10 pages, 7 figure, CVPR 2022 conference",
    "descriptor": "\nComments: 10 pages, 7 figure, CVPR 2022 conference\n",
    "authors": [
      "Cheng Luo",
      "Qinliang Lin",
      "Weicheng Xie",
      "Bizhu Wu",
      "Jinheng Xie",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05151"
  },
  {
    "id": "arXiv:2203.05238",
    "title": "Back to Reality: Weakly-supervised 3D Object Detection with Shape-guided  Label Enhancement",
    "abstract": "Comments: Accepted to CVPR2022",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Xiuwei Xu",
      "Yifan Wang",
      "Yu Zheng",
      "Yongming Rao",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05238"
  },
  {
    "id": "arXiv:2203.05340",
    "title": "Domain Generalization via Shuffled Style Assembly for Face Anti-Spoofing",
    "abstract": "Comments: Accepted by CVPR2022",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Zhuo Wang",
      "Zezheng Wang",
      "Zitong Yu",
      "Weihong Deng",
      "Jiahong Li",
      "Size Li",
      "Zhongyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05340"
  },
  {
    "id": "arXiv:2203.05866",
    "title": "Uncloneable Decryptors from Quantum Copy-Protection",
    "abstract": "Uncloneable Decryptors from Quantum Copy-Protection",
    "descriptor": "",
    "authors": [
      "Or Sattath",
      "Shai Wyborski"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.05866"
  },
  {
    "id": "arXiv:2203.05886",
    "title": "Improved uniform error bounds on time-splitting methods for the  long-time dynamics of the weakly nonlinear Dirac equation",
    "abstract": "Improved uniform error bounds on time-splitting methods for the  long-time dynamics of the weakly nonlinear Dirac equation",
    "descriptor": "",
    "authors": [
      "Weizhu Bao",
      "Yongyong Cai",
      "Feng Yue"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.05886"
  },
  {
    "id": "arXiv:2203.05903",
    "title": "Formal Control Synthesis for Stochastic Neural Network Dynamic Models",
    "abstract": "Formal Control Synthesis for Stochastic Neural Network Dynamic Models",
    "descriptor": "",
    "authors": [
      "Steven Adams",
      "Morteza Lahijanian",
      "Luca Laurenti"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05903"
  },
  {
    "id": "arXiv:2203.05925",
    "title": "Formalizing Cost Fairness for Two-Party Exchange Protocols using Game  Theory and Applications to Blockchain (Extended Version)",
    "abstract": "Comments: Updated acknowledgements",
    "descriptor": "\nComments: Updated acknowledgements\n",
    "authors": [
      "Matthias Lohr",
      "Kenneth Skiba",
      "Marco Konersmann",
      "Jan J\u00fcrjens",
      "Steffen Staab"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.05925"
  },
  {
    "id": "arXiv:2203.06172",
    "title": "Deep AutoAugment",
    "abstract": "Comments: ICLR 2022 camera-ready. Code: this https URL",
    "descriptor": "\nComments: ICLR 2022 camera-ready. Code: this https URL\n",
    "authors": [
      "Yu Zheng",
      "Zhi Zhang",
      "Shen Yan",
      "Mi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.06172"
  },
  {
    "id": "arXiv:2203.06239",
    "title": "Sampling Bias Correction for Supervised Machine Learning: A Bayesian  Inference Approach with Practical Applications",
    "abstract": "Comments: 13 pages, 0 figures",
    "descriptor": "\nComments: 13 pages, 0 figures\n",
    "authors": [
      "Max Sklar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06239"
  },
  {
    "id": "arXiv:2203.06271",
    "title": "Bit-Metric Decoding Rate in Multi-User MIMO Systems: Theory",
    "abstract": "Comments: This is the first part of a two-part paper. This part has 28 pages and 6 figures. The second part is titled \"Bit-Metric Decoding Rate in Multi-User MIMO Systems: Applications\". References have been updated in this version",
    "descriptor": "\nComments: This is the first part of a two-part paper. This part has 28 pages and 6 figures. The second part is titled \"Bit-Metric Decoding Rate in Multi-User MIMO Systems: Applications\". References have been updated in this version\n",
    "authors": [
      "K. Pavan Srinath",
      "Jakob Hoydis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06271"
  },
  {
    "id": "arXiv:2203.06273",
    "title": "Bit-Metric Decoding Rate in Multi-User MIMO Systems: Applications",
    "abstract": "Comments: This is the second part of a two-part paper. This part has 24 pages and 11 figures. The first part is titled \"Bit-Metric Decoding Rate in Multi-User MIMO Systems: Theory\". Section II and References have been updated in this version",
    "descriptor": "\nComments: This is the second part of a two-part paper. This part has 24 pages and 11 figures. The first part is titled \"Bit-Metric Decoding Rate in Multi-User MIMO Systems: Theory\". Section II and References have been updated in this version\n",
    "authors": [
      "K. Pavan Srinath",
      "Jakob Hoydis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06273"
  },
  {
    "id": "arXiv:2203.06319",
    "title": "PillarGrid: Deep Learning-based Cooperative Perception for 3D Object  Detection from Onboard-Roadside LiDAR",
    "abstract": "Comments: Submitted to The 25th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2022)",
    "descriptor": "\nComments: Submitted to The 25th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2022)\n",
    "authors": [
      "Zhengwei Bai",
      "Guoyuan Wu",
      "Matthew J. Barth",
      "Yongkang Liu",
      "Emrah Akin Sisbot",
      "Kentaro Oguchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.06319"
  },
  {
    "id": "arXiv:2203.06371",
    "title": "Varying Coefficient Linear Discriminant Analysis for Dynamic Data",
    "abstract": "Varying Coefficient Linear Discriminant Analysis for Dynamic Data",
    "descriptor": "",
    "authors": [
      "Yajie Bao",
      "Yuyang Liu"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06371"
  },
  {
    "id": "arXiv:2203.06451",
    "title": "Bringing Rolling Shutter Images Alive with Dual Reversed Distortion",
    "abstract": "Bringing Rolling Shutter Images Alive with Dual Reversed Distortion",
    "descriptor": "",
    "authors": [
      "Zhihang Zhong",
      "Mingdeng Cao",
      "Xiao Sun",
      "Zhirong Wu",
      "Zhongyi Zhou",
      "Yinqiang Zheng",
      "Stephen Lin",
      "Imari Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06451"
  },
  {
    "id": "arXiv:2203.06474",
    "title": "Optimizer Amalgamation",
    "abstract": "Comments: To appear in ICLR 2022",
    "descriptor": "\nComments: To appear in ICLR 2022\n",
    "authors": [
      "Tianshu Huang",
      "Tianlong Chen",
      "Sijia Liu",
      "Shiyu Chang",
      "Lisa Amini",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06474"
  },
  {
    "id": "arXiv:2203.06568",
    "title": "Semidefinite programming bounds for binary codes from a split  Terwilliger algebra",
    "abstract": "Semidefinite programming bounds for binary codes from a split  Terwilliger algebra",
    "descriptor": "",
    "authors": [
      "Pin-Chieh Tseng",
      "Ching-Yi Lai",
      "Wei-Hsuan Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.06568"
  },
  {
    "id": "arXiv:2203.06581",
    "title": "An implicitly extended Crank-Nicolson scheme for the heat equation on  time-dependent domains",
    "abstract": "An implicitly extended Crank-Nicolson scheme for the heat equation on  time-dependent domains",
    "descriptor": "",
    "authors": [
      "Stefan Frei",
      "Maneesh Kumar Singh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.06581"
  },
  {
    "id": "arXiv:2203.06587",
    "title": "Policy Learning for Robust Markov Decision Process with a Mismatched  Generative Model",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Jialian Li",
      "Tongzheng Ren",
      "Dong Yan",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.06587"
  },
  {
    "id": "arXiv:2203.06605",
    "title": "Depth-Aware Generative Adversarial Network for Talking Head Video  Generation",
    "abstract": "Comments: 15 Pages; Accepted by CVPR 2022",
    "descriptor": "\nComments: 15 Pages; Accepted by CVPR 2022\n",
    "authors": [
      "Fa-Ting Hong",
      "Longhao Zhang",
      "Li Shen",
      "Dan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06605"
  },
  {
    "id": "arXiv:2203.06631",
    "title": "A ROS Architecture for Personalised HRI with a Bartender Social Robot",
    "abstract": "Comments: 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)",
    "descriptor": "\nComments: 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Alessandra Rossi",
      "Maria Di Maro",
      "Antonio Origlia",
      "Agostino Palmiero",
      "Silvia Rossi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.06631"
  },
  {
    "id": "arXiv:2203.06667",
    "title": "Towards Visual-Prompt Temporal Answering Grounding in Medical  Instructional Video",
    "abstract": "Comments: 7 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 7 pages, 5 figures, 3 tables\n",
    "authors": [
      "Bin Li",
      "Yixuan Weng",
      "Bin Sun",
      "Shutao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.06667"
  },
  {
    "id": "arXiv:2203.06728",
    "title": "SciNLI: A Corpus for Natural Language Inference on Scientific Text",
    "abstract": "SciNLI: A Corpus for Natural Language Inference on Scientific Text",
    "descriptor": "",
    "authors": [
      "Mobashir Sadat",
      "Cornelia Caragea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.06728"
  },
  {
    "id": "arXiv:2203.06759",
    "title": "Adaptive Gap Entangled Polynomial Coding for Multi-Party Computation at  the Edge",
    "abstract": "Comments: 22 pages, 9 figures",
    "descriptor": "\nComments: 22 pages, 9 figures\n",
    "authors": [
      "Elahe Vedadi",
      "Yasaman Keshtkarjahromi",
      "Hulya Seferoglu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.06759"
  },
  {
    "id": "arXiv:2203.06762",
    "title": "The development of battery storage systems in Germany: A market review  (status 2022)",
    "abstract": "Comments: 15 pages, 13 Figures, 3 Tables",
    "descriptor": "\nComments: 15 pages, 13 Figures, 3 Tables\n",
    "authors": [
      "Jan Figgener",
      "Christopher Hecht",
      "David Haberschusz",
      "Jakob Bors",
      "Kai Gerd Spreuer",
      "Kai-Philipp Kairies",
      "Peter Stenzel",
      "Dirk Uwe Sauer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.06762"
  },
  {
    "id": "arXiv:2203.06786",
    "title": "Similarity Equivariant Linear Transformation of Joint Orientation-Scale  Space Representations",
    "abstract": "Comments: 17 pages, 2 figures",
    "descriptor": "\nComments: 17 pages, 2 figures\n",
    "authors": [
      "Xinhua Zhang",
      "Lance R. Williams"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06786"
  },
  {
    "id": "arXiv:2203.06791",
    "title": "HDPView: Differentially Private Materialized View for Exploring High  Dimensional Relational Data",
    "abstract": "HDPView: Differentially Private Materialized View for Exploring High  Dimensional Relational Data",
    "descriptor": "",
    "authors": [
      "Fumiyuki Kato",
      "Tsubasa Takahashi",
      "Shun Takagi",
      "Yang Cao",
      "Seng Pei Liew",
      "Masatoshi Yoshikawa"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.06791"
  },
  {
    "id": "arXiv:2203.06904",
    "title": "Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for  Pre-trained Language Models",
    "abstract": "Comments: 49 pages",
    "descriptor": "\nComments: 49 pages\n",
    "authors": [
      "Ning Ding",
      "Yujia Qin",
      "Guang Yang",
      "Fuchao Wei",
      "Zonghan Yang",
      "Yusheng Su",
      "Shengding Hu",
      "Yulin Chen",
      "Chi-Min Chan",
      "Weize Chen",
      "Jing Yi",
      "Weilin Zhao",
      "Xiaozhi Wang",
      "Zhiyuan Liu",
      "Hai-Tao Zheng",
      "Jianfei Chen",
      "Yang Liu",
      "Jie Tang",
      "Juanzi Li",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06904"
  },
  {
    "id": "arXiv:2203.06935",
    "title": "A Systematic Review on Affective Computing: Emotion Models, Databases,  and Recent Advances",
    "abstract": "A Systematic Review on Affective Computing: Emotion Models, Databases,  and Recent Advances",
    "descriptor": "",
    "authors": [
      "Yan Wang",
      "Wei Song",
      "Wei Tao",
      "Antonio Liotta",
      "Dawei Yang",
      "Xinlei Li",
      "Shuyong Gao",
      "Yixuan Sun",
      "Weifeng Ge",
      "Wei Zhang",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.06935"
  },
  {
    "id": "arXiv:2203.06947",
    "title": "XYLayoutLM: Towards Layout-Aware Multimodal Networks For Visually-Rich  Document Understanding",
    "abstract": "Comments: Accepted by CVPR2022",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Zhangxuan Gu",
      "Changhua Meng",
      "Ke Wang",
      "Jun Lan",
      "Weiqiang Wang",
      "Ming Gu",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.06947"
  },
  {
    "id": "arXiv:2203.06951",
    "title": "Computer Vision and Deep Learning for Fish Classification in Underwater  Habitats: A Survey",
    "abstract": "Comments: Submitted to Fish and Fisheries , Wiley Online Library",
    "descriptor": "\nComments: Submitted to Fish and Fisheries , Wiley Online Library\n",
    "authors": [
      "Alzayat Saleh",
      "Marcus Sheaves",
      "Mostafa Rahimi Azghadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06951"
  },
  {
    "id": "arXiv:2203.06967",
    "title": "Blind2Unblind: Self-Supervised Image Denoising with Visible Blind Spots",
    "abstract": "Comments: Accepted to CVPR2022",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Zejin Wang",
      "Jiazheng Liu",
      "Guoqing Li",
      "Hua Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06967"
  },
  {
    "id": "arXiv:2203.07096",
    "title": "On Semialgebraic Range Reporting",
    "abstract": "Comments: Full version of the SoCG'22 paper",
    "descriptor": "\nComments: Full version of the SoCG'22 paper\n",
    "authors": [
      "Peyman Afshani",
      "Pingan Cheng"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.07096"
  },
  {
    "id": "arXiv:2203.07138",
    "title": "Adversarial amplitude swap towards robust image classifiers",
    "abstract": "Comments: 13+6 pages (main+supplement), 3 figures",
    "descriptor": "\nComments: 13+6 pages (main+supplement), 3 figures\n",
    "authors": [
      "Chun Yang Tan",
      "Hiroshi Kera",
      "Kazuhiko Kawamoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07138"
  },
  {
    "id": "arXiv:2203.07260",
    "title": "Graph-Survival: A Survival Analysis Framework for Machine Learning on  Temporal Networks",
    "abstract": "Graph-Survival: A Survival Analysis Framework for Machine Learning on  Temporal Networks",
    "descriptor": "",
    "authors": [
      "Rapha\u00ebl Romero",
      "Bo Kang",
      "Tijl De Bie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07260"
  },
  {
    "id": "arXiv:2203.07363",
    "title": "Implicit Motion Handling for Video Camouflaged Object Detection",
    "abstract": "Comments: Accepted to CVPR 2022; Xuelian Cheng and Huan Xiong made equal contributions; Corresponding author: Deng-Ping Fan (dengpfan@gmail.com). Dataset: this https URL",
    "descriptor": "\nComments: Accepted to CVPR 2022; Xuelian Cheng and Huan Xiong made equal contributions; Corresponding author: Deng-Ping Fan (dengpfan@gmail.com). Dataset: this https URL\n",
    "authors": [
      "Xuelian Cheng",
      "Huan Xiong",
      "Deng-Ping Fan",
      "Yiran Zhong",
      "Mehrtash Harandi",
      "Tom Drummond",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07363"
  }
]
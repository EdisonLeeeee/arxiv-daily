[
  {
    "id": "arXiv:2203.04995",
    "title": "CUBES: A Parallel Synthesizer for SQL Using Examples",
    "abstract": "In recent years, more and more people see their work depend on data\nmanipulation tasks. However, many of these users do not have the background in\nprogramming required to write complex programs, particularly SQL queries. One\nway of helping these users is to automatically synthesize the SQL query given a\nsmall set of examples provided by the user - a task known as Query Reverse\nEngineering. In the last decade, a large plethora of program synthesizers for\nSQL have been proposed, but none of the current tools take advantage of the\nincreased number of cores per processor. This paper proposes CUBES, a parallel\nprogram synthesizer for the domain of SQL queries using input-output examples.\nCUBES extends current sequential query synthesizers with new pruning techniques\nand a divide-and-conquer approach, splitting the search space into smaller\nindependent sub-problems.\nExamples are an under-specification, and the synthesized query may not match\nthe user's intent. We improve the accuracy of CUBES by developing a\ndisambiguation procedure based on fuzzing that interacts with the user and\nincreases our confidence that the returned query matches the user intent.\nWe perform an extensive evaluation on around 4000 SQL queries from different\ndomains. Experimental results show that our sequential version can solve more\ninstances than other state-of-the-art SQL synthesizers. Moreover, the parallel\napproach can scale up to 16 processes with super-linear speedups for many hard\ninstances. Our disambiguation approach is critical to achieving an accuracy of\naround 75%, significantly larger than other SQL synthesizers.",
    "descriptor": "",
    "authors": [
      "Ricardo Brancas",
      "Miguel Terra-Neves",
      "Miguel Ventura",
      "Vasco Manquinho",
      "Ruben Martins"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Databases (cs.DB)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.04995"
  },
  {
    "id": "arXiv:2203.05006",
    "title": "Resource-Efficient Invariant Networks: Exponential Gains by Unrolled  Optimization",
    "abstract": "Achieving invariance to nuisance transformations is a fundamental challenge\nin the construction of robust and reliable vision systems. Existing approaches\nto invariance scale exponentially with the dimension of the family of\ntransformations, making them unable to cope with natural variabilities in\nvisual data such as changes in pose and perspective. We identify a common\nlimitation of these approaches--they rely on sampling to traverse the\nhigh-dimensional space of transformations--and propose a new computational\nprimitive for building invariant networks based instead on optimization, which\nin many scenarios provides a provably more efficient method for\nhigh-dimensional exploration than sampling. We provide empirical and\ntheoretical corroboration of the efficiency gains and soundness of our proposed\nmethod, and demonstrate its utility in constructing an efficient invariant\nnetwork for a simple hierarchical object detection task when combined with\nunrolled optimization. Code for our networks and experiments is available at\nhttps://github.com/sdbuch/refine.",
    "descriptor": "",
    "authors": [
      "Sam Buchanan",
      "Jingkai Yan",
      "Ellie Haber",
      "John Wright"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.05006"
  },
  {
    "id": "arXiv:2203.05008",
    "title": "Sentence-Select: Large-Scale Language Model Data Selection for Rare-Word  Speech Recognition",
    "abstract": "Language model fusion helps smart assistants recognize words which are rare\nin acoustic data but abundant in text-only corpora (typed search logs).\nHowever, such corpora have properties that hinder downstream performance,\nincluding being (1) too large, (2) beset with domain-mismatched content, and\n(3) heavy-headed rather than heavy-tailed (excessively many duplicate search\nqueries such as \"weather\"). We show that three simple strategies for selecting\nlanguage modeling data can dramatically improve rare-word recognition without\nharming overall performance. First, to address the heavy-headedness, we\ndownsample the data according to a soft log function, which tunably reduces\nhigh frequency (head) sentences. Second, to encourage rare-word exposure, we\nexplicitly filter for words rare in the acoustic data. Finally, we tackle\ndomain-mismatch via perplexity-based contrastive selection, filtering for\nexamples matched to the target domain. We down-select a large corpus of web\nsearch queries by a factor of 53x and achieve better LM perplexities than\nwithout down-selection. When shallow-fused with a state-of-the-art, production\nspeech engine, our LM achieves WER reductions of up to 24% relative on\nrare-word sentences (without changing overall WER) compared to a baseline LM\ntrained on the raw corpus. These gains are further validated through favorable\nside-by-side evaluations on live voice search traffic.",
    "descriptor": "",
    "authors": [
      "W. Ronny Huang",
      "Cal Peyser",
      "Tara N. Sainath",
      "Ruoming Pang",
      "Trevor Strohman",
      "Shankar Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.05008"
  },
  {
    "id": "arXiv:2203.05012",
    "title": "Learning to control from expert demonstrations",
    "abstract": "In this paper, we revisit the problem of learning a stabilizing controller\nfrom a finite number of demonstrations by an expert. By first focusing on\nfeedback linearizable systems, we show how to combine expert demonstrations\ninto a stabilizing controller, provided that demonstrations are sufficiently\nlong and there are at least $n+1$ of them, where $n$ is the number of states of\nthe system being controlled. When we have more than $n+1$ demonstrations, we\ndiscuss how to optimally choose the best $n+1$ demonstrations to construct the\nstabilizing controller. We then extend these results to a class of systems that\ncan be embedded into a higher-dimensional system containing a chain of\nintegrators. The feasibility of the proposed algorithm is demonstrated by\napplying it on a CrazyFlie 2.0 quadrotor.",
    "descriptor": "",
    "authors": [
      "Alimzhan Sultangazin",
      "Luigi Pannocchi",
      "Lucas Fraile",
      "Paulo Tabuada"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.05012"
  },
  {
    "id": "arXiv:2203.05015",
    "title": "COMMAND: Certifiable Open Measurable Mandates",
    "abstract": "Security mandates today are often in the form of checklists and are generally\ninflexible and slow to adapt to changing threats. This paper introduces an\nalternate approach called open mandates, which mandate that vendors must\ndedicate some amount of resources (e.g. system speed, energy, design cost,\netc.) towards security but unlike checklist security does not prescribe\nspecific controls that must be implemented. The goal of open mandates is to\nprovide flexibility to vendors in implementing security controls that they see\nfit while requiring all vendors to commit to a certain level of security. In\nthis paper, we first demonstrate the usefulness of open security mandates: for\ninstance, we show that mandating 10% of resources towards security reduces\ndefenders losses by 8% and forestalls attackers by 10%. We then show how open\nmandates can be implemented in practice. Specifically, we solve the problem of\nidentifying a system's overhead due to security, a key problem towards making\nsuch an open mandate enforceable in practice. As examples we demonstrate our\nopen mandate system -- COMMAND -- for two contemporary software hardening\ntechniques and show that our methodology can predict security overheads to a\nvery high degree of accuracy (<1% mean and median error) with low resource\nrequirements. We also present experiments that quantify, in terms of dollars,\nhow much end users value the performance lost to security, which help determine\nthe costs of such a program. Taken together -- the usefulness of mandates,\ntheir enforceability, and their quantifiable costs -- make the case for an\nalternate resource-based mandate.",
    "descriptor": "",
    "authors": [
      "Adam Hastings",
      "Ryan Piersma",
      "Simha Sethumadhavan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.05015"
  },
  {
    "id": "arXiv:2203.05016",
    "title": "Shfl-BW: Accelerating Deep Neural Network Inference with Tensor-Core  Aware Weight Pruning",
    "abstract": "Weight pruning in deep neural networks (DNNs) can reduce storage and\ncomputation cost, but struggles to bring practical speedup to the model\ninference time. Tensor-cores can significantly boost the throughput of GPUs on\ndense computation, but exploiting tensor-cores for sparse DNNs is very\nchallenging. Compared to existing CUDA-cores, tensor-cores require higher data\nreuse and matrix-shaped instruction granularity, both difficult to yield from\nsparse DNN kernels. Existing pruning approaches fail to balance the demands of\naccuracy and efficiency: random sparsity preserves the model quality well but\nprohibits tensor-core acceleration, while highly-structured block-wise sparsity\ncan exploit tensor-cores but suffers from severe accuracy loss.\nIn this work, we propose a novel sparse pattern, Shuffled Block-wise sparsity\n(Shfl-BW), designed to efficiently utilize tensor-cores while minimizing the\nconstraints on the weight structure. Our insight is that row- and column-wise\npermutation provides abundant flexibility for the weight structure, while\nintroduces negligible overheads using our GPU kernel designs. We optimize the\nGPU kernels for Shfl-BW in linear and convolution layers. Evaluations show that\nour techniques can achieve the state-of-the-art speed-accuracy trade-offs on\nGPUs. For example, with small accuracy loss, we can accelerate the\ncomputation-intensive layers of Transformer by 1.81, 4.18 and 1.90 times on\nNVIDIA V100, T4 and A100 GPUs respectively at 75% sparsity.",
    "descriptor": "\nComments: To-appear in Design Automation Conference (DAC), July 2022\n",
    "authors": [
      "Guyue Huang",
      "Haoran Li",
      "Minghai Qin",
      "Fei Sun",
      "Yufei Din",
      "Yuan Xie"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.05016"
  },
  {
    "id": "arXiv:2203.05019",
    "title": "Quantum and Classical Algorithms for Bounded Distance Decoding",
    "abstract": "In this paper, we provide a comprehensive overview of a recent debate over\nthe quantum versus classical solvability of bounded distance decoding (BDD).\nSpecifically, we review the work of Eldar and Hallgren [EH22], [Hal21]\ndemonstrating a quantum algorithm solving $\\lambda_1 2^{-\\Omega(\\sqrt{k \\log\nq})}$-BDD in polynomial time for lattices of periodicity $q$, finite group rank\n$k$, and shortest lattice vector length $\\lambda_1$. Subsequently, we prove the\nresults of [DvW21a], [DvW21b] with far greater detail and elaboration than in\nthe original work. Namely, we show that there exists a deterministic, classical\nalgorithm achieving the same result.",
    "descriptor": "",
    "authors": [
      "Richard Allen",
      "Ratip Emin Berker",
      "S\u00edlvia Casacuberta",
      "Michael Gul"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.05019"
  },
  {
    "id": "arXiv:2203.05022",
    "title": "A proof of P != NP (New symmetric encryption algorithm against any  linear attacks and differential attacks)",
    "abstract": "P vs NP problem is the most important unresolved problem in the field of\ncomputational complexity. Its impact has penetrated into all aspects of\nalgorithm design, especially in the field of cryptography. The security of\ncryptographic algorithms based on short keys depends on whether P is equal to\nNP. In fact, Shannon[1] strictly proved that the one-time-pad system meets\nunconditional security, but because the one-time-pad system requires the length\nof key to be at least the length of plaintext, how to transfer the key is a\ntroublesome problem that restricts the use of the one-time-pad system in\npractice. Cryptography algorithms used in practice are all based on short key,\nand the security of the short key mechanism is ultimately based on \"one-way\"\nassumption, that is, it is assumed that a one-way function exists. In fact, the\nexistence of one-way function can directly lead to the important conclusion P\n!= NP. In this paper, we originally constructed a short-key block cipher\nalgorithm. The core feature of this algorithm is that for any block, when a\nplaintext-ciphertext pair is known, any key in the key space can satisfy the\nplaintext-ciphertext pair, that is, for each block, the plaintext-ciphertext\npair and the key are independence, and the independence between blocks is also\neasy to construct. This feature is completely different from all existing\nshort-key cipher algorithms. Based on the above feature, we construct a problem\nand theoretically prove that the problem satisfies the properties of one-way\nfunctions, thereby solving the problem of the existence of one-way functions,\nthat is, directly proving that P != NP.",
    "descriptor": "",
    "authors": [
      "Gao Ming"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.05022"
  },
  {
    "id": "arXiv:2203.05025",
    "title": "Power-of-Two Quantization for Low Bitwidth and Hardware Compliant Neural  Networks",
    "abstract": "Deploying Deep Neural Networks in low-power embedded devices for real\ntime-constrained applications requires optimization of memory and computational\ncomplexity of the networks, usually by quantizing the weights. Most of the\nexisting works employ linear quantization which causes considerable degradation\nin accuracy for weight bit widths lower than 8. Since the distribution of\nweights is usually non-uniform (with most weights concentrated around zero),\nother methods, such as logarithmic quantization, are more suitable as they are\nable to preserve the shape of the weight distribution more precise. Moreover,\nusing base-2 logarithmic representation allows optimizing the multiplication by\nreplacing it with bit shifting. In this paper, we explore non-linear\nquantization techniques for exploiting lower bit precision and identify\nfavorable hardware implementation options. We developed the Quantization Aware\nTraining (QAT) algorithm that allowed training of low bit width Power-of-Two\n(PoT) networks and achieved accuracies on par with state-of-the-art floating\npoint models for different tasks. We explored PoT weight encoding techniques\nand investigated hardware designs of MAC units for three different quantization\nschemes - uniform, PoT and Additive-PoT (APoT) - to show the increased\nefficiency when using the proposed approach. Eventually, the experiments showed\nthat for low bit width precision, non-uniform quantization performs better than\nuniform, and at the same time, PoT quantization vastly reduces the\ncomputational complexity of the neural network.",
    "descriptor": "\nComments: TinyML Research Symposium\n",
    "authors": [
      "Dominika Przewlocka-Rus",
      "Syed Shakib Sarwar",
      "H. Ekin Sumbul",
      "Yuecheng Li",
      "Barbara De Salvo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05025"
  },
  {
    "id": "arXiv:2203.05026",
    "title": "Transfer Learning as an Essential Tool for Digital Twins in Renewable  Energy Systems",
    "abstract": "Transfer learning (TL), the next frontier in machine learning (ML), has\ngained much popularity in recent years, due to the various challenges faced in\nML, like the requirement of vast amounts of training data, expensive and\ntime-consuming labelling processes for data samples, and long training duration\nfor models. TL is useful in tackling these problems, as it focuses on\ntransferring knowledge from previously solved tasks to new tasks. Digital twins\nand other intelligent systems need to utilise TL to use the previously gained\nknowledge and solve new tasks in a more self-reliant way, and to incrementally\nincrease their knowledge base. Therefore, in this article, the critical\nchallenges in power forecasting and anomaly detection in the context of\nrenewable energy systems are identified, and a potential TL framework to meet\nthese challenges is proposed. This article also proposes a feature embedding\napproach to handle the missing sensors data. The proposed TL methods help to\nmake a system more autonomous in the context of organic computing.",
    "descriptor": "\nComments: Accepted at the Organic Computing Doctoral Dissertation Colloquium (OC-DDC) 2021 Workshop\n",
    "authors": [
      "Chandana Priya Nivarthi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05026"
  },
  {
    "id": "arXiv:2203.05028",
    "title": "Dynamic Instance Domain Adaptation",
    "abstract": "Most existing studies on unsupervised domain adaptation (UDA) assume that\neach domain's training samples come with domain labels (e.g., painting, photo).\nSamples from each domain are assumed to follow the same distribution and the\ndomain labels are exploited to learn domain-invariant features via feature\nalignment. However, such an assumption often does not hold true -- there often\nexist numerous finer-grained domains (e.g., dozens of modern painting styles\nhave been developed, each differing dramatically from those of the classic\nstyles). Therefore, forcing feature distribution alignment across each\nartificially-defined and coarse-grained domain can be ineffective. In this\npaper, we address both single-source and multi-source UDA from a completely\ndifferent perspective, which is to view each instance as a fine domain. Feature\nalignment across domains is thus redundant. Instead, we propose to perform\ndynamic instance domain adaptation (DIDA). Concretely, a dynamic neural network\nwith adaptive convolutional kernels is developed to generate instance-adaptive\nresiduals to adapt domain-agnostic deep features to each individual instance.\nThis enables a shared classifier to be applied to both source and target domain\ndata without relying on any domain annotation. Further, instead of imposing\nintricate feature alignment losses, we adopt a simple semi-supervised learning\nparadigm using only a cross-entropy loss for both labeled source and pseudo\nlabeled target data. Our model, dubbed DIDA-Net, achieves state-of-the-art\nperformance on several commonly used single-source and multi-source UDA\ndatasets including Digits, Office-Home, DomainNet, Digit-Five, and PACS.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Zhongying Deng",
      "Kaiyang Zhou",
      "Da Li",
      "Junjun He",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05028"
  },
  {
    "id": "arXiv:2203.05031",
    "title": "A PDE-based Adaptive Kernel Method for Solving Optimal Filtering  Problems",
    "abstract": "In this paper, we introduce an adaptive kernel method for solving the optimal\nfiltering problem. The computational framework that we adopt is the Bayesian\nfilter, in which we recursively generate an optimal estimate for the state of a\ntarget stochastic dynamical system based on partial noisy observational data.\nThe mathematical model that we use to formulate the propagation of the state\ndynamics is the Fokker-Planck equation, and we introduce an operator\ndecomposition method to efficiently solve the Fokker-Planck equation. An\nadaptive kernel method is introduced to adaptively construct Gaussian kernels\nto approximate the probability distribution of the target state. Bayesian\ninference is applied to incorporate the observational data into the state model\nsimulation. Numerical experiments have been carried out to validate the\nperformance of our kernel method.",
    "descriptor": "",
    "authors": [
      "Zezhong Zhang",
      "Richard Archibald",
      "Feng Bao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.05031"
  },
  {
    "id": "arXiv:2203.05037",
    "title": "Human-GDPR Interaction: Practical Experiences of Accessing Personal Data",
    "abstract": "In our data-centric world, most services rely on collecting and using\npersonal data. The EU's General Data Protection Regulation (GDPR) aims to\nenhance individuals' control over their data, but its practical impact is not\nwell understood. We present a 10-participant study, where each participant\nfiled 4-5 data access requests. Through interviews accompanying these requests\nand discussions scrutinising returned data, it appears that GDPR falls short of\nits goals due to non-compliance and low-quality responses. Participants found\ntheir hopes to understand providers' data practices or harness their own data\nunmet. This causes increased distrust without any subjective improvement in\npower, although more transparent providers do earn greater trust. We propose\ndesigning more effective, data-inclusive and open policies and data access\nsystems to improve both customer relations and individual agency, and also that\nwider public use of GDPR rights could help with delivering accountability and\nmotivating providers to improve data practices.",
    "descriptor": "\nComments: 19 pages, to be published in CHI Conference on Human Factors in Computing Systems (CHI '22), April 29 - May 05, 2022, New Orleans, LA, USA\n",
    "authors": [
      "Alex Bowyer",
      "Jack Holt",
      "Josephine Go Jefferies",
      "Rob Wilson",
      "David Kirk",
      "Jan David Smeddinck"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.05037"
  },
  {
    "id": "arXiv:2203.05043",
    "title": "In-Place Rotation for Enhancing Snake-like Robot Mobility",
    "abstract": "Gaits engineered for snake-like robots to rotate in-place instrumentally fill\na gap in the set of locomotive gaits that have traditionally prioritized\ntranslation. This paper designs a Turn-in-Place gait and demonstrates the\nability of a shape-centric modeling framework to capture the gait's locomotive\nproperties. Shape modeling for turning involves a time-varying continuous body\ncurve described by a standing wave. Presumed viscous robot-ground frictional\ninteractions lead to body dynamics conditioned on the time-varying shape model.\nThe dynamic equations describing the Turn-in-Place gait are validated by an\narticulated snake-like robot using a physics-based simulator and a physical\nrobot. The results affirm the shape-centric modeling framework's capacity to\nmodel a variety of snake-like robot gaits with fundamentally different\nbody-ground contact patterns. As an applied demonstration, example locomotion\nscenarios partner the shape-centric Turn-in-Place gait with a Rectilinear gait\nfor maneuvering through constrained environments based on a multi-modal\nlocomotive planning strategy. Unified shape-centric modeling facilitates\ntrajectory planning and tracking for a snake-like robot to successfully\nnegotiate non-trivial obstacle configurations.",
    "descriptor": "\nComments: 8 pages, 5 figures. Submitted to RA-L (IEEE Robotics and Automation Letters) with IROS 2022 Option\n",
    "authors": [
      "Alexander H. Chang",
      "Patricio A. Vela"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05043"
  },
  {
    "id": "arXiv:2203.05045",
    "title": "Do Small Code Changes Merge Faster? A Multi-Language Empirical  Investigation",
    "abstract": "Code velocity, or the speed with which code changes are integrated into a\nproduction environment, plays a crucial role in Continuous Integration and\nContinuous Deployment. Many studies report factors influencing code velocity.\nHowever, solutions to increase code velocity are unclear. Meanwhile, the\nindustry continues to issue guidelines on \"ideal\" code change size, believing\nit increases code velocity despite lacking evidence validating the practice.\nSurprisingly, this fundamental question has not been studied to date. This\nstudy investigates the practicality of improving code velocity by optimizing\npull request size and composition (ratio of insertions, deletions, and\nmodifications). We start with a hypothesis that a moderate correlation exists\nbetween pull request size and time-to-merge. We selected 100 most popular,\nactively developed projects from 10 programming languages on GitHub. We\nanalyzed our dataset of 845,316 pull requests by size, composition, and context\nto explore its relationship to time-to-merge - a proxy to measure code\nvelocity. Our study shows that pull request size and composition do not relate\nto time-to-merge. Regardless of the contextual factors that can influence pull\nrequest size or composition (e.g., programming language), the observation\nholds. Pull request data from two other platforms: Gerrit and Phabricator\n(401,790 code reviews) confirms the lack of relationship. This negative result\nas in \"... eliminate useless hypotheses ...\" challenges a widespread belief by\nshowing that small code changes do not merge faster to increase code velocity.",
    "descriptor": "\nComments: 12 pages. To be published in Proceedings of MSR '22: Proceedings of the 19th International Conference on Mining Software Repositories (MSR 2022). ACM, New York, NY, USA\n",
    "authors": [
      "Gunnar Kudrjavets",
      "Nachiappan Nagappan",
      "Ayushi Rastogi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.05045"
  },
  {
    "id": "arXiv:2203.05046",
    "title": "Adaptive Trajectory Prediction via Transferable GNN",
    "abstract": "Pedestrian trajectory prediction is an essential component in a wide range of\nAI applications such as autonomous driving and robotics. Existing methods\nusually assume the training and testing motions follow the same pattern while\nignoring the potential distribution differences (e.g., shopping mall and\nstreet). This issue results in inevitable performance decrease. To address this\nissue, we propose a novel Transferable Graph Neural Network (T-GNN) framework,\nwhich jointly conducts trajectory prediction as well as domain alignment in a\nunified framework. Specifically, a domain invariant GNN is proposed to explore\nthe structural motion knowledge where the domain specific knowledge is reduced.\nMoreover, an attention-based adaptive knowledge learning module is further\nproposed to explore fine-grained individual-level feature representation for\nknowledge transfer. By this way, disparities across different trajectory\ndomains will be better alleviated. More challenging while practical trajectory\nprediction experiments are designed, and the experimental results verify the\nsuperior performance of our proposed model. To the best of our knowledge, our\nwork is the pioneer which fills the gap in benchmarks and techniques for\npractical pedestrian trajectory prediction across different domains.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Yi Xu",
      "Lichen Wang",
      "Yizhou Wang",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05046"
  },
  {
    "id": "arXiv:2203.05048",
    "title": "Mining Code Review Data to Understand Waiting Times Between Acceptance  and Merging: An Empirical Analysis",
    "abstract": "Increasing code velocity (or the speed with which code changes are reviewed\nand merged) is integral to speeding up development and contributes to the work\nsatisfaction of engineers. While factors affecting code change acceptance have\nbeen investigated in the past, solutions to decrease the code review lifetime\nare less understood. This study investigates the code review process to\nquantify delays and investigate opportunities to potentially increase code\nvelocity. We study the temporal characteristics of half a million code reviews\nhosted on Gerrit and Phabricator, starting from the first response, to a\ndecision to accept or reject the changes, and until the changes are merged into\na target branch. We identified two types of time delays: (a) the wait time from\nthe proposal of code changes until first response, and (b) the wait time\nbetween acceptance and merging. Our study indicates that reducing the time\nbetween acceptance and merging has the potential to speed up Phabricator code\nreviews by 29-63%. Small code changes and changes made by authors with a large\nnumber of previously accepted code reviews have a higher chance of being\nimmediately accepted, without code review iterations. Our analysis suggests\nthat switching from manual to automatic merges can help increase code velocity.",
    "descriptor": "\nComments: 12 pages. To be published in Proceedings of MSR '22: Proceedings of the 19th International Conference on Mining Software Repositories (MSR 2022). ACM, New York, NY, USA\n",
    "authors": [
      "Gunnar Kudrjavets",
      "Aditya Kumar",
      "Nachiappan Nagappan",
      "Ayushi Rastogi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.05048"
  },
  {
    "id": "arXiv:2203.05051",
    "title": "Evaluating Proposed Fairness Models for Face Recognition Algorithms",
    "abstract": "The development of face recognition algorithms by academic and commercial\norganizations is growing rapidly due to the onset of deep learning and the\nwidespread availability of training data. Though tests of face recognition\nalgorithm performance indicate yearly performance gains, error rates for many\nof these systems differ based on the demographic composition of the test set.\nThese \"demographic differentials\" in algorithm performance can contribute to\nunequal or unfair outcomes for certain groups of people, raising concerns with\nincreased worldwide adoption of face recognition systems. Consequently,\nregulatory bodies in both the United States and Europe have proposed new rules\nrequiring audits of biometric systems for \"discriminatory impacts\" (European\nUnion Artificial Intelligence Act) and \"fairness\" (U.S. Federal Trade\nCommission). However, no standard for measuring fairness in biometric systems\nyet exists. This paper characterizes two proposed measures of face recognition\nalgorithm fairness (fairness measures) from scientists in the U.S. and Europe.\nWe find that both proposed methods are challenging to interpret when applied to\ndisaggregated face recognition error rates as they are commonly experienced in\npractice. To address this, we propose a set of interpretability criteria,\ntermed the Functional Fairness Measure Criteria (FFMC), that outlines a set of\nproperties desirable in a face recognition algorithm fairness measure. We\nfurther develop a new fairness measure, the Gini Aggregation Rate for Biometric\nEquitability (GARBE), and show how, in conjunction with the Pareto\noptimization, this measure can be used to select among alternative algorithms\nbased on the accuracy/fairness trade-space. Finally, we have open-sourced our\ndataset of machine-readable, demographically disaggregated error rates. We\nbelieve this is currently the largest open-source dataset of its kind.",
    "descriptor": "",
    "authors": [
      "John J. Howard",
      "Eli J. Laird",
      "Yevgeniy B. Sirotin",
      "Rebecca E. Rubin",
      "Jerry L. Tipton",
      "Arun R. Vemury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05051"
  },
  {
    "id": "arXiv:2203.05053",
    "title": "Optical Flow Training under Limited Label Budget via Active Learning",
    "abstract": "Supervised training of optical flow predictors generally yields better\naccuracy than unsupervised training. However, the improved performance comes at\nan often high annotation cost. Semi-supervised training trades off accuracy\nagainst annotation cost. We use a simple yet effective semi-supervised training\nmethod to show that even a small fraction of labels can improve flow accuracy\nby a significant margin over unsupervised training. In addition, we propose\nactive learning methods based on simple heuristics to further reduce the number\nof labels required to achieve the same target accuracy. Our experiments on both\nsynthetic and real optical flow datasets show that our semi-supervised networks\ngenerally need around 50% of the labels to achieve close to full-label\naccuracy, and only around 20% with active learning on Sintel. We also analyze\nand show insights on the factors that may influence our active learning\nperformance. Code will be made available soon.",
    "descriptor": "",
    "authors": [
      "Shuai Yuan",
      "Xian Sun",
      "Hannah Kim",
      "Shuzhi Yu",
      "Carlo Tomasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05053"
  },
  {
    "id": "arXiv:2203.05056",
    "title": "SynWoodScape: Synthetic Surround-view Fisheye Camera Dataset for  Autonomous Driving",
    "abstract": "Surround-view cameras are a primary sensor for automated driving, used for\nnear field perception. It is one of the most commonly used sensors in\ncommercial vehicles. Four fisheye cameras with a 190{\\deg} field of view cover\nthe 360{\\deg} around the vehicle. Due to its high radial distortion, the\nstandard algorithms do not extend easily. Previously, we released the first\npublic fisheye surround-view dataset named WoodScape. In this work, we release\na synthetic version of the surround-view dataset, covering many of its\nweaknesses and extending it. Firstly, it is not possible to obtain ground truth\nfor pixel-wise optical flow and depth. Secondly, WoodScape did not have all\nfour cameras simultaneously in order to sample diverse frames. However, this\nmeans that multi-camera algorithms cannot be designed, which is enabled in the\nnew dataset. We implemented surround-view fisheye geometric projections in\nCARLA Simulator matching WoodScape's configuration and created SynWoodScape. We\nrelease 80k images from the synthetic dataset with annotations for 10+ tasks.\nWe also release the baseline code and supporting scripts.",
    "descriptor": "",
    "authors": [
      "Ahmed Rida Sekkat",
      "Yohan Dupuis",
      "Varun Ravi Kumar",
      "Hazem Rashed",
      "Senthil Yogamani",
      "Pascal Vasseur",
      "Paul Honeine"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05056"
  },
  {
    "id": "arXiv:2203.05057",
    "title": "On Linking Level Segments",
    "abstract": "An increasingly common area of study in procedural content generation is the\ncreation of level segments: short pieces that can be used to form larger\nlevels. Previous work has used basic concatenation to form these larger levels.\nHowever, even if the segments themselves are completable and well-formed,\nconcatenation can fail to produce levels that are completable and can cause\nbroken in-game structures (e.g. malformed pipes in Mario). We show this with\nthree tile-based games: a side-scrolling platformer, a vertical platformer, and\na top-down roguelike. Additionally, we present a Markov chain and a tree search\nalgorithm that finds a link between two level segments, which uses filters to\nensure completability and unbroken in-game structures in the linked segments.\nWe further show that these links work well for multi-segment levels. We find\nthat this method reliably finds links between segments and is customizable to\nmeet a designer's needs.",
    "descriptor": "",
    "authors": [
      "Colan Biemer",
      "Seth Cooper"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05057"
  },
  {
    "id": "arXiv:2203.05060",
    "title": "Resize Me! Exploring the User Experience of Embodied Realistic  Modulatable Avatars for Body Image Intervention in Virtual Reality",
    "abstract": "Obesity is a serious disease that can affect both physical and psychological\nwell-being. Due to weight stigmatization, many affected individuals suffer from\nbody image disturbances whereby they perceive their body in a distorted way,\nevaluate it negatively, or neglect it. Beyond established interventions such as\nmirror exposure, recent advancements aim to complement body image treatments by\nthe embodiment of visually altered virtual bodies in virtual reality (VR). We\npresent a high-fidelity prototype of an advanced VR system that allows users to\nembody a rapidly generated personalized, photorealistic avatar and to\nrealistically modulate its body weight in real-time within a carefully designed\nvirtual environment. In a formative multi-method approach, a total of 12\nparticipants rated the general user experience (UX) of our system during body\nscan and VR experience using semi-structured qualitative interviews and\nmultiple quantitative UX measures. By using body weight modification tasks, we\nfurther compared three different interaction methods for real-time body weight\nmodification and measured our system's impact on the body image relevant\nmeasures body awareness and body weight perception. From the feedback received,\ndemonstrating an already solid UX of our overall system and providing\nconstructive input for further improvement, we derived a set of design\nguidelines to guide future development and evaluation processes of systems\nsupporting body image interventions.",
    "descriptor": "",
    "authors": [
      "Nina D\u00f6llinger",
      "Erik Wolf",
      "David Mal",
      "Stephan Wenninger",
      "Mario Botsch",
      "Marc Erich Latoschik",
      "Carolin Wienrich"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.05060"
  },
  {
    "id": "arXiv:2203.05061",
    "title": "HealthPrompt: A Zero-shot Learning Paradigm for Clinical Natural  Language Processing",
    "abstract": "Deep learning algorithms are dependent on the availability of large-scale\nannotated clinical text datasets. The lack of such publicly available datasets\nis the biggest bottleneck for the development of clinical Natural Language\nProcessing(NLP) systems. Zero-Shot Learning(ZSL) refers to the use of deep\nlearning models to classify instances from new classes of which no training\ndata have been seen before. Prompt-based learning is an emerging ZSL technique\nwhere we define task-based templates for NLP tasks. We developed a novel\nprompt-based clinical NLP framework called HealthPrompt and applied the\nparadigm of prompt-based learning on clinical texts. In this technique, rather\nthan fine-tuning a Pre-trained Language Model(PLM), the task definitions are\ntuned by defining a prompt template. We performed an in-depth analysis of\nHealthPrompt on six different PLMs in a no-data setting. Our experiments prove\nthat prompts effectively capture the context of clinical texts and perform\nremarkably well without any training data.",
    "descriptor": "",
    "authors": [
      "Sonish Sivarajkumar",
      "Yanshan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.05061"
  },
  {
    "id": "arXiv:2203.05067",
    "title": "Universal Regression with Adversarial Responses",
    "abstract": "We provide algorithms for regression with adversarial responses under large\nclasses of non-i.i.d. instance sequences, on general separable metric spaces,\nwith provably minimal assumptions. We also give characterizations of\nlearnability in this regression context. We consider universal consistency\nwhich asks for strong consistency of a learner without restrictions on the\nvalue responses. Our analysis shows that such objective is achievable for a\nsignificantly larger class of instance sequences than stationary processes, and\nunveils a fundamental dichotomy between value spaces: whether finite-horizon\nmean-estimation is achievable or not. We further provide optimistically\nuniversal learning rules, i.e., such that if they fail to achieve universal\nconsistency, any other algorithm will fail as well. For unbounded losses, we\npropose a mild integrability condition under which there exist algorithms for\nadversarial regression under large classes of non-i.i.d. instance sequences. In\naddition, our analysis also provides a learning rule for mean-estimation in\ngeneral metric spaces that is consistent under adversarial responses without\nany moment conditions on the sequence, a result of independent interest.",
    "descriptor": "",
    "authors": [
      "Mo\u00efse Blanchard",
      "Patrick Jaillet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.05067"
  },
  {
    "id": "arXiv:2203.05068",
    "title": "An Empirical Eye-Tracking Study of Feature Model Comprehension",
    "abstract": "Software Product Lines (SPLs) are families of related software systems which\nare distinguished by the set of features each system provides. Feature Models\nare the de facto standard for modelling the variability of SPLs because they\ndescribe the features, their relations, and all the combinations of features\nthat constitute a SPL. Because of their key role, feature models are at the\ncore of many tasks in SPL engineering. Our work presents an empirical study on\nthe comprehension of feature models for the task of checking the validity of\nconfigurations. Our study explored the relation between the number of features\nand the number of cross-tree constraints with the accuracy of participants'\nanswers to validity checking questions, and used eye fixations for analyzing\nthe difficulty in interpreting fixated information and the amount of cognitive\nprocessing of the different parts of the feature model stimuli. We found that\nanswer accuracy does not relate individually to the number of features or to\nthe number of cross-tree constrains of a feature model, but both factors do\nshow an interaction on accuracy. Additionally, our study identified differences\nin feature models with cross-tree constraints in both number of fixations and\nfixation time, but no differences in those models without cross-tree\nconstraints.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Elmira Rezaei Sepasi",
      "Kambiz Nezami Balouchi",
      "Julien Mercier",
      "Roberto Erick Lopez-Herrejon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.05068"
  },
  {
    "id": "arXiv:2203.05071",
    "title": "On the influence of over-parameterization in manifold based surrogates  and deep neural operators",
    "abstract": "Constructing accurate and generalizable approximators for complex\nphysico-chemical processes exhibiting highly non-smooth dynamics is\nchallenging. In this work, we propose new developments and perform comparisons\nfor two promising approaches: manifold-based polynomial chaos expansion (m-PCE)\nand the deep neural operator (DeepONet), and we examine the effect of\nover-parameterization on generalization. We demonstrate the performance of\nthese methods in terms of generalization accuracy by solving the 2D\ntime-dependent Brusselator reaction-diffusion system with uncertainty sources,\nmodeling an autocatalytic chemical reaction between two species. We first\npropose an extension of the m-PCE by constructing a mapping between latent\nspaces formed by two separate embeddings of input functions and output QoIs. To\nenhance the accuracy of the DeepONet, we introduce weight self-adaptivity in\nthe loss function. We demonstrate that the performance of m-PCE and DeepONet is\ncomparable for cases of relatively smooth input-output mappings. However, when\nhighly non-smooth dynamics is considered, DeepONet shows higher accuracy. We\nalso find that for m-PCE, modest over-parameterization leads to better\ngeneralization, both within and outside of distribution, whereas aggressive\nover-parameterization leads to over-fitting. In contrast, an even highly\nover-parameterized DeepONet leads to better generalization for both smooth and\nnon-smooth dynamics. Furthermore, we compare the performance of the above\nmodels with another operator learning model, the Fourier Neural Operator, and\nshow that its over-parameterization also leads to better generalization. Our\nstudies show that m-PCE can provide very good accuracy at very low training\ncost, whereas a highly over-parameterized DeepONet can provide better accuracy\nand robustness to noise but at higher training cost. In both methods, the\ninference cost is negligible.",
    "descriptor": "\nComments: 28 pages, 7 figures\n",
    "authors": [
      "Katiana Kontolati",
      "Somdatta Goswami",
      "Michael D. Shields",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05071"
  },
  {
    "id": "arXiv:2203.05072",
    "title": "Exoshuffle: Large-Scale Shuffle at the Application Level",
    "abstract": "Shuffle is a key primitive in large-scale data processing applications. The\ndifficulty of large-scale shuffle has inspired a myriad of implementations.\nWhile these have greatly improved shuffle performance and reliability over\ntime, it comes at a cost: flexibility. First, each shuffle system is\nessentially built from scratch, which is a significant developer effort.\nSecond, because each shuffle system is monolithic, they are not flexible to\nsupporting other applications, such as online aggregation of shuffle results.\nWe show that shuffle can be implemented with high performance and reliability\non a general-purpose abstraction for distributed computing: distributed\nfutures. While previous systems have implemented shuffle on top of distributed\nfutures before, we are the first to identify and build the common components\nnecessary to support a large-scale shuffle. We show that it is possible to: (1)\nexpress optimizations from previous shuffle systems in a few hundred lines of\npurely application-level Python code, and (2) achieve interoperability with\nother data processing applications without modifying the shuffle system. Thus,\nwe present Exoshuffle, an application-level shuffle system that outperforms\nSpark and achieves 82\\% of theoretical performance on a 100TB sort on 100\nnodes.",
    "descriptor": "",
    "authors": [
      "Frank Sifei Luan",
      "Stephanie Wang",
      "Samyukta Yagati",
      "Sean Kim",
      "Kenneth Lien",
      "SangBin Cho",
      "Eric Liang",
      "Ion Stoica"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.05072"
  },
  {
    "id": "arXiv:2203.05074",
    "title": "The Transitive Information Theory and its Application to Deep Generative  Models",
    "abstract": "Paradoxically, a Variational Autoencoder (VAE) could be pushed in two\nopposite directions, utilizing powerful decoder model for generating realistic\nimages but collapsing the learned representation, or increasing regularization\ncoefficient for disentangling representation but ultimately generating blurry\nexamples. Existing methods narrow the issues to the rate-distortion trade-off\nbetween compression and reconstruction. We argue that a good reconstruction\nmodel does learn high capacity latents that encode more details, however, its\nuse is hindered by two major issues: the prior is random noise which is\ncompletely detached from the posterior and allow no controllability in the\ngeneration; mean-field variational inference doesn't enforce hierarchy\nstructure which makes the task of recombining those units into plausible novel\noutput infeasible. As a result, we develop a system that learns a hierarchy of\ndisentangled representation together with a mechanism for recombining the\nlearned representation for generalization. This is achieved by introducing a\nminimal amount of inductive bias to learn controllable prior for the VAE. The\nidea is supported by here developed transitive information theory, that is, the\nmutual information between two target variables could alternately be maximized\nthrough the mutual information to the third variable, thus bypassing the\nrate-distortion bottleneck in VAE design. In particular, we show that our\nmodel, named SemafoVAE (inspired by the similar concept in computer science),\ncould generate high-quality examples in a controllable manner, perform smooth\ntraversals of the disentangled factors and intervention at a different level of\nrepresentation hierarchy.",
    "descriptor": "",
    "authors": [
      "Trung Ngo",
      "Ville Hautam\u00e4ki",
      "Merja Hein\u00e4niemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05074"
  },
  {
    "id": "arXiv:2203.05076",
    "title": "Connecting sufficient conditions for domain adaptation: source-guided  uncertainty, relaxed divergences and discrepancy localization",
    "abstract": "Recent advances in domain adaptation establish that requiring a low risk on\nthe source domain and equal feature marginals degrade the adaptation's\nperformance. At the same time, empirical evidence shows that incorporating an\nunsupervised target domain term that pushes decision boundaries away from the\nhigh-density regions, along with relaxed alignment, improves adaptation. In\nthis paper, we theoretically justify such observations via a new bound on the\ntarget risk, and we connect two notions of relaxation for divergence, namely\n$\\beta-$relaxed divergences and localization. This connection allows us to\nincorporate the source domain's categorical structure into the relaxation of\nthe considered divergence, provably resulting in a better handling of the label\nshift case in particular.",
    "descriptor": "",
    "authors": [
      "Sofien Dhouib",
      "Setareh Maghsudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05076"
  },
  {
    "id": "arXiv:2203.05079",
    "title": "SAGE: Generating Symbolic Goals for Myopic Models in Deep Reinforcement  Learning",
    "abstract": "Model-based reinforcement learning algorithms are typically more sample\nefficient than their model-free counterparts, especially in sparse reward\nproblems. Unfortunately, many interesting domains are too complex to specify\nthe complete models required by traditional model-based approaches. Learning a\nmodel takes a large number of environment samples, and may not capture critical\ninformation if the environment is hard to explore. If we could specify an\nincomplete model and allow the agent to learn how best to use it, we could take\nadvantage of our partial understanding of many domains. Existing hybrid\nplanning and learning systems which address this problem often impose highly\nrestrictive assumptions on the sorts of models which can be used, limiting\ntheir applicability to a wide range of domains. In this work we propose SAGE,\nan algorithm combining learning and planning to exploit a previously unusable\nclass of incomplete models. This combines the strengths of symbolic planning\nand neural learning approaches in a novel way that outperforms competing\nmethods on variations of taxi world and Minecraft.",
    "descriptor": "\nComments: 11 pages, 8 figures, 3 tables\n",
    "authors": [
      "Andrew Chester",
      "Michael Dann",
      "Fabio Zambetta",
      "John Thangarajah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05079"
  },
  {
    "id": "arXiv:2203.05080",
    "title": "Natural Gas Short-Term Operation Problem with Dynamics: A Rank  Minimization Approach",
    "abstract": "Natural gas-fired generation units can hedge against the volatility in the\nuncertain renewable generation, which may occur during very short periods. It\nis crucial to utilize models capable of correctly capturing the natural gas\nnetwork dynamics induced by the volatile demand of gas-fired units. The\nWeymouth equation is commonly implemented in literature to avoid dealing with\nthe mathematical complications of solving the original governing differential\nequations of the natural gas dynamics. However, it is shown in this paper that\nthis approach is not reliable in the short-term operation problem. Here, the\nmerit of the non-convex transient model is compared with the simplified\nWeymouth equation, and the drawbacks of employing the Weymouth equation are\nillustrated. The results demonstrate how changes in the natural gas demand are\nmet by adjustment in the pressure within pipelines rather than the output of\nnatural gas suppliers. This work presents a convex relaxation scheme for the\noriginal non-linear and non-convex natural gas flow equations with dynamics,\nutilizing a rank minimization approach to ensure the tightness. The proposed\nmethod renders a computationally efficient framework that can accurately solve\nthe non-convex non-linear gas operation problem and accurately capture its\ndynamics. Also, the results suggest that the proposed model improves the\nsolution optimality and solution time compared to the original non-linear\nnon-convex model. Finally, the scalability of the proposed approach is verified\nin the case study.",
    "descriptor": "",
    "authors": [
      "Reza Bayani",
      "Saeed D. Manshadi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05080"
  },
  {
    "id": "arXiv:2203.05081",
    "title": "NLX-GPT: A Model for Natural Language Explanations in Vision and  Vision-Language Tasks",
    "abstract": "Natural language explanation (NLE) models aim at explaining the\ndecision-making process of a black box system via generating natural language\nsentences which are human-friendly, high-level and fine-grained. Current NLE\nmodels explain the decision-making process of a vision or vision-language model\n(a.k.a., task model), e.g., a VQA model, via a language model (a.k.a.,\nexplanation model), e.g., GPT. Other than the additional memory resources and\ninference time required by the task model, the task and explanation models are\ncompletely independent, which disassociates the explanation from the reasoning\nprocess made to predict the answer. We introduce NLX-GPT, a general, compact\nand faithful language model that can simultaneously predict an answer and\nexplain it. We first conduct pre-training on large scale data of image-caption\npairs for general understanding of images, and then formulate the answer as a\ntext prediction task along with the explanation. Without region proposals nor a\ntask model, our resulting overall framework attains better evaluation scores,\ncontains much less parameters and is 15$\\times$ faster than the current SoA\nmodel. We then address the problem of evaluating the explanations which can be\nin many times generic, data-biased and can come in several forms. We therefore\ndesign 2 new evaluation measures: (1) explain-predict and (2) retrieval-based\nattack, a self-evaluation framework that requires no labels. Code is at:\nhttps://github.com/fawazsammani/nlxgpt.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Fawaz Sammani",
      "Tanmoy Mukherjee",
      "Nikos Deligiannis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05081"
  },
  {
    "id": "arXiv:2203.05082",
    "title": "Givens Coordinate Descent Methods for Rotation Matrix Learning in  Trainable Embedding Indexes",
    "abstract": "Product quantization (PQ) coupled with a space rotation, is widely used in\nmodern approximate nearest neighbor (ANN) search systems to significantly\ncompress the disk storage for embeddings and speed up the inner product\ncomputation. Existing rotation learning methods, however, minimize quantization\ndistortion for fixed embeddings, which are not applicable to an end-to-end\ntraining scenario where embeddings are updated constantly. In this paper, based\non geometric intuitions from Lie group theory, in particular the special\northogonal group $SO(n)$, we propose a family of block Givens coordinate\ndescent algorithms to learn rotation matrix that are provably convergent on any\nconvex objectives. Compared to the state-of-the-art SVD method, the Givens\nalgorithms are much more parallelizable, reducing runtime by orders of\nmagnitude on modern GPUs, and converge more stably according to experimental\nstudies. They further improve upon vanilla product quantization significantly\nin an end-to-end training scenario.",
    "descriptor": "\nComments: published in ICLR 2022\n",
    "authors": [
      "Yunjiang Jiang",
      "Han Zhang",
      "Yiming Qiu",
      "Yun Xiao",
      "Bo Long",
      "Wen-Yun Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05082"
  },
  {
    "id": "arXiv:2203.05084",
    "title": "IncShrink: Architecting Efficient Outsourced Databases using Incremental  MPC and Differential Privacy",
    "abstract": "In this paper, we consider secure outsourced growing databases that support\nview-based query answering. These databases allow untrusted servers to\nprivately maintain a materialized view, such that they can use only the\nmaterialized view to process query requests instead of accessing the original\ndata from which the view was derived. To tackle this, we devise a novel\nview-based secure outsourced growing database framework, Incshrink. The key\nfeatures of this solution are: (i) Incshrink maintains the view using\nincremental MPC operators which eliminates the need for a trusted third party\nupfront, and (ii) to ensure high performance, Incshrink guarantees that the\nleakage satisfies DP in the presence of updates. To the best of our knowledge,\nthere are no existing systems that have these properties. We demonstrate\nIncshrink's practical feasibility in terms of efficiency and accuracy with\nextensive empirical evaluations on real-world datasets and the TPC-ds\nbenchmark. The evaluation results show that Incshrink provides a 3-way\ntrade-off in terms of privacy, accuracy, and efficiency guarantees, and offers\nat least a 7,800 times performance advantage over standard secure outsourced\ndatabases that do not support the view-based query paradigm.",
    "descriptor": "",
    "authors": [
      "Chenghong Wang",
      "Johes Bater",
      "Kartik Nayak",
      "Ashwin Machanavajjhala"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.05084"
  },
  {
    "id": "arXiv:2203.05085",
    "title": "Census TopDown: The Impacts of Differential Privacy on Redistricting",
    "abstract": "The 2020 Decennial Census will be released with a new disclosure avoidance\nsystem in place, putting differential privacy in the spotlight for a wide range\nof data users. We consider several key applications of Census data in\nredistricting, developing tools and demonstrations for practitioners who are\nconcerned about the impacts of this new noising algorithm called TopDown. Based\non a close look at reconstructed Texas data, we find reassuring evidence that\nTopDown will not threaten the ability to produce districts with tolerable\npopulation balance or to detect signals of racial polarization for Voting\nRights Act enforcement.",
    "descriptor": "\nComments: 2nd Symposium on Foundations of Responsible Computing (FORC 2021)\n",
    "authors": [
      "Aloni Cohen",
      "Moon Duchin",
      "JN Matthews",
      "Bhushan Suwal"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.05085"
  },
  {
    "id": "arXiv:2203.05087",
    "title": "False Data Injection Attack on Electric Vehicle-Assisted Voltage  Regulation",
    "abstract": "With the large scale penetration of electric vehicles (EVs) and the advent of\nbidirectional chargers, EV aggregators will become a major player in the\nvoltage regulation market. This paper proposes a novel false data injection\nattack (FDIA) against the voltage regulation capacity estimation of EV charging\nstations, the process that underpins voltage regulation in distribution system.\nThe proposed FDIA takes into account the uncertainty in EV mobility and network\nconditions. The attack vector with the largest expected adverse impact is the\nsolution of a stochastic optimization problem subject to a constraint that\nensures it can bypass bad data detection. We show that this attack vector can\nbe determined by solving a sequence of convex quadratically constrained linear\nprograms. The case studies examined in a co-simulation platform, based on two\nstandard test feeders, reveal the vulnerability of the voltage regulation\ncapacity estimation.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Yuan Liu",
      "Omid Ardakanian",
      "Ioanis Nikolaidis",
      "Hao Liang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05087"
  },
  {
    "id": "arXiv:2203.05092",
    "title": "A Tree-Structured Multi-Task Model Recommender",
    "abstract": "Tree-structured multi-task architectures have been employed to jointly tackle\nmultiple vision tasks in the context of multi-task learning (MTL). The major\nchallenge is to determine where to branch out for each task given a backbone\nmodel to optimize for both task accuracy and computation efficiency. To address\nthe challenge, this paper proposes a recommender that, given a set of tasks and\na convolutional neural network-based backbone model, automatically suggests\ntree-structured multi-task architectures that could achieve a high task\nperformance while meeting a user-specified computation budget without\nperforming model training. Extensive evaluations on popular MTL benchmarks show\nthat the recommended architectures could achieve competitive task accuracy and\ncomputation efficiency compared with state-of-the-art MTL methods.",
    "descriptor": "\nComments: 23 pages, 4 figures\n",
    "authors": [
      "Lijun Zhang",
      "Xiao Liu",
      "Hui Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05092"
  },
  {
    "id": "arXiv:2203.05095",
    "title": "Model-Architecture Co-Design for High Performance Temporal GNN Inference  on FPGA",
    "abstract": "Temporal Graph Neural Networks (TGNNs) are powerful models to capture\ntemporal, structural, and contextual information on temporal graphs. The\ngenerated temporal node embeddings outperform other methods in many downstream\ntasks. Real-world applications require high performance inference on real-time\nstreaming dynamic graphs. However, these models usually rely on complex\nattention mechanisms to capture relationships between temporal neighbors. In\naddition, maintaining vertex memory suffers from intrinsic temporal data\ndependency that hinders task-level parallelism, making it inefficient on\ngeneral-purpose processors. In this work, we present a novel model-architecture\nco-design for inference in memory-based TGNNs on FPGAs. The key modeling\noptimizations we propose include a light-weight method to compute attention\nscores and a related temporal neighbor pruning strategy to further reduce\ncomputation and memory accesses. These are holistically coupled with key\nhardware optimizations that leverage FPGA hardware. We replace the temporal\nsampler with an on-chip FIFO based hardware sampler and the time encoder with a\nlook-up-table. We train our simplified models using knowledge distillation to\nensure similar accuracy vis-\\'a-vis the original model. Taking advantage of the\nmodel optimizations, we propose a principled hardware architecture using\nbatching, pipelining, and prefetching techniques to further improve the\nperformance. We also propose a hardware mechanism to ensure the chronological\nvertex updating without sacrificing the computation parallelism. We evaluate\nthe performance of the proposed hardware accelerator on three real-world\ndatasets.",
    "descriptor": "\nComments: IPDPS'22\n",
    "authors": [
      "Hongkuan Zhou",
      "Bingyi Zhang",
      "Rajgopal Kannan",
      "Viktor Prasanna",
      "Carl Busart"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05095"
  },
  {
    "id": "arXiv:2203.05096",
    "title": "Heterogeneous Sparse Matrix-Vector Multiplication via Compressed Sparse  Row Format",
    "abstract": "Due to ill performance on many devices, sparse matrix-vector multiplication\n(SpMV) normally requires special care to store and tune for a given device.\nHowever, SpMV is one of the most important kernels in high-performance\ncomputing (HPC), and therefore, a storage format and tuning are required that\nallows for efficient SpMV operations with low memory and tuning overheads\nacross heterogeneous devices. Additionally, the primary users of SpMV\noperations in HPC are normally application scientists that already have\nnumerous other libraries they depend on the use of some standard sparse matrix\nstorage format. As such, the ideal heterogeneous format would also be something\nthat could easily be understood and requires no major changes to be translated\ninto a standard sparse matrix format, such as compressed sparse row (CSR). This\npaper presents a heterogeneous format based on CSR, named CSR-k, that can be\ntuned quickly, requires minimal memory overheads, outperforms the average\nperformance of NVIDIA's cuSPARSE on our test suite, and does not need any\nconversion to be used by standard library calls that require a CSR format\ninput. In particular, CSR-k achieves this by grouping rows into a hierarchical\nstructure of super-rows and super-super-rows that are represented by just a few\nextra arrays of pointers (i.e., <2% memory overhead to keep arrays for both GPU\nand CPU execution). Due to its simplicity, a model can be tuned for a device,\nand this model can be used to select super-row and super-super-rows sizes in\nconstant time. We observe in this paper that CSR-k can achieve about 15%\nimprovement on a V100 and about 17.4% improvement on an A100 over NVIDIA's\ncuSPARSE while still providing about a 13x speedup on an AMD Epyc 7713.",
    "descriptor": "\nComments: 10 pages, intended for submission to the Journal of Parallel Computing, 13 figures, 3 listings, 1 table\n",
    "authors": [
      "Phillip Allen Lane",
      "Joshua Dennis Booth"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.05096"
  },
  {
    "id": "arXiv:2203.05097",
    "title": "A Framework for the Interoperability of Cloud Platforms: Towards FAIR  Data in SAFE Environments",
    "abstract": "As the number of cloud platforms supporting biomedical research grows, there\nis an increasing need to support interoperability between two or more cloud\nplatforms. A well accepted core concept is to make data in cloud platforms\nfindable, accessible, interoperable and reusable (FAIR). We introduce a\ncompanion concept that applies to cloud-based computing environments that we\ncall a Secure and Authorized FAIR Environment (SAFE). SAFE environments require\ndata and platform governance structures. A SAFE environment is a cloud platform\nthat has been approved through a defined data and platform governance process\nas authorized to hold data from another cloud platform and exposes appropriate\nAPIs for the two platforms to interoperate.",
    "descriptor": "\nComments: 11 pages with 1 figure and a 2 page appendix\n",
    "authors": [
      "Robert L. Grossman",
      "Rebecca R. Boyles",
      "Brandi N. Davis-Dusenbery",
      "Amanda Haddock",
      "Allison P. Heath",
      "Brian D. O'Connor",
      "Adam C. Resnick",
      "Deanne M. Taylor",
      "Stan Ahalt"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.05097"
  },
  {
    "id": "arXiv:2203.05102",
    "title": "Adaptive relaying for streaming erasure codes in a three node relay  network",
    "abstract": "This paper investigates adaptive streaming codes over a three-node relayed\nnetwork. In this setting, a source node transmits a sequence of message packets\nto a destination through a relay. The source-to-relay and relay-to-destination\nlinks are unreliable and introduce at most $N_1$ and $N_2$ packet erasures,\nrespectively. The destination node must recover each message packet within a\nstrict delay constraint $T$. The paper presents achievable streaming codes for\nall feasible parameters $\\{N_1, N_2, T\\}$ that exploit the fact that the relay\nnaturally observes the erasure pattern occurring in the link from source to\nrelay, thus it can adapt its relaying strategy based on these observations. In\na recent work, Fong et al. provide streaming codes featuring\nchannel-state-independent relaying strategies. The codes proposed in this paper\nachieve rates higher than the ones proposed by Fong et al. whenever $N_2 >\nN_1$, and achieve the same rate when $N_2 = N_1$. The paper also presents an\nupper bound on the achievable rate that takes into account erasures in both\nlinks in order to bound the rate in the second link. The upper bound is shown\nto be tighter than a trivial bound that considers only the erasures in the\nsecond link.",
    "descriptor": "\nComments: Paper has been submitted to transactions on information theory\n",
    "authors": [
      "Gustavo Kasper Facenda",
      "M. Nikhil Krishnan",
      "Elad Domanovitz",
      "Silas L. Fong",
      "Ashish Khisti",
      "Wai-Tian Tan",
      "John Apostolopoulos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.05102"
  },
  {
    "id": "arXiv:2203.05103",
    "title": "Improving Neural ODEs via Knowledge Distillation",
    "abstract": "Neural Ordinary Differential Equations (Neural ODEs) construct the continuous\ndynamics of hidden units using ordinary differential equations specified by a\nneural network, demonstrating promising results on many tasks. However, Neural\nODEs still do not perform well on image recognition tasks. The possible reason\nis that the one-hot encoding vector commonly used in Neural ODEs can not\nprovide enough supervised information. We propose a new training based on\nknowledge distillation to construct more powerful and robust Neural ODEs\nfitting image recognition tasks. Specially, we model the training of Neural\nODEs into a teacher-student learning process, in which we propose ResNets as\nthe teacher model to provide richer supervised information. The experimental\nresults show that the new training manner can improve the classification\naccuracy of Neural ODEs by 24% on CIFAR10 and 5% on SVHN. In addition, we also\nquantitatively discuss the effect of both knowledge distillation and time\nhorizon in Neural ODEs on robustness against adversarial examples. The\nexperimental analysis concludes that introducing the knowledge distillation and\nincreasing the time horizon can improve the robustness of Neural ODEs against\nadversarial examples.",
    "descriptor": "",
    "authors": [
      "Haoyu Chu",
      "Shikui Wei",
      "Qiming Lu",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05103"
  },
  {
    "id": "arXiv:2203.05104",
    "title": "Transition to Linearity of Wide Neural Networks is an Emerging Property  of Assembling Weak Models",
    "abstract": "Wide neural networks with linear output layer have been shown to be\nnear-linear, and to have near-constant neural tangent kernel (NTK), in a region\ncontaining the optimization path of gradient descent. These findings seem\ncounter-intuitive since in general neural networks are highly complex models.\nWhy does a linear structure emerge when the networks become wide? In this work,\nwe provide a new perspective on this \"transition to linearity\" by considering a\nneural network as an assembly model recursively built from a set of sub-models\ncorresponding to individual neurons. In this view, we show that the linearity\nof wide neural networks is, in fact, an emerging property of assembling a large\nnumber of diverse \"weak\" sub-models, none of which dominate the assembly.",
    "descriptor": "\nComments: Published at ICLR 2022 (spotlight paper)\n",
    "authors": [
      "Chaoyue Liu",
      "Libin Zhu",
      "Mikhail Belkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05104"
  },
  {
    "id": "arXiv:2203.05108",
    "title": "A Tighter Approximation Guarantee for Greedy Minimum Entropy Coupling",
    "abstract": "We examine the minimum entropy coupling problem, where one must find the\nminimum entropy variable that has a given set of distributions $S = \\{p_1,\n\\dots, p_m \\}$ as its marginals. Although this problem is NP-Hard, previous\nworks have proposed algorithms with varying approximation guarantees. In this\npaper, we show that the greedy coupling algorithm of [Kocaoglu et al., AAAI'17]\nis always within $\\log_2(e)$ ($\\approx 1.44$) bits of the minimum entropy\ncoupling. In doing so, we show that the entropy of the greedy coupling is\nupper-bounded by $H\\left(\\bigwedge S \\right) + \\log_2(e)$. This improves the\npreviously best known approximation guarantee of $2$ bits within the optimal\n[Li, IEEE Trans. Inf. Theory '21]. Moreover, we show our analysis is tight by\nproving there is no algorithm whose entropy is upper-bounded by\n$H\\left(\\bigwedge S \\right) + c$ for any constant $c<\\log_2(e)$. Additionally,\nwe examine a special class of instances where the greedy coupling algorithm is\nexactly optimal.",
    "descriptor": "",
    "authors": [
      "Spencer Compton"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.05108"
  },
  {
    "id": "arXiv:2203.05109",
    "title": "The Pattern is in the Details: An Evaluation of Interaction Techniques  for Locating, Searching, and Contextualizing Details in Multivariate Matrix  Visualizations",
    "abstract": "Matrix visualizations are widely used to display large-scale network,\ntabular, set, or sequential data. They typically only encode a single value per\ncell, e.g., through color. However, this can greatly limit the visualizations'\nutility when exploring multivariate data, where each cell represents a data\npoint with multiple values (referred to as details). Three well-established\ninteraction approaches can be applicable in multivariate matrix visualizations\n(or MMV): focus+context, pan&zoom, and overview+detail. However, there is\nlittle empirical knowledge of how these approaches compare in exploring MMV. We\nreport on two studies comparing them for locating, searching, and\ncontextualizing details in MMV. We first compared four focus+context techniques\nand found that the fisheye lens overall outperformed the others. We then\ncompared the fisheye lens, to pan&zoom and overview+detail. We found that\npan&zoom was faster in locating and searching details, and as good as\noverview+detail in contextualizing details.",
    "descriptor": "\nComments: To appear in the ACM CHI Conference on Human Factors in Computing Systems (CHI 2022)\n",
    "authors": [
      "Yalong Yang",
      "Wenyu Xia",
      "Fritz Lekschas",
      "Carolina Nobre",
      "Robert Krueger",
      "Hanspeter Pfister"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.05109"
  },
  {
    "id": "arXiv:2203.05112",
    "title": "Librarian-in-the-Loop: A Natural Language Processing Paradigm for  Detecting Informal Mentions of Research Data in Academic Literature",
    "abstract": "Data citations provide a foundation for studying research data impact.\nCollecting and managing data citations is a new frontier in archival science\nand scholarly communication. However, the discovery and curation of research\ndata citations is labor intensive. Data citations that reference unique\nidentifiers (i.e. DOIs) are readily findable; however, informal mentions made\nto research data are more challenging to infer. We propose a natural language\nprocessing (NLP) paradigm to support the human task of identifying informal\nmentions made to research datasets. The work of discovering informal data\nmentions is currently performed by librarians and their staff in the\nInter-university Consortium for Political and Social Research (ICPSR), a large\nsocial science data archive that maintains a large bibliography of data-related\nliterature. The NLP model is bootstrapped from data citations actively\ncollected by librarians at ICPSR. The model combines pattern matching with\nmultiple iterations of human annotations to learn additional rules for\ndetecting informal data mentions. These examples are then used to train an NLP\npipeline. The librarian-in-the-loop paradigm is centered in the data work\nperformed by ICPSR librarians, supporting broader efforts to build a more\ncomprehensive bibliography of data-related literature that reflects the\nscholarly communities of research data users.",
    "descriptor": "",
    "authors": [
      "Lizhou Fan",
      "Sara Lafia",
      "David Bleckley",
      "Elizabeth Moss",
      "Andrea Thomer",
      "Libby Hemphill"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05112"
  },
  {
    "id": "arXiv:2203.05114",
    "title": "OpenTAL: Towards Open Set Temporal Action Localization",
    "abstract": "Temporal Action Localization (TAL) has experienced remarkable success under\nthe supervised learning paradigm. However, existing TAL methods are rooted in\nthe closed set assumption, which cannot handle the inevitable unknown actions\nin open-world scenarios. In this paper, we, for the first time, step toward the\nOpen Set TAL (OSTAL) problem and propose a general framework OpenTAL based on\nEvidential Deep Learning (EDL). Specifically, the OpenTAL consists of\nuncertainty-aware action classification, actionness prediction, and temporal\nlocation regression. With the proposed importance-balanced EDL method,\nclassification uncertainty is learned by collecting categorical evidence\nmajorly from important samples. To distinguish the unknown actions from\nbackground video frames, the actionness is learned by the positive-unlabeled\nlearning. The classification uncertainty is further calibrated by leveraging\nthe guidance from the temporal localization quality. The OpenTAL is general to\nenable existing TAL models for open set scenarios, and experimental results on\nTHUMOS14 and ActivityNet1.3 benchmarks show the effectiveness of our method.\nThe code and pre-trained models are released at\nhttps://www.rit.edu/actionlab/opental.",
    "descriptor": "\nComments: CVPR 2022 [camera ready with supplement]\n",
    "authors": [
      "Wentao Bao",
      "Qi Yu",
      "Yu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05114"
  },
  {
    "id": "arXiv:2203.05115",
    "title": "Internet-augmented language models through few-shot prompting for  open-domain question answering",
    "abstract": "In this work, we aim to capitalize on the unique few-shot capabilities\noffered by large-scale language models to overcome some of their challenges\nwith respect to grounding to factual and up-to-date information. Motivated by\nsemi-parametric language models, which ground their decisions in external\nretrieved evidence, we use few-shot prompting to learn to condition language\nmodels on information returned from the web using Google Search, a broad and\nconstantly updated knowledge source. Our approach does not involve fine-tuning\nor learning additional parameters, thus making it applicable to any language\nmodel, offering like this a strong baseline. Indeed, we find that language\nmodels conditioned on the web surpass performance of closed-book models of\nsimilar, or even larger, model sizes in open-domain question answering.\nFinally, we find that increasing the inference-time compute of models, achieved\nvia using multiple retrieved evidences to generate multiple answers followed by\na reranking stage, alleviates generally decreased performance of smaller\nfew-shot language models. All in all, our findings suggest that it might be\nbeneficial to slow down the race towards the biggest model and instead shift\nthe attention towards finding more effective ways to use models, including but\nnot limited to better prompting or increasing inference-time compute.",
    "descriptor": "",
    "authors": [
      "Angeliki Lazaridou",
      "Elena Gribovskaya",
      "Wojciech Stokowiec",
      "Nikolai Grigorev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05115"
  },
  {
    "id": "arXiv:2203.05118",
    "title": "Semi-supervision semantic segmentation with uncertainty-guided self  cross supervision",
    "abstract": "As a powerful way of realizing semi-supervised segmentation, the cross\nsupervision method learns cross consistency based on independent ensemble\nmodels using abundant unlabeled images. However, the wrong pseudo labeling\ninformation generated by cross supervision would confuse the training process\nand negatively affect the effectiveness of the segmentation model. Besides, the\ntraining process of ensemble models in such methods also multiplies the cost of\ncomputation resources and decreases the training efficiency. To solve these\nproblems, we propose a novel cross supervision method, namely\nuncertainty-guided self cross supervision (USCS). In addition to ensemble\nmodels, we first design a multi-input multi-output (MIMO) segmentation model\nwhich can generate multiple outputs with shared model and consequently impose\nconsistency over the outputs, saving the cost on parameters and calculations.\nOn the other hand, we employ uncertainty as guided information to encourage the\nmodel to focus on the high confident regions of pseudo labels and mitigate the\neffects of wrong pseudo labeling in self cross supervision, improving the\nperformance of the segmentation model. Extensive experiments show that our\nmethod achieves state-of-the-art performance while saving 40.5% and 49.1% cost\non parameters and calculations.",
    "descriptor": "",
    "authors": [
      "Yunyang Zhang",
      "Zhiqiang Gong",
      "Xiaohu Zheng",
      "Xiaoyu Zhao",
      "Wen Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05118"
  },
  {
    "id": "arXiv:2203.05119",
    "title": "MetAug: Contrastive Learning via Meta Feature Augmentation",
    "abstract": "What matters for contrastive learning? We argue that contrastive learning\nheavily relies on informative features, or \"hard\" (positive or negative)\nfeatures. Early works include more informative features by applying complex\ndata augmentations and large batch size or memory bank, and recent works design\nelaborate sampling approaches to explore informative features. The key\nchallenge toward exploring such features is that the source multi-view data is\ngenerated by applying random data augmentations, making it infeasible to always\nadd useful information in the augmented data. Consequently, the informativeness\nof features learned from such augmented data is limited. In response, we\npropose to directly augment the features in latent space, thereby learning\ndiscriminative representations without a large amount of input data. We perform\na meta learning technique to build the augmentation generator that updates its\nnetwork parameters by considering the performance of the encoder. However,\ninsufficient input data may lead the encoder to learn collapsed features and\ntherefore malfunction the augmentation generator. A new margin-injected\nregularization is further added in the objective function to avoid the encoder\nlearning a degenerate mapping. To contrast all features in one gradient\nback-propagation step, we adopt the proposed optimization-driven unified\ncontrastive loss instead of the conventional contrastive loss. Empirically, our\nmethod achieves state-of-the-art results on several benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Jiangmeng Li",
      "Wenwen Qiang",
      "Changwen Zheng",
      "Bing Su",
      "Hui Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05119"
  },
  {
    "id": "arXiv:2203.05121",
    "title": "Collusion Detection in Team-Based Multiplayer Games",
    "abstract": "In the context of competitive multiplayer games, collusion happens when two\nor more teams decide to collaborate towards a common goal, with the intention\nof gaining an unfair advantage from this cooperation. The task of identifying\ncolluders from the player population is however infeasible to game designers\ndue to the sheer size of the player population. In this paper, we propose a\nsystem that detects colluding behaviors in team-based multiplayer games and\nhighlights the players that most likely exhibit colluding behaviors. The game\ndesigners then proceed to analyze a smaller subset of players and decide what\naction to take. For this reason, it is important and necessary to be extremely\ncareful with false positives when automating the detection. The proposed method\nanalyzes the players' social relationships paired with their in-game behavioral\npatterns and, using tools from graph theory, infers a feature set that allows\nus to detect and measure the degree of collusion exhibited by each pair of\nplayers from opposing teams. We then automate the detection using Isolation\nForest, an unsupervised learning technique specialized in highlighting\noutliers, and show the performance and efficiency of our approach on two real\ndatasets, each with over 170,000 unique players and over 100,000 different\nmatches.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Laura Greige",
      "Fernando De Mesentier Silva",
      "Meredith Trotter",
      "Chris Lawrence",
      "Peter Chin",
      "Dilip Varadarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.05121"
  },
  {
    "id": "arXiv:2203.05122",
    "title": "DEER: Detection-agnostic End-to-End Recognizer for Scene Text Spotting",
    "abstract": "Recent end-to-end scene text spotters have achieved great improvement in\nrecognizing arbitrary-shaped text instances. Common approaches for text\nspotting use region of interest pooling or segmentation masks to restrict\nfeatures to single text instances. However, this makes it hard for the\nrecognizer to decode correct sequences when the detection is not accurate i.e.\none or more characters are cropped out. Considering that it is hard to\naccurately decide word boundaries with only the detector, we propose a novel\nDetection-agnostic End-to-End Recognizer, DEER, framework. The proposed method\nreduces the tight dependency between detection and recognition modules by\nbridging them with a single reference point for each text instance, instead of\nusing detected regions. The proposed method allows the decoder to recognize the\ntexts that are indicated by the reference point, with features from the whole\nimage. Since only a single point is required to recognize the text, the\nproposed method enables text spotting without an arbitrarily-shaped detector or\nbounding polygon annotations. Experimental results present that the proposed\nmethod achieves competitive results on regular and arbitrarily-shaped text\nspotting benchmarks. Further analysis shows that DEER is robust to the\ndetection errors. The code and dataset will be publicly available.",
    "descriptor": "",
    "authors": [
      "Seonghyeon Kim",
      "Seung Shin",
      "Yoonsik Kim",
      "Han-Cheol Cho",
      "Taeho Kil",
      "Jaeheung Surh",
      "Seunghyun Park",
      "Bado Lee",
      "Youngmin Baek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05122"
  },
  {
    "id": "arXiv:2203.05123",
    "title": "Multi-Task Adversarial Learning for Treatment Effect Estimation in  Basket Trials",
    "abstract": "Estimating treatment effects from observational data provides insights about\ncausality guiding many real-world applications such as different clinical study\ndesigns, which are the formulations of trials, experiments, and observational\nstudies in medical, clinical, and other types of research. In this paper, we\ndescribe causal inference for application in a novel clinical design called\nbasket trial that tests how well a new drug works in patients who have\ndifferent types of cancer that all have the same mutation. We propose a\nmulti-task adversarial learning (MTAL) method, which incorporates feature\nselection multi-task representation learning and adversarial learning to\nestimate potential outcomes across different tumor types for patients sharing\nthe same genetic mutation but having different tumor types. In our paper, the\nbasket trial is employed as an intuitive example to present this new causal\ninference setting. This new causal inference setting includes, but is not\nlimited to basket trials. This setting has the same challenges as the\ntraditional causal inference problem, i.e., missing counterfactual outcomes\nunder different subgroups and treatment selection bias due to confounders. We\npresent the practical advantages of our MTAL method for the analysis of\nsynthetic basket trial data and evaluate the proposed estimator on two\nbenchmarks, IHDP and News. The results demonstrate the superiority of our MTAL\nmethod over the competing state-of-the-art methods.",
    "descriptor": "\nComments: Proceedings of Machine Learning Research (PMLR); Conference on Health, Inference, and Learning (CHIL) 2022\n",
    "authors": [
      "Zhixuan Chu",
      "Stephen L. Rathbun",
      "Sheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.05123"
  },
  {
    "id": "arXiv:2203.05126",
    "title": "PACTran: PAC-Bayesian Metrics for Estimating the Transferability of  Pretrained Models to Classification Tasks",
    "abstract": "With the increasing abundance of pretrained models in recent years, the\nproblem of selecting the best pretrained checkpoint for a particular downstream\nclassification task has been gaining increased attention. Although several\nmethods have recently been proposed to tackle the selection problem (e.g. LEEP,\nH-score), these methods resort to applying heuristics that are not well\nmotivated by learning theory. In this paper we present PACTran, a theoretically\ngrounded family of metrics for pretrained model selection and transferability\nmeasurement. We first show how to derive PACTran metrics from the optimal\nPAC-Bayesian bound under the transfer learning setting. We then empirically\nevaluate three metric instantiations of PACTran on a number of vision tasks\n(VTAB) as well as a language-and-vision (OKVQA) task. An analysis of the\nresults shows PACTran is a more consistent and effective transferability\nmeasure compared to existing selection methods.",
    "descriptor": "",
    "authors": [
      "Nan Ding",
      "Xi Chen",
      "Tomer Levinboim",
      "Beer Changpinyo",
      "Radu Soricut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05126"
  },
  {
    "id": "arXiv:2203.05128",
    "title": "LlamaTune: Sample-Efficient DBMS Configuration Tuning",
    "abstract": "Tuning a database system to achieve optimal performance on a given workload\nis a long-standing problem in the database community. A number of recent papers\nhave leveraged ML-based approaches to guide the sampling of large parameter\nspaces (hundreds of tuning knobs) in search for high performance\nconfigurations. Looking at Microsoft production services operating millions of\ndatabases, sample efficiency emerged as a crucial requirement to use tuners on\ndiverse workloads. This motivates our investigation in LlamaTune, a system that\nleverages two key insights: 1) an automated dimensionality reduction technique\nbased on randomized embeddings, and 2) a biased sampling approach to handle\nspecial values for certain tuning knobs. LlamaTune compares favorably with the\nstate-of-the-art optimizers across a diverse set of workloads achieving the\nbest performing configurations with up to $11\\times$ fewer workload runs, and\nreaching up to $21\\%$ higher throughput. We also show that benefits from\nLlamaTune generalizes across random-forest and Gaussian Process-based Bayesian\noptimizers. While the journey to perform database tuning at cloud-scale remains\nlong, LlamaTune goes a long way in making automatic DB tuning practical at\nscale.",
    "descriptor": "",
    "authors": [
      "Konstantinos Kanellis",
      "Cong Ding",
      "Brian Kroth",
      "Andreas M\u00fcller",
      "Carlo Curino",
      "Shivaram Venkataraman"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.05128"
  },
  {
    "id": "arXiv:2203.05132",
    "title": "Compilable Neural Code Generation with Compiler Feedback",
    "abstract": "Automatically generating compilable programs with (or without) natural\nlanguage descriptions has always been a touchstone problem for computational\nlinguistics and automated software engineering. Existing deep-learning\napproaches model code generation as text generation, either constrained by\ngrammar structures in decoder, or driven by pre-trained language models on\nlarge-scale code corpus (e.g., CodeGPT, PLBART, and CodeT5). However, few of\nthem account for compilability of the generated programs. To improve\ncompilability of the generated programs, this paper proposes COMPCODER, a\nthree-stage pipeline utilizing compiler feedback for compilable code\ngeneration, including language model fine-tuning, compilability reinforcement,\nand compilability discrimination. Comprehensive experiments on two code\ngeneration tasks demonstrate the effectiveness of our proposed approach,\nimproving the success rate of compilation from 44.18 to 89.18 in code\ncompletion on average and from 70.3 to 96.2 in text-to-code generation,\nrespectively, when comparing with the state-of-the-art CodeGPT.",
    "descriptor": "\nComments: Accepted by ACL 2022\n",
    "authors": [
      "Xin Wang",
      "Yasheng Wang",
      "Yao Wan",
      "Fei Mi",
      "Yitong Li",
      "Pingyi Zhou",
      "Jin Liu",
      "Hao Wu",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.05132"
  },
  {
    "id": "arXiv:2203.05134",
    "title": "Manifold Modeling in Quotient Space: Learning An Invariant Mapping with  Decodability of Image Patches",
    "abstract": "This study proposes a framework for manifold learning of image patches using\nthe concept of equivalence classes: manifold modeling in quotient space (MMQS).\nIn MMQS, we do not consider a set of local patches of the image as it is, but\nrather the set of their canonical patches obtained by introducing the concept\nof equivalence classes and performing manifold learning on their canonical\npatches. Canonical patches represent equivalence classes, and their\nauto-encoder constructs a manifold in the quotient space. Based on this\nframework, we produce a novel manifold-based image model by introducing\nrotation-flip-equivalence relations. In addition, we formulate an image\nreconstruction problem by fitting the proposed image model to a corrupted\nobserved image and derive an algorithm to solve it. Our experiments show that\nthe proposed image model is effective for various self-supervised image\nreconstruction tasks, such as image inpainting, deblurring, super-resolution,\nand denoising.",
    "descriptor": "",
    "authors": [
      "Tatsuya Yokota",
      "Hidekata Hontani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05134"
  },
  {
    "id": "arXiv:2203.05137",
    "title": "Cross-modal Map Learning for Vision and Language Navigation",
    "abstract": "We consider the problem of Vision-and-Language Navigation (VLN). The majority\nof current methods for VLN are trained end-to-end using either unstructured\nmemory such as LSTM, or using cross-modal attention over the egocentric\nobservations of the agent. In contrast to other works, our key insight is that\nthe association between language and vision is stronger when it occurs in\nexplicit spatial representations. In this work, we propose a cross-modal map\nlearning model for vision-and-language navigation that first learns to predict\nthe top-down semantics on an egocentric map for both observed and unobserved\nregions, and then predicts a path towards the goal as a set of waypoints. In\nboth cases, the prediction is informed by the language through cross-modal\nattention mechanisms. We experimentally test the basic hypothesis that\nlanguage-driven navigation can be solved given a map, and then show competitive\nresults on the full VLN-CE benchmark.",
    "descriptor": "",
    "authors": [
      "Georgios Georgakis",
      "Karl Schmeckpeper",
      "Karan Wanchoo",
      "Soham Dan",
      "Eleni Miltsakaki",
      "Dan Roth",
      "Kostas Daniilidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.05137"
  },
  {
    "id": "arXiv:2203.05140",
    "title": "Speciesist Language and Nonhuman Animal Bias in English Masked Language  Models",
    "abstract": "Various existing studies have analyzed what social biases are inherited by\nNLP models. These biases may directly or indirectly harm people, therefore\nprevious studies have focused only on human attributes. If the social biases in\nNLP models can be indirectly harmful to humans involved, then the models can\nalso indirectly harm nonhuman animals. However, until recently no research on\nsocial biases in NLP regarding nonhumans existed. In this paper, we analyze\nbiases to nonhuman animals, i.e. speciesist bias, inherent in English Masked\nLanguage Models. We analyze this bias using template-based and corpus-extracted\nsentences which contain speciesist (or non-speciesist) language, to show that\nthese models tend to associate harmful words with nonhuman animals. Our code\nfor reproducing the experiments will be made available on GitHub.",
    "descriptor": "\nComments: Anonymous previous version of this paper is accessible at (this https URL). Our code will be available at (this https URL)\n",
    "authors": [
      "Masashi Takeshita",
      "Rafal Rzepka",
      "Kenji Araki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05140"
  },
  {
    "id": "arXiv:2203.05142",
    "title": "IAE-Net: Integral Autoencoders for Discretization-Invariant Learning",
    "abstract": "Discretization invariant learning aims at learning in the\ninfinite-dimensional function spaces with the capacity to process heterogeneous\ndiscrete representations of functions as inputs and/or outputs of a learning\nmodel. This paper proposes a novel deep learning framework based on integral\nautoencoders (IAE-Net) for discretization invariant learning. The basic\nbuilding block of IAE-Net consists of an encoder and a decoder as integral\ntransforms with data-driven kernels, and a fully connected neural network\nbetween the encoder and decoder. This basic building block is applied in\nparallel in a wide multi-channel structure, which are repeatedly composed to\nform a deep and densely connected neural network with skip connections as\nIAE-Net. IAE-Net is trained with randomized data augmentation that generates\ntraining data with heterogeneous structures to facilitate the performance of\ndiscretization invariant learning. The proposed IAE-Net is tested with various\napplications in predictive data science, solving forward and inverse problems\nin scientific computing, and signal/image processing. Compared with\nalternatives in the literature, IAE-Net achieves state-of-the-art performance\nin existing applications and creates a wide range of new applications.",
    "descriptor": "",
    "authors": [
      "Yong Zheng Ong",
      "Zuowei Shen",
      "Haizhao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.05142"
  },
  {
    "id": "arXiv:2203.05145",
    "title": "Intention-aware Feature Propagation Network for Interactive Segmentation",
    "abstract": "We aim to tackle the problem of point-based interactive segmentation, in\nwhich two key challenges are to infer user's intention correctly and to\npropagate the user-provided annotations to unlabeled regions efficiently. To\naddress those challenges, we propose a novel intention-aware feature\npropagation strategy that performs explicit user intention estimation and\nlearns an efficient click-augmented feature representation for high-resolution\nforeground segmentation. Specifically, we develop a coarse-to-fine sparse\npropagation network for each interactive segmentation step, which consists of a\ncoarse-level network for more effective tracking of user's interest, and a\nfine-level network for zooming to the target object and performing fine-level\nsegmentation. Moreover, we design a new sparse graph network module for both\nlevels to enable efficient long-range propagation of click information.\nExtensive experiments show that our method surpasses the previous\nstate-of-the-art methods on all popular benchmarks, demonstrating its efficacy.",
    "descriptor": "",
    "authors": [
      "Chuyu Zhang",
      "Chuanyang Hu",
      "Yongfei Liu",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05145"
  },
  {
    "id": "arXiv:2203.05147",
    "title": "An Accurate Unsupervised Method for Joint Entity Alignment and Dangling  Entity Detection",
    "abstract": "Knowledge graph integration typically suffers from the widely existing\ndangling entities that cannot find alignment cross knowledge graphs (KGs). The\ndangling entity set is unavailable in most real-world scenarios, and manually\nmining the entity pairs that consist of entities with the same meaning is\nlabor-consuming. In this paper, we propose a novel accurate Unsupervised method\nfor joint Entity alignment (EA) and Dangling entity detection (DED), called\nUED. The UED mines the literal semantic information to generate pseudo entity\npairs and globally guided alignment information for EA and then utilizes the EA\nresults to assist the DED. We construct a medical cross-lingual knowledge graph\ndataset, MedED, providing data for both the EA and DED tasks. Extensive\nexperiments demonstrate that in the EA task, UED achieves EA results comparable\nto those of state-of-the-art supervised EA baselines and outperforms the\ncurrent state-of-the-art EA methods by combining supervised EA data. For the\nDED task, UED obtains high-quality results without supervision.",
    "descriptor": "\nComments: Long paper; ACL 2022 (Findings)\n",
    "authors": [
      "Shengxuan Luo",
      "Sheng Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05147"
  },
  {
    "id": "arXiv:2203.05148",
    "title": "Efficient Topology Assessment for Integrated Transmission and  Distribution Network with 10,000+ Inverter-based Resources",
    "abstract": "The renewable energy proliferation calls upon the grid operators and planners\nto systematically evaluate the potential impacts of distributed energy\nresources (DERs). Considering the significant differences between various\ninverter-based resources (IBRs), especially the different capabilities between\ngrid-forming inverters and grid-following inverters, it is crucial to develop\nan efficient and effective assessment procedure besides available co-simulation\nframework with high computation burdens. This paper presents a streamlined\ngraph-based topology assessment for the integrated power system transmission\nand distribution networks. Graph analyses were performed based on the\nintegrated graph of modified miniWECC grid model and IEEE 8500-node test feeder\nmodel, high performance computing platform with 40 nodes and total 2400 CPUs\nhas been utilized to process this integrated graph, which has 100,000+ nodes\nand 10,000+ IBRs. The node ranking results not only verified the applicability\nof the proposed method, but also revealed the potential of distributed grid\nforming (GFM) and grid following (GFL) inverters interacting with the\ncentralized power plants.",
    "descriptor": "\nComments: 5 pages, 5 figures, 3 tables\n",
    "authors": [
      "Tao Fu",
      "Dexin Wang",
      "Xiaoyuan Fan",
      "Huiying Ren",
      "Jim Ogle",
      "Yousu Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05148"
  },
  {
    "id": "arXiv:2203.05151",
    "title": "Frequency-driven Imperceptible Adversarial Attack on Semantic Similarity",
    "abstract": "Current adversarial attack research reveals the vulnerability of\nlearning-based classifiers against carefully crafted perturbations. However,\nmost existing attack methods have inherent limitations in cross-dataset\ngeneralization as they rely on a classification layer with a closed set of\ncategories. Furthermore, the perturbations generated by these methods may\nappear in regions easily perceptible to the human visual system (HVS). To\ncircumvent the former problem, we propose a novel algorithm that attacks\nsemantic similarity on feature representations. In this way, we are able to\nfool classifiers without limiting attacks to a specific dataset. For\nimperceptibility, we introduce the low-frequency constraint to limit\nperturbations within high-frequency components, ensuring perceptual similarity\nbetween adversarial examples and originals. Extensive experiments on three\ndatasets (CIFAR-10, CIFAR-100, and ImageNet-1K) and three public online\nplatforms indicate that our attack can yield misleading and transferable\nadversarial examples across architectures and datasets. Additionally,\nvisualization results and quantitative performance (in terms of four different\nmetrics) show that the proposed algorithm generates more imperceptible\nperturbations than the state-of-the-art methods. Code is made available at.",
    "descriptor": "\nComments: 10 pages, 7 figure, CVPR 2022 conference\n",
    "authors": [
      "Cheng Luo",
      "Qinliang Lin",
      "Weicheng Xie",
      "Bizhu Wu",
      "Jinheng Xie",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05151"
  },
  {
    "id": "arXiv:2203.05153",
    "title": "Determining Existence of Logical Obstructions to the Distributed Task  Solvability",
    "abstract": "To study the distributed task solvability, Goubault, Ledent, and Rajsbaum\ndevised a model of dynamic epistemic logic that is equivalent to the\ntopological model for distributed computing. In the logical model, the\nunsolvability of a particular distributed task can be proven by finding a\nformula, called logical obstruction. This logical method is very appealing\nbecause the concrete formulas that prevent to solve task would have\nimplications of intuitive factors for the unsolvability. However, it has not\nbeen well studied when a logical obstruction exists and how to systematically\nconstruct a concrete logical obstruction formula, if any. In addition, it is\nproved that there are some tasks that are solvable but do not admit logical\nobstructions.\nIn this paper, we propose a method to prove the non-existence of logical\nobstructions to the solvability of distributed tasks, based on the technique of\nsimulation. Moreover, we give a method to determine whether a logical\nobstruction exists or not for a finite protocol and a finite task, and if it\nexists, construct a concrete obstruction. Using this method, we demonstrate\nthat the language of the standard epistemic logic, without distributed\nknowledge, does not admit logical obstruction to the solvability of $k$-set\nagreement tasks. We also show that there is no logical obstruction for\nmulti-round immediate snapshot even in the language of epistemic logic with\ndistributed knowledge. In addition, for the know-all model, we provide a\nconcrete obstruction formula that shows the unsolvability of the $k$-set\nagreement task.",
    "descriptor": "\nComments: 22 pages, 5 figures\n",
    "authors": [
      "Sou Hoshino"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.05153"
  },
  {
    "id": "arXiv:2203.05154",
    "title": "Practical Evaluation of Adversarial Robustness via Adaptive Auto Attack",
    "abstract": "Defense models against adversarial attacks have grown significantly, but the\nlack of practical evaluation methods has hindered progress. Evaluation can be\ndefined as looking for defense models' lower bound of robustness given a budget\nnumber of iterations and a test dataset. A practical evaluation method should\nbe convenient (i.e., parameter-free), efficient (i.e., fewer iterations) and\nreliable (i.e., approaching the lower bound of robustness). Towards this\ntarget, we propose a parameter-free Adaptive Auto Attack (A$^3$) evaluation\nmethod which addresses the efficiency and reliability in a test-time-training\nfashion. Specifically, by observing that adversarial examples to a specific\ndefense model follow some regularities in their starting points, we design an\nAdaptive Direction Initialization strategy to speed up the evaluation.\nFurthermore, to approach the lower bound of robustness under the budget number\nof iterations, we propose an online statistics-based discarding strategy that\nautomatically identifies and abandons hard-to-attack images. Extensive\nexperiments demonstrate the effectiveness of our A$^3$. Particularly, we apply\nA$^3$ to nearly 50 widely-used defense models. By consuming much fewer\niterations than existing methods, i.e., $1/10$ on average (10$\\times$ speed\nup), we achieve lower robust accuracy in all cases. Notably, we won\n$\\textbf{first place}$ out of 1681 teams in CVPR 2021 White-box Adversarial\nAttacks on Defense Models competitions with this method. Code is available at:\n$\\href{https://github.com/liuye6666/adaptive_auto_attack}{https://github.com/liuye6666/adaptive\\_auto\\_attack}$",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Ye Liu",
      "Yaya Cheng",
      "Lianli Gao",
      "Xianglong Liu",
      "Qilong Zhang",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05154"
  },
  {
    "id": "arXiv:2203.05156",
    "title": "Zero-Shot Action Recognition with Transformer-based Video Semantic  Embedding",
    "abstract": "While video action recognition has been an active area of research for\nseveral years, zero-shot action recognition has only recently started gaining\ntraction. However, there is a lack of a formal definition for the zero-shot\nlearning paradigm leading to uncertainty about classes that can be considered\nas previously unseen. In this work, we take a new comprehensive look at the\ninductive zero-shot action recognition problem from a realistic standpoint.\nSpecifically, we advocate for a concrete formulation for zero-shot action\nrecognition that avoids an exact overlap between the training and testing\nclasses and also limits the intra-class variance; and propose a novel\nend-to-end trained transformer model which is capable of capturing long range\nspatiotemporal dependencies efficiently, contrary to existing approaches which\nuse 3D-CNNs. The proposed approach outperforms the existing state-of-the-art\nalgorithms in many settings on all benchmark datasets by a wide margin.",
    "descriptor": "",
    "authors": [
      "Keval Doshi",
      "Yasin Yilmaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05156"
  },
  {
    "id": "arXiv:2203.05158",
    "title": "Devouring the Leader Bottleneck in BFT Consensus",
    "abstract": "There is a resurgence of interest in Byzantine fault-tolerant (BFT) systems\ndue to blockchains. However, leader-based BFT consensus protocols used by\npermissioned blockchains have limited scalability and robustness. To alleviate\nthe leader bottleneck in BFT consensus, we introduce \\emph{Stratus}, a robust\nshared mempool protocol that decouples transaction distribution from consensus.\nOur idea is to have replicas disseminate transactions in a distributed manner\nand have the leader only propose transaction ids. Stratus uses a provably\navailable broadcast (PAB) protocol to ensure the availability of the referenced\ntransactions. % This is necessary for integrity checking. To deal with\nunbalanced load across replicas, Stratus adopts a distributed load balancing\nprotocol that is co-designed with PAB.\nWe implemented and evaluated Stratus by integrating it with state-of-the-art\nBFT-based blockchain protocols and evaluated these protocols in both LAN and\nWAN settings. Our results show that Stratus-based protocols achieve up to\n$5\\sim20\\times$ more throughput than their native counterparts in a network\nwith hundreds of replicas. In addition, the performance of Stratus degrades\ngracefully in the presence of network asynchrony, Byzantine attackers, and\nunbalanced workloads. Our design provides easy-to-use APIs so that other BFT\nsystems suffering from leader bottlenecks can use Stratus.",
    "descriptor": "",
    "authors": [
      "Fangyu Gai",
      "Jianyu Niu",
      "Ivan Beschastnikh",
      "Chen Feng",
      "Sheng Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.05158"
  },
  {
    "id": "arXiv:2203.05160",
    "title": "Deterministic Rendezvous in Infinite Trees",
    "abstract": "The rendezvous task calls for two mobile agents, starting from different\nnodes of a network modeled as a graph to meet at the same node. Agents have\ndifferent labels which are integers from a set $\\{1,\\dots,L\\}$. They wake up at\npossibly different times and move in synchronous rounds. In each round, an\nagent can either stay idle or move to an adjacent node. We consider\ndeterministic rendezvous algorithms. The time of such an algorithm is the\nnumber of rounds since the wakeup of the earlier agent till the meeting. In\nthis paper we consider rendezvous in infinite trees. Our main goal is to study\nthe impact of orientation of a tree on the time of rendezvous.\nWe first design a rendezvous algorithm working for unoriented regular trees,\nwhose time is in $O(z(D) \\log L)$, where $z(D)$ is the size of the ball of\nradius $D$, i.e, the number of nodes at distance at most $D$ from a given node.\nThe algorithm works for arbitrary delay between waking times of agents and does\nnot require any initial information about parameters $L$ or $D$. Its\ndisadvantage is its complexity: $z(D)$ is exponential in $D$ for any degree\n$d>2$ of the tree. We prove that this high complexity is inevitable:\n$\\Omega(z(D))$ turns out to be a lower bound on rendezvous time in unoriented\nregular trees, even for simultaneous start and even when agents know $L$ and\n$D$. Then we turn attention to oriented trees. While for arbitrary delay\nbetween waking times of agents the lower bound $\\Omega(z(D))$ still holds, for\nsimultaneous start the time of rendezvous can be dramatically shortened. We\nshow that if agents know either a polynomial upper bound on $L$ or a linear\nupper bound on $D$, then rendezvous can be accomplished in oriented trees in\ntime $O(D\\log L)$, which is optimal. When no such extra knowledge is available,\nwe design an algorithm working in time $O(D^2+\\log ^2L)$.",
    "descriptor": "",
    "authors": [
      "Subhash Bhagat",
      "Andrzej Pelc"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.05160"
  },
  {
    "id": "arXiv:2203.05161",
    "title": "Container Orchestration in Edge and Fog Computing Environments for  Real-Time IoT Applications",
    "abstract": "Resource management is the principal factor to fully utilize the potential of\nEdge/Fog computing to execute real-time and critical IoT applications. Although\nsome resource management frameworks exist, the majority are not designed based\non distributed containerized components. Hence, they are not suitable for\nhighly distributed and heterogeneous computing environments. Containerized\nresource management frameworks such as FogBus2 enable efficient distribution of\nframework's components alongside IoT applications' components. However, the\nmanagement, deployment, health-check, and scalability of a large number of\ncontainers are challenging issues. To orchestrate a multitude of containers,\nseveral orchestration tools are developed. But, many of these orchestration\ntools are heavy-weight and have a high overhead, especially for\nresource-limited Edge/Fog nodes. Thus, for hybrid computing environments,\nconsisting of heterogeneous Edge/Fog and/or Cloud nodes, lightweight container\norchestration tools are required to support both resource-limited resources at\nthe Edge/Fog and resource-rich resources at the Cloud. Thus, in this paper, we\npropose a feasible approach to build a hybrid and lightweight cluster based on\nK3s, for the FogBus2 framework that offers containerized resource management\nframework. This work addresses the challenge of creating lightweight computing\nclusters in hybrid computing environments. It also proposes three design\npatterns for the deployment of the FogBus2 framework in hybrid environments,\nincluding 1) Host Network, 2) Proxy Server, and 3) Environment Variable. The\nperformance evaluation shows that the proposed approach improves the response\ntime of real-time IoT applications up to 29% with acceptable and low overhead.",
    "descriptor": "\nComments: 20 pages, 10 figures\n",
    "authors": [
      "Zhiyu Wang",
      "Mohammad Goudarzi",
      "Jagannath Aryal",
      "Rajkumar Buyya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.05161"
  },
  {
    "id": "arXiv:2203.05166",
    "title": "Program Repair: Automated vs. Manual",
    "abstract": "Various automated program repair (APR) techniques have been proposed to fix\nbugs automatically in the last decade. Although recent researches have made\nsignificant progress on the effectiveness and efficiency, it is still unclear\nhow APR techniques perform with human intervention in a real debugging\nscenario. To bridge this gap, we conduct an extensive study to compare three\nstate-of-the-art APR tools with manual program repair, and further investigate\nwhether the assistance of APR tools (i.e., repair reports) can improve manual\nprogram repair. To that end, we recruit 20 participants for a controlled\nexperiment, resulting in a total of 160 manual repair tasks and a questionnaire\nsurvey. The experiment reveals several notable observations that (1) manual\nprogram repair may be influenced by the frequency of repair actions sometimes;\n(2) APR tools are more efficient in terms of debugging time, while manual\nprogram repair tends to generate a correct patch with fewer attempts; (3) APR\ntools can further improve manual program repair regarding the number of\ncorrectly-fixed bugs, while there exists a negative impact on the patch\ncorrectness; (4) participants are used to consuming more time to identify\nincorrect patches, while they are still misguided easily; (5) participants are\npositive about the tools' repair performance, while they generally lack\nconfidence about the usability in practice. Besides, we provide some guidelines\nfor improving the usability of APR tools (e.g., the misleading information in\nreports and the observation of feedback).",
    "descriptor": "",
    "authors": [
      "Quanjun Zhang",
      "Yuan Zhao",
      "Weisong Sun",
      "Chunrong Fang",
      "Ziyuan Wang",
      "Lingming Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.05166"
  },
  {
    "id": "arXiv:2203.05167",
    "title": "TiSAT: Time Series Anomaly Transformer",
    "abstract": "While anomaly detection in time series has been an active area of research\nfor several years, most recent approaches employ an inadequate evaluation\ncriterion leading to an inflated F1 score. We show that a rudimentary Random\nGuess method can outperform state-of-the-art detectors in terms of this popular\nbut faulty evaluation criterion. In this work, we propose a proper evaluation\nmetric that measures the timeliness and precision of detecting sequential\nanomalies. Moreover, most existing approaches are unable to capture temporal\nfeatures from long sequences. Self-attention based approaches, such as\ntransformers, have been demonstrated to be particularly efficient in capturing\nlong-range dependencies while being computationally efficient during training\nand inference. We also propose an efficient transformer approach for anomaly\ndetection in time series and extensively evaluate our proposed approach on\nseveral popular benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Keval Doshi",
      "Shatha Abudalou",
      "Yasin Yilmaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.05167"
  },
  {
    "id": "arXiv:2203.05169",
    "title": "Unpacking Invisible Work Practices, Constraints, and Latent Power  Relationships in Child Welfare through Casenote Analysis",
    "abstract": "Caseworkers are trained to write detailed narratives about families in\nChild-Welfare (CW) which informs collaborative high-stakes decision-making.\nUnlike other administrative data, these narratives offer a more credible source\nof information with respect to workers' interactions with families as well as\nunderscore the role of systemic factors in decision-making. SIGCHI researchers\nhave emphasized the need to understand human discretion at the street-level to\nbe able to design human-centered algorithms for the public sector. In this\nstudy, we conducted computational text analysis of casenotes at a child-welfare\nagency in the midwestern United States and highlight patterns of invisible\nstreet-level discretionary work and latent power structures that have direct\nimplications for algorithm design. Casenotes offer a unique lens for\npolicymakers and CW leadership towards understanding the experiences of\non-the-ground caseworkers. As a result of this study, we highlight how\nstreet-level discretionary work needs to be supported by sociotechnical systems\ndeveloped through worker-centered design. This study offers the first\ncomputational inspection of casenotes and introduces them to the SIGCHI\ncommunity as a critical data source for studying complex sociotechnical\nsystems.",
    "descriptor": "",
    "authors": [
      "Devansh Saxena",
      "Erina Seh-Young Moon",
      "Dahlia Shehata",
      "Shion Guha"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.05169"
  },
  {
    "id": "arXiv:2203.05173",
    "title": "TextConvoNet:A Convolutional Neural Network based Architecture for Text  Classification",
    "abstract": "In recent years, deep learning-based models have significantly improved the\nNatural Language Processing (NLP) tasks. Specifically, the Convolutional Neural\nNetwork (CNN), initially used for computer vision, has shown remarkable\nperformance for text data in various NLP problems. Most of the existing\nCNN-based models use 1-dimensional convolving filters n-gram detectors), where\neach filter specialises in extracting n-grams features of a particular input\nword embedding. The input word embeddings, also called sentence matrix, is\ntreated as a matrix where each row is a word vector. Thus, it allows the model\nto apply one-dimensional convolution and only extract n-gram based features\nfrom a sentence matrix. These features can be termed as intra-sentence n-gram\nfeatures. To the extent of our knowledge, all the existing CNN models are based\non the aforementioned concept. In this paper, we present a CNN-based\narchitecture TextConvoNet that not only extracts the intra-sentence n-gram\nfeatures but also captures the inter-sentence n-gram features in input text\ndata. It uses an alternative approach for input matrix representation and\napplies a two-dimensional multi-scale convolutional operation on the input. To\nevaluate the performance of TextConvoNet, we perform an experimental study on\nfive text classification datasets. The results are evaluated by using various\nperformance metrics. The experimental results show that the presented\nTextConvoNet outperforms state-of-the-art machine learning and deep learning\nmodels for text classification purposes.",
    "descriptor": "",
    "authors": [
      "Sanskar Soni",
      "Satyendra Singh Chouhan",
      "Santosh Singh Rathore"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.05173"
  },
  {
    "id": "arXiv:2203.05175",
    "title": "MVP: Multimodality-guided Visual Pre-training",
    "abstract": "Recently, masked image modeling (MIM) has become a promising direction for\nvisual pre-training. In the context of vision transformers, MIM learns\neffective visual representation by aligning the token-level features with a\npre-defined space (e.g., BEIT used a d-VAE trained on a large image corpus as\nthe tokenizer). In this paper, we go one step further by introducing guidance\nfrom other modalities and validating that such additional knowledge leads to\nimpressive gains for visual pre-training. The proposed approach is named\nMultimodality-guided Visual Pre-training (MVP), in which we replace the\ntokenizer with the vision branch of CLIP, a vision-language model pre-trained\non 400 million image-text pairs. We demonstrate the effectiveness of MVP by\nperforming standard experiments, i.e., pre-training the ViT models on ImageNet\nand fine-tuning them on a series of downstream visual recognition tasks. In\nparticular, pre-training ViT-Base/16 for 300 epochs, MVP reports a 52.4% mIoU\non ADE20K, surpassing BEIT (the baseline and previous state-of-the-art) with an\nimpressive margin of 6.8%.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Longhui Wei",
      "Lingxi Xie",
      "Wengang Zhou",
      "Houqiang Li",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05175"
  },
  {
    "id": "arXiv:2203.05176",
    "title": "Stability of structure-aware Taylor methods for tents",
    "abstract": "Structure-aware Taylor (SAT) methods are a class of timestepping schemes\ndesigned for propagating linear hyperbolic solutions within a tent-shaped\nspacetime region. Tents are useful to design explicit time marching schemes on\nunstructured advancing fronts with built-in locally variable timestepping for\narbitrary spatial and temporal discretization orders. The main result of this\npaper is that an $s$-stage SAT timestepping within a tent is weakly stable\nunder the time step constraint $\\Delta t \\leq Ch^{1+1/s}$, where $\\Delta t$ is\nthe time step size and $h$ is the spatial mesh size. Improved stability\nproperties are also presented for high order SAT time discretizations coupled\nwith low order spatial polynomials. A numerical verification of the sharpness\nof proven estimates is also included.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Jay Gopalakrishnan",
      "Zheng Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.05176"
  },
  {
    "id": "arXiv:2203.05178",
    "title": "An Audio-Visual Attention Based Multimodal Network for Fake Talking Face  Videos Detection",
    "abstract": "DeepFake based digital facial forgery is threatening the public media\nsecurity, especially when lip manipulation has been used in talking face\ngeneration, the difficulty of fake video detection is further improved. By only\nchanging lip shape to match the given speech, the facial features of identity\nis hard to be discriminated in such fake talking face videos. Together with the\nlack of attention on audio stream as the prior knowledge, the detection failure\nof fake talking face generation also becomes inevitable. Inspired by the\ndecision-making mechanism of human multisensory perception system, which\nenables the auditory information to enhance post-sensory visual evidence for\ninformed decisions output, in this study, a fake talking face detection\nframework FTFDNet is proposed by incorporating audio and visual representation\nto achieve more accurate fake talking face videos detection. Furthermore, an\naudio-visual attention mechanism (AVAM) is proposed to discover more\ninformative features, which can be seamlessly integrated into any audio-visual\nCNN architectures by modularization. With the additional AVAM, the proposed\nFTFDNet is able to achieve a better detection performance on the established\ndataset (FTFDD). The evaluation of the proposed work has shown an excellent\nperformance on the detection of fake talking face videos, which is able to\narrive at a detection rate above 97%.",
    "descriptor": "",
    "authors": [
      "Ganglai Wang",
      "Peng Zhang",
      "Lei Xie",
      "Wei Huang",
      "Yufei Zha",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.05178"
  },
  {
    "id": "arXiv:2203.05179",
    "title": "Towards Open-Set Text Recognition via Label-to-Prototype Learning",
    "abstract": "Scene text recognition is a popular topic and can benefit various tasks.\nAlthough many methods have been proposed for the close-set text recognition\nchallenges, they cannot be directly applied to open-set scenarios, where the\nevaluation set contains novel characters not appearing in the training set.\nConventional methods require collecting new data and retraining the model to\nhandle these novel characters, which is an expensive and tedious process. In\nthis paper, we propose a label-to-prototype learning framework to handle novel\ncharacters without retraining the model. In the proposed framework, novel\ncharacters are effectively mapped to their corresponding prototypes with a\nlabel-to-prototype learning module. This module is trained on characters with\nseen labels and can be easily generalized to novel characters. Additionally,\nfeature-level rectification is conducted via topology-preserving\ntransformation, resulting in better alignments between visual features and\nconstructed prototypes while having a reasonably small impact on model speed. A\nlot of experiments show that our method achieves promising performance on a\nvariety of zero-shot, close-set, and open-set text recognition datasets.",
    "descriptor": "",
    "authors": [
      "Chang Liu",
      "Chun Yang",
      "Hai-Bo Qin",
      "Xiaobin Zhu",
      "JieBo Hou",
      "Xu-Cheng Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05179"
  },
  {
    "id": "arXiv:2203.05180",
    "title": "Knowledge Distillation as Efficient Pre-training: Faster Convergence,  Higher Data-efficiency, and Better Transferability",
    "abstract": "Large-scale pre-training has been proven to be crucial for various computer\nvision tasks. However, with the increase of pre-training data amount, model\narchitecture amount, and the private/inaccessible data, it is not very\nefficient or possible to pre-train all the model architectures on large-scale\ndatasets. In this work, we investigate an alternative strategy for\npre-training, namely Knowledge Distillation as Efficient Pre-training (KDEP),\naiming to efficiently transfer the learned feature representation from existing\npre-trained models to new student models for future downstream tasks. We\nobserve that existing Knowledge Distillation (KD) methods are unsuitable\ntowards pre-training since they normally distill the logits that are going to\nbe discarded when transferred to downstream tasks. To resolve this problem, we\npropose a feature-based KD method with non-parametric feature dimension\naligning. Notably, our method performs comparably with supervised pre-training\ncounterparts in 3 downstream tasks and 9 downstream datasets requiring 10x less\ndata and 5x less pre-training time. Code is available at\nhttps://github.com/CVMI-Lab/KDEP.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Ruifei He",
      "Shuyang Sun",
      "Jihan Yang",
      "Song Bai",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05180"
  },
  {
    "id": "arXiv:2203.05181",
    "title": "LineVD: Statement-level Vulnerability Detection using Graph Neural  Networks",
    "abstract": "Current machine-learning based software vulnerability detection methods are\nprimarily conducted at the function-level. However, a key limitation of these\nmethods is that they do not indicate the specific lines of code contributing to\nvulnerabilities. This limits the ability of developers to efficiently inspect\nand interpret the predictions from a learnt model, which is crucial for\nintegrating machine-learning based tools into the software development\nworkflow. Graph-based models have shown promising performance in function-level\nvulnerability detection, but their capability for statement-level vulnerability\ndetection has not been extensively explored. While interpreting function-level\npredictions through explainable AI is one promising direction, we herein\nconsider the statement-level software vulnerability detection task from a fully\nsupervised learning perspective. We propose a novel deep learning framework,\nLineVD, which formulates statement-level vulnerability detection as a node\nclassification task. LineVD leverages control and data dependencies between\nstatements using graph neural networks, and a transformer-based model to encode\nthe raw source code tokens. In particular, by addressing the conflicting\noutputs between function-level and statement-level information, LineVD\nsignificantly improve the prediction performance without vulnerability status\nfor function code. We have conducted extensive experiments against a\nlarge-scale collection of real-world C/C++ vulnerabilities obtained from\nmultiple real-world projects, and demonstrate an increase of 105\\% in F1-score\nover the current state-of-the-art.",
    "descriptor": "\nComments: Accepted in the 19th International Conference on Mining Software Repositories Technical Papers\n",
    "authors": [
      "David Hin",
      "Andrey Kan",
      "Huaming Chen",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.05181"
  },
  {
    "id": "arXiv:2203.05186",
    "title": "Suspected Object Matters: Rethinking Model's Prediction for One-stage  Visual Grounding",
    "abstract": "Recently, one-stage visual grounders attract high attention due to the\ncomparable accuracy but significantly higher efficiency than two-stage\ngrounders. However, inter-object relation modeling has not been well studied\nfor one-stage grounders. Inter-object relationship modeling, though important,\nis not necessarily performed among all the objects within the image, as only a\npart of them are related to the text query and may confuse the model. We call\nthese objects \"suspected objects\". However, exploring relationships among these\nsuspected objects in the one-stage visual grounding paradigm is non-trivial due\nto two core problems: (1) no object proposals are available as the basis on\nwhich to select suspected objects and perform relationship modeling; (2)\ncompared with those irrelevant to the text query, suspected objects are more\nconfusing, as they may share similar semantics, be entangled with certain\nrelationships, etc, and thereby more easily mislead the model's prediction. To\naddress the above issues, this paper proposes a Suspected Object Graph (SOG)\napproach to encourage the correct referred object selection among the suspected\nones in the one-stage visual grounding. Suspected objects are dynamically\nselected from a learned activation map as nodes to adapt to the current\ndiscrimination ability of the model during training. Afterward, on top of the\nsuspected objects, a Keyword-aware Node Representation module (KNR) and an\nExploration by Random Connection strategy (ERC) are concurrently proposed\nwithin the SOG to help the model rethink its initial prediction. Extensive\nablation studies and comparison with state-of-the-art approaches on prevalent\nvisual grounding benchmarks demonstrate the effectiveness of our proposed\nmethod.",
    "descriptor": "",
    "authors": [
      "Yang Jiao",
      "Zequn Jie",
      "Jingjing Chen",
      "Lin Ma",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05186"
  },
  {
    "id": "arXiv:2203.05187",
    "title": "Cluttered Food Grasping with Adaptive Fingers and Synthetic-Data Trained  Object Detection",
    "abstract": "The food packaging industry handles an immense variety of food products with\nwide-ranging shapes and sizes, even within one kind of food. Menus are also\ndiverse and change frequently, making automation of pick-and-place difficult. A\npopular approach to bin-picking is to first identify each piece of food in the\ntray by using an instance segmentation method. However, human annotations to\ntrain these methods are unreliable and error-prone since foods are packed close\ntogether with unclear boundaries and visual similarity making separation of\npieces difficult. To address this problem, we propose a method that trains\npurely on synthetic data and successfully transfers to the real world using\nsim2real methods by creating datasets of filled food trays using high-quality\n3d models of real pieces of food for the training instance segmentation models.\nAnother concern is that foods are easily damaged during grasping. We address\nthis by introducing two additional methods -- a novel adaptive finger mechanism\nto passively retract when a collision occurs, and a method to filter grasps\nthat are likely to cause damage to neighbouring pieces of food during a grasp.\nWe demonstrate the effectiveness of the proposed method on several kinds of\nreal foods.",
    "descriptor": "\nComments: 8 pages. Accepted at ICRA2022. An accompanying video is available at this https URL\n",
    "authors": [
      "Avinash Ummadisingu",
      "Kuniyuki Takahashi",
      "Naoki Fukaya"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05187"
  },
  {
    "id": "arXiv:2203.05189",
    "title": "NeRFocus: Neural Radiance Field for 3D Synthetic Defocus",
    "abstract": "Neural radiance fields (NeRF) bring a new wave for 3D interactive\nexperiences. However, as an important part of the immersive experiences, the\ndefocus effects have not been fully explored within NeRF. Some recent\nNeRF-based methods generate 3D defocus effects in a post-process fashion by\nutilizing multiplane technology. Still, they are either time-consuming or\nmemory-consuming. This paper proposes a novel thin-lens-imaging-based NeRF\nframework that can directly render various 3D defocus effects, dubbed NeRFocus.\nUnlike the pinhole, the thin lens refracts rays of a scene point, so its\nimaging on the sensor plane is scattered as a circle of confusion (CoC). A\ndirect solution sampling enough rays to approximate this process is\ncomputationally expensive. Instead, we propose to inverse the thin lens imaging\nto explicitly model the beam path for each point on the sensor plane and\ngeneralize this paradigm to the beam path of each pixel, then use the\nfrustum-based volume rendering to render each pixel's beam path. We further\ndesign an efficient probabilistic training (p-training) strategy to simplify\nthe training process vastly. Extensive experiments demonstrate that our\nNeRFocus can achieve various 3D defocus effects with adjustable camera pose,\nfocus distance, and aperture size. Existing NeRF can be regarded as our special\ncase by setting aperture size as zero to render large depth-of-field images.\nDespite such merits, NeRFocus does not sacrifice NeRF's original performance\n(e.g., training and inference time, parameter consumption, rendering quality),\nwhich implies its great potential for broader application and further\nimprovement.",
    "descriptor": "",
    "authors": [
      "Yinhuai Wang",
      "Shuzhou Yang",
      "Yujie Hu",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05189"
  },
  {
    "id": "arXiv:2203.05192",
    "title": "A Systematic Literature Review on Blockchain Enabled Federated Learning  Framework for Internet of Vehicles",
    "abstract": "While the convergence of Artificial Intelligence (AI) techniques with\nimproved information technology systems ensured enormous benefits to the\nInternet of Vehicles (IoVs) systems, it also introduced an increased amount of\nsecurity and privacy threats. To ensure the security of IoVs data, privacy\npreservation methodologies have gained significant attention in the literature.\nHowever, these strategies also need specific adjustments and modifications to\ncope with the advances in IoVs design. In the interim, Federated Learning (FL)\nhas been proven as an emerging idea to protect IoVs data privacy and security.\nOn the other hand, Blockchain technology is showing prominent possibilities\nwith secured, dispersed, and auditable data recording and sharing schemes. In\nthis paper, we present a comprehensive survey on the application and\nimplementation of Blockchain-Enabled Federated Learning frameworks for IoVs.\nBesides, probable issues, challenges, solutions, and future research directions\nfor BC-Enabled FL frameworks for IoVs are also presented. This survey can\nfurther be used as the basis for developing modern BC-Enabled FL solutions to\nresolve different data privacy issues and scenarios of IoVs.",
    "descriptor": "",
    "authors": [
      "Mustain Billah",
      "Sk. Tanzir Mehedi",
      "Adnan Anwar",
      "Ziaur Rahman",
      "Rafiqul Islam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05192"
  },
  {
    "id": "arXiv:2203.05193",
    "title": "Adaptive Background Matting Using Background Matching",
    "abstract": "Due to the difficulty of solving the matting problem, lots of methods use\nsome kinds of assistance to acquire high quality alpha matte. Green screen\nmatting methods rely on physical equipment. Trimap-based methods take manual\ninteractions as external input. Background-based methods require a\npre-captured, static background. The methods are not flexible and convenient\nenough to use widely. Trimap-free methods are flexible but not stable in\ncomplicated video applications. To be stable and flexible in real applications,\nwe propose an adaptive background matting method. The user first captures their\nvideos freely, moving the cameras. Then the user captures the background video\nafterwards, roughly covering the previous captured regions. We use dynamic\nbackground video instead of static background for accurate matting. The\nproposed method is convenient to use in any scenes as the static camera and\nbackground is no more the limitation. To achieve this goal, we use background\nmatching network to find the best-matched background frame by frame from\ndynamic backgrounds. Then, robust semantic estimation network is used to\nestimate the coarse alpha matte. Finally, we crop and zoom the target region\naccording to the coarse alpha matte, and estimate the final accurate alpha\nmatte. In experiments, the proposed method is able to perform comparably\nagainst the state-of-the-art matting methods.",
    "descriptor": "",
    "authors": [
      "Jinlin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05193"
  },
  {
    "id": "arXiv:2203.05194",
    "title": "Learning Torque Control for Quadrupedal Locomotion",
    "abstract": "Reinforcement learning (RL) is a promising tool for developing controllers\nfor quadrupedal locomotion. The design of most learning-based locomotion\ncontrollers adopts the joint position-based paradigm, wherein a low-frequency\nRL policy outputs target joint positions that are then tracked by a\nhigh-frequency proportional-derivative (PD) controller that outputs joint\ntorques. However, the low frequency of such a policy hinders the advancement of\nhighly dynamic locomotion behaviors. Moreover, determining the PD gains for\noptimal tracking performance is laborious and dependent on the task at hand. In\nthis paper, we introduce a learning torque control framework for quadrupedal\nlocomotion, which trains an RL policy that directly predicts joint torques at a\nhigh frequency, thus circumventing the use of PD controllers. We validate the\nproposed framework with extensive experiments where the robot is able to both\ntraverse various terrains and resist external pushes, given user-specified\ncommands. To our knowledge, this is the first attempt of learning torque\ncontrol for quadrupedal locomotion with an end-to-end single neural network\nthat has led to successful real-world experiments among recent research on\nlearning-based quadrupedal locomotion which is mostly position-based.",
    "descriptor": "",
    "authors": [
      "Shuxiao Chen",
      "Bike Zhang",
      "Mark W. Mueller",
      "Akshara Rai",
      "Koushil Sreenath"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05194"
  },
  {
    "id": "arXiv:2203.05195",
    "title": "A Review of Open Source Software Tools for Time Series Analysis",
    "abstract": "Time series data is used in a wide range of real world applications. In a\nvariety of domains , detailed analysis of time series data (via Forecasting and\nAnomaly Detection) leads to a better understanding of how events associated\nwith a specific time instance behave. Time Series Analysis (TSA) is commonly\nperformed with plots and traditional models. Machine Learning (ML) approaches ,\non the other hand , have seen an increase in the state of the art for\nForecasting and Anomaly Detection because they provide comparable results when\ntime and data constraints are met. A number of time series toolboxes are\navailable that offer rich interfaces to specific model classes (ARIMA/filters ,\nneural networks) or framework interfaces to isolated time series modelling\ntasks (forecasting , feature extraction , annotation , classification).\nNonetheless , open source machine learning capabilities for time series remain\nlimited , and existing libraries are frequently incompatible with one another.\nThe goal of this paper is to provide a concise and user friendly overview of\nthe most important open source tools for time series analysis. This article\nexamines two related toolboxes (1) forecasting and (2) anomaly detection. This\npaper describes a typical Time Series Analysis (TSA) framework with an\narchitecture and lists the main features of TSA framework. The tools are\ncategorized based on the criteria of analysis tasks completed , data\npreparation methods employed , and evaluation methods for results generated.\nThis paper presents quantitative analysis and discusses the current state of\nactively developed open source Time Series Analysis frameworks. Overall , this\narticle considered 60 time series analysis tools , and 32 of which provided\nforecasting modules , and 21 packages included anomaly detection.",
    "descriptor": "\nComments: 21 Pages, 2 Figures\n",
    "authors": [
      "Yunus Parvej Faniband",
      "Iskandar Ishak",
      "Sadiq M.Sait"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05195"
  },
  {
    "id": "arXiv:2203.05198",
    "title": "A Screen-Shooting Resilient Document Image Watermarking Scheme using  Deep Neural Network",
    "abstract": "With the advent of the screen-reading era, the confidential documents\ndisplayed on the screen can be easily captured by a camera without leaving any\ntraces. Thus, this paper proposes a novel screen-shooting resilient\nwatermarking scheme for document image using deep neural network. By applying\nthis scheme, when the watermarked image is displayed on the screen and captured\nby a camera, the watermark can be still extracted from the captured\nphotographs. Specifically, our scheme is an end-to-end neural network with an\nencoder to embed watermark and a decoder to extract watermark. During the\ntraining process, a distortion layer between encoder and decoder is added to\nsimulate the distortions introduced by screen-shooting process in real scenes,\nsuch as camera distortion, shooting distortion, light source distortion.\nBesides, an embedding strength adjustment strategy is designed to improve the\nvisual quality of the watermarked image with little loss of extraction\naccuracy. The experimental results show that the scheme has higher robustness\nand visual quality than other three recent state-of-the-arts. Specially, even\nif the shooting distances and angles are in extreme, our scheme can also obtain\nhigh extraction accuracy.",
    "descriptor": "",
    "authors": [
      "Sulong Ge",
      "Zhihua Xia",
      "Yao Tong",
      "Jian Weng",
      "Jianan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05198"
  },
  {
    "id": "arXiv:2203.05199",
    "title": "Hyperspectral Imaging for cherry tomato",
    "abstract": "Cherry tomato (Solanum Lycopersicum) is popular with consumers over the world\ndue to its special flavor. Soluble solids content (SSC) and firmness are two\nkey metrics for evaluating the product qualities. In this work, we develop\nnon-destructive testing techniques for SSC and fruit firmness based on\nhyperspectral images and a corresponding deep learning regression model.\nHyperspectral reflectance images of over 200 tomato fruits are derived with\nspectrum ranging from 400 to 1000 nm. The acquired hyperspectral images are\ncorrected and the spectral information is extracted. A novel\none-dimensional(1D) convolutional ResNet (Con1dResNet) based regression model\nis prosed and compared with the state of art techniques. Experimental results\nshow that, with a relatively large number of samples our technique is 26.4\\%\nbetter than state of art technique for SSC and 33.7\\% for firmness. The results\nof this study indicate the application potential of hyperspectral imaging\ntechnique in the SSC and firmness detection, which provides a new option for\nnon-destructive testing of cherry tomato fruit quality in the future.",
    "descriptor": "",
    "authors": [
      "Yun Xiang",
      "Qijun Chen",
      "Zhongjin Su",
      "Lu Zhang",
      "Zuohui Chen",
      "Guozhi Zhou",
      "Zhuping Yao",
      "Qi Xuan",
      "Yuan Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05199"
  },
  {
    "id": "arXiv:2203.05201",
    "title": "Online Deep Metric Learning via Mutual Distillation",
    "abstract": "Deep metric learning aims to transform input data into an embedding space,\nwhere similar samples are close while dissimilar samples are far apart from\neach other. In practice, samples of new categories arrive incrementally, which\nrequires the periodical augmentation of the learned model. The fine-tuning on\nthe new categories usually leads to poor performance on the old, which is known\nas \"catastrophic forgetting\". Existing solutions either retrain the model from\nscratch or require the replay of old samples during the training. In this\npaper, a complete online deep metric learning framework is proposed based on\nmutual distillation for both one-task and multi-task scenarios. Different from\nthe teacher-student framework, the proposed approach treats the old and new\nlearning tasks with equal importance. No preference over the old or new\nknowledge is caused. In addition, a novel virtual feature estimation approach\nis proposed to recover the features assumed to be extracted by the old models.\nIt allows the distillation between the new and the old models without the\nreplay of old training samples or the holding of old models during the\ntraining. A comprehensive study shows the superior performance of our approach\nwith the support of different backbones.",
    "descriptor": "",
    "authors": [
      "Gao-Dong Liu",
      "Wan-Lei Zhao",
      "Jie Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05201"
  },
  {
    "id": "arXiv:2203.05203",
    "title": "MORE: Multi-Order RElation Mining for Dense Captioning in 3D Scenes",
    "abstract": "3D dense captioning is a recently-proposed novel task, where point clouds\ncontain more geometric information than the 2D counterpart. However, it is also\nmore challenging due to the higher complexity and wider variety of inter-object\nrelations. Existing methods only treat such relations as by-products of object\nfeature learning in graphs without specifically encoding them, which leads to\nsub-optimal results. In this paper, aiming at improving 3D dense captioning via\ncapturing and utilizing the complex relations in the 3D scene, we propose MORE,\na Multi-Order RElation mining model, to support generating more descriptive and\ncomprehensive captions. Technically, our MORE encodes object relations in a\nprogressive manner since complex relations can be deduced from a limited number\nof basic ones. We first devise a novel Spatial Layout Graph Convolution (SLGC),\nwhich semantically encodes several first-order relations as edges of a graph\nconstructed over 3D object proposals. Next, from the resulting graph, we\nfurther extract multiple triplets which encapsulate basic first-order relations\nas the basic unit and construct several Object-centric Triplet Attention Graphs\n(OTAG) to infer multi-order relations for every target object. The updated node\nfeatures from OTAG are aggregated and fed into the caption decoder to provide\nabundant relational cues so that captions including diverse relations with\ncontext objects can be generated. Extensive experiments on the Scan2Cap dataset\nprove the effectiveness of our proposed MORE and its components, and we also\noutperform the current state-of-the-art method.",
    "descriptor": "",
    "authors": [
      "Yang Jiao",
      "Shaoxiang Chen",
      "Zequn Jie",
      "Jingjing Chen",
      "Lin Ma",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05203"
  },
  {
    "id": "arXiv:2203.05205",
    "title": "Crowd Source Scene Change Detection and Local Map Update",
    "abstract": "As scene changes with time map descriptors become outdated, affecting VPS\nlocalization accuracy. In this work, we propose an approach to detect\nstructural and texture scene changes to be followed by map update. In our\nmethod - map includes 3D points with descriptors generated either via LiDAR or\nSFM. Common approaches suffer from shortcomings: 1) Direct comparison of the\ntwo point-clouds for change detection is slow due to the need to build new\npoint-cloud every time we want to compare; 2) Image based comparison requires\nto keep the map images adding substantial storage overhead. To circumvent this\nproblems, we propose an approach based on point-clouds descriptors comparison:\n1) Based on VPS poses select close query and map images pairs, 2) Registration\nof query images to map image descriptors, 3) Use segmentation to filter out\ndynamic or short term temporal changes, 4) Compare the descriptors between\ncorresponding segments.",
    "descriptor": "",
    "authors": [
      "Itzik Wilf",
      "Nati Daniel",
      "Lin Manqing",
      "Firas Shama",
      "Omri Asraf",
      "Feng Wensen",
      "Ofer Kruzel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05205"
  },
  {
    "id": "arXiv:2203.05206",
    "title": "ReF -- Rotation Equivariant Features for Local Feature Matching",
    "abstract": "Sparse local feature matching is pivotal for many computer vision and\nrobotics tasks. To improve their invariance to challenging appearance\nconditions and viewing angles, and hence their usefulness, existing\nlearning-based methods have primarily focused on data augmentation-based\ntraining. In this work, we propose an alternative, complementary approach that\ncenters on inducing bias in the model architecture itself to generate\n`rotation-specific' features using Steerable E2-CNNs, that are then\ngroup-pooled to achieve rotation-invariant local features. We demonstrate that\nthis high performance, rotation-specific coverage from the steerable CNNs can\nbe expanded to all rotation angles by combining it with augmentation-trained\nstandard CNNs which have broader coverage but are often inaccurate, thus\ncreating a state-of-the-art rotation-robust local feature matcher. We benchmark\nour proposed methods against existing techniques on HPatches and a newly\nproposed UrbanScenes3D-Air dataset for visual place recognition. Furthermore,\nwe present a detailed analysis of the performance effects of ensembling, robust\nestimation, network architecture variations, and the use of rotation priors.",
    "descriptor": "",
    "authors": [
      "Abhishek Peri",
      "Kinal Mehta",
      "Avneesh Mishra",
      "Michael Milford",
      "Sourav Garg",
      "K. Madhava Krishna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.05206"
  },
  {
    "id": "arXiv:2203.05207",
    "title": "Computing Whittle (and Gittins) Index in Subcubic Time",
    "abstract": "Whittle index is a generalization of Gittins index that provides very\nefficient allocation rules for restless multiarmed bandits. In this paper, we\ndevelop an algorithm to test the indexability and compute the Whittle indices\nof any finite-state Markovian bandit problem. This algorithm works in the\ndiscounted and non-discounted cases. As a byproduct, it can also be used to\ncompute Gittins index. Our algorithm builds on three tools: (1) a careful\ncharacterization of Whittle index that allows one to compute recursively the th\nsmallest index from the (-- 1)th smallest, and to test indexability, (2) the\nuse of Sherman-Morrison formula to make this recursive computation efficient,\nand (3) a sporadic use of fast matrix inversion and multiplication to obtain a\nsubcubic complexity. We show that an efficient use of the Sherman-Morrison\nformula leads to an algorithm that computes Whittle index in (2$\\Uparrow$3) 3 +\n(3) arithmetic operations, where is the number of states of the arm. The\ncareful use of fast matrix multiplication leads to the first subcubic algorithm\nto compute Whittle (or Gittins) index. By using the current fastest matrix\nmultiplications, our algorithm runs in (2.5286). We also conduct a series of\nexperiments that demonstrate that our algorithm is very efficient in practice\nand can compute indices of Markov chains with several thousands of states in a\nfew seconds.",
    "descriptor": "",
    "authors": [
      "Nicolas Gast",
      "Bruno Gaujal",
      "Kimang Khun"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.05207"
  },
  {
    "id": "arXiv:2203.05208",
    "title": "Transferring Dual Stochastic Graph Convolutional Network for Facial  Micro-expression Recognition",
    "abstract": "Micro-expression recognition has drawn increasing attention due to its wide\napplication in lie detection, criminal detection and psychological\nconsultation. To improve the recognition performance of the small\nmicro-expression data, this paper presents a transferring dual stochastic Graph\nConvolutional Network (TDSGCN) model. We propose a stochastic graph\nconstruction method and dual graph convolutional network to extract more\ndiscriminative features from the micro-expression images. We use transfer\nlearning to pre-train SGCNs from macro expression data. Optical flow algorithm\nis also integrated to extract their temporal features. We fuse both spatial and\ntemporal features to improve the recognition performance. To the best of our\nknowledge, this is the first attempt to utilize the transferring learning and\ngraph convolutional network in micro-expression recognition task. In addition,\nto handle the class imbalance problem of dataset, we focus on the design of\nfocal loss function. Through extensive evaluation, our proposed method achieves\nstate-of-the-art performance on SAMM and recently released MMEW benchmarks. Our\ncode will be publicly available accompanying this paper.",
    "descriptor": "",
    "authors": [
      "Hui Tang",
      "Li Chai",
      "Wanli Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.05208"
  },
  {
    "id": "arXiv:2203.05212",
    "title": "Membership Privacy Protection for Image Translation Models via  Adversarial Knowledge Distillation",
    "abstract": "Image-to-image translation models are shown to be vulnerable to the\nMembership Inference Attack (MIA), in which the adversary's goal is to identify\nwhether a sample is used to train the model or not. With daily increasing\napplications based on image-to-image translation models, it is crucial to\nprotect the privacy of these models against MIAs.\nWe propose adversarial knowledge distillation (AKD) as a defense method\nagainst MIAs for image-to-image translation models. The proposed method\nprotects the privacy of the training samples by improving the generalizability\nof the model. We conduct experiments on the image-to-image translation models\nand show that AKD achieves the state-of-the-art utility-privacy tradeoff by\nreducing the attack performance up to 38.9% compared with the regular training\nmodel at the cost of a slight drop in the quality of the generated output\nimages. The experimental results also indicate that the models trained by AKD\ngeneralize better than the regular training models. Furthermore, compared with\nexisting defense methods, the results show that at the same privacy protection\nlevel, image translation models trained by AKD generate outputs with higher\nquality; while at the same quality of outputs, AKD enhances the privacy\nprotection over 30%.",
    "descriptor": "",
    "authors": [
      "Saeed Ranjbar Alvar",
      "Lanjun Wang",
      "Jian Pei",
      "Yong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.05212"
  },
  {
    "id": "arXiv:2203.05215",
    "title": "A Benchmark for Active Learning of Variability-Intensive Systems",
    "abstract": "Behavioral models are the key enablers for behavioral analysis of Software\nProduct Lines (SPL), including testing and model checking. Active model\nlearning comes to the rescue when family behavioral models are non-existent or\noutdated. A key challenge on active model learning is to detect commonalities\nand variability efficiently and combine them into concise family models.\nBenchmarks and their associated metrics will play a key role in shaping the\nresearch agenda in this promising field and provide an effective means for\ncomparing and identifying relative strengths and weaknesses in the forthcoming\ntechniques. In this challenge, we seek benchmarks to evaluate the efficiency\n(e.g., learning time and memory footprint) and effectiveness (e.g., conciseness\nand accuracy of family models) of active model learning methods in the software\nproduct line context. These benchmark sets must contain the structural and\nbehavioral variability models of at least one SPL. Each SPL in a benchmark must\ncontain products that requires more than one round of model learning with\nrespect to the basic active learning $L^{*}$ algorithm. Alternatively, tools\nsupporting the synthesis of artificial benchmark models are also welcome.",
    "descriptor": "\nComments: 5 pages, 3 figures, Paper accepted in the Challenge Cases Track of the 26th ACM International Systems and Software Product Line Conference (SPLC 2022)\n",
    "authors": [
      "Shaghayegh Tavassoli",
      "Carlos Diego Nascimento Damasceno",
      "Mohammad Reza Mousavi",
      "Ramtin Khosravi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.05215"
  },
  {
    "id": "arXiv:2203.05219",
    "title": "Organisations (de-)centralised to a greater or lesser degree for  allocating cities in two Multiple Travelling Salesmen Problems",
    "abstract": "Decisions in organisations may be made either by a Central Authority (CA),\ne.g., in a hierarchy, or by the agents in a decentralised way, e.g., in a\nheterarchy. Since both kinds of organisations have their advantages (e.g.,\noptimality for centralised organisations and reactivity for decentralised\nones), our goal is ultimately to understand when and how to use each of them.\nOur previous work proposed a variant of the Multiple Travelling Salesmen\nProblem, which we now call MTSPs . We use the subscript \"s\" to refer to\nsalesmen's selfishness when they minimise their individual route length. If, on\nthe contrary, they are assumed to be benevolent, we add subscript \"b\" and thus\nthe term MTSPb to refer to the traditional MTSP in which the salesmen minimise\nthe total route length. This article shows how to obtain such benevolent agents\nby slightly modifying selfish agents. We can then compare organisations which\nare (de-)centralised to a greater or lesser degree, which enables us to carry\nout the allocation of cities in the MTSPb . The first experiment shows that the\nrelative efficiency (ranking) of the organisations differs between MTSPb and\nMTSPs . Since reactivity fosters decentralisation, the second experiment\ngradually reduces the time taken for it to impact this ranking. Both\nexperiments show that pure centralisation is either the best or the worst\noption, and that the zone between the two situations is very narrow.",
    "descriptor": "",
    "authors": [
      "Thierry Moyaux"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.05219"
  },
  {
    "id": "arXiv:2203.05221",
    "title": "Realizing Implicit Computational Complexity",
    "abstract": "This abstract aims at presenting an ongoing effort to apply a novel typing\nmechanism stemming from Implicit Computational Complexity (ICC), that tracks\ndependencies between variables in three different ways, at different stages of\nmaturation.The first and third projects bend the original typing discipline to\ngain finer-grained view on statements independence, to optimize loops by\nhoisting invariant and by splitting loops \"horizontally\" to parallelize them\nmore efficiently.The second project refines and implements the original\nanalysis to obtain a fast, modular static analyzer.All three projects aims at\npushing the original type system, inspired from ICC, to its limits, to assess\nhow ICC can in practice leads to original, sometimes orthogonal, approaches.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Aubert",
      "Thomas Rubiano",
      "Neea Rusch",
      "Thomas Seiller"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.05221"
  },
  {
    "id": "arXiv:2203.05222",
    "title": "Clustering Label Inference Attack against Practical Split Learning",
    "abstract": "Split learning is deemed as a promising paradigm for privacy-preserving\ndistributed learning, where the learning model can be cut into multiple\nportions to be trained at the participants collaboratively. The participants\nonly exchange the intermediate learning results at the cut layer, including\nsmashed data via forward-pass (i.e., features extracted from the raw data) and\ngradients during backward-propagation.Understanding the security performance of\nsplit learning is critical for various privacy-sensitive applications.With the\nemphasis on private labels, this paper proposes a passive clustering label\ninference attack for practical split learning. The adversary (either clients or\nservers) can accurately retrieve the private labels by collecting the exchanged\ngradients and smashed data.We mathematically analyse potential label leakages\nin split learning and propose the cosine and Euclidean similarity measurements\nfor clustering attack. Experimental results validate that the proposed approach\nis scalable and robust under different settings (e.g., cut layer positions,\nepochs, and batch sizes) for practical split learning.The adversary can still\nachieve accurate predictions, even when differential privacy and gradient\ncompression are adopted for label protections.",
    "descriptor": "",
    "authors": [
      "Junlin Liu",
      "Xinchen Lyu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.05222"
  },
  {
    "id": "arXiv:2203.05227",
    "title": "Faithfulness in Natural Language Generation: A Systematic Survey of  Analysis, Evaluation and Optimization Methods",
    "abstract": "Natural Language Generation (NLG) has made great progress in recent years due\nto the development of deep learning techniques such as pre-trained language\nmodels. This advancement has resulted in more fluent, coherent and even\nproperties controllable (e.g. stylistic, sentiment, length etc.) generation,\nnaturally leading to development in downstream tasks such as abstractive\nsummarization, dialogue generation, machine translation, and data-to-text\ngeneration. However, the faithfulness problem that the generated text usually\ncontains unfaithful or non-factual information has become the biggest\nchallenge, which makes the performance of text generation unsatisfactory for\npractical applications in many real-world scenarios. Many studies on analysis,\nevaluation, and optimization methods for faithfulness problems have been\nproposed for various tasks, but have not been organized, compared and discussed\nin a combined manner. In this survey, we provide a systematic overview of the\nresearch progress on the faithfulness problem of NLG, including problem\nanalysis, evaluation metrics and optimization methods. We organize the\nevaluation and optimization methods for different tasks into a unified taxonomy\nto facilitate comparison and learning across tasks. Several research trends are\ndiscussed further.",
    "descriptor": "\nComments: The first version\n",
    "authors": [
      "Wei Li",
      "Wenhao Wu",
      "Moye Chen",
      "Jiachen Liu",
      "Xinyan Xiao",
      "Hua Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05227"
  },
  {
    "id": "arXiv:2203.05232",
    "title": "Evaluation of Machine Learning Algorithms in Network-Based Intrusion  Detection System",
    "abstract": "Cybersecurity has become one of the focuses of organisations. The number of\ncyberattacks keeps increasing as Internet usage continues to grow. An intrusion\ndetection system (IDS) is an alarm system that helps to detect cyberattacks. As\nnew types of cyberattacks continue to emerge, researchers focus on developing\nmachine learning (ML) based IDS to detect zero-day attacks. Researchers usually\nremove some or all attack samples from the training dataset and only include\nthem in the testing dataset when evaluating the performance of an IDS on\ndetecting zero-day attacks. Although this method may show the ability of an IDs\nto detect unknown attacks; however, it does not reflect the long-term\nperformance of the IDS as it only shows the changes in the type of attacks. In\nthis paper, we focus on evaluating the long-term performance of ML based IDS.\nTo achieve this goal, we propose evaluating the ML-based IDS using a dataset\nthat is created later than the training dataset. The proposed method can better\nassess the long-term performance of an ML-based IDS, as the testing dataset\nreflects the changes in the type of attack and the changes in network\ninfrastructure over time. We have implemented six of the most popular ML models\nthat are used for IDS, including decision tree (DT), random forest (RF),\nsupport vector machine (SVM), na\\\"ive Bayes (NB), artificial neural network\n(ANN) and deep neural network (DNN). Our experiments using the CIC-IDS2017 and\nthe CSE-CIC-IDS2018 datasets show that SVM and ANN are most resistant to\noverfitting. Besides that, our experiment results also show that DT and RF\nsuffer the most from overfitting, although they perform well on the training\ndataset. On the other hand, our experiments using the LUFlow dataset have shown\nthat all models can perform well when the difference between the training and\ntesting datasets is small.",
    "descriptor": "",
    "authors": [
      "Tuan-Hong Chua",
      "Iftekhar Salam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.05232"
  },
  {
    "id": "arXiv:2203.05237",
    "title": "Entropy Rate Bounds via Second-Order Statistics",
    "abstract": "This work contains two single-letter upper bounds on the entropy rate of a\ndiscrete-valued stationary stochastic process, which only depend on\nsecond-order statistics, and are primarily suitable for models which consist of\nrelatively large alphabets. The first bound stems from Gaussian maximum-entropy\nconsiderations and depends on the power spectral density (PSD) function of the\nprocess. While the PSD function cannot always be calculated in a closed-form,\nwe also propose a second bound, which merely relies on some finite collection\nof auto-covariance values of the process. Both of the bounds consist of a\none-dimensional integral, while the second bound also consists of a\nminimization problem over a bounded region, hence they can be efficiently\ncalculated numerically. Examples are also provided to show that the new bounds\noutperform the standard conditional entropy bound.",
    "descriptor": "",
    "authors": [
      "Ran Tamir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.05237"
  },
  {
    "id": "arXiv:2203.05238",
    "title": "Back to Reality: Weakly-supervised 3D Object Detection with Shape-guided  Label Enhancement",
    "abstract": "In this paper, we propose a weakly-supervised approach for 3D object\ndetection, which makes it possible to train strong 3D detector with\nposition-level annotations (i.e. annotations of object centers). In order to\nremedy the information loss from box annotations to centers, our method, namely\nBack to Reality (BR), makes use of synthetic 3D shapes to convert the weak\nlabels into fully-annotated virtual scenes as stronger supervision, and in turn\nutilizes the perfect virtual labels to complement and refine the real labels.\nSpecifically, we first assemble 3D shapes into physically reasonable virtual\nscenes according to the coarse scene layout extracted from position-level\nannotations. Then we go back to reality by applying a virtual-to-real domain\nadaptation method, which refine the weak labels and additionally supervise the\ntraining of detector with the virtual scenes. Furthermore, we propose a more\nchallenging benckmark for indoor 3D object detection with more diversity in\nobject sizes to better show the potential of BR. With less than 5% of the\nlabeling labor, we achieve comparable detection performance with some popular\nfully-supervised approaches on the widely used ScanNet dataset. Code is\navailable at: https://github.com/xuxw98/BackToReality",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Xiuwei Xu",
      "Yifan Wang",
      "Yu Zheng",
      "Yongming Rao",
      "Jiwen Lu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05238"
  },
  {
    "id": "arXiv:2203.05241",
    "title": "Theory of Network Wave (On a Primary Path)",
    "abstract": "Aiming at the disorder problem (i.e. uncertainty problem) of the utilization\nof network resources commonly existing in multi-hop transmission networks, the\npaper proposes the idea and the corresponding supporting theory, i.e. theory of\nnetwork wave, by constructing volatility information transmission mechanism\nbetween the sending nodes of a primary path, so as to improve the orderliness\nof the utilization of network resources. It is proved that the maximum\nasymptotic throughput of a primary path depends on its intrinsic period, which\nin itself is equal to the intrinsic interference intensity of a primary path.\nBased on the proposed theory of network wave, an algorithm for the transmission\nof information blocks based on the intrinsic period of a primary path is\nproposed, which can maximize the asymptotic throughput of the primary path. The\nresearch results of the paper lay an ideological and theoretical foundation for\nfurther exploring more general methods that can improve the orderly utilization\nof network resources.",
    "descriptor": "",
    "authors": [
      "Bo Li",
      "Mao Yang",
      "Zhongjiang Yan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.05241"
  },
  {
    "id": "arXiv:2203.05242",
    "title": "Conditional Synthetic Data Generation for Personal Thermal Comfort  Models",
    "abstract": "Personal thermal comfort models aim to predict an individual's thermal\ncomfort response, instead of the average response of a large group. Recently,\nmachine learning algorithms have proven to be having enormous potential as a\ncandidate for personal thermal comfort models. But, often within the normal\nsettings of a building, personal thermal comfort data obtained via experiments\nare heavily class-imbalanced. There are a disproportionately high number of\ndata samples for the \"Prefer No Change\" class, as compared with the \"Prefer\nWarmer\" and \"Prefer Cooler\" classes. Machine learning algorithms trained on\nsuch class-imbalanced data perform sub-optimally when deployed in the real\nworld. To develop robust machine learning-based applications using the above\nclass-imbalanced data, as well as for privacy-preserving data sharing, we\npropose to implement a state-of-the-art conditional synthetic data generator to\ngenerate synthetic data corresponding to the low-frequency classes. Via\nexperiments, we show that the synthetic data generated has a distribution that\nmimics the real data distribution. The proposed method can be extended for use\nby other smart building datasets/use-cases.",
    "descriptor": "",
    "authors": [
      "Hari Prasanna Das",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05242"
  },
  {
    "id": "arXiv:2203.05243",
    "title": "A Closer Look at Debiased Temporal Sentence Grounding in Videos:  Dataset, Metric, and Approach",
    "abstract": "Temporal Sentence Grounding in Videos (TSGV), which aims to ground a natural\nlanguage sentence in an untrimmed video, has drawn widespread attention over\nthe past few years. However, recent studies have found that current benchmark\ndatasets may have obvious moment annotation biases, enabling several simple\nbaselines even without training to achieve SOTA performance. In this paper, we\ntake a closer look at existing evaluation protocols, and find both the\nprevailing dataset and evaluation metrics are the devils that lead to\nuntrustworthy benchmarking. Therefore, we propose to re-organize the two\nwidely-used datasets, making the ground-truth moment distributions different in\nthe training and test splits, i.e., out-of-distribution (OOD) test. Meanwhile,\nwe introduce a new evaluation metric \"dR@n,IoU@m\" that discounts the basic\nrecall scores to alleviate the inflating evaluation caused by biased datasets.\nNew benchmarking results indicate that our proposed evaluation protocols can\nbetter monitor the research progress. Furthermore, we propose a novel\ncausality-based Multi-branch Deconfounding Debiasing (MDD) framework for\nunbiased moment prediction. Specifically, we design a multi-branch deconfounder\nto eliminate the effects caused by multiple confounders with causal\nintervention. In order to help the model better align the semantics between\nsentence queries and video moments, we enhance the representations during\nfeature encoding. Specifically, for textual information, the query is parsed\ninto several verb-centered phrases to obtain a more fine-grained textual\nfeature. For visual information, the positional information has been decomposed\nfrom moment features to enhance representations of moments with diverse\nlocations. Extensive experiments demonstrate that our proposed approach can\nachieve competitive results among existing SOTA approaches and outperform the\nbase model with great gains.",
    "descriptor": "",
    "authors": [
      "Xiaohan Lan",
      "Yitian Yuan",
      "Xin Wang",
      "Long Chen",
      "Zhi Wang",
      "Lin Ma",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.05243"
  },
  {
    "id": "arXiv:2203.05248",
    "title": "Look Backward and Forward: Self-Knowledge Distillation with  Bidirectional Decoder for Neural Machine Translation",
    "abstract": "Neural Machine Translation(NMT) models are usually trained via unidirectional\ndecoder which corresponds to optimizing one-step-ahead prediction. However,\nthis kind of unidirectional decoding framework may incline to focus on local\nstructure rather than global coherence. To alleviate this problem, we propose a\nnovel method, Self-Knowledge Distillation with Bidirectional Decoder for Neural\nMachine Translation(SBD-NMT). We deploy a backward decoder which can act as an\neffective regularization method to the forward decoder. By leveraging the\nbackward decoder's information about the longer-term future, distilling\nknowledge learned in the backward decoder can encourage auto-regressive NMT\nmodels to plan ahead. Experiments show that our method is significantly better\nthan the strong Transformer baselines on multiple machine translation data\nsets. Our codes will be released on github soon.",
    "descriptor": "",
    "authors": [
      "Xuanwei Zhang",
      "Libin Shen",
      "Disheng Pan",
      "Liang Wang",
      "Yanjun Miao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05248"
  },
  {
    "id": "arXiv:2203.05251",
    "title": "Real-time Scene Text Detection Based on Global Level and Word Level  Features",
    "abstract": "It is an extremely challenging task to detect arbitrary shape text in natural\nscenes on high accuracy and efficiency. In this paper, we propose a scene text\ndetection framework, namely GWNet, which mainly includes two modules: Global\nmodule and RCNN module. Specifically, Global module improves the adaptive\nperformance of the DB (Differentiable Binarization) module by adding k\nsubmodule and shift submodule. Two submodules enhance the adaptability of\namplifying factor k, accelerate the convergence of models and help to produce\nmore accurate detection results. RCNN module fuses global-level and word-level\nfeatures. The word-level label is generated by obtaining the minimum\naxis-aligned rectangle boxes of the shrunk polygon. In the inference period,\nGWNet only uses global-level features to output simple polygon detections.\nExperiments on four benchmark datasets, including the MSRA-TD500, Total-Text,\nICDAR2015 and CTW-1500, demonstrate that our GWNet outperforms the\nstate-of-the-art detectors. Specifically, with a backbone of ResNet-50, we\nachieve an F-measure of 88.6% on MSRA- TD500, 87.9% on Total-Text, 89.2% on\nICDAR2015 and 87.5% on CTW-1500.",
    "descriptor": "",
    "authors": [
      "Fuqiang Zhao",
      "Jionghua Yu",
      "Enjun Xing",
      "Wenming Song",
      "Xue Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05251"
  },
  {
    "id": "arXiv:2203.05256",
    "title": "Cyber security and the Leviathan",
    "abstract": "Dedicated cyber-security functions are common in commercial businesses, who\nare confronted by evolving and pervasive threats of data breaches and other\nperilous security events. Such businesses are enmeshed with the wider societies\nin which they operate. Using data gathered from in-depth, semi-structured\ninterviews with 15 Chief Information Security Officers, as well as six senior\norganisational leaders, we show that the work of political philosopher Thomas\nHobbes, particularly Leviathan, offers a useful lens through which to\nunderstand the context of these functions and of cyber security in Western\nsociety. Our findings indicate that cyber security within these businesses\ndemonstrates a number of Hobbesian features that are further implicated in, and\nprovide significant benefits to, the wider Leviathan-esque state. These include\nthe normalisation of intrusive controls, such as surveillance, and the\nstimulation of consumption. We conclude by suggesting implications for\ncyber-security practitioners, in particular, the reflexivity that these\nperspectives offer, as well as for businesses and other researchers.",
    "descriptor": "",
    "authors": [
      "Joseph Da Silva"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.05256"
  },
  {
    "id": "arXiv:2203.05261",
    "title": "Stable Parametrization of Continuous and Piecewise-Linear Functions",
    "abstract": "Rectified-linear-unit (ReLU) neural networks, which play a prominent role in\ndeep learning, generate continuous and piecewise-linear (CPWL) functions. While\nthey provide a powerful parametric representation, the mapping between the\nparameter and function spaces lacks stability. In this paper, we investigate an\nalternative representation of CPWL functions that relies on local hat basis\nfunctions. It is predicated on the fact that any CPWL function can be specified\nby a triangulation and its values at the grid points. We give the necessary and\nsufficient condition on the triangulation (in any number of dimensions) for the\nhat functions to form a Riesz basis, which ensures that the link between the\nparameters and the corresponding CPWL function is stable and unique. In\naddition, we provide an estimate of the $\\ell_2\\rightarrow L_2$ condition\nnumber of this local representation. Finally, as a special case of our\nframework, we focus on a systematic parametrization of $\\mathbb{R}^d$ with\ncontrol points placed on a uniform grid. In particular, we choose hat basis\nfunctions that are shifted replicas of a single linear box spline. In this\nsetting, we prove that our general estimate of the condition number is optimal.\nWe also relate our local representation to a nonlocal one based on shifts of a\ncausal ReLU-like function.",
    "descriptor": "",
    "authors": [
      "Alexis Goujon",
      "Joaquim Campos",
      "Michael Unser"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.05261"
  },
  {
    "id": "arXiv:2203.05266",
    "title": "EVExchange: A Relay Attack on Electric Vehicle Charging System",
    "abstract": "To support the increasing spread of Electric Vehicles (EVs), Charging\nStations (CSs) are being installed worldwide. The new generation of CSs employs\nthe Vehicle-To-Grid (V2G) paradigm by implementing novel standards such as the\nISO 15118. This standard enables high-level communication between the vehicle\nand the charging column, helps manage the charge smartly, and simplifies the\npayment phase. This novel charging paradigm, which connects the Smart Grid to\nexternal networks (e.g., EVs and CSs), has not been thoroughly examined yet.\nTherefore, it may lead to dangerous vulnerability surfaces and new research\nchallenges.\nIn this paper, we present EVExchange, the first attack to steal energy during\na charging session in a V2G communication: i.e., charging the attacker's car\nwhile letting the victim pay for it. Furthermore, if reverse charging flow is\nenabled, the attacker can even sell the energy available on the victim's car!\nThus, getting the economic profit of this selling, and leaving the victim with\na completely discharged battery. We developed a virtual and a physical testbed\nin which we validate the attack and prove its effectiveness in stealing the\nenergy. To prevent the attack, we propose a lightweight modification of the ISO\n15118 protocol to include a distance bounding algorithm. Finally, we validated\nthe countermeasure on our testbeds. Our results show that the proposed\ncountermeasure can identify all the relay attack attempts while being\ntransparent to the user.",
    "descriptor": "\nComments: 20 pages, 6 figures\n",
    "authors": [
      "Mauro Conti",
      "Denis Donadel",
      "Radha Poovendran",
      "Federico Turrin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.05266"
  },
  {
    "id": "arXiv:2203.05267",
    "title": "Simple Approximative Algorithms for Free-Support Wasserstein Barycenters",
    "abstract": "Computing Wasserstein barycenters of discrete measures has recently attracted\nconsiderable attention due to its wide variety of applications in data science.\nIn general, this problem is NP-hard, calling for practical approximative\nalgorithms. In this paper, we analyze two straightforward algorithms for\napproximating barycenters, which produce sparse support solutions and show\npromising numerical results. These algorithms require $N-1$ and $N(N-1)/2$\nstandard two-marginal OT computations between the $N$ input measures,\nrespectively, so that they are fast, in particular the first algorithm, as well\nas memory-efficient and easy to implement. Further, they can be used with any\nOT solver as a black box. Based on relations of the barycenter problem to the\nmulti-marginal optimal transport problem, which are interesting on their own,\nwe prove sharp upper bounds for the relative approximation error. In the second\nalgorithm, this upper bound can be evaluated specifically for the given\nproblem, which always guaranteed an error of at most a few percent in our\nnumerical experiments.",
    "descriptor": "",
    "authors": [
      "Johannes von Lindheim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.05267"
  },
  {
    "id": "arXiv:2203.05272",
    "title": "Contrastive Boundary Learning for Point Cloud Segmentation",
    "abstract": "Point cloud segmentation is fundamental in understanding 3D environments.\nHowever, current 3D point cloud segmentation methods usually perform poorly on\nscene boundaries, which degenerates the overall segmentation performance. In\nthis paper, we focus on the segmentation of scene boundaries. Accordingly, we\nfirst explore metrics to evaluate the segmentation performance on scene\nboundaries. To address the unsatisfactory performance on boundaries, we then\npropose a novel contrastive boundary learning (CBL) framework for point cloud\nsegmentation. Specifically, the proposed CBL enhances feature discrimination\nbetween points across boundaries by contrasting their representations with the\nassistance of scene contexts at multiple scales. By applying CBL on three\ndifferent baseline methods, we experimentally show that CBL consistently\nimproves different baselines and assists them to achieve compelling performance\non boundaries, as well as the overall performance, eg in mIoU. The experimental\nresults demonstrate the effectiveness of our method and the importance of\nboundaries for 3D point cloud segmentation. Code and model will be made\npublicly available at https://github.com/LiyaoTang/contrastBoundary.",
    "descriptor": "\nComments: Preprint; To appear in CVPR2022\n",
    "authors": [
      "Liyao Tang",
      "Yibing Zhan",
      "Zhe Chen",
      "Baosheng Yu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05272"
  },
  {
    "id": "arXiv:2203.05281",
    "title": "Regret-Matching Learning-Based Task Assignment in Vehicular Edge  Computing",
    "abstract": "Vehicular edge computing has recently been proposed to support\ncomputation-intensive applications in Intelligent Transportation Systems (ITS)\nsuch as augmented reality and autonomous driving. Despite recent progress in\nthis area, significant challenges remain to efficiently allocate limited\ncomputation resources to a range of time-critical ITS tasks. Toward this end,\nthe current paper develops a new task assignment scheme for vehicles in a\nhighway scenario. Because of the high speed of vehicles and the limited\ncommunication range of road side units (RSUs), the computation tasks of\nparticipating vehicles are to be migrated across multiple servers. We formulate\na binary nonlinear programming (BNLP) problem of assigning computation tasks\nfrom vehicles to RSUs and a macrocell base station. To deal with the\npotentially large size of the formulated optimization problem, we develop a\ndistributed multi-agent regret-matching learning algorithm. Based on the regret\nminimization principle, the proposed algorithm employs a forgetting method that\nallows the learning process to quickly adapt to and effectively handle the high\nmobility feature of vehicle networks. We theoretically prove that it converges\nto the correlated equilibrium solutions of the considered BNLP problem.\nSimulation results with practical parameter settings show that the proposed\nalgorithm offers the lowest total delay and cost of processing tasks.\nImportantly, our algorithm converges much faster than existing methods as the\nproblem size grows, demonstrating its clear advantage in large-scale vehicular\nnetworks.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Bach Long Nguyen",
      "Duong D. Nguyen",
      "Hung X. Nguyen",
      "Duy T. Ngo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05281"
  },
  {
    "id": "arXiv:2203.05283",
    "title": "Beyond the Badge: Reproducibility Engineering as a Lifetime Skill",
    "abstract": "Ascertaining reproducibility of scientific experiments is receiving increased\nattention across disciplines. We argue that the necessary skills are important\nbeyond pure scientific utility, and that they should be taught as part of\nsoftware engineering (SWE) education. They serve a dual purpose: Apart from\nacquiring the coveted badges assigned to reproducible research, reproducibility\nengineering is a lifetime skill for a professional industrial career in\ncomputer science. SWE curricula seem an ideal fit for conveying such\ncapabilities, yet they require some extensions, especially given that even at\nflagship conferences like ICSE, only slightly more than one-third of the\ntechnical papers (at the 2021 edition) receive recognition for artefact\nreusability. Knowledge and capabilities in setting up engineering environments\nthat allow for reproducing artefacts and results over decades (a standard\nrequirement in many traditional engineering disciplines), writing semi-literate\ncommit messages that document crucial steps of a decision-making process and\nthat are tightly coupled with code, or sustainably taming dynamic, quickly\nchanging software dependencies, to name a few: They all contribute to solving\nthe scientific reproducibility crisis, and enable software engineers to build\nsustainable, long-term maintainable, software-intensive, industrial systems. We\npropose to teach these skills at the undergraduate level, on par with\ntraditional SWE topics.",
    "descriptor": "",
    "authors": [
      "Wolfgang Mauerer",
      "Stefan Klessinger",
      "Stefanie Scherzinger"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.05283"
  },
  {
    "id": "arXiv:2203.05285",
    "title": "API: Boosting Multi-Agent Reinforcement Learning via  Agent-Permutation-Invariant Networks",
    "abstract": "Multi-agent reinforcement learning suffers from poor sample efficiency due to\nthe exponential growth of the state-action space. Considering a homogeneous\nmultiagent system, a global state consisting of $m$ homogeneous components has\n$m!$ differently ordered representations, thus designing functions satisfying\npermutation invariant (PI) can reduce the state space by a factor of\n$\\frac{1}{m!}$. However, mainstream MARL algorithms ignore this property and\nlearn over the original state space. To achieve PI, previous works including\ndata augmentation based methods and embedding-sharing architecture based\nmethods, suffer from training instability and limited model capacity. In this\nwork, we propose two novel designs to achieve PI, while avoiding the above\nlimitations. The first design permutes the same but differently ordered inputs\nback to the same order and the downstream networks only need to learn function\nmapping over fixed-ordering inputs instead of all permutations, which is much\neasier to train. The second design applies a hypernetwork to generate\ncustomized embedding for each component, which has higher representational\ncapacity than the previous embedding-sharing method. Empirical results on the\nSMAC benchmark show that the proposed method achieves 100% win-rates in almost\nall hard and super-hard scenarios (never achieved before), and superior\nsample-efficiency than the state-of-the-art baselines by up to 400%.",
    "descriptor": "",
    "authors": [
      "Xiaotian Hao",
      "Weixun Wang",
      "Hangyu Mao",
      "Yaodong Yang",
      "Dong Li",
      "Yan Zheng",
      "Zhen Wang",
      "Jianye Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.05285"
  },
  {
    "id": "arXiv:2203.05291",
    "title": "On Robustness in Optimization-Based Constrained Iterative Learning  Control",
    "abstract": "Iterative learning control (ILC) is a control strategy for repetitive tasks\nwherein information from previous runs is leveraged to improve future\nperformance. Optimization-based ILC (OB-ILC) is a powerful design framework for\nconstrained ILC where measurements from the process are integrated into an\noptimization algorithm to provide robustness against noise and modelling error.\nThis paper proposes a robust ILC controller for constrained linear processes\nbased on the forward-backward splitting algorithm. It demonstrates how\nstructured uncertainty information can be leveraged to ensure constraint\nsatisfaction and provides a rigorous stability analysis in the iteration domain\nby combining concepts from monotone operator theory and robust control.\nNumerical simulations of a precision motion stage support the theoretical\nresults.",
    "descriptor": "",
    "authors": [
      "Dominic Liao-McPherson",
      "Efe C. Balta",
      "Alisa Rupenyan",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05291"
  },
  {
    "id": "arXiv:2203.05294",
    "title": "Domain Generalisation for Object Detection",
    "abstract": "Domain generalisation aims to promote the learning of domain-invariant\nfeatures while suppressing domain specific features, so that a model can\ngeneralise well on previously unseen target domains. This paper studies domain\ngeneralisation in the object detection setting. We propose new terms for\nhandling both the bounding box detector and domain belonging, and incorporate\nthem with consistency regularisation. This allows us to learn a domain agnostic\nfeature representation for object detection, applicable to the problem of\ndomain generalisation. The proposed approach is evaluated using four standard\nobject detection datasets with available domain metadata, namely GWHD,\nCityscapes, BDD100K, Sim10K and exhibits consistently superior generalisation\nperformance over baselines.",
    "descriptor": "",
    "authors": [
      "Karthik Seemakurthy",
      "Charles Fox",
      "Erchan Aptoula",
      "Petra Bosilj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05294"
  },
  {
    "id": "arXiv:2203.05297",
    "title": "BEAT: A Large-Scale Semantic and Emotional Multi-Modal Dataset for  Conversational Gestures Synthesis",
    "abstract": "Achieving realistic, vivid, and human-like synthesized conversational\ngestures conditioned on multi-modal data is still an unsolved problem, due to\nthe lack of available datasets, models and standard evaluation metrics. To\naddress this, we build Body-Expression-Audio-Text dataset, BEAT, which has i)\n76 hours, high-quality, multi-modal data captured from 30 speakers talking with\neight different emotions and in four different languages, ii) 32 millions\nframe-level emotion and semantic relevance annotations.Our statistical analysis\non BEAT demonstrates the correlation of conversational gestures with facial\nexpressions, emotions, and semantics, in addition to the known correlation with\naudio, text, and speaker identity. Qualitative and quantitative experiments\ndemonstrate metrics' validness, ground truth data quality, and baseline's\nstate-of-the-art performance. To the best of our knowledge, BEAT is the largest\nmotion capture dataset for investigating the human gestures, which may\ncontribute to a number of different research fields including controllable\ngesture synthesis, cross-modality analysis, emotional gesture recognition. The\ndata, code and model will be released for research.",
    "descriptor": "",
    "authors": [
      "Haiyang Liu",
      "Zihao Zhu",
      "Naoya Iwamoto",
      "Yichen Peng",
      "Zhengqing Li",
      "You Zhou",
      "Elif Bozkurt",
      "Bo Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.05297"
  },
  {
    "id": "arXiv:2203.05300",
    "title": "Connecting Neural Response measurements & Computational Models of  language: a non-comprehensive guide",
    "abstract": "Understanding the neural basis of language comprehension in the brain has\nbeen a long-standing goal of various scientific research programs. Recent\nadvances in language modelling and in neuroimaging methodology promise\npotential improvements in both the investigation of language's neurobiology and\nin the building of better and more human-like language models. This survey\ntraces a line from early research linking Event Related Potentials and\ncomplexity measures derived from simple language models to contemporary studies\nemploying Artificial Neural Network models trained on large corpora in\ncombination with neural response recordings from multiple modalities using\nnaturalistic stimuli.",
    "descriptor": "",
    "authors": [
      "Mostafa Abdou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05300"
  },
  {
    "id": "arXiv:2203.05301",
    "title": "Double Constacyclic Codes over Two Finite Commutative Chain Rings",
    "abstract": "Many kinds of codes which possess two cycle structures over two special\nfinite commutative chain rings, such as ${\\Bbb Z}_2{\\Bbb Z}_4$-additive cyclic\ncodes and quasi-cyclic codes of fractional index etc., were proved\nasymptotically good. In this paper we extend the study in two directions: we\nconsider any two finite commutative chain rings with a surjective homomorphism\nfrom one to the other, and consider double constacyclic structures. We\nconstruct an extensive kind of double constacyclic codes over two finite\ncommutative chain rings. And, developing a probabilistic method suitable for\nquasi-cyclic codes over fields, we prove that the double constacyclic codes\nover two finite commutative chain rings are asymptotically good.",
    "descriptor": "",
    "authors": [
      "Yun Fan",
      "Hualu Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.05301"
  },
  {
    "id": "arXiv:2203.05303",
    "title": "Use of Digital Technologies in Public Health Responses to Tackle  Covid-19: the Bangladesh Perspective",
    "abstract": "This paper aims to study the fight against COVID-19 in Bangladesh and digital\nintervention initiatives. To achieve the purpose of our research, we conducted\na methodical review of online content. We have reviewed the first digital\nintervention that COVID-19 has been used to fight against worldwide. Then we\nreviewed the initiatives that have been taken in Bangladesh. Our paper has\nshown that while Bangladesh can take advantage of the digital intervention\napproach, it will require rigorous collaboration between government\norganizations and universities to get the most out of it. Public health can\nbecome increasingly digital in the future, and we are reviewing international\nalignment requirements. This exploration also focused on the strategies for\ncontrolling, evaluating, and using digital technology to strengthen epidemic\nmanagement and future preparations for COVID-19.",
    "descriptor": "\nComments: 13 pages, 11 figures, 1 table\n",
    "authors": [
      "Samrat Kumar Dey",
      "Khaleda Mehrin",
      "Lubana Akter",
      "Mshura Akter"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.05303"
  },
  {
    "id": "arXiv:2203.05306",
    "title": "GrainSpace: A Large-scale Dataset for Fine-grained and Domain-adaptive  Recognition of Cereal Grains",
    "abstract": "Cereal grains are a vital part of human diets and are important commodities\nfor people's livelihood and international trade. Grain Appearance Inspection\n(GAI) serves as one of the crucial steps for the determination of grain quality\nand grain stratification for proper circulation, storage and food processing,\netc. GAI is routinely performed manually by qualified inspectors with the aid\nof some hand tools. Automated GAI has the benefit of greatly assisting\ninspectors with their jobs but has been limited due to the lack of datasets and\nclear definitions of the tasks.\nIn this paper we formulate GAI as three ubiquitous computer vision tasks:\nfine-grained recognition, domain adaptation and out-of-distribution\nrecognition. We present a large-scale and publicly available cereal grains\ndataset called GrainSpace. Specifically, we construct three types of device\nprototypes for data acquisition, and a total of 5.25 million images determined\nby professional inspectors. The grain samples including wheat, maize and rice\nare collected from five countries and more than 30 regions. We also develop a\ncomprehensive benchmark based on semi-supervised learning and self-supervised\nlearning techniques. To the best of our knowledge, GrainSpace is the first\npublicly released dataset for cereal grain inspection.",
    "descriptor": "\nComments: 8pages, 6 figures, accepted by CVPR2022 dataset is available at \\url{this https URL}\n",
    "authors": [
      "Lei Fan",
      "Yiwen Ding",
      "Dongdong Fan",
      "Donglin Di",
      "Maurice Pagnucco",
      "Yang Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.05306"
  },
  {
    "id": "arXiv:2203.05309",
    "title": "Adaptive Safety for Internet of Things in e-Health",
    "abstract": "Wireless pervasive computing devices are rapidly penetrating our\nenvironments, where e-Health is among the most critical ones. In the e-Health\nenvironment it is not only important to address security and privacy issues\n(which are usually in the focus), but also safety needs for appropriate\ntreatment. With an increasing proportion of pervasive (smart dust) devices\nwhich lack computing power, security, privacy, and safety provisioning in such\nenvironments is a demanding task - not to mention additional requirement about\ntheir adaptive provisioning. However, some twenty years ago an interesting\nresearch branch in computing domain appeared, called trust management. This\nbranch is considered as a very handy alternative to support traditional hard\nsecurity and privacy approaches. It is, therefore, often referred to as soft\nsecurity (privacy) provisioning mechanism. As trust is inherently adaptive and\nas security and safety are much related, this paper presents a new approach\nwhere trust management is deployed in e-Health environments to enable adaptive\nsafety provisioning. This paper also introduces a trustworthiness calculation\nframework that extends trust management methods with a comparative analysis of\ncomputational trust in Internet of Things (IoT).",
    "descriptor": "\nComments: 11 pages, 1 figure, 1 table\n",
    "authors": [
      "Denis Tr\u010dek",
      "Habtamu Abie",
      "\u00c5smund Skomedal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.05309"
  },
  {
    "id": "arXiv:2203.05311",
    "title": "Design-Technology Co-Optimization for NVM-based Neuromorphic Processing  Elements",
    "abstract": "Neuromorphic hardware platforms can significantly lower the energy overhead\nof a machine learning inference task. We present a design-technology tradeoff\nanalysis to implement such inference tasks on the processing elements (PEs) of\na Non- Volatile Memory (NVM)-based neuromorphic hardware. Through detailed\ncircuit-level simulations at scaled process technology nodes, we show the\nnegative impact of technology scaling on the information-processing latency,\nwhich impacts the quality-of-service (QoS) of an embedded ML system. At a finer\ngranularity, the latency inside a PE depends on 1) the delay introduced by\nparasitic components on its current paths, and 2) the varying delay to sense\ndifferent resistance states of its NVM cells. Based on these two observations,\nwe make the following three contributions. First, on the technology front, we\npropose an optimization scheme where the NVM resistance state that takes the\nlongest time to sense is set on current paths having the least delay, and vice\nversa, reducing the average PE latency, which improves the QoS. Second, on the\narchitecture front, we introduce isolation transistors within each PE to\npartition it into regions that can be individually power-gated, reducing both\nlatency and energy. Finally, on the system-software front, we propose a\nmechanism to leverage the proposed technological and architectural enhancements\nwhen implementing a machine-learning inference task on neuromorphic PEs of the\nhardware. Evaluations with a recent neuromorphic hardware architecture show\nthat our proposed design-technology co-optimization approach improves both\nperformance and energy efficiency of machine-learning inference tasks without\nincurring high cost-per-bit.",
    "descriptor": "\nComments: Accepted for publication at ACM TECS\n",
    "authors": [
      "Shihao Song",
      "Adarsha Balaji",
      "Anup Das",
      "Nagarajan Kandasamy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2203.05311"
  },
  {
    "id": "arXiv:2203.05314",
    "title": "SoK: On the Semantic AI Security in Autonomous Driving",
    "abstract": "Autonomous Driving (AD) systems rely on AI components to make safety and\ncorrect driving decisions. Unfortunately, today's AI algorithms are known to be\ngenerally vulnerable to adversarial attacks. However, for such AI\ncomponent-level vulnerabilities to be semantically impactful at the system\nlevel, it needs to address non-trivial semantic gaps both (1) from the\nsystem-level attack input spaces to those at AI component level, and (2) from\nAI component-level attack impacts to those at the system level. In this paper,\nwe define such research space as semantic AI security as opposed to generic AI\nsecurity. Over the past 5 years, increasingly more research works are performed\nto tackle such semantic AI security challenges in AD context, which has started\nto show an exponential growth trend.\nIn this paper, we perform the first systematization of knowledge of such\ngrowing semantic AD AI security research space. In total, we collect and\nanalyze 53 such papers, and systematically taxonomize them based on research\naspects critical for the security field. We summarize 6 most substantial\nscientific gaps observed based on quantitative comparisons both vertically\namong existing AD AI security works and horizontally with security works from\nclosely-related domains. With these, we are able to provide insights and\npotential future directions not only at the design level, but also at the\nresearch goal, methodology, and community levels. To address the most critical\nscientific methodology-level gap, we take the initiative to develop an\nopen-source, uniform, and extensible system-driven evaluation platform, named\nPASS, for the semantic AD AI security research community. We also use our\nimplemented platform prototype to showcase the capabilities and benefits of\nsuch a platform using representative semantic AD AI attacks.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Junjie Shen",
      "Ningfei Wang",
      "Ziwen Wan",
      "Yunpeng Luo",
      "Takami Sato",
      "Zhisheng Hu",
      "Xinyang Zhang",
      "Shengjian Guo",
      "Zhenyu Zhong",
      "Kang Li",
      "Ziming Zhao",
      "Chunming Qiao",
      "Qi Alfred Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.05314"
  },
  {
    "id": "arXiv:2203.05321",
    "title": "StyleBabel: Artistic Style Tagging and Captioning",
    "abstract": "We present StyleBabel, a unique open access dataset of natural language\ncaptions and free-form tags describing the artistic style of over 135K digital\nartworks, collected via a novel participatory method from experts studying at\nspecialist art and design schools. StyleBabel was collected via an iterative\nmethod, inspired by `Grounded Theory': a qualitative approach that enables\nannotation while co-evolving a shared language for fine-grained artistic style\nattribute description. We demonstrate several downstream tasks for StyleBabel,\nadapting the recent ALADIN architecture for fine-grained style similarity, to\ntrain cross-modal embeddings for: 1) free-form tag generation; 2) natural\nlanguage description of artistic style; 3) fine-grained text search of style.\nTo do so, we extend ALADIN with recent advances in Visual Transformer (ViT) and\ncross-modal representation learning, achieving a state of the art accuracy in\nfine-grained style retrieval.",
    "descriptor": "",
    "authors": [
      "Dan Ruta",
      "Andrew Gilbert",
      "Pranav Aggarwal",
      "Naveen Marri",
      "Ajinkya Kale",
      "Jo Briggs",
      "Chris Speed",
      "Hailin Jin",
      "Baldo Faieta",
      "Alex Filipkowski",
      "Zhe Lin",
      "John Collomosse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05321"
  },
  {
    "id": "arXiv:2203.05323",
    "title": "Exploiting the Potential of Datasets: A Data-Centric Approach for Model  Robustness",
    "abstract": "Robustness of deep neural networks (DNNs) to malicious perturbations is a hot\ntopic in trustworthy AI. Existing techniques obtain robust models given fixed\ndatasets, either by modifying model structures, or by optimizing the process of\ninference or training. While significant improvements have been made, the\npossibility of constructing a high-quality dataset for model robustness remain\nunexplored. Follow the campaign of data-centric AI launched by Andrew Ng, we\npropose a novel algorithm for dataset enhancement that works well for many\nexisting DNN models to improve robustness. Transferable adversarial examples\nand 14 kinds of common corruptions are included in our optimized dataset. In\nthe data-centric robust learning competition hosted by Alibaba Group and\nTsinghua University, our algorithm came third out of more than 3000 competitors\nin the first stage while we ranked fourth in the second stage. Our code is\navailable at \\url{https://github.com/hncszyq/tianchi_challenge}.",
    "descriptor": "\nComments: Accepted by the AAAI2022 Workshop on Adversarial Machine Learning and Beyond as a competition paper\n",
    "authors": [
      "Yiqi Zhong",
      "Lei Wu",
      "Xianming Liu",
      "Junjun Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05323"
  },
  {
    "id": "arXiv:2203.05325",
    "title": "AIFB-WebScience at SemEval-2022 Task 12: Relation Extraction First --  Using Relation Extraction to Identify Entities",
    "abstract": "In this paper, we present an end-to-end joint entity and relation extraction\napproach based on transformer-based language models. We apply the model to the\ntask of linking mathematical symbols to their descriptions in LaTeX documents.\nIn contrast to existing approaches, which perform entity and relation\nextraction in sequence, our system incorporates information from relation\nextraction into entity extraction. This means that the system can be trained\neven on data sets where only a subset of all valid entity spans is annotated.\nWe provide an extensive evaluation of the proposed system and its strengths and\nweaknesses. Our approach, which can be scaled dynamically in computational\ncomplexity at inference time, produces predictions with high precision and\nreaches 3rd place in the leaderboard of SemEval-2022 Task 12. For inputs in the\ndomain of physics and math, it achieves high relation extraction macro f1\nscores of 95.43% and 79.17%, respectively. The code used for training and\nevaluating our models is available at: https://github.com/nicpopovic/RE1st",
    "descriptor": "\nComments: SemEval-2022 workshop paper. 5 content pages, 2 figures, 3 tables\n",
    "authors": [
      "Nicholas Popovic",
      "Walter Laurito",
      "Michael F\u00e4rber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05325"
  },
  {
    "id": "arXiv:2203.05328",
    "title": "Backbone is All Your Need: A Simplified Architecture for Visual Object  Tracking",
    "abstract": "Exploiting a general-purpose neural architecture to replace hand-wired\ndesigns or inductive biases has recently drawn extensive interest. However,\nexisting tracking approaches rely on customized sub-modules and need prior\nknowledge for architecture selection, hindering the tracking development in a\nmore general system. This paper presents a Simplified Tracking architecture\n(SimTrack) by leveraging a transformer backbone for joint feature extraction\nand interaction. Unlike existing Siamese trackers, we serialize the input\nimages and concatenate them directly before the one-branch backbone. Feature\ninteraction in the backbone helps to remove well-designed interaction modules\nand produce a more efficient and effective framework. To reduce the information\nloss from down-sampling in vision transformers, we further propose a foveal\nwindow strategy, providing more diverse input patches with acceptable\ncomputational costs. Our SimTrack improves the baseline with 2.5%/2.6% AUC\ngains on LaSOT/TNL2K and gets results competitive with other specialized\ntracking algorithms without bells and whistles.",
    "descriptor": "",
    "authors": [
      "Boyu Chen",
      "Peixia Li",
      "Lei Bai",
      "Lei Qiao",
      "Qiuhong Shen",
      "Bo Li",
      "Weihao Gan",
      "Wei Wu",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05328"
  },
  {
    "id": "arXiv:2203.05332",
    "title": "SelfTune: Metrically Scaled Monocular Depth Estimation through  Self-Supervised Learning",
    "abstract": "Monocular depth estimation in the wild inherently predicts depth up to an\nunknown scale. To resolve scale ambiguity issue, we present a learning\nalgorithm that leverages monocular simultaneous localization and mapping (SLAM)\nwith proprioceptive sensors. Such monocular SLAM systems can provide metrically\nscaled camera poses. Given these metric poses and monocular sequences, we\npropose a self-supervised learning method for the pre-trained supervised\nmonocular depth networks to enable metrically scaled depth estimation. Our\napproach is based on a teacher-student formulation which guides our network to\npredict high-quality depths. We demonstrate that our approach is useful for\nvarious applications such as mobile robot navigation and is applicable to\ndiverse environments. Our full system shows improvements over recent\nself-supervised depth estimation and completion methods on EuRoC, OpenLORIS,\nand ScanNet datasets.",
    "descriptor": "",
    "authors": [
      "Jaehoon Choi",
      "Dongki Jung",
      "Yonghan Lee",
      "Deokhwa Kim",
      "Dinesh Manocha",
      "Donghwan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05332"
  },
  {
    "id": "arXiv:2203.05333",
    "title": "EACELEB: An East Asian Language Speaking Celebrity Dataset for Speaker  Recognition",
    "abstract": "Large datasets are very useful for training speaker recognition systems, and\nvarious research groups have constructed several over the years. Voxceleb is a\nlarge dataset for speaker recognition that is extracted from Youtube videos.\nThis paper presents an audio-visual method for acquiring audio data from\nYoutube given the speaker's name as input. The system follows a pipeline\nsimilar to that of the Voxceleb data acquisition method. However, our work\nfocuses on fast data acquisition by using face-tracking in subsequent frames\nonce a face has been detected -- this is preferable over face detection for\nevery frame considering its computational cost. We show that applying audio\ndiarization to our data after acquiring it can yield equal error rates\ncomparable to Voxceleb. A secondary set of experiments showed that we could\nfurther decrease the error rate by fine-tuning a pre-trained x-vector system\nwith the acquired data. Like Voxceleb, the work here focuses primarily on\ndeveloping audio for celebrities. However, unlike Voxceleb, our target audio\ndata is from celebrities in East Asian countries. Finally, we set up a speaker\nverification task to evaluate the accuracy of our acquired data. After\ndiarization and fine-tuning, we achieved an equal error rate of approximately\n4\\% across our entire dataset.",
    "descriptor": "",
    "authors": [
      "Desmond Caulley",
      "Yufeng Yang",
      "David Anderson"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.05333"
  },
  {
    "id": "arXiv:2203.05334",
    "title": "Iterative Corresponding Geometry: Fusing Region and Depth for Highly  Efficient 3D Tracking of Textureless Objects",
    "abstract": "Tracking objects in 3D space and predicting their 6DoF pose is an essential\ntask in computer vision. State-of-the-art approaches often rely on object\ntexture to tackle this problem. However, while they achieve impressive results,\nmany objects do not contain sufficient texture, violating the main underlying\nassumption. In the following, we thus propose ICG, a novel probabilistic\ntracker that fuses region and depth information and only requires the object\ngeometry. Our method deploys correspondence lines and points to iteratively\nrefine the pose. We also implement robust occlusion handling to improve\nperformance in real-world settings. Experiments on the YCB-Video, OPT, and Choi\ndatasets demonstrate that, even for textured objects, our approach outperforms\nthe current state of the art with respect to accuracy and robustness. At the\nsame time, ICG shows fast convergence and outstanding efficiency, requiring\nonly 1.3 ms per frame on a single CPU core. Finally, we analyze the influence\nof individual components and discuss our performance compared to deep\nlearning-based methods. The source code of our tracker is publicly available.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Manuel Stoiber",
      "Martin Sundermeyer",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05334"
  },
  {
    "id": "arXiv:2203.05335",
    "title": "Non-generative Generalized Zero-shot Learning via Task-correlated  Disentanglement and Controllable Samples Synthesis",
    "abstract": "Synthesizing pseudo samples is currently the most effective way to solve the\nGeneralized Zero Shot Learning (GZSL) problem. Most models achieve competitive\nperformance but still suffer from two problems: (1) feature confounding, that\ntask-correlated and task-independent features are confounded in overall\nrepresentations, which is unreasonable to synthesize reliable pseudo samples;\nand (2) distribution uncertainty, that massive data is needed when existing\nmodels synthesize samples from the uncertain distribution, which causes poor\nperformance in limited samples of seen classes. In this paper, we propose a\nnon-generative model to address these problems correspondingly in two modules:\n(1) Task-correlated feature disentanglement, to exclude the task-correlated\nfeatures from task-independent ones by adversarial learning of domain adaption\ntowards reasonable synthesis; and (2) Controllable pseudo sample synthesis, to\nsynthesize edge-pseudo and center-pseudo samples with certain characteristics\ntowards more diversity generated and intuitive transfer. To describe the new\nscene that is the limit seen class samples in the training process, we further\nformulate a new ZSL task named the 'Few-shot Seen class and Zero-shot Unseen\nclass learning' (FSZU). Extensive experiments on four benchmarks verify that\nthe proposed method is competitive in the GZSL and the FSZU tasks.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Yaogong Feng",
      "Xiaowen Huang",
      "Pengbo Yang",
      "Jian Yu",
      "Jitao Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05335"
  },
  {
    "id": "arXiv:2203.05337",
    "title": "Parsimonious Random Projection Neural Networks for the Numerical  Solution of Initial-Value Problems of ODEs and index-1 DAEs",
    "abstract": "We address a physics-informed neural network based on the concept of random\nprojections for the numerical solution of IVPs of nonlinear ODEs in\nlinear-implicit form and index-1 DAEs, which may also arise from the spatial\ndiscretization of PDEs. The scheme has a single hidden layer with appropriately\nrandomly parametrized Gaussian kernels and a linear output layer, while the\ninternal weights are fixed to ones. The unknown weights between the hidden and\noutput layer are computed by Newton's iterations, using the Moore-Penrose\npseudoinverse for low to medium, and sparse QR decomposition with\nregularization for medium to large scale systems. To deal with stiffness and\nsharp gradients, we propose a variable step size scheme for adjusting the\ninterval of integration and address a continuation method for providing good\ninitial guesses for the Newton iterations. Based on previous works on random\nprojections, we prove the approximation capability of the scheme for ODEs in\nthe canonical form and index-1 DAEs in the semiexplicit form. The optimal\nbounds of the uniform distribution are parsimoniously chosen based on the\nbias-variance trade-off. The performance of the scheme is assessed through\nseven benchmark problems: four index-1 DAEs, the Robertson model, a model of\nfive DAEs describing the motion of a bead, a model of six DAEs describing a\npower discharge control problem, the chemical Akzo Nobel problem and three\nstiff problems, the Belousov-Zhabotinsky, the Allen-Cahn PDE and the\nKuramoto-Sivashinsky PDE. The efficiency of the scheme is compared with three\nsolvers ode23t, ode23s, ode15s of the MATLAB ODE suite. Our results show that\nthe proposed scheme outperforms the stiff solvers in several cases, especially\nin regimes where high stiffness or sharp gradients arise in terms of numerical\naccuracy, while the computational costs are for any practical purposes\ncomparable.",
    "descriptor": "",
    "authors": [
      "Gianluca Fabiani",
      "Evangelos Galaris",
      "Lucia Russo",
      "Constantinos Siettos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.05337"
  },
  {
    "id": "arXiv:2203.05338",
    "title": "TrueType Transformer: Character and Font Style Recognition in Outline  Format",
    "abstract": "We propose TrueType Transformer (T3), which can perform character and font\nstyle recognition in an outline format. The outline format, such as TrueType,\nrepresents each character as a sequence of control points of stroke contours\nand is frequently used in born-digital documents. T3 is organized by a deep\nneural network, so-called Transformer. Transformer is originally proposed for\nsequential data, such as text, and therefore appropriate for handling the\noutline data. In other words, T3 directly accepts the outline data without\nconverting it into a bitmap image. Consequently, T3 realizes a\nresolution-independent classification. Moreover, since the locations of the\ncontrol points represent the fine and local structures of the font style, T3 is\nsuitable for font style classification, where such structures are very\nimportant. In this paper, we experimentally show the applicability of T3 in\ncharacter and font style recognition tasks, while observing how the individual\ncontrol points contribute to classification results.",
    "descriptor": "\nComments: DAS 2022\n",
    "authors": [
      "Yusuke Nagata",
      "Jinki Otao",
      "Daichi Haraguchi",
      "Seiichi Uchida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05338"
  },
  {
    "id": "arXiv:2203.05340",
    "title": "Domain Generalization via Shuffled Style Assembly for Face Anti-Spoofing",
    "abstract": "With diverse presentation attacks emerging continually, generalizable face\nanti-spoofing (FAS) has drawn growing attention. Most existing methods\nimplement domain generalization (DG) on the complete representations. However,\ndifferent image statistics may have unique properties for the FAS tasks. In\nthis work, we separate the complete representation into content and style ones.\nA novel Shuffled Style Assembly Network (SSAN) is proposed to extract and\nreassemble different content and style features for a stylized feature space.\nThen, to obtain a generalized representation, a contrastive learning strategy\nis developed to emphasize liveness-related style information while suppress the\ndomain-specific one. Finally, the representations of the correct assemblies are\nused to distinguish between living and spoofing during the inferring. On the\nother hand, despite the decent performance, there still exists a gap between\nacademia and industry, due to the difference in data quantity and distribution.\nThus, a new large-scale benchmark for FAS is built up to further evaluate the\nperformance of algorithms in reality. Both qualitative and quantitative results\non existing and proposed benchmarks demonstrate the effectiveness of our\nmethods. The codes will be available at https://github.com/wangzhuo2019/SSAN.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Zhuo Wang",
      "Zezheng Wang",
      "Zitong Yu",
      "Weihong Deng",
      "Jiahong Li",
      "Size Li",
      "Zhongyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05340"
  },
  {
    "id": "arXiv:2203.05344",
    "title": "EyeLoveGAN: Exploiting domain-shifts to boost network learning with  cycleGANs",
    "abstract": "This paper presents our contribution to the REFUGE challenge 2020. The\nchallenge consisted of three tasks based on a dataset of retinal images:\nSegmentation of optic disc and cup, classification of glaucoma, and\nlocalization of fovea. We propose employing convolutional neural networks for\nall three tasks. Segmentation is performed using a U-Net, classification is\nperformed by a pre-trained InceptionV3 network, and fovea detection is\nperformed by employing stacked hour-glass for heatmap prediction. The challenge\ndataset contains images from three different data sources. To enhance\nperformance, cycleGANs were utilized to create a domain-shift between the data\nsources. These cycleGANs move images across domains, thus creating artificial\nimages which can be used for training.",
    "descriptor": "",
    "authors": [
      "Josefine Vilsb\u00f8ll Sundgaard",
      "Kristine Aavild Juhl",
      "Jakob M\u00f8lkj\u00e6r Slipsager"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05344"
  },
  {
    "id": "arXiv:2203.05346",
    "title": "Knowledge-enriched Attention Network with Group-wise Semantic for Visual  Storytelling",
    "abstract": "As a technically challenging topic, visual storytelling aims at generating an\nimaginary and coherent story with narrative multi-sentences from a group of\nrelevant images. Existing methods often generate direct and rigid descriptions\nof apparent image-based contents, because they are not capable of exploring\nimplicit information beyond images. Hence, these schemes could not capture\nconsistent dependencies from holistic representation, impairing the generation\nof reasonable and fluent story. To address these problems, a novel\nknowledge-enriched attention network with group-wise semantic model is\nproposed. Three main novel components are designed and supported by substantial\nexperiments to reveal practical advantages. First, a knowledge-enriched\nattention network is designed to extract implicit concepts from external\nknowledge system, and these concepts are followed by a cascade cross-modal\nattention mechanism to characterize imaginative and concrete representations.\nSecond, a group-wise semantic module with second-order pooling is developed to\nexplore the globally consistent guidance. Third, a unified one-stage story\ngeneration model with encoder-decoder structure is proposed to simultaneously\ntrain and infer the knowledge-enriched attention network, group-wise semantic\nmodule and multi-modal story generation decoder in an end-to-end fashion.\nSubstantial experiments on the popular Visual Storytelling dataset with both\nobjective and subjective evaluation metrics demonstrate the superior\nperformance of the proposed scheme as compared with other state-of-the-art\nmethods.",
    "descriptor": "",
    "authors": [
      "Tengpeng Li",
      "Hanli Wang",
      "Bin He",
      "Chang Wen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05346"
  },
  {
    "id": "arXiv:2203.05349",
    "title": "Two-stream Hierarchical Similarity Reasoning for Image-text Matching",
    "abstract": "Reasoning-based approaches have demonstrated their powerful ability for the\ntask of image-text matching. In this work, two issues are addressed for\nimage-text matching. First, for reasoning processing, conventional approaches\nhave no ability to find and use multi-level hierarchical similarity\ninformation. To solve this problem, a hierarchical similarity reasoning module\nis proposed to automatically extract context information, which is then\nco-exploited with local interaction information for efficient reasoning.\nSecond, previous approaches only consider learning single-stream similarity\nalignment (i.e., image-to-text level or text-to-image level), which is\ninadequate to fully use similarity information for image-text matching. To\naddress this issue, a two-stream architecture is developed to decompose\nimage-text matching into image-to-text level and text-to-image level similarity\ncomputation. These two issues are investigated by a unifying framework that is\ntrained in an end-to-end manner, namely two-stream hierarchical similarity\nreasoning network. The extensive experiments performed on the two benchmark\ndatasets of MSCOCO and Flickr30K show the superiority of the proposed approach\nas compared to existing state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Ran Chen",
      "Hanli Wang",
      "Lei Wang",
      "Sam Kwong"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05349"
  },
  {
    "id": "arXiv:2203.05351",
    "title": "Multi-index Sequential Monte Carlo ratio estimators for Bayesian Inverse  problems",
    "abstract": "We consider the problem of estimating expectations with respect to a target\ndistribution with an unknown normalizing constant, and where even the\nunnormalized target needs to be approximated at finite resolution. This setting\nis ubiquitous across science and engineering applications, for example in the\ncontext of Bayesian inference where a physics-based model governed by an\nintractable partial differential equation (PDE) appears in the likelihood. A\nmulti-index Sequential Monte Carlo (MISMC) method is used to construct ratio\nestimators which provably enjoy the complexity improvements of multi-index\nMonte Carlo (MIMC) as well as the efficiency of Sequential Monte Carlo (SMC)\nfor inference. In particular, the proposed method provably achieves the\ncanonical complexity of MSE$^{-1}$, while single level methods require\nMSE$^{-\\xi}$ for $\\xi>1$. This is illustrated on examples of Bayesian inverse\nproblems with an elliptic PDE forward model in $1$ and $2$ spatial dimensions,\nwhere $\\xi=5/4$ and $\\xi=3/2$, respectively. It is also illustrated on a more\nchallenging log Gaussian process models, where single level complexity is\napproximately $\\xi=9/4$ and multilevel Monte Carlo (or MIMC with an\ninappropriate index set) gives $\\xi = 5/4 + \\omega$, for any $\\omega > 0$,\nwhereas our method is again canonical.",
    "descriptor": "",
    "authors": [
      "Kody J. H. Law",
      "Neil Walton",
      "Shangda Yang",
      "Ajay Jasra"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.05351"
  },
  {
    "id": "arXiv:2203.05352",
    "title": "Temporal Context for Robust Maritime Obstacle Detection",
    "abstract": "Robust maritime obstacle detection is essential for fully autonomous unmanned\nsurface vehicles (USVs). The currently widely adopted segmentation-based\nobstacle detection methods are prone to misclassification of object reflections\nand sun glitter as obstacles, producing many false positive detections,\neffectively rendering the methods impractical for USV navigation. However,\nwater-turbulence-induced temporal appearance changes on object reflections are\nvery distinctive from the appearance dynamics of true objects. We harness this\nproperty to design WaSR-T, a novel maritime obstacle detection network, that\nextracts the temporal context from a sequence of recent frames to reduce\nambiguity. By learning the local temporal characteristics of object reflection\non the water surface, WaSR-T substantially improves obstacle detection accuracy\nin the presence of reflections and glitter. Compared with existing single-frame\nmethods, WaSR-T reduces the number of false positive detections by 41% overall\nand by over 53% within the danger zone of the boat, while preserving a high\nrecall, and achieving new state-of-the-art performance on the challenging MODS\nmaritime obstacle detection benchmark.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Lojze \u017dust",
      "Matej Kristan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05352"
  },
  {
    "id": "arXiv:2203.05354",
    "title": "Machine Learning-based Beamforming Design for Millimeter Wave IRS  Communications with Discrete Phase Shifters",
    "abstract": "In this paper, we investigate an intelligent reflecting surface\n(IRS)-assisted millimeter-wave multiple-input single-output downlink wireless\ncommunication system. By jointly calculating the active beamforming at the base\nstation and the passive beamforming at the IRS, we aim to minimize the transmit\npower under the constraint of each user' signal-to-interference-plus-noise\nratio. To solve this problem, we propose a low-complexity machine\nlearning-based cross-entropy (CE) algorithm to alternately optimize the active\nbeamforming and the passive beamforming. Specifically, in the alternative\niteration process, the zero-forcing (ZF) method and CE algorithm are applied to\nacquire the active beamforming and the passive beamforming, respectively. The\nCE algorithm starts with random sampling, by the idea of distribution focusing,\nnamely shifting the distribution towards a desired one by minimizing CE, and a\nnear optimal reflection coefficients with adequately high probability can be\nobtained. In addition, we extend the original one-bit phase shift at the IRS to\nthe common case with high-resolution phase shift to enhance the effectiveness\nof the algorithms. Simulation results verify that the proposed algorithm can\nobtain a near optimal solution with lower computational complexity.",
    "descriptor": "",
    "authors": [
      "Wencai Yan",
      "Gangcan Sun",
      "Wanming Hao",
      "Zhengyu Zhu",
      "Zheng Chu",
      "Pei Xiao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.05354"
  },
  {
    "id": "arXiv:2203.05355",
    "title": "SATLab at SemEval-2022 Task 4: Trying to Detect Patronizing and  Condescending Language with only Character and Word N-grams",
    "abstract": "A logistic regression model only fed with character and word n-grams is\nproposed for the SemEval-2022 Task 4 on Patronizing and Condescending Language\nDetection (PCL). It obtained an average level of performance, well above the\nperformance of a system that tries to guess without using any knowledge about\nthe task, but much lower than the best teams. As the proposed model is very\nsimilar to the one that performed well on a task requiring to automatically\nidentify hate speech and offensive content, this paper confirms the difficulty\nof PCL detection.",
    "descriptor": "\nComments: Submitted to SemEval-2022\n",
    "authors": [
      "Yves Bestgen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05355"
  },
  {
    "id": "arXiv:2203.05360",
    "title": "Deep Residual Reinforcement Learning based Autonomous Blimp Control",
    "abstract": "Blimps are well suited to perform long-duration aerial tasks as they are\nenergy efficient, relatively silent and safe. To address the blimp navigation\nand control task, in previous work we developed a hardware and\nsoftware-in-the-loop framework and a PID-based controller for large blimps in\nthe presence of wind disturbance. However, blimps have a deformable structure\nand their dynamics are inherently non-linear and time-delayed, making PID\ncontrollers difficult to tune. Thus, often resulting in large tracking errors.\nMoreover, the buoyancy of a blimp is constantly changing due to variations in\nambient temperature and pressure. To address these issues, in this paper we\npresent a learning-based framework based on deep residual reinforcement\nlearning (DRRL), for the blimp control task. Within this framework, we first\nemploy a PID controller to provide baseline performance. Subsequently, the DRRL\nagent learns to modify the PID decisions by interaction with the environment.\nWe demonstrate in simulation that DRRL agent consistently improves the PID\nperformance. Through rigorous simulation experiments, we show that the agent is\nrobust to changes in wind speed and buoyancy. In real-world experiments, we\ndemonstrate that the agent, trained only in simulation, is sufficiently robust\nto control an actual blimp in windy conditions. We openly provide the source\ncode of our approach at https://github.com/\nrobot-perception-group/AutonomousBlimpDRL.",
    "descriptor": "",
    "authors": [
      "Yu Tang Liu",
      "Eric Price",
      "Michael J. Black",
      "Aamir Ahmad"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05360"
  },
  {
    "id": "arXiv:2203.05362",
    "title": "Efficient Runtime Profiling for Black-box Machine Learning Services on  Sensor Streams",
    "abstract": "In highly distributed environments such as cloud, edge and fog computing, the\napplication of machine learning for automating and optimizing processes is on\nthe rise. Machine learning jobs are frequently applied in streaming conditions,\nwhere models are used to analyze data streams originating from e.g. video\nstreams or sensory data. Often the results for particular data samples need to\nbe provided in time before the arrival of next data. Thus, enough resources\nmust be provided to ensure the just-in-time processing for the specific data\nstream. This paper focuses on proposing a runtime modeling strategy for\ncontainerized machine learning jobs, which enables the optimization and\nadaptive adjustment of resources per job and component. Our black-box approach\nassembles multiple techniques into an efficient runtime profiling method, while\nmaking no assumptions about underlying hardware, data streams, or applied\nmachine learning jobs. The results show that our method is able to capture the\ngeneral runtime behaviour of different machine learning jobs already after a\nshort profiling phase.",
    "descriptor": "\nComments: Accepted as a short paper at the 6th IEEE International Conference on Fog and Edge Computing 2022\n",
    "authors": [
      "Soeren Becker",
      "Dominik Scheinert",
      "Florian Schmidt",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.05362"
  },
  {
    "id": "arXiv:2203.05364",
    "title": "Parameterized Algorithms for Upward Planarity",
    "abstract": "We obtain new parameterized algorithms for the classical problem of\ndetermining whether a directed acyclic graph admits an upward planar drawing.\nOur results include a new fixed-parameter algorithm parameterized by the number\nof sources, an XP-algorithm parameterized by treewidth, and a fixed-parameter\nalgorithm parameterized by treedepth. All three algorithms are obtained using a\nnovel framework for the problem that combines SPQR tree-decompositions with\nparameterized techniques. Our approach unifies and pushes beyond previous\ntractability results for the problem on series-parallel digraphs, single-source\ndigraphs and outerplanar digraphs.",
    "descriptor": "\nComments: To appear at the 38th International Symposium on Computational Geometry (SoCG 2022)\n",
    "authors": [
      "Steven Chaplick",
      "Emilio Di Giacomo",
      "Fabrizio Frati",
      "Robert Ganian",
      "Chrysanthi N. Raftopoulou",
      "Kirill Simonov"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.05364"
  },
  {
    "id": "arXiv:2203.05367",
    "title": "TIDF-DLPM: Term and Inverse Document Frequency based Data Leakage  Prevention Model",
    "abstract": "Confidentiality of the data is being endangered as it has been categorized\ninto false categories which might get leaked to an unauthorized party. For this\nreason, various organizations are mainly implementing data leakage prevention\nsystems (DLPs). Firewalls and intrusion detection systems are being outdated\nversions of security mechanisms. The data which are being used, in sending\nstate or are rest are being monitored by DLPs. The confidential data is\nprevented with the help of neighboring contexts and contents of DLPs. In this\npaper, a semantic-based approach is used to classify data based on the\nstatistical data leakage prevention model. To detect involved private data,\nstatistical analysis is being used to contribute secure mechanisms in the\nenvironment of data leakage. The favored Frequency-Inverse Document Frequency\n(TF-IDF) is the facts and details recapture function to arrange documents under\nparticular topics. The results showcase that a similar statistical DLP approach\ncould appropriately classify documents in case of extent alteration as well as\ninterchanged documents.",
    "descriptor": "",
    "authors": [
      "Ishu Gupta",
      "Sloni Mittal",
      "Ankit Tiwari",
      "Priya Agarwal",
      "Ashutosh Kumar Singh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.05367"
  },
  {
    "id": "arXiv:2203.05368",
    "title": "Temporal Network Epistemology: on Reaching Consensus in Real World  Setting",
    "abstract": "This work develops the concept of temporal network epistemology model\nenabling the simulation of the learning process in dynamic networks. The\nresults of the research, conducted on the temporal social network generated\nusing the CogSNet model and on the static topologies as a reference, indicate a\nsignificant influence of the network temporal dynamics on the outcome and flow\nof the learning process. It has been shown that not only the dynamics of\nreaching consensus is different compared to baseline models but also that\npreviously unobserved phenomena appear, such as uninformed agents or different\nconsensus states for disconnected components. It has been also observed that\nsometimes only the change of the network structure can contribute to reaching\nconsensus. The introduced approach and the experimental results can be used to\nbetter understand the way how human communities collectively solve both complex\nproblems at the scientific level and to inquire into the correctness of less\ncomplex but common and equally important beliefs' spreading across entire\nsocieties.",
    "descriptor": "",
    "authors": [
      "Rados\u0142aw Michalski",
      "Damian Serwata",
      "Mateusz Nurek",
      "Boleslaw K. Szymanski",
      "Przemys\u0142aw Kazienko",
      "Tao Jia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.05368"
  },
  {
    "id": "arXiv:2203.05369",
    "title": "A Contribution-based Device Selection Scheme in Federated Learning",
    "abstract": "In a Federated Learning (FL) setup, a number of devices contribute to the\ntraining of a common model. We present a method for selecting the devices that\nprovide updates in order to achieve improved generalization, fast convergence,\nand better device-level performance. We formulate a min-max optimization\nproblem and decompose it into a primal-dual setup, where the duality gap is\nused to quantify the device-level performance. Our strategy combines\n\\emph{exploration} of data freshness through a random device selection with\n\\emph{exploitation} through simplified estimates of device contributions. This\nimproves the performance of the trained model both in terms of generalization\nand personalization. A modified Truncated Monte-Carlo (TMC) method is applied\nduring the exploitation phase to estimate the device's contribution and lower\nthe communication overhead. The experimental results show that the proposed\napproach has a competitive performance, with lower communication overhead and\ncompetitive personalization performance against the baseline schemes.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Shashi Raj Pandey",
      "Lam D. Nguyen",
      "Petar Popovski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.05369"
  },
  {
    "id": "arXiv:2203.05377",
    "title": "Scalable Security Investment Methods for Voltage Stability of Power  Systems",
    "abstract": "We develop investment approaches to secure electric power systems against\nload attacks that may cause voltage instability. The attacker attempts to alter\nthe reactive power setpoints of the loads covertly and intelligently to reduce\nthe voltage stability margin of the grid. The defender, or the system operator,\naims to compensate for this reduction by retuning the reactive power dispatch\nof control devices such as shunt capacitor banks. The question is: how much\nfinancial investment should the attacker and the defender plan for to succeed\nin their respective objectives? To address this question, we formulate a\ncost-based Stackelberg game, where the defender is aware of the attacker's\nbudget, and a robust-defense sequential algorithm for the realistic case when\nthe defender is not fully informed about the attacker's resources. We\ndemonstrate that these methods operate reliably under time-varying load\nuncertainties. To provide scalability to large-scale power system models, we\ndevelop a genetic algorithm where both players evolve their candidate solutions\nin opposite directions simultaneously. Finally, the proposed methods are\nvalidated using IEEE prototype models, demonstrating that reliable and robust\ndefense is feasible unless the defender's resources are severely limited\nrelative to the attacker's resources.",
    "descriptor": "\nComments: 8 pages, 8 figures, submitted to IEEE transaction on Power Systems for peer review\n",
    "authors": [
      "Lu An",
      "Pratishtha Shukla",
      "Aranya Chakrabortty",
      "Alexandra Duel-Hallen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.05377"
  },
  {
    "id": "arXiv:2203.05378",
    "title": "Forecasting the abnormal events at well drilling with machine learning",
    "abstract": "We present a data-driven and physics-informed algorithm for drilling accident\nforecasting. The core machine-learning algorithm uses the data from the\ndrilling telemetry representing the time-series. We have developed a\nBag-of-features representation of the time series that enables the algorithm to\npredict the probabilities of six types of drilling accidents in real-time. The\nmachine-learning model is trained on the 125 past drilling accidents from 100\ndifferent Russian oil and gas wells. Validation shows that the model can\nforecast 70% of drilling accidents with a false positive rate equals to 40%.\nThe model addresses partial prevention of the drilling accidents at the well\nconstruction.",
    "descriptor": "\nComments: Appl Intell (2022)\n",
    "authors": [
      "Ekaterina Gurina",
      "Nikita Klyuchnikov",
      "Ksenia Antipova",
      "Dmitry Koroteev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05378"
  },
  {
    "id": "arXiv:2203.05380",
    "title": "Spatial Commonsense Graph for Object Localisation in Partial Scenes",
    "abstract": "We solve object localisation in partial scenes, a new problem of estimating\nthe unknown position of an object (e.g. where is the bag?) given a partial 3D\nscan of a scene. The proposed solution is based on a novel scene graph model,\nthe Spatial Commonsense Graph (SCG), where objects are the nodes and edges\ndefine pairwise distances between them, enriched by concept nodes and\nrelationships from a commonsense knowledge base. This allows SCG to better\ngeneralise its spatial inference over unknown 3D scenes. The SCG is used to\nestimate the unknown position of the target object in two steps: first, we feed\nthe SCG into a novel Proximity Prediction Network, a graph neural network that\nuses attention to perform distance prediction between the node representing the\ntarget object and the nodes representing the observed objects in the SCG;\nsecond, we propose a Localisation Module based on circular intersection to\nestimate the object position using all the predicted pairwise distances in\norder to be independent of any reference system. We create a new dataset of\npartially reconstructed scenes to benchmark our method and baselines for object\nlocalisation in partial scenes, where our proposed method achieves the best\nlocalisation performance.",
    "descriptor": "\nComments: Accepted to CVPR 2022, project website: this http URL\n",
    "authors": [
      "Francesco Giuliari",
      "Geri Skenderi",
      "Marco Cristani",
      "Yiming Wang",
      "Alessio Del Bue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05380"
  },
  {
    "id": "arXiv:2203.05386",
    "title": "Faking Fake News for Real Fake News Detection: Propaganda-loaded  Training Data Generation",
    "abstract": "While there has been a lot of research and many recent advances in neural\nfake news detection, defending against human-written disinformation remains\nunderexplored. Upon analyzing current approaches for fake news generation and\nhuman-crafted articles, we found that there is a gap between them, which can\nexplain the poor performance on detecting human-written fake news for detectors\ntrained on automatically generated data. To address this issue, we propose a\nnovel framework for generating articles closer to human-written ones.\nSpecifically, we perform self-critical sequence training with natural language\ninference to ensure the validity of the generated articles. We then explicitly\nincorporate propaganda techniques into the generated articles to mimic how\nhumans craft fake news. Eventually, we create a fake news detection training\ndataset, PropaNews, which includes 2,256 examples. Our experimental results\nshow that detectors trained on PropaNews are 7.3% to 12.0% more accurate for\ndetecting human-written disinformation than for counterparts trained on data\ngenerated by state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Kung-Hsiang Huang",
      "Kathleen McKeown",
      "Preslav Nakov",
      "Yejin Choi",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05386"
  },
  {
    "id": "arXiv:2203.05389",
    "title": "Flexible Behavior Trees: In search of the mythical HFSMBTH for  Collaborative Autonomy in Robotics",
    "abstract": "In recent years, the model of computation known as Behavior Trees (BT), first\ndeveloped in the video game industry, has become more popular in the robotics\ncommunity for defining discrete behavior switching. BTs are threatening to\nsupplant the venerable Hierarchical Finite State Machine (HFSM) model. In this\npaper we contrast BT and HFSM, pointing out some potential issues with the BT\nform, and advocate for a hybrid model of computation that uses both BT and HFSM\nin ways that leverage their individual strengths. The work introduces a new\nopen-source package for ROS 2 that extends the Flexible Behavior Engine\n(FlexBE) to enable interaction with BT-based behaviors within a HFSM in a way\nthat supports collaborative autonomy. Simulation and hardware demonstrations\nillustrate the concepts.",
    "descriptor": "\nComments: Submitted to IROS 22, 7 figures\n",
    "authors": [
      "Joshua M. Zutell",
      "David C. Conner",
      "Philipp Schillinger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.05389"
  },
  {
    "id": "arXiv:2203.05390",
    "title": "Sequence-of-Constraints MPC: Reactive Timing-Optimal Control of  Sequential Manipulation",
    "abstract": "Task and Motion Planning has made great progress in solving hard sequential\nmanipulation problems. However, a gap between such planning formulations and\ncontrol methods for reactive execution remains. In this paper we propose a\nmodel predictive control approach dedicated to robustly execute a single\nsequence of constraints, which corresponds to a discrete decision sequence of a\nTAMP plan. We decompose the overall control problem into three sub-problems\n(solving for sequential waypoints, their timing, and a short receding horizon\npath) that each is a non-linear program solved online in each MPC cycle. The\nresulting control strategy can account for long-term interdependencies of\nconstraints and reactively plan for a timing-optimal transition through all\nconstraints. We additionally propose phase backtracking when running\nconstraints are missed, leading to a fluent re-initiation behavior that is\nrobust to perturbations and interferences by an experimenter.",
    "descriptor": "",
    "authors": [
      "Marc Toussaint",
      "Jason Harris",
      "Jung-Su Ha",
      "Danny Driess",
      "Wolfgang H\u00f6nig"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.05390"
  },
  {
    "id": "arXiv:2203.05395",
    "title": "Annotation Efficient Person Re-Identification with Diverse Cluster-Based  Pair Selection",
    "abstract": "Person Re-identification (Re-ID) has attracted great attention due to its\npromising real-world applications. However, in practice, it is always costly to\nannotate the training data to train a Re-ID model, and it still remains\nchallenging to reduce the annotation cost while maintaining the performance for\nthe Re-ID task. To solve this problem, we propose the Annotation Efficient\nPerson Re-Identification method to select image pairs from an alternative pair\nset according to the fallibility and diversity of pairs, and train the Re-ID\nmodel based on the annotation. Specifically, we design an annotation and\ntraining framework to firstly reduce the size of the alternative pair set by\nclustering all images considering the locality of features, secondly select\nimages pairs from intra-/inter-cluster samples for human to annotate, thirdly\nre-assign clusters according to the annotation, and finally train the model\nwith the re-assigned clusters. During the pair selection, we seek for valuable\npairs according to pairs' fallibility and diversity, which includes an\nintra-cluster criterion to construct image pairs with the most chaotic samples\nand the representative samples within clusters, an inter-cluster criterion to\nconstruct image pairs between clusters based on the second-order Wasserstein\ndistance, and a diversity criterion for clusterbased pair selection. Combining\nall criteria above, a greedy strategy is developed to solve the pair selection\nproblem. Finally, the above\nclustering-selecting-annotating-reassigning-training procedure will be repeated\nuntil the annotation budget is reached. Extensive experiments on three widely\nadopted Re-ID datasets show that we can greatly reduce the annotation cost\nwhile achieving better performance compared with state-of-the-art works.",
    "descriptor": "\nComments: submitted to ICME2022\n",
    "authors": [
      "Lantian Xue",
      "Yixiong Zou",
      "Peixi Peng",
      "Yonghong Tian",
      "Tiejun Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05395"
  },
  {
    "id": "arXiv:2203.05399",
    "title": "Designing ML-Resilient Locking at Register-Transfer Level",
    "abstract": "Various logic-locking schemes have been proposed to protect hardware from\nintellectual property piracy and malicious design modifications. Since\ntraditional locking techniques are applied on the gate-level netlist after\nlogic synthesis, they have no semantic knowledge of the design function.\nData-driven, machine-learning (ML) attacks can uncover the design flaws within\ngate-level locking. Recent proposals on register-transfer level (RTL) locking\nhave access to semantic hardware information. We investigate the resilience of\nASSURE, a state-of-the-art RTL locking method, against ML attacks. We used the\nlessons learned to derive two ML-resilient RTL locking schemes built to\nreinforce ASSURE locking. We developed ML-driven security metrics to evaluate\nthe schemes against an RTL adaptation of the state-of-the-art, ML-based\nSnapShot attack.",
    "descriptor": "\nComments: Accepted at ACM/IEEE Design Automation Conference (DAC) 2022\n",
    "authors": [
      "Dominik Sisejkovic",
      "Luca Collini",
      "Benjamin Tan",
      "Christian Pilato",
      "Ramesh Karri",
      "Rainer Leupers"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.05399"
  },
  {
    "id": "arXiv:2203.05402",
    "title": "Representation Compensation Networks for Continual Semantic Segmentation",
    "abstract": "In this work, we study the continual semantic segmentation problem, where the\ndeep neural networks are required to incorporate new classes continually\nwithout catastrophic forgetting. We propose to use a structural\nre-parameterization mechanism, named representation compensation (RC) module,\nto decouple the representation learning of both old and new knowledge. The RC\nmodule consists of two dynamically evolved branches with one frozen and one\ntrainable. Besides, we design a pooled cube knowledge distillation strategy on\nboth spatial and channel dimensions to further enhance the plasticity and\nstability of the model. We conduct experiments on two challenging continual\nsemantic segmentation scenarios, continual class segmentation and continual\ndomain segmentation. Without any extra computational overhead and parameters\nduring inference, our method outperforms state-of-the-art performance. The code\nis available at \\url{https://github.com/zhangchbin/RCIL}.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Chang-Bin Zhang",
      "Jia-Wen Xiao",
      "Xialei Liu",
      "Ying-Cong Chen",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05402"
  },
  {
    "id": "arXiv:2203.05403",
    "title": "Robustness Analysis of Classification Using Recurrent Neural Networks  with Perturbed Sequential Input",
    "abstract": "For a given stable recurrent neural network (RNN) that is trained to perform\na classification task using sequential inputs, we quantify explicit robustness\nbounds as a function of trainable weight matrices. The sequential inputs can be\nperturbed in various ways, e.g., streaming images can be deformed due to robot\nmotion or imperfect camera lens. Using the notion of the Voronoi diagram and\nLipschitz properties of stable RNNs, we provide a thorough analysis and\ncharacterize the maximum allowable perturbations while guaranteeing the full\naccuracy of the classification task. We illustrate and validate our theoretical\nresults using a map dataset with clouds as well as the MNIST dataset.",
    "descriptor": "",
    "authors": [
      "Guangyi Liu",
      "Arash Amini",
      "Martin Takac",
      "Nader Motee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05403"
  },
  {
    "id": "arXiv:2203.05406",
    "title": "Disentangled Multimodal Representation Learning for Recommendation",
    "abstract": "Many multimodal recommender systems have been proposed to exploit the rich\nside information associated with users or items (e.g., user reviews and item\nimages) for learning better user and item representations to enhance the\nrecommendation performance. Studies in psychology show that users have\nindividual differences in the utilization of different modalities for\norganizing information. Therefore, for a certain factor of an item (such as\nappearance or quality), the features of different modalities are of different\nimportance to a user. However, existing methods ignore the fact that different\nmodalities contribute differently to a user's preferences on various factors of\nan item. In light of this, in this paper, we propose a novel Disentangled\nMultimodal Representation Learning (DMRL) recommendation model, which can\ncapture users' attention to different modalities on each factor in user\npreference modeling. In particular, we adopt a disentangled representation\ntechnique to ensure the features of different factors in each modality are\nindependent to each other. A multimodal attention mechanism is then designed to\ncapture user's modality preference for each factor. Based on the estimated\nweights obtained by the attention mechanism, we make recommendation by\ncombining the preference scores of a user's preferences to each factor of the\ntarget item over different modalities. Extensive evaluations on five real-world\ndatasets demonstrate the superiority of our method compared with existing\nmethods.",
    "descriptor": "",
    "authors": [
      "Fan Liu",
      "Zhiyong Cheng",
      "Huilin Chen",
      "Anan Liu",
      "Liqiang Nie",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.05406"
  },
  {
    "id": "arXiv:2203.05408",
    "title": "Attacks as Defenses: Designing Robust Audio CAPTCHAs Using Attacks on  Automatic Speech Recognition Systems",
    "abstract": "Audio CAPTCHAs are supposed to provide a strong defense for online resources;\nhowever, advances in speech-to-text mechanisms have rendered these defenses\nineffective. Audio CAPTCHAs cannot simply be abandoned, as they are\nspecifically named by the W3C as important enablers of accessibility.\nAccordingly, demonstrably more robust audio CAPTCHAs are important to the\nfuture of a secure and accessible Web. We look to recent literature on attacks\non speech-to-text systems for inspiration for the construction of robust,\nprinciple-driven audio defenses. We begin by comparing 20 recent attack papers,\nclassifying and measuring their suitability to serve as the basis of new\n\"robust to transcription\" but \"easy for humans to understand\" CAPTCHAs. After\nshowing that none of these attacks alone are sufficient, we propose a new\nmechanism that is both comparatively intelligible (evaluated through a user\nstudy) and hard to automatically transcribe (i.e., $P({\\rm transcription}) = 4\n\\times 10^{-5}$). Finally, we demonstrate that our audio samples have a high\nprobability of being detected as CAPTCHAs when given to speech-to-text systems\n($P({\\rm evasion}) = 1.77 \\times 10^{-4}$). In so doing, we not only\ndemonstrate a CAPTCHA that is approximately four orders of magnitude more\ndifficult to crack, but that such systems can be designed based on the insights\ngained from attack papers using the differences between the ways that humans\nand computers process audio.",
    "descriptor": "",
    "authors": [
      "Hadi Abdullah",
      "Aditya Karlekar",
      "Saurabh Prasad",
      "Muhammad Sajidur Rahman",
      "Logan Blue",
      "Luke A. Bauer",
      "Vincent Bindschaedler",
      "Patrick Traynor"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.05408"
  },
  {
    "id": "arXiv:2203.05412",
    "title": "OneRel:Joint Entity and Relation Extraction with One Module in One Step",
    "abstract": "Joint entity and relation extraction is an essential task in natural language\nprocessing and knowledge graph construction. Existing approaches usually\ndecompose the joint extraction task into several basic modules or processing\nsteps to make it easy to conduct. However, such a paradigm ignores the fact\nthat the three elements of a triple are interdependent and indivisible.\nTherefore, previous joint methods suffer from the problems of cascading errors\nand redundant information. To address these issues, in this paper, we propose a\nnovel joint entity and relation extraction model, named OneRel, which casts\njoint extraction as a fine-grained triple classification problem. Specifically,\nour model consists of a scoring-based classifier and a relation-specific horns\ntagging strategy. The former evaluates whether a token pair and a relation\nbelong to a factual triple. The latter ensures a simple but effective decoding\nprocess. Extensive experimental results on two widely used datasets demonstrate\nthat the proposed method performs better than the state-of-the-art baselines,\nand delivers consistent performance gain on complex scenarios of various\noverlapping patterns and multiple triples.",
    "descriptor": "\nComments: AAAI-2022 Accepted\n",
    "authors": [
      "Yu-Ming Shang",
      "Heyan Huang",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05412"
  },
  {
    "id": "arXiv:2203.05413",
    "title": "A Self-Tuning Impedance-based Interaction Planner for Robotic Haptic  Exploration",
    "abstract": "This paper presents a novel interaction planning method that exploits\nimpedance tuning techniques in response to environmental uncertainties and\nunpredictable conditions using haptic information only. The proposed algorithm\nplans the robot's trajectory based on the haptic interaction with the\nenvironment and adapts planning strategies as needed. Two approaches are\nconsidered: Exploration and Bouncing strategies. The Exploration strategy takes\nthe actual motion of the robot into account in planning, while the Bouncing\nstrategy exploits the forces and the motion vector of the robot. Moreover,\nself-tuning impedance is performed according to the planned trajectory to\nensure stable contact and low contact forces. In order to show the performance\nof the proposed methodology, two experiments with a torque-controller robotic\narm are carried out. The first considers a maze exploration without obstacles,\nwhereas the second includes obstacles. The proposed method performance is\nanalyzed and compared against previously proposed solutions in both cases.\nExperimental results demonstrate that: i) the robot can successfully plan its\ntrajectory autonomously in the most feasible direction according to the\ninteraction with the environment, and ii) a stable interaction with an unknown\nenvironment despite the uncertainties is achieved. Finally, a scalability\ndemonstration is carried out to show the potential of the proposed method under\nmultiple scenarios.",
    "descriptor": "\nComments: 8 pages, 9 figures, submitted to IEEE Robotics and Automation Letters (RA-L) and IEEE/RSJ International Conference on Intelligent Robots and Systems\n",
    "authors": [
      "Yasuhiro Kato",
      "Pietro Balatti",
      "Juan M. Gandarias",
      "Mattia Leonori",
      "Toshiaki Tsuji",
      "Arash Ajoudani"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.05413"
  },
  {
    "id": "arXiv:2203.05420",
    "title": "Evaluating Elements of Web-based Data Enrichment for Pseudo-Relevance  Feedback Retrieval",
    "abstract": "In this work, we analyze a pseudo-relevance retrieval method based on the\nresults of web search engines. By enriching topics with text data from web\nsearch engine result pages and linked contents, we train topic-specific and\ncost-efficient classifiers that can be used to search test collections for\nrelevant documents. Building upon attempts initially made at TREC Common Core\n2018 by Grossman and Cormack, we address questions of system performance over\ntime considering different search engines, queries, and test collections. Our\nexperimental results show how and to which extent the considered components\naffect the retrieval performance. Overall, the analyzed method is robust in\nterms of average retrieval performance and a promising way to use web content\nfor the data enrichment of relevance feedback methods.",
    "descriptor": "",
    "authors": [
      "Timo Breuer",
      "Melanie Pest",
      "Philipp Schaer"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.05420"
  },
  {
    "id": "arXiv:2203.05425",
    "title": "Semantic Norm Recognition and its application to Portuguese Law",
    "abstract": "Being able to clearly interpret legal texts and fully understanding our\nrights, obligations and other legal norms has become progressively more\nimportant in the digital society. However, simply giving citizens access to the\nlaws is not enough, as there is a need to provide meaningful information that\ncater to their specific queries and needs. For this, it is necessary to extract\nthe relevant semantic information present in legal texts. Thus, we introduce\nthe SNR (Semantic Norm Recognition) system, an automatic semantic information\nextraction system trained on a domain-specific (legal) text corpus taken from\nPortuguese Consumer Law. The SNR system uses the Portuguese Bert (BERTimbau)\nand was trained on a legislative Portuguese corpus. We demonstrate how our\nsystem achieved good results (81.44\\% F1-score) on this domain-specific corpus,\ndespite existing noise, and how it can be used to improve downstream tasks such\nas information retrieval.",
    "descriptor": "",
    "authors": [
      "Maria Duarte",
      "Pedro A. Santos",
      "Jo\u00e3o Dias",
      "Jorge Baptista"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05425"
  },
  {
    "id": "arXiv:2203.05430",
    "title": "Overview of LiLAS 2021 -- Living Labs for Academic Search",
    "abstract": "The Living Labs for Academic Search (LiLAS) lab aims to strengthen the\nconcept of user-centric living labs for academic search. The methodological gap\nbetween real-world and lab-based evaluation should be bridged by allowing lab\nparticipants to evaluate their retrieval approaches in two real-world academic\nsearch systems from life sciences and social sciences. This overview paper\noutlines the two academic search systems LIVIVO and GESIS Search, and their\ncorresponding tasks within LiLAS, which are ad-hoc retrieval and dataset\nrecommendation. The lab is based on a new evaluation infrastructure named\nSTELLA that allows participants to submit results corresponding to their\nexperimental systems in the form of pre-computed runs and Docker containers\nthat can be integrated into production systems and generate experimental\nresults in real-time. Both submission types are interleaved with the results\nprovided by the productive systems allowing for a seamless presentation and\nevaluation. The evaluation of results and a meta-analysis of the different\ntasks and submission types complement this overview.",
    "descriptor": "",
    "authors": [
      "Philipp Schaer",
      "Timo Breuer",
      "Leyla Jael Castro",
      "Benjamin Wolff",
      "Johann Schaible",
      "Narges Tavakolpoursaleh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.05430"
  },
  {
    "id": "arXiv:2203.05434",
    "title": "Near-optimal Deep Reinforcement Learning Policies from Data for Zone  Temperature Control",
    "abstract": "Replacing poorly performing existing controllers with smarter solutions will\ndecrease the energy intensity of the building sector. Recently, controllers\nbased on Deep Reinforcement Learning (DRL) have been shown to be more effective\nthan conventional baselines. However, since the optimal solution is usually\nunknown, it is still unclear if DRL agents are attaining near-optimal\nperformance in general or if there is still a large gap to bridge.\nIn this paper, we investigate the performance of DRL agents compared to the\ntheoretically optimal solution. To that end, we leverage Physically Consistent\nNeural Networks (PCNNs) as simulation environments, for which optimal control\ninputs are easy to compute. Furthermore, PCNNs solely rely on data to be\ntrained, avoiding the difficult physics-based modeling phase, while retaining\nphysical consistency. Our results hint that DRL agents not only clearly\noutperform conventional rule-based controllers, they furthermore attain\nnear-optimal performance.",
    "descriptor": "\nComments: Submitted to IEEE ICCA 2022 - 6 pages, 5 figures\n",
    "authors": [
      "Loris Di Natale",
      "Bratislav Svetozarevic",
      "Philipp Heer",
      "Colin N. Jones"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05434"
  },
  {
    "id": "arXiv:2203.05437",
    "title": "IndicNLG Suite: Multilingual Datasets for Diverse NLG Tasks in Indic  Languages",
    "abstract": "In this paper, we present the IndicNLG suite, a collection of datasets for\nbenchmarking Natural Language Generation (NLG) for 11 Indic languages. We focus\non five diverse tasks, namely, biography generation using Wikipedia infoboxes\n(WikiBio), news headline generation, sentence summarization, question\ngeneration and paraphrase generation. We describe the process of creating the\ndatasets and present statistics of the dataset, following which we train and\nreport a variety of strong monolingual and multilingual baselines that leverage\npre-trained sequence-to-sequence models and analyze the results to understand\nthe challenges involved in Indic language NLG. To the best of our knowledge,\nthis is the first NLG dataset for Indic languages and also the largest\nmultilingual NLG dataset. Our methods can also be easily applied to\nmodest-resource languages with reasonable monolingual and parallel corpora, as\nwell as corpora containing structured data like Wikipedia. We hope this dataset\nspurs research in NLG on diverse languages and tasks, particularly for Indic\nlanguages. The datasets and models are publicly available at\nhttps://indicnlp.ai4bharat.org/indicnlg-suite.",
    "descriptor": "\nComments: 30 pages, work in progress, datasets are available, models will be available shortly\n",
    "authors": [
      "Aman Kumar",
      "Himani Shrotriya",
      "Prachi Sahu",
      "Raj Dabre",
      "Ratish Puduppully",
      "Anoop Kunchukuttan",
      "Amogh Mishra",
      "Mitesh M. Khapra",
      "Pratyush Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05437"
  },
  {
    "id": "arXiv:2203.05438",
    "title": "Deliberation in autonomous robotic surgery: a framework for handling  anatomical uncertainty",
    "abstract": "Autonomous robotic surgery requires deliberation, i.e. the ability to plan\nand execute a task adapting to uncertain and dynamic environments. Uncertainty\nin the surgical domain is mainly related to the partial pre-operative knowledge\nabout patient-specific anatomical properties. In this paper, we introduce a\nlogic-based framework for surgical tasks with deliberative functions of\nmonitoring and learning. The DEliberative Framework for Robot-Assisted Surgery\n(DEFRAS) estimates a pre-operative patient-specific plan, and executes it while\ncontinuously measuring the applied force obtained from a biomechanical\npre-operative model. Monitoring module compares this model with the actual\nsituation reconstructed from sensors. In case of significant mismatch, the\nlearning module is invoked to update the model, thus improving the estimate of\nthe exerted force. DEFRAS is validated both in simulated and real environment\nwith da Vinci Research Kit executing soft tissue retraction. Compared with\nstate-of-the art related works, the success rate of the task is improved while\nminimizing the interaction with the tissue to prevent unintentional damage.",
    "descriptor": "\nComments: 2022 International Conference on Robotics and Automation\n",
    "authors": [
      "Eleonora Tagliabue",
      "Daniele Meli",
      "Diego Dall'Alba",
      "Paolo Fiorini"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.05438"
  },
  {
    "id": "arXiv:2203.05446",
    "title": "Algorithms for the Maximum Eulerian Cycle Decomposition Problem",
    "abstract": "Given an Eulerian graph G, in the Maximum Eulerian Cycle Decomposition\nproblem, we are interested in finding a collection of edge-disjoint cycles\n{E_1, E_2, ..., E_k} in G such that all edges of G are in exactly one cycle and\nk is maximum. We present an algorithm to solve the pricing problem of a column\ngeneration Integer Linear Programming (ILP) model introduced by Lancia and\nSerafini (2016). Furthermore, we propose a greedy heuristic, which searches for\nminimum size cycles starting from a random vertex, and a heuristic based on\npartially solving the ILP model. We performed tests comparing the three\napproaches in relation to the quality of solutions and execution time, using\ndistinct sets of Eulerian graphs, each set grouping graphs with different\nnumbers of vertices and edges. Our experimental results show that the ILP based\nheuristic outperforms the other methods.",
    "descriptor": "",
    "authors": [
      "Pedro O. Pinheiro",
      "Alexsandro Oliveira Alexandrino",
      "Andre R. Oliveira",
      "Cid C. de Souza",
      "Zanoni Dias"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.05446"
  },
  {
    "id": "arXiv:2203.05449",
    "title": "Artificial Intelligence in Vehicular Wireless Networks: A Case Study  Using ns-3",
    "abstract": "Artificial intelligence (AI) techniques have emerged as a powerful approach\nto make wireless networks more efficient and adaptable. In this paper we\npresent an ns-3 simulation framework, able to implement AI algorithms for the\noptimization of wireless networks. Our pipeline consists of: (i) a new\ngeometry-based mobility-dependent channel model for V2X; (ii) all the layers of\na 5G-NR-compliant protocol stack, based on the ns3-mmwave module; (iii) a new\napplication to simulate V2X data transmission, and (iv) a new intelligent\nentity for the control of the network via AI. Thanks to its flexible and\nmodular design, researchers can use this tool to implement, train, and evaluate\ntheir own algorithms in a realistic and controlled environment. We test the\nbehavior of our framework in a Predictive Quality of Service (PQoS) scenario,\nwhere AI functionalities are implemented using Reinforcement Learning (RL), and\ndemonstrate that it promotes better network optimization compared to baseline\nsolutions that do not implement AI.",
    "descriptor": "\nComments: 8 pages, 4 figures, submitted to WNS3 2022\n",
    "authors": [
      "Matteo Drago",
      "Tommaso Zugno",
      "Federico Mason",
      "Marco Giordani",
      "Mate Boban",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05449"
  },
  {
    "id": "arXiv:2203.05452",
    "title": "Invariant domain preserving high-order spectral discontinuous  approximations of hyperbolic systems",
    "abstract": "We propose a limiting procedure to preserve invariant domains with time\nexplicit discrete high-order spectral discontinuous approximate solutions to\nhyperbolic systems of conservation laws. Provided the scheme is discretely\nconservative and satisfy geometric conservation laws at the discrete level, we\nderive a condition on the time step to guaranty that the cell-averaged\napproximate solution is a convex combination of states in the invariant domain.\nThese states are then used to define local bounds which are then imposed to the\nfull high-order approximate solution within the cell via an a posteriori\nscaling limiter. Numerical experiments are then presented with modal and nodal\ndiscontinuous Galerkin schemes confirm the robustness and stability enhancement\nof the present approach.",
    "descriptor": "\nComments: 25 pages, 7 figures\n",
    "authors": [
      "Florent Renac",
      "Valentin Carlier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.05452"
  },
  {
    "id": "arXiv:2203.05465",
    "title": "LoopITR: Combining Dual and Cross Encoder Architectures for Image-Text  Retrieval",
    "abstract": "Dual encoders and cross encoders have been widely used for image-text\nretrieval. Between the two, the dual encoder encodes the image and text\nindependently followed by a dot product, while the cross encoder jointly feeds\nimage and text as the input and performs dense multi-modal fusion. These two\narchitectures are typically modeled separately without interaction. In this\nwork, we propose LoopITR, which combines them in the same network for joint\nlearning. Specifically, we let the dual encoder provide hard negatives to the\ncross encoder, and use the more discriminative cross encoder to distill its\npredictions back to the dual encoder. Both steps are efficiently performed\ntogether in the same model. Our work centers on empirical analyses of this\ncombined architecture, putting the main focus on the design of the distillation\nobjective. Our experimental results highlight the benefits of training the two\nencoders in the same network, and demonstrate that distillation can be quite\neffective with just a few hard negative examples. Experiments on two standard\ndatasets (Flickr30K and COCO) show our approach achieves state-of-the-art dual\nencoder performance when compared with approaches using a similar amount of\ndata.",
    "descriptor": "",
    "authors": [
      "Jie Lei",
      "Xinlei Chen",
      "Ning Zhang",
      "Mengjiao Wang",
      "Mohit Bansal",
      "Tamara L. Berg",
      "Licheng Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05465"
  },
  {
    "id": "arXiv:2203.05466",
    "title": "Wavelength Multiplexed Ultralow-Power Photonic Edge Computing",
    "abstract": "Advances in deep neural networks (DNNs) are transforming science and\ntechnology. However, the increasing computational demands of the most powerful\nDNNs limit deployment on low-power devices, such as smartphones and sensors --\nand this trend is accelerated by the simultaneous move towards\nInternet-of-Things (IoT) devices. Numerous efforts are underway to lower power\nconsumption, but a fundamental bottleneck remains due to energy consumption in\nmatrix algebra, even for analog approaches including neuromorphic, analog\nmemory and photonic meshes. Here we introduce and demonstrate a new approach\nthat sharply reduces energy required for matrix algebra by doing away with\nweight memory access on edge devices, enabling orders of magnitude energy and\nlatency reduction. At the core of our approach is a new concept that\ndecentralizing the DNN for delocalized, optically accelerated matrix algebra on\nedge devices. Using a silicon photonic smart transceiver, we demonstrate\nexperimentally that this scheme, termed Netcast, dramatically reduces energy\nconsumption. We demonstrate operation in a photon-starved environment with 40\naJ/multiply of optical energy for 98.8% accurate image recognition and <1\nphoton/multiply using single photon detectors. Furthermore, we show realistic\ndeployment of our system, classifying images with 3 THz of bandwidth over 86 km\nof deployed optical fiber in a Boston-area fiber network. Our approach enables\ncomputing on a new generation of edge devices with speeds comparable to modern\ndigital electronics and power consumption that is orders of magnitude lower.",
    "descriptor": "",
    "authors": [
      "Alexander Sludds",
      "Saumil Bandyopadhyay",
      "Zaijun Chen",
      "Zhizhen Zhong",
      "Liane Bernstein",
      "Darius Bunandar",
      "Matthew Streshinsky",
      "Ari Novack",
      "Tom Baehr-Jones",
      "Michael Hochberg",
      "Manya Ghobadi",
      "Ryan Hamerly",
      "Dirk Englund"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2203.05466"
  },
  {
    "id": "arXiv:2203.05468",
    "title": "CoCo-FL: Communication- and Computation-Aware Federated Learning via  Partial NN Freezing and Quantization",
    "abstract": "Devices participating in federated learning (FL) typically have heterogeneous\ncommunication and computation resources. However, all devices need to finish\ntraining by the same deadline dictated by the server when applying synchronous\nFL, as we consider in this paper. Reducing the complexity of the trained neural\nnetwork (NN) at constrained devices, i.e., by dropping neurons/filters, is\ninsufficient as it tightly couples reductions in communication and computation\nrequirements, wasting resources. Quantization has proven effective to\naccelerate inference, but quantized training suffers from accuracy losses. We\npresent a novel mechanism that quantizes during training parts of the NN to\nreduce the computation requirements, freezes them to reduce the communication\nand computation requirements, and trains the remaining parts in full precision\nto maintain a high convergence speed and final accuracy. Using this mechanism,\nwe present the first FL technique that independently optimizes for specific\ncommunication and computation constraints in FL: CoCo-FL. We show that CoCo-FL\nreaches a much higher convergence speed than the state of the art and a\nsignificantly higher final accuracy.",
    "descriptor": "",
    "authors": [
      "Kilian Pfeiffer",
      "Martin Rapp",
      "Ramin Khalili",
      "J\u00f6rg Henkel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05468"
  },
  {
    "id": "arXiv:2203.05469",
    "title": "Prediction-Guided Distillation for Dense Object Detection",
    "abstract": "Real-world object detection models should be cheap and accurate. Knowledge\ndistillation (KD) can boost the accuracy of a small, cheap detection model by\nleveraging useful information from a larger teacher model. However, a key\nchallenge is identifying the most informative features produced by the teacher\nfor distillation. In this work, we show that only a very small fraction of\nfeatures within a ground-truth bounding box are responsible for a teacher's\nhigh detection performance. Based on this, we propose Prediction-Guided\nDistillation (PGD), which focuses distillation on these key predictive regions\nof the teacher and yields considerable gains in performance over many existing\nKD baselines. In addition, we propose an adaptive weighting scheme over the key\nregions to smooth out their influence and achieve even better performance. Our\nproposed approach outperforms current state-of-the-art KD baselines on a\nvariety of advanced one-stage detection architectures. Specifically, on the\nCOCO dataset, our method achieves between +3.1% and +4.6% AP improvement using\nResNet-101 and ResNet-50 as the teacher and student backbones, respectively. On\nthe CrowdHuman dataset, we achieve +3.2% and +2.0% improvements in MR and AP,\nalso using these backbones. Our code is available at\nhttps://github.com/ChenhongyiYang/PGD.",
    "descriptor": "",
    "authors": [
      "Chenhongyi Yang",
      "Mateusz Ochal",
      "Amos Storkey",
      "Elliot J. Crowley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05469"
  },
  {
    "id": "arXiv:2203.05471",
    "title": "A Full Dive into Realizing the Edge-enabled Metaverse: Visions, Enabling  Technologies,and Challenges",
    "abstract": "Dubbed \"the successor to the mobile Internet\", the concept of the Metaverse\nhas grown in popularity. While there exist lite versions of the Metaverse\ntoday, they are still far from realizing the full vision of an immersive,\nembodied, and interoperable Metaverse. Without addressing the issues of\nimplementation from the communication and networking, as well as computation\nperspectives, the Metaverse is difficult to succeed the Internet, especially in\nterms of its accessibility to billions of users today. In this survey, we focus\non the edge-enabled Metaverse to realize its ultimate vision. We first provide\nreaders with a succinct tutorial of the Metaverse, an introduction to the\narchitecture, as well as current developments. To enable the ubiquitous,\nseamless, and embodied access to the Metaverse, we discuss the communication\nand networking challenges and survey cutting-edge solutions and concepts that\nleverage next-generation communication systems for users to be telepresent and\nteleoperate in the Metaverse. Moreover, given the high computation costs\nrequired, e.g., to render immersive 3D worlds and run data hungry artificial\nintelligence (AI) driven applications, we discuss the computation challenges\nand cloud-edge-end computation framework driven solutions to realize the\nMetaverse on resource-constrained edge devices. Next, we explore how blockchain\ntechnologies can aid in the interoperable development of the Metaverse, not\njust in terms of empowering the economic circulation of virtual user-generated\ncontents, but also to manage physical edge resources in a decentralized,\ntransparent, and tamper-proof manner. Finally, we discuss the future research\ndirections towards realizing the true vision of the edge-enabled Metaverse.",
    "descriptor": "",
    "authors": [
      "Minrui Xu",
      "Wei Chong Ng",
      "Wei Yang Bryan Lim",
      "Jiawen Kang",
      "Zehui Xiong",
      "Dusit Niyato",
      "Qiang Yang",
      "Xuemin Sherman Shen",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.05471"
  },
  {
    "id": "arXiv:2203.05479",
    "title": "Summation-by-parts operators for general function spaces",
    "abstract": "Summation-by-parts (SBP) operators are popular building blocks for\nsystematically developing stable and high-order accurate numerical methods for\ntime-dependent differential equations. The main idea behind existing SBP\noperators is that the solution is assumed to be well approximated by\npolynomials up to a certain degree, and the SBP operator should therefore be\nexact for them. However, polynomials might not provide the best approximation\nfor some problems, and other approximation spaces may be more appropriate. In\nthis paper, a theory for SBP operators based on general function spaces is\ndeveloped. We demonstrate that most of the established results for\npolynomial-based SBP operators carry over to this general class of SBP\noperators. Our findings imply that the concept of SBP operators can be applied\nto a significantly larger class of methods than currently known. We exemplify\nthe general theory by considering trigonometric, exponential and radial basis\nfunctions.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Jan Glaubitz",
      "Jan Nordstr\u00f6m",
      "Philipp \u00d6ffner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.05479"
  },
  {
    "id": "arXiv:2203.05481",
    "title": "Fully Adaptive Composition in Differential Privacy",
    "abstract": "Composition is a key feature of differential privacy. Well-known advanced\ncomposition theorems allow one to query a private database quadratically more\ntimes than basic privacy composition would permit. However, these results\nrequire that the privacy parameters of all algorithms be fixed before\ninteracting with the data. To address this, Rogers et al. introduced fully\nadaptive composition, wherein both algorithms and their privacy parameters can\nbe selected adaptively. The authors introduce two probabilistic objects to\nmeasure privacy in adaptive composition: privacy filters, which provide\ndifferential privacy guarantees for composed interactions, and privacy\nodometers, time-uniform bounds on privacy loss. There are substantial gaps\nbetween advanced composition and existing filters and odometers. First,\nexisting filters place stronger assumptions on the algorithms being composed.\nSecond, these odometers and filters suffer from large constants, making them\nimpractical. We construct filters that match the tightness of advanced\ncomposition, including constants, despite allowing for adaptively chosen\nprivacy parameters. We also construct several general families of odometers.\nThese odometers can match the tightness of advanced composition at an\narbitrary, preselected point in time, or at all points in time simultaneously,\nup to a doubly-logarithmic factor. We obtain our results by leveraging recent\nadvances in time-uniform martingale concentration. In sum, we show that fully\nadaptive privacy is obtainable at almost no loss, and conjecture that our\nresults are essentially unimprovable (even in constants) in general.",
    "descriptor": "\nComments: 25 pages, 3 figures\n",
    "authors": [
      "Justin Whitehouse",
      "Aaditya Ramdas",
      "Ryan Rogers",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.05481"
  },
  {
    "id": "arXiv:2203.05482",
    "title": "Model soups: averaging weights of multiple fine-tuned models improves  accuracy without increasing inference time",
    "abstract": "The conventional recipe for maximizing model accuracy is to (1) train\nmultiple models with various hyperparameters and (2) pick the individual model\nwhich performs best on a held-out validation set, discarding the remainder. In\nthis paper, we revisit the second step of this procedure in the context of\nfine-tuning large pre-trained models, where fine-tuned models often appear to\nlie in a single low error basin. We show that averaging the weights of multiple\nmodels fine-tuned with different hyperparameter configurations often improves\naccuracy and robustness. Unlike a conventional ensemble, we may average many\nmodels without incurring any additional inference or memory costs -- we call\nthe results \"model soups.\" When fine-tuning large pre-trained models such as\nCLIP, ALIGN, and a ViT-G pre-trained on JFT, our soup recipe provides\nsignificant improvements over the best model in a hyperparameter sweep on\nImageNet. As a highlight, the resulting ViT-G model attains 90.94% top-1\naccuracy on ImageNet, a new state of the art. Furthermore, we show that the\nmodel soup approach extends to multiple image classification and natural\nlanguage processing tasks, improves out-of-distribution performance, and\nimproves zero-shot performance on new downstream tasks. Finally, we\nanalytically relate the performance similarity of weight-averaging and\nlogit-ensembling to flatness of the loss and confidence of the predictions, and\nvalidate this relation empirically.",
    "descriptor": "\nComments: The last three authors contributed equally\n",
    "authors": [
      "Mitchell Wortsman",
      "Gabriel Ilharco",
      "Samir Yitzhak Gadre",
      "Rebecca Roelofs",
      "Raphael Gontijo-Lopes",
      "Ari S. Morcos",
      "Hongseok Namkoong",
      "Ali Farhadi",
      "Yair Carmon",
      "Simon Kornblith",
      "Ludwig Schmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05482"
  },
  {
    "id": "arXiv:2203.05483",
    "title": "projUNN: efficient method for training deep networks with unitary  matrices",
    "abstract": "In learning with recurrent or very deep feed-forward networks, employing\nunitary matrices in each layer can be very effective at maintaining long-range\nstability. However, restricting network parameters to be unitary typically\ncomes at the cost of expensive parameterizations or increased training runtime.\nWe propose instead an efficient method based on rank-$k$ updates -- or their\nrank-$k$ approximation -- that maintains performance at a nearly optimal\ntraining runtime. We introduce two variants of this method, named Direct\n(projUNN-D) and Tangent (projUNN-T) projected Unitary Neural Networks, that can\nparameterize full $N$-dimensional unitary or orthogonal matrices with a\ntraining runtime scaling as $O(kN^2)$. Our method either projects low-rank\ngradients onto the closest unitary matrix (projUNN-T) or transports unitary\nmatrices in the direction of the low-rank gradient (projUNN-D). Even in the\nfastest setting ($k=1$), projUNN is able to train a model's unitary parameters\nto reach comparable performances against baseline implementations. By\nintegrating our projUNN algorithm into both recurrent and convolutional neural\nnetworks, our models can closely match or exceed benchmarked results from\nstate-of-the-art algorithms.",
    "descriptor": "",
    "authors": [
      "Bobak Kiani",
      "Randall Balestriero",
      "Yann Lecun",
      "Seth Lloyd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.05483"
  },
  {
    "id": "arXiv:2203.05488",
    "title": "Geometric and Topological Inference for Deep Representations of Complex  Networks",
    "abstract": "Understanding the deep representations of complex networks is an important\nstep of building interpretable and trustworthy machine learning applications in\nthe age of internet. Global surrogate models that approximate the predictions\nof a black box model (e.g. an artificial or biological neural net) are usually\nused to provide valuable theoretical insights for the model interpretability.\nIn order to evaluate how well a surrogate model can account for the\nrepresentation in another model, we need to develop inference methods for model\ncomparison. Previous studies have compared models and brains in terms of their\nrepresentational geometries (characterized by the matrix of distances between\nrepresentations of the input patterns in a model layer or cortical area). In\nthis study, we propose to explore these summary statistical descriptions of\nrepresentations in models and brains as part of a broader class of statistics\nthat emphasize the topology as well as the geometry of representations. The\ntopological summary statistics build on topological data analysis (TDA) and\nother graph-based methods. We evaluate these statistics in terms of the\nsensitivity and specificity that they afford when used for model selection,\nwith the goal to relate different neural network models to each other and to\nmake inferences about the computational mechanism that might best account for a\nblack box representation. These new methods enable brain and computer\nscientists to visualize the dynamic representational transformations learned by\nbrains and models, and to perform model-comparative statistical inference.",
    "descriptor": "\nComments: To appear in Proceeding of WWW 2022. This work extends our prior work (arXiv:1810.02923, arXiv:1906.09264, arXiv:1902.10658) and put them in perspectives along with many other ongoing research in this direction\n",
    "authors": [
      "Baihan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geometric Topology (math.GT)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2203.05488"
  },
  {
    "id": "arXiv:2203.05492",
    "title": "An Empirical Study of Low Precision Quantization for TinyML",
    "abstract": "Tiny machine learning (tinyML) has emerged during the past few years aiming\nto deploy machine learning models to embedded AI processors with highly\nconstrained memory and computation capacity. Low precision quantization is an\nimportant model compression technique that can greatly reduce both memory\nconsumption and computation cost of model inference. In this study, we focus on\npost-training quantization (PTQ) algorithms that quantize a model to low-bit\n(less than 8-bit) precision with only a small set of calibration data and\nbenchmark them on different tinyML use cases. To achieve a fair comparison, we\nbuild a simulated quantization framework to investigate recent PTQ algorithms.\nFurthermore, we break down those algorithms into essential components and\nre-assembled a generic PTQ pipeline. With ablation study on different\nalternatives of components in the pipeline, we reveal key design choices when\nperforming low precision quantization. We hope this work could provide useful\ndata points and shed lights on the future research of low precision\nquantization.",
    "descriptor": "\nComments: tinyML Research Symposium 2022\n",
    "authors": [
      "Shaojie Zhuo",
      "Hongyu Chen",
      "Ramchalam Kinattinkara Ramakrishnan",
      "Tommy Chen",
      "Chen Feng",
      "Yicheng Lin",
      "Parker Zhang",
      "Liang Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05492"
  },
  {
    "id": "arXiv:2203.05496",
    "title": "A Universal Triangulation for Flat Tori",
    "abstract": "A result due to Burago and Zalgaller states that every orientable polyhedral\nsurface, one that is obtained by gluing Euclidean polygons, has an isometric\npiecewise linear (PL) embedding into Euclidean space $\\mathbb{E}^3$. A flat\ntorus, resulting from the identification of the opposite sides of a Euclidean\nparallelogram, is a simple example of polyhedral surface. In a first part, we\nadapt the proof of Burago and Zalgaller, which is partially constructive, to\nproduce PL isometric embeddings of flat tori. In practice, the resulting\nembeddings have a huge number of vertices, moreover distinct for every flat\ntorus. In a second part, based on another construction of Zalgaller and on\nrecent works by Arnoux et al., we exhibit a universal triangulation with 5974\ntriangles which can be embedded linearly on each triangle in order to realize\nthe metric of any flat torus.",
    "descriptor": "\nComments: 33 pages, 29 figures\n",
    "authors": [
      "Francis Lazarus",
      "Florent Tallerie"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Geometric Topology (math.GT)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2203.05496"
  },
  {
    "id": "arXiv:2203.05508",
    "title": "Towards Less Constrained Macro-Neural Architecture Search",
    "abstract": "Networks found with Neural Architecture Search (NAS) achieve state-of-the-art\nperformance in a variety of tasks, out-performing human-designed networks.\nHowever, most NAS methods heavily rely on human-defined assumptions that\nconstrain the search: architecture's outer-skeletons, number of layers,\nparameter heuristics and search spaces. Additionally, common search spaces\nconsist of repeatable modules (cells) instead of fully exploring the\narchitecture's search space by designing entire architectures (macro-search).\nImposing such constraints requires deep human expertise and restricts the\nsearch to pre-defined settings. In this paper, we propose LCMNAS, a method that\npushes NAS to less constrained search spaces by performing macro-search without\nrelying on pre-defined heuristics or bounded search spaces. LCMNAS introduces\nthree components for the NAS pipeline: i) a method that leverages information\nabout well-known architectures to autonomously generate complex search spaces\nbased on Weighted Directed Graphs with hidden properties, ii) a evolutionary\nsearch strategy that generates complete architectures from scratch, and iii) a\nmixed-performance estimation approach that combines information about\narchitectures at initialization stage and lower fidelity estimates to infer\ntheir trainability and capacity to model complex functions. We present\nexperiments showing that LCMNAS generates state-of-the-art architectures from\nscratch with minimal GPU computation. We study the importance of different NAS\ncomponents on a macro-search setting. Code for reproducibility is public at\n\\url{https://github.com/VascoLopes/LCMNAS}.",
    "descriptor": "\nComments: 8 pages double-column, 6 tables, 3 figures\n",
    "authors": [
      "Vasco Lopes",
      "Lu\u00eds A. Alexandre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.05508"
  },
  {
    "id": "arXiv:2203.05516",
    "title": "VirtualSync+: Timing Optimization with Virtual Synchronization",
    "abstract": "In digital circuit designs, sequential components such as flip-flops are used\nto synchronize signal propagations. Logic computations are aligned at and thus\nisolated by flip-flop stages. Although this fully synchronous style can reduce\ndesign efforts significantly, it may affect circuit performance negatively,\nbecause sequential components can only introduce delays into signal\npropagations but never accelerate them. In this paper, we propose a new timing\nmodel, VirtualSync+, in which signals, specially those along critical paths,\nare allowed to propagate through several sequential stages without flip-flops.\nTiming constraints are still satisfied at the boundary of the optimized circuit\nto maintain a consistent interface with existing designs. By removing\nclock-to-q delays and setup time requirements of flip-flops on critical paths,\nthe performance of a circuit can be pushed even beyond the limit of traditional\nsequential designs. In addition, we further enhance the optimization with\nVirtualSync+ by fine-tuning with commercial design tools, e.g., Design Compiler\nfrom Synopsys, to achieve more accurate result. Experimental results\ndemonstrate that circuit performance can be improved by up to 4% (average 1.5%)\ncompared with that after extreme retiming and sizing, while the increase of\narea is still negligible. This timing performance is enhanced beyond the limit\nof traditional sequential designs. It also demonstrates that compared with\nthose after retiming and sizing, the circuits with VirtualSync+ can achieve\nbetter timing performance under the same area cost or smaller area cost under\nthe same clock period, respectively.",
    "descriptor": "",
    "authors": [
      "Grace Li Zhang",
      "Bing Li",
      "Xing Huang",
      "Xunzhao Yin",
      "Cheng Zhuo",
      "Masanori Hashimoto",
      "Ulf Schlichtmann"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.05516"
  },
  {
    "id": "arXiv:2203.05522",
    "title": "Data-driven Abstractions with Probabilistic Guarantees for Linear PETC  Systems",
    "abstract": "We employ the scenario approach to compute probably approximately correct\n(PAC) bounds on the average inter-sample time (AIST) generated by an unknown\nPETC system, based on a finite number of samples. We extend the scenario\napproach to multiclass SVM algorithms in order to construct a PAC map between\nthe concrete, unknown state-space and the inter-sample times. We then build a\ntraffic model applying an $\\ell$-complete relation and find, in the underlying\ngraph, the cycles of minimum and maximum average weight: these provide lower\nand upper bounds on the AIST. Numerical benchmarks show the practical\napplicability of our method, which is compared against model-based\nstate-of-the-art tools.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Andrea Peruffo",
      "Manuel Mazo Jr"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2203.05522"
  },
  {
    "id": "arXiv:2203.05523",
    "title": "SoftSNN: Low-Cost Fault Tolerance for Spiking Neural Network  Accelerators under Soft Errors",
    "abstract": "Specialized hardware accelerators have been designed and employed to maximize\nthe performance efficiency of Spiking Neural Networks (SNNs). However, such\naccelerators are vulnerable to transient faults (i.e., soft errors), which\noccur due to high-energy particle strikes, and manifest as bit flips at the\nhardware layer. These errors can change the weight values and neuron operations\nin the compute engine of SNN accelerators, thereby leading to incorrect outputs\nand accuracy degradation. However, the impact of soft errors in the compute\nengine and the respective mitigation techniques have not been thoroughly\nstudied yet for SNNs. A potential solution is employing redundant executions\n(re-execution) for ensuring correct outputs, but it leads to huge latency and\nenergy overheads. Toward this, we propose SoftSNN, a novel methodology to\nmitigate soft errors in the weight registers (synapses) and neurons of SNN\naccelerators without re-execution, thereby maintaining the accuracy with low\nlatency and energy overheads. Our SoftSNN methodology employs the following key\nsteps: (1) analyzing the SNN characteristics under soft errors to identify\nfaulty weights and neuron operations, which are required for recognizing faulty\nSNN behavior; (2) a Bound-and-Protect technique that leverages this analysis to\nimprove the SNN fault tolerance by bounding the weight values and protecting\nthe neurons from faulty operations; and (3) devising lightweight hardware\nenhancements for the neural hardware accelerator to efficiently support the\nproposed technique. The experimental results show that, for a 900-neuron\nnetwork with even a high fault rate, our SoftSNN maintains the accuracy\ndegradation below 3%, while reducing latency and energy by up to 3x and 2.3x\nrespectively, as compared to the re-execution technique.",
    "descriptor": "\nComments: To appear at the 59th IEEE/ACM Design Automation Conference (DAC), July 2022, San Francisco, CA, USA\n",
    "authors": [
      "Rachmad Vidya Wicaksana Putra",
      "Muhammad Abdullah Hanif",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.05523"
  },
  {
    "id": "arXiv:2203.05532",
    "title": "Robust Radical Sylvester-Gallai Theorem for Quadratics",
    "abstract": "We prove a robust generalization of a Sylvester-Gallai type theorem for\nquadratic polynomials, generalizing the result in [S'20]. More precisely, given\na parameter $0 < \\delta \\leq 1$ and a finite collection $\\mathcal{F}$ of\nirreducible and pairwise independent polynomials of degree at most 2, we say\nthat $\\mathcal{F}$ is a $(\\delta, 2)$-radical Sylvester-Gallai configuration if\nfor any polynomial $F_i \\in \\mathcal{F}$, there exist $\\delta(|\\mathcal{F}|\n-1)$ polynomials $F_j$ such that $|\\mathrm{rad}(F_i, F_j) \\cap \\mathcal{F}|\n\\geq 3$, that is, the radical of $F_i, F_j$ contains a third polynomial in the\nset.\nIn this work, we prove that any $(\\delta, 2)$-radical Sylvester-Gallai\nconfiguration $\\mathcal{F}$ must be of low dimension: that is $$\\dim\n\\mathrm{span}(\\mathcal{F}) = \\mathrm{poly}(1/\\delta).$$",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Abhibhav Garg",
      "Rafael Oliveira",
      "Akash Sengupta"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.05532"
  },
  {
    "id": "arXiv:2203.05534",
    "title": "AGCN: Augmented Graph Convolutional Network for Lifelong Multi-label  Image Recognition",
    "abstract": "The Lifelong Multi-Label (LML) image recognition builds an online\nclass-incremental classifier in a sequential multi-label image recognition data\nstream. The key challenges of LML image recognition are the construction of\nlabel relationships on Partial Labels of training data and the Catastrophic\nForgetting on old classes, resulting in poor generalization. To solve the\nproblems, the study proposes an Augmented Graph Convolutional Network (AGCN)\nmodel that can construct the label relationships across the sequential\nrecognition tasks and sustain the catastrophic forgetting. First, we build an\nAugmented Correlation Matrix (ACM) across all seen classes, where the\nintra-task relationships derive from the hard label statistics while the\ninter-task relationships leverage both hard and soft labels from data and a\nconstructed expert network. Then, based on the ACM, the proposed AGCN captures\nlabel dependencies with dynamic augmented structure and yields effective class\nrepresentations. Last, to suppress the forgetting of label dependencies across\nold tasks, we propose a relationship-preserving loss as a constraint to the\nconstruction of label relationships. The proposed method is evaluated using two\nmulti-label image benchmarks and the experimental results show that the\nproposed method is effective for LML image recognition and can build convincing\ncorrelation across tasks even if the labels of previous tasks are missing. Our\ncode is available at https://github.com/Kaile-Du/AGCN.",
    "descriptor": "",
    "authors": [
      "Kaile Du",
      "Fan Lyu",
      "Fuyuan Hu",
      "Linyan Li",
      "Wei Feng",
      "Fenglei Xu",
      "Qiming Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05534"
  },
  {
    "id": "arXiv:2203.05549",
    "title": "Context is Everything: Implicit Identification for Dynamics Adaptation",
    "abstract": "Understanding environment dynamics is necessary for robots to act safely and\noptimally in the world. In realistic scenarios, dynamics are non-stationary and\nthe causal variables such as environment parameters cannot necessarily be\nprecisely measured or inferred, even during training. We propose Implicit\nIdentification for Dynamics Adaptation (IIDA), a simple method to allow\npredictive models to adapt to changing environment dynamics. IIDA assumes no\naccess to the true variations in the world and instead implicitly infers\nproperties of the environment from a small amount of contextual data. We\ndemonstrate IIDA's ability to perform well in unseen environments through a\nsuite of simulated experiments on MuJoCo environments and a real robot dynamic\nsliding task. In general, IIDA significantly reduces model error and results in\nhigher task performance over commonly used methods. Our code and robot videos\nare at https://bennevans.github.io/iida/",
    "descriptor": "\nComments: Accepted at ICRA 2022\n",
    "authors": [
      "Ben Evans",
      "Abitha Thankaraj",
      "Lerrel Pinto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05549"
  },
  {
    "id": "arXiv:2203.05550",
    "title": "An Empirical Investigation of 3D Anomaly Detection and Segmentation",
    "abstract": "Anomaly detection and segmentation in images has made tremendous progress in\nrecent years while 3D information has often been ignored. The objective of this\npaper is to further understand the benefit and role of 3D as opposed to color\nin image anomaly detection. Our study begins by presenting a surprising\nfinding: standard color-only anomaly segmentation methods, when applied to 3D\ndatasets, significantly outperform all current methods. On the other hand, we\nobserve that color-only methods are insufficient for images containing\ngeometric anomalies where shape cannot be unambiguously inferred from 2D. This\nsuggests that better 3D methods are needed. We investigate different\nrepresentations for 3D anomaly detection and discover that handcrafted\norientation-invariant representations are unreasonably effective on this task.\nWe uncover a simple 3D-only method that outperforms all recent approaches while\nnot using deep learning, external pretraining datasets, or color information.\nAs the 3D-only method cannot detect color and texture anomalies, we combine it\nwith 2D color features, granting us the best current results by a large margin\n(Pixel-wise ROCAUC: 99.2%, PRO: 95.9% on MVTec 3D-AD). We conclude by\ndiscussing future challenges for 3D anomaly detection and segmentation.",
    "descriptor": "",
    "authors": [
      "Eliahu Horwitz",
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05550"
  },
  {
    "id": "arXiv:2203.05551",
    "title": "Cellular automata can classify data by inducing trajectory phase  coexistence",
    "abstract": "We show that cellular automata can classify data by inducing a form of\ndynamical phase coexistence. We use Monte Carlo methods to search for general\ntwo-dimensional deterministic automata that classify images on the basis of\nactivity, the number of state changes that occur in a trajectory initiated from\nthe image. When the depth of the automaton is a trainable parameter, the search\nscheme identifies automata that generate a population of dynamical trajectories\ndisplaying high or low activity, depending on initial conditions. Automata of\nthis nature behave as nonlinear activation functions with an output that is\neffectively binary, resembling an emergent version of a spiking neuron. Our\nwork connects machine learning and reservoir computing to phenomena\nconceptually similar to those seen in physical systems such as magnets and\nglasses.",
    "descriptor": "",
    "authors": [
      "Stephen Whitelam",
      "Isaac Tamblyn"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2203.05551"
  },
  {
    "id": "arXiv:2203.05553",
    "title": "Transfer of Representations to Video Label Propagation: Implementation  Factors Matter",
    "abstract": "This work studies feature representations for dense label propagation in\nvideo, with a focus on recently proposed methods that learn video\ncorrespondence using self-supervised signals such as colorization or temporal\ncycle consistency. In the literature, these methods have been evaluated with an\narray of inconsistent settings, making it difficult to discern trends or\ncompare performance fairly. Starting with a unified formulation of the label\npropagation algorithm that encompasses most existing variations, we\nsystematically study the impact of important implementation factors in feature\nextraction and label propagation. Along the way, we report the accuracies of\nproperly tuned supervised and unsupervised still image baselines, which are\nhigher than those found in previous works. We also demonstrate that augmenting\nvideo-based correspondence cues with still-image-based ones can further improve\nperformance. We then attempt a fair comparison of recent video-based methods on\nthe DAVIS benchmark, showing convergence of best methods to performance levels\nnear our strong ImageNet baseline, despite the usage of a variety of\nspecialized video-based losses and training particulars. Additional comparisons\non JHMDB and VIP datasets confirm the similar performance of current methods.\nWe hope that this study will help to improve evaluation practices and better\ninform future research directions in temporal correspondence.",
    "descriptor": "",
    "authors": [
      "Daniel McKee",
      "Zitong Zhan",
      "Bing Shuai",
      "Davide Modolo",
      "Joseph Tighe",
      "Svetlana Lazebnik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05553"
  },
  {
    "id": "arXiv:2203.05556",
    "title": "On Embeddings for Numerical Features in Tabular Deep Learning",
    "abstract": "Recently, Transformer-like deep architectures have shown strong performance\non tabular data problems. Unlike traditional models, e.g., MLP, these\narchitectures map scalar values of numerical features to high-dimensional\nembeddings before mixing them in the main backbone. In this work, we argue that\nembeddings for numerical features are an underexplored degree of freedom in\ntabular DL, which allows constructing more powerful DL models and competing\nwith GBDT on some traditionally GBDT-friendly benchmarks. We start by\ndescribing two conceptually different approaches to building embedding modules:\nthe first one is based on a piecewise linear encoding of scalar values, and the\nsecond one utilizes periodic activations. Then, we empirically demonstrate that\nthese two approaches can lead to significant performance boosts compared to the\nembeddings based on conventional blocks such as linear layers and ReLU\nactivations. Importantly, we also show that embedding numerical features is\nbeneficial for many backbones, not only for Transformers. Specifically, after\nproper embeddings, simple MLP-like models can perform on par with the\nattention-based architectures. Overall, we highlight that embeddings for\nnumerical features are an important design aspect, which has good potential for\nfurther improvements in tabular DL.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Yura Gorishniy",
      "Ivan Rubachev",
      "Artem Babenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05556"
  },
  {
    "id": "arXiv:2203.05557",
    "title": "Conditional Prompt Learning for Vision-Language Models",
    "abstract": "With the rise of powerful pre-trained vision-language models like CLIP, it\nbecomes essential to investigate ways to adapt these models to downstream\ndatasets. A recently proposed method named Context Optimization (CoOp)\nintroduces the concept of prompt learning -- a recent trend in NLP -- to the\nvision domain for adapting pre-trained vision-language models. Specifically,\nCoOp turns context words in a prompt into a set of learnable vectors and, with\nonly a few labeled images for learning, can achieve huge improvements over\nintensively-tuned manual prompts. In our study we identify a critical problem\nof CoOp: the learned context is not generalizable to wider unseen classes\nwithin the same dataset, suggesting that CoOp overfits base classes observed\nduring training. To address the problem, we propose Conditional Context\nOptimization (CoCoOp), which extends CoOp by further learning a lightweight\nneural network to generate for each image an input-conditional token (vector).\nCompared to CoOp's static prompts, our dynamic prompts adapt to each instance\nand are thus less sensitive to class shift. Extensive experiments show that\nCoCoOp generalizes much better than CoOp to unseen classes, even showing\npromising transferability beyond a single dataset; and yields stronger domain\ngeneralization performance as well. Code is available at\nhttps://github.com/KaiyangZhou/CoOp.",
    "descriptor": "\nComments: CVPR 2022. TL;DR: We propose a conditional prompt learning approach to solve the generalizability issue of static prompts\n",
    "authors": [
      "Kaiyang Zhou",
      "Jingkang Yang",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05557"
  },
  {
    "id": "arXiv:2203.04958",
    "title": "Fluid registration between lung CT and stationary chest tomosynthesis  images",
    "abstract": "Registration is widely used in image-guided therapy and image-guided surgery\nto estimate spatial correspondences between organs of interest between planning\nand treatment images. However, while high-quality computed tomography (CT)\nimages are often available at planning time, limited angle acquisitions are\nfrequently used during treatment because of radiation concerns or imaging time\nconstraints. This requires algorithms to register CT images based on limited\nangle acquisitions. We, therefore, formulate a 3D/2D registration approach\nwhich infers a 3D deformation based on measured projections and digitally\nreconstructed radiographs of the CT. Most 3D/2D registration approaches use\nsimple transformation models or require complex mathematical derivations to\nformulate the underlying optimization problem. Instead, our approach entirely\nrelies on differentiable operations which can be combined with modern\ncomputational toolboxes supporting automatic differentiation. This then allows\nfor rapid prototyping, integration with deep neural networks, and to support a\nvariety of transformation models including fluid flow models. We demonstrate\nour approach for the registration between CT and stationary chest tomosynthesis\n(sDCT) images and show how it naturally leads to an iterative image\nreconstruction approach.",
    "descriptor": "",
    "authors": [
      "Lin Tian",
      "Connor Puett",
      "Peirong Liu",
      "Zhengyang Shen",
      "Stephen R. Aylward",
      "Yueh Z. Lee",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.04958"
  },
  {
    "id": "arXiv:2203.04959",
    "title": "ModDrop++: A Dynamic Filter Network with Intra-subject Co-training for  Multiple Sclerosis Lesion Segmentation with Missing Modalities",
    "abstract": "Multiple Sclerosis (MS) is a chronic neuroinflammatory disease and\nmulti-modality MRIs are routinely used to monitor MS lesions. Many automatic MS\nlesion segmentation models have been developed and have reached human-level\nperformance. However, most established methods assume the MRI modalities used\nduring training are also available during testing, which is not guaranteed in\nclinical practice. A training strategy termed Modality Dropout (ModDrop) has\nbeen applied to MS lesion segmentation to achieve the state-of-the-art\nperformance for missing modality. We present a novel method dubbed ModDrop++ to\ntrain a unified network adaptive to an arbitrary number of input MRI sequences.\nMoreover, ModDrop++ can be easily applied to any existing model architectures.\nSpecifically, ModDrop++ upgrades the main idea of ModDrop in two key ways.\nFirst, we devise a plug-and-play dynamic head and adopt a filter scaling\nstrategy to improve the expressiveness of the network. Second, we design a\nco-training strategy to leverage the intra-subject relation between full\nmodality and missing modality. In particular, the intra-subject co-training\nstrategy aims to guide the dynamic head to generate similar feature\nrepresentations between the full- and missing-modality data from the same\nsubject. We use two public MS datasets to show the superiority of ModDrop++.\nSource code and trained models are available at\nhttps://github.com/han-liu/ModDropPlusPlus.",
    "descriptor": "",
    "authors": [
      "Han Liu",
      "Yubo Fan",
      "Hao Li",
      "Jiacheng Wang",
      "Dewei Hu",
      "Can Cui",
      "Ho Hin Lee",
      "Ipek Oguz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04959"
  },
  {
    "id": "arXiv:2203.04960",
    "title": "Memory-augmented Deep Unfolding Network for Guided Image  Super-resolution",
    "abstract": "Guided image super-resolution (GISR) aims to obtain a high-resolution (HR)\ntarget image by enhancing the spatial resolution of a low-resolution (LR)\ntarget image under the guidance of a HR image. However, previous model-based\nmethods mainly takes the entire image as a whole, and assume the prior\ndistribution between the HR target image and the HR guidance image, simply\nignoring many non-local common characteristics between them. To alleviate this\nissue, we firstly propose a maximal a posterior (MAP) estimation model for GISR\nwith two types of prior on the HR target image, i.e., local implicit prior and\nglobal implicit prior. The local implicit prior aims to model the complex\nrelationship between the HR target image and the HR guidance image from a local\nperspective, and the global implicit prior considers the non-local\nauto-regression property between the two images from a global perspective.\nSecondly, we design a novel alternating optimization algorithm to solve this\nmodel for GISR. The algorithm is in a concise framework that facilitates to be\nreplicated into commonly used deep network structures. Thirdly, to reduce the\ninformation loss across iterative stages, the persistent memory mechanism is\nintroduced to augment the information representation by exploiting the Long\nshort-term memory unit (LSTM) in the image and feature spaces. In this way, a\ndeep network with certain interpretation and high representation ability is\nbuilt. Extensive experimental results validate the superiority of our method on\na variety of GISR tasks, including Pan-sharpening, depth image\nsuper-resolution, and MR image super-resolution.",
    "descriptor": "\nComments: 24 pages, 16 figures\n",
    "authors": [
      "Man Zhou",
      "Keyu Yan",
      "Jinshan Pan",
      "Wenqi Ren",
      "Qi Xie",
      "Xiangyong Cao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04960"
  },
  {
    "id": "arXiv:2203.04961",
    "title": "Sharing Generative Models Instead of Private Data: A Simulation Study on  Mammography Patch Classification",
    "abstract": "Early detection of breast cancer in mammography screening via deep-learning\nbased computer-aided detection systems shows promising potential in improving\nthe curability and mortality rates of breast cancer. However, many clinical\ncentres are restricted in the amount and heterogeneity of available data to\ntrain such models to (i) achieve promising performance and to (ii) generalise\nwell across acquisition protocols and domains. As sharing data between centres\nis restricted due to patient privacy concerns, we propose a potential solution:\nsharing trained generative models between centres as substitute for real\npatient data. In this work, we use three well known mammography datasets to\nsimulate three different centres, where one centre receives the trained\ngenerator of Generative Adversarial Networks (GANs) from the two remaining\ncentres in order to augment the size and heterogeneity of its training dataset.\nWe evaluate the utility of this approach on mammography patch classification on\nthe test set of the GAN-receiving centre using two different classification\nmodels, (a) a convolutional neural network and (b) a transformer neural\nnetwork. Our experiments demonstrate that shared GANs notably increase the\nperformance of both transformer and convolutional classification models and\nhighlight this approach as a viable alternative to inter-centre data sharing.",
    "descriptor": "\nComments: Draft accepted as oral presentation at International Workshop on Breast Imaging (IWBI) 2022. 9 pages, 3 figures\n",
    "authors": [
      "Zuzanna Szafranowska",
      "Richard Osuala",
      "Bennet Breier",
      "Kaisar Kushibar",
      "Karim Lekadir",
      "Oliver Diaz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04961"
  },
  {
    "id": "arXiv:2203.04962",
    "title": "Learning the Degradation Distribution for Blind Image Super-Resolution",
    "abstract": "Synthetic high-resolution (HR) \\& low-resolution (LR) pairs are widely used\nin existing super-resolution (SR) methods. To avoid the domain gap between\nsynthetic and test images, most previous methods try to adaptively learn the\nsynthesizing (degrading) process via a deterministic model. However, some\ndegradations in real scenarios are stochastic and cannot be determined by the\ncontent of the image. These deterministic models may fail to model the random\nfactors and content-independent parts of degradations, which will limit the\nperformance of the following SR models. In this paper, we propose a\nprobabilistic degradation model (PDM), which studies the degradation\n$\\mathbf{D}$ as a random variable, and learns its distribution by modeling the\nmapping from a priori random variable $\\mathbf{z}$ to $\\mathbf{D}$. Compared\nwith previous deterministic degradation models, PDM could model more diverse\ndegradations and generate HR-LR pairs that may better cover the various\ndegradations of test images, and thus prevent the SR model from over-fitting to\nspecific ones. Extensive experiments have demonstrated that our degradation\nmodel can help the SR model achieve better performance on different datasets.\nThe source codes are released at \\url{git@github.com:greatlog/UnpairedSR.git}.",
    "descriptor": "\nComments: Accepted to CVRP2022\n",
    "authors": [
      "Zhengxiong Luo",
      "Yan Huang",
      "Shang Li",
      "Liang Wang",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04962"
  },
  {
    "id": "arXiv:2203.04963",
    "title": "Neural Data-Dependent Transform for Learned Image Compression",
    "abstract": "Learned image compression has achieved great success due to its excellent\nmodeling capacity, but seldom further considers the Rate-Distortion\nOptimization (RDO) of each input image. To explore this potential in the\nlearned codec, we make the first attempt to build a neural data-dependent\ntransform and introduce a continuous online mode decision mechanism to jointly\noptimize the coding efficiency for each individual image. Specifically, apart\nfrom the image content stream, we employ an additional model stream to generate\nthe transform parameters at the decoder side. The presence of a model stream\nenables our model to learn more abstract neural-syntax, which helps cluster the\nlatent representations of images more compactly. Beyond the transform stage, we\nalso adopt neural-syntax based post-processing for the scenarios that require\nhigher quality reconstructions regardless of extra decoding overhead. Moreover,\nthe involvement of the model stream further makes it possible to optimize both\nthe representation and the decoder in an online way, i.e. RDO at the testing\ntime. It is equivalent to a continuous online mode decision, like coding modes\nin the traditional codecs, to improve the coding efficiency based on the\nindividual input image. The experimental results show the effectiveness of the\nproposed neural-syntax design and the continuous online mode decision\nmechanism, demonstrating the superiority of our method in coding efficiency\ncompared to the latest conventional standard Versatile Video Coding (VVC) and\nother state-of-the-art learning-based methods.",
    "descriptor": "\nComments: Accepted by CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Dezhao Wang",
      "Wenhan Yang",
      "Yueyu Hu",
      "Jiaying Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04963"
  },
  {
    "id": "arXiv:2203.04964",
    "title": "Metastatic Cancer Outcome Prediction with Injective Multiple Instance  Pooling",
    "abstract": "Cancer stage is a large determinant of patient prognosis and management in\nmany cancer types, and is often assessed using medical imaging modalities, such\nas CT and MRI. These medical images contain rich information that can be\nexplored to stratify patients within each stage group to further improve\nprognostic algorithms. Although the majority of cancer deaths result from\nmetastatic and multifocal disease, building imaging biomarkers for patients\nwith multiple tumors has been a challenging task due to the lack of annotated\ndatasets and standard study framework. In this paper, we process two public\ndatasets to set up a benchmark cohort of 341 patient in total for studying\noutcome prediction of multifocal metastatic cancer. We identify the lack of\nexpressiveness in common multiple instance classification networks and propose\ntwo injective multiple instance pooling functions that are better suited to\noutcome prediction. Our results show that multiple instance learning with\ninjective pooling functions can achieve state-of-the-art performance in the\nnon-small-cell lung cancer CT and head and neck CT outcome prediction\nbenchmarking tasks. We will release the processed multifocal datasets, our code\nand the intermediate files i.e. extracted radiomic features to support further\ntransparent and reproducible research.",
    "descriptor": "",
    "authors": [
      "Jianan Chen",
      "Anne L. Martel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04964"
  },
  {
    "id": "arXiv:2203.04967",
    "title": "UNeXt: MLP-based Rapid Medical Image Segmentation Network",
    "abstract": "UNet and its latest extensions like TransUNet have been the leading medical\nimage segmentation methods in recent years. However, these networks cannot be\neffectively adopted for rapid image segmentation in point-of-care applications\nas they are parameter-heavy, computationally complex and slow to use. To this\nend, we propose UNeXt which is a Convolutional multilayer perceptron (MLP)\nbased network for image segmentation. We design UNeXt in an effective way with\nan early convolutional stage and a MLP stage in the latent stage. We propose a\ntokenized MLP block where we efficiently tokenize and project the convolutional\nfeatures and use MLPs to model the representation. To further boost the\nperformance, we propose shifting the channels of the inputs while feeding in to\nMLPs so as to focus on learning local dependencies. Using tokenized MLPs in\nlatent space reduces the number of parameters and computational complexity\nwhile being able to result in a better representation to help segmentation. The\nnetwork also consists of skip connections between various levels of encoder and\ndecoder. We test UNeXt on multiple medical image segmentation datasets and show\nthat we reduce the number of parameters by 72x, decrease the computational\ncomplexity by 68x, and improve the inference speed by 10x while also obtaining\nbetter segmentation performance over the state-of-the-art medical image\nsegmentation architectures. Code is available at\nhttps://github.com/jeya-maria-jose/UNeXt-pytorch",
    "descriptor": "\nComments: Tech Report\n",
    "authors": [
      "Jeya Maria Jose Valanarasu",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04967"
  },
  {
    "id": "arXiv:2203.04989",
    "title": "Generalised entropy accumulation",
    "abstract": "Consider a sequential process in which each step outputs a system $A_i$ and\nupdates a side information register $E$. We prove that if this process\nsatisfies a natural \"non-signalling\" condition between past outputs and future\nside information, the min-entropy of the outputs $A_1, \\dots, A_n$ conditioned\non the side information $E$ at the end of the process can be bounded from below\nby a sum of von Neumann entropies associated with the individual steps. This is\na generalisation of the entropy accumulation theorem (EAT), which deals with a\nmore restrictive model of side information: there, past side information cannot\nbe updated in subsequent rounds, and newly generated side information has to\nsatisfy a Markov condition. Due to its more general model of side-information,\nour generalised EAT can be applied more easily and to a broader range of\ncryptographic protocols. As examples, we give the first multi-round security\nproof for blind randomness expansion and a simplified analysis of the E91 QKD\nprotocol. The proof of our generalised EAT relies on a new variant of Uhlmann's\ntheorem and new chain rules for the Renyi divergence and entropy, which might\nbe of independent interest.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Tony Metger",
      "Omar Fawzi",
      "David Sutter",
      "Renato Renner"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.04989"
  },
  {
    "id": "arXiv:2203.05086",
    "title": "Detecting and Diagnosing Terrestrial Gravitational-Wave Mimics Through  Feature Learning",
    "abstract": "As engineered systems grow in complexity, there is an increasing need for\nautomatic methods that can detect, diagnose, and even correct transient\nanomalies that inevitably arise and can be difficult or impossible to diagnose\nand fix manually. Among the most sensitive and complex systems of our\ncivilization are the detectors that search for incredibly small variations in\ndistance caused by gravitational waves -- phenomena originally predicted by\nAlbert Einstein to emerge and propagate through the universe as the result of\ncollisions between black holes and other massive objects in deep space. The\nextreme complexity and precision of such detectors causes them to be subject to\ntransient noise issues that can significantly limit their sensitivity and\neffectiveness.\nIn this work, we present a demonstration of a method that can detect and\ncharacterize emergent transient anomalies of such massively complex systems. We\nillustrate the performance, precision, and adaptability of the automated\nsolution via one of the prevalent issues limiting gravitational-wave\ndiscoveries: noise artifacts of terrestrial origin that contaminate\ngravitational wave observatories' highly sensitive measurements and can obscure\nor even mimic the faint astrophysical signals for which they are listening.\nSpecifically, we demonstrate how a highly interpretable convolutional\nclassifier can automatically learn to detect transient anomalies from auxiliary\ndetector data without needing to observe the anomalies themselves. We also\nillustrate several other useful features of the model, including how it\nperforms automatic variable selection to reduce tens of thousands of auxiliary\ndata channels to only a few relevant ones; how it identifies behavioral\nsignatures predictive of anomalies in those channels; and how it can be used to\ninvestigate individual anomalies and the channels associated with them.",
    "descriptor": "",
    "authors": [
      "Robert E. Colgan",
      "Zsuzsa M\u00e1rka",
      "Jingkai Yan",
      "Imre Bartos",
      "John N. Wright",
      "Szabolcs M\u00e1rka"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2203.05086"
  },
  {
    "id": "arXiv:2203.05093",
    "title": "Sampling from the Sherrington-Kirkpatrick Gibbs measure via algorithmic  stochastic localization",
    "abstract": "We consider the Sherrington-Kirkpatrick model of spin glasses at\nhigh-temperature and no external field, and study the problem of sampling from\nthe Gibbs distribution $\\mu$ in polynomial time. We prove that, for any inverse\ntemperature $\\beta<1/2$, there exists an algorithm with complexity $O(n^2)$\nthat samples from a distribution $\\mu^{alg}$ which is close in normalized\nWasserstein distance to $\\mu$. Namely, there exists a coupling of $\\mu$ and\n$\\mu^{alg}$ such that if $(x,x^{alg})\\in\\{-1,+1\\}^n\\times \\{-1,+1\\}^n$ is a\npair drawn from this coupling, then $n^{-1}\\mathbb\nE\\{||x-x^{alg}||_2^2\\}=o_n(1)$. The best previous results, by Bauerschmidt and\nBodineau and by Eldan, Koehler, and Zeitouni, implied efficient algorithms to\napproximately sample (under a stronger metric) for $\\beta<1/4$.\nWe complement this result with a negative one, by introducing a suitable\n\"stability\" property for sampling algorithms, which is verified by many\nstandard techniques. We prove that no stable algorithm can approximately sample\nfor $\\beta>1$, even under the normalized Wasserstein metric.\nOur sampling method is based on an algorithmic implementation of stochastic\nlocalization, which progressively tilts the measure $\\mu$ towards a single\nconfiguration, together with an approximate message passing algorithm that is\nused to approximate the mean of the tilted measure.",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Ahmed El Alaoui",
      "Andrea Montanari",
      "Mark Sellke"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.05093"
  },
  {
    "id": "arXiv:2203.05117",
    "title": "Optimal Methods for Risk Averse Distributed Optimization",
    "abstract": "This paper studies the communication complexity of risk averse optimization\nover a network. The problem generalizes the well-studied risk-neutral\nfinite-sum distributed optimization problem and its importance stems from the\nneed to handle risk in an uncertain environment. For algorithms in the\nliterature, there exists a gap in communication complexities for solving\nrisk-averse and risk-neutral problems. We propose two distributed algorithms,\nnamely the distributed risk averse optimization (DRAO) method and the\ndistributed risk averse optimization with sliding (DRAO-S) method, to close the\ngap. Specifically, the DRAO method achieves the optimal communication\ncomplexity by assuming a certain saddle point subproblem can be easily solved\nin the server node. The DRAO-S method removes the strong assumption by\nintroducing a novel saddle point sliding subroutine which only requires the\nprojection over the ambiguity set $P$. We observe that the number of\n$P$-projections performed by DRAO-S is optimal. Moreover, we develop matching\nlower complexity bounds to show that communication complexities of both DRAO\nand DRAO-S are not improvable. Numerical experiments are conducted to\ndemonstrate the encouraging empirical performance of the DRAO-S method.",
    "descriptor": "",
    "authors": [
      "Gaunghui Lan",
      "Zhe Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05117"
  },
  {
    "id": "arXiv:2203.05127",
    "title": "Action-Constrained Reinforcement Learning for Frame-Level Bit Allocation  in HEVC/H.265 through Frank-Wolfe Policy Optimization",
    "abstract": "This paper presents a reinforcement learning (RL) framework that leverages\nFrank-Wolfe policy optimization to address frame-level bit allocation for\nHEVC/H.265. Most previous RL-based approaches adopt the single-critic design,\nwhich weights the rewards for distortion minimization and rate regularization\nby an empirically chosen hyper-parameter. More recently, the dual-critic design\nis proposed to update the actor network by alternating the rate and distortion\ncritics. However, the convergence of training is not guaranteed. To address\nthis issue, we introduce Neural Frank-Wolfe Policy Optimization (NFWPO) in\nformulating the frame-level bit allocation as an action-constrained RL problem.\nIn this new framework, the rate critic serves to specify a feasible action set,\nand the distortion critic updates the actor network towards maximizing the\nreconstruction quality while conforming to the action constraint. Experimental\nresults show that when trained to optimize the video multi-method assessment\nfusion (VMAF) metric, our NFWPO-based model outperforms both the single-critic\nand the dual-critic methods. It also demonstrates comparable rate-distortion\nperformance to the 2-pass average bit rate control of x265.",
    "descriptor": "",
    "authors": [
      "Yung-Han Ho",
      "Yun Liang",
      "Chia-Hao Kao",
      "Wen-Hsiao Peng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05127"
  },
  {
    "id": "arXiv:2203.05130",
    "title": "The Waiting-Time Distribution for Network Partitions in Cascading  Failures in Power Networks",
    "abstract": "Network redundancy is one of the spatial network structural properties\ncritical to robustness against cascading failures in power networks. The\nwaiting-time distributions for network partitions in cascading failures explain\nhow the spatial network structures affect the cascading behaviors. Two waiting\ntime events associated with the first and largest network partitions are\nstudied for cascading failures under different network redundancies. With the\nsynthetic power networks, the waiting-time distributions of network partitions\ncan be systematically analyzed for various network redundancies. Waiting-time\ndistributions shift to the right accordingly when network redundancies\nincrease. Meanwhile, the sizes of the largest partitions decrease while the\nnumbers of them increase statistically. The realistic power networks of France,\nTexas, and Poland also show the same trend for waiting-time distributions.",
    "descriptor": "",
    "authors": [
      "Long Huo",
      "Xin Chen"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05130"
  },
  {
    "id": "arXiv:2203.05174",
    "title": "Assessing Phenotype Definitions for Algorithmic Fairness",
    "abstract": "Disease identification is a core, routine activity in observational health\nresearch. Cohorts impact downstream analyses, such as how a condition is\ncharacterized, how patient risk is defined, and what treatments are studied. It\nis thus critical to ensure that selected cohorts are representative of all\npatients, independently of their demographics or social determinants of health.\nWhile there are multiple potential sources of bias when constructing phenotype\ndefinitions which may affect their fairness, it is not standard in the field of\nphenotyping to consider the impact of different definitions across subgroups of\npatients. In this paper, we propose a set of best practices to assess the\nfairness of phenotype definitions. We leverage established fairness metrics\ncommonly used in predictive models and relate them to commonly used\nepidemiological cohort description metrics. We describe an empirical study for\nCrohn's disease and diabetes type 2, each with multiple phenotype definitions\ntaken from the literature across two sets of patient subgroups (gender and\nrace). We show that the different phenotype definitions exhibit widely varying\nand disparate performance according to the different fairness metrics and\nsubgroups. We hope that the proposed best practices can help in constructing\nfair and inclusive phenotype definitions.",
    "descriptor": "\nComments: Conference on Health, Inference, and Learning (CHIL) 2022 - Invited non-archival presentation\n",
    "authors": [
      "Tony Y. Sun",
      "Shreyas Bhave",
      "Jaan Altosaar",
      "No\u00e9mie Elhadad"
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05174"
  },
  {
    "id": "arXiv:2203.05245",
    "title": "Data-driven Control of Unknown Linear Systems via Quantized Feedback",
    "abstract": "Control using quantized feedback is a fundamental approach to system\nsynthesis with limited communication capacity. In this paper, we address the\nstabilization problem for unknown linear systems with logarithmically quantized\nfeedback, via a direct data-driven control method. By leveraging a recently\ndeveloped matrix S-lemma, we prove a sufficient and necessary condition for the\nexistence of a common stabilizing controller for all possible dynamics\nconsistent with data, in the form of a linear matrix inequality. Moreover, we\nformulate semi-definite programming to solve the coarsest quantization density.\nBy establishing its connections to unstable eigenvalues of the state matrix, we\nfurther prove a necessary rank condition on the data for quantized feedback\nstabilization. Finally, we validate our theoretical results by numerical\nexamples.",
    "descriptor": "\nComments: To appear at the 4th Annual Conference on Learning for Dynamics and Control\n",
    "authors": [
      "Feiran Zhao",
      "Xingchen Li",
      "Keyou You"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05245"
  },
  {
    "id": "arXiv:2203.05250",
    "title": "On the computational properties of basic mathematical notions",
    "abstract": "We investigate the computational properties of basic mathematical notions\npertaining to $\\mathbb{R}\\rightarrow \\mathbb{R}$-functions and subsets of\n$\\mathbb{R}$, like finiteness, countability, (absolute) continuity, bounded\nvariation, suprema, and regularity. We work in higher-order computability\ntheory based on Kleene's S1-S9 schemes. We show that the aforementioned\nitalicised properties give rise to two huge and robust classes of\ncomputationally equivalent operations, the latter based on well-known theorems\nfrom the mainstream mathematics literature. As part of this endeavour, we\ndevelop an equivalent $\\lambda$-calculus formulation of S1-S9 that accommodates\npartial objects. We show that the latter are essential to our enterprise via\nthe study of countably based and partial functionals of type $3$. We also\nexhibit a connection to \\emph{infinite time} Turing machines.",
    "descriptor": "",
    "authors": [
      "Dag Normann",
      "Sam Sanders"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.05250"
  },
  {
    "id": "arXiv:2203.05265",
    "title": "Echo-enabled Direction-of-Arrival and range estimation of a mobile  source in Ambisonic domain",
    "abstract": "Range estimation of a far field sound source in a reverberant environment is\nknown to be a notoriously difficult problem, hence most localization methods\nare only capable of estimating the source's Direction-of-Arrival (DoA). In an\nearlier work, we have demonstrated that, under certain restrictive acoustic\nconditions and given the orientation of a reflecting surface, one can exploit\nthe dominant acoustic reflection to evaluate the DoA \\emph{and} the distance to\na static sound source in Ambisonic domain. In this article, we leverage the\nrecently presented Generalized Time-domain Velocity Vector (GTVV)\nrepresentation to estimate these quantities for a moving sound source without\nan a priori knowledge of reflectors' orientations. We show that the\ntrajectories of a moving source and the corresponding reflections are spatially\nand temporally related, which can be used to infer the absolute delay of the\npropagating source signal and, therefore, approximate the microphone-to-source\ndistance. Experiments on real sound data confirm the validity of the proposed\napproach.",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "J\u00e9r\u00f4me Daniel",
      "Sr\u0111an Kiti\u0107"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.05265"
  },
  {
    "id": "arXiv:2203.05288",
    "title": "Compliance with restrictive measures during the COVID-19 pandemic in  Europe: Does political partisanship influence behavioural responses?",
    "abstract": "The success of public health policies aimed at curtailing the COVID-19\npandemic have relied on large-scale and protracted compliance by the public. A\nseries of studies have recently argued that previous voting patterns are\nimportant predictors of such compliance. Our research further investigates such\nconnection by tracking the relationships between parties' vote shares and\nmobility in six European countries over an extended period of time. We observe\nthat while vote shares are occasionally related to variations in mobility\nwithin each country, there is no systematic pattern of decrease or increase in\nmobility across all six selected countries depending on party family or\ngovernment membership. Over time, the relationships between mobility and vote\nshares tend to grow stronger in some but not all countries, again suggesting\nthat there is no clear connection between vote shares for several party\nfamilies and compliance with social distancing measures.",
    "descriptor": "",
    "authors": [
      "Stefano Maria Iacus",
      "Marco Scipioni",
      "Spyridon Spyratos",
      "Guido Tintori"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.05288"
  },
  {
    "id": "arXiv:2203.05298",
    "title": "Synchronizing Boolean networks asynchronously",
    "abstract": "The {\\em asynchronous automaton} associated with a Boolean network\n$f:\\{0,1\\}^n\\to\\{0,1\\}^n$, considered in many applications, is the finite\ndeterministic automaton where the set of states is $\\{0,1\\}^n$, the alphabet is\n$[n]$, and the action of letter $i$ on a state $x$ consists in either switching\nthe $i$th component if $f_i(x)\\neq x_i$ or doing nothing otherwise. These\nactions are extended to words in the natural way. A word is then {\\em\nsynchronizing} if the result of its action is the same for every state. In this\npaper, we ask for the existence of synchronizing words, and their minimal\nlength, for a basic class of Boolean networks called and-or-nets: given an\narc-signed digraph $G$ on $[n]$, we say that $f$ is an {\\em and-or-net} on $G$\nif, for every $i\\in [n]$, there is $a$ such that, for all state $x$, $f_i(x)=a$\nif and only if $x_j=a$ ($x_j\\neq a$) for every positive (negative) arc from $j$\nto $i$; so if $a=1$ ($a=0$) then $f_i$ is a conjunction (disjunction) of\npositive or negative literals. Our main result is that if $G$ is strongly\nconnected and has no positive cycles, then either every and-or-net on $G$ has a\nsynchronizing word of length at most $10(\\sqrt{5}+1)^n$, much smaller than the\nbound $(2^n-1)^2$ given by the well known \\v{C}ern\\'y's conjecture, or $G$ is a\ncycle and no and-or-net on $G$ has a synchronizing word. This contrasts with\nthe following complexity result: it is coNP-hard to decide if every and-or-net\non $G$ has a synchronizing word, even if $G$ is strongly connected or has no\npositive cycles.",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Julio Aracena",
      "Adrien Richard",
      "Lilian Salinas"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.05298"
  },
  {
    "id": "arXiv:2203.05363",
    "title": "Differentially Private Learning Needs Hidden State (Or Much Faster  Convergence)",
    "abstract": "Differential privacy analysis of randomized learning algorithms typically\nrelies on composition theorems, where the implicit assumption is that the\ninternal state of the iterative algorithm is revealed to the adversary.\nHowever, by assuming hidden states for DP algorithms (when only the\nlast-iterate is observable), recent works prove a converging privacy bound for\nnoisy gradient descent (on strongly convex smooth loss function) that is\nsignificantly smaller than composition bounds after $O(1/\\text{step-size})$\nepochs. In this paper, we extend this hidden-state analysis to the noisy\nmini-batch stochastic gradient descent algorithms on strongly-convex smooth\nloss functions. We prove converging R\\'enyi DP bounds under various mini-batch\nsampling schemes, such as \"shuffle and partition\" (which are used in practical\nimplementations of DP-SGD) and \"sampling without replacement\". We prove that,\nin these settings, our privacy bound is much smaller than the composition bound\nfor training with a large number of iterations (which is the case for learning\nfrom high-dimensional data). Our converging privacy analysis, thus, shows that\ndifferentially private learning, with a tight bound, needs hidden state privacy\nanalysis or a fast convergence. To complement our theoretical results, we run\nexperiment on training classification models on MNIST, FMNIST and CIFAR-10\ndatasets, and observe a better accuracy given fixed privacy budgets, under the\nhidden-state analysis.",
    "descriptor": "",
    "authors": [
      "Jiayuan Ye",
      "Reza Shokri"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05363"
  },
  {
    "id": "arXiv:2203.05383",
    "title": "KSoF: The Kassel State of Fluency Dataset -- A Therapy Centered Dataset  of Stuttering",
    "abstract": "Stuttering is a complex speech disorder that negatively affects an\nindividual's ability to communicate effectively. Persons who stutter (PWS)\noften suffer considerably under the condition and seek help through therapy.\nFluency shaping is a therapy approach where PWSs learn to modify their speech\nto help them to overcome their stutter. Mastering such speech techniques takes\ntime and practice, even after therapy. Shortly after therapy, success is\nevaluated highly, but relapse rates are high. To be able to monitor speech\nbehavior over a long time, the ability to detect stuttering events and\nmodifications in speech could help PWSs and speech pathologists to track the\nlevel of fluency. Monitoring could create the ability to intervene early by\ndetecting lapses in fluency. To the best of our knowledge, no public dataset is\navailable that contains speech from people who underwent stuttering therapy\nthat changed the style of speaking. This work introduces the Kassel State of\nFluency (KSoF), a therapy-based dataset containing over 5500 clips of PWSs. The\nclips were labeled with six stuttering-related event types: blocks,\nprolongations, sound repetitions, word repetitions, interjections, and -\nspecific to therapy - speech modifications. The audio was recorded during\ntherapy sessions at the Institut der Kasseler Stottertherapie. The data will be\nmade available for research purposes upon request.",
    "descriptor": "\nComments: Submitted to LREC 2022 Conference on Language Resources and Evaluation\n",
    "authors": [
      "Sebastian P. Bayerl",
      "Alexander Wolff von Gudenberg",
      "Florian H\u00f6nig",
      "Elmar N\u00f6th",
      "Korbinian Riedhammer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05383"
  },
  {
    "id": "arXiv:2203.05400",
    "title": "Asymptotic Bounds for Smoothness Parameter Estimates in Gaussian Process  Regression",
    "abstract": "It is common to model a deterministic response function, such as the output\nof a computer experiment, as a Gaussian process with a Mat\\'ern covariance\nkernel. The smoothness parameter of a Mat\\'ern kernel determines many important\nproperties of the model in the large data limit, such as the rate of\nconvergence of the conditional mean to the response function. We prove that the\nmaximum likelihood and cross-validation estimates of the smoothness parameter\ncannot asymptotically undersmooth the truth when the data are obtained on a\nfixed bounded subset of $\\mathbb{R}^d$. That is, if the data-generating\nresponse function has Sobolev smoothness $\\nu_0 + d/2$, then the smoothness\nparameter estimates cannot remain below $\\nu_0$ as more data are obtained.\nThese results are based on a general theorem, proved using reproducing kernel\nHilbert space techniques, about sets of values the parameter estimates cannot\ntake and approximation theory in Sobolev spaces.",
    "descriptor": "\nComments: -\n",
    "authors": [
      "Toni Karvonen"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.05400"
  },
  {
    "id": "arXiv:2203.05407",
    "title": "Blind Extraction of Equitable Partitions from Graph Signals",
    "abstract": "Finding equitable partitions is closely related to the extraction of graph\nsymmetries and of interest in a variety of applications context such as node\nrole detection, cluster synchronization, consensus dynamics, and network\ncontrol problems. In this work we study a blind identification problem in which\nwe aim to recover an equitable partition of a network without the knowledge of\nthe network's edges but based solely on the observations of the outputs of an\nunknown graph filter. Specifically, we consider two settings. First, we\nconsider a scenario in which we can control the input to the graph filter and\npresent a method to extract the partition inspired by the well known\nWeisfeiler-Lehman (color refinement) algorithm. Second, we generalize this idea\nto a setting where only observe the outputs to random, low-rank excitations of\nthe graph filter, and present a simple spectral algorithm to extract the\nrelevant equitable partitions. Finally, we establish theoretical bounds on the\nerror that this spectral detection scheme incurs and perform numerical\nexperiments that illustrate our theoretical results and compare both\nalgorithms.",
    "descriptor": "\nComments: 8 pages, IEEE ICASSP 2022\n",
    "authors": [
      "Michael Scholkemper",
      "Michael Schaub"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.05407"
  },
  {
    "id": "arXiv:2203.05417",
    "title": "Deep Regression Ensembles",
    "abstract": "We introduce a methodology for designing and training deep neural networks\n(DNN) that we call \"Deep Regression Ensembles\" (DRE). It bridges the gap\nbetween DNN and two-layer neural networks trained with random feature\nregression. Each layer of DRE has two components, randomly drawn input weights\nand output weights trained myopically (as if the final output layer) using\nlinear ridge regression. Within a layer, each neuron uses a different subset of\ninputs and a different ridge penalty, constituting an ensemble of random\nfeature ridge regressions. Our experiments show that a single DRE architecture\nis at par with or exceeds state-of-the-art DNN in many data sets. Yet, because\nDRE neural weights are either known in closed-form or randomly drawn, its\ncomputational cost is orders of magnitude smaller than DNN.",
    "descriptor": "",
    "authors": [
      "Antoine Didisheim",
      "Bryan Kelly",
      "Semyon Malamud"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05417"
  },
  {
    "id": "arXiv:2203.05431",
    "title": "RACIMO@Bucaramanga: A Citizen Science Project on Data Science and  Climate Awareness",
    "abstract": "This paper describes a collaborative experience to empower organized\ncommunities to produce, curate and disseminate environmental data. A particular\nemphasis is done on the description of open hardware & software architecture\nand the processes of commissioning of the low cost Arduino-Raspberry-Pi weather\nstation which measures: atmospheric pressure, temperature, humidity,\nprecipitation, cloudiness, and illuminance/irradiance. The idea is to encourage\nmore people to replicate this open-science initiative. We have started this\nexperience training students & teachers from seven mid secondary schools\nthrough a syllabus of 12 two-hours lectures with a web-based support which\nexposes them to basic concepts and practices of Citizen Science and Open Data\nScience.",
    "descriptor": "",
    "authors": [
      "J. Pe\u00f1a-Rodr\u00edguez",
      "P. A. Salgado-Meza",
      "H. Asorey",
      "L. A. N\u00fa\u00f1ez",
      "A. N\u00fa\u00f1ez-Casti\u00f1eyra",
      "C. Sarmiento-Cano",
      "M. Su\u00e1rez-Dur\u00e1n"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05431"
  },
  {
    "id": "arXiv:2203.05443",
    "title": "Bias-variance decomposition of overparameterized regression with random  linear features",
    "abstract": "In classical statistics, the bias-variance trade-off describes how varying a\nmodel's complexity (e.g., number of fit parameters) affects its ability to make\naccurate predictions. According to this trade-off, optimal performance is\nachieved when a model is expressive enough to capture trends in the data, yet\nnot so complex that it overfits idiosyncratic features of the training data.\nRecently, it has become clear that this classic understanding of the\nbias-variance must be fundamentally revisited in light of the incredible\npredictive performance of \"overparameterized models\" -- models that avoid\noverfitting even when the number of fit parameters is large enough to perfectly\nfit the training data. Here, we present results for one of the simplest\nexamples of an overparameterized model: regression with random linear features\n(i.e. a two-layer neural network with a linear activation function). Using the\nzero-temperature cavity method, we derive analytic expressions for the training\nerror, test error, bias, and variance. We show that the linear random features\nmodel exhibits three phase transitions: two different transitions to an\ninterpolation regime where the training error is zero, along with an additional\ntransition between regimes with large bias and minimal bias. Using random\nmatrix theory, we show how each transition arises due to small nonzero\neigenvalues in the Hessian matrix. Finally, we compare and contrast the phase\ndiagram of the random linear features model to the random nonlinear features\nmodel and ordinary regression, highlighting the new phase transitions that\nresult from the use of linear basis functions.",
    "descriptor": "\nComments: 10 pages (double column), 3 figures, 11 pages of appendices (single column)\n",
    "authors": [
      "Jason W. Rocks",
      "Pankaj Mehta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05443"
  },
  {
    "id": "arXiv:2203.05511",
    "title": "Multi-Party Quantum Purity Distillation with Bounded Classical  Communication",
    "abstract": "We consider the task of distilling local purity from a noisy quantum state\n$\\rho^{ABC}$, wherein we provide a protocol for three parties, Alice, Bob and\nCharlie, to distill local purity (at a rate $P$) from many independent copies\nof a given quantum state $\\rho^{ABC}$. The three parties have access to their\nrespective subsystems of $\\rho^{ABC}$, and are provided with pure ancilla\ncatalytically, i.e., with the promise of returning them unaltered after the end\nof the protocol. In addition, Alice and Bob can communicate with Charlie using\na one-way multiple-access dephasing channel of link rates $R_1$ and $R_2$,\nrespectively. The objective of the protocol is to minimize the usage of the\ndephasing channel (in terms of rates $R_1$ and $R_2$) while maximizing the\nasymptotic purity that can be jointly distilled from $\\rho^{ABC}$. To achieve\nthis, we employ ideas from distributed measurement compression protocols, and\nin turn, characterize a set of sufficient conditions on $(P,R_1,R_2)$ in terms\nof quantum information theoretic quantities such that $P$ amount of purity can\nbe distilled using rates $R_1$ and $R_2$. Finally, we also incorporate the\ntechnique of asymptotic algebraic structured coding, and provide a unified\napproach of characterizing the performance limits.",
    "descriptor": "",
    "authors": [
      "Touheed Anwar Atif",
      "S. Sandeep Pradhan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.05511"
  },
  {
    "id": "arXiv:2203.05548",
    "title": "LiDAR Aided Future Beam Prediction in Real-World Millimeter Wave V2I  Communications",
    "abstract": "This paper presents the first large-scale real-world evaluation for using\nLiDAR data to guide the mmWave beam prediction task. A machine learning (ML)\nmodel that leverages the LiDAR sensory data to predict the current and future\nbeams was developed. Based on the large-scale real-world dataset, DeepSense 6G,\nthis model was evaluated in a vehicle-to-infrastructure communication scenario\nwith highly-mobile vehicles. The experimental results show that the developed\nLiDAR-aided beam prediction and tracking model can predict the optimal beam in\n$95\\%$ of the cases and with more than $90\\%$ reduction in the beam training\noverhead. The LiDAR-aided beam tracking achieves comparable accuracy\nperformance to a baseline solution that has perfect knowledge of the previous\noptimal beams, without requiring any knowledge about the previous optimal beam\ninformation and without any need for beam calibration. This highlights a\npromising solution for the critical beam alignment challenges in mmWave and\nterahertz communication systems.",
    "descriptor": "\nComments: The dataset and code files will be available on the DeepSense 6G website this https URL\n",
    "authors": [
      "Shuaifeng Jiang",
      "Gouranga Charan",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.05548"
  },
  {
    "id": "arXiv:1403.5617",
    "title": "On the Rise and Fall of Online Social Networks",
    "abstract": "On the Rise and Fall of Online Social Networks",
    "descriptor": "",
    "authors": [
      "Arnab Basu",
      "Saswata Shannigrahi",
      "Simrat Singh Chhabra",
      "Ajit Brundavanam"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/1403.5617"
  },
  {
    "id": "arXiv:1902.10890",
    "title": "Supervised ML Solution for Band Assignment in Dual-Band Systems with  Omnidirectional and Directional Antennas",
    "abstract": "Comments: 16 pages, 11 figures, 6 tables",
    "descriptor": "\nComments: 16 pages, 11 figures, 6 tables\n",
    "authors": [
      "Daoud Burghal",
      "Rui Wang",
      "Abdullah Alghafis",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1902.10890"
  },
  {
    "id": "arXiv:1905.02682",
    "title": "The complexity of MinRank",
    "abstract": "Comments: Final version. Theorem numbering adjusted to match the published version",
    "descriptor": "\nComments: Final version. Theorem numbering adjusted to match the published version\n",
    "authors": [
      "Alessio Caminata",
      "Elisa Gorla"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1905.02682"
  },
  {
    "id": "arXiv:1909.03339",
    "title": "On the complexity of counting feedback arc sets",
    "abstract": "On the complexity of counting feedback arc sets",
    "descriptor": "",
    "authors": [
      "Kevin Perrot"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/1909.03339"
  },
  {
    "id": "arXiv:2002.08853",
    "title": "A General Pairwise Comparison Model for Extremely Sparse Networks",
    "abstract": "Comments: 33 pages, 1 figure, 1 table",
    "descriptor": "\nComments: 33 pages, 1 figure, 1 table\n",
    "authors": [
      "Ruijian Han",
      "Yiming Xu",
      "Kani Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2002.08853"
  },
  {
    "id": "arXiv:2004.02534",
    "title": "Weakly and Strongly Aperiodic Subshifts of Finite Type on  Baumslag-Solitar Groups",
    "abstract": "Comments: New version with better proofs. Removed a subsection on \"shift-similar\" substitutions, as the definition was not as interesting as we first thought. Most of the results of this subsection were therefore not that helpful in understanding substitutions that can be \"embedded\" into BS(1,n)",
    "descriptor": "\nComments: New version with better proofs. Removed a subsection on \"shift-similar\" substitutions, as the definition was not as interesting as we first thought. Most of the results of this subsection were therefore not that helpful in understanding substitutions that can be \"embedded\" into BS(1,n)\n",
    "authors": [
      "Julien Esnay",
      "Etienne Moutot"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Discrete Mathematics (cs.DM)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2004.02534"
  },
  {
    "id": "arXiv:2005.03350",
    "title": "A Locally Adaptive Interpretable Regression",
    "abstract": "A Locally Adaptive Interpretable Regression",
    "descriptor": "",
    "authors": [
      "Lkhagvadorj Munkhdalai",
      "Tsendsuren Munkhdalai",
      "Keun Ho Ryu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.03350"
  },
  {
    "id": "arXiv:2007.03875",
    "title": "KQA Pro: A Dataset with Explicit Compositional Programs for Complex  Question Answering over Knowledge Base",
    "abstract": "KQA Pro: A Dataset with Explicit Compositional Programs for Complex  Question Answering over Knowledge Base",
    "descriptor": "",
    "authors": [
      "Shulin Cao",
      "Jiaxin Shi",
      "Liangming Pan",
      "Lunyiu Nie",
      "Yutong Xiang",
      "Lei Hou",
      "Juanzi Li",
      "Bin He",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2007.03875"
  },
  {
    "id": "arXiv:2008.06340",
    "title": "On the finite representation of group equivariant operators via  permutant measures",
    "abstract": "Comments: We have extended the introduction, providing more context about our approach, and the discussion. We have also added Section 4, showing possible advantages of the use of GENEOs built by permutant measures. The experiment described in Section 4 has been made by Giovanni Bocchi. For this reason, he has been added to the list of authors of the paper",
    "descriptor": "\nComments: We have extended the introduction, providing more context about our approach, and the discussion. We have also added Section 4, showing possible advantages of the use of GENEOs built by permutant measures. The experiment described in Section 4 has been made by Giovanni Bocchi. For this reason, he has been added to the list of authors of the paper\n",
    "authors": [
      "Giovanni Bocchi",
      "Stefano Botteghi",
      "Martina Brasini",
      "Patrizio Frosini",
      "Nicola Quercioli"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Machine Learning (cs.LG)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2008.06340"
  },
  {
    "id": "arXiv:2011.04976",
    "title": "Conceptual Compression via Deep Structure and Texture Synthesis",
    "abstract": "Comments: 15 pages, 14 figures",
    "descriptor": "\nComments: 15 pages, 14 figures\n",
    "authors": [
      "Jianhui Chang",
      "Zhenghui Zhao",
      "Chuanmin Jia",
      "Shiqi Wang",
      "Lingbo Yang",
      "Qi Mao",
      "Jian Zhang",
      "Siwei Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2011.04976"
  },
  {
    "id": "arXiv:2011.13913",
    "title": "Progressively Volumetrized Deep Generative Models for Data-Efficient  Contextual Learning of MR Image Recovery",
    "abstract": "Progressively Volumetrized Deep Generative Models for Data-Efficient  Contextual Learning of MR Image Recovery",
    "descriptor": "",
    "authors": [
      "Mahmut Yurt",
      "Muzaffer \u00d6zbey",
      "Salman Ul Hassan Dar",
      "Berk T\u0131naz",
      "Kader Karl\u0131 O\u011fuz",
      "Tolga \u00c7ukur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.13913"
  },
  {
    "id": "arXiv:2101.02023",
    "title": "Perfect domination, Roman domination and perfect Roman domination in  lexicographic product graphs",
    "abstract": "Perfect domination, Roman domination and perfect Roman domination in  lexicographic product graphs",
    "descriptor": "",
    "authors": [
      "A. Cabrera Martinez",
      "C. Garcia-Gomez",
      "J. A. Rodriguez-Velazquez"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2101.02023"
  },
  {
    "id": "arXiv:2101.02776",
    "title": "The Nonconvex Geometry of Linear Inverse Problems",
    "abstract": "The Nonconvex Geometry of Linear Inverse Problems",
    "descriptor": "",
    "authors": [
      "Armin Eftekhari",
      "Peyman Mohajerin Esfahani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2101.02776"
  },
  {
    "id": "arXiv:2101.05417",
    "title": "High-order FDTD schemes for Maxwell's interface problems with  discontinuous coefficients and complex interfaces based on the Correction  Function Method",
    "abstract": "Comments: 27 pages, 12 figures",
    "descriptor": "\nComments: 27 pages, 12 figures\n",
    "authors": [
      "Yann-Meing Law",
      "Jean-Christophe Nave"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2101.05417"
  },
  {
    "id": "arXiv:2101.07491",
    "title": "Automated Verification and Synthesis of Stochastic Hybrid Systems: A  Survey",
    "abstract": "Automated Verification and Synthesis of Stochastic Hybrid Systems: A  Survey",
    "descriptor": "",
    "authors": [
      "Abolfazl Lavaei",
      "Sadegh Soudjani",
      "Alessandro Abate",
      "Majid Zamani"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.07491"
  },
  {
    "id": "arXiv:2101.08936",
    "title": "Numerical Methods for Backward Stochastic Differential Equations: A  Survey",
    "abstract": "Comments: 38 pages",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Jared Chessari",
      "Reiichiro Kawai",
      "Yuji Shinozaki",
      "Toshihiro Yamada"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2101.08936"
  },
  {
    "id": "arXiv:2101.10862",
    "title": "HANA: A HAndwritten NAme Database for Offline Handwritten Text  Recognition",
    "abstract": "HANA: A HAndwritten NAme Database for Offline Handwritten Text  Recognition",
    "descriptor": "",
    "authors": [
      "Christian M. Dahl",
      "Torben Johansen",
      "Emil N. S\u00f8rensen",
      "Simon Wittrock"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2101.10862"
  },
  {
    "id": "arXiv:2102.09136",
    "title": "From Extreme Multi-label to Multi-class: A Hierarchical Approach for  Automated ICD-10 Coding Using Phrase-level Attention",
    "abstract": "From Extreme Multi-label to Multi-class: A Hierarchical Approach for  Automated ICD-10 Coding Using Phrase-level Attention",
    "descriptor": "",
    "authors": [
      "Cansu Sen",
      "Bingyang Ye",
      "Javed Aslam",
      "Amir Tahmasebi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.09136"
  },
  {
    "id": "arXiv:2102.10104",
    "title": "Arena-Independent Finite-Memory Determinacy in Stochastic Games",
    "abstract": "Comments: Full version of CONCUR 2021 conference paper. 46 pages, 4 figures",
    "descriptor": "\nComments: Full version of CONCUR 2021 conference paper. 46 pages, 4 figures\n",
    "authors": [
      "Patricia Bouyer",
      "Youssouf Oualhadj",
      "Mickael Randour",
      "Pierre Vandenhove"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.10104"
  },
  {
    "id": "arXiv:2103.10858",
    "title": "Toward Compact Deep Neural Networks via Energy-Aware Pruning",
    "abstract": "Comments: 10 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 10 pages, 5 figures, 3 tables\n",
    "authors": [
      "Seul-Ki Yeom",
      "Kyung-Hwan Shim",
      "Jee-Hyun Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10858"
  },
  {
    "id": "arXiv:2103.11773",
    "title": "Computationally Efficient Learning of Statistical Manifolds",
    "abstract": "Comments: 29 pages, 10 figures",
    "descriptor": "\nComments: 29 pages, 10 figures\n",
    "authors": [
      "Fan Cheng",
      "Anastasios Panagiotelis",
      "Rob J Hyndman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2103.11773"
  },
  {
    "id": "arXiv:2104.02705",
    "title": "deepregression: a Flexible Neural Network Framework for Semi-Structured  Deep Distributional Regression",
    "abstract": "deepregression: a Flexible Neural Network Framework for Semi-Structured  Deep Distributional Regression",
    "descriptor": "",
    "authors": [
      "David R\u00fcgamer",
      "Chris Kolb",
      "Cornelius Fritz",
      "Florian Pfisterer",
      "Philipp Kopper",
      "Bernd Bischl",
      "Ruolin Shen",
      "Christina Bukas",
      "Lisa Barros de Andrade e Sousa",
      "Dominik Thalmeier",
      "Philipp Baumann",
      "Lucas Kook",
      "Nadja Klein",
      "Christian L. M\u00fcller"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2104.02705"
  },
  {
    "id": "arXiv:2104.05128",
    "title": "A Scalable Algorithm for Decentralized Actor Termination Detection",
    "abstract": "A Scalable Algorithm for Decentralized Actor Termination Detection",
    "descriptor": "",
    "authors": [
      "Dan Plyukhin",
      "Gul Agha"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.05128"
  },
  {
    "id": "arXiv:2104.05711",
    "title": "The world-wide waste web",
    "abstract": "Comments: Nat Commun (2022). Main manuscript, and supplementary information. Total of 15 figures and 58 pages",
    "descriptor": "\nComments: Nat Commun (2022). Main manuscript, and supplementary information. Total of 15 figures and 58 pages\n",
    "authors": [
      "Johann H. Mart\u00ednez",
      "Sergi Romero",
      "Jos\u00e9 J. Ramasco",
      "Ernesto Estrada"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.05711"
  },
  {
    "id": "arXiv:2104.07091",
    "title": "SummScreen: A Dataset for Abstractive Screenplay Summarization",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Mingda Chen",
      "Zewei Chu",
      "Sam Wiseman",
      "Kevin Gimpel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.07091"
  },
  {
    "id": "arXiv:2104.08696",
    "title": "Knowledge Neurons in Pretrained Transformers",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Damai Dai",
      "Li Dong",
      "Yaru Hao",
      "Zhifang Sui",
      "Baobao Chang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08696"
  },
  {
    "id": "arXiv:2104.10823",
    "title": "Resilient Ramp Control for Highways Facing Stochastic Perturbations",
    "abstract": "Resilient Ramp Control for Highways Facing Stochastic Perturbations",
    "descriptor": "",
    "authors": [
      "Yu Tang",
      "Li Jin",
      "Alexander A. Kurzhanskiy",
      "Saurabh Amin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.10823"
  },
  {
    "id": "arXiv:2104.11667",
    "title": "Deep Learning for Bayesian Optimization of Scientific Problems with  High-Dimensional Structure",
    "abstract": "Comments: 25 pages, 11 figures; updated results and discussion",
    "descriptor": "\nComments: 25 pages, 11 figures; updated results and discussion\n",
    "authors": [
      "Samuel Kim",
      "Peter Y. Lu",
      "Charlotte Loh",
      "Jamie Smith",
      "Jasper Snoek",
      "Marin Solja\u010di\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)",
      "Chemical Physics (physics.chem-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2104.11667"
  },
  {
    "id": "arXiv:2105.01990",
    "title": "Evaluation Of Word Embeddings From Large-Scale French Web Content",
    "abstract": "Evaluation Of Word Embeddings From Large-Scale French Web Content",
    "descriptor": "",
    "authors": [
      "Hadi Abdine",
      "Christos Xypolopoulos",
      "Moussa Kamal Eddine",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.01990"
  },
  {
    "id": "arXiv:2105.07465",
    "title": "SLGPT: Using Transfer Learning to Directly Generate Simulink Model Files  and Find Bugs in the Simulink Toolchain",
    "abstract": "Comments: Changes from published version: In Algorithm 1, while condition in line 1 changed from \"and\" to \"or\"",
    "descriptor": "\nComments: Changes from published version: In Algorithm 1, while condition in line 1 changed from \"and\" to \"or\"\n",
    "authors": [
      "Sohil Lal Shrestha",
      "Christoph Csallner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.07465"
  },
  {
    "id": "arXiv:2105.09169",
    "title": "Everything You Always Wanted to Know About Generalization of Proof  Obligations in PDR",
    "abstract": "Everything You Always Wanted to Know About Generalization of Proof  Obligations in PDR",
    "descriptor": "",
    "authors": [
      "Tobias Seufert",
      "Felix Winterer",
      "Christoph Scholl",
      "Karsten Scheibler",
      "Tobias Paxian",
      "Bernd Becker"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.09169"
  },
  {
    "id": "arXiv:2106.00706",
    "title": "A Non-stiff Summation-By-Parts Finite Difference Method for the Wave  Equation in Second Order Form: Characteristic Boundary Conditions and  Nonlinear Interfaces",
    "abstract": "Comments: 40 pages, 7 figures",
    "descriptor": "\nComments: 40 pages, 7 figures\n",
    "authors": [
      "Jeremy E Kozdon",
      "Brittany A Erickson",
      "Tobias Harvey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00706"
  },
  {
    "id": "arXiv:2106.00942",
    "title": "JUMBO: Scalable Multi-task Bayesian Optimization using Offline Data",
    "abstract": "JUMBO: Scalable Multi-task Bayesian Optimization using Offline Data",
    "descriptor": "",
    "authors": [
      "Kourosh Hakhamaneshi",
      "Pieter Abbeel",
      "Vladimir Stojanovic",
      "Aditya Grover"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00942"
  },
  {
    "id": "arXiv:2106.04928",
    "title": "Reliable Adversarial Distillation with Unreliable Teachers",
    "abstract": "Comments: ICLR2022",
    "descriptor": "\nComments: ICLR2022\n",
    "authors": [
      "Jianing Zhu",
      "Jiangchao Yao",
      "Bo Han",
      "Jingfeng Zhang",
      "Tongliang Liu",
      "Gang Niu",
      "Jingren Zhou",
      "Jianliang Xu",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04928"
  },
  {
    "id": "arXiv:2106.04949",
    "title": "On the Analysis of the Second Order Time Filtered Backward Euler Method  for the EMAC formulation of Navier-Stokes Equations",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Medine Demir",
      "Aytekin \u00c7\u0131b\u0131k",
      "Song\u00fcl Kaya"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.04949"
  },
  {
    "id": "arXiv:2106.05763",
    "title": "A Deep Variational Approach to Clustering Survival Data",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Laura Manduchi",
      "Ri\u010dards Marcinkevi\u010ds",
      "Michela C. Massi",
      "Thomas Weikert",
      "Alexander Sauter",
      "Verena Gotta",
      "Timothy M\u00fcller",
      "Flavio Vasella",
      "Marian C. Neidert",
      "Marc Pfister",
      "Bram Stieltjes",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.05763"
  },
  {
    "id": "arXiv:2106.12996",
    "title": "Sparse Multi-Reference Alignment : Phase Retrieval, Uniform Uncertainty  Principles and the Beltway Problem",
    "abstract": "Sparse Multi-Reference Alignment : Phase Retrieval, Uniform Uncertainty  Principles and the Beltway Problem",
    "descriptor": "",
    "authors": [
      "Subhro Ghosh",
      "Philippe Rigollet"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.12996"
  },
  {
    "id": "arXiv:2106.14636",
    "title": "Asymptotic Degradation of Linear Regression Estimates With Strategic  Data Sources",
    "abstract": "Comments: 30 pages, 7 figures",
    "descriptor": "\nComments: 30 pages, 7 figures\n",
    "authors": [
      "Benjamin Roussillon",
      "Nicolas Gast",
      "Patrick Loiseau",
      "Panayotis Mertikopoulos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.14636"
  },
  {
    "id": "arXiv:2107.01241",
    "title": "Temporal Regular Path Queries",
    "abstract": "Temporal Regular Path Queries",
    "descriptor": "",
    "authors": [
      "Marcelo Arenas",
      "Pedro Bahamondes",
      "Amir Aghasadeghi",
      "Julia Stoyanovich"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.01241"
  },
  {
    "id": "arXiv:2107.03234",
    "title": "Quadratic and Higher-Order Unconstrained Binary Optimization of Railway  Rescheduling for Quantum Computing",
    "abstract": "Quadratic and Higher-Order Unconstrained Binary Optimization of Railway  Rescheduling for Quantum Computing",
    "descriptor": "",
    "authors": [
      "Krzysztof Domino",
      "Akash Kundu",
      "\u00d6zlem Salehi",
      "Krzysztof Krawiec"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Systems and Control (eess.SY)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.03234"
  },
  {
    "id": "arXiv:2107.08981",
    "title": "Hierarchical Few-Shot Imitation with Skill Transition Models",
    "abstract": "Hierarchical Few-Shot Imitation with Skill Transition Models",
    "descriptor": "",
    "authors": [
      "Kourosh Hakhamaneshi",
      "Ruihan Zhao",
      "Albert Zhan",
      "Pieter Abbeel",
      "Michael Laskin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.08981"
  },
  {
    "id": "arXiv:2107.10869",
    "title": "Filament Plots for Data Visualization",
    "abstract": "Comments: 43 pages, 13 figures; newest version updates plots, clarifies some terminology, and clarifies proofs",
    "descriptor": "\nComments: 43 pages, 13 figures; newest version updates plots, clarifies some terminology, and clarifies proofs\n",
    "authors": [
      "Nate Strawn"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.10869"
  },
  {
    "id": "arXiv:2107.11022",
    "title": "AD-GAN: End-to-end Unsupervised Nuclei Segmentation with Aligned  Disentangling Training",
    "abstract": "AD-GAN: End-to-end Unsupervised Nuclei Segmentation with Aligned  Disentangling Training",
    "descriptor": "",
    "authors": [
      "Kai Yao",
      "Kaizhu Huang",
      "Jie Sun",
      "Curran Jude"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.11022"
  },
  {
    "id": "arXiv:2108.04002",
    "title": "Preparing for Performance Analysis at Exascale",
    "abstract": "Comments: 10 pages, 6 figures and 5 tables. Revised version submitted to IPDPS'22",
    "descriptor": "\nComments: 10 pages, 6 figures and 5 tables. Revised version submitted to IPDPS'22\n",
    "authors": [
      "Jonathon Anderson",
      "Yumeng Liu",
      "John Mellor-Crummey"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2108.04002"
  },
  {
    "id": "arXiv:2108.04314",
    "title": "Malware-on-the-Brain: Illuminating Malware Byte Codes with Images for  Malware Classification",
    "abstract": "Malware-on-the-Brain: Illuminating Malware Byte Codes with Images for  Malware Classification",
    "descriptor": "",
    "authors": [
      "Fangtian Zhong",
      "Zekai Chen",
      "Minghui Xu",
      "Guoming Zhang",
      "Dongxiao Yu",
      "Xiuzhen Cheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.04314"
  },
  {
    "id": "arXiv:2108.05560",
    "title": "Patchwork: Concentric Zone-based Region-wise Ground Segmentation with  Ground Likelihood Estimation Using a 3D LiDAR Sensor",
    "abstract": "Patchwork: Concentric Zone-based Region-wise Ground Segmentation with  Ground Likelihood Estimation Using a 3D LiDAR Sensor",
    "descriptor": "",
    "authors": [
      "Hyungtae Lim",
      "Minho Oh",
      "Hyun Myung"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.05560"
  },
  {
    "id": "arXiv:2108.05769",
    "title": "Enhanced Multi-Resolution Analysis for Multi-Dimensional Data Utilizing  Line Filtering Techniques",
    "abstract": "Comments: Submitted to SISC",
    "descriptor": "\nComments: Submitted to SISC\n",
    "authors": [
      "Matthew J. Picklo",
      "Jennifer K. Ryan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.05769"
  },
  {
    "id": "arXiv:2108.06116",
    "title": "Topology optimization for acoustic structures considering viscous and  thermal boundary layers using a sequential linearized Navier-Stokes model",
    "abstract": "Topology optimization for acoustic structures considering viscous and  thermal boundary layers using a sequential linearized Navier-Stokes model",
    "descriptor": "",
    "authors": [
      "Yuki Noguchi",
      "Takayuki Yamada"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2108.06116"
  },
  {
    "id": "arXiv:2109.01064",
    "title": "Lower Bounds on the Total Variation Distance Between Mixtures of Two  Gaussians",
    "abstract": "Comments: 22 pages, 1 figure; Accepted to ALT 2022",
    "descriptor": "\nComments: 22 pages, 1 figure; Accepted to ALT 2022\n",
    "authors": [
      "Sami Davies",
      "Arya Mazumdar",
      "Soumyabrata Pal",
      "Cyrus Rashtchian"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2109.01064"
  },
  {
    "id": "arXiv:2109.06709",
    "title": "QKD parameter estimation by two-universal hashing leads to faster  convergence to the asymptotic rate",
    "abstract": "QKD parameter estimation by two-universal hashing leads to faster  convergence to the asymptotic rate",
    "descriptor": "",
    "authors": [
      "Dimiter Ostrev"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06709"
  },
  {
    "id": "arXiv:2109.07962",
    "title": "Stochastic modelling of symmetric positive-definite material tensors",
    "abstract": "Stochastic modelling of symmetric positive-definite material tensors",
    "descriptor": "",
    "authors": [
      "Sharana Kumar Shivanand",
      "Bojana Rosi\u0107",
      "Hermann G. Matthies"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2109.07962"
  },
  {
    "id": "arXiv:2109.08599",
    "title": "Taxonomy and Survey on Remote Human Input Systems for Driving Automation  Systems",
    "abstract": "Comments: Accepted for publication at FICC 2022",
    "descriptor": "\nComments: Accepted for publication at FICC 2022\n",
    "authors": [
      "Daniel Bogdoll",
      "Stefan Orf",
      "Lars T\u00f6ttel",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.08599"
  },
  {
    "id": "arXiv:2109.08618",
    "title": "A review and experimental evaluation of deep learning methods for MRI  reconstruction",
    "abstract": "Comments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging 2022:2022:001. pp 1-58 Submitted 09/2021; Published 02/2022",
    "descriptor": "\nComments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging 2022:2022:001. pp 1-58 Submitted 09/2021; Published 02/2022\n",
    "authors": [
      "Arghya Pal",
      "Yogesh Rathi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.08618"
  },
  {
    "id": "arXiv:2109.09884",
    "title": "ShapeMap 3-D: Efficient shape mapping through dense touch and vision",
    "abstract": "Comments: Camera-ready version for the 2022 IEEE International Conference on Robotics and Automation (ICRA 2022). Modified PDF title",
    "descriptor": "\nComments: Camera-ready version for the 2022 IEEE International Conference on Robotics and Automation (ICRA 2022). Modified PDF title\n",
    "authors": [
      "Sudharshan Suresh",
      "Zilin Si",
      "Joshua G. Mangelson",
      "Wenzhen Yuan",
      "Michael Kaess"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.09884"
  },
  {
    "id": "arXiv:2109.09934",
    "title": "Balancing Control and Pose Optimization for Wheel-legged Robots  Navigating High Obstacles",
    "abstract": "Comments: 7 pages, 8 figures, preprint submitted to IROS 2022 with RAL option",
    "descriptor": "\nComments: 7 pages, 8 figures, preprint submitted to IROS 2022 with RAL option\n",
    "authors": [
      "Junheng Li",
      "Junchao Ma",
      "Quan Nguyen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.09934"
  },
  {
    "id": "arXiv:2109.10967",
    "title": "Learning Contrastive Representation for Semantic Correspondence",
    "abstract": "Learning Contrastive Representation for Semantic Correspondence",
    "descriptor": "",
    "authors": [
      "Taihong Xiao",
      "Sifei Liu",
      "Shalini De Mello",
      "Zhiding Yu",
      "Jan Kautz",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.10967"
  },
  {
    "id": "arXiv:2109.11410",
    "title": "Learning to Robustly Aggregate Labeling Functions for Semi-supervised  Data Programming",
    "abstract": "Comments: Findings of ACL, 2022",
    "descriptor": "\nComments: Findings of ACL, 2022\n",
    "authors": [
      "Ayush Maheshwari",
      "Krishnateja Killamsetty",
      "Ganesh Ramakrishnan",
      "Rishabh Iyer",
      "Marina Danilevsky",
      "Lucian Popa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.11410"
  },
  {
    "id": "arXiv:2109.11723",
    "title": "Distributed Deep Reinforcement Learning for Adaptive Medium Access and  Modulation in Shared Spectrum",
    "abstract": "Comments: Will not be appearing in IEEE TCCN. A shorter version will appear in a conference later in 2022",
    "descriptor": "\nComments: Will not be appearing in IEEE TCCN. A shorter version will appear in a conference later in 2022\n",
    "authors": [
      "Akash Doshi",
      "Jeffrey G. Andrews"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.11723"
  },
  {
    "id": "arXiv:2109.13132",
    "title": "Optimization Landscape of Gradient Descent for Discrete-time Static  Output Feedback",
    "abstract": "Optimization Landscape of Gradient Descent for Discrete-time Static  Output Feedback",
    "descriptor": "",
    "authors": [
      "Jingliang Duan",
      "Jie Li",
      "Shengbo Eben Li",
      "Lin Zhao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.13132"
  },
  {
    "id": "arXiv:2110.00429",
    "title": "Topologically-Informed Atlas Learning",
    "abstract": "Comments: Accepted to the 2022 IEEE International Conference on Robotics and Automation (ICRA). Contact: Thomas Cohn, cohnt@umich.edu",
    "descriptor": "\nComments: Accepted to the 2022 IEEE International Conference on Robotics and Automation (ICRA). Contact: Thomas Cohn, cohnt@umich.edu\n",
    "authors": [
      "Thomas Cohn",
      "Nikhil Devraj",
      "Odest Chadwicke Jenkins"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00429"
  },
  {
    "id": "arXiv:2110.02195",
    "title": "TensorPlan and the Few Actions Lower Bound for Planning in MDPs under  Linear Realizability of Optimal Value Functions",
    "abstract": "TensorPlan and the Few Actions Lower Bound for Planning in MDPs under  Linear Realizability of Optimal Value Functions",
    "descriptor": "",
    "authors": [
      "Gell\u00e9rt Weisz",
      "Csaba Szepesv\u00e1ri",
      "Andr\u00e1s Gy\u00f6rgy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02195"
  },
  {
    "id": "arXiv:2110.02498",
    "title": "Adversarial Attacks on Machinery Fault Diagnosis",
    "abstract": "Comments: 5 pages, 5 figures. Submitted to Interspeech 2022",
    "descriptor": "\nComments: 5 pages, 5 figures. Submitted to Interspeech 2022\n",
    "authors": [
      "Jiahao Chen",
      "Diqun Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02498"
  },
  {
    "id": "arXiv:2110.02807",
    "title": "Fitting Distances by Tree Metrics Minimizing the Total Error within a  Constant Factor",
    "abstract": "Comments: Postprint, Accepted to FOCS 2021",
    "descriptor": "\nComments: Postprint, Accepted to FOCS 2021\n",
    "authors": [
      "Vincent Cohen-Addad",
      "Debarati Das",
      "Evangelos Kipouridis",
      "Nikos Parotsidis",
      "Mikkel Thorup"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02807"
  },
  {
    "id": "arXiv:2110.03485",
    "title": "Cartoon Explanations of Image Classifiers",
    "abstract": "Cartoon Explanations of Image Classifiers",
    "descriptor": "",
    "authors": [
      "Stefan Kolek",
      "Duc Anh Nguyen",
      "Ron Levie",
      "Joan Bruna",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03485"
  },
  {
    "id": "arXiv:2110.04447",
    "title": "EfficientPhys: Enabling Simple, Fast and Accurate Camera-Based Vitals  Measurement",
    "abstract": "EfficientPhys: Enabling Simple, Fast and Accurate Camera-Based Vitals  Measurement",
    "descriptor": "",
    "authors": [
      "Xin Liu",
      "Brian L. Hill",
      "Ziheng Jiang",
      "Shwetak Patel",
      "Daniel McDuff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04447"
  },
  {
    "id": "arXiv:2110.04966",
    "title": "Revisit Dictionary Learning for Video Compressive Sensing under the  Plug-and-Play Framework",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Qing Yang",
      "Yaping Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.04966"
  },
  {
    "id": "arXiv:2110.05603",
    "title": "Generalizing to New Domains by Mapping Natural Language to Lifted LTL",
    "abstract": "Comments: 7 pages (6 + 1 references page), 3 figures, 2 tables. Accepted to ICRA 2022. To appear in Proceedings of the 2022 International Conference on Robotics and Automation, May 2022",
    "descriptor": "\nComments: 7 pages (6 + 1 references page), 3 figures, 2 tables. Accepted to ICRA 2022. To appear in Proceedings of the 2022 International Conference on Robotics and Automation, May 2022\n",
    "authors": [
      "Eric Hsiung",
      "Hiloni Mehta",
      "Junchi Chu",
      "Xinyu Liu",
      "Roma Patel",
      "Stefanie Tellex",
      "George Konidaris"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05603"
  },
  {
    "id": "arXiv:2110.05743",
    "title": "Program Transfer for Answering Complex Questions over Knowledge Bases",
    "abstract": "Program Transfer for Answering Complex Questions over Knowledge Bases",
    "descriptor": "",
    "authors": [
      "Shulin Cao",
      "Jiaxin Shi",
      "Zijun Yao",
      "Xin Lv",
      "Jifan Yu",
      "Lei Hou",
      "Juanzi Li",
      "Zhiyuan Liu",
      "Jinghui Xiao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05743"
  },
  {
    "id": "arXiv:2110.06123",
    "title": "COVID-19 Diagnosis from Cough Acoustics using ConvNets and Data  Augmentation",
    "abstract": "Comments: DiCOVA, top 1st",
    "descriptor": "\nComments: DiCOVA, top 1st\n",
    "authors": [
      "Saranga Kingkor Mahanta",
      "Darsh Kaushik",
      "Shubham Jain",
      "Hoang Van Truong",
      "Koushik Guha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06123"
  },
  {
    "id": "arXiv:2110.06764",
    "title": "Contact-timing and Trajectory Optimization for 3D Jumping on Quadruped  Robots",
    "abstract": "Comments: 7 pages, 11 figures",
    "descriptor": "\nComments: 7 pages, 11 figures\n",
    "authors": [
      "Chuong Nguyen",
      "Quan Nguyen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06764"
  },
  {
    "id": "arXiv:2110.07855",
    "title": "Hierarchical Curriculum Learning for AMR Parsing",
    "abstract": "Hierarchical Curriculum Learning for AMR Parsing",
    "descriptor": "",
    "authors": [
      "Peiyi Wang",
      "Liang Chen",
      "Tianyu Liu",
      "Damai Dai",
      "Yunbo Cao",
      "Baobao Chang",
      "Zhifang Sui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.07855"
  },
  {
    "id": "arXiv:2110.08300",
    "title": "The Dangers of Underclaiming: Reasons for Caution When Reporting How NLP  Systems Fail",
    "abstract": "Comments: Proceedings of ACL 2022",
    "descriptor": "\nComments: Proceedings of ACL 2022\n",
    "authors": [
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08300"
  },
  {
    "id": "arXiv:2110.08464",
    "title": "Seeking Patterns, Not just Memorizing Procedures: Contrastive Learning  for Solving Math Word Problems",
    "abstract": "Comments: Accepted to ACL 2022",
    "descriptor": "\nComments: Accepted to ACL 2022\n",
    "authors": [
      "Zhongli Li",
      "Wenxuan Zhang",
      "Chao Yan",
      "Qingyu Zhou",
      "Chao Li",
      "Hongzhi Liu",
      "Yunbo Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08464"
  },
  {
    "id": "arXiv:2110.12746",
    "title": "Planning for Risk-Aversion and Expected Value in MDPs",
    "abstract": "Comments: Accepted to ICAPS 2022",
    "descriptor": "\nComments: Accepted to ICAPS 2022\n",
    "authors": [
      "Marc Rigter",
      "Paul Duckworth",
      "Bruno Lacerda",
      "Nick Hawes"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12746"
  },
  {
    "id": "arXiv:2110.13464",
    "title": "MarS-FL: Enabling Competitors to Collaborate in Federated Learning",
    "abstract": "MarS-FL: Enabling Competitors to Collaborate in Federated Learning",
    "descriptor": "",
    "authors": [
      "Xiaohu Wu",
      "Han Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.13464"
  },
  {
    "id": "arXiv:2110.13532",
    "title": "Playing Coopetitive Polymatrix Games with Small Manipulation Cost",
    "abstract": "Playing Coopetitive Polymatrix Games with Small Manipulation Cost",
    "descriptor": "",
    "authors": [
      "Shivakumar Mahesh",
      "Nicholas Bishop",
      "Le Cong Dinh",
      "Long Tran-Thanh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.13532"
  },
  {
    "id": "arXiv:2111.00232",
    "title": "MFNet: Multi-class Few-shot Segmentation Network with Pixel-wise Metric  Learning",
    "abstract": "MFNet: Multi-class Few-shot Segmentation Network with Pixel-wise Metric  Learning",
    "descriptor": "",
    "authors": [
      "Miao Zhang",
      "Miaojing Shi",
      "Li Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00232"
  },
  {
    "id": "arXiv:2111.03390",
    "title": "Stress-informed Control of Medium- and High-head Hydropower Plants to  Reduce Penstock Fatigue",
    "abstract": "Stress-informed Control of Medium- and High-head Hydropower Plants to  Reduce Penstock Fatigue",
    "descriptor": "",
    "authors": [
      "Stefano Cassano",
      "Fabrizio Sossan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.03390"
  },
  {
    "id": "arXiv:2111.05055",
    "title": "MAC-ReconNet: A Multiple Acquisition Context based Convolutional Neural  Network for MR Image Reconstruction using Dynamic Weight Prediction",
    "abstract": "MAC-ReconNet: A Multiple Acquisition Context based Convolutional Neural  Network for MR Image Reconstruction using Dynamic Weight Prediction",
    "descriptor": "",
    "authors": [
      "Sriprabha Ramanarayanan",
      "Balamurali Murugesan",
      "Keerthi Ram",
      "Mohanasankar Sivaprakasam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.05055"
  },
  {
    "id": "arXiv:2111.07867",
    "title": "Faster-than-Nyquist Signaling for MIMO Communications",
    "abstract": "Comments: Have been submitted to IEEE transactions on wireless communications",
    "descriptor": "\nComments: Have been submitted to IEEE transactions on wireless communications\n",
    "authors": [
      "Zichao Zhang",
      "Melda Yuksel",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.07867"
  },
  {
    "id": "arXiv:2111.08492",
    "title": "SequentialPointNet: A strong frame-level parallel point cloud sequence  network for 3D action recognition",
    "abstract": "SequentialPointNet: A strong frame-level parallel point cloud sequence  network for 3D action recognition",
    "descriptor": "",
    "authors": [
      "Xing Li",
      "Qian Huang",
      "Zhijian Wang",
      "Zhenjie Hou",
      "Tianjin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08492"
  },
  {
    "id": "arXiv:2111.08954",
    "title": "TraSw: Tracklet-Switch Adversarial Attacks against Multi-Object Tracking",
    "abstract": "TraSw: Tracklet-Switch Adversarial Attacks against Multi-Object Tracking",
    "descriptor": "",
    "authors": [
      "Delv Lin",
      "Qi Chen",
      "Chengyu Zhou",
      "Kun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08954"
  },
  {
    "id": "arXiv:2111.09136",
    "title": "IntraQ: Learning Synthetic Images with Intra-Class Heterogeneity for  Zero-Shot Network Quantization",
    "abstract": "Comments: CVPR2022",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Yunshan Zhong",
      "Mingbao Lin",
      "Gongrui Nan",
      "Jianzhuang Liu",
      "Baochang Zhang",
      "Yonghong Tian",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09136"
  },
  {
    "id": "arXiv:2111.09815",
    "title": "Improving Prediction-Based Lossy Compression Dramatically Via  Ratio-Quality Modeling",
    "abstract": "Comments: 14 pages, 14 figures, under revision in submission to ICDE 2022",
    "descriptor": "\nComments: 14 pages, 14 figures, under revision in submission to ICDE 2022\n",
    "authors": [
      "Sian Jin",
      "Sheng Di",
      "Jiannan Tian",
      "Suren Byna",
      "Dingwen Tao",
      "Franck Cappello"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.09815"
  },
  {
    "id": "arXiv:2111.11191",
    "title": "Deep Learning Based Automated COVID-19 Classification from Computed  Tomography Images",
    "abstract": "Deep Learning Based Automated COVID-19 Classification from Computed  Tomography Images",
    "descriptor": "",
    "authors": [
      "Kenan Morani",
      "Devrim Unay"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11191"
  },
  {
    "id": "arXiv:2111.12476",
    "title": "Hierarchical Modular Network for Video Captioning",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Hanhua Ye",
      "Guorong Li",
      "Yuankai Qi",
      "Shuhui Wang",
      "Qingming Huang",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12476"
  },
  {
    "id": "arXiv:2111.13359",
    "title": "Neural Collaborative Graph Machines for Table Structure Recognition",
    "abstract": "Comments: Accepted to CVPR2022",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Hao Liu",
      "Xin Li",
      "Bing Liu",
      "Deqiang Jiang",
      "Yinsong Liu",
      "Bo Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13359"
  },
  {
    "id": "arXiv:2111.14377",
    "title": "Collective Intelligence for Deep Learning: A Survey of Recent  Developments",
    "abstract": "Collective Intelligence for Deep Learning: A Survey of Recent  Developments",
    "descriptor": "",
    "authors": [
      "David Ha",
      "Yujin Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.14377"
  },
  {
    "id": "arXiv:2111.14820",
    "title": "Towards Robust and Adaptive Motion Forecasting: A Causal Representation  Perspective",
    "abstract": "Comments: CVPR 2022. Code is available at this https URL",
    "descriptor": "\nComments: CVPR 2022. Code is available at this https URL\n",
    "authors": [
      "Yuejiang Liu",
      "Riccardo Cadei",
      "Jonas Schweizer",
      "Sherwin Bahmani",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.14820"
  },
  {
    "id": "arXiv:2111.15141",
    "title": "Path Integral Sampler: a stochastic control approach for sampling",
    "abstract": "Comments: iclr submission",
    "descriptor": "\nComments: iclr submission\n",
    "authors": [
      "Qinsheng Zhang",
      "Yongxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15141"
  },
  {
    "id": "arXiv:2111.15640",
    "title": "Diffusion Autoencoders: Toward a Meaningful and Decodable Representation",
    "abstract": "Comments: Please visit our project page: this https URL",
    "descriptor": "\nComments: Please visit our project page: this https URL\n",
    "authors": [
      "Konpat Preechakul",
      "Nattanat Chatthee",
      "Suttisak Wizadwongsa",
      "Supasorn Suwajanakorn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15640"
  },
  {
    "id": "arXiv:2112.01252",
    "title": "Australia's Approach to AI Governance in Security and Defence",
    "abstract": "Comments: 60 pages, 7 boxes, 2 figures, 2 annexes, submitted for Eds M. Raska, Z. Stanley-Lockman, & R. Bitzinger. AI Governance for National Security and Defence: Assessing Military AI Strategic Perspectives. Routledge",
    "descriptor": "\nComments: 60 pages, 7 boxes, 2 figures, 2 annexes, submitted for Eds M. Raska, Z. Stanley-Lockman, & R. Bitzinger. AI Governance for National Security and Defence: Assessing Military AI Strategic Perspectives. Routledge\n",
    "authors": [
      "Susannah Kate Devitt",
      "Damian Copeland"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.01252"
  },
  {
    "id": "arXiv:2112.03203",
    "title": "An unsupervised extractive summarization method based on multi-round  computation",
    "abstract": "An unsupervised extractive summarization method based on multi-round  computation",
    "descriptor": "",
    "authors": [
      "Dehao Tao",
      "Yingzhu Xiong",
      "Zhongliang Yang",
      "Yongfeng Huang",
      "Jin He",
      "Kevin Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03203"
  },
  {
    "id": "arXiv:2112.03656",
    "title": "Tighter Bounds for Reconstruction from $\u03b5$-samples",
    "abstract": "Comments: 24 pages, 16 figures. Full version of paper to be published in SoCG proceedings",
    "descriptor": "\nComments: 24 pages, 16 figures. Full version of paper to be published in SoCG proceedings\n",
    "authors": [
      "H\u00e5vard Bakke Bjerkevik"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2112.03656"
  },
  {
    "id": "arXiv:2112.05999",
    "title": "Curvature-guided dynamic scale networks for Multi-view Stereo",
    "abstract": "Comments: Accepted to ICLR 2022",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "Khang Truong Giang",
      "Soohwan Song",
      "Sungho Jo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.05999"
  },
  {
    "id": "arXiv:2112.07508",
    "title": "Anti-Money Laundering Alert Optimization Using Machine Learning with  Graphs",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Ahmad Naser Eddin",
      "Jacopo Bono",
      "David Apar\u00edcio",
      "David Polido",
      "Jo\u00e3o Tiago Ascens\u00e3o",
      "Pedro Bizarro",
      "Pedro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07508"
  },
  {
    "id": "arXiv:2112.14016",
    "title": "Recursive Least-Squares Estimator-Aided Online Learning for Visual  Tracking",
    "abstract": "Comments: Accepted by TPAMI. Extended version of the RLS-RTMDNet tracker (CVPR2020)",
    "descriptor": "\nComments: Accepted by TPAMI. Extended version of the RLS-RTMDNet tracker (CVPR2020)\n",
    "authors": [
      "Jin Gao",
      "Yan Lu",
      "Xiaojuan Qi",
      "Yutong Kou",
      "Bing Li",
      "Liang Li",
      "Shan Yu",
      "Weiming Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.14016"
  },
  {
    "id": "arXiv:2112.14315",
    "title": "A Near-Optimal Finite Approximation Approach for Computing Stationary  Distribution and Performance Measures of Continuous-State Markov Chains",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Shukai Li",
      "Sanjay Mehrotra"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.14315"
  },
  {
    "id": "arXiv:2112.14931",
    "title": "Dense Depth Estimation from Multiple 360-degree Images Using Virtual  Depth",
    "abstract": "Comments: 16 pages, 11 figures, Applied Intelligence",
    "descriptor": "\nComments: 16 pages, 11 figures, Applied Intelligence\n",
    "authors": [
      "Seongyeop Yang",
      "Kunhee Kim",
      "Yeejin Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.14931"
  },
  {
    "id": "arXiv:2201.01537",
    "title": "Few-shot Domain Adaptation for IMU Denoising",
    "abstract": "Few-shot Domain Adaptation for IMU Denoising",
    "descriptor": "",
    "authors": [
      "Feiyu Yao",
      "Zongkai Wu",
      "Zhenyu Wei",
      "Donglin Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.01537"
  },
  {
    "id": "arXiv:2201.01996",
    "title": "Skip Vectors for RDF Data: Extraction Based on the Complexity of Feature  Patterns",
    "abstract": "Skip Vectors for RDF Data: Extraction Based on the Complexity of Feature  Patterns",
    "descriptor": "",
    "authors": [
      "Yota Minami",
      "Ken Kaneiwa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.01996"
  },
  {
    "id": "arXiv:2201.03794",
    "title": "Efficient Non-Local Contrastive Attention for Image Super-Resolution",
    "abstract": "Comments: Code is available at this https URL",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Bin Xia",
      "Yucheng Hang",
      "Yapeng Tian",
      "Wenming Yang",
      "Qingmin Liao",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.03794"
  },
  {
    "id": "arXiv:2201.03954",
    "title": "The Dataset Nutrition Label (2nd Gen): Leveraging Context to Mitigate  Harms in Artificial Intelligence",
    "abstract": "The Dataset Nutrition Label (2nd Gen): Leveraging Context to Mitigate  Harms in Artificial Intelligence",
    "descriptor": "",
    "authors": [
      "Kasia S. Chmielinski",
      "Sarah Newman",
      "Matt Taylor",
      "Josh Joseph",
      "Kemi Thomas",
      "Jessica Yurkofsky",
      "Yue Chelsea Qiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.03954"
  },
  {
    "id": "arXiv:2201.04064",
    "title": "Differentially Describing Groups of Graphs",
    "abstract": "Comments: 9 pages, 6 figures, accepted for publication at AAAI22",
    "descriptor": "\nComments: 9 pages, 6 figures, accepted for publication at AAAI22\n",
    "authors": [
      "Corinna Coupette",
      "Sebastian Dalleiger",
      "Jilles Vreeken"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.04064"
  },
  {
    "id": "arXiv:2201.04358",
    "title": "Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation  for Reference-based Super-Resolution",
    "abstract": "Comments: code is availavle at this https URL",
    "descriptor": "\nComments: code is availavle at this https URL\n",
    "authors": [
      "Bin Xia",
      "Yapeng Tian",
      "Yucheng Hang",
      "Wenming Yang",
      "Qingmin Liao",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.04358"
  },
  {
    "id": "arXiv:2201.07048",
    "title": "Fully Connected Reconfigurable Intelligent Surface Aided Rate-Splitting  Multiple Access for Multi-User Multi-Antenna Transmission",
    "abstract": "Comments: 6 pages, 5figures, conference",
    "descriptor": "\nComments: 6 pages, 5figures, conference\n",
    "authors": [
      "Tianyu Fang",
      "Yijie Mao",
      "Shanpu Shen",
      "Zhencai Zhu",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.07048"
  },
  {
    "id": "arXiv:2201.09118",
    "title": "Optimizing Huffman Decoding for Error-Bounded Lossy Compression on GPUs",
    "abstract": "Comments: 11 pages, 5 figures, 5 tables, accepted by IEEE IPDPS'22",
    "descriptor": "\nComments: 11 pages, 5 figures, 5 tables, accepted by IEEE IPDPS'22\n",
    "authors": [
      "Cody Rivera",
      "Sheng Di",
      "Jiannan Tian",
      "Xiaodong Yu",
      "Dingwen Tao",
      "Franck Cappello"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.09118"
  },
  {
    "id": "arXiv:2201.10712",
    "title": "Toward Data-Driven STAP Radar",
    "abstract": "Comments: 5 pages, 4 figures. Submitted to 2022 IEEE Radar Conference (RadarConf)",
    "descriptor": "\nComments: 5 pages, 4 figures. Submitted to 2022 IEEE Radar Conference (RadarConf)\n",
    "authors": [
      "Shyam Venkatasubramanian",
      "Chayut Wongkamthong",
      "Mohammadreza Soltani",
      "Bosung Kang",
      "Sandeep Gogineni",
      "Ali Pezeshki",
      "Muralidhar Rangaswamy",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.10712"
  },
  {
    "id": "arXiv:2201.11079",
    "title": "Orienteering with one endomorphism",
    "abstract": "Comments: 39 pages, 1 figure; 2nd revision implements small corrections and expositional improvements",
    "descriptor": "\nComments: 39 pages, 1 figure; 2nd revision implements small corrections and expositional improvements\n",
    "authors": [
      "Sarah Arpin",
      "Mingjie Chen",
      "Kristin E. Lauter",
      "Renate Scheidler",
      "Katherine E. Stange",
      "Ha T. N. Tran"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11079"
  },
  {
    "id": "arXiv:2202.00265",
    "title": "Access Control of Object Detection Models Using Encrypted Feature Maps",
    "abstract": "Comments: To appear in 2022 IEEE 4th Global Conference on Life Sciences and Technologies (LifeTech 2022)",
    "descriptor": "\nComments: To appear in 2022 IEEE 4th Global Conference on Life Sciences and Technologies (LifeTech 2022)\n",
    "authors": [
      "Teru Nagamori",
      "Hiroki Ito",
      "April Pyone Maung Maung",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00265"
  },
  {
    "id": "arXiv:2202.02096",
    "title": "To Impute or not to Impute? Missing Data in Treatment Effect Estimation",
    "abstract": "To Impute or not to Impute? Missing Data in Treatment Effect Estimation",
    "descriptor": "",
    "authors": [
      "Jeroen Berrevoets",
      "Fergus Imrie",
      "Trent Kyono",
      "James Jordon",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02096"
  },
  {
    "id": "arXiv:2202.05924",
    "title": "Compute Trends Across Three Eras of Machine Learning",
    "abstract": "Compute Trends Across Three Eras of Machine Learning",
    "descriptor": "",
    "authors": [
      "Jaime Sevilla",
      "Lennart Heim",
      "Anson Ho",
      "Tamay Besiroglu",
      "Marius Hobbhahn",
      "Pablo Villalobos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.05924"
  },
  {
    "id": "arXiv:2202.06767",
    "title": "Wukong: 100 Million Large-scale Chinese Cross-modal Pre-training Dataset  and A Foundation Framework",
    "abstract": "Wukong: 100 Million Large-scale Chinese Cross-modal Pre-training Dataset  and A Foundation Framework",
    "descriptor": "",
    "authors": [
      "Jiaxi Gu",
      "Xiaojun Meng",
      "Guansong Lu",
      "Lu Hou",
      "Minzhe Niu",
      "Xiaodan Liang",
      "Lewei Yao",
      "Runhui Huang",
      "Wei Zhang",
      "Xin Jiang",
      "Chunjing Xu",
      "Hang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06767"
  },
  {
    "id": "arXiv:2202.07108",
    "title": "Dynamic optical contrast imaging for real-time delineation of tumor  resection margins using head and neck cancer as a model",
    "abstract": "Comments: 21 pages, 7 figures and 1 table",
    "descriptor": "\nComments: 21 pages, 7 figures and 1 table\n",
    "authors": [
      "Yong Hu",
      "Shan Huang",
      "Albert Y. Han",
      "Seong Moon",
      "Jeffrey F. Krane",
      "Oscar Stafsudd",
      "Warren Grundfest",
      "Maie A. St. John"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Systems and Control (eess.SY)",
      "Biological Physics (physics.bio-ph)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.07108"
  },
  {
    "id": "arXiv:2202.07447",
    "title": "Trustworthy Autonomous Systems (TAS): Engaging TAS experts in curriculum  design",
    "abstract": "Trustworthy Autonomous Systems (TAS): Engaging TAS experts in curriculum  design",
    "descriptor": "",
    "authors": [
      "Mohammad Naiseh",
      "Caitlin Bentley",
      "Sarvapali D. Ramchurn"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07447"
  },
  {
    "id": "arXiv:2202.08370",
    "title": "Learning Transferrable Representations of Career Trajectories for  Economic Prediction",
    "abstract": "Learning Transferrable Representations of Career Trajectories for  Economic Prediction",
    "descriptor": "",
    "authors": [
      "Keyon Vafa",
      "Emil Palikot",
      "Tianyu Du",
      "Ayush Kanodia",
      "Susan Athey",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2202.08370"
  },
  {
    "id": "arXiv:2202.08937",
    "title": "When, Why, and Which Pretrained GANs Are Useful?",
    "abstract": "When, Why, and Which Pretrained GANs Are Useful?",
    "descriptor": "",
    "authors": [
      "Timofey Grigoryev",
      "Andrey Voynov",
      "Artem Babenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08937"
  },
  {
    "id": "arXiv:2202.09724",
    "title": "Bayes-Optimal Classifiers under Group Fairness",
    "abstract": "Bayes-Optimal Classifiers under Group Fairness",
    "descriptor": "",
    "authors": [
      "Xianli Zeng",
      "Edgar Dobriban",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09724"
  },
  {
    "id": "arXiv:2202.09830",
    "title": "Practical Interference Exploitation Precoding without Symbol-by-Symbol  Optimization: A Block-Level Approach",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. v2: Update Eq. 41",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. v2: Update Eq. 41\n",
    "authors": [
      "Ang Li",
      "Chao Shen",
      "Xuewen Liao",
      "Christos Masouros",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.09830"
  },
  {
    "id": "arXiv:2202.09988",
    "title": "Outlier-based Autism Detection using Longitudinal Structural MRI",
    "abstract": "Outlier-based Autism Detection using Longitudinal Structural MRI",
    "descriptor": "",
    "authors": [
      "Devika K",
      "Venkata Ramana Murthy Oruganti",
      "Dwarikanath Mahapatra",
      "Ramanathan Subramanian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09988"
  },
  {
    "id": "arXiv:2202.10668",
    "title": "Automatically Generating Counterfactuals for Relation Classification",
    "abstract": "Comments: 7 pages,3 figures",
    "descriptor": "\nComments: 7 pages,3 figures\n",
    "authors": [
      "Mi Zhang",
      "Tieyun Qian",
      "Ting Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.10668"
  },
  {
    "id": "arXiv:2202.10746",
    "title": "CD-ROM: Complementary Deep-Reduced Order Model",
    "abstract": "Comments: Submitted to the Journal of Computational Physics",
    "descriptor": "\nComments: Submitted to the Journal of Computational Physics\n",
    "authors": [
      "Emmanuel Menier",
      "Michele Alessandro Bucci",
      "Mouadh Yagoubi",
      "Lionel Mathelin",
      "Marc Schoenauer"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.10746"
  },
  {
    "id": "arXiv:2202.13541",
    "title": "Pattern Based Multivariable Regression using Deep Learning (PBMR-DP)",
    "abstract": "Comments: 7 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 7 pages, 5 figures, 3 tables\n",
    "authors": [
      "Jiztom Kavalakkatt Francis",
      "Chandan Kumar",
      "Jansel Herrera-Gerena",
      "Kundan Kumar",
      "Matthew J Darr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.13541"
  },
  {
    "id": "arXiv:2203.00190",
    "title": "Semi-supervised Deep Learning for Image Classification with Distribution  Mismatch: A Survey",
    "abstract": "Comments: Submission to IEEE Transactions on AI",
    "descriptor": "\nComments: Submission to IEEE Transactions on AI\n",
    "authors": [
      "Saul Calderon-Ramirez",
      "Shengxiang Yang",
      "David Elizondo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.00190"
  },
  {
    "id": "arXiv:2203.00237",
    "title": "Mental Health Pandemic during the COVID-19 Outbreak: Calls for Help on  Social Media",
    "abstract": "Mental Health Pandemic during the COVID-19 Outbreak: Calls for Help on  Social Media",
    "descriptor": "",
    "authors": [
      "Michelle Bak",
      "Jessie Chin",
      "Chungyi Chiu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.00237"
  },
  {
    "id": "arXiv:2203.00636",
    "title": "Distributional Reinforcement Learning for Scheduling of Chemical  Production Processes",
    "abstract": "Distributional Reinforcement Learning for Scheduling of Chemical  Production Processes",
    "descriptor": "",
    "authors": [
      "Max Mowbray",
      "Dongda Zhang",
      "Ehecatl Antonio Del Rio Chanona"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.00636"
  },
  {
    "id": "arXiv:2203.00756",
    "title": "Real time spectrogram inversion on mobile phone",
    "abstract": "Comments: Submitted to interspeech 2022",
    "descriptor": "\nComments: Submitted to interspeech 2022\n",
    "authors": [
      "Oleg Rybakov",
      "Marco Tagliasacchi",
      "Yunpeng Li",
      "Liyang Jiang",
      "Xia Zhang",
      "Fadi Biadsy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.00756"
  },
  {
    "id": "arXiv:2203.01156",
    "title": "Engineering the Neural Automatic Passenger Counter",
    "abstract": "Comments: 12 pages, 8 figures",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Nico Jahn",
      "Michael Siebert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.01156"
  },
  {
    "id": "arXiv:2203.01416",
    "title": "A Fully Memristive Spiking Neural Network with Unsupervised Learning",
    "abstract": "A Fully Memristive Spiking Neural Network with Unsupervised Learning",
    "descriptor": "",
    "authors": [
      "Peng Zhou",
      "Dong-Uk Choi",
      "Jason K. Eshraghian",
      "Sung-Mo Kang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2203.01416"
  },
  {
    "id": "arXiv:2203.01426",
    "title": "SPICEprop: Backpropagating Errors Through Memristive Spiking Neural  Networks",
    "abstract": "SPICEprop: Backpropagating Errors Through Memristive Spiking Neural  Networks",
    "descriptor": "",
    "authors": [
      "Peng Zhou",
      "Jason K. Eshraghian",
      "Dong-Uk Choi",
      "Sung-Mo Kang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2203.01426"
  },
  {
    "id": "arXiv:2203.01536",
    "title": "Recent Advances in Vision Transformer: A Survey and Outlook of Recent  Work",
    "abstract": "Comments: Added AAAI 2022 methods and working on ICLR 2022 methods",
    "descriptor": "\nComments: Added AAAI 2022 methods and working on ICLR 2022 methods\n",
    "authors": [
      "Khawar Islam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.01536"
  },
  {
    "id": "arXiv:2203.01623",
    "title": "ETCetera: beyond Event-Triggered Control",
    "abstract": "Comments: To be presented at the 25th ACM International Conference on Hybrid Systems: Computation and Control 2022 (HSCC 2022)",
    "descriptor": "\nComments: To be presented at the 25th ACM International Conference on Hybrid Systems: Computation and Control 2022 (HSCC 2022)\n",
    "authors": [
      "Giannis Delimpaltadakis",
      "Gabriel de A. Gleizer",
      "Ivo van Straalen",
      "Manuel Mazo Jr"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.01623"
  },
  {
    "id": "arXiv:2203.02104",
    "title": "Interactive Image Synthesis with Panoptic Layout Generation",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Bo Wang",
      "Tao Wu",
      "Minfeng Zhu",
      "Peng Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02104"
  },
  {
    "id": "arXiv:2203.02140",
    "title": "Analysis of closed-loop inertial gradient dynamics",
    "abstract": "Comments: Accepted for the 13th Asian Control Conference, 2022",
    "descriptor": "\nComments: Accepted for the 13th Asian Control Conference, 2022\n",
    "authors": [
      "Subhransu S. Bhattacharjee",
      "Ian R. Petersen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.02140"
  },
  {
    "id": "arXiv:2203.02380",
    "title": "Exploring Scalable, Distributed Real-Time Anomaly Detection for Bridge  Health Monitoring",
    "abstract": "Comments: 14 pages, 5 tables, 12 figures",
    "descriptor": "\nComments: 14 pages, 5 tables, 12 figures\n",
    "authors": [
      "Amirhossein Moallemi",
      "Alessio Burrello",
      "Davide Brunelli",
      "Luca Benini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.02380"
  },
  {
    "id": "arXiv:2203.02459",
    "title": "From Simultaneous to Streaming Machine Translation by Leveraging  Streaming History",
    "abstract": "Comments: ACL 2022 - Camera ready; v2 fixes Figure 4 which contained series from a follow-up work",
    "descriptor": "\nComments: ACL 2022 - Camera ready; v2 fixes Figure 4 which contained series from a follow-up work\n",
    "authors": [
      "Javier Iranzo-S\u00e1nchez",
      "Jorge Civera",
      "Alfons Juan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.02459"
  },
  {
    "id": "arXiv:2203.02503",
    "title": "HyperTransformer: A Textural and Spectral Feature Fusion Transformer for  Pansharpening",
    "abstract": "Comments: Accepted at CVPR'22. Project page: this https URL Code available at: this https URL",
    "descriptor": "\nComments: Accepted at CVPR'22. Project page: this https URL Code available at: this https URL\n",
    "authors": [
      "Wele Gedara Chaminda Bandara",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.02503"
  },
  {
    "id": "arXiv:2203.02925",
    "title": "Weakly Supervised Temporal Action Localization via Representative  Snippet Knowledge Propagation",
    "abstract": "Comments: Accepted by CVPR 2022. Code is available at this https URL",
    "descriptor": "\nComments: Accepted by CVPR 2022. Code is available at this https URL\n",
    "authors": [
      "Linjiang Huang",
      "Liang Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02925"
  },
  {
    "id": "arXiv:2203.02932",
    "title": "Doctor Recommendation in Online Health Forums via Expertise Learning",
    "abstract": "Comments: Accepted to ACL 2022 main conference",
    "descriptor": "\nComments: Accepted to ACL 2022 main conference\n",
    "authors": [
      "Xiaoxin Lu",
      "Yubo Zhang",
      "Jing Li",
      "Shi Zong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.02932"
  },
  {
    "id": "arXiv:2203.02994",
    "title": "Interactive Disambiguation for Behavior Tree Execution",
    "abstract": "Interactive Disambiguation for Behavior Tree Execution",
    "descriptor": "",
    "authors": [
      "Matteo Iovino",
      "Fethiye Irmak Do\u011fan",
      "Iolanda Leite",
      "Christian Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.02994"
  },
  {
    "id": "arXiv:2203.03116",
    "title": "Kernel Packet: An Exact and Scalable Algorithm for Gaussian Process  Regression with Mat\u00e9rn Correlations",
    "abstract": "Kernel Packet: An Exact and Scalable Algorithm for Gaussian Process  Regression with Mat\u00e9rn Correlations",
    "descriptor": "",
    "authors": [
      "Haoyuan Chen",
      "Liang Ding",
      "Rui Tuo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.03116"
  },
  {
    "id": "arXiv:2203.03157",
    "title": "SingleSketch2Mesh : Generating 3D Mesh model from Sketch",
    "abstract": "Comments: Working on some updates",
    "descriptor": "\nComments: Working on some updates\n",
    "authors": [
      "Nitish Bhardwaj",
      "Dhornala Bharadwaj",
      "Alpana Dubey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03157"
  },
  {
    "id": "arXiv:2203.03179",
    "title": "Detecting data-driven robust statistical arbitrage strategies with deep  neural networks",
    "abstract": "Detecting data-driven robust statistical arbitrage strategies with deep  neural networks",
    "descriptor": "",
    "authors": [
      "Ariel Neufeld",
      "Julian Sester",
      "Daiying Yin"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)",
      "Statistical Finance (q-fin.ST)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2203.03179"
  },
  {
    "id": "arXiv:2203.03204",
    "title": "Piloting Diversity and Inclusion Workshops in Artificial Intelligence  and Robotics for Children",
    "abstract": "Piloting Diversity and Inclusion Workshops in Artificial Intelligence  and Robotics for Children",
    "descriptor": "",
    "authors": [
      "Antonio Badillo-Perez",
      "Donato Badillo-Perez",
      "Diego Coyotzi-Molina",
      "Dago Cruz",
      "Rocio Montenegro",
      "Leticia Vazquez",
      "Miguel Xochicale"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03204"
  },
  {
    "id": "arXiv:2203.03399",
    "title": "Building and curating conversational corpora for diversity-aware  language science and technology",
    "abstract": "Building and curating conversational corpora for diversity-aware  language science and technology",
    "descriptor": "",
    "authors": [
      "Andreas Liesenfeld",
      "Mark Dingemanse"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03399"
  },
  {
    "id": "arXiv:2203.03515",
    "title": "Identifying Scenarios in Field Data to Enable Validation of Highly  Automated Driving Systems",
    "abstract": "Comments: at review for VEHITS 2022",
    "descriptor": "\nComments: at review for VEHITS 2022\n",
    "authors": [
      "Christian Reichenb\u00e4cher",
      "Maximilian Rasch",
      "Zafer Kayatas",
      "Florian Wirthm\u00fcller",
      "Jochen Hipp",
      "Thao Dang",
      "Oliver Bringmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03515"
  },
  {
    "id": "arXiv:2203.03560",
    "title": "Targeted Data Poisoning Attack on News Recommendation System by Content  Perturbation",
    "abstract": "Targeted Data Poisoning Attack on News Recommendation System by Content  Perturbation",
    "descriptor": "",
    "authors": [
      "Xudong Zhang",
      "Zan Wang",
      "Jingke Zhao",
      "Lanjun Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03560"
  },
  {
    "id": "arXiv:2203.03663",
    "title": "Towards Sub-Quadratic Diameter Computation in Geometric Intersection  Graphs",
    "abstract": "Comments: Full version of SoCG '22 paper",
    "descriptor": "\nComments: Full version of SoCG '22 paper\n",
    "authors": [
      "Karl Bringmann",
      "S\u00e1ndor Kisfaludi-Bak",
      "Marvin K\u00fcnnemann",
      "Andr\u00e9 Nusser",
      "Zahra Parsaeian"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.03663"
  },
  {
    "id": "arXiv:2203.03812",
    "title": "SpeechFormer: A Hierarchical Efficient Framework Incorporating the  Characteristics of Speech",
    "abstract": "Comments: 5 pages, 4figures. This paper was submitted to Insterspeech 2022",
    "descriptor": "\nComments: 5 pages, 4figures. This paper was submitted to Insterspeech 2022\n",
    "authors": [
      "Weidong Chen",
      "Xiaofen Xing",
      "Xiangmin Xu",
      "Jianxin Pang",
      "Lan Du"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.03812"
  },
  {
    "id": "arXiv:2203.03816",
    "title": "Quantum Volume in Practice: What Users Can Expect from NISQ Devices",
    "abstract": "Quantum Volume in Practice: What Users Can Expect from NISQ Devices",
    "descriptor": "",
    "authors": [
      "Elijah Pelofske",
      "Andreas B\u00e4rtschi",
      "Stephan Eidenbenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2203.03816"
  },
  {
    "id": "arXiv:2203.03844",
    "title": "Dynamic Dual Trainable Bounds for Ultra-low Precision Super-Resolution  Networks",
    "abstract": "Dynamic Dual Trainable Bounds for Ultra-low Precision Super-Resolution  Networks",
    "descriptor": "",
    "authors": [
      "Yunshan Zhong",
      "Mingbao Lin",
      "Xunchao Li",
      "Ke Li",
      "Yunhang Shen",
      "Fei Chao",
      "Yongjian Wu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03844"
  },
  {
    "id": "arXiv:2203.03916",
    "title": "Estimating the average causal effect of intervention in continuous  variables using machine learning",
    "abstract": "Estimating the average causal effect of intervention in continuous  variables using machine learning",
    "descriptor": "",
    "authors": [
      "Yoshiaki Kitazawa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03916"
  },
  {
    "id": "arXiv:2203.04228",
    "title": "Twitter Engagement with Retracted Articles: Who, When, and How?",
    "abstract": "Twitter Engagement with Retracted Articles: Who, When, and How?",
    "descriptor": "",
    "authors": [
      "Rod Abhari",
      "Nicholas Vincent",
      "Henry K. Dambanemuya",
      "Herminio Bodon",
      "Em\u0151ke-\u00c1gnes Horv\u00e1t"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.04228"
  },
  {
    "id": "arXiv:2203.04489",
    "title": "Online Non-linear Centroidal MPC for Humanoid Robot Locomotion with Step  Adjustment",
    "abstract": "Comments: Paper accepted in ICRA 2022",
    "descriptor": "\nComments: Paper accepted in ICRA 2022\n",
    "authors": [
      "Giulio Romualdi",
      "Stefano Dafarra",
      "Giuseppe L'Erario",
      "Ines Sorrentino",
      "Silvio Traversaro",
      "Daniele Pucci"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.04489"
  },
  {
    "id": "arXiv:2203.04604",
    "title": "Data-driven detector signal characterization with constrained bottleneck  autoencoders",
    "abstract": "Data-driven detector signal characterization with constrained bottleneck  autoencoders",
    "descriptor": "",
    "authors": [
      "C\u00e9sar Jes\u00fas-Valls",
      "Thorsten Lux",
      "Federico S\u00e1nchez"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2203.04604"
  },
  {
    "id": "arXiv:2203.04623",
    "title": "Controllable Evaluation and Generation of Physical Adversarial Patch on  Face Recognition",
    "abstract": "Controllable Evaluation and Generation of Physical Adversarial Patch on  Face Recognition",
    "descriptor": "",
    "authors": [
      "Xiao Yang",
      "Yinpeng Dong",
      "Tianyu Pang",
      "Zihao Xiao",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04623"
  },
  {
    "id": "arXiv:2203.04814",
    "title": "Text-DIAE: Degradation Invariant Autoencoders for Text Recognition and  Document Enhancement",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Mohamed Ali Souibgui",
      "Sanket Biswas",
      "Andres Mafla",
      "Ali Furkan Biten",
      "Alicia Forn\u00e9s",
      "Yousri Kessentini",
      "Josep Llad\u00f3s",
      "Lluis Gomez",
      "Dimosthenis Karatzas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04814"
  },
  {
    "id": "arXiv:2203.04927",
    "title": "Investigation of Factorized Optical Flows as Mid-Level Representations",
    "abstract": "Comments: Ting-Hsuan Liao, Hsu-Shen Liu, Li-Yuan Tsao, Tzu-Wen Wang, and Shan-Ya Yang contributed equally to this work, names listed in alphabetical order; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: Ting-Hsuan Liao, Hsu-Shen Liu, Li-Yuan Tsao, Tzu-Wen Wang, and Shan-Ya Yang contributed equally to this work, names listed in alphabetical order; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Hsuan-Kung Yang",
      "Tsu-Ching Hsiao",
      "Ting-Hsuan Liao",
      "Hsu-Shen Liu",
      "Li-Yuan Tsao",
      "Tzu-Wen Wang",
      "Shan-Ya Yang",
      "Yu-Wen Chen",
      "Huang-Ru Liao",
      "Chun-Yi Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.04927"
  }
]
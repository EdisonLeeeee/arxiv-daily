[
  {
    "id": "arXiv:2203.14958",
    "title": "Requirements Elicitation in Cognitive Service for Recommendation",
    "abstract": "Nowadays, cognitive service provides more interactive way to understand\nusers' requirements via human-machine conversation. In other words, it has to\ncapture users' requirements from their utterance and respond them with the\nrelevant and suitable service resources. To this end, two phases must be\napplied: I.Sequence planning and Real-time detection of user requirement,\nII.Service resource selection and Response generation. The existing works\nignore the potential connection between these two phases. To model their\nconnection, Two-Phase Requirement Elicitation Method is proposed. For the phase\nI, this paper proposes a user requirement elicitation framework (URef) to plan\na potential requirement sequence grounded on user profile and personal\nknowledge base before the conversation. In addition, it can also predict user's\ntrue requirement and judge whether the requirement is completed based on the\nuser's utterance during the conversation. For the phase II, this paper proposes\na response generation model based on attention, SaRSNet. It can select the\nappropriate resource (i.e. knowledge triple) in line with the requirement\npredicted by URef, and then generates a suitable response for recommendation.\nThe experimental results on the open dataset \\emph{DuRecDial} have been\nsignificantly improved compared to the baseline, which proves the effectiveness\nof the proposed methods.",
    "descriptor": "",
    "authors": [
      "Bolin Zhang",
      "Zhiying Tu",
      "Yunzhe Xu",
      "Dianhui Chu",
      "Xiaofei Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.14958"
  },
  {
    "id": "arXiv:2203.14960",
    "title": "Domino: Discovering Systematic Errors with Cross-Modal Embeddings",
    "abstract": "Machine learning models that achieve high overall accuracy often make\nsystematic errors on important subsets (or slices) of data. Identifying\nunderperforming slices is particularly challenging when working with\nhigh-dimensional inputs (e.g. images, audio), where important slices are often\nunlabeled. In order to address this issue, recent studies have proposed\nautomated slice discovery methods (SDMs), which leverage learned model\nrepresentations to mine input data for slices on which a model performs poorly.\nTo be useful to a practitioner, these methods must identify slices that are\nboth underperforming and coherent (i.e. united by a human-understandable\nconcept). However, no quantitative evaluation framework currently exists for\nrigorously assessing SDMs with respect to these criteria. Additionally, prior\nqualitative evaluations have shown that SDMs often identify slices that are\nincoherent. In this work, we address these challenges by first designing a\nprincipled evaluation framework that enables a quantitative comparison of SDMs\nacross 1,235 slice discovery settings in three input domains (natural images,\nmedical images, and time-series data). Then, motivated by the recent\ndevelopment of powerful cross-modal representation learning approaches, we\npresent Domino, an SDM that leverages cross-modal embeddings and a novel\nerror-aware mixture model to discover and describe coherent slices. We find\nthat Domino accurately identifies 36% of the 1,235 slices in our framework - a\n12 percentage point improvement over prior methods. Further, Domino is the\nfirst SDM that can provide natural language descriptions of identified slices,\ncorrectly generating the exact name of the slice in 35% of settings.",
    "descriptor": "\nComments: ICLR 2022 (Oral)\n",
    "authors": [
      "Sabri Eyuboglu",
      "Maya Varma",
      "Khaled Saab",
      "Jean-Benoit Delbrouck",
      "Christopher Lee-Messer",
      "Jared Dunnmon",
      "James Zou",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.14960"
  },
  {
    "id": "arXiv:2203.14961",
    "title": "A Deep Learning Approach for Thermal Plume Prediction of Groundwater  Heat Pumps",
    "abstract": "Climate control of buildings makes up a significant portion of global energy\nconsumption, with groundwater heat pumps providing a suitable alternative. To\nprevent possibly negative interactions between heat pumps throughout a city,\ncity planners have to optimize their layouts in the future. We develop a novel\ndata-driven approach for building small-scale surrogates for modelling the\nthermal plumes generated by groundwater heat pumps in the surrounding\nsubsurface water. Building on a data set generated from 2D numerical\nsimulations, we train a convolutional neural network for predicting\nsteady-state subsurface temperature fields from a given subsurface velocity\nfield. We show that compared to existing models ours can capture more complex\ndynamics while still being quick to compute. The resulting surrogate is thus\nwell-suited for interactive design tools by city planners.",
    "descriptor": "",
    "authors": [
      "Raphael Leiteritz",
      "Kyle Davis",
      "Miriam Schulte",
      "Dirk Pfl\u00fcger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2203.14961"
  },
  {
    "id": "arXiv:2203.14963",
    "title": "Deep Learning and Artificial General Intelligence: Still a Long Way to  Go",
    "abstract": "In recent years, deep learning using neural network architecture, i.e. deep\nneural networks, has been on the frontier of computer science research. It has\neven lead to superhuman performance in some problems, e.g., in computer vision,\ngames and biology, and as a result the term deep learning revolution was\ncoined. The undisputed success and rapid growth of deep learning suggests that,\nin future, it might become an enabler for Artificial General Intelligence\n(AGI). In this article, we approach this statement critically showing five\nmajor reasons of why deep neural networks, as of the current state, are not\nready to be the technique of choice for reaching AGI.",
    "descriptor": "\nComments: Accepted as a poster at 3rd Polish Conference on Artificial Intelligence (PP-RAI'2022)\n",
    "authors": [
      "Maciej \u015awiechowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.14963"
  },
  {
    "id": "arXiv:2203.14965",
    "title": "A Systematic Survey of Attack Detection and Prevention in Connected and  Autonomous Vehicles",
    "abstract": "The number of Connected and Autonomous Vehicles (CAVs) is increasing rapidly\nin various smart transportation services and applications due to many benefits\nto society, people, and the environment. Several research surveys were\nconducted in the domain of CAVs. Such surveys primarily focus on various\nsecurity threats and vulnerabilities in the domain of CAVs to classify\ndifferent types of attacks, impacts of attacks, attacks features, cyber-risk,\ndefense methodologies against attacks, and safety standards in CAVs. However,\nthe importance of attacks detection and prevention approaches for CAVs has not\nbeen discussed extensively in the state-of-the-art surveys, and there is a\nclear gap in the existing literature on such methodologies to detect new and\nconventional threats and protect the CAV system from unexpected hazards on the\nroad. There are some surveys with a limited discussion on Attacks Detection and\nPrevention Systems (ADPS), but such surveys provide only partial coverage of\ndifferent types of ADPS for CAVs. Furthermore, there is a scope for discussing\nsecurity, privacy, and efficiency challenges in ADPS that can give an overview\nof important security and performance attributes.\nThis survey paper presents the significance of CAVs, potential challenges in\nCAVs, and an explanation of important security and privacy properties, attack\nscenarios, possible attacks in CAV, and performance evaluation parameters for\nADPS. This survey paper extensively provides a discussion on the overview of\ndifferent ADPS categories and state-of-the-art research works based on each\nADPS category that gives the latest findings in this research domain. This\nsurvey also discusses crucial and open security research problems that are\nrequired to be focused on a secure deployment of CAVs in the market.",
    "descriptor": "\nComments: This article is under review in IEEE Communications Surveys and Tutorials\n",
    "authors": [
      "Trupil Limbasiya",
      "Ko Zheng Teng",
      "Sudipta Chattopadhyay",
      "Jianying Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.14965"
  },
  {
    "id": "arXiv:2203.14966",
    "title": "Error Correction Code Transformer",
    "abstract": "Error correction code is a major part of the communication physical layer,\nensuring the reliable transfer of data over noisy channels. Recently, neural\ndecoders were shown to outperform classical decoding techniques. However, the\nexisting neural approaches present strong overfitting due to the exponential\ntraining complexity, or a restrictive inductive bias due to reliance on Belief\nPropagation. Recently, Transformers have become methods of choice in many\napplications thanks to their ability to represent complex interactions between\nelements. In this work, we propose to extend for the first time the Transformer\narchitecture to the soft decoding of linear codes at arbitrary block lengths.\nWe encode each channel's output dimension to high dimension for better\nrepresentation of the bits information to be processed separately. The\nelement-wise processing allows the analysis of the channel output reliability,\nwhile the algebraic code and the interaction between the bits are inserted into\nthe model via an adapted masked self-attention module. The proposed approach\ndemonstrates the extreme power and flexibility of Transformers and outperforms\nexisting state-of-the-art neural decoders by large margins at a fraction of\ntheir time complexity.",
    "descriptor": "",
    "authors": [
      "Yoni Choukroun",
      "Lior Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.14966"
  },
  {
    "id": "arXiv:2203.14987",
    "title": "Multilingual Knowledge Graph Completion with Self-Supervised Adaptive  Graph Alignment",
    "abstract": "Predicting missing facts in a knowledge graph (KG) is crucial as modern KGs\nare far from complete. Due to labor-intensive human labeling, this phenomenon\ndeteriorates when handling knowledge represented in various languages. In this\npaper, we explore multilingual KG completion, which leverages limited seed\nalignment as a bridge, to embrace the collective knowledge from multiple\nlanguages. However, language alignment used in prior works is still not fully\nexploited: (1) alignment pairs are treated equally to maximally push parallel\nentities to be close, which ignores KG capacity inconsistency; (2) seed\nalignment is scarce and new alignment identification is usually in a noisily\nunsupervised manner. To tackle these issues, we propose a novel self-supervised\nadaptive graph alignment (SS-AGA) method. Specifically, SS-AGA fuses all KGs as\na whole graph by regarding alignment as a new edge type. As such, information\npropagation and noise influence across KGs can be adaptively controlled via\nrelation-aware attention weights. Meanwhile, SS-AGA features a new pair\ngenerator that dynamically captures potential alignment pairs in a\nself-supervised paradigm. Extensive experiments on both the public multilingual\nDBPedia KG and newly-created industrial multilingual E-commerce KG empirically\ndemonstrate the effectiveness of SS-AG",
    "descriptor": "",
    "authors": [
      "Zijie Huang",
      "Zheng Li",
      "Haoming Jiang",
      "Tianyu Cao",
      "Hanqing Lu",
      "Bing Yin",
      "Karthik Subbian",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.14987"
  },
  {
    "id": "arXiv:2203.14996",
    "title": "Comparing in context: Improving cosine similarity measures with a metric  tensor",
    "abstract": "Cosine similarity is a widely used measure of the relatedness of pre-trained\nword embeddings, trained on a language modeling goal. Datasets such as\nWordSim-353 and SimLex-999 rate how similar words are according to human\nannotators, and as such are often used to evaluate the performance of language\nmodels. Thus, any improvement on the word similarity task requires an improved\nword representation. In this paper, we propose instead the use of an extended\ncosine similarity measure to improve performance on that task, with gains in\ninterpretability. We explore the hypothesis that this approach is particularly\nuseful if the word-similarity pairs share the same context, for which distinct\ncontextualized similarity measures can be learned. We first use the dataset of\nRichie et al. (2020) to learn contextualized metrics and compare the results\nwith the baseline values obtained using the standard cosine similarity measure,\nwhich consistently shows improvement. We also train a contextualized similarity\nmeasure for both SimLex-999 and WordSim-353, comparing the results with the\ncorresponding baselines, and using these datasets as independent test sets for\nthe all-context similarity measure learned on the contextualized dataset,\nobtaining positive results for a number of tests.",
    "descriptor": "\nComments: Presented at the 18th International Conference in Natural Language Processing (ICON `21). 11 pages, 3 figures, 6 tables\n",
    "authors": [
      "Isa M. Apallius de Vos",
      "Ghislaine L. van den Boogerd",
      "Mara D. Fennema",
      "Adriana D. Correia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.14996"
  },
  {
    "id": "arXiv:2203.15004",
    "title": "Offline-Online Learning of Deformation Model for Cable Manipulation with  Graph Neural Networks",
    "abstract": "Manipulating deformable linear objects by robots has a wide range of\napplications, e.g., manufacturing and medical surgery. To complete such tasks,\nan accurate dynamics model for predicting the deformation is critical for\nrobust control. In this work, we deal with this challenge by proposing a hybrid\noffline-online method to learn the dynamics of cables in a robust and\ndata-efficient manner. In the offline phase, we adopt Graph Neural Network\n(GNN) to learn the deformation dynamics purely from the simulation data. Then a\nlinear residual model is learned in real-time to bridge the sim-to-real gap.\nThe learned model is then utilized as the dynamics constraint of a trust region\nbased Model Predictive Controller (MPC) to calculate the optimal robot\nmovements. The online learning and MPC run in a closed-loop manner to robustly\naccomplish the task. Finally, comparative results with existing methods are\nprovided to quantitatively show the effectiveness and robustness.",
    "descriptor": "",
    "authors": [
      "Changhao Wang",
      "Yuyou Zhang",
      "Xiang Zhang",
      "Zheng Wu",
      "Xinghao Zhu",
      "Shiyu Jin",
      "Te Tang",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15004"
  },
  {
    "id": "arXiv:2203.15006",
    "title": "TL-GAN: Improving Traffic Light Recognition via Data Synthesis for  Autonomous Driving",
    "abstract": "Traffic light recognition, as a critical component of the perception module\nof self-driving vehicles, plays a vital role in the intelligent transportation\nsystems. The prevalent deep learning based traffic light recognition methods\nheavily hinge on the large quantity and rich diversity of training data.\nHowever, it is quite challenging to collect data in various rare scenarios such\nas flashing, blackout or extreme weather, thus resulting in the imbalanced\ndistribution of training data and consequently the degraded performance in\nrecognizing rare classes. In this paper, we seek to improve traffic light\nrecognition by leveraging data synthesis. Inspired by the generative\nadversarial networks (GANs), we propose a novel traffic light generation\napproach TL-GAN to synthesize the data of rare classes to improve traffic light\nrecognition for autonomous driving. TL-GAN disentangles traffic light sequence\ngeneration into image synthesis and sequence assembling. In the image synthesis\nstage, our approach enables conditional generation to allow full control of the\ncolor of the generated traffic light images. In the sequence assembling stage,\nwe design the style mixing and adaptive template to synthesize realistic and\ndiverse traffic light sequences. Extensive experiments show that the proposed\nTL-GAN renders remarkable improvement over the baseline without using the\ngenerated data, leading to the state-of-the-art performance in comparison with\nthe competing algorithms that are used for general image synthesis and data\nimbalance tackling.",
    "descriptor": "",
    "authors": [
      "Danfeng Wang",
      "Xin Ma",
      "Xiaodong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15006"
  },
  {
    "id": "arXiv:2203.15007",
    "title": "Registering Explicit to Implicit: Towards High-Fidelity Garment mesh  Reconstruction from Single Images",
    "abstract": "Fueled by the power of deep learning techniques and implicit shape learning,\nrecent advances in single-image human digitalization have reached unprecedented\naccuracy and could recover fine-grained surface details such as garment\nwrinkles. However, a common problem for the implicit-based methods is that they\ncannot produce separated and topology-consistent mesh for each garment piece,\nwhich is crucial for the current 3D content creation pipeline. To address this\nissue, we proposed a novel geometry inference framework ReEF that reconstructs\ntopology-consistent layered garment mesh by registering the explicit garment\ntemplate to the whole-body implicit fields predicted from single images.\nExperiments demonstrate that our method notably outperforms its counterparts on\nsingle-image layered garment reconstruction and could bring high-quality\ndigital assets for further content creation.",
    "descriptor": "\nComments: CVPR 2022, For project page, please see: this https URL\n",
    "authors": [
      "Heming Zhu",
      "Lingteng Qiu",
      "Yuda Qiu",
      "Xiaoguang Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15007"
  },
  {
    "id": "arXiv:2203.15019",
    "title": "Sacrificing CSI for a Greater Good: RIS-enabled Opportunistic Rate  Splitting",
    "abstract": "In reconfigurable intelligent surface (RIS)-assisted systems, the\noptimization of the phase shifts requires separate acquisition of the channel\nstate information (CSI) for the direct and RIS-assisted channels, posing\nsignificant design challenges. In this paper, a novel scheme is proposed, which\nconsiders practical limitations like pilot overhead and channel estimation (CE)\nerrors to increase the net performance. More specifically, at the cost of\nunpredictable interference, a portion of the CSI for the RIS-assisted channels\nis sacrificed in order to reduce the CE time. By alternating the CSI between\ncoherence blocks and employing rate splitting, it becomes possible to mitigate\nthe interference, thereby compensating the adverse effect of the sacrificed\nCSI. Numerical simulations validate that the proposed scheme exhibits better\nperformance in terms of achievable net rate, resulting in gains of up to 160%\ncompared non-orthogonal multiple access (NOMA), when CE time and CE errors are\nconsidered.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to IEEE SAM2022 Special Session on Reconfigurable Intelligent Surfaces for signal processing and communications\n",
    "authors": [
      "Kevin Weinberger",
      "Aydin Sezgin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.15019"
  },
  {
    "id": "arXiv:2203.15021",
    "title": "Few-Shot Object Detection with Fully Cross-Transformer",
    "abstract": "Few-shot object detection (FSOD), with the aim to detect novel objects using\nvery few training examples, has recently attracted great research interest in\nthe community. Metric-learning based methods have been demonstrated to be\neffective for this task using a two-branch based siamese network, and calculate\nthe similarity between image regions and few-shot examples for detection.\nHowever, in previous works, the interaction between the two branches is only\nrestricted in the detection head, while leaving the remaining hundreds of\nlayers for separate feature extraction. Inspired by the recent work on vision\ntransformers and vision-language transformers, we propose a novel Fully\nCross-Transformer based model (FCT) for FSOD by incorporating cross-transformer\ninto both the feature backbone and detection head. The asymmetric-batched\ncross-attention is proposed to aggregate the key information from the two\nbranches with different batch sizes. Our model can improve the few-shot\nsimilarity learning between the two branches by introducing the multi-level\ninteractions. Comprehensive experiments on both PASCAL VOC and MSCOCO FSOD\nbenchmarks demonstrate the effectiveness of our model.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Guangxing Han",
      "Jiawei Ma",
      "Shiyuan Huang",
      "Long Chen",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.15021"
  },
  {
    "id": "arXiv:2203.15026",
    "title": "A systematic review and meta-analysis of Digital Elevation Model (DEM)  fusion: pre-processing, methods and applications",
    "abstract": "The remote sensing community has identified data fusion as one of the key\nchallenging topics of the 21st century. The subject of image fusion in\ntwo-dimensional (2D) space has been covered in several published reviews.\nHowever, the special case of 2.5D/3D Digital Elevation Model (DEM) fusion has\nnot been addressed till date. DEM fusion is a key application of data fusion in\nremote sensing. It takes advantage of the complementary characteristics of\nmulti-source DEMs to deliver a more complete, accurate and reliable elevation\ndataset. Although several methods for fusing DEMs have been developed, the\nabsence of a well-rounded review has limited their proliferation among\nresearchers and end-users. It is often required to combine knowledge from\nmultiple studies to inform a holistic perspective and guide further research.\nIn response, this paper provides a systematic review of DEM fusion: the\npre-processing workflow, methods and applications, enhanced with a\nmeta-analysis. Through the discussion and comparative analysis, unresolved\nchallenges and open issues were identified, and future directions for research\nwere proposed. This review is a timely solution and an invaluable source of\ninformation for researchers within the fields of remote sensing and spatial\ninformation science, and the data fusion community at large.",
    "descriptor": "",
    "authors": [
      "Chukwuma Okolie",
      "Julian Smit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15026"
  },
  {
    "id": "arXiv:2203.15030",
    "title": "Solving Disjunctive Temporal Networks with Uncertainty under Restricted  Time-Based Controllability using Tree Search and Graph Neural Networks",
    "abstract": "We present a novel approach based on tree search and graph machine learning\nfor the scheduling problem known as Disjunctive Temporal Networks with\nUncertainty (DTNU). Dynamic Controllability (DC) of DTNUs seeks a reactive\nscheduling strategy to satisfy temporal constraints in response to\nuncontrollable action durations. We introduce new semantics for reactive\nscheduling: Time-based Dynamic Controllability (TDC) and a restricted subset of\nTDC, R-TDC. We design a tree search algorithm to determine whether or not a\nDTNU is R-TDC. Moreover, we leverage a graph neural network as a heuristic for\ntree search guidance. Finally, we conduct experiments on a known benchmark on\nwhich we show R-TDC to retain significant completeness with regard to DC, while\nbeing faster to prove. This results in the tree search processing fifty percent\nmore DTNU problems in R-TDC than the state-of-the-art DC solver does in DC with\nthe same time budget. We also observe that graph neural network search guidance\nleads to substantial performance gains on benchmarks of more complex DTNUs,\nwith up to eleven times more problems solved than the baseline tree search.",
    "descriptor": "\nComments: Thirty-Sixth AAAI Conference on Artificial Intelligence. This version includes the technical appendix. arXiv admin note: substantial text overlap with arXiv:2108.01068\n",
    "authors": [
      "Kevin Osanlou",
      "Jeremy Frank",
      "Andrei Bursuc",
      "Tristan Cazenave",
      "Eric Jacopin",
      "Christophe Guettier",
      "J. Benton"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15030"
  },
  {
    "id": "arXiv:2203.15034",
    "title": "Learning Parameterized Task Structure for Generalization to Unseen  Entities",
    "abstract": "Real world tasks are hierarchical and compositional. Tasks can be composed of\nmultiple subtasks (or sub-goals) that are dependent on each other. These\nsubtasks are defined in terms of entities (e.g., \"apple\", \"pear\") that can be\nrecombined to form new subtasks (e.g., \"pickup apple\", and \"pickup pear\"). To\nsolve these tasks efficiently, an agent must infer subtask dependencies (e.g.\nan agent must execute \"pickup apple\" before \"place apple in pot\"), and\ngeneralize the inferred dependencies to new subtasks (e.g. \"place apple in pot\"\nis similar to \"place apple in pan\"). Moreover, an agent may also need to solve\nunseen tasks, which can involve unseen entities. To this end, we formulate\nparameterized subtask graph inference (PSGI), a method for modeling subtask\ndependencies using first-order logic with subtask entities. To facilitate this,\nwe learn entity attributes in a zero-shot manner, which are used as quantifiers\n(e.g. \"is_pickable(X)\") for the parameterized subtask graph. We show this\napproach accurately learns the latent structure on hierarchical and\ncompositional tasks more efficiently than prior work, and show PSGI can\ngeneralize by modelling structure on subtasks unseen during adaptation.",
    "descriptor": "\nComments: Published in AAAI 2022\n",
    "authors": [
      "Anthony Z. Liu",
      "Sungryull Sohn",
      "Mahdi Qazwini",
      "Honglak Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15034"
  },
  {
    "id": "arXiv:2203.15037",
    "title": "Online Algorithms for Matching Platforms with Multi-Channel Traffic",
    "abstract": "Two-sided platforms rely on their recommendation algorithms to help visitors\nsuccessfully find a match. However, on platforms such as VolunteerMatch (VM) --\nwhich has facilitated millions of connections between volunteers and nonprofits\n-- a sizable fraction of website traffic arrives directly to a nonprofit's\nvolunteering page via an external link, thus bypassing the platform's\nrecommendation algorithm. We study how such platforms should account for this\nexternal traffic in the design of their recommendation algorithms, given the\ngoal of maximizing successful matches. We model the platform's problem as a\nspecial case of online matching, where (using VM terminology) volunteers arrive\nsequentially and probabilistically match with one opportunity, each of which\nhas finite need for volunteers. In our framework, external traffic is\ninterested only in their targeted opportunity; by contrast, internal traffic\nmay be interested in many opportunities, and the platform's online algorithm\nselects which opportunity to recommend. In evaluating different algorithms, we\nparameterize the competitive ratio based on the amount of external traffic.\nAfter demonstrating the shortcomings of a commonly-used algorithm that is\noptimal in the absence of external traffic, we propose a new algorithm --\nAdaptive Capacity (AC) -- which accounts for matches differently based on\nwhether they originate from internal or external traffic. We provide a lower\nbound on AC's competitive ratio that is increasing in the amount of external\ntraffic and that is close to the parameterized upper bound we establish on the\ncompetitive ratio of any online algorithm. Our analysis utilizes a path-based,\npseudo-rewards approach, which we further generalize to settings where the\nplatform can recommend a ranked set of opportunities. Beyond our theoretical\nresults, we show the strong performance of AC in a case study motivated by VM\ndata.",
    "descriptor": "",
    "authors": [
      "Vahideh Manshadi",
      "Scott Rodilitz",
      "Daniela Saban",
      "Akshaya Suresh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.15037"
  },
  {
    "id": "arXiv:2203.15041",
    "title": "Socially Compliant Navigation Dataset (SCAND): A Large-Scale Dataset of  Demonstrations for Social Navigation",
    "abstract": "Social navigation is the capability of an autonomous agent, such as a robot,\nto navigate in a 'socially compliant' manner in the presence of other\nintelligent agents such as humans. With the emergence of autonomously\nnavigating mobile robots in human populated environments (e.g., domestic\nservice robots in homes and restaurants and food delivery robots on public\nsidewalks), incorporating socially compliant navigation behaviors on these\nrobots becomes critical to ensuring safe and comfortable human robot\ncoexistence. To address this challenge, imitation learning is a promising\nframework, since it is easier for humans to demonstrate the task of social\nnavigation rather than to formulate reward functions that accurately capture\nthe complex multi objective setting of social navigation. The use of imitation\nlearning and inverse reinforcement learning to social navigation for mobile\nrobots, however, is currently hindered by a lack of large scale datasets that\ncapture socially compliant robot navigation demonstrations in the wild. To fill\nthis gap, we introduce Socially CompliAnt Navigation Dataset (SCAND) a large\nscale, first person view dataset of socially compliant navigation\ndemonstrations. Our dataset contains 8.7 hours, 138 trajectories, 25 miles of\nsocially compliant, human teleoperated driving demonstrations that comprises\nmulti modal data streams including 3D lidar, joystick commands, odometry,\nvisual and inertial information, collected on two morphologically different\nmobile robots a Boston Dynamics Spot and a Clearpath Jackal by four different\nhuman demonstrators in both indoor and outdoor environments. We additionally\nperform preliminary analysis and validation through real world robot\nexperiments and show that navigation policies learned by imitation learning on\nSCAND generate socially compliant behaviors",
    "descriptor": "",
    "authors": [
      "Haresh Karnan",
      "Anirudh Nair",
      "Xuesu Xiao",
      "Garrett Warnell",
      "Soeren Pirk",
      "Alexander Toshev",
      "Justin Hart",
      "Joydeep Biswas",
      "Peter Stone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15041"
  },
  {
    "id": "arXiv:2203.15043",
    "title": "Efficient Algorithm for Deterministic Search of Hot Elements",
    "abstract": "When facing a very large stream of data, it is often desirable to extract\nmost important statistics online in a short time and using small memory. For\nexample, one may want to quickly find the most influential users generating\nposts online or check if the stream contains many identical elements. In this\npaper, we study streams containing insertions and deletions of elements from a\npossibly large set $N$ of size $|N| = n$, that are being processed by online\ndeterministic algorithms. At any point in the stream the algorithm may be\nqueried to output elements of certain frequency in the already processed\nstream. More precisely, the most frequent elements in the stream so far. The\noutput is considered correct if the returned elements it contains all elements\nwith frequency greater than a given parameter $\\varphi$ and no element with\nfrequency smaller than $\\varphi-\\epsilon$. We present an efficient online\ndeterministic algorithm for solving this problem using $O(\\min(n,\n\\frac{polylog(n)}{\\epsilon}))$ memory and $O(polylog(n))$ time per processing\nand outputting an element. It is the first such algorithm as the previous\nalgorithms were either randomized, or processed elements in substantially\nlarger time $\\Omega(\\min(n, \\frac{\\log n}{\\epsilon}))$, or handled only\ninsertions and required two passes over the stream (i.e., were not truly\nonline). Our solution is almost-optimally scalable (with only a polylogarithmic\noverhead) and does not require randomness or scanning twice through the stream.\nWe complement the algorithm analysis with a lower bound $\\Omega(\\min(n,\n\\frac{1}{\\epsilon}))$ on required memory.",
    "descriptor": "",
    "authors": [
      "Dariusz R. Kowalski",
      "Dominik Pajak"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.15043"
  },
  {
    "id": "arXiv:2203.15044",
    "title": "Are Deepfakes Concerning? Analyzing Conversations of Deepfakes on Reddit  and Exploring Societal Implications",
    "abstract": "Deepfakes are synthetic content generated using advanced deep learning and AI\ntechnologies. The advancement of technology has created opportunities for\nanyone to create and share deepfakes much easier. This may lead to societal\nconcerns based on how communities engage with it. However, there is limited\nresearch available to understand how communities perceive deepfakes. We\nexamined deepfake conversations on Reddit from 2018 to 2021 -- including major\ntopics and their temporal changes as well as implications of these\nconversations. Using a mixed-method approach -- topic modeling and qualitative\ncoding, we found 6,638 posts and 86,425 comments discussing concerns of the\nbelievable nature of deepfakes and how platforms moderate them. We also found\nReddit conversations to be pro-deepfake and building a community that supports\ncreating and sharing deepfake artifacts and building a marketplace regardless\nof the consequences. Possible implications derived from qualitative codes\nindicate that deepfake conversations raise societal concerns. We propose that\nthere are implications for Human Computer Interaction (HCI) to mitigate the\nharm created from deepfakes.",
    "descriptor": "\nComments: 19pgs, CHI22: CHI Conference on Human Factors in Computing Systems April 29-May 5, 2022 New Orleans, LA, USA\n",
    "authors": [
      "Dilrukshi Gamage",
      "Piyush Ghasiya",
      "Vamshi Krishna Bonagiri",
      "Mark E Whiting",
      "Kazutoshi Sasahara"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.15044"
  },
  {
    "id": "arXiv:2203.15046",
    "title": "AUC Maximization in the Era of Big Data and AI: A Survey",
    "abstract": "Area under the ROC curve, a.k.a. AUC, is a measure of choice for assessing\nthe performance of a classifier for imbalanced data. AUC maximization refers to\na learning paradigm that learns a predictive model by directly maximizing its\nAUC score. It has been studied for more than two decades dating back to late\n90s and a huge amount of work has been devoted to AUC maximization since then.\nRecently, stochastic AUC maximization for big data and deep AUC maximization\nfor deep learning have received increasing attention and yielded dramatic\nimpact for solving real-world problems. However, to the best our knowledge\nthere is no comprehensive survey of related works for AUC maximization. This\npaper aims to address the gap by reviewing the literature in the past two\ndecades. We not only give a holistic view of the literature but also present\ndetailed explanations and comparisons of different papers from formulations to\nalgorithms and theoretical guarantees. We also identify and discuss remaining\nand emerging issues for deep AUC maximization, and provide suggestions on\ntopics for future work.",
    "descriptor": "",
    "authors": [
      "Tianbao Yang",
      "Yiming Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15046"
  },
  {
    "id": "arXiv:2203.15052",
    "title": "Learning Minimum-Time Flight in Cluttered Environments",
    "abstract": "We tackle the problem of minimum-time flight for a quadrotor through a\nsequence of waypoints in the presence of obstacles while exploiting the full\nquadrotor dynamics. Early works relied on simplified dynamics or polynomial\ntrajectory representations that did not exploit the full actuator potential of\nthe quadrotor, and, thus, resulted in suboptimal solutions. Recent works can\nplan minimum-time trajectories; yet, the trajectories are executed with control\nmethods that do not account for obstacles. Thus, a successful execution of such\ntrajectories is prone to errors due to model mismatch and in-flight\ndisturbances. To this end, we leverage deep reinforcement learning and\nclassical topological path planning to train robust neural-network controllers\nfor minimum-time quadrotor flight in cluttered environments. The resulting\nneural network controller demonstrates significantly better performance of up\nto 19% over state-of-the-art methods. More importantly, the learned policy\nsolves the planning and control problem simultaneously online to account for\ndisturbances, thus achieving much higher robustness. As such, the presented\nmethod achieves 100% success rate of flying minimum-time policies without\ncollision, while traditional planning and control approaches achieve only 40%.\nThe proposed method is validated in both simulation and the real world.",
    "descriptor": "",
    "authors": [
      "Robert Penicka",
      "Yunlong Song",
      "Elia Kaufmann",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15052"
  },
  {
    "id": "arXiv:2203.15053",
    "title": "Application of Stabilized Explicit Runge-Kutta Methods to the  Incompressible Navier-Stokes Equations by means of a Projection Method and a  Differential Algebraic Approach",
    "abstract": "In this master thesis we have compared different second order stabilized\nexplicit Runge-Kutta methods when applied to the incompressible Navier-Stokes\nequations by means of a projection method and a differential algebraic\napproach. We explored the stability and accuracy properties of the RKC, ROCK2\nand PIROCK schemes when coupled with the projection and the differential\nalgebraic approach. PIROCK has shown unexpected instabilities, ROCK2 resulted\nto be the most efficient and versatile Runge-Kutta method taken into account.\nThe differential algebraic approach sounds computationally costly but it\nexhibits better accuracy and a larger stability region. These properties make\nit more efficient than the projection method. The theory presented in the first\nchapters is supported by numerical experiments.",
    "descriptor": "",
    "authors": [
      "Giacomo Rosilho de Souza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15053"
  },
  {
    "id": "arXiv:2203.15058",
    "title": "A distribution-dependent Mumford-Shah model for unsupervised  hyperspectral image segmentation",
    "abstract": "Hyperspectral images provide a rich representation of the underlying spectrum\nfor each pixel, allowing for a pixel-wise classification/segmentation into\ndifferent classes. As the acquisition of labeled training data is very\ntime-consuming, unsupervised methods become crucial in hyperspectral image\nanalysis. The spectral variability and noise in hyperspectral data make this\ntask very challenging and define special requirements for such methods.\nHere, we present a novel unsupervised hyperspectral segmentation framework.\nIt starts with a denoising and dimensionality reduction step by the\nwell-established Minimum Noise Fraction (MNF) transform. Then, the Mumford-Shah\n(MS) segmentation functional is applied to segment the data. We equipped the MS\nfunctional with a novel robust distribution-dependent indicator function\ndesigned to handle the characteristic challenges of hyperspectral data. To\noptimize our objective function with respect to the parameters for which no\nclosed form solution is available, we propose an efficient fixed point\niteration scheme. Numerical experiments on four public benchmark datasets show\nthat our method produces competitive results, which outperform two\nstate-of-the-art methods substantially on three of these datasets.",
    "descriptor": "",
    "authors": [
      "Jan-Christopher Cohrs",
      "Chandrajit Bajaj",
      "Benjamin Berkels"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15058"
  },
  {
    "id": "arXiv:2203.15060",
    "title": "A Deep Learning Technique using a Sequence of Follow Up X-Rays for  Disease classification",
    "abstract": "The ability to predict lung and heart based diseases using deep learning\ntechniques is central to many researchers, particularly in the medical field\naround the world. In this paper, we present a unique outlook of a very familiar\nproblem of disease classification using X-rays. We present a hypothesis that\nX-rays of patients included with the follow up history of their most recent\nthree chest X-ray images would perform better in disease classification in\ncomparison to one chest X-ray image input using an internal CNN to perform\nfeature extraction. We have discovered that our generic deep learning\narchitecture which we propose for solving this problem performs well with 3\ninput X ray images provided per sample for each patient. In this paper, we have\nalso established that without additional layers before the output\nclassification, the CNN models will improve the performance of predicting the\ndisease labels for each patient. We have provided our results in ROC curves and\nAUROC scores. We define a fresh approach of collecting three X-ray images for\ntraining deep learning models, which we have concluded has clearly improved the\nperformance of the models. We have shown that ResNet, in general, has a better\nresult than any other CNN model used in the feature extraction phase. With our\noriginal approach to data pre-processing, image training, and pre-trained\nmodels, we believe that the current research will assist many medical\ninstitutions around the world, and this will improve the prediction of\npatients' symptoms and diagnose them with more accurate cure.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Sairamvinay Vijayaraghavan",
      "David Haddad",
      "Shikun Huang",
      "Seongwoo Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15060"
  },
  {
    "id": "arXiv:2203.15064",
    "title": "Cycle-Consistent Counterfactuals by Latent Transformations",
    "abstract": "CounterFactual (CF) visual explanations try to find images similar to the\nquery image that change the decision of a vision system to a specified outcome.\nExisting methods either require inference-time optimization or joint training\nwith a generative adversarial model which makes them time-consuming and\ndifficult to use in practice. We propose a novel approach, Cycle-Consistent\nCounterfactuals by Latent Transformations (C3LT), which learns a latent\ntransformation that automatically generates visual CFs by steering in the\nlatent space of generative models. Our method uses cycle consistency between\nthe query and CF latent representations which helps our training to find better\nsolutions. C3LT can be easily plugged into any state-of-the-art pretrained\ngenerative network. This enables our method to generate high-quality and\ninterpretable CF images at high resolution such as those in ImageNet. In\naddition to several established metrics for evaluating CF explanations, we\nintroduce a novel metric tailored to assess the quality of the generated CF\nexamples and validate the effectiveness of our method on an extensive set of\nexperiments.",
    "descriptor": "",
    "authors": [
      "Saeed Khorram",
      "Li Fuxin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15064"
  },
  {
    "id": "arXiv:2203.15065",
    "title": "DeepShadow: Neural Shape from Shadow",
    "abstract": "This paper presents DeepShadow, a one-shot method for recovering the depth\nmap and surface normals from photometric stereo shadow maps. Previous works\nthat try to recover the surface normals from photometric stereo images treat\ncast shadows as a disturbance. We show that the self and cast shadows not only\ndo not disturb 3D reconstruction, but can be used alone, as a strong learning\nsignal, to recover the depth map and surface normals. We demonstrate that 3D\nreconstruction from shadows can even outperform shape-from-shading in certain\ncases. To the best of our knowledge, our method is the first to reconstruct 3D\nshape-from-shadows using neural networks. The method does not require any\npre-training or expensive labeled data, and is optimized during inference time.",
    "descriptor": "",
    "authors": [
      "Asaf Karnieli",
      "Ohad Fried",
      "Yacov Hel-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15065"
  },
  {
    "id": "arXiv:2203.15068",
    "title": "Face Verification Bypass",
    "abstract": "Face verification systems aim to validate the claimed identity using feature\nvectors and distance metrics. However, no attempt has been made to bypass such\na system using generated images that are constrained by the same feature\nvectors. In this work, we train StarGAN v2 to generate diverse images based on\na human user, that have similar feature vectors yet qualitatively look\ndifferent. We then demonstrate a proof of concept on a custom face verification\nsystem and verify our claims by demonstrating the same proof of concept in a\nblack box setting on dating applications that utilize similar face verification\nsystems.",
    "descriptor": "",
    "authors": [
      "Sanjana Sarda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.15068"
  },
  {
    "id": "arXiv:2203.15069",
    "title": "Leveraging Tactile Sensors for Low Latency Embedded Smart Hands for  Prosthetic and Robotic Applications",
    "abstract": "Tactile sensing is a crucial perception mode for robots and human amputees in\nneed of controlling a prosthetic device. Today robotic and prosthetic systems\nare still missing the important feature of accurate tactile sensing. This lack\nis mainly due to the fact that the existing tactile technologies have limited\nspatial and temporal resolution and are either expensive or not scalable. In\nthis paper, we present the design and the implementation of a hardware-software\nembedded system called SmartHand. It is specifically designed to enable the\nacquisition and the real-time processing of high-resolution tactile information\nfrom a hand-shaped multi-sensor array for prosthetic and robotic applications.\nDuring data collection, our system can deliver a high throughput of 100 frames\nper second, which is 13.7x higher than previous related work. We collected a\nnew tactile dataset while interacting with daily-life objects during five\ndifferent sessions. We propose a compact yet accurate convolutional neural\nnetwork that requires one order of magnitude less memory and 15.6x fewer\ncomputations compared to related work without degrading classification\naccuracy. The top-1 and top-3 cross-validation accuracies are respectively\n98.86% and 99.83%. We further analyze the inter-session variability and obtain\nthe best top-3 leave-one-out-validation accuracy of 77.84%. We deploy the\ntrained model on a high-performance ARM Cortex-M7 microcontroller achieving an\ninference time of only 100 ms minimizing the response latency. The overall\nmeasured power consumption is 505 mW. Finally, we fabricate a new control\nsensor and perform additional experiments to provide analyses on sensor\ndegradation and slip detection. This work is a step forward in giving robotic\nand prosthetic devices a sense of touch and demonstrates the practicality of a\nsmart embedded system empowered by tiny machine learning.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2107.14598\n",
    "authors": [
      "Xiaying Wang",
      "Fabian Geiger",
      "Vlad Niculescu",
      "Michele Magno",
      "Luca Benini"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15069"
  },
  {
    "id": "arXiv:2203.15071",
    "title": "User Driven Model Adjustment via Boolean Rule Explanations",
    "abstract": "AI solutions are heavily dependant on the quality and accuracy of the input\ntraining data, however the training data may not always fully reflect the most\nup-to-date policy landscape or may be missing business logic. The advances in\nexplainability have opened the possibility of allowing users to interact with\ninterpretable explanations of ML predictions in order to inject modifications\nor constraints that more accurately reflect current realities of the system. In\nthis paper, we present a solution which leverages the predictive power of ML\nmodels while allowing the user to specify modifications to decision boundaries.\nOur interactive overlay approach achieves this goal without requiring model\nretraining, making it appropriate for systems that need to apply instant\nchanges to their decision making. We demonstrate that user feedback rules can\nbe layered with the ML predictions to provide immediate changes which in turn\nsupports learning with less data.",
    "descriptor": "",
    "authors": [
      "Elizabeth M. Daly",
      "Massimiliano Mattetti",
      "\u00d6znur Alkan",
      "Rahul Nair"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15071"
  },
  {
    "id": "arXiv:2203.15072",
    "title": "Semantic Motion Correction Via Iterative Nonlinear Optimization and  Animation",
    "abstract": "Here, we present an end-to-end method to create 2D animation for a goalkeeper\nattempting to block a penalty kick, and then correct that motion using an\niterative nonlinear optimization scheme. The input is a raw video that is fed\ninto pose and object detection networks to find the skeleton of the goalkeeper\nand the ball. The output is a set of key frames of the skeleton associated with\nthe corrected motion so that if the goalkeeper missed the ball, the animation\nwill show then successfully deflecting it. Our method is robust enough correct\ndifferent kinds of mistakes the goalkeeper can make, such as not lunging far\nenough or jumping to the incorrect side. Our method is also meant to be\nsemantically similar to the goalkeeper's original motion, which helps keep our\nanimation grounded with respect to actual human behavior.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Sairamvinay Vijayaraghavan",
      "Jinxiao Song",
      "Wan-Jhen Lin",
      "Michael J Livanos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15072"
  },
  {
    "id": "arXiv:2203.15073",
    "title": "Understanding Questions that Arise When Working with Business Documents",
    "abstract": "While digital assistants are increasingly used to help with various\nproductivity tasks, less attention has been paid to employing them in the\ndomain of business documents. To build an agent that can handle users'\ninformation needs in this domain, we must first understand the types of\nassistance that users desire when working on their documents. In this work, we\npresent results from two user studies that characterize the information needs\nand queries of authors, reviewers, and readers of business documents. In the\nfirst study, we used experience sampling to collect users' questions in-situ as\nthey were working with their documents, and in the second, we built a\nhuman-in-the-loop document Q&A system which rendered assistance with a variety\nof users' questions. Our results have implications for the design of document\nassistants that complement AI with human intelligence including whether\nparticular skillsets or roles within the document are needed from human\nrespondents, as well as the challenges around such systems.",
    "descriptor": "\nComments: This paper will appear in CSCW'22\n",
    "authors": [
      "Farnaz Jahanbakhsh",
      "Elnaz Nouri",
      "Robert Sim",
      "Ryen W. White",
      "Adam Fourney"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.15073"
  },
  {
    "id": "arXiv:2203.15076",
    "title": "Neurosymbolic hybrid approach to driver collision warning",
    "abstract": "There are two main algorithmic approaches to autonomous driving systems: (1)\nAn end-to-end system in which a single deep neural network learns to map\nsensory input directly into appropriate warning and driving responses. (2) A\nmediated hybrid recognition system in which a system is created by combining\nindependent modules that detect each semantic feature. While some researchers\nbelieve that deep learning can solve any problem, others believe that a more\nengineered and symbolic approach is needed to cope with complex environments\nwith less data. Deep learning alone has achieved state-of-the-art results in\nmany areas, from complex gameplay to predicting protein structures. In\nparticular, in image classification and recognition, deep learning models have\nachieved accuracies as high as humans. But sometimes it can be very difficult\nto debug if the deep learning model doesn't work. Deep learning models can be\nvulnerable and are very sensitive to changes in data distribution.\nGeneralization can be problematic. It's usually hard to prove why it works or\ndoesn't. Deep learning models can also be vulnerable to adversarial attacks.\nHere, we combine deep learning-based object recognition and tracking with an\nadaptive neurosymbolic network agent, called the Non-Axiomatic Reasoning System\n(NARS), that can adapt to its environment by building concepts based on\nperceptual sequences. We achieved an improved intersection-over-union (IOU)\nobject recognition performance of 0.65 in the adaptive retraining model\ncompared to IOU 0.31 in the COCO data pre-trained model. We improved the object\ndetection limits using RADAR sensors in a simulated environment, and\ndemonstrated the weaving car detection capability by combining deep\nlearning-based object detection and tracking with a neurosymbolic model.",
    "descriptor": "\nComments: SPIE Defense and Commercial Sensing 2022\n",
    "authors": [
      "Kyongsik Yun",
      "Thomas Lu",
      "Alexander Huyen",
      "Patrick Hammer",
      "Pei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15076"
  },
  {
    "id": "arXiv:2203.15078",
    "title": "CD-Net: Histopathology Representation Learning using Pyramidal  Context-Detail Network",
    "abstract": "Extracting rich phenotype information, such as cell density and arrangement,\nfrom whole slide histology images (WSIs), requires analysis of large field of\nview, i.e more contexual information. This can be achieved through analyzing\nthe digital slides at lower resolution. A potential drawback is missing out on\ndetails present at a higher resolution. To jointly leverage complementary\ninformation from multiple resolutions, we present a novel transformer based\nPyramidal Context-Detail Network (CD-Net). CD-Net exploits the WSI pyramidal\nstructure through co-training of proposed Context and Detail Modules, which\noperate on inputs from multiple resolutions. The residual connections between\nthe modules enable the joint training paradigm while learning self-supervised\nrepresentation for WSIs. The efficacy of CD-Net is demonstrated in classifying\nLung Adenocarcinoma from Squamous cell carcinoma.",
    "descriptor": "\nComments: Submitted to MICCAI 2022\n",
    "authors": [
      "Saarthak Kapse",
      "Srijan Das",
      "Prateek Prasanna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15078"
  },
  {
    "id": "arXiv:2203.15082",
    "title": "Iterative, Deep Synthetic Aperture Sonar Image Segmentation",
    "abstract": "Synthetic aperture sonar (SAS) systems produce high-resolution images of the\nseabed environment. Moreover, deep learning has demonstrated superior ability\nin finding robust features for automating imagery analysis. However, the\nsuccess of deep learning is conditioned on having lots of labeled training\ndata, but obtaining generous pixel-level annotations of SAS imagery is often\npractically infeasible. This challenge has thus far limited the adoption of\ndeep learning methods for SAS segmentation. Algorithms exist to segment SAS\nimagery in an unsupervised manner, but they lack the benefit of\nstate-of-the-art learning methods and the results present significant room for\nimprovement. In view of the above, we propose a new iterative algorithm for\nunsupervised SAS image segmentation combining superpixel formation, deep\nlearning, and traditional clustering methods. We call our method Iterative Deep\nUnsupervised Segmentation (IDUS). IDUS is an unsupervised learning framework\nthat can be divided into four main steps: 1) A deep network estimates class\nassignments. 2) Low-level image features from the deep network are clustered\ninto superpixels. 3) Superpixels are clustered into class assignments (which we\ncall pseudo-labels) using $k$-means. 4) Resulting pseudo-labels are used for\nloss backpropagation of the deep network prediction. These four steps are\nperformed iteratively until convergence. A comparison of IDUS to current\nstate-of-the-art methods on a realistic benchmark dataset for SAS image\nsegmentation demonstrates the benefits of our proposal even as the IDUS incurs\na much lower computational burden during inference (actual labeling of a test\nimage). Finally, we also develop a semi-supervised (SS) extension of IDUS\ncalled IDSS and demonstrate experimentally that it can further enhance\nperformance while outperforming supervised alternatives that exploit the same\nlabeled training imagery.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.14563\n",
    "authors": [
      "Yung-Chen Sun",
      "Isaac D. Gerg",
      "Vishal Monga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15082"
  },
  {
    "id": "arXiv:2203.15086",
    "title": "X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval",
    "abstract": "In text-video retrieval, the objective is to learn a cross-modal similarity\nfunction between a text and a video that ranks relevant text-video pairs higher\nthan irrelevant pairs. However, videos inherently express a much wider gamut of\ninformation than texts. Instead, texts often capture sub-regions of entire\nvideos and are most semantically similar to certain frames within videos.\nTherefore, for a given text, a retrieval model should focus on the text's most\nsemantically similar video sub-regions to make a more relevant comparison. Yet,\nmost existing works aggregate entire videos without directly considering text.\nCommon text-agnostic aggregations schemes include mean-pooling or\nself-attention over the frames, but these are likely to encode misleading\nvisual information not described in the given text. To address this, we propose\na cross-modal attention model called X-Pool that reasons between a text and the\nframes of a video. Our core mechanism is a scaled dot product attention for a\ntext to attend to its most semantically similar frames. We then generate an\naggregated video representation conditioned on the text's attention weights\nover the frames. We evaluate our method on three benchmark datasets of MSR-VTT,\nMSVD and LSMDC, achieving new state-of-the-art results by up to 12% in relative\nimprovement in Recall@1. Our findings thereby highlight the importance of joint\ntext-video reasoning to extract important visual cues according to text. Full\ncode and demo can be found at: https://layer6ai-labs.github.io/xpool/",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Satya Krishna Gorti",
      "Noel Vouitsis",
      "Junwei Ma",
      "Keyvan Golestan",
      "Maksims Volkovs",
      "Animesh Garg",
      "Guangwei Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15086"
  },
  {
    "id": "arXiv:2203.15089",
    "title": "Learning Optical Flow, Depth, and Scene Flow without Real-World Labels",
    "abstract": "Self-supervised monocular depth estimation enables robots to learn 3D\nperception from raw video streams. This scalable approach leverages projective\ngeometry and ego-motion to learn via view synthesis, assuming the world is\nmostly static. Dynamic scenes, which are common in autonomous driving and\nhuman-robot interaction, violate this assumption. Therefore, they require\nmodeling dynamic objects explicitly, for instance via estimating pixel-wise 3D\nmotion, i.e. scene flow. However, the simultaneous self-supervised learning of\ndepth and scene flow is ill-posed, as there are infinitely many combinations\nthat result in the same 3D point. In this paper we propose DRAFT, a new method\ncapable of jointly learning depth, optical flow, and scene flow by combining\nsynthetic data with geometric self-supervision. Building upon the RAFT\narchitecture, we learn optical flow as an intermediate task to bootstrap depth\nand scene flow learning via triangulation. Our algorithm also leverages\ntemporal and geometric consistency losses across tasks to improve multi-task\nlearning. Our DRAFT architecture simultaneously establishes a new state of the\nart in all three tasks in the self-supervised monocular setting on the standard\nKITTI benchmark. Project page: https://sites.google.com/tri.global/draft.",
    "descriptor": "\nComments: Accepted to RA-L + ICRA 2022\n",
    "authors": [
      "Vitor Guizilini",
      "Kuan-Hui Lee",
      "Rares Ambrus",
      "Adrien Gaidon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15089"
  },
  {
    "id": "arXiv:2203.15090",
    "title": "New pyramidal hybrid textural and deep features based automatic skin  cancer classification model: Ensemble DarkNet and textural feature extractor",
    "abstract": "Background: Skin cancer is one of the widely seen cancer worldwide and\nautomatic classification of skin cancer can be benefited dermatology clinics\nfor an accurate diagnosis. Hence, a machine learning-based automatic skin\ncancer detection model must be developed. Material and Method: This research\ninterests to overcome automatic skin cancer detection problem. A colored skin\ncancer image dataset is used. This dataset contains 3297 images with two\nclasses. An automatic multilevel textural and deep features-based model is\npresented. Multilevel fuse feature generation using discrete wavelet transform\n(DWT), local phase quantization (LPQ), local binary pattern (LBP), pre-trained\nDarkNet19, and DarkNet53 are utilized to generate features of the skin cancer\nimages, top 1000 features are selected threshold value-based neighborhood\ncomponent analysis (NCA). The chosen top 1000 features are classified using the\n10-fold cross-validation technique. Results: To obtain results, ten-fold\ncross-validation is used and 91.54% classification accuracy results are\nobtained by using the recommended pyramidal hybrid feature generator and NCA\nselector-based model. Further, various training and testing separation ratios\n(90:10, 80:20, 70:30, 60:40, 50:50) are used and the maximum classification\nrate is calculated as 95.74% using the 90:10 separation ratio. Conclusions: The\nfindings and accuracies calculated are denoted that this model can be used in\ndermatology and pathology clinics to simplify the skin cancer detection process\nand help physicians.",
    "descriptor": "\nComments: 22 pages, 7 figures\n",
    "authors": [
      "Mehmet Baygin",
      "Turker Tuncer",
      "Sengul Dogan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15090"
  },
  {
    "id": "arXiv:2203.15095",
    "title": "Robust Speaker Recognition with Transformers Using wav2vec 2.0",
    "abstract": "Recent advances in unsupervised speech representation learning discover new\napproaches and provide new state-of-the-art for diverse types of speech\nprocessing tasks. This paper presents an investigation of using wav2vec 2.0\ndeep speech representations for the speaker recognition task. The proposed\nfine-tuning procedure of wav2vec 2.0 with simple TDNN and statistic pooling\nback-end using additive angular margin loss allows to obtain deep speaker\nembedding extractor that is well-generalized across different domains. It is\nconcluded that Contrastive Predictive Coding pretraining scheme efficiently\nutilizes the power of unlabeled data, and thus opens the door to powerful\ntransformer-based speaker recognition systems. The experimental results\nobtained in this study demonstrate that fine-tuning can be done on relatively\nsmall sets and a clean version of data. Using data augmentation during\nfine-tuning provides additional performance gains in speaker verification. In\nthis study speaker recognition systems were analyzed on a wide range of\nwell-known verification protocols: VoxCeleb1 cleaned test set, NIST SRE 18\ndevelopment set, NIST SRE 2016 and NIST SRE 2019 evaluation set, VOiCES\nevaluation set, NIST 2021 SRE, and CTS challenges sets.",
    "descriptor": "\nComments: Submitted to Interspeech2022. arXiv admin note: text overlap with arXiv:2111.02298\n",
    "authors": [
      "Sergey Novoselov",
      "Galina Lavrentyeva",
      "Anastasia Avdeeva",
      "Vladimir Volokhov",
      "Aleksei Gusev"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15095"
  },
  {
    "id": "arXiv:2203.15097",
    "title": "Dissipation-preserving discretization of the Cahn--Hilliard equation  with dynamic boundary conditions",
    "abstract": "This paper deals with time stepping schemes for the Cahn--Hilliard equation\nwith three different types of dynamic boundary conditions. The proposed schemes\nof first and second order are mass-conservative and energy-dissipative and --\nas they are based on a formulation as a coupled system of partial differential\nequations -- allow different spatial discretizations in the bulk and on the\nboundary. The latter enables refinements on the boundary without an adaptation\nof the mesh in the interior of the domain. The resulting computational gain is\nillustrated in numerical experiments.",
    "descriptor": "",
    "authors": [
      "R. Altmann",
      "C. Zimmer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15097"
  },
  {
    "id": "arXiv:2203.15099",
    "title": "LogicInference: A New Dataset for Teaching Logical Inference to seq2seq  Models",
    "abstract": "Machine learning models such as Transformers or LSTMs struggle with tasks\nthat are compositional in nature such as those involving reasoning/inference.\nAlthough many datasets exist to evaluate compositional generalization, when it\ncomes to evaluating inference abilities, options are more limited. This paper\npresents LogicInference, a new dataset to evaluate the ability of models to\nperform logical inference. The dataset focuses on inference using propositional\nlogic and a small subset of first-order logic, represented both in semi-formal\nlogical notation, as well as in natural language. We also report initial\nresults using a collection of machine learning models to establish an initial\nbaseline in this dataset.",
    "descriptor": "\nComments: Accepted at ICLR 2022 OSC workshop\n",
    "authors": [
      "Santiago Ontanon",
      "Joshua Ainslie",
      "Vaclav Cvicek",
      "Zachary Fisher"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15099"
  },
  {
    "id": "arXiv:2203.15100",
    "title": "Understanding out-of-distribution accuracies through quantifying  difficulty of test samples",
    "abstract": "Existing works show that although modern neural networks achieve remarkable\ngeneralization performance on the in-distribution (ID) dataset, the accuracy\ndrops significantly on the out-of-distribution (OOD) datasets\n\\cite{recht2018cifar, recht2019imagenet}. To understand why a variety of models\nconsistently make more mistakes in the OOD datasets, we propose a new metric to\nquantify the difficulty of the test images (either ID or OOD) that depends on\nthe interaction of the training dataset and the model. In particular, we\nintroduce \\textit{confusion score} as a label-free measure of image difficulty\nwhich quantifies the amount of disagreement on a given test image based on the\nclass conditional probabilities estimated by an ensemble of trained models.\nUsing the confusion score, we investigate CIFAR-10 and its OOD derivatives.\nNext, by partitioning test and OOD datasets via their confusion scores, we\npredict the relationship between ID and OOD accuracies for various\narchitectures. This allows us to obtain an estimator of the OOD accuracy of a\ngiven model only using ID test labels. Our observations indicate that the\nbiggest contribution to the accuracy drop comes from images with high confusion\nscores. Upon further inspection, we report on the nature of the misclassified\nimages grouped by their confusion scores: \\textit{(i)} images with high\nconfusion scores contain \\textit{weak spurious correlations} that appear in\nmultiple classes in the training data and lack clear \\textit{class-specific\nfeatures}, and \\textit{(ii)} images with low confusion scores exhibit spurious\ncorrelations that belong to another class, namely \\textit{class-specific\nspurious correlations}.",
    "descriptor": "\nComments: 18 pages, 15 figures\n",
    "authors": [
      "Berfin Simsek",
      "Melissa Hall",
      "Levent Sagun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15100"
  },
  {
    "id": "arXiv:2203.15101",
    "title": "Federated Named Entity Recognition",
    "abstract": "We present an analysis of the performance of Federated Learning in a\nparadigmatic natural-language processing task: Named-Entity Recognition (NER).\nFor our evaluation, we use the language-independent CoNLL-2003 dataset as our\nbenchmark dataset and a Bi-LSTM-CRF model as our benchmark NER model. We show\nthat federated training reaches almost the same performance as the centralized\nmodel, though with some performance degradation as the learning environments\nbecome more heterogeneous. We also show the convergence rate of federated\nmodels for NER. Finally, we discuss existing challenges of Federated Learning\nfor NLP applications that can foster future research directions.",
    "descriptor": "",
    "authors": [
      "Joel Mathew",
      "Dimitris Stripelis",
      "Jos\u00e9 Luis Ambite"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15101"
  },
  {
    "id": "arXiv:2203.15102",
    "title": "Rethinking Semantic Segmentation: A Prototype View",
    "abstract": "Prevalent semantic segmentation solutions, despite their different network\ndesigns (FCN based or attention based) and mask decoding strategies (parametric\nsoftmax based or pixel-query based), can be placed in one category, by\nconsidering the softmax weights or query vectors as learnable class prototypes.\nIn light of this prototype view, this study uncovers several limitations of\nsuch parametric segmentation regime, and proposes a nonparametric alternative\nbased on non-learnable prototypes. Instead of prior methods learning a single\nweight/query vector for each class in a fully parametric manner, our model\nrepresents each class as a set of non-learnable prototypes, relying solely on\nthe mean features of several training pixels within that class. The dense\nprediction is thus achieved by nonparametric nearest prototype retrieving. This\nallows our model to directly shape the pixel embedding space, by optimizing the\narrangement between embedded pixels and anchored prototypes. It is able to\nhandle arbitrary number of classes with a constant amount of learnable\nparameters. We empirically show that, with FCN based and attention based\nsegmentation models (i.e., HRNet, Swin, SegFormer) and backbones (i.e., ResNet,\nHRNet, Swin, MiT), our nonparametric framework yields compelling results over\nseveral datasets (i.e., ADE20K, Cityscapes, COCO-Stuff), and performs well in\nthe large-vocabulary situation. We expect this work will provoke a rethink of\nthe current de facto semantic segmentation model design.",
    "descriptor": "\nComments: Accepted to CVPR 2022 (Oral); Code: this https URL\n",
    "authors": [
      "Tianfei Zhou",
      "Wenguan Wang",
      "Ender Konukoglu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15102"
  },
  {
    "id": "arXiv:2203.15103",
    "title": "Adversarial Motion Priors Make Good Substitutes for Complex Reward  Functions",
    "abstract": "Training a high-dimensional simulated agent with an under-specified reward\nfunction often leads the agent to learn physically infeasible strategies that\nare ineffective when deployed in the real world. To mitigate these unnatural\nbehaviors, reinforcement learning practitioners often utilize complex reward\nfunctions that encourage physically plausible behaviors. However, a tedious\nlabor-intensive tuning process is often required to create hand-designed\nrewards which might not easily generalize across platforms and tasks. We\npropose substituting complex reward functions with \"style rewards\" learned from\na dataset of motion capture demonstrations. A learned style reward can be\ncombined with an arbitrary task reward to train policies that perform tasks\nusing naturalistic strategies. These natural strategies can also facilitate\ntransfer to the real world. We build upon Adversarial Motion Priors -- an\napproach from the computer graphics domain that encodes a style reward from a\ndataset of reference motions -- to demonstrate that an adversarial approach to\ntraining policies can produce behaviors that transfer to a real quadrupedal\nrobot without requiring complex reward functions. We also demonstrate that an\neffective style reward can be learned from a few seconds of motion capture data\ngathered from a German Shepherd and leads to energy-efficient locomotion\nstrategies with natural gait transitions.",
    "descriptor": "\nComments: 8 pages, 6 figures, 3 tables\n",
    "authors": [
      "Alejandro Escontrela",
      "Xue Bin Peng",
      "Wenhao Yu",
      "Tingnan Zhang",
      "Atil Iscen",
      "Ken Goldberg",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15103"
  },
  {
    "id": "arXiv:2203.15104",
    "title": "FedADMM: A Federated Primal-Dual Algorithm Allowing Partial  Participation",
    "abstract": "Federated learning is a framework for distributed optimization that places\nemphasis on communication efficiency. In particular, it follows a client-server\nbroadcast model and is particularly appealing because of its ability to\naccommodate heterogeneity in client compute and storage resources, non-i.i.d.\ndata assumptions, and data privacy. Our contribution is to offer a new\nfederated learning algorithm, FedADMM, for solving non-convex composite\noptimization problems with non-smooth regularizers. We prove converges of\nFedADMM for the case when not all clients are able to participate in a given\ncommunication round under a very general sampling model.",
    "descriptor": "",
    "authors": [
      "Han Wang",
      "Siddartha Marella",
      "James Anderson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.15104"
  },
  {
    "id": "arXiv:2203.15106",
    "title": "Investigation of Different Calibration Methods for Deep Speaker  Embedding based Verification Systems",
    "abstract": "Deep speaker embedding extractors have already become new state-of-the-art\nsystems in the speaker verification field. However, the problem of verification\nscore calibration for such systems often remains out of focus. An irrelevant\nscore calibration leads to serious issues, especially in the case of unknown\nacoustic conditions, even if we use a strong speaker verification system in\nterms of threshold-free metrics. This paper presents an investigation over\nseveral methods of score calibration: a classical approach based on the\nlogistic regression model; the recently presented magnitude estimation network\nMagnetO that uses activations from the pooling layer of the trained deep\nspeaker extractor and generalization of such approach based on separate scale\nand offset prediction neural networks. An additional focus of this research is\nto estimate the impact of score normalization on the calibration performance of\nthe system. The obtained results demonstrate that there are no serious problems\nif in-domain development data are used for calibration tuning. Otherwise, a\ntrade-off between good calibration performance and threshold-free system\nquality arises. In most cases using adaptive s-norm helps to stabilize score\ndistributions and to improve system performance. Meanwhile, some experiments\ndemonstrate that novel approaches have their limits in score stabilization on\nseveral datasets.",
    "descriptor": "\nComments: Submitted to Interspeech2022\n",
    "authors": [
      "Galina Lavrentyeva",
      "Sergey Novoselov",
      "Andrey Shulipa",
      "Marina Volkova",
      "Aleksandr Kozlov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15106"
  },
  {
    "id": "arXiv:2203.15107",
    "title": "Motion Planning for Agile Legged Locomotion using Failure Margin  Constraints",
    "abstract": "The complex dynamics of agile robotic legged locomotion requires motion\nplanning to intelligently adjust footstep locations. Often, bipedal footstep\nand motion planning use mathematically simple models such as the linear\ninverted pendulum, instead of dynamically-rich models that do not have\nclosed-form solutions. We propose a real-time optimization method to plan for\ndynamical models that do not have closed form solutions and experience\nirrecoverable failure. Our method uses a data-driven approximation of the\nstep-to-step dynamics and of a failure margin function. This failure margin\nfunction is an oriented distance function in state-action space where it\ndescribes the signed distance to success or failure. The motion planning\nproblem is formed as a nonlinear program with constraints that enforce the\napproximated forward dynamics and the validity of state-action pairs. For\nillustration, this method is applied to create a planner for an actuated\nspring-loaded inverted pendulum model. In an ablation study, the failure margin\nconstraints decreased the number of invalid solutions by between 24 and 47\npercentage points across different objectives and horizon lengths. While we\ndemonstrate the method on a canonical model of locomotion, we also discuss how\nthis can be applied to data-driven models and full-order robot models.",
    "descriptor": "\nComments: 6 pages, 5 figures, 1 table\n",
    "authors": [
      "Kevin Green",
      "John Warila",
      "Ross L. Hatton",
      "Jonathan Hurst"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15107"
  },
  {
    "id": "arXiv:2203.15108",
    "title": "A Well-Composed Text is Half Done! Composition Sampling for Diverse  Conditional Generation",
    "abstract": "We propose Composition Sampling, a simple but effective method to generate\ndiverse outputs for conditional generation of higher quality compared to\nprevious stochastic decoding strategies. It builds on recently proposed\nplan-based neural generation models (Narayan et al, 2021) that are trained to\nfirst create a composition of the output and then generate by conditioning on\nit and the input. Our approach avoids text degeneration by first sampling a\ncomposition in the form of an entity chain and then using beam search to\ngenerate the best possible text grounded to this entity chain. Experiments on\nsummarization (CNN/DailyMail and XSum) and question generation (SQuAD), using\nexisting and newly proposed automatic metrics together with human-based\nevaluation, demonstrate that Composition Sampling is currently the best\navailable decoding strategy for generating diverse meaningful outputs.",
    "descriptor": "\nComments: 21 pages, ACL 2022\n",
    "authors": [
      "Shashi Narayan",
      "Gon\u00e7alo Sim\u00f5es",
      "Yao Zhao",
      "Joshua Maynez",
      "Dipanjan Das",
      "Michael Collins",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.15108"
  },
  {
    "id": "arXiv:2203.15109",
    "title": "27 Open Problems in Kolmogorov Complexity",
    "abstract": "The paper proposes open problems in classical Kolmogorov complexity. Each\nproblem is presented with background information and thus the article also\nsurveys some recent studies in the area.",
    "descriptor": "\nComments: The paper has appeared in the Open Problems column of SIGACT News\n",
    "authors": [
      "Andrei Romashchenko",
      "Alexander Shen",
      "Marius Zimand"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.15109"
  },
  {
    "id": "arXiv:2203.15110",
    "title": "The State of Fortran",
    "abstract": "A community of developers has formed to modernize the Fortran ecosystem. In\nthis article, we describe the high-level features of Fortran that continue to\nmake it a good choice for scientists and engineers in the 21st century. Ongoing\nefforts include the development of a Fortran standard library and package\nmanager, the fostering of a friendly and welcoming online community, improved\ncompiler support, and language feature development. The lessons learned are\ncommon across contemporary programming languages and help reduce the learning\ncurve and increase adoption of Fortran.",
    "descriptor": "\nComments: 12 pages, 2 figures, 1 table. Computing in Science & Engineering (2022)\n",
    "authors": [
      "Laurence Kedward",
      "Balint",
      "Aradi",
      "Ondrej Certik",
      "Milan Curcic",
      "Sebastian Ehlert",
      "Philipp Engel",
      "Rohit Goswami",
      "Michael Hirsch",
      "Asdrubal Lozada-Blanco",
      "Vincent Magnin",
      "Arjen Markus",
      "Emanuele Pagone",
      "Ivan Pribec",
      "Brad Richardson",
      "Harris Snyder"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.15110"
  },
  {
    "id": "arXiv:2203.15111",
    "title": "Multi-constrained topology optimization via the topological sensitivity",
    "abstract": "The objective of this paper is to introduce and demonstrate a robust method\nfor multi-constrained topology optimization. The method is derived by combining\nthe topological sensitivity with the classic augmented Lagrangian formulation.\nThe primary advantages of the proposed method are: (1) it rests on\nwell-established augmented Lagrangian formulation for constrained optimization,\n(2) the augmented topological level-set can be derived systematically for an\narbitrary set of loads and constraints, and (3) the level-set can be updated\nefficiently. The method is illustrated through numerical experiments.",
    "descriptor": "",
    "authors": [
      "Shiguang Deng",
      "Krishnan Suresh"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.15111"
  },
  {
    "id": "arXiv:2203.15112",
    "title": "Domain Knowledge Driven Pseudo Labels for Interpretable Goal-Conditioned  Interactive Trajectory Prediction",
    "abstract": "Motion forecasting in highly interactive scenarios is a challenging problem\nin autonomous driving. In such scenarios, we need to accurately predict the\njoint behavior of interacting agents to ensure the safe and efficient\nnavigation of autonomous vehicles. Recently, goal-conditioned methods have\ngained increasing attention due to their advantage in performance and their\nability to capture the multimodality in trajectory distribution. In this work,\nwe study the joint trajectory prediction problem with the goal-conditioned\nframework. In particular, we introduce a\nconditional-variational-autoencoder-based (CVAE) model to explicitly encode\ndifferent interaction modes into the latent space. However, we discover that\nthe vanilla model suffers from posterior collapse and cannot induce an\ninformative latent space as desired. To address these issues, we propose a\nnovel approach to avoid KL vanishing and induce an interpretable interactive\nlatent space with pseudo labels. The pseudo labels allow us to incorporate\narbitrary domain knowledge on interaction. We motivate the proposed method\nusing an illustrative toy example. In addition, we validate our framework on\nthe Waymo Open Motion Dataset with both quantitative and qualitative\nevaluations.",
    "descriptor": "",
    "authors": [
      "Lingfeng Sun",
      "Chen Tang",
      "Yaru Niu",
      "Enna Sachdeva",
      "Chiho Cho",
      "Teruhisa Misu",
      "Masayoshi Tomizuka",
      "Wei Zhan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15112"
  },
  {
    "id": "arXiv:2203.15115",
    "title": "Multi-constrained 3D topology optimization via augmented topological  level-set",
    "abstract": "The objective of this paper is to introduce and demonstrate a robust\nmethodology for solving multi-constrained 3D topology optimization problems.\nThe proposed methodology is a combination of the topological level-set\nformulation, augmented Lagrangian algorithm, and assembly-free deflated finite\nelement analysis (FEA). The salient features of the proposed method include:\n(1) it exploits the topological sensitivity fields that can be derived for a\nvariety of constraints, (2) it rests on well-established augmented Lagrangian\nformulation to solve constrained problems, and (3) it overcomes the\ncomputational challenges by employing assembly-free deflated FEA. The proposed\nmethod is illustrated through several 3D numerical experiments.",
    "descriptor": "",
    "authors": [
      "Shiguang Deng",
      "Suresh Krishnan"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.15115"
  },
  {
    "id": "arXiv:2203.15117",
    "title": "Stress constrained thermo-elastic topology optimization with varying  temperature fields via augmented topological sensitivity based level-set",
    "abstract": "Engineering structures must often be designed to resist thermally induced\nstresses. Significant progress has been made on the design of such structures\nthrough thermo-elastic topology optimization. However, a computationally\nefficient framework to handle stress-constrained large-scale problems is\nlacking. The main contribution of this paper is to address this limitation. In\nparticular, a unified topological-sensitivity (TS) based level-set approach is\npresented in this paper for optimizing thermo-elastic structures subject to\nnon-uniform temperatures. The TS fields for various thermo-elastic objectives\nare derived, and, to address multiple constraints, an augmented Lagrangian\nmethod is developed to explore Pareto topologies. Numerical examples\ndemonstrate the capability of the proposed framework to solve large-scale\ndesign problems. Comparison is made between pure elastic problems, and its\nthermo-elastic counterpart, shedding light on the influence of thermo-elastic\ncoupling on optimized topologies.",
    "descriptor": "",
    "authors": [
      "Shiguang Deng",
      "Krishnan Suresh"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.15117"
  },
  {
    "id": "arXiv:2203.15118",
    "title": "LiDAR Snowfall Simulation for Robust 3D Object Detection",
    "abstract": "3D object detection is a central task for applications such as autonomous\ndriving, in which the system needs to localize and classify surrounding traffic\nagents, even in the presence of adverse weather. In this paper, we address the\nproblem of LiDAR-based 3D object detection under snowfall. Due to the\ndifficulty of collecting and annotating training data in this setting, we\npropose a physically based method to simulate the effect of snowfall on real\nclear-weather LiDAR point clouds. Our method samples snow particles in 2D space\nfor each LiDAR line and uses the induced geometry to modify the measurement for\neach LiDAR beam accordingly. Moreover, as snowfall often causes wetness on the\nground, we also simulate ground wetness on LiDAR point clouds. We use our\nsimulation to generate partially synthetic snowy LiDAR data and leverage these\ndata for training 3D object detection models that are robust to snowfall. We\nconduct an extensive evaluation using several state-of-the-art 3D object\ndetection methods and show that our simulation consistently yields significant\nperformance gains on the real snowy STF dataset compared to clear-weather\nbaselines and competing simulation approaches, while not sacrificing\nperformance in clear weather. Our code is available at\nwww.github.com/SysCV/LiDAR_snow_sim.",
    "descriptor": "\nComments: Oral at CVPR 2022\n",
    "authors": [
      "Martin Hahner",
      "Christos Sakaridis",
      "Mario Bijelic",
      "Felix Heide",
      "Fisher Yu",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15118"
  },
  {
    "id": "arXiv:2203.15119",
    "title": "Visual Odometry for RGB-D Cameras",
    "abstract": "Visual odometry is the process of estimating the position and orientation of\na camera by analyzing the images associated to it. This paper develops a quick\nand accurate approach to visual odometry of a moving RGB-D camera navigating on\na static environment. The proposed algorithm uses SURF (Speeded Up Robust\nFeatures) as feature extractor, RANSAC (Random Sample Consensus) to filter the\nresults and Minimum Mean Square to estimate the rigid transformation of six\nparameters between successive video frames. Data from a Kinect camera were used\nin the tests. The results show that this approach is feasible and promising,\nsurpassing in performance the algorithms ICP (Interactive Closest Point) and\nSfM (Structure from Motion) in tests using a publicly available dataset.",
    "descriptor": "",
    "authors": [
      "Afonso Fontes",
      "Jose Everardo Bessa Maia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15119"
  },
  {
    "id": "arXiv:2203.15120",
    "title": "The...Tinderverse?: Opportunities and Challenges for User Safety in  Extended Reality (XR) Dating Apps",
    "abstract": "Dating apps such as Tinder have announced plans for a dating metaverse: the\nincorporation of XR technologies into the online dating process to augment\ninteractions between potential sexual partners across virtual and physical\nworlds. While the dating metaverse is still in conceptual stages we can\nforecast significant harms that it may expose daters to given prior research\ninto the frequency and severity of sexual harms facilitated by dating apps as\nwell as harms within social VR environments. In this workshop paper we envision\nhow XR could enrich virtual-to-physical interaction between potential sexual\npartners and outline harms that it will likely perpetuate as well. We then\nintroduce our ongoing research to preempt such harms: a participatory design\nstudy with sexual violence experts and demographics at disproportionate risk of\nsexual violence to produce mitigative solutions to sexual violence perpetuated\nby XR-enabled dating apps.",
    "descriptor": "\nComments: Accepted to CHI 22 Workshop \"Novel Challenges of Safety, Security and Privacy in Extended Reality\"\n",
    "authors": [
      "Sarath S. Shanker",
      "Douglas Zytko"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.15120"
  },
  {
    "id": "arXiv:2203.15121",
    "title": "Tightly Seal Your Sensitive Pointers with PACTight",
    "abstract": "ARM is becoming more popular in desktops and data centers, opening a new\nrealm in terms of security attacks against ARM. ARM has released Pointer\nAuthentication, a new hardware security feature that is intended to ensure\npointer integrity with cryptographic primitives. In this paper, we utilize\nPointer Authentication (PA) to build a novel scheme to completely prevent any\nmisuse of security-sensitive pointers. We propose PACTight to tightly seal\nthese pointers. PACTight utilizes a strong and unique modifier that addresses\nthe current issues with the state-of-the-art PA defense mechanisms. We\nimplement four defenses based on the PACTight mechanism. Our security and\nperformance evaluation results show that PACTight defenses are more efficient\nand secure. Using real PA instructions, we evaluated PACTight on 30 different\napplications, including NGINX web server, with an average performance overhead\nof 4.07% even when enforcing our strongest defense. PACTight demonstrates its\neffectiveness and efficiency with real PA instructions on real hardware.",
    "descriptor": "\nComments: Accepted for publication to USENIX Security 2022\n",
    "authors": [
      "Mohannad Ismail",
      "Andrew Quach",
      "Christopher Jelesnianski",
      "Yeongjin Jang",
      "Changwoo Min"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.15121"
  },
  {
    "id": "arXiv:2203.15124",
    "title": "Toward Deep Learning Based Access Control",
    "abstract": "A common trait of current access control approaches is the challenging need\nto engineer abstract and intuitive access control models. This entails\ndesigning access control information in the form of roles (RBAC), attributes\n(ABAC), or relationships (ReBAC) as the case may be, and subsequently,\ndesigning access control rules. This framework has its benefits but has\nsignificant limitations in the context of modern systems that are dynamic,\ncomplex, and large-scale, due to which it is difficult to maintain an accurate\naccess control state in the system for a human administrator. This paper\nproposes Deep Learning Based Access Control (DLBAC) by leveraging significant\nadvances in deep learning technology as a potential solution to this problem.\nWe envision that DLBAC could complement and, in the long-term, has the\npotential to even replace, classical access control models with a neural\nnetwork that reduces the burden of access control model engineering and\nupdates. Without loss of generality, we conduct a thorough investigation of a\ncandidate DLBAC model, called DLBAC_alpha, using both real-world and synthetic\ndatasets. We demonstrate the feasibility of the proposed approach by addressing\nissues related to accuracy, generalization, and explainability. We also discuss\nchallenges and future research directions.",
    "descriptor": "\nComments: 12 pages, 15 figures, to appear in CODASPY 2022\n",
    "authors": [
      "Mohammad Nur Nobi",
      "Ram Krishnan",
      "Yufei Huang",
      "Mehrnoosh Shakarami",
      "Ravi Sandhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15124"
  },
  {
    "id": "arXiv:2203.15125",
    "title": "Text2Pos: Text-to-Point-Cloud Cross-Modal Localization",
    "abstract": "Natural language-based communication with mobile devices and home appliances\nis becoming increasingly popular and has the potential to become natural for\ncommunicating with mobile robots in the future. Towards this goal, we\ninvestigate cross-modal text-to-point-cloud localization that will allow us to\nspecify, for example, a vehicle pick-up or goods delivery location. In\nparticular, we propose Text2Pos, a cross-modal localization module that learns\nto align textual descriptions with localization cues in a coarse- to-fine\nmanner. Given a point cloud of the environment, Text2Pos locates a position\nthat is specified via a natural language-based description of the immediate\nsurroundings. To train Text2Pos and study its performance, we construct\nKITTI360Pose, the first dataset for this task based on the recently introduced\nKITTI360 dataset. Our experiments show that we can localize 65% of textual\nqueries within 15m distance to query locations for top-10 retrieved locations.\nThis is a starting point that we hope will spark future developments towards\nlanguage-based navigation.",
    "descriptor": "\nComments: CVPR2022 Camera Ready Version\n",
    "authors": [
      "Manuel Kolmet",
      "Qunjie Zhou",
      "Aljosa Osep",
      "Laura Leal-Taixe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15125"
  },
  {
    "id": "arXiv:2203.15126",
    "title": "Network Performance Estimator with Applications to Route Selection for  IoT Multimedia Applications",
    "abstract": "Estimating the performance of multimedia traffic is important in numerous\ncontexts, including routing and forwarding, QoS provisioning, and adaptive\nvideo streaming. This paper proposes a network performance estimator which aims\nat providing, in quasi real-time, network performance estimates for IoT\nmultimedia traffic in IEEE 802.11 multihop wireless networks. To our knowledge,\nthe proposed multimedia-aware performance estimator, or MAPE, is the first\ndeterministic simulation-based estimator that provides real-time per-flow\nthroughput, packet loss and delay estimates while considering inter-flow\ninterference and multi-rate flows, typical of multimedia traffic. Our\nexperimental results indicate that MAPE is able to provide network performance\nestimates that can be used by IoT multimedia services, notably to inform\nreal-time route selection in IoT video transmission, at a fraction of the\nexecution time when compared to stochastic network simulators. When compared to\nexisting deterministic simulators, MAPE yields higher accuracy at comparable\nexecution times due to its ability to consider multi-rate flows.",
    "descriptor": "\nComments: 16 pages, 11 figures, 2 tables and 1 algorithm\n",
    "authors": [
      "Fabiano Bhering",
      "Diego Passos",
      "C\u00e9lio Albuquerque",
      "Katia Obraczka"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.15126"
  },
  {
    "id": "arXiv:2203.15127",
    "title": "An Online Approach to Solve the Dynamic Vehicle Routing Problem with  Stochastic Trip Requests for Paratransit Services",
    "abstract": "Many transit agencies operating paratransit and microtransit services have to\nrespond to trip requests that arrive in real-time, which entails solving hard\ncombinatorial and sequential decision-making problems under uncertainty. To\navoid decisions that lead to significant inefficiency in the long term,\nvehicles should be allocated to requests by optimizing a non-myopic utility\nfunction or by batching requests together and optimizing a myopic utility\nfunction. While the former approach is typically offline, the latter can be\nperformed online. We point out two major issues with such approaches when\napplied to paratransit services in practice. First, it is difficult to batch\nparatransit requests together as they are temporally sparse. Second, the\nenvironment in which transit agencies operate changes dynamically (e.g.,\ntraffic conditions), causing estimates that are learned offline to become\nstale. To address these challenges, we propose a fully online approach to solve\nthe dynamic vehicle routing problem (DVRP) with time windows and stochastic\ntrip requests that is robust to changing environmental dynamics by\nconstruction. We focus on scenarios where requests are relatively sparse - our\nproblem is motivated by applications to paratransit services. We formulate DVRP\nas a Markov decision process and use Monte Carlo tree search to evaluate\nactions for any given state. Accounting for stochastic requests while\noptimizing a non-myopic utility function is computationally challenging;\nindeed, the action space for such a problem is intractably large in practice.\nTo tackle the large action space, we leverage the structure of the problem to\ndesign heuristics that can sample promising actions for the tree search. Our\nexperiments using real-world data from our partner agency show that the\nproposed approach outperforms existing state-of-the-art approaches both in\nterms of performance and robustness.",
    "descriptor": "",
    "authors": [
      "Michael Wilbur",
      "Salah Uddin Kadir",
      "Youngseo Kim",
      "Geoffrey Pettet",
      "Ayan Mukhopadhyay",
      "Philip Pugliese",
      "Samitha Samaranayake",
      "Aron Laszka",
      "Abhishek Dubey"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.15127"
  },
  {
    "id": "arXiv:2203.15129",
    "title": "A Study of Reinforcement Learning Algorithms for Aggregates of  Minimalistic Robots",
    "abstract": "The aim of this paper is to study how to apply deep reinforcement learning\nfor the control of aggregates of minimalistic robots. We define aggregates as\ngroups of robots with a physical connection that compels them to form a\nspecified shape. In our case, the robots are pre-attached to an object that\nmust be collectively transported to a known location. Minimalism, in our\nsetting, stems from the barebone capabilities we assume: The robots can sense\nthe target location and the immediate obstacles, but lack the means to\ncommunicate explicitly through, e.g., message-passing. In our setting,\ncommunication is implicit, i.e., mediated by aggregated push-and-pull on the\nobject exerted by each robot. We analyze the ability to reach coordinated\nbehavior of four well-known algorithms for deep reinforcement learning (DQN,\nDDQN, DDPG, and TD3). Our experiments include robot failures and different\ntypes of environmental obstacles. We compare the performance of the best\ncontrol strategies found, highlighting strengths and weaknesses of each of the\nconsidered training algorithms.",
    "descriptor": "\nComments: 7 pages, submitted to IROS 2022\n",
    "authors": [
      "Joshua Bloom",
      "Apratim Mukherjee",
      "Carlo Pinciroli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15129"
  },
  {
    "id": "arXiv:2203.15132",
    "title": "LocalBins: Improving Depth Estimation by Learning Local Distributions",
    "abstract": "We propose a novel architecture for depth estimation from a single image. The\narchitecture itself is based on the popular encoder-decoder architecture that\nis frequently used as a starting point for all dense regression tasks. We build\non AdaBins which estimates a global distribution of depth values for the input\nimage and evolve the architecture in two ways. First, instead of predicting\nglobal depth distributions, we predict depth distributions of local\nneighborhoods at every pixel. Second, instead of predicting depth distributions\nonly towards the end of the decoder, we involve all layers of the decoder. We\ncall this new architecture LocalBins. Our results demonstrate a clear\nimprovement over the state-of-the-art in all metrics on the NYU-Depth V2\ndataset. Code and pretrained models will be made publicly available.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Shariq Farooq Bhat",
      "Ibraheem Alhashim",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15132"
  },
  {
    "id": "arXiv:2203.15135",
    "title": "Filler Word Detection and Classification: A Dataset and Benchmark",
    "abstract": "Filler words such as `uh' or `um' are sounds or words people use to signal\nthey are pausing to think. Finding and removing filler words from recordings is\na common and tedious task in media editing. Automatically detecting and\nclassifying filler words could greatly aid in this task, but few studies have\nbeen published on this problem. A key reason is the absence of a dataset with\nannotated filler words for training and evaluation. In this work, we present a\nnovel speech dataset, PodcastFillers, with 35K annotated filler words and 50K\nannotations of other sounds that commonly occur in podcasts such as breaths,\nlaughter, and word repetitions. We propose a pipeline that leverages VAD and\nASR to detect filler candidates and a classifier to distinguish between filler\nword types. We evaluate our proposed pipeline on PodcastFillers, compare to\nseveral baselines, and present a detailed ablation study. In particular, we\nevaluate the importance of using ASR and how it compares to a\ntranscription-free approach resembling keyword spotting. We show that our\npipeline obtains state-of-the-art results, and that leveraging ASR strongly\noutperforms a keyword spotting approach. We make PodcastFillers publicly\navailable, and hope our work serves as a benchmark for future research.",
    "descriptor": "\nComments: Submitted to Insterspeech 2022\n",
    "authors": [
      "Ge Zhu",
      "Juan-Pablo Caceres",
      "Justin Salamon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15135"
  },
  {
    "id": "arXiv:2203.15140",
    "title": "Improving Source Separation by Explicitly Modeling Dependencies Between  Sources",
    "abstract": "We propose a new method for training a supervised source separation system\nthat aims to learn the interdependent relationships between all combinations of\nsources in a mixture. Rather than independently estimating each source from a\nmix, we reframe the source separation problem as an Orderless Neural\nAutoregressive Density Estimator (NADE), and estimate each source from both the\nmix and a random subset of the other sources. We adapt a standard source\nseparation architecture, Demucs, with additional inputs for each individual\nsource, in addition to the input mixture. We randomly mask these input sources\nduring training so that the network learns the conditional dependencies between\nthe sources. By pairing this training method with a block Gibbs sampling\nprocedure at inference time, we demonstrate that the network can iteratively\nimprove its separation performance by conditioning a source estimate on its\nearlier source estimates. Experiments on two source separation datasets show\nthat training a Demucs model with an Orderless NADE approach and using Gibbs\nsampling (up to 512 steps) at inference time strongly outperforms a Demucs\nbaseline that uses a standard regression loss and direct (one step) estimation\nof sources.",
    "descriptor": "\nComments: To appear at ICASSP 2022\n",
    "authors": [
      "Ethan Manilow",
      "Curtis Hawthorne",
      "Cheng-Zhi Anna Huang",
      "Bryan Pardo",
      "Jesse Engel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15140"
  },
  {
    "id": "arXiv:2203.15143",
    "title": "Towards End-to-End Unified Scene Text Detection and Layout Analysis",
    "abstract": "Scene text detection and document layout analysis have long been treated as\ntwo separate tasks in different image domains. In this paper, we bring them\ntogether and introduce the task of unified scene text detection and layout\nanalysis. The first hierarchical scene text dataset is introduced to enable\nthis novel research task. We also propose a novel method that is able to\nsimultaneously detect scene text and form text clusters in a unified way.\nComprehensive experiments show that our unified model achieves better\nperformance than multiple well-designed baseline methods. Additionally, this\nmodel achieves state-of-the-art results on multiple scene text detection\ndatasets without the need of complex post-processing. Dataset and code:\nhttps://github.com/google-research-datasets/hiertext.",
    "descriptor": "\nComments: To appear at CVPR 2022\n",
    "authors": [
      "Shangbang Long",
      "Siyang Qin",
      "Dmitry Panteleev",
      "Alessandro Bissacco",
      "Yasuhisa Fujii",
      "Michalis Raptis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15143"
  },
  {
    "id": "arXiv:2203.15144",
    "title": "Human-AI Collaboration Enables More Empathic Conversations in Text-based  Peer-to-Peer Mental Health Support",
    "abstract": "Advances in artificial intelligence (AI) are enabling systems that augment\nand collaborate with humans to perform simple, mechanistic tasks like\nscheduling meetings and grammar-checking text. However, such Human-AI\ncollaboration poses challenges for more complex, creative tasks, such as\ncarrying out empathic conversations, due to difficulties of AI systems in\nunderstanding complex human emotions and the open-ended nature of these tasks.\nHere, we focus on peer-to-peer mental health support, a setting in which\nempathy is critical for success, and examine how AI can collaborate with humans\nto facilitate peer empathy during textual, online supportive conversations. We\ndevelop Hailey, an AI-in-the-loop agent that provides just-in-time feedback to\nhelp participants who provide support (peer supporters) respond more\nempathically to those seeking help (support seekers). We evaluate Hailey in a\nnon-clinical randomized controlled trial with real-world peer supporters on\nTalkLife (N=300), a large online peer-to-peer support platform. We show that\nour Human-AI collaboration approach leads to a 19.60% increase in\nconversational empathy between peers overall. Furthermore, we find a larger\n38.88% increase in empathy within the subsample of peer supporters who\nself-identify as experiencing difficulty providing support. We systematically\nanalyze the Human-AI collaboration patterns and find that peer supporters are\nable to use the AI feedback both directly and indirectly without becoming\noverly reliant on AI while reporting improved self-efficacy post-feedback. Our\nfindings demonstrate the potential of feedback-driven, AI-in-the-loop writing\nsystems to empower humans in open-ended, social, creative tasks such as\nempathic conversations.",
    "descriptor": "",
    "authors": [
      "Ashish Sharma",
      "Inna W. Lin",
      "Adam S. Miner",
      "David C. Atkins",
      "Tim Althoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.15144"
  },
  {
    "id": "arXiv:2203.15145",
    "title": "RoBoa: Construction and Evaluation of a Steerable Vine Robot for Search  and Rescue Applications",
    "abstract": "RoBoa is a vine-like search and rescue robot that can explore narrow and\ncluttered environments such as destroyed buildings. The robot assists rescue\nteams in finding and communicating with trapped people. It employs the\nprinciple of vine robots for locomotion, everting the tip of its tube to move\nforward. Inside the tube, pneumatic actuators enable lateral movement. The head\ncarries sensors and is mounted outside at the tip of the tube. At the back, a\nsupply box contains the rolled up tube and provides pressurized air, power,\ncomputation, as well as an interface for the user to interact with the system.\nA decentralized control scheme was implemented that reduces the required number\nof cables and takes care of the low-level control of the pneumatic actuators.\nThe design, characterization, and experimental evaluation of the system and its\ncrucial components is shown. The complete prototype is fully functional and was\nevaluated in a realistic environment of a collapsed building where the\nremote-controlled robot was able to repeatedly locate a trapped person after a\ntravel distance of about 10 m.",
    "descriptor": "\nComments: 6 pages, 5 figures, 2021 IEEE 4th International Conference on Soft Robotics (RoboSoft). For associated video, see this this https URL\n",
    "authors": [
      "Pascal Auf der Maur",
      "Betim Djambazi",
      "Yves Haberth\u00fcr",
      "Patricia H\u00f6rmann",
      "Alexander K\u00fcbler",
      "Michael Lustenberger",
      "Samuel Sigrist",
      "Oda Vigen",
      "Julian F\u00f6rster",
      "Florian Achermann",
      "Elias Hampp",
      "Robert K. Katzschmann",
      "Roland Siegwart"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15145"
  },
  {
    "id": "arXiv:2203.15149",
    "title": "CMGAN: Conformer-based Metric GAN for Speech Enhancement",
    "abstract": "Recently, convolution-augmented transformer (Conformer) has achieved\npromising performance in automatic speech recognition (ASR) and time-domain\nspeech enhancement (SE), as it can capture both local and global dependencies\nin the speech signal. In this paper, we propose a conformer-based metric\ngenerative adversarial network (CMGAN) for SE in the time-frequency (TF)\ndomain. In the generator, we utilize two-stage conformer blocks to aggregate\nall magnitude and complex spectrogram information by modeling both time and\nfrequency dependencies. The estimation of magnitude and complex spectrogram is\ndecoupled in the decoder stage and then jointly incorporated to reconstruct the\nenhanced speech. In addition, a metric discriminator is employed to further\nimprove the quality of the enhanced estimated speech by optimizing the\ngenerator with respect to a corresponding evaluation score. Quantitative\nanalysis on Voice Bank+DEMAND dataset indicates the capability of CMGAN in\noutperforming various previous models with a margin, i.e., PESQ of 3.41 and\nSSNR of 11.10 dB.",
    "descriptor": "\nComments: 5 pages, 1 figure, 2 tables, submitted to INTERSPEECH 2022\n",
    "authors": [
      "Ruizhe Cao",
      "Sherif Abdulatif",
      "Bin Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15149"
  },
  {
    "id": "arXiv:2203.15150",
    "title": "A super-polynomial lower bound for learning nonparametric mixtures",
    "abstract": "We study the problem of learning nonparametric distributions in a finite\nmixture, and establish a super-polynomial lower bound on the sample complexity\nof learning the component distributions in such models. Namely, we are given\ni.i.d. samples from $f$ where $$ f=\\sum_{i=1}^k w_i f_i, \\quad\\sum_{i=1}^k\nw_i=1, \\quad w_i>0 $$ and we are interested in learning each component $f_i$.\nWithout any assumptions on $f_i$, this problem is ill-posed. In order to\nidentify the components $f_i$, we assume that each $f_i$ can be written as a\nconvolution of a Gaussian and a compactly supported density $\\nu_i$ with\n$\\text{supp}(\\nu_i)\\cap \\text{supp}(\\nu_j)=\\emptyset$. Our main result shows\nthat $\\Omega((\\frac{1}{\\varepsilon})^{C\\log\\log \\frac{1}{\\varepsilon}})$\nsamples are required for estimating each $f_i$. The proof relies on a fast rate\nfor approximation with Gaussians, which may be of independent interest. This\nresult has important implications for the hardness of learning more general\nnonparametric latent variable models that arise in machine learning\napplications.",
    "descriptor": "",
    "authors": [
      "Bryon Aragam",
      "Wai Ming Tai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15150"
  },
  {
    "id": "arXiv:2203.15151",
    "title": "A machine learning-based severity prediction tool for diabetic  sensorimotor polyneuropathy using Michigan neuropathy screening  instrumentations",
    "abstract": "Background: Diabetic Sensorimotor polyneuropathy (DSPN) is a major long-term\ncomplication in diabetic patients associated with painful neuropathy, foot\nulceration and amputation. The Michigan neuropathy screening instrument (MNSI)\nis one of the most common screening techniques for DSPN, however, it does not\nprovide any direct severity grading system. Method: For designing and modelling\nthe DSPN severity grading systems for MNSI, 19 years of data from Epidemiology\nof Diabetes Interventions and Complications (EDIC) clinical trials were used.\nMNSI variables and patient outcomes were investigated using machine learning\ntools to identify the features having higher association in DSPN\nidentification. A multivariable logistic regression-based nomogram was\ngenerated and validated for DSPN severity grading. Results: The top-7 ranked\nfeatures from MNSI: 10-gm filament, Vibration perception (R), Vibration\nperception (L), previous diabetic neuropathy, the appearance of deformities,\nappearance of callus and appearance of fissure were identified as key features\nfor identifying DSPN using the extra tree model. The area under the curve (AUC)\nof the nomogram for the internal and external datasets were 0.9421 and 0.946,\nrespectively. From the developed nomogram, the probability of having DSPN was\npredicted and a DSPN severity scoring system for MNSI was developed from the\nprobability score. The model performance was validated on an independent\ndataset. Patients were stratified into four severity levels: absent, mild,\nmoderate, and severe using a cut-off value of 10.5, 12.7 and 15 for a DSPN\nprobability less than 50%, 75% to 90%, and above 90%, respectively.\nConclusions: This study provides a simple, easy-to-use and reliable algorithm\nfor defining the prognosis and management of patients with DSPN.",
    "descriptor": "\nComments: 21 pages, 6 Figures, 11 Tables\n",
    "authors": [
      "Fahmida Haque",
      "Mamun B. I. Reaz",
      "Muhammad E. H. Chowdhury",
      "Rayaz Malik",
      "Mohammed Alhatou",
      "Syoji Kobashi",
      "Iffat Ara",
      "Sawal H. M. Ali",
      "Ahmad A. A Bakar",
      "Geetika Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.15151"
  },
  {
    "id": "arXiv:2203.15152",
    "title": "A Generalized Cluster-Free NOMA Framework Towards Next-Generation  Multiple Access",
    "abstract": "A generalized downlink multi-antenna non-orthogonal multiple access (NOMA)\ntransmission framework is proposed with the novel concept of cluster-free\nsuccessive interference cancellation (SIC). In contrast to conventional NOMA\napproaches, where SIC is successively carried out within the same cluster, the\nkey idea is that the SIC can be flexibly implemented between any arbitrary\nusers to achieve efficient interference elimination. Based on the proposed\nframework, a sum rate maximization problem is formulated for jointly optimizing\nthe transmit beamforming and the SIC operations between users, subject to the\nSIC decoding conditions and users' minimal data rate requirements. To tackle\nthis highly-coupled mixed-integer nonlinear programming problem, an alternating\ndirection method of multipliers-successive convex approximation (ADMM-SCA)\nalgorithm is developed. The original problem is first reformulated into a\ntractable biconvex augmented Lagrangian (AL) problem by handling the non-convex\nterms via SCA. Then, this AL problem is decomposed into two subproblems that\nare iteratively solved by the ADMM to obtain the stationary solution. Moreover,\nto reduce the computational complexity and alleviate the parameter\ninitialization sensitivity of ADMM-SCA, a Matching-SCA algorithm is proposed.\nThe intractable binary SIC operations are solved through an extended\nmany-to-many matching, which is jointly combined with an SCA process to\noptimize the transmit beamforming. The proposed Matching-SCA can converge to an\nenhanced exchange-stable matching that guarantees the local optimality.\nNumerical results demonstrate that: i) the proposed Matching-SCA algorithm\nachieves comparable performance and a faster convergence compared to ADMM-SCA;\nii) the proposed generalized framework realizes scenario-adaptive\ncommunications and outperforms traditional multi-antenna NOMA approaches in\nvarious communication regimes.",
    "descriptor": "\nComments: 30 pages, 9 figures, submitted to IEEE TWC\n",
    "authors": [
      "Xiaoxia Xu",
      "Yuanwei Liu",
      "Xidong Mu",
      "Qimei Chen",
      "Zhiguo Ding"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.15152"
  },
  {
    "id": "arXiv:2203.15155",
    "title": "Learning to Synthesize Volumetric Meshes from Vision-based Tactile  Imprints",
    "abstract": "Vision-based tactile sensors typically utilize a deformable elastomer and a\ncamera mounted above to provide high-resolution image observations of contacts.\nObtaining accurate volumetric meshes for the deformed elastomer can provide\ndirect contact information and benefit robotic grasping and manipulation. This\npaper focuses on learning to synthesize the volumetric mesh of the elastomer\nbased on the image imprints acquired from vision-based tactile sensors.\nSynthetic image-mesh pairs and real-world images are gathered from 3D finite\nelement methods (FEM) and physical sensors, respectively. A graph neural\nnetwork (GNN) is introduced to learn the image-to-mesh mappings with supervised\nlearning. A self-supervised adaptation method and image augmentation techniques\nare proposed to transfer networks from simulation to reality, from primitive\ncontacts to unseen contacts, and from one sensor to another. Using these\nlearned and adapted networks, our proposed method can accurately reconstruct\nthe deformation of the real-world tactile sensor elastomer in various domains,\nas indicated by the quantitative and qualitative results.",
    "descriptor": "\nComments: To appear in the Proceedings of the IEEE International Conference on Robotics and Automation (ICRA 2022), Philadelphia (PA), USA\n",
    "authors": [
      "Xinghao Zhu",
      "Siddarth Jain",
      "Masayoshi Tomizuka",
      "Jeroen van Baar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15155"
  },
  {
    "id": "arXiv:2203.15158",
    "title": "Practical Aspects of Zero-Shot Learning",
    "abstract": "One of important areas of machine learning research is zero-shot learning. It\nis applied when properly labeled training data set is not available. A number\nof zero-shot algorithms have been proposed and experimented with. However, none\nof them seems to be the \"overall winner\". In situations like this, it may be\npossible to develop a meta-classifier that would combine \"best aspects\" of\nindividual classifiers and outperform all of them. In this context, the goal of\nthis contribution is twofold. First, multiple state-of-the-art zero-shot\nlearning methods are compared for standard benchmark datasets. Second, multiple\nmeta-classifiers are suggested and experimentally compared (for the same\ndatasets).",
    "descriptor": "",
    "authors": [
      "Elie Saad",
      "Marcin Paprzycki",
      "Maria Ganzha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15158"
  },
  {
    "id": "arXiv:2203.15162",
    "title": "A Distribution Evolutionary Algorithm for Graph Coloring",
    "abstract": "Graph Coloring Problem (GCP) is a classic combinatorial optimization problem\nthat has a wide application in theoretical research and engineering. To address\ncomplicated GCPs efficiently, a distribution evolutionary algorithm based on\npopulation of probability models (DEA-PPM) is proposed. Based on a novel\nrepresentation of probability model, DEA-PPM employs a Gaussian orthogonal\nsearch strategy to explore the probability space, by which global exploration\ncan be realized using a small population. With assistance of local exploitation\non a small solution population, DEA-PPM strikes a good balance between\nexploration and exploitation. Numerical results demonstrate that DEA-PPM\nperforms well on selected complicated GCPs, which contributes to its\ncompetitiveness to the state-of-the-art metaheuristics.",
    "descriptor": "",
    "authors": [
      "Yongjian Xu",
      "Huabin Cheng",
      "Yu Chen",
      "Chengwang Xie"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.15162"
  },
  {
    "id": "arXiv:2203.15166",
    "title": "Autonomous Road Vehicle Emergency Obstacle Avoidance Maneuver Framework  at Highway Speeds",
    "abstract": "An Autonomous Road Vehicle (ARV) can navigate various types of road networks\nusing inputs such as throttle (acceleration), braking (deceleration), and\nsteering (change of lateral direction). In most ARV driving scenarios that\ninvolve normal vehicle traffic and encounters with vulnerable road users\n(VRUs), ARVs are not required to take evasive action. This paper presents a\nnovel Emergency Obstacle Avoidance Maneuver (EOAM) methodology for ARVs\ntraveling at higher speeds and lower road surface friction, involving\ntime-critical maneuver determination and control. The proposed EOAM Framework\noffers usage of the ARV's sensing, perception, control, and actuation system\nabilities as one cohesive system, to accomplish avoidance of an on-road\nobstacle, based first on performance feasibility and second on passenger\ncomfort, and is designed to be well-integrated within an ARV high-level system.\nCo-simulation including the ARV EOAM logic in Simulink and a vehicle model in\nCarSim is conducted with speeds ranging from 55 to 165 km/h and on road\nsurfaces with friction ranging from 1.0 to 0.1. The results are analyzed and\ngiven in the context of an entire ARV system, with implications for future\nwork.",
    "descriptor": "\nComments: 50 pages, 25 figures, 2 tables\n",
    "authors": [
      "Evan Lowe",
      "Levent G\u00fcven\u00e7"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15166"
  },
  {
    "id": "arXiv:2203.15171",
    "title": "Self-Supervised Light Field Depth Estimation Using Epipolar Plane Images",
    "abstract": "Exploiting light field data makes it possible to obtain dense and accurate\ndepth map. However, synthetic scenes with limited disparity range cannot\ncontain the diversity of real scenes. By training in synthetic data, current\nlearning-based methods do not perform well in real scenes. In this paper, we\npropose a self-supervised learning framework for light field depth estimation.\nDifferent from the existing end-to-end training methods using disparity label\nper pixel, our approach implements network training by estimating EPI disparity\nshift after refocusing, which extends the disparity range of epipolar lines. To\nreduce the sensitivity of EPI to noise, we propose a new input mode called\nEPI-Stack, which stacks EPIs in the view dimension. This method is less\nsensitive to noise scenes than traditional input mode and improves the\nefficiency of estimation. Compared with other state-of-the-art methods, the\nproposed method can also obtain higher quality results in real-world scenarios,\nespecially in the complex occlusion and depth discontinuity.",
    "descriptor": "",
    "authors": [
      "Kunyuan Li",
      "Jun Zhang",
      "Jun Gao",
      "Meibin Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15171"
  },
  {
    "id": "arXiv:2203.15172",
    "title": "Assessing Evolutionary Terrain Generation Methods for Curriculum  Reinforcement Learning",
    "abstract": "Curriculum learning allows complex tasks to be mastered via incremental\nprogression over `stepping stone' goals towards a final desired behaviour.\nTypical implementations learn locomotion policies for challenging environments\nthrough gradual complexification of a terrain mesh generated through a\nparameterised noise function. To date, researchers have predominantly generated\nterrains from a limited range of noise functions, and the effect of the\ngenerator on the learning process is underrepresented in the literature. We\ncompare popular noise-based terrain generators to two indirect encodings, CPPN\nand GAN. To allow direct comparison between both direct and indirect\nrepresentations, we assess the impact of a range of representation-agnostic\nMAP-Elites feature descriptors that compute metrics directly from the generated\nterrain meshes. Next, performance and coverage are assessed when training a\nhumanoid robot in a physics simulator using the PPO algorithm. Results describe\nkey differences between the generators that inform their use in curriculum\nlearning, and present a range of useful feature descriptors for uptake by the\ncommunity.",
    "descriptor": "\nComments: 8 pages, 8 figures, 2022 Genetic and Evolutionary Computing Conference (GECCO'22)\n",
    "authors": [
      "David Howard",
      "Josh Kannemeyer",
      "Davide Dolcetti",
      "Humphrey Munn",
      "Nicole Robinson"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15172"
  },
  {
    "id": "arXiv:2203.15173",
    "title": "An Evaluation Dataset for Legal Word Embedding: A Case Study On Chinese  Codex",
    "abstract": "Word embedding is a modern distributed word representations approach widely\nused in many natural language processing tasks. Converting the vocabulary in a\nlegal document into a word embedding model facilitates subjecting legal\ndocuments to machine learning, deep learning, and other algorithms and\nsubsequently performing the downstream tasks of natural language processing\nvis-\\`a-vis, for instance, document classification, contract review, and\nmachine translation. The most common and practical approach of accuracy\nevaluation with the word embedding model uses a benchmark set with linguistic\nrules or the relationship between words to perform analogy reasoning via\nalgebraic calculation. This paper proposes establishing a 1,134 Legal\nAnalogical Reasoning Questions Set (LARQS) from the 2,388 Chinese Codex corpus\nusing five kinds of legal relations, which are then used to evaluate the\naccuracy of the Chinese word embedding model. Moreover, we discovered that\nlegal relations might be ubiquitous in the word embedding model.",
    "descriptor": "\nComments: 16 pages, 9 figures, 3rd International Conference on Natural Language Computing and AI (NLCAI 2022)\n",
    "authors": [
      "Chun-Hsien Lin",
      "Pu-Jen Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15173"
  },
  {
    "id": "arXiv:2203.15174",
    "title": "Disentangling Object Motion and Occlusion for Unsupervised Multi-frame  Monocular Depth",
    "abstract": "Conventional self-supervised monocular depth prediction methods are based on\na static environment assumption, which leads to accuracy degradation in dynamic\nscenes due to the mismatch and occlusion problems introduced by object motions.\nExisting dynamic-object-focused methods only partially solved the mismatch\nproblem at the training loss level. In this paper, we accordingly propose a\nnovel multi-frame monocular depth prediction method to solve these problems at\nboth the prediction and supervision loss levels. Our method, called\nDynamicDepth, is a new framework trained via a self-supervised cycle consistent\nlearning scheme. A Dynamic Object Motion Disentanglement (DOMD) module is\nproposed to disentangle object motions to solve the mismatch problem. Moreover,\nnovel occlusion-aware Cost Volume and Re-projection Loss are designed to\nalleviate the occlusion effects of object motions. Extensive analyses and\nexperiments on the Cityscapes and KITTI datasets show that our method\nsignificantly outperforms the state-of-the-art monocular depth prediction\nmethods, especially in the areas of dynamic objects. Our code will be made\npublicly available.",
    "descriptor": "",
    "authors": [
      "Ziyue Feng",
      "Liang Yang",
      "Longlong Jing",
      "Haiyan Wang",
      "YingLi Tian",
      "Bing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15174"
  },
  {
    "id": "arXiv:2203.15175",
    "title": "Unified Transformer Tracker for Object Tracking",
    "abstract": "As an important area in computer vision, object tracking has formed two\nseparate communities that respectively study Single Object Tracking (SOT) and\nMultiple Object Tracking (MOT). However, current methods in one tracking\nscenario are not easily adapted to the other due to the divergent training\ndatasets and tracking objects of both tasks. Although UniTrack\n\\cite{wang2021different} demonstrates that a shared appearance model with\nmultiple heads can be used to tackle individual tracking tasks, it fails to\nexploit the large-scale tracking datasets for training and performs poorly on\nsingle object tracking. In this work, we present the Unified Transformer\nTracker (UTT) to address tracking problems in different scenarios with one\nparadigm. A track transformer is developed in our UTT to track the target in\nboth SOT and MOT. The correlation between the target and tracking frame\nfeatures is exploited to localize the target. We demonstrate that both SOT and\nMOT tasks can be solved within this framework. The model can be simultaneously\nend-to-end trained by alternatively optimizing the SOT and MOT objectives on\nthe datasets of individual tasks. Extensive experiments are conducted on\nseveral benchmarks with a unified model trained on SOT and MOT datasets. Code\nwill be available at https://github.com/Flowerfan/Trackron.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Fan Ma",
      "Mike Zheng Shou",
      "Linchao Zhu",
      "Haoqi Fan",
      "Yilei Xu",
      "Yi Yang",
      "Zhicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15175"
  },
  {
    "id": "arXiv:2203.15176",
    "title": "Improving Generalization of Deep Neural Network Acoustic Models with  Length Perturbation and N-best Based Label Smoothing",
    "abstract": "We introduce two techniques, length perturbation and n-best based label\nsmoothing, to improve generalization of deep neural network (DNN) acoustic\nmodels for automatic speech recognition (ASR). Length perturbation is a data\naugmentation algorithm that randomly drops and inserts frames of an utterance\nto alter the length of the speech feature sequence. N-best based label\nsmoothing randomly injects noise to ground truth labels during training in\norder to avoid overfitting, where the noisy labels are generated from n-best\nhypotheses. We evaluate these two techniques extensively on the 300-hour\nSwitchboard (SWB300) dataset and an in-house 500-hour Japanese (JPN500) dataset\nusing recurrent neural network transducer (RNNT) acoustic models for ASR. We\nshow that both techniques improve the generalization of RNNT models\nindividually and they can also be complementary. In particular, they yield good\nimprovements over a strong SWB300 baseline and give state-of-art performance on\nSWB300 using RNNT models.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Xiaodong Cui",
      "George Saon",
      "Tohru Nagano",
      "Masayuki Suzuki",
      "Takashi Fukuda",
      "Brian Kingsbury",
      "Gakuto Kurata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.15176"
  },
  {
    "id": "arXiv:2203.15177",
    "title": "Min-Max Similarity: A Contrastive Learning Based Semi-Supervised  Learning Network for Surgical Tools Segmentation",
    "abstract": "Segmentation of images is a popular topic in medical AI. This is mainly due\nto the difficulty to obtain a significant number of pixel-level annotated data\nto train a neural network. To address this issue, we proposed a semi-supervised\nsegmentation network based on contrastive learning. In contrast to the previous\nstate-of-the-art, we introduce a contrastive learning form of dual-view\ntraining by employing classifiers and projectors to build all-negative, and\npositive and negative feature pairs respectively to formulate the learning\nproblem as solving min-max similarity problem. The all-negative pairs are used\nto supervise the networks learning from different views and make sure to\ncapture general features, and the consistency of unlabeled predictions is\nmeasured by pixel-wise contrastive loss between positive and negative pairs. To\nquantitative and qualitative evaluate our proposed method, we test it on two\npublic endoscopy surgical tool segmentation datasets and one cochlear implant\nsurgery dataset which we manually annotate the cochlear implant in surgical\nvideos. The segmentation performance (dice coefficients) indicates that our\nproposed method outperforms state-of-the-art semi-supervised and fully\nsupervised segmentation algorithms consistently. The code is publicly available\nat: https://github.com/AngeLouCN/Min_Max_Similarity",
    "descriptor": "",
    "authors": [
      "Ange Lou",
      "Xing Yao",
      "Ziteng Liu",
      "Jack Noble"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.15177"
  },
  {
    "id": "arXiv:2203.15178",
    "title": "DesCert: Design for Certification",
    "abstract": "The goal of the DARPA Automated Rapid Certification Of Software (ARCOS)\nprogram is to \"automate the evaluation of software assurance evidence to enable\ncertifiers to determine rapidly that system risk is acceptable.\" As part of\nthis program, the DesCert project focuses on the assurance-driven development\nof new software. The DesCert team consists of SRI International, Honeywell\nResearch, and the University of Washington. We have adopted a formal,\ntool-based approach to the construction of software artifacts that are\nsupported by rigorous evidence. The DesCert workflow integrates evidence\ngeneration into a design process that goes from requirements capture and\nanalysis to the decomposition of the high-level software requirements into\narchitecture properties and software components with assertional contracts, and\non to software that can be analyzed both dynamically and statically. The\ngenerated evidence is organized by means of an assurance ontology and\nintegrated into the RACK knowledge base.",
    "descriptor": "\nComments: 142 pages, 63 figures\n",
    "authors": [
      "Natarajan Shankar",
      "Devesh Bhatt",
      "Michael Ernst",
      "Minyoung Kim",
      "Srivatsan Varadarajan",
      "Suzanne Millstein",
      "Jorge Navas",
      "Jason Biatek",
      "Huascar Sanchez",
      "Anitha Murugesan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.15178"
  },
  {
    "id": "arXiv:2203.15182",
    "title": "Long-term Visual Map Sparsification with Heterogeneous GNN",
    "abstract": "We address the problem of map sparsification for long-term visual\nlocalization. For map sparsification, a commonly employed assumption is that\nthe pre-build map and the later captured localization query are consistent.\nHowever, this assumption can be easily violated in the dynamic world.\nAdditionally, the map size grows as new data accumulate through time, causing\nlarge data overhead in the long term. In this paper, we aim to overcome the\nenvironmental changes and reduce the map size at the same time by selecting\npoints that are valuable to future localization. Inspired by the recent\nprogress in Graph Neural Network(GNN), we propose the first work that models\nSfM maps as heterogeneous graphs and predicts 3D point importance scores with a\nGNN, which enables us to directly exploit the rich information in the SfM map\ngraph. Two novel supervisions are proposed: 1) a data-fitting term for\nselecting valuable points to future localization based on training queries; 2)\na K-Cover term for selecting sparse points with full map coverage. The\nexperiments show that our method selected map points on stable and widely\nvisible structures and outperformed baselines in localization performance.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Ming-Fang Chang",
      "Yipu Zhao",
      "Rajvi Shah",
      "Jakob J. Engel",
      "Michael Kaess",
      "Simon Lucey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15182"
  },
  {
    "id": "arXiv:2203.15186",
    "title": "On the relaxed greedy deterministic row and column iterative methods",
    "abstract": "For solving the large-scale linear system by iteration methods, we utilize\nthe Petrov-Galerkin conditions and relaxed greedy index selection technique and\nprovide two relaxed greedy deterministic row (RGDR) and column (RGDC) iterative\nmethods, in which one special case of RGDR reduces to the fast deterministic\nblock Kaczmarz method proposed in Chen and Huang (Numer. Algor., 89: 1007-1029,\n2021). Our convergence analyses reveal that the resulting algorithms all have\nthe linear convergence rates, which are bounded by the explicit expressions.\nNumerical examples show that the proposed algorithms are more effective than\nthe relaxed greedy randomized row and column iterative methods.",
    "descriptor": "",
    "authors": [
      "Nian-Ci Wu",
      "Ling-Xia",
      "Qian Zuo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15186"
  },
  {
    "id": "arXiv:2203.15187",
    "title": "ASM-Loc: Action-aware Segment Modeling for Weakly-Supervised Temporal  Action Localization",
    "abstract": "Weakly-supervised temporal action localization aims to recognize and localize\naction segments in untrimmed videos given only video-level action labels for\ntraining. Without the boundary information of action segments, existing methods\nmostly rely on multiple instance learning (MIL), where the predictions of\nunlabeled instances (i.e., video snippets) are supervised by classifying\nlabeled bags (i.e., untrimmed videos). However, this formulation typically\ntreats snippets in a video as independent instances, ignoring the underlying\ntemporal structures within and across action segments. To address this problem,\nwe propose \\system, a novel WTAL framework that enables explicit, action-aware\nsegment modeling beyond standard MIL-based methods. Our framework entails three\nsegment-centric components: (i) dynamic segment sampling for compensating the\ncontribution of short actions; (ii) intra- and inter-segment attention for\nmodeling action dynamics and capturing temporal dependencies; (iii) pseudo\ninstance-level supervision for improving action boundary prediction.\nFurthermore, a multi-step refinement strategy is proposed to progressively\nimprove action proposals along the model training process. Extensive\nexperiments on THUMOS-14 and ActivityNet-v1.3 demonstrate the effectiveness of\nour approach, establishing new state of the art on both datasets. The code and\nmodels are publicly available at~\\url{https://github.com/boheumd/ASM-Loc}.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Bo He",
      "Xitong Yang",
      "Le Kang",
      "Zhiyu Cheng",
      "Xin Zhou",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15187"
  },
  {
    "id": "arXiv:2203.15189",
    "title": "Coarse to Fine: Image Restoration Boosted by Multi-Scale Low-Rank Tensor  Completion",
    "abstract": "Existing low-rank tensor completion (LRTC) approaches aim at restoring a\npartially observed tensor by imposing a global low-rank constraint on the\nunderlying completed tensor. However, such a global rank assumption suffers the\ntrade-off between restoring the originally details-lacking parts and neglecting\nthe potentially complex objects, making the completion performance\nunsatisfactory on both sides. To address this problem, we propose a novel and\npractical strategy for image restoration that restores the partially observed\ntensor in a coarse-to-fine (C2F) manner, which gets rid of such trade-off by\nsearching proper local ranks for both low- and high-rank parts. Extensive\nexperiments are conducted to demonstrate the superiority of the proposed C2F\nscheme. The codes are available at: https://github.com/RuiLin0212/C2FLRTC.",
    "descriptor": "",
    "authors": [
      "Rui Lin",
      "Cong Chen",
      "Ngai Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15189"
  },
  {
    "id": "arXiv:2203.15190",
    "title": "3D Shape Reconstruction from 2D Images with Disentangled Attribute Flow",
    "abstract": "Reconstructing 3D shape from a single 2D image is a challenging task, which\nneeds to estimate the detailed 3D structures based on the semantic attributes\nfrom 2D image. So far, most of the previous methods still struggle to extract\nsemantic attributes for 3D reconstruction task. Since the semantic attributes\nof a single image are usually implicit and entangled with each other, it is\nstill challenging to reconstruct 3D shape with detailed semantic structures\nrepresented by the input image. To address this problem, we propose 3DAttriFlow\nto disentangle and extract semantic attributes through different semantic\nlevels in the input images. These disentangled semantic attributes will be\nintegrated into the 3D shape reconstruction process, which can provide definite\nguidance to the reconstruction of specific attribute on 3D shape. As a result,\nthe 3D decoder can explicitly capture high-level semantic features at the\nbottom of the network, and utilize low-level features at the top of the\nnetwork, which allows to reconstruct more accurate 3D shapes. Note that the\nexplicit disentangling is learned without extra labels, where the only\nsupervision used in our training is the input image and its corresponding 3D\nshape. Our comprehensive experiments on ShapeNet dataset demonstrate that\n3DAttriFlow outperforms the state-of-the-art shape reconstruction methods, and\nwe also validate its generalization ability on shape completion task.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Xin Wen",
      "Junsheng Zhou",
      "Yu-Shen Liu",
      "Zhen Dong",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15190"
  },
  {
    "id": "arXiv:2203.15191",
    "title": "Idea and Theory of Particle Access",
    "abstract": "Aiming at some problems existing in the current quality of service (QoS)\nmechanism of large-scale networks (i.e. poor scalability, coarse granularity\nfor provided service levels, poor fairness between different service levels,\nand improving delay performance at the expense of sacrificing some resource\nutilization), the paper puts forward the idea and thoery of particle access. In\nthe proposed particle access mechanism, the network first granulates the\ninformation flow (that is, the information flow is subdivided into information\nparticles, each of which is given its corresponding attributes), and allocates\naccess resources to the information particle group which is composed of all the\ninformation particles to be transmitted, so as to ensure that the occupied\nbandwidth resources is minimized on the premise of meeting the delay\nrequirements of each information particle. Moreover, in the paper, the concepts\nof both information particle and information particle group are defined; Basic\nproperties of the minimum reachable access bandwidth of an information particle\ngroup are analyzed; The influences of time attribute and attribute of bearing\ncapacity of an information particle group on the minimum reachable access\nbandwidth are analyzed; Finally, an effective method for the calculation of the\nminimum reachable access bandwidth of an information particle group is given,\nand a particle access algorithm based on dynamically adjusting the minimum\nreachable access bandwidth is proposed. The research of the paper pave a new\nway for further improving QoS mechanisms of large-scale networks, and lay the\ncorresponding theoretical foundation.",
    "descriptor": "",
    "authors": [
      "Bo Li",
      "Ke Sun",
      "Zhongjiang Yan",
      "Mao Yang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.15191"
  },
  {
    "id": "arXiv:2203.15193",
    "title": "Mismatched Rate-Distortion Theory: Ensembles, Bounds, and General  Alphabets",
    "abstract": "In this paper, we consider the mismatched rate-distortion problem, in which\nthe encoding is done using a codebook, and the encoder chooses the\nminimum-distortion codeword according to a mismatched distortion function that\ndiffers from the true one. For the case of discrete memoryless sources, we\nestablish achievable rate-distortion bounds using multi-user coding techniques,\nnamely, superposition coding and expurgated parallel coding. We give examples\nwhere these attain the matched rate-distortion trade-off but a standard\nensemble with independent codewords fails to do so. On the other hand, in\ncontrast with the channel coding counterpart, we show that there are cases\nwhere structured codebooks can perform worse than their unstructured\ncounterparts. In addition, in view of the difficulties in adapting the existing\nand above-mentioned results to general alphabets, we consider a simpler\ni.i.d.~random coding ensemble, and establish its achievable rate-distortion\nbounds for general alphabets.",
    "descriptor": "",
    "authors": [
      "Millen Kanabar",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.15193"
  },
  {
    "id": "arXiv:2203.15195",
    "title": "AnoDFDNet: A Deep Feature Difference Network for Anomaly Detection",
    "abstract": "This paper proposed a novel anomaly detection (AD) approach of High-speed\nTrain images based on convolutional neural networks and the Vision Transformer.\nDifferent from previous AD works, in which anomalies are identified with a\nsingle image using classification, segmentation, or object detection methods,\nthe proposed method detects abnormal difference between two images taken at\ndifferent times of the same region. In other words, we cast anomaly detection\nproblem with a single image into a difference detection problem with two\nimages. The core idea of the proposed method is that the 'anomaly' usually\nrepresents an abnormal state instead of a specific object, and this state\nshould be identified by a pair of images. In addition, we introduced a deep\nfeature difference AD network (AnoDFDNet) which sufficiently explored the\npotential of the Vision Transformer and convolutional neural networks. To\nverify the effectiveness of the proposed AnoDFDNet, we collected three\ndatasets, a difference dataset (Diff Dataset), a foreign body dataset (FB\nDataset), and an oil leakage dataset (OL Dataset). Experimental results on\nabove datasets demonstrate the superiority of proposed method. Source code are\navailable at https://github.com/wangle53/AnoDFDNet.",
    "descriptor": "\nComments: 14pages, 8figures\n",
    "authors": [
      "Zhixue Wang",
      "Yu Zhang",
      "Lin Luo",
      "Nan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15195"
  },
  {
    "id": "arXiv:2203.15198",
    "title": "Model-Based Control of Planar Piezoelectric Inchworm Soft Robot for  Crawling in Constrained Environments",
    "abstract": "Soft robots have drawn significant attention recently for their ability to\nachieve rich shapes when interacting with complex environments. However, their\nelasticity and flexibility compared to rigid robots also pose significant\nchallenges for precise and robust shape control in real-time. Motivated by\ntheir potential to operate in highly-constrained environments, as in\nsearch-and-rescue operations, this work addresses these challenges of soft\nrobots by developing a model-based full-shape controller, validated and\ndemonstrated by experiments. A five-actuator planar soft robot was constructed\nwith planar piezoelectric layers bonded to a steel foil substrate, enabling\ninchworm-like motion. The controller uses a soft-body continuous model for\nshape planning and control, given target shapes and/or environmental\nconstraints, such as crawling under overhead barriers or \"roof\" safety lines.\nAn approach to background model calibrations is developed to address deviations\nof actual robot shape due to material parameter variations and drift. Full\nexperimental shape control and optimal movement under a roof safety line are\ndemonstrated, where the robot maximizes its speed within the overhead\nconstraint. The mean-squared error between the measured and target shapes\nimproves from ~0.05 cm$^{2}$ without calibration to ~0.01 cm$^{2}$ with\ncalibration. Simulation-based validation is also performed with various\ndifferent roof shapes.",
    "descriptor": "\nComments: Accepted to the 2022 IEEE 5th International Conference on Soft Robotics (RoboSoft). Project website: this https URL Summary video: this https URL\n",
    "authors": [
      "Zhiwu Zheng",
      "Prakhar Kumar",
      "Yenan Chen",
      "Hsin Cheng",
      "Sigurd Wagner",
      "Minjie Chen",
      "Naveen Verma",
      "James C. Sturm"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15198"
  },
  {
    "id": "arXiv:2203.15200",
    "title": "Search Methods for Policy Decompositions",
    "abstract": "Computing optimal control policies for complex dynamical systems requires\napproximation methods to remain computationally tractable. Several\napproximation methods have been developed to tackle this problem. However,\nthese methods do not reason about the suboptimality induced in the resulting\ncontrol policies due to these approximations. We introduced Policy\nDecomposition, an approximation method that provides a suboptimality estimate,\nin our earlier work. Policy decomposition proposes strategies to break an\noptimal control problem into lower-dimensional subproblems, whose optimal\nsolutions are combined to build a control policy for the original system.\nHowever, the number of possible strategies to decompose a system scale quickly\nwith the complexity of a system, posing a combinatorial challenge. In this work\nwe investigate the use of Genetic Algorithm and Monte-Carlo Tree Search to\nalleviate this challenge. We identify decompositions for swing-up control of a\n4 degree-of-freedom manipulator, balance control of a simplified biped, and\nhover control of a quadcopter.",
    "descriptor": "",
    "authors": [
      "Ashwin Khadke",
      "Hartmut Geyer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15200"
  },
  {
    "id": "arXiv:2203.15201",
    "title": "Light Field Depth Estimation Based on Stitched-EPI",
    "abstract": "Depth estimation is one of the most essential problems for light field\napplications. In EPI-based methods, the slope computation usually suffers low\naccuracy due to the discretization error and low angular resolution. In\naddition, recent methods work well in most regions but often struggle with\nblurry edges over occluded regions and ambiguity over texture-less regions. To\naddress these challenging issues, we first propose the stitched-EPI and\nhalf-stitched-EPI algorithms for non-occluded and occluded regions,\nrespectively. The algorithms improve slope computation by shifting and\nconcatenating lines in different EPIs but related to the same point in 3D\nscene, while the half-stitched-EPI only uses non-occluded part of lines.\nCombined with the joint photo-consistency cost proposed by us, the more\naccurate and robust depth map can be obtained in both occluded and non-occluded\nregions. Furthermore, to improve the depth estimation in texture-less regions,\nwe propose a depth propagation strategy that determines their depth from the\nedge to interior, from accurate regions to coarse regions. Experimental and\nablation results demonstrate that the proposed method achieves accurate and\nrobust depth maps in all regions effectively.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Ping Zhou",
      "Xiaoyang Liu",
      "Jing Jin",
      "Yuting Zhang",
      "Junhui Hou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15201"
  },
  {
    "id": "arXiv:2203.15202",
    "title": "SimT: Handling Open-set Noise for Domain Adaptive Semantic Segmentation",
    "abstract": "This paper studies a practical domain adaptive (DA) semantic segmentation\nproblem where only pseudo-labeled target data is accessible through a black-box\nmodel. Due to the domain gap and label shift between two domains,\npseudo-labeled target data contains mixed closed-set and open-set label noises.\nIn this paper, we propose a simplex noise transition matrix (SimT) to model the\nmixed noise distributions in DA semantic segmentation and formulate the problem\nas estimation of SimT. By exploiting computational geometry analysis and\nproperties of segmentation, we design three complementary regularizers, i.e.\nvolume regularization, anchor guidance, convex guarantee, to approximate the\ntrue SimT. Specifically, volume regularization minimizes the volume of simplex\nformed by rows of the non-square SimT, which ensures outputs of segmentation\nmodel to fit into the ground truth label distribution. To compensate for the\nlack of open-set knowledge, anchor guidance and convex guarantee are devised to\nfacilitate the modeling of open-set noise distribution and enhance the\ndiscriminative feature learning among closed-set and open-set classes. The\nestimated SimT is further utilized to correct noise issues in pseudo labels and\npromote the generalization ability of segmentation model on target domain data.\nExtensive experimental results demonstrate that the proposed SimT can be\nflexibly plugged into existing DA methods to boost the performance. The source\ncode is available at \\url{https://github.com/CityU-AIM-Group/SimT}.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Xiaoqing Guo",
      "Jie Liu",
      "Tongliang Liu",
      "Yiyuan Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15202"
  },
  {
    "id": "arXiv:2203.15203",
    "title": "Periocular Biometrics and its Relevance to Partially Masked Faces: A  Survey",
    "abstract": "The performance of face recognition systems can be negatively impacted in the\npresence of masks and other types of facial coverings that have become\nprevalent due to the COVID-19 pandemic. In such cases, the periocular region of\nthe human face becomes an important biometric cue. In this article, we present\na detailed review of periocular biometrics. We first examine the various face\nand periocular techniques specially designed to recognize humans wearing a face\nmask. Then, we review different aspects of periocular biometrics: (a) the\nanatomical cues present in the periocular region useful for recognition, (b)\nthe various feature extraction and matching techniques developed, (c)\nrecognition across different spectra, (d) fusion with other biometric\nmodalities (face or iris), (e) recognition on mobile devices, (f) its\nusefulness in other applications, (g) periocular datasets, and (h) competitions\norganized for evaluating the efficacy of this biometric modality. Finally, we\ndiscuss various challenges and future directions in the field of periocular\nbiometrics.",
    "descriptor": "",
    "authors": [
      "Renu Sharma",
      "Arun Ross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15203"
  },
  {
    "id": "arXiv:2203.15205",
    "title": "SPAct: Self-supervised Privacy Preservation for Action Recognition",
    "abstract": "Visual private information leakage is an emerging key issue for the fast\ngrowing applications of video understanding like activity recognition. Existing\napproaches for mitigating privacy leakage in action recognition require privacy\nlabels along with the action labels from the video dataset. However, annotating\nframes of video dataset for privacy labels is not feasible. Recent developments\nof self-supervised learning (SSL) have unleashed the untapped potential of the\nunlabeled data. For the first time, we present a novel training framework which\nremoves privacy information from input video in a self-supervised manner\nwithout requiring privacy labels. Our training framework consists of three main\ncomponents: anonymization function, self-supervised privacy removal branch, and\naction recognition branch. We train our framework using a minimax optimization\nstrategy to minimize the action recognition cost function and maximize the\nprivacy cost function through a contrastive self-supervised loss. Employing\nexisting protocols of known-action and privacy attributes, our framework\nachieves a competitive action-privacy trade-off to the existing\nstate-of-the-art supervised methods. In addition, we introduce a new protocol\nto evaluate the generalization of learned the anonymization function to\nnovel-action and privacy attributes and show that our self-supervised framework\noutperforms existing supervised methods. Code available at:\nhttps://github.com/DAVEISHAN/SPAct",
    "descriptor": "\nComments: CVPR-2022\n",
    "authors": [
      "Ishan Rajendrakumar Dave",
      "Chen Chen",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15205"
  },
  {
    "id": "arXiv:2203.15206",
    "title": "Shifted Chunk Encoder for Transformer Based Streaming End-to-End ASR",
    "abstract": "Currently, there are mainly three Transformer encoder based streaming End to\nEnd (E2E) Automatic Speech Recognition (ASR) approaches, namely time-restricted\nmethods, chunk-wise methods, and memory based methods. However, all of them\nhave some limitations in aspects of global context modeling, linear\ncomputational complexity, and model parallelism. In this work, we aim to build\na single model to achieve the benefits of all the three aspects for streaming\nE2E ASR. Particularly, we propose to use a shifted chunk mechanism instead of\nthe conventional chunk mechanism for streaming Transformer and Conformer. This\nshifted chunk mechanism can significantly enhance modeling power through\nallowing chunk self-attention to capture global context across local chunks,\nwhile keeping linear computational complexity and parallel trainable. We name\nthe Shifted Chunk Transformer and Conformer as SChunk-Transofromer and\nSChunk-Conformer, respectively. And we verify their performance on the widely\nused AISHELL-1 benckmark. Experiments show that the SChunk-Transformer and\nSChunk-Conformer achieve CER 6.43% and 5.77%, respectively. That surpasses the\nexisting chunk-wise and memory based methods by a large margin, and is\ncompetitive even compared with the state-of-the-art time-restricted methods\nwhich have quadratic computational complexity.",
    "descriptor": "",
    "authors": [
      "Fangyuan Wang",
      "Bo Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15206"
  },
  {
    "id": "arXiv:2203.15207",
    "title": "Generalizing Few-Shot NAS with Gradient Matching",
    "abstract": "Efficient performance estimation of architectures drawn from large search\nspaces is essential to Neural Architecture Search. One-Shot methods tackle this\nchallenge by training one supernet to approximate the performance of every\narchitecture in the search space via weight-sharing, thereby drastically\nreducing the search cost. However, due to coupled optimization between child\narchitectures caused by weight-sharing, One-Shot supernet's performance\nestimation could be inaccurate, leading to degraded search outcomes. To address\nthis issue, Few-Shot NAS reduces the level of weight-sharing by splitting the\nOne-Shot supernet into multiple separated sub-supernets via edge-wise\n(layer-wise) exhaustive partitioning. Since each partition of the supernet is\nnot equally important, it necessitates the design of a more effective splitting\ncriterion. In this work, we propose a gradient matching score (GM) that\nleverages gradient information at the shared weight for making informed\nsplitting decisions. Intuitively, gradients from different child models can be\nused to identify whether they agree on how to update the shared modules, and\nsubsequently to decide if they should share the same weight. Compared with\nexhaustive partitioning, the proposed criterion significantly reduces the\nbranching factor per edge. This allows us to split more edges (layers) for a\ngiven budget, resulting in substantially improved performance as NAS search\nspaces usually include dozens of edges (layers). Extensive empirical\nevaluations of the proposed method on a wide range of search spaces\n(NASBench-201, DARTS, MobileNet Space), datasets (cifar10, cifar100, ImageNet)\nand search algorithms (DARTS, SNAS, RSPS, ProxylessNAS, OFA) demonstrate that\nit significantly outperforms its Few-Shot counterparts while surpassing\nprevious comparable methods in terms of the accuracy of derived architectures.",
    "descriptor": "\nComments: Accepted by ICLR2022\n",
    "authors": [
      "Shoukang Hu",
      "Ruochen Wang",
      "Lanqing Hong",
      "Zhenguo Li",
      "Cho-Jui Hsieh",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15207"
  },
  {
    "id": "arXiv:2203.15209",
    "title": "OrphicX: A Causality-Inspired Latent Variable Model for Interpreting  Graph Neural Networks",
    "abstract": "This paper proposes a new eXplanation framework, called OrphicX, for\ngenerating causal explanations for any graph neural networks (GNNs) based on\nlearned latent causal factors. Specifically, we construct a distinct generative\nmodel and design an objective function that encourages the generative model to\nproduce causal, compact, and faithful explanations. This is achieved by\nisolating the causal factors in the latent space of graphs by maximizing the\ninformation flow measurements. We theoretically analyze the cause-effect\nrelationships in the proposed causal graph, identify node attributes as\nconfounders between graphs and GNN predictions, and circumvent such confounder\neffect by leveraging the backdoor adjustment formula. Our framework is\ncompatible with any GNNs, and it does not require access to the process by\nwhich the target GNN produces its predictions. In addition, it does not rely on\nthe linear-independence assumption of the explained features, nor require prior\nknowledge on the graph learning tasks. We show a proof-of-concept of OrphicX on\ncanonical classification problems on graph data. In particular, we analyze the\nexplanatory subgraphs obtained from explanations for molecular graphs (i.e.,\nMutag) and quantitatively evaluate the explanation performance with frequently\noccurring subgraph patterns. Empirically, we show that OrphicX can effectively\nidentify the causal semantics for generating causal explanations, significantly\noutperforming its alternatives.",
    "descriptor": "\nComments: Accepted by CVPR 2022, an oral presentation, source code: this https URL\n",
    "authors": [
      "Wanyu Lin",
      "Hao Lan",
      "Hao Wang",
      "Baochun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15209"
  },
  {
    "id": "arXiv:2203.15210",
    "title": "Camera-Conditioned Stable Feature Generation for Isolated Camera  Supervised Person Re-IDentification",
    "abstract": "To learn camera-view invariant features for person Re-IDentification (Re-ID),\nthe cross-camera image pairs of each person play an important role. However,\nsuch cross-view training samples could be unavailable under the ISolated Camera\nSupervised (ISCS) setting, e.g., a surveillance system deployed across distant\nscenes.To handle this challenging problem, a new pipeline is introduced by\nsynthesizing the cross-camera samples in the feature space for model training.\nSpecifically, the feature encoder and generator are end-to-end optimized under\na novel method, Camera-Conditioned Stable Feature Generation (CCSFG). Its joint\nlearning procedure raises concern on the stability of generative model\ntraining. Therefore, a new feature generator, $\\sigma$-Regularized Conditional\nVariational Autoencoder ($\\sigma$-Reg.~CVAE), is proposed with theoretical and\nexperimental analysis on its robustness. Extensive experiments on two ISCS\nperson Re-ID datasets demonstrate the superiority of our CCSFG to the\ncompetitors.",
    "descriptor": "\nComments: 11 pages, 9 figures, accepted by CVPR 2022\n",
    "authors": [
      "Chao Wu",
      "Wenhang Ge",
      "Ancong Wu",
      "Xiaobin Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15210"
  },
  {
    "id": "arXiv:2203.15212",
    "title": "Are Edge Weights in Summary Graphs Useful? -- A Comparative Study",
    "abstract": "Which one is better between two representative graph summarization models\nwith and without edge weights? From web graphs to online social networks, large\ngraphs are everywhere. Graph summarization, which is an effective graph\ncompression technique, aims to find a compact summary graph that accurately\nrepresents a given large graph. Two versions of the problem, where one allows\nedge weights in summary graphs and the other does not, have been studied in\nparallel without direct comparison between their underlying representation\nmodels. In this work, we conduct a systematic comparison by extending three\nsearch algorithms to both models and evaluating their outputs on eight datasets\nin five aspects: (a) reconstruction error, (b) error in node importance, (c)\nerror in node proximity, (d) the size of reconstructed graphs, and (e)\ncompression ratios. Surprisingly, using unweighted summary graphs leads to\noutputs significantly better in all the aspects than using weighted ones, and\nthis finding is supported theoretically. Notably, we show that a\nstate-of-the-art algorithm can be improved substantially (specifically, 8.2X,\n7.8X, and 5.9X in terms of (a), (b), and (c), respectively, when (e) is fixed)\nbased on the observation.",
    "descriptor": "\nComments: To be published in the 26th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2022)\n",
    "authors": [
      "Shinhwan Kang",
      "Kyuhan Lee",
      "Kijung Shin"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.15212"
  },
  {
    "id": "arXiv:2203.15215",
    "title": "Spatial-Aware Local Community Detection Guided by Dominance Relation",
    "abstract": "The problem of finding the spatial-aware community for a given node has been\ndefined and investigated in geo-social networks. However, existing studies\nsuffer from two limitations: a) the criteria of defining communities are\ndetermined by parameters, which are difficult to set; b) algorithms may require\nglobal information and are not suitable for situations where the network is\nincomplete. Therefore, we propose spatial-aware local community detection\n(SLCD), which finds the spatial-aware local community with only local\ninformation and defines the community based on the difference in the sparseness\nof edges inside and outside the community. Specifically, to address the SLCD\nproblem, we design a novel spatial aware local community detection algorithm\nbased on dominance relation, but this algorithm incurs high cost. To further\nimprove the efficiency, we propose an approximate algorithm. Experimental\nresults demonstrate that the proposed approximate algorithm outperforms the\ncomparison algorithms.",
    "descriptor": "",
    "authors": [
      "Li Ni",
      "Hefei Xu",
      "Yiwen Zhang",
      "Wenjian Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.15215"
  },
  {
    "id": "arXiv:2203.15216",
    "title": "Affine Medical Image Registration with Coarse-to-Fine Vision Transformer",
    "abstract": "Affine registration is indispensable in a comprehensive medical image\nregistration pipeline. However, only a few studies focus on fast and robust\naffine registration algorithms. Most of these studies utilize convolutional\nneural networks (CNNs) to learn joint affine and non-parametric registration,\nwhile the standalone performance of the affine subnetwork is less explored.\nMoreover, existing CNN-based affine registration approaches focus either on the\nlocal misalignment or the global orientation and position of the input to\npredict the affine transformation matrix, which are sensitive to spatial\ninitialization and exhibit limited generalizability apart from the training\ndataset. In this paper, we present a fast and robust learning-based algorithm,\nCoarse-to-Fine Vision Transformer (C2FViT), for 3D affine medical image\nregistration. Our method naturally leverages the global connectivity and\nlocality of the convolutional vision transformer and the multi-resolution\nstrategy to learn the global affine registration. We evaluate our method on 3D\nbrain atlas registration and template-matching normalization. Comprehensive\nresults demonstrate that our method is superior to the existing CNNs-based\naffine registration methods in terms of registration accuracy, robustness and\ngeneralizability while preserving the runtime advantage of the learning-based\nmethods. The source code is available at https://github.com/cwmok/C2FViT.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Tony C. W. Mok",
      "Albert C. S. Chung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15216"
  },
  {
    "id": "arXiv:2203.15219",
    "title": "AR Point&Click: An Interface for Setting Robot Navigation Goals",
    "abstract": "This paper considers the problem of designating navigation goal locations for\ninteractive mobile robots. We propose a point-and-click interface, implemented\nwith an Augmented Reality (AR) headset. The cameras on the AR headset are used\nto detect natural pointing gestures performed by the user. The selected goal is\nvisualized through the AR headset, allowing the users to adjust the goal\nlocation if desired. We conduct a user study in which participants set\nconsecutive navigation goals for the robot using three different interfaces: AR\nPoint & Click, Person Following and Tablet (birdeye map view). Results show\nthat the proposed AR Point&Click interface improved the perceived accuracy,\nefficiency and reduced mental load compared to the baseline tablet interface,\nand it performed on-par to the Person Following method. These results show that\nthe AR Point\\&Click is a feasible interaction model for setting navigation\ngoals.",
    "descriptor": "\nComments: 6 Pages, 5 Figures, 4 Tables\n",
    "authors": [
      "Morris Gu",
      "Elizabeth Croft",
      "Akansel Cosgun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15219"
  },
  {
    "id": "arXiv:2203.15221",
    "title": "Few Could Be Better Than All: Feature Sampling and Grouping for Scene  Text Detection",
    "abstract": "Recently, transformer-based methods have achieved promising progresses in\nobject detection, as they can eliminate the post-processes like NMS and enrich\nthe deep representations. However, these methods cannot well cope with scene\ntext due to its extreme variance of scales and aspect ratios. In this paper, we\npresent a simple yet effective transformer-based architecture for scene text\ndetection. Different from previous approaches that learn robust deep\nrepresentations of scene text in a holistic manner, our method performs scene\ntext detection based on a few representative features, which avoids the\ndisturbance by background and reduces the computational cost. Specifically, we\nfirst select a few representative features at all scales that are highly\nrelevant to foreground text. Then, we adopt a transformer for modeling the\nrelationship of the sampled features, which effectively divides them into\nreasonable groups. As each feature group corresponds to a text instance, its\nbounding box can be easily obtained without any post-processing operation.\nUsing the basic feature pyramid network for feature extraction, our method\nconsistently achieves state-of-the-art results on several popular datasets for\nscene text detection.",
    "descriptor": "",
    "authors": [
      "Jingqun Tang",
      "Wenqing Zhang",
      "Hongye Liu",
      "MingKun Yang",
      "Bo Jiang",
      "Guanglong Hu",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15221"
  },
  {
    "id": "arXiv:2203.15224",
    "title": "Panoptic NeRF: 3D-to-2D Label Transfer for Panoptic Urban Scene  Segmentation",
    "abstract": "Large-scale training data with high-quality annotations is critical for\ntraining semantic and instance segmentation models. Unfortunately, pixel-wise\nannotation is labor-intensive and costly, raising the demand for more efficient\nlabeling strategies. In this work, we present a novel 3D-to-2D label transfer\nmethod, Panoptic NeRF, which aims for obtaining per-pixel 2D semantic and\ninstance labels from easy-to-obtain coarse 3D bounding primitives. Our method\nutilizes NeRF as a differentiable tool to unify coarse 3D annotations and 2D\nsemantic cues transferred from existing datasets. We demonstrate that this\ncombination allows for improved geometry guided by semantic information,\nenabling rendering of accurate semantic maps across multiple views.\nFurthermore, this fusion process resolves label ambiguity of the coarse 3D\nannotations and filters noise in the 2D predictions. By inferring in 3D space\nand rendering to 2D labels, our 2D semantic and instance labels are multi-view\nconsistent by design. Experimental results show that Panoptic NeRF outperforms\nexisting semantic and instance label transfer methods in terms of accuracy and\nmulti-view consistency on challenging urban scenes of the KITTI-360 dataset.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Xiao Fu",
      "Shangzhan Zhang",
      "Tianrun Chen",
      "Yichong Lu",
      "Lanyun Zhu",
      "Xiaowei Zhou",
      "Andreas Geiger",
      "Yiyi Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15224"
  },
  {
    "id": "arXiv:2203.15227",
    "title": "Temporal Feature Alignment and Mutual Information Maximization for  Video-Based Human Pose Estimation",
    "abstract": "Multi-frame human pose estimation has long been a compelling and fundamental\nproblem in computer vision. This task is challenging due to fast motion and\npose occlusion that frequently occur in videos. State-of-the-art methods strive\nto incorporate additional visual evidences from neighboring frames (supporting\nframes) to facilitate the pose estimation of the current frame (key frame). One\naspect that has been obviated so far, is the fact that current methods directly\naggregate unaligned contexts across frames. The spatial-misalignment between\npose features of the current frame and neighboring frames might lead to\nunsatisfactory results. More importantly, existing approaches build upon the\nstraightforward pose estimation loss, which unfortunately cannot constrain the\nnetwork to fully leverage useful information from neighboring frames. To tackle\nthese problems, we present a novel hierarchical alignment framework, which\nleverages coarse-to-fine deformations to progressively update a neighboring\nframe to align with the current frame at the feature level. We further propose\nto explicitly supervise the knowledge extraction from neighboring frames,\nguaranteeing that useful complementary cues are extracted. To achieve this\ngoal, we theoretically analyzed the mutual information between the frames and\narrived at a loss that maximizes the task-relevant mutual information. These\nallow us to rank No.1 in the Multi-frame Person Pose Estimation Challenge on\nbenchmark dataset PoseTrack2017, and obtain state-of-the-art performance on\nbenchmarks Sub-JHMDB and Pose-Track2018. Our code is released at\nhttps://github. com/Pose-Group/FAMI-Pose, hoping that it will be useful to the\ncommunity.",
    "descriptor": "\nComments: This paper is accepted as CVPR2022-ORAL\n",
    "authors": [
      "Zhenguang Liu",
      "Runyang Feng",
      "Haoming Chen",
      "Shuang Wu",
      "Yixing Gao",
      "Yunjun Gao",
      "Xiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15227"
  },
  {
    "id": "arXiv:2203.15228",
    "title": "SHOP: A Deep Learning Based Pipeline for near Real-Time Detection of  Small Handheld Objects Present in Blurry Video",
    "abstract": "While prior works have investigated and developed computational models\ncapable of object detection, models still struggle to reliably interpret images\nwith motion blur and small objects. Moreover, none of these models are\nspecifically designed for handheld object detection. In this work, we present\nSHOP (Small Handheld Object Pipeline), a pipeline that reliably and efficiently\ninterprets blurry images containing handheld objects. The specific models used\nin each stage of the pipeline are flexible and can be changed based on\nperformance requirements. First, images are deblurred and then run through a\npose detection system where areas-of-interest are proposed around the hands of\nany people present. Next, object detection is performed on the images by a\nsingle-stage object detector. Finally, the proposed areas-of-interest are used\nto filter out low confidence detections. Testing on a handheld subset of\nMicrosoft Common Objects in Context (MS COCO) demonstrates that this 3 stage\nprocess results in a 70 percent decrease in false positives while only reducing\ntrue positives by 17 percent in its strongest configuration. We also present a\nsubset of MS COCO consisting solely of handheld objects that can be used to\ncontinue the development of handheld object detection methods.\nhttps://github.com/spider-sense/SHOP",
    "descriptor": "\nComments: 8 pages, 5 figures. Accepted to IEEE SoutheastCon 2022\n",
    "authors": [
      "Abhinav Ganguly",
      "Amar C Gandhi",
      "Sylvia E",
      "Jeffrey D Chang",
      "Ian M Hudson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15228"
  },
  {
    "id": "arXiv:2203.15229",
    "title": "Edge Detection and Deep Learning Based SETI Signal Classification Method",
    "abstract": "Scientists at the Berkeley SETI Research Center are Searching for\nExtraterrestrial Intelligence (SETI) by a new signal detection method that\nconverts radio signals into spectrograms through Fourier transforms and\nclassifies signals represented by two-dimensional time-frequency spectrums,\nwhich successfully converts a signal classification problem into an image\nclassification task. In view of the negative impact of background noises on the\naccuracy of spectrograms classification, a new method is introduced in this\npaper. After Gaussian convolution smoothing the signals, edge detection\nfunctions are applied to detect the edge of the signals and enhance the outline\nof the signals, then the processed spectrograms are used to train the deep\nneural network to compare the classification accuracy of various image\nclassification networks. The results show that the proposed method can\neffectively improve the classification accuracy of SETI spectrums.",
    "descriptor": "\nComments: Article submitted to Computers, Materials & Continua\n",
    "authors": [
      "Zhewei Chen",
      "Sami Ahmed Haider"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.15229"
  },
  {
    "id": "arXiv:2203.15230",
    "title": "Zero-Query Transfer Attacks on Context-Aware Object Detectors",
    "abstract": "Adversarial attacks perturb images such that a deep neural network produces\nincorrect classification results. A promising approach to defend against\nadversarial attacks on natural multi-object scenes is to impose a\ncontext-consistency check, wherein, if the detected objects are not consistent\nwith an appropriately defined context, then an attack is suspected. Stronger\nattacks are needed to fool such context-aware detectors. We present the first\napproach for generating context-consistent adversarial attacks that can evade\nthe context-consistency check of black-box object detectors operating on\ncomplex, natural scenes. Unlike many black-box attacks that perform repeated\nattempts and open themselves to detection, we assume a \"zero-query\" setting,\nwhere the attacker has no knowledge of the classification decisions of the\nvictim system. First, we derive multiple attack plans that assign incorrect\nlabels to victim objects in a context-consistent manner. Then we design and use\na novel data structure that we call the perturbation success probability\nmatrix, which enables us to filter the attack plans and choose the one most\nlikely to succeed. This final attack plan is implemented using a\nperturbation-bounded adversarial attack algorithm. We compare our zero-query\nattack against a few-query scheme that repeatedly checks if the victim system\nis fooled. We also compare against state-of-the-art context-agnostic attacks.\nAgainst a context-aware defense, the fooling rate of our zero-query approach is\nsignificantly higher than context-agnostic approaches and higher than that\nachievable with up to three rounds of the few-query scheme.",
    "descriptor": "\nComments: CVPR 2022 Accepted\n",
    "authors": [
      "Zikui Cai",
      "Shantanu Rane",
      "Alejandro E. Brito",
      "Chengyu Song",
      "Srikanth V. Krishnamurthy",
      "Amit K. Roy-Chowdhury",
      "M. Salman Asif"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15230"
  },
  {
    "id": "arXiv:2203.15232",
    "title": "Unified Performance Assessment of Optical Wireless Communication over  Multi-Layer Underwater Channels",
    "abstract": "In this paper, we model the multi-layer vertical underwater link as a\ncascaded channel and unify the performance analysis for the underwater optical\ncommunication (UWOC) system using generalized Gamma (GG), exponential GG (EGG),\nexponentiated Weibull (EW), and Gamma-Gamma ({\\Gamma}{\\Gamma}) oceanic\nturbulence models. We derive unified analytical expressions for probability\ndensity function (PDF) and cumulative distribution function (CDF) for the\nsignal-to-noise ratios (SNR) considering independent and non-identical\n(i.ni.d.) turbulent models and zero bore-sight model for pointing errors. We\ndevelop performance metrics of the considered UWOC system using outage\nprobability, average bit error rate (BER), and ergodic capacity with asymptotic\nexpressions for outage probability and average BER. We develop the diversity\norder of the proposed system to provide a better insight into the system\nperformance at a high SNR. We also integrate a terrestrial OWC (TOWC) subjected\nto the combined effect of generalized Malaga atmospheric turbulence,\nfog-induced random path gain, and pointing errors to communicate with the UWOC\nlink using the fixed-gain amplify-and-forward (AF) relaying. We analyze the\nperformance of the mixed TWOC and multi-layer UWOC system by deriving PDF, CDF,\noutage probability, and average BER using the bivariate Fox H-function. We use\nMonte-Carlo simulation results to validate our exact and asymptotic expressions\nand demonstrate the performance of the considered underwater UWOC system using\nmeasurement-based parametric data available for turbulent oceanic channels.",
    "descriptor": "\nComments: This paper has been submitted in IEEE for possible publication. arXiv admin note: substantial text overlap with arXiv:2203.14003\n",
    "authors": [
      "Ziyaur Rahman",
      "Neel Vipulbhai Tailor",
      "S. M. Zafaruddin",
      "V. K. Chaubey"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.15232"
  },
  {
    "id": "arXiv:2203.15233",
    "title": "AutoPoly: Predicting a Polygonal Mesh Construction Sequence from a  Silhouette Image",
    "abstract": "Polygonal modeling is a core task of content creation in Computer Graphics.\nThe complexity of modeling, in terms of the number and the order of operations\nand time required to execute them makes it challenging to learn and execute.\nOur goal is to automatically derive a polygonal modeling sequence for a given\ntarget. Then, one can learn polygonal modeling by observing the resulting\nsequence and also expedite the modeling process by starting from the\nauto-generated result. As a starting point for building a system for 3D\nmodeling in the future, we tackle the 2D shape modeling problem and present\nAutoPoly, a hybrid method that generates a polygonal mesh construction sequence\nfrom a silhouette image. The key idea of our method is the use of the Monte\nCarlo tree search (MCTS) algorithm and differentiable rendering to separately\npredict sequential topological actions and geometric actions. Our hybrid method\ncan alter topology, whereas the recently proposed inverse shape estimation\nmethods using differentiable rendering can only handle a fixed topology. Our\nnovel reward function encourages MCTS to select topological actions that lead\nto a simpler shape without self-intersection. We further designed two deep\nlearning-based methods to improve the expansion and simulation steps in the\nMCTS search process: an $n$-step \"future action prediction\" network (nFAP-Net)\nto generate candidates for potential topological actions, and a shape warping\nnetwork (WarpNet) to predict polygonal shapes given the predicted rendered\nimages and topological actions. We demonstrate the efficiency of our method on\n2D polygonal shapes of multiple man-made object categories.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "I-Chao Shen",
      "Yu Ju Chen",
      "Oliver van Kaick",
      "Takeo Igarashi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.15233"
  },
  {
    "id": "arXiv:2203.15234",
    "title": "Equivariance Allows Handling Multiple Nuisance Variables When Analyzing  Pooled Neuroimaging Datasets",
    "abstract": "Pooling multiple neuroimaging datasets across institutions often enables\nimprovements in statistical power when evaluating associations (e.g., between\nrisk factors and disease outcomes) that may otherwise be too weak to detect.\nWhen there is only a {\\em single} source of variability (e.g., different\nscanners), domain adaptation and matching the distributions of representations\nmay suffice in many scenarios. But in the presence of {\\em more than one}\nnuisance variable which concurrently influence the measurements, pooling\ndatasets poses unique challenges, e.g., variations in the data can come from\nboth the acquisition method as well as the demographics of participants\n(gender, age). Invariant representation learning, by itself, is ill-suited to\nfully model the data generation process. In this paper, we show how bringing\nrecent results on equivariant representation learning (for studying symmetries\nin neural networks) instantiated on structured spaces together with simple use\nof classical results on causal inference provides an effective practical\nsolution. In particular, we demonstrate how our model allows dealing with more\nthan one nuisance variable under some assumptions and can enable analysis of\npooled scientific datasets in scenarios that would otherwise entail removing a\nlarge portion of the samples.",
    "descriptor": "\nComments: Accepted at 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\n",
    "authors": [
      "Vishnu Suresh Lokhande",
      "Rudrasis Chakraborty",
      "Sathya N. Ravi",
      "Vikas Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15234"
  },
  {
    "id": "arXiv:2203.15235",
    "title": "Pop-Out Motion: 3D-Aware Image Deformation via Learning the Shape  Laplacian",
    "abstract": "We propose a framework that can deform an object in a 2D image as it exists\nin 3D space. Most existing methods for 3D-aware image manipulation are limited\nto (1) only changing the global scene information or depth, or (2) manipulating\nan object of specific categories. In this paper, we present a 3D-aware image\ndeformation method with minimal restrictions on shape category and deformation\ntype. While our framework leverages 2D-to-3D reconstruction, we argue that\nreconstruction is not sufficient for realistic deformations due to the\nvulnerability to topological errors. Thus, we propose to take a supervised\nlearning-based approach to predict the shape Laplacian of the underlying volume\nof a 3D reconstruction represented as a point cloud. Given the deformation\nenergy calculated using the predicted shape Laplacian and user-defined\ndeformation handles (e.g., keypoints), we obtain bounded biharmonic weights to\nmodel plausible handle-based image deformation. In the experiments, we present\nour results of deforming 2D character and clothed human images. We also\nquantitatively show that our approach can produce more accurate deformation\nweights compared to alternative methods (i.e., mesh reconstruction and point\ncloud Laplacian methods).",
    "descriptor": "\nComments: 16 pages, 10 figures, accepted to CVPR 2022\n",
    "authors": [
      "Jihyun Lee",
      "Minhyuk Sung",
      "Hyunjin Kim",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15235"
  },
  {
    "id": "arXiv:2203.15239",
    "title": "Enabling hand gesture customization on wrist-worn devices",
    "abstract": "We present a framework for gesture customization requiring minimal examples\nfrom users, all without degrading the performance of existing gesture sets. To\nachieve this, we first deployed a large-scale study (N=500+) to collect data\nand train an accelerometer-gyroscope recognition model with a cross-user\naccuracy of 95.7% and a false-positive rate of 0.6 per hour when tested on\neveryday non-gesture data. Next, we design a few-shot learning framework which\nderives a lightweight model from our pre-trained model, enabling knowledge\ntransfer without performance degradation. We validate our approach through a\nuser study (N=20) examining on-device customization from 12 new gestures,\nresulting in an average accuracy of 55.3%, 83.1%, and 87.2% on using one,\nthree, or five shots when adding a new gesture, while maintaining the same\nrecognition accuracy and false-positive rate from the pre-existing gesture set.\nWe further evaluate the usability of our real-time implementation with a user\nexperience study (N=20). Our results highlight the effectiveness, learnability,\nand usability of our customization framework. Our approach paves the way for a\nfuture where users are no longer bound to pre-existing gestures, freeing them\nto creatively introduce new gestures tailored to their preferences and\nabilities.",
    "descriptor": "\nComments: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems\n",
    "authors": [
      "Xuhai Xu",
      "Jun Gong",
      "Carolina Brum",
      "Lilian Liang",
      "Bongsoo Suh",
      "Kumar Gupta",
      "Yash Agarwal",
      "Laurence Lindsey",
      "Runchang Kang",
      "Behrooz Shahsavari",
      "Tu Nguyen",
      "Heriberto Nieto",
      "Scott E. Hudson",
      "Charlie Maalouf",
      "Seyed Mousavi",
      "Gierad Laput"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15239"
  },
  {
    "id": "arXiv:2203.15241",
    "title": "Semi-Supervised Image-to-Image Translation using Latent Space Mapping",
    "abstract": "Recent image-to-image translation works have been transferred from supervised\nto unsupervised settings due to the expensive cost of capturing or labeling\nlarge amounts of paired data. However, current unsupervised methods using the\ncycle-consistency constraint may not find the desired mapping, especially for\ndifficult translation tasks. On the other hand, a small number of paired data\nare usually accessible. We therefore introduce a general framework for\nsemi-supervised image translation. Unlike previous works, our main idea is to\nlearn the translation over the latent feature space instead of the image space.\nThanks to the low dimensional feature space, it is easier to find the desired\nmapping function, resulting in improved quality of translation results as well\nas the stability of the translation model. Empirically we show that using\nfeature translation generates better results, even using a few bits of paired\ndata. Experimental comparisons with state-of-the-art approaches demonstrate the\neffectiveness of the proposed framework on a variety of challenging\nimage-to-image translation tasks",
    "descriptor": "",
    "authors": [
      "Pan Zhang",
      "Jianmin Bao",
      "Ting Zhang",
      "Dong Chen",
      "Fang Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15241"
  },
  {
    "id": "arXiv:2203.15243",
    "title": "Fine-tuning Image Transformers using Learnable Memory",
    "abstract": "In this paper we propose augmenting Vision Transformer models with learnable\nmemory tokens. Our approach allows the model to adapt to new tasks, using few\nparameters, while optionally preserving its capabilities on previously learned\ntasks. At each layer we introduce a set of learnable embedding vectors that\nprovide contextual information useful for specific datasets. We call these\n\"memory tokens\". We show that augmenting a model with just a handful of such\ntokens per layer significantly improves accuracy when compared to conventional\nhead-only fine-tuning, and performs only slightly below the significantly more\nexpensive full fine-tuning. We then propose an attention-masking approach that\nenables extension to new downstream tasks, with a computation reuse. In this\nsetup in addition to being parameters efficient, models can execute both old\nand new tasks as a part of single inference at a small incremental cost.",
    "descriptor": "",
    "authors": [
      "Mark Sandler",
      "Andrey Zhmoginov",
      "Max Vladymyrov",
      "Andrew Jackson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15243"
  },
  {
    "id": "arXiv:2203.15245",
    "title": "Robust Structured Declarative Classifiers for 3D Point Clouds: Defending  Adversarial Attacks with Implicit Gradients",
    "abstract": "Deep neural networks for 3D point cloud classification, such as PointNet,\nhave been demonstrated to be vulnerable to adversarial attacks. Current\nadversarial defenders often learn to denoise the (attacked) point clouds by\nreconstruction, and then feed them to the classifiers as input. In contrast to\nthe literature, we propose a family of robust structured declarative\nclassifiers for point cloud classification, where the internal constrained\noptimization mechanism can effectively defend adversarial attacks through\nimplicit gradients. Such classifiers can be formulated using a bilevel\noptimization framework. We further propose an effective and efficient\ninstantiation of our approach, namely, Lattice Point Classifier (LPC), based on\nstructured sparse coding in the permutohedral lattice and 2D convolutional\nneural networks (CNNs) that is end-to-end trainable. We demonstrate\nstate-of-the-art robust point cloud classification performance on ModelNet40\nand ScanNet under seven different attackers. For instance, we achieve 89.51%\nand 83.16% test accuracy on each dataset under the recent JGBA attacker that\noutperforms DUP-Net and IF-Defense with PointNet by ~70%. Demo code is\navailable at https://zhang-vislab.github.io.",
    "descriptor": "",
    "authors": [
      "Kaidong Li",
      "Ziming Zhang",
      "Cuncong Zhong",
      "Guanghui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15245"
  },
  {
    "id": "arXiv:2203.15246",
    "title": "A quantum-inspired tensor network method for constrained combinatorial  optimization problems",
    "abstract": "Combinatorial optimization is of general interest for both theoretical study\nand real-world applications. Fast-developing quantum algorithms provide a\ndifferent perspective on solving combinatorial optimization problems. In this\npaper, we propose a quantum inspired algorithm for general locally constrained\ncombinatorial optimization problems by encoding the constraints directly into a\ntensor network state. The optimal solution can be efficiently solved by\nborrowing the imaginary time evolution from a quantum many-body system. We\ndemonstrate our algorithm with the open-pit mining problem numerically. Our\ncomputational results show the effectiveness of this construction and potential\napplications in further studies for general combinatorial optimization\nproblems.",
    "descriptor": "",
    "authors": [
      "Tianyi Hao",
      "Xuxin Huang",
      "Chunjing Jia",
      "Cheng Peng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.15246"
  },
  {
    "id": "arXiv:2203.15249",
    "title": "MFA-Conformer: Multi-scale Feature Aggregation Conformer for Automatic  Speaker Verification",
    "abstract": "In this paper, we present Multi-scale Feature Aggregation Conformer\n(MFA-Conformer), an easy-to-implement, simple but effective backbone for\nautomatic speaker verification based on the Convolution-augmented Transformer\n(Conformer). The architecture of the MFA-Conformer is inspired by recent\nstate-of-the-art models in speech recognition and speaker verification.\nFirstly, we introduce a convolution sub-sampling layer to decrease the\ncomputational cost of the model. Secondly, we adopt Conformer blocks which\ncombine Transformers and convolution neural networks (CNNs) to capture global\nand local features effectively. Finally, the output feature maps from all\nConformer blocks are concatenated to aggregate multi-scale representations\nbefore final pooling. We evaluate the MFA-Conformer on the widely used\nbenchmarks. The best system obtains 0.64%, 1.29% and 1.63% EER on VoxCeleb1-O,\nSITW.Dev, and SITW.Eval set, respectively. MFA-Conformer significantly\noutperforms the popular ECAPA-TDNN systems in both recognition performance and\ninference speed. Last but not the least, the ablation studies clearly\ndemonstrate that the combination of global and local feature learning can lead\nto robust and accurate speaker embedding extraction. We will release the code\nfor future works to do comparison.",
    "descriptor": "\nComments: submitted to INTERSPEECH 2022\n",
    "authors": [
      "Yang Zhang",
      "Zhiqiang Lv",
      "Haibin Wu",
      "Shanshan Zhang",
      "Pengfei Hu",
      "Zhiyong Wu",
      "Hung-yi Lee",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15249"
  },
  {
    "id": "arXiv:2203.15251",
    "title": "Exploring Intra- and Inter-Video Relation for Surgical Semantic Scene  Segmentation",
    "abstract": "Automatic surgical scene segmentation is fundamental for facilitating\ncognitive intelligence in the modern operating theatre. Previous works rely on\nconventional aggregation modules (e.g., dilated convolution, convolutional\nLSTM), which only make use of the local context. In this paper, we propose a\nnovel framework STswinCL that explores the complementary intra- and inter-video\nrelations to boost segmentation performance, by progressively capturing the\nglobal context. We firstly develop a hierarchy Transformer to capture\nintra-video relation that includes richer spatial and temporal cues from\nneighbor pixels and previous frames. A joint space-time window shift scheme is\nproposed to efficiently aggregate these two cues into each pixel embedding.\nThen, we explore inter-video relation via pixel-to-pixel contrastive learning,\nwhich well structures the global embedding space. A multi-source contrast\ntraining objective is developed to group the pixel embeddings across videos\nwith the ground-truth guidance, which is crucial for learning the global\nproperty of the whole data. We extensively validate our approach on two public\nsurgical video benchmarks, including EndoVis18 Challenge and CaDIS dataset.\nExperimental results demonstrate the promising performance of our method, which\nconsistently exceeds previous state-of-the-art approaches. Code will be\navailable at https://github.com/YuemingJin/STswinCL.",
    "descriptor": "",
    "authors": [
      "Yueming Jin",
      "Yang Yu",
      "Cheng Chen",
      "Zixu Zhao",
      "Pheng-Ann Heng",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15251"
  },
  {
    "id": "arXiv:2203.15252",
    "title": "Identification and classification of exfoliated graphene flakes from  microscopy images using a hierarchical deep convolutional neural network",
    "abstract": "Identification of the mechanically exfoliated graphene flakes and\nclassification of the thickness is important in the nanomanufacturing of\nnext-generation materials and devices that overcome the bottleneck of Moore's\nLaw. Currently, identification and classification of exfoliated graphene flakes\nare conducted by human via inspecting the optical microscope images. The\nexisting state-of-the-art automatic identification by machine learning is not\nable to accommodate images with different backgrounds while different\nbackgrounds are unavoidable in experiments. This paper presents a deep learning\nmethod to automatically identify and classify the thickness of exfoliated\ngraphene flakes on Si/SiO2 substrates from optical microscope images with\nvarious settings and background colors. The presented method uses a\nhierarchical deep convolutional neural network that is capable of learning new\nimages while preserving the knowledge from previous images. The deep learning\nmodel was trained and used to classify exfoliated graphene flakes into\nmonolayer (1L), bi-layer (2L), tri-layer (3L), four-to-six-layer (4-6L),\nseven-to-ten-layer (7-10L), and bulk categories. Compared with existing machine\nlearning methods, the presented method possesses high accuracy and efficiency\nas well as robustness to the backgrounds and resolutions of images. The results\nindicated that our deep learning model has accuracy as high as 99% in\nidentifying and classifying exfoliated graphene flakes. This research will shed\nlight on scaled-up manufacturing and characterization of graphene for advanced\nmaterials and devices.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Soroush Mahjoubi",
      "Fan Ye",
      "Yi Bao",
      "Weina Meng",
      "Xian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.15252"
  },
  {
    "id": "arXiv:2203.15253",
    "title": "NeuraGen-A Low-Resource Neural Network based approach for Gender  Classification",
    "abstract": "Human voice is the source of several important information. This is in the\nform of features. These Features help in interpreting various features\nassociated with the speaker and speech. The speaker dependent work\nresearchersare targeted towards speaker identification, Speaker verification,\nspeaker biometric, forensics using feature, and cross-modal matching via speech\nand face images. In such context research, it is a very difficult task to come\nacross clean, and well annotated publicly available speech corpus as data set.\nAcquiring volunteers to generate such dataset is also very expensive, not to\nmention the enormous amount of effort and time researchers spend to gather such\ndata. The present paper work, a Neural Network proposal as NeuraGen focused\nwhich is a low-resource ANN architecture. The proposed tool used to classify\ngender of the speaker from the speech recordings. We have used speech\nrecordings collected from the ELSDSR and limited TIMIT datasets, from which we\nextracted 8 speech features, which were pre-processed and then fed into\nNeuraGen to identify the gender. NeuraGen has successfully achieved accuracy of\n90.7407% and F1 score of 91.227% in train and 20-fold cross validation dataset.",
    "descriptor": "",
    "authors": [
      "Shankhanil Ghosh",
      "Chhanda Saha",
      "Naagamani Molakathaala"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15253"
  },
  {
    "id": "arXiv:2203.15254",
    "title": "Constructing Effective Customer Feedback Systems -- A Design Science  Study Leveraging Blockchain Technology",
    "abstract": "Organizations have to adjust to changes in the ecosystem, and customer\nfeedback systems (CFS) provide important information to adapt products and\nservices to changing customer preferences. However, current systems are limited\nto single-dimensional rating scales and are subject to self-selection biases.\nThis work contributes design principles for CFS and implements a CFS that\nadvances current systems by means of contextualized feedback according to\nspecific organizational objectives. It also uses blockchain-based incentives to\nsupport CFS use. We apply Design Science Research (DSR) methodology and report\non a longitudinal DSR journey considering multiple stakeholder values. We\nconducted expert interviews, design workshops, demonstrations, and a four-day\nexperiment in an organizational setup, involving 132 customers of a major Swiss\nlibrary. This validates the identified design principles and the implemented\nsoftware artifact both qualitatively and quantitatively. Based on this\nevaluation, the design principles are revisited and conclusions for the\nconstruction of successful CFS are drawn. The findings of this work advance the\nknowledge on the design of CFS and provide a guideline to managers and decision\nmakers for designing effective CFS.",
    "descriptor": "",
    "authors": [
      "Mark C. Ballandies",
      "Valentin Holzwarth",
      "Barry Sunderland",
      "Evangelos Pournaras",
      "Jan vom Brocke"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.15254"
  },
  {
    "id": "arXiv:2203.15255",
    "title": "Survival analysis for user disengagement prediction:  question-and-answering communities' case",
    "abstract": "We used survival analysis to model user disengagement in three distinct\nquestions-and-answering communities in this work. We used the complete\nhistorical data of {Politics, Data Science, Computer Science} Stack Exchange\ncommunities from their inception until May 2021, which include the information\nabout all users who were members of one of these three communities.\nFurthermore, formulating the user disengagement prediction as a survival\nanalysis task, we utilised two survival analysis techniques to model and\npredict the probabilities of members of each community becoming disengaged. Our\nmain finding is that the likelihood of users with even a few contributions\nstaying active is noticeably higher than the users who were making no\ncontributions; this distinction may widen as time passes. Moreover, the results\nof our experiments indicate that users with more favourable views towards the\ncontent shared on the platform may stay engaged longer. Finally, the observed\npattern holds for all three communities, regardless of their themes.",
    "descriptor": "",
    "authors": [
      "Hassan Abedi Firouzjaei"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.15255"
  },
  {
    "id": "arXiv:2203.15258",
    "title": "Efficient Reflectance Capture with a Deep Gated Mixture-of-Experts",
    "abstract": "We present a novel framework to efficiently acquire near-planar anisotropic\nreflectance in a pixel-independent fashion, using a deep gated\nmixtureof-experts. While existing work employs a unified network to handle all\npossible input, our network automatically learns to condition on the input for\nenhanced reconstruction. We train a gating module to select one out of a number\nof specialized decoders for reflectance reconstruction, based on photometric\nmeasurements, essentially trading generality for quality. A common, pre-trained\nlatent transform module is also appended to each decoder, to offset the burden\nof the increased number of decoders. In addition, the illumination conditions\nduring acquisition can be jointly optimized. The effectiveness of our framework\nis validated on a wide variety of challenging samples using a near-field\nlightstage. Compared with the state-of-the-art technique, our results are\nimproved at the same input bandwidth, and our bandwidth can be reduced to about\n1/3 for equal-quality results.",
    "descriptor": "",
    "authors": [
      "Xiaohe Ma",
      "Yaxin Yu",
      "Hongzhi Wu",
      "Kun Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.15258"
  },
  {
    "id": "arXiv:2203.15259",
    "title": "Eigencontours: Novel Contour Descriptors Based on Low-Rank Approximation",
    "abstract": "Novel contour descriptors, called eigencontours, based on low-rank\napproximation are proposed in this paper. First, we construct a contour matrix\ncontaining all object boundaries in a training set. Second, we decompose the\ncontour matrix into eigencontours via the best rank-M approximation. Third, we\nrepresent an object boundary by a linear combination of the M eigencontours. We\nalso incorporate the eigencontours into an instance segmentation framework.\nExperimental results demonstrate that the proposed eigencontours can represent\nobject boundaries more effectively and more efficiently than existing\ndescriptors in a low-dimensional space. Furthermore, the proposed algorithm\nyields meaningful performances on instance segmentation datasets.",
    "descriptor": "\nComments: accepted to CVPR2022 (oral)\n",
    "authors": [
      "Wonhui Park",
      "Dongkwon Jin",
      "Chang-Su Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15259"
  },
  {
    "id": "arXiv:2203.15260",
    "title": "Efficient Convex Optimization Requires Superlinear Memory",
    "abstract": "We show that any memory-constrained, first-order algorithm which minimizes\n$d$-dimensional, $1$-Lipschitz convex functions over the unit ball to\n$1/\\mathrm{poly}(d)$ accuracy using at most $d^{1.25 - \\delta}$ bits of memory\nmust make at least $\\tilde{\\Omega}(d^{1 + (4/3)\\delta})$ first-order queries\n(for any constant $\\delta \\in [0, 1/4]$). Consequently, the performance of such\nmemory-constrained algorithms are a polynomial factor worse than the optimal\n$\\tilde{O}(d)$ query bound for this problem obtained by cutting plane methods\nthat use $\\tilde{O}(d^2)$ memory. This resolves a COLT 2019 open problem of\nWoodworth and Srebro.",
    "descriptor": "\nComments: 33 pages, 1 figure\n",
    "authors": [
      "Annie Marsden",
      "Vatsal Sharan",
      "Aaron Sidford",
      "Gregory Valiant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15260"
  },
  {
    "id": "arXiv:2203.15266",
    "title": "Interactive Multi-Class Tiny-Object Detection",
    "abstract": "Annotating tens or hundreds of tiny objects in a given image is laborious yet\ncrucial for a multitude of Computer Vision tasks. Such imagery typically\ncontains objects from various categories, yet the multi-class interactive\nannotation setting for the detection task has thus far been unexplored. To\naddress these needs, we propose a novel interactive annotation method for\nmultiple instances of tiny objects from multiple classes, based on a few\npoint-based user inputs. Our approach, C3Det, relates the full image context\nwith annotator inputs in a local and global manner via late-fusion and\nfeature-correlation, respectively. We perform experiments on the Tiny-DOTA and\nLCell datasets using both two-stage and one-stage object detection\narchitectures to verify the efficacy of our approach. Our approach outperforms\nexisting approaches in interactive annotation, achieving higher mAP with fewer\nclicks. Furthermore, we validate the annotation efficiency of our approach in a\nuser study where it is shown to be 2.85x faster and yield only 0.36x task load\n(NASA-TLX, lower is better) compared to manual annotation. The code is\navailable at\nhttps://github.com/ChungYi347/Interactive-Multi-Class-Tiny-Object-Detection.",
    "descriptor": "",
    "authors": [
      "Chunggi Lee",
      "Seonwook Park",
      "Heon Song",
      "Jeongun Ryu",
      "Sanghoon Kim",
      "Haejoon Kim",
      "S\u00e9rgio Pereira",
      "Donggeun Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15266"
  },
  {
    "id": "arXiv:2203.15270",
    "title": "MAT: Mask-Aware Transformer for Large Hole Image Inpainting",
    "abstract": "Recent studies have shown the importance of modeling long-range interactions\nin the inpainting problem. To achieve this goal, existing approaches exploit\neither standalone attention techniques or transformers, but usually under a low\nresolution in consideration of computational cost. In this paper, we present a\nnovel transformer-based model for large hole inpainting, which unifies the\nmerits of transformers and convolutions to efficiently process high-resolution\nimages. We carefully design each component of our framework to guarantee the\nhigh fidelity and diversity of recovered images. Specifically, we customize an\ninpainting-oriented transformer block, where the attention module aggregates\nnon-local information only from partial valid tokens, indicated by a dynamic\nmask. Extensive experiments demonstrate the state-of-the-art performance of the\nnew model on multiple benchmark datasets. Code is released at\nhttps://github.com/fenglinglwb/MAT.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Wenbo Li",
      "Zhe Lin",
      "Kun Zhou",
      "Lu Qi",
      "Yi Wang",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15270"
  },
  {
    "id": "arXiv:2203.15272",
    "title": "Sparse Image based Navigation Architecture to Mitigate the need of  precise Localization in Mobile Robots",
    "abstract": "Traditional simultaneous localization and mapping (SLAM) methods focus on\nimprovement in the robot's localization under environment and sensor\nuncertainty. This paper, however, focuses on mitigating the need for exact\nlocalization of a mobile robot to pursue autonomous navigation using a sparse\nset of images. The proposed method consists of a model architecture - RoomNet,\nfor unsupervised learning resulting in a coarse identification of the\nenvironment and a separate local navigation policy for local identification and\nnavigation. The former learns and predicts the scene based on the short term\nimage sequences seen by the robot along with the transition image scenarios\nusing long term image sequences. The latter uses sparse image matching to\ncharacterise the similarity of frames achieved vis-a-vis the frames viewed by\nthe robot during the mapping and training stage. A sparse graph of the image\nsequence is created which is then used to carry out robust navigation purely on\nthe basis of visual goals. The proposed approach is evaluated on two robots in\na test environment and demonstrates the ability to navigate in dynamic\nenvironments where landmarks are obscured and classical localization methods\nfail.",
    "descriptor": "\nComments: 7 Pages, 4 figures\n",
    "authors": [
      "Pranay Mathur",
      "Rajesh Kumar",
      "Sarthak Upadhyay"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15272"
  },
  {
    "id": "arXiv:2203.15274",
    "title": "Finding Structure and Causality in Linear Programs",
    "abstract": "Linear Programs (LP) are celebrated widely, particularly so in machine\nlearning where they have allowed for effectively solving probabilistic\ninference tasks or imposing structure on end-to-end learning systems. Their\npotential might seem depleted but we propose a foundational, causal perspective\nthat reveals intriguing intra- and inter-structure relations for LP components.\nWe conduct a systematic, empirical investigation on general-, shortest path-\nand energy system LPs.",
    "descriptor": "\nComments: Main paper: 5 pages, References: 2 pages, Appendix: 1 page. Figures: 8 main, 1 appendix. Tables: 1 appendix\n",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Florian Peter Busch",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15274"
  },
  {
    "id": "arXiv:2203.15276",
    "title": "Applying Syntax$\\unicode{x2013}$Prosody Mapping Hypothesis and Prosodic  Well-Formedness Constraints to Neural Sequence-to-Sequence Speech Synthesis",
    "abstract": "End-to-end text-to-speech synthesis (TTS), which generates speech sounds\ndirectly from strings of texts or phonemes, has improved the quality of speech\nsynthesis over the conventional TTS. However, most previous studies have been\nevaluated based on subjective naturalness and have not objectively examined\nwhether they can reproduce pitch patterns of phonological phenomena such as\ndownstep, rhythmic boost, and initial lowering that reflect syntactic\nstructures in Japanese. These phenomena can be linguistically explained by\nphonological constraints and the syntax$\\unicode{x2013}$prosody mapping\nhypothesis (SPMH), which assumes projections from syntactic structures to\nphonological hierarchy. Although some experiments in psycholinguistics have\nverified the validity of the SPMH, it is crucial to investigate whether it can\nbe implemented in TTS. To synthesize linguistic phenomena involving syntactic\nor phonological constraints, we propose a model using phonological symbols\nbased on the SPMH and prosodic well-formedness constraints. Experimental\nresults showed that the proposed method synthesized similar pitch patterns to\nthose reported in linguistics experiments for the phenomena of initial lowering\nand rhythmic boost. The proposed model efficiently synthesizes phonological\nphenomena in the test data that were not explicitly included in the training\ndata.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Kei Furukawa",
      "Takeshi Kishiyama",
      "Satoshi Nakamura"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15276"
  },
  {
    "id": "arXiv:2203.15285",
    "title": "Semantic Line Detection Using Mirror Attention and Comparative Ranking  and Matching",
    "abstract": "A novel algorithm to detect semantic lines is proposed in this paper. We\ndevelop three networks: detection network with mirror attention (D-Net) and\ncomparative ranking and matching networks (R-Net and M-Net). D-Net extracts\nsemantic lines by exploiting rich contextual information. To this end, we\ndesign the mirror attention module. Then, through pairwise comparisons of\nextracted semantic lines, we iteratively select the most semantic line and\nremove redundant ones overlapping with the selected one. For the pairwise\ncomparisons, we develop R-Net and M-Net in the Siamese architecture.\nExperiments demonstrate that the proposed algorithm outperforms the\nconventional semantic line detector significantly. Moreover, we apply the\nproposed algorithm to detect two important kinds of semantic lines\nsuccessfully: dominant parallel lines and reflection symmetry axes. Our codes\nare available at https://github.com/dongkwonjin/Semantic-Line-DRM.",
    "descriptor": "\nComments: Accepted to ECCV2020\n",
    "authors": [
      "Dongkwon Jin",
      "Jun-Tae Lee",
      "Chang-Su Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15285"
  },
  {
    "id": "arXiv:2203.15287",
    "title": "Accelerating Code Search with Deep Hashing and Code Classification",
    "abstract": "Code search is to search reusable code snippets from source code corpus based\non natural languages queries. Deep learning-based methods of code search have\nshown promising results. However, previous methods focus on retrieval accuracy\nbut lacked attention to the efficiency of the retrieval process. We propose a\nnovel method CoSHC to accelerate code search with deep hashing and code\nclassification, aiming to perform an efficient code search without sacrificing\ntoo much accuracy. To evaluate the effectiveness of CoSHC, we apply our method\nto five code search models. Extensive experimental results indicate that\ncompared with previous code search baselines, CoSHC can save more than 90% of\nretrieval time meanwhile preserving at least 99% of retrieval accuracy.",
    "descriptor": "",
    "authors": [
      "Wenchao Gu",
      "Yanlin Wang",
      "Lun Du",
      "Hongyu Zhang",
      "Shi Han",
      "Dongmei Zhang",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15287"
  },
  {
    "id": "arXiv:2203.15290",
    "title": "Design strategies for controlling neuron-connected robots using  reinforcement learning",
    "abstract": "Despite the growing interest in robot control utilizing the computation of\nbiological neurons, context-dependent behavior by neuron-connected robots\nremains a challenge. Context-dependent behavior here is defined as behavior\nthat is not the result of a simple sensory-motor coupling, but rather based on\nan understanding of the task goal. This paper proposes design principles for\ntraining neuron-connected robots based on task goals to achieve\ncontext-dependent behavior. First, we employ deep reinforcement learning (RL)\nto enable training that accounts for goal achievements. Second, we propose a\nneuron simulator as a probability distribution based on recorded neural data,\naiming to represent physiologically valid neural dynamics while avoiding\ncomplex modeling with high computational costs. Furthermore, we propose to\nupdate the simulators during the training to bridge the gap between the\nsimulation and the real settings. The experiments showed that the robot\ngradually learned context-dependent behaviors in pole balancing and robot\nnavigation tasks. Moreover, the learned policies were valid for neural\nsimulators based on novel neural data, and the task performance increased by\nupdating the simulators during training. These results suggest the\neffectiveness of the proposed design principle for the context-dependent\nbehavior of neuron-connected robots.",
    "descriptor": "\nComments: Last updated March 29th, 2022\n",
    "authors": [
      "Haruto Sawada",
      "Naoki Wake",
      "Kazuhiro Sasabuchi",
      "Jun Takamatsu",
      "Hirokazu Takahashi",
      "Katsushi Ikeuchi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15290"
  },
  {
    "id": "arXiv:2203.15293",
    "title": "Uncertainty-Aware Adaptation for Self-Supervised 3D Human Pose  Estimation",
    "abstract": "The advances in monocular 3D human pose estimation are dominated by\nsupervised techniques that require large-scale 2D/3D pose annotations. Such\nmethods often behave erratically in the absence of any provision to discard\nunfamiliar out-of-distribution data. To this end, we cast the 3D human pose\nlearning as an unsupervised domain adaptation problem. We introduce MRP-Net\nthat constitutes a common deep network backbone with two output heads\nsubscribing to two diverse configurations; a) model-free joint localization and\nb) model-based parametric regression. Such a design allows us to derive\nsuitable measures to quantify prediction uncertainty at both pose and joint\nlevel granularity. While supervising only on labeled synthetic samples, the\nadaptation process aims to minimize the uncertainty for the unlabeled target\nimages while maximizing the same for an extreme out-of-distribution dataset\n(backgrounds). Alongside synthetic-to-real 3D pose adaptation, the\njoint-uncertainties allow expanding the adaptation to work on in-the-wild\nimages even in the presence of occlusion and truncation scenarios. We present a\ncomprehensive evaluation of the proposed approach and demonstrate\nstate-of-the-art performance on benchmark datasets.",
    "descriptor": "\nComments: CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Jogendra Nath Kundu",
      "Siddharth Seth",
      "Pradyumna YM",
      "Varun Jampani",
      "Anirban Chakraborty",
      "R. Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15293"
  },
  {
    "id": "arXiv:2203.15297",
    "title": "Kernel Modulation: A Parameter-Efficient Method for Training  Convolutional Neural Networks",
    "abstract": "Deep Neural Networks, particularly Convolutional Neural Networks (ConvNets),\nhave achieved incredible success in many vision tasks, but they usually require\nmillions of parameters for good accuracy performance. With increasing\napplications that use ConvNets, updating hundreds of networks for multiple\ntasks on an embedded device can be costly in terms of memory, bandwidth, and\nenergy. Approaches to reduce this cost include model compression and\nparameter-efficient models that adapt a subset of network layers for each new\ntask. This work proposes a novel parameter-efficient kernel modulation (KM)\nmethod that adapts all parameters of a base network instead of a subset of\nlayers. KM uses lightweight task-specialized kernel modulators that require\nonly an additional 1.4% of the base network parameters. With multiple tasks,\nonly the task-specialized KM weights are communicated and stored on the\nend-user device. We applied this method in training ConvNets for Transfer\nLearning and Meta-Learning scenarios. Our results show that KM delivers up to\n9% higher accuracy than other parameter-efficient methods on the Transfer\nLearning benchmark.",
    "descriptor": "\nComments: Accepted at 2022 26th International Conference on Pattern Recognition (ICPR)\n",
    "authors": [
      "Yuhuang Hu",
      "Shih-Chii Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15297"
  },
  {
    "id": "arXiv:2203.15298",
    "title": "A Wavelet, AR and SVM based hybrid method for short-term wind speed  prediction",
    "abstract": "Wind speed modelling and prediction has been gaining importance because of\nits significant roles in various stages of wind energy management. In this\npaper, we propose a hybrid model, based on wavelet transform to improve the\naccuracy of the short-term forecast. The wind speed time series are split into\nvarious frequency components using wavelet decomposition technique, and each\nfrequency components are modelled separately. Since the components associated\nwith the high- frequency range shows stochastic nature, we modelled them with\nautoregressive (AR) method and rest of low-frequency components modelled with\nsupport vector machine (SVM). The results of the hybrid method show a promising\nimprovement in accuracy of wind speed prediction compared to that of\nstand-alone AR or SVM model.",
    "descriptor": "",
    "authors": [
      "G.V. Drisya",
      "K. Satheesh Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15298"
  },
  {
    "id": "arXiv:2203.15302",
    "title": "Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes",
    "abstract": "A novel algorithm to detect road lanes in the eigenlane space is proposed in\nthis paper. First, we introduce the notion of eigenlanes, which are data-driven\ndescriptors for structurally diverse lanes, including curved, as well as\nstraight, lanes. To obtain eigenlanes, we perform the best rank-M approximation\nof a lane matrix containing all lanes in a training set. Second, we generate a\nset of lane candidates by clustering the training lanes in the eigenlane space.\nThird, using the lane candidates, we determine an optimal set of lanes by\ndeveloping an anchor-based detection network, called SIIC-Net. Experimental\nresults demonstrate that the proposed algorithm provides excellent detection\nperformance for structurally diverse lanes. Our codes are available at\nhttps://github.com/dongkwonjin/Eigenlanes.",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Dongkwon Jin",
      "Wonhui Park",
      "Seong-Gyun Jeong",
      "Heeyeon Kwon",
      "Chang-Su Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15302"
  },
  {
    "id": "arXiv:2203.15305",
    "title": "Suboptimal Safety-Critical Control for Continuous Systems Using  Prediction-Correction Online Optimization",
    "abstract": "This paper investigates the control barrier function (CBF) based\nsafety-critical control for continuous nonlinear control affine systems using\nmore efficient online algorithms by the time-varying optimization method. The\nidea of the algorithms is that when quadratic programming (QP) or other convex\noptimization algorithms needed in the CBF-based method is not computation\naffordable, the alternative suboptimal feasible solutions can be obtained more\neconomically. By using the barrier-based interior point method, the constrained\nCBF-QP problems are transformed into unconstrained ones with suboptimal\nsolutions tracked by two continuous descent-based algorithms. Considering the\nlag effect of tracking and exploiting the system information, the prediction\nmethod is added to the algorithms, which achieves exponential convergence to\nthe time-varying suboptimal solutions. The convergence and robustness of the\ndesigned methods as well as the safety criteria of the algorithms are studied\ntheoretically. The effectiveness is illustrated by simulations on the\nanti-swing and obstacle avoidance tasks.",
    "descriptor": "",
    "authors": [
      "Shengbo Wang",
      "Shiping wen",
      "Kaibo Shi",
      "Tingwen Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15305"
  },
  {
    "id": "arXiv:2203.15309",
    "title": "Learning-based Point Cloud Registration for 6D Object Pose Estimation in  the Real World",
    "abstract": "In this work, we tackle the task of estimating the 6D pose of an object from\npoint cloud data. While recent learning-based approaches to addressing this\ntask have shown great success on synthetic datasets, we have observed them to\nfail in the presence of real-world data. We thus analyze the causes of these\nfailures, which we trace back to the difference between the feature\ndistributions of the source and target point clouds, and the sensitivity of the\nwidely-used SVD-based loss function to the range of rotation between the two\npoint clouds. We address the first challenge by introducing a new normalization\nstrategy, Match Normalization, and the second via the use of a loss function\nbased on the negative log likelihood of point correspondences. Our two\ncontributions are general and can be applied to many existing learning-based 3D\nobject registration frameworks, which we illustrate by implementing them in two\nof them, DCP and IDAM. Our experiments on the real-scene TUD-L, LINEMOD and\nOccluded-LINEMOD datasets evidence the benefits of our strategies. They allow\nfor the first time learning-based 3D object registration methods to achieve\nmeaningful results on real-world data. We therefore expect them to be key to\nthe future development of point cloud registration methods.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Zheng Dang",
      "Lizhou Wang",
      "Yu Guo",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15309"
  },
  {
    "id": "arXiv:2203.15310",
    "title": "Hybrid Routing Transformer for Zero-Shot Learning",
    "abstract": "Zero-shot learning (ZSL) aims to learn models that can recognize unseen image\nsemantics based on the training of data with seen semantics. Recent studies\neither leverage the global image features or mine discriminative local patch\nfeatures to associate the extracted visual features to the semantic attributes.\nHowever, due to the lack of the necessary top-down guidance and semantic\nalignment for ensuring the model attending to the real attribute-correlation\nregions, these methods still encounter a significant semantic gap between the\nvisual modality and the attribute modality, which makes their prediction on\nunseen semantics unreliable. To solve this problem, this paper establishes a\nnovel transformer encoder-decoder model, called hybrid routing transformer\n(HRT). In HRT encoder, we embed an active attention, which is constructed by\nboth the bottom-up and the top-down dynamic routing pathways to generate the\nattribute-aligned visual feature. While in HRT decoder, we use static routing\nto calculate the correlation among the attribute-aligned visual features, the\ncorresponding attribute semantics, and the class attribute vectors to generate\nthe final class label predictions. This design makes the presented transformer\nmodel a hybrid of 1) top-down and bottom-up attention pathways and 2) dynamic\nand static routing pathways. Comprehensive experiments on three widely-used\nbenchmark datasets, namely CUB, SUN, and AWA2, are conducted. The obtained\nexperimental results demonstrate the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "De Cheng",
      "Gerong Wang",
      "Bo Wang",
      "Qiang Zhang",
      "Jungong Han",
      "Dingwen Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15310"
  },
  {
    "id": "arXiv:2203.15312",
    "title": "In-N-Out Generative Learning for Dense Unsupervised Video Segmentation",
    "abstract": "In this paper, we focus on the unsupervised Video Object Segmentation (VOS)\ntask which learns visual correspondence from unlabeled videos. Previous methods\nare mainly based on the contrastive learning paradigm, which optimize either in\npixel level or image level and show unsatisfactory scalability. Image-level\noptimization learns pixel-wise information implicitly therefore is sub-optimal\nfor such dense prediction task, while pixel-level optimization ignores the\nhigh-level semantic scope for capturing object deformation. To complementarily\nlearn these two levels of information in an unified framework, we propose the\nIn-aNd-Out (INO) generative learning from a purely generative perspective,\nwhich captures both high-level and fine-grained semantics by leveraging the\nstructural superiority of Vision Transformer (ViT) and achieves better\nscalability. Specifically, the in-generative learning recovers the corrupted\nparts of an image via inferring its fine-grained semantic structure, while the\nout-generative learning captures high-level semantics by imagining the global\ninformation of an image given only random fragments. To better discover the\ntemporal information, we additionally force the inter-frame consistency from\nboth feature level and affinity matrix level. Extensive experiments on\nDAVIS-2017 val and YouTube-VOS 2018 val show that our INO outperforms previous\nstate-of-the-art methods by significant margins.",
    "descriptor": "",
    "authors": [
      "Xiao Pan",
      "Peike Li",
      "Zongxin Yang",
      "Huiling Zhou",
      "Chang Zhou",
      "Hongxia Yang",
      "Jingren Zhou",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15312"
  },
  {
    "id": "arXiv:2203.15314",
    "title": "Cross-Modality High-Frequency Transformer for MR Image Super-Resolution",
    "abstract": "Improving the resolution of magnetic resonance (MR) image data is critical to\ncomputer-aided diagnosis and brain function analysis. Higher resolution helps\nto capture more detailed content, but typically induces to lower\nsignal-to-noise ratio and longer scanning time. To this end, MR image\nsuper-resolution has become a widely-interested topic in recent times. Existing\nworks establish extensive deep models with the conventional architectures based\non convolutional neural networks (CNN). In this work, to further advance this\nresearch field, we make an early effort to build a Transformer-based MR image\nsuper-resolution framework, with careful designs on exploring valuable domain\nprior knowledge. Specifically, we consider two-fold domain priors including the\nhigh-frequency structure prior and the inter-modality context prior, and\nestablish a novel Transformer architecture, called Cross-modality\nhigh-frequency Transformer (Cohf-T), to introduce such priors into\nsuper-resolving the low-resolution (LR) MR images. Comprehensive experiments on\ntwo datasets indicate that Cohf-T achieves new state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Chaowei Fang",
      "Dingwen Zhang",
      "Liang Wang",
      "Yulun Zhang",
      "Lechao Cheng",
      "Junwei Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15314"
  },
  {
    "id": "arXiv:2203.15316",
    "title": "Systematically Evaluation of Challenge Obfuscated APUFs",
    "abstract": "As a well-known physical unclonable function that can provide huge number of\nchallenge response pairs (CRP) with a compact design and fully compatibility\nwith current electronic fabrication process, the arbiter PUF (APUF) has\nattracted great attention. To improve its resilience against modeling attacks,\nmany APUF variants have been proposed so far. Though the modeling resilience of\nresponse obfuscated APUF variants such as XOR-APUF and lightweight secure APUF\n(LSPUF) have been well studied, the challenge obfuscated APUFs (CO-APUFs) such\nas feed-forward APUF (FF-APUF), and XOR-FF-APUF are less elucidated,\nespecially, with the deep learning (DL) methods. This work systematically\nevaluates five CO-APUFs including three influential designs of FF-APUF,\nXOR-FF-APUF, iPUF, one very recently design and our newly optimized design\n(dubbed as OAX-FF-APUF), in terms of their reliability, uniformity (related to\nuniqueness), and modeling resilience. Three DL techniques of GRU, TCN and MLP\nare employed to examine these CO-APUFs' modeling resilience -- the first two\nare newly explored. With computation resource of a common personal computer, we\nshow that all five CO-APUFs with relatively large scale can be successfully\nmodeled -- attacking accuracy higher or close to its reliability. The\nhyper-parameter tuning of DL technique is crucial for implementing efficient\nattacks. Increasing the scale of the CO-APUF is validated to be able to improve\nthe resilience but should be done with minimizing the reliability degradation.\nAs the powerful capability of DL technique affirmed by us, we recommend the DL,\nspecifically the MLP technique always demonstrating best efficacy, to be always\nconsidered for examining the modeling resilience when newly composited APUFs\nare devised or to a large extent, other strong PUFs are constructed.",
    "descriptor": "",
    "authors": [
      "Yansong Gao",
      "Jianrong Yao",
      "Lihui Pang",
      "Zhi Zhang",
      "Anmin Fu",
      "Naixue Xiong",
      "Hyoungshick Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.15316"
  },
  {
    "id": "arXiv:2203.15317",
    "title": "Agreement or Disagreement in Noise-tolerant Mutual Learning?",
    "abstract": "Deep learning has made many remarkable achievements in many fields but\nsuffers from noisy labels in datasets. The state-of-the-art learning with noisy\nlabel method Co-teaching and Co-teaching+ confronts the noisy label by\nmutual-information between dual-network. However, the dual network always tends\nto convergent which would weaken the dual-network mechanism to resist the noisy\nlabels. In this paper, we proposed a noise-tolerant framework named MLC in an\nend-to-end manner. It adjusts the dual-network with divergent regularization to\nensure the effectiveness of the mechanism. In addition, we correct the label\ndistribution according to the agreement between dual-networks. The proposed\nmethod can utilize the noisy data to improve the accuracy, generalization, and\nrobustness of the network. We test the proposed method on the simulate noisy\ndataset MNIST, CIFAR-10, and the real-world noisy dataset Clothing1M. The\nexperimental result shows that our method outperforms the previous\nstate-of-the-art method. Besides, our method is network-free thus it is\napplicable to many tasks.",
    "descriptor": "",
    "authors": [
      "Jiarun Liu",
      "Daguang Jiang",
      "Yukun Yang",
      "Ruirui Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15317"
  },
  {
    "id": "arXiv:2203.15318",
    "title": "Evolving Multi-Label Fuzzy Classifier",
    "abstract": "Multi-label classification has attracted much attention in the machine\nlearning community to address the problem of assigning single samples to more\nthan one class at the same time. We propose an evolving multi-label fuzzy\nclassifier (EFC-ML) which is able to self-adapt and self-evolve its structure\nwith new incoming multi-label samples in an incremental, single-pass manner. It\nis based on a multi-output Takagi-Sugeno type architecture, where for each\nclass a separate consequent hyper-plane is defined. The learning procedure\nembeds a locally weighted incremental correlation-based algorithm combined with\n(conventional) recursive fuzzily weighted least squares and Lasso-based\nregularization. The correlation-based part ensures that the interrelations\nbetween class labels, a specific well-known property in multi-label\nclassification for improved performance, are preserved properly; the\nLasso-based regularization reduces the curse of dimensionality effects in the\ncase of a higher number of inputs. Antecedent learning is achieved by\nproduct-space clustering and conducted for all class labels together, which\nyields a single rule base, allowing a compact knowledge view. Furthermore, our\napproach comes with an online active learning (AL) strategy for updating the\nclassifier on just a number of selected samples, which in turn makes the\napproach applicable for scarcely labelled streams in applications, where the\nannotation effort is typically expensive. Our approach was evaluated on several\ndata sets from the MULAN repository and showed significantly improved\nclassification accuracy compared to (evolving) one-versus-rest or classifier\nchaining concepts. A significant result was that, due to the online AL method,\na 90\\% reduction in the number of samples used for classifier updates had\nlittle effect on the accumulated accuracy trend lines compared to a full update\nin most data set cases.",
    "descriptor": "",
    "authors": [
      "Edwin Lughofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15318"
  },
  {
    "id": "arXiv:2203.15319",
    "title": "Can NMT Understand Me? Towards Perturbation-based Evaluation of NMT  Models for Code Generation",
    "abstract": "Neural Machine Translation (NMT) has reached a level of maturity to be\nrecognized as the premier method for the translation between different\nlanguages and aroused interest in different research areas, including software\nengineering. A key step to validate the robustness of the NMT models consists\nin evaluating the performance of the models on adversarial inputs, i.e., inputs\nobtained from the original ones by adding small amounts of perturbation.\nHowever, when dealing with the specific task of the code generation (i.e., the\ngeneration of code starting from a description in natural language), it has not\nyet been defined an approach to validate the robustness of the NMT models. In\nthis work, we address the problem by identifying a set of perturbations and\nmetrics tailored for the robustness assessment of such models. We present a\npreliminary experimental evaluation, showing what type of perturbations affect\nthe model the most and deriving useful insights for future directions.",
    "descriptor": "\nComments: Paper accepted for publication in the proceedings of The 1st Intl. Workshop on Natural Language-based Software Engineering (NLBSE) to be held with ICSE 2022\n",
    "authors": [
      "Pietro Liguori",
      "Cristina Improta",
      "Simona De Vivo",
      "Roberto Natella",
      "Bojan Cukic",
      "Domenico Cotroneo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.15319"
  },
  {
    "id": "arXiv:2203.15320",
    "title": "Dressing in the Wild by Watching Dance Videos",
    "abstract": "While significant progress has been made in garment transfer, one of the most\napplicable directions of human-centric image generation, existing works\noverlook the in-the-wild imagery, presenting severe garment-person misalignment\nas well as noticeable degradation in fine texture details. This paper,\ntherefore, attends to virtual try-on in real-world scenes and brings essential\nimprovements in authenticity and naturalness especially for loose garment\n(e.g., skirts, formal dresses), challenging poses (e.g., cross arms, bent\nlegs), and cluttered backgrounds. Specifically, we find that the pixel flow\nexcels at handling loose garments whereas the vertex flow is preferred for hard\nposes, and by combining their advantages we propose a novel generative network\ncalled wFlow that can effectively push up garment transfer to in-the-wild\ncontext. Moreover, former approaches require paired images for training.\nInstead, we cut down the laboriousness by working on a newly constructed\nlarge-scale video dataset named Dance50k with self-supervised cross-frame\ntraining and an online cycle optimization. The proposed Dance50k can boost\nreal-world virtual dressing by covering a wide variety of garments under\ndancing poses. Extensive experiments demonstrate the superiority of our wFlow\nin generating realistic garment transfer results for in-the-wild images without\nresorting to expensive paired datasets.",
    "descriptor": "\nComments: Accepted at CVPR2022, Project: this https URL\n",
    "authors": [
      "Xin Dong",
      "Fuwei Zhao",
      "Zhenyu Xie",
      "Xijin Zhang",
      "Daniel K. Du",
      "Min Zheng",
      "Xiang Long",
      "Xiaodan Liang",
      "Jianchao Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15320"
  },
  {
    "id": "arXiv:2203.15321",
    "title": "Noise-robust Speech Recognition with 10 Minutes Unparalleled In-domain  Data",
    "abstract": "Noise-robust speech recognition systems require large amounts of training\ndata including noisy speech data and corresponding transcripts to achieve\nstate-of-the-art performances in face of various practical environments.\nHowever, such plenty of in-domain data is not always available in the real-life\nworld. In this paper, we propose a generative adversarial network to simulate\nnoisy spectrum from the clean spectrum (Simu-GAN), where only 10 minutes of\nunparalleled in-domain noisy speech data is required as labels. Furthermore, we\nalso propose a dual-path speech recognition system to improve the robustness of\nthe system under noisy conditions. Experimental results show that the proposed\nspeech recognition system achieves 7.3% absolute improvement with simulated\nnoisy data by Simu-GAN over the best baseline in terms of word error rate\n(WER).",
    "descriptor": "\nComments: Accepted by ICASSP2022\n",
    "authors": [
      "Chen Chen",
      "Nana Hou",
      "Yuchen Hu",
      "Shashank Shirol",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15321"
  },
  {
    "id": "arXiv:2203.15322",
    "title": "Time Reversal Precoding at SubTHz Frequencies: Experimental Results on  Spatiotemporal Focusing",
    "abstract": "Due to availability of large spectrum chunks, the sub-TeraHertz (subTHz)\nfrequency band can support Ultra-WideBand (UWB) wireless communications, paving\nthe way for unprecedented increase in the wireless network capacity. This fact\nis expected to be the next breakthrough for the upcoming sixth Generation (6G)\nstandards. However, the technology of subTHz transceivers is not yet mature\nenough to apply the advanced signal processing currently being implemented for\nmillimeter wave wireless communications. In this paper, we consider the Time\nReversal (TR) precoding technique, which provides simple and robust processing\ncapable to offer highly focalized in time and space UWB waveforms, exploiting\nthe spatial diversity of wireless channels. We first investigate experimentally\nthe performance of subTHz TR focusing in complex media inside a leaking\nreverberation cavity. We then combine TR with received spatial modulation to\nrealize data communication using a simple non-coherent receiver with two\nantennas. Our results showcase the capability of TR to offer focusing in time\nin the order of few nanoseconds and in space in the order of less than 1 mm.",
    "descriptor": "\nComments: 5 pages, 5 figures, presented at IEEE Conference on Standards for Communications and Networking 2021\n",
    "authors": [
      "Ali Mokh",
      "Julien de Rosny",
      "George C. Alexandropoulos",
      "Ramin Khayatzadeh",
      "Abdelwaheb Ourir",
      "Mohamed Kamoun",
      "Arnaud Tourin",
      "Mathias Fink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.15322"
  },
  {
    "id": "arXiv:2203.15323",
    "title": "Improving Persian Relation Extraction Models by Data Augmentation",
    "abstract": "Relation extraction that is the task of predicting semantic relation type\nbetween entities in a sentence or document is an important task in natural\nlanguage processing. Although there are many researches and datasets for\nEnglish, Persian suffers from sufficient researches and comprehensive datasets.\nThe only available Persian dataset for this task is PERLEX, which is a Persian\nexpert-translated version of the SemEval-2010-Task-8 dataset. In this paper, we\npresent our augmented dataset and the results and findings of our system,\nparticipated in the Persian relation Extraction shared task of NSURL 2021\nworkshop. We use PERLEX as the base dataset and enhance it by applying some\ntext preprocessing steps and by increasing its size via data augmentation\ntechniques to improve the generalization and robustness of applied models. We\nthen employ two different models including ParsBERT and multilingual BERT for\nrelation extraction on the augmented PERLEX dataset. Our best model obtained\n64.67% of Macro-F1 on the test phase of the contest and it achieved 83.68% of\nMacro-F1 on the test set of PERLEX.",
    "descriptor": "\nComments: 5 pages, 6 images\n",
    "authors": [
      "Moein Salimi Sartakhti",
      "Romina Etezadi",
      "Mehrnoush Shamsfard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.15323"
  },
  {
    "id": "arXiv:2203.15324",
    "title": "syslrn: Learning What to Monitor for Efficient Anomaly Detection",
    "abstract": "While monitoring system behavior to detect anomalies and failures is\nimportant, existing methods based on log-analysis can only be as good as the\ninformation contained in the logs, and other approaches that look at the\nOS-level software state introduce high overheads. We tackle the problem with\nsyslrn, a system that first builds an understanding of a target system offline,\nand then tailors the online monitoring instrumentation based on the learned\nidentifiers of normal behavior. While our syslrn prototype is still preliminary\nand lacks many features, we show in a case study for the monitoring of\nOpenStack failures that it can outperform state-of-the-art log-analysis systems\nwith little overhead.",
    "descriptor": "",
    "authors": [
      "Davide Sanvito",
      "Giuseppe Siracusano",
      "Sharan Santhanam",
      "Roberto Gonzalez",
      "Roberto Bifulco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2203.15324"
  },
  {
    "id": "arXiv:2203.15325",
    "title": "Robust Single Image Dehazing Based on Consistent and Contrast-Assisted  Reconstruction",
    "abstract": "Single image dehazing as a fundamental low-level vision task, is essential\nfor the development of robust intelligent surveillance system. In this paper,\nwe make an early effort to consider dehazing robustness under variational haze\ndensity, which is a realistic while under-studied problem in the research filed\nof singe image dehazing. To properly address this problem, we propose a novel\ndensity-variational learning framework to improve the robustness of the image\ndehzing model assisted by a variety of negative hazy images, to better deal\nwith various complex hazy scenarios. Specifically, the dehazing network is\noptimized under the consistency-regularized framework with the proposed\nContrast-Assisted Reconstruction Loss (CARL). The CARL can fully exploit the\nnegative information to facilitate the traditional positive-orient dehazing\nobjective function, by squeezing the dehazed image to its clean target from\ndifferent directions. Meanwhile, the consistency regularization keeps\nconsistent outputs given multi-level hazy images, thus improving the model\nrobustness. Extensive experimental results on two synthetic and three\nreal-world datasets demonstrate that our method significantly surpasses the\nstate-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "De Cheng",
      "Yan Li",
      "Dingwen Zhang",
      "Nannan Wang",
      "Xinbo Gao",
      "Jiande Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15325"
  },
  {
    "id": "arXiv:2203.15326",
    "title": "Speech Emotion Recognition with Co-Attention based Multi-level Acoustic  Information",
    "abstract": "Speech Emotion Recognition (SER) aims to help the machine to understand\nhuman's subjective emotion from only audio information. However, extracting and\nutilizing comprehensive in-depth audio information is still a challenging task.\nIn this paper, we propose an end-to-end speech emotion recognition system using\nmulti-level acoustic information with a newly designed co-attention module. We\nfirstly extract multi-level acoustic information, including MFCC, spectrogram,\nand the embedded high-level acoustic information with CNN, BiLSTM and wav2vec2,\nrespectively. Then these extracted features are treated as multimodal inputs\nand fused by the proposed co-attention mechanism. Experiments are carried on\nthe IEMOCAP dataset, and our model achieves competitive performance with two\ndifferent speaker-independent cross-validation strategies. Our code is\navailable on GitHub.",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Heqing Zou",
      "Yuke Si",
      "Chen Chen",
      "Deepu Rajan",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15326"
  },
  {
    "id": "arXiv:2203.15328",
    "title": "Compact Token Representations with Contextual Quantization for Efficient  Document Re-ranking",
    "abstract": "Transformer based re-ranking models can achieve high search relevance through\ncontext-aware soft matching of query tokens with document tokens. To alleviate\nruntime complexity of such inference, previous work has adopted a late\ninteraction architecture with pre-computed contextual token representations at\nthe cost of a large online storage. This paper proposes contextual quantization\nof token embeddings by decoupling document-specific and document-independent\nranking contributions during codebook-based compression. This allows effective\nonline decompression and embedding composition for better search relevance.\nThis paper presents an evaluation of the above compact token representation\nmodel in terms of relevance and space efficiency.",
    "descriptor": "",
    "authors": [
      "Yingrui Yang",
      "Yifan Qiao",
      "Tao Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.15328"
  },
  {
    "id": "arXiv:2203.15331",
    "title": "CNN Filter DB: An Empirical Investigation of Trained Convolutional  Filters",
    "abstract": "Currently, many theoretical as well as practically relevant questions towards\nthe transferability and robustness of Convolutional Neural Networks (CNNs)\nremain unsolved. While ongoing research efforts are engaging these problems\nfrom various angles, in most computer vision related cases these approaches can\nbe generalized to investigations of the effects of distribution shifts in image\ndata. In this context, we propose to study the shifts in the learned weights of\ntrained CNN models. Here we focus on the properties of the distributions of\ndominantly used 3x3 convolution filter kernels. We collected and publicly\nprovide a dataset with over 1.4 billion filters from hundreds of trained CNNs,\nusing a wide range of datasets, architectures, and vision tasks. In a first use\ncase of the proposed dataset, we can show highly relevant properties of many\npublicly available pre-trained models for practical applications: I) We analyze\ndistribution shifts (or the lack thereof) between trained filters along\ndifferent axes of meta-parameters, like visual category of the dataset, task,\narchitecture, or layer depth. Based on these results, we conclude that model\npre-training can succeed on arbitrary datasets if they meet size and variance\nconditions. II) We show that many pre-trained models contain degenerated\nfilters which make them less robust and less suitable for fine-tuning on target\napplications.\nData & Project website: https://github.com/paulgavrikov/cnn-filter-db",
    "descriptor": "\nComments: Accepted as ORAL at IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022 (CVPR)\n",
    "authors": [
      "Paul Gavrikov",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15331"
  },
  {
    "id": "arXiv:2203.15332",
    "title": "Balanced Multimodal Learning via On-the-fly Gradient Modulation",
    "abstract": "Multimodal learning helps to comprehensively understand the world, by\nintegrating different senses. Accordingly, multiple input modalities are\nexpected to boost model performance, but we actually find that they are not\nfully exploited even when the multimodal model outperforms its uni-modal\ncounterpart. Specifically, in this paper we point out that existing multimodal\ndiscriminative models, in which uniform objective is designed for all\nmodalities, could remain under-optimized uni-modal representations, caused by\nanother dominated modality in some scenarios, e.g., sound in blowing wind\nevent, vision in drawing picture event, etc. To alleviate this optimization\nimbalance, we propose on-the-fly gradient modulation to adaptively control the\noptimization of each modality, via monitoring the discrepancy of their\ncontribution towards the learning objective. Further, an extra Gaussian noise\nthat changes dynamically is introduced to avoid possible generalization drop\ncaused by gradient modulation. As a result, we achieve considerable improvement\nover common fusion methods on different multimodal tasks, and this simple\nstrategy can also boost existing multimodal methods, which illustrates its\nefficacy and versatility. The source code is available at\n\\url{https://github.com/GeWu-Lab/OGM-GE_CVPR2022}.",
    "descriptor": "\nComments: Accepted by CVPR 2022 (ORAL)\n",
    "authors": [
      "Xiaokang Peng",
      "Yake Wei",
      "Andong Deng",
      "Dong Wang",
      "Di Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15332"
  },
  {
    "id": "arXiv:2203.15333",
    "title": "On Affine Policies for Wasserstein Distributionally Robust Unit  Commitment",
    "abstract": "This paper proposes a unit commitment (UC) model based on data-driven\nWasserstein distributionally robust optimization (WDRO) for power systems under\nuncertainty of renewable generation as well as its tractable exact\nreformulation. The proposed model is formulated as a WDRO problem relying on an\naffine policy, which nests an infinite-dimensional worst-case expectation\nproblem and satisfies the non-anticipativity constraint. To reduce\nconservativeness, we develop a novel technique that defines a subset of the\nuncertainty set with a probabilistic guarantee. Subsequently, the proposed\nmodel is recast as a semi-infinite programming problem that can be efficiently\nsolved using existing algorithms. Notably, the scale of this reformulation is\ninvariant with the sample size. As a result, a number of samples are easily\nincorporated without using sophisticated decomposition algorithms. Numerical\nsimulations on 6- and 24-bus test systems demonstrate the economic and\ncomputational efficiency of the proposed model.",
    "descriptor": "",
    "authors": [
      "Youngchae Cho",
      "Insoon Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15333"
  },
  {
    "id": "arXiv:2203.15334",
    "title": "AnyFace: Free-style Text-to-Face Synthesis and Manipulation",
    "abstract": "Existing text-to-image synthesis methods generally are only applicable to\nwords in the training dataset. However, human faces are so variable to be\ndescribed with limited words. So this paper proposes the first free-style\ntext-to-face method namely AnyFace enabling much wider open world applications\nsuch as metaverse, social media, cosmetics, forensics, etc. AnyFace has a novel\ntwo-stream framework for face image synthesis and manipulation given arbitrary\ndescriptions of the human face. Specifically, one stream performs text-to-face\ngeneration and the other conducts face image reconstruction. Facial text and\nimage features are extracted using the CLIP (Contrastive Language-Image\nPre-training) encoders. And a collaborative Cross Modal Distillation (CMD)\nmodule is designed to align the linguistic and visual features across these two\nstreams. Furthermore, a Diverse Triplet Loss (DT loss) is developed to model\nfine-grained features and improve facial diversity. Extensive experiments on\nMulti-modal CelebA-HQ and CelebAText-HQ demonstrate significant advantages of\nAnyFace over state-of-the-art methods. AnyFace can achieve high-quality,\nhigh-resolution, and high-diversity face synthesis and manipulation results\nwithout any constraints on the number and content of input captions.",
    "descriptor": "",
    "authors": [
      "Jianxin Sun",
      "Qiyao Deng",
      "Qi Li",
      "Muyi Sun",
      "Min Ren",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15334"
  },
  {
    "id": "arXiv:2203.15335",
    "title": "Iranian Modal Music (Dastgah) detection using deep neural networks",
    "abstract": "In this work, several deep neural networks are implemented to recognize\nIranian modal music in seven high correlated categories. The best model, which\nachieved 92 percent overall accuracy, uses an architecture inspired by\nautoencoder, including BiLSTM and BiGRU layers. This model is trained using the\nNava dataset, with 1786 records and up to 55 hours of music played solo by\nKamanche, Tar, Setar, Reed, and Santoor (Dulcimer). Features that have been\nstudied through this research contain MFCC, Chroma CENS, and Mel spectrogram.\nThe results indicate that MFCC carries more valuable information for detecting\nIranian modal music (Dastgah) than other sound representations. Moreover, the\narchitecture, which is inspired by autoencoder, is robust in distinguishing\nhigh correlated data like Dastgahs. It also shows that because of the precise\norder in Iranian Dastgah Music, Bidirectional Recurrent networks are more\nefficient than any other networks that have been implemented in this study.",
    "descriptor": "",
    "authors": [
      "Danial Ebrat",
      "Farzad Didehvar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15335"
  },
  {
    "id": "arXiv:2203.15336",
    "title": "End-to-End Compressed Video Representation Learning for Generic Event  Boundary Detection",
    "abstract": "Generic event boundary detection aims to localize the generic, taxonomy-free\nevent boundaries that segment videos into chunks. Existing methods typically\nrequire video frames to be decoded before feeding into the network, which\ndemands considerable computational power and storage space. To that end, we\npropose a new end-to-end compressed video representation learning for event\nboundary detection that leverages the rich information in the compressed\ndomain, i.e., RGB, motion vectors, residuals, and the internal group of\npictures (GOP) structure, without fully decoding the video. Specifically, we\nfirst use the ConvNets to extract features of the I-frames in the GOPs. After\nthat, a light-weight spatial-channel compressed encoder is designed to compute\nthe feature representations of the P-frames based on the motion vectors,\nresiduals and representations of their dependent I-frames. A temporal\ncontrastive module is proposed to determine the event boundaries of video\nsequences. To remedy the ambiguities of annotations and speed up the training\nprocess, we use the Gaussian kernel to preprocess the ground-truth event\nboundaries. Extensive experiments conducted on the Kinetics-GEBD dataset\ndemonstrate that the proposed method achieves comparable results to the\nstate-of-the-art methods with $4.5\\times$ faster running speed.",
    "descriptor": "",
    "authors": [
      "Congcong Li",
      "Xinyao Wang",
      "Longyin Wen",
      "Dexiang Hong",
      "Tiejian Luo",
      "Libo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15336"
  },
  {
    "id": "arXiv:2203.15337",
    "title": "Infrared and Visible Image Fusion via Interactive Compensatory Attention  Adversarial Learning",
    "abstract": "The existing generative adversarial fusion methods generally concatenate\nsource images and extract local features through convolution operation, without\nconsidering their global characteristics, which tends to produce an unbalanced\nresult and is biased towards the infrared image or visible image. Toward this\nend, we propose a novel end-to-end mode based on generative adversarial\ntraining to achieve better fusion balance, termed as \\textit{interactive\ncompensatory attention fusion network} (ICAFusion). In particular, in the\ngenerator, we construct a multi-level encoder-decoder network with a triple\npath, and adopt infrared and visible paths to provide additional intensity and\ngradient information. Moreover, we develop interactive and compensatory\nattention modules to communicate their pathwise information, and model their\nlong-range dependencies to generate attention maps, which can more focus on\ninfrared target perception and visible detail characterization, and further\nincrease the representation power for feature extraction and feature\nreconstruction. In addition, dual discriminators are designed to identify the\nsimilar distribution between fused result and source images, and the generator\nis optimized to produce a more balanced result. Extensive experiments\nillustrate that our ICAFusion obtains superior fusion performance and better\ngeneralization ability, which precedes other advanced methods in the subjective\nvisual description and objective metric evaluation. Our codes will be public at\n\\url{https://github.com/Zhishe-Wang/ICAFusion}",
    "descriptor": "\nComments: 13pages,12 figures\n",
    "authors": [
      "Zhishe Wang",
      "Wenyu Shao",
      "Yanlin Chen",
      "Jiawei Xu",
      "Xiaoqin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15337"
  },
  {
    "id": "arXiv:2203.15338",
    "title": "Dynamic-subarray with Fixed Phase Shifters for Energy-efficient  Terahertz Hybrid Beamforming under Partial CSI",
    "abstract": "Terahertz (THz) communications are regarded as a pillar technology for the 6G\nsystems, by offering multi-ten-GHz bandwidth. To overcome the huge propagation\nloss while reducing the hardware complexity, THz ultra-massive (UM) MIMO\nsystems with hybrid beamforming are proposed to offer high array gain. Notably,\nthe adjustable-phase-shifters considered in most existing hybrid beamforming\nstudies are power-hungry and difficult to realize in the THz band. Moreover,\ndue to the ultra-massive antennas, full channel-state-information (CSI) is\nchallenging to obtain. To address these practical concerns, in this paper, an\nenergy-efficient dynamic-subarray with fixed-phase-shifters (DS-FPS)\narchitecture is proposed for THz hybrid beamforming. To compensate for the\nspectral efficiency loss caused by the fixed-phase of FPS, a switch network is\ninserted to enable dynamic connections. In addition, by considering the partial\nCSI, we propose a row-successive-decomposition (RSD) algorithm to design the\nhybrid beamforming matrices for DS-FPS. A row-by-row (RBR) algorithm is further\nproposed to reduce computational complexity. Extensive simulation results show\nthat, the proposed DS-FPS architecture with the RSD and RBR algorithms achieves\nmuch higher energy efficiency than the existing architectures. Moreover, the\nDS-FPS architecture with partial CSI achieves 97% spectral efficiency of that\nwith full CSI.",
    "descriptor": "\nComments: 30 pages, 10 figures\n",
    "authors": [
      "Longfei Yan",
      "Chong Han",
      "Nan Yang",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.15338"
  },
  {
    "id": "arXiv:2203.15340",
    "title": "Splitting-based randomized iterative methods for solving indefinite  least squares problem",
    "abstract": "The indefinite least squares (ILS) problem is a generalization of the famous\nlinear least squares problem. It minimizes an indefinite quadratic form with\nrespect to a signature matrix. For this problem, we first propose an\nimpressively simple and effective splitting (SP) method according to its own\nstructure and prove that it converges 'unconditionally' for any initial value.\nFurther, to avoid implementing some matrix multiplications and calculating the\ninverse of large matrix and considering the acceleration and efficiency of the\nrandomized strategy, we develop two randomized iterative methods on the basis\nof the SP method as well as the randomized Kaczmarz, Gauss-Seidel and\ncoordinate descent methods, and describe their convergence properties.\nNumerical results show that our three methods all have quite decent performance\nin both computing time and iteration numbers compared with the latest iterative\nmethod of the ILS problem, and also demonstrate that the two randomized methods\nindeed yield significant acceleration in term of computing time.",
    "descriptor": "",
    "authors": [
      "Yanjun Zhang",
      "Hanyu Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15340"
  },
  {
    "id": "arXiv:2203.15345",
    "title": "Task-specific Inconsistency Alignment for Domain Adaptive Object  Detection",
    "abstract": "Detectors trained with massive labeled data often exhibit dramatic\nperformance degradation in some particular scenarios with data distribution\ngap. To alleviate this problem of domain shift, conventional wisdom typically\nconcentrates solely on reducing the discrepancy between the source and target\ndomains via attached domain classifiers, yet ignoring the difficulty of such\ntransferable features in coping with both classification and localization\nsubtasks in object detection. To address this issue, in this paper, we propose\nTask-specific Inconsistency Alignment (TIA), by developing a new alignment\nmechanism in separate task spaces, improving the performance of the detector on\nboth subtasks. Specifically, we add a set of auxiliary predictors for both\nclassification and localization branches, and exploit their behavioral\ninconsistencies as finer-grained domain-specific measures. Then, we devise\ntask-specific losses to align such cross-domain disagreement of both subtasks.\nBy optimizing them individually, we are able to well approximate the category-\nand boundary-wise discrepancies in each task space, and therefore narrow them\nin a decoupled manner. TIA demonstrates superior results on various scenarios\nto the previous state-of-the-art methods. It is also observed that both the\nclassification and localization capabilities of the detector are sufficiently\nstrengthened, further demonstrating the effectiveness of our TIA method. Code\nand trained models are publicly available at https://github.com/MCG-NJU/TIA.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Liang Zhao",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15345"
  },
  {
    "id": "arXiv:2203.15346",
    "title": "Enumeration of extended irreducible binary Goppa codes",
    "abstract": "The family of Goppa codes is one of the most interesting subclasses of linear\ncodes. As the McEliece cryptosystem often chooses a random Goppa code as its\nkey,knowledge of the number of inequivalent Goppa codes for fixed parameters\nmay facilitate in the evaluation of the security of such a cryptosystem. In\nthis paper we present a new approach to give an upper bound on the number of\ninequivalent extended irreducible binary Goppa codes. To be more specific, let\n$n>3$ be an odd prime number and $q=2^n$; let $r\\geq3$ be a positive integer\nsatisfying $\\gcd(r,n)=1$ and $\\gcd\\big(r,q(q^2-1)\\big)=1$. We obtain an upper\nbound for the number of inequivalent extended irreducible binary Goppa codes of\nlength $q+1$ and degree $r$.",
    "descriptor": "\nComments: This paper is already accepted by IEEE Transactions on Information Theory on March 3, 2022\n",
    "authors": [
      "Bocong Chen",
      "Guanghui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.15346"
  },
  {
    "id": "arXiv:2203.15349",
    "title": "LDKP: A Dataset for Identifying Keyphrases from Long Scientific  Documents",
    "abstract": "Identifying keyphrases (KPs) from text documents is a fundamental task in\nnatural language processing and information retrieval. Vast majority of the\nbenchmark datasets for this task are from the scientific domain containing only\nthe document title and abstract information. This limits keyphrase extraction\n(KPE) and keyphrase generation (KPG) algorithms to identify keyphrases from\nhuman-written summaries that are often very short (approx 8 sentences). This\npresents three challenges for real-world applications: human-written summaries\nare unavailable for most documents, the documents are almost always long, and a\nhigh percentage of KPs are directly found beyond the limited context of title\nand abstract. Therefore, we release two extensive corpora mapping KPs of ~1.3M\nand ~100K scientific articles with their fully extracted text and additional\nmetadata including publication venue, year, author, field of study, and\ncitations for facilitating research on this real-world problem.",
    "descriptor": "",
    "authors": [
      "Debanjan Mahata",
      "Naveen Agarwal",
      "Dibya Gautam",
      "Amardeep Kumar",
      "Swapnil Parekh",
      "Yaman Kumar Singla",
      "Anish Acharya",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.15349"
  },
  {
    "id": "arXiv:2203.15350",
    "title": "End-to-End Transformer Based Model for Image Captioning",
    "abstract": "CNN-LSTM based architectures have played an important role in image\ncaptioning, but limited by the training efficiency and expression ability,\nresearchers began to explore the CNN-Transformer based models and achieved\ngreat success. Meanwhile, almost all recent works adopt Faster R-CNN as the\nbackbone encoder to extract region-level features from given images. However,\nFaster R-CNN needs a pre-training on an additional dataset, which divides the\nimage captioning task into two stages and limits its potential applications. In\nthis paper, we build a pure Transformer-based model, which integrates image\ncaptioning into one stage and realizes end-to-end training. Firstly, we adopt\nSwinTransformer to replace Faster R-CNN as the backbone encoder to extract\ngrid-level features from given images; Then, referring to Transformer, we build\na refining encoder and a decoder. The refining encoder refines the grid\nfeatures by capturing the intra-relationship between them, and the decoder\ndecodes the refined features into captions word by word. Furthermore, in order\nto increase the interaction between multi-modal (vision and language) features\nto enhance the modeling capability, we calculate the mean pooling of grid\nfeatures as the global feature, then introduce it into refining encoder to\nrefine with grid features together, and add a pre-fusion process of refined\nglobal feature and generated words in decoder. To validate the effectiveness of\nour proposed model, we conduct experiments on MSCOCO dataset. The experimental\nresults compared to existing published works demonstrate that our model\nachieves new state-of-the-art performances of 138.2% (single model) and 141.0%\n(ensemble of 4 models) CIDEr scores on `Karpathy' offline test split and 136.0%\n(c5) and 138.3% (c40) CIDEr scores on the official online test server. Trained\nmodels and source code will be released.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Yiyu Wang",
      "Jungang Xu",
      "Yingfei Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15350"
  },
  {
    "id": "arXiv:2203.15351",
    "title": "Random Geometric Graph: Some recent developments and perspectives",
    "abstract": "The Random Geometric Graph (RGG) is a random graph model for network data\nwith an underlying spatial representation. Geometry endows RGGs with a rich\ndependence structure and often leads to desirable properties of real-world\nnetworks such as the small-world phenomenon and clustering. Originally\nintroduced to model wireless communication networks, RGGs are now very popular\nwith applications ranging from network user profiling to protein-protein\ninteractions in biology. RGGs are also of purely theoretical interest since the\nunderlying geometry gives rise to challenging mathematical questions. Their\nresolutions involve results from probability, statistics, combinatorics or\ninformation theory, placing RGGs at the intersection of a large span of\nresearch communities. This paper surveys the recent developments in RGGs from\nthe lens of high dimensional settings and non-parametric inference. We also\nexplain how this model differs from classical community based random graph\nmodels and we review recent works that try to take the best of both worlds. As\na by-product, we expose the scope of the mathematical tools used in the proofs.",
    "descriptor": "\nComments: This is a research report that is part of a Chapter of a PhD thesis. An updated version will be available soon\n",
    "authors": [
      "Quentin Duchemin",
      "Yohann de Castro"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2203.15351"
  },
  {
    "id": "arXiv:2203.15353",
    "title": "SIOD: Single Instance Annotated Per Category Per Image for Object  Detection",
    "abstract": "Object detection under imperfect data receives great attention recently.\nWeakly supervised object detection (WSOD) suffers from severe localization\nissues due to the lack of instance-level annotation, while semi-supervised\nobject detection (SSOD) remains challenging led by the inter-image discrepancy\nbetween labeled and unlabeled data. In this study, we propose the Single\nInstance annotated Object Detection (SIOD), requiring only one instance\nannotation for each existing category in an image. Degraded from inter-task\n(WSOD) or inter-image (SSOD) discrepancies to the intra-image discrepancy, SIOD\nprovides more reliable and rich prior knowledge for mining the rest of\nunlabeled instances and trades off the annotation cost and performance. Under\nthe SIOD setting, we propose a simple yet effective framework, termed\nDual-Mining (DMiner), which consists of a Similarity-based Pseudo Label\nGenerating module (SPLG) and a Pixel-level Group Contrastive Learning module\n(PGCL). SPLG firstly mines latent instances from feature representation space\nto alleviate the annotation missing problem. To avoid being misled by\ninaccurate pseudo labels, we propose PGCL to boost the tolerance to false\npseudo labels. Extensive experiments on MS COCO verify the feasibility of the\nSIOD setting and the superiority of the proposed method, which obtains\nconsistent and significant improvements compared to baseline methods and\nachieves comparable results with fully supervised object detection (FSOD)\nmethods with only 40% instances annotated.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Hanjun Li",
      "Xingjia Pan",
      "Ke Yan",
      "Fan Tang",
      "Wei-Shi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15353"
  },
  {
    "id": "arXiv:2203.15354",
    "title": "Signing at Scale: Learning to Co-Articulate Signs for Large-Scale  Photo-Realistic Sign Language Production",
    "abstract": "Sign languages are visual languages, with vocabularies as rich as their\nspoken language counterparts. However, current deep-learning based Sign\nLanguage Production (SLP) models produce under-articulated skeleton pose\nsequences from constrained vocabularies and this limits applicability. To be\nunderstandable and accepted by the deaf, an automatic SLP system must be able\nto generate co-articulated photo-realistic signing sequences for large domains\nof discourse.\nIn this work, we tackle large-scale SLP by learning to co-articulate between\ndictionary signs, a method capable of producing smooth signing while scaling to\nunconstrained domains of discourse. To learn sign co-articulation, we propose a\nnovel Frame Selection Network (FS-Net) that improves the temporal alignment of\ninterpolated dictionary signs to continuous signing sequences. Additionally, we\npropose SignGAN, a pose-conditioned human synthesis model that produces\nphoto-realistic sign language videos direct from skeleton pose. We propose a\nnovel keypoint-based loss function which improves the quality of synthesized\nhand images.\nWe evaluate our SLP model on the large-scale meineDGS (mDGS) corpus,\nconducting extensive user evaluation showing our FS-Net approach improves\nco-articulation of interpolated dictionary signs. Additionally, we show that\nSignGAN significantly outperforms all baseline methods for quantitative\nmetrics, human perceptual studies and native deaf signer comprehension.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2011.09846\n",
    "authors": [
      "Ben Saunders",
      "Necati Cihan Camgoz",
      "Richard Bowden"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15354"
  },
  {
    "id": "arXiv:2203.15355",
    "title": "Online Continual Learning on a Contaminated Data Stream with Blurry Task  Boundaries",
    "abstract": "Learning under a continuously changing data distribution with incorrect\nlabels is a desirable real-world problem yet challenging. A large body of\ncontinual learning (CL) methods, however, assumes data streams with clean\nlabels, and online learning scenarios under noisy data streams are yet\nunderexplored. We consider a more practical CL task setup of an online learning\nfrom blurry data stream with corrupted labels, where existing CL methods\nstruggle. To address the task, we first argue the importance of both diversity\nand purity of examples in the episodic memory of continual learning models. To\nbalance diversity and purity in the episodic memory, we propose a novel\nstrategy to manage and use the memory by a unified approach of label noise\naware diverse sampling and robust learning with semi-supervised learning. Our\nempirical validations on four real-world or synthetic noise datasets (CIFAR10\nand 100, mini-WebVision, and Food-101N) exhibit that our method significantly\noutperforms prior arts in this realistic and challenging continual learning\nscenario. Code and data splits are available in\nhttps://github.com/clovaai/puridiver.",
    "descriptor": "\nComments: Accepted paper at CVPR 2022\n",
    "authors": [
      "Jihwan Bang",
      "Hyunseo Koh",
      "Seulki Park",
      "Hwanjun Song",
      "Jung-Woo Ha",
      "Jonghyun Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15355"
  },
  {
    "id": "arXiv:2203.15358",
    "title": "On the influence of the nonlinear term in the numerical approximation of  Incompressible Flows by means of proper orthogonal decomposition methods",
    "abstract": "We consider proper orthogonal decomposition (POD) methods to approximate the\nincompressible Navier-Stokes equations. We study the case in which one\ndiscretization for the nonlinear term is used in the snapshots (that are\ncomputed with a full order method (FOM)) and a different discretization of the\nnonlinear term is applied in the POD method. We prove that an additional error\nterm appears in this case, compared with the case in which the same\ndiscretization of the nonlinear term is applied for both the FOM and the POD\nmethods. However, the added term has the same size as the error coming from the\nFOM so that the rate of convergence of the POD method is barely affected. We\nanalyze the case in which we add grad-div stabilization to both the FOM and the\nPOD methods because it allows to get error bounds with constants independent of\ninverse powers of the viscosity. We also study the case in which no\nstabilization is added. Some numerical experiments support the theoretical\nanalysis.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.00211\n",
    "authors": [
      "Bosco Garc\u00eda-Archilla",
      "Julia Novo",
      "Samuele Rubino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15358"
  },
  {
    "id": "arXiv:2203.15359",
    "title": "Nested Collaborative Learning for Long-Tailed Visual Recognition",
    "abstract": "The networks trained on the long-tailed dataset vary remarkably, despite the\nsame training settings, which shows the great uncertainty in long-tailed\nlearning. To alleviate the uncertainty, we propose a Nested Collaborative\nLearning (NCL), which tackles the problem by collaboratively learning multiple\nexperts together. NCL consists of two core components, namely Nested Individual\nLearning (NIL) and Nested Balanced Online Distillation (NBOD), which focus on\nthe individual supervised learning for each single expert and the knowledge\ntransferring among multiple experts, respectively. To learn representations\nmore thoroughly, both NIL and NBOD are formulated in a nested way, in which the\nlearning is conducted on not just all categories from a full perspective but\nsome hard categories from a partial perspective. Regarding the learning in the\npartial perspective, we specifically select the negative categories with high\npredicted scores as the hard categories by using a proposed Hard Category\nMining (HCM). In the NCL, the learning from two perspectives is nested, highly\nrelated and complementary, and helps the network to capture not only global and\nrobust features but also meticulous distinguishing ability. Moreover,\nself-supervision is further utilized for feature enhancement. Extensive\nexperiments manifest the superiority of our method with outperforming the\nstate-of-the-art whether by using a single model or an ensemble.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Jun Li",
      "Zichang Tan",
      "Jun Wan",
      "Zhen Lei",
      "Guodong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15359"
  },
  {
    "id": "arXiv:2203.15360",
    "title": "Time-optimal control of cranes subject to container height constraints",
    "abstract": "The productivity and efficiency of port operations strongly depend on how\nfast a ship can be unloaded and loaded again. With this in mind, ship-to-shore\ncranes perform the critical task of transporting containers into and onto a\nship and must do so as fast as possible. Though the problem of minimizing the\ntime spent in moving the payload has been addressed in previous studies, the\ndifferent heights of the container stacks have not been the focus. In this\npaper, we perform a change of variable and reformulate the optimization problem\nto deal with the constraints on the stack heights. As consequence, these\nconstraints become trivial and easy to represent since they turn into bound\nconstraints when the problem is discretized for the numerical solver. To\nvalidate the idea, we simulate a small-scale scenario where different stack\nheights are used. The results confirm our idea and the representation of the\nstack constraints become indeed trivial. This approach is promising to be\napplied in real crane operations and has the potential to enhance their\nautomation.",
    "descriptor": "\nComments: Paper accepted for presentation at, and publication in the proceedings of, the 2022 American Control Conference\n",
    "authors": [
      "Filipe Marques Barbosa",
      "Johan L\u00f6fberg"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.15360"
  },
  {
    "id": "arXiv:2203.15361",
    "title": "Self-Supervised Image Representation Learning with Geometric Set  Consistency",
    "abstract": "We propose a method for self-supervised image representation learning under\nthe guidance of 3D geometric consistency. Our intuition is that 3D geometric\nconsistency priors such as smooth regions and surface discontinuities may imply\nconsistent semantics or object boundaries, and can act as strong cues to guide\nthe learning of 2D image representations without semantic labels. Specifically,\nwe introduce 3D geometric consistency into a contrastive learning framework to\nenforce the feature consistency within image views. We propose to use geometric\nconsistency sets as constraints and adapt the InfoNCE loss accordingly. We show\nthat our learned image representations are general. By fine-tuning our\npre-trained representations for various 2D image-based downstream tasks,\nincluding semantic segmentation, object detection, and instance segmentation on\nreal-world indoor scene datasets, we achieve superior performance compared with\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Nenglun Chen",
      "Lei Chu",
      "Hao Pan",
      "Yan Lu",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15361"
  },
  {
    "id": "arXiv:2203.15362",
    "title": "Domain Invariant Siamese Attention Mask for Small Object Change  Detection via Everyday Indoor Robot Navigation",
    "abstract": "The problem of image change detection via everyday indoor robot navigation is\nexplored from a novel perspective of the self-attention technique. Detecting\nsemantically non-distinctive and visually small changes remains a key challenge\nin the robotics community. Intuitively, these small non-distinctive changes may\nbe better handled by the recent paradigm of the attention mechanism, which is\nthe basic idea of this work. However, existing self-attention models require\nsignificant retraining cost per domain, so it is not directly applicable to\nrobotics applications. We propose a new self-attention technique with an\nability of unsupervised on-the-fly domain adaptation, which introduces an\nattention mask into the intermediate layer of an image change detection model,\nwithout modifying the input and output layers of the model. Experiments, in\nwhich an indoor robot aims to detect visually small changes in everyday\nnavigation, demonstrate that our attention technique significantly boosts the\nstate-of-the-art image change detection model.",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Koji Takeda",
      "Kanji Tanaka",
      "Yoshimasa Nakamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15362"
  },
  {
    "id": "arXiv:2203.15364",
    "title": "The Inefficiency of Language Models in Scholarly Retrieval: An  Experimental Walk-through",
    "abstract": "Language models are increasingly becoming popular in AI-powered scientific IR\nsystems. This paper evaluates popular scientific language models in handling\n(i) short-query texts and (ii) textual neighbors. Our experiments showcase the\ninability to retrieve relevant documents for a short-query text even under the\nmost relaxed conditions. Additionally, we leverage textual neighbors, generated\nby small perturbations to the original text, to demonstrate that not all\nperturbations lead to close neighbors in the embedding space. Further, an\nexhaustive categorization yields several classes of orthographically and\nsemantically related, partially related, and completely unrelated neighbors.\nRetrieval performance turns out to be more influenced by the surface form\nrather than the semantics of the text.",
    "descriptor": "\nComments: 21 pages. To appear in Findings of ACL 2022\n",
    "authors": [
      "Shruti Singh",
      "Mayank Singh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.15364"
  },
  {
    "id": "arXiv:2203.15366",
    "title": "Face segmentation: A comparison between visible and thermal images",
    "abstract": "Face segmentation is a first step for face biometric systems. In this paper\nwe present a face segmentation algorithm for thermographic images. This\nalgorithm is compared with the classic Viola and Jones algorithm used for\nvisible images. Experimental results reveal that, when segmenting a\nmultispectral (visible and thermal) face database, the proposed algorithm is\nmore than 10 times faster, while the accuracy of face segmentation in thermal\nimages is higher than in case of Viola-Jones",
    "descriptor": "\nComments: 5 pages, published in 44th Annual 2010 IEEE International Carnahan Conference on Security Technology, 2010, pp. 185-189, 5-8 Oct. 2010 San Jose (California, USA)\n",
    "authors": [
      "Jiri Mekyska",
      "Virginia Espinosa-Dur\u00f3",
      "Marcos Faundez-Zanuy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15366"
  },
  {
    "id": "arXiv:2203.15369",
    "title": "Geographic Diversity in Public Code Contributions",
    "abstract": "We conduct an exploratory, large-scale, longitudinal study of 50 years of\ncommits to publicly available version control system repositories, in order to\ncharacterize the geographic diversity of contributors to public code and its\nevolution over time. We analyze in total 2.2 billion commits collected by\nSoftware Heritage from 160 million projects and authored by 43 million authors\nduring the 1971-2021 time period. We geolocate developers to 12 world regions\nderived from the United Nation geoscheme, using as signals email top-level\ndomains, author names compared with names distributions around the world, and\nUTC offsets mined from commit metadata.We find evidence of the early dominance\nof North America in open source software, later joined by Europe. After that\nperiod, the geographic diversity in public code has been constantly increasing.\nWe also identify relevant historical shifts related to the UNIX wars, the\nincrease of coding literacy in Central and South Asia, and broader phenomena\nlike colonialism and people movement across countries (immigration/emigration).",
    "descriptor": "\nComments: The 2022 Mining Software Repositories Conference, May 2022, Pittsburgh, Pennsylvania, United States\n",
    "authors": [
      "Davide Rossi",
      "Stefano Zacchiroli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.15369"
  },
  {
    "id": "arXiv:2203.15370",
    "title": "A Principle-based Ethical Assurance Argument for AI and Autonomous  Systems",
    "abstract": "An assurance case presents a clear and defensible argument, supported by\nevidence, that a system will operate as intended in a particular context.\nAssurance cases often inform third party certification of a system. One\nemerging proposal within the trustworthy AI and Autonomous Systems (AS)\nresearch community is to extend and apply the assurance case methodology to\nachieve justified confidence that a system will be ethically acceptable when\nused in a particular context. In this paper, we develop and further advance\nthis proposal, in order to bring the idea of ethical assurance cases to life.\nFirst, we discuss the assurance case methodology and the Goal Structuring\nNotation (GSN), which is a graphical notation that is widely used to record and\npresent assurance cases. Second, we describe four core ethical principles to\nguide the design and deployment of AI/AS: justice; beneficence;\nnon-maleficence; and respect for personal autonomy. Third, we bring these two\ncomponents together and structure an ethical assurance argument pattern - a\nreusable template for ethical assurance cases - on the basis of the four\nethical principles. We call this a Principle-based Ethical Assurance Argument\npattern. Throughout, we connect stages of the argument to examples of AI/AS\napplications and contexts. This helps to show the initial plausibility of the\nproposed methodology.",
    "descriptor": "",
    "authors": [
      "Zoe Porter",
      "Ibrahim Habli",
      "John McDermid"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15370"
  },
  {
    "id": "arXiv:2203.15371",
    "title": "mc-BEiT: Multi-choice Discretization for Image BERT Pre-training",
    "abstract": "Image BERT pre-training with masked image modeling (MIM) becomes a popular\npractice to cope with self-supervised representation learning. A seminal work,\nBEiT, casts MIM as a classification task with a visual vocabulary, tokenizing\nthe continuous visual signals into discrete vision tokens using a pre-learned\ndVAE. Despite a feasible solution, the improper discretization hinders further\nimprovements of image pre-training. Since image discretization has no\nground-truth answers, we believe that the masked patch should not be assigned\nwith a unique token id even if a better tokenizer can be obtained. In this\nwork, we introduce an improved BERT-style image pre-training method, namely\nmc-BEiT, which performs MIM proxy tasks towards eased and refined multi-choice\ntraining objectives. Specifically, the multi-choice supervision for the masked\nimage patches is formed by the soft probability vectors of the discrete token\nids, which are predicted by the off-the-shelf image tokenizer and further\nrefined by high-level inter-patch perceptions resorting to the observation that\nsimilar patches should share their choices. Extensive experiments on\nclassification, segmentation, and detection tasks demonstrate the superiority\nof our method, e.g., the pre-trained ViT-B achieves 84.1% top-1 fine-tuning\naccuracy on ImageNet-1K classification, 51.2% mIOU on ADE20K semantic\nsegmentation, 51.2% AP^b and 44.3% AP^m of object detection and instance\nsegmentation on COCO, outperforming the competitive counterparts.",
    "descriptor": "",
    "authors": [
      "Xiaotong Li",
      "Yixiao Ge",
      "Kun Yi",
      "Zixuan Hu",
      "Ying Shan",
      "Ling-Yu Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15371"
  },
  {
    "id": "arXiv:2203.15375",
    "title": "A Style-aware Discriminator for Controllable Image Translation",
    "abstract": "Current image-to-image translations do not control the output domain beyond\nthe classes used during training, nor do they interpolate between different\ndomains well, leading to implausible results. This limitation largely arises\nbecause labels do not consider the semantic distance. To mitigate such\nproblems, we propose a style-aware discriminator that acts as a critic as well\nas a style encoder to provide conditions. The style-aware discriminator learns\na controllable style space using prototype-based self-supervised learning and\nsimultaneously guides the generator. Experiments on multiple datasets verify\nthat the proposed model outperforms current state-of-the-art image-to-image\ntranslation methods. In contrast with current methods, the proposed approach\nsupports various applications, including style interpolation, content\ntransplantation, and local image translation.",
    "descriptor": "\nComments: 2022 CVPR\n",
    "authors": [
      "Kunhee Kim",
      "Sanghun Park",
      "Eunyeong Jeon",
      "Taehun Kim",
      "Daijin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15375"
  },
  {
    "id": "arXiv:2203.15377",
    "title": "Spoofing-Aware Speaker Verification by Multi-Level Fusion",
    "abstract": "Recently, many novel techniques have been introduced to deal with spoofing\nattacks, and achieve promising countermeasure (CM) performances. However, these\nworks only take the stand-alone CM models into account. Nowadays, a spoofing\naware speaker verification (SASV) challenge which aims to facilitate the\nresearch of integrated CM and ASV models, arguing that jointly optimizing CM\nand ASV models will lead to better performance, is taking place. In this paper,\nwe propose a novel multi-model and multi-level fusion strategy to tackle the\nSASV task. Compared with purely scoring fusion and embedding fusion methods,\nthis framework first utilizes embeddings from CM models, propagating CM\nembeddings into a CM block to obtain a CM score. In the second-level fusion,\nthe CM score and ASV scores directly from ASV systems will be concatenated into\na prediction block for the final decision. As a result, the best single fusion\nsystem has achieved the SASV-EER of 0.97% on the evaluation set. Then by\nensembling the top-5 fusion systems, the final SASV-EER reached 0.89%.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Haibin Wu",
      "Lingwei Meng",
      "Jiawen Kang",
      "Jinchao Li",
      "Xu Li",
      "Xixin Wu",
      "Hung-yi Lee",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15377"
  },
  {
    "id": "arXiv:2203.15379",
    "title": "VoiceMe: Personalized voice generation in TTS",
    "abstract": "Novel text-to-speech systems can generate entirely new voices that were not\nseen during training. However, it remains a difficult task to efficiently\ncreate personalized voices from a high dimensional speaker space. In this work,\nwe use speaker embeddings from a state-of-the-art speaker verification model\n(SpeakerNet) trained on thousands of speakers to condition a TTS model. We\nemploy a human sampling paradigm to explore this speaker latent space. We show\nthat users can create voices that fit well to photos of faces, art portraits,\nand cartoons. We recruit online participants to collectively manipulate the\nvoice of a speaking face. We show that (1) a separate group of human raters\nconfirms that the created voices match the faces, (2) speaker gender apparent\nfrom the face is well-recovered in the voice, and (3) people are consistently\nmoving towards the real voice prototype for the given face. Our results\ndemonstrate that this technology can be applied in a wide number of\napplications including character voice development in audiobooks and games,\npersonalized speech assistants, and individual voices for people with speech\nimpairment.",
    "descriptor": "\nComments: Submitted to Interspeech'22\n",
    "authors": [
      "Pol van Rijn",
      "Silvan Mertes",
      "Dominik Schiller",
      "Piotr Dura",
      "Hubert Siuzdak",
      "Peter M. C. Harrison",
      "Elisabeth Andr\u00e9",
      "Nori Jacoby"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15379"
  },
  {
    "id": "arXiv:2203.15380",
    "title": "SepViT: Separable Vision Transformer",
    "abstract": "Vision Transformers have witnessed prevailing success in a series of vision\ntasks. However, they often require enormous amount of computations to achieve\nhigh performance, which is burdensome to deploy on resource-constrained\ndevices. To address these issues, we draw lessons from depthwise separable\nconvolution and imitate its ideology to design the Separable Vision\nTransformer, abbreviated as SepViT. SepViT helps to carry out the information\ninteraction within and among the windows via a depthwise separable\nself-attention. The novel window token embedding and grouped self-attention are\nemployed to model the attention relationship among windows with negligible\ncomputational cost and capture a long-range visual dependencies of multiple\nwindows, respectively. Extensive experiments on various benchmark tasks\ndemonstrate SepViT can achieve state-of-the-art results in terms of trade-off\nbetween accuracy and latency. Among them, SepViT achieves 84.0% top-1 accuracy\non ImageNet-1K classification while decreasing the latency by 40%, compared to\nthe ones with similar accuracy (e.g., CSWin, PVTV2). As for the downstream\nvision tasks, SepViT with fewer FLOPs can achieve 50.4% mIoU on ADE20K semantic\nsegmentation task, 47.5 AP on the RetinaNet-based COCO detection task, 48.7 box\nAP and 43.9 mask AP on Mask R-CNN-based COCO detection and segmentation tasks.",
    "descriptor": "\nComments: The code will be released\n",
    "authors": [
      "Wei Li",
      "Xing Wang",
      "Xin Xia",
      "Jie Wu",
      "Xuefeng Xiao",
      "Min Zheng",
      "Shiping Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15380"
  },
  {
    "id": "arXiv:2203.15381",
    "title": "Alignment-Uniformity aware Representation Learning for Zero-shot Video  Classification",
    "abstract": "Most methods tackle zero-shot video classification by aligning\nvisual-semantic representations within seen classes, which limits\ngeneralization to unseen classes. To enhance model generalizability, this paper\npresents an end-to-end framework that preserves alignment and uniformity\nproperties for representations on both seen and unseen classes. Specifically,\nwe formulate a supervised contrastive loss to simultaneously align\nvisual-semantic features (i.e., alignment) and encourage the learned features\nto distribute uniformly (i.e., uniformity). Unlike existing methods that only\nconsider the alignment, we propose uniformity to preserve maximal-info of\nexisting features, which improves the probability that unobserved features fall\naround observed data. Further, we synthesize features of unseen classes by\nproposing a class generator that interpolates and extrapolates the features of\nseen classes. Besides, we introduce two metrics, closeness and dispersion, to\nquantify the two properties and serve as new measurements of model\ngeneralizability. Experiments show that our method significantly outperforms\nSoTA by relative improvements of 28.1% on UCF101 and 27.0% on HMDB51. Code is\navailable.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Shi Pu",
      "Kaili Zhao",
      "Mao Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15381"
  },
  {
    "id": "arXiv:2203.15386",
    "title": "Pareto Set Learning for Neural Multi-objective Combinatorial  Optimization",
    "abstract": "Multiobjective combinatorial optimization (MOCO) problems can be found in\nmany real-world applications. However, exactly solving these problems would be\nvery challenging, particularly when they are NP-hard. Many handcrafted\nheuristic methods have been proposed to tackle different MOCO problems over the\npast decades. In this work, we generalize the idea of neural combinatorial\noptimization, and develop a learning-based approach to approximate the whole\nPareto set for a given MOCO problem without further search procedure. We\npropose a single preference-conditioned model to directly generate approximate\nPareto solutions for any trade-off preference, and design an efficient\nmultiobjective reinforcement learning algorithm to train this model. Our\nproposed method can be treated as a learning-based extension for the\nwidely-used decomposition-based multiobjective evolutionary algorithm (MOEA/D).\nIt uses a single model to accommodate all the possible preferences, whereas\nother methods use a finite number of solution to approximate the Pareto set.\nExperimental results show that our proposed method significantly outperforms\nsome other methods on the multiobjective traveling salesman problem,\nmultiobjective vehicle routing problem and multiobjective knapsack problem in\nterms of solution quality, speed, and model efficiency.",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Xi Lin",
      "Zhiyuan Yang",
      "Qingfu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.15386"
  },
  {
    "id": "arXiv:2203.15387",
    "title": "Commande hybride d' un drone convertible pour des d\u00e9placements sous  optimaux",
    "abstract": "Whether for their maneuverability, autonomy or ergonomics, convertible UAVs,\nmeaning those with the ability to take off or land vertically and fly like an\nairplane, present many interests. However, their dynamics are complicated by\nvarious phenomena such as non-linearities, aerodynamic couplings or the large\nnumber of degrees of freedom, and it is necessary to use new control tools.\nThus, hybrid control becomes crucial, useful when making binary choices. Since\nthe drone is able to move in two ways, in pseudo-stationary flight and in\nhorizontal flight, the question of the relevance of a command with respect to\nthe other, according to the operational context, arises. This problem is\nanswered by the design of two nonlinear control laws, based on Lyapunov\nfunctions, which allow to validate the requirements. Therefore, depending on\nthe configuration, the hybrid mechanism will have to select the appropriate\nflight mode. Finally, with the objective of a flight in real conditions, an\nimplementation has been initiated.",
    "descriptor": "\nComments: Rapport de stage pr\\'esent\\'e pour l'obtention d'un dipl\\^ome d'ing\\'enieur a\\'eronautique \\`a l'\\'Ecole Nationale de l'Aviation Civile, in French language\n",
    "authors": [
      "Florian Sansou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15387"
  },
  {
    "id": "arXiv:2203.15390",
    "title": "ReIL: A Framework for Reinforced Intervention-based Imitation Learning",
    "abstract": "Compared to traditional imitation learning methods such as DAgger and DART,\nintervention-based imitation offers a more convenient and sample efficient data\ncollection process to users. In this paper, we introduce Reinforced\nIntervention-based Learning (ReIL), a framework consisting of a general\nintervention-based learning algorithm and a multi-task imitation learning model\naimed at enabling non-expert users to train agents in real environments with\nlittle supervision or fine tuning. ReIL achieves this with an algorithm that\ncombines the advantages of imitation learning and reinforcement learning and a\nmodel capable of concurrently processing demonstrations, past experience, and\ncurrent observations. Experimental results from real world mobile robot\nnavigation challenges indicate that ReIL learns rapidly from sparse supervisor\ncorrections without suffering deterioration in performance that is\ncharacteristic of supervised learning-based methods such as HG-Dagger and IWR.\nThe results also demonstrate that in contrast to other intervention-based\nmethods such as IARL and EGPO, ReIL can utilize an arbitrary reward function\nfor training without any additional heuristics.",
    "descriptor": "",
    "authors": [
      "Rom Parnichkun",
      "Matthew N. Dailey",
      "Atsushi Yamashita"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15390"
  },
  {
    "id": "arXiv:2203.15392",
    "title": "Efficient Hybrid Network: Inducting Scattering Features",
    "abstract": "Recent work showed that hybrid networks, which combine predefined and learnt\nfilters within a single architecture, are more amenable to theoretical analysis\nand less prone to overfitting in data-limited scenarios. However, their\nperformance has yet to prove competitive against the conventional counterparts\nwhen sufficient amounts of training data are available. In an attempt to\naddress this core limitation of current hybrid networks, we introduce an\nEfficient Hybrid Network (E-HybridNet). We show that it is the first scattering\nbased approach that consistently outperforms its conventional counterparts on a\ndiverse range of datasets. It is achieved with a novel inductive architecture\nthat embeds scattering features into the network flow using Hybrid Fusion\nBlocks. We also demonstrate that the proposed design inherits the key property\nof prior hybrid networks -- an effective generalisation in data-limited\nscenarios. Our approach successfully combines the best of the two worlds:\nflexibility and power of learnt features and stability and predictability of\nscattering representations.",
    "descriptor": "\nComments: Accepted to ICPR-2022\n",
    "authors": [
      "Dmitry Minskiy",
      "Miroslaw Bober"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15392"
  },
  {
    "id": "arXiv:2203.15395",
    "title": "Quantifying Societal Bias Amplification in Image Captioning",
    "abstract": "We study societal bias amplification in image captioning. Image captioning\nmodels have been shown to perpetuate gender and racial biases, however, metrics\nto measure, quantify, and evaluate the societal bias in captions are not yet\nstandardized. We provide a comprehensive study on the strengths and limitations\nof each metric, and propose LIC, a metric to study captioning bias\namplification. We argue that, for image captioning, it is not enough to focus\non the correct prediction of the protected attribute, and the whole context\nshould be taken into account. We conduct extensive evaluation on traditional\nand state-of-the-art image captioning models, and surprisingly find that, by\nonly focusing on the protected attribute prediction, bias mitigation models are\nunexpectedly amplifying bias.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Yusuke Hirota",
      "Yuta Nakashima",
      "Noa Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.15395"
  },
  {
    "id": "arXiv:2203.15396",
    "title": "Towards Maintainable Platform Software -- Delivery Cost Control in  Continuous Software Development",
    "abstract": "Modern platform software delivery cost increases rapidly as it usually needs\nto align with many hardware and silicon's TTMs, feature evolvement and involves\nhundreds of engineers. In this paper, citing one ultra-large-scale software -\nIntel Media Driver as an example, we analyze the hotspots leading to delivery\ncost increase in continuous software development, the challenges on our\nsoftware design and our experiences on software delivery cost shrink against\nthe targeted design enhancements. We expect the identified hotspots can help\nmore researchers to form the corresponding research agendas and the experiences\nshared can help following practitioners to apply similar enhancements.",
    "descriptor": "\nComments: 7 pages, 5 figures, 11th International Conference on Software Engineering and Applications (SEA 2022)\n",
    "authors": [
      "Ning Luo",
      "Yue Xiong"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.15396"
  },
  {
    "id": "arXiv:2203.15398",
    "title": "Learning to act: a Reinforcement Learning approach to recommend the best  next activities",
    "abstract": "The rise of process data availability has led in the last decade to the\ndevelopment of several data-driven learning approaches. However, most of these\napproaches limit themselves to use the learned model to predict the future of\nongoing process executions. The goal of this paper is moving a step forward and\nleveraging data with the purpose of learning to act by supporting users with\nrecommendations for the best strategy to follow, in order to optimize a measure\nof performance. In this paper, we take the (optimization) perspective of one\nprocess actor and we recommend the best activities to execute next, in response\nto what happens in a complex external environment, where there is no control on\nexogenous factors. To this aim, we investigate an approach that learns, by\nmeans of Reinforcement Learning, an optimal policy from the observation of past\nexecutions and recommends the best activities to carry on for optimizing a Key\nPerformance Indicator of interest. The potentiality of the approach has been\ndemonstrated on two scenarios taken from real-life data.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Stefano Branchi",
      "Chiara Di Francescomarino",
      "Chiara Ghidini",
      "David Massimo",
      "Francesco Ricci",
      "Massimiliano Ronzani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15398"
  },
  {
    "id": "arXiv:2203.15399",
    "title": "Time Reversal for Multiple Access and Mobility: Algorithmic Design and  Experimental Results",
    "abstract": "Time Reversal (TR) has been proposed as a competitive precoding strategy for\nlow-complexity wireless devices relying on Ultra-WideBand (UWB) signal\nwaveforms. However, when TR is applied for multiple access, the signals\nreceived by the multiple users suffer from significant levels of inter-symbol\nand inter-user interference, which requires additional processing for\nmitigation by each receiving user. In this paper, we present an iterative\nTime-Reversal Division Multiple Access (TRDMA) approach that aims to dim the\nlatter interference levels. The performance of iterative TRDMA is evaluated\nexperimentally in a reverberation chamber that mimics a rich scattering indoor\nwireless propagation environment. The improved efficiency, in terms of the\nnumber of algorithmic iterations, of the proposed approach compared to\nconventional TRDMA, is demonstrated. We also consider a mobile user\nconfiguration, where the position of the receiver changes between the channel\nestimation and data transmission steps. It is showcased, even for this\nexperimental setup, that the proposed iterative TRDMA approach is more\nefficient than conventional precoding schemes.",
    "descriptor": "\nComments: 6 pages, 6 figures, to be presented at IEEE Wireless Communications and Networking Conference 2022\n",
    "authors": [
      "A. Mokh",
      "J. de Rosny",
      "G. C. Alexandropoulos",
      "R. Khayatzadeh",
      "M. Kamoun",
      "A. Ourir",
      "A. Tourin",
      "M. Fink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.15399"
  },
  {
    "id": "arXiv:2203.15400",
    "title": "(Nearly) All Cardinality Estimators Are Differentially Private",
    "abstract": "We consider privacy in the context of streaming algorithms for cardinality\nestimation. We show that a large class of algorithms all satisfy\n$\\epsilon$-differential privacy, so long as (a) the algorithm is combined with\na simple down-sampling procedure, and (b) the cardinality of the input stream\nis $\\Omega(k/\\epsilon)$. Here, $k$ is a certain parameter of the sketch that is\nalways at most the sketch size in bits, but is typically much smaller. We also\nshow that, even with no modification, algorithms in our class satisfy\n$(\\epsilon, \\delta)$-differential privacy, where $\\delta$ falls exponentially\nwith the stream cardinality.\nOur analysis applies to essentially all popular cardinality estimation\nalgorithms, and substantially generalizes and tightens privacy bounds from\nearlier works.",
    "descriptor": "",
    "authors": [
      "Charlie Dickens",
      "Justin Thaler",
      "Daniel Ting"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.15400"
  },
  {
    "id": "arXiv:2203.15401",
    "title": "Neural Face Video Compression using Multiple Views",
    "abstract": "Recent advances in deep generative models led to the development of neural\nface video compression codecs that use an order of magnitude less bandwidth\nthan engineered codecs. These neural codecs reconstruct the current frame by\nwarping a source frame and using a generative model to compensate for\nimperfections in the warped source frame. Thereby, the warp is encoded and\ntransmitted using a small number of keypoints rather than a dense flow field,\nwhich leads to massive savings compared to traditional codecs. However, by\nrelying on a single source frame only, these methods lead to inaccurate\nreconstructions (e.g. one side of the head becomes unoccluded when turning the\nhead and has to be synthesized). Here, we aim to tackle this issue by relying\non multiple source frames (views of the face) and present encouraging results.",
    "descriptor": "",
    "authors": [
      "Anna Volokitin",
      "Stefan Brugger",
      "Ali Benlalah",
      "Sebastian Martin",
      "Brian Amberg",
      "Michael Tschannen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15401"
  },
  {
    "id": "arXiv:2203.15404",
    "title": "Short-Term Word-Learning in a Dynamically Changing Environment",
    "abstract": "Neural sequence-to-sequence automatic speech recognition (ASR) systems are in\nprinciple open vocabulary systems, when using appropriate modeling units. In\npractice, however, they often fail to recognize words not seen during training,\ne.g., named entities, numbers or technical terms. To alleviate this problem,\nHuber et al. proposed to supplement an end-to-end ASR system with a word/phrase\nmemory and a mechanism to access this memory to recognize the words and phrases\ncorrectly. In this paper we study, a) methods to acquire important words for\nthis memory dynamically and, b) the trade-off between improvement in\nrecognition accuracy of new words and the potential danger of false alarms for\nthose added words. We demonstrate significant improvements in the detection\nrate of new words with only a minor increase in false alarms (F1 score 0.30\n$\\rightarrow$ 0.80), when using an appropriate number of new words. In\naddition, we show that important keywords can be extracted from supporting\ndocuments and used effectively.",
    "descriptor": "\nComments: This paper was submitted to Interspeech 2022\n",
    "authors": [
      "Christian Huber",
      "Rishu Kumar",
      "Ond\u0159ej Bojar",
      "Alexander Waibel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.15404"
  },
  {
    "id": "arXiv:2203.15406",
    "title": "TransGAN: a Transductive Adversarial Model for Novelty Detection",
    "abstract": "Novelty detection, a widely studied problem in machine learning, is the\nproblem of detecting a novel class of data that has not been previously\nobserved. A common setting for novelty detection is inductive whereby only\nexamples of the negative class are available during training time. Transductive\nnovelty detection on the other hand has only witnessed a recent surge in\ninterest, it not only makes use of the negative class during training but also\nincorporates the (unlabeled) test set to detect novel examples. Several studies\nhave emerged under the transductive setting umbrella that have demonstrated its\nadvantage over its inductive counterpart. Depending on the assumptions about\nthe data, these methods go by different names (e.g. transductive novelty\ndetection, semi-supervised novelty detection, positive-unlabeled learning,\nout-of-distribution detection). With the use of generative adversarial networks\n(GAN), a segment of those studies have adopted a transductive setup in order to\nlearn how to generate examples of the novel class. In this study, we propose\nTransGAN, a transductive generative adversarial network that attempts to learn\nhow to generate image examples from both the novel and negative classes by\nusing a mixture of two Gaussians in the latent space. It achieves that by\nincorporating an adversarial autoencoder with a GAN network, the ability to\ngenerate examples of novel data points offers not only a visual representation\nof novelties, but also overcomes the hurdle faced by many inductive methods of\nhow to tune the model hyperparameters at the decision rule level. Our model has\nshown superior performance over state-of-the-art inductive and transductive\nmethods. Our study is fully reproducible with the code available publicly.",
    "descriptor": "",
    "authors": [
      "Najiba Toron",
      "Janaina Mourao-Miranda",
      "John Shawe-Taylor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15406"
  },
  {
    "id": "arXiv:2203.15407",
    "title": "Equivalences among Z_{p^s}-linear Generalized Hadamard Codes",
    "abstract": "The $\\Z_{p^s}$-additive codes of length $n$ are subgroups of $\\Z_{p^s}^n$,\nand can be seen as a generalization of linear codes over $\\Z_2$, $\\Z_4$, or\n$\\Z_{2^s}$ in general. A $\\Z_{p^s}$-linear generalized Hadamard (GH) code is a\nGH code over $\\Z_p$ which is the image of a $\\Z_{p^s}$-additive code by a\ngeneralized Gray map. A partial classification of these codes by using the\ndimension of the kernel is known. In this paper, we establish that some\n$\\Z_{p^s}$-linear GH codes of length $p^t$ are equivalent, once $t$ is fixed.\nThis allows us to improve the known upper bounds for the number of such\nnonequivalent codes. Moreover, up to $t=10$, this new upper bound coincides\nwith a known lower bound (based on the rank and dimension of the kernel).",
    "descriptor": "",
    "authors": [
      "Dipak K. Bhunia",
      "Cristina Fern\u00e1ndez-C\u00f3rdoba",
      "Carlos Vela",
      "Merc\u00e8 Villanueva"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.15407"
  },
  {
    "id": "arXiv:2203.15408",
    "title": "AutoCoMet: Smart Neural Architecture Search via Co-Regulated Shaping  Reinforcement",
    "abstract": "Designing suitable deep model architectures, for AI-driven on-device apps and\nfeatures, at par with rapidly evolving mobile hardware and increasingly complex\ntarget scenarios is a difficult task. Though Neural Architecture Search\n(NAS/AutoML) has made this easier by shifting paradigm from extensive manual\neffort to automated architecture learning from data, yet it has major\nlimitations, leading to critical bottlenecks in the context of mobile devices,\nincluding model-hardware fidelity, prohibitive search times and deviation from\nprimary target objective(s). Thus, we propose AutoCoMet that can learn the most\nsuitable DNN architecture optimized for varied types of device hardware and\ntask contexts, ~ 3x faster. Our novel co-regulated shaping reinforcement\ncontroller together with the high fidelity hardware meta-behavior predictor\nproduces a smart, fast NAS framework that adapts to context via a generalized\nformalism for any kind of multi-criteria optimization.",
    "descriptor": "\nComments: ICPR 2022\n",
    "authors": [
      "Mayukh Das",
      "Brijraj Singh",
      "Harsh Kanti Chheda",
      "Pawan Sharma",
      "Pradeep NS"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15408"
  },
  {
    "id": "arXiv:2203.15414",
    "title": "Quality Assurance of Generative Dialog Models in an Evolving  Conversational Agent Used for Swedish Language Practice",
    "abstract": "Due to the migration megatrend, efficient and effective second-language\nacquisition is vital. One proposed solution involves AI-enabled conversational\nagents for person-centered interactive language practice. We present results\nfrom ongoing action research targeting quality assurance of proprietary\ngenerative dialog models trained for virtual job interviews. The action team\nelicited a set of 38 requirements for which we designed corresponding automated\ntest cases for 15 of particular interest to the evolving solution. Our results\nshow that six of the test case designs can detect meaningful differences\nbetween candidate models. While quality assurance of natural language\nprocessing applications is complex, we provide initial steps toward an\nautomated framework for machine learning model selection in the context of an\nevolving conversational agent. Future work will focus on model selection in an\nMLOps setting.",
    "descriptor": "\nComments: Accepted for publication in the Proc. of the 1st International Conference on AI Engineering, 2022\n",
    "authors": [
      "Markus Borg",
      "Johan Bengtsson",
      "Harald \u00d6sterling",
      "Alexander Hagelborn",
      "Isabella Gagner",
      "Piotr Tomaszewski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.15414"
  },
  {
    "id": "arXiv:2203.15418",
    "title": "Comparative Evaluations of Visualization Onboarding Methods",
    "abstract": "Comprehending and exploring large and complex data is becoming increasingly\nimportant for users in a wide range of application domains. Still, non-experts\nin visual data analysis often have problems with correctly reading and\ninterpreting information from visualizations that are new to them. To support\nnovices in learning how to use new digital technologies, the concept of\nonboarding has been successfully applied in other fields and first approaches\nalso exist in the visualization domain. However, empirical evidence on the\neffectiveness of such approaches is scarce. Therefore, we conducted 3 studies:\n1) Firstly, we explored the effect of vis onboarding, using an interactive\nstep-by-step guide, on user performance for four increasingly complex\nvisualization techniques. We performed a between-subject experiment with 596\nparticipants in total. The results showed that there are no significant\ndifferences between the answer correctness of the questions with and without\nonboarding. Furthermore, participants commented that for highly familiar\nvisualization types no onboarding is needed. 2) Second, we performed another\nstudy with MTurk workers to assess if there is a difference in user\nperformances on different onboarding types: step-by-step, scrollytelling\ntutorial, and video tutorial. The study revealed that the video tutorial was\nranked as the most positive on average, based on sentiment analysis, followed\nby the scrollytelling tutorial and the interactive step-by-step guide. 3) For\nour third study with students, we gathered data on users' experience in using\nan in-situ scrollytelling for the VA tool. The results showed that they\npreferred scrollytelling over the tutorial integrated into the landing page. In\nsummary, the in-situ scrollytelling approach works well for visualization\nonboarding and a video tutorial can help to introduce interaction techniques.",
    "descriptor": "",
    "authors": [
      "Christina Stoiber",
      "Conny Walchshofer",
      "Margit Pohl",
      "Benjamin Potzmann",
      "Florian Grassinger",
      "Holger Stitz",
      "Marc Streit",
      "Wolfgang Aigner"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.15418"
  },
  {
    "id": "arXiv:2203.15419",
    "title": "A Pressure Correction Projection Finite Element Method for The 2D/3D  Time-Dependent Thermomicropolar Fluid Problem",
    "abstract": "In this paper, the pressure correctionfinite element method is proposed for\nthe 2D/3D time-dependent thermomicropolarfluid equations. Thefirst-order and\nsecond-order backward difference formulas (BDF) are adopted to approximate the\ntime derivative term, stability analysis and error estimation of the\nfirst-order semi-discrete scheme are proved. Finally, some numerical examples\nare given to show the effectiveness and reliability of the proposed method,\nwhich can be used to simulate the problem with high Rayleigh number.",
    "descriptor": "",
    "authors": [
      "Yuhang Ren",
      "Demin Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15419"
  },
  {
    "id": "arXiv:2203.15423",
    "title": "Development of a Scale to Measure Technology Acceptance in Smart  Agriculture",
    "abstract": "This paper describes the development of a scale to measure technology\nacceptance in smart agriculture. The scale is intended for use in diverse\nsituations, ranging for the evaluation of existing technologies already in\nwidespread use, to the evaluation of prototype systems. A systematic screening\nof prior literature was conducted to identify initial scale items regarding how\ntechnology acceptance is currently understood and measured. These items were\niteratively reviewed and systematically categorised to develop the final scale\nproposed in this paper. In future work, this scale will be validated through\nuser studies. The purpose of this paper is to make the initial scale available\nto the research community with a view to initial use and further evaluation.",
    "descriptor": "",
    "authors": [
      "Rosemary J Thomas",
      "Rebecca Whetton",
      "Andy Doyle",
      "David Coyle"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.15423"
  },
  {
    "id": "arXiv:2203.15424",
    "title": "Semantic properties of English nominal pluralization: Insights from word  embeddings",
    "abstract": "Semantic differentiation of nominal pluralization is grammaticalized in many\nlanguages. For example, plural markers may only be relevant for human nouns.\nEnglish does not appear to make such distinctions. Using distributional\nsemantics, we show that English nominal pluralization exhibits semantic\nclusters. For instance, pluralization of fruit words is more similar to one\nanother and less similar to pluralization of other semantic classes. Therefore,\nreduction of the meaning shift in plural formation to the addition of an\nabstract plural meaning is too simplistic. A semantically informed method,\ncalled CosClassAvg, is introduced that outperforms pluralization methods in\ndistributional semantics which assume plural formation amounts to the addition\nof a fixed plural vector. In comparison with our approach, a method from\ncompositional distributional semantics, called FRACSS, predicted plural vectors\nthat were more similar to the corpus-extracted plural vectors in terms of\ndirection but not vector length. A modeling study reveals that the observed\ndifference between the two predicted semantic spaces by CosClassAvg and FRACSS\ncarries over to how well a computational model of the listener can understand\npreviously unencountered plural forms. Mappings from word forms, represented\nwith triphone vectors, to predicted semantic vectors are more productive when\nCosClassAvg-generated semantic vectors are employed as gold standard vectors\ninstead of FRACSS-generated vectors.",
    "descriptor": "\nComments: 45 pages (including references), 14 figures. This article is under review at `Morphology'\n",
    "authors": [
      "Elnaz Shafaei-Bajestan",
      "Masoumeh Moradipour-Tari",
      "Peter Uhrig",
      "R. Harald Baayen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.15424"
  },
  {
    "id": "arXiv:2203.15425",
    "title": "Process Mining Analysis of Puzzle-Based Cybersecurity Training",
    "abstract": "The hands-on cybersecurity training quality is crucial to mitigate cyber\nthreats and attacks effectively. However, practical cybersecurity training is\nstrongly process-oriented, making the post-training analysis very difficult.\nThis paper presents process-mining methods applied to the learning analytics\nworkflow. We introduce a unified approach to reconstruct behavioral graphs from\nsparse event logs of cyber ranges. Furthermore, we discuss significant data\nfeatures that affect their practical usability for educational process mining.\nBased on that, methods of dealing with the complexity of process graphs are\npresented, taking advantage of the puzzle-based gamification of in-class\ntraining sessions.",
    "descriptor": "",
    "authors": [
      "Martin Macak",
      "Radek Oslejsek",
      "Barbora Buhnova"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.15425"
  },
  {
    "id": "arXiv:2203.15426",
    "title": "On Reinforcement Learning, Effect Handlers, and the State Monad",
    "abstract": "We study the algebraic effects and handlers as a way to support\ndecision-making abstractions in functional programs, whereas a user can ask a\nlearning algorithm to resolve choices without implementing the underlying\nselection mechanism, and give a feedback by way of rewards. Differently from\nsome recently proposed approach to the problem based on the selection monad\n[Abadi and Plotkin, LICS 2021], we express the underlying intelligence as a\nreinforcement learning algorithm implemented as a set of handlers for some of\nthese algebraic operations, including those for choices and rewards. We show\nhow we can in practice use algebraic operations and handlers -- as available in\nthe programming language EFF -- to clearly separate the learning algorithm from\nits environment, thus allowing for a good level of modularity. We then show how\nthe host language can be taken as a lambda-calculus with handlers, this way\nshowing what the essential linguistic features are. We conclude by hinting at\nhow type and effect systems could ensure safety properties, at the same time\npointing at some directions for further work.",
    "descriptor": "",
    "authors": [
      "Ugo Dal Lago",
      "Francesco Gavazzo",
      "Alexis Ghyselen"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.15426"
  },
  {
    "id": "arXiv:2203.15427",
    "title": "Long-term Video Frame Interpolation via Feature Propagation",
    "abstract": "Video frame interpolation (VFI) works generally predict intermediate frame(s)\nby first estimating the motion between inputs and then warping the inputs to\nthe target time with the estimated motion. This approach, however, is not\noptimal when the temporal distance between the input sequence increases as\nexisting motion estimation modules cannot effectively handle large motions.\nHence, VFI works perform well for small frame gaps and perform poorly as the\nframe gap increases. In this work, we propose a novel framework to address this\nproblem. We argue that when there is a large gap between inputs, instead of\nestimating imprecise motion that will eventually lead to inaccurate\ninterpolation, we can safely propagate from one side of the input up to a\nreliable time frame using the other input as a reference. Then, the rest of the\nintermediate frames can be interpolated using standard approaches as the\ntemporal gap is now narrowed. To this end, we propose a propagation network\n(PNet) by extending the classic feature-level forecasting with a novel\nmotion-to-feature approach. To be thorough, we adopt a simple interpolation\nmodel along with PNet as our full model and design a simple procedure to train\nthe full model in an end-to-end manner. Experimental results on several\nbenchmark datasets confirm the effectiveness of our method for long-term VFI\ncompared to state-of-the-art approaches.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Dawit Mureja Argaw",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15427"
  },
  {
    "id": "arXiv:2203.15429",
    "title": "Heterogeneous Differential Privacy via Graphs",
    "abstract": "We generalize a previous framework for designing utility-optimal\ndifferentially private (DP) mechanisms via graphs, where datasets are vertices\nin the graph and edges represent dataset neighborhood. The boundary set\ncontains datasets where an individual's response changes the binary-valued\nquery compared to its neighbors. Previous work was limited to the homogeneous\ncase where the privacy parameter $\\varepsilon$ across all datasets was the same\nand the mechanism at boundary datasets was identical. In our work, the\nmechanism can take different distributions at the boundary and the privacy\nparameter $\\varepsilon$ is a function of neighboring datasets, which recovers\nan earlier definition of personalized DP as special case. The problem is how to\nextend the mechanism, which is only defined at the boundary set, to other\ndatasets in the graph in a computationally efficient and utility optimal\nmanner. Using the concept of strongest induced DP condition we solve this\nproblem efficiently in polynomial time (in the size of the graph).",
    "descriptor": "",
    "authors": [
      "Sahel Torkamani",
      "Javad B. Ebrahimi",
      "Parastoo Sadeghi",
      "Rafael G. L. D'Oliveira",
      "Muriel Medard"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.15429"
  },
  {
    "id": "arXiv:2203.15431",
    "title": "Investigating Self-supervised Pretraining Frameworks for Pathological  Speech Recognition",
    "abstract": "We investigate the performance of self-supervised pretraining frameworks on\npathological speech datasets used for automatic speech recognition (ASR).\nModern end-to-end models require thousands of hours of data to train well, but\nonly a small number of pathological speech datasets are publicly available. A\nproven solution to this problem is by first pretraining the model on a huge\nnumber of healthy speech datasets and then fine-tuning it on the pathological\nspeech datasets. One new pretraining framework called self-supervised learning\n(SSL) trains a network using only speech data, providing more flexibility in\ntraining data requirements and allowing more speech data to be used in\npretraining. We investigate SSL frameworks such as the wav2vec 2.0 and WavLM\nmodels using different setups and compare their performance with different\nsupervised pretraining setups, using two types of pathological speech, namely,\nJapanese electrolaryngeal and English dysarthric. Although the SSL setup is\npromising against Transformer-based supervised setups, other supervised setups\nsuch as the Conformer still outperform SSL pretraining. Our results show that\nthe best supervised setup outperforms the best SSL setup by 13.9\\% character\nerror rate in electrolaryngeal speech and 16.8\\% word error rate in dysarthric\nspeech.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Lester Phillip Violeta",
      "Wen-Chin Huang",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15431"
  },
  {
    "id": "arXiv:2203.15435",
    "title": "Impact of Network Densification on the Performance of a Non-Public URLLC  Factory Network",
    "abstract": "Densification of the network deployment, for example by adding new sectors or\nsites within an existing mobile communication network, has traditionally been\nan efficient way to improve the system coverage and capacity. That will be the\ncase even for the ultra-reliable low-latency communication (URLLC) services,\nbut the overall situation and the feasibility of the different deployment\noptions will depend on the characteristics of the URLLC service in question.\nURLLC services with relaxed latency requirements, allowing multiple\ntransmission attempts, can tolerate a decent level of inter-cell interference\nwhile still being able to guarantee the desired quality-of-service for all\nusers, which makes it possible to improve the URLLC service capacity by adding\nnew gNodeBs with omnidirectional or directional antennas. However, when the\nURLLC services require extremely low latency that do not allow for\nretransmissions, the system performance becomes quite sensitive to the\ninter-cell interference, which means that in practice the gNodeBs should be\nequipped with beamformed antennas to reach high levels of URLLC service\ncapacity. Finally, an active distributed antenna system could be an efficient\nway to secure good coverage throughout the desired service area.",
    "descriptor": "\nComments: 6 pages, 4 figures. Accepted for publication in: IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC) 2021\n",
    "authors": [
      "Kimmo Hiltunen",
      "Yanpeng Yang",
      "Fedor Chernogorov"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.15435"
  },
  {
    "id": "arXiv:2203.15437",
    "title": "Contextual Information Based Anomaly Detection for a Multi-Scene UAV  Aerial Videos",
    "abstract": "UAV based surveillance is gaining much interest worldwide due to its\nextensive applications in monitoring wildlife, urban planning, disaster\nmanagement, campus security, etc. These videos are analyzed for\nstrange/odd/anomalous patterns which are essential aspects of surveillance. But\nmanual analysis of these videos is tedious and laborious. Hence, the\ndevelopment of computer-aided systems for the analysis of UAV based\nsurveillance videos is crucial. Despite this interest, in literature, several\ncomputer aided systems are developed focusing only on CCTV based surveillance\nvideos. These methods are designed for single scene scenarios and lack\ncontextual knowledge which is required for multi-scene scenarios. Furthermore,\nthe lack of standard UAV based anomaly detection datasets limits the\ndevelopment of these systems. In this regard, the present work aims at the\ndevelopment of a Computer Aided Decision support system to analyse UAV based\nsurveillance videos. A new UAV based multi-scene anomaly detection dataset is\ndeveloped with frame-level annotations for the development of computer aided\nsystems. It holistically uses contextual, temporal and appearance features for\naccurate detection of anomalies. Furthermore, a new inference strategy is\nproposed that utilizes few anomalous samples along with normal samples to\nidentify better decision boundaries. The proposed method is extensively\nevaluated on the UAV based anomaly detection dataset and performed\ncompetitively with respect to state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Girisha S",
      "Ujjwal Verma",
      "Manohara Pai M M",
      "Radhika M Pai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15437"
  },
  {
    "id": "arXiv:2203.15439",
    "title": "Eventor: An Efficient Event-Based Monocular Multi-View Stereo  Accelerator on FPGA Platform",
    "abstract": "Event cameras are bio-inspired vision sensors that asynchronously represent\npixel-level brightness changes as event streams. Event-based monocular\nmulti-view stereo (EMVS) is a technique that exploits the event streams to\nestimate semi-dense 3D structure with known trajectory. It is a critical task\nfor event-based monocular SLAM. However, the required intensive computation\nworkloads make it challenging for real-time deployment on embedded platforms.\nIn this paper, Eventor is proposed as a fast and efficient EMVS accelerator by\nrealizing the most critical and time-consuming stages including event\nback-projection and volumetric ray-counting on FPGA. Highly paralleled and\nfully pipelined processing elements are specially designed via FPGA and\nintegrated with the embedded ARM as a heterogeneous system to improve the\nthroughput and reduce the memory footprint. Meanwhile, the EMVS algorithm is\nreformulated to a more hardware-friendly manner by rescheduling, approximate\ncomputing and hybrid data quantization. Evaluation results on DAVIS dataset\nshow that Eventor achieves up to $24\\times$ improvement in energy efficiency\ncompared with Intel i5 CPU platform.",
    "descriptor": "\nComments: 6 pages, accepted by DAC 2022\n",
    "authors": [
      "Mingjun Li",
      "Jianlei Yang",
      "Yingjie Qi",
      "Meng Dong",
      "Yuhao Yang",
      "Runze Liu",
      "Weitao Pan",
      "Bei Yu",
      "Weisheng Zhao"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15439"
  },
  {
    "id": "arXiv:2203.15441",
    "title": "UnShadowNet: Illumination Critic Guided Contrastive Learning For Shadow  Removal",
    "abstract": "Shadows are frequently encountered natural phenomena that significantly\nhinder the performance of computer vision perception systems in practical\nsettings, e.g., autonomous driving. A solution to this would be to eliminate\nshadow regions from the images before the processing of the perception system.\nYet, training such a solution requires pairs of aligned shadowed and\nnon-shadowed images which are difficult to obtain. We introduce a novel weakly\nsupervised shadow removal framework UnShadowNet trained using contrastive\nlearning. It comprises of a DeShadower network responsible for removal of the\nextracted shadow under the guidance of an Illumination network which is trained\nadversarially by the illumination critic and a Refinement network to further\nremove artifacts. We show that UnShadowNet can also be easily extended to a\nfully-supervised setup to exploit the ground-truth when available. UnShadowNet\noutperforms existing state-of-the-art approaches on three publicly available\nshadow datasets (ISTD, adjusted ISTD, SRD) in both the weakly and fully\nsupervised setups.",
    "descriptor": "",
    "authors": [
      "Subhrajyoti Dasgupta",
      "Arindam Das",
      "Sudip Das",
      "Andrei Bursuc",
      "Ujjwal Bhattacharya",
      "Senthil Yogamani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15441"
  },
  {
    "id": "arXiv:2203.15442",
    "title": "Shifting More Attention to Visual Backbone: Query-modulated Refinement  Networks for End-to-End Visual Grounding",
    "abstract": "Visual grounding focuses on establishing fine-grained alignment between\nvision and natural language, which has essential applications in multimodal\nreasoning systems. Existing methods use pre-trained query-agnostic visual\nbackbones to extract visual feature maps independently without considering the\nquery information. We argue that the visual features extracted from the visual\nbackbones and the features really needed for multimodal reasoning are\ninconsistent. One reason is that there are differences between pre-training\ntasks and visual grounding. Moreover, since the backbones are query-agnostic,\nit is difficult to completely avoid the inconsistency issue by training the\nvisual backbone end-to-end in the visual grounding framework. In this paper, we\npropose a Query-modulated Refinement Network (QRNet) to address the\ninconsistent issue by adjusting intermediate features in the visual backbone\nwith a novel Query-aware Dynamic Attention (QD-ATT) mechanism and query-aware\nmultiscale fusion. The QD-ATT can dynamically compute query-dependent visual\nattention at the spatial and channel levels of the feature maps produced by the\nvisual backbone. We apply the QRNet to an end-to-end visual grounding\nframework. Extensive experiments show that the proposed method outperforms\nstate-of-the-art methods on five widely used datasets.",
    "descriptor": "",
    "authors": [
      "Jiabo Ye",
      "Junfeng Tian",
      "Ming Yan",
      "Xiaoshan Yang",
      "Xuwu Wang",
      "Ji Zhang",
      "Liang He",
      "Xin Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.15442"
  },
  {
    "id": "arXiv:2203.15443",
    "title": "A Naturalistic Database of Thermal Emotional Facial Expressions and  Effects of Induced Emotions on Memory",
    "abstract": "This work defines a procedure for collecting naturally induced emotional\nfacial expressions through the vision of movie excerpts with high emotional\ncontents and reports experimental data ascertaining the effects of emotions on\nmemory word recognition tasks. The induced emotional states include the four\nbasic emotions of sadness, disgust, happiness, and surprise, as well as the\nneutral emotional state. The resulting database contains both thermal and\nvisible emotional facial expressions, portrayed by forty Italian subjects and\nsimultaneously acquired by appropriately synchronizing a thermal and a standard\nvisible camera. Each subject's recording session lasted 45 minutes, allowing\nfor each mode (thermal or visible) to collect a minimum of 2000 facial\nexpressions from which a minimum of 400 were selected as highly expressive of\neach emotion category. The database is available to the scientific community\nand can be obtained contacting one of the authors. For this pilot study, it was\nfound that emotions and/or emotion categories do not affect individual\nperformance on memory word recognition tasks and temperature changes in the\nface or in some regions of it do not discriminate among emotional states.",
    "descriptor": "\nComments: 15 pages published in Esposito, A., Esposito, A.M., Vinciarelli, A., Hoffmann, R., M\\\"uller, V.C. (eds) Cognitive Behavioural Systems. Lecture Notes in Computer Science, vol 7403. Springer, Berlin, Heidelberg\n",
    "authors": [
      "Anna Esposito",
      "Vincenzo Capuano",
      "Jiri Mekyska",
      "Marcos Faundez-Zanuy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15443"
  },
  {
    "id": "arXiv:2203.15448",
    "title": "ZK-SecreC: a Domain-Specific Language for Zero Knowledge Proofs",
    "abstract": "We present ZK-SecreC, a domain-specific language for zero-knowledge proofs.\nWe present the rationale for its design, its syntax and semantics, and\ndemonstrate its usefulness on the basis of a number of non-trivial examples.\nThe design features a type system, where each piece of data is assigned both a\nconfidentiality and an integrity type, which are not orthogonal to each other.\nWe perform an empiric evaluation of the statements produced by its compiler in\nterms of their size. We also show the integration of the compiler with the\nimplementation of a zero-knowledge proof technique, and evaluate the running\ntime of both Prover and Verifier.",
    "descriptor": "\nComments: 45 pp\n",
    "authors": [
      "Dan Bogdanov",
      "Joosep J\u00e4\u00e4ger",
      "Peeter Laud",
      "H\u00e4rmel Nestra",
      "Martin Pettai",
      "Jaak Randmets",
      "Ville Sokk",
      "Kert Tali",
      "Sandhra-Mirella Valdma"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.15448"
  },
  {
    "id": "arXiv:2203.15455",
    "title": "WeNet 2.0: More Productive End-to-End Speech Recognition Toolkit",
    "abstract": "Recently, we made available WeNet, a production-oriented end-to-end speech\nrecognition toolkit, which introduces a unified two-pass (U2) framework and a\nbuilt-in runtime to address the streaming and non-streaming decoding modes in a\nsingle model. To further improve ASR performance and facilitate various\nproduction requirements, in this paper, we present WeNet 2.0 with four\nimportant updates. (1) We propose U2++, a unified two-pass framework with\nbidirectional attention decoders, which includes the future contextual\ninformation by a right-to-left attention decoder to improve the representative\nability of the shared encoder and the performance during the rescoring stage.\n(2) We introduce an n-gram based language model and a WFST-based decoder into\nWeNet 2.0, promoting the use of rich text data in production scenarios. (3) We\ndesign a unified contextual biasing framework, which leverages user-specific\ncontext (e.g., contact lists) to provide rapid adaptation ability for\nproduction and improves ASR accuracy in both with-LM and without-LM scenarios.\n(4) We design a unified IO to support large-scale data for effective model\ntraining. In summary, the brand-new WeNet 2.0 achieves up to 10\\% relative\nrecognition performance improvement over the original WeNet on various corpora\nand makes available several important production-oriented features.",
    "descriptor": "",
    "authors": [
      "Binbin Zhang",
      "Di Wu",
      "Zhendong Peng",
      "Xingchen Song",
      "Zhuoyuan Yao",
      "Hang Lv",
      "Lei Xie",
      "Chao Yang",
      "Fuping Pan",
      "Jianwei Niu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15455"
  },
  {
    "id": "arXiv:2203.15458",
    "title": "Efficient Virtual View Selection for 3D Hand Pose Estimation",
    "abstract": "3D hand pose estimation from single depth is a fundamental problem in\ncomputer vision, and has wide applications.However, the existing methods still\ncan not achieve satisfactory hand pose estimation results due to view variation\nand occlusion of human hand. In this paper, we propose a new virtual view\nselection and fusion module for 3D hand pose estimation from single depth.We\npropose to automatically select multiple virtual viewpoints for pose estimation\nand fuse the results of all and find this empirically delivers accurate and\nrobust pose estimation. In order to select most effective virtual views for\npose fusion, we evaluate the virtual views based on the confidence of virtual\nviews using a light-weight network via network distillation. Experiments on\nthree main benchmark datasets including NYU, ICVL and Hands2019 demonstrate\nthat our method outperforms the state-of-the-arts on NYU and ICVL, and achieves\nvery competitive performance on Hands2019-Task1, and our proposed virtual view\nselection and fusion module is both effective for 3D hand pose estimation.",
    "descriptor": "\nComments: Accepted by AAAI2022\n",
    "authors": [
      "Jian Cheng",
      "Yanguang Wan",
      "Dexin Zuo",
      "Cuixia Ma",
      "Jian Gu",
      "Ping Tan",
      "Hongan Wang",
      "Xiaoming Deng",
      "Yinda Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15458"
  },
  {
    "id": "arXiv:2203.15459",
    "title": "Influence of Communication Among Shared Developers on the Productivity  of Open Source Software Projects",
    "abstract": "Many software developers rely on open source software for developing their\napplications and writing their source codes. Measuring an independent project's\noverall productivity is still an open problem for many technology companies. In\nthis project, we address to bridge the gap of analyzing which are the most\nimportant features for prediction of a productivity based system. We have\nchosen to collect data from GitHub via their application programming interfaces\n(API) and analyze the data we gathered to understand the relation between the\naverage time to close an issue and the features that we collected. Since most\nof the data we gathered were not Gaussian, we had to preprocess the data using\noutlier detection and applying transformations before statistical modeling. The\nbest model we observed was polynomial regression with degree 5. Overall, we\nnoticed that there are many aspects of software development that make\ndevelopers increase their productivity.",
    "descriptor": "",
    "authors": [
      "Sairamvinay Vijayaraghavan",
      "Jinxiao Song",
      "Terry Guan",
      "Seongwoo Choi",
      "Sutej Kulkarni"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.15459"
  },
  {
    "id": "arXiv:2203.15467",
    "title": "Graded Monads and Behavioural Equivalence Games",
    "abstract": "The framework of graded semantics uses graded monads to capture behavioural\nequivalences of varying granularity, for example as found on the\nlinear-time/branching-time spectrum, over general system types. We describe a\ngeneric Spoiler-Duplicator game for graded semantics that is extracted from the\ngiven graded monad, and may be seen as playing out an equational proof;\ninstances include standard pebble games for simulation and bisimulation as well\nas games for trace-like equivalences and coalgebraic behavioural equivalence.\nConsiderations on an infinite variant of such games lead to a novel notion of\ninfinite-depth graded semantics. Under reasonable restrictions, the\ninfinite-depth graded semantics associated to a given graded equivalence can be\ncharacterized in terms of a determinization construction for coalgebras under\nthe equivalence at hand.",
    "descriptor": "",
    "authors": [
      "Harsh Beohar",
      "Chase Ford",
      "Barbara K\u00f6nig",
      "Stefan Milius",
      "Lutz Schr\u00f6der"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.15467"
  },
  {
    "id": "arXiv:2203.15468",
    "title": "Machine Composition of Korean Music via Topological Data Analysis and  Artificial Neural Network",
    "abstract": "Common AI music composition algorithms based on artificial neural networks\nare to train a machine by feeding a large number of music pieces and create\nartificial neural networks that can produce music similar to the input music\ndata. This approach is a blackbox optimization, that is, the underlying\ncomposition algorithm is, in general, not known to users.\nIn this paper, we present a way of machine composition that trains a machine\nthe composition principle embedded in the given music data instead of directly\nfeeding music pieces. We propose this approach by using the concept of\n{\\color{black}{Overlap}} matrix proposed in \\cite{TPJ}. In \\cite{TPJ}, a type\nof Korean music, so-called the {\\it Dodeuri} music such as Suyeonjangjigok has\nbeen analyzed using topological data analysis (TDA), particularly using\npersistent homology. As the raw music data is not suitable for TDA analysis,\nthe music data is first reconstructed as a graph. The node of the graph is\ndefined as a two-dimensional vector composed of the pitch and duration of each\nmusic note. The edge between two nodes is created when those nodes appear\nconsecutively in the music flow. Distance is defined based on the frequency of\nsuch appearances. Through TDA on the constructed graph, a unique set of cycles\nis found for the given music. In \\cite{TPJ}, the new concept of the {\\it\n{\\color{black}{Overlap}} matrix} has been proposed, which visualizes how those\ncycles are interconnected over the music flow, in a matrix form.\nIn this paper, we explain how we use the {\\color{black}{Overlap}} matrix for\nmachine composition. The {\\color{black}{Overlap}} matrix makes it possible to\ncompose a new music piece algorithmically and also provide a seed music towards\nthe desired artificial neural network. In this paper, we use the {\\it Dodeuri}\nmusic and explain detailed steps.",
    "descriptor": "",
    "authors": [
      "Mai Lan Tran",
      "Dongjin Lee",
      "Jae-Hun Jung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15468"
  },
  {
    "id": "arXiv:2203.15469",
    "title": "Abstract Flow for Temporal Semantic Segmentation on the Permutohedral  Lattice",
    "abstract": "Semantic segmentation is a core ability required by autonomous agents, as\nbeing able to distinguish which parts of the scene belong to which object class\nis crucial for navigation and interaction with the environment. Approaches\nwhich use only one time-step of data cannot distinguish between moving objects\nnor can they benefit from temporal integration. In this work, we extend a\nbackbone LatticeNet to process temporal point cloud data. Additionally, we take\ninspiration from optical flow methods and propose a new module called Abstract\nFlow which allows the network to match parts of the scene with similar abstract\nfeatures and gather the information temporally. We obtain state-of-the-art\nresults on the SemanticKITTI dataset that contains LiDAR scans from real urban\nenvironments. We share the PyTorch implementation of TemporalLatticeNet at\nhttps://github.com/AIS-Bonn/temporal_latticenet .",
    "descriptor": "\nComments: Accepted IEEE International Conference on Robotics and Automation (ICRA) 2022, Code available at this https URL\n",
    "authors": [
      "Peer Sch\u00fctt",
      "Radu Alexandru Rosu",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15469"
  },
  {
    "id": "arXiv:2203.15474",
    "title": "Gaussian Control Barrier Functions : A Non-Parametric Paradigm to Safety",
    "abstract": "Inspired by the success of control barrier functions (CBFs) in addressing\nsafety, and the rise of data-driven techniques for modeling functions, we\npropose a non-parametric approach for online synthesis of CBFs using Gaussian\nProcesses (GPs). Mathematical constructs such as CBFs have achieved safety by\ndesigning a candidate function a priori. However, designing such a candidate\nfunction can be challenging. A practical example of such a setting would be to\ndesign a CBF in a disaster recovery scenario where safe and navigable regions\nneed to be determined. The decision boundary for safety in such an example is\nunknown and cannot be designed a priori. In our approach, we work with safety\nsamples or observations to construct the CBF online by assuming a flexible GP\nprior on these samples, and term our formulation as a Gaussian CBF. GPs have\nfavorable properties, in addition to being non-parametric, such as analytical\ntractability and robust uncertainty estimation. This allows realizing the\nposterior components with high safety guarantees by incorporating variance\nestimation, while also computing associated partial derivatives in closed-form\nto achieve safe control. Moreover, the synthesized safety function from our\napproach allows changing the corresponding safe set arbitrarily based on the\ndata, thus allowing non-convex safe sets. We validate our approach\nexperimentally on a quadrotor by demonstrating safe control for fixed but\narbitrary safe sets and collision avoidance where the safe set is constructed\nonline. Finally, we juxtapose Gaussian CBFs with regular CBFs in the presence\nof noisy states to highlight its flexibility and robustness to noise. The\nexperiment video can be seen at: https://youtu.be/HX6uokvCiGk",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Mouhyemen Khan",
      "Tatsuya Ibuki",
      "Abhijit Chatterjee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.15474"
  },
  {
    "id": "arXiv:2203.15479",
    "title": "Speech Segmentation Optimization using Segmented Bilingual Speech Corpus  for End-to-end Speech Translation",
    "abstract": "Speech segmentation, which splits long speech into short segments, is\nessential for speech translation (ST). Popular VAD tools like WebRTC VAD have\ngenerally relied on pause-based segmentation. Unfortunately, pauses in speech\ndo not necessarily match sentence boundaries, and sentences can be connected by\na very short pause that is difficult to detect by VAD. In this study, we\npropose a speech segmentation method using a binary classification model\ntrained using a segmented bilingual speech corpus. We also propose a hybrid\nmethod that combines VAD and the above speech segmentation method. Experimental\nresults revealed that the proposed method is more suitable for cascade and\nend-to-end ST systems than conventional segmentation methods. The hybrid\napproach further improved the translation performance.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Ryo Fukuda",
      "Katsuhito Sudoh",
      "Satoshi Nakamura"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15479"
  },
  {
    "id": "arXiv:2203.15480",
    "title": "SAR-ShipNet: SAR-Ship Detection Neural Network via Bidirectional  Coordinate Attention and Multi-resolution Feature Fusion",
    "abstract": "This paper studies a practically meaningful ship detection problem from\nsynthetic aperture radar (SAR) images by the neural network. We broadly extract\ndifferent types of SAR image features and raise the intriguing question that\nwhether these extracted features are beneficial to (1) suppress data variations\n(e.g., complex land-sea backgrounds, scattered noise) of real-world SAR images,\nand (2) enhance the features of ships that are small objects and have different\naspect (length-width) ratios, therefore resulting in the improvement of ship\ndetection. To answer this question, we propose a SAR-ship detection neural\nnetwork (call SAR-ShipNet for short), by newly developing Bidirectional\nCoordinate Attention (BCA) and Multi-resolution Feature Fusion (MRF) based on\nCenterNet. Moreover, considering the varying length-width ratio of arbitrary\nships, we adopt elliptical Gaussian probability distribution in CenterNet to\nimprove the performance of base detector models. Experimental results on the\npublic SAR-Ship dataset show that our SAR-ShipNet achieves competitive\nadvantages in both speed and accuracy.",
    "descriptor": "\nComments: This paper was accepted by the International Conference on Acoustics, Speech, and Signal Processing(ICASSP) 2022\n",
    "authors": [
      "Yuwen Deng",
      "Donghai Guan",
      "Yanyu Chen",
      "Weiwei Yuan",
      "Jiemin Ji",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15480"
  },
  {
    "id": "arXiv:2203.15483",
    "title": "Representing `how you say' with `what you say': English corpus of  focused speech and text reflecting corresponding implications",
    "abstract": "In speech communication, how something is said (paralinguistic information)\nis as crucial as what is said (linguistic information). As a type of\nparalinguistic information, English speech uses sentence stress, the heaviest\nprominence within a sentence, to convey emphasis. While different placements of\nsentence stress communicate different emphatic implications, current speech\ntranslation systems return the same translations if the utterances are\nlinguistically identical, losing paralinguistic information. Concentrating on\nfocus, a type of emphasis, we propose mapping paralinguistic information into\nthe linguistic domain within the source language using lexical and grammatical\ndevices. This method enables us to translate the paraphrased text\nrepresentations instead of the transcription of the original speech and obtain\ntranslations that preserve paralinguistic information. As a first step, we\npresent the collection of an English corpus containing speech that differed in\nthe placement of focus along with the corresponding text, which was designed to\nreflect the implied meaning of the speech. Also, analyses of our corpus\ndemonstrated that mapping of focus from the paralinguistic domain into the\nlinguistic domain involved various lexical and grammatical methods. The data\nand insights from our analysis will further advance research into\nparalinguistic translation. The corpus will be published via LDC.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Naoaki Suzuki",
      "Satoshi Nakamura"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.15483"
  },
  {
    "id": "arXiv:2203.15485",
    "title": "Learning Structured Gaussians to Approximate Deep Ensembles",
    "abstract": "This paper proposes using a sparse-structured multivariate Gaussian to\nprovide a closed-form approximator for the output of probabilistic ensemble\nmodels used for dense image prediction tasks. This is achieved through a\nconvolutional neural network that predicts the mean and covariance of the\ndistribution, where the inverse covariance is parameterised by a sparsely\nstructured Cholesky matrix. Similarly to distillation approaches, our single\nnetwork is trained to maximise the probability of samples from pre-trained\nprobabilistic models, in this work we use a fixed ensemble of networks. Once\ntrained, our compact representation can be used to efficiently draw spatially\ncorrelated samples from the approximated output distribution. Importantly, this\napproach captures the uncertainty and structured correlations in the\npredictions explicitly in a formal distribution, rather than implicitly through\nsampling alone. This allows direct introspection of the model, enabling\nvisualisation of the learned structure. Moreover, this formulation provides two\nfurther benefits: estimation of a sample probability, and the introduction of\narbitrary spatial conditioning at test time. We demonstrate the merits of our\napproach on monocular depth estimation and show that the advantages of our\napproach are obtained with comparable quantitative performance.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Ivor J.A. Simpson",
      "Sara Vicente",
      "Neill D.F. Campbell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15485"
  },
  {
    "id": "arXiv:2203.15488",
    "title": "Over-the-Air Federated Learning via Second-Order Optimization",
    "abstract": "Federated learning (FL) is a promising learning paradigm that can tackle the\nincreasingly prominent isolated data islands problem while keeping users' data\nlocally with privacy and security guarantees. However, FL could result in\ntask-oriented data traffic flows over wireless networks with limited radio\nresources. To design communication-efficient FL, most of the existing studies\nemploy the first-order federated optimization approach that has a slow\nconvergence rate. This however results in excessive communication rounds for\nlocal model updates between the edge devices and edge server. To address this\nissue, in this paper, we instead propose a novel over-the-air second-order\nfederated optimization algorithm to simultaneously reduce the communication\nrounds and enable low-latency global model aggregation. This is achieved by\nexploiting the waveform superposition property of a multi-access channel to\nimplement the distributed second-order optimization algorithm over wireless\nnetworks. The convergence behavior of the proposed algorithm is further\ncharacterized, which reveals a linear-quadratic convergence rate with an\naccumulative error term in each iteration. We thus propose a system\noptimization approach to minimize the accumulated error gap by joint device\nselection and beamforming design. Numerical results demonstrate the system and\ncommunication efficiency compared with the state-of-the-art approaches.",
    "descriptor": "\nComments: 30 pages, 9 figures\n",
    "authors": [
      "Peng Yang",
      "Yuning Jiang",
      "Ting Wang",
      "Yong Zhou",
      "Yuanming Shi",
      "Colin N. Jones"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.15488"
  },
  {
    "id": "arXiv:2203.15489",
    "title": "Fruit Mapping with Shape Completion for Autonomous Crop Monitoring",
    "abstract": "Autonomous crop monitoring is a difficult task due to the complex structure\nof plants. Occlusions from leaves can make it impossible to obtain complete\nviews about all fruits of, e.g., pepper plants. Therefore, accurately\nestimating the shape and volume of fruits from partial information is crucial\nto enable further advanced automation tasks such as yield estimation and\nautomated fruit picking. In this paper, we present an approach for mapping\nfruits on plants and estimating their shape by matching superellipsoids. Our\nsystem segments fruits in images and uses their masks to generate point clouds\nof the fruits. To combine sequences of acquired point clouds, we utilize a\nreal-time 3D mapping framework and build up a fruit map based on truncated\nsigned distance fields. We cluster fruits from this map and use optimized\nsuperellipsoids for matching to obtain accurate shape estimates. In our\nexperiments, we show in various simulated scenarios with a robotic arm equipped\nwith an RGB-D camera that our approach can accurately estimate fruit volumes.\nAdditionally, we provide qualitative results of estimated fruit shapes from\ndata recorded in a commercial glasshouse environment.",
    "descriptor": "\nComments: 7 pages, 5 figures, submitted to CASE 2022\n",
    "authors": [
      "Salih Marangoz",
      "Tobias Zaenker",
      "Rohit Menon",
      "Maren Bennewitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15489"
  },
  {
    "id": "arXiv:2203.15491",
    "title": "Improving the Learnability of Machine Learning APIs by Semi-Automated  API Wrapping",
    "abstract": "A major hurdle for students and professional software developers who want to\nenter the world of machine learning (ML), is mastering not just the scientific\nbackground but also the available ML APIs. Therefore, we address the challenge\nof creating APIs that are easy to learn and use, especially by novices.\nHowever, it is not clear how this can be achieved without compromising\nexpressiveness. We investigate this problem for \\skl{}, a widely used ML API.\nIn this paper, we analyze its use by the Kaggle community, identifying unused\nand apparently useless parts of the API that can be eliminated without\naffecting client programs. In addition, we discuss usability issues in the\nremaining parts, propose related design improvements and show how they can be\nimplemented by semi-automated wrapping of the existing third-party API.",
    "descriptor": "\nComments: The definitive Version of Record was published in New Ideas and Emerging Results (ICSE-NIER'22), May 21-29, 2022, Pittsburgh, PA, USA\n",
    "authors": [
      "Lars Reimann",
      "G\u00fcnter Kniesel-W\u00fcnsche"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15491"
  },
  {
    "id": "arXiv:2203.15494",
    "title": "Comparing the Manipulability of Approval Voting and Borda",
    "abstract": "The Gibbard-Satterthwaite theorem established that no non-trivial voting rule\nis strategy-proof, but that does not mean that all voting rules are equally\nsusceptible to strategic manipulation. Over the past fifty years numerous\napproaches have been proposed to compare the manipulability of voting rules in\nterms of the probability of manipulation, the domains on which manipulation is\npossible, the complexity of finding such a manipulation, and others. In the\nclosely related field of matching, Pathak and Sonmez pioneered a notion of\nmanipulability based on case-by-case comparison of manipulable profiles. The\nadvantage of this approach is that it is independent of the underlying\nstatistical culture or the computational power of the agents, and it has proven\nfruitful in the matching literature. In this paper, we extend the notion of\nPathak and Sonmez to voting, studying the families of $k$-approval and\ntruncated Borda scoring rules. We find that, with one exception, the notion\ndoes not allow for a meaningful ordering of the manipulability of these rules.",
    "descriptor": "",
    "authors": [
      "Daria Teplova",
      "Egor Ianovski"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.15494"
  },
  {
    "id": "arXiv:2203.15496",
    "title": "Analysis of Count-Min sketch under conservative update",
    "abstract": "Count-Min sketch is a hash-based data structure to represent a dynamically\nchanging associative array of counters. Here we analyse the counting version of\nCount-Min under a stronger update rule known as \\textit{conservative update},\nassuming the uniform distribution of input keys. We show that the accuracy of\nconservative update strategy undergoes a phase transition, depending on the\nnumber of distinct keys in the input as a fraction of the size of the Count-Min\narray. We prove that below the threshold, the relative error is asymptotically\n$o(1)$ (as opposed to the regular Count-Min strategy), whereas above the\nthreshold, the relative error is $\\Theta(1)$. The threshold corresponds to the\npeelability threshold of random $k$-uniform hypergraphs. We demonstrate that\neven for small number of keys, peelability of the underlying hypergraph is a\ncrucial property to ensure the $o(1)$ error.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "\u00c9ric Fusy",
      "Gregory Kucherov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.15496"
  },
  {
    "id": "arXiv:2203.15498",
    "title": "Powerful Physical Adversarial Examples Against Practical Face  Recognition Systems",
    "abstract": "It is well-known that the most existing machine learning (ML)-based\nsafety-critical applications are vulnerable to carefully crafted input\ninstances called adversarial examples (AXs). An adversary can conveniently\nattack these target systems from digital as well as physical worlds. This paper\naims to the generation of robust physical AXs against face recognition systems.\nWe present a novel smoothness loss function and a patch-noise combo attack for\nrealizing powerful physical AXs. The smoothness loss interjects the concept of\ndelayed constraints during the attack generation process, thereby causing\nbetter handling of optimization complexity and smoother AXs for the physical\ndomain. The patch-noise combo attack combines patch noise and imperceptibly\nsmall noises from different distributions to generate powerful\nregistration-based physical AXs. An extensive experimental analysis found that\nour smoothness loss results in robust and more transferable digital and\nphysical AXs than the conventional techniques. Notably, our smoothness loss\nresults in a 1.17 and 1.97 times better mean attack success rate (ASR) in\nphysical white-box and black-box attacks, respectively. Our patch-noise combo\nattack furthers the performance gains and results in 2.39 and 4.74 times higher\nmean ASR than conventional technique in physical world white-box and black-box\nattacks, respectively.",
    "descriptor": "\nComments: Accepted at IEEE/CVF WACV 2022 MAP\n",
    "authors": [
      "Inderjeet Singh",
      "Toshinori Araki",
      "Kazuya Kakizaki"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15498"
  },
  {
    "id": "arXiv:2203.15501",
    "title": "Deep Learning for Encrypted Traffic Classification and Unknown Data  Detection",
    "abstract": "Despite the widespread use of encryption techniques to provide\nconfidentiality over Internet communications, mobile device users are still\nsusceptible to privacy and security risks. In this paper, a new Deep Neural\nNetwork (DNN) based user activity detection framework is proposed to identify\nfine grained user activities performed on mobile applications (known as in-app\nactivities) from a sniffed encrypted Internet traffic stream. One of the\nchallenges is that there are countless applications, and it is practically\nimpossible to collect and train a DNN model using all possible data from them.\nTherefore, in this work we exploit the probability distribution of DNN output\nlayer to filter the data from applications that are not considered during the\nmodel training (i.e., unknown data). The proposed framework uses a time window\nbased approach to divide the traffic flow of an activity into segments, so that\nin-app activities can be identified just by observing only a fraction of the\nactivity related traffic. Our tests have shown that the DNN based framework has\ndemonstrated an accuracy of 90% or above in identifying previously trained\nin-app activities and an average accuracy of 79% in identifying previously\nuntrained in-app activity traffic as unknown data when this framework is\nemployed.",
    "descriptor": "",
    "authors": [
      "Madushi H. Pathmaperuma",
      "Yogachandran Rahulamathavan",
      "Safak Dogan",
      "Ahmet M. Kondoz",
      "Rongxing Lu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.15501"
  },
  {
    "id": "arXiv:2203.15502",
    "title": "Analysis of OODA Loop based on Adversarial for Complex Game Environments",
    "abstract": "To address the problem of imperfect confrontation strategy caused by the lack\nof information of game environment in the simulation of non-complete\ninformation dynamic countermeasure modeling for intelligent game, the\nhierarchical analysis game strategy of confrontation model based on OODA ring\n(Observation, Orientation, Decision, Action) theory is proposed. At the same\ntime, taking into account the trend of unmanned future warfare, NetLogo\nsoftware simulation is used to construct a dynamic derivation of the\nconfrontation between two tanks. In the validation process, the OODA loop\ntheory is used to describe the operation process of the complex system between\nred and blue sides, and the four-step cycle of observation, judgment, decision\nand execution is carried out according to the number of armor of both sides,\nand then the OODA loop system adjusts the judgment and decision time\ncoefficients for the next confrontation cycle according to the results of the\nfirst cycle. Compared with traditional simulation methods that consider\nobjective factors such as loss rate and support rate, the OODA-loop-based\nhierarchical game analysis can analyze the confrontation situation more\ncomprehensively.",
    "descriptor": "",
    "authors": [
      "Xiangri Lu",
      "Hongbin Ma",
      "Zhanqing Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15502"
  },
  {
    "id": "arXiv:2203.15504",
    "title": "Improved DC Bus Voltage Control of Single-Phase Grid-Connected Voltage  Source Converters for Minimising Bus Capacitance and Line Current Harmonics",
    "abstract": "There is a trade-off between transient performance and line current\ndistortion of the DC bus voltage control of single-phase grid-connected voltage\nsource converters. This paper presents an improved DC bus voltage control\nscheme of such converters using a proportional-integral controller in series\nwith a first-order low pass filter. The extended symmetrical tuning method was\nadopted in the design of a regulator parameter, which greatly reduced the\noscillating component at the double line frequency. The proposed control\nmethodology allowed the loop bandwidth to increase without distorting the line\ncurrent. Consequently, the DC bus voltage fluctuation or DC bus capacitance was\nreduced with a shorter settling time during a step load, compared with the\nconventional scheme. The proposed voltage scheme was found to be robust to the\ngrid voltage variation and was less susceptible to the line voltage harmonics.\nSimulation and experimental results of a 1.5 kVA PWM rectifier verified the\nproposed methodology.",
    "descriptor": "",
    "authors": [
      "Sakda Somkun",
      "Viboon Chunkag"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15504"
  },
  {
    "id": "arXiv:2203.15506",
    "title": "Trojan Horse Training for Breaking Defenses against Backdoor Attacks in  Deep Learning",
    "abstract": "Machine learning (ML) models that use deep neural networks are vulnerable to\nbackdoor attacks. Such attacks involve the insertion of a (hidden) trigger by\nan adversary. As a consequence, any input that contains the trigger will cause\nthe neural network to misclassify the input to a (single) target class, while\nclassifying other inputs without a trigger correctly. ML models that contain a\nbackdoor are called Trojan models. Backdoors can have severe consequences in\nsafety-critical cyber and cyber physical systems when only the outputs of the\nmodel are available. Defense mechanisms have been developed and illustrated to\nbe able to distinguish between outputs from a Trojan model and a non-Trojan\nmodel in the case of a single-target backdoor attack with accuracy > 96\npercent. Understanding the limitations of a defense mechanism requires the\nconstruction of examples where the mechanism fails. Current single-target\nbackdoor attacks require one trigger per target class. We introduce a new, more\ngeneral attack that will enable a single trigger to result in misclassification\nto more than one target class. Such a misclassification will depend on the true\n(actual) class that the input belongs to. We term this category of attacks\nmulti-target backdoor attacks. We demonstrate that a Trojan model with either a\nsingle-target or multi-target trigger can be trained so that the accuracy of a\ndefense mechanism that seeks to distinguish between outputs coming from a\nTrojan and a non-Trojan model will be reduced. Our approach uses the non-Trojan\nmodel as a teacher for the Trojan model and solves a min-max optimization\nproblem between the Trojan model and defense mechanism. Empirical evaluations\ndemonstrate that our training procedure reduces the accuracy of a\nstate-of-the-art defense mechanism from >96 to 0 percent.",
    "descriptor": "\nComments: Submitted to conference\n",
    "authors": [
      "Arezoo Rajabi",
      "Bhaskar Ramasubramanian",
      "Radha Poovendran"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15506"
  },
  {
    "id": "arXiv:2203.15507",
    "title": "Computation of Centroidal Voronoi Tessellations in High Dimensional  spaces",
    "abstract": "Owing to the natural interpretation and various desirable mathematical\nproperties, centroidal Voronoi tessellations (CVT) have found a wide range of\napplications and correspondingly a vast development in their literature.\nHowever the computation of CVT in higher dimensional spaces still remains\ndifficult. In this paper, we exploit the non-uniqueness of CVTs in higher\ndimensional spaces for their computation. We construct such high dimensional\ntessellations from CVTs in one-dimensional spaces. We then prove that such a\ntessellation is centroidal under the condition of independence among densities\nover the one-dimensional spaces considered. Various numerical evaluations\nbackup the theoretical result through the low energy of the tessellations. The\nresulting grid-like tessellations are obtained efficiently with minimal\ncomputation time.",
    "descriptor": "",
    "authors": [
      "Bhagyashri Telsang",
      "Seddik Djouadi"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.15507"
  },
  {
    "id": "arXiv:2203.15508",
    "title": "Improving Contrastive Learning with Model Augmentation",
    "abstract": "The sequential recommendation aims at predicting the next items in user\nbehaviors, which can be solved by characterizing item relationships in\nsequences. Due to the data sparsity and noise issues in sequences, a new\nself-supervised learning (SSL) paradigm is proposed to improve the performance,\nwhich employs contrastive learning between positive and negative views of\nsequences.\nHowever, existing methods all construct views by adopting augmentation from\ndata perspectives, while we argue that 1) optimal data augmentation methods are\nhard to devise, 2) data augmentation methods destroy sequential correlations,\nand 3) data augmentation fails to incorporate comprehensive self-supervised\nsignals.\nTherefore, we investigate the possibility of model augmentation to construct\nview pairs. We propose three levels of model augmentation methods: neuron\nmasking, layer dropping, and encoder complementing.\nThis work opens up a novel direction in constructing views for contrastive\nSSL. Experiments verify the efficacy of model augmentation for the SSL in the\nsequential recommendation. Code is\navailable\\footnote{\\url{https://github.com/salesforce/SRMA}}.",
    "descriptor": "\nComments: Preprint. Still under reivew\n",
    "authors": [
      "Zhiwei Liu",
      "Yongjun Chen",
      "Jia Li",
      "Man Luo",
      "Philip S. Yu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.15508"
  },
  {
    "id": "arXiv:2203.15509",
    "title": "Firefighter Problem with Minimum Budget: Hardness and Approximation  Algorithm for Unit Disk Graphs",
    "abstract": "Unit disk graphs are the set of graphs which represent the intersection of\ndisk graphs and interval graphs. These graphs are of great importance due to\ntheir structural similarity with wireless communication networks. Firefighter\nproblem on unit disk graph is interesting as it models the virus spreading in\nan wireless network and asks for a solution to stop it. In this paper, we\nconsider the MIN-BUDGET firefighter problem where the goal is to determine the\nminimum number of firefighters required and the nodes to place them at each\ntime instant to save a given set of vertices of a given graph and a fire\nbreakout node. We show that, the MIN-BUDGET firefighter problem in a unit disk\ngraph is NP-Hard. We also present a constant factor approximation algorithm.",
    "descriptor": "\nComments: 10 pages, 2 algorithms\n",
    "authors": [
      "Diptendu Chatterjee",
      "Rishiraj Bhattacharyya"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.15509"
  },
  {
    "id": "arXiv:2203.15510",
    "title": "Achieving Guidance in Applied Machine Learning through Software  Engineering Techniques",
    "abstract": "Development of machine learning (ML) applications is hard. Producing\nsuccessful applications requires, among others, being deeply familiar with a\nvariety of complex and quickly evolving application programming interfaces\n(APIs). It is therefore critical to understand what prevents developers from\nlearning these APIs, using them properly at development time, and understanding\nwhat went wrong when it comes to debugging. We look at the (lack of) guidance\nthat currently used development environments and ML APIs provide to developers\nof ML applications, contrast these with software engineering best practices,\nand identify gaps in the current state of the art. We show that current ML\ntools fall short of fulfilling some basic software engineering gold standards\nand point out ways in which software engineering concepts, tools and techniques\nneed to be extended and adapted to match the special needs of ML application\ndevelopment. Our findings point out ample opportunities for research on\nML-specific software engineering.",
    "descriptor": "\nComments: The definitive Version of Record was published in Companion Proceedings of the 4th International Conference on the Art, Science, and Engineering of Programming (&lt;Programming'20&gt; Companion), March 23-26, 2020, Porto, Portugal\n",
    "authors": [
      "Lars Reimann",
      "G\u00fcnter Kniesel-W\u00fcnsche"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15510"
  },
  {
    "id": "arXiv:2203.15511",
    "title": "Explaining random forest prediction through diverse rulesets",
    "abstract": "Tree-ensemble algorithms, such as random forest, are effective machine\nlearning methods popular for their flexibility, high performance, and\nrobustness to overfitting. However, since multiple learners are combined,they\nare not as interpretable as a single decision tree. In this work we propose a\nmethodology, called Local Tree eXtractor (LTreeX) which is able to explain the\nforest prediction for a given test instance with a few diverse rules. Starting\nfrom the decision trees generated by a random forest, our method 1) pre-selects\na subset of them, 2) creates a vector representation, and 3) eventually\nclusters such a representation. Each cluster prototype results in a rule that\nexplains the test instance prediction. We test the effectiveness of LTreeX on\n71 real-world datasets and we demonstrate the validity of our approach for\nbinary classification, regression, multi-label classification and time-to-event\ntasks. In all set-ups, we show that our extracted surrogate model manages to\napproximate the performance of the corresponding ensemble model, while\nselecting only few trees from the whole forest.We also show that our proposed\napproach substantially outperforms other explainable methods in terms of\npredictive performance.",
    "descriptor": "",
    "authors": [
      "Klest Dedja",
      "Felipe Kenji Nakano",
      "Konstantinos Pliakos",
      "Celine Vens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15511"
  },
  {
    "id": "arXiv:2203.15514",
    "title": "Human Response to an AI-Based Decision Support System: A User Study on  the Effects of Accuracy and Bias",
    "abstract": "Artificial Intelligence (AI) is increasingly used to build Decision Support\nSystems (DSS) across many domains. This paper describes a series of experiments\ndesigned to observe human response to different characteristics of a DSS such\nas accuracy and bias, particularly the extent to which participants rely on the\nDSS, and the performance they achieve. In our experiments, participants play a\nsimple online game inspired by so-called \"wildcat\" (i.e., exploratory) drilling\nfor oil. The landscape has two layers: a visible layer describing the costs\n(terrain), and a hidden layer describing the reward (oil yield). Participants\nin the control group play the game without receiving any assistance, while in\ntreatment groups they are assisted by a DSS suggesting places to drill. For\ncertain treatments, the DSS does not consider costs, but only rewards, which\nintroduces a bias that is observable by users. Between subjects, we vary the\naccuracy and bias of the DSS, and observe the participants' total score, time\nto completion, the extent to which they follow or ignore suggestions. We also\nmeasure the acceptability of the DSS in an exit survey. Our results show that\nparticipants tend to score better with the DSS, that the score increase is due\nto users following the DSS advice, and related to the difficulty of the game\nand the accuracy of the DSS. We observe that this setting elicits mostly\nrational behavior from participants, who place a moderate amount of trust in\nthe DSS and show neither algorithmic aversion (under-reliance) nor automation\nbias (over-reliance).However, their stated willingness to accept the DSS in the\nexit survey seems less sensitive to the accuracy of the DSS than their\nbehavior, suggesting that users are only partially aware of the (lack of)\naccuracy of the DSS.",
    "descriptor": "",
    "authors": [
      "David Solans",
      "Andrea Beretta",
      "Manuel Portela",
      "Carlos Castillo",
      "Anna Monreale"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15514"
  },
  {
    "id": "arXiv:2203.15516",
    "title": "Rich Feature Construction for the Optimization-Generalization Dilemma",
    "abstract": "There often is a dilemma between ease of optimization and robust\nout-of-distribution (OoD) generalization. For instance, many OoD methods rely\non penalty terms whose optimization is challenging. They are either too strong\nto optimize reliably or too weak to achieve their goals.\nIn order to escape this dilemma, we propose to first construct a rich\nrepresentation (RFC) containing a palette of potentially useful features, ready\nto be used by even simple models. On the one hand, a rich representation\nprovides a good initialization for the optimizer. On the other hand, it also\nprovides an inductive bias that helps OoD generalization. RFC is constructed in\na succession of training episodes. During each step of the discovery phase, we\ncraft a multi-objective optimization criterion and its associated datasets in a\nmanner that prevents the network from using the features constructed in the\nprevious iterations. During the synthesis phase, we use knowledge distillation\nto force the network to simultaneously develop all the features identified\nduring the discovery phase.\nRFC consistently helps six OoD methods achieve top performance on challenging\ninvariant training benchmarks, ColoredMNIST (Arjovsky et al., 2020).\nFurthermore, on the realistic Camelyon17 task, our method helps both OoD and\nERM methods outperform earlier compatable results by at least $5\\%$, reduce\nstandard deviation by at least $4.1\\%$, and makes hyperparameter tuning and\nmodel selection more reliable.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Jianyu Zhang",
      "David Lopez-Paz",
      "L\u00e9on Bottou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15516"
  },
  {
    "id": "arXiv:2203.15519",
    "title": "Learning neural audio features without supervision",
    "abstract": "Deep audio classification, traditionally cast as training a deep neural\nnetwork on top of mel-filterbanks in a supervised fashion, has recently\nbenefited from two independent lines of work. The first one explores \"learnable\nfrontends\", i.e., neural modules that produce a learnable time-frequency\nrepresentation, to overcome limitations of fixed features. The second one uses\nself-supervised learning to leverage unprecedented scales of pre-training data.\nIn this work, we study the feasibility of combining both approaches, i.e.,\npre-training learnable frontend jointly with the main architecture for\ndownstream classification. First, we show that pretraining two previously\nproposed frontends (SincNet and LEAF) on Audioset drastically improves\nlinear-probe performance over fixed mel-filterbanks, suggesting that learnable\ntime-frequency representations can benefit self-supervised pre-training even\nmore than supervised training. Surprisingly, randomly initialized learnable\nfilterbanks outperform mel-scaled initialization in the self-supervised\nsetting, a counter-intuitive result that questions the appropriateness of\nstrong priors when designing learnable filters. Through exploratory analysis of\nthe learned frontend components, we uncover crucial differences in properties\nof these frontends when used in a supervised and self-supervised setting,\nespecially the affinity of self-supervised filters to diverge significantly\nfrom the mel-scale to model a broader range of frequencies.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Sarthak Yadav",
      "Neil Zeghidour"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15519"
  },
  {
    "id": "arXiv:2203.15522",
    "title": "Collision-Free Navigation using Evolutionary Symmetrical Neural Networks",
    "abstract": "Collision avoidance systems play a vital role in reducing the number of\nvehicle accidents and saving human lives. This paper extends the previous work\nusing evolutionary neural networks for reactive collision avoidance. We are\nproposing a new method we have called symmetric neural networks. The method\nimproves the model's performance by enforcing constraints between the network\nweights which reduces the model optimization search space and hence, learns\nmore accurate control of the vehicle steering for improved maneuvering. The\ntraining and validation processes are carried out using a simulation\nenvironment - the codebase is publicly available. Extensive experiments are\nconducted to analyze the proposed method and evaluate its performance. The\nmethod is tested in several simulated driving scenarios. In addition, we have\nanalyzed the effect of the rangefinder sensor resolution and noise on the\noverall goal of reactive collision avoidance. Finally, we have tested the\ngeneralization of the proposed method. The results are encouraging; the\nproposed method has improved the model's learning curve for training scenarios\nand generalization to the new test scenarios. Using constrained weights has\nsignificantly improved the number of generations required for the Genetic\nAlgorithm optimization.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1609.08414\n",
    "authors": [
      "Hesham M. Eraqi",
      "Mena Nagiub",
      "Peter Sidra"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15522"
  },
  {
    "id": "arXiv:2203.15526",
    "title": "Interactive Audio-text Representation for Automated Audio Captioning  with Contrastive Learning",
    "abstract": "Automated Audio captioning (AAC) is a cross-modal task that generates natural\nlanguage to describe the content of input audio. Most prior works usually\nextract single-modality acoustic features and are therefore sub-optimal for the\ncross-modal decoding task. In this work, we propose a novel AAC system called\nCLIP-AAC to learn interactive cross-modality representation with both acoustic\nand textual information. Specifically, the proposed CLIP-AAC introduces an\naudio-head and a text-head in the pre-trained encoder to extract audio-text\ninformation. Furthermore, we also apply contrastive learning to narrow the\ndomain difference by learning the correspondence between the audio signal and\nits paired captions. Experimental results show that the proposed CLIP-AAC\napproach surpasses the best baseline by a significant margin on the Clotho\ndataset in terms of NLP evaluation metrics. The ablation study indicates that\nboth the pre-trained model and contrastive learning contribute to the\nperformance gain of the AAC model.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Chen Chen",
      "Nana Hou",
      "Yuchen Hu",
      "Heqing Zou",
      "Xiaofeng Qi",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15526"
  },
  {
    "id": "arXiv:2203.15529",
    "title": "Treatment Learning Transformer for Noisy Image Classification",
    "abstract": "Current top-notch deep learning (DL) based vision models are primarily based\non exploring and exploiting the inherent correlations between training data\nsamples and their associated labels. However, a known practical challenge is\ntheir degraded performance against \"noisy\" data, induced by different\ncircumstances such as spurious correlations, irrelevant contexts, domain shift,\nand adversarial attacks. In this work, we incorporate this binary information\nof \"existence of noise\" as treatment into image classification tasks to improve\nprediction accuracy by jointly estimating their treatment effects. Motivated\nfrom causal variational inference, we propose a transformer-based architecture,\nTreatment Learning Transformer (TLT), that uses a latent generative model to\nestimate robust feature representations from current observational input for\nnoise image classification. Depending on the estimated noise level (modeled as\na binary treatment factor), TLT assigns the corresponding inference network\ntrained by the designed causal loss for prediction. We also create new noisy\nimage datasets incorporating a wide range of noise factors (e.g., object\nmasking, style transfer, and adversarial perturbation) for performance\nbenchmarking. The superior performance of TLT in noisy image classification is\nfurther validated by several refutation evaluation metrics. As a by-product,\nTLT also improves visual salience methods for perceiving noisy images.",
    "descriptor": "\nComments: Preprint. The first version was finished in May 2018\n",
    "authors": [
      "Chao-Han Huck Yang",
      "I-Te Danny Hung",
      "Yi-Chieh Liu",
      "Pin-Yu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.15529"
  },
  {
    "id": "arXiv:2203.15533",
    "title": "OSOP: A Multi-Stage One Shot Object Pose Estimation Framework",
    "abstract": "We present a novel one-shot method for object detection and 6 DoF pose\nestimation, that does not require training on target objects. At test time, it\ntakes as input a target image and a textured 3D query model. The core idea is\nto represent a 3D model with a number of 2D templates rendered from different\nviewpoints. This enables CNN-based direct dense feature extraction and\nmatching. The object is first localized in 2D, then its approximate viewpoint\nis estimated, followed by dense 2D-3D correspondence prediction. The final pose\nis computed with PnP. We evaluate the method on LineMOD, Occlusion, Homebrewed,\nYCB-V and TLESS datasets and report very competitive performance in comparison\nto the state-of-the-art methods trained on synthetic data, even though our\nmethod is not trained on the object models used for testing.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Ivan Shugurov",
      "Fu Li",
      "Benjamin Busam",
      "Slobodan Ilic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15533"
  },
  {
    "id": "arXiv:2203.15534",
    "title": "Design and Implementation of Knowledge Base for Runtime Management of  Software Defined Hardware",
    "abstract": "Runtime-reconfigurable software coupled with reconfigurable hardware is\nhighly desirable as a means towards maximizing runtime efficiency without\ncompromising programmability. Compilers for such software systems are extremely\ndifficult to design as they must leverage different types of hardware at\nruntime. To address the need for static and dynamic compiler optimization of\nworkflows matched to dynamically reconfigurable hardware, we propose a novel\ndesign of the central component of a dynamic software compiler for software\ndefined hardware. Our comprehensive design focuses not just on static knowledge\nbut also on semi-supervised extraction of knowledge from program executions and\ndeveloping their performance models. Specifically, our novel {\\it dynamic and\nextensible knowledge base} 1) continuously gathers knowledge during execution\nof workflows 2) identifies {\\it optimal} implementations of workflows on {\\it\noptimal} (available) hardware configurations. It plays a hub role in storing\ninformation from, and providing information to other components of the\ncompiler, as well as the human analyst. Through a rich tripartite graph\nrepresentation, the knowledge base captures and learns extensive information on\ndecomposition and mapping of code steps to kernels and mapping of kernels to\navailable hardware configurations. The knowledge base is implemented using the\nC++ Boost Library and is capable of quickly processing offline and online\nqueries and updates. We show that our knowledge base can answer queries in\n$1ms$ regardless of the number of workflows it stores. To the best of our\nknowledge, this is the first design of a dynamic and extensible knowledge base\nto support compilation of high-level languages to leverage arbitrary\nreconfigurable platforms.",
    "descriptor": "\nComments: HPEC'19\n",
    "authors": [
      "Hongkuan Zhou",
      "Ajitesh Srivastava",
      "Rajgopal Kannan",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.15534"
  },
  {
    "id": "arXiv:2203.15535",
    "title": "Game-theoretical trajectory planning enhances social acceptability for  humans",
    "abstract": "Since humans and robots are increasingly sharing portions of their\noperational spaces, experimental evidence is needed to ascertain the safety and\nsocial acceptability of robots in human-populated environments. Although\nseveral studies have aimed at devising strategies for robot trajectory planning\nto perform \\emph{safe} motion in populated environments, a few efforts have\n\\emph{measured} to what extent a robot trajectory is \\emph{accepted} by humans.\nHere, we present a navigation system for autonomous robotics that ensures\nsafety and social acceptability of robotic trajectories. We overcome the\ntypical reactive nature of state-of-the-art trajectory planners by leveraging\nnon-cooperative game theory to design a planner that encapsulates human-like\nfeatures of preservation of a vital space, recognition of groups, sequential\nand strategized decision making, and smooth obstacle avoidance. Social\nacceptability is measured through a variation of the Turing test administered\nin the form of a survey questionnaire to a pool of 691 participants. Comparison\nterms for our tests are a state-of-the-art navigation algorithm (Enhanced\nVector Field Histogram, VFH) and purely human trajectories. While all\nparticipants easily recognized the non-human nature of VFH-generated\ntrajectories, the distinction between game-theoretical trajectories and human\nones were hardly revealed. These results mark a strong milestone toward the\nfull integration of robots in social environments.",
    "descriptor": "",
    "authors": [
      "Giada Galati",
      "Stefano Primatesta",
      "Sergio Grammatico",
      "Simone Macr\u00ec",
      "Alessandro Rizzo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.15535"
  },
  {
    "id": "arXiv:2203.15536",
    "title": "BARC: Learning to Regress 3D Dog Shape from Images by Exploiting Breed  Information",
    "abstract": "Our goal is to recover the 3D shape and pose of dogs from a single image.\nThis is a challenging task because dogs exhibit a wide range of shapes and\nappearances, and are highly articulated. Recent work has proposed to directly\nregress the SMAL animal model, with additional limb scale parameters, from\nimages. Our method, called BARC (Breed-Augmented Regression using\nClassification), goes beyond prior work in several important ways. First, we\nmodify the SMAL shape space to be more appropriate for representing dog shape.\nBut, even with a better shape model, the problem of regressing dog shape from\nan image is still challenging because we lack paired images with 3D ground\ntruth. To compensate for the lack of paired data, we formulate novel losses\nthat exploit information about dog breeds. In particular, we exploit the fact\nthat dogs of the same breed have similar body shapes. We formulate a novel\nbreed similarity loss consisting of two parts: One term encourages the shape of\ndogs from the same breed to be more similar than dogs of different breeds. The\nsecond one, a breed classification loss, helps to produce recognizable\nbreed-specific shapes. Through ablation studies, we find that our breed losses\nsignificantly improve shape accuracy over a baseline without them. We also\ncompare BARC qualitatively to WLDO with a perceptual study and find that our\napproach produces dogs that are significantly more realistic. This work shows\nthat a-priori information about genetic similarity can help to compensate for\nthe lack of 3D training data. This concept may be applicable to other animal\nspecies or groups of species. Our code is publicly available for research\npurposes at https://barc.is.tue.mpg.de/.",
    "descriptor": "\nComments: accepted for publication at CVPR 2022\n",
    "authors": [
      "Nadine Rueegg",
      "Silvia Zuffi",
      "Konrad Schindler",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15536"
  },
  {
    "id": "arXiv:2203.15539",
    "title": "A second-order low-regularity correction of Lie splitting for the  semilinear Klein--Gordon equation",
    "abstract": "The numerical approximation of the semilinear Klein--Gordon equation in the\n$d$-dimensional space, with $d=1,2,3$, is studied by analyzing the consistency\nerrors in approximating the solution. By discovering and utilizing a new\ncancellation structure in the semilinear Klein--Gordon equation, a\nlow-regularity correction of the Lie splitting method is constructed, which can\nhave second-order convergence in the energy space under the regularity\ncondition $(u,\\partial_tu)\\in L^\\infty(0,T;H^{1+\\frac{d}{4}}\\times\nH^{\\frac{d}{4}})$, where $d=1,2,3$ denotes the dimension of space. In one\ndimension, the proposed method is shown to have a convergence order arbitrarily\nclose to $\\frac53$ in the energy space for solutions in the same space, i.e. no\nadditional regularity in the solution is required. Rigorous error estimates are\npresented for a fully discrete spectral method with the proposed low-regularity\ntime-stepping scheme. Numerical examples are provided to support the\ntheoretical analysis and to illustrate the performance of the proposed method\nin approximating both nonsmooth and smooth solutions of the semilinear\nKlein--Gordon equation.",
    "descriptor": "",
    "authors": [
      "Buyang Li",
      "Katharina Schratz",
      "Franco Zivcovich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15539"
  },
  {
    "id": "arXiv:2203.15542",
    "title": "Modeling Users' Contextualized Page-wise Feedback for Click-Through Rate  Prediction in E-commerce Search",
    "abstract": "Modeling user's historical feedback is essential for Click-Through Rate\nPrediction in personalized search and recommendation. Existing methods usually\nonly model users' positive feedback information such as click sequences which\nneglects the context information of the feedback. In this paper, we propose a\nnew perspective for context-aware users' behavior modeling by including the\nwhole page-wisely exposed products and the corresponding feedback as\ncontextualized page-wise feedback sequence. The intra-page context information\nand inter-page interest evolution can be captured to learn more specific user\npreference. We design a novel neural ranking model RACP(i.e., Recurrent\nAttention over Contextualized Page sequence), which utilizes page-context aware\nattention to model the intra-page context. A recurrent attention process is\nused to model the cross-page interest convergence evolution as denoising the\ninterest in the previous pages. Experiments on public and real-world industrial\ndatasets verify our model's effectiveness.",
    "descriptor": "",
    "authors": [
      "Zhifang Fan",
      "Dan Ou",
      "Yulong Gu",
      "Bairan Fu",
      "Xiang Li",
      "Wentian Bao",
      "Xin-Yu Dai",
      "Xiaoyi Zeng",
      "Tao Zhuang",
      "Qingwen Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15542"
  },
  {
    "id": "arXiv:2203.15544",
    "title": "Graph Neural Networks are Dynamic Programmers",
    "abstract": "Recent advances in neural algorithmic reasoning with graph neural networks\n(GNNs) are propped up by the notion of algorithmic alignment. Broadly, a neural\nnetwork will be better at learning to execute a reasoning task (in terms of\nsample complexity) if its individual components align well with the target\nalgorithm. Specifically, GNNs are claimed to align with dynamic programming\n(DP), a general problem-solving strategy which expresses many polynomial-time\nalgorithms. However, has this alignment truly been demonstrated and\ntheoretically quantified? Here we show, using methods from category theory and\nabstract algebra, that there exists an intricate connection between GNNs and\nDP, going well beyond the initial observations over individual algorithms such\nas Bellman-Ford. Exposing this connection, we easily verify several prior\nfindings in the literature, and hope it will serve as a foundation for building\nstronger algorithmically aligned GNNs.",
    "descriptor": "\nComments: 9 pages, 1 figure. To appear at the ICLR 2022 GroundedML and GTRL Workshops. Work in progress -- comments welcome!\n",
    "authors": [
      "Andrew Dudzik",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Category Theory (math.CT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15544"
  },
  {
    "id": "arXiv:2203.15547",
    "title": "ME-CapsNet: A Multi-Enhanced Capsule Networks with Routing Mechanism",
    "abstract": "Convolutional Neural Networks need the construction of informative features,\nwhich are determined by channel-wise and spatial-wise information at the\nnetwork's layers. In this research, we focus on bringing in a novel solution\nthat uses sophisticated optimization for enhancing both the spatial and channel\ncomponents inside each layer's receptive field. Capsule Networks were used to\nunderstand the spatial association between features in the feature map.\nStandalone capsule networks have shown good results on comparatively simple\ndatasets than on complex datasets as a result of the inordinate amount of\nfeature information. Thus, to tackle this issue, we have proposed ME-CapsNet by\nintroducing deeper convolutional layers to extract important features before\npassing through modules of capsule layers strategically to improve the\nperformance of the network significantly. The deeper convolutional layer\nincludes blocks of Squeeze-Excitation networks which uses a soft-pooling\napproach for progressively reducing the spatial size thereby dynamically\nrecalibrating the channels by reconstructing their interdependencies without\nmuch loss of important feature information. Extensive experimentation was done\nusing commonly used datasets demonstrating the efficiency of the proposed\nME-CapsNet, which clearly outperforms various research works by achieving\nhigher accuracy with minimal model complexity in complex datasets.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Jerrin Bright",
      "Suryaprakash R",
      "Arockia Selvakumar Arockia Doss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15547"
  },
  {
    "id": "arXiv:2203.15548",
    "title": "Image Segmentation with Adaptive Spatial Priors from Joint Registration",
    "abstract": "Image segmentation is a crucial but challenging task that has many\napplications. In medical imaging for instance, intensity inhomogeneity and\nnoise are common. In thigh muscle images, different muscles are closed packed\ntogether and there are often no clear boundaries between them. Intensity based\nsegmentation models cannot separate one muscle from another. To solve such\nproblems, in this work we present a segmentation model with adaptive spatial\npriors from joint registration. This model combines segmentation and\nregistration in a unified framework to leverage their positive mutual\ninfluence. The segmentation is based on a modified Gaussian mixture model\n(GMM), which integrates intensity inhomogeneity and spacial smoothness. The\nregistration plays the role of providing a shape prior. We adopt a modified sum\nof squared difference (SSD) fidelity term and Tikhonov regularity term for\nregistration, and also utilize Gaussian pyramid and parametric method for\nrobustness. The connection between segmentation and registration is guaranteed\nby the cross entropy metric that aims to make the segmentation map (from\nsegmentation) and deformed atlas (from registration) as similar as possible.\nThis joint framework is implemented within a constraint optimization framework,\nwhich leads to an efficient algorithm. We evaluate our proposed model on\nsynthetic and thigh muscle MR images. Numerical results show the improvement as\ncompared to segmentation and registration performed separately and other joint\nmodels.",
    "descriptor": "",
    "authors": [
      "Haifeng Li",
      "Weihong Guo",
      "Jun Liu",
      "Li Cui",
      "Dongxing Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15548"
  },
  {
    "id": "arXiv:2203.15556",
    "title": "Training Compute-Optimal Large Language Models",
    "abstract": "We investigate the optimal model size and number of tokens for training a\ntransformer language model under a given compute budget. We find that current\nlarge language models are significantly undertrained, a consequence of the\nrecent focus on scaling language models whilst keeping the amount of training\ndata constant. By training over \\nummodels language models ranging from 70\nmillion to over 16 billion parameters on 5 to 500 billion tokens, we find that\nfor compute-optimal training, the model size and the number of training tokens\nshould be scaled equally: for every doubling of model size the number of\ntraining tokens should also be doubled. We test this hypothesis by training a\npredicted compute-optimal model, \\chinchilla, that uses the same compute budget\nas \\gopher but with 70B parameters and 4$\\times$ more more data. \\chinchilla\nuniformly and significantly outperforms \\Gopher (280B), GPT-3 (175B),\nJurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of\ndownstream evaluation tasks. This also means that \\chinchilla uses\nsubstantially less compute for fine-tuning and inference, greatly facilitating\ndownstream usage. As a highlight, \\chinchilla reaches a state-of-the-art\naverage accuracy of 67.5\\% on the MMLU benchmark, greater than a 7\\%\nimprovement over \\gopher.",
    "descriptor": "",
    "authors": [
      "Jordan Hoffmann",
      "Sebastian Borgeaud",
      "Arthur Mensch",
      "Elena Buchatskaya",
      "Trevor Cai",
      "Eliza Rutherford",
      "Diego de Las Casas",
      "Lisa Anne Hendricks",
      "Johannes Welbl",
      "Aidan Clark",
      "Tom Hennigan",
      "Eric Noland",
      "Katie Millican",
      "George van den Driessche",
      "Bogdan Damoc",
      "Aurelia Guy",
      "Simon Osindero",
      "Karen Simonyan",
      "Erich Elsen",
      "Jack W. Rae",
      "Oriol Vinyals",
      "Laurent Sifre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15556"
  },
  {
    "id": "arXiv:2203.15557",
    "title": "Near-Field Hierarchical Beam Management for RIS-Enabled Millimeter Wave  Multi-Antenna Systems",
    "abstract": "In this paper, we present a low overhead beam management approach for\nnear-field millimeter-wave multi-antenna communication systems enabled by\nReconfigurable Intelligent Surfaces (RISs). We devise a novel variable-width\nhierarchical phaseshift codebook suitable for both the near- and far-field of\nthe RIS, and present a fast alignment algorithm for the RIS phase shifts and\nthe transceiver beamformers. Indicative performance evaluation results are\nshown, verifying the effectiveness of the proposed approach in comparison with\nvarious benchmark schemes.",
    "descriptor": "",
    "authors": [
      "George C. Alexandropoulos",
      "Vahid Jamali",
      "Robert Schober",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.15557"
  },
  {
    "id": "arXiv:2203.15558",
    "title": "Wildfire risk forecast: An optimizable fire danger index",
    "abstract": "Wildfire events have caused severe losses in many places around the world and\nare expected to increase with climate change. Throughout the years many\ntechnologies have been developed to identify fire events early on and to\nsimulate fire behavior once they have started. Another particularly helpful\ntechnology is fire risk indices, which use weather forcing to make advanced\npredictions of the risk of fire. Predictions of fire risk indices can be used,\nfor instance, to allocate resources in places with high risk. These indices\nhave been developed over the years as empirical models with parameters that\nwere estimated in lab experiments and field tests. These parameters, however,\nmay not fit well all places where these models are used. In this paper we\npropose a novel implementation of one index (NFDRS IC) as a differentiable\nfunction in which one can optimize its internal parameters via gradient\ndescent. We leverage existing machine learning frameworks (PyTorch) to\nconstruct our model. This approach has two benefits: (1) the NFDRS IC\nparameters can be improved for each region using actual observed fire events,\nand (2) the internal variables remain intact for interpretations by specialists\ninstead of meaningless hidden layers as in traditional neural networks. In this\npaper we evaluate our strategy with actual fire events for locations in the USA\nand Europe.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Eduardo Rodrigues",
      "Bianca Zadrozny",
      "Campbell Watson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15558"
  },
  {
    "id": "arXiv:2203.15559",
    "title": "Multifidelity Orbit Uncertainty Propagation using Taylor Polynomials",
    "abstract": "A new multifidelity method is developed for nonlinear orbit uncertainty\npropagation. This approach guarantees improved computational efficiency and\nlimited accuracy losses compared to fully high-fidelity counterparts. The\ninitial uncertainty is modeled as a weighted sum of Gaussian distributions\nwhose number is adapted online to satisfy the required accuracy. As needed,\nunivariate splitting libraries are used to split the mixture components along\nthe direction of maximum nonlinearity. Differential Algebraic techniques are\nused to propagate these Gaussian kernels and compute a measure of nonlinearity\nrequired for the split decision and direction identification. Taylor expansions\nof the flow of the dynamics are computed using a low-fidelity dynamical model\nto maximize computational efficiency and corrected with selected high-fidelity\nsamples to minimize accuracy losses. The effectiveness of the proposed method\nis demonstrated for different dynamical regimes combining SGP4 theory and\nnumerical propagation as low- and high-fidelity models respectively.",
    "descriptor": "\nComments: 24 pages, 5 figures\n",
    "authors": [
      "Alberto Foss\u00e0",
      "Roberto Armellin",
      "Emmanuel Delande",
      "Matteo Losacco",
      "Francesco Sanfedino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15559"
  },
  {
    "id": "arXiv:2203.15561",
    "title": "Algorithmic Improvement and GPU Acceleration of the GenASM Algorithm",
    "abstract": "We improve on GenASM, a recent algorithm for genomic sequence alignment, by\nsignificantly reducing its memory footprint and bandwidth requirement. Our\nalgorithmic improvements reduce the memory footprint by 24$\\times$ and the\nnumber of memory accesses by 12$\\times$. We efficiently parallelize the\nalgorithm for GPUs, achieving a 4.1$\\times$ speedup over a CPU implementation\nof the same algorithm, a 62$\\times$ speedup over minimap2's CPU-based KSW2 and\na 7.2$\\times$ speedup over the CPU-based Edlib for long reads.",
    "descriptor": "\nComments: To appear at the 21st IEEE International Workshop on High Performance Computational Biology (HiCOMB) 2022\n",
    "authors": [
      "Jo\u00ebl Lindegger",
      "Damla Senol Cali",
      "Mohammed Alser",
      "Juan G\u00f3mez-Luna",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.15561"
  },
  {
    "id": "arXiv:2203.15563",
    "title": "Attacker Attribution of Audio Deepfakes",
    "abstract": "Deepfakes are synthetically generated media often devised with malicious\nintent. They have become increasingly more convincing with large training\ndatasets advanced neural networks. These fakes are readily being misused for\nslander, misinformation and fraud. For this reason, intensive research for\ndeveloping countermeasures is also expanding. However, recent work is almost\nexclusively limited to deepfake detection - predicting if audio is real or\nfake. This is despite the fact that attribution (who created which fake?) is an\nessential building block of a larger defense strategy, as practiced in the\nfield of cybersecurity for a long time. This paper considers the problem of\ndeepfake attacker attribution in the domain of audio. We present several\nmethods for creating attacker signatures using low-level acoustic descriptors\nand machine learning embeddings. We show that speech signal features are\ninadequate for characterizing attacker signatures. However, we also demonstrate\nthat embeddings from a recurrent neural network can successfully characterize\nattacks from both known and unknown attackers. Our attack signature embeddings\nresult in distinct clusters, both for seen and unseen audio deepfakes. We show\nthat these embeddings can be used in downstream-tasks to high-effect, scoring\n97.10% accuracy in attacker-id classification.",
    "descriptor": "\nComments: Submitted to Insterspeech 2022\n",
    "authors": [
      "Nicolas M. M\u00fcller",
      "Franziska Dieckmann",
      "Jennifer Williams"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15563"
  },
  {
    "id": "arXiv:2203.15565",
    "title": "Killing Two Birds with One Stone:Efficient and Robust Training of Face  Recognition CNNs by Partial FC",
    "abstract": "Learning discriminative deep feature embeddings by using million-scale\nin-the-wild datasets and margin-based softmax loss is the current\nstate-of-the-art approach for face recognition. However, the memory and\ncomputing cost of the Fully Connected (FC) layer linearly scales up to the\nnumber of identities in the training set. Besides, the large-scale training\ndata inevitably suffers from inter-class conflict and long-tailed distribution.\nIn this paper, we propose a sparsely updating variant of the FC layer, named\nPartial FC (PFC). In each iteration, positive class centers and a random subset\nof negative class centers are selected to compute the margin-based softmax\nloss. All class centers are still maintained throughout the whole training\nprocess, but only a subset is selected and updated in each iteration.\nTherefore, the computing requirement, the probability of inter-class conflict,\nand the frequency of passive update on tail class centers, are dramatically\nreduced. Extensive experiments across different training data and backbones\n(e.g. CNN and ViT) confirm the effectiveness, robustness and efficiency of the\nproposed PFC. The source code is available at\n\\https://github.com/deepinsight/insightface/tree/master/recognition.",
    "descriptor": "\nComments: 8 pages, 16 figures\n",
    "authors": [
      "Xiang An",
      "Jiankang Deng",
      "Jia Guo",
      "Ziyong Feng",
      "Xuhan Zhu",
      "Jing Yang",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15565"
  },
  {
    "id": "arXiv:2203.15566",
    "title": "Core Risk Minimization using Salient ImageNet",
    "abstract": "Deep neural networks can be unreliable in the real world especially when they\nheavily use spurious features for their predictions. Recently, Singla & Feizi\n(2022) introduced the Salient Imagenet dataset by annotating and localizing\ncore and spurious features of ~52k samples from 232 classes of Imagenet. While\nthis dataset is useful for evaluating the reliance of pretrained models on\nspurious features, its small size limits its usefulness for training models. In\nthis work, we first introduce the Salient Imagenet-1M dataset with more than 1\nmillion soft masks localizing core and spurious features for all 1000 Imagenet\nclasses. Using this dataset, we first evaluate the reliance of several Imagenet\npretrained models (42 total) on spurious features and observe that: (i)\ntransformers are more sensitive to spurious features compared to Convnets, (ii)\nzero-shot CLIP transformers are highly susceptible to spurious features. Next,\nwe introduce a new learning paradigm called Core Risk Minimization (CoRM) whose\nobjective ensures that the model predicts a class using its core features. We\nevaluate different computational approaches for solving CoRM and achieve\nsignificantly higher (+12%) core accuracy (accuracy when non-core regions\ncorrupted using noise) with no drop in clean accuracy compared to models\ntrained via Empirical Risk Minimization.",
    "descriptor": "",
    "authors": [
      "Sahil Singla",
      "Mazda Moayeri",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15566"
  },
  {
    "id": "arXiv:2203.15568",
    "title": "A Dataset for Speech Emotion Recognition in Greek Theatrical Plays",
    "abstract": "Machine learning methodologies can be adopted in cultural applications and\npropose new ways to distribute or even present the cultural content to the\npublic. For instance, speech analytics can be adopted to automatically generate\nsubtitles in theatrical plays, in order to (among other purposes) help people\nwith hearing loss. Apart from a typical speech-to-text transcription with\nAutomatic Speech Recognition (ASR), Speech Emotion Recognition (SER) can be\nused to automatically predict the underlying emotional content of speech\ndialogues in theatrical plays, and thus to provide a deeper understanding how\nthe actors utter their lines. However, real-world datasets from theatrical\nplays are not available in the literature. In this work we present GreThE, the\nGreek Theatrical Emotion dataset, a new publicly available data collection for\nspeech emotion recognition in Greek theatrical plays. The dataset contains\nutterances from various actors and plays, along with respective valence and\narousal annotations. Towards this end, multiple annotators have been asked to\nprovide their input for each speech recording and inter-annotator agreement is\ntaken into account in the final ground truth generation. In addition, we\ndiscuss the results of some indicative experiments that have been conducted\nwith machine and deep learning frameworks, using the dataset, along with some\nwidely used databases in the field of speech emotion recognition.",
    "descriptor": "",
    "authors": [
      "Maria Moutti",
      "Sofia Eleftheriou",
      "Panagiotis Koromilas",
      "Theodoros Giannakopoulos"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15568"
  },
  {
    "id": "arXiv:2203.15570",
    "title": "Fast and stable schemes for non-linear osmosis filtering",
    "abstract": "We consider a non-linear variant of the transport-diffusion osmosis model for\nsolving a variety of imaging problems such as shadow/soft-light removal and\ncompact data representation. The non-linear behaviour is encoded in terms of a\ngeneral scalar function g with suitable properties, which allows to balance the\ndiffusion intensity on the different regions of the image while preventing\nsmoothing artefacts. For the proposed model, conservation properties (intensity\nand non-negativity) are proved and a variational interpretation is showed for\nspecific choices of g. Upon suitable spatial discretisation, both an explicit\nand a semi-implicit iterative scheme are considered, for which convergence\nrestrictions and unconditional stability are proved, respectively. To validate\nthe proposed modelling and the computational speed of the numerical schemes\nconsidered, we report several results and comparisons for the problem of\nshadow/light-spot removal and compact data representation, showing that\nartefact-free and computationally efficient results are obtained in comparison\nto standard linear and anisotropic models, and state-of-the art approaches.",
    "descriptor": "\nComments: 25 pages, 14 figures\n",
    "authors": [
      "L.Calatroni",
      "S.Morigi",
      "S.Parisotto",
      "G.A.Recupero"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15570"
  },
  {
    "id": "arXiv:2203.15576",
    "title": "Subspace-based Representation and Learning for Phonotactic Spoken  Language Recognition",
    "abstract": "Phonotactic constraints can be employed to distinguish languages by\nrepresenting a speech utterance as a multinomial distribution or phone events.\nIn the present study, we propose a new learning mechanism based on\nsubspace-based representation, which can extract concealed phonotactic\nstructures from utterances, for language verification and dialect/accent\nidentification. The framework mainly involves two successive parts. The first\npart involves subspace construction. Specifically, it decodes each utterance\ninto a sequence of vectors filled with phone-posteriors and transforms the\nvector sequence into a linear orthogonal subspace based on low-rank matrix\nfactorization or dynamic linear modeling. The second part involves subspace\nlearning based on kernel machines, such as support vector machines and the\nnewly developed subspace-based neural networks (SNNs). The input layer of SNNs\nis specifically designed for the sample represented by subspaces. The topology\nensures that the same output can be derived from identical subspaces by\nmodifying the conventional feed-forward pass to fit the mathematical definition\nof subspace similarity. Evaluated on the \"General LR\" test of NIST LRE 2007,\nthe proposed method achieved up to 52%, 46%, 56%, and 27% relative reductions\nin equal error rates over the sequence-based PPR-LM, PPR-VSM, and PPR-IVEC\nmethods and the lattice-based PPR-LM method, respectively. Furthermore, on the\ndialect/accent identification task of NIST LRE 2009, the SNN-based system\nperformed better than the aforementioned four baseline methods.",
    "descriptor": "\nComments: Published in IEEE/ACM Trans. Audio, Speech, Lang. Process., 2020, vol. 28, pp. 3065-3079\n",
    "authors": [
      "Hung-Shin Lee",
      "Yu Tsao",
      "Shyh-Kang Jeng",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15576"
  },
  {
    "id": "arXiv:2203.15577",
    "title": "Understanding Code Snippets in Code Reviews: A Preliminary Study of the  OpenStack Community",
    "abstract": "Code review is a mature practice for software quality assurance in software\ndevelopment with which reviewers check the code that has been committed by\ndevelopers, and verify the quality of code. During the code review discussions,\nreviewers and developers might use code snippets to provide necessary\ninformation (e.g., suggestions or explanations). However, little is known about\nthe intentions and impacts of code snippets in code reviews. To this end, we\nconducted a preliminary study to investigate the nature of code snippets and\ntheir purposes in code reviews. We manually collected and checked 10,790 review\ncomments from the Nova and Neutron projects of the OpenStack community, and\nfinally obtained 626 review comments that contain code snippets for further\nanalysis. The results show that: (1) code snippets are not prevalently used in\ncode reviews, and most of the code snippets are provided by reviewers. (2) We\nidentified two high-level purposes of code snippets provided by reviewers\n(i.e., Suggestion and Citation) with six detailed purposes, among which,\nImproving Code Implementation is the most common purpose. (3) For the code\nsnippets in code reviews with the aim of suggestion, around 68.1% was accepted\nby developers. The results highlight promising research directions on using\ncode snippets in code reviews.",
    "descriptor": "\nComments: The 30th IEEE/ACM International Conference on Program Comprehension (ICPC)\n",
    "authors": [
      "Liming Fu",
      "Peng Liang",
      "Beiqi Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.15577"
  },
  {
    "id": "arXiv:2203.15578",
    "title": "Disentangling speech from surroundings in a neural audio codec",
    "abstract": "We present a method to separate speech signals from noisy environments in the\ncompressed domain of a neural audio codec. We introduce a new training\nprocedure that allows our model to produce structured encodings of audio\nwaveforms given by embedding vectors, where one part of the embedding vector\nrepresents the speech signal, and the rest represents the environment. We\nachieve this by partitioning the embeddings of different input waveforms and\ntraining the model to faithfully reconstruct audio from mixed partitions,\nthereby ensuring each partition encodes a separate audio attribute. As use\ncases, we demonstrate the separation of speech from background noise or from\nreverberation characteristics. Our method also allows for targeted adjustments\nof the audio output characteristics.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Ahmed Omran",
      "Neil Zeghidour",
      "Zal\u00e1n Borsos",
      "F\u00e9lix de Chaumont Quitry",
      "Malcolm Slaney",
      "Marco Tagliasacchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15578"
  },
  {
    "id": "arXiv:2203.15580",
    "title": "Learning a Structured Latent Space for Unsupervised Point Cloud  Completion",
    "abstract": "Unsupervised point cloud completion aims at estimating the corresponding\ncomplete point cloud of a partial point cloud in an unpaired manner. It is a\ncrucial but challenging problem since there is no paired partial-complete\nsupervision that can be exploited directly. In this work, we propose a novel\nframework, which learns a unified and structured latent space that encoding\nboth partial and complete point clouds. Specifically, we map a series of\nrelated partial point clouds into multiple complete shape and occlusion code\npairs and fuse the codes to obtain their representations in the unified latent\nspace. To enforce the learning of such a structured latent space, the proposed\nmethod adopts a series of constraints including structured ranking\nregularization, latent code swapping constraint, and distribution supervision\non the related partial point clouds. By establishing such a unified and\nstructured latent space, better partial-complete geometry consistency and shape\ncompletion accuracy can be achieved. Extensive experiments show that our\nproposed method consistently outperforms state-of-the-art unsupervised methods\non both synthetic ShapeNet and real-world KITTI, ScanNet, and Matterport3D\ndatasets.",
    "descriptor": "\nComments: 8 pages, 5 figures, cvpr2022\n",
    "authors": [
      "Yingjie Cai",
      "Kwan-Yee Lin",
      "Chao Zhang",
      "Qiang Wang",
      "Xiaogang Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15580"
  },
  {
    "id": "arXiv:2203.15586",
    "title": "Discovering Governing Equations by Machine Learning implemented with  Invariance",
    "abstract": "The partial differential equation (PDE) plays a significantly important role\nin many fields of science and engineering. The conventional case of the\nderivation of PDE mainly relies on first principles and empirical observation.\nHowever, the development of machine learning technology allows us to mine\npotential control equations from the massive amounts of stored data in a fresh\nway. Although there has been considerable progress in the data-driven discovery\nof PDE, the extant literature mostly focuses on the improvements of discovery\nmethods, without substantial breakthroughs in the discovery process itself,\nincluding the principles for the construction of candidates and how to\nincorporate physical priors. In this paper, through rigorous derivation of\nformulas, novel physically enhanced machining learning discovery methods for\ncontrol equations: GSNN (Galileo Symbolic Neural Network) and LSNN (Lorentz\nSymbolic Neural Network) are firstly proposed based on Galileo invariance and\nLorentz invariance respectively, setting forth guidelines for building the\ncandidates of discovering equations. The adoption of mandatory embedding of\nphysical constraints is fundamentally different from PINN in the form of the\nloss function, thus ensuring that the designed Neural Network strictly obeys\nthe physical prior of invariance and enhancing the interpretability of the\nnetwork. By comparing the results with PDE-NET in numerical experiments of\nBurgers equation and Sine-Gordon equation, it shows that the method presented\nin this study has better accuracy, parsimony, and interpretability.",
    "descriptor": "",
    "authors": [
      "Chao Chen",
      "Xiaowei Jin",
      "Hui Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15586"
  },
  {
    "id": "arXiv:2203.15587",
    "title": "RGB-D Neural Radiance Fields: Local Sampling for Faster Training",
    "abstract": "Learning a 3D representation of a scene has been a challenging problem for\ndecades in computer vision. Recent advances in implicit neural representation\nfrom images using neural radiance fields(NeRF) have shown promising results.\nSome of the limitations of previous NeRF based methods include longer training\ntime, and inaccurate underlying geometry. The proposed method takes advantage\nof RGB-D data to reduce training time by leveraging depth sensing to improve\nlocal sampling. This paper proposes a depth-guided local sampling strategy and\na smaller neural network architecture to achieve faster training time without\ncompromising quality.",
    "descriptor": "",
    "authors": [
      "Arnab Dey",
      "Andrew I. Comport"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15587"
  },
  {
    "id": "arXiv:2203.15588",
    "title": "Deep Multi-modal Fusion of Image and Non-image Data in Disease Diagnosis  and Prognosis: A Review",
    "abstract": "The rapid development of diagnostic technologies in healthcare is leading to\nhigher requirements for physicians to handle and integrate the heterogeneous,\nyet complementary data that are produced during routine practice. For instance,\nthe personalized diagnosis and treatment planning for a single cancer patient\nrelies on the various images (e.g., radiological, pathological, and camera\nimages) and non-image data (e.g., clinical data and genomic data). However,\nsuch decision-making procedures can be subjective, qualitative, and have large\ninter-subject variabilities. With the recent advances in multi-modal deep\nlearning technologies, an increasingly large number of efforts have been\ndevoted to a key question: how do we extract and aggregate multi-modal\ninformation to ultimately provide more objective, quantitative computer-aided\nclinical decision making? This paper reviews the recent studies on dealing with\nsuch a question. Briefly, this review will include the (1) overview of current\nmulti-modal learning workflows, (2) summarization of multi-modal fusion\nmethods, (3) discussion of the performance, (4) applications in disease\ndiagnosis and prognosis, and (5) challenges and future directions.",
    "descriptor": "",
    "authors": [
      "Can Cui",
      "Haichun Yang",
      "Yaohong Wang",
      "Shilin Zhao",
      "Zuhayr Asad",
      "Lori A. Coburn",
      "Keith T. Wilson",
      "Bennett A. Landman",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15588"
  },
  {
    "id": "arXiv:2203.15589",
    "title": "On Kernelized Multi-Armed Bandits with Constraints",
    "abstract": "We study a stochastic bandit problem with a general unknown reward function\nand a general unknown constraint function. Both functions can be non-linear\n(even non-convex) and are assumed to lie in a reproducing kernel Hilbert space\n(RKHS) with a bounded norm. This kernelized bandit setup strictly generalizes\nstandard multi-armed bandits and linear bandits. In contrast to safety-type\nhard constraints studied in prior works, we consider soft constraints that may\nbe violated in any round as long as the cumulative violations are small, which\nis motivated by various practical applications. Our ultimate goal is to study\nhow to utilize the nature of soft constraints to attain a finer\ncomplexity-regret-constraint trade-off in the kernelized bandit setting. To\nthis end, leveraging primal-dual optimization, we propose a general framework\nfor both algorithm design and performance analysis. This framework builds upon\na novel sufficient condition, which not only is satisfied under general\nexploration strategies, including \\emph{upper confidence bound} (UCB),\n\\emph{Thompson sampling} (TS), and new ones based on \\emph{random exploration},\nbut also enables a unified analysis for showing both sublinear regret and\nsublinear or even zero constraint violation. We demonstrate the superior\nperformance of our proposed algorithms via numerical experiments based on both\nsynthetic and real-world datasets. Along the way, we also make the first\ndetailed comparison between two popular methods for analyzing constrained\nbandits and Markov decision processes (MDPs) by discussing the key difference\nand some subtleties in the analysis, which could be of independent interest to\nthe communities.",
    "descriptor": "",
    "authors": [
      "Xingyu Zhou",
      "Bo Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15589"
  },
  {
    "id": "arXiv:2203.15590",
    "title": "Heuristic-based Inter-training to Improve Few-shot Multi-perspective  Dialog Summarization",
    "abstract": "Many organizations require their customer-care agents to manually summarize\ntheir conversations with customers. These summaries are vital for decision\nmaking purposes of the organizations. The perspective of the summary that is\nrequired to be created depends on the application of the summaries. With this\nwork, we study the multi-perspective summarization of customer-care\nconversations between support agents and customers. We observe that there are\ndifferent heuristics that are associated with summaries of different\nperspectives, and explore these heuristics to create weak-labeled data for\nintermediate training of the models before fine-tuning with scarce human\nannotated summaries. Most importantly, we show that our approach supports\nmodels to generate multi-perspective summaries with a very small amount of\nannotated data. For example, our approach achieves 94\\% of the performance\n(Rouge-2) of a model trained with the original data, by training only with 7\\%\nof the original data.",
    "descriptor": "",
    "authors": [
      "Benjamin Sznajder",
      "Chulaka Gunasekara",
      "Guy Lev",
      "Sachin Joshi",
      "Eyal Shnarch",
      "Noam Slonim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.15590"
  },
  {
    "id": "arXiv:2203.15591",
    "title": "Earnings-22: A Practical Benchmark for Accents in the Wild",
    "abstract": "Modern automatic speech recognition (ASR) systems have achieved superhuman\nWord Error Rate (WER) on many common corpora despite lacking adequate\nperformance on speech in the wild. Beyond that, there is a lack of real-world,\naccented corpora to properly benchmark academic and commercial models. To\nensure this type of speech is represented in ASR benchmarking, we present\nEarnings-22, a 125 file, 119 hour corpus of English-language earnings calls\ngathered from global companies. We run a comparison across 4 commercial models\nshowing the variation in performance when taking country of origin into\nconsideration. Looking at hypothesis transcriptions, we explore errors common\nto all ASR systems tested. By examining Individual Word Error Rate (IWER), we\nfind that key speech features impact model performance more for certain accents\nthan others. Earnings-22 provides a free-to-use benchmark of real-world,\naccented audio to bridge academic and industrial research.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Miguel Del Rio",
      "Peter Ha",
      "Quinten McNamara",
      "Corey Miller",
      "Shipra Chandra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.15591"
  },
  {
    "id": "arXiv:2203.15592",
    "title": "Demystifying Software Release Note Issues on GitHub",
    "abstract": "Release notes (RNs) summarize main changes between two consecutive software\nversions and serve as a central source of information when users upgrade\nsoftware. While producing high quality RNs can be hard and poses a variety of\nchallenges to developers, a comprehensive empirical understanding of these\nchallenges is still lacking. In this paper, we bridge this knowledge gap by\nmanually analyzing 1,731 latest GitHub issues to build a comprehensive taxonomy\nof RN issues with four dimensions: Content, Presentation, Accessibility, and\nProduction. Among these issues, nearly half (48.47%) of them focus on\nProduction; Content, Accessibility, and Presentation take 25.61%, 17.65%, and\n8.27%, respectively. We find that: 1) RN producers are more likely to miss\ninformation than to include incorrect information, especially for breaking\nchanges; 2) improper layout may bury important information and confuse users;\n3) many users find RNs inaccessible due to link deterioration, lack of\nnotification, and obfuscate RN locations; 4) automating and regulating RN\nproduction remains challenging despite the great needs of RN producers. Our\ntaxonomy not only pictures a roadmap to improve RN production in practice but\nalso reveals interesting future research directions for automating RN\nproduction.",
    "descriptor": "\nComments: Accepted for IEEE/ACM 30th International Conference on Program Comprehension (ICPC 2022)\n",
    "authors": [
      "Jianyu Wu",
      "Hao He",
      "Wenxin Xiao",
      "Kai Gao",
      "Minghui Zhou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.15592"
  },
  {
    "id": "arXiv:2203.15595",
    "title": "Cross-Media Scientific Research Achievements Retrieval Based on Deep  Language Model",
    "abstract": "Science and technology big data contain a lot of cross-media\ninformation.There are images and texts in the scientific paper.The s ingle\nmodal search method cannot well meet the needs of scientific researchers.This\npaper proposes a cross-media scientific research achievements retrieval method\nbased on deep language model (CARDL).It achieves a unified cross-media semantic\nrepresentation by learning the semantic association between different modal\ndata, and is applied to the generation of text semantic vector of scientific\nresearch achievements, and then cross-media retrieval is realized through\nsemantic similarity matching between different modal data.Experimental results\nshow that the proposed CARDL method achieves better cross-modal retrieval\nperformance than existing methods. Key words science and technology big data ;\ncross-media retrieval; cross-media semantic association learning; deep language\nmodel; semantic similarity",
    "descriptor": "",
    "authors": [
      "Benzhi Wang",
      "Meiyu Liang",
      "Feifei Kou",
      "Mingying Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15595"
  },
  {
    "id": "arXiv:2203.15597",
    "title": "Sparse Pose Graph Optimization in Cycle Space",
    "abstract": "The state-of-the-art modern pose-graph optimization (PGO) systems are vertex\nbased. In this context the number of variables might be high, albeit the number\nof cycles in the graph (loop closures) is relatively low. For sparse problems\nparticularly, the cycle space has a significantly smaller dimension than the\nnumber of vertices. By exploiting this observation, in this paper we propose an\nalternative solution to PGO, that directly exploits the cycle space. We\ncharacterize the topology of the graph as a cycle matrix, and re-parameterize\nthe problem using relative poses, which are further constrained by a cycle\nbasis of the graph. We show that by using a minimum cycle basis, the\ncycle-based approach has superior convergence properties against its\nvertex-based counterpart, in terms of convergence speed and convergence to the\nglobal minimum. For sparse graphs, our cycle-based approach is also more time\nefficient than the vertex-based. As an additional contribution of this work we\npresent an effective algorithm to compute the minimum cycle basis. Albeit known\nin computer science, we believe that this algorithm is not familiar to the\nrobotics community. All the claims are validated by experiments on both\nstandard benchmarks and simulated datasets. To foster the reproduction of the\nresults, we provide a complete open-source C++ implementation (Code:\n\\url{https://bitbucket.org/FangBai/cycleBasedPGO) of our approach.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Fang Bai",
      "Teresa Vidal-Calleja",
      "Giorgio Grisetti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.15597"
  },
  {
    "id": "arXiv:2203.15601",
    "title": "Photographic Visualization of Weather Forecasts with Generative  Adversarial Networks",
    "abstract": "Outdoor webcam images are an information-dense yet accessible visualization\nof past and present weather conditions, and are consulted by meteorologists and\nthe general public alike. Weather forecasts, however, are still communicated as\ntext, pictograms or charts. We therefore introduce a novel method that uses\nphotographic images to also visualize future weather conditions.\nThis is challenging, because photographic visualizations of weather forecasts\nshould look real, be free of obvious artifacts, and should match the predicted\nweather conditions. The transition from observation to forecast should be\nseamless, and there should be visual continuity between images for consecutive\nlead times. We use conditional Generative Adversarial Networks to synthesize\nsuch visualizations. The generator network, conditioned on the analysis and the\nforecasting state of the numerical weather prediction (NWP) model, transforms\nthe present camera image into the future. The discriminator network judges\nwhether a given image is the real image of the future, or whether it has been\nsynthesized. Training the two networks against each other results in a\nvisualization method that scores well on all four evaluation criteria.\nWe present results for three camera sites across Switzerland that differ in\nclimatology and terrain. We show that users find it challenging to distinguish\nreal from generated images, performing not much better than if they guessed\nrandomly. The generated images match the atmospheric, ground and illumination\nconditions of the COSMO-1 NWP model forecast in at least 89 % of the examined\ncases. Nowcasting sequences of generated images achieve a seamless transition\nfrom observation to forecast and attain visual continuity.",
    "descriptor": "",
    "authors": [
      "Christian Sigg",
      "Flavia Cavallaro",
      "Tobias G\u00fcnther",
      "Martin R. Oswald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.15601"
  },
  {
    "id": "arXiv:2203.15607",
    "title": "Typical Error Exponents: A Dual Domain Derivation",
    "abstract": "This paper shows that the probability that the error exponent of a given code\nrandomly generated from a pairwise independent ensemble being smaller than a\nlower bound on the typical random-coding exponent tends to zero as the codeword\nlength tends to infinity. This lower bound is known to be tight for i.i.d.\nensembles over the binary symmetric channel and for constant-composition codes\nover memoryless channels. Our results recover both as special cases and remain\nvalid for arbitrary alphabets, arbitrary channels -- for example finite-state\nchannels with memory -- and arbitrary pairwise-independent ensembles. We\nspecialize our results to the i.i.d., constant-composition and cost-constrained\nensembles over discrete memoryless channels and to ensembles over finite-state\nchannels.",
    "descriptor": "\nComments: 29 pages, 1 figure\n",
    "authors": [
      "Giuseppe Cocco",
      "Albert Guill\u00e9n i F\u00e0bregas",
      "Josep Font-Segura"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.15607"
  },
  {
    "id": "arXiv:2203.15609",
    "title": "Locality Matters: A Locality-Biased Linear Attention for Automatic  Speech Recognition",
    "abstract": "Conformer has shown a great success in automatic speech recognition (ASR) on\nmany public benchmarks. One of its crucial drawbacks is the quadratic\ntime-space complexity with respect to the input sequence length, which\nprohibits the model to scale-up as well as process longer input audio\nsequences. To solve this issue, numerous linear attention methods have been\nproposed. However, these methods often have limited performance on ASR as they\ntreat tokens equally in modeling, neglecting the fact that the neighbouring\ntokens are often more connected than the distanced tokens. In this paper, we\ntake this fact into account and propose a new locality-biased linear attention\nfor Conformer. It not only achieves higher accuracy than the vanilla Conformer,\nbut also enjoys linear space-time computational complexity. To be specific, we\nreplace the softmax attention with a locality-biased linear attention (LBLA)\nmechanism in Conformer blocks. The LBLA contains a kernel function to ensure\nthe linear complexities and a cosine reweighing matrix to impose more weights\non neighbouring tokens. Extensive experiments on the LibriSpeech corpus show\nthat by introducing this locality bias to the Conformer, our method achieves a\nlower word error rate with more than 22% inference speed.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to interspeech 2022\n",
    "authors": [
      "Jingyu Sun",
      "Guiping Zhong",
      "Dinghao Zhou",
      "Baoxiang Li",
      "Yiran Zhong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15609"
  },
  {
    "id": "arXiv:2203.15612",
    "title": "Three-Dimensional Spectrum Occupancy Measurement using UAV: Performance  Analysis and Algorithm Design",
    "abstract": "Spectrum sharing, as an approach to significantly improve spectrum efficiency\nin the era of 6th generation mobile networks (6G), has attracted extensive\nattention. Radio Environment Map (REM) based low-complexity spectrum sharing is\nwidely studied where the spectrum occupancy measurement (SOM) is vital to\nconstruct REM. The SOM in three-dimensional (3D) space is becoming increasingly\nessential to support the spectrum sharing with space-air-ground integrated\nnetwork being a great momentum of 6G. In this paper, we analyze the performance\nof 3D SOM to further study the tradeoff between accuracy and efficiency in 3D\nSOM. We discover that the error of 3D SOM is related with the area of the\nboundary surfaces of licensed networks, the number of discretized cubes, and\nthe length of the edge of 3D space. Moreover, we design a fast and accurate 3D\nSOM algorithm that utilizes unmanned aerial vehicle (UAV) to measure the\nspectrum occupancy considering the path planning of UAV, which improves the\nmeasurement efficiency by requiring less measurement time and flight time of\nthe UAV for satisfactory performance. The theoretical results obtained in this\npaper reveal the essential dependencies that describe the 3D SOM methodology,\nand the proposed algorithm is beneficial to improve the efficiency of 3D SOM.\nIt is noted that the theoretical results and algorithm in this paper may\nprovide a guideline for more areas such as spectrum monitoring, spectrum\nmeasurement, network measurement, planning, etc.",
    "descriptor": "",
    "authors": [
      "Zhiqing Wei",
      "Rubing Yao",
      "Jie Kang",
      "Xu Chen",
      "Huici Wu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15612"
  },
  {
    "id": "arXiv:2203.15613",
    "title": "Dynamic Latency for CTC-Based Streaming Automatic Speech Recognition  With Emformer",
    "abstract": "An inferior performance of the streaming automatic speech recognition models\nversus non-streaming model is frequently seen due to the absence of future\ncontext. In order to improve the performance of the streaming model and reduce\nthe computational complexity, a frame-level model using efficient augment\nmemory transformer block and dynamic latency training method is employed for\nstreaming automatic speech recognition in this paper. The long-range history\ncontext is stored into the augment memory bank as a complement to the limited\nhistory context used in the encoder. Key and value are cached by a cache\nmechanism and reused for next chunk to reduce computation. Afterwards, a\ndynamic latency training method is proposed to obtain better performance and\nsupport low and high latency inference simultaneously. Our experiments are\nconducted on benchmark 960h LibriSpeech data set. With an average latency of\n640ms, our model achieves a relative WER reduction of 6.0% on test-clean and\n3.0% on test-other versus the truncate chunk-wise Transformer.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to interspeech 2022\n",
    "authors": [
      "Jingyu Sun",
      "Guiping Zhong",
      "Dinghao Zhou",
      "Baoxiang Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15613"
  },
  {
    "id": "arXiv:2203.15614",
    "title": "Integrate Lattice-Free MMI into End-to-End Speech Recognition",
    "abstract": "In automatic speech recognition (ASR) research, discriminative criteria have\nachieved superior performance in DNN-HMM systems. Given this success, the\nadoption of discriminative criteria is promising to boost the performance of\nend-to-end (E2E) ASR systems. With this motivation, previous works have\nintroduced the minimum Bayesian risk (MBR, one of the discriminative criteria)\ninto E2E ASR systems. However, the effectiveness and efficiency of the\nMBR-based methods are compromised: the MBR criterion is only used in system\ntraining, which creates a mismatch between training and decoding; the\non-the-fly decoding process in MBR-based methods results in the need for\npre-trained models and slow training speeds. To this end, novel algorithms are\nproposed in this work to integrate another widely used discriminative\ncriterion, lattice-free maximum mutual information (LF-MMI), into E2E ASR\nsystems not only in the training stage but also in the decoding process. The\nproposed LF-MMI training and decoding methods show their effectiveness on two\nwidely used E2E frameworks: Attention-Based Encoder-Decoders (AEDs) and Neural\nTransducers (NTs). Compared with MBR-based methods, the proposed LF-MMI method:\nmaintains the consistency between training and decoding; eschews the on-the-fly\ndecoding process; trains from randomly initialized models with superior\ntraining efficiency. Experiments suggest that the LF-MMI method outperforms its\nMBR counterparts and consistently leads to statistically significant\nperformance improvements on various frameworks and datasets from 30 hours to\n14.3k hours. The proposed method achieves state-of-the-art (SOTA) results on\nAishell-1 (CER 4.10%) and Aishell-2 (CER 5.02%) datasets. Code is released.",
    "descriptor": "",
    "authors": [
      "Jinchuan Tian",
      "Jianwei Yu",
      "Chao Weng",
      "Yuexian Zou",
      "Dong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15614"
  },
  {
    "id": "arXiv:2203.15618",
    "title": "Exploring Body Texture from mmW Images for Person Recognition",
    "abstract": "Imaging using millimeter waves (mmWs) has many advantages including the\nability to penetrate obscurants such as clothes and polymers. After having\nexplored shape information retrieved from mmW images for person recognition, in\nthis work we aim to gain some insight about the potential of using mmW texture\ninformation for the same task, considering not only the mmW face, but also mmW\ntorso and mmW wholebody. We report experimental results using the mmW TNO\ndatabase consisting of 50 individuals based on both hand-crafted and learned\nfeatures from Alexnet and VGG-face pretrained Convolutional Neural Networks\n(CNN) models. First, we analyze the individual performance of three mmW body\nparts, concluding that: i) mmW torso region is more discriminative than mmW\nface and the whole body, ii) CNN features produce better results compared to\nhand-crafted features on mmW faces and the entire body, and iii) hand-crafted\nfeatures slightly outperform CNN features on mmW torso. In the second part of\nthis work, we analyze different multi-algorithmic and multi-modal techniques,\nincluding a novel CNN-based fusion technique, improving verification results to\n2% EER and identification rank-1 results up to 99%. Comparative analyses with\nmmW body shape information and face recognition in the visible and NIR spectral\nbands are also reported.",
    "descriptor": "\nComments: Published at IEEE Transactions on Biometrics, Behavior, and Identity Science\n",
    "authors": [
      "E. Gonzalez-Sosa",
      "J. Fierrez",
      "R. Vera-Rodriguez",
      "F. Alonso-Fernandez",
      "V. M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15618"
  },
  {
    "id": "arXiv:2203.15619",
    "title": "Classification of Hyperspectral Images Using SVM with Shape-adaptive  Reconstruction and Smoothed Total Variation",
    "abstract": "In this work, a novel algorithm called SVM with Shape-adaptive Reconstruction\nand Smoothed Total Variation (SaR-SVM-STV) is introduced to classify\nhyperspectral images, which makes full use of spatial and spectral information.\nThe Shape-adaptive Reconstruction (SaR) is introduced to preprocess each pixel\nbased on the Pearson Correlation between pixels in its shape-adaptive (SA)\nregion. Support Vector Machines (SVMs) are trained to estimate the pixel-wise\nprobability maps of each class. Then the Smoothed Total Variation (STV) model\nis applied to denoise and generate the final classification map. Experiments\nshow that SaR-SVM-STV outperforms the SVM-STV method with a few training\nlabels, demonstrating the significance of reconstructing hyperspectral images\nbefore classification.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Ruoning Li",
      "Kangning Cui",
      "Raymond H. Chan",
      "Robert J. Plemmons"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15619"
  },
  {
    "id": "arXiv:2203.15625",
    "title": "PoseTriplet: Co-evolving 3D Human Pose Estimation, Imitation, and  Hallucination under Self-supervision",
    "abstract": "Existing self-supervised 3D human pose estimation schemes have largely relied\non weak supervisions like consistency loss to guide the learning, which,\ninevitably, leads to inferior results in real-world scenarios with unseen\nposes. In this paper, we propose a novel self-supervised approach that allows\nus to explicitly generate 2D-3D pose pairs for augmenting supervision, through\na self-enhancing dual-loop learning framework. This is made possible via\nintroducing a reinforcement-learning-based imitator, which is learned jointly\nwith a pose estimator alongside a pose hallucinator; the three components form\ntwo loops during the training process, complementing and strengthening one\nanother. Specifically, the pose estimator transforms an input 2D pose sequence\nto a low-fidelity 3D output, which is then enhanced by the imitator that\nenforces physical constraints. The refined 3D poses are subsequently fed to the\nhallucinator for producing even more diverse data, which are, in turn,\nstrengthened by the imitator and further utilized to train the pose estimator.\nSuch a co-evolution scheme, in practice, enables training a pose estimator on\nself-generated motion data without relying on any given 3D data. Extensive\nexperiments across various benchmarks demonstrate that our approach yields\nencouraging results significantly outperforming the state of the art and, in\nsome cases, even on par with results of fully-supervised methods. Notably, it\nachieves 89.1% 3D PCK on MPI-INF-3DHP under self-supervised cross-dataset\nevaluation setup, improving upon the previous best self-supervised methods by\n8.6%. Code can be found at: https://github.com/Garfield-kh/PoseTriplet",
    "descriptor": "\nComments: CVPR 2022 Oral Paper, code available: this https URL\n",
    "authors": [
      "Kehong Gong",
      "Bingbing Li",
      "Jianfeng Zhang",
      "Tao Wang",
      "Jing Huang",
      "Michael Bi Mi",
      "Jiashi Feng",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15625"
  },
  {
    "id": "arXiv:2203.15627",
    "title": "Low Treewidth Embeddings of Planar and Minor-Free Metrics",
    "abstract": "Cohen-Addad, Filtser, Klein and Le [FOCS'20] constructed a stochastic\nembedding of minor-free graphs of diameter $D$ into graphs of treewidth\n$O_{\\epsilon}(\\log n)$ with expected additive distortion $+\\epsilon D$.\nCohen-Addad et al. then used the embedding to design the first quasi-polynomial\ntime approximation scheme (QPTAS) for the capacitated vehicle routing problem.\nFiltser and Le [STOC'21] used the embedding (in a different way) to design a\nQPTAS for the metric Baker's problems in minor-free graphs. In this work, we\ndevise a new embedding technique to improve the treewidth bound of Cohen-Addad\net al. exponentially to $O_{\\epsilon}(\\log\\log n)^2$. As a corollary, we obtain\nthe first efficient PTAS for the capacitated vehicle routing problem in\nminor-free graphs. We also significantly improve the running time of the QPTAS\nfor the metric Baker's problems in minor-free graphs from\n$n^{O_{\\epsilon}(\\log(n))}$ to $n^{O_{\\epsilon}(\\log\\log(n))^3}$.\nApplying our embedding technique to planar graphs, we obtain a deterministic\nembedding of planar graphs of diameter $D$ into graphs of treewidth\n$O((\\log\\log n)^2)/\\epsilon)$ and additive distortion $+\\epsilon D$ that can be\nconstructed in nearly linear time. Important corollaries of our result include\na bicriteria PTAS for metric Baker's problems and a PTAS for the vehicle\nrouting problem with bounded capacity in planar graphs, both run in\nalmost-linear time. The running time of our algorithms is significantly better\nthan previous algorithms that require quadratic time.\nA key idea in our embedding is the construction of an (exact) emulator for\ntree metrics with treewidth $O(\\log\\log n)$ and hop-diameter $O(\\log \\log n)$.\nThis result may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Arnold Filtser",
      "Hung Le"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.15627"
  },
  {
    "id": "arXiv:2203.15628",
    "title": "Exploring Opportunities in Usable Hazard Analysis Processes for AI  Engineering",
    "abstract": "Embedding artificial intelligence into systems introduces significant\nchallenges to modern engineering practices. Hazard analysis tools and processes\nhave not yet been adequately adapted to the new paradigm. This paper describes\ninitial research and findings regarding current practices in AI-related hazard\nanalysis and on the tools used to conduct this work. Our goal with this initial\nresearch is to better understand the needs of practitioners and the emerging\nchallenges of considering hazards and risks for AI-enabled products and\nservices. Our primary research question is: Can we develop new structured\nthinking methods and systems engineering tools to support effective and\nengaging ways for preemptively considering failure modes in AI systems? The\npreliminary findings from our review of the literature and interviews with\npractitioners highlight various challenges around integrating hazard analysis\ninto modern AI development processes and suggest opportunities for exploration\nof usable, human-centered hazard analysis tools.",
    "descriptor": "\nComments: 8 pages, Presented at 2022 AAAI Spring Symposium Series Workshop on AI Engineering: Creating Scalable, Human-Centered and Robust AI Systems\n",
    "authors": [
      "Nikolas Martelaro",
      "Carol J. Smith",
      "Tamara Zilovic"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.15628"
  },
  {
    "id": "arXiv:2203.15629",
    "title": "Stochastic Conservative Contextual Linear Bandits",
    "abstract": "Many physical systems have underlying safety considerations that require that\nthe strategy deployed ensures the satisfaction of a set of constraints.\nFurther, often we have only partial information on the state of the system. We\nstudy the problem of safe real-time decision making under uncertainty. In this\npaper, we formulate a conservative stochastic contextual bandit formulation for\nreal-time decision making when an adversary chooses a distribution on the set\nof possible contexts and the learner is subject to certain safety/performance\nconstraints. The learner observes only the context distribution and the exact\ncontext is unknown, and the goal is to develop an algorithm that selects a\nsequence of optimal actions to maximize the cumulative reward without violating\nthe safety constraints at any time step. By leveraging the UCB algorithm for\nthis setting, we propose a conservative linear UCB algorithm for stochastic\nbandits with context distribution. We prove an upper bound on the regret of the\nalgorithm and show that it can be decomposed into three terms: (i) an upper\nbound for the regret of the standard linear UCB algorithm, (ii) a constant term\n(independent of time horizon) that accounts for the loss of being conservative\nin order to satisfy the safety constraint, and (ii) a constant term\n(independent of time horizon) that accounts for the loss for the contexts being\nunknown and only the distribution being known. To validate the performance of\nour approach we perform extensive simulations on synthetic data and on\nreal-world maize data collected through the Genomes to Fields (G2F) initiative.",
    "descriptor": "",
    "authors": [
      "Jiabin Lin",
      "Xian Yeow Lee",
      "Talukder Jubery",
      "Shana Moothedath",
      "Soumik Sarkar",
      "Baskar Ganapathysubramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15629"
  },
  {
    "id": "arXiv:2203.15630",
    "title": "Adaptive Hermite Spectral Methods in Unbounded Domains",
    "abstract": "Recently, new adaptive techniques were developed that greatly improved the\nefficiency of solving PDEs using spectral methods. These adaptive spectral\ntechniques are especially suited for accurately solving problems in unbounded\ndomains and require the monitoring and dynamic adjustment of three key tunable\nparameters: the scaling factor, the displacement of the basis functions, and\nthe spectral expansion order. There have been few analyses of numerical methods\nfor unbounded domain problems. Specifically, there is no analysis of adaptive\nspectral methods to provide insight into how to increase efficiency and\naccuracy through dynamical adjustment of parameters. In this paper, we perform\nthe first numerical analysis of the adaptive spectral method using generalized\nHermite functions defined on the whole line. We investigate how the\nimplementation of the adaptive spectral methods affects numerical results,\nthereby providing guidelines for the proper tuning of parameters. Finally, we\nfurther improve performance by extending the adaptive methods to allow\nbidirectional basis function translation.",
    "descriptor": "\nComments: 24 pages, 5 figures\n",
    "authors": [
      "Tom Chou",
      "Sihong Shao",
      "Mingtao Xia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15630"
  },
  {
    "id": "arXiv:2203.15633",
    "title": "Lenses for Composable Servers",
    "abstract": "We implement the semantics of server operations using parameterised lenses.\nThey allow us to define endpoints and extend them using classical lens\ncomposition. The parameterised nature of lenses models state updates while the\nlens laws mimic properties expected from HTTP.\nThis first approach to server development is extended to use dependent\nparameterised lenses. An upgrade necessary to model not only endpoints, but\nentire servers, unlocking the ability to compose them together.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Andre Videla",
      "Matteo Capucci"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.15633"
  },
  {
    "id": "arXiv:2203.15636",
    "title": "Diffusion Models for Counterfactual Explanations",
    "abstract": "Counterfactual explanations have shown promising results as a post-hoc\nframework to make image classifiers more explainable. In this paper, we propose\nDiME, a method allowing the generation of counterfactual images using the\nrecent diffusion models. By leveraging the guided generative diffusion process,\nour proposed methodology shows how to use the gradients of the target\nclassifier to generate counterfactual explanations of input instances. Further,\nwe analyze current approaches to evaluate spurious correlations and extend the\nevaluation measurements by proposing a new metric: Correlation Difference. Our\nexperimental validations show that the proposed algorithm surpasses previous\nState-of-the-Art results on 5 out of 6 metrics on CelebA.",
    "descriptor": "",
    "authors": [
      "Guillaume Jeanneret",
      "Lo\u00efc Simon",
      "Fr\u00e9d\u00e9ric Jurie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15636"
  },
  {
    "id": "arXiv:2203.15638",
    "title": "NL-FCOS: Improving FCOS through Non-Local Modules for Object Detection",
    "abstract": "During the last years, we have seen significant advances in the object\ndetection task, mainly due to the outperforming results of convolutional neural\nnetworks. In this vein, anchor-based models have achieved the best results.\nHowever, these models require prior information about the aspect and scales of\ntarget objects, needing more hyperparameters to fit. In addition, using anchors\nto fit bounding boxes seems far from how our visual system does the same visual\ntask. Instead, our visual system uses the interactions of different scene parts\nto semantically identify objects, called perceptual grouping. An object\ndetection methodology closer to the natural model is anchor-free detection,\nwhere models like FCOS or Centernet have shown competitive results, but these\nhave not yet exploited the concept of perceptual grouping. Therefore, to\nincrease the effectiveness of anchor-free models keeping the inference time\nlow, we propose to add non-local attention (NL modules) modules to boost the\nfeature map of the underlying backbone. NL modules implement the perceptual\ngrouping mechanism, allowing receptive fields to cooperate in visual\nrepresentation learning. We show that non-local modules combined with an FCOS\nhead (NL-FCOS) are practical and efficient. Thus, we establish state-of-the-art\nperformance in clothing detection and handwritten amount recognition problems.",
    "descriptor": "",
    "authors": [
      "Lukas Pavez",
      "Jose M. Saavedra Rondo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15638"
  },
  {
    "id": "arXiv:2203.15640",
    "title": "Synthesis and Execution of Communicative Robotic Movements with  Generative Adversarial Networks",
    "abstract": "Object manipulation is a natural activity we perform every day. How humans\nhandle objects can communicate not only the willfulness of the acting, or key\naspects of the context where we operate, but also the properties of the objects\ninvolved, without any need for explicit verbal description. Since human\nintelligence comprises the ability to read the context, allowing robots to\nperform actions that intuitively convey this kind of information would greatly\nfacilitate collaboration. In this work, we focus on how to transfer on two\ndifferent robotic platforms the same kinematics modulation that humans adopt\nwhen manipulating delicate objects, aiming to endow robots with the capability\nto show carefulness in their movements. We choose to modulate the velocity\nprofile adopted by the robots' end-effector, inspired by what humans do when\ntransporting objects with different characteristics. We exploit a novel\nGenerative Adversarial Network architecture, trained with human kinematics\nexamples, to generalize over them and generate new and meaningful velocity\nprofiles, either associated with careful or not careful attitudes. This\napproach would allow next generation robots to select the most appropriate\nstyle of movement, depending on the perceived context, and autonomously\ngenerate their motor action execution.",
    "descriptor": "\nComments: Submitted to the Special Issue on Emerging Topics on Development and Learning, IEEE TCDS. Unpublished, review process ongoing. Luca Garello and Linda Lastrico contributed equally to this work, hence they share the first name\n",
    "authors": [
      "Linda Lastrico",
      "Luca Garello",
      "Alessandra Sciutti",
      "Nicoletta Noceti",
      "Fulvio Mastrogiovanni",
      "Francesco Rea"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15640"
  },
  {
    "id": "arXiv:2203.15643",
    "title": "Nix-TTS: An Incredibly Lightweight End-to-End Text-to-Speech Model via  Non End-to-End Distillation",
    "abstract": "We propose Nix-TTS, a lightweight neural TTS (Text-to-Speech) model achieved\nby applying knowledge distillation to a powerful yet large-sized generative TTS\nteacher model. Distilling a TTS model might sound unintuitive due to the\ngenerative and disjointed nature of TTS architectures, but pre-trained TTS\nmodels can be simplified into encoder and decoder structures, where the former\nencodes text into some latent representation and the latter decodes the latent\ninto speech data. We devise a framework to distill each component in a non\nend-to-end fashion. Nix-TTS is end-to-end (vocoder-free) with only 5.23M\nparameters or up to 82\\% reduction of the teacher model, it achieves over\n3.26$\\times$ and 8.36$\\times$ inference speedup on Intel-i7 CPU and Raspberry\nPi respectively, and still retains a fair voice naturalness and intelligibility\ncompared to the teacher model. We publicly release Nix-TTS pretrained models\nand audio samples in English (https://github.com/rendchevi/nix-tts).",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022. Associated materials can be seen in this https URL\n",
    "authors": [
      "Rendi Chevi",
      "Radityo Eko Prasojo",
      "Alham Fikri Aji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15643"
  },
  {
    "id": "arXiv:2203.15651",
    "title": "Gaze-based Object Detection in the Wild",
    "abstract": "In human-robot collaboration, one challenging task is to teach a robot new\nyet unknown objects. Thereby, gaze can contain valuable information. We\ninvestigate if it is possible to detect objects (object or no object) from gaze\ndata and determine their bounding box parameters. For this purpose, we explore\ndifferent sizes of temporal windows, which serve as a basis for the computation\nof heatmaps, i.e., the spatial distribution of the gaze data. Additionally, we\nanalyze different grid sizes of these heatmaps, and various machine learning\ntechniques are applied. To generate the data, we conducted a small study with\nfive subjects who could move freely and thus, turn towards arbitrary objects.\nThis way, we chose a scenario for our data collection that is as realistic as\npossible. Since the subjects move while facing objects, the heatmaps also\ncontain gaze data trajectories, complicating the detection and parameter\nregression.",
    "descriptor": "",
    "authors": [
      "Daniel Weber",
      "Wolfgang Fuhl",
      "Andreas Zell",
      "Enkelejda Kasneci"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15651"
  },
  {
    "id": "arXiv:2203.15653",
    "title": "Towards the Future: Bring Program Correctness back to the focus",
    "abstract": "Program correctness used to be the main concern of computer software in the\nearly days when formal semantics was a hot topic. But, the word \"correct\" was\nafterwards replaced by reliable, robust and trustworthy etc., a tradeoff\nsituation then. This is not because correctness is no longer important, but\nbecause people found no way to get through in this direction. The tradeoff has\nled software engineers to focus on techniques and testing tools. Rapid\ndevelopment of software engineering has now reached a peak and programmers are\nnow working freely without worrying too much about bugs, since bugs are not\navoidable anyway.\nIs it meaningful to talk about program correctness today? Our answer is yes.\nIt is the time to seriously consider correctness again, before it is too late,\nto prepare for the future. Future generation computer systems should be\ncorrect, both syntactically (statically) and semantically (dynamically).\nThe book \"OESPA: Semantic Oriented Theory of Programming\" (2019) by the first\nauthor has opened a new direction for semantic study. Theoretically speaking,\nit is possible now, based on OESPA, to compute program semantics from program\ntext so that program correctness could be proved.\nBut, semantic computations and correctness proving cannot be done by hand\nwhen the size of a program is big. Automatic tools are necessary. This paper\ntries to lay a foundation for developing needed auto tools, so that OESPA is\nenriched to serve future need. To this end, a new concept named conditional\nsemantic predicate is proposed. Concepts in OESPA, including semantic\nfunctions, semantic predicates, semantic formulas and semantic calculus, are\nre-represented in accordance. Such re-introduction is necessary since the book\nis the only publication on semantic calculus so far. The new version of\nsemantic calculus illustrates how semantics auto-computation would be carried\nout.",
    "descriptor": "",
    "authors": [
      "Chongyi Yuan",
      "Lijie Wen",
      "Xiongliang Yan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.15653"
  },
  {
    "id": "arXiv:2203.15655",
    "title": "Parameterized Consistency Learning-based Deep Polynomial Chaos Neural  Network Method for Reliability Analysis in Aerospace Engineering",
    "abstract": "Polynomial chaos expansion (PCE) is a powerful surrogate model-based\nreliability analysis method in aerospace engineering. Generally, a PCE model\nwith a higher expansion order is usually required to obtain an accurate\nsurrogate model for some non-linear complex stochastic systems. However, the\nhigh-order PCE increases the labeled training data cost for solving the\nexpansion coefficients. To alleviate this problem, this paper proposes a\nparameterized consistency learning-based deep polynomial chaos neural network\n(Deep PCNN) method, including the low-order adaptive PCE model (the auxiliary\nmodel) and the high-order polynomial chaos neural network (the main model). The\nexpansion coefficients of the high-order main model are parameterized into the\nlearnable weights of the polynomial chaos neural network. The auxiliary model\nuses a proposed unsupervised consistency loss function to assist in training\nthe main model. The Deep PCNN method can significantly reduce the training data\ncost in constructing a high-order PCE model without losing surrogate model\naccuracy by using a small amount of labeled data and many unlabeled data. A\nnumerical example validates the effectiveness of the Deep PCNN method, and the\nDeep PCNN method is applied to analyze the reliability of two aerospace\nengineering systems.",
    "descriptor": "",
    "authors": [
      "Xiaohu Zheng",
      "Wen Yao",
      "Yunyang Zhang",
      "Xiaoya Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15655"
  },
  {
    "id": "arXiv:2203.15657",
    "title": "Construction and Linearity of Z_pZ_{p^2}-Linear Generalized Hadamard  Codes",
    "abstract": "The $\\Z_p\\Z_{p^2}$-additive codes are subgroups of $\\Z_p^{\\alpha_1} \\times\n\\Z_{p^2}^{\\alpha_2}$, and can be seen as linear codes over $\\Z_p$ when\n$\\alpha_2=0$, $\\Z_{p^2}$-additive codes when $\\alpha_1=0$, or\n$\\Z_2\\Z_4$-additive codes when $p=2$. A $\\Z_p\\Z_{p^2}$-linear generalized\nHadamard (GH) code is a GH code over $\\Z_p$ which is the Gray map image of a\n$\\Z_p\\Z_{p^2}$-additive code. In this paper, we generalize some known results\nfor $\\Z_p\\Z_{p^2}$-linear GH codes with $p=2$ to any $p\\geq 3$ prime when\n$\\alpha_1 \\neq 0$. First, we give a recursive construction of\n$\\Z_p\\Z_{p^2}$-additive GH codes of type $(\\alpha_1,\\alpha_2;t_1,t_2)$ with\n$t_1,t_2\\geq 1$. Then, we show for which types the corresponding\n$\\Z_p\\Z_{p^2}$-linear GH codes are non-linear over $\\Z_p$. Finally, according\nto some computational results, we see that, unlike $\\Z_4$-linear GH codes, when\n$p\\geq 3$ prime, the $\\Z_{p^2}$-linear GH codes are not included in the family\nof $\\Z_p\\Z_{p^2}$-linear GH codes with $\\alpha_1\\not =0$.",
    "descriptor": "",
    "authors": [
      "Dipak K. Bhunia",
      "Cristina Fern\u00e1ndez-C\u00f3rdoba",
      "Merc\u00e8 Villanueva"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.15657"
  },
  {
    "id": "arXiv:2203.15661",
    "title": "Temporal Robustness of Temporal Logic Specifications: Analysis and  Control Design",
    "abstract": "We study the temporal robustness of temporal logic specifications and show\nhow to design temporally robust control laws for time-critical control systems.\nThis topic is of particular interest in connected systems and interleaving\nprocesses such as multi-robot and human-robot systems where uncertainty in the\nbehavior of individual agents and humans can induce timing uncertainty. Despite\nthe importance of time-critical systems, temporal robustness of temporal logic\nspecifications has not been studied, especially from a control design point of\nview. We define synchronous and asynchronous temporal robustness and show that\nthese notions quantify the robustness with respect to synchronous and\nasynchronous time shifts in the predicates of the temporal logic specification.\nIt is further shown that the synchronous temporal robustness upper bounds the\nasynchronous temporal robustness. We then study the control design problem in\nwhich we aim to design a control law that maximizes the temporal robustness of\na dynamical system. Our solution consists of a Mixed-Integer Linear Programming\n(MILP) encoding that can be used to obtain a sequence of optimal control\ninputs. While asynchronous temporal robustness is arguably more nuanced than\nsynchronous temporal robustness, we show that control design using synchronous\ntemporal robustness is computationally more efficient. This trade-off can be\nexploited by the designer depending on the particular application at hand. We\nconclude the paper with a variety of case studies.",
    "descriptor": "\nComments: Submitted journal article under review\n",
    "authors": [
      "Al\u00ebna Rodionova",
      "Lars Lindemann",
      "Manfred Morari",
      "George J. Pappas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2203.15661"
  },
  {
    "id": "arXiv:2203.15662",
    "title": "MatteFormer: Transformer-Based Image Matting via Prior-Tokens",
    "abstract": "In this paper, we propose a transformer-based image matting model called\nMatteFormer, which takes full advantage of trimap information in the\ntransformer block. Our method first introduces a prior-token which is a global\nrepresentation of each trimap region (e.g. foreground, background and unknown).\nThese prior-tokens are used as global priors and participate in the\nself-attention mechanism of each block. Each stage of the encoder is composed\nof PAST (Prior-Attentive Swin Transformer) block, which is based on the Swin\nTransformer block, but differs in a couple of aspects: 1) It has PA-WSA\n(Prior-Attentive Window Self-Attention) layer, performing self-attention not\nonly with spatial-tokens but also with prior-tokens. 2) It has prior-memory\nwhich saves prior-tokens accumulatively from the previous blocks and transfers\nthem to the next block. We evaluate our MatteFormer on the commonly used image\nmatting datasets: Composition-1k and Distinctions-646. Experiment results show\nthat our proposed method achieves state-of-the-art performance with a large\nmargin. Our codes are available at https://github.com/webtoon/matteformer.",
    "descriptor": "",
    "authors": [
      "GyuTae Park",
      "SungJoon Son",
      "JaeYoung Yoo",
      "SeHo Kim",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15662"
  },
  {
    "id": "arXiv:2203.15664",
    "title": "Nearly Minimax Algorithms for Linear Bandits with Shared Representation",
    "abstract": "We give novel algorithms for multi-task and lifelong linear bandits with\nshared representation. Specifically, we consider the setting where we play $M$\nlinear bandits with dimension $d$, each for $T$ rounds, and these $M$ bandit\ntasks share a common $k(\\ll d)$ dimensional linear representation. For both the\nmulti-task setting where we play the tasks concurrently, and the lifelong\nsetting where we play tasks sequentially, we come up with novel algorithms that\nachieve $\\widetilde{O}\\left(d\\sqrt{kMT} + kM\\sqrt{T}\\right)$ regret bounds,\nwhich matches the known minimax regret lower bound up to logarithmic factors\nand closes the gap in existing results [Yang et al., 2021]. Our main technique\ninclude a more efficient estimator for the low-rank linear feature extractor\nand an accompanied novel analysis for this estimator.",
    "descriptor": "\nComments: 19 pages, 3 figures\n",
    "authors": [
      "Jiaqi Yang",
      "Qi Lei",
      "Jason D. Lee",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15664"
  },
  {
    "id": "arXiv:2203.15667",
    "title": "Algorithms and Barriers in the Symmetric Binary Perceptron Model",
    "abstract": "The symmetric binary perceptron ($\\texttt{SBP}$) exhibits a dramatic\nstatistical-to-computational gap: the densities at which known efficient\nalgorithms find solutions are far below the threshold for the existence of\nsolutions. Furthermore, the $\\texttt{SBP}$ exhibits a striking structural\nproperty: at all positive constraint densities almost all of its solutions are\n'totally frozen' singletons separated by large Hamming distance\n\\cite{perkins2021frozen,abbe2021proof}. This suggests that finding a solution\nto the $\\texttt{SBP}$ may be computationally intractable. At the same time, the\n$\\texttt{SBP}$ does admit polynomial-time search algorithms at low enough\ndensities. A conjectural explanation for this conundrum was put forth in\n\\cite{baldassi2020clustering}: efficient algorithms succeed in the face of\nfreezing by finding exponentially rare clusters of large size. However, it was\ndiscovered recently that such rare large clusters exist at all subcritical\ndensities, even at those well above the limits of known efficient algorithms\n\\cite{abbe2021binary}. Thus the driver of the statistical-to-computational gap\nexhibited by this model remains a mystery.\nIn this paper, we conduct a different landscape analysis to explain the\nalgorithmic tractability of this problem. We show that at high enough densities\nthe $\\texttt{SBP}$ exhibits the multi Overlap Gap Property ($m-$OGP), an\nintricate geometrical property known to be a rigorous barrier for large classes\nof algorithms. Our analysis shows that the $m-$OGP threshold (a) is well below\nthe satisfiability threshold; and (b) matches the best known algorithmic\nthreshold up to logarithmic factors as $m\\to\\infty$. We then prove that the\n$m-$OGP rules out the class of stable algorithms for the $\\texttt{SBP}$ above\nthis threshold. We conjecture that the $m \\to \\infty$ limit of the $m$-OGP\nthreshold marks the algorithmic threshold for the problem.",
    "descriptor": "",
    "authors": [
      "David Gamarnik",
      "Eren C. K\u0131z\u0131lda\u011f",
      "Will Perkins",
      "Changji Xu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.15667"
  },
  {
    "id": "arXiv:2203.15671",
    "title": "100 Gb/s High Throughput Serial Protocol (HTSP) for Data Acquisition  Systems",
    "abstract": "Demands on Field-Programmable Gate Array (FPGA) data transport have been\nincreasing over the years as frame sizes and refresh rates increase. As the\nbandwidths requirements increase the ability to implement data transport\nprotocol layers using \"soft\" programmable logic becomes harder and start to\nrequires harden IP blocks implementation. This paper presents a way to leverage\nexisting FPGA harden IP blocks to achieve a robust, low latency 100 Gb/s\npoint-to-point link with minimal programmable logic overhead geared towards the\nneeds of Data Acquisition Systems.",
    "descriptor": "",
    "authors": [
      "L. Ruckman",
      "D. Doering"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2203.15671"
  },
  {
    "id": "arXiv:2203.15674",
    "title": "Exploring Frequency Adversarial Attacks for Face Forgery Detection",
    "abstract": "Various facial manipulation techniques have drawn serious public concerns in\nmorality, security, and privacy. Although existing face forgery classifiers\nachieve promising performance on detecting fake images, these methods are\nvulnerable to adversarial examples with injected imperceptible perturbations on\nthe pixels. Meanwhile, many face forgery detectors always utilize the frequency\ndiversity between real and fake faces as a crucial clue. In this paper, instead\nof injecting adversarial perturbations into the spatial domain, we propose a\nfrequency adversarial attack method against face forgery detectors. Concretely,\nwe apply discrete cosine transform (DCT) on the input images and introduce a\nfusion module to capture the salient region of adversary in the frequency\ndomain. Compared with existing adversarial attacks (e.g. FGSM, PGD) in the\nspatial domain, our method is more imperceptible to human observers and does\nnot degrade the visual quality of the original images. Moreover, inspired by\nthe idea of meta-learning, we also propose a hybrid adversarial attack that\nperforms attacks in both the spatial and frequency domains. Extensive\nexperiments indicate that the proposed method fools not only the spatial-based\ndetectors but also the state-of-the-art frequency-based detectors effectively.\nIn addition, the proposed frequency attack enhances the transferability across\nface forgery detectors as black-box attacks.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Shuai Jia",
      "Chao Ma",
      "Taiping Yao",
      "Bangjie Yin",
      "Shouhong Ding",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15674"
  },
  {
    "id": "arXiv:2203.15683",
    "title": "DRSpeech: Degradation-Robust Text-to-Speech Synthesis with Frame-Level  and Utterance-Level Acoustic Representation Learning",
    "abstract": "Most text-to-speech (TTS) methods use high-quality speech corpora recorded in\na well-designed environment, incurring a high cost for data collection. To\nsolve this problem, existing noise-robust TTS methods are intended to use noisy\nspeech corpora as training data. However, they only address either\ntime-invariant or time-variant noises. We propose a degradation-robust TTS\nmethod, which can be trained on speech corpora that contain both additive\nnoises and environmental distortions. It jointly represents the time-variant\nadditive noises with a frame-level encoder and the time-invariant environmental\ndistortions with an utterance-level encoder. We also propose a regularization\nmethod to attain clean environmental embedding that is disentangled from the\nutterance-dependent information such as linguistic contents and speaker\ncharacteristics. Evaluation results show that our method achieved significantly\nhigher-quality synthetic speech than previous methods in the condition\nincluding both additive noise and reverberation.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Takaaki Saeki",
      "Kentaro Tachibana",
      "Ryuichi Yamamoto"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15683"
  },
  {
    "id": "arXiv:2203.15685",
    "title": "EnvEdit: Environment Editing for Vision-and-Language Navigation",
    "abstract": "In Vision-and-Language Navigation (VLN), an agent needs to navigate through\nthe environment based on natural language instructions. Due to limited\navailable data for agent training and finite diversity in navigation\nenvironments, it is challenging for the agent to generalize to new, unseen\nenvironments. To address this problem, we propose EnvEdit, a data augmentation\nmethod that creates new environments by editing existing environments, which\nare used to train a more generalizable agent. Our augmented environments can\ndiffer from the seen environments in three diverse aspects: style, object\nappearance, and object classes. Training on these edit-augmented environments\nprevents the agent from overfitting to existing environments and helps\ngeneralize better to new, unseen environments. Empirically, on both the\nRoom-to-Room and the multi-lingual Room-Across-Room datasets, we show that our\nproposed EnvEdit method gets significant improvements in all metrics on both\npre-trained and non-pre-trained VLN agents, and achieves the new\nstate-of-the-art on the test leaderboard. We further ensemble the VLN agents\naugmented on different edited environments and show that these edit methods are\ncomplementary. Code and data are available at\nhttps://github.com/jialuli-luka/EnvEdit",
    "descriptor": "\nComments: CVPR 2022 (17 pages)\n",
    "authors": [
      "Jialu Li",
      "Hao Tan",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.15685"
  },
  {
    "id": "arXiv:2203.15686",
    "title": "Forecasting with Economic News",
    "abstract": "The goal of this paper is to evaluate the informational content of sentiment\nextracted from news articles about the state of the economy. We propose a\nfine-grained aspect-based sentiment analysis that has two main characteristics:\n1) we consider only the text in the article that is semantically dependent on a\nterm of interest (aspect-based) and, 2) assign a sentiment score to each word\nbased on a dictionary that we develop for applications in economics and finance\n(fine-grained). Our data set includes six large US newspapers, for a total of\nover 6.6 million articles and 4.2 billion words. Our findings suggest that\nseveral measures of economic sentiment track closely business cycle\nfluctuations and that they are relevant predictors for four major macroeconomic\nvariables. We find that there are significant improvements in forecasting when\nsentiment is considered along with macroeconomic factors. In addition, we also\nfind that sentiment matters to explains the tails of the probability\ndistribution across several macroeconomic variables.",
    "descriptor": "\nComments: 46 pages, 11 figures, to be published in Journal of Business & Economic Statistics\n",
    "authors": [
      "Luca Barbaglia",
      "Sergio Consoli",
      "Sebastiano Manzan"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.15686"
  },
  {
    "id": "arXiv:2203.15687",
    "title": "Texture based Prototypical Network for Few-Shot Semantic Segmentation of  Forest Cover: Generalizing for Different Geographical Regions",
    "abstract": "Forest plays a vital role in reducing greenhouse gas emissions and mitigating\nclimate change besides maintaining the world's biodiversity. The existing\nsatellite-based forest monitoring system utilizes supervised learning\napproaches that are limited to a particular region and depend on manually\nannotated data to identify forest. This work envisages forest identification as\na few-shot semantic segmentation task to achieve generalization across\ndifferent geographical regions. The proposed few-shot segmentation approach\nincorporates a texture attention module in the prototypical network to\nhighlight the texture features of the forest. Indeed, the forest exhibits a\ncharacteristic texture different from other classes, such as road, water, etc.\nIn this work, the proposed approach is trained for identifying tropical forests\nof South Asia and adapted to determine the temperate forest of Central Europe\nwith the help of a few (one image for 1-shot) manually annotated support images\nof the temperate forest. An IoU of 0.62 for forest class (1-way 1-shot) was\nobtained using the proposed method, which is significantly higher (0.46 for\nPANet) than the existing few-shot semantic segmentation approach. This result\ndemonstrates that the proposed approach can generalize across geographical\nregions for forest identification, creating an opportunity to develop a global\nforest cover identification tool.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Gokul P",
      "Ujjwal Verma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15687"
  },
  {
    "id": "arXiv:2203.15691",
    "title": "Improved Counting and Localization from Density Maps for Object  Detection in 2D and 3D Microscopy Imaging",
    "abstract": "Object counting and localization are key steps for quantitative analysis in\nlarge-scale microscopy applications. This procedure becomes challenging when\ntarget objects are overlapping, are densely clustered, and/or present fuzzy\nboundaries. Previous methods producing density maps based on deep learning have\nreached a high level of accuracy for object counting by assuming that object\ncounting is equivalent to the integration of the density map. However, this\nmodel fails when objects show significant overlap regarding accurate\nlocalization. We propose an alternative method to count and localize objects\nfrom the density map to overcome this limitation. Our procedure includes the\nfollowing three key aspects: 1) Proposing a new counting method based on the\nstatistical properties of the density map, 2) optimizing the counting results\nfor those objects which are well-detected based on the proposed counting\nmethod, and 3) improving localization of poorly detected objects using the\nproposed counting method as prior information. Validation includes processing\nof microscopy data with known ground truth and comparison with other models\nthat use conventional processing of the density map. Our results show improved\nperformance in counting and localization of objects in 2D and 3D microscopy\ndata. Furthermore, the proposed method is generic, considering various\napplications that rely on the density map approach. Our code will be released\npost-review.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Shijie Li",
      "Thomas Ach",
      "Guido Gerig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15691"
  },
  {
    "id": "arXiv:2203.15696",
    "title": "Auditing Privacy Defenses in Federated Learning via Generative Gradient  Leakage",
    "abstract": "Federated Learning (FL) framework brings privacy benefits to distributed\nlearning systems by allowing multiple clients to participate in a learning task\nunder the coordination of a central server without exchanging their private\ndata. However, recent studies have revealed that private information can still\nbe leaked through shared gradient information. To further protect user's\nprivacy, several defense mechanisms have been proposed to prevent privacy\nleakage via gradient information degradation methods, such as using additive\nnoise or gradient compression before sharing it with the server. In this work,\nwe validate that the private training data can still be leaked under certain\ndefense settings with a new type of leakage, i.e., Generative Gradient Leakage\n(GGL). Unlike existing methods that only rely on gradient information to\nreconstruct data, our method leverages the latent space of generative\nadversarial networks (GAN) learned from public image datasets as a prior to\ncompensate for the informational loss during gradient degradation. To address\nthe nonlinearity caused by the gradient operator and the GAN model, we explore\nvarious gradient-free optimization methods (e.g., evolution strategies and\nBayesian optimization) and empirically show their superiority in reconstructing\nhigh-quality images from gradients compared to gradient-based optimizers. We\nhope the proposed method can serve as a tool for empirically measuring the\namount of privacy leakage to facilitate the design of more robust defense\nmechanisms.",
    "descriptor": "",
    "authors": [
      "Zhuohang Li",
      "Jiaxin Zhang",
      "Luyang Liu",
      "Jian Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15696"
  },
  {
    "id": "arXiv:2203.15698",
    "title": "Addressing Non-Intervention Challenges via Resilient Robotics utilizing  a Digital Twin",
    "abstract": "Multi-robot systems face challenges in reducing human interventions as they\nare often deployed in dangerous environments. It is therefore necessary to\ninclude a methodology to assess robot failure rates to reduce the requirement\nfor costly human intervention. A solution to this problem includes robots with\nthe ability to work together to ensure mission resilience. To prevent this\nintervention, robots should be able to work together to ensure mission\nresilience. However, robotic platforms generally lack built-in\ninterconnectivity with other platforms from different vendors. This work aims\nto tackle this issue by enabling the functionality through a bidirectional\ndigital twin. The twin enables the human operator to transmit and receive\ninformation to and from the multi-robot fleet. This digital twin considers\nmission resilience, decision making and a run-time reliability ontology for\nfailure detection to enable the resilience of a multi-robot fleet. This creates\nthe cooperation, corroboration, and collaboration of diverse robots to leverage\nthe capability of robots and support recovery of a failed robot.",
    "descriptor": "\nComments: 6 pages, 7 figures, preprint conference submission for IROS 2022\n",
    "authors": [
      "Sam Harper",
      "Shivoh Nandakumar",
      "Daniel Mitchell",
      "Jamie Blanche",
      "Osama Zaki",
      "Theodore Lim",
      "Ikuo Yamamoto",
      "David Flynn"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.15698"
  },
  {
    "id": "arXiv:2203.15700",
    "title": "MAP-Gen: An Automated 3D-Box Annotation Flow with Multimodal Attention  Point Generator",
    "abstract": "Manually annotating 3D point clouds is laborious and costly, limiting the\ntraining data preparation for deep learning in real-world object detection.\nWhile a few previous studies tried to automatically generate 3D bounding boxes\nfrom weak labels such as 2D boxes, the quality is sub-optimal compared to human\nannotators. This work proposes a novel autolabeler, called multimodal attention\npoint generator (MAP-Gen), that generates high-quality 3D labels from weak 2D\nboxes. It leverages dense image information to tackle the sparsity issue of 3D\npoint clouds, thus improving label quality. For each 2D pixel, MAP-Gen predicts\nits corresponding 3D coordinates by referencing context points based on their\n2D semantic or geometric relationships. The generated 3D points densify the\noriginal sparse point clouds, followed by an encoder to regress 3D bounding\nboxes. Using MAP-Gen, object detection networks that are weakly supervised by\n2D boxes can achieve 94~99% performance of those fully supervised by 3D\nannotations. It is hopeful this newly proposed MAP-Gen autolabeling flow can\nshed new light on utilizing multimodal information for enriching sparse point\nclouds.",
    "descriptor": "\nComments: 6 pages, 4 figures, accepted by ICPR 2022\n",
    "authors": [
      "Chang Liu",
      "Xiaoyan Qian",
      "Xiaojuan Qi",
      "Edmund Y. Lam",
      "Siew-Chong Tan",
      "Ngai Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15700"
  },
  {
    "id": "arXiv:2203.15702",
    "title": "Contrasting the landscape of contrastive and non-contrastive learning",
    "abstract": "A lot of recent advances in unsupervised feature learning are based on\ndesigning features which are invariant under semantic data augmentations. A\ncommon way to do this is contrastive learning, which uses positive and negative\nsamples. Some recent works however have shown promising results for\nnon-contrastive learning, which does not require negative samples. However, the\nnon-contrastive losses have obvious \"collapsed\" minima, in which the encoders\noutput a constant feature embedding, independent of the input. A folk\nconjecture is that so long as these collapsed solutions are avoided, the\nproduced feature representations should be good. In our paper, we cast doubt on\nthis story: we show through theoretical results and controlled experiments that\neven on simple data models, non-contrastive losses have a preponderance of\nnon-collapsed bad minima. Moreover, we show that the training process does not\navoid these minima.",
    "descriptor": "\nComments: Accepted for publication in the AISTATS 2022 conference (this http URL)\n",
    "authors": [
      "Ashwini Pokle",
      "Jinjin Tian",
      "Yuchen Li",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15702"
  },
  {
    "id": "arXiv:2203.15703",
    "title": "Towards Everyday Virtual Reality through Eye Tracking",
    "abstract": "With developments in computer graphics, hardware technology, perception\nengineering, and human-computer interaction, virtual reality and virtual\nenvironments are becoming more integrated into our daily lives. Head-mounted\ndisplays, however, are still not used as frequently as other mobile devices\nsuch as smart phones and watches. With increased usage of this technology and\nthe acclimation of humans to virtual application scenarios, it is possible that\nin the near future an everyday virtual reality paradigm will be realized. When\nconsidering the marriage of everyday virtual reality and head-mounted displays,\neye tracking is an emerging technology that helps to assess human behaviors in\na real time and non-intrusive way. Still, multiple aspects need to be\nresearched before these technologies become widely available in daily life.\nFirstly, attention and cognition models in everyday scenarios should be\nthoroughly understood. Secondly, as eyes are related to visual biometrics,\nprivacy preserving methodologies are necessary. Lastly, instead of studies or\napplications utilizing limited human participants with relatively homogeneous\ncharacteristics, protocols and use-cases for making such technology more\naccessible should be essential. In this work, taking the aforementioned points\ninto account, a significant scientific push towards everyday virtual reality\nhas been completed with three main research contributions.",
    "descriptor": "\nComments: PhD Thesis, University of T\\\"ubingen\n",
    "authors": [
      "Efe Bozkir"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15703"
  },
  {
    "id": "arXiv:2203.15704",
    "title": "Fine-Grained Visual Entailment",
    "abstract": "Visual entailment is a recently proposed multimodal reasoning task where the\ngoal is to predict the logical relationship of a piece of text to an image. In\nthis paper, we propose an extension of this task, where the goal is to predict\nthe logical relationship of fine-grained knowledge elements within a piece of\ntext to an image. Unlike prior work, our method is inherently explainable and\nmakes logical predictions at different levels of granularity. Because we lack\nfine-grained labels to train our method, we propose a novel multi-instance\nlearning approach which learns a fine-grained labeling using only sample-level\nsupervision. We also impose novel semantic structural constraints which ensure\nthat fine-grained predictions are internally semantically consistent. We\nevaluate our method on a new dataset of manually annotated knowledge elements\nand show that our method achieves 68.18\\% accuracy at this challenging task\nwhile significantly outperforming several strong baselines. Finally, we present\nextensive qualitative results illustrating our method's predictions and the\nvisual evidence our method relied on. Our code and annotated dataset can be\nfound here: https://github.com/SkrighYZ/FGVE.",
    "descriptor": "",
    "authors": [
      "Christopher Thomas",
      "Yipeng Zhang",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15704"
  },
  {
    "id": "arXiv:2203.15705",
    "title": "IoT Forensic Frameworks (DFIF, IoTDOTS,FSAIoT): A Comprehensive Study",
    "abstract": "In the Internet of Things, millions of electronic items, including\nautomobiles, smoke alarms, watches, eyeglasses, webcams, and other devices, are\nnow connected to the Internet (IoT). Aside from the luxury and comfort that the\nindividual obtains in the field of IoT, as well as its ability to communicate\nand obtain information easily and quickly, the other concerning aspect is the\nachievement of privacy and security in this connection, especially given the\nrapid increase in the number of existing and new IoT devices. Concerns,\nthreats, and assaults related to IoT security have been regarded as a potential\nand problematic area of research. This necessitates the quick development or\ncreation of suitable technologies with the nature of crimes in the IoT\nenvironment. On the other hand, criminal investigation specialists encounter\ndifficulties and hurdles due to various locations, data types, instruments\nused, and device recognition. This paper provides an in-depth explanation of\nthe criminal content of the Internet of Things. It compares its stages to the\ndetailed stages of traditional digital forensics in terms of similarities and\ndifferences, the frameworks used in dealing with electronic crimes, and the\ntechniques used in both types. This paper presents previous discussions of\nresearchers in the field of digital forensics. For the IoT, which brings us to\nthe most important parts of this paper, which is a comprehensive study of the\nIoT criminal frameworks that are used to protect communication in the field of\nIoT, such as Digital Forensic Investigation Framework (DFIF), Digital Forensic\nFramework for Smart Environments (IoTDOTS), Forensic State Acquisition from the\nInternet of Things (FSAIoT), and discusses the challenges in their general\nframeworks and provides solutions and strategies.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Mohammad A. Hassan",
      "Ghassan Samara",
      "Mohammad Abu Fadda"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.15705"
  },
  {
    "id": "arXiv:2203.15706",
    "title": "Stabilized Neural Ordinary Differential Equations for Long-Time  Forecasting of Dynamical Systems",
    "abstract": "In data-driven modeling of spatiotemporal phenomena careful consideration\noften needs to be made in capturing the dynamics of the high wavenumbers. This\nproblem becomes especially challenging when the system of interest exhibits\nshocks or chaotic dynamics. We present a data-driven modeling method that\naccurately captures shocks and chaotic dynamics by proposing a novel\narchitecture, stabilized neural ordinary differential equation (ODE). In our\nproposed architecture, we learn the right-hand-side (RHS) of an ODE by adding\nthe outputs of two NN together where one learns a linear term and the other a\nnonlinear term. Specifically, we implement this by training a sparse linear\nconvolutional NN to learn the linear term and a dense fully-connected nonlinear\nNN to learn the nonlinear term. This is in contrast with the standard neural\nODE which involves training only a single NN for learning the RHS. We apply\nthis setup to the viscous Burgers equation, which exhibits shocked behavior,\nand show better short-time tracking and prediction of the energy spectrum at\nhigh wavenumbers than a standard neural ODE. We also find that the stabilized\nneural ODE models are much more robust to noisy initial conditions than the\nstandard neural ODE approach. We also apply this method to chaotic trajectories\nof the Kuramoto-Sivashinsky equation. In this case, stabilized neural ODEs keep\nlong-time trajectories on the attractor, and are highly robust to noisy initial\nconditions, while standard neural ODEs fail at achieving either of these\nresults. We conclude by demonstrating how stabilizing neural ODEs provide a\nnatural extension for use in reduced-order modeling by projecting the dynamics\nonto the eigenvectors of the learned linear term.",
    "descriptor": "",
    "authors": [
      "Alec J. Linot",
      "Josh W. Burby",
      "Qi Tang",
      "Prasanna Balaprakash",
      "Michael D. Graham",
      "Romit Maulik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15706"
  },
  {
    "id": "arXiv:2203.15709",
    "title": "OakInk: A Large-scale Knowledge Repository for Understanding Hand-Object  Interaction",
    "abstract": "Learning how humans manipulate objects requires machines to acquire knowledge\nfrom two perspectives: one for understanding object affordances and the other\nfor learning human's interactions based on the affordances. Even though these\ntwo knowledge bases are crucial, we find that current databases lack a\ncomprehensive awareness of them. In this work, we propose a multi-modal and\nrich-annotated knowledge repository, OakInk, for visual and cognitive\nunderstanding of hand-object interactions. We start to collect 1,800 common\nhousehold objects and annotate their affordances to construct the first\nknowledge base: Oak. Given the affordance, we record rich human interactions\nwith 100 selected objects in Oak. Finally, we transfer the interactions on the\n100 recorded objects to their virtual counterparts through a novel method:\nTink. The recorded and transferred hand-object interactions constitute the\nsecond knowledge base: Ink. As a result, OakInk contains 50,000 distinct\naffordance-aware and intent-oriented hand-object interactions. We benchmark\nOakInk on pose estimation and grasp generation tasks. Moreover, we propose two\npractical applications of OakInk: intent-based interaction generation and\nhandover generation. Our datasets and source code are publicly available at\nhttps://github.com/lixiny/OakInk.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Lixin Yang",
      "Kailin Li",
      "Xinyu Zhan",
      "Fei Wu",
      "Anran Xu",
      "Liu Liu",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15709"
  },
  {
    "id": "arXiv:2203.15712",
    "title": "Integrative Few-Shot Learning for Classification and Segmentation",
    "abstract": "We introduce the integrative task of few-shot classification and segmentation\n(FS-CS) that aims to both classify and segment target objects in a query image\nwhen the target classes are given with a few examples. This task combines two\nconventional few-shot learning problems, few-shot classification and\nsegmentation. FS-CS generalizes them to more realistic episodes with arbitrary\nimage pairs, where each target class may or may not be present in the query. To\naddress the task, we propose the integrative few-shot learning (iFSL) framework\nfor FS-CS, which trains a learner to construct class-wise foreground maps for\nmulti-label classification and pixel-wise segmentation. We also develop an\neffective iFSL model, attentive squeeze network (ASNet), that leverages deep\nsemantic correlation and global self-attention to produce reliable foreground\nmaps. In experiments, the proposed method shows promising performance on the\nFS-CS task and also achieves the state of the art on standard few-shot\nsegmentation benchmarks.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Dahyun Kang",
      "Minsu Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15712"
  },
  {
    "id": "arXiv:2203.15720",
    "title": "Transformer Inertial Poser: Attention-based Real-time Human Motion  Reconstruction from Sparse IMUs",
    "abstract": "Real-time human motion reconstruction from a sparse set of wearable IMUs\nprovides an non-intrusive and economic approach to motion capture. Without the\nability to acquire absolute position information using IMUs, many prior works\ntook data-driven approaches that utilize large human motion datasets to tackle\nthe under-determined nature of the problem. Still, challenges such as temporal\nconsistency, global translation estimation, and diverse coverage of motion or\nterrain types remain. Inspired by recent success of Transformer models in\nsequence modeling, we propose an attention-based deep learning method to\nreconstruct full-body motion from six IMU sensors in real-time. Together with a\nphysics-based learning objective to predict \"stationary body points\", our\nmethod achieves new state-of-the-art results both quantitatively and\nqualitatively, while being simple to implement and smaller in size. We evaluate\nour method extensively on synthesized and real IMU data, and with real-time\nlive demos.",
    "descriptor": "",
    "authors": [
      "Yifeng Jiang",
      "Yuting Ye",
      "Deepak Gopinath",
      "Jungdam Won",
      "Alexander W. Winkler",
      "C. Karen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.15720"
  },
  {
    "id": "arXiv:2203.15721",
    "title": "On Decoding Strategies for Neural Text Generators",
    "abstract": "When generating text from probabilistic models, the chosen decoding strategy\nhas a profound effect on the resulting text. Yet the properties elicited by\nvarious decoding strategies do not always transfer across natural language\ngeneration tasks. For example, while mode-seeking methods like beam search\nperform remarkably well for machine translation, they have been observed to\nlead to incoherent and repetitive text in story generation. Despite such\nobservations, the effectiveness of decoding strategies is often assessed with\nrespect to only a single task. This work -- in contrast -- provides a\ncomprehensive analysis of the interaction between language generation tasks and\ndecoding strategies. Specifically, we measure changes in attributes of\ngenerated text as a function of both decoding strategy and task using human and\nautomatic evaluation. Our results reveal both previously-observed and\nsurprising findings. For example, the nature of the diversity-quality trade-off\nin language generation is very task-specific; the length bias often attributed\nto beam search is not constant across tasks.",
    "descriptor": "",
    "authors": [
      "Gian Wiher",
      "Clara Meister",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15721"
  },
  {
    "id": "arXiv:2203.15722",
    "title": "Transformer Network-based Reinforcement Learning Method for Power  Distribution Network (PDN) Optimization of High Bandwidth Memory (HBM)",
    "abstract": "In this article, for the first time, we propose a transformer network-based\nreinforcement learning (RL) method for power distribution network (PDN)\noptimization of high bandwidth memory (HBM). The proposed method can provide an\noptimal decoupling capacitor (decap) design to maximize the reduction of PDN\nself- and transfer impedance seen at multiple ports. An attention-based\ntransformer network is implemented to directly parameterize decap optimization\npolicy. The optimality performance is significantly improved since the\nattention mechanism has powerful expression to explore massive combinatorial\nspace for decap assignments. Moreover, it can capture sequential relationships\nbetween the decap assignments. The computing time for optimization is\ndramatically reduced due to the reusable network on positions of probing ports\nand decap assignment candidates. This is because the transformer network has a\ncontext embedding process to capture meta-features including probing ports\npositions. In addition, the network is trained with randomly generated data\nsets. Therefore, without additional training, the trained network can solve new\ndecap optimization problems. The computing time for training and data cost are\ncritically decreased due to the scalability of the network. Thanks to its\nshared weight property, the network can adapt to a larger scale of problems\nwithout additional training. For verification, we compare the results with\nconventional genetic algorithm (GA), random search (RS), and all the previous\nRL-based methods. As a result, the proposed method outperforms in all the\nfollowing aspects: optimality performance, computing time, and data efficiency.",
    "descriptor": "\nComments: 16 pages, 13 figures, Under review as a journal paper at IEEE Transactions on Microwave and Theory and Techniques (TMTT)\n",
    "authors": [
      "Hyunwook Park",
      "Minsu Kim",
      "Seongguk Kim",
      "Keunwoo Kim",
      "Haeyeon Kim",
      "Taein Shin",
      "Keeyoung Son",
      "Boogyo Sim",
      "Subin Kim",
      "Seungtaek Jeong",
      "Chulsoon Hwang",
      "Joungho Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15722"
  },
  {
    "id": "arXiv:2203.15723",
    "title": "Few-shot Structured Radiology Report Generation Using Natural Language  Prompts",
    "abstract": "Chest radiograph reporting is time-consuming, and numerous solutions to\nautomate this process have been proposed. Due to the complexity of medical\ninformation, the variety of writing styles, and free text being prone to typos\nand inconsistencies, the efficacy of quantifying the clinical accuracy of\nfree-text reports using natural language processing measures is challenging. On\nthe other hand, structured reports ensure consistency and can more easily be\nused as a quality assurance tool. To accomplish this, we present a strategy for\npredicting clinical observations and their anatomical location that is easily\nextensible to other structured findings. First, we train a contrastive\nlanguage-image model using related chest radiographs and free-text radiological\nreports. Then, we create textual prompts for each structured finding and\noptimize a classifier for predicting clinical findings and their associations\nwithin the medical image. The results indicate that even when only a few\nimage-level annotations are used for training, the method can localize\npathologies in chest radiographs and generate structured reports.",
    "descriptor": "\nComments: 8 pages, 1 figure, 3 tables\n",
    "authors": [
      "Matthias Keicher",
      "Kamilia Mullakaeva",
      "Tobias Czempiel",
      "Kristina Mach",
      "Ashkan Khakzar",
      "Nassir Navab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15723"
  },
  {
    "id": "arXiv:2203.15724",
    "title": "On $d$-stable locally checkable problems on bounded mim-width graphs",
    "abstract": "In this paper we continue the study of locally checkable problems under the\nframework introduced by Bonomo-Braberman and Gonzalez in 2020, by focusing on\ngraphs of bounded mim-width. We study which restrictions on a locally checkable\nproblem are necessary in order to be able to solve it efficiently on graphs of\nbounded mim-width. To this end, we introduce the concept of $d$-stability of a\ncheck function. The related locally checkable problems contain large classes of\nproblems, among which we can mention, for example, LCVP problems. We provide an\nalgorithm which solves all $d$-stable locally checkable problems on graphs of\nbounded mim-width in polynomial time and explain how we can include additional\nglobal properties (size of the color classes and connectivity). We explore the\nrelation between $d$-stable locally checkable problems with the recently\nintroduced DN-logic (Bergougnoux, Dreier and Jaffke, 2022). We conclude by\nlisting concrete examples of problems whose complexity on graphs of bounded\nmim-width was open so far.",
    "descriptor": "",
    "authors": [
      "Carolina Luc\u00eda Gonzalez",
      "Felix Mann"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.15724"
  },
  {
    "id": "arXiv:2203.15726",
    "title": "Scheduling UET-UCT DAGs of Depth Two on Two Processors",
    "abstract": "Given unit execution time (UET) tasks whose precedence constraints form a\ndirected acyclic graph (DAG), the arcs are associated with unit communication\ntime (UCT) delays. The problem is to schedule the tasks on two processors in\norder to minimize the makespan. Several polynomial algorithms in the literature\nare proposed for special classes of digraphs, but the complexity of solving\nthis problem in general case stills a challenging open question. We propose in\nthis paper a linear time algorithm to compute an optimal schedule for the class\nof DAGs of depth two.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Ruzayn Quaddoura",
      "Gassan Samara"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.15726"
  },
  {
    "id": "arXiv:2203.15733",
    "title": "Energy Balancing Algorithm for Wireless Sensor Network",
    "abstract": "A Wireless Sensor Network (WSN) is made up of a large number of nodes that\nare spread randomly or on a regular basis to detect the surrounding environment\nand transfer data to a base station (BS) over the Internet to the user. It is\nwidely used in a variety of civil and military concerns. Because the sensor has\nlimited battery capacity, energy efficiency is a critical issue with WSNs. As a\nresult, developing a routing protocol that decreases energy consumption in\nsensor nodes to extend the lifetime of the WSN using an intelligence algorithm\nhas become difficult. LEACH is the first hierarchical routing protocol that\ndivides the WSN into clusters to reduce energy usage. However, it has reached\nits limit in selecting a suitable cluster head and the sensor nodes to be\njoined, as well as their quantity. Thus, this research proposes an algorithm\ncalled Wireless Energy Balancing algorithm (WEB) that works on energy balancing\ndistribution by identifying a suitable cluster head with minimum distance and\nhigh energy. Then it uses the knapsack-problem as a novel algorithm to design\nthe cluster members. The simulation results demonstrate that the WEB algorithm\noutperforms LEACH by 31% in terms of energy conservation and WSN lifetime\nextension.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Ghassan Samara",
      "Mohammad A. Hassan",
      "Munir Al-Okour"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.15733"
  },
  {
    "id": "arXiv:2203.15737",
    "title": "Towards Spatio-Temporal Aware Traffic Time Series Forecasting--Full  Version",
    "abstract": "Traffic time series forecasting is challenging due to complex spatio-temporal\ndynamics-time series from different locations often have distinct patterns; and\nfor the same time series, patterns may vary across time, where, for example,\nthere exist certain periods across a day showing stronger temporal\ncorrelations. Although recent forecasting models, in particular deep learning\nbased models, show promising results, they suffer from being spatio-temporal\nagnostic. Such spatio-temporal agnostic models employ a shared parameter space\nirrespective of the time series locations and the time periods and they assume\nthat the temporal patterns are similar across locations and do not evolve\nacross time, which may not always hold, thus leading to sub-optimal results. In\nthis work, we propose a framework that aims at turning spatio-temporal agnostic\nmodels to spatio-temporal aware models. To do so, we encode time series from\ndifferent locations into stochastic variables, from which we generate\nlocation-specific and time-varying model parameters to better capture the\nspatio-temporal dynamics. We show how to integrate the framework with canonical\nattentions to enable spatio-temporal aware attentions. Next, to compensate for\nthe additional overhead introduced by the spatio-temporal aware model parameter\ngeneration process, we propose a novel window attention scheme, which helps\nreduce the complexity from quadratic to linear, making spatio-temporal aware\nattentions also have competitive efficiency. We show strong empirical evidence\non four traffic time series datasets, where the proposed spatio-temporal aware\nattentions outperform state-of-the-art methods in term of accuracy and\nefficiency. This manuscript provides a full version of [1].",
    "descriptor": "\nComments: Accepted at ICDE 22\n",
    "authors": [
      "Razvan-Gabriel Cirstea",
      "Bin Yang",
      "Chenjuan Guo",
      "Tung Kieu",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15737"
  },
  {
    "id": "arXiv:2203.15738",
    "title": "Encryption and encoding of facial images into quick response and high  capacity color 2d code for biometric passport security system",
    "abstract": "In this thesis, a multimodal biometric, secure encrypted data and encrypted\nbiometric encoded into the QR code-based biometric-passport authentication\nmethod is proposed for national security applications. Firstly, using the\nExtended Profile - Local Binary Patterns (EP-LBP), a Canny edge detector, and\nthe Scale Invariant Feature Transform (SIFT) algorithm with Image File\nInformation (IMFINFO) process, the facial mark size recognition is initially\nachieved. Secondly, by using the Active Shape Model (ASM) into Active\nAppearance Model (AAM) to follow the hand and infusion the hand geometry\ncharacteristics for verification and identification, hand geometry recognition\nis achieved. Thirdly, the encrypted biometric passport information that is\npublicly accessible is encoded into the QR code and inserted into the\nelectronic passport to improve protection. Further, Personal information and\nbiometric data are encrypted by applying the Advanced Encryption Standard (AES)\nand the Secure Hash Algorithm (SHA) 256 algorithm. It will enhance the\nbiometric passport security system.",
    "descriptor": "\nComments: 158, 41, Ph.D. thesis\n",
    "authors": [
      "Ziaul Haque Choudhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15738"
  },
  {
    "id": "arXiv:2203.15745",
    "title": "Super-resolving multiple scatterers detection in SAR Tomography assisted  by correlation information",
    "abstract": "This paper proposes a method for detecting multiple scatterers (targets) in\nthe elevation direction for synthetic aperture radar (SAR) tomography. The\nproposed method can resolve closely spaced targets through a twostep procedure.\nIn the first step, coarse detection is performed with a successive cancellation\nscheme in which possible locations of targets are marked. Then, in the second\nstep, by searching in the reduced search space which is finely 10 gridded, the\naccurate location of the targets is found. For estimating the actual number of\ntargets, a model order selection scheme is used in two cases of known and\nunknown noise variance. Also, by analytical investigation of the probability of\ndetection for the proposed method, the effect of the influential parameters on\nthe detection ability is explicitly demonstrated. Compared to the\nsuper-resolution methods based on compressed sensing (CS), the proposed method\nhas a lower computational cost and higher estimation accuracy, especially at\nlow signal-to-noise ratio regime. 15 Simulation results show the superiority of\nthe proposed method in terms of both 3D scatterer reconstruction and detection\nability",
    "descriptor": "",
    "authors": [
      "Ahmad Naghavia",
      "Mohammad Sadegh Fazel",
      "Mojtaba Beheshti",
      "Ehsan Yazdian"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.15745"
  },
  {
    "id": "arXiv:2203.15748",
    "title": "An Adaptive Benchmark for Modeling User Exploration of Large Datasets",
    "abstract": "Interactive analysis systems provide efficient and accessible means by which\nusers of varying technical experience can comfortably manipulate and analyze\ndata using interactive widgets. Widgets are elements of interaction within a\nuser interface (e.g. scrollbar, button, etc). Interactions with these widgets\nproduce database queries whose results determine the subsequent changes made to\nthe current visualization made by the user. In this paper, we present a tool\nthat extends IDEBench to ingest visualization interfaces and a dataset, and\nestimate the expected database load that would be generated by real users. Our\ntool analyzes the interactive capabilities of the visualization and creates the\nqueries that support the various interactions. We began with a proof of concept\nimplementation of every interaction widget, which led us to define three\ndistinct sets of query templates that can support all interactions. We then\nshow that these templates can be layered to imitate various interfaces and\ntailored to any dataset. Secondly, we simulate how users would interact with\nthe proposed interface and report on the strain that such use would place on\nthe database management system.",
    "descriptor": "",
    "authors": [
      "Joanna Purich",
      "Hira Mahmood",
      "Diana Chou",
      "Chidi Udeze",
      "Leilani Battle"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.15748"
  },
  {
    "id": "arXiv:2203.15752",
    "title": "Information Consumption and Boundary Spanning in Decentralized Online  Social Networks: the case of Mastodon Users",
    "abstract": "Decentralized Online Social Networks (DOSNs) represent a growing trend in the\nsocial media landscape, as opposed to the well-known centralized peers, which\nare often in the spotlight due to privacy concerns and a vision typically\nfocused on monetization through user relationships. By exploiting open-source\nsoftware, DOSNs allow users to create their own servers, or instances, thus\nfavoring the proliferation of platforms that are independent yet interconnected\nwith each other in a transparent way. Nonetheless, the resulting cooperation\nmodel, commonly known as the Fediverse, still represents a world to be fully\ndiscovered, since existing studies have mainly focused on a limited number of\nstructural aspects of interest in DOSNs. In this work, we aim to fill a lack of\nstudy on user relations and roles in DOSNs, by taking two main actions:\nunderstanding the impact of decentralization on how users relate to each other\nwithin their membership instance and/or across different instances, and\nunveiling user roles that can explain two interrelated axes of social\nbehavioral phenomena, namely information consumption and boundary spanning. To\nthis purpose, we build our analysis on user networks from Mastodon, since it\nrepresents the most widely used DOSN platform. We believe that the findings\ndrawn from our study on Mastodon users' roles and information flow can pave a\nway for further development of fascinating research on DOSNs.",
    "descriptor": "\nComments: Under review, Online Social Networks and Media, Elsevier (2021)\n",
    "authors": [
      "Lucio La Cava",
      "Andrea Tagarelli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.15752"
  },
  {
    "id": "arXiv:2203.15753",
    "title": "HardVis: Visual Analytics to Handle Instance Hardness Using  Undersampling and Oversampling Techniques",
    "abstract": "Despite the tremendous advances in machine learning (ML), training with\nimbalanced data still poses challenges in many real-world applications. Among a\nseries of diverse techniques to solve this problem, sampling algorithms are\nregarded as an efficient solution. However, the problem is more fundamental,\nwith many works emphasizing the importance of instance hardness. This issue\nrefers to the significance of managing unsafe or potentially noisy instances\nthat are more likely to be misclassified and serve as the root cause of poor\nclassification performance. This paper introduces HardVis, a visual analytics\nsystem designed to handle instance hardness mainly in imbalanced classification\nscenarios. Our proposed system assists users in visually comparing different\ndistributions of data types, selecting types of instances based on local\ncharacteristics that will later be affected by the active sampling method, and\nvalidating which suggestions from undersampling or oversampling techniques are\nbeneficial for the ML model. Additionally, rather than uniformly\nundersampling/oversampling a specific class, we allow users to find and sample\neasy and difficult to classify training instances from all classes. Users can\nexplore subsets of data from different perspectives to decide all those\nparameters, while HardVis keeps track of their steps and evaluates the model's\npredictive performance in a test set separately. The end result is a\nwell-balanced data set that boosts the predictive power of the ML model. The\nefficacy and effectiveness of HardVis are demonstrated with a hypothetical\nusage scenario and a use case. Finally, we also look at how useful our system\nis based on feedback we received from ML experts.",
    "descriptor": "\nComments: This manuscript is currently under review\n",
    "authors": [
      "Angelos Chatzimparmpas",
      "Fernando V. Paulovich",
      "Andreas Kerren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15753"
  },
  {
    "id": "arXiv:2203.15754",
    "title": "Evaluating Prompts Across Multiple Choice Tasks In a Zero-Shot Setting",
    "abstract": "Large language models have shown that impressive zero-shot performance can be\nachieved through natural language prompts (Radford et al., 2019; Brown et al.,\n2020; Sanh et al., 2021). Creating an effective prompt, however, requires\nsignificant trial and error. That \\textit{prompts} the question: how do the\nqualities of a prompt effects its performance? To this end, we collect and\nstandardize prompts from a diverse range of tasks for use with tasks they were\nnot designed for. We then evaluate these prompts across fixed multiple choice\ndatasets for a quantitative analysis of how certain attributes of a prompt\naffect performance. We find that including the choices and using prompts not\nused during pre-training provide significant improvements. All experiments and\ncode can be found https://github.com/gabeorlanski/zero-shot-cross-task.",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Gabriel Orlanski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15754"
  },
  {
    "id": "arXiv:2203.15755",
    "title": "Demonstration-Bootstrapped Autonomous Practicing via Multi-Task  Reinforcement Learning",
    "abstract": "Reinforcement learning systems have the potential to enable continuous\nimprovement in unstructured environments, leveraging data collected\nautonomously. However, in practice these systems require significant amounts of\ninstrumentation or human intervention to learn in the real world. In this work,\nwe propose a system for reinforcement learning that leverages multi-task\nreinforcement learning bootstrapped with prior data to enable continuous\nautonomous practicing, minimizing the number of resets needed while being able\nto learn temporally extended behaviors. We show how appropriately provided\nprior data can help bootstrap both low-level multi-task policies and strategies\nfor sequencing these tasks one after another to enable learning with minimal\nresets. This mechanism enables our robotic system to practice with minimal\nhuman intervention at training time while being able to solve long horizon\ntasks at test time. We show the efficacy of the proposed system on a\nchallenging kitchen manipulation task both in simulation and in the real world,\ndemonstrating the ability to practice autonomously in order to solve temporally\nextended problems.",
    "descriptor": "\nComments: Interactive website at this https URL\n",
    "authors": [
      "Abhishek Gupta",
      "Corey Lynch",
      "Brandon Kinman",
      "Garrett Peake",
      "Sergey Levine",
      "Karol Hausman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15755"
  },
  {
    "id": "arXiv:2203.15758",
    "title": "A Sparsity-promoting Dictionary Model for Variational Autoencoders",
    "abstract": "Structuring the latent space in probabilistic deep generative models, e.g.,\nvariational autoencoders (VAEs), is important to yield more expressive models\nand interpretable representations, and to avoid overfitting. One way to achieve\nthis objective is to impose a sparsity constraint on the latent variables,\ne.g., via a Laplace prior. However, such approaches usually complicate the\ntraining phase, and they sacrifice the reconstruction quality to promote\nsparsity. In this paper, we propose a simple yet effective methodology to\nstructure the latent space via a sparsity-promoting dictionary model, which\nassumes that each latent code can be written as a sparse linear combination of\na dictionary's columns. In particular, we leverage a computationally efficient\nand tuning-free method, which relies on a zero-mean Gaussian latent prior with\nlearnable variances. We derive a variational inference scheme to train the\nmodel. Experiments on speech generative modeling demonstrate the advantage of\nthe proposed approach over competing techniques, since it promotes sparsity\nwhile not deteriorating the output speech quality.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Mostafa Sadeghi",
      "Paul Magron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15758"
  },
  {
    "id": "arXiv:2203.15760",
    "title": "A New Expression for the Product of Two $\u03ba-\u03bc$ Shadowed Random  Variables and its Application to Wireless Communication",
    "abstract": "In this work, the product of two independent and non-identically distributed\n(i.n.i.d) $\\kappa - \\mu $ shadowed random variables is studied. We derive the\nseries expression for the probability density function (PDF), cumulative\ndistribution function (CDF), and moment generating function (MGF) of the\nproduct of two (i.n.i.d) $\\kappa - \\mu $ shadowed random variables. The derived\nformulation in this work is quite general as they incorporate most of the\ntypically used fading channels. As an application example, outage probability\n(OP) has been derived for cascaded wireless systems and relay-assisted\ncommunications with a variable gain relay. Extensive Monte-Carlo simulations\nhave also been carried out.",
    "descriptor": "",
    "authors": [
      "Shashank Shekhar",
      "Sheetal Kalyani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.15760"
  },
  {
    "id": "arXiv:2203.15765",
    "title": "FisherMatch: Semi-Supervised Rotation Regression via Entropy-based  Filtering",
    "abstract": "Estimating the 3DoF rotation from a single RGB image is an important yet\nchallenging problem. Recent works achieve good performance relying on a large\namount of expensive-to-obtain labeled data. To reduce the amount of\nsupervision, we for the first time propose a general framework, FisherMatch,\nfor semi-supervised rotation regression, without assuming any domain-specific\nknowledge or paired data. Inspired by the popular semi-supervised approach,\nFixMatch, we propose to leverage pseudo label filtering to facilitate the\ninformation flow from labeled data to unlabeled data in a teacher-student\nmutual learning framework. However, incorporating the pseudo label filtering\nmechanism into semi-supervised rotation regression is highly non-trivial,\nmainly due to the lack of a reliable confidence measure for rotation\nprediction. In this work, we propose to leverage matrix Fisher distribution to\nbuild a probabilistic model of rotation and devise a matrix Fisher-based\nregressor for jointly predicting rotation along with its prediction\nuncertainty. We then propose to use the entropy of the predicted distribution\nas a confidence measure, which enables us to perform pseudo label filtering for\nrotation regression. For supervising such distribution-like pseudo labels, we\nfurther investigate the problem of how to enforce loss between two matrix\nFisher distributions. Our extensive experiments show that our method can work\nwell even under very low labeled data ratios on different benchmarks, achieving\nsignificant and consistent performance improvement over supervised learning and\nother semi-supervised learning baselines. Our project page is at\nhttps://yd-yin.github.io/FisherMatch.",
    "descriptor": "\nComments: CVPR2022 Oral\n",
    "authors": [
      "Yingda Yin",
      "Yingcheng Cai",
      "He Wang",
      "Baoquan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15765"
  },
  {
    "id": "arXiv:2203.15767",
    "title": "Polite or Direct? Conversation Design of a Smart Display for Older  Adults Based on Politeness Theory",
    "abstract": "Conversational interfaces increasingly rely on human-like dialogue to offer a\nnatural experience. However, relying on dialogue involving multiple exchanges\nfor even simple tasks can overburden users, particularly older adults. In this\npaper, we explored the use of politeness theory in conversation design to\nalleviate this burden and improve user experience. To achieve this goal, we\ncategorized the voice interaction offered by a smart display application\ndesigned for older adults into seven major speech acts: request, suggest,\ninstruct, comment, welcome, farewell, and repair. We identified face needs for\neach speech act, applied politeness strategies that best address these needs,\nand tested the ability of these strategies to shape the perceived politeness of\na voice assistant in an online study ($n=64$). Based on the findings of this\nstudy, we designed direct and polite versions of the system and conducted a\nfield study ($n=15$) in which participants used each of the versions for five\ndays at their homes. Based on five factors merged from our qualitative\nfindings, we identified four distinctive user personas$\\unicode{x2013}$socially\noriented follower, socially oriented leader, utility oriented follower, and\nutility oriented leader$\\unicode{x2013}$that can inform personalized design of\nsmart displays.",
    "descriptor": "\nComments: To be published in 2022 CHI Conference on Human Factors in Computing Systems (CHI '22)\n",
    "authors": [
      "Yaxin Hu",
      "Yuxiao Qu",
      "Adam Maus",
      "Bilge Mutlu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.15767"
  },
  {
    "id": "arXiv:2203.15770",
    "title": "Target Geometry Estimation Using Deep Neural Networks in Sonar Sensing",
    "abstract": "Accurate imaging of target shape is a crucial aspect of wideband FM biosonar\nin echolocating bats, for which we have developed new algorithms that provide a\nsolution for the shape of complicated targets in the computational domain. We\nuse recurrent neural networks and convolutional neural networks to determine\nthe number of glints (i.e., major reflecting surfaces) making up the target's\nstructure and the distances between the glints (target shape in sonar). Echoes\nare dechirped relative to broadcasts, and the dechirped spectrograms are\nscanned in short time segments to find local spectral ripple patterns arising\nfrom different interglint delay separations. By proceeding in successive\ntime-window slices, we mimic time-frequency neural processing in the bat's\nauditory system as a novel means of real-time target discrimination for sonar\nsensing in robotics.",
    "descriptor": "",
    "authors": [
      "Chen Ming",
      "James A. Simmons"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15770"
  },
  {
    "id": "arXiv:2203.15772",
    "title": "Impact of Information Flow Topology on Safety of Tightly-coupled  Connected and Automated Vehicle Platoons Utilizing Stochastic Control",
    "abstract": "Cooperative driving, enabled by Vehicle-to-Everything (V2X) communication, is\nexpected to significantly contribute to the transportation system's safety and\nefficiency. Cooperative Adaptive Cruise Control (CACC), a major cooperative\ndriving application, has been the subject of many studies in recent years. The\nprimary motivation behind using CACC is to reduce traffic congestion and\nimprove traffic flow, traffic throughput, and highway capacity. Since the\ninformation flow between cooperative vehicles can significantly affect the\ndynamics of a platoon, the design and performance of control components are\ntightly dependent on the communication component performance. In addition, the\nchoice of Information Flow Topology (IFT) can affect certain platoons\nproperties such as stability and scalability. Although cooperative vehicles\nperception can be expanded to multiple predecessors information by using V2X\ncommunication, the communication technologies still suffer from scalability\nissues. Therefore, cooperative vehicles are required to predict each other's\nbehavior to compensate for the effects of non-ideal communication. The notion\nof Model-Based Communication (MBC) was proposed to enhance cooperative vehicles\nperception under non-ideal communication by introducing a new flexible content\nstructure for broadcasting joint vehicles dynamic/drivers behavior models. By\nutilizing a non-parametric (Bayesian) modeling scheme, i.e., Gaussian Process\nRegression (GPR), and the MBC concept, this paper develops a discrete hybrid\nstochastic model predictive control approach and examines the impact of\ncommunication losses and different information flow topologies on the\nperformance and safety of the platoon. The results demonstrate an improvement\nin response time and safety using more vehicles information, validating the\npotential of cooperation to attenuate disturbances and improve traffic flow and\nsafety.",
    "descriptor": "",
    "authors": [
      "Mahdi Razzaghpour",
      "Sahand Mosharafian",
      "Arash Raftari",
      "Javad Mohammadpour Velni",
      "Yaser P. Fallah"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15772"
  },
  {
    "id": "arXiv:2203.15773",
    "title": "Streaming parallel transducer beam search with fast-slow cascaded  encoders",
    "abstract": "Streaming ASR with strict latency constraints is required in many speech\nrecognition applications. In order to achieve the required latency, streaming\nASR models sacrifice accuracy compared to non-streaming ASR models due to lack\nof future input context. Previous research has shown that streaming and\nnon-streaming ASR for RNN Transducers can be unified by cascading causal and\nnon-causal encoders. This work improves upon this cascaded encoders framework\nby leveraging two streaming non-causal encoders with variable input context\nsizes that can produce outputs at different audio intervals (e.g. fast and\nslow). We propose a novel parallel time-synchronous beam search algorithm for\ntransducers that decodes from fast-slow encoders, where the slow encoder\ncorrects the mistakes generated from the fast encoder. The proposed algorithm,\nachieves up to 20% WER reduction with a slight increase in token emission\ndelays on the public Librispeech dataset and in-house datasets. We also explore\ntechniques to reduce the computation by distributing processing between the\nfast and slow encoders. Lastly, we explore sharing the parameters in the fast\nencoder to reduce the memory footprint. This enables low latency processing on\nedge devices with low computation cost and a low memory footprint.",
    "descriptor": "\nComments: 5 pages, 2 figures, Interspeech 2022 submission\n",
    "authors": [
      "Jay Mahadeokar",
      "Yangyang Shi",
      "Ke Li",
      "Duc Le",
      "Jiedan Zhu",
      "Vikas Chandra",
      "Ozlem Kalinli",
      "Michael L Seltzer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15773"
  },
  {
    "id": "arXiv:2203.15776",
    "title": "Efficiently Evolving Swarm Behaviors Using Grammatical Evolution With  PPA-style Behavior Trees",
    "abstract": "Evolving swarm behaviors with artificial agents is computationally expensive\nand challenging. Because reward structures are often sparse in swarm problems,\nonly a few simulations among hundreds evolve successful swarm behaviors.\nAdditionally, swarm evolutionary algorithms typically rely on ad hoc fitness\nstructures, and novel fitness functions need to be designed for each swarm\ntask. This paper evolves swarm behaviors by systematically combining\nPostcondition-Precondition-Action (PPA) canonical Behavior Trees (BT) with a\nGrammatical Evolution. The PPA structure replaces ad hoc reward structures with\nsystematic postcondition checks, which allows a common grammar to learn\nsolutions to different tasks using only environmental cues and BT feedback. The\nstatic performance of learned behaviors is poor because no agent learns all\nnecessary subtasks, but performance while evolving is excellent because agents\ncan quickly change behaviors in new contexts. The evolving algorithm succeeded\nin 75\\% of learning trials for both foraging and nest maintenance tasks, an\neight-fold improvement over prior work.",
    "descriptor": "\nComments: To be published in ICLR Cells2Societies Workshop 2022\n",
    "authors": [
      "Aadesh Neupane",
      "Michael A. Goodrich"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.15776"
  },
  {
    "id": "arXiv:2203.15778",
    "title": "Text-Driven Video Acceleration: A Weakly-Supervised Reinforcement  Learning Method",
    "abstract": "The growth of videos in our digital age and the users' limited time raise the\ndemand for processing untrimmed videos to produce shorter versions conveying\nthe same information. Despite the remarkable progress that summarization\nmethods have made, most of them can only select a few frames or skims, creating\nvisual gaps and breaking the video context. This paper presents a novel\nweakly-supervised methodology based on a reinforcement learning formulation to\naccelerate instructional videos using text. A novel joint reward function\nguides our agent to select which frames to remove and reduce the input video to\na target length without creating gaps in the final video. We also propose the\nExtended Visually-guided Document Attention Network (VDAN+), which can generate\na highly discriminative embedding space to represent both textual and visual\ndata. Our experiments show that our method achieves the best performance in\nPrecision, Recall, and F1 Score against the baselines while effectively\ncontrolling the video's output length. Visit\nhttps://www.verlab.dcc.ufmg.br/semantic-hyperlapse/tpami2022/ for code and\nextra results.",
    "descriptor": "\nComments: Accepted to the IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 2022. arXiv admin note: text overlap with arXiv:2003.14229\n",
    "authors": [
      "Washington Ramos",
      "Michel Silva",
      "Edson Araujo",
      "Victor Moura",
      "Keller Oliveira",
      "Leandro Soriano Marcolino",
      "Erickson R. Nascimento"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15778"
  },
  {
    "id": "arXiv:2203.15780",
    "title": "Adaptive Learning with Artificial Barriers Yielding Nash Equilibria in  General Games",
    "abstract": "Artificial barriers in Learning Automata (LA) is a powerful and yet\nunder-explored concept although it was first proposed in the 1980s. Introducing\nartificial non-absorbing barriers makes the LA schemes resilient to being\ntrapped in absorbing barriers, a phenomenon which is often referred to as lock\nin probability leading to an exclusive choice of one action after convergence.\nWithin the field of LA and reinforcement learning in general, there is a\nsacristy of theoretical works and applications of schemes with artificial\nbarriers. In this paper, we devise a LA with artificial barriers for solving a\ngeneral form of stochastic bimatrix game. Classical LA systems possess\nproperties of absorbing barriers and they are a powerful tool in game theory\nand were shown to converge to game's of Nash equilibrium under limited\ninformation. However, the stream of works in LA for solving game theoretical\nproblems can merely solve the case where the Saddle Point of the game exists in\na pure strategy and fail to reach mixed Nash equilibrium when no Saddle Point\nexists for a pure strategy. In this paper, by resorting to the powerful concept\nof artificial barriers, we suggest a LA that converges to an optimal mixed Nash\nequilibrium even though there may be no Saddle Point when a pure strategy is\ninvoked. Our deployed scheme is of Linear Reward-Inaction ($L_{R-I}$) flavor\nwhich is originally an absorbing LA scheme, however, we render it non-absorbing\nby introducing artificial barriers in an elegant and natural manner, in the\nsense that that the well-known legacy $L_{R-I}$ scheme can be seen as an\ninstance of our proposed algorithm for a particular choice of the barrier.\nFurthermore, we present an $S$ Learning version of our LA with absorbing\nbarriers that is able to handle $S$-Learning environment in which the feedback\nis continuous and not binary as in the case of the $L_{R-I}$.",
    "descriptor": "",
    "authors": [
      "Ismail Hassan",
      "Anis Yazidi",
      "B. John Oommen"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15780"
  },
  {
    "id": "arXiv:2203.15781",
    "title": "Deep Reinforcement Learning Aided Platoon Control Relying on V2X  Information",
    "abstract": "The impact of Vehicle-to-Everything (V2X) communications on platoon control\nperformance is investigated. Platoon control is essentially a sequential\nstochastic decision problem (SSDP), which can be solved by Deep Reinforcement\nLearning (DRL) to deal with both the control constraints and uncertainty in the\nplatoon leading vehicle's behavior. In this context, the value of V2X\ncommunications for DRL-based platoon controllers is studied with an emphasis on\nthe tradeoff between the gain of including exogenous information in the system\nstate for reducing uncertainty and the performance erosion due to the\ncurse-of-dimensionality. Our objective is to find the specific set of\ninformation that should be shared among the vehicles for the construction of\nthe most appropriate state space. SSDP models are conceived for platoon control\nunder different information topologies (IFT) by taking into account `just\nsufficient' information. Furthermore, theorems are established for comparing\nthe performance of their optimal policies. In order to determine whether a\npiece of information should or should not be transmitted for improving the\nDRL-based control policy, we quantify its value by deriving the conditional KL\ndivergence of the transition models. More meritorious information is given\nhigher priority in transmission, since including it in the state space has a\nhigher probability in offsetting the negative effect of having higher state\ndimensions. Finally, simulation results are provided to illustrate the\ntheoretical analysis.",
    "descriptor": "",
    "authors": [
      "Lei Lei",
      "Tong Liu",
      "Kan Zheng",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15781"
  },
  {
    "id": "arXiv:2203.15783",
    "title": "A Systematic Review on Interactive Virtual Reality Laboratory",
    "abstract": "Virtual Reality has become a significant element of education throughout the\nyears. To understand the quality and advantages of these techniques, it is\nimportant to understand how they were developed and evaluated. Since COVID-19,\nthe education system has drastically changed a lot. It has shifted from being\nin a classroom with a whiteboard and projectors to having your own room in\nfront of your laptop in a virtual meeting. In this respect, virtual reality in\nthe laboratory or Virtual Laboratory is the main focus of this research, which\nis intended to comprehend the work done in quality education from a distance\nusing VR. As per the findings of the study, adopting virtual reality in\neducation can help students learn more effectively and also help them increase\nperspective, enthusiasm, and knowledge of complex notions by offering them an\ninteractive experience in which they can engage and learn more effectively.\nThis highlights the importance of a significant expansion of VR use in\nlearning, the majority of which employ scientific comparison approaches to\ncompare students who use VR to those who use the traditional method for\nlearning.",
    "descriptor": "\nComments: 10 pages, 7 figures, 7 tables\n",
    "authors": [
      "Fozlur Rahman",
      "Marium Sana Mim",
      "Feekra Baset Baishakhi",
      "Mahmudul Hasan",
      "Md. Kishor Morol"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15783"
  },
  {
    "id": "arXiv:2203.15784",
    "title": "Implementation of an Automated Learning System for Non-experts",
    "abstract": "Automated machine learning systems for non-experts could be critical for\nindustries to adopt artificial intelligence to their own applications. This\npaper detailed the engineering system implementation of an automated machine\nlearning system called YMIR, which completely relies on graphical interface to\ninteract with users. After importing training/validation data into the system,\na user without AI knowledge can label the data, train models, perform data\nmining and evaluation by simply clicking buttons. The paper described: 1) Open\nimplementation of model training and inference through docker containers. 2)\nImplementation of task and resource management. 3) Integration of Labeling\nsoftware. 4) Implementation of HCI (Human Computer Interaction) with a rebuilt\ncollaborative development paradigm. We also provide subsequent case study on\ntraining models with the system. We hope this paper can facilitate the\nprosperity of our automated machine learning community from industry\napplication perspective. The code of the system has already been released to\nGitHub (https://github.com/industryessentials/ymir).",
    "descriptor": "",
    "authors": [
      "Phoenix X. Huang",
      "Zhiwei Zhao",
      "Chao Liu",
      "Jingyi Liu",
      "Wenze Hu",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15784"
  },
  {
    "id": "arXiv:2203.15786",
    "title": "Electric-field-coupled oscillators for collective electrochemical  perception in underwater robotics",
    "abstract": "This work explores the application of nonlinear oscillators coupled by\nelectric field in water for collective tasks in underwater robotics. Such\ncoupled oscillators operate in clear and colloidal (mud, bottom silt) water and\nrepresent a collective electrochemical sensor that is sensitive to global\nenvironmental parameters, geometry of common electric field and spatial\ndynamics of autonomous underwater vehicles (AUVs). Implemented in hardware and\nsoftware, this approach can be used to create global awareness in the group of\nrobots, which possess limited sensing and communication capabilities. Using\noscillators from different AUVs enables extending the range limitations related\nto electric dipole of a single AUV. Applications of this technique are\ndemonstrated for detecting the number of AUVs, distances between them,\nperception of dielectric objects, synchronization of behavior and\ndiscrimination between 'collective self' and 'collective non-self' through an\n'electrical mirror'. These approaches have been implemented in several research\nprojects with AUVs in fresh and salt water.",
    "descriptor": "",
    "authors": [
      "Serge Kernbach"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2203.15786"
  },
  {
    "id": "arXiv:2203.15787",
    "title": "Effective and Acceptable Eco-Driving Guidance for Human-Driving  Vehicles: A Review",
    "abstract": "Ecodriving guidance includes courses or suggestions for human drivers to\nimprove driving behaviour, reducing energy use and emissions. This paper\npresents a systematic review of existing eco-driving guidance studies and\nidentifies challenges to tackle in the future. A standard agreement on the\nguidance design has not been reached, leading to difficulties in designing and\nimplementing eco-driving guidance for human drivers. Both static and dynamic\nguidance systems have a great variety of guidance results. In addition, the\ninfluencing factors, such as the suggestion content, the displaying methods,\nand drivers socio-demographic characteristics, have opposite effects on the\nguidance result across studies, while the reason has not been revealed. Drivers\nmotivation to practice eco behaviour, especially long-term, is overlooked.\nBesides, the relationship between users acceptance and system effectiveness is\nstill unclear. Adaptive driving suggestions based on drivers habits can improve\nthe effectiveness, while this field is under investigation.",
    "descriptor": "",
    "authors": [
      "Ran Tu",
      "Junshi Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.15787"
  },
  {
    "id": "arXiv:2203.15788",
    "title": "COMPASS: Contrastive Multimodal Pretraining for Autonomous Systems",
    "abstract": "Learning representations that generalize across tasks and domains is\nchallenging yet necessary for autonomous systems. Although task-driven\napproaches are appealing, designing models specific to each application can be\ndifficult in the face of limited data, especially when dealing with highly\nvariable multimodal input spaces arising from different tasks in different\nenvironments.We introduce the first general-purpose pretraining pipeline,\nCOntrastive Multimodal Pretraining for AutonomouS Systems (COMPASS), to\novercome the limitations of task-specific models and existing pretraining\napproaches. COMPASS constructs a multimodal graph by considering the essential\ninformation for autonomous systems and the properties of different modalities.\nThrough this graph, multimodal signals are connected and mapped into two\nfactorized spatio-temporal latent spaces: a \"motion pattern space\" and a\n\"current state space.\" By learning from multimodal correspondences in each\nlatent space, COMPASS creates state representations that models necessary\ninformation such as temporal dynamics, geometry, and semantics. We pretrain\nCOMPASS on a large-scale multimodal simulation dataset TartanAir\n\\cite{tartanair2020iros} and evaluate it on drone navigation, vehicle racing,\nand visual odometry tasks. The experiments indicate that COMPASS can tackle all\nthree scenarios and can also generalize to unseen environments and real-world\ndata.",
    "descriptor": "",
    "authors": [
      "Shuang Ma",
      "Sai Vemprala",
      "Wenshan Wang",
      "Jayesh K. Gupta",
      "Yale Song",
      "Daniel McDuff",
      "Ashish Kapoor"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15788"
  },
  {
    "id": "arXiv:2203.15789",
    "title": "Revisiting Neighborhood-based Link Prediction for Collaborative  Filtering",
    "abstract": "Collaborative filtering (CF) is one of the most successful and fundamental\ntechniques in recommendation systems. In recent years, Graph Neural Network\n(GNN)-based CF models, such as NGCF [31], LightGCN [10] and GTN [9] have\nachieved tremendous success and significantly advanced the state-of-the-art.\nWhile there is a rich literature of such works using advanced models for\nlearning user and item representations separately, item recommendation is\nessentially a link prediction problem between users and items. Furthermore,\nwhile there have been early works employing link prediction for collaborative\nfiltering [5, 6], this trend has largely given way to works focused on\naggregating information from user and item nodes, rather than modeling links\ndirectly. In this paper, we propose a new linkage (connectivity) score for\nbipartite graphs, generalizing multiple standard link prediction methods. We\ncombine this new score with an iterative degree update process in the user-item\ninteraction bipartite graph to exploit local graph structures without any node\nmodeling. The result is a simple, non-deep learning model with only six\nlearnable parameters. Despite its simplicity, we demonstrate our approach\nsignificantly outperforms existing state-of-the-art GNN-based CF approaches on\nfour widely used benchmarks. In particular, on Amazon-Book, we demonstrate an\nover 60% improvement for both Recall and NDCG. We hope our work would invite\nthe community to revisit the link prediction aspect of collaborative filtering,\nwhere significant performance gains could be achieved through aligning link\nprediction with item recommendations.",
    "descriptor": "\nComments: Accepted by Graph Learning Workshop at WWW'22\n",
    "authors": [
      "Hao-Ming Fu",
      "Patrick Poirson",
      "Kwot Sin Lee",
      "Chen Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15789"
  },
  {
    "id": "arXiv:2203.15792",
    "title": "Target and Task specific Source-Free Domain Adaptive Image Segmentation",
    "abstract": "Solving the domain shift problem during inference is essential in medical\nimaging as most deep-learning based solutions suffer from it. In practice,\ndomain shifts are tackled by performing Unsupervised Domain Adaptation (UDA),\nwhere a model is adapted to an unlabeled target domain by leveraging the\nlabelled source domain. In medical scenarios, the data comes with huge privacy\nconcerns making it difficult to apply standard UDA techniques. Hence, a closer\nclinical setting is Source-Free UDA (SFUDA), where we have access to source\ntrained model but not the source data during adaptation. Methods trying to\nsolve SFUDA typically address the domain shift using pseudo-label based\nself-training techniques. However, due to domain shift, these pseudo-labels are\nusually of high entropy and denoising them still does not make them perfect\nlabels to supervise the model. Therefore, adapting the source model with noisy\npseudo labels reduces its segmentation capability while addressing the domain\nshift. To this end, we propose a two-stage approach for source-free domain\nadaptive image segmentation: 1) Target-specific adaptation followed by 2)\nTask-specific adaptation. In the first stage, we focus on generating\ntarget-specific pseudo labels while suppressing high entropy regions by\nproposing an Ensemble Entropy Minimization loss. We also introduce a selective\nvoting strategy to enhance pseudo-label generation. In the second stage, we\nfocus on adapting the network for task-specific representation by using a\nteacher-student self-training approach based on augmentation-guided\nconsistency. We evaluate our proposed method on both 2D fundus datasets and 3D\nMRI volumes across 7 different domain shifts where we achieve better\nperformance than recent UDA and SF-UDA methods for medical image segmentation.\nCode is available at https://github.com/Vibashan/tt-sfuda.",
    "descriptor": "",
    "authors": [
      "Vibashan VS",
      "Jeya Maria Jose Valanarasu",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15792"
  },
  {
    "id": "arXiv:2203.15793",
    "title": "Instance Relation Graph Guided Source-Free Domain Adaptive Object  Detection",
    "abstract": "Unsupervised Domain Adaptation (UDA) is an effective approach to tackle the\nissue of domain shift. Specifically, UDA methods try to align the source and\ntarget representations to improve the generalization on the target domain.\nFurther, UDA methods work under the assumption that the source data is\naccessible during the adaptation process. However, in real-world scenarios, the\nlabelled source data is often restricted due to privacy regulations, data\ntransmission constraints, or proprietary data concerns. The Source-Free Domain\nAdaptation (SFDA) setting aims to alleviate these concerns by adapting a\nsource-trained model for the target domain without requiring access to the\nsource data. In this paper, we explore the SFDA setting for the task of\nadaptive object detection. To this end, we propose a novel training strategy\nfor adapting a source-trained object detector to the target domain without\nsource data. More precisely, we design a novel contrastive loss to enhance the\ntarget representations by exploiting the objects relations for a given target\ndomain input. These object instance relations are modelled using an Instance\nRelation Graph (IRG) network, which are then used to guide the contrastive\nrepresentation learning. In addition, we utilize a student-teacher based\nknowledge distillation strategy to avoid overfitting to the noisy pseudo-labels\ngenerated by the source-trained model. Extensive experiments on multiple object\ndetection benchmark datasets show that the proposed approach is able to\nefficiently adapt source-trained object detectors to the target domain,\noutperforming previous state-of-the-art domain adaptive detection methods. Code\nis available at https://github.com/Vibashan/irg-sfda.",
    "descriptor": "",
    "authors": [
      "Vibashan VS",
      "Poojan Oza",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15793"
  },
  {
    "id": "arXiv:2203.15794",
    "title": "CHEX: CHannel EXploration for CNN Model Compression",
    "abstract": "Channel pruning has been broadly recognized as an effective technique to\nreduce the computation and memory cost of deep convolutional neural networks.\nHowever, conventional pruning methods have limitations in that: they are\nrestricted to pruning process only, and they require a fully pre-trained large\nmodel. Such limitations may lead to sub-optimal model quality as well as\nexcessive memory and training cost. In this paper, we propose a novel Channel\nExploration methodology, dubbed as CHEX, to rectify these problems. As opposed\nto pruning-only strategy, we propose to repeatedly prune and regrow the\nchannels throughout the training process, which reduces the risk of pruning\nimportant channels prematurely. More exactly: From intra-layer's aspect, we\ntackle the channel pruning problem via a well known column subset selection\n(CSS) formulation. From inter-layer's aspect, our regrowing stages open a path\nfor dynamically re-allocating the number of channels across all the layers\nunder a global channel sparsity constraint. In addition, all the exploration\nprocess is done in a single training from scratch without the need of a\npre-trained large model. Experimental results demonstrate that CHEX can\neffectively reduce the FLOPs of diverse CNN architectures on a variety of\ncomputer vision tasks, including image classification, object detection,\ninstance segmentation, and 3D vision. For example, our compressed ResNet-50\nmodel on ImageNet dataset achieves 76% top1 accuracy with only 25% FLOPs of the\noriginal ResNet-50 model, outperforming previous state-of-the-art channel\npruning methods. The checkpoints and code are available at here .",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Zejiang Hou",
      "Minghai Qin",
      "Fei Sun",
      "Xiaolong Ma",
      "Kun Yuan",
      "Yi Xu",
      "Yen-Kuang Chen",
      "Rong Jin",
      "Yuan Xie",
      "Sun-Yuan Kung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15794"
  },
  {
    "id": "arXiv:2203.15795",
    "title": "Not Another School Resource Map: Meeting Underserved Families'  Information Needs Requires Trusting Relationships and Personalized Care",
    "abstract": "Public school districts across the United States have implemented school\nchoice systems that have the potential to improve underserved students' access\nto educational opportunities. However, research has shown that learning about\nand applying for schools can be extremely time-consuming and expensive, making\nit difficult for these systems to create more equitable access to resources in\npractice. A common factor surfaced in prior work is unequal access to\ninformation about the schools and enrollment process. In response, governments\nand non-profits have invested in providing more information about schools to\nparents, for instance, through detailed online dashboards. However, we know\nlittle about what information is actually useful for historically marginalized\nand underserved families. We conducted interviews with 10 low-income families\nand families of color to learn about the challenges they faced navigating an\nonline school choice and enrollment system. We complement this data with four\ninterviews with people who have supported families through the enrollment\nprocess in a wide range of roles, from school principal to non-profit staff\n(\"parent advocates\"). Our findings highlight the value of personalized support\nand trusting relationships to delivering relevant and helpful information. We\ncontrast this against online information resources and dashboards, which tend\nto be impersonal, target a broad audience, and make strong assumptions about\nwhat parents should look for in a school without sensitivity to families'\nvarying circumstances. We advocate for an assets-based design approach to\ninformation support in public school enrollment, which would ask how we can\nsupport the local, one-on-one support that community members already provide.",
    "descriptor": "\nComments: To appear in CSCW 2022\n",
    "authors": [
      "Samantha Robertson",
      "Tonya Nguyen",
      "Niloufar Salehi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.15795"
  },
  {
    "id": "arXiv:2203.15798",
    "title": "DRaCoN -- Differentiable Rasterization Conditioned Neural Radiance  Fields for Articulated Avatars",
    "abstract": "Acquisition and creation of digital human avatars is an important problem\nwith applications to virtual telepresence, gaming, and human modeling. Most\ncontemporary approaches for avatar generation can be viewed either as 3D-based\nmethods, which use multi-view data to learn a 3D representation with appearance\n(such as a mesh, implicit surface, or volume), or 2D-based methods which learn\nphoto-realistic renderings of avatars but lack accurate 3D representations. In\nthis work, we present, DRaCoN, a framework for learning full-body volumetric\navatars which exploits the advantages of both the 2D and 3D neural rendering\ntechniques. It consists of a Differentiable Rasterization module, DiffRas, that\nsynthesizes a low-resolution version of the target image along with additional\nlatent features guided by a parametric body model. The output of DiffRas is\nthen used as conditioning to our conditional neural 3D representation module\n(c-NeRF) which generates the final high-res image along with body geometry\nusing volumetric rendering. While DiffRas helps in obtaining photo-realistic\nimage quality, c-NeRF, which employs signed distance fields (SDF) for 3D\nrepresentations, helps to obtain fine 3D geometric details. Experiments on the\nchallenging ZJU-MoCap and Human3.6M datasets indicate that DRaCoN outperforms\nstate-of-the-art methods both in terms of error metrics and visual quality.",
    "descriptor": "\nComments: Project page at this https URL\n",
    "authors": [
      "Amit Raj",
      "Umar Iqbal",
      "Koki Nagano",
      "Sameh Khamis",
      "Pavlo Molchanov",
      "James Hays",
      "Jan Kautz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15798"
  },
  {
    "id": "arXiv:2203.15799",
    "title": "StyleT2I: Toward Compositional and High-Fidelity Text-to-Image Synthesis",
    "abstract": "Although progress has been made for text-to-image synthesis, previous methods\nfall short of generalizing to unseen or underrepresented attribute compositions\nin the input text. Lacking compositionality could have severe implications for\nrobustness and fairness, e.g., inability to synthesize the face images of\nunderrepresented demographic groups. In this paper, we introduce a new\nframework, StyleT2I, to improve the compositionality of text-to-image\nsynthesis. Specifically, we propose a CLIP-guided Contrastive Loss to better\ndistinguish different compositions among different sentences. To further\nimprove the compositionality, we design a novel Semantic Matching Loss and a\nSpatial Constraint to identify attributes' latent directions for intended\nspatial region manipulations, leading to better disentangled latent\nrepresentations of attributes. Based on the identified latent directions of\nattributes, we propose Compositional Attribute Adjustment to adjust the latent\ncode, resulting in better compositionality of image synthesis. In addition, we\nleverage the $\\ell_2$-norm regularization of identified latent directions (norm\npenalty) to strike a nice balance between image-text alignment and image\nfidelity. In the experiments, we devise a new dataset split and an evaluation\nmetric to evaluate the compositionality of text-to-image synthesis models. The\nresults show that StyleT2I outperforms previous approaches in terms of the\nconsistency between the input text and synthesized images and achieves higher\nfidelity.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Zhiheng Li",
      "Martin Renqiang Min",
      "Kai Li",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15799"
  },
  {
    "id": "arXiv:2109.13714",
    "title": "MSR-NV: Neural Vocoder Using Multiple Sampling Rates",
    "abstract": "The development of neural vocoders (NVs) has resulted in the high-quality and\nfast generation of waveforms. However, conventional NVs target a single\nsampling rate and require re-training when applied to different sampling rates.\nA suitable sampling rate varies from application to application due to the\ntrade-off between speech quality and generation speed. In this study, we\npropose a method to handle multiple sampling rates in a single NV, called the\nMSR-NV. By generating waveforms step-by-step starting from a low sampling rate,\nMSR-NV can efficiently learn the characteristics of each frequency band and\nsynthesize high-quality speech at multiple sampling rates. It can be regarded\nas an extension of the previously proposed NVs, and in this study, we extend\nthe structure of Parallel WaveGAN (PWG). Experimental evaluation results\ndemonstrate that the proposed method achieves remarkably higher subjective\nquality than the original PWG trained separately at 16, 24, and 48 kHz, without\nincreasing the inference time. We also show that MSR-NV can leverage speech\nwith lower sampling rates to further improve the quality of the synthetic\nspeech.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Kentaro Mitsui",
      "Kei Sawada"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.13714"
  },
  {
    "id": "arXiv:2203.10509",
    "title": "Stability Of Matrix Polynomials In One And Several Variables",
    "abstract": "The paper presents methods of eigenvalue localisation of regular matrix\npolynomials, in particular, stability of matrix polynomials is investigated.\nFor this aim a stronger notion of hyperstability is introduced and widely\ndiscussed. Matrix versions of the Gauss-Lucas theorem and Sz\\'asz inequality\nare shown. Further, tools for investigating (hyper)stability by multivariate\ncomplex analysis methods are provided. Several second- and third-order matrix\npolynomials with particular semi-definiteness assumptions on coefficients are\nshown to be stable.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Oskar Jakub Szyma\u0144ski",
      "Micha\u0142 Wojtylak"
    ],
    "subjectives": [
      "Complex Variables (math.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.10509"
  },
  {
    "id": "arXiv:2203.11602",
    "title": "An Algorithm for Solving Solvable Polynomial Equations of Arbitrary  Degree by Radicals",
    "abstract": "This work provides a method(an algorithm) for solving the solvable unary\nalgebraic equation $f(x)=0$ ($f(x)\\in\\mathbb{Q}[x]$) of arbitrary degree and\nobtaining the exact radical roots. This method requires that we know the Galois\ngroup as the permutation group of the roots of $f(x)$ and the approximate roots\nwith sufficient precision beforehand. Of course, the approximate roots are not\nnecessary but can help reduce the quantity of computation. The algorithm\ncomplexity is approximately proportional to the 4th power of the size of the\nGalois group of $f(x)$. The whole algorithm doesn't need to deal with\ntremendous polynomials or reduce symmetric polynomials.",
    "descriptor": "",
    "authors": [
      "Song Li"
    ],
    "subjectives": [
      "Rings and Algebras (math.RA)",
      "Data Structures and Algorithms (cs.DS)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.11602"
  },
  {
    "id": "arXiv:2203.13847",
    "title": "Cluster Algebras: Network Science and Machine Learning",
    "abstract": "Cluster algebras have recently become an important player in mathematics and\nphysics. In this work, we investigate them through the lens of modern data\nscience, specifically with techniques from network science and\nmachine-learning. Network analysis methods are applied to the exchange graphs\nfor cluster algebras of varying mutation types. The analysis indicates that\nwhen the graphs are represented without identifying by permutation equivalence\nbetween clusters an elegant symmetry emerges in the quiver exchange graph\nembedding. The ratio between number of seeds and number of quivers associated\nto this symmetry is computed for finite Dynkin type algebras up to rank 5, and\nconjectured for higher ranks. Simple machine learning techniques successfully\nlearn to differentiate cluster algebras from their seeds. The learning\nperformance exceeds 0.9 accuracies between algebras of the same mutation type\nand between types, as well as relative to artificially generated data.",
    "descriptor": "\nComments: 38 pages, 27 figures\n",
    "authors": [
      "Pierre-Philippe Dechant",
      "Yang-Hui He",
      "Elli Heyes",
      "Edward Hirst"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2203.13847"
  },
  {
    "id": "arXiv:2203.14000",
    "title": "On Time Stepping Schemes Considering Switching Behaviors for Power  System Electromagnetic Transient Simulation",
    "abstract": "Several difficulties will appear when typical electromagnetic transient\nsimulation, using the implicit trapezoidal method and fixed step sizes, is\napplied to power systems with switching behaviors. These difficulties are\naddressed by different aspects of time stepping schemes in the literature. This\npaper first details the different aspects and reviews corresponding methods.\nSome misunderstanding in the literature is clarified. Issues that may be\nencountered by the existing methods are concurrently revealed. Based on the\ndetailed review, the paper then puts forward a novel time stepping scheme which\nfully addresses the difficulties. The effectiveness of the proposed scheme is\ndemonstrated via numerical case studies.",
    "descriptor": "\nComments: Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sheng Lei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.14000"
  },
  {
    "id": "arXiv:2203.14173",
    "title": "Maximal origami flip graphs of flat-foldable vertices: properties and  algorithms",
    "abstract": "Flat origami studies straight line, planar graphs $C=(V,E)$ drawn on a region\n$R\\subset\\mathbb{R}^2$ that can act as crease patterns to map, or fold, $R$\ninto $\\mathbb{R}^2$ in a way that is continuous and a piecewise isometry\nexactly on the faces of $C$. Associated with such crease pattern graphs are\nvalid mountain-valley (MV) assignments $\\mu:E\\to\\{-1,1\\}$, indicating which\ncreases can be mountains (convex) or valleys (concave) to allow $R$ to\nphysically fold flat without self-intersecting. In this paper, we initiate the\nfirst study of how valid MV assignments of single-vertex crease patterns are\nrelated to one another via face-flips, a concept that emerged from applications\nof origami in engineering and physics, where flipping a face $F$ means\nswitching the MV parity of all creases of $C$ that border $F$. Specifically, we\nstudy the origami flip graph ${\\rm{OFG}}(C)$, whose vertices are all valid MV\nassignments of $C$ and edges connect assignments that differ by only one face\nflip. We prove that, for the single-vertex crease pattern $A_{2n}$ whose $2n$\nsector angles around the vertex are all equal, ${\\rm{OFG}}(A_{2n})$ contains as\nsubgraphs all other origami flip graphs of degree-$2n$ flat origami vertex\ncrease patterns. We also prove that ${\\rm{OFG}}(A_{2n})$ is connected and has\ndiameter $n$ by providing two $O(n^2)$ algorithms to traverse between vertices\nin the graph, and we enumerate the vertices, edges, and degree sequence of\n${\\rm{OFG}}(A_{2n})$. We conclude with open questions on the surprising\ncomplexity found in origami flip graphs of this type.",
    "descriptor": "",
    "authors": [
      "Thomas C. Hull",
      "Manuel Morales",
      "Sarah Nash",
      "Natalya Ter-Saakov"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.14173"
  },
  {
    "id": "arXiv:2203.14593",
    "title": "On-the-fly Feature Based Speaker Adaptation for Dysarthric and Elderly  Speech Recognition",
    "abstract": "Automatic recognition of dysarthric and elderly speech highly challenging\ntasks to date. Speaker-level heterogeneity attributed to accent or gender\ncommonly found in normal speech, when aggregated with age and speech impairment\nseverity, create large diversity among speakers. Speaker adaptation techniques\nplay a crucial role in personalization of ASR systems for such users. Their\nmobility issues limit the amount of speaker-level data available for model\nbased adaptation. To this end, this paper investigates two novel forms of\nfeature based on-the-fly rapid speaker adaptation approaches. The first is\nbased on speaker-level variance regularized spectral basis embedding (SBEVR)\nfeatures, while the other uses on-the-fly learning hidden unit contributions\n(LHUC) transforms conditioned on speaker-level spectral features. Experiments\nconducted on the UASpeech dysarthric and DimentiaBank Pitt elderly speech\ndatasets suggest the proposed SBEVR features based adaptation statistically\nsignificantly outperform both the baseline on-the-fly i-Vector adapted hybrid\nTDNN/DNN systems by up to 2.48% absolute (7.92% relative) reduction in word\nerror rate (WER), and offline batch mode model based LHUC adaptation using all\nspeaker-level data by 0.78% absolute (2.41% relative) in WER reduction.",
    "descriptor": "\nComments: In submission to Interspeech 2022\n",
    "authors": [
      "Mengzhe Geng",
      "Xurong Xie",
      "Rongfeng Su",
      "Jianwei Yu",
      "Zi Ye",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.14593"
  },
  {
    "id": "arXiv:2203.14962",
    "title": "Learning to segment fetal brain tissue from noisy annotations",
    "abstract": "Automatic fetal brain tissue segmentation can enhance the quantitative\nassessment of brain development at this critical stage. Deep learning methods\nrepresent the state of the art in medical image segmentation and have also\nachieved impressive results in brain segmentation. However, effective training\nof a deep learning model to perform this task requires a large number of\ntraining images to represent the rapid development of the transient fetal brain\nstructures. On the other hand, manual multi-label segmentation of a large\nnumber of 3D images is prohibitive. To address this challenge, we segmented 272\ntraining images, covering 19-39 gestational weeks, using an automatic\nmulti-atlas segmentation strategy based on deformable registration and\nprobabilistic atlas fusion, and manually corrected large errors in those\nsegmentations. Since this process generated a large training dataset with noisy\nsegmentations, we developed a novel label smoothing procedure and a loss\nfunction to train a deep learning model with smoothed noisy segmentations. Our\nproposed methods properly account for the uncertainty in tissue boundaries. We\nevaluated our method on 23 manually-segmented test images of a separate set of\nfetuses. Results show that our method achieves an average Dice similarity\ncoefficient of 0.893 and 0.916 for the transient structures of younger and\nolder fetuses, respectively. Our method generated results that were\nsignificantly more accurate than several state-of-the-art methods including\nnnU-Net that achieved the closest results to our method. Our trained model can\nserve as a valuable tool to enhance the accuracy and reproducibility of fetal\nbrain analysis in MRI.",
    "descriptor": "",
    "authors": [
      "Davood Karimi",
      "Caitlin K. Rollins",
      "Clemente Velasco-Annis",
      "Abdelhakim Ouaalam",
      "Ali Gholipour"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.14962"
  },
  {
    "id": "arXiv:2203.15009",
    "title": "DAMNETS: A Deep Autoregressive Model for Generating Markovian Network  Time Series",
    "abstract": "In this work, we introduce DAMNETS, a deep generative model for Markovian\nnetwork time series. Time series of networks are found in many fields such as\ntrade or payment networks in economics, contact networks in epidemiology or\nsocial media posts over time. Generative models of such data are useful for\nMonte-Carlo estimation and data set expansion, which is of interest for both\ndata privacy and model fitting. Using recent ideas from the Graph Neural\nNetwork (GNN) literature, we introduce a novel GNN encoder-decoder structure in\nwhich an encoder GNN learns a latent representation of the input graph, and a\ndecoder GNN uses this representation to simulate the network dynamics. We show\nusing synthetic data sets that DAMNETS can replicate features of network\ntopology across time observed in the real world, such as changing community\nstructure and preferential attachment. DAMNETS outperforms competing methods on\nall of our measures of sample quality over several real and synthetic data\nsets.",
    "descriptor": "\nComments: 12 pages, 10 figures, 2 tables\n",
    "authors": [
      "Jase Clarkson",
      "Mihai Cucuringu",
      "Andrew Elliott",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.15009"
  },
  {
    "id": "arXiv:2203.15015",
    "title": "Deep Interactive Learning-based ovarian cancer segmentation of  H&E-stained whole slide images to study morphological patterns of BRCA  mutation",
    "abstract": "Deep learning has been widely used to analyze digitized hematoxylin and eosin\n(H&E)-stained histopathology whole slide images. Automated cancer segmentation\nusing deep learning can be used to diagnose malignancy and to find novel\nmorphological patterns to predict molecular subtypes. To train pixel-wise\ncancer segmentation models, manual annotation from pathologists is generally a\nbottleneck due to its time-consuming nature. In this paper, we propose Deep\nInteractive Learning with a pretrained segmentation model from a different\ncancer type to reduce manual annotation time. Instead of annotating all pixels\nfrom cancer and non-cancer regions on giga-pixel whole slide images, an\niterative process of annotating mislabeled regions from a segmentation model\nand training/finetuning the model with the additional annotation can reduce the\ntime. Especially, employing a pretrained segmentation model can further reduce\nthe time than starting annotation from scratch. We trained an accurate ovarian\ncancer segmentation model with a pretrained breast segmentation model by 3.5\nhours of manual annotation which achieved intersection-over-union of 0.74,\nrecall of 0.86, and precision of 0.84. With automatically extracted high-grade\nserous ovarian cancer patches, we attempted to train another deep learning\nmodel to predict BRCA mutation. The segmentation model and code have been\nreleased at https://github.com/MSKCC-Computational-Pathology/DMMN-ovary.",
    "descriptor": "",
    "authors": [
      "David Joon Ho",
      "M. Herman Chui",
      "Chad M. Vanderbilt",
      "Jiwon Jung",
      "Mark E. Robson",
      "Chan-Sik Park",
      "Jin Roh",
      "Thomas J. Fuchs"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15015"
  },
  {
    "id": "arXiv:2203.15038",
    "title": "Accelerating innovation with software abstractions for scalable  computational geophysics",
    "abstract": "We present the SLIM (https://github.com/slimgroup) open-source software\nframework for computational geophysics, and more generally, inverse problems\nbased on the wave-equation (e.g., medical ultrasound). We developed a software\nenvironment aimed at scalable research and development by designing multiple\nlayers of abstractions. This environment allows the researchers to easily\nformulate their problem in an abstract fashion, while still being able to\nexploit the latest developments in high-performance computing. We illustrate\nand demonstrate the benefits of our software design on many geophysical\napplications, including seismic inversion and physics-informed machine learning\nfor geophysics (e.g., loop unrolled imaging, uncertainty quantification), all\nwhile facilitating the integration of external software.",
    "descriptor": "",
    "authors": [
      "Mathias Louboutin",
      "Philipp A. Witte",
      "Ali Siahkoohi",
      "Gabrio Rizzuti",
      "Ziyi Yin",
      "Rafael Orozco",
      "Felix J. Herrmann"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Mathematical Software (cs.MS)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.15038"
  },
  {
    "id": "arXiv:2203.15081",
    "title": "Word Discovery in Visually Grounded, Self-Supervised Speech Models",
    "abstract": "We present a method for visually-grounded spoken term discovery. After\ntraining either a HuBERT or wav2vec2.0 model to associate spoken captions with\nnatural images, we show that powerful word segmentation and clustering\ncapability emerges within the model's self-attention heads. Our experiments\nreveal that this ability is not present to nearly the same extent in the base\nHuBERT and wav2vec2.0 models, suggesting that the visual grounding task is a\ncrucial component of the word discovery capability we observe. We also evaluate\nour method on the Buckeye word segmentation and ZeroSpeech spoken term\ndiscovery tasks, where we outperform all currently published methods on several\nmetrics.",
    "descriptor": "\nComments: submitted to Interspeech 2022\n",
    "authors": [
      "Puyuan Peng",
      "David Harwath"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15081"
  },
  {
    "id": "arXiv:2203.15092",
    "title": "Improved singing voice separation with chromagram-based pitch-aware  remixing",
    "abstract": "Singing voice separation aims to separate music into vocals and accompaniment\ncomponents. One of the major constraints for the task is the limited amount of\ntraining data with separated vocals. Data augmentation techniques such as\nrandom source mixing have been shown to make better use of existing data and\nmildly improve model performance. We propose a novel data augmentation\ntechnique, chromagram-based pitch-aware remixing, where music segments with\nhigh pitch alignment are mixed. By performing controlled experiments in both\nsupervised and semi-supervised settings, we demonstrate that training models\nwith pitch-aware remixing significantly improves the test signal-to-distortion\nratio (SDR)",
    "descriptor": "\nComments: To appear at ICASSP 2022, 5 pages, 1 figure\n",
    "authors": [
      "Siyuan Yuan",
      "Zhepei Wang",
      "Umut Isik",
      "Ritwik Giri",
      "Jean-Marc Valin",
      "Michael M. Goodwin",
      "Arvindh Krishnaswamy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15092"
  },
  {
    "id": "arXiv:2203.15147",
    "title": "Separate What You Describe: Language-Queried Audio Source Separation",
    "abstract": "In this paper, we introduce the task of language-queried audio source\nseparation (LASS), which aims to separate a target source from an audio mixture\nbased on a natural language query of the target source (e.g., \"a man tells a\njoke followed by people laughing\"). A unique challenge in LASS is associated\nwith the complexity of natural language description and its relation with the\naudio sources. To address this issue, we proposed LASS-Net, an end-to-end\nneural network that is learned to jointly process acoustic and linguistic\ninformation, and separate the target source that is consistent with the\nlanguage query from an audio mixture. We evaluate the performance of our\nproposed system with a dataset created from the AudioCaps dataset. Experimental\nresults show that LASS-Net achieves considerable improvements over baseline\nmethods. Furthermore, we observe that LASS-Net achieves promising\ngeneralization results when using diverse human-annotated descriptions as\nqueries, indicating its potential use in real-world scenarios. The separated\naudio samples and source code are available at\nhttps://liuxubo717.github.io/LASS-demopage.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022, 5 pages, 3 figures\n",
    "authors": [
      "Xubo Liu",
      "Haohe Liu",
      "Qiuqiang Kong",
      "Xinhao Mei",
      "Jinzheng Zhao",
      "Qiushi Huang",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.15147"
  },
  {
    "id": "arXiv:2203.15163",
    "title": "CAT-Net: A Cross-Slice Attention Transformer Model for Prostate Zonal  Segmentation in MRI",
    "abstract": "Prostate cancer is the second leading cause of cancer death among men in the\nUnited States. The diagnosis of prostate MRI often relies on the accurate\nprostate zonal segmentation. However, state-of-the-art automatic segmentation\nmethods often fail to produce well-contained volumetric segmentation of the\nprostate zones since certain slices of prostate MRI, such as base and apex\nslices, are harder to segment than other slices. This difficulty can be\novercome by accounting for the cross-slice relationship of adjacent slices, but\ncurrent methods do not fully learn and exploit such relationships. In this\npaper, we propose a novel cross-slice attention mechanism, which we use in a\nTransformer module to systematically learn the cross-slice relationship at\ndifferent scales. The module can be utilized in any existing learning-based\nsegmentation framework with skip connections. Experiments show that our\ncross-slice attention is able to capture the cross-slice information in\nprostate zonal segmentation and improve the performance of current\nstate-of-the-art methods. Our method significantly improves segmentation\naccuracy in the peripheral zone, such that the segmentation results are\nconsistent across all the prostate slices (apex, mid-gland, and base).",
    "descriptor": "",
    "authors": [
      "Alex Ling Yu Hung",
      "Haoxin Zheng",
      "Qi Miao",
      "Steven S. Raman",
      "Demetri Terzopoulos",
      "Kyunghyun Sung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15163"
  },
  {
    "id": "arXiv:2203.15167",
    "title": "On Convergence of General Truncation-Augmentation Schemes for  Approximating Stationary Distributions of Markov Chains",
    "abstract": "In the analysis of Markov chains and processes, it is sometimes convenient to\nreplace an unbounded state space with a \"truncated\" bounded state space. When\nsuch a replacement is made, one often wants to know whether the equilibrium\nbehavior of the truncated chain or process is close to that of the untruncated\nsystem. For example, such questions arise naturally when considering numerical\nmethods for computing stationary distributions on unbounded state space. In\nthis paper, we study general truncation-augmentation schemes, in which the\nsubstochastic truncated \"northwest corner\" of the transition matrix or kernel\nis stochasticized (or augmented) arbitrarily. In the presence of a Lyapunov\ncondition involving a coercive function, we show that such schemes are\ngenerally convergent in countable state space, provided that the truncation is\nchosen as a sublevel set of the Lyapunov function. For stochastically monotone\nMarkov chains on $\\mathbb Z_+$, we prove that we can always choose the\ntruncation sets to be of the form $\\{0,1,...,n\\}$. We then provide sufficient\nconditions for weakly continuous Markov chains under which general\ntruncation-augmentation schemes converge weakly in continuous state space.\nFinally, we briefly discuss the extension of the theory to continuous time\nMarkov jump processes.",
    "descriptor": "",
    "authors": [
      "Alex Infanger",
      "Peter W. Glynn",
      "Yuanyuan Liu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15167"
  },
  {
    "id": "arXiv:2203.15183",
    "title": "Visualizations of Complex Sequences of Family-Infant Vocalizations Using  Bag-of-Audio-Words Approach Based on Wav2vec 2.0 Features",
    "abstract": "In the U.S., approximately 15-17% of children 2-8 years of age are estimated\nto have at least one diagnosed mental, behavioral or developmental disorder.\nHowever, such disorders often go undiagnosed, and the ability to evaluate and\ntreat disorders in the first years of life is limited. To analyze infant\ndevelopmental changes, previous studies have shown advanced ML models excel at\nclassifying infant and/or parent vocalizations collected using cell phone,\nvideo, or audio-only recording device like LENA. In this study, we pilot test\nthe audio component of a new infant wearable multi-modal device that we have\ndeveloped called LittleBeats (LB). LB audio pipeline is advanced in that it\nprovides reliable labels for both speaker diarization and vocalization\nclassification tasks, compared with other platforms that only record audio\nand/or provide speaker diarization labels. We leverage wav2vec 2.0 to obtain\nsuperior and more nuanced results with the LB family audio stream. We use a\nbag-of-audio-words method with wav2vec 2.0 features to create high-level\nvisualizations to understand family-infant vocalization interactions. We\ndemonstrate that our high-quality visualizations capture major types of family\nvocalization interactions, in categories indicative of mental, behavioral, and\ndevelopmental health, for both labeled and unlabeled LB audio.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Jialu Li",
      "Mark Hasegawa-Johnson",
      "Nancy L. McElwain"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15183"
  },
  {
    "id": "arXiv:2203.15236",
    "title": "Best Arm Identification in Restless Markov Multi-Armed Bandits",
    "abstract": "We study the problem of identifying the best arm in a multi-armed bandit\nenvironment when each arm is a time-homogeneous and ergodic discrete-time\nMarkov process on a common, finite state space. The state evolution on each arm\nis governed by the arm's transition probability matrix (TPM). A decision entity\nthat knows the set of arm TPMs but not the exact mapping of the TPMs to the\narms, wishes to find the index of the best arm as quickly as possible, subject\nto an upper bound on the error probability. The decision entity selects one arm\nat a time sequentially, and all the unselected arms continue to undergo state\nevolution ({\\em restless} arms). For this problem, we derive the first-known\nproblem instance-dependent asymptotic lower bound on the growth rate of the\nexpected time required to find the index of the best arm, where the asymptotics\nis as the error probability vanishes. Further, we propose a sequential policy\nthat, for an input parameter $R$, forcibly selects an arm that has not been\nselected for $R$ consecutive time instants. We show that this policy achieves\nan upper bound that depends on $R$ and is monotonically non-increasing as\n$R\\to\\infty$. The question of whether, in general, the limiting value of the\nupper bound as $R\\to\\infty$ matches with the lower bound, remains open. We\nidentify a special case in which the upper and the lower bounds match. Prior\nworks on best arm identification have dealt with (a) independent and\nidentically distributed observations from the arms, and (b) rested Markov arms,\nwhereas our work deals with the more difficult setting of restless Markov arms.",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "P. N. Karthik",
      "Kota Srinivas Reddy",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15236"
  },
  {
    "id": "arXiv:2203.15250",
    "title": "Analysis of EEG frequency bands for Envisioned Speech Recognition",
    "abstract": "The use of Automatic speech recognition (ASR) interfaces have become\nincreasingly popular in daily life for use in interaction and control of\nelectronic devices. The interfaces currently being used are not feasible for a\nvariety of users such as those suffering from a speech disorder, locked-in\nsyndrome, paralysis or people with utmost privacy requirements. In such cases,\nan interface that can identify envisioned speech using electroencephalogram\n(EEG) signals can be of great benefit. Various works targeting this problem\nhave been done in the past. However, there has been limited work in identifying\nthe frequency bands ($\\delta, \\theta, \\alpha, \\beta, \\gamma$) of the EEG signal\nthat contribute towards envisioned speech recognition. Therefore, in this work,\nwe aim to analyze the significance of different EEG frequency bands and signals\nobtained from different lobes of the brain and their contribution towards\nrecognizing envisioned speech. Signals obtained from different lobes and\nbandpass filtered for different frequency bands are fed to a spatio-temporal\ndeep learning architecture with Convolutional Neural Network (CNN) and Long\nShort-Term Memory (LSTM). The performance is evaluated on a publicly available\ndataset comprising of three classification tasks - digit, character and images.\nWe obtain a classification accuracy of $85.93\\%$, $87.27\\%$ and $87.51\\%$ for\nthe three tasks respectively. The code for the implementation has been made\navailable at https://github.com/ayushayt/ImaginedSpeechRecognition.",
    "descriptor": "",
    "authors": [
      "Ayush Tripathi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2203.15250"
  },
  {
    "id": "arXiv:2203.15257",
    "title": "$L_2$-Gain Analysis of Coupled Linear 2D PDEs using Linear PI  Inequalities",
    "abstract": "In this paper, we present a semidefinite programming method for estimating\nthe $L_2$-gain of systems governed by 2nd order linear Partial Differential\nEquations (PDEs) in two spatial variables. It has previously been shown that,\nfor any such PDE, an equivalent Partial Integral Equation (PIE) can be derived.\nThese PIEs are expressed in terms of Partial Integral (PI) operators mapping\nstates in $L_2[\\Omega_{xy}]$, and are free of the boundary and continuity\nconstraints appearing in PDEs. In this paper, we extend the 2D PIE\nrepresentation to include input and output signals in $\\mathbb{R}^n$, deriving\na bijective map between solutions of the PDE and the PIE, along with the\nnecessary formulae to convert between the two representations. Next, using the\nalgebraic properties of PI operators, we prove that an upper bound on the\n$L_2$-gain of PIEs can be verified by testing feasibility of a Linear PI\nInequality (LPI), expressed as a positivity constraint on PI operators mapping\n$\\mathbb{R}^n\\times L_2[\\Omega_{xy}]$. Finally, we use positive matrices to\nparameterize the cone of positive PI operators on $\\mathbb{R}^n\\times\nL_2[\\Omega_{xy}]$, allowing feasibility of the $L_2$-gain LPI to be tested as\nan LMI. We implement this test in the MATLAB toolbox PIETOOLS, and demonstrate\nthat this approach allows the $L_2$-gain of PDEs to be estimated with\nrelatively little conservatism.",
    "descriptor": "",
    "authors": [
      "Declan S. Jagt",
      "Matthew M. Peet"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.15257"
  },
  {
    "id": "arXiv:2203.15269",
    "title": "Vision Transformers in Medical Computer Vision -- A Contemplative  Retrospection",
    "abstract": "Recent escalation in the field of computer vision underpins a huddle of\nalgorithms with the magnificent potential to unravel the information contained\nwithin images. These computer vision algorithms are being practised in medical\nimage analysis and are transfiguring the perception and interpretation of\nImaging data. Among these algorithms, Vision Transformers are evolved as one of\nthe most contemporary and dominant architectures that are being used in the\nfield of computer vision. These are immensely utilized by a plenty of\nresearchers to perform new as well as former experiments. Here, in this article\nwe investigate the intersection of Vision Transformers and Medical images and\nproffered an overview of various ViTs based frameworks that are being used by\ndifferent researchers in order to decipher the obstacles in Medical Computer\nVision. We surveyed the application of Vision transformers in different areas\nof medical computer vision such as image-based disease classification,\nanatomical structure segmentation, registration, region-based lesion Detection,\ncaptioning, report generation, reconstruction using multiple medical imaging\nmodalities that greatly assist in medical diagnosis and hence treatment\nprocess. Along with this, we also demystify several imaging modalities used in\nMedical Computer Vision. Moreover, to get more insight and deeper\nunderstanding, self-attention mechanism of transformers is also explained\nbriefly. Conclusively, we also put some light on available data sets, adopted\nmethodology, their performance measures, challenges and their solutions in form\nof discussion. We hope that this review article will open future directions for\nresearchers in medical computer vision.",
    "descriptor": "",
    "authors": [
      "Arshi Parvaiz",
      "Muhammad Anwaar Khalid",
      "Rukhsana Zafar",
      "Huma Ameer",
      "Muhammad Ali",
      "Muhammad Moazam Fraz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15269"
  },
  {
    "id": "arXiv:2203.15275",
    "title": "A Multi-size Kernel based Adaptive Convolutional Neural Network for  Bearing Fault Diagnosis",
    "abstract": "Bearing fault identification and analysis is an important research area in\nthe field of machinery fault diagnosis. Aiming at the common faults of rolling\nbearings, we propose a data-driven diagnostic algorithm based on the\ncharacteristics of bearing vibrations called multi-size kernel based adaptive\nconvolutional neural network (MSKACNN). Using raw bearing vibration signals as\nthe inputs, MSKACNN provides vibration feature learning and signal\nclassification capabilities to identify and analyze bearing faults. Ball mixing\nis a ball bearing production quality problem that is difficult to identify\nusing traditional frequency domain analysis methods since it requires high\nfrequency resolutions of the measurement signals and results in a long\nanalyzing time. The proposed MSKACNN is shown to improve the efficiency and\naccuracy of ball mixing diagnosis. To further demonstrate the effectiveness of\nMSKACNN in bearing fault identification, a bearing vibration data acquisition\nsystem was developed, and vibration signal acquisition was performed on rolling\nbearings under five different fault conditions including ball mixing. The\nresulting datasets were used to analyze the performance of our proposed model.\nTo validate the adaptive ability of MSKACNN, fault test data from the Case\nWestern Reserve University Bearing Data Center were also used. Test results\nshow that MSKACNN can identify the different bearing conditions with high\naccuracy with high generalization ability. We presented an implementation of\nthe MSKACNN as a lightweight module for a real-time bearing fault diagnosis\nsystem that is suitable for production.",
    "descriptor": "\nComments: 21 pages, 16 figures\n",
    "authors": [
      "Guangwei Yu",
      "Gang Li",
      "Xingtong Si",
      "Zhuoyuan Song"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15275"
  },
  {
    "id": "arXiv:2203.15277",
    "title": "Decomposed Temporal Dynamic CNN: Efficient Time-Adaptive Network for  Text-Independent Speaker Verification Explained with Speaker Activation Map",
    "abstract": "Temporal dynamic models for text-independent speaker verification extract\nconsistent speaker information regardless of phonemes by using temporal dynamic\nCNN (TDY-CNN) in which kernels adapt to each time bin. However, TDY-CNN shows\nlimitations that the model is too large and does not guarantee the diversity of\nadaptive kernels. To address these limitations, we propose decomposed temporal\ndynamic CNN (DTDY-CNN) that makes adaptive kernel by combining static kernel\nand dynamic residual based on matrix decomposition. The baseline model using\nDTDY-CNN maintained speaker verification performance while reducing the number\nof model parameters by 35% compared to the model using TDY-CNN. In addition,\ndetailed behaviors of temporal dynamic models on extraction of speaker\ninformation was explained using speaker activation maps (SAM) modified from\ngradient-weighted class activation mapping (Grad-CAM). In DTDY-CNN, the static\nkernel activates voiced features of utterances, and the dynamic residual\nactivates unvoiced high-frequency features of phonemes. DTDY-CNN effectively\nextracts speaker information from not only formant frequencies and harmonics\nbut also detailed unvoiced phonemes' information, thus explaining its\noutstanding performance on text-independent speaker verification.",
    "descriptor": "\nComments: Submitted to InterSpeech 2022\n",
    "authors": [
      "Seong-Hu Kim",
      "Hyeonuk Nam",
      "Yong-Hwa Park"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15277"
  },
  {
    "id": "arXiv:2203.15283",
    "title": "Mel Frequency Spectral Domain Defenses against Adversarial Attacks on  Speech Recognition Systems",
    "abstract": "A variety of recent works have looked into defenses for deep neural networks\nagainst adversarial attacks particularly within the image processing domain.\nSpeech processing applications such as automatic speech recognition (ASR) are\nincreasingly relying on deep learning models, and so are also prone to\nadversarial attacks. However, many of the defenses explored for ASR simply\nadapt the image-domain defenses, which may not provide optimal robustness. This\npaper explores speech specific defenses using the mel spectral domain, and\nintroduces a novel defense method called 'mel domain noise flooding' (MDNF).\nMDNF applies additive noise to the mel spectrogram of a speech utterance prior\nto re-synthesising the audio signal. We test the defenses against strong\nwhite-box adversarial attacks such as projected gradient descent (PGD) and\nCarlini-Wagner (CW) attacks, and show better robustness compared to a\nrandomized smoothing baseline across strong threat models.",
    "descriptor": "\nComments: This paper is 5 pages long and was submitted to Interspeech 2022\n",
    "authors": [
      "Nicholas Mehlman",
      "Anirudh Sreeram",
      "Raghuveer Peri",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15283"
  },
  {
    "id": "arXiv:2203.15292",
    "title": "A Two-phase Framework with a B\u00e9zier Simplex-based Interpolation  Method for Computationally Expensive Multi-objective Optimization",
    "abstract": "This paper proposes a two-phase framework with a B\\'{e}zier simplex-based\ninterpolation method (TPB) for computationally expensive multi-objective\noptimization. The first phase in TPB aims to approximate a few Pareto optimal\nsolutions by optimizing a sequence of single-objective scalar problems. The\nfirst phase in TPB can fully exploit a state-of-the-art single-objective\nderivative-free optimizer. The second phase in TPB utilizes a B\\'{e}zier\nsimplex model to interpolate the solutions obtained in the first phase. The\nsecond phase in TPB fully exploits the fact that a B\\'{e}zier simplex model can\napproximate the Pareto optimal solution set by exploiting its simplex structure\nwhen a given problem is simplicial. We investigate the performance of TPB on\nthe 55 bi-objective BBOB problems. The results show that TPB performs\nsignificantly better than HMO-CMA-ES and some state-of-the-art meta-model-based\noptimizers.",
    "descriptor": "\nComments: This is an accepted version of a paper published in the proceedings of GECCO 2022\n",
    "authors": [
      "Ryoji Tanabe",
      "Youhei Akimoto",
      "Ken Kobayashi",
      "Hiroshi Umeki",
      "Shinichi Shirakawa",
      "Naoki Hamada"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.15292"
  },
  {
    "id": "arXiv:2203.15347",
    "title": "Harmonizing Pathological and Normal Pixels for Pseudo-healthy Synthesis",
    "abstract": "Synthesizing a subject-specific pathology-free image from a pathological\nimage is valuable for algorithm development and clinical practice. In recent\nyears, several approaches based on the Generative Adversarial Network (GAN)\nhave achieved promising results in pseudo-healthy synthesis. However, the\ndiscriminator (i.e., a classifier) in the GAN cannot accurately identify\nlesions and further hampers from generating admirable pseudo-healthy images. To\naddress this problem, we present a new type of discriminator, the segmentor, to\naccurately locate the lesions and improve the visual quality of pseudo-healthy\nimages. Then, we apply the generated images into medical image enhancement and\nutilize the enhanced results to cope with the low contrast problem existing in\nmedical image segmentation. Furthermore, a reliable metric is proposed by\nutilizing two attributes of label noise to measure the health of synthetic\nimages. Comprehensive experiments on the T2 modality of BraTS demonstrate that\nthe proposed method substantially outperforms the state-of-the-art methods. The\nmethod achieves better performance than the existing methods with only 30\\% of\nthe training data. The effectiveness of the proposed method is also\ndemonstrated on the LiTS and the T1 modality of BraTS. The code and the\npre-trained model of this study are publicly available at\nhttps://github.com/Au3C2/Generator-Versus-Segmentor.",
    "descriptor": "",
    "authors": [
      "Yunlong Zhang",
      "Xin Lin",
      "Yihong Zhuang",
      "LiyanSun",
      "Yue Huang",
      "Xinghao Ding",
      "Guisheng Wang",
      "Lin Yang",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15347"
  },
  {
    "id": "arXiv:2203.15368",
    "title": "Multiclass classification using quantum convolutional neural networks  with hybrid quantum-classical learning",
    "abstract": "Multiclass classification is of great interest for various machine learning\napplications, for example, it is a common task in computer vision, where one\nneeds to categorize an image into three or more classes. Here we propose a\nquantum machine learning approach based on quantum convolutional neural\nnetworks for solving this problem. The corresponding learning procedure is\nimplemented via TensorFlowQuantum as a hybrid quantum-classical (variational)\nmodel, where quantum output results are fed to softmax cost function with\nsubsequent minimization of it via optimization of parameters of quantum\ncircuit. Our conceptional improvements include a new model for quantum\nperceptron and optimized structure of the quantum circuit. We use the proposed\napproach to demonstrate the 4-class classification for the case of the MNIST\ndataset using eight qubits for data encoding and four acnilla qubits. Our\nresults demonstrate comparable accuracy of our solution with classical\nconvolutional neural networks with comparable numbers of trainable parameters.\nWe expect that our finding provide a new step towards the use of quantum\nmachine learning for solving practically relevant problems in the NISQ era and\nbeyond.",
    "descriptor": "\nComments: 7 pages, 5 figures, 3 tables\n",
    "authors": [
      "Denis Bokhan",
      "Alena S. Mastiukova",
      "Aleksey S. Boev",
      "Dmitrii N. Trubnikov",
      "Aleksey K. Fedorov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15368"
  },
  {
    "id": "arXiv:2203.15383",
    "title": "Category Guided Attention Network for Brain Tumor Segmentation in MRI",
    "abstract": "Objective: Magnetic resonance imaging (MRI) has been widely used for the\nanalysis and diagnosis of brain diseases. Accurate and automatic brain tumor\nsegmentation is of paramount importance for radiation treatment. However, low\ntissue contrast in tumor regions makes it a challenging task.Approach: We\npropose a novel segmentation network named Category Guided Attention U-Net (CGA\nU-Net). In this model, we design a Supervised Attention Module (SAM) based on\nthe attention mechanism, which can capture more accurate and stable long-range\ndependency in feature maps without introducing much computational cost.\nMoreover, we propose an intra-class update approach to reconstruct feature maps\nby aggregating pixels of the same category. Main results: Experimental results\non the BraTS 2019 datasets show that the proposed method outperformers the\nstate-of-the-art algorithms in both segmentation performance and computational\ncomplexity. Significance: The CGA U-Net can effectively capture the global\nsemantic information in the MRI image by using the SAM module, while\nsignificantly reducing the computational cost. Code is available at\nhttps://github.com/delugewalker/CGA-U-Net.",
    "descriptor": "",
    "authors": [
      "Jiangyun Li",
      "Hong Yu",
      "Chen Chen",
      "Meng Ding",
      "Sen Zha"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15383"
  },
  {
    "id": "arXiv:2203.15402",
    "title": "Physics-informed deep-learning applications to experimental fluid  mechanics",
    "abstract": "High-resolution reconstruction of flow-field data from low-resolution and\nnoisy measurements is of interest due to the prevalence of such problems in\nexperimental fluid mechanics, where the measurement data are in general sparse,\nincomplete and noisy. Deep-learning approaches have been shown suitable for\nsuch super-resolution tasks. However, a high number of high-resolution examples\nis needed, which may not be available for many cases. Moreover, the obtained\npredictions may lack in complying with the physical principles, e.g. mass and\nmomentum conservation. Physics-informed deep learning provides frameworks for\nintegrating data and physical laws for learning. In this study, we apply\nphysics-informed neural networks (PINNs) for super-resolution of flow-field\ndata both in time and space from a limited set of noisy measurements without\nhaving any high-resolution reference data. Our objective is to obtain a\ncontinuous solution of the problem, providing a physically-consistent\nprediction at any point in the solution domain. We demonstrate the\napplicability of PINNs for the super-resolution of flow-field data in time and\nspace through three canonical cases: Burgers' equation, two-dimensional vortex\nshedding behind a circular cylinder and the minimal turbulent channel flow. The\nrobustness of the models is also investigated by adding synthetic Gaussian\nnoise. Our results show excellent capabilities of PINNs in the context of data\naugmentation for experiments in fluid mechanics.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Hamidreza Eivazi",
      "Ricardo Vinuesa"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15402"
  },
  {
    "id": "arXiv:2203.15405",
    "title": "Automatic Detection of Speech Sound Disorder in Child Speech Using  Posterior-based Speaker Representations",
    "abstract": "This paper presents a macroscopic approach to automatic detection of speech\nsound disorder (SSD) in child speech. Typically, SSD is manifested by\npersistent articulation and phonological errors on specific phonemes in the\nlanguage. The disorder can be detected by focally analyzing the phonemes or the\nwords elicited by the child subject. In the present study, instead of\nattempting to detect individual phone- and word-level errors, we propose to\nextract a subject-level representation from a long utterance that is\nconstructed by concatenating multiple test words. The speaker verification\napproach, and posterior features generated by deep neural network models, are\napplied to derive various types of holistic representations. A linear\nclassifier is trained to differentiate disordered speech in normal one. On the\ntask of detecting SSD in Cantonese-speaking children, experimental results show\nthat the proposed approach achieves improved detection performance over\nprevious method that requires fusing phone-level detection results. Using\narticulatory posterior features to derive i-vectors from multiple-word\nutterances achieves an unweighted average recall of 78.2% and a macro F1 score\nof 78.0%.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Si-Ioi Ng",
      "Cymie Wing-Yee Ng",
      "Jiarui Wang",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15405"
  },
  {
    "id": "arXiv:2203.15410",
    "title": "Proximal-like algorithms for equilibrium seeking in mixed-integer Nash  equilibrium problems",
    "abstract": "We consider potential games with mixed-integer variables, for which we\npropose two distributed, proximal-like equilibrium seeking algorithms.\nSpecifically, we focus on two scenarios: i) the underlying game is generalized\nordinal and the agents update through iterations by choosing an exact optimal\nstrategy; ii) the game admits an exact potential and the agents adopt\napproximated optimal responses. By exploiting the properties of\ninteger-compatible regularization functions used as penalty terms affecting the\nlocal cost function of each agent, we are able to show that both algorithms\nconverge to either an exact or an $\\epsilon$-approximate equilibrium. We\ncorroborate our findings on a numerical instance of a Cournot oligopoly model.",
    "descriptor": "",
    "authors": [
      "Filippo Fabiani",
      "Barbara Franci",
      "Simone Sagratella",
      "Martin Schmidt",
      "Mathias Staudigl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15410"
  },
  {
    "id": "arXiv:2203.15412",
    "title": "A stochastic generalized Nash equilibrium model for platforms  competition in the ride-hail market",
    "abstract": "The presence of uncertainties in the ride-hailing market complicates the\npricing strategies of on-demand platforms that compete each other to offer a\nmobility service while striving to maximize their profit. Looking at this\nproblem as a stochastic generalized Nash equilibrium problem (SGNEP), we design\na distributed, stochastic equilibrium seeking algorithm with Tikhonov\nregularization to find an optimal pricing strategy. Remarkably, the proposed\niterative scheme does not require an increasing (possibly infinite) number of\nsamples of the random variable to perform the stochastic approximation, thus\nmaking it appealing from a practical perspective. Moreover, we show that the\nalgorithm returns a Nash equilibrium under mere monotonicity assumption and a\ncareful choice of the step size sequence, obtained by exploiting the specific\nstructure of the SGNEP at hand. We finally corroborate our results on a\nnumerical instance of the on-demand ride-hailing market.",
    "descriptor": "",
    "authors": [
      "Filippo Fabiani",
      "Barbara Franci"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15412"
  },
  {
    "id": "arXiv:2203.15413",
    "title": "Deep Reinforcement Learning for Data-Driven Adaptive Scanning in  Ptychography",
    "abstract": "We present a method that lowers the dose required for a ptychographic\nreconstruction by adaptively scanning the specimen, thereby providing the\nrequired spatial information redundancy in the regions of highest importance.\nThe proposed method is built upon a deep learning model that is trained by\nreinforcement learning (RL), using prior knowledge of the specimen structure\nfrom training data sets. We show that equivalent low-dose experiments using\nadaptive scanning outperform conventional ptychography experiments in terms of\nreconstruction resolution.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Marcel Schloz",
      "Johannes M\u00fcller",
      "Thomas C. Pekin",
      "Wouter Van den Broek",
      "Christoph T. Koch"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15413"
  },
  {
    "id": "arXiv:2203.15415",
    "title": "Spatiotemporal Patterns in Neurobiology: An Overview for Future  Artificial Intelligence",
    "abstract": "In recent years, there has been increasing interest in developing models and\ntools to address the complex patterns of connectivity found in brain tissue.\nSpecifically, this is due to a need to understand how emergent properties\nemerge from these network structures at multiple spatiotemporal scales. We\nargue that computational models are key tools for elucidating the possible\nfunctionalities that can emerge from interactions of heterogeneous neurons\nconnected by complex networks on multi-scale temporal and spatial domains. Here\nwe review several classes of models including spiking neurons, integrate and\nfire neurons with short term plasticity (STP), conductance based\nintegrate-and-fire models with STP, and population density neural field (PDNF)\nmodels using simple examples with emphasis on neuroscience applications while\nalso providing some potential future research directions for AI. These\ncomputational approaches allow us to explore the impact of changing underlying\nmechanisms on resulting network function both experimentally as well as\ntheoretically. Thus we hope these studies will inform future developments in\nartificial intelligence algorithms as well as help validate our understanding\nof brain processes based on experiments in animals or humans.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Sean Knight"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2203.15415"
  },
  {
    "id": "arXiv:2203.15434",
    "title": "Clean Implicit 3D Structure from Noisy 2D STEM Images",
    "abstract": "Scanning Transmission Electron Microscopes (STEMs) acquire 2D images of a 3D\nsample on the scale of individual cell components. Unfortunately, these 2D\nimages can be too noisy to be fused into a useful 3D structure and facilitating\ngood denoisers is challenging due to the lack of clean-noisy pairs.\nAdditionally, representing a detailed 3D structure can be difficult even for\nclean data when using regular 3D grids. Addressing these two limitations, we\nsuggest a differentiable image formation model for STEM, allowing to learn a\njoint model of 2D sensor noise in STEM together with an implicit 3D model. We\nshow, that the combination of these models are able to successfully disentangle\n3D signal and noise without supervision and outperform at the same time several\nbaselines on synthetic and real data.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Hannah Kniesel",
      "Timo Ropinski",
      "Tim Bergner",
      "Kavitha Shaga Devan",
      "Clarissa Read",
      "Paul Walther",
      "Tobias Ritschel",
      "Pedro Hermosilla"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15434"
  },
  {
    "id": "arXiv:2203.15446",
    "title": "A framework for minimal hereditary classes of graphs of unbounded  clique-width",
    "abstract": "We create a framework for hereditary graph classes $\\mathcal{G}^\\delta$ built\non a two-dimensional grid of vertices and edge sets defined by a triple\n$\\delta=\\{\\alpha,\\beta,\\gamma\\}$ of objects that define edges between\nconsecutive columns, edges between non-consecutive columns (called bonds), and\nedges within columns. This framework captures all previously proven minimal\nhereditary classes of graph of unbounded clique-width, and many new ones,\nalthough we do not claim this includes all such classes.\nWe show that a graph class $\\mathcal{G}^\\delta$ has unbounded clique-width if\nand only if a certain parameter $\\mathcal{N}^\\delta$ is unbounded. We further\nshow that $\\mathcal{G}^\\delta$ is minimal of unbounded clique-width (and,\nindeed, minimal of unbounded linear clique-width) if another parameter\n$\\mathcal{M}^\\beta$ is bounded, and also $\\delta$ has defined recurrence\ncharacteristics. Both the parameters $\\mathcal{N}^\\delta$ and\n$\\mathcal{M}^\\beta$ are properties of a triple $\\delta=(\\alpha,\\beta,\\gamma)$,\nand measure the number of distinct neighbourhoods in certain auxiliary graphs.\nThroughout our work, we introduce new methods to the study of clique-width,\nincluding the use of Ramsey theory in arguments related to unboundedness, and\nexplicit (linear) clique-width expressions for subclasses of minimal classes of\nunbounded clique-width.",
    "descriptor": "\nComments: 32 pages, 7 figures\n",
    "authors": [
      "Robert Brignall",
      "Daniel Cocks"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.15446"
  },
  {
    "id": "arXiv:2203.15447",
    "title": "Transfer Learning Framework for Low-Resource Text-to-Speech using a  Large-Scale Unlabeled Speech Corpus",
    "abstract": "Training a text-to-speech (TTS) model requires a large scale text labeled\nspeech corpus, which is troublesome to collect. In this paper, we propose a\ntransfer learning framework for TTS that utilizes a large amount of unlabeled\nspeech dataset for pre-training. By leveraging wav2vec2.0 representation,\nunlabeled speech can highly improve performance, especially in the lack of\nlabeled speech. We also extend the proposed method to zero-shot multi-speaker\nTTS (ZS-TTS). The experimental results verify the effectiveness of the proposed\nmethod in terms of naturalness, intelligibility, and speaker generalization. We\nhighlight that the single speaker TTS model fine-tuned on the only 10 minutes\nof labeled dataset outperforms the other baselines, and the ZS-TTS model\nfine-tuned on the only 30 minutes of single speaker dataset can generate the\nvoice of the arbitrary speaker, by pre-training on unlabeled multi-speaker\nspeech corpus.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Minchan Kim",
      "Myeonghun Jeong",
      "Byoung Jin Choi",
      "Sunghwan Ahn",
      "Joun Yeop Lee",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15447"
  },
  {
    "id": "arXiv:2203.15450",
    "title": "High fidelity fluid-structure interaction by radial basis functions mesh  adaption of moving walls: a workflow applied to an aortic valve",
    "abstract": "Fluid-Structure Interaction (FSI) can be investigated by means of non-linear\nFinite Element Models (FEM), suitable to capture large deflections of\nstructural parts interacting with fluids, and Computational Fluid Dynamics\n(CFD). High fidelity simulations are obtained using the fine spatial resolution\nof both the structural and fluid computational grids. A key enabler to have a\nproper exchange of information between the structural solver and the fluid one\nis the management of the interface at wetted surfaces where the grids are\nusually non matching. A class of applications, known also as one-way FSI\nproblems, involves a complex movement of the walls that is known in advance as\nmeasured or as computed by FEM, and that has to be imposed at the boundaries\nduring a transient CFD solution. Effective methods for the time marching\nadaption of the whole computational grid of the CFD model according to the\nevolving shape of its boundaries are required. A very well established approach\nconsists of a continuum update of the mesh that is regenerated by adding and\nremoving cells to fit the evolution of the moving walls. In this paper, an\ninnovative method based on Radial Basis Functions (RBF) mesh morphing is\nproposed, allowing the retention of the same mesh topology suitable for a\ncontinuum update of the shape. The proposed method is exact at a set of given\nkey configurations and relies on shape blending time interpolation between key\nframes. The study of the complex motion of a Polymeric-Prosthetic Heart Valve\n(P-PHV) is presented using the new framework and considering as a reference the\nestablished approach based on remeshing.",
    "descriptor": "\nComments: Article of 21 pages\n",
    "authors": [
      "Leonardo Geronzi",
      "Emanuele Gasparotti",
      "Katia Capellini",
      "Ubaldo Cella",
      "Corrado Groth",
      "Stefano Porziani",
      "Andrea Chiappa",
      "Simona Celi",
      "Marco Evangelos Biancolini"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15450"
  },
  {
    "id": "arXiv:2203.15457",
    "title": "Uniqueness of the Gibbs measure for the anti-ferromagnetic Potts model  on the infinite $\u0394$-regular tree for large $\u0394$",
    "abstract": "In this paper we prove that for any integer $q\\geq 5$, the anti-ferromagnetic\n$q$-state Potts model on the infinite $\\Delta$-regular tree has a unique Gibbs\nmeasure for all edge interaction parameters $w\\in [1-q/\\Delta,1)$, provided\n$\\Delta$ is large enough. This confirms a longstanding folklore conjecture.",
    "descriptor": "\nComments: 20 pages, 1 figure\n",
    "authors": [
      "Ferenc Bencs",
      "David de Boer",
      "Pjotr Buys",
      "Guus Regts"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Mathematical Physics (math-ph)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.15457"
  },
  {
    "id": "arXiv:2203.15465",
    "title": "Protein language models trained on multiple sequence alignments learn  phylogenetic relationships",
    "abstract": "Self-supervised neural language models with attention have recently been\napplied to biological sequence data, advancing structure, function and\nmutational effect prediction. Some protein language models, including MSA\nTransformer and AlphaFold's EvoFormer, take multiple sequence alignments (MSAs)\nof evolutionarily related proteins as inputs. Simple combinations of MSA\nTransformer's row attentions have led to state-of-the-art unsupervised\nstructural contact prediction. We demonstrate that similarly simple, and\nuniversal, combinations of MSA Transformer's column attentions strongly\ncorrelate with Hamming distances between sequences in MSAs. Therefore,\nMSA-based language models encode detailed phylogenetic relationships. This\ncould aid them to separate coevolutionary signals encoding functional and\nstructural constraints from phylogenetic correlations arising from historical\ncontingency. To test this hypothesis, we generate synthetic MSAs, either\nwithout or with phylogeny, from Potts models trained on natural MSAs. We\ndemonstrate that unsupervised contact prediction is indeed substantially more\nresilient to phylogenetic noise when using MSA Transformer versus inferred\nPotts models.",
    "descriptor": "\nComments: 23 pages, 6 figures, 4 tables\n",
    "authors": [
      "Umberto Lupo",
      "Damiano Sgarbossa",
      "Anne-Florence Bitbol"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2203.15465"
  },
  {
    "id": "arXiv:2203.15470",
    "title": "Graph similarity learning for change-point detection in dynamic networks",
    "abstract": "Dynamic networks are ubiquitous for modelling sequential graph-structured\ndata, e.g., brain connectome, population flows and messages exchanges. In this\nwork, we consider dynamic networks that are temporal sequences of graph\nsnapshots, and aim at detecting abrupt changes in their structure. This task is\noften termed network change-point detection and has numerous applications, such\nas fraud detection or physical motion monitoring. Leveraging a graph neural\nnetwork model, we design a method to perform online network change-point\ndetection that can adapt to the specific network domain and localise changes\nwith no delay. The main novelty of our method is to use a siamese graph neural\nnetwork architecture for learning a data-driven graph similarity function,\nwhich allows to effectively compare the current graph and its recent history.\nImportantly, our method does not require prior knowledge on the network\ngenerative distribution and is agnostic to the type of change-points; moreover,\nit can be applied to a large variety of networks, that include for instance\nedge weights and node attributes. We show on synthetic and real data that our\nmethod enjoys a number of benefits: it is able to learn an adequate graph\nsimilarity function for performing online network change-point detection in\ndiverse types of change-point settings, and requires a shorter data history to\ndetect changes than most existing state-of-the-art baselines.",
    "descriptor": "\nComments: 33 pages, 21 figures, 5 tables\n",
    "authors": [
      "Deborah Sulem",
      "Henry Kenlay",
      "Mihai Cucuringu",
      "Xiaowen Dong"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.15470"
  },
  {
    "id": "arXiv:2203.15471",
    "title": "State space models vs. multi-step predictors in predictive control: Are  state space models complicating safe data-driven designs?",
    "abstract": "This paper contrasts recursive state space models and direct multi-step\npredictors for linear predictive control. We provide a tutorial exposition for\nboth model structures to solve the following problems: 1. stochastic optimal\ncontrol; 2. system identification; 3. stochastic optimal control based on the\nestimated model. Throughout the paper, we provide detailed discussions of the\nbenefits and limitations of these two model parametrizations for predictive\ncontrol and highlight the relation to existing works. Additionally, we derive a\nnovel (partially tight) constraint tightening for stochastic predictive control\nwith parametric uncertainty in the multi-step predictor.",
    "descriptor": "",
    "authors": [
      "Johannes K\u00f6hler",
      "Kim P. Wabersich",
      "Julian Berberich",
      "Melanie N. Zeilinger"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15471"
  },
  {
    "id": "arXiv:2203.15490",
    "title": "Neural representation of a time optimal, constant acceleration  rendezvous",
    "abstract": "We train neural models to represent both the optimal policy (i.e. the optimal\nthrust direction) and the value function (i.e. the time of flight) for a time\noptimal, constant acceleration low-thrust rendezvous. In both cases we develop\nand make use of the data augmentation technique we call backward generation of\noptimal examples. We are thus able to produce and work with large dataset and\nto fully exploit the benefit of employing a deep learning framework. We\nachieve, in all cases, accuracies resulting in successful rendezvous (simulated\nfollowing the learned policy) and time of flight predictions (using the learned\nvalue function). We find that residuals as small as a few m/s, thus well within\nthe possibility of a spacecraft navigation $\\Delta V$ budget, are achievable\nfor the velocity at rendezvous. We also find that, on average, the absolute\nerror to predict the optimal time of flight to rendezvous from any orbit in the\nasteroid belt to an Earth-like orbit is small (less than 4\\%) and thus also of\ninterest for practical uses, for example, during preliminary mission design\nphases.",
    "descriptor": "",
    "authors": [
      "Dario Izzo",
      "Sebastien Origer"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15490"
  },
  {
    "id": "arXiv:2203.15517",
    "title": "A multimodal approach for Parkinson disease analysis",
    "abstract": "Parkinson's disease (PD) is the second most frequent neurodegenerative\ndisease with prevalence among general population reaching 0.1-1 %, and an\nannual incidence between 1.3-2.0/10000 inhabitants. The mean age at diagnosis\nof PD is 55 and most patients are between 50 and 80 years old. The most obvious\nsymptoms are movement-related; these include tremor, rigidity, slowness of\nmovement and walking difficulties. Frequently these are the symptoms that lead\nto the PD diagnoses. Later, thinking and behavioral problems may arise, and\nother symptoms include cognitive impairment and sensory, sleep and emotional\nproblems. In this paper we will present an ongoing project that will evaluate\nif voice and handwriting analysis can be reliable predictors/indicators of\nswallowing and balance impairments in PD. An important advantage of voice and\nhandwritten analysis is its low intrusiveness and easy implementation in\nclinical practice. Thus, if a significant correlation between these simple\nanalyses and the gold standard video-fluoroscopic analysis will imply simpler\nand less stressing diagnostic test for the patients as well as the use of\ncheaper analysis systems.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Marcos Faundez-Zanuy",
      "Antonio Satue-Villar",
      "Jiri Mekyska",
      "Viridiana Arreola",
      "Pilar Sanz",
      "Carles Paul",
      "Luis Guirao",
      "Mateu Serra",
      "Laia Rofes",
      "Pere Clav\u00e9",
      "Enric Sesa-Nogueras",
      "Josep Roure"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15517"
  },
  {
    "id": "arXiv:2203.15537",
    "title": "On Metric Learning for Audio-Text Cross-Modal Retrieval",
    "abstract": "Audio-text retrieval aims at retrieving a target audio clip or caption from a\npool of candidates given a query in another modality. Solving such cross-modal\nretrieval task is challenging because it not only requires learning robust\nfeature representations for both modalities, but also requires capturing the\nfine-grained alignment between these two modalities. Existing cross-modal\nretrieval models are mostly optimized by metric learning objectives as both of\nthem attempt to map data to an embedding space, where similar data are close\ntogether and dissimilar data are far apart. Unlike other cross-modal retrieval\ntasks such as image-text and video-text retrievals, audio-text retrieval is\nstill an unexplored task. In this work, we aim to study the impact of different\nmetric learning objectives on the audio-text retrieval task. We present an\nextensive evaluation of popular metric learning objectives on the AudioCaps and\nClotho datasets. We demonstrate that NT-Xent loss adapted from self-supervised\nlearning shows stable performance across different datasets and training\nsettings, and outperforms the popular triplet-based losses.",
    "descriptor": "\nComments: 5 pages, submitted to InterSpeech2022\n",
    "authors": [
      "Xinhao Mei",
      "Xubo Liu",
      "Jianyuan Sun",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15537"
  },
  {
    "id": "arXiv:2203.15549",
    "title": "Invariance Learning based on Label Hierarchy",
    "abstract": "Deep Neural Networks inherit spurious correlations embedded in training data\nand hence may fail to predict desired labels on unseen domains (or\nenvironments), which have different distributions from the domain used in\ntraining. Invariance Learning (IL) has been developed recently to overcome this\nshortcoming; using training data in many domains, IL estimates such a predictor\nthat is invariant to a change of domain. However, the requirement of training\ndata in multiple domains is a strong restriction of IL, since it often needs\nhigh annotation cost. We propose a novel IL framework to overcome this problem.\nAssuming the availability of data from multiple domains for a higher level of\nclassification task, for which the labeling cost is low, we estimate an\ninvariant predictor for the target classification task with training data in a\nsingle domain. Additionally, we propose two cross-validation methods for\nselecting hyperparameters of invariance regularization to solve the issue of\nhyperparameter selection, which has not been handled properly in existing IL\nmethods. The effectiveness of the proposed framework, including the\ncross-validation, is demonstrated empirically, and the correctness of the\nhyperparameter selection is proved under some conditions.",
    "descriptor": "\nComments: 30 pages, submitted for a publication\n",
    "authors": [
      "Shoji Toyota",
      "Kenji Fukumizu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15549"
  },
  {
    "id": "arXiv:2203.15574",
    "title": "Circuit encapsulation for efficient quantum computing based on  controlled many-body dynamics",
    "abstract": "Controlling the time evolution of interacting spin systems is an important\napproach of implementing quantum computing. Different from the approaches by\ncompiling the circuits into the product of multiple elementary gates, we here\npropose the quantum circuit encapsulation (QCE), where we encapsulate the\ncircuits into different parts, and optimize the magnetic fields to realize the\nunitary transformation of each part by the time evolution. The QCE is\ndemonstrated to possess well-controlled error and time cost, which avoids the\nerror accumulations by aiming at finding the shortest path directly to the\ntarget unitary. We test four different encapsulation ways to realize the\nmulti-qubit quantum Fourier transformations by controlling the time evolution\nof the quantum Ising chain. The scaling behaviors of the time costs and errors\nagainst the number of two-qubit controlled gates are demonstrated. The QCE\nprovides an alternative compiling scheme that translates the circuits into a\nphysically-executable form based on the quantum many-body dynamics, where the\nkey issue becomes the encapsulation way to balance between the efficiency and\nflexibility.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Ying Lu",
      "Peng-Fei Zhou",
      "Shao-Ming Fei",
      "Shi-Ju Ran"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15574"
  },
  {
    "id": "arXiv:2203.15598",
    "title": "Angular Super-Resolution in Diffusion MRI with a 3D Recurrent  Convolutional Autoencoder",
    "abstract": "High resolution diffusion MRI (dMRI) data is often constrained by limited\nscanning time in clinical settings, thus restricting the use of downstream\nanalysis techniques that would otherwise be available. In this work we develop\na 3D recurrent convolutional neural network (RCNN) capable of super-resolving\ndMRI volumes in the angular (q-space) domain. Our approach formulates the task\nof angular super-resolution as a patch-wise regression using a 3D autoencoder\nconditioned on target b-vectors. Within the network we use a convolutional long\nshort term memory (ConvLSTM) cell to model the relationship between q-space\nsamples. We compare model performance against a baseline spherical harmonic\ninterpolation and a 1D variant of the model architecture. We show that the 3D\nmodel has the lowest error rates across different subsampling schemes and\nb-values. The relative performance of the 3D RCNN is greatest in the very low\nangular resolution domain. Code for this project is available at\nhttps://github.com/m-lyon/dMRI-RCNN.",
    "descriptor": "\nComments: Accepted to published in MIDL'22. Openreview link: this https URL\n",
    "authors": [
      "Matthew Lyon",
      "Paul Armitage",
      "Mauricio A. \u00c1lvarez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15598"
  },
  {
    "id": "arXiv:2203.15610",
    "title": "LightHuBERT: Lightweight and Configurable Speech Representation Learning  with Once-for-All Hidden-Unit BERT",
    "abstract": "Self-supervised speech representation learning has shown promising results in\nvarious speech processing tasks. However, the pre-trained models, e.g., HuBERT,\nare storage-intensive Transformers, limiting their scope of applications under\nlow-resource settings. To this end, we propose LightHuBERT, a once-for-all\nTransformer compression framework, to find the desired architectures\nautomatically by pruning structured parameters. More precisely, we create a\nTransformer-based supernet that is nested with thousands of weight-sharing\nsubnets and design a two-stage distillation strategy to leverage the\ncontextualized latent representations from HuBERT. Experiments on automatic\nspeech recognition (ASR) and the SUPERB benchmark show the proposed LightHuBERT\nenables over $10^9$ architectures concerning the embedding dimension, attention\ndimension, head number, feed-forward network ratio, and network depth.\nLightHuBERT outperforms the original HuBERT on ASR and five SUPERB tasks with\nthe HuBERT size, achieves comparable performance to the teacher model in most\ntasks with a reduction of 29% parameters, and obtains a $3.5\\times$ compression\nratio in three SUPERB tasks, e.g., automatic speaker verification, keyword\nspotting, and intent classification, with a slight accuracy loss. The code and\npre-trained models are available at\nhttps://github.com/mechanicalsea/lighthubert.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to Insterspeech 2022\n",
    "authors": [
      "Rui Wang",
      "Qibing Bai",
      "Junyi Ao",
      "Long Zhou",
      "Zhixiang Xiong",
      "Zhihua Wei",
      "Yu Zhang",
      "Tom Ko",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15610"
  },
  {
    "id": "arXiv:2203.15634",
    "title": "Convex Non-negative Matrix Factorization Through Quantum Annealing",
    "abstract": "In this paper we provide the quantum version of the Convex Non-negative\nMatrix Factorization algorithm (Convex-NMF) by using the D-wave quantum\nannealer. More precisely, we use D-wave 2000Q to find the low rank\napproximation of a fixed real-valued matrix X by the product of two\nnon-negative matrices factors W and G such that the Frobenius norm of the\ndifference X-XWG is minimized. In order to solve this optimization problem we\nproceed in two steps. In the first step we transform the global real\noptimization problem depending on W,G into two quadratic unconstrained binary\noptimization problems (QUBO) depending on W and G respectively. In the second\nstep we use an alternative strategy between the two QUBO problems corresponding\nto W and G to find the global solution. The running of these two QUBO problems\non D-wave 2000Q need to use an embedding to the chimera graph of D-wave 2000Q,\nthis embedding is limited by the number of qubits of D-wave 2000Q. We perform a\nstudy on the maximum number of real data to be used by our approach on D-wave\n2000Q. The proposed study is based on the number of qubits used to represent\neach real variable. We also tested our approach on D-Wave 2000Q with several\nrandomly generated data sets to prove that our approach is faster than the\nclassical approach and also to prove that it gets the best results.",
    "descriptor": "",
    "authors": [
      "Ahmed Zaiou",
      "Basarab Matei",
      "Youn\u00e8s Bennani",
      "Mohamed Hibti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15634"
  },
  {
    "id": "arXiv:2203.15635",
    "title": "BASiNETEntropy: an alignment-free method for classification of  biological sequences through complex networks and entropy maximization",
    "abstract": "The discovery of nucleic acids and the structure of DNA have brought\nconsiderable advances in the understanding of life. The development of\nnext-generation sequencing technologies has led to a large-scale generation of\ndata, for which computational methods have become essential for analysis and\nknowledge discovery. In particular, RNAs have received much attention because\nof the diversity of their functionalities in the organism and the discoveries\nof different classes with different functions in many biological processes.\nTherefore, the correct identification of RNA sequences is increasingly\nimportant to provide relevant information to understand the functioning of\norganisms. This work addresses this context by presenting a new method for the\nclassification of biological sequences through complex networks and entropy\nmaximization. The maximum entropy principle is proposed to identify the most\ninformative edges about the RNA class, generating a filtered complex network.\nThe proposed method was evaluated in the classification of different RNA\nclasses from 13 species. The proposed method was compared to PLEK, CPC2 and\nBASiNET methods, outperforming all compared methods. BASiNETEntropy classified\nall RNA sequences with high accuracy and low standard deviation in results,\nshowing assertiveness and robustness. The proposed method is implemented in an\nopen source in R language and is freely available at\nhttps://cran.r-project.org/web/packages/BASiNETEntropy.",
    "descriptor": "",
    "authors": [
      "Murilo Montanini Breve",
      "Matheus Henrique Pimenta-Zanon",
      "Fabr\u00edcio Martins Lopes"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2203.15635"
  },
  {
    "id": "arXiv:2203.15652",
    "title": "CycleGAN-Based Unpaired Speech Dereverberation",
    "abstract": "Typically, neural network-based speech dereverberation models are trained on\npaired data, composed of a dry utterance and its corresponding reverberant\nutterance. The main limitation of this approach is that such models can only be\ntrained on large amounts of data and a variety of room impulse responses when\nthe data is synthetically reverberated, since acquiring real paired data is\ncostly. In this paper we propose a CycleGAN-based approach that enables\ndereverberation models to be trained on unpaired data. We quantify the impact\nof using unpaired data by comparing the proposed unpaired model to a paired\nmodel with the same architecture and trained on the paired version of the same\ndataset. We show that the performance of the unpaired model is comparable to\nthe performance of the paired model on two different datasets, according to\nobjective evaluation metrics. Furthermore, we run two subjective evaluations\nand show that both models achieve comparable subjective quality on the AMI\ndataset, which was not seen during training.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Hannah Muckenhirn",
      "Aleksandr Safin",
      "Hakan Erdogan",
      "Felix de Chaumont Quitry",
      "Marco Tagliasacchi",
      "Scott Wisdom",
      "John R. Hershey"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15652"
  },
  {
    "id": "arXiv:2203.15672",
    "title": "SurvCaus : Representation Balancing for Survival Causal Inference",
    "abstract": "Individual Treatment Effects (ITE) estimation methods have risen in\npopularity in the last years. Most of the time, individual effects are better\npresented as Conditional Average Treatment Effects (CATE). Recently,\nrepresentation balancing techniques have gained considerable momentum in causal\ninference from observational data, still limited to continuous (and binary)\noutcomes. However, in numerous pathologies, the outcome of interest is a\n(possibly censored) survival time. Our paper proposes theoretical guarantees\nfor a representation balancing framework applied to counterfactual inference in\na survival setting using a neural network capable of predicting the factual and\ncounterfactual survival functions (and then the CATE), in the presence of\ncensorship, at the individual level. We also present extensive experiments on\nsynthetic and semisynthetic datasets that show that the proposed extensions\noutperform baseline methods.",
    "descriptor": "",
    "authors": [
      "Ayoub Abraich",
      "Agathe Guilloux",
      "Blaise Hanczar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.15672"
  },
  {
    "id": "arXiv:2203.15695",
    "title": "Performance of surface codes in realistic quantum hardware",
    "abstract": "Surface codes are generally studied based on the assumption that each of the\nqubits that make up the surface code lattice suffers noise that is independent\nand identically distributed (i.i.d.). However, real benchmarks of the\nindividual relaxation ($T_1$) and dephasing ($T_2$) times of the constituent\nqubits of state-of-the-art quantum processors have recently shown that the\ndecoherence effects suffered by each particular qubit will actually vary in\nintensity. In this article, we propose a decoherence model that takes this\nnon-uniform behaviour into account, the independent non-identically distributed\n(i.ni.d.) noise model, and we analyze how the performance of planar codes is\nimpacted by this new model. For this purpose we employ data from four\nstate-of-the-art superconducting processors: ibmq\\_brooklyn, ibm\\_washington,\nZuchongzhi and Rigetti Aspen-11. Our results show that the i.i.d. noise\nassumption overestimates the performance of surface codes, which can suffer up\nto $85\\%$ performance decrements in terms of the code pseudo-threshold when\nthey are subjected to the i.ni.d. noise model. Furthermore, in this work we\nalso consider the relationship between code performance and qubit arrangement\nin the surface code lattice. We show how surface code performance varies as a\nfunction of qubit placement within the lattice (because of the different\ndecoherence parameters) and we introduce an algorithm that re-arranges the\nqubits of the surface code lattice in a way that optimizes code performance.\nThe optimum qubit configuration derived with this algorithm can attain planar\ncode pseudo-threshold values that are up to $249\\%$ higher than for the general\nplanar code architectures.",
    "descriptor": "\nComments: Includes supplementary material (19 pages total)\n",
    "authors": [
      "Antonio deMarti iOlius",
      "Josu Etxezarreta Martinez",
      "Patricio Fuentes",
      "Pedro M. Crespo",
      "Javier Garcia-Frias"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15695"
  },
  {
    "id": "arXiv:2203.15725",
    "title": "Synergizing Physics/Model-based and Data-driven Methods for Low-Dose CT",
    "abstract": "Since 2016, deep learning (DL) has advanced tomographic imaging with\nremarkable successes, especially in low-dose computed tomography (LDCT)\nimaging. Despite being driven by big data, the LDCT denoising and pure\nend-to-end reconstruction networks often suffer from the black box nature and\nmajor issues such as instabilities, which is a major barrier to apply deep\nlearning methods in low-dose CT applications. An emerging trend is to integrate\nimaging physics and model into deep networks, enabling a hybridization of\nphysics/model-based and data-driven elements. In this paper, we systematically\nreview the physics/model-based data-driven methods for LDCT, summarize the loss\nfunctions and training strategies, evaluate the performance of different\nmethods, and discuss relevant issues and future directions",
    "descriptor": "",
    "authors": [
      "Wenjun Xia",
      "Hongming Shan",
      "Ge Wang",
      "Yi Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.15725"
  },
  {
    "id": "arXiv:2203.15736",
    "title": "Exact Community Recovery in Correlated Stochastic Block Models",
    "abstract": "We consider the problem of learning latent community structure from multiple\ncorrelated networks. We study edge-correlated stochastic block models with two\nbalanced communities, focusing on the regime where the average degree is\nlogarithmic in the number of vertices. Our main result derives the precise\ninformation-theoretic threshold for exact community recovery using multiple\ncorrelated graphs. This threshold captures the interplay between the community\nrecovery and graph matching tasks. In particular, we uncover and characterize a\nregion of the parameter space where exact community recovery is possible using\nmultiple correlated graphs, even though (1) this is information-theoretically\nimpossible using a single graph and (2) exact graph matching is also\ninformation-theoretically impossible. In this regime, we develop a novel\nalgorithm that carefully synthesizes algorithms from the community recovery and\ngraph matching literatures.",
    "descriptor": "\nComments: 54 pages, 6 figures\n",
    "authors": [
      "Julia Gaudio",
      "Miklos Z. Racz",
      "Anirudh Sridhar"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.15736"
  },
  {
    "id": "arXiv:2203.15751",
    "title": "A Passive Similarity based CNN Filter Pruning for Efficient Acoustic  Scene Classification",
    "abstract": "We present a method to develop low-complexity convolutional neural networks\n(CNNs) for acoustic scene classification (ASC). The large size and high\ncomputational complexity of typical CNNs is a bottleneck for their deployment\non resource-constrained devices. We propose a passive filter pruning framework,\nwhere a few convolutional filters from the CNNs are eliminated to yield\ncompressed CNNs. Our hypothesis is that similar filters produce similar\nresponses and give redundant information allowing such filters to be eliminated\nfrom the network. To identify similar filters, a cosine distance based greedy\nalgorithm is proposed. A fine-tuning process is then performed to regain much\nof the performance lost due to filter elimination. To perform efficient\nfine-tuning, we analyze how the performance varies as the number of fine-tuning\ntraining examples changes. An experimental evaluation of the proposed framework\nis performed on the publicly available DCASE 2021 Task 1A baseline network\ntrained for ASC. The proposed method is simple, reduces computations per\ninference by 27%, with 25% fewer parameters, with less than 1% drop in\naccuracy.",
    "descriptor": "\nComments: Submitted to Interspeech 2022 conference\n",
    "authors": [
      "Arshdeep Singh",
      "Mark D. Plumbley"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15751"
  },
  {
    "id": "arXiv:2203.15756",
    "title": "Causal de Finetti: On the Identification of Invariant Causal Structure  in Exchangeable Data",
    "abstract": "Learning invariant causal structure often relies on conditional independence\ntesting and assumption of independent and identically distributed data. Recent\nwork has explored inferring invariant causal structure using data coming from\ndifferent environments. These approaches are based on independent causal\nmechanism (ICM) principle which postulates that the cause mechanism is\nindependent of the effect given cause mechanism. Despite its wide application\nin machine learning and causal inference, there lacks a statistical\nformalization of what independent mechanism means. Here we present Causal de\nFinetti which offers a first statistical formalization of ICM principle.",
    "descriptor": "",
    "authors": [
      "Siyuan Guo",
      "Viktor T\u00f3th",
      "Bernhard Sch\u00f6lkopf",
      "Ferenc Husz\u00e1r"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.15756"
  },
  {
    "id": "arXiv:2203.15796",
    "title": "Unsupervised Text-to-Speech Synthesis by Unsupervised Automatic Speech  Recognition",
    "abstract": "An unsupervised text-to-speech synthesis (TTS) system learns to generate the\nspeech waveform corresponding to any written sentence in a language by\nobserving: 1) a collection of untranscribed speech waveforms in that language;\n2) a collection of texts written in that language without access to any\ntranscribed speech. Developing such a system can significantly improve the\navailability of speech technology to languages without a large amount of\nparallel speech and text data. This paper proposes an unsupervised TTS system\nby leveraging recent advances in unsupervised automatic speech recognition\n(ASR). Our unsupervised system can achieve comparable performance to the\nsupervised system in seven languages with about 10-20 hours of speech each. A\ncareful study on the effect of text units and vocoders has also been conducted\nto better understand what factors may affect unsupervised TTS performance. The\nsamples generated by our models can be found at\nhttps://cactuswiththoughts.github.io/UnsupTTS-Demo.",
    "descriptor": "\nComments: submitted to INTERSPEECH\n",
    "authors": [
      "Junrui Ni",
      "Liming Wang",
      "Heting Gao",
      "Kaizhi Qian",
      "Yang Zhang",
      "Shiyu Chang",
      "Mark Hasegawa-Johnson"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15796"
  },
  {
    "id": "arXiv:2203.15797",
    "title": "Convergence and Complexity of Stochastic Subgradient Methods with  Dependent Data for Nonconvex Optimization",
    "abstract": "We show that under a general dependent data sampling scheme, the classical\nstochastic projected and proximal subgradient methods for weakly convex\nfunctions have worst-case rate of convergence $\\tilde{O}(n^{-1/4})$ and\ncomplexity $\\tilde{O}(\\varepsilon^{-4})$ for achieving an $\\varepsilon$-near\nstationary point in terms of the norm of the gradient of Moreau envelope. While\nclassical convergence guarantee requires i.i.d. data sampling from the target\ndistribution, we only require a mild mixing condition of the conditional\ndistribution, which holds for a wide class of Markov chain sampling algorithms.\nThis improves the existing complexity for the specific case of constrained\nsmooth nonconvex optimization with dependent data from\n$\\tilde{O}(\\varepsilon^{-8})$ to $\\tilde{O}(\\varepsilon^{-4})$ with a\nsignificantly simpler analysis. We illustrate the generality of our approach by\nderiving convergence results with dependent data for adaptive stochastic\nsubgradient algorithm AdaGrad and stochastic subgradient algorithm with heavy\nball momentum. As an application, we obtain first online nonnegative matrix\nfactorization algorithms for dependent data based on stochastic projected\ngradient methods with adaptive step sizes with optimal rate of convergence\nguarantee.",
    "descriptor": "",
    "authors": [
      "Ahmet Alacaoglu",
      "Hanbaek Lyu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15797"
  },
  {
    "id": "arXiv:1701.07447",
    "title": "An Explicit, Coupled-Layer Construction of a High-Rate Regenerating Code  with Low Sub-Packetization Level, Small Field Size and $d< (n-1)$",
    "abstract": "Comments: In the revised version, a correction is made in the rate calculation. As the rate stands corrected, the code fails to be an MSR code. arXiv admin note: text overlap with arXiv:1607.07335",
    "descriptor": "\nComments: In the revised version, a correction is made in the rate calculation. As the rate stands corrected, the code fails to be an MSR code. arXiv admin note: text overlap with arXiv:1607.07335\n",
    "authors": [
      "Birenjith Sasidharan",
      "Myna Vajha",
      "P. Vijay Kumar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1701.07447"
  },
  {
    "id": "arXiv:1806.06537",
    "title": "Boolean-like algebras of finite dimension",
    "abstract": "Boolean-like algebras of finite dimension",
    "descriptor": "",
    "authors": [
      "Antonio Bucciarelli",
      "Antonio Ledda",
      "Francesco Paoli",
      "Antonino Salibra"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1806.06537"
  },
  {
    "id": "arXiv:1810.10172",
    "title": "Modified Multidimensional Scaling and High Dimensional Clustering",
    "abstract": "Comments: This paper will be subsumed by another paper",
    "descriptor": "\nComments: This paper will be subsumed by another paper\n",
    "authors": [
      "Xiucai Ding",
      "Qiang Sun"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1810.10172"
  },
  {
    "id": "arXiv:1812.10761",
    "title": "Improving Generalization of Deep Neural Networks by Leveraging Margin  Distribution",
    "abstract": "Comments: 25 pages, 7 figures, 1 table. Accepted by Neural Networks",
    "descriptor": "\nComments: 25 pages, 7 figures, 1 table. Accepted by Neural Networks\n",
    "authors": [
      "Shen-Huan Lyu",
      "Lu Wang",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1812.10761"
  },
  {
    "id": "arXiv:1901.07868",
    "title": "Constant Time Graph Neural Networks",
    "abstract": "Comments: TKDD 2022",
    "descriptor": "\nComments: TKDD 2022\n",
    "authors": [
      "Ryoma Sato",
      "Makoto Yamada",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.07868"
  },
  {
    "id": "arXiv:1902.03820",
    "title": "Fixed-Parameter Tractable Algorithms for Corridor Guarding Problems",
    "abstract": "Comments: Errors in the preprocessing steps used for the k-CMST and k-CTSP",
    "descriptor": "\nComments: Errors in the preprocessing steps used for the k-CMST and k-CTSP\n",
    "authors": [
      "Remi Raman",
      "R Subashini",
      "Subhasree Methirumangalath"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1902.03820"
  },
  {
    "id": "arXiv:1910.09056",
    "title": "Amortized Rejection Sampling in Universal Probabilistic Programming",
    "abstract": "Comments: AISTATS 2022 camera ready",
    "descriptor": "\nComments: AISTATS 2022 camera ready\n",
    "authors": [
      "Saeid Naderiparizi",
      "Adam \u015acibior",
      "Andreas Munk",
      "Mehrdad Ghadiri",
      "At\u0131l\u0131m G\u00fcne\u015f Baydin",
      "Bradley Gram-Hansen",
      "Christian Schroeder de Witt",
      "Robert Zinkov",
      "Philip H.S. Torr",
      "Tom Rainforth",
      "Yee Whye Teh",
      "Frank Wood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.09056"
  },
  {
    "id": "arXiv:2002.10438",
    "title": "xAI-GAN: Enhancing Generative Adversarial Networks via Explainable AI  Systems",
    "abstract": "Comments: 7 pages (+ 2 page for reference)",
    "descriptor": "\nComments: 7 pages (+ 2 page for reference)\n",
    "authors": [
      "Vineel Nagisetty",
      "Laura Graves",
      "Joseph Scott",
      "Vijay Ganesh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.10438"
  },
  {
    "id": "arXiv:2003.02993",
    "title": "Random sampling stability in weighted reproducing kernel subspaces of  $L_\u03bd^p(\\mathbb{R}^d)$",
    "abstract": "Random sampling stability in weighted reproducing kernel subspaces of  $L_\u03bd^p(\\mathbb{R}^d)$",
    "descriptor": "",
    "authors": [
      "Yingchun Jiang",
      "Yajing Zhang",
      "Wan Li"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2003.02993"
  },
  {
    "id": "arXiv:2003.03564",
    "title": "Ternary Compression for Communication-Efficient Federated Learning",
    "abstract": "Ternary Compression for Communication-Efficient Federated Learning",
    "descriptor": "",
    "authors": [
      "Jinjin Xu",
      "Wenli Du",
      "Ran Cheng",
      "Wangli He",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.03564"
  },
  {
    "id": "arXiv:2003.08330",
    "title": "Local Multiple Traces Formulation for Electromagnetics: Stability and  Preconditioning for Smooth Geometries",
    "abstract": "Local Multiple Traces Formulation for Electromagnetics: Stability and  Preconditioning for Smooth Geometries",
    "descriptor": "",
    "authors": [
      "Alan Ayala",
      "Xavier Claeys",
      "Paul Escapil-Inchausp\u00e9",
      "Carlos Jerez-Hanckes"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2003.08330"
  },
  {
    "id": "arXiv:2006.13448",
    "title": "On Multivariate Singular Spectrum Analysis and its Variants",
    "abstract": "On Multivariate Singular Spectrum Analysis and its Variants",
    "descriptor": "",
    "authors": [
      "Anish Agarwal",
      "Abdullah Alomar",
      "Devavrat Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.13448"
  },
  {
    "id": "arXiv:2007.10213",
    "title": "Software Development Analytics in Practice: A Systematic Literature  Review",
    "abstract": "Software Development Analytics in Practice: A Systematic Literature  Review",
    "descriptor": "",
    "authors": [
      "Joao Caldeira",
      "Fernando Brito e Abreu",
      "Jorge Cardoso",
      "Rachel Sim\u00f5es",
      "Toacy Oliveira",
      "Jos\u00e9 Reis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2007.10213"
  },
  {
    "id": "arXiv:2008.05865",
    "title": "DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis",
    "abstract": "DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis",
    "descriptor": "",
    "authors": [
      "Ming Tao",
      "Hao Tang",
      "Fei Wu",
      "Xiao-Yuan Jing",
      "Bing-Kun Bao",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.05865"
  },
  {
    "id": "arXiv:2008.08992",
    "title": "A New Combinatorial Property of Geometric Unique Sink Orientations",
    "abstract": "A New Combinatorial Property of Geometric Unique Sink Orientations",
    "descriptor": "",
    "authors": [
      "Yuan Gao",
      "Bernd G\u00e4rtner",
      "Jourdain Lamperski"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2008.08992"
  },
  {
    "id": "arXiv:2008.09371",
    "title": "Towards Improving Selective Prediction Ability of NLP Systems",
    "abstract": "Comments: ACL 2022 RepL4NLP Workshop",
    "descriptor": "\nComments: ACL 2022 RepL4NLP Workshop\n",
    "authors": [
      "Neeraj Varshney",
      "Swaroop Mishra",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.09371"
  },
  {
    "id": "arXiv:2009.02472",
    "title": "Towards Flexible Sparsity-Aware Modeling: Automatic Tensor Rank Learning  Using The Generalized Hyperbolic Prior",
    "abstract": "Towards Flexible Sparsity-Aware Modeling: Automatic Tensor Rank Learning  Using The Generalized Hyperbolic Prior",
    "descriptor": "",
    "authors": [
      "Lei Cheng",
      "Zhongtao Chen",
      "Qingjiang Shi",
      "Yik-Chung Wu",
      "Sergios Theodoridis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.02472"
  },
  {
    "id": "arXiv:2009.11275",
    "title": "Random points are optimal for the approximation of Sobolev functions",
    "abstract": "Comments: 29 pages, strengthened Prop. 1 and 3 which is needed in the proof of Cor. 2, extended Thm. 2, typos corrected",
    "descriptor": "\nComments: 29 pages, strengthened Prop. 1 and 3 which is needed in the proof of Cor. 2, extended Thm. 2, typos corrected\n",
    "authors": [
      "David Krieg",
      "Mathias Sonnleitner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2009.11275"
  },
  {
    "id": "arXiv:2010.09891",
    "title": "Robust Optimization as Data Augmentation for Large-scale Graphs",
    "abstract": "Comments: Accepted at CVPR 2022",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Kezhi Kong",
      "Guohao Li",
      "Mucong Ding",
      "Zuxuan Wu",
      "Chen Zhu",
      "Bernard Ghanem",
      "Gavin Taylor",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.09891"
  },
  {
    "id": "arXiv:2010.16225",
    "title": "Effects of round-to-nearest and stochastic rounding in the numerical  solution of the heat equation in low precision",
    "abstract": "Comments: 30 pages, 4 figures",
    "descriptor": "\nComments: 30 pages, 4 figures\n",
    "authors": [
      "Matteo Croci",
      "Michael B. Giles"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2010.16225"
  },
  {
    "id": "arXiv:2011.05028",
    "title": "Bi-Parametric Operator Preconditioning",
    "abstract": "Bi-Parametric Operator Preconditioning",
    "descriptor": "",
    "authors": [
      "Paul Escapil-Inchausp\u00e9",
      "Carlos Jerez-Hanckes"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.05028"
  },
  {
    "id": "arXiv:2011.06922",
    "title": "Image Animation with Perturbed Masks",
    "abstract": "Image Animation with Perturbed Masks",
    "descriptor": "",
    "authors": [
      "Yoav Shalev",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.06922"
  },
  {
    "id": "arXiv:2011.12745",
    "title": "Deep Magnification-Flexible Upsampling over 3D Point Clouds",
    "abstract": "Comments: 15 pages, 16 figures, 6 tables. This paper has been published in IEEE TIP",
    "descriptor": "\nComments: 15 pages, 16 figures, 6 tables. This paper has been published in IEEE TIP\n",
    "authors": [
      "Yue Qian",
      "Junhui Hou",
      "Sam Kwong",
      "Ying He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.12745"
  },
  {
    "id": "arXiv:2012.01028",
    "title": "CRaDLe: Deep Code Retrieval Based on Semantic Dependency Learning",
    "abstract": "CRaDLe: Deep Code Retrieval Based on Semantic Dependency Learning",
    "descriptor": "",
    "authors": [
      "Wenchao Gu",
      "Zongjie Li",
      "Cuiyun Gao",
      "Chaozheng Wang",
      "Hongyu Zhang",
      "Zenglin Xu",
      "Michael R.Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2012.01028"
  },
  {
    "id": "arXiv:2012.04263",
    "title": "Towards Accurate Active Camera Localization",
    "abstract": "Towards Accurate Active Camera Localization",
    "descriptor": "",
    "authors": [
      "Qihang Fang",
      "Yingda Yin",
      "Qingnan Fan",
      "Fei Xia",
      "Siyan Dong",
      "Sheng Wang",
      "Jue Wang",
      "Leonidas Guibas",
      "Baoquan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04263"
  },
  {
    "id": "arXiv:2012.05567",
    "title": "Debiased-CAM to mitigate image perturbations with faithful visual  explanations of machine learning",
    "abstract": "Comments: CHI 2022",
    "descriptor": "\nComments: CHI 2022\n",
    "authors": [
      "Wencan Zhang",
      "Mariella Dimiccoli",
      "Brian Y. Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.05567"
  },
  {
    "id": "arXiv:2012.11026",
    "title": "Independent Approximates enable closed-form estimation of heavy-tailed  distributions",
    "abstract": "Comments: 37 pages, 11 figures, 8 tables",
    "descriptor": "\nComments: 37 pages, 11 figures, 8 tables\n",
    "authors": [
      "Kenric P. Nelson"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2012.11026"
  },
  {
    "id": "arXiv:2012.11706",
    "title": "A generalized conditional gradient method for dynamic inverse problems  with optimal transport regularization",
    "abstract": "Comments: 40 pages, 8 figures, 1 table",
    "descriptor": "\nComments: 40 pages, 8 figures, 1 table\n",
    "authors": [
      "Kristian Bredies",
      "Marcello Carioni",
      "Silvio Fanzon",
      "Francisco Romero"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2012.11706"
  },
  {
    "id": "arXiv:2012.12600",
    "title": "AutonoML: Towards an Integrated Framework for Autonomous Machine  Learning",
    "abstract": "Comments: Updated with feedback from ML community",
    "descriptor": "\nComments: Updated with feedback from ML community\n",
    "authors": [
      "David Jacob Kedziora",
      "Katarzyna Musial",
      "Bogdan Gabrys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.12600"
  },
  {
    "id": "arXiv:2012.13073",
    "title": "Task-Adaptive Negative Class Envision for Few-Shot Open-Set Recognition",
    "abstract": "Comments: Accepted by CVPR2022",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Shiyuan Huang",
      "Jiawei Ma",
      "Guangxing Han",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.13073"
  },
  {
    "id": "arXiv:2101.05792",
    "title": "Group Testing with a Graph Infection Spread Model",
    "abstract": "Group Testing with a Graph Infection Spread Model",
    "descriptor": "",
    "authors": [
      "Batuhan Arasli",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2101.05792"
  },
  {
    "id": "arXiv:2102.00499",
    "title": "On the Indecisiveness of Kelly-Strategyproof Social Choice Functions",
    "abstract": "Comments: Appears in: Proceedings of the 20th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2021",
    "descriptor": "\nComments: Appears in: Proceedings of the 20th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2021\n",
    "authors": [
      "Felix Brandt",
      "Martin Bullinger",
      "Patrick Lederer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2102.00499"
  },
  {
    "id": "arXiv:2102.10163",
    "title": "On Gradient Coding with Partial Recovery",
    "abstract": "On Gradient Coding with Partial Recovery",
    "descriptor": "",
    "authors": [
      "Sahasrajit Sarmasarkar",
      "V. Lalitha",
      "Nikhil Karamchandani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.10163"
  },
  {
    "id": "arXiv:2102.10407",
    "title": "VisualGPT: Data-efficient Adaptation of Pretrained Language Models for  Image Captioning",
    "abstract": "VisualGPT: Data-efficient Adaptation of Pretrained Language Models for  Image Captioning",
    "descriptor": "",
    "authors": [
      "Jun Chen",
      "Han Guo",
      "Kai Yi",
      "Boyang Li",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2102.10407"
  },
  {
    "id": "arXiv:2102.10502",
    "title": "A Sketching Method for Finding the Closest Point on a Convex Hull",
    "abstract": "A Sketching Method for Finding the Closest Point on a Convex Hull",
    "descriptor": "",
    "authors": [
      "Roozbeh Yousefzadeh"
    ],
    "subjectives": [
      "Differential Geometry (math.DG)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.10502"
  },
  {
    "id": "arXiv:2102.12332",
    "title": "Interactive Frequency Dynamics Between Grid-Forming Inverters and  Synchronous Generators in Power Electronics-Dominated Power Systems",
    "abstract": "Comments: 12 pages, 12 figures",
    "descriptor": "\nComments: 12 pages, 12 figures\n",
    "authors": [
      "Rick Wallace Kenyon",
      "Amirhossein Sajadi",
      "Matt Bossart",
      "Bri-Mathias Hodge"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.12332"
  },
  {
    "id": "arXiv:2102.13505",
    "title": "Approximation of Stochastic Volterra Equations with kernels of  completely monotone type",
    "abstract": "Approximation of Stochastic Volterra Equations with kernels of  completely monotone type",
    "descriptor": "",
    "authors": [
      "Aur\u00e9lien Alfonsi",
      "Ahmed Kebaier"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2102.13505"
  },
  {
    "id": "arXiv:2103.01209",
    "title": "Generative Adversarial Transformers",
    "abstract": "Comments: Published as a conference paper at ICML 2021",
    "descriptor": "\nComments: Published as a conference paper at ICML 2021\n",
    "authors": [
      "Drew A. Hudson",
      "C. Lawrence Zitnick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01209"
  },
  {
    "id": "arXiv:2103.02850",
    "title": "MPED: Quantifying Point Cloud Distortion based on Multiscale Potential  Energy Discrepancy",
    "abstract": "MPED: Quantifying Point Cloud Distortion based on Multiscale Potential  Energy Discrepancy",
    "descriptor": "",
    "authors": [
      "Qi Yang",
      "Yujie Zhang",
      "Siheng Chen",
      "Yiling Xu",
      "Jun Sun",
      "Zhan Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.02850"
  },
  {
    "id": "arXiv:2103.03280",
    "title": "Finding Efficient Trade-offs in Multi-Fidelity Response Surface Modeling",
    "abstract": "Comments: 12 pages, 9 figures. This article has been accepted for publication in Engineering Optimization, published by Taylor & Francis",
    "descriptor": "\nComments: 12 pages, 9 figures. This article has been accepted for publication in Engineering Optimization, published by Taylor & Francis\n",
    "authors": [
      "Sander van Rijn",
      "Sebastian Schmitt",
      "Matthijs van Leeuwen",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2103.03280"
  },
  {
    "id": "arXiv:2103.05611",
    "title": "Optimal Pricing with a Single Point",
    "abstract": "Optimal Pricing with a Single Point",
    "descriptor": "",
    "authors": [
      "Amine Allouah",
      "Achraf Bahamou",
      "Omar Besbes"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.05611"
  },
  {
    "id": "arXiv:2103.07258",
    "title": "Packing Squares into a Disk with Optimal Worst-Case Density",
    "abstract": "Comments: 24 pages, 15 figures. Full version of a SoCG 2021 paper with the same title",
    "descriptor": "\nComments: 24 pages, 15 figures. Full version of a SoCG 2021 paper with the same title\n",
    "authors": [
      "S\u00e1ndor P. Fekete",
      "Vijaykrishna Gurunathan",
      "Kushagra Juneja",
      "Phillip Keldenich",
      "Linda Kleist",
      "Christian Scheffer"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2103.07258"
  },
  {
    "id": "arXiv:2103.09748",
    "title": "On the Whitney extension problem for near isometries and beyond",
    "abstract": "Comments: The subscript in the last entry of the Block slow twist matrix should be $r$ and not $D$",
    "descriptor": "\nComments: The subscript in the last entry of the Block slow twist matrix should be $r$ and not $D$\n",
    "authors": [
      "Steven B. Damelin"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.09748"
  },
  {
    "id": "arXiv:2103.11139",
    "title": "MogFace: Towards a Deeper Appreciation on Face Detection",
    "abstract": "MogFace: Towards a Deeper Appreciation on Face Detection",
    "descriptor": "",
    "authors": [
      "Yang Liu",
      "Fei Wang",
      "Jiankang Deng",
      "Zhipeng Zhou",
      "Baigui Sun",
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.11139"
  },
  {
    "id": "arXiv:2103.11641",
    "title": "iRotate: Active Visual SLAM for Omnidirectional Robots",
    "abstract": "Comments: 15 pages, 14 figures, 3 tables. ACCEPTED for publication in Robotics and Autonomous Systems - Elsevier",
    "descriptor": "\nComments: 15 pages, 14 figures, 3 tables. ACCEPTED for publication in Robotics and Autonomous Systems - Elsevier\n",
    "authors": [
      "Elia Bonetto",
      "Pascal Goldschmid",
      "Michael Pabst",
      "Michael J. Black",
      "Aamir Ahmad"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.11641"
  },
  {
    "id": "arXiv:2103.15383",
    "title": "Selective Output Smoothing Regularization: Regularize Neural Networks by  Softening Output Distributions",
    "abstract": "Selective Output Smoothing Regularization: Regularize Neural Networks by  Softening Output Distributions",
    "descriptor": "",
    "authors": [
      "Xuan Cheng",
      "Tianshu Xie",
      "Xiaomin Wang",
      "Qifeng Weng",
      "Minghui Liu",
      "Jiali Deng",
      "Ming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15383"
  },
  {
    "id": "arXiv:2104.07611",
    "title": "Adapting Coreference Resolution Models through Active Learning",
    "abstract": "Comments: Accepted at ACL 2022 Main Conference",
    "descriptor": "\nComments: Accepted at ACL 2022 Main Conference\n",
    "authors": [
      "Michelle Yuan",
      "Patrick Xia",
      "Chandler May",
      "Benjamin Van Durme",
      "Jordan Boyd-Graber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.07611"
  },
  {
    "id": "arXiv:2104.09443",
    "title": "Numerical analysis of a Neumann boundary control problem with a  stochastic parabolic equation",
    "abstract": "Numerical analysis of a Neumann boundary control problem with a  stochastic parabolic equation",
    "descriptor": "",
    "authors": [
      "Qin Zhou",
      "Binjie Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.09443"
  },
  {
    "id": "arXiv:2104.11221",
    "title": "Opening up Open-World Tracking",
    "abstract": "Comments: CVPR 2022 (Oral). this https URL",
    "descriptor": "\nComments: CVPR 2022 (Oral). this https URL\n",
    "authors": [
      "Yang Liu",
      "Idil Esen Zulfikar",
      "Jonathon Luiten",
      "Achal Dave",
      "Deva Ramanan",
      "Bastian Leibe",
      "Aljo\u0161a O\u0161ep",
      "Laura Leal-Taix\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.11221"
  },
  {
    "id": "arXiv:2104.11934",
    "title": "RelTransformer: A Transformer-Based Long-Tail Visual Relationship  Recognition",
    "abstract": "RelTransformer: A Transformer-Based Long-Tail Visual Relationship  Recognition",
    "descriptor": "",
    "authors": [
      "Jun Chen",
      "Aniket Agarwal",
      "Sherif Abdelkarim",
      "Deyao Zhu",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.11934"
  },
  {
    "id": "arXiv:2104.13844",
    "title": "A Generalized Projected Bellman Error for Off-policy Value Estimation in  Reinforcement Learning",
    "abstract": "Comments: Accepted for publication in JMLR 2022",
    "descriptor": "\nComments: Accepted for publication in JMLR 2022\n",
    "authors": [
      "Andrew Patterson",
      "Adam White",
      "Martha White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.13844"
  },
  {
    "id": "arXiv:2105.00419",
    "title": "Graph Vulnerability and Robustness: A Survey",
    "abstract": "Comments: Accepted into Transactions on Knowledge and Data Engineering (TKDE) 2022",
    "descriptor": "\nComments: Accepted into Transactions on Knowledge and Data Engineering (TKDE) 2022\n",
    "authors": [
      "Scott Freitas",
      "Diyi Yang",
      "Srijan Kumar",
      "Hanghang Tong",
      "Duen Horng Chau"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.00419"
  },
  {
    "id": "arXiv:2105.02487",
    "title": "High-dimensional Functional Graphical Model Structure Learning via  Neighborhood Selection Approach",
    "abstract": "High-dimensional Functional Graphical Model Structure Learning via  Neighborhood Selection Approach",
    "descriptor": "",
    "authors": [
      "Boxin Zhao",
      "Percy S. Zhai",
      "Y. Samuel Wang",
      "Mladen Kolar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.02487"
  },
  {
    "id": "arXiv:2105.02914",
    "title": "Self-Replication via Tile Self-Assembly",
    "abstract": "Comments: Updated to include changes reflecting reviewer comments",
    "descriptor": "\nComments: Updated to include changes reflecting reviewer comments\n",
    "authors": [
      "Andrew Alseth",
      "Daniel Hader",
      "Matthew J. Patitz"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2105.02914"
  },
  {
    "id": "arXiv:2105.06166",
    "title": "The Dynamic k-Mismatch Problem",
    "abstract": "The Dynamic k-Mismatch Problem",
    "descriptor": "",
    "authors": [
      "Rapha\u00ebl Clifford",
      "Pawe\u0142 Gawrychowski",
      "Tomasz Kociumaka",
      "Daniel P. Martin",
      "Przemys\u0142aw Uzna\u0144ski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.06166"
  },
  {
    "id": "arXiv:2105.11527",
    "title": "Unsupervised Visual Representation Learning by Online Constrained  K-Means",
    "abstract": "Comments: accepted by CVPR'22",
    "descriptor": "\nComments: accepted by CVPR'22\n",
    "authors": [
      "Qi Qian",
      "Yuanhong Xu",
      "Juhua Hu",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11527"
  },
  {
    "id": "arXiv:2105.13353",
    "title": "Unsupervised Action Segmentation by Joint Representation Learning and  Online Clustering",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Sateesh Kumar",
      "Sanjay Haresh",
      "Awais Ahmed",
      "Andrey Konin",
      "M. Zeeshan Zia",
      "Quoc-Huy Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13353"
  },
  {
    "id": "arXiv:2105.14839",
    "title": "Greedy-layer Pruning: Speeding up Transformer Models for Natural  Language Processing",
    "abstract": "Comments: Accepted at Pattern Recognition Letters",
    "descriptor": "\nComments: Accepted at Pattern Recognition Letters\n",
    "authors": [
      "David Peer",
      "Sebastian Stabinger",
      "Stefan Engl",
      "Antonio Rodriguez-Sanchez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14839"
  },
  {
    "id": "arXiv:2106.00896",
    "title": "Asymptotics of Sequential Composite Hypothesis Testing under  Probabilistic Constraints",
    "abstract": "Comments: The paper was presented in part at the 2021 International Symposium on Information Theory (ISIT). It was accepted by Transactions on Information Theory",
    "descriptor": "\nComments: The paper was presented in part at the 2021 International Symposium on Information Theory (ISIT). It was accepted by Transactions on Information Theory\n",
    "authors": [
      "Jiachun Pan",
      "Yonglong Li",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.00896"
  },
  {
    "id": "arXiv:2106.04550",
    "title": "DETReg: Unsupervised Pretraining with Region Priors for Object Detection",
    "abstract": "Comments: CVPR 2022 Camera Ready",
    "descriptor": "\nComments: CVPR 2022 Camera Ready\n",
    "authors": [
      "Amir Bar",
      "Xin Wang",
      "Vadim Kantorov",
      "Colorado J Reed",
      "Roei Herzig",
      "Gal Chechik",
      "Anna Rohrbach",
      "Trevor Darrell",
      "Amir Globerson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04550"
  },
  {
    "id": "arXiv:2106.09485",
    "title": "Secure Multi-Function Computation with Private Remote Sources",
    "abstract": "Comments: Shorter version appeared in the IEEE International Symposium on Information Theory 2021",
    "descriptor": "\nComments: Shorter version appeared in the IEEE International Symposium on Information Theory 2021\n",
    "authors": [
      "Onur G\u00fcnl\u00fc",
      "Matthieu Bloch",
      "Rafael F. Schaefer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.09485"
  },
  {
    "id": "arXiv:2106.14308",
    "title": "Concentration of Contractive Stochastic Approximation and Reinforcement  Learning",
    "abstract": "Comments: 20 pages, Submitted to Stochastic Systems",
    "descriptor": "\nComments: 20 pages, Submitted to Stochastic Systems\n",
    "authors": [
      "Siddharth Chandak",
      "Vivek S. Borkar",
      "Parth Dodhia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.14308"
  },
  {
    "id": "arXiv:2106.14802",
    "title": "Communication Analysis through Visual Analytics: Current Practices,  Challenges, and New Frontiers",
    "abstract": "Comments: 11 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 11 pages, 3 figures, 2 tables\n",
    "authors": [
      "Maximilian T. Fischer",
      "Frederik L. Dennig",
      "Daniel Seebacher",
      "Daniel A. Keim",
      "Mennatallah El-Assady"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.14802"
  },
  {
    "id": "arXiv:2107.00309",
    "title": "Spotting adversarial samples for speaker verification by neural vocoders",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Haibin Wu",
      "Po-chun Hsu",
      "Ji Gao",
      "Shanshan Zhang",
      "Shen Huang",
      "Jian Kang",
      "Zhiyong Wu",
      "Helen Meng",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.00309"
  },
  {
    "id": "arXiv:2107.01189",
    "title": "NTIRE 2021 Multi-modal Aerial View Object Classification Challenge",
    "abstract": "Comments: We need to withdraw this paper due to bureaucratic reasons. This paper hasn't gone through all the necessary passes for public release regarding the Air Force Research Laboratory and thus we need to withdraw from arXiv",
    "descriptor": "\nComments: We need to withdraw this paper due to bureaucratic reasons. This paper hasn't gone through all the necessary passes for public release regarding the Air Force Research Laboratory and thus we need to withdraw from arXiv\n",
    "authors": [
      "Jerrick Liu",
      "Nathan Inkawhich",
      "Oliver Nina",
      "Radu Timofte",
      "Sahil Jain",
      "Bob Lee",
      "Yuru Duan",
      "Wei Wei",
      "Lei Zhang",
      "Songzheng Xu",
      "Yuxuan Sun",
      "Jiaqi Tang",
      "Xueli Geng",
      "Mengru Ma",
      "Gongzhe Li",
      "Xueli Geng",
      "Huanqia Cai",
      "Chengxue Cai",
      "Sol Cummings",
      "Casian Miron",
      "Alexandru Pasarica",
      "Cheng-Yen Yang",
      "Hung-Min Hsu",
      "Jiarui Cai",
      "Jie Mei",
      "Chia-Ying Yeh",
      "Jenq-Neng Hwang",
      "Michael Xin",
      "Zhongkai Shangguan",
      "Zihe Zheng",
      "Xu Yifei",
      "Lehan Yang",
      "Kele Xu",
      "Min Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01189"
  },
  {
    "id": "arXiv:2107.06800",
    "title": "Signed Barcodes for Multi-Parameter Persistence via Rank Decompositions  and Rank-Exact Resolutions",
    "abstract": "Comments: Clarified the positioning w.r.t. the related work; added a section on signed prominence diagrams (6.3) discussing the signal-vs-noise ratio in signed barcodes; improved the exposition and corrected minor bugs, taking some of the SoCG reviewers' comments into account",
    "descriptor": "\nComments: Clarified the positioning w.r.t. the related work; added a section on signed prominence diagrams (6.3) discussing the signal-vs-noise ratio in signed barcodes; improved the exposition and corrected minor bugs, taking some of the SoCG reviewers' comments into account\n",
    "authors": [
      "Magnus Bakke Botnan",
      "Steffen Oppermann",
      "Steve Oudot"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2107.06800"
  },
  {
    "id": "arXiv:2108.01036",
    "title": "Optimal Solving of Constrained Path-Planning Problems with Graph  Convolutional Networks and Optimized Tree Search",
    "abstract": "Comments: Complete version with full references",
    "descriptor": "\nComments: Complete version with full references\n",
    "authors": [
      "Kevin Osanlou",
      "Andrei Bursuc",
      "Christophe Guettier",
      "Tristan Cazenave",
      "Eric Jacopin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.01036"
  },
  {
    "id": "arXiv:2108.01405",
    "title": "Region-wise Loss for Biomedical Image Segmentation",
    "abstract": "Region-wise Loss for Biomedical Image Segmentation",
    "descriptor": "",
    "authors": [
      "Juan Miguel Valverde",
      "Jussi Tohka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01405"
  },
  {
    "id": "arXiv:2108.02297",
    "title": "Spartus: A 9.4 TOp/s FPGA-based LSTM Accelerator Exploiting  Spatio-Temporal Sparsity",
    "abstract": "Comments: Preprint. Under review",
    "descriptor": "\nComments: Preprint. Under review\n",
    "authors": [
      "Chang Gao",
      "Tobi Delbruck",
      "Shih-Chii Liu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.02297"
  },
  {
    "id": "arXiv:2108.04601",
    "title": "Cellular-Connected UAV with Adaptive Air-to-Ground Interference  Cancellation and Trajectory Optimization",
    "abstract": "Comments: Technical Report",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Peiming Li",
      "Lifeng Xie",
      "Jianping Yao",
      "Jie Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.04601"
  },
  {
    "id": "arXiv:2108.08581",
    "title": "F-PKI: Enabling Innovation and Trust Flexibility in the HTTPS Public-Key  Infrastructure",
    "abstract": "Comments: Network and Distributed System Security Symposium (NDSS) 2022",
    "descriptor": "\nComments: Network and Distributed System Security Symposium (NDSS) 2022\n",
    "authors": [
      "Laurent Chuat",
      "Cyrill Kr\u00e4henb\u00fchl",
      "Prateek Mittal",
      "Adrian Perrig"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.08581"
  },
  {
    "id": "arXiv:2108.08871",
    "title": "Structure Learning for Directed Trees",
    "abstract": "Structure Learning for Directed Trees",
    "descriptor": "",
    "authors": [
      "Martin Emil Jakobsen",
      "Rajen D. Shah",
      "Peter B\u00fchlmann",
      "Jonas Peters"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08871"
  },
  {
    "id": "arXiv:2108.10360",
    "title": "Interpreting Face Inference Models using Hierarchical Network Dissection",
    "abstract": "Interpreting Face Inference Models using Hierarchical Network Dissection",
    "descriptor": "",
    "authors": [
      "Divyang Teotia",
      "Agata Lapedriza",
      "Sarah Ostadabbas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.10360"
  },
  {
    "id": "arXiv:2108.11552",
    "title": "An efficient unconditionally stable method for Dirichlet partitions in  arbitrary domains",
    "abstract": "Comments: 28 pages, 17 figures",
    "descriptor": "\nComments: 28 pages, 17 figures\n",
    "authors": [
      "Dong Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.11552"
  },
  {
    "id": "arXiv:2108.12314",
    "title": "Multiple Hypothesis Testing Framework for Spatial Signals",
    "abstract": "Comments: Submitted to IEEE Transactions on Signal and Information Processing over Networks",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Signal and Information Processing over Networks\n",
    "authors": [
      "Martin G\u00f6lz",
      "Abdelhak M. Zoubir",
      "Visa Koivunen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2108.12314"
  },
  {
    "id": "arXiv:2109.04094",
    "title": "An Experimental Study of Class Imbalance in Federated Learning",
    "abstract": "An Experimental Study of Class Imbalance in Federated Learning",
    "descriptor": "",
    "authors": [
      "C. Xiao",
      "S. Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04094"
  },
  {
    "id": "arXiv:2109.09477",
    "title": "Beyond Semantic to Instance Segmentation: Weakly-Supervised Instance  Segmentation via Semantic Knowledge Transfer and Self-Refinement",
    "abstract": "Comments: CVPR 2022, Accepted",
    "descriptor": "\nComments: CVPR 2022, Accepted\n",
    "authors": [
      "Beomyoung Kim",
      "Youngjoon Yoo",
      "Chaeeun Rhee",
      "Junmo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.09477"
  },
  {
    "id": "arXiv:2109.10742",
    "title": "Early Lane Change Prediction for Automated Driving Systems Using  Multi-Task Attention-based Convolutional Neural Networks",
    "abstract": "Comments: 13 pages, 11 figures",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Sajjad Mozaffari",
      "Eduardo Arnold",
      "Mehrdad Dianati",
      "Saber Fallah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.10742"
  },
  {
    "id": "arXiv:2109.13854",
    "title": "Optimal Sensor Gain Control for Minimum-Information Estimation of  Continuous-Time Gauss-Markov Processes",
    "abstract": "Optimal Sensor Gain Control for Minimum-Information Estimation of  Continuous-Time Gauss-Markov Processes",
    "descriptor": "",
    "authors": [
      "Vrushabh Zinage",
      "Takashi Tanaka",
      "Valeri Ugrinovskii"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.13854"
  },
  {
    "id": "arXiv:2109.13926",
    "title": "PSI: Constructing ad-hoc Simplices to Interpolate High-Dimensional  Unstructured Data",
    "abstract": "Comments: 4 pages, 4 figures",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Stefan L\u00fcders",
      "Klaus Dolag"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2109.13926"
  },
  {
    "id": "arXiv:2109.14834",
    "title": "IntentVizor: Towards Generic Query Guided Interactive Video  Summarization",
    "abstract": "Comments: 10 pages and 4 figures, CVPR 2022",
    "descriptor": "\nComments: 10 pages and 4 figures, CVPR 2022\n",
    "authors": [
      "Guande Wu",
      "Jianzhe Lin",
      "Claudio T. Silva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.14834"
  },
  {
    "id": "arXiv:2110.03012",
    "title": "Emphasis control for parallel neural TTS",
    "abstract": "Comments: 5 pages, 5 figures, submitted to Interspeech 2022",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to Interspeech 2022\n",
    "authors": [
      "Shreyas Seshadri",
      "Tuomo Raitio",
      "Dan Castellani",
      "Jiangchuan Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03012"
  },
  {
    "id": "arXiv:2110.03299",
    "title": "End-To-End Label Uncertainty Modeling for Speech-based Arousal  Recognition Using Bayesian Neural Networks",
    "abstract": "Comments: This paper is submitted to INTERSPEECH 2022",
    "descriptor": "\nComments: This paper is submitted to INTERSPEECH 2022\n",
    "authors": [
      "Navin Raj Prabhu",
      "Guillaume Carbajal",
      "Nale Lehmann-Willenbrock",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03299"
  },
  {
    "id": "arXiv:2110.03380",
    "title": "Disentangled dimensionality reduction for noise-robust speaker  diarisation",
    "abstract": "Comments: This paper was submitted to Interspeech2022",
    "descriptor": "\nComments: This paper was submitted to Interspeech2022\n",
    "authors": [
      "You Jin Kim",
      "Hee-Soo Heo",
      "Jee-weon Jung",
      "Youngki Kwon",
      "Bong-Jin Lee",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03380"
  },
  {
    "id": "arXiv:2110.03715",
    "title": "PEAF: Learnable Power Efficient Analog Acoustic Features for Audio  Recognition",
    "abstract": "Comments: Submitted to Interspeech 2022",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Boris Bergsma",
      "Minhao Yang",
      "Milos Cernak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.03715"
  },
  {
    "id": "arXiv:2110.05064",
    "title": "Ab-Initio Potential Energy Surfaces by Pairing GNNs with Neural Wave  Functions",
    "abstract": "Comments: Published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Nicholas Gao",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05064"
  },
  {
    "id": "arXiv:2110.05069",
    "title": "Efficient Training of Audio Transformers with Patchout",
    "abstract": "Comments: Submitted to Interspeech 2022. Source code: this https URL",
    "descriptor": "\nComments: Submitted to Interspeech 2022. Source code: this https URL\n",
    "authors": [
      "Khaled Koutini",
      "Jan Schl\u00fcter",
      "Hamid Eghbal-zadeh",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05069"
  },
  {
    "id": "arXiv:2110.05313",
    "title": "Unsupervised Source Separation via Bayesian Inference in the Latent  Domain",
    "abstract": "Comments: 5 pages, 2 figures, submitted to Interspeech 2022",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to Interspeech 2022\n",
    "authors": [
      "Michele Mancusi",
      "Emilian Postolache",
      "Giorgio Mariani",
      "Marco Fumero",
      "Andrea Santilli",
      "Luca Cosmo",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05313"
  },
  {
    "id": "arXiv:2110.05909",
    "title": "Rescoring Sequence-to-Sequence Models for Text Line Recognition with  CTC-Prefixes",
    "abstract": "Comments: 15 pages, 6 tables, 3 figures",
    "descriptor": "\nComments: 15 pages, 6 tables, 3 figures\n",
    "authors": [
      "Christoph Wick",
      "Jochen Z\u00f6llner",
      "Tobias Gr\u00fcning"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05909"
  },
  {
    "id": "arXiv:2110.06651",
    "title": "MDERank: A Masked Document Embedding Rank Approach for Unsupervised  Keyphrase Extraction",
    "abstract": "Comments: 13 pages, 5 figures",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Linhan Zhang",
      "Qian Chen",
      "Wen Wang",
      "Chong Deng",
      "Shiliang Zhang",
      "Bing Li",
      "Wei Wang",
      "Xin Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06651"
  },
  {
    "id": "arXiv:2110.06691",
    "title": "Diverse Audio Captioning via Adversarial Training",
    "abstract": "Comments: 5 pages, 1 figure, accepted by ICASSP 2022",
    "descriptor": "\nComments: 5 pages, 1 figure, accepted by ICASSP 2022\n",
    "authors": [
      "Xinhao Mei",
      "Xubo Liu",
      "Jianyuan Sun",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.06691"
  },
  {
    "id": "arXiv:2110.07018",
    "title": "Algebraic Reasoning of Quantum Programs via Non-idempotent Kleene  Algebra",
    "abstract": "Comments: extended version, 23 pages, 6 figures, to appear at the 43rd ACM SIGPLAN PLDI 2022",
    "descriptor": "\nComments: extended version, 23 pages, 6 figures, to appear at the 43rd ACM SIGPLAN PLDI 2022\n",
    "authors": [
      "Yuxiang Peng",
      "Mingsheng Ying",
      "Xiaodi Wu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.07018"
  },
  {
    "id": "arXiv:2110.08214",
    "title": "From Start to Finish: Latency Reduction Strategies for Incremental  Speech Synthesis in Simultaneous Speech-to-Speech Translation",
    "abstract": "Comments: Submitted to Interspeech 2022",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Danni Liu",
      "Changhan Wang",
      "Hongyu Gong",
      "Xutai Ma",
      "Yun Tang",
      "Juan Pino"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.08214"
  },
  {
    "id": "arXiv:2110.08470",
    "title": "Case-based Reasoning for Better Generalization in Textual Reinforcement  Learning",
    "abstract": "Comments: Published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Mattia Atzeni",
      "Shehzaad Dhuliawala",
      "Keerthiram Murugesan",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08470"
  },
  {
    "id": "arXiv:2110.08515",
    "title": "Multimodal Dialogue Response Generation",
    "abstract": "Comments: Accepted to ACL 2022 Main Conference",
    "descriptor": "\nComments: Accepted to ACL 2022 Main Conference\n",
    "authors": [
      "Qingfeng Sun",
      "Yujing Wang",
      "Can Xu",
      "Kai Zheng",
      "Yaming Yang",
      "Huang Hu",
      "Fei Xu",
      "Jessica Zhang",
      "Xiubo Geng",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.08515"
  },
  {
    "id": "arXiv:2110.08851",
    "title": "Unsupervised Representation Learning for Binary Networks by Joint  Classifier Learning",
    "abstract": "Comments: to appear in CVPR2022",
    "descriptor": "\nComments: to appear in CVPR2022\n",
    "authors": [
      "Dahyun Kim",
      "Jonghyun Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08851"
  },
  {
    "id": "arXiv:2110.10026",
    "title": "Private Language Model Adaptation for Speech Recognition",
    "abstract": "Comments: Submitted to INTERSPEECH 2022",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Zhe Liu",
      "Ke Li",
      "Shreyan Bakshi",
      "Fuchun Peng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.10026"
  },
  {
    "id": "arXiv:2110.10720",
    "title": "Privacy in Open Search: A Review of Challenges and Solutions",
    "abstract": "Comments: Paper accepted at OSSYM 2021 - Third International Open Search Symposium",
    "descriptor": "\nComments: Paper accepted at OSSYM 2021 - Third International Open Search Symposium\n",
    "authors": [
      "Samuel Sousa",
      "Christian Guetl",
      "Roman Kern"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.10720"
  },
  {
    "id": "arXiv:2110.10928",
    "title": "Quantum field theories, Markov random fields and machine learning",
    "abstract": "Quantum field theories, Markov random fields and machine learning",
    "descriptor": "",
    "authors": [
      "Dimitrios Bachtis",
      "Gert Aarts",
      "Biagio Lucini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "High Energy Physics - Lattice (hep-lat)"
    ],
    "url": "https://arxiv.org/abs/2110.10928"
  },
  {
    "id": "arXiv:2110.11241",
    "title": "Measuring the (Over)use of Service Workers for In-Page Push Advertising  Purposes",
    "abstract": "Comments: 13 pages, PAM'22",
    "descriptor": "\nComments: 13 pages, PAM'22\n",
    "authors": [
      "George Pantelakis",
      "Panagiotis Papadopoulos",
      "Nicolas Kourtellis",
      "Evangelos P. Markatos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.11241"
  },
  {
    "id": "arXiv:2110.12509",
    "title": "Per-Pixel Lung Thickness and Lung Capacity Estimation on Chest X-Rays  using Convolutional Neural Networks",
    "abstract": "Comments: v4: fixed simulation bug, improved text, various other improvements",
    "descriptor": "\nComments: v4: fixed simulation bug, improved text, various other improvements\n",
    "authors": [
      "Manuel Schultheiss",
      "Philipp Schmette",
      "Thorsten Sellerer",
      "Rafael Schick",
      "Kirsten Taphorn",
      "Korbinian Mechlem",
      "Lorenz Birnbacher",
      "Bernhard Renger",
      "Marcus R. Makowski",
      "Franz Pfeiffer",
      "Daniela Pfeiffer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12509"
  },
  {
    "id": "arXiv:2110.12663",
    "title": "Industrial Scene Text Detection with Refined Feature-attentive Network",
    "abstract": "Industrial Scene Text Detection with Refined Feature-attentive Network",
    "descriptor": "",
    "authors": [
      "Tongkun Guan",
      "Chaochen Gu",
      "Changsheng Lu",
      "Jingzheng Tu",
      "Qi Feng",
      "Kaijie Wu",
      "Xinping Guan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12663"
  },
  {
    "id": "arXiv:2111.02277",
    "title": "Counting Small Induced Subgraphs with Hereditary Properties",
    "abstract": "Comments: An extended abstract of this work is accepted for publication at STOC22, 29 pages, 4 figures",
    "descriptor": "\nComments: An extended abstract of this work is accepted for publication at STOC22, 29 pages, 4 figures\n",
    "authors": [
      "Jacob Focke",
      "Marc Roth"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.02277"
  },
  {
    "id": "arXiv:2111.02599",
    "title": "Leveraging Time Irreversibility with Order-Contrastive Pre-training",
    "abstract": "Leveraging Time Irreversibility with Order-Contrastive Pre-training",
    "descriptor": "",
    "authors": [
      "Monica Agrawal",
      "Hunter Lang",
      "Michael Offin",
      "Lior Gazit",
      "David Sontag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02599"
  },
  {
    "id": "arXiv:2111.04330",
    "title": "Characterizing the adversarial vulnerability of speech self-supervised  learning",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Haibin Wu",
      "Bo Zheng",
      "Xu Li",
      "Xixin Wu",
      "Hung-yi Lee",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.04330"
  },
  {
    "id": "arXiv:2111.04414",
    "title": "Open-Source Internships With Industry Mentors",
    "abstract": "Comments: Will appear in Proceedings of the 27th ACM Conference on Innovation and Technology in Computer Science Education",
    "descriptor": "\nComments: Will appear in Proceedings of the 27th ACM Conference on Innovation and Technology in Computer Science Education\n",
    "authors": [
      "Tyler Menezes",
      "Alex Parra",
      "Mingjie Jiang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.04414"
  },
  {
    "id": "arXiv:2111.05132",
    "title": "BreakBot: Analyzing the Impact of Breaking Changes to Assist Library  Evolution",
    "abstract": "Comments: 44th IEEE/ACM International Conference on Software Engineering: New Ideas and Emerging Results, ICSE (NIER) 2022, May 2022, Pittsburgh, United States",
    "descriptor": "\nComments: 44th IEEE/ACM International Conference on Software Engineering: New Ideas and Emerging Results, ICSE (NIER) 2022, May 2022, Pittsburgh, United States\n",
    "authors": [
      "Lina Ochoa",
      "Thomas Degueule",
      "Jean-R\u00e9my Falleri"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.05132"
  },
  {
    "id": "arXiv:2111.07818",
    "title": "A Teacher-Student Markov Decision Process-based Framework for Online  Correctional Learning",
    "abstract": "Comments: 8 pages, 7 figures",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "In\u00eas Louren\u00e7o",
      "Rebecka Winqvist",
      "Cristian R. Rojas",
      "Bo Wahlberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.07818"
  },
  {
    "id": "arXiv:2111.09354",
    "title": "Punyo-1: Soft tactile-sensing upper-body robot for large object  manipulation and physical human interaction",
    "abstract": "Comments: Research done at Toyota Research Institute. Accepted to the 5th IEEE International Conference on Soft Robotics (RoboSoft 2022). The supplemental video is available publicly at this https URL",
    "descriptor": "\nComments: Research done at Toyota Research Institute. Accepted to the 5th IEEE International Conference on Soft Robotics (RoboSoft 2022). The supplemental video is available publicly at this https URL\n",
    "authors": [
      "Aimee Goncalves",
      "Naveen Kuppuswamy",
      "Andrew Beaulieu",
      "Avinash Uttamchandani",
      "Katherine M. Tsui",
      "Alex Alspach"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.09354"
  },
  {
    "id": "arXiv:2111.09639",
    "title": "Recurrent Variational Network: A Deep Learning Inverse Problem Solver  applied to the task of Accelerated MRI Reconstruction",
    "abstract": "Comments: 18 pages, 10 figures, 3 tables, CVPR 22",
    "descriptor": "\nComments: 18 pages, 10 figures, 3 tables, CVPR 22\n",
    "authors": [
      "George Yiasemis",
      "Jan-Jakob Sonke",
      "Clarisa S\u00e1nchez",
      "Jonas Teuwen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.09639"
  },
  {
    "id": "arXiv:2111.10761",
    "title": "An OSRC Preconditioner for the EFIE",
    "abstract": "An OSRC Preconditioner for the EFIE",
    "descriptor": "",
    "authors": [
      "Ignacia Fierro-Piccardo",
      "Timo Betcke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.10761"
  },
  {
    "id": "arXiv:2111.11210",
    "title": "GCR: Gradient Coreset Based Replay Buffer Selection For Continual  Learning",
    "abstract": "Comments: Published at CVPR 2022",
    "descriptor": "\nComments: Published at CVPR 2022\n",
    "authors": [
      "Rishabh Tiwari",
      "Krishnateja Killamsetty",
      "Rishabh Iyer",
      "Pradeep Shenoy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.11210"
  },
  {
    "id": "arXiv:2111.12727",
    "title": "Universal Captioner: Inducing Content-Style Separation in  Vision-and-Language Model Training",
    "abstract": "Universal Captioner: Inducing Content-Style Separation in  Vision-and-Language Model Training",
    "descriptor": "",
    "authors": [
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Giuseppe Fiameni",
      "Rita Cucchiara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.12727"
  },
  {
    "id": "arXiv:2111.13152",
    "title": "Scene Representation Transformer: Geometry-Free Novel View Synthesis  Through Set-Latent Scene Representations",
    "abstract": "Comments: Accepted to CVPR 2022, Project website: this https URL",
    "descriptor": "\nComments: Accepted to CVPR 2022, Project website: this https URL\n",
    "authors": [
      "Mehdi S. M. Sajjadi",
      "Henning Meyer",
      "Etienne Pot",
      "Urs Bergmann",
      "Klaus Greff",
      "Noha Radwan",
      "Suhani Vora",
      "Mario Lucic",
      "Daniel Duckworth",
      "Alexey Dosovitskiy",
      "Jakob Uszkoreit",
      "Thomas Funkhouser",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.13152"
  },
  {
    "id": "arXiv:2111.13839",
    "title": "Towards Principled Disentanglement for Domain Generalization",
    "abstract": "Comments: CVPR 2022 Oral",
    "descriptor": "\nComments: CVPR 2022 Oral\n",
    "authors": [
      "Hanlin Zhang",
      "Yi-Fan Zhang",
      "Weiyang Liu",
      "Adrian Weller",
      "Bernhard Sch\u00f6lkopf",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13839"
  },
  {
    "id": "arXiv:2111.13844",
    "title": "Adaptive Image Transformations for Transfer-based Adversarial Attack",
    "abstract": "Comments: 33 pages, 7 figures, 10 tables",
    "descriptor": "\nComments: 33 pages, 7 figures, 10 tables\n",
    "authors": [
      "Zheng Yuan",
      "Jie Zhang",
      "Shiguang Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13844"
  },
  {
    "id": "arXiv:2111.14562",
    "title": "Instance-wise Occlusion and Depth Orders in Natural Scenes",
    "abstract": "Comments: Accepted to CVPR 2022. Code is available at this https URL",
    "descriptor": "\nComments: Accepted to CVPR 2022. Code is available at this https URL\n",
    "authors": [
      "Hyunmin Lee",
      "Jaesik Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.14562"
  },
  {
    "id": "arXiv:2111.14755",
    "title": "FaceAtlasAR: Atlas of Facial Acupuncture Points in Augmented Reality",
    "abstract": "FaceAtlasAR: Atlas of Facial Acupuncture Points in Augmented Reality",
    "descriptor": "",
    "authors": [
      "Menghe Zhang",
      "Jurgen Schulze",
      "Dong Zhang"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.14755"
  },
  {
    "id": "arXiv:2111.14777",
    "title": "Deep Decomposition for Stochastic Normal-Abnormal Transport",
    "abstract": "Comments: Accepted as ORAL to CVPR 2022 (15 pages, 5 figures)",
    "descriptor": "\nComments: Accepted as ORAL to CVPR 2022 (15 pages, 5 figures)\n",
    "authors": [
      "Peirong Liu",
      "Yueh Lee",
      "Stephen Aylward",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14777"
  },
  {
    "id": "arXiv:2111.14788",
    "title": "Comparing Machine Learning and Interpolation Methods for Loop-Level  Calculations",
    "abstract": "Comments: 30 pages, 17 figures, v2:added a few references, v3: new title, added a few references",
    "descriptor": "\nComments: 30 pages, 17 figures, v2:added a few references, v3: new title, added a few references\n",
    "authors": [
      "Ibrahim Chahrour",
      "James D. Wells"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14788"
  },
  {
    "id": "arXiv:2111.14820",
    "title": "Towards Robust and Adaptive Motion Forecasting: A Causal Representation  Perspective",
    "abstract": "Comments: CVPR 2022. Code is available at this https URL v3: update details",
    "descriptor": "\nComments: CVPR 2022. Code is available at this https URL v3: update details\n",
    "authors": [
      "Yuejiang Liu",
      "Riccardo Cadei",
      "Jonas Schweizer",
      "Sherwin Bahmani",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.14820"
  },
  {
    "id": "arXiv:2111.14887",
    "title": "DAFormer: Improving Network Architectures and Training Strategies for  Domain-Adaptive Semantic Segmentation",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Lukas Hoyer",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14887"
  },
  {
    "id": "arXiv:2111.15307",
    "title": "Gaussian Mechanisms Against Statistical Inference: Synthesis Tools",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2108.01755",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2108.01755\n",
    "authors": [
      "Haleh Hayati",
      "Carlos Murguia",
      "Nathan van de Wouw"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.15307"
  },
  {
    "id": "arXiv:2111.15666",
    "title": "HyperStyle: StyleGAN Inversion with HyperNetworks for Real Image Editing",
    "abstract": "Comments: Accepted to CVPR 2022; Project page available at this http URL",
    "descriptor": "\nComments: Accepted to CVPR 2022; Project page available at this http URL\n",
    "authors": [
      "Yuval Alaluf",
      "Omer Tov",
      "Ron Mokady",
      "Rinon Gal",
      "Amit H. Bermano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15666"
  },
  {
    "id": "arXiv:2112.00054",
    "title": "Task2Sim : Towards Effective Pre-training and Transfer from Synthetic  Data",
    "abstract": "Comments: Accepted to CVPR'22",
    "descriptor": "\nComments: Accepted to CVPR'22\n",
    "authors": [
      "Samarth Mishra",
      "Rameswar Panda",
      "Cheng Perng Phoo",
      "Chun-Fu Chen",
      "Leonid Karlinsky",
      "Kate Saenko",
      "Venkatesh Saligrama",
      "Rogerio S. Feris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00054"
  },
  {
    "id": "arXiv:2112.00071",
    "title": "What to Learn, and How: Toward Effective Learning from Rationales",
    "abstract": "Comments: Accepted to ACL Findings 2022 13 pages, 8 figures",
    "descriptor": "\nComments: Accepted to ACL Findings 2022 13 pages, 8 figures\n",
    "authors": [
      "Samuel Carton",
      "Surya Kanoria",
      "Chenhao Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00071"
  },
  {
    "id": "arXiv:2112.00726",
    "title": "MonoScene: Monocular 3D Semantic Scene Completion",
    "abstract": "Comments: Accepted at CVPR 2022. Project page: this https URL",
    "descriptor": "\nComments: Accepted at CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Anh-Quan Cao",
      "Raoul de Charette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00726"
  },
  {
    "id": "arXiv:2112.01882",
    "title": "Incremental Learning in Semantic Segmentation from Image Labels",
    "abstract": "Comments: To appear in CVPR 22",
    "descriptor": "\nComments: To appear in CVPR 22\n",
    "authors": [
      "Fabio Cermelli",
      "Dario Fontanel",
      "Antonio Tavera",
      "Marco Ciccone",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01882"
  },
  {
    "id": "arXiv:2112.01900",
    "title": "Novel Class Discovery in Semantic Segmentation",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Yuyang Zhao",
      "Zhun Zhong",
      "Nicu Sebe",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01900"
  },
  {
    "id": "arXiv:2112.02236",
    "title": "SemanticStyleGAN: Learning Compositional Generative Priors for  Controllable Image Synthesis and Editing",
    "abstract": "Comments: Camera-ready for CVPR 2022. Project page at this https URL",
    "descriptor": "\nComments: Camera-ready for CVPR 2022. Project page at this https URL\n",
    "authors": [
      "Yichun Shi",
      "Xiao Yang",
      "Yangyue Wan",
      "Xiaohui Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02236"
  },
  {
    "id": "arXiv:2112.02290",
    "title": "Interactive Disentanglement: Learning Concepts by Interacting with their  Prototype Representations",
    "abstract": "Comments: To be published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022",
    "descriptor": "\nComments: To be published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022\n",
    "authors": [
      "Wolfgang Stammer",
      "Marius Memmel",
      "Patrick Schramowski",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02290"
  },
  {
    "id": "arXiv:2112.02306",
    "title": "Toward Practical Monocular Indoor Depth Estimation",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Cho-Ying Wu",
      "Jialiang Wang",
      "Michael Hall",
      "Ulrich Neumann",
      "Shuochen Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02306"
  },
  {
    "id": "arXiv:2112.02779",
    "title": "Revisiting LiDAR Registration and Reconstruction: A Range Image  Perspective",
    "abstract": "Comments: 14 pages, 9 figures. This paper is under the review",
    "descriptor": "\nComments: 14 pages, 9 figures. This paper is under the review\n",
    "authors": [
      "Wei Dong",
      "Kwonyoung Ryu",
      "Michael Kaess",
      "Jaesik Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.02779"
  },
  {
    "id": "arXiv:2112.03109",
    "title": "General Facial Representation Learning in a Visual-Linguistic Manner",
    "abstract": "Comments: CVPR22 oral; 16 pages, 6 figures, 14 tables",
    "descriptor": "\nComments: CVPR22 oral; 16 pages, 6 figures, 14 tables\n",
    "authors": [
      "Yinglin Zheng",
      "Hao Yang",
      "Ting Zhang",
      "Jianmin Bao",
      "Dongdong Chen",
      "Yangyu Huang",
      "Lu Yuan",
      "Dong Chen",
      "Ming Zeng",
      "Fang Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03109"
  },
  {
    "id": "arXiv:2112.03902",
    "title": "MS-TCT: Multi-Scale Temporal ConvTransformer for Action Detection",
    "abstract": "Comments: Accepted in CVPR 2022",
    "descriptor": "\nComments: Accepted in CVPR 2022\n",
    "authors": [
      "Rui Dai",
      "Srijan Das",
      "Kumara Kahatapitiya",
      "Michael S. Ryoo",
      "Francois Bremond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03902"
  },
  {
    "id": "arXiv:2112.03909",
    "title": "Vehicle trajectory prediction works, but not everywhere",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Mohammadhossein Bahari",
      "Saeed Saadatnejad",
      "Ahmad Rahimi",
      "Mohammad Shaverdikondori",
      "Amir-Hossein Shahidzadeh",
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03909"
  },
  {
    "id": "arXiv:2112.04809",
    "title": "Next Steps: Learning a Disentangled Gait Representation for Versatile  Quadruped Locomotion",
    "abstract": "Comments: 7 pages, 4 figures, accepted at IEEE International Conference on Robotics and Automation (ICRA), 2022",
    "descriptor": "\nComments: 7 pages, 4 figures, accepted at IEEE International Conference on Robotics and Automation (ICRA), 2022\n",
    "authors": [
      "Alexander L. Mitchell",
      "Wolfgang Merkt",
      "Mathieu Geisert",
      "Siddhant Gangapurwala",
      "Martin Engelcke",
      "Oiwi Parker Jones",
      "Ioannis Havoutis",
      "Ingmar Posner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04809"
  },
  {
    "id": "arXiv:2112.05135",
    "title": "PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures",
    "abstract": "Comments: CVPR 2022. Code and models are available at this https URL",
    "descriptor": "\nComments: CVPR 2022. Code and models are available at this https URL\n",
    "authors": [
      "Dan Hendrycks",
      "Andy Zou",
      "Mantas Mazeika",
      "Leonard Tang",
      "Bo Li",
      "Dawn Song",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.05135"
  },
  {
    "id": "arXiv:2112.05749",
    "title": "Label, Verify, Correct: A Simple Few Shot Object Detection Method",
    "abstract": "Comments: CVPR 2022, project page: this https URL",
    "descriptor": "\nComments: CVPR 2022, project page: this https URL\n",
    "authors": [
      "Prannay Kaul",
      "Weidi Xie",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.05749"
  },
  {
    "id": "arXiv:2112.06183",
    "title": "Few-shot Keypoint Detection with Uncertainty Learning for Unseen Species",
    "abstract": "Comments: 8 pages for main paper, 6 pages for supplementary materials",
    "descriptor": "\nComments: 8 pages for main paper, 6 pages for supplementary materials\n",
    "authors": [
      "Changsheng Lu",
      "Piotr Koniusz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06183"
  },
  {
    "id": "arXiv:2112.06632",
    "title": "Lifelong Unsupervised Domain Adaptive Person Re-identification with  Coordinated Anti-forgetting and Adaptation",
    "abstract": "Comments: Accepted by CVPR2022",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Zhipeng Huang",
      "Zhizheng Zhang",
      "Cuiling Lan",
      "Wenjun Zeng",
      "Peng Chu",
      "Quanzeng You",
      "Jiang Wang",
      "Zicheng Liu",
      "Zheng-jun Zha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06632"
  },
  {
    "id": "arXiv:2112.06721",
    "title": "PM-MMUT: Boosted Phone-mask Data Augmentation using Multi-Modeling Unit  Training for Phonetic-Reduction-Robust E2E Speech Recognition",
    "abstract": "Comments: Submitted to INTERSPEECH 2022",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Guodong Ma",
      "Pengfei Hu",
      "Nurmemet Yolwas",
      "Shen Huang",
      "Hao Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.06721"
  },
  {
    "id": "arXiv:2112.07919",
    "title": "Sample-Efficient Sparse Phase Retrieval via Stochastic Alternating  Minimization",
    "abstract": "Sample-Efficient Sparse Phase Retrieval via Stochastic Alternating  Minimization",
    "descriptor": "",
    "authors": [
      "Jian-Feng Cai",
      "Yuling Jiao",
      "Xiliang Lu",
      "Juntao You"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07919"
  },
  {
    "id": "arXiv:2112.08177",
    "title": "Multi-View Depth Estimation by Fusing Single-View Depth Probability with  Multi-View Geometry",
    "abstract": "Comments: CVPR 2022 (oral)",
    "descriptor": "\nComments: CVPR 2022 (oral)\n",
    "authors": [
      "Gwangbin Bae",
      "Ignas Budvytis",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08177"
  },
  {
    "id": "arXiv:2112.08274",
    "title": "Putting People in their Place: Monocular Regression of 3D People in  Depth",
    "abstract": "Comments: CVPR 2022; Code this https URL; Dataset this https URL",
    "descriptor": "\nComments: CVPR 2022; Code this https URL; Dataset this https URL\n",
    "authors": [
      "Yu Sun",
      "Wu Liu",
      "Qian Bao",
      "Yili Fu",
      "Tao Mei",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08274"
  },
  {
    "id": "arXiv:2112.08718",
    "title": "Domain Prompts: Towards memory and compute efficient domain adaptation  of ASR systems",
    "abstract": "Comments: InterSpeech 2022 submission",
    "descriptor": "\nComments: InterSpeech 2022 submission\n",
    "authors": [
      "Saket Dingliwal",
      "Ashish Shenoy",
      "Sravan Bodapati",
      "Ankur Gandhe",
      "Ravi Teja Gadde",
      "Katrin Kirchhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08718"
  },
  {
    "id": "arXiv:2112.09127",
    "title": "ICON: Implicit Clothed humans Obtained from Normals",
    "abstract": "Comments: Project page: this https URL Accepted by CVPR 2022",
    "descriptor": "\nComments: Project page: this https URL Accepted by CVPR 2022\n",
    "authors": [
      "Yuliang Xiu",
      "Jinlong Yang",
      "Dimitrios Tzionas",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.09127"
  },
  {
    "id": "arXiv:2112.09687",
    "title": "Light Field Neural Rendering",
    "abstract": "Comments: Project page with code and videos at this https URL",
    "descriptor": "\nComments: Project page with code and videos at this https URL\n",
    "authors": [
      "Mohammed Suhail",
      "Carlos Esteves",
      "Leonid Sigal",
      "Ameesh Makadia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09687"
  },
  {
    "id": "arXiv:2112.10703",
    "title": "Mega-NeRF: Scalable Construction of Large-Scale NeRFs for Virtual  Fly-Throughs",
    "abstract": "Comments: CVPR 2022 Project page: this https URL GitHub: this https URL",
    "descriptor": "\nComments: CVPR 2022 Project page: this https URL GitHub: this https URL\n",
    "authors": [
      "Haithem Turki",
      "Deva Ramanan",
      "Mahadev Satyanarayanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.10703"
  },
  {
    "id": "arXiv:2112.11989",
    "title": "FedLGA: Towards System-Heterogeneity of Federated Learning via Local  Gradient Approximation",
    "abstract": "FedLGA: Towards System-Heterogeneity of Federated Learning via Local  Gradient Approximation",
    "descriptor": "",
    "authors": [
      "Xingyu Li",
      "Zhe Qu",
      "Bo Tang",
      "Zhuo Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.11989"
  },
  {
    "id": "arXiv:2112.12785",
    "title": "NinjaDesc: Content-Concealing Visual Descriptors via Adversarial  Learning",
    "abstract": "Comments: Accepted at CVPR 2022. Supplementary material included after references. 15 pages, 14 figures, 6 tables",
    "descriptor": "\nComments: Accepted at CVPR 2022. Supplementary material included after references. 15 pages, 14 figures, 6 tables\n",
    "authors": [
      "Tony Ng",
      "Hyo Jin Kim",
      "Vincent Lee",
      "Daniel DeTone",
      "Tsun-Yi Yang",
      "Tianwei Shen",
      "Eddy Ilg",
      "Vassileios Balntas",
      "Krystian Mikolajczyk",
      "Chris Sweeney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12785"
  },
  {
    "id": "arXiv:2112.13941",
    "title": "Safe Reinforcement Learning with Chance-constrained Model Predictive  Control",
    "abstract": "Comments: 4th Annual Conference on Learning for Dynamics and Control",
    "descriptor": "\nComments: 4th Annual Conference on Learning for Dynamics and Control\n",
    "authors": [
      "Samuel Pfrommer",
      "Tanmay Gautam",
      "Alec Zhou",
      "Somayeh Sojoudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.13941"
  },
  {
    "id": "arXiv:2112.14005",
    "title": "Towards Relatable Explainable AI with the Perceptual Process",
    "abstract": "Comments: 14 pages, 7 figures, 4 tables, accepted by chi2022",
    "descriptor": "\nComments: 14 pages, 7 figures, 4 tables, accepted by chi2022\n",
    "authors": [
      "Wencan Zhang",
      "Brian Y. Lim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.14005"
  },
  {
    "id": "arXiv:2112.14317",
    "title": "Quantum Merkle Trees",
    "abstract": "Quantum Merkle Trees",
    "descriptor": "",
    "authors": [
      "Lijie Chen",
      "Ramis Movassagh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.14317"
  },
  {
    "id": "arXiv:2112.14598",
    "title": "Distance-Aware Precoding for Near-Field Capacity Improvement",
    "abstract": "Comments: 12 pages, twocolumn, 9 figures. The simulation codes will be provided at: this http URL",
    "descriptor": "\nComments: 12 pages, twocolumn, 9 figures. The simulation codes will be provided at: this http URL\n",
    "authors": [
      "Zidong Wu",
      "Mingyao Cui",
      "Zijian Zhang",
      "Linglong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.14598"
  },
  {
    "id": "arXiv:2112.14793",
    "title": "A sampling-based approach for efficient clustering in large datasets",
    "abstract": "Comments: 10 pages, 5 figures, 1 table, an open source implementation of the algorithm is provided in the this https URL",
    "descriptor": "\nComments: 10 pages, 5 figures, 1 table, an open source implementation of the algorithm is provided in the this https URL\n",
    "authors": [
      "Georgios Exarchakis",
      "Omar Oubari",
      "Gregor Lenz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.14793"
  },
  {
    "id": "arXiv:2112.15370",
    "title": "Subresultant of several univariate polynomials",
    "abstract": "Subresultant of several univariate polynomials",
    "descriptor": "",
    "authors": [
      "Hoon Hong",
      "Jing Yang"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Commutative Algebra (math.AC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2112.15370"
  },
  {
    "id": "arXiv:2201.00667",
    "title": "Sketch-and-project methods for tensor linear systems",
    "abstract": "Sketch-and-project methods for tensor linear systems",
    "descriptor": "",
    "authors": [
      "Ling Tang",
      "Yajie Yu",
      "Yanjun Zhang",
      "Hanyu Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.00667"
  },
  {
    "id": "arXiv:2201.02074",
    "title": "EM-driven unsupervised learning for efficient motion segmentation",
    "abstract": "EM-driven unsupervised learning for efficient motion segmentation",
    "descriptor": "",
    "authors": [
      "Etienne Meunier",
      "Ana\u00efs Badoual",
      "Patrick Bouthemy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.02074"
  },
  {
    "id": "arXiv:2201.02110",
    "title": "Eye Know You Too: A DenseNet Architecture for End-to-end Eye Movement  Biometrics",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Dillon Lohr",
      "Oleg V Komogortsev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.02110"
  },
  {
    "id": "arXiv:2201.03943",
    "title": "Neural Architecture Search For LF-MMI Trained Time Delay Neural Networks",
    "abstract": "Comments: Accepted by IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP). arXiv admin note: text overlap with arXiv:2007.08818",
    "descriptor": "\nComments: Accepted by IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP). arXiv admin note: text overlap with arXiv:2007.08818\n",
    "authors": [
      "Shoukang Hu",
      "Xurong Xie",
      "Mingyu Cui",
      "Jiajun Deng",
      "Shansong Liu",
      "Jianwei Yu",
      "Mengzhe Geng",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2201.03943"
  },
  {
    "id": "arXiv:2201.05023",
    "title": "Stereo Magnification with Multi-Layer Images",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Taras Khakhulin",
      "Denis Korzhenkov",
      "Pavel Solovev",
      "Gleb Sterkin",
      "Timotei Ardelean",
      "Victor Lempitsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2201.05023"
  },
  {
    "id": "arXiv:2201.05346",
    "title": "Saliency Constrained Arbitrary Image Style Transfer using SIFT and DCNN",
    "abstract": "Comments: There was an error in Eq.4. And in section Results and Comparison, the all results which genetraed by the proposed method are wrong",
    "descriptor": "\nComments: There was an error in Eq.4. And in section Results and Comparison, the all results which genetraed by the proposed method are wrong\n",
    "authors": [
      "HuiHuang Zhao",
      "Yaonan Wang",
      "Yuhua Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05346"
  },
  {
    "id": "arXiv:2201.05905",
    "title": "SS-3DCapsNet: Self-supervised 3D Capsule Networks for Medical  Segmentation on Less Labeled Data",
    "abstract": "Comments: Accepted to ISBI 2022",
    "descriptor": "\nComments: Accepted to ISBI 2022\n",
    "authors": [
      "Minh Tran",
      "Loi Ly",
      "Binh-Son Hua",
      "Ngan Le"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05905"
  },
  {
    "id": "arXiv:2201.06147",
    "title": "Data augmentation through multivariate scenario forecasting in Data  Centers using Generative Adversarial Networks",
    "abstract": "Data augmentation through multivariate scenario forecasting in Data  Centers using Generative Adversarial Networks",
    "descriptor": "",
    "authors": [
      "Jaime P\u00e9rez",
      "Patricia Arroba",
      "Jos\u00e9 M. Moya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.06147"
  },
  {
    "id": "arXiv:2201.06346",
    "title": "Can We Find Neurons that Cause Unrealistic Images in Deep Generative  Networks?",
    "abstract": "Can We Find Neurons that Cause Unrealistic Images in Deep Generative  Networks?",
    "descriptor": "",
    "authors": [
      "Hwanil Choi",
      "Wonjoon Chang",
      "Jaesik Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.06346"
  },
  {
    "id": "arXiv:2201.09032",
    "title": "NAS-VAD: Neural Architecture Search for Voice Activity Detection",
    "abstract": "Comments: Submitted to Interspeech 2022",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Daniel Rho",
      "Jinhyeok Park",
      "Jong Hwan Ko"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.09032"
  },
  {
    "id": "arXiv:2201.09366",
    "title": "Optimal transport for causal discovery",
    "abstract": "Optimal transport for causal discovery",
    "descriptor": "",
    "authors": [
      "Ruibo Tu",
      "Kun Zhang",
      "Hedvig Kjellstr\u00f6m",
      "Cheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2201.09366"
  },
  {
    "id": "arXiv:2201.10326",
    "title": "ShapeFormer: Transformer-based Shape Completion via Sparse  Representation",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Xingguang Yan",
      "Liqiang Lin",
      "Niloy J. Mitra",
      "Dani Lischinski",
      "Daniel Cohen-Or",
      "Hui Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10326"
  },
  {
    "id": "arXiv:2201.12183",
    "title": "Signaling in Posted Price Auctions",
    "abstract": "Signaling in Posted Price Auctions",
    "descriptor": "",
    "authors": [
      "Matteo Castiglioni",
      "Giulia Romano",
      "Alberto Marchesi",
      "Nicola Gatti"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.12183"
  },
  {
    "id": "arXiv:2202.00450",
    "title": "Approximation of Images via Generalized Higher Order Singular Value  Decomposition over Finite-dimensional Commutative Semisimple Algebra",
    "abstract": "Comments: 20 pages, several typos corrected, one appendix added",
    "descriptor": "\nComments: 20 pages, several typos corrected, one appendix added\n",
    "authors": [
      "Liang Liao",
      "Sen Lin",
      "Lun Li",
      "Xiuwei Zhang",
      "Song Zhao",
      "Yan Wang",
      "Xinqiang Wang",
      "Qi Gao",
      "Jingyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)",
      "Representation Theory (math.RT)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00450"
  },
  {
    "id": "arXiv:2202.00660",
    "title": "Interactron: Embodied Adaptive Object Detection",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Klemen Kotar",
      "Roozbeh Mottaghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00660"
  },
  {
    "id": "arXiv:2202.01279",
    "title": "PromptSource: An Integrated Development Environment and Repository for  Natural Language Prompts",
    "abstract": "Comments: ACL 2022 Demo",
    "descriptor": "\nComments: ACL 2022 Demo\n",
    "authors": [
      "Stephen H. Bach",
      "Victor Sanh",
      "Zheng-Xin Yong",
      "Albert Webson",
      "Colin Raffel",
      "Nihal V. Nayak",
      "Abheesht Sharma",
      "Taewoon Kim",
      "M Saiful Bari",
      "Thibault Fevry",
      "Zaid Alyafeai",
      "Manan Dey",
      "Andrea Santilli",
      "Zhiqing Sun",
      "Srulik Ben-David",
      "Canwen Xu",
      "Gunjan Chhablani",
      "Han Wang",
      "Jason Alan Fries",
      "Maged S. Al-shaibani",
      "Shanya Sharma",
      "Urmish Thakker",
      "Khalid Almubarak",
      "Xiangru Tang",
      "Dragomir Radev",
      "Mike Tian-Jian Jiang",
      "Alexander M. Rush"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.01279"
  },
  {
    "id": "arXiv:2202.01808",
    "title": "Hacking the Colony: On the Disruptive Effect of Misleading Pheromone and  How to Defend Against It",
    "abstract": "Comments: 8 pages, accepted at AAMAS2022, best paper award",
    "descriptor": "\nComments: 8 pages, accepted at AAMAS2022, best paper award\n",
    "authors": [
      "Ashay Aswale",
      "Antonio Lopez",
      "Aukkawut Ammartayakun",
      "Carlo Pinciroli"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.01808"
  },
  {
    "id": "arXiv:2202.01850",
    "title": "A Robust Phased Elimination Algorithm for Corruption-Tolerant Gaussian  Process Bandits",
    "abstract": "Comments: Added references",
    "descriptor": "\nComments: Added references\n",
    "authors": [
      "Ilija Bogunovic",
      "Zihan Li",
      "Andreas Krause",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01850"
  },
  {
    "id": "arXiv:2202.03800",
    "title": "Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the  Structure Space",
    "abstract": "Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the  Structure Space",
    "descriptor": "",
    "authors": [
      "Yaohua Wang",
      "Yaobin Zhang",
      "Fangyi Zhang",
      "Ming Lin",
      "YuQi Zhang",
      "Senzhang Wang",
      "Xiuyu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03800"
  },
  {
    "id": "arXiv:2202.04774",
    "title": "SHAS: Approaching optimal Segmentation for End-to-End Speech Translation",
    "abstract": "Comments: Submitted to Interspeech 2022, 5 pages. Previous version (v1) has additionally a 2-page Appendix",
    "descriptor": "\nComments: Submitted to Interspeech 2022, 5 pages. Previous version (v1) has additionally a 2-page Appendix\n",
    "authors": [
      "Ioannis Tsiamas",
      "Gerard I. G\u00e1llego",
      "Jos\u00e9 A. R. Fonollosa",
      "Marta R. Costa-juss\u00e0"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04774"
  },
  {
    "id": "arXiv:2202.06546",
    "title": "Coalgebraic Semantics for Nominal Automata",
    "abstract": "Coalgebraic Semantics for Nominal Automata",
    "descriptor": "",
    "authors": [
      "Florian Frank",
      "Stefan Milius",
      "Henning Urbat"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.06546"
  },
  {
    "id": "arXiv:2202.07016",
    "title": "Discrete Adjoint Momentum-Weighted Interpolation Strategies",
    "abstract": "Comments: Corrected typo in Eqn. (4)",
    "descriptor": "\nComments: Corrected typo in Eqn. (4)\n",
    "authors": [
      "Niklas K\u00fchl",
      "Thomas Rung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.07016"
  },
  {
    "id": "arXiv:2202.08703",
    "title": "Robust Frequency Constrained UC Using Data Driven Logistic Regression  for Island Power Systems",
    "abstract": "Robust Frequency Constrained UC Using Data Driven Logistic Regression  for Island Power Systems",
    "descriptor": "",
    "authors": [
      "Mohammad Rajabdorri",
      "Enrique Lobato",
      "Lukas Sigrist"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08703"
  },
  {
    "id": "arXiv:2202.10645",
    "title": "Combining the Silhouette and Skeleton Data for Gait Recognition",
    "abstract": "Comments: The paper is under consideration at Computer Vision and Image Understanding",
    "descriptor": "\nComments: The paper is under consideration at Computer Vision and Image Understanding\n",
    "authors": [
      "Likai Wang",
      "Ruize Han",
      "Jinyan Chen",
      "Wei Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.10645"
  },
  {
    "id": "arXiv:2202.11124",
    "title": "Learning with Free Object Segments for Long-Tailed Instance Segmentation",
    "abstract": "Learning with Free Object Segments for Long-Tailed Instance Segmentation",
    "descriptor": "",
    "authors": [
      "Cheng Zhang",
      "Tai-Yu Pan",
      "Tianle Chen",
      "Jike Zhong",
      "Wenjin Fu",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11124"
  },
  {
    "id": "arXiv:2202.11426",
    "title": "Open5x: Accessible 5-axis 3D printing and conformal slicing",
    "abstract": "Comments: 6 pages, 7 Figures, Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems",
    "descriptor": "\nComments: 6 pages, 7 Figures, Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems\n",
    "authors": [
      "Freddie Hong",
      "Steve Hodges",
      "Connor Myant",
      "David Boyle"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.11426"
  },
  {
    "id": "arXiv:2202.11783",
    "title": "Adversarially-regularized mixed effects deep learning (ARMED) models for  improved interpretability, performance, and generalization on clustered data",
    "abstract": "Comments: Reformatted and made minor text edits. Results are unchanged. 13 pages, 6 figures, 5 tables",
    "descriptor": "\nComments: Reformatted and made minor text edits. Results are unchanged. 13 pages, 6 figures, 5 tables\n",
    "authors": [
      "Kevin P. Nguyen",
      "Albert Montillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.11783"
  },
  {
    "id": "arXiv:2202.12513",
    "title": "TeachAugment: Data Augmentation Optimization Using Teacher Knowledge",
    "abstract": "Comments: To appear in CVPR2022 (Oral presentation) Code: this https URL",
    "descriptor": "\nComments: To appear in CVPR2022 (Oral presentation) Code: this https URL\n",
    "authors": [
      "Teppei Suzuki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12513"
  },
  {
    "id": "arXiv:2202.13560",
    "title": "ConvNeXt-backbone HoVerNet for nuclei segmentation and classification",
    "abstract": "ConvNeXt-backbone HoVerNet for nuclei segmentation and classification",
    "descriptor": "",
    "authors": [
      "Jiachen Li",
      "Chixin Wang",
      "Banban Huang",
      "Zekun Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.13560"
  },
  {
    "id": "arXiv:2202.13925",
    "title": "Bonsai: A Generalized Look at Dual Deduplication",
    "abstract": "Bonsai: A Generalized Look at Dual Deduplication",
    "descriptor": "",
    "authors": [
      "Hadi Sehat",
      "Anders Lindskov Kloborg",
      "Christian M\u00f8rup",
      "Elena Pagnin",
      "Daniel E. Lucani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.13925"
  },
  {
    "id": "arXiv:2203.00838",
    "title": "OmniFusion: 360 Monocular Depth Estimation via Geometry-Aware Fusion",
    "abstract": "Comments: CVPR 2022, accepted as Oral",
    "descriptor": "\nComments: CVPR 2022, accepted as Oral\n",
    "authors": [
      "Yuyan Li",
      "Yuliang Guo",
      "Zhixin Yan",
      "Xinyu Huang",
      "Ye Duan",
      "Liu Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.00838"
  },
  {
    "id": "arXiv:2203.01305",
    "title": "DN-DETR: Accelerate DETR Training by Introducing Query DeNoising",
    "abstract": "Comments: To appear in CVPR 2022",
    "descriptor": "\nComments: To appear in CVPR 2022\n",
    "authors": [
      "Feng Li",
      "Hao Zhang",
      "Shilong Liu",
      "Jian Guo",
      "Lionel M. Ni",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.01305"
  },
  {
    "id": "arXiv:2203.01522",
    "title": "BatchFormer: Learning to Explore Sample Relationships for Robust  Representation Learning",
    "abstract": "Comments: Camera Ready, CVPR2022",
    "descriptor": "\nComments: Camera Ready, CVPR2022\n",
    "authors": [
      "Zhi Hou",
      "Baosheng Yu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01522"
  },
  {
    "id": "arXiv:2203.01577",
    "title": "HOI4D: A 4D Egocentric Dataset for Category-Level Human-Object  Interaction",
    "abstract": "HOI4D: A 4D Egocentric Dataset for Category-Level Human-Object  Interaction",
    "descriptor": "",
    "authors": [
      "Yunze Liu",
      "Yun Liu",
      "Che Jiang",
      "Kangbo Lyu",
      "Weikang Wan",
      "Hao Shen",
      "Boqiang Liang",
      "Zhoujie Fu",
      "He Wang",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01577"
  },
  {
    "id": "arXiv:2203.02574",
    "title": "Style-ERD: Responsive and Coherent Online Motion Style Transfer",
    "abstract": "Comments: CVPR 2022, project page: this https URL",
    "descriptor": "\nComments: CVPR 2022, project page: this https URL\n",
    "authors": [
      "Tianxin Tao",
      "Xiaohang Zhan",
      "Zhongquan Chen",
      "Michiel van de Panne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.02574"
  },
  {
    "id": "arXiv:2203.03605",
    "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object  Detection",
    "abstract": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object  Detection",
    "descriptor": "",
    "authors": [
      "Hao Zhang",
      "Feng Li",
      "Shilong Liu",
      "Lei Zhang",
      "Hang Su",
      "Jun Zhu",
      "Lionel M. Ni",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03605"
  },
  {
    "id": "arXiv:2203.03609",
    "title": "Human-Aware Object Placement for Visual Environment Reconstruction",
    "abstract": "Comments: Accepted by CVPR2022",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Hongwei Yi",
      "Chun-Hao P. Huang",
      "Dimitrios Tzionas",
      "Muhammed Kocabas",
      "Mohamed Hassan",
      "Siyu Tang",
      "Justus Thies",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.03609"
  },
  {
    "id": "arXiv:2203.03831",
    "title": "Deep Rectangling for Image Stitching: A Learning Baseline",
    "abstract": "Comments: Accepted by CVPR2022 (oral); Codes and dataset: this https URL",
    "descriptor": "\nComments: Accepted by CVPR2022 (oral); Codes and dataset: this https URL\n",
    "authors": [
      "Lang Nie",
      "Chunyu Lin",
      "Kang Liao",
      "Shuaicheng Liu",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03831"
  },
  {
    "id": "arXiv:2203.04234",
    "title": "Adaptative Perturbation Patterns: Realistic Adversarial Learning for  Robust Intrusion Detection",
    "abstract": "Comments: 18 pages, 6 tables, 10 figures, Future Internet journal",
    "descriptor": "\nComments: 18 pages, 6 tables, 10 figures, Future Internet journal\n",
    "authors": [
      "Jo\u00e3o Vitorino",
      "Nuno Oliveira",
      "Isabel Pra\u00e7a"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.04234"
  },
  {
    "id": "arXiv:2203.04554",
    "title": "ChiTransformer:Towards Reliable Stereo from Cues",
    "abstract": "Comments: 11 pages, 3 figures, CVPR2022",
    "descriptor": "\nComments: 11 pages, 3 figures, CVPR2022\n",
    "authors": [
      "Qing Su",
      "Shihao Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04554"
  },
  {
    "id": "arXiv:2203.05074",
    "title": "The Transitive Information Theory and its Application to Deep Generative  Models",
    "abstract": "The Transitive Information Theory and its Application to Deep Generative  Models",
    "descriptor": "",
    "authors": [
      "Trung Ngo",
      "Najwa Laabid",
      "Ville Hautam\u00e4ki",
      "Merja Hein\u00e4niemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05074"
  },
  {
    "id": "arXiv:2203.06718",
    "title": "Local Hadwiger's Conjecture",
    "abstract": "Comments: 24 pages; some minor typos have been fixed",
    "descriptor": "\nComments: 24 pages; some minor typos have been fixed\n",
    "authors": [
      "Benjamin Moore",
      "Luke Postle",
      "Lise Turner"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.06718"
  },
  {
    "id": "arXiv:2203.06995",
    "title": "The many facets of academic mobility and its impact on scholars' career",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Fakhri Momeni",
      "Fariba Karimi",
      "Philipp Mayr",
      "Isabella Peters",
      "Stefan Dietze"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2203.06995"
  },
  {
    "id": "arXiv:2203.07615",
    "title": "Learning What Not to Segment: A New Perspective on Few-Shot Segmentation",
    "abstract": "Comments: Accepted to CVPR 2022 Oral",
    "descriptor": "\nComments: Accepted to CVPR 2022 Oral\n",
    "authors": [
      "Chunbo Lang",
      "Gong Cheng",
      "Binfei Tu",
      "Junwei Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07615"
  },
  {
    "id": "arXiv:2203.08080",
    "title": "Implicit Feature Decoupling with Depthwise Quantization",
    "abstract": "Comments: to be published in CVPR-2022",
    "descriptor": "\nComments: to be published in CVPR-2022\n",
    "authors": [
      "Iordanis Fostiropoulos",
      "Barry Boehm"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08080"
  },
  {
    "id": "arXiv:2203.08207",
    "title": "SocialVAE: Human Trajectory Prediction using Timewise Latents",
    "abstract": "SocialVAE: Human Trajectory Prediction using Timewise Latents",
    "descriptor": "",
    "authors": [
      "Pei Xu",
      "Jean-Bernard Hayet",
      "Ioannis Karamouzas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08207"
  },
  {
    "id": "arXiv:2203.08488",
    "title": "Pushing the limits of raw waveform speaker recognition",
    "abstract": "Comments: submitted to INTERSPEECH 2022 as a conference paper. 5 pages, 2 figures, 5 tables",
    "descriptor": "\nComments: submitted to INTERSPEECH 2022 as a conference paper. 5 pages, 2 figures, 5 tables\n",
    "authors": [
      "Jee-weon Jung",
      "You Jin Kim",
      "Hee-Soo Heo",
      "Bong-Jin Lee",
      "Youngki Kwon",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08488"
  },
  {
    "id": "arXiv:2203.08667",
    "title": "Graph Flow: Cross-layer Graph Flow Distillation for Dual Efficient  Medical Image Segmentation",
    "abstract": "Graph Flow: Cross-layer Graph Flow Distillation for Dual Efficient  Medical Image Segmentation",
    "descriptor": "",
    "authors": [
      "Wenxuan Zou",
      "Muyi Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08667"
  },
  {
    "id": "arXiv:2203.08685",
    "title": "A Feasibility Study of Answer-Agnostic Question Generation for Education",
    "abstract": "Comments: To be published in 60th Annual Meeting of the Association for Computational Linguistics (ACL 2022)",
    "descriptor": "\nComments: To be published in 60th Annual Meeting of the Association for Computational Linguistics (ACL 2022)\n",
    "authors": [
      "Liam Dugan",
      "Eleni Miltsakaki",
      "Shriyash Upadhyay",
      "Etan Ginsberg",
      "Hannah Gonzalez",
      "Dayheon Choi",
      "Chuning Yuan",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.08685"
  },
  {
    "id": "arXiv:2203.08937",
    "title": "Backpropagation through Time and Space: Learning Numerical Methods with  Multi-Agent Reinforcement Learning",
    "abstract": "Backpropagation through Time and Space: Learning Numerical Methods with  Multi-Agent Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Elliot Way",
      "Dheeraj S.K. Kapilavai",
      "Yiwei Fu",
      "Lei Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.08937"
  },
  {
    "id": "arXiv:2203.09116",
    "title": "MotionAug: Augmentation with Physical Correction for Human Motion  Prediction",
    "abstract": "Comments: Accepted at CVPR2022",
    "descriptor": "\nComments: Accepted at CVPR2022\n",
    "authors": [
      "Takahiro Maeda",
      "Norimichi Ukita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09116"
  },
  {
    "id": "arXiv:2203.09324",
    "title": "Localizing Visual Sounds the Easy Way",
    "abstract": "Localizing Visual Sounds the Easy Way",
    "descriptor": "",
    "authors": [
      "Shentong Mo",
      "Pedro Morgado"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.09324"
  },
  {
    "id": "arXiv:2203.09658",
    "title": "Lupa: A Framework for Large Scale Analysis of the Programming Language  Usage",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Anna Vlasova",
      "Maria Tigina",
      "Ilya Vlasov",
      "Anastasiia Birillo",
      "Yaroslav Golubev",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.09658"
  },
  {
    "id": "arXiv:2203.10133",
    "title": "Probing Factually Grounded Content Transfer with Factual Ablation",
    "abstract": "Probing Factually Grounded Content Transfer with Factual Ablation",
    "descriptor": "",
    "authors": [
      "Peter West",
      "Chris Quirk",
      "Michel Galley",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.10133"
  },
  {
    "id": "arXiv:2203.10289",
    "title": "METL: a modern ETL pipeline with a dynamic mapping matrix",
    "abstract": "Comments: version 4: improved presentation throughout the paper, improved explanation of the two different compacting strategies",
    "descriptor": "\nComments: version 4: improved presentation throughout the paper, improved explanation of the two different compacting strategies\n",
    "authors": [
      "Christian Haase",
      "Timo R\u00f6seler",
      "Mattias Seidel"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.10289"
  },
  {
    "id": "arXiv:2203.10618",
    "title": "Interval Dominance based Structural Results for Markov Decision Process",
    "abstract": "Interval Dominance based Structural Results for Markov Decision Process",
    "descriptor": "",
    "authors": [
      "Vikram Krishnamurthy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.10618"
  },
  {
    "id": "arXiv:2203.10627",
    "title": "Enriching Unsupervised User Embedding via Medical Concepts",
    "abstract": "Comments: accepted at ACM CHIL 2022. a revision for section reformat",
    "descriptor": "\nComments: accepted at ACM CHIL 2022. a revision for section reformat\n",
    "authors": [
      "Xiaolei Huang",
      "Franck Dernoncourt",
      "Mark Dredze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.10627"
  },
  {
    "id": "arXiv:2203.10637",
    "title": "Vocal effort modeling in neural TTS for improving the intelligibility of  synthetic speech in noise",
    "abstract": "Comments: 5 pages, 5 figures. Submitted to Interspeech 2022, revision includes more data in results and improved text",
    "descriptor": "\nComments: 5 pages, 5 figures. Submitted to Interspeech 2022, revision includes more data in results and improved text\n",
    "authors": [
      "Tuomo Raitio",
      "Petko Petkov",
      "Jiangchuan Li",
      "Muhammed Shifas",
      "Andrea Davis",
      "Yannis Stylianou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.10637"
  },
  {
    "id": "arXiv:2203.10886",
    "title": "ELIC: Efficient Learned Image Compression with Unevenly Grouped  Space-Channel Contextual Adaptive Coding",
    "abstract": "Comments: accepted by CVPR 2022 (oral)",
    "descriptor": "\nComments: accepted by CVPR 2022 (oral)\n",
    "authors": [
      "Dailan He",
      "Ziming Yang",
      "Weikun Peng",
      "Rui Ma",
      "Hongwei Qin",
      "Yan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.10886"
  },
  {
    "id": "arXiv:2203.11082",
    "title": "MixFormer: End-to-End Tracking with Iterative Mixed Attention",
    "abstract": "Comments: Accepted to CVPR2022 (Oral)",
    "descriptor": "\nComments: Accepted to CVPR2022 (Oral)\n",
    "authors": [
      "Yutao Cui",
      "Cheng Jiang",
      "Limin Wang",
      "Gangshan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11082"
  },
  {
    "id": "arXiv:2203.11480",
    "title": "WuDaoMM: A large-scale Multi-Modal Dataset for Pre-training models",
    "abstract": "Comments: 7 pages, 2 tables, 3 figures",
    "descriptor": "\nComments: 7 pages, 2 tables, 3 figures\n",
    "authors": [
      "Sha Yuan",
      "Shuai Zhao",
      "Jiahong Leng",
      "Zhao Xue",
      "Hanyu Zhao",
      "Peiyu Liu",
      "Zheng Gong",
      "Wayne Xin Zhao",
      "Junyi Li",
      "Jie Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11480"
  },
  {
    "id": "arXiv:2203.11481",
    "title": "Mixed Differential Privacy in Computer Vision",
    "abstract": "Comments: Accepted at CVPR 2022",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Aditya Golatkar",
      "Alessandro Achille",
      "Yu-Xiang Wang",
      "Aaron Roth",
      "Michael Kearns",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.11481"
  },
  {
    "id": "arXiv:2203.11804",
    "title": "Information-Theoretic Approaches to Differential Privacy",
    "abstract": "Information-Theoretic Approaches to Differential Privacy",
    "descriptor": "",
    "authors": [
      "Ayse Unsal",
      "Melek Onen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.11804"
  },
  {
    "id": "arXiv:2203.12082",
    "title": "PlaneMVS: 3D Plane Reconstruction from Multi-View Stereo",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Jiachen Liu",
      "Pan Ji",
      "Nitin Bansal",
      "Changjiang Cai",
      "Qingan Yan",
      "Xiaolei Huang",
      "Yi Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12082"
  },
  {
    "id": "arXiv:2203.12338",
    "title": "Real-time Object Detection for Streaming Perception",
    "abstract": "Comments: CVPR 2022 Accepted Paper (Oral)",
    "descriptor": "\nComments: CVPR 2022 Accepted Paper (Oral)\n",
    "authors": [
      "Jinrong Yang",
      "Songtao Liu",
      "Zeming Li",
      "Xiaoping Li",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12338"
  },
  {
    "id": "arXiv:2203.12369",
    "title": "MetricGAN+/-: Increasing Robustness of Noise Reduction on Unseen Data",
    "abstract": "Comments: 5 pages, 4 figures, Submitted to EUSIPCO 2022",
    "descriptor": "\nComments: 5 pages, 4 figures, Submitted to EUSIPCO 2022\n",
    "authors": [
      "George Close",
      "Thomas Hain",
      "Stefan Goetze"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.12369"
  },
  {
    "id": "arXiv:2203.12386",
    "title": "Modules in Robinson Spaces",
    "abstract": "Modules in Robinson Spaces",
    "descriptor": "",
    "authors": [
      "Mikhael Carmona",
      "Victor Chepoi",
      "Guyslain Naves",
      "Pascal Pr\u00e9a"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.12386"
  },
  {
    "id": "arXiv:2203.12485",
    "title": "CroMo: Cross-Modal Learning for Monocular Depth Estimation",
    "abstract": "Comments: Accepted for publication at CVPR2022",
    "descriptor": "\nComments: Accepted for publication at CVPR2022\n",
    "authors": [
      "Yannick Verdi\u00e9",
      "Jifei Song",
      "Barnab\u00e9 Mas",
      "Benjamin Busam",
      "Ale\u0161 Leonardis",
      "Steven McDonagh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12485"
  },
  {
    "id": "arXiv:2203.12667",
    "title": "Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future  Directions",
    "abstract": "Comments: 19 pages. Accepted to ACL 2022",
    "descriptor": "\nComments: 19 pages. Accepted to ACL 2022\n",
    "authors": [
      "Jing Gu",
      "Eliana Stefani",
      "Qi Wu",
      "Jesse Thomason",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.12667"
  },
  {
    "id": "arXiv:2203.12668",
    "title": "Pseudo Label Is Better Than Human Label",
    "abstract": "Comments: 6 pages, 2 figures, 9 tables, submitted to INTERSPEECH",
    "descriptor": "\nComments: 6 pages, 2 figures, 9 tables, submitted to INTERSPEECH\n",
    "authors": [
      "Dongseong Hwang",
      "Khe Chai Sim",
      "Zhouyuan Huo",
      "Trevor Strohman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.12668"
  },
  {
    "id": "arXiv:2203.12691",
    "title": "Learning to generate line drawings that convey geometry and semantics",
    "abstract": "Comments: Corrected and added references",
    "descriptor": "\nComments: Corrected and added references\n",
    "authors": [
      "Caroline Chan",
      "Fredo Durand",
      "Phillip Isola"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.12691"
  },
  {
    "id": "arXiv:2203.12707",
    "title": "Maximum Spatial Perturbation Consistency for Unpaired Image-to-Image  Translation",
    "abstract": "Comments: CVPR 2022 accepted paper",
    "descriptor": "\nComments: CVPR 2022 accepted paper\n",
    "authors": [
      "Yanwu Xu",
      "Shaoan Xie",
      "Wenhao Wu",
      "Kun Zhang",
      "Mingming Gong",
      "Kayhan Batmanghelich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.12707"
  },
  {
    "id": "arXiv:2203.12818",
    "title": "Random Forest Regression for continuous affect using Facial Action Units",
    "abstract": "Random Forest Regression for continuous affect using Facial Action Units",
    "descriptor": "",
    "authors": [
      "Saurabh Hinduja",
      "Shaun Canavan",
      "Liza Jivnani",
      "Sk Rahatul Jannat",
      "V Sri Chakra Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.12818"
  },
  {
    "id": "arXiv:2203.12845",
    "title": "Multiple Emotion Descriptors Estimation at the ABAW3 Challenge",
    "abstract": "Comments: The technical report for our multi-task approach in the ABAW3 Challenge",
    "descriptor": "\nComments: The technical report for our multi-task approach in the ABAW3 Challenge\n",
    "authors": [
      "Didan Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12845"
  },
  {
    "id": "arXiv:2203.12872",
    "title": "Intrinsic Bias Identification on Medical Image Datasets",
    "abstract": "Comments: 19pages, 12 figures",
    "descriptor": "\nComments: 19pages, 12 figures\n",
    "authors": [
      "Shijie Zhang",
      "Lanjun Wang",
      "Lian Ding",
      "An-an Liu",
      "Senhua Zhu",
      "Dandan Tu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12872"
  },
  {
    "id": "arXiv:2203.12961",
    "title": "Multilevel Bayesian Deep Neural Networks",
    "abstract": "Multilevel Bayesian Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Neil K. Chada",
      "Ajay Jasra",
      "Kody J. H. Law",
      "Sumeetpal S. Singh"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.12961"
  },
  {
    "id": "arXiv:2203.12980",
    "title": "MERLIN -- Malware Evasion with Reinforcement LearnINg",
    "abstract": "MERLIN -- Malware Evasion with Reinforcement LearnINg",
    "descriptor": "",
    "authors": [
      "Tony Quertier",
      "Benjamin Marais",
      "St\u00e9phane Morucci",
      "Bertrand Fournel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.12980"
  },
  {
    "id": "arXiv:2203.13005",
    "title": "GX-Plug: a Middleware for Plugging Accelerators to Distributed Graph  Processing",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Kai Zou",
      "Xike Xie",
      "Qi Li",
      "Deyu Kong"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.13005"
  },
  {
    "id": "arXiv:2203.13009",
    "title": "CVF-SID: Cyclic multi-Variate Function for Self-Supervised Image  Denoising by Disentangling Noise from Image",
    "abstract": "Comments: Published at CVPR 2022",
    "descriptor": "\nComments: Published at CVPR 2022\n",
    "authors": [
      "Reyhaneh Neshatavar",
      "Mohsen Yavartanoo",
      "Sanghyun Son",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13009"
  },
  {
    "id": "arXiv:2203.13254",
    "title": "EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for  Monocular Object Pose Estimation",
    "abstract": "Comments: CVPR 2022 Oral, code available at this https URL",
    "descriptor": "\nComments: CVPR 2022 Oral, code available at this https URL\n",
    "authors": [
      "Hansheng Chen",
      "Pichao Wang",
      "Fan Wang",
      "Wei Tian",
      "Lu Xiong",
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13254"
  },
  {
    "id": "arXiv:2203.13278",
    "title": "Practical Blind Denoising via Swin-Conv-UNet and Data Synthesis",
    "abstract": "Comments: Codes: this https URL",
    "descriptor": "\nComments: Codes: this https URL\n",
    "authors": [
      "Kai Zhang",
      "Yawei Li",
      "Jingyun Liang",
      "Jiezhang Cao",
      "Yulun Zhang",
      "Hao Tang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.13278"
  },
  {
    "id": "arXiv:2203.13285",
    "title": "Continuous-Time Audiovisual Fusion with Recurrence vs. Attention for  In-The-Wild Affect Recognition",
    "abstract": "Comments: 10 pages, 1 figures, added references and an overview figure",
    "descriptor": "\nComments: 10 pages, 1 figures, added references and an overview figure\n",
    "authors": [
      "Vincent Karas",
      "Mani Kumar Tellamekala",
      "Adria Mallol-Ragolta",
      "Michel Valstar",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13285"
  },
  {
    "id": "arXiv:2203.13510",
    "title": "Joint Distribution of Distance and Angles in Finite Wireless Networks",
    "abstract": "Comments: 14 pages, 14 figures",
    "descriptor": "\nComments: 14 pages, 14 figures\n",
    "authors": [
      "Francisco J. Mart\u00edn-Vega",
      "Gerardo G\u00f3mez",
      "David Morales-Jim\u00e9nez",
      "F. Javier L\u00f3pez-Mart\u00ednez",
      "Mari Carmen Aguayo-Torres"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.13510"
  },
  {
    "id": "arXiv:2203.13645",
    "title": "Audio-text Retrieval in Context",
    "abstract": "Audio-text Retrieval in Context",
    "descriptor": "",
    "authors": [
      "Siyu Lou",
      "Xuenan Xu",
      "Mengyue Wu",
      "Kai Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13645"
  },
  {
    "id": "arXiv:2203.13968",
    "title": "Tuning Particle Accelerators with Safety Constraints using Bayesian  Optimization",
    "abstract": "Tuning Particle Accelerators with Safety Constraints using Bayesian  Optimization",
    "descriptor": "",
    "authors": [
      "Johannes Kirschner",
      "Mojmir Mutn\u00fd",
      "Andreas Krause",
      "Jaime Coello de Portugal",
      "Nicole Hiller",
      "Jochem Snuverink"
    ],
    "subjectives": [
      "Accelerator Physics (physics.acc-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13968"
  },
  {
    "id": "arXiv:2203.14057",
    "title": "FaceVerse: a Fine-grained and Detail-controllable 3D Face Morphable  Model from a Hybrid Dataset",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Lizhen Wang",
      "Zhiyuan Chen",
      "Tao Yu",
      "Chenguang Ma",
      "Liang Li",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.14057"
  },
  {
    "id": "arXiv:2203.14093",
    "title": "MQDD: Pre-training of Multimodal Question Duplicity Detection for  Software Engineering Domain",
    "abstract": "MQDD: Pre-training of Multimodal Question Duplicity Detection for  Software Engineering Domain",
    "descriptor": "",
    "authors": [
      "Jan Pa\u0161ek",
      "Jakub Sido",
      "Miloslav Konop\u00edk",
      "Ond\u0159ej Pra\u017e\u00e1k"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.14093"
  },
  {
    "id": "arXiv:2203.14124",
    "title": "Feature Selective Transformer for Semantic Image Segmentation",
    "abstract": "Feature Selective Transformer for Semantic Image Segmentation",
    "descriptor": "",
    "authors": [
      "Fangjian Lin",
      "Tianyi Wu",
      "Sitong Wu",
      "Shengwei Tian",
      "Guodong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.14124"
  },
  {
    "id": "arXiv:2203.14143",
    "title": "The Mean Field Fokker-Planck Equation with Nonlinear No-flux Boundary  Conditions",
    "abstract": "Comments: The paper was withdrawn by the authors due to a critical error in the definition of the system of Langevin equations",
    "descriptor": "\nComments: The paper was withdrawn by the authors due to a critical error in the definition of the system of Langevin equations\n",
    "authors": [
      "R. D. Mills-Williams",
      "B. D. Goddard",
      "G. A. Pavliotis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.14143"
  },
  {
    "id": "arXiv:2203.14177",
    "title": "Benchmarking Deep AUROC Optimization: Loss Functions and Algorithmic  Choices",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Dixian Zhu",
      "Xiaodong Wu",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.14177"
  },
  {
    "id": "arXiv:2203.14240",
    "title": "Audio-Adaptive Activity Recognition Across Video Domains",
    "abstract": "Comments: Accepted at CVPR 2022",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Yunhua Zhang",
      "Hazel Doughty",
      "Ling Shao",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.14240"
  },
  {
    "id": "arXiv:2203.14331",
    "title": "SuperMVS: Non-Uniform Cost Volume For High-Resolution Multi-View Stereo",
    "abstract": "SuperMVS: Non-Uniform Cost Volume For High-Resolution Multi-View Stereo",
    "descriptor": "",
    "authors": [
      "Tao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.14331"
  },
  {
    "id": "arXiv:2203.14333",
    "title": "Locality-Aware Inter-and Intra-Video Reconstruction for Self-Supervised  Correspondence Learning",
    "abstract": "Comments: CVPR 2022. Code: this https URL",
    "descriptor": "\nComments: CVPR 2022. Code: this https URL\n",
    "authors": [
      "Liulei Li",
      "Tianfei Zhou",
      "Wenguan Wang",
      "Lu Yang",
      "Jianwu Li",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.14333"
  },
  {
    "id": "arXiv:2203.14335",
    "title": "Deep Hierarchical Semantic Segmentation",
    "abstract": "Comments: CVPR 2022. Code: this https URL",
    "descriptor": "\nComments: CVPR 2022. Code: this https URL\n",
    "authors": [
      "Liulei Li",
      "Tianfei Zhou",
      "Wenguan Wang",
      "Jianwu Li",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.14335"
  },
  {
    "id": "arXiv:2203.14341",
    "title": "MFSNet: A Multi Focus Segmentation Network for Skin Lesion Segmentation",
    "abstract": "MFSNet: A Multi Focus Segmentation Network for Skin Lesion Segmentation",
    "descriptor": "",
    "authors": [
      "Hritam Basak",
      "Rohit Kundu",
      "Ram Sarkar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.14341"
  },
  {
    "id": "arXiv:2203.14367",
    "title": "Thin-Plate Spline Motion Model for Image Animation",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Jian Zhao",
      "Hui Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.14367"
  },
  {
    "id": "arXiv:2203.14491",
    "title": "A nonlocal Stokes system with volume constraints",
    "abstract": "Comments: accepted for publication in Numerical Mathematics: Theory, Methods and Applications",
    "descriptor": "\nComments: accepted for publication in Numerical Mathematics: Theory, Methods and Applications\n",
    "authors": [
      "Qiang Du",
      "Zuoqiang Shi"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.14491"
  },
  {
    "id": "arXiv:2203.14493",
    "title": "ARCS: Accurate Rotation and Correspondence Search",
    "abstract": "Comments: Accepted in part to CVPR 2022",
    "descriptor": "\nComments: Accepted in part to CVPR 2022\n",
    "authors": [
      "Liangzu Peng",
      "Manolis C. Tsakiris",
      "Ren\u00e9 Vidal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.14493"
  },
  {
    "id": "arXiv:2203.14585",
    "title": "Interoperability in the IoT -- An Evaluation of the Semantic-Based  Approach",
    "abstract": "Comments: 9 pages, 8 figures, 4 tables",
    "descriptor": "\nComments: 9 pages, 8 figures, 4 tables\n",
    "authors": [
      "Kristina Sahlmann",
      "Florian Mikolajczak",
      "Bettina Schnor"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.14585"
  },
  {
    "id": "arXiv:2203.14597",
    "title": "New insights into four-boson renormalization group limit cycles",
    "abstract": "Comments: 26 pages, 5 figures",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Bastian Kaspschak",
      "Ulf-G. Mei\u00dfner"
    ],
    "subjectives": [
      "Nuclear Theory (nucl-th)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.14597"
  },
  {
    "id": "arXiv:2203.14636",
    "title": "A 3D Positioning-based Channel Estimation Method for RIS-aided mmWave  Communications",
    "abstract": "Comments: This paper needs further revision",
    "descriptor": "\nComments: This paper needs further revision\n",
    "authors": [
      "Yaoshen Cui",
      "Haifan Yin",
      "Li Tan",
      "Marco Di Renzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.14636"
  },
  {
    "id": "arXiv:2203.14711",
    "title": "Towards Formal Verification of HotStuff-based Byzantine Fault Tolerant  Consensus in Agda: Extended Version",
    "abstract": "Comments: 23 pages, 1 figure, extended version of version to be published in 14th NASA Formal Methods Symposium (NFM 2022)",
    "descriptor": "\nComments: 23 pages, 1 figure, extended version of version to be published in 14th NASA Formal Methods Symposium (NFM 2022)\n",
    "authors": [
      "Harold Carr",
      "Christopher Jenkins",
      "Mark Moir",
      "Victor Cacciari Miraldo",
      "Lisandra Silva"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.14711"
  },
  {
    "id": "arXiv:2203.14807",
    "title": "Who is next: rising star prediction via diffusion of user interest in  social networks",
    "abstract": "Comments: Accepted to TKDE 2022",
    "descriptor": "\nComments: Accepted to TKDE 2022\n",
    "authors": [
      "Xuan Yang",
      "Yang Yang",
      "Jintao Su",
      "Yifei Sun",
      "Shen Fan",
      "Zhongyao Wang",
      "Jun Zhang",
      "Jingmin Chen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.14807"
  },
  {
    "id": "arXiv:2203.14835",
    "title": "Multilingual Simultaneous Speech Translation",
    "abstract": "Comments: Submitted to Interspeech 2022",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Shashank Subramanya",
      "Jan Niehues"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.14835"
  }
]
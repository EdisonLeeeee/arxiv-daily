[
  {
    "id": "arXiv:2203.08801",
    "title": "Base-Rate Fallacy Redux and a Deep Dive Review in Cybersecurity",
    "abstract": "This paper examines the current state of the science underlying cybersecurity\nresearch with an emphasis on the non-signature-based intrusion detection\ndomain. First, the paper re-examines the base-rate fallacy originally published\nby Axelsson, putting the impact of false positives into context. Given the\nrelative high numbers of false positives, the paper argues for deeper analysis\nof false positives, akin to the analysis that true positives are treated to.\nThe second section of the paper examines the metrics being used to analyze\nnon-signature intrusion detection techniques, the current status quo of\nemployed metrics, and the impact of the status quo on scientific advancement.\nFinally, the paper analyzes the use of online attack graphs and their\napplicability, especially in scenarios of constrained environments, such as\nInternet of Things devices. The use of offline attack graphs in such\nconstrained environments is also examined. In essence, a deep dive review\nidentified multiple areas throughout the field in which the effectiveness and\nvalidity of the scientific method can be greatly improved, e.g., through\nremoval of logical fallacies.",
    "descriptor": "",
    "authors": [
      "Robert F. Erbacher"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08801"
  },
  {
    "id": "arXiv:2203.08808",
    "title": "Neural-Network-Directed Genetic Programmer for Discovery of Governing  Equations",
    "abstract": "We develop a symbolic regression framework for extracting the governing\nmathematical expressions from observed data. The evolutionary approach, faiGP,\nis designed to leverage the properties of a function algebra that have been\nencoded into a grammar, providing a theoretical guarantee of universal\napproximation and a way to minimize bloat. In this framework, the choice of\noperators of the grammar may be informed by a physical theory or symmetry\nconsiderations. Since there is currently no theory that can derive the\n'constants of nature', an empirical investigation on extracting these\ncoefficients from an evolutionary process is of methodological interest. We\nquantify the impact of different types of regularizers, including a diversity\nmetric adapted from studies of the transcriptome and a complexity measure, on\nthe performance of the framework. Our implementation, which leverages neural\nnetworks and a genetic programmer, generates non-trivial symbolically\nequivalent expressions (\"Ramanujan expressions\") or approximations with\npotentially interesting numerical applications. To illustrate the framework, a\nmodel of ligand-receptor binding kinetics, including an account of gene\nregulation by transcription factors, and a model of the regulatory range of the\ncistrome from omics data are presented. This study has important implications\non the development of data-driven methodologies for the discovery of governing\nequations in experimental data derived from new sensing systems and\nhigh-throughput screening technologies.",
    "descriptor": "",
    "authors": [
      "Shahab Razavi",
      "Eric R. Gamazon"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08808"
  },
  {
    "id": "arXiv:2203.08813",
    "title": "Example Perplexity",
    "abstract": "Some examples are easier for humans to classify than others. The same should\nbe true for deep neural networks (DNNs). We use the term example perplexity to\nrefer to the level of difficulty of classifying an example. In this paper, we\npropose a method to measure the perplexity of an example and investigate what\nfactors contribute to high example perplexity. The related codes and resources\nare available at https://github.com/vaynexie/Example-Perplexity.",
    "descriptor": "",
    "authors": [
      "Nevin L. Zhang",
      "Weiyan Xie",
      "Zhi Lin",
      "Guanfang Dong",
      "Xiao-Hui Li",
      "Caleb Chen Cao",
      "Yunpeng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08813"
  },
  {
    "id": "arXiv:2203.08815",
    "title": "QUBOs for Sorting Lists and Building Trees",
    "abstract": "We show that the fundamental tasks of sorting lists and building search trees\nor heaps can be modeled as quadratic unconstrained binary optimization problems\n(QUBOs). The idea is to understand these tasks as permutation problems and to\ndevise QUBOs whose solutions represent appropriate permutation matrices. We\ndiscuss how to construct such QUBOs and how to solve them using Hopfield nets\nor adiabatic) quantum computing. In short, we show that neurocomputing methods\nor quantum computers can solve problems usually associated with abstract data\nstructures.",
    "descriptor": "",
    "authors": [
      "Christian Bauckhage",
      "Thore Gerlach",
      "Nico Piatkowski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.08815"
  },
  {
    "id": "arXiv:2203.08822",
    "title": "Understanding robustness and generalization of artificial neural  networks through Fourier masks",
    "abstract": "Despite the enormous success of artificial neural networks (ANNs) in many\ndisciplines, the characterization of their computations and the origin of key\nproperties such as generalization and robustness remain open questions. Recent\nliterature suggests that robust networks with good generalization properties\ntend to be biased towards processing low frequencies in images. To explore the\nfrequency bias hypothesis further, we develop an algorithm that allows us to\nlearn modulatory masks highlighting the essential input frequencies needed for\npreserving a trained network's performance. We achieve this by imposing\ninvariance in the loss with respect to such modulations in the input\nfrequencies. We first use our method to test the low-frequency preference\nhypothesis of adversarially trained or data-augmented networks. Our results\nsuggest that adversarially robust networks indeed exhibit a low-frequency bias\nbut we find this bias is also dependent on directions in frequency space.\nHowever, this is not necessarily true for other types of data augmentation. Our\nresults also indicate that the essential frequencies in question are\neffectively the ones used to achieve generalization in the first place.\nSurprisingly, images seen through these modulatory masks are not recognizable\nand resemble texture-like patterns.",
    "descriptor": "",
    "authors": [
      "Nikos Karantzas",
      "Emma Besier",
      "Josue Ortega Caro",
      "Xaq Pitkow",
      "Andreas S. Tolias",
      "Ankit B. Patel",
      "Fabio Anselmi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.08822"
  },
  {
    "id": "arXiv:2203.08848",
    "title": "Greedy Algorithms for Decision Trees with Hypotheses",
    "abstract": "We investigate at decision trees that incorporate both traditional queries\nbased on one attribute and queries based on hypotheses about the values of all\nattributes. Such decision trees are similar to ones studied in exact learning,\nwhere membership and equivalence queries are allowed. We present greedy\nalgorithms based on diverse uncertainty measures for construction of above\ndecision trees and discuss results of computer experiments on various data sets\nfrom the UCI ML Repository and randomly generated Boolean functions. We also\nstudy the length and coverage of decision rules derived from the decisiontrees\nconstructed by greedy algorithms.",
    "descriptor": "",
    "authors": [
      "Mohammad Azad",
      "Igor Chikalov",
      "Shahid Hussain",
      "Mikhail Moshkov",
      "Beata Zielosko"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.08848"
  },
  {
    "id": "arXiv:2203.08849",
    "title": "FairFoody: Bringing in Fairness in Food Delivery",
    "abstract": "Along with the rapid growth and rise to prominence of food delivery\nplatforms, concerns have also risen about the terms of employment of the \"gig\nworkers\" underpinning this growth. Our analysis on data derived from a\nreal-world food delivery platform across three large cities from India show\nthat there is significant inequality in the money delivery agents earn. In this\npaper, we formulate the multi-objective} problem of fair income distribution\namong agents while also ensuring timely food delivery. We establish that the\nproblem is not only NP-hard but also inapproximable in polynomial time. We\novercome this computational bottleneck through a novel matching algorithm\ncalled FairFoody. Extensive experiments over real-world food delivery datasets\nshow FairFoody imparts up to $10$ times improvement in equitable income\ndistribution when compared to baseline strategies, while also ensuring minimal\nimpact on customer experience.",
    "descriptor": "\nComments: Appeared in Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI) 2022\n",
    "authors": [
      "Anjali",
      "Rahul Yadav",
      "Ashish Nair",
      "Abhijnan Chakraborty",
      "Sayan Ranu",
      "Amitabha Bagchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.08849"
  },
  {
    "id": "arXiv:2203.08850",
    "title": "Pre-Trained Multilingual Sequence-to-Sequence Models: A Hope for  Low-Resource Language Translation?",
    "abstract": "What can pre-trained multilingual sequence-to-sequence models like mBART\ncontribute to translating low-resource languages? We conduct a thorough\nempirical experiment in 10 languages to ascertain this, considering five\nfactors: (1) the amount of fine-tuning data, (2) the noise in the fine-tuning\ndata, (3) the amount of pre-training data in the model, (4) the impact of\ndomain mismatch, and (5) language typology. In addition to yielding several\nheuristics, the experiments form a framework for evaluating the data\nsensitivities of machine translation systems. While mBART is robust to domain\ndifferences, its translations for unseen and typologically distant languages\nremain below 3.0 BLEU. In answer to our title's question, mBART is not a\nlow-resource panacea; we therefore encourage shifting the emphasis from new\nmodels to new data.",
    "descriptor": "",
    "authors": [
      "En-Shiun Annie Lee",
      "Sarubi Thillainathan",
      "Shravan Nayak",
      "Surangika Ranathunga",
      "David Ifeoluwa Adelani",
      "Ruisi Su",
      "Arya D. McCarthy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08850"
  },
  {
    "id": "arXiv:2203.08851",
    "title": "Adaptive Objective Configuration in Bi-Objective Evolutionary  Optimization for Cervical Cancer Brachytherapy Treatment Planning",
    "abstract": "The Multi-Objective Real-Valued Gene-pool Optimal Mixing Evolutionary\nAlgorithm (MO-RV-GOMEA) has been proven effective and efficient in solving\nreal-world problems. A prime example is optimizing treatment plans for prostate\ncancer brachytherapy, an internal form of radiation treatment, for which\nequally important clinical aims from a base protocol are grouped into two\nobjectives and bi-objectively optimized. This use of MO-RV-GOMEA was recently\nsuccessfully introduced into clinical practice. Brachytherapy can also play an\nimportant role in treating cervical cancer. However, using the same approach to\noptimize treatment plans often does not immediately lead to clinically\ndesirable results. Concordantly, medical experts indicate that they use\nadditional aims beyond the cervix base protocol. Moreover, these aims have\ndifferent priorities and can be patient-specifically adjusted. For this reason,\nwe propose a novel adaptive objective configuration method to use with\nMO-RV-GOMEA so that we can accommodate additional aims of this nature. Based on\nresults using only the base protocol, in consultation with medical experts, we\nconfigured key additional aims. We show how, for 10 patient cases, the new\napproach achieves the intended result, properly taking into account the\nadditional aims. Consequently, plans resulting from the new approach are\npreferred by medical specialists in 8/10 cases.",
    "descriptor": "",
    "authors": [
      "Leah R.M. Dickhoff",
      "Ellen M. Kerkhof",
      "Heloisa H. Deuzeman",
      "Carien L. Creutzberg",
      "Tanja Alderliesten",
      "Peter A.N. Bosman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.08851"
  },
  {
    "id": "arXiv:2203.08852",
    "title": "Learning the Dynamics of Physical Systems from Sparse Observations with  Finite Element Networks",
    "abstract": "We propose a new method for spatio-temporal forecasting on arbitrarily\ndistributed points. Assuming that the observed system follows an unknown\npartial differential equation, we derive a continuous-time model for the\ndynamics of the data via the finite element method. The resulting graph neural\nnetwork estimates the instantaneous effects of the unknown dynamics on each\ncell in a meshing of the spatial domain. Our model can incorporate prior\nknowledge via assumptions on the form of the unknown PDE, which induce a\nstructural bias towards learning specific processes. Through this mechanism, we\nderive a transport variant of our model from the convection equation and show\nthat it improves the transfer performance to higher-resolution meshes on sea\nsurface temperature and gas flow forecasting against baseline models\nrepresenting a selection of spatio-temporal forecasting methods. A qualitative\nanalysis shows that our model disentangles the data dynamics into their\nconstituent parts, which makes it uniquely interpretable.",
    "descriptor": "",
    "authors": [
      "Marten Lienen",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08852"
  },
  {
    "id": "arXiv:2203.08856",
    "title": "Planar Rosa : a family of quasiperiodic substitution discrete plane  tilings with $2n$-fold rotational symmetry",
    "abstract": "We present Planar Rosa, a family of rhombus tilings with a $2n$-fold\nrotational symmetry that are generated by a primitive substitution and that are\nalso discrete plane tilings, meaning that they are obtained as a projection of\na higher dimensional discrete plane. The discrete plane condition is a relaxed\nversion of the cut-and-project condition. We also prove that the Sub Rosa\nsubstitution tilings with $2n$-fold rotational symmetry defined by Kari and\nRissanen do not satisfy even the weaker discrete plane condition. We prove our\nresults for all even $n\\geq 4$. This completes our previously published results\nfor odd values of $n$.",
    "descriptor": "",
    "authors": [
      "Jarkko Kari",
      "Victor Lutfalla"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.08856"
  },
  {
    "id": "arXiv:2203.08861",
    "title": "Towards an HPC Complementary Computing Facility",
    "abstract": "This Letter considers the design for computing facilities that are\ncomplementary to the leadership class High Performance Computing (HPC)\nfacilities. This design envisions a future where funding agencies are\nallocating greater resources for leadership class facilities and these\nfacilities will provide a significant part of the total compute cycles for HEP\nExperiments. While a leadership class facility (LCF) may provide cycles and\nadvanced architectures, the facility does not necessarily provide all of the\nservices needed to help HEP users make the best use of the HPC facility, as\nwell as the services needed to provide computing for workflows that are not a\ngood fit for the HPC facilities. This Letter outlines some of the necessary\ncomponents of a facility designed to provide those services and capabilities.",
    "descriptor": "\nComments: 4 pages, contribution to Snowmass 2021\n",
    "authors": [
      "K. Herner",
      "M. Kirby",
      "S. Timm"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2203.08861"
  },
  {
    "id": "arXiv:2203.08864",
    "title": "\"It Feels Like Taking a Gamble\": Exploring Perceptions, Practices, and  Challenges of Using Makeup and Cosmetics for People with Visual Impairments",
    "abstract": "Makeup and cosmetics offer the potential for self-expression and the\nreshaping of social roles for visually impaired people. However, there exist\nbarriers to conducting a beauty regime because of the reliance on visual\ninformation and color variances in makeup. We present a content analysis of 145\nYouTube videos to demonstrate visually impaired individuals' unique practices\nbefore, during, and after doing makeup. Based on the makeup practices, we then\nconducted semi-structured interviews with 12 visually impaired people to\ndiscuss their perceptions of and challenges with the makeup process in more\ndepth. Overall, through our findings and discussion, we present novel\nperceptions of makeup from visually impaired individuals (e.g., broader\nrepresentations of blindness and beauty). The existing challenges provide\nopportunities for future research to address learning barriers, insufficient\nfeedback, and physical and environmental barriers, making the experience of\ndoing makeup more accessible to people with visual impairments.",
    "descriptor": "\nComments: In CHI Conference on Human Factors in Computing Systems (CHI '22), April 29-May 5, 2022, New Orleans, LA, USA. ACM, New York, NY, USA, 15 pages. this https URL\n",
    "authors": [
      "Franklin Mingzhe Li",
      "Franchesca Spektor",
      "Meng Xia",
      "Mina Huh",
      "Peter Cederberg",
      "Yuqi Gong",
      "Kristen Shinohara",
      "Patrick Carrington"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.08864"
  },
  {
    "id": "arXiv:2203.08875",
    "title": "SC2: Supervised Compression for Split Computing",
    "abstract": "Split computing distributes the execution of a neural network (e.g., for a\nclassification task) between a mobile device and a more powerful edge server. A\nsimple alternative to splitting the network is to carry out the supervised task\npurely on the edge server while compressing and transmitting the full data, and\nmost approaches have barely outperformed this baseline. This paper proposes a\nnew approach for discretizing and entropy-coding intermediate feature\nactivations to efficiently transmit them from the mobile device to the edge\nserver. We show that a efficient splittable network architecture results from a\nthree-way tradeoff between (a) minimizing the computation on the mobile device,\n(b) minimizing the size of the data to be transmitted, and (c) maximizing the\nmodel's prediction performance. We propose an architecture based on this\ntradeoff and train the splittable network and entropy model in a knowledge\ndistillation framework. In an extensive set of experiments involving three\nvision tasks, three datasets, nine baselines, and more than 180 trained models,\nwe show that our approach improves supervised rate-distortion tradeoffs while\nmaintaining a considerably smaller encoder size. We also release sc2bench, an\ninstallable Python package, to encourage and facilitate future studies on\nsupervised compression for split computing (SC2).",
    "descriptor": "\nComments: Preprint. Code and models are available at this https URL\n",
    "authors": [
      "Yoshitomo Matsubara",
      "Ruihan Yang",
      "Marco Levorato",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.08875"
  },
  {
    "id": "arXiv:2203.08876",
    "title": "Encrypted Operator Computing: an alternative to Fully Homomorphic  Encryption",
    "abstract": "We introduce a new approach to computation on encrypted data -- Encrypted\nOperator Computing (EOC) -- as an alternative to Fully Homomorphic Encryption\n(FHE). EOC can be viewed as a reversible computation performed in a transformed\n(encrypted) frame of reference on transformed (encrypted) data, with both the\ntransformation and the data, as well as the function to be computed, hidden\nfrom adversaries. Encryption is implemented via a fast-scrambling two-stage\ncipher based on shallow -- ${\\cal O}(\\log n)$ depth -- random reversible\ncircuits of long-ranged 3-bit gates, organized in a hierarchical tree structure\n[1]. Encrypted functions are expressed as a concatenation of a polynomial\nnumber of \"chips\", $n$-input/$n$-output reversible functions, the outputs of\nwhich are expressed as ordered Binary Decision Diagrams (OBDDs). OBDDs are\nnormal forms that only expose the functionality of the chip but hide its\nprecise circuit implementation. The ${\\cal O}(\\log n)$ depth of the cipher\nallows us to prove analytically that the output OBDDs are polynomial in size,\nestablishing individual chips as examples of Best Possible Obfuscators\nintroduced by Goldwasser and Rothblum [2]. To extend single-chip security to\nthe concatenation of chips we add random pairs of NOT gates, which are split\napart and distributed across the system, for each recursive step in our\nconstruction. This randomization process, which is amplified by the\nnonlinearity of the cipher, scrambles the functionality of individual chips but\npreserves that of the whole circuit, thus enhancing the security of the full\ncomputation beyond that conferred by Best Possible Obfuscation of individual\nchips. While the paper focuses on symmetric encryption, we also present a\ngeneralization to public-private encryption.",
    "descriptor": "",
    "authors": [
      "Claudio Chamon",
      "Jonathan Jakes-Schauer",
      "Eduardo R. Mucciolo",
      "Andrei E. Ruckenstein"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08876"
  },
  {
    "id": "arXiv:2203.08877",
    "title": "Code Smells in Elixir: Early Results from a Grey Literature Review",
    "abstract": "Elixir is a new functional programming language whose popularity is rising in\nthe industry. However, there are few works in the literature focused on\nstudying the internal quality of systems implemented in this language.\nParticularly, to the best of our knowledge, there is currently no catalog of\ncode smells for Elixir. Therefore, in this paper, through a grey literature\nreview, we investigate whether Elixir developers discuss code smells. Our\npreliminary results indicate that 11 of the 22 traditional code smells\ncataloged by Fowler and Beck are discussed by Elixir developers. We also\npropose a list of 18 new smells specific for Elixir systems and investigate\nwhether these smells are currently identified by Credo, a well-known static\ncode analysis tool for Elixir. We conclude that only two traditional code\nsmells and one Elixir-specific code smell are automatically detected by this\ntool. Thus, these early results represent an opportunity for extending tools\nsuch as Credo to detect code smells and then contribute to improving the\ninternal quality of Elixir systems.",
    "descriptor": "\nComments: Accepted at 30th IEEE/ACM International Conference on Program Comprehension (ICPC'22 ERA), 5 pages, 2022\n",
    "authors": [
      "Lucas Francisco da Matta Vegi",
      "Marco Tulio Valente"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.08877"
  },
  {
    "id": "arXiv:2203.08878",
    "title": "Layer Ensembles: A Single-Pass Uncertainty Estimation in Deep Learning  for Segmentation",
    "abstract": "Uncertainty estimation in deep learning has become a leading research field\nin medical image analysis due to the need for safe utilisation of AI algorithms\nin clinical practice. Most approaches for uncertainty estimation require\nsampling the network weights multiple times during testing or training multiple\nnetworks. This leads to higher training and testing costs in terms of time and\ncomputational resources. In this paper, we propose Layer Ensembles, a novel\nuncertainty estimation method that uses a single network and requires only a\nsingle pass to estimate predictive uncertainty of a network. Moreover, we\nintroduce an image-level uncertainty metric, which is more beneficial for\nsegmentation tasks compared to the commonly used pixel-wise metrics such as\nentropy and variance. We evaluate our approach on 2D and 3D, binary and\nmulti-class medical image segmentation tasks. Our method shows competitive\nresults with state-of-the-art Deep Ensembles, requiring only a single network\nand a single pass.",
    "descriptor": "",
    "authors": [
      "Kaisar Kushibar",
      "V\u00edctor Manuel Campello",
      "Lidia Garrucho Moras",
      "Akis Linardos",
      "Petia Radeva",
      "Karim Lekadir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08878"
  },
  {
    "id": "arXiv:2203.08880",
    "title": "Finite-Length Scaling of SC-LDPC Codes With a Limited Number of Decoding  Iterations",
    "abstract": "We propose four finite-length scaling laws to predict the frame error rate\n(FER) performance of spatially-coupled low-density parity-check codes under\nfull belief propagation (BP) decoding with a limit on the number of decoding\niterations and a scaling law for sliding window decoding, also with limited\niterations. The laws for full BP decoding provide a choice between accuracy and\ncomputational complexity; a good balance between them is achieved by the law\nthat models the number of decoded bits after a certain number of BP iterations\nby a time-integrated Ornstein-Uhlenbeck process. This framework is developed\nfurther to model sliding window decoding as a race between the integrated\nOrnstein-Uhlenbeck process and an absorbing barrier that corresponds to the\nleft boundary of the sliding window. The proposed scaling laws yield accurate\nFER predictions.",
    "descriptor": "",
    "authors": [
      "Roman Sokolovskii",
      "Alexandre Graell i Amat",
      "Fredrik Br\u00e4nnstr\u00f6m"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.08880"
  },
  {
    "id": "arXiv:2203.08881",
    "title": "Hyperbolic Uncertainty Aware Semantic Segmentation",
    "abstract": "Semantic segmentation (SS) aims to classify each pixel into one of the\npre-defined classes. This task plays an important role in self-driving cars and\nautonomous drones. In SS, many works have shown that most misclassified pixels\nare commonly near object boundaries with high uncertainties. However, existing\nSS loss functions are not tailored to handle these uncertain pixels during\ntraining, as these pixels are usually treated equally as confidently classified\npixels and cannot be embedded with arbitrary low distortion in Euclidean space,\nthereby degenerating the performance of SS. To overcome this problem, this\npaper designs a \"Hyperbolic Uncertainty Loss\" (HyperUL), which dynamically\nhighlights the misclassified and high-uncertainty pixels in Hyperbolic space\nduring training via the hyperbolic distances. The proposed HyperUL is model\nagnostic and can be easily applied to various neural architectures. After\nemploying HyperUL to three recent SS models, the experimental results on\nCityscapes and UAVid datasets reveal that the segmentation performance of\nexisting SS models can be consistently improved.",
    "descriptor": "",
    "authors": [
      "Bike Chen",
      "Wei Peng",
      "Xiaofeng Cao",
      "Juha R\u00f6ning"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08881"
  },
  {
    "id": "arXiv:2203.08885",
    "title": "Short and local transformations between ($\u0394+1$)-colorings",
    "abstract": "Recoloring a graph is about finding a sequence of proper colorings of this\ngraph from an initial coloring $\\sigma$ to a target coloring $\\eta$. Each pair\nof consecutive colorings must differ on exactly one vertex. The question\nbecomes: is there a sequence of colorings from $\\sigma$ to $\\eta$?\nIn this paper, we focus on $(\\Delta+1)$-colorings of graphs of maximum degree\n$\\Delta$. Feghali, Johnson and Paulusma proved that, if both colorings are\nnon-frozen (i.e. we can change the color of a least one vertex), then a\nquadratic recoloring sequence always exists. We improve their result by proving\nthat there actually exists a linear transformation.\nIn addition, we prove that the core of our algorithm can be performed\nlocally. Informally, if we start from a coloring where there is a set of\nwell-spread non-frozen vertices, then we can reach any other such coloring by\nrecoloring only $f(\\Delta)$ independent sets one after another. Moreover, these\nindependent sets can be computed efficiently in the LOCAL model of distributed\ncomputing.",
    "descriptor": "",
    "authors": [
      "Nicolas Bousquet",
      "Laurent Feuilloley",
      "Marc Heinrich",
      "Mika\u00ebl Rabie"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.08885"
  },
  {
    "id": "arXiv:2203.08889",
    "title": "Social-Cultural Factors in the Design of Technology for Hispanic People  with Stroke",
    "abstract": "Stroke is a leading cause of serious, long-term disability in the United\nStates. There exist disparities in both stroke prevalence and outcomes between\npeople with stroke in Hispanic and Latinx communities and the general stroke\npopulation. Current stroke technology - which aims to improve quality of life\nand bring people with stroke to the most functional, independent state possible\n- has shown promising results for the general stroke population, but has failed\nto close the recovery outcome gap for underserved Hispanic and Latinx people\nwith stroke. Previous work in health education, digital health, and HRI has\nimproved human health outcomes by incorporating social-cultural factors, though\nnot for stroke. In this position paper, we aim to justify accounting for unique\ncultural factors in stroke technology design for the Hispanic and Latinx\ncommunity. We review examples of successful culturally appropriate\ninterventions and suggest design considerations (mutually beneficial community\nconsultation, accommodating for barriers beforehand, building on culture, and\nincorporating education of the family) to provide more culturally appropriate\ndesign of Hispanic and Latinx stroke technology and reduce the disparity gap.",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "Elizabeth D. Vasquez",
      "Allison M. Okamura",
      "Sean Follmer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08889"
  },
  {
    "id": "arXiv:2203.08890",
    "title": "The Mathematics of Artificial Intelligence",
    "abstract": "We currently witness the spectacular success of artificial intelligence in\nboth science and public life. However, the development of a rigorous\nmathematical foundation is still at an early stage. In this survey article,\nwhich is based on an invited lecture at the International Congress of\nMathematicians 2022, we will in particular focus on the current \"workhorse\" of\nartificial intelligence, namely deep neural networks. We will present the main\ntheoretical directions along with several exemplary results and discuss key\nopen problems.",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "History and Overview (math.HO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08890"
  },
  {
    "id": "arXiv:2203.08893",
    "title": "Multimodal Learning on Graphs for Disease Relation Extraction",
    "abstract": "Objective: Disease knowledge graphs are a way to connect, organize, and\naccess disparate information about diseases with numerous benefits for\nartificial intelligence (AI). To create knowledge graphs, it is necessary to\nextract knowledge from multimodal datasets in the form of relationships between\ndisease concepts and normalize both concepts and relationship types. Methods:\nWe introduce REMAP, a multimodal approach for disease relation extraction and\nclassification. The REMAP machine learning approach jointly embeds a partial,\nincomplete knowledge graph and a medical language dataset into a compact latent\nvector space, followed by aligning the multimodal embeddings for optimal\ndisease relation extraction. Results: We apply REMAP approach to a disease\nknowledge graph with 96,913 relations and a text dataset of 1.24 million\nsentences. On a dataset annotated by human experts, REMAP improves text-based\ndisease relation extraction by 10.0% (accuracy) and 17.2% (F1-score) by fusing\ndisease knowledge graphs with text information. Further, REMAP leverages text\ninformation to recommend new relationships in the knowledge graph,\noutperforming graph-based methods by 8.4% (accuracy) and 10.4% (F1-score).\nDiscussion: Systematized knowledge is becoming the backbone of AI, creating\nopportunities to inject semantics into AI and fully integrate it into machine\nlearning algorithms. While prior semantic knowledge can assist in extracting\ndisease relationships from text, existing methods can not fully leverage\nmultimodal datasets. Conclusion: REMAP is a multimodal approach for extracting\nand classifying disease relationships by fusing structured knowledge and text\ninformation. REMAP provides a flexible neural architecture to easily find,\naccess, and validate AI-driven relationships between disease concepts.",
    "descriptor": "",
    "authors": [
      "Yucong Lin",
      "Keming Lu",
      "Sheng Yu",
      "Tianxi Cai",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.08893"
  },
  {
    "id": "arXiv:2203.08894",
    "title": "Decision Trees with Hypotheses for Recognition of Monotone Boolean  Functions and for Sorting",
    "abstract": "In this paper, we consider decision trees that use both queries based on one\nattribute each and queries based on hypotheses about values of all attributes.\nSuch decision trees are similar to ones studied in exact learning, where not\nonly membership but also equivalence queries are allowed. We investigate the\nproblem of recognition of monotone Boolean functions with $n$ variables, $n=2,\n\\ldots, 4$, and the problem of sorting $n$ pairwise different elements from\nlinearly ordered set, $n=3, \\ldots, 6$. For each of these problems, we compare\nthe complexity of different types of optimal (relative to the depth or the\nnumber of realizable nodes) decision trees with hypotheses. We also study the\ncomplexity of decision trees constructed by entropy-based greedy algorithm and\nanalyze the length of decision rules derived from these trees.",
    "descriptor": "",
    "authors": [
      "Mohammad Azad",
      "Igor Chikalov",
      "Shahid Hussain",
      "Mikhail Moshkov",
      "Beata Zielosko"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.08894"
  },
  {
    "id": "arXiv:2203.08895",
    "title": "Explaining Preference-driven Schedules: the EXPRES Framework",
    "abstract": "Scheduling is the task of assigning a set of scarce resources distributed\nover time to a set of agents, who typically have preferences about the\nassignments they would like to get. Due to the constrained nature of these\nproblems, satisfying all agents' preferences is often infeasible, which might\nlead to some agents not being happy with the resulting schedule. Providing\nexplanations has been shown to increase satisfaction and trust in solutions\nproduced by AI tools. However, it is particularly challenging to explain\nsolutions that are influenced by and impact on multiple agents. In this paper\nwe introduce the EXPRES framework, which can explain why a given preference was\nunsatisfied in a given optimal schedule. The EXPRES framework consists of: (i)\nan explanation generator that, based on a Mixed-Integer Linear Programming\nmodel, finds the best set of reasons that can explain an unsatisfied\npreference; and (ii) an explanation parser, which translates the generated\nexplanations into human interpretable ones. Through simulations, we show that\nthe explanation generator can efficiently scale to large instances. Finally,\nthrough a set of user studies within J.P. Morgan, we show that employees\npreferred the explanations generated by EXPRES over human-generated ones when\nconsidering workforce scheduling scenarios.",
    "descriptor": "",
    "authors": [
      "Alberto Pozanco",
      "Francesca Mosca",
      "Parisa Zehtabi",
      "Daniele Magazzeni",
      "Sarit Kraus"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08895"
  },
  {
    "id": "arXiv:2203.08896",
    "title": "Sat-NeRF: Learning Multi-View Satellite Photogrammetry With Transient  Objects and Shadow Modeling Using RPC Cameras",
    "abstract": "We introduce the Satellite Neural Radiance Field (Sat-NeRF), a new end-to-end\nmodel for learning multi-view satellite photogrammetry in the wild. Sat-NeRF\ncombines some of the latest trends in neural rendering with native satellite\ncamera models, represented by rational polynomial coefficient (RPC) functions.\nThe proposed method renders new views and infers surface models of similar\nquality to those obtained with traditional state-of-the-art stereo pipelines.\nMulti-date images exhibit significant changes in appearance, mainly due to\nvarying shadows and transient objects (cars, vegetation). Robustness to these\nchallenges is achieved by a shadow-aware irradiance model and uncertainty\nweighting to deal with transient phenomena that cannot be explained by the\nposition of the sun. We evaluate Sat-NeRF using WorldView-3 images from\ndifferent locations and stress the advantages of applying a bundle adjustment\nto the satellite camera models prior to training. This boosts the network\nperformance and can optionally be used to extract additional cues for depth\nsupervision.",
    "descriptor": "",
    "authors": [
      "Roger Mar\u00ed",
      "Gabriele Facciolo",
      "Thibaud Ehret"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08896"
  },
  {
    "id": "arXiv:2203.08897",
    "title": "Gate-Shift-Fuse for Video Action Recognition",
    "abstract": "Convolutional Neural Networks are the de facto models for image recognition.\nHowever 3D CNNs, the straight forward extension of 2D CNNs for video\nrecognition, have not achieved the same success on standard action recognition\nbenchmarks. One of the main reasons for this reduced performance of 3D CNNs is\nthe increased computational complexity requiring large scale annotated datasets\nto train them in scale. 3D kernel factorization approaches have been proposed\nto reduce the complexity of 3D CNNs. Existing kernel factorization approaches\nfollow hand-designed and hard-wired techniques. In this paper we propose\nGate-Shift-Fuse (GSF), a novel spatio-temporal feature extraction module which\ncontrols interactions in spatio-temporal decomposition and learns to adaptively\nroute features through time and combine them in a data dependent manner. GSF\nleverages grouped spatial gating to decompose input tensor and channel\nweighting to fuse the decomposed tensors. GSF can be inserted into existing 2D\nCNNs to convert them into an efficient and high performing spatio-temporal\nfeature extractor, with negligible parameter and compute overhead. We perform\nan extensive analysis of GSF using two popular 2D CNN families and achieve\nstate-of-the-art or competitive performance on five standard action recognition\nbenchmarks. Code and models will be made publicly available at\nhttps://github.com/swathikirans/GSF.",
    "descriptor": "",
    "authors": [
      "Swathikiran Sudhakaran",
      "Sergio Escalera",
      "Oswald Lanz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08897"
  },
  {
    "id": "arXiv:2203.08900",
    "title": "A Structure-Preserving Divide-and-Conquer Method for Pseudosymmetric  Matrices",
    "abstract": "We devise a spectral divide-and-conquer scheme for matrices that are\nself-adjoint with respect to a given indefinite scalar product (i.e.\npseudosymmetic matrices). The pseudosymmetric structure of the matrix is\npreserved in the spectral division, such that the method can be applied\nrecursively to achieve full diagonalization. The method is well-suited for\nstructured matrices that come up in computational quantum physics and\nchemistry. In this application context, additional definiteness properties\nguarantee a convergence of the matrix sign function iteration within two steps\nwhen Zolotarev functions are used. The steps are easily parallelizable.\nFurthermore, it is shown that the matrix decouples into symmetric definite\neigenvalue problems after just one step of spectral division.",
    "descriptor": "",
    "authors": [
      "Peter Benner",
      "Yuji Nakatsukasa",
      "Carolin Penke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08900"
  },
  {
    "id": "arXiv:2203.08901",
    "title": "Blockchain as privacy and security solution for smart environments: A  Survey",
    "abstract": "Blockchain was always associated with Bitcoin, cryptocurrencies, and digital\nasset trading. However, its benefits are far beyond that. It supports\ntechnologies like the Internet-of-Things (IoT) to pave the way for futuristic\nsmart environments, like smart homes, smart transportation, smart energy\ntrading, smart industries, smart supply chains, and more. To enable these\nenvironments, IoT devices, machines, appliances, and vehicles, need to\nintercommunicate without the need for centralized trusted parties. Blockchain\nreplaces these trusted parties in such trustless environments. It provides\nsecurity enforcement, privacy assurance, authentication, and other key features\nto IoT ecosystems. Besides IoT-Blockchain integration, other technologies add\nmore benefits that attract the research community. Software-Defined Networking\n(SDN), Fog, Edge, and Cloud Computing technologies, for example, play a key\nrole in enabling realistic IoT applications. Moreover, the integration of\nArtificial Intelligence (AI) provides smart, dynamic, and autonomous\ndecision-making capabilities for IoT devices in smart environments. To push the\nresearch further in this domain, we provide in this paper a comprehensive\nsurvey that includes state-of-the-art technological integration, challenges,\nand solutions for smart environments, and the role of these technologies as the\nbuilding blocks of such smart environments. We also demonstrate how the level\nof integration between these technologies has increased over the years, which\nbrings us closer to the futuristic view of smart environments. We further\ndiscuss the current need to provide general-purpose Blockchain platforms that\ncan adapt to unique design requirements of different applications and\nsolutions. Finally, we provide a simplified architecture of futuristic smart\nenvironments that integrate these technologies, showing the advantage of such\nintegration.",
    "descriptor": "\nComments: 22 pages, 10 figures, 2 tables\n",
    "authors": [
      "Maad Ebrahim",
      "Abdelhakim Hafid",
      "Etienne Elie"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.08901"
  },
  {
    "id": "arXiv:2203.08903",
    "title": "SMARTmBOT: A ROS2-based Low-cost and Open-source Mobile Robot Platform",
    "abstract": "This paper introduces SMARTmBOT, an open-source mobile robot platform based\non Robot Operating System 2 (ROS2). The characteristics of the SMARTmBOT,\nincluding low-cost, modular-typed, customizable and expandable design, make it\nan easily achievable and effective robot platform to support broad robotics\nresearch and education involving either single-robot or multi-robot systems.\nThe total cost per robot is approximately $210, and most hardware components\ncan be fabricated by a generic 3D printer, hence allowing users to build the\nrobots or replace any broken parts conveniently. The SMARTmBot is also equipped\nwith a rich range of sensors, making it competent for general task scenarios,\nsuch as point-to-point navigation and obstacle avoidance. We validated the\nmobility and function of SMARTmBOT through various robot navigation experiments\nand applications with tasks including go-to-goal, pure-pursuit, line following,\nand swarming. All source code necessary for reading sensors, streaming from an\nembedded camera, and controlling the robot including robot navigation\ncontrollers is available through an online repository that can be found at\nhttps://github.com/SMARTlab-Purdue/SMARTmBOT.",
    "descriptor": "\nComments: 6 pages, 7 figures, and this paper was submitted to the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Wonse Jo",
      "Jaeeun Kim",
      "Ruiqi Wang",
      "Jeremy Pan",
      "Revanth Krishna Senthilkumaran",
      "Byung-Cheol Min"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Hardware Architecture (cs.AR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08903"
  },
  {
    "id": "arXiv:2203.08906",
    "title": "ORCA: A Network and Architecture Co-design for Offloading us-scale  Datacenter Applications",
    "abstract": "Responding to the \"datacenter tax\" and \"killer microseconds\" problems for\ndatacenter applications, diverse solutions including Smart NIC-based ones have\nbeen proposed. Nonetheless, they often suffer from high overhead of\ncommunications over network and/or PCIe links. To tackle the limitations of the\ncurrent solutions, this paper proposes ORCA, a holistic network and\narchitecture co-design solution that leverages current RDMA and emerging\ncache-coherent off-chip interconnect technologies. Specifically, ORCA consists\nof four hardware and software components: (1) unified abstraction of inter- and\nintra-machine communications managed by one-sided RDMA write and cache-coherent\nmemory write; (2) efficient notification of requests to accelerators assisted\nby cache coherence; (3) cache-coherent accelerator architecture directly\nprocessing requests received by NIC; and (4) adaptive device-to-host data\ntransfer for modern server memory systems consisting of both DRAM and NVM\nexploiting state-of-the-art features in CPUs and PCIe. We prototype ORCA with a\ncommercial system and evaluate three popular datacenter applications: in-memory\nkey-value store, chain replication-based distributed transaction system, and\ndeep learning recommendation model inference. The evaluation shows that ORCA\nprovides 30.1~69.1% lower latency, up to 2.5x higher throughput, and 3x higher\npower efficiency than the current state-of-the-art solutions.",
    "descriptor": "",
    "authors": [
      "Yifan Yuan",
      "Jinghan Huang",
      "Yan Sun",
      "Tianchen Wang",
      "Jacob Nelson",
      "Dan R. K. Ports",
      "Yipeng Wang",
      "Ren Wang",
      "Charlie Tai",
      "Nam Sung Kim"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.08906"
  },
  {
    "id": "arXiv:2203.08908",
    "title": "Adversarial Support Alignment",
    "abstract": "We study the problem of aligning the supports of distributions. Compared to\nthe existing work on distribution alignment, support alignment does not require\nthe densities to be matched. We propose symmetric support difference as a\ndivergence measure to quantify the mismatch between supports. We show that\nselect discriminators (e.g. discriminator trained for Jensen-Shannon\ndivergence) are able to map support differences as support differences in their\none-dimensional output space. Following this result, our method aligns supports\nby minimizing a symmetrized relaxed optimal transport cost in the discriminator\n1D space via an adversarial process. Furthermore, we show that our approach can\nbe viewed as a limit of existing notions of alignment by increasing\ntransportation assignment tolerance. We quantitatively evaluate the method\nacross domain adaptation tasks with shifts in label distributions. Our\nexperiments show that the proposed method is more robust against these shifts\nthan other alignment-based baselines.",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "Shangyuan Tong",
      "Timur Garipov",
      "Yang Zhang",
      "Shiyu Chang",
      "Tommi S. Jaakkola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08908"
  },
  {
    "id": "arXiv:2203.08909",
    "title": "Morphological Processing of Low-Resource Languages: Where We Are and  What's Next",
    "abstract": "Automatic morphological processing can aid downstream natural language\nprocessing applications, especially for low-resource languages, and assist\nlanguage documentation efforts for endangered languages. Having long been\nmultilingual, the field of computational morphology is increasingly moving\ntowards approaches suitable for languages with minimal or no annotated\nresources. First, we survey recent developments in computational morphology\nwith a focus on low-resource languages. Second, we argue that the field is\nready to tackle the logical next challenge: understanding a language's\nmorphology from raw text alone. We perform an empirical study on a truly\nunsupervised version of the paradigm completion task and show that, while\nexisting state-of-the-art models bridged by two newly proposed models we devise\nperform reasonably, there is still much room for improvement. The stakes are\nhigh: solving this task will increase the language coverage of morphological\nresources by a number of magnitudes.",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Adam Wiemerslage",
      "Miikka Silfverberg",
      "Changbing Yang",
      "Arya D. McCarthy",
      "Garrett Nicolai",
      "Eliana Colunga",
      "Katharina Kann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08909"
  },
  {
    "id": "arXiv:2203.08912",
    "title": "The Best of Both Worlds: Combining Learned Embeddings with Engineered  Features for Accurate Prediction of Correct Patches",
    "abstract": "A large body of the literature on automated program repair develops\napproaches where patches are automatically generated to be validated against an\noracle (e.g., a test suite). Because such an oracle can be imperfect, the\ngenerated patches, although validated by the oracle, may actually be incorrect.\nOur empirical work investigates different representation learning approaches\nfor code changes to derive embeddings that are amenable to similarity\ncomputations of patch correctness identification, and assess the possibility of\naccurate classification of correct patch by combining learned embeddings with\nengineered features. Experimental results demonstrate the potential of learned\nembeddings to empower Leopard (a patch correctness predicting framework\nimplemented in this work) with learning algorithms in reasoning about patch\ncorrectness: a machine learning predictor with BERT transformer-based learned\nembeddings associated with XGBoost achieves an AUC value of about 0.895 in the\nprediction of patch correctness on a new dataset of 2,147 labeled patches that\nwe collected for the experiments. Our investigations show that deep learned\nembeddings can lead to complementary/better performance when comparing against\nthe state-of-the-art, PATCH-SIM, which relies on dynamic information. By\ncombining deep learned embeddings and engineered features, Panther (the\nupgraded version of Leopard implemented in this work) outperforms Leopard with\nhigher scores in terms of AUC, +Recall and -Recall, and can accurately identify\nmore (in)correct patches that cannot be predicted by the classifiers only with\nlearned embeddings or engineered features. Finally, we use an explainable ML\ntechnique, SHAP, to empirically interpret how the learned embeddings and\nengineered features are contributed to the patch correctness prediction.",
    "descriptor": "",
    "authors": [
      "Haoye Tian",
      "Kui Liu",
      "Yinghua Li",
      "Abdoul Kader Kabor\u00e9",
      "Anil Koyuncu",
      "Andrew Habib",
      "Li Li",
      "Junhao Wen",
      "Jacques Klein",
      "Tegawend\u00e9 F. Bissyand\u00e9"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.08912"
  },
  {
    "id": "arXiv:2203.08913",
    "title": "Memorizing Transformers",
    "abstract": "Language models typically need to be trained or finetuned in order to acquire\nnew knowledge, which involves updating their weights. We instead envision\nlanguage models that can simply read and memorize new data at inference time,\nthus acquiring new knowledge immediately. In this work, we extend language\nmodels with the ability to memorize the internal representations of past\ninputs. We demonstrate that an approximate kNN lookup into a non-differentiable\nmemory of recent (key, value) pairs improves language modeling across various\nbenchmarks and tasks, including generic webtext (C4), math papers (arXiv),\nbooks (PG-19), code (Github), as well as formal theorems (Isabelle). We show\nthat the performance steadily improves when we increase the size of memory up\nto 262K tokens. On benchmarks including code and mathematics, we find that the\nmodel is capable of making use of newly defined functions and theorems during\ntest time.",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022 (spotlight)\n",
    "authors": [
      "Yuhuai Wu",
      "Markus N. Rabe",
      "DeLesley Hutchins",
      "Christian Szegedy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08913"
  },
  {
    "id": "arXiv:2203.08914",
    "title": "Automated Grading of Radiographic Knee Osteoarthritis Severity Combined  with Joint Space Narrowing",
    "abstract": "The assessment of knee osteoarthritis (KOA) severity on knee X-rays is a\ncentral criteria for the use of total knee arthroplasty. However, this\nassessment suffers from imprecise standards and a remarkably high inter-reader\nvariability. An algorithmic, automated assessment of KOA severity could improve\noverall outcomes of knee replacement procedures by increasing the\nappropriateness of its use. We propose a novel deep learning-based five-step\nalgorithm to automatically grade KOA from posterior-anterior (PA) views of\nradiographs: (1) image preprocessing (2) localization of knees joints in the\nimage using the YOLO v3-Tiny model, (3) initial assessment of the severity of\nosteoarthritis using a convolutional neural network-based classifier, (4)\nsegmentation of the joints and calculation of the joint space narrowing (JSN),\nand (5), a combination of the JSN and the initial assessment to determine a\nfinal Kellgren-Lawrence (KL) score. Furthermore, by displaying the segmentation\nmasks used to make the assessment, our algorithm demonstrates a higher degree\nof transparency compared to typical \"black box\" deep learning classifiers. We\nperform a comprehensive evaluation using two public datasets and one dataset\nfrom our institution, and show that our algorithm reaches state-of-the art\nperformance. Moreover, we also collected ratings from multiple radiologists at\nour institution and showed that our algorithm performs at the radiologist\nlevel.\nThe software has been made publicly available at\nhttps://github.com/MaciejMazurowski/osteoarthritis-classification.",
    "descriptor": "",
    "authors": [
      "Hanxue Gu",
      "Keyu Li",
      "Roy J. Colglazier",
      "Jichen Yang",
      "Michael Lebhar",
      "Jonathan O'Donnell",
      "William A. Jiranek",
      "Richard C. Mather",
      "Rob J. French",
      "Nicholas Said",
      "Jikai Zhang",
      "Christine Park",
      "Maciej A. Mazurowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08914"
  },
  {
    "id": "arXiv:2203.08917",
    "title": "Sound Development of Safety Supervisors",
    "abstract": "Safety supervisors are controllers enforcing safety properties by keeping a\nsystem in (or returning it to) a safe state. The development of such\nhigh-integrity components can benefit from a rigorous workflow integrating\nformal design and verification. In this paper, we present a workflow for the\nsound development of safety supervisors combining the best of two worlds,\nverified synthesis and complete testing. Synthesis allows one to focus on\nproblem specification and model validation. Testing compensates for the\ncrossing of abstraction, formalism, and tool boundaries and is a key element to\nobtain certification credit before entry into service. We establish soundness\nof our workflow through a rigorous argument. Our approach is tool-supported,\naims at modern autonomous systems, and is illustrated with a collaborative\nrobotics example.",
    "descriptor": "\nComments: 18 pages, 8 figures, 1 table\n",
    "authors": [
      "Mario Gleirscher",
      "Lukas Plecher",
      "Jan Peleska"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08917"
  },
  {
    "id": "arXiv:2203.08921",
    "title": "Hybrid Pixel-Unshuffled Network for Lightweight Image Super-Resolution",
    "abstract": "Convolutional neural network (CNN) has achieved great success on image\nsuper-resolution (SR). However, most deep CNN-based SR models take massive\ncomputations to obtain high performance. Downsampling features for\nmulti-resolution fusion is an efficient and effective way to improve the\nperformance of visual recognition. Still, it is counter-intuitive in the SR\ntask, which needs to project a low-resolution input to high-resolution. In this\npaper, we propose a novel Hybrid Pixel-Unshuffled Network (HPUN) by introducing\nan efficient and effective downsampling module into the SR task. The network\ncontains pixel-unshuffled downsampling and Self-Residual Depthwise Separable\nConvolutions. Specifically, we utilize pixel-unshuffle operation to downsample\nthe input features and use grouped convolution to reduce the channels. Besides,\nwe enhance the depthwise convolution's performance by adding the input feature\nto its output. Experiments on benchmark datasets show that our HPUN achieves\nand surpasses the state-of-the-art reconstruction performance with fewer\nparameters and computation costs.",
    "descriptor": "",
    "authors": [
      "Bin Sun",
      "Yulun Zhang",
      "Songyao Jiang",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08921"
  },
  {
    "id": "arXiv:2203.08923",
    "title": "Towards True Detail Restoration for Super-Resolution: A Benchmark and a  Quality Metric",
    "abstract": "Super-resolution (SR) has become a widely researched topic in recent years.\nSR methods can improve overall image and video quality and create new\npossibilities for further content analysis. But the SR mainstream focuses\nprimarily on increasing the naturalness of the resulting image despite\npotentially losing context accuracy. Such methods may produce an incorrect\ndigit, character, face, or other structural object even though they otherwise\nyield good visual quality. Incorrect detail restoration can cause errors when\ndetecting and identifying objects both manually and automatically. To analyze\nthe detail-restoration capabilities of image and video SR models, we developed\na benchmark based on our own video dataset, which contains complex patterns\nthat SR models generally fail to correctly restore. We assessed 32 recent SR\nmodels using our benchmark and compared their ability to preserve scene\ncontext. We also conducted a crowd-sourced comparison of restored details and\ndeveloped an objective assessment metric that outperforms other quality metrics\nby correlation with subjective scores for this task. In conclusion, we provide\na deep analysis of benchmark results that yields insights for future SR-based\nwork.",
    "descriptor": "",
    "authors": [
      "Eugene Lyapustin",
      "Anastasia Kirillova",
      "Viacheslav Meshchaninov",
      "Evgeney Zimin",
      "Nikolai Karetin",
      "Dmitriy Vatolin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08923"
  },
  {
    "id": "arXiv:2203.08924",
    "title": "Traffic-Aware UAV Placement Using a Generalizable Deep Reinforcement  Learning Methodology",
    "abstract": "Unmanned Aerial Vehicles (UAVs) acting as Flying Access Points (FAPs) are\nbeing used to provide on-demand wireless connectivity in extreme scenarios.\nDespite ongoing research, the optimization of UAVs' positions according to\ndynamic users' traffic demands remains challenging. We propose the\nTraffic-aware UAV Placement Algorithm (TUPA), which positions a UAV acting as\nFAP according to the users' traffic demands, in order to maximize the network\nutility. Using a DRL approach enables the FAP to autonomously learn and adapt\nto dynamic conditions and requirements of networking scenarios. Moreover, the\nproposed DRL methodology allows TUPA to generalize knowledge acquired during\ntraining to unknown combinations of users' positions and traffic demands, with\nno additional training. TUPA is trained and evaluated using network simulator\nns-3 and ns3-gym framework. The results demonstrate that TUPA increases the\nnetwork utility, compared to baseline solutions, increasing the average network\nutility up to 4x in scenarios with heterogeneous traffic demands.",
    "descriptor": "",
    "authors": [
      "Eduardo Nuno Almeida",
      "Rui Campos",
      "Manuel Ricardo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.08924"
  },
  {
    "id": "arXiv:2203.08925",
    "title": "Any Way You Look At It: Semantic Crossview Localization and Mapping with  LiDAR",
    "abstract": "Currently, GPS is by far the most popular global localization method.\nHowever, it is not always reliable or accurate in all environments. SLAM\nmethods enable local state estimation but provide no means of registering the\nlocal map to a global one, which can be important for inter-robot collaboration\nor human interaction. In this work, we present a real-time method for utilizing\nsemantics to globally localize a robot using only egocentric 3D semantically\nlabelled LiDAR and IMU as well as top-down RGB images obtained from satellites\nor aerial robots. Additionally, as it runs, our method builds a globally\nregistered, semantic map of the environment. We validate our method on KITTI as\nwell as our own challenging datasets, and show better than 10 meter accuracy, a\nhigh degree of robustness, and the ability to estimate the scale of a top-down\nmap on the fly if it is initially unknown.",
    "descriptor": "\nComments: Published in the IEEE Robotics and Automation Letters and presented at the IEEE 2021 International Conference on Robotics and Automation. See this https URL for accompanying video\n",
    "authors": [
      "Ian D. Miller",
      "Anthony Cowley",
      "Ravi Konkimalla",
      "Shreyas S. Shivakumar",
      "Ty Nguyen",
      "Trey Smith",
      "Camillo Jose Taylor",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08925"
  },
  {
    "id": "arXiv:2203.08926",
    "title": "Synthetic Question Value Estimation for Domain Adaptation of Question  Answering",
    "abstract": "Synthesizing QA pairs with a question generator (QG) on the target domain has\nbecome a popular approach for domain adaptation of question answering (QA)\nmodels. Since synthetic questions are often noisy in practice, existing work\nadapts scores from a pretrained QA (or QG) model as criteria to select\nhigh-quality questions. However, these scores do not directly serve the\nultimate goal of improving QA performance on the target domain. In this paper,\nwe introduce a novel idea of training a question value estimator (QVE) that\ndirectly estimates the usefulness of synthetic questions for improving the\ntarget-domain QA performance. By conducting comprehensive experiments, we show\nthat the synthetic questions selected by QVE can help achieve better\ntarget-domain QA performance, in comparison with existing techniques. We\nadditionally show that by using such questions and only around 15% of the human\nannotations on the target domain, we can achieve comparable performance to the\nfully-supervised baselines.",
    "descriptor": "\nComments: ACL 2022 Main Conference\n",
    "authors": [
      "Xiang Yue",
      "Ziyu Yao",
      "Huan Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08926"
  },
  {
    "id": "arXiv:2203.08928",
    "title": "C-MORE: Pretraining to Answer Open-Domain Questions by Consulting  Millions of References",
    "abstract": "We consider the problem of pretraining a two-stage open-domain question\nanswering (QA) system (retriever + reader) with strong transfer capabilities.\nThe key challenge is how to construct a large amount of high-quality\nquestion-answer-context triplets without task-specific annotations.\nSpecifically, the triplets should align well with downstream tasks by: (i)\ncovering a wide range of domains (for open-domain applications), (ii) linking a\nquestion to its semantically relevant context with supporting evidence (for\ntraining the retriever), and (iii) identifying the correct answer in the\ncontext (for training the reader). Previous pretraining approaches generally\nfall short of one or more of these requirements. In this work, we automatically\nconstruct a large-scale corpus that meets all three criteria by consulting\nmillions of references cited within Wikipedia. The well-aligned pretraining\nsignals benefit both the retriever and the reader significantly. Our pretrained\nretriever leads to 2%-10% absolute gains in top-20 accuracy. And with our\npretrained reader, the entire system improves by up to 4% in exact match.",
    "descriptor": "\nComments: ACL 2022 Main Conference\n",
    "authors": [
      "Xiang Yue",
      "Xiaoman Pan",
      "Wenlin Yao",
      "Dian Yu",
      "Dong Yu",
      "Jianshu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08928"
  },
  {
    "id": "arXiv:2203.08929",
    "title": "An Analysis of Negation in Natural Language Understanding Corpora",
    "abstract": "This paper analyzes negation in eight popular corpora spanning six natural\nlanguage understanding tasks. We show that these corpora have few negations\ncompared to general-purpose English, and that the few negations in them are\noften unimportant. Indeed, one can often ignore negations and still make the\nright predictions. Additionally, experimental results show that\nstate-of-the-art transformers trained with these corpora obtain substantially\nworse results with instances that contain negation, especially if the negations\nare important. We conclude that new corpora accounting for negation are needed\nto solve natural language understanding tasks when negation is present.",
    "descriptor": "\nComments: To appear in the proceedings of ACL 2022 (main conference)\n",
    "authors": [
      "Md Mosharaf Hossain",
      "Dhivya Chinnappa",
      "Eduardo Blanco"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08929"
  },
  {
    "id": "arXiv:2203.08931",
    "title": "Creating Multimedia Summaries Using Tweets and Videos",
    "abstract": "While popular televised events such as presidential debates or TV shows are\nairing, people provide commentary on them in real-time. In this paper, we\npropose a simple yet effective approach to combine social media commentary and\nvideos to create a multimedia summary of televised events. Our approach\nidentifies scenes from these events based on spikes of mentions of people\ninvolved in the event and automatically selects tweets and frames from the\nvideos that occur during the time period of the spike that talk about and show\nthe people being discussed.",
    "descriptor": "\nComments: 8 pages, 3 figures, 7 tables\n",
    "authors": [
      "Anietie Andy",
      "Siyi Liu",
      "Daphne Ippolito",
      "Reno Kriz",
      "Chris Callison-Burch",
      "Derry Wijaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08931"
  },
  {
    "id": "arXiv:2203.08932",
    "title": "$\\ell_p$ Slack Norm Support Vector Data Description",
    "abstract": "The support vector data description (SVDD) approach serves as a de facto\nstandard for one-class classification where the learning task entails inferring\nthe smallest hyper-sphere to enclose target objects while linearly penalising\nany errors/slacks via an $\\ell_1$-norm penalty term. In this study, we\ngeneralise this modelling formalism to a general $\\ell_p$-norm ($p\\geq1$) slack\npenalty function. By virtue of an $\\ell_p$ slack norm, the proposed approach\nenables formulating a non-linear cost function with respect to slacks. From a\ndual problem perspective, the proposed method introduces a sparsity-inducing\ndual norm into the objective function, and thus, possesses a higher capacity to\ntune into the inherent sparsity of the problem for enhanced descriptive\ncapability. A theoretical analysis based on Rademacher complexities\ncharacterises the generalisation performance of the proposed approach in terms\nof parameter $p$ while the experimental results on several datasets confirm the\nmerits of the proposed method compared to other alternatives.",
    "descriptor": "",
    "authors": [
      "Shervin R. Arashloo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08932"
  },
  {
    "id": "arXiv:2203.08935",
    "title": "Understanding Privacy Switching Behaviour on Twitter",
    "abstract": "Changing a Twitter account's privacy setting between public and protected\nchanges the visibility of past tweets. By inspecting the privacy setting of\nover 100K Twitter users over 3 months, we noticed that over 40% of those users\nchange their privacy setting at least once with around 16% changing it over 5\ntimes. This motivated us to explore the reasons why people switch their privacy\nsetting. We studied these switching phenomena quantitatively by comparing the\ntweeting behaviour of users when public vs protected, and qualitatively using\ntwo follow-up surveys (n=100, n=324) to understand potential reasoning behind\nthe observed behaviours. Our quantitative analysis shows that users who switch\nprivacy settings mention others and share hashtags more when their setting is\npublic. Our surveys highlighted that users turn protected to share personal\ncontent and regulate boundaries while they turn public to interact with others\nin ways prevented by being protected.",
    "descriptor": "\nComments: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI'22)\n",
    "authors": [
      "Dilara Kek\u00fcll\u00fco\u011flu",
      "Kami Vaniea",
      "Walid Magdy"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.08935"
  },
  {
    "id": "arXiv:2203.08936",
    "title": "Painting the Landscape of Automotive Software in GitHub",
    "abstract": "The automotive industry has transitioned from being an electro-mechanical to\na software-intensive industry. A current high-end production vehicle contains\n100 million+ lines of code surpassing modern airplanes, the Large Hadron\nCollider, the Android OS, and Facebook's front-end software, in code size by a\nhuge margin. Today, software companies worldwide, including Apple, Google,\nHuawei, Baidu, and Sony are reportedly working to bring their vehicles to the\nroad. This paper ventures into the automotive software landscape in open\nsource, providing the first glimpse into this multi-disciplinary industry with\na long history of closed source development. We paint the landscape of\nautomotive software on GitHub by describing its characteristics and development\nstyles.\nThe landscape is defined by 15,000+ users contributing to ~600\nactively-developed automotive software projects created in a span of 12 years\nfrom 2010 until 2021. These projects range from vehicle dynamics-related\nsoftware; firmware and drivers for sensors like LiDAR and camera; algorithms\nfor perception and motion control; to complete operating systems integrating\nthe above. Developments in the field are spearheaded by industry and academia\nalike, with one in three actively developed automotive software repositories\nowned by an organization. We observe shifts along multiple dimensions,\nincluding preferred language from MATLAB to Python and prevalence of perception\nand decision-related software over traditional automotive software. This study\nwitnesses the open-source automotive software boom in its infancy with many\nimplications for future research and practice.",
    "descriptor": "",
    "authors": [
      "Sangeeth Kochanthara",
      "Yanja Dajsuren",
      "Loek Cleophas",
      "Mark van den Brand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.08936"
  },
  {
    "id": "arXiv:2203.08937",
    "title": "Backpropagation through Time and Space: Learning Numerical Methods with  Multi-Agent Reinforcement Learning",
    "abstract": "We introduce Backpropagation Through Time and Space (BPTTS), a method for\ntraining a recurrent spatio-temporal neural network, that is used in a\nhomogeneous multi-agent reinforcement learning (MARL) setting to learn\nnumerical methods for hyperbolic conservation laws. We treat the numerical\nschemes underlying partial differential equations (PDEs) as a Partially\nObservable Markov Game (POMG) in Reinforcement Learning (RL). Similar to\nnumerical solvers, our agent acts at each discrete location of a computational\nspace for efficient and generalizable learning. To learn higher-order spatial\nmethods by acting on local states, the agent must discern how its actions at a\ngiven spatiotemporal location affect the future evolution of the state. The\nmanifestation of this non-stationarity is addressed by BPTTS, which allows for\nthe flow of gradients across both space and time. The learned numerical\npolicies are comparable to the SOTA numerics in two settings, the Burgers'\nEquation and the Euler Equations, and generalize well to other simulation\nset-ups.",
    "descriptor": "",
    "authors": [
      "Elliot Way",
      "Dheeraj S.K. Kapilivai",
      "Yiwei Fu",
      "Lei Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.08937"
  },
  {
    "id": "arXiv:2203.08941",
    "title": "Translating Canonical SQL to Imperative Code in Coq",
    "abstract": "SQL is by far the most widely used and implemented query language. Yet, on\nsome key features, such as correlated queries and NULL value semantics, many\nimplementations diverge or contain bugs. We leverage recent advances in the\nformalization of SQL and query compilers to develop DBCert, the first\nmechanically verified compiler from SQL queries written in a canonical form to\nimperative code. Building DBCert required several new contributions which are\ndescribed in this paper. First, we specify and mechanize a complete translation\nfrom SQL to the Nested Relational Algebra which can be used for query\noptimization. Second, we define Imp, a small imperative language sufficient to\nexpress SQL and which can target several execution languages including\nJavaScript. Finally, we develop a mechanized translation from the nested\nrelational algebra to Imp, using the nested relational calculus as an\nintermediate step.",
    "descriptor": "\nComments: Version with appendix of a paper published at OOPSLA 2022\n",
    "authors": [
      "V\u00e9ronique Benzaken",
      "\u00c9velyne Contejean",
      "Mohammed Houssem Hachmaoui",
      "Chantal Keller",
      "Louis Mandel",
      "Avraham Shinnar",
      "J\u00e9r\u00f4me Sim\u00e9on"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.08941"
  },
  {
    "id": "arXiv:2203.08942",
    "title": "ABN: Agent-Aware Boundary Networks for Temporal Action Proposal  Generation",
    "abstract": "Temporal action proposal generation (TAPG) aims to estimate temporal\nintervals of actions in untrimmed videos, which is a challenging yet plays an\nimportant role in many tasks of video analysis and understanding. Despite the\ngreat achievement in TAPG, most existing works ignore the human perception of\ninteraction between agents and the surrounding environment by applying a deep\nlearning model as a black-box to the untrimmed videos to extract video visual\nrepresentation. Therefore, it is beneficial and potentially improve the\nperformance of TAPG if we can capture these interactions between agents and the\nenvironment. In this paper, we propose a novel framework named Agent-Aware\nBoundary Network (ABN), which consists of two sub-networks (i) an Agent-Aware\nRepresentation Network to obtain both agent-agent and agents-environment\nrelationships in the video representation, and (ii) a Boundary Generation\nNetwork to estimate the confidence score of temporal intervals. In the\nAgent-Aware Representation Network, the interactions between agents are\nexpressed through local pathway, which operates at a local level to focus on\nthe motions of agents whereas the overall perception of the surroundings are\nexpressed through global pathway, which operates at a global level to perceive\nthe effects of agents-environment. Comprehensive evaluations on 20-action\nTHUMOS-14 and 200-action ActivityNet-1.3 datasets with different backbone\nnetworks (i.e C3D, SlowFast and Two-Stream) show that our proposed ABN robustly\noutperforms state-of-the-art methods regardless of the employed backbone\nnetwork on TAPG. We further examine the proposal quality by leveraging\nproposals generated by our method onto temporal action detection (TAD)\nframeworks and evaluate their detection performances. The source code can be\nfound in this URL https://github.com/vhvkhoa/TAPG-AgentEnvNetwork.git.",
    "descriptor": "\nComments: Accepted in the journal of IEEE Access Vol. 9\n",
    "authors": [
      "Khoa Vo",
      "Kashu Yamazaki",
      "Sang Truong",
      "Minh-Triet Tran",
      "Akihiro Sugimoto",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08942"
  },
  {
    "id": "arXiv:2203.08943",
    "title": "CachePerf: A Unified Cache Miss Classifier via Hybrid Hardware Sampling",
    "abstract": "The cache plays a key role in determining the performance of applications, no\nmatter for sequential or concurrent programs on homogeneous and heterogeneous\narchitecture. Fixing cache misses requires to understand the origin and the\ntype of cache misses. However, this remains to be an unresolved issue even\nafter decades of research. This paper proposes a unified profiling\ntool--CachePerf--that could correctly identify different types of cache misses,\ndifferentiate allocator-induced issues from those of applications, and exclude\nminor issues without much performance impact. The core idea behind CachePerf is\na hybrid sampling scheme: it employs the PMU-based coarse-grained sampling to\nselect very few susceptible instructions (with frequent cache misses) and then\nemploys the breakpoint-based fine-grained sampling to collect the memory access\npattern of these instructions. Based on our evaluation, CachePerf only imposes\n14% performance overhead and 19% memory overhead (for applications with large\nfootprints), while identifying the types of cache misses correctly. CachePerf\ndetected 9 previous-unknown bugs. Fixing the reported bugs achieves from 3% to\n3788% performance speedup. CachePerf will be an indispensable complementary to\nexisting profilers due to its effectiveness and low overhead.",
    "descriptor": "",
    "authors": [
      "Jin Zhou",
      "Steven",
      "Tang",
      "Hanmei Yang",
      "Tongping Liu"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.08943"
  },
  {
    "id": "arXiv:2203.08944",
    "title": "Autonomous Wheel Loader Trajectory Tracking Control Using LPV-MPC",
    "abstract": "In this paper, we present a systematic approach for high-performance and\nefficient trajectory tracking control of autonomous wheel loaders. With the\nnonlinear dynamic model of a wheel loader, nonlinear model predictive control\n(MPC) is used in offline trajectory planning to obtain a high-performance\nstate-control trajectory while satisfying the state and control constraints. In\ntracking control, the nonlinear model is embedded into a Linear Parameter\nVarying (LPV) model and the LPV-MPC strategy is used to achieve fast online\ncomputation and good tracking performance. To demonstrate the effectiveness and\nthe advantages of the LPV-MPC, we test and compare three model predictive\ncontrol strategies in the high-fidelity simulation environment. With the\nplanned trajectory, three tracking control strategies LPV-MPC, nonlinear MPC,\nand LTI-MPC are simulated and compared in the perspectives of computational\nburden and tracking performance. The LPV-MPC can achieve better performance\nthan conventional LTI-MPC because more accurate nominal system dynamics are\ncaptured in the LPV model. In addition, LPV-MPC achieves slightly worse\ntracking performance but tremendously improved computational efficiency than\nnonlinear MPC. A video with loading cycles completed by our autonomous wheel\nloader in the simulation environment can be found here:\nhttps://youtu.be/QbNfS_wZKKA.",
    "descriptor": "",
    "authors": [
      "Ruitao Song",
      "Zhixian Ye",
      "Liyang Wang",
      "Tianyi He",
      "Liangjun Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08944"
  },
  {
    "id": "arXiv:2203.08945",
    "title": "Provable Adversarial Robustness for Fractional Lp Threat Models",
    "abstract": "In recent years, researchers have extensively studied adversarial robustness\nin a variety of threat models, including L_0, L_1, L_2, and L_infinity-norm\nbounded adversarial attacks. However, attacks bounded by fractional L_p \"norms\"\n(quasi-norms defined by the L_p distance with 0<p<1) have yet to be thoroughly\nconsidered. We proactively propose a defense with several desirable properties:\nit provides provable (certified) robustness, scales to ImageNet, and yields\ndeterministic (rather than high-probability) certified guarantees when applied\nto quantized data (e.g., images). Our technique for fractional L_p robustness\nconstructs expressive, deep classifiers that are globally Lipschitz with\nrespect to the L_p^p metric, for any 0<p<1. However, our method is even more\ngeneral: we can construct classifiers which are globally Lipschitz with respect\nto any metric defined as the sum of concave functions of components. Our\napproach builds on a recent work, Levine and Feizi (2021), which provides a\nprovable defense against L_1 attacks. However, we demonstrate that our proposed\nguarantees are highly non-vacuous, compared to the trivial solution of using\n(Levine and Feizi, 2021) directly and applying norm inequalities. Code is\navailable at https://github.com/alevine0/fractionalLpRobustness.",
    "descriptor": "\nComments: AISTATS 2022 accepted paper\n",
    "authors": [
      "Alexander Levine",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08945"
  },
  {
    "id": "arXiv:2203.08946",
    "title": "One Bad Apple Can Spoil Your IPv6 Privacy",
    "abstract": "IPv6 is being more and more adopted, in part to facilitate the millions of\nsmart devices that have already been installed at home. Unfortunately, we find\nthat the privacy of a substantial fraction of end-users is still at risk,\ndespite the efforts by ISPs and electronic vendors to improve end-user\nsecurity, e.g., by adopting prefix rotation and IPv6 privacy extensions. By\nanalyzing passive data from a large ISP, we find that around 19% of end-users'\nprivacy can be at risk. When we investigate the root causes, we notice that a\nsingle device at home that encodes its MAC address into the IPv6 address can be\nutilized as a tracking identifier for the entire end-user prefix -- even if\nother devices use IPv6 privacy extensions. Our results show that IoT devices\ncontribute the most to this privacy leakage and, to a lesser extent, personal\ncomputers and mobile devices. To our surprise, some of the most popular IoT\nmanufacturers have not yet adopted privacy extensions that could otherwise\nmitigate this privacy risk. Finally, we show that third-party providers, e.g.,\nhypergiants, can track up to 17% of subscriber lines in our study.",
    "descriptor": "\nComments: Accepted at ACM SIGCOMM Computer Communication Review, to appear in the April 2022 issue\n",
    "authors": [
      "Said Jawad Saidi",
      "Oliver Gasser",
      "Georgios Smaragdakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.08946"
  },
  {
    "id": "arXiv:2203.08949",
    "title": "Latent-Variable Advantage-Weighted Policy Optimization for Offline RL",
    "abstract": "Offline reinforcement learning methods hold the promise of learning policies\nfrom pre-collected datasets without the need to query the environment for new\ntransitions. This setting is particularly well-suited for continuous control\nrobotic applications for which online data collection based on trial-and-error\nis costly and potentially unsafe. In practice, offline datasets are often\nheterogeneous, i.e., collected in a variety of scenarios, such as data from\nseveral human demonstrators or from policies that act with different purposes.\nUnfortunately, such datasets can exacerbate the distribution shift between the\nbehavior policy underlying the data and the optimal policy to be learned,\nleading to poor performance. To address this challenge, we propose to leverage\nlatent-variable policies that can represent a broader class of policy\ndistributions, leading to better adherence to the training data distribution\nwhile maximizing reward via a policy over the latent variable. As we\nempirically show on a range of simulated locomotion, navigation, and\nmanipulation tasks, our method referred to as latent-variable\nadvantage-weighted policy optimization (LAPO), improves the average performance\nof the next best-performing offline reinforcement learning methods by 49% on\nheterogeneous datasets, and by 8% on datasets with narrow and biased\ndistributions.",
    "descriptor": "",
    "authors": [
      "Xi Chen",
      "Ali Ghadirzadeh",
      "Tianhe Yu",
      "Yuan Gao",
      "Jianhao Wang",
      "Wenzhe Li",
      "Bin Liang",
      "Chelsea Finn",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08949"
  },
  {
    "id": "arXiv:2203.08951",
    "title": "Meta-Learning of NAS for Few-shot Learning in Medical Image Applications",
    "abstract": "Deep learning methods have been successful in solving tasks in machine\nlearning and have made breakthroughs in many sectors owing to their ability to\nautomatically extract features from unstructured data. However, their\nperformance relies on manual trial-and-error processes for selecting an\nappropriate network architecture, hyperparameters for training, and\npre-/post-procedures. Even though it has been shown that network architecture\nplays a critical role in learning feature representation feature from data and\nthe final performance, searching for the best network architecture is\ncomputationally intensive and heavily relies on researchers' experience.\nAutomated machine learning (AutoML) and its advanced techniques i.e. Neural\nArchitecture Search (NAS) have been promoted to address those limitations. Not\nonly in general computer vision tasks, but NAS has also motivated various\napplications in multiple areas including medical imaging. In medical imaging,\nNAS has significant progress in improving the accuracy of image classification,\nsegmentation, reconstruction, and more. However, NAS requires the availability\nof large annotated data, considerable computation resources, and pre-defined\ntasks. To address such limitations, meta-learning has been adopted in the\nscenarios of few-shot learning and multiple tasks. In this book chapter, we\nfirst present a brief review of NAS by discussing well-known approaches in\nsearch space, search strategy, and evaluation strategy. We then introduce\nvarious NAS approaches in medical imaging with different applications such as\nclassification, segmentation, detection, reconstruction, etc. Meta-learning in\nNAS for few-shot learning and multiple tasks is then explained. Finally, we\ndescribe several open problems in NAS.",
    "descriptor": "\nComments: book chapter, in Meta-Learning with Medical Imaging and Health Informatics Applications\n",
    "authors": [
      "Viet-Khoa Vo-Ho",
      "Kashu Yamazaki",
      "Hieu Hoang",
      "Minh-Triet Tran",
      "Ngan Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.08951"
  },
  {
    "id": "arXiv:2203.08954",
    "title": "BPE vs. Morphological Segmentation: A Case Study on Machine Translation  of Four Polysynthetic Languages",
    "abstract": "Morphologically-rich polysynthetic languages present a challenge for NLP\nsystems due to data sparsity, and a common strategy to handle this issue is to\napply subword segmentation. We investigate a wide variety of supervised and\nunsupervised morphological segmentation methods for four polysynthetic\nlanguages: Nahuatl, Raramuri, Shipibo-Konibo, and Wixarika. Then, we compare\nthe morphologically inspired segmentation methods against Byte-Pair Encodings\n(BPEs) as inputs for machine translation (MT) when translating to and from\nSpanish. We show that for all language pairs except for Nahuatl, an\nunsupervised morphological segmentation algorithm outperforms BPEs consistently\nand that, although supervised methods achieve better segmentation scores, they\nunder-perform in MT challenges. Finally, we contribute two new morphological\nsegmentation datasets for Raramuri and Shipibo-Konibo, and a parallel corpus\nfor Raramuri--Spanish.",
    "descriptor": "\nComments: Accepted to Findings of ACL 2022\n",
    "authors": [
      "Manuel Mager",
      "Arturo Oncevay",
      "Elisabeth Mager",
      "Katharina Kann",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08954"
  },
  {
    "id": "arXiv:2203.08957",
    "title": "Risk-Averse No-Regret Learning in Online Convex Games",
    "abstract": "We consider an online stochastic game with risk-averse agents whose goal is\nto learn optimal decisions that minimize the risk of incurring significantly\nhigh costs. Specifically, we use the Conditional Value at Risk (CVaR) as a risk\nmeasure that the agents can estimate using bandit feedback in the form of the\ncost values of only their selected actions. Since the distributions of the cost\nfunctions depend on the actions of all agents that are generally unobservable,\nthey are themselves unknown and, therefore, the CVaR values of the costs are\ndifficult to compute. To address this challenge, we propose a new online\nrisk-averse learning algorithm that relies on one-point zeroth-order estimation\nof the CVaR gradients computed using CVaR values that are estimated by\nappropriately sampling the cost functions. We show that this algorithm achieves\nsub-linear regret with high probability. We also propose two variants of this\nalgorithm that improve performance. The first variant relies on a new sampling\nstrategy that uses samples from the previous iteration to improve the\nestimation accuracy of the CVaR values. The second variant employs residual\nfeedback that uses CVaR values from the previous iteration to reduce the\nvariance of the CVaR gradient estimates. We theoretically analyze the\nconvergence properties of these variants and illustrate their performance on an\nonline market problem that we model as a Cournot game.",
    "descriptor": "",
    "authors": [
      "Zifan Wang",
      "Yi Shen",
      "Michael M. Zavlanos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.08957"
  },
  {
    "id": "arXiv:2203.08958",
    "title": "On the Usefulness of the Fit-on-the-Test View on Evaluating Calibration  of Classifiers",
    "abstract": "Every uncalibrated classifier has a corresponding true calibration map that\ncalibrates its confidence. Deviations of this idealistic map from the identity\nmap reveal miscalibration. Such calibration errors can be reduced with many\npost-hoc calibration methods which fit some family of calibration maps on a\nvalidation dataset. In contrast, evaluation of calibration with the expected\ncalibration error (ECE) on the test set does not explicitly involve fitting.\nHowever, as we demonstrate, ECE can still be viewed as if fitting a family of\nfunctions on the test data. This motivates the fit-on-the-test view on\nevaluation: first, approximate a calibration map on the test data, and second,\nquantify its distance from the identity. Exploiting this view allows us to\nunlock missed opportunities: (1) use the plethora of post-hoc calibration\nmethods for evaluating calibration; (2) tune the number of bins in ECE with\ncross-validation. Furthermore, we introduce: (3) benchmarking on pseudo-real\ndata where the true calibration map can be estimated very precisely; and (4)\nnovel calibration and evaluation methods using new calibration map families PL\nand PL3.",
    "descriptor": "\nComments: ECML-PKDD journal track\n",
    "authors": [
      "Markus K\u00e4ngsepp",
      "Kaspar Valk",
      "Meelis Kull"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08958"
  },
  {
    "id": "arXiv:2203.08959",
    "title": "Robustness through Cognitive Dissociation Mitigation in Contrastive  Adversarial Training",
    "abstract": "In this paper, we introduce a novel neural network training framework that\nincreases model's adversarial robustness to adversarial attacks while\nmaintaining high clean accuracy by combining contrastive learning (CL) with\nadversarial training (AT). We propose to improve model robustness to\nadversarial attacks by learning feature representations that are consistent\nunder both data augmentations and adversarial perturbations. We leverage\ncontrastive learning to improve adversarial robustness by considering an\nadversarial example as another positive example, and aim to maximize the\nsimilarity between random augmentations of data samples and their adversarial\nexample, while constantly updating the classification head in order to avoid a\ncognitive dissociation between the classification head and the embedding space.\nThis dissociation is caused by the fact that CL updates the network up to the\nembedding space, while freezing the classification head which is used to\ngenerate new positive adversarial examples. We validate our method, Contrastive\nLearning with Adversarial Features(CLAF), on the CIFAR-10 dataset on which it\noutperforms both robust accuracy and clean accuracy over alternative supervised\nand self-supervised adversarial learning methods.",
    "descriptor": "",
    "authors": [
      "Adir Rahamim",
      "Itay Naeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08959"
  },
  {
    "id": "arXiv:2203.08961",
    "title": "On the Convergence of Certified Robust Training with Interval Bound  Propagation",
    "abstract": "Interval Bound Propagation (IBP) is so far the base of state-of-the-art\nmethods for training neural networks with certifiable robustness guarantees\nwhen potential adversarial perturbations present, while the convergence of IBP\ntraining remains unknown in existing literature. In this paper, we present a\ntheoretical analysis on the convergence of IBP training. With an\noverparameterized assumption, we analyze the convergence of IBP robust\ntraining. We show that when using IBP training to train a randomly initialized\ntwo-layer ReLU neural network with logistic loss, gradient descent can linearly\nconverge to zero robust training error with a high probability if we have\nsufficiently small perturbation radius and large network width.",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Yihan Wang",
      "Zhouxing Shi",
      "Quanquan Gu",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08961"
  },
  {
    "id": "arXiv:2203.08964",
    "title": "Point-Unet: A Context-aware Point-based Neural Network for Volumetric  Segmentation",
    "abstract": "Medical image analysis using deep learning has recently been prevalent,\nshowing great performance for various downstream tasks including medical image\nsegmentation and its sibling, volumetric image segmentation. Particularly, a\ntypical volumetric segmentation network strongly relies on a voxel grid\nrepresentation which treats volumetric data as a stack of individual voxel\n`slices', which allows learning to segment a voxel grid to be as\nstraightforward as extending existing image-based segmentation networks to the\n3D domain. However, using a voxel grid representation requires a large memory\nfootprint, expensive test-time and limiting the scalability of the solutions.\nIn this paper, we propose Point-Unet, a novel method that incorporates the\nefficiency of deep learning with 3D point clouds into volumetric segmentation.\nOur key idea is to first predict the regions of interest in the volume by\nlearning an attentional probability map, which is then used for sampling the\nvolume into a sparse point cloud that is subsequently segmented using a\npoint-based neural network. We have conducted the experiments on the medical\nvolumetric segmentation task with both a small-scale dataset Pancreas and\nlarge-scale datasets BraTS18, BraTS19, and BraTS20 challenges. A comprehensive\nbenchmark on different metrics has shown that our context-aware Point-Unet\nrobustly outperforms the SOTA voxel-based networks at both accuracies, memory\nusage during training, and time consumption during testing. Our code is\navailable at https://github.com/VinAIResearch/Point-Unet.",
    "descriptor": "\nComments: Accepted in MICCAI 2021\n",
    "authors": [
      "Ngoc-Vuong Ho",
      "Tan Nguyen",
      "Gia-Han Diep",
      "Ngan Le",
      "Binh-Son Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08964"
  },
  {
    "id": "arXiv:2203.08965",
    "title": "3D-UCaps: 3D Capsules Unet for Volumetric Image Segmentation",
    "abstract": "Medical image segmentation has been so far achieving promising results with\nConvolutional Neural Networks (CNNs). However, it is arguable that in\ntraditional CNNs, its pooling layer tends to discard important information such\nas positions. Moreover, CNNs are sensitive to rotation and affine\ntransformation. Capsule network is a data-efficient network design proposed to\novercome such limitations by replacing pooling layers with dynamic routing and\nconvolutional strides, which aims to preserve the part-whole relationships.\nCapsule network has shown a great performance in image recognition and natural\nlanguage processing, but applications for medical image segmentation,\nparticularly volumetric image segmentation, has been limited. In this work, we\npropose 3D-UCaps, a 3D voxel-based Capsule network for medical volumetric image\nsegmentation. We build the concept of capsules into a CNN by designing a\nnetwork with two pathways: the first pathway is encoded by 3D Capsule blocks,\nwhereas the second pathway is decoded by 3D CNNs blocks. 3D-UCaps, therefore\ninherits the merits from both Capsule network to preserve the spatial\nrelationship and CNNs to learn visual representation. We conducted experiments\non various datasets to demonstrate the robustness of 3D-UCaps including\niSeg-2017, LUNA16, Hippocampus, and Cardiac, where our method outperforms\nprevious Capsule networks and 3D-Unets.",
    "descriptor": "\nComments: Accepted in MICCAI 2021\n",
    "authors": [
      "Tan Nguyen",
      "Binh-Son Hua",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08965"
  },
  {
    "id": "arXiv:2203.08966",
    "title": "On Distributed Gravitational N-Body Simulations",
    "abstract": "The N-body problem is a classic problem involving a system of N discrete\nbodies mutually interacting in a dynamical system. At any moment in time there\nare N*(N - 1)/2 such interactions occurring. This scaling as N^2 leads to\ncomputational difficulties where simulations range from tens of thousands of\nbodies to many millions. Approximation algorithms, such as the famous\nBarnes-Hut algorithm, simplify the number of interactions to scale as N(log N).\nEven still, this improvement in complexity is insufficient to achieve the\ndesired performance for very large simulations on computing clusters with many\nnodes and many cores. In this work we explore a variety of algorithmic\ntechniques for distributed and parallel variations on the Barnes-Hut algorithm\nto improve parallelism and reduce inter-process communication requirements.\nExplicit algorithms and details are provided for reproducibility. Our MPI\nimplementation of distributed gravitational N-body simulation, freely available\non GitHub, is evaluated on a cluster of 10 nodes, each with two 6-core CPUs, to\ntest the effectiveness and scalability of the aforementioned techniques.",
    "descriptor": "\nComments: 41 pages, 10 figures\n",
    "authors": [
      "Alexander Brandt"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2203.08966"
  },
  {
    "id": "arXiv:2203.08972",
    "title": "Extensive Threat Analysis of Vein Attack Databases and Attack Detection  by Fusion of Comparison Scores",
    "abstract": "The last decade has brought forward many great contributions regarding\npresentation attack detection for the domain of finger and hand vein\nbiometrics. Among those contributions, one is able to find a variety of\ndifferent attack databases that are either private or made publicly available\nto the research community. However, it is not always shown whether the used\nattack samples hold the capability to actually deceive a realistic vein\nrecognition system. Inspired by previous works, this study provides a\nsystematic threat evaluation including three publicly available finger vein\nattack databases and one private dorsal hand vein database. To do so, 14\ndistinct vein recognition schemes are confronted with attack samples and the\npercentage of wrongly accepted attack samples is then reported as the Impostor\nAttack Presentation Match Rate. As a second step, comparison scores from\ndifferent recognition schemes are combined using score level fusion with the\ngoal of performing presentation attack detection.",
    "descriptor": "",
    "authors": [
      "Johannes Schuiki",
      "Michael Linortner",
      "Georg Wimmer",
      "Andreas Uhl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08972"
  },
  {
    "id": "arXiv:2203.08975",
    "title": "A Survey of Multi-Agent Reinforcement Learning with Communication",
    "abstract": "Communication is an effective mechanism for coordinating the behavior of\nmultiple agents. In the field of multi-agent reinforcement learning, agents can\nimprove the overall learning performance and achieve their objectives by\ncommunication. Moreover, agents can communicate various types of messages,\neither to all agents or to specific agent groups, and through specific\nchannels. With the growing body of research work in MARL with communication\n(Comm-MARL), there is lack of a systematic and structural approach to\ndistinguish and classify existing Comm-MARL systems. In this paper, we survey\nrecent works in the Comm-MARL field and consider various aspects of\ncommunication that can play a role in the design and development of multi-agent\nreinforcement learning systems. With these aspects in mind, we propose several\ndimensions along which Comm-MARL systems can be analyzed, developed, and\ncompared.",
    "descriptor": "\nComments: 10 pages, 4 figures, 10 tables\n",
    "authors": [
      "Changxi Zhu",
      "Mehdi Dastani",
      "Shihan Wang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08975"
  },
  {
    "id": "arXiv:2203.08977",
    "title": "Adaptive n-ary Activation Functions for Probabilistic Boolean Logic",
    "abstract": "Balancing model complexity against the information contained in observed data\nis the central challenge to learning. In order for complexity-efficient models\nto exist and be discoverable in high dimensions, we require a computational\nframework that relates a credible notion of complexity to simple parameter\nrepresentations. Further, this framework must allow excess complexity to be\ngradually removed via gradient-based optimization. Our n-ary, or n-argument,\nactivation functions fill this gap by approximating belief functions\n(probabilistic Boolean logic) using logit representations of probability. Just\nas Boolean logic determines the truth of a consequent claim from relationships\namong a set of antecedent propositions, probabilistic formulations generalize\npredictions when antecedents, truth tables, and consequents all retain\nuncertainty. Our activation functions demonstrate the ability to learn\narbitrary logic, such as the binary exclusive disjunction (p xor q) and ternary\nconditioned disjunction ( c ? p : q ), in a single layer using an activation\nfunction of matching or greater arity. Further, we represent belief tables\nusing a basis that directly associates the number of nonzero parameters to the\neffective arity of the belief function, thus capturing a concrete relationship\nbetween logical complexity and efficient parameter representations. This opens\noptimization approaches to reduce logical complexity by inducing parameter\nsparsity.",
    "descriptor": "",
    "authors": [
      "Jed A. Duersch",
      "Thomas A. Catanach",
      "Niladri Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08977"
  },
  {
    "id": "arXiv:2203.08979",
    "title": "Speaker Information Can Guide Models to Better Inductive Biases: A Case  Study On Predicting Code-Switching",
    "abstract": "Natural language processing (NLP) models trained on people-generated data can\nbe unreliable because, without any constraints, they can learn from spurious\ncorrelations that are not relevant to the task. We hypothesize that enriching\nmodels with speaker information in a controlled, educated way can guide them to\npick up on relevant inductive biases. For the speaker-driven task of predicting\ncode-switching points in English--Spanish bilingual dialogues, we show that\nadding sociolinguistically-grounded speaker features as prepended prompts\nsignificantly improves accuracy. We find that by adding influential phrases to\nthe input, speaker-informed models learn useful and explainable linguistic\ninformation. To our knowledge, we are the first to incorporate speaker\ncharacteristics in a neural model for code-switching, and more generally, take\na step towards developing transparent, personalized models that use speaker\ninformation in a controlled way.",
    "descriptor": "\nComments: To appear in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL 2022)\n",
    "authors": [
      "Alissa Ostapenko",
      "Shuly Wintner",
      "Melinda Fricke",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08979"
  },
  {
    "id": "arXiv:2203.08984",
    "title": "Koopman-based Differentiable Predictive Control for the Dynamics-Aware  Economic Dispatch Problem",
    "abstract": "The dynamics-aware economic dispatch (DED) problem embeds low-level generator\ndynamics and operational constraints to enable near real-time scheduling of\ngeneration units in a power network. DED produces a more dynamic supervisory\ncontrol policy than traditional economic dispatch (T-ED) that leads to reduced\noverall generation costs. However, the incorporation of differential equations\nthat govern the system dynamics makes DED an optimization problem that is\ncomputationally prohibitive to solve. In this work, we present a new\ndata-driven approach based on differentiable programming to efficiently obtain\nparametric solutions to the underlying DED problem. In particular, we employ\nthe recently proposed differentiable predictive control (DPC) for offline\nlearning of explicit neural control policies using an identified Koopman\noperator (KO) model of the power system dynamics. We demonstrate the high\nsolution quality and five orders of magnitude computational-time savings of the\nDPC method over the original online optimization-based DED approach on a 9-bus\ntest power grid network.",
    "descriptor": "\nComments: The code for producing this work is available in the repo: this https URL\n",
    "authors": [
      "Ethan King",
      "Jan Drgona",
      "Aaron Tuor",
      "Shrirang Abhyankar",
      "Craig Bakker",
      "Arnab Bhattacharya",
      "Draguna Vrabie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08984"
  },
  {
    "id": "arXiv:2203.08985",
    "title": "Label Semantics for Few Shot Named Entity Recognition",
    "abstract": "We study the problem of few shot learning for named entity recognition.\nSpecifically, we leverage the semantic information in the names of the labels\nas a way of giving the model additional signal and enriched priors. We propose\na neural architecture that consists of two BERT encoders, one to encode the\ndocument and its tokens and another one to encode each of the labels in natural\nlanguage format. Our model learns to match the representations of named\nentities computed by the first encoder with label representations computed by\nthe second encoder. The label semantics signal is shown to support improved\nstate-of-the-art results in multiple few shot NER benchmarks and on-par\nperformance in standard benchmarks. Our model is especially effective in low\nresource settings.",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Jie Ma",
      "Miguel Ballesteros",
      "Srikanth Doss",
      "Rishita Anubhai",
      "Sunil Mallya",
      "Yaser Al-Onaizan",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08985"
  },
  {
    "id": "arXiv:2203.08989",
    "title": "Detecting silent data corruptions in the wild",
    "abstract": "Silent Errors within hardware devices occur when an internal defect manifests\nin a part of the circuit which does not have check logic to detect the\nincorrect circuit operation. The results of such a defect can range from\nflipping a single bit in a single data value, up to causing the software to\nexecute the wrong instructions. Silent data corruptions (SDC) in hardware\nimpact computational integrity for large-scale applications. Manifestations of\nsilent errors are accelerated by datapath variations, temperature variance, and\nage, among other silicon factors. These errors do not leave any record or trace\nin system logs. As a result, silent errors stay undetected within workloads,\nand their effects can propagate across several services, causing problems to\nappear in systems far removed from the original defect. In this paper, we\ndescribe testing strategies to detect silent data corruptions within a large\nscale infrastructure. Given the challenging nature of the problem, we\nexperimented with different methods for detection and mitigation. We compare\nand contrast two such approaches - 1. Fleetscanner (out-of-production testing)\nand 2. Ripple (in-production testing).We evaluate the infrastructure tradeoffs\nassociated with the silicon testing funnel across 3+ years of production\nexperience.",
    "descriptor": "\nComments: 7 pages, 4 figures, 1 table, 31 references\n",
    "authors": [
      "Harish Dattatraya Dixit",
      "Laura Boyle",
      "Gautham Vunnam",
      "Sneha Pendharkar",
      "Matt Beadon",
      "Sriram Sankar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.08989"
  },
  {
    "id": "arXiv:2203.08991",
    "title": "AdapLeR: Speeding up Inference by Adaptive Length Reduction",
    "abstract": "Pre-trained language models have shown stellar performance in various\ndownstream tasks. But, this usually comes at the cost of high latency and\ncomputation, hindering their usage in resource-limited settings. In this work,\nwe propose a novel approach for reducing the computational cost of BERT with\nminimal loss in downstream performance. Our method dynamically eliminates less\ncontributing tokens through layers, resulting in shorter lengths and\nconsequently lower computational cost. To determine the importance of each\ntoken representation, we train a Contribution Predictor for each layer using a\ngradient-based saliency method. Our experiments on several diverse\nclassification tasks show speedups up to 22x during inference time without much\nsacrifice in performance. We also validate the quality of the selected tokens\nin our method using human annotations in the ERASER benchmark. In comparison to\nother widely used strategies for selecting important tokens, such as saliency\nand attention, our proposed method has a significantly lower false positive\nrate in generating rationales. Our code is freely available at\nhttps://github.com/amodaresi/AdapLeR .",
    "descriptor": "\nComments: Accepted to ACL 2022 (main conference)\n",
    "authors": [
      "Ali Modarressi",
      "Hosein Mohebbi",
      "Mohammad Taher Pilehvar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08991"
  },
  {
    "id": "arXiv:2203.08992",
    "title": "AdaLoGN: Adaptive Logic Graph Network for Reasoning-Based Machine  Reading Comprehension",
    "abstract": "Recent machine reading comprehension datasets such as ReClor and LogiQA\nrequire performing logical reasoning over text. Conventional neural models are\ninsufficient for logical reasoning, while symbolic reasoners cannot directly\napply to text. To meet the challenge, we present a neural-symbolic approach\nwhich, to predict an answer, passes messages over a graph representing logical\nrelations between text units. It incorporates an adaptive logic graph network\n(AdaLoGN) which adaptively infers logical relations to extend the graph and,\nessentially, realizes mutual and iterative reinforcement between neural and\nsymbolic reasoning. We also implement a novel subgraph-to-node message passing\nmechanism to enhance context-option interaction for answering multiple-choice\nquestions. Our approach shows promising results on ReClor and LogiQA.",
    "descriptor": "\nComments: 11 pages, accepted to the main conference of ACL 2022\n",
    "authors": [
      "Xiao Li",
      "Gong Cheng",
      "Ziheng Chen",
      "Yawei Sun",
      "Yuzhong Qu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2203.08992"
  },
  {
    "id": "arXiv:2203.08994",
    "title": "AI Autonomy: Self-Initiation, Adaptation and Continual Learning",
    "abstract": "As more and more AI agents are used in practice, it is time to think about\nhow to make these agents fully autonomous so that they can (1) learn by\nthemselves continually in a self-motivated and self-initiated manner rather\nthan being retrained offline periodically on the initiation of human engineers\nand (2) accommodate or adapt to unexpected or novel circumstances. As the\nreal-world is an open environment that is full of unknowns or novelties,\ndetecting novelties, characterizing them, accommodating or adapting to them,\nand gathering ground-truth training data and incrementally learning the\nunknowns/novelties are critical to making the AI agent more and more\nknowledgeable and powerful over time. The key challenge is how to automate the\nprocess so that it is carried out continually on the agent's own initiative and\nthrough its own interactions with humans, other agents and the environment just\nlike human on-the-job learning. This paper proposes a framework (called SOLA)\nfor this learning paradigm to promote the research of building autonomous and\ncontinual learning enabled AI agents. To show feasibility, an implemented agent\nis also described.",
    "descriptor": "",
    "authors": [
      "Bing Liu",
      "Sahisnu Mazumder",
      "Eric Robertson",
      "Scott Grigsby"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08994"
  },
  {
    "id": "arXiv:2203.09006",
    "title": "The Data Airlock: infrastructure for restricted data informatics",
    "abstract": "Data science collaboration is problematic when access to operational data or\nmodels from outside the data-holding organisation is prohibited, for a variety\nof legal, security, ethical, or practical reasons. There are significant data\nprivacy challenges when performing collaborative data science work against such\nrestricted data. In this paper we describe a range of causes and risks\nassociated with restricted data along with the social, environmental, data, and\ncryptographic measures that may be used to mitigate such issues. We then show\nhow these are generally inadequate for restricted data contexts and introduce\nthe 'Data Airlock' - secure infrastructure that facilitates 'eyes-off' data\nscience workloads. After describing our use-case we detail the architecture and\nimplementation of a first, single-organisation version of the Data Airlock\ninfrastructure. We conclude with outcomes and learning from this\nimplementation, and outline requirements for a second, federated version.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Gregory Rolan",
      "Janis Dalins",
      "Campbell Wilson"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.09006"
  },
  {
    "id": "arXiv:2203.09009",
    "title": "Example-Based Vulnerability Detection and Repair in Java Code",
    "abstract": "The Java libraries JCA and JSSE offer cryptographic APIs to facilitate secure\ncoding. When developers misuse some of the APIs, their code becomes vulnerable\nto cyber-attacks. To eliminate such vulnerabilities, people built tools to\ndetect security-API misuses via pattern matching. However, most tools do not\n(1) fix misuses or (2) allow users to extend tools' pattern sets. To overcome\nboth limitations, we created Seader-an example-based approach to detect and\nrepair security-API misuses. Given an exemplar <insecure, secure>code pair,\nSeader compares the snippets to infer any API-misuse template and corresponding\nfixing edit. Based on the inferred info, given a program, Seader performs\ninter-procedural static analysis to search for security-API misuses and to\npropose customized fixes. For evaluation, we applied Seader to 28 <insecure,\nsecure> codepairs; Seader successfully inferred 21 unique API-misuse templates\nand related fixes. With these <vulnerability, fix> patterns, we applied SEADER\nto a program benchmark that has 86 known vulnerabilities. Seader detected\nvulnerabilities with 95% precision, 72% recall, and82% F-score. We also applied\nSeader to 100 open-source projects and manually checked 77 suggested repairs;\n76 of the repairs were correct. Seader can help developers correctly use\nsecurity APIs.",
    "descriptor": "",
    "authors": [
      "Ying Zhang",
      "Ya Xiao",
      "Md Mahir Asef Kabir",
      "Danfeng",
      "Na Meng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.09009"
  },
  {
    "id": "arXiv:2203.09016",
    "title": "Natural Language Communication with a Teachable Agent",
    "abstract": "Conversational teachable agents offer a promising platform to support\nlearning, both in the classroom and in remote settings. In this context, the\nagent takes the role of the novice, while the student takes on the role of\nteacher. This framing is significant for its ability to elicit the Prot\\'eg\\'e\neffect in the student-teacher, a pedagogical phenomenon known to increase\nengagement in the teaching task, and also improve cognitive outcomes. In prior\nwork, teachable agents often take a passive role in the learning interaction,\nand there are few studies in which the agent and student engage in natural\nlanguage dialogue during the teaching task. This work investigates the effect\nof teaching modality when interacting with a virtual agent, via the web-based\nteaching platform, the Curiosity Notebook. A method of teaching the agent by\nselecting sentences from source material is compared to a method paraphrasing\nthe source material and typing text input to teach. A user study has been\nconducted to measure the effect teaching modality on the learning outcomes and\nengagement of the participants. The results indicate that teaching via\nparaphrasing and text input has a positive effect on learning outcomes for the\nmaterial covered, and also on aspects of affective engagement. Furthermore,\nincreased paraphrasing effort, as measured by the similarity between the source\nmaterial and the material the teacher conveyed to the robot, improves learning\noutcomes for participants.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Rachel Love",
      "Edith Law",
      "Philip R. Cohen",
      "Dana Kuli\u0107"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09016"
  },
  {
    "id": "arXiv:2203.09017",
    "title": "Semantic-diversity transfer network for generalized zero-shot learning  via inner disagreement based OOD detector",
    "abstract": "Zero-shot learning (ZSL) aims to recognize objects from unseen classes, where\nthe kernel problem is to transfer knowledge from seen classes to unseen classes\nby establishing appropriate mappings between visual and semantic features. The\nknowledge transfer in many existing works is limited mainly due to the facts\nthat 1) the widely used visual features are global ones but not totally\nconsistent with semantic attributes; 2) only one mapping is learned in existing\nworks, which is not able to effectively model diverse visual-semantic\nrelations; 3) the bias problem in the generalized ZSL (GZSL) could not be\neffectively handled. In this paper, we propose two techniques to alleviate\nthese limitations. Firstly, we propose a Semantic-diversity transfer Network\n(SetNet) addressing the first two limitations, where 1) a multiple-attention\narchitecture and a diversity regularizer are proposed to learn multiple local\nvisual features that are more consistent with semantic attributes and 2) a\nprojector ensemble that geometrically takes diverse local features as inputs is\nproposed to model visual-semantic relations from diverse local perspectives.\nSecondly, we propose an inner disagreement based domain detection module (ID3M)\nfor GZSL to alleviate the third limitation, which picks out unseen-class data\nbefore class-level classification. Due to the absence of unseen-class data in\ntraining stage, ID3M employs a novel self-contained training scheme and detects\nout unseen-class data based on a designed inner disagreement criterion.\nExperimental results on three public datasets demonstrate that the proposed\nSetNet with the explored ID3M achieves a significant improvement against $30$\nstate-of-the-art methods.",
    "descriptor": "\nComments: 35 pages, 6 figures\n",
    "authors": [
      "Bo Liu",
      "Qiulei Dong",
      "Zhanyi Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09017"
  },
  {
    "id": "arXiv:2203.09018",
    "title": "Kan Extensions in Data Science and Machine Learning",
    "abstract": "A common problem in data science is \"use this function defined over this\nsmall set to generate predictions over that larger set.\" Extrapolation,\ninterpolation, statistical inference and forecasting all reduce to this\nproblem. The Kan extension is a powerful tool in category theory that\ngeneralizes this notion. In this work we explore several applications of Kan\nextensions to data science. We begin by deriving a simple classification\nalgorithm as a Kan extension and experimenting with this algorithm on real\ndata. Next, we use the Kan extension to derive a procedure for learning\nclustering algorithms from labels and explore the performance of this procedure\non real data. We then investigate how Kan extensions can be used to learn a\ngeneral mapping from datasets of labeled examples to functions and to\napproximate a complex function with a simpler one.",
    "descriptor": "",
    "authors": [
      "Dan Shiebler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09018"
  },
  {
    "id": "arXiv:2203.09020",
    "title": "Graph Augmentation Learning",
    "abstract": "Graph Augmentation Learning (GAL) provides outstanding solutions for graph\nlearning in handling incomplete data, noise data, etc. Numerous GAL methods\nhave been proposed for graph-based applications such as social network analysis\nand traffic flow forecasting. However, the underlying reasons for the\neffectiveness of these GAL methods are still unclear. As a consequence, how to\nchoose optimal graph augmentation strategy for a certain application scenario\nis still in black box. There is a lack of systematic, comprehensive, and\nexperimentally validated guideline of GAL for scholars. Therefore, in this\nsurvey, we in-depth review GAL techniques from macro (graph), meso (subgraph),\nand micro (node/edge) levels. We further detailedly illustrate how GAL enhance\nthe data quality and the model performance. The aggregation mechanism of\naugmentation strategies and graph learning models are also discussed by\ndifferent application scenarios, i.e., data-specific, model-specific, and\nhybrid scenarios. To better show the outperformance of GAL, we experimentally\nvalidate the effectiveness and adaptability of different GAL strategies in\ndifferent downstream tasks. Finally, we share our insights on several open\nissues of GAL, including heterogeneity, spatio-temporal dynamics, scalability,\nand generalization.",
    "descriptor": "\nComments: 14 pages, 4 figures, Accepted in The First International Workshop on Graph Learning in IW3C2\n",
    "authors": [
      "Shuo Yu",
      "Huafei Huang",
      "Minh N. Dao",
      "Feng Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09020"
  },
  {
    "id": "arXiv:2203.09021",
    "title": "Structure-Preserving Model Reduction for Nonlinear Power Grid Network",
    "abstract": "We develop a structure-preserving system-theoretic model reduction framework\nfor nonlinear power grid networks. First, via a lifting transformation, we\nconvert the original nonlinear system with trigonometric nonlinearities to an\nequivalent quadratic nonlinear model. This equivalent representation allows us\nto employ the $\\mathcal{H}_2$-based model reduction approach, Quadratic\nIterative Rational Krylov Algorithm (Q-IRKA), as an intermediate model\nreduction step. Exploiting the structure of the underlying power network model,\nwe show that the model reduction bases resulting from Q-IRKA have a special\nsubspace structure, which allows us to effectively construct the final model\nreduction basis. This final basis is applied on the original nonlinear\nstructure to yield a reduced model that preserves the physically meaningful\n(second-order) structure of the original model. The effectiveness of our\nproposed framework is illustrated via two numerical examples.",
    "descriptor": "",
    "authors": [
      "Bita Safaee",
      "Serkan Gugercin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.09021"
  },
  {
    "id": "arXiv:2203.09022",
    "title": "Robust Control Approaches for Minimizing the Bandwidth Ratio in  Multi-Loop Control",
    "abstract": "Conventional dc-dc, dc-ac converter control entail an inner current and outer\nvoltage (ICOV) control loop. Stability of multi-loop control is achieved by\nensuring faster dynamics of inner loops, often separating the bandwidths by\nlarge factors. Heuristically a factor-of-ten has often been used to separate\nthe bandwidths of two adjacent loops in the nested architecture. In this paper,\nwe present a numerical method to optimally select the ratio of bandwidths for a\nnested controller. We first manipulate the robust framework to show that the\noptimal $H_\\infty$ subsumes the classical inner current outer voltage control.\nWe then use optimality of the proposed $H_\\infty$ controller to inspect\nfeasibility of different ratios of bandwidths of the inner and outer\ncontrollers. We finally select the numerically closest bandwidths of the two\nnested loops which the guarantee stability. Simulation models are used to\nverify the optimal bandwidth separation for a candidate grid-forming dc-ac\nconverter with inner current-outer voltage control.",
    "descriptor": "\nComments: 10 pages, 21 figures\n",
    "authors": [
      "Rahul Mallik"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.09022"
  },
  {
    "id": "arXiv:2203.09023",
    "title": "Measuring Consumer Perceived Warm-Glow for Technology Adoption Modeling",
    "abstract": "In this paper, we adapt and validate two constructs, perceived extrinsic\nwarm-glow (PIWG) and perceived intrinsic warm-glow (PIWG), to measure the two\ndimensions of consumer perceived warm-glow (i.e., extrinsic and intrinsic) for\nuse with the practice of technology adoption model-ing. Taking an experimental\napproach, participants were exposed to one of four vignettes de-signed to\nsimulate the absence or the presence of warm-glow (specifically, extrinsic\nwarm-glow, intrinsic warm-glow, and concurrently extrinsic and intrinsic\nwarm-glow). The results revealed that both constructs measured their respective\nforms of warm-glow with two caveats. The first that singularly trying to evoke\nextrinsic warm-glow led to only a slight increase in consumer perception of\nextrinsic warm-glow. We attributed this finding to individuals not being\nattracted to technology products that overtly target and seek to satisfy their\nvanity, instead preferring technology that does so subtly. The second that\nsingularly trying to evoke intrinsic warm-glow also resulted in the\nmanifestation of extrinsic warm-glow. Thus, warm-glow appears as a blend of\nextrinsic and intrinsic dimensions. A finding serves to reinforce what has\nalready been reported in the warm-glow literature and the idea of impure\naltruism.",
    "descriptor": "",
    "authors": [
      "Antonios Saravanos",
      "Dongnanzi Zheng",
      "Stavros Zervoudakis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.09023"
  },
  {
    "id": "arXiv:2203.09026",
    "title": "Complex Network Analysis of the Bitcoin Transaction Network",
    "abstract": "In this brief, we conduct a complex-network analysis of the Bitcoin\ntransaction network. In particular, we design a new sampling method, namely\nrandom walk with flying-back (RWFB), to conduct effective data sampling. We\nthen conduct a comprehensive analysis of the Bitcoin network in terms of the\ndegree distribution, clustering coefficient, the shortest-path length,\nconnected component, centrality, assortativity, and the rich-club coefficient.\nWe obtain several important observations including the small-world phenomenon,\nmulti-center status, preferential attachment, and non-rich-club effect of the\ncurrent network. This work brings up an in-depth understanding of the current\nBitcoin blockchain network and offers implications for future directions in\nmalicious activity and fraud detection in cryptocurrency blockchain networks.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Bishenghui Tao",
      "Hong-Ning Dai",
      "Jiajing Wu",
      "Ivan Wang-Hei Ho",
      "Zibin Zheng",
      "Chak Fong Cheang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.09026"
  },
  {
    "id": "arXiv:2203.09027",
    "title": "Triangular Transfer: Freezing the Pivot for Triangular Machine  Translation",
    "abstract": "Triangular machine translation is a special case of low-resource machine\ntranslation where the language pair of interest has limited parallel data, but\nboth languages have abundant parallel data with a pivot language. Naturally,\nthe key to triangular machine translation is the successful exploitation of\nsuch auxiliary data. In this work, we propose a transfer-learning-based\napproach that utilizes all types of auxiliary data. As we train auxiliary\nsource-pivot and pivot-target translation models, we initialize some parameters\nof the pivot side with a pre-trained language model and freeze them to\nencourage both translation models to work in the same pivot language space, so\nthat they can be smoothly transferred to the source-target translation model.\nExperiments show that our approach can outperform previous ones.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Meng Zhang",
      "Liangyou Li",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09027"
  },
  {
    "id": "arXiv:2203.09029",
    "title": "Sub-Terahertz Wireless Coverage Analysis at 142 GHz in Urban Microcell",
    "abstract": "Small-cell cellular base stations are going to be used for mmWave and sub-THz\ncommunication systems to provide multi-Gbps data rates and reliable coverage to\nmobile users. This paper analyzes the base station coverage of sub-THz\ncommunication systems and the system performance in terms of spectral\nefficiency through Monte Carlo simulations for both single-cell and multi-cell\ncases. The simulations are based on realistic channel models derived from\noutdoor field measurements at 142 GHz in urban microcell (UMi) environments\nconducted in downtown Brooklyn, New York. The single-cell base station can\nprovide a downlink coverage area with a radius of 200 m and the 7-cell system\ncan provide a downlink coverage area with a radius of 400 m at 142 GHz. Using a\n1 GHz downlink bandwidth and 100 MHz uplink bandwidth, the 7-cell system can\nprovide about 4.5 Gbps downlink average data rate and 410 Mbps uplink average\ndata rate at 142 GHz.",
    "descriptor": "\nComments: 6 pages, 7 figures, 1 table, IEEE ICC 2022\n",
    "authors": [
      "Yunchou Xing",
      "Ojas Kanhere",
      "Shihao Ju",
      "Theodore S. Rappaport"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.09029"
  },
  {
    "id": "arXiv:2203.09032",
    "title": "Coordinated Power Control for Network Integrated Sensing and  Communication",
    "abstract": "This correspondence paper studies a network integrated sensing and\ncommunication (ISAC) system that unifies the interference channel for\ncommunication and distributed radar sensing. In this system, a set of\ndistributed ISAC transmitters send individual messages to their respective\ncommunication users (CUs), and at the same time cooperate with multiple sensing\nreceivers to estimate the location of one target. We exploit the coordinated\npower control among ISAC transmitters to minimize their total transmit power\nwhile ensuring the minimum signal-to-interference-plus-noise ratio (SINR)\nconstraints at individual CUs and the maximum Cram\\'{e}r-Rao lower bound (CRLB)\nrequirement for target location estimation. Although the formulated coordinated\npower control problem is non-convex and difficult to solve in general, we\npropose two efficient algorithms to obtain high-quality solutions based on the\nsemi-definite relaxation (SDR) and CRLB approximation, respectively. Numerical\nresults show that the proposed designs achieve substantial performance gains in\nterms of power reduction, as compared to the benchmark with a heuristic\nseparate communication-sensing design.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Yi Huang",
      "Yuan Fang",
      "Xinmin Li",
      "Jie Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.09032"
  },
  {
    "id": "arXiv:2203.09033",
    "title": "Phased Flight Trajectory Prediction with Deep Learning",
    "abstract": "The unprecedented increase of commercial airlines and private jets over the\nnext ten years presents a challenge for air traffic control. Precise flight\ntrajectory prediction is of great significance in air transportation\nmanagement, which contributes to the decision-making for safe and orderly\nflights. Existing research and application mainly focus on the sequence\ngeneration based on historical trajectories, while the aircraft-aircraft\ninteractions in crowded airspace especially the airspaces near busy airports\nhave been largely ignored. On the other hand, there are distinct\ncharacteristics of aerodynamics for different flight phases, and the trajectory\nmay be affected by various uncertainties such as weather and advisories from\nair traffic controllers. However, there is no literature fully considers all\nthese issues. Therefore, we proposed a phased flight trajectory prediction\nframework. Multi-source and multi-modal datasets have been analyzed and mined\nusing variants of recurrent neural network (RNN) mixture. To be specific, we\nfirst introduce spatio temporal graphs into the low-altitude airway prediction\nproblem, and the motion constraints of an aircraft are embedded to the\ninference process for reliable forecasting results. In the en-route phase, the\ndual attention mechanism is employed to adaptively extract much more important\nfeatures from overall datasets to learn the hidden patterns in dynamical\nenvironments. The experimental results demonstrate our proposed framework can\noutperform state-of-the-art methods for flight trajectory prediction for large\npassenger/transport airplanes.",
    "descriptor": "\nComments: 20 pages, 9 figures\n",
    "authors": [
      "Kai Zhang",
      "Bowen Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09033"
  },
  {
    "id": "arXiv:2203.09034",
    "title": "GATE: Graph CCA for Temporal SElf-supervised Learning for  Label-efficient fMRI Analysis",
    "abstract": "In this work, we focus on the challenging task, neuro-disease classification,\nusing functional magnetic resonance imaging (fMRI). In population graph-based\ndisease analysis, graph convolutional neural networks (GCNs) have achieved\nremarkable success. However, these achievements are inseparable from abundant\nlabeled data and sensitive to spurious signals. To improve fMRI representation\nlearning and classification under a label-efficient setting, we propose a novel\nand theory-driven self-supervised learning (SSL) framework on GCNs, namely\nGraph CCA for Temporal self-supervised learning on fMRI analysis GATE.\nConcretely, it is demanding to design a suitable and effective SSL strategy to\nextract formation and robust features for fMRI. To this end, we investigate\nseveral new graph augmentation strategies from fMRI dynamic functional\nconnectives (FC) for SSL training. Further, we leverage canonical-correlation\nanalysis (CCA) on different temporal embeddings and present the theoretical\nimplications. Consequently, this yields a novel two-step GCN learning procedure\ncomprised of (i) SSL on an unlabeled fMRI population graph and (ii) fine-tuning\non a small labeled fMRI dataset for a classification task. Our method is tested\non two independent fMRI datasets, demonstrating superior performance on autism\nand dementia diagnosis.",
    "descriptor": "",
    "authors": [
      "Liang Peng",
      "Nan Wang",
      "Jie Xu",
      "Xiaofeng Zhu",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.09034"
  },
  {
    "id": "arXiv:2203.09035",
    "title": "HybridNets: End-to-End Perception Network",
    "abstract": "End-to-end Network has become increasingly important in multi-tasking. One\nprominent example of this is the growing significance of a driving perception\nsystem in autonomous driving. This paper systematically studies an end-to-end\nperception network for multi-tasking and proposes several key optimizations to\nimprove accuracy. First, the paper proposes efficient segmentation head and\nbox/class prediction networks based on weighted bidirectional feature network.\nSecond, the paper proposes automatically customized anchor for each level in\nthe weighted bidirectional feature network. Third, the paper proposes an\nefficient training loss function and training strategy to balance and optimize\nnetwork. Based on these optimizations, we have developed an end-to-end\nperception network to perform multi-tasking, including traffic object\ndetection, drivable area segmentation and lane detection simultaneously, called\nHybridNets, which achieves better accuracy than prior art. In particular,\nHybridNets achieves 77.3 mean Average Precision on Berkeley DeepDrive Dataset,\noutperforms lane detection with 31.6 mean Intersection Over Union with 12.83\nmillion parameters and 15.6 billion floating-point operations. In addition, it\ncan perform visual perception tasks in real-time and thus is a practical and\naccurate solution to the multi-tasking problem. Code is available at\nhttps://github.com/datvuthanh/HybridNets.",
    "descriptor": "",
    "authors": [
      "Dat Vu",
      "Bao Ngo",
      "Hung Phan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09035"
  },
  {
    "id": "arXiv:2203.09036",
    "title": "An Active Contour Model with Local Variance Force Term and Its Efficient  Minimization Solver for Multi-phase Image Segmentation",
    "abstract": "In this paper, we propose an active contour model with a local variance force\n(LVF) term that can be applied to multi-phase image segmentation problems. With\nthe LVF, the proposed model is very effective in the segmentation of images\nwith noise. To solve this model efficiently, we represent the regularization\nterm by characteristic functions and then design a minimization algorithm based\non a modification of the iterative convolution-thresholding method (ICTM),\nnamely ICTM-LVF. This minimization algorithm enjoys the energy-decaying\nproperty under some conditions and has highly efficient performance in the\nsegmentation. To overcome the initialization issue of active contour models, we\ngeneralize the inhomogeneous graph Laplacian initialization method (IGLIM) to\nthe multi-phase case and then apply it to give the initial contour of the\nICTM-LVF solver. Numerical experiments are conducted on synthetic images and\nreal images to demonstrate the capability of our initialization method, and the\neffectiveness of the local variance force for noise robustness in the\nmulti-phase image segmentation.",
    "descriptor": "",
    "authors": [
      "Chaoyu Liu",
      "Zhonghua Qiao",
      "Qian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.09036"
  },
  {
    "id": "arXiv:2203.09037",
    "title": "Collision Avoidance of 3-Dimensional Objects in Dynamic Environments",
    "abstract": "Achieving collision avoidance between moving objects is an important\nobjective while determining robot trajectories. In performing collision\navoidance maneuvers, the relative shapes of the objects play an important role.\nThe literature largely models the shapes of the objects as spheres, and this\ncan make the avoidance maneuvers very conservative, especially when the objects\nare of elongated shape and/or non-convex. In this paper, we model the shapes of\nthe objects using suitable combinations of ellipsoids and\none-sheeted/two-sheeted hyperboloids, and employ a collision cone approach to\nachieve collision avoidance. We present a method to construct the 3-D collision\ncone, and present simulation results demonstrating the working of the collision\navoidance laws.",
    "descriptor": "",
    "authors": [
      "Kashish Dhal",
      "Abhishek Kashyap",
      "Animesh Chakravarthy"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09037"
  },
  {
    "id": "arXiv:2203.09038",
    "title": "Optimal Control of Partially Observable Markov Decision Processes with  Finite Linear Temporal Logic Constraints",
    "abstract": "Autonomous agents often operate in scenarios where the state is partially\nobserved. In addition to maximizing their cumulative reward, agents must\nexecute complex tasks with rich temporal and logical structures. These tasks\ncan be expressed using temporal logic languages like finite linear temporal\nlogic (LTL_f). This paper, for the first time, provides a structured framework\nfor designing agent policies that maximize the reward while ensuring that the\nprobability of satisfying the temporal logic specification is sufficiently\nhigh. We reformulate the problem as a constrained partially observable Markov\ndecision process (POMDP) and provide a novel approach that can leverage\noff-the-shelf unconstrained POMDP solvers for solving it. Our approach\nguarantees approximate optimality and constraint satisfaction with high\nprobability. We demonstrate its effectiveness by implementing it on several\nmodels of interest.",
    "descriptor": "",
    "authors": [
      "Krishna C. Kalagarla",
      "Dhruva Kartik",
      "Dongming Shen",
      "Rahul Jain",
      "Ashutosh Nayyar",
      "Pierluigi Nuzzo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.09038"
  },
  {
    "id": "arXiv:2203.09040",
    "title": "A Survey of Multi-Tenant Deep Learning Inference on GPU",
    "abstract": "Deep Learning (DL) models have achieved superior performance. Meanwhile,\ncomputing hardware like NVIDIA GPUs also demonstrated strong computing scaling\ntrends with 2x throughput and memory bandwidth for each generation. With such\nstrong computing scaling of GPUs, multi-tenant deep learning inference by\nco-locating multiple DL models onto the same GPU becomes widely deployed to\nimprove resource utilization, enhance serving throughput, reduce energy cost,\netc. However, achieving efficient multi-tenant DL inference is challenging\nwhich requires thorough full-stack system optimization. This survey aims to\nsummarize and categorize the emerging challenges and optimization opportunities\nfor multi-tenant DL inference on GPU. By overviewing the entire optimization\nstack, summarizing the multi-tenant computing innovations, and elaborating the\nrecent technological advances, we hope that this survey could shed light on new\noptimization perspectives and motivate novel works in future large-scale DL\nsystem optimization.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Fuxun Yu",
      "Di Wang",
      "Longfei Shangguan",
      "Minjia Zhang",
      "Chenchen Liu",
      "Xiang Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.09040"
  },
  {
    "id": "arXiv:2203.09041",
    "title": "DATA: Domain-Aware and Task-Aware Pre-training",
    "abstract": "The paradigm of training models on massive data without label through\nself-supervised learning (SSL) and finetuning on many downstream tasks has\nbecome a trend recently. However, due to the high training costs and the\nunconsciousness of downstream usages, most self-supervised learning methods\nlack the capability to correspond to the diversities of downstream scenarios,\nas there are various data domains, different vision tasks and latency\nconstraints on models. Neural architecture search (NAS) is one universally\nacknowledged fashion to conquer the issues above, but applying NAS on SSL seems\nimpossible as there is no label or metric provided for judging model selection.\nIn this paper, we present DATA, a simple yet effective NAS approach specialized\nfor SSL that provides Domain-Aware and Task-Aware pre-training. Specifically,\nwe (i) train a supernet which could be deemed as a set of millions of networks\ncovering a wide range of model scales without any label, (ii) propose a\nflexible searching mechanism compatible with SSL that enables finding networks\nof different computation costs, for various downstream vision tasks and data\ndomains without explicit metric provided. Instantiated With MoCo v2, our method\nachieves promising results across a wide range of computation costs on\ndownstream tasks, including image classification, object detection and semantic\nsegmentation. DATA is orthogonal to most existing SSL methods and endows them\nthe ability of customization on downstream needs. Extensive experiments on\nother SSL methods demonstrate the generalizability of the proposed method. Code\nis released at https://github.com/GAIA-vision/GAIA-ssl",
    "descriptor": "\nComments: CVPR 2022,8 pages,3 figures\n",
    "authors": [
      "Qing Chang",
      "Junran Peng",
      "Lingxie Xie",
      "Jiajun Sun",
      "Haoran Yin",
      "Qi Tian",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09041"
  },
  {
    "id": "arXiv:2203.09043",
    "title": "Latent Image Animator: Learning to Animate Images via Latent Space  Navigation",
    "abstract": "Due to the remarkable progress of deep generative models, animating images\nhas become increasingly efficient, whereas associated results have become\nincreasingly realistic. Current animation-approaches commonly exploit structure\nrepresentation extracted from driving videos. Such structure representation is\ninstrumental in transferring motion from driving videos to still images.\nHowever, such approaches fail in case the source image and driving video\nencompass large appearance variation. Moreover, the extraction of structure\ninformation requires additional modules that endow the animation-model with\nincreased complexity. Deviating from such models, we here introduce the Latent\nImage Animator (LIA), a self-supervised autoencoder that evades need for\nstructure representation. LIA is streamlined to animate images by linear\nnavigation in the latent space. Specifically, motion in generated video is\nconstructed by linear displacement of codes in the latent space. Towards this,\nwe learn a set of orthogonal motion directions simultaneously, and use their\nlinear combination, in order to represent any displacement in the latent space.\nExtensive quantitative and qualitative analysis suggests that our model\nsystematically and significantly outperforms state-of-art methods on VoxCeleb,\nTaichi and TED-talk datasets w.r.t. generated quality.",
    "descriptor": "\nComments: ICLR 2022, project link this https URL\n",
    "authors": [
      "Yaohui Wang",
      "Di Yang",
      "Francois Bremond",
      "Antitza Dantcheva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09043"
  },
  {
    "id": "arXiv:2203.09044",
    "title": "Convert, compress, correct: Three steps toward communication-efficient  DNN training",
    "abstract": "In this paper, we introduce a novel algorithm, $\\mathsf{CO}_3$, for\ncommunication-efficiency distributed Deep Neural Network (DNN) training.\n$\\mathsf{CO}_3$ is a joint training/communication protocol, which encompasses\nthree processing steps for the network gradients: (i) quantization through\nfloating-point conversion, (ii) lossless compression, and (iii) error\ncorrection. These three components are crucial in the implementation of\ndistributed DNN training over rate-constrained links. The interplay of these\nthree steps in processing the DNN gradients is carefully balanced to yield a\nrobust and high-performance scheme. The performance of the proposed scheme is\ninvestigated through numerical evaluations over CIFAR-10.",
    "descriptor": "",
    "authors": [
      "Zhong-Jing Chen",
      "Eduin E. Hernandez",
      "Yu-Chih Huang",
      "Stefano Rini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09044"
  },
  {
    "id": "arXiv:2203.09047",
    "title": "Three-dimensional third-order gas-kinetic scheme on hybrid unstructured  meshes for Euler and Navier-Stokes equations",
    "abstract": "In this paper, a third order gas kinetic scheme is developed on the three\ndimensional hybrid unstructured meshes for the numerical simulation of\ncompressible inviscid and viscous flows. A third-order WENO reconstruction is\ndeveloped on the hybrid unstructured meshes, including tetrahedron, pyramid,\nprism and hexahedron. A simple strategy is adopted for the selection of big\nstencil and sub-stencils. Incorporate with the two-stage fourth-order temporal\ndiscretization and lower-upper symmetric Gauss-Seidel methods, both explicit\nand implicit high-order gas-kinetic schemes are developed. A variety of\nnumerical examples, from the subsonic to supersonic flows, are presented to\nvalidate the accuracy and robustness for both inviscid and viscous flows.",
    "descriptor": "",
    "authors": [
      "Yaqing Yang",
      "Liang Pan",
      "Kun Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.09047"
  },
  {
    "id": "arXiv:2203.09050",
    "title": "Insights for post-pandemic pedagogy across one CS department",
    "abstract": "Adaptive remote instruction has led to important lessons for the future,\nincluding rediscovery of known pedagogical principles in new contexts and new\ninsights for supporting remote learning. Studying one computer science\ndepartment that serves residential and remote undergraduate and graduate\nstudents, we conducted interviews with stakeholders in the department (n=26)\nand ran a department-wide student survey (n=102) during the four academic\nquarters from spring 2020 to spring 2021. Our case study outlines what the\ninstructors did, summarizes what instructors and students say about courses\nduring this period, and provides recommendations for CS departments with\nsimilar scope going forward. Specific insights address: (1) how instructional\ncomponents are best structured for students; (2) how students are assessed for\ntheir learning; and (3) how students are supported in student-initiated\ncomponents of learning. The institution is a large U.S. research university\nthat has a history of online programs including online enrollment in regular\non-campus courses and large-scale open enrollment courses. Our recommendations\nto instructors across the scope of this department may also be applicable to\nother institutions that provide technology-supported in-person instruction,\nremote enrollment, and hybrid courses combining both modalities.",
    "descriptor": "",
    "authors": [
      "Maxwell Bigman",
      "Yosefa Gilon",
      "Jenny Han",
      "John C Mitchell"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.09050"
  },
  {
    "id": "arXiv:2203.09052",
    "title": "DU-VLG: Unifying Vision-and-Language Generation via Dual  Sequence-to-Sequence Pre-training",
    "abstract": "Due to the limitations of the model structure and pre-training objectives,\nexisting vision-and-language generation models cannot utilize pair-wise images\nand text through bi-directional generation. In this paper, we propose DU-VLG, a\nframework which unifies vision-and-language generation as sequence generation\nproblems. DU-VLG is trained with novel dual pre-training tasks: multi-modal\ndenoising autoencoder tasks and modality translation tasks. To bridge the gap\nbetween image understanding and generation, we further design a novel\ncommitment loss. We compare pre-training objectives on image captioning and\ntext-to-image generation datasets. Results show that DU-VLG yields better\nperformance than variants trained with uni-directional generation objectives or\nthe variant without the commitment loss. We also obtain higher scores compared\nto previous state-of-the-art systems on three vision-and-language generation\ntasks. In addition, human judges further confirm that our model generates real\nand relevant images as well as faithful and informative captions.",
    "descriptor": "\nComments: To appear at Findings of ACL 2022\n",
    "authors": [
      "Luyang Huang",
      "Guocheng Niu",
      "Jiachen Liu",
      "Xinyan Xiao",
      "Hua Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09052"
  },
  {
    "id": "arXiv:2203.09053",
    "title": "Reducing Position Bias in Simultaneous Machine Translation with  Length-Aware Framework",
    "abstract": "Simultaneous machine translation (SiMT) starts translating while receiving\nthe streaming source inputs, and hence the source sentence is always incomplete\nduring translating. Different from the full-sentence MT using the conventional\nseq-to-seq architecture, SiMT often applies prefix-to-prefix architecture,\nwhich forces each target word to only align with a partial source prefix to\nadapt to the incomplete source in streaming inputs. However, the source words\nin the front positions are always illusoryly considered more important since\nthey appear in more prefixes, resulting in position bias, which makes the model\npay more attention on the front source positions in testing. In this paper, we\nfirst analyze the phenomenon of position bias in SiMT, and develop a\nLength-Aware Framework to reduce the position bias by bridging the structural\ngap between SiMT and full-sentence MT. Specifically, given the streaming\ninputs, we first predict the full-sentence length and then fill the future\nsource position with positional encoding, thereby turning the streaming inputs\ninto a pseudo full-sentence. The proposed framework can be integrated into most\nexisting SiMT methods to further improve performance. Experiments on two\nrepresentative SiMT methods, including the state-of-the-art adaptive policy,\nshow that our method successfully reduces the position bias and achieves better\nSiMT performance.",
    "descriptor": "\nComments: Accept to ACL 2022 main conference. 14 pages, 11 figures\n",
    "authors": [
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09053"
  },
  {
    "id": "arXiv:2203.09055",
    "title": "Fine- and Coarse-Granularity Hybrid Self-Attention for Efficient BERT",
    "abstract": "Transformer-based pre-trained models, such as BERT, have shown extraordinary\nsuccess in achieving state-of-the-art results in many natural language\nprocessing applications. However, deploying these models can be prohibitively\ncostly, as the standard self-attention mechanism of the Transformer suffers\nfrom quadratic computational cost in the input sequence length. To confront\nthis, we propose FCA, a fine- and coarse-granularity hybrid self-attention that\nreduces the computation cost through progressively shortening the computational\nsequence length in self-attention. Specifically, FCA conducts an\nattention-based scoring strategy to determine the informativeness of tokens at\neach layer. Then, the informative tokens serve as the fine-granularity\ncomputing units in self-attention and the uninformative tokens are replaced\nwith one or several clusters as the coarse-granularity computing units in\nself-attention. Experiments on GLUE and RACE datasets show that BERT with FCA\nachieves 2x reduction in FLOPs over original BERT with <1% loss in accuracy. We\nshow that FCA offers a significantly better trade-off between accuracy and\nFLOPs compared to prior methods.",
    "descriptor": "\nComments: Accepted as ACL-2022\n",
    "authors": [
      "Jing Zhao",
      "Yifan Wang",
      "Junwei Bao",
      "Youzheng Wu",
      "Xiaodong He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09055"
  },
  {
    "id": "arXiv:2203.09056",
    "title": "Robust Table Detection and Structure Recognition from Heterogeneous  Document Images",
    "abstract": "We introduce a new table detection and structure recognition approach named\nRobusTabNet to detect the boundaries of tables and reconstruct the cellular\nstructure of the table from heterogeneous document images. For table detection,\nwe propose to use CornerNet as a new region proposal network to generate higher\nquality table proposals for Faster R-CNN, which has significantly improved the\nlocalization accuracy of Faster R-CNN for table detection. Consequently, our\ntable detection approach achieves state-of-the-art performance on three public\ntable detection benchmarks, namely cTDaR TrackA, PubLayNet and IIIT-AR-13K, by\nonly using a lightweight ResNet-18 backbone network. Furthermore, we propose a\nnew split-and-merge based table structure recognition approach, in which a\nnovel spatial CNN based separation line prediction module is proposed to split\neach detected table into a grid of cells, and a Grid CNN based cell merging\nmodule is applied to recover the spanning cells. As the spatial CNN module can\neffectively propagate contextual information across the whole table image, our\ntable structure recognizer can robustly recognize tables with large blank\nspaces and geometrically distorted (even curved) tables. Thanks to these two\ntechniques, our table structure recognition approach achieves state-of-the-art\nperformance on three public benchmarks, including SciTSR, PubTabNet and cTDaR\nTrackB. Moreover, we have further demonstrated the advantages of our approach\nin recognizing tables with complex structures, large blank spaces, empty or\nspanning cells as well as geometrically distorted or even curved tables on a\nmore challenging in-house dataset.",
    "descriptor": "",
    "authors": [
      "Chixiang Ma",
      "Weihong Lin",
      "Lei Sun",
      "Qiang Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09056"
  },
  {
    "id": "arXiv:2203.09057",
    "title": "A Real-Time Millimeter Wave V2V Channel Sounder",
    "abstract": "Wireless communication in millimeter wave spectrum is poised to provide the\nlatency and bandwidth needed for advanced use cases unfeasible at lower\nfrequencies. Despite the market potential of vehicular communication networks,\ninvestigations into the millimeter wave vehicular channel are lacking. In this\npaper, we present a detailed overview of a novel 1 GHz wide, multi-antenna\nvehicle to vehicle directional channel sounding and measurement platform\noperating at 28 GHz. The channel sounder uses two 256-element phased arrays at\nthe transmitter vehicle and four 64-element arrays at the receiver vehicle,\nwith the receiver measuring 116 different directional beams in less than 1\nmillisecond. By measuring the full multi-beam channel impulse response at large\nbandwidths, our system provides unprecedented insight in instantaneous mobile\nvehicle to vehicle channels. The system also uses centimeter-level global\nposition tracking and 360 degree video capture to provide additional contextual\ninformation for joint communication and sensing applications. An initial\nmeasurement campaign was conducted on highway and surface streets in Austin,\nTexas. We show example data that highlights the sensing capability of the\nsystem. Preliminary results from the measurement campaign show that bumper\nmounted mmWave arrays provide rich scattering in traffic as well a provide\nsignificant directional diversity aiding towards high reliability vehicular\ncommunication. Additionally, potential waveguide effects from high traffic in\nlanes can also extend the range of mmWave signals significantly.",
    "descriptor": "\nComments: 2022 IEEE Wireless Communications and Networking Conference (WCNC)\n",
    "authors": [
      "Aditya Chopra",
      "Andrew Thornburg",
      "Ojas Kanhere",
      "Saeed S. Ghassemzadeh",
      "Milap Majmundar",
      "Theodore S. Rappaport"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.09057"
  },
  {
    "id": "arXiv:2203.09063",
    "title": "Hierarchical Intention Tracking for Robust Human-Robot Collaboration in  Industrial Assembly Tasks",
    "abstract": "Collaborative robots require effective intention estimation to safely and\nsmoothly work with humans in less structured tasks such as industrial assembly.\nDuring these tasks, human intention continuously changes across multiple steps,\nand is composed of a hierarchy including high-level interactive intention and\nlow-level task intention. Thus, we propose the concept of intention tracking\nand introduce a collaborative robot system with a hierarchical framework that\nconcurrently tracks intentions at both levels by observing force/torque\nmeasurements, robot state sequences, and tracked human trajectories. The\nhigh-level intention estimate enables the robot to both (1) safely avoid\ncollision with the human to minimize interruption and (2) cooperatively\napproach the human and help recover from an assembly failure through admittance\ncontrol. The low-level intention estimate provides the robot with task-specific\ninformation (e.g., which part the human is working on) for concurrent task\nexecution. We implement the system on a UR5e robot, and demonstrate robust,\nseamless and ergonomic collaboration between the human and the robot in an\nassembly use case through an ablative pilot study.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Zhe Huang",
      "Ye-Ji Mun",
      "Xiang Li",
      "Yiqing Xie",
      "Ninghan Zhong",
      "Weihang Liang",
      "Junyi Geng",
      "Tan Chen",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09063"
  },
  {
    "id": "arXiv:2203.09064",
    "title": "Attribute Surrogates Learning and Spectral Tokens Pooling in  Transformers for Few-shot Learning",
    "abstract": "This paper presents new hierarchically cascaded transformers that can improve\ndata efficiency through attribute surrogates learning and spectral tokens\npooling. Vision transformers have recently been thought of as a promising\nalternative to convolutional neural networks for visual recognition. But when\nthere is no sufficient data, it gets stuck in overfitting and shows inferior\nperformance. To improve data efficiency, we propose hierarchically cascaded\ntransformers that exploit intrinsic image structures through spectral tokens\npooling and optimize the learnable parameters through latent attribute\nsurrogates. The intrinsic image structure is utilized to reduce the ambiguity\nbetween foreground content and background noise by spectral tokens pooling. And\nthe attribute surrogate learning scheme is designed to benefit from the rich\nvisual information in image-label pairs instead of simple visual concepts\nassigned by their labels. Our Hierarchically Cascaded Transformers, called\nHCTransformers, is built upon a self-supervised learning framework DINO and is\ntested on several popular few-shot learning benchmarks.\nIn the inductive setting, HCTransformers surpass the DINO baseline by a large\nmargin of 9.7% 5-way 1-shot accuracy and 9.17% 5-way 5-shot accuracy on\nminiImageNet, which demonstrates HCTransformers are efficient to extract\ndiscriminative features. Also, HCTransformers show clear advantages over SOTA\nfew-shot classification methods in both 5-way 1-shot and 5-way 5-shot settings\non four popular benchmark datasets, including miniImageNet, tieredImageNet,\nFC100, and CIFAR-FS. The trained weights and codes are available at\nhttps://github.com/StomachCold/HCTransformers.",
    "descriptor": "\nComments: To appear in CVPR 2022, codes are released at this https URL\n",
    "authors": [
      "Yangji He",
      "Weihan Liang",
      "Dongyang Zhao",
      "Hong-Yu Zhou",
      "Weifeng Ge",
      "Yizhou Yu",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09064"
  },
  {
    "id": "arXiv:2203.09065",
    "title": "STPLS3D: A Large-Scale Synthetic and Real Aerial Photogrammetry 3D Point  Cloud Dataset",
    "abstract": "Although various 3D datasets with different functions and scales have been\nproposed recently, it remains challenging for individuals to complete the whole\npipeline of large-scale data collection, sanitization, and annotation.\nMoreover, the created datasets usually suffer from extremely imbalanced class\ndistribution or partial low-quality data samples. Motivated by this, we explore\nthe procedurally synthetic 3D data generation paradigm to equip individuals\nwith the full capability of creating large-scale annotated photogrammetry point\nclouds. Specifically, we introduce a synthetic aerial photogrammetry point\nclouds generation pipeline that takes full advantage of open geospatial data\nsources and off-the-shelf commercial packages. Unlike generating synthetic data\nin virtual games, where the simulated data usually have limited gaming\nenvironments created by artists, the proposed pipeline simulates the\nreconstruction process of the real environment by following the same UAV flight\npattern on different synthetic terrain shapes and building densities, which\nensure similar quality, noise pattern, and diversity with real data. In\naddition, the precise semantic and instance annotations can be generated fully\nautomatically, avoiding the expensive and time-consuming manual annotation.\nBased on the proposed pipeline, we present a richly-annotated synthetic 3D\naerial photogrammetry point cloud dataset, termed STPLS3D, with more than 16\n$km^2$ of landscapes and up to 18 fine-grained semantic categories. For\nverification purposes, we also provide a parallel dataset collected from four\nareas in the real environment. Extensive experiments conducted on our datasets\ndemonstrate the effectiveness and quality of the proposed synthetic dataset.",
    "descriptor": "",
    "authors": [
      "Meida Chen",
      "Qingyong Hu",
      "Thomas Hugues",
      "Andrew Feng",
      "Yu Hou",
      "Kyle McCullough",
      "Lucio Soibelman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09065"
  },
  {
    "id": "arXiv:2203.09067",
    "title": "UNIMO-2: End-to-End Unified Vision-Language Grounded Learning",
    "abstract": "Vision-Language Pre-training (VLP) has achieved impressive performance on\nvarious cross-modal downstream tasks. However, most existing methods can only\nlearn from aligned image-caption data and rely heavily on expensive regional\nfeatures, which greatly limits their scalability and performance. In this\npaper, we propose an end-to-end unified-modal pre-training framework, namely\nUNIMO-2, for joint learning on both aligned image-caption data and unaligned\nimage-only and text-only corpus. We build a unified Transformer model to\njointly learn visual representations, textual representations and semantic\nalignment between images and texts. In particular, we propose to conduct\ngrounded learning on both images and texts via a sharing grounded space, which\nhelps bridge unaligned images and texts, and align the visual and textual\nsemantic spaces on different types of corpora. The experiments show that our\ngrounded learning method can improve textual and visual semantic alignment for\nimproving performance on various cross-modal tasks. Moreover, benefiting from\neffective joint modeling of different types of corpora, our model also achieves\nimpressive performance on single-modal visual and textual tasks. Our code and\nmodels are public at the UNIMO project page https://unimo-ptm.github.io/.",
    "descriptor": "\nComments: Accepted by ACL2022\n",
    "authors": [
      "Wei Li",
      "Can Gao",
      "Guocheng Niu",
      "Xinyan Xiao",
      "Hao Liu",
      "Jiachen Liu",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09067"
  },
  {
    "id": "arXiv:2203.09070",
    "title": "Proactive Posturing of Large Power Grid for Mitigating Hurricane Impacts",
    "abstract": "In the past decade, natural disasters such as hurricanes have challenged the\noperation and control of U.S. power grid. It is crucial to develop proactive\nstrategies to assist grid operators for better emergency response and minimized\nelectricity service interruptions; the better the grid may be preserved, the\nfaster the grid can be restored. In this paper, we propose a proactive\nposturing of power system elements, and formulate a Security-Constrained\nOptimal Power Flow (SCOPF) informed by cross-domain hurricane modeling as well\nas its potential impacts on grid elements. Simulation results based on\nreal-world power grid and historical hurricane event have verified the\napplicability of the proposed optimization formulation, which shows potential\nto enable grid operators and planners with interactive cross-domain data\nanalytics for mitigating hurricane impacts.",
    "descriptor": "\nComments: 5 pages, 2 figures, 1 table\n",
    "authors": [
      "Edward Quarm Jnr.",
      "Xiaoyuan Fan",
      "Marcelo Elizondo",
      "Ramtin Madani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.09070"
  },
  {
    "id": "arXiv:2203.09072",
    "title": "Gaussian Multi-head Attention for Simultaneous Machine Translation",
    "abstract": "Simultaneous machine translation (SiMT) outputs translation while receiving\nthe streaming source inputs, and hence needs a policy to determine where to\nstart translating. The alignment between target and source words often implies\nthe most informative source word for each target word, and hence provides the\nunified control over translation quality and latency, but unfortunately the\nexisting SiMT methods do not explicitly model the alignment to perform the\ncontrol. In this paper, we propose Gaussian Multi-head Attention (GMA) to\ndevelop a new SiMT policy by modeling alignment and translation in a unified\nmanner. For SiMT policy, GMA models the aligned source position of each target\nword, and accordingly waits until its aligned position to start translating. To\nintegrate the learning of alignment into the translation model, a Gaussian\ndistribution centered on predicted aligned position is introduced as an\nalignment-related prior, which cooperates with translation-related soft\nattention to determine the final attention. Experiments on En-Vi and De-En\ntasks show that our method outperforms strong baselines on the trade-off\nbetween translation and latency.",
    "descriptor": "\nComments: Accept to ACL 2022 findings. 12 pages, 8 figures\n",
    "authors": [
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09072"
  },
  {
    "id": "arXiv:2203.09073",
    "title": "Ask to Understand: Question Generation for Multi-hop Question Answering",
    "abstract": "Multi-hop Question Answering (QA) requires the machine to answer complex\nquestions by finding scattering clues and reasoning from multiple documents.\nGraph Network (GN) and Question Decomposition (QD) are two common approaches at\npresent. The former uses the \"black-box\" reasoning process to capture the\npotential relationship between entities and sentences, thus achieving good\nperformance. At the same time, the latter provides a clear reasoning logical\nroute by decomposing multi-hop questions into simple single-hop sub-questions.\nIn this paper, we propose a novel method to complete multi-hop QA from the\nperspective of Question Generation (QG). Specifically, we carefully design an\nend-to-end QG module on the basis of a classical QA module, which could help\nthe model understand the context by asking inherently logical sub-questions,\nthus inheriting interpretability from the QD-based method and showing superior\nperformance. Experiments on the HotpotQA dataset demonstrate that the\neffectiveness of our proposed QG module, human evaluation further clarifies its\ninterpretability quantitatively, and thorough analysis shows that the QG module\ncould generate better sub-questions than QD methods in terms of fluency,\nconsistency, and diversity.",
    "descriptor": "\nComments: 10 pages, Work-in-Progress\n",
    "authors": [
      "Jiawei Li",
      "Mucheng Ren",
      "Yang Gao",
      "Yizhe Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09073"
  },
  {
    "id": "arXiv:2203.09074",
    "title": "Numerical simulations of semi-linear Klein-Gordon equations in the de  Sitter spacetime with structure preserving scheme",
    "abstract": "We perform some simulations of the Klein-Gordon equation in the de Sitter\nspacetime. We reported the stable and high-precision numerical results of the\nequation using the structure preserving scheme (SPS) in an earlier publication\n(Tsuchiya and Nakamura in J. Comput. Appl. Math. 361: 396--412, 2019). To\ninvestigate the factors of the stability and accuracy of the simulations with\nSPS, we perform some simulations with three discretized formulations. The first\nformulation is the discretized equations with SPS, the second is with SPS which\nreplaced the second derivative term as the standard difference, and the third\nis with SPS which replaced the non-linear term as the standard expression. As a\nresult, the above two replacements in SPS are found to be effective for stable\nand high-precision simulations.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Takuya Tsuchiya",
      "Makoto Nakamura"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.09074"
  },
  {
    "id": "arXiv:2203.09081",
    "title": "Do We Really Need a Learnable Classifier at the End of Deep Neural  Network?",
    "abstract": "Modern deep neural networks for classification usually jointly learn a\nbackbone for representation and a linear classifier to output the logit of each\nclass. A recent study has shown a phenomenon called neural collapse that the\nwithin-class means of features and the classifier vectors converge to the\nvertices of a simplex equiangular tight frame (ETF) at the terminal phase of\ntraining on a balanced dataset. Since the ETF geometric structure maximally\nseparates the pair-wise angles of all classes in the classifier, it is natural\nto raise the question, why do we spend an effort to learn a classifier when we\nknow its optimal geometric structure? In this paper, we study the potential of\nlearning a neural network for classification with the classifier randomly\ninitialized as an ETF and fixed during training. Our analytical work based on\nthe layer-peeled model indicates that the feature learning with a fixed ETF\nclassifier naturally leads to the neural collapse state even when the dataset\nis imbalanced among classes. We further show that in this case the cross\nentropy (CE) loss is not necessary and can be replaced by a simple squared loss\nthat shares the same global optimality but enjoys a more accurate gradient and\nbetter convergence property. Our experimental results show that our method is\nable to achieve similar performances on image classification for balanced\ndatasets, and bring significant improvements in the long-tailed and\nfine-grained classification tasks.",
    "descriptor": "",
    "authors": [
      "Yibo Yang",
      "Liang Xie",
      "Shixiang Chen",
      "Xiangtai Li",
      "Zhouchen Lin",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09081"
  },
  {
    "id": "arXiv:2203.09082",
    "title": "Confidence Dimension for Deep Learning based on Hoeffding Inequality and  Relative Evaluation",
    "abstract": "Research on the generalization ability of deep neural networks (DNNs) has\nrecently attracted a great deal of attention. However, due to their complex\narchitectures and large numbers of parameters, measuring the generalization\nability of specific DNN models remains an open challenge. In this paper, we\npropose to use multiple factors to measure and rank the relative generalization\nof DNNs based on a new concept of confidence dimension (CD). Furthermore, we\nprovide a feasible framework in our CD to theoretically calculate the upper\nbound of generalization based on the conventional Vapnik-Chervonenk dimension\n(VC-dimension) and Hoeffding's inequality. Experimental results on image\nclassification and object detection demonstrate that our CD can reflect the\nrelative generalization ability for different DNNs. In addition to\nfull-precision DNNs, we also analyze the generalization ability of binary\nneural networks (BNNs), whose generalization ability remains an unsolved\nproblem. Our CD yields a consistent and reliable measure and ranking for both\nfull-precision DNNs and BNNs on all the tasks.",
    "descriptor": "",
    "authors": [
      "Runqi Wang",
      "Linlin Yang",
      "Baochang Zhang",
      "Wentao Zhu",
      "David Doermann",
      "Guodong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09082"
  },
  {
    "id": "arXiv:2203.09087",
    "title": "GPU Computation of the Euler Characteristic Curve for Imaging Data",
    "abstract": "Persistent homology is perhaps the most popular and useful tool offered by\ntopological data analysis, with point-cloud data being the most common setup.\nIts older cousin, the Euler characteristic curve (ECC) is less expressive, but\nfar easier to compute. It is particularly suitable for analyzing imaging data,\nand is commonly used in fields ranging from astrophysics to biomedical image\nanalysis. These fields are embracing GPU computations to handle increasingly\nlarge datasets. We therefore propose an optimized GPU implementation of ECC\ncomputation for 2D and 3D grayscale images. The goal of this paper is twofold.\nFirst, we offer a practical tool, illustrating its performance with thorough\nexperimentation, but also explain its inherent shortcomings. Second, this\nsimple algorithm serves as a perfect backdrop for highlighting basic GPU\nprogramming techniques that make our implementation so efficient, and some\ncommon pitfalls we avoided. This is intended as a step towards a wider usage of\nGPU programming in computational geometry and topology software. We find this\nis particularly important as geometric and topological tools are used in\nconjunction with modern, GPU-accelerated machine learning frameworks.",
    "descriptor": "\nComments: 17pages, 7 figures, SoCG2022\n",
    "authors": [
      "Fan Wang",
      "Hubert Wagner",
      "Chao Chen"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.09087"
  },
  {
    "id": "arXiv:2203.09088",
    "title": "Deep Point Cloud Simplification for High-quality Surface Reconstruction",
    "abstract": "The growing size of point clouds enlarges consumptions of storage,\ntransmission, and computation of 3D scenes. Raw data is redundant, noisy, and\nnon-uniform. Therefore, simplifying point clouds for achieving compact, clean,\nand uniform points is becoming increasingly important for 3D vision and\ngraphics tasks. Previous learning based methods aim to generate fewer points\nfor scene understanding, regardless of the quality of surface reconstruction,\nleading to results with low reconstruction accuracy and bad point distribution.\nIn this paper, we propose a novel point cloud simplification network (PCS-Net)\ndedicated to high-quality surface mesh reconstruction while maintaining\ngeometric fidelity. We first learn a sampling matrix in a feature-aware\nsimplification module to reduce the number of points. Then we propose a novel\ndouble-scale resampling module to refine the positions of the sampled points,\nto achieve a uniform distribution. To further retain important shape features,\nan adaptive sampling strategy with a novel saliency loss is designed. With our\nPCS-Net, the input non-uniform and noisy point cloud can be simplified in a\nfeature-aware manner, i.e., points near salient features are consolidated but\nstill with uniform distribution locally. Experiments demonstrate the\neffectiveness of our method and show that we outperform previous simplification\nor reconstruction-oriented upsampling methods.",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "Yuanqi Li",
      "Jianwei Guo",
      "Xinran Yang",
      "Shun Liu",
      "Jie Guo",
      "Xiaopeng Zhang",
      "Yanwen Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09088"
  },
  {
    "id": "arXiv:2203.09090",
    "title": "Energy-Efficient Power Control and Beamforming for Reconfigurable  Intelligent Surface-Aided Uplink IoT Networks",
    "abstract": "Recently, reconfigurable intelligent surface (RIS), a planar metasurface\nconsisting of a large number of low-cost reflecting elements, has received much\nattention due to its ability to improve both the spectrum and energy\nefficiencies by reconfiguring the wireless propagation environment. In this\npaper, we propose a RIS phase shift and BS beamforming optimization technique\nthat minimizes the uplink transmit power of a RIS-aided IoT network. Key idea\nof the proposed scheme, referred to as Riemannian conjugate gradient-based\njoint optimization (RCG-JO), is to jointly optimize the RIS phase shifts and\nthe BS beamforming vectors using the Riemannian conjugate gradient technique.\nBy exploiting the product Riemannian manifold structure of the sets of\nunit-modulus phase shifts and unit-norm beamforming vectors, we convert the\nnonconvex uplink power minimization problem into the unconstrained problem and\nthen find out the optimal solution on the product Riemannian manifold. From the\nperformance analysis and numerical evaluations, we demonstrate that the\nproposed RCG-JO technique achieves $94\\%$ reduction of the uplink transmit\npower over the conventional scheme without RIS.",
    "descriptor": "",
    "authors": [
      "Jiao Wu",
      "Seungnyun Kim",
      "Byonghyo Shim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.09090"
  },
  {
    "id": "arXiv:2203.09091",
    "title": "deepNIR: Datasets for generating synthetic NIR images and improved fruit  detection system using deep learning techniques",
    "abstract": "This paper presents datasets utilised for synthetic near-infrared (NIR) image\ngeneration and bounding-box level fruit detection systems. It is undeniable\nthat high-calibre machine learning frameworks such as Tensorflow or Pytorch,\nand large-scale ImageNet or COCO datasets with the aid of accelerated GPU\nhardware have pushed the limit of machine learning techniques for more than\ndecades. Among these breakthroughs, a high-quality dataset is one of the\nessential building blocks that can lead to success in model generalisation and\nthe deployment of data-driven deep neural networks. In particular, synthetic\ndata generation tasks often require more training samples than other supervised\napproaches. Therefore, in this paper, we share the NIR+RGB datasets that are\nre-processed from two public datasets (i.e., nirscene and SEN12MS) and our\nnovel NIR+RGB sweet pepper(capsicum) dataset. We quantitatively and\nqualitatively demonstrate that these NIR+RGB datasets are sufficient to be used\nfor synthetic NIR image generation. We achieved Frechet Inception Distance\n(FID) of 11.36, 26.53, and 40.15 for nirscene1, SEN12MS, and sweet pepper\ndatasets respectively. In addition, we release manual annotations of 11 fruit\nbounding boxes that can be exported as various formats using cloud service.\nFour newly added fruits [blueberry, cherry, kiwi, and wheat] compound 11 novel\nbounding box datasets on top of our previous work presented in the deepFruits\nproject [apple, avocado, capsicum, mango, orange, rockmelon, strawberry]. The\ntotal number of bounding box instances of the dataset is 162k and it is ready\nto use from cloud service. For the evaluation of the dataset, Yolov5 single\nstage detector is exploited and reported impressive\nmean-average-precision,mAP[0.5:0.95] results of[min:0.49, max:0.812]. We hope\nthese datasets are useful and serve as a baseline for the future studies.",
    "descriptor": "\nComments: 35 pages, 27 figures, submitted to MDPI Remote Sensing journal\n",
    "authors": [
      "Inkyu Sa",
      "JongYoon Lim",
      "Ho Seok Ahn",
      "Bruce MacDonald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09091"
  },
  {
    "id": "arXiv:2203.09093",
    "title": "Semantic-aligned Fusion Transformer for One-shot Object Detection",
    "abstract": "One-shot object detection aims at detecting novel objects according to merely\none given instance. With extreme data scarcity, current approaches explore\nvarious feature fusions to obtain directly transferable meta-knowledge. Yet,\ntheir performances are often unsatisfactory. In this paper, we attribute this\nto inappropriate correlation methods that misalign query-support semantics by\noverlooking spatial structures and scale variances. Upon analysis, we leverage\nthe attention mechanism and propose a simple but effective architecture named\nSemantic-aligned Fusion Transformer (SaFT) to resolve these issues.\nSpecifically, we equip SaFT with a vertical fusion module (VFM) for cross-scale\nsemantic enhancement and a horizontal fusion module (HFM) for cross-sample\nfeature fusion. Together, they broaden the vision for each feature point from\nthe support to a whole augmented feature pyramid from the query, facilitating\nsemantic-aligned associations. Extensive experiments on multiple benchmarks\ndemonstrate the superiority of our framework. Without fine-tuning on novel\nclasses, it brings significant performance gains to one-stage baselines,\nlifting state-of-the-art results to a higher level.",
    "descriptor": "",
    "authors": [
      "Yizhou Zhao",
      "Xun Guo",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09093"
  },
  {
    "id": "arXiv:2203.09095",
    "title": "CodeReviewer: Pre-Training for Automating Code Review Activities",
    "abstract": "Code review is an essential part to software development lifecycle since it\naims at guaranteeing the quality of codes. Modern code review activities\nnecessitate developers viewing, understanding and even running the programs to\nassess logic, functionality, latency, style and other factors. It turns out\nthat developers have to spend far too much time reviewing the code of their\npeers. Accordingly, it is in significant demand to automate the code review\nprocess. In this research, we focus on utilizing pre-training techniques for\nthe tasks in the code review scenario. We collect a large-scale dataset of real\nworld code changes and code reviews from open-source projects in nine of the\nmost popular programming languages. To better understand code diffs and\nreviews, we propose CodeReviewer, a pre-trained model that utilizes four\npre-training tasks tailored specifically for the code review senario. To\nevaluate our model, we focus on three key tasks related to code review\nactivities, including code change quality estimation, review comment generation\nand code refinement. Furthermore, we establish a high-quality benchmark dataset\nbased on our collected data for these three tasks and conduct comprehensive\nexperiments on it. The experimental results demonstrate that our model\noutperforms the previous state-of-the-art pre-training approaches in all tasks.\nFurther analysis show that our proposed pre-training tasks and the multilingual\npre-training dataset benefit the model on the understanding of code changes and\nreviews.",
    "descriptor": "\nComments: Preprint; 17 pages\n",
    "authors": [
      "Zhiyu Li",
      "Shuai Lu",
      "Daya Guo",
      "Nan Duan",
      "Shailesh Jannu",
      "Grant Jenks",
      "Deep Majumder",
      "Jared Green",
      "Alexey Svyatkovskiy",
      "Shengyu Fu",
      "Neel Sundaresan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09095"
  },
  {
    "id": "arXiv:2203.09096",
    "title": "DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression  for Real-World Clinical Applications",
    "abstract": "The ability to predict the future trajectory of a patient is a key step\ntoward the development of therapeutics for complex diseases such as Alzheimer's\ndisease (AD). However, most machine learning approaches developed for\nprediction of disease progression are either single-task or single-modality\nmodels, which can not be directly adopted to our setting involving multi-task\nlearning with high dimensional images. Moreover, most of those approaches are\ntrained on a single dataset (i.e. cohort), which can not be generalized to\nother cohorts. We propose a novel multimodal multi-task deep learning model to\npredict AD progression by analyzing longitudinal clinical and neuroimaging data\nfrom multiple cohorts. Our proposed model integrates high dimensional MRI\nfeatures from a 3D convolutional neural network with other data modalities,\nincluding clinical and demographic information, to predict the future\ntrajectory of patients. Our model employs an adversarial loss to alleviate the\nstudy-specific imaging bias, in particular the inter-study domain shifts. In\naddition, a Sharpness-Aware Minimization (SAM) optimization technique is\napplied to further improve model generalization. The proposed model is trained\nand tested on various datasets in order to evaluate and validate the results.\nOur results showed that 1) our model yields significant improvement over the\nbaseline models, and 2) models using extracted neuroimaging features from 3D\nconvolutional neural network outperform the same models when applied to\nMRI-derived volumetric features.",
    "descriptor": "",
    "authors": [
      "Somaye Hashemifar",
      "Claudia Iriondo",
      "Evan Casey",
      "Mohsen Hejrat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.09096"
  },
  {
    "id": "arXiv:2203.09098",
    "title": "TMS: A Temporal Multi-scale Backbone Design for Speaker Embedding",
    "abstract": "Speaker embedding is an important front-end module to explore discriminative\nspeaker features for many speech applications where speaker information is\nneeded. Current SOTA backbone networks for speaker embedding are designed to\naggregate multi-scale features from an utterance with multi-branch network\narchitectures for speaker representation. However, naively adding many branches\nof multi-scale features with the simple fully convolutional operation could not\nefficiently improve the performance due to the rapid increase of model\nparameters and computational complexity. Therefore, in the most current\nstate-of-the-art network architectures, only a few branches corresponding to a\nlimited number of temporal scales could be designed for speaker embeddings. To\naddress this problem, in this paper, we propose an effective temporal\nmulti-scale (TMS) model where multi-scale branches could be efficiently\ndesigned in a speaker embedding network almost without increasing computational\ncosts. The new model is based on the conventional TDNN, where the network\narchitecture is smartly separated into two modeling operators: a\nchannel-modeling operator and a temporal multi-branch modeling operator. Adding\ntemporal multi-scale in the temporal multi-branch operator needs only a little\nbit increase of the number of parameters, and thus save more computational\nbudget for adding more branches with large temporal scales. Moreover, in the\ninference stage, we further developed a systemic re-parameterization method to\nconvert the TMS-based model into a single-path-based topology in order to\nincrease inference speed. We investigated the performance of the new TMS method\nfor automatic speaker verification (ASV) on in-domain and out-of-domain\nconditions. Results show that the TMS-based model obtained a significant\nincrease in the performance over the SOTA ASV models, meanwhile, had a faster\ninference speed.",
    "descriptor": "\nComments: Due to the limitation \"The abstract field cannot be longer than 1,920 characters\", the abstract here is shorter than that in the PDF file\n",
    "authors": [
      "Ruiteng Zhang",
      "Jianguo Wei",
      "Xugang Lu",
      "Wenhuan Lu",
      "Di Jin",
      "Junhai Xu",
      "Lin Zhang",
      "Yantao Ji",
      "Jianwu Dang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.09098"
  },
  {
    "id": "arXiv:2203.09100",
    "title": "PLANET: Dynamic Content Planning in Autoregressive Transformers for  Long-form Text Generation",
    "abstract": "Despite recent progress of pre-trained language models on generating fluent\ntext, existing methods still suffer from incoherence problems in long-form text\ngeneration tasks that require proper content control and planning to form a\ncoherent high-level logical flow. In this work, we propose PLANET, a novel\ngeneration framework leveraging autoregressive self-attention mechanism to\nconduct content planning and surface realization dynamically. To guide the\ngeneration of output sentences, our framework enriches the Transformer decoder\nwith latent representations to maintain sentence-level semantic plans grounded\nby bag-of-words. Moreover, we introduce a new coherence-based contrastive\nlearning objective to further improve the coherence of output. Extensive\nexperiments are conducted on two challenging long-form text generation tasks\nincluding counterargument generation and opinion article generation. Both\nautomatic and human evaluations show that our method significantly outperforms\nstrong baselines and generates more coherent texts with richer contents.",
    "descriptor": "",
    "authors": [
      "Zhe Hu",
      "Hou Pong Chan",
      "Jiachen Liu",
      "Xinyan Xiao",
      "Hua Wu",
      "Lifu Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09100"
  },
  {
    "id": "arXiv:2203.09101",
    "title": "RelationPrompt: Leveraging Prompts to Generate Synthetic Data for  Zero-Shot Relation Triplet Extraction",
    "abstract": "Despite the importance of relation extraction in building and representing\nknowledge, less research is focused on generalizing to unseen relations types.\nWe introduce the task setting of Zero-Shot Relation Triplet Extraction\n(ZeroRTE) to encourage further research in low-resource relation extraction\nmethods. Given an input sentence, each extracted triplet consists of the head\nentity, relation label, and tail entity where the relation label is not seen at\nthe training stage. To solve ZeroRTE, we propose to synthesize relation\nexamples by prompting language models to generate structured texts. Concretely,\nwe unify language model prompts and structured text approaches to design a\nstructured prompt template for generating synthetic relation samples when\nconditioning on relation label prompts (RelationPrompt). To overcome the\nlimitation for extracting multiple relation triplets in a sentence, we design a\nnovel Triplet Search Decoding method. Experiments on FewRel and Wiki-ZSL\ndatasets show the efficacy of RelationPrompt for the ZeroRTE task and zero-shot\nrelation classification. Our code and data are available at\ngithub.com/declare-lab/RelationPrompt.",
    "descriptor": "\nComments: 13 pages, 9 figures, to appear in ACL Findings 2022\n",
    "authors": [
      "Yew Ken Chia",
      "Lidong Bing",
      "Soujanya Poria",
      "Luo Si"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09101"
  },
  {
    "id": "arXiv:2203.09103",
    "title": "Knowledge Graph-Enabled Text-Based Automatic Personality Prediction",
    "abstract": "How people think, feel, and behave, primarily is a representation of their\npersonality characteristics. By being conscious of personality characteristics\nof individuals whom we are dealing with or decided to deal with, one can\ncompetently ameliorate the relationship, regardless of its type. With the rise\nof Internet-based communication infrastructures (social networks, forums,\netc.), a considerable amount of human communications take place there. The most\nprominent tool in such communications, is the language in written and spoken\nform that adroitly encodes all those essential personality characteristics of\nindividuals. Text-based Automatic Personality Prediction (APP) is the automated\nforecasting of the personality of individuals based on the generated/exchanged\ntext contents. This paper presents a novel knowledge graph-enabled approach to\ntext-based APP that relies on the Big Five personality traits. To this end,\ngiven a text a knowledge graph which is a set of interlinked descriptions of\nconcepts, was built through matching the input text's concepts with DBpedia\nknowledge base entries. Then, due to achieving more powerful representation the\ngraph was enriched with the DBpedia ontology, NRC Emotion Intensity Lexicon,\nand MRC psycholinguistic database information. Afterwards, the knowledge graph\nwhich is now a knowledgeable alternative for the input text was embedded to\nyield an embedding matrix. Finally, to perform personality predictions the\nresulting embedding matrix was fed to four suggested deep learning models\nindependently, which are based on convolutional neural network (CNN), simple\nrecurrent neural network (RNN), long short term memory (LSTM) and bidirectional\nlong short term memory (BiLSTM). The results indicated a considerable\nimprovements in prediction accuracies in all of the suggested classifiers.",
    "descriptor": "",
    "authors": [
      "Majid Ramezani",
      "Mohammad-Reza Feizi-Derakhshi",
      "Mohammad-Ali Balafar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09103"
  },
  {
    "id": "arXiv:2203.09106",
    "title": "Parameterized and Exact Algorithms for Class Domination Coloring",
    "abstract": "A class domination coloring (also called cd-Coloring or dominated coloring)\nof a graph is a proper coloring in which every color class is contained in the\nneighbourhood of some vertex. The minimum number of colors required for any\ncd-coloring of $G$, denoted by $\\chi_{cd}(G)$, is called the class domination\nchromatic number (cd-chromatic number) of $G$. In this work, we consider two\nproblems associated with the cd-coloring of a graph in the context of exact\nexponential-time algorithms and parameterized complexity. (1) Given a graph $G$\non $n$ vertices, find its cd-chromatic number. (2) Given a graph $G$ and\nintegers $k$ and $q$, can we delete at most $k$ vertices such that the\ncd-chromatic number of the resulting graph is at most $q$? For the first\nproblem, we give an exact algorithm with running time $\\Oh(2^n n^4 \\log n)$.\nAlso, we show that the problem is \\FPT\\ with respect to the number $q$ of\ncolors as the parameter on chordal graphs. On graphs of girth at least 5, we\nshow that the problem also admits a kernel with $\\Oh(q^3)$ vertices. For the\nsecond (deletion) problem, we show \\NP-hardness for each $q \\geq 2$. Further,\non split graphs, we show that the problem is \\NP-hard if $q$ is a part of the\ninput and \\FPT\\ with respect to $k$ and $q$ as combined parameters. As\nrecognizing graphs with cd-chromatic number at most $q$ is \\NP-hard in general\nfor $q \\geq 4$, the deletion problem is unlikely to be \\FPT\\ when parameterized\nby the size of the deletion set on general graphs. We show fixed parameter\ntractability for $q \\in \\{2,3\\}$ using the known algorithms for finding a\nvertex cover and an odd cycle transversal as subroutines.",
    "descriptor": "",
    "authors": [
      "R. Krithika",
      "Ashutosh Rai",
      "Saket Saurabh",
      "Prafullkumar Tale"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.09106"
  },
  {
    "id": "arXiv:2203.09109",
    "title": "Community-Driven Comprehensive Scientific Paper Summarization: Insight  from cvpaper.challenge",
    "abstract": "The present paper introduces a group activity involving writing summaries of\nconference proceedings by volunteer participants. The rapid increase in\nscientific papers is a heavy burden for researchers, especially non-native\nspeakers, who need to survey scientific literature. To alleviate this problem,\nwe organized a group of non-native English speakers to write summaries of\npapers presented at a computer vision conference to share the knowledge of the\npapers read by the group. We summarized a total of 2,000 papers presented at\nthe Conference on Computer Vision and Pattern Recognition, a top-tier\nconference on computer vision, in 2019 and 2020. We quantitatively analyzed\nparticipants' selection regarding which papers they read among the many\navailable papers. The experimental results suggest that we can summarize a wide\nrange of papers without asking participants to read papers unrelated to their\ninterests.",
    "descriptor": "",
    "authors": [
      "Shintaro Yamamoto",
      "Hirokatsu Kataoka",
      "Ryota Suzuki",
      "Seitaro Shinagawa",
      "Shigeo Morishima"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09109"
  },
  {
    "id": "arXiv:2203.09114",
    "title": "Causal Robot Communication Inspired by Observational Learning Insights",
    "abstract": "Autonomous robots must communicate about their decisions to gain trust and\nacceptance. When doing so, robots must determine which actions are causal,\ni.e., which directly give rise to the desired outcome, so that these actions\ncan be included in explanations. In behavior learning in psychology, this sort\nof reasoning during an action sequence has been studied extensively in the\ncontext of imitation learning. And yet, these techniques and empirical insights\nare rarely applied to human-robot interaction (HRI). In this work, we discuss\nthe relevance of behavior learning insights for robot intent communication, and\npresent the first application of these insights for a robot to efficiently\ncommunicate its intent by selectively explaining the causal actions in an\naction sequence.",
    "descriptor": "\nComments: Appears in Proceedings of the AAAI SSS-22 Symposium \"Closing the Assessment Loop: Communicating Proficiency and Intent in Human-Robot Teaming\". Paper webpage: this https URL\n",
    "authors": [
      "Zhao Han",
      "Boyoung Kim",
      "Holly A. Yanco",
      "Tom Williams"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.09114"
  },
  {
    "id": "arXiv:2203.09116",
    "title": "MotionAug: Augmentation with Physical Correction for Human Motion  Prediction",
    "abstract": "This paper presents a motion data augmentation scheme incorporating motion\nsynthesis encouraging diversity and motion correction imposing physical\nplausibility. This motion synthesis consists of our modified Variational\nAutoEncoder (VAE) and Inverse Kinematics (IK). In this VAE, our proposed\nsampling-near-samples method generates various valid motions even with\ninsufficient training motion data. Our IK-based motion synthesis method allows\nus to generate a variety of motions semi-automatically. Since these two schemes\ngenerate unrealistic artifacts in the synthesized motions, our motion\ncorrection rectifies them. This motion correction scheme consists of imitation\nlearning with physics simulation and subsequent motion debiasing. For this\nimitation learning, we propose the PD-residual force that significantly\naccelerates the training process. Furthermore, our motion debiasing\nsuccessfully offsets the motion bias induced by imitation learning to maximize\nthe effect of augmentation. As a result, our method outperforms previous\nnoise-based motion augmentation methods by a large margin on both Recurrent\nNeural Network-based and Graph Convolutional Network-based human motion\nprediction models. The code is available at {\\rm\n\\url{https://github.com/meaten/MotionAug}}.",
    "descriptor": "",
    "authors": [
      "Takahiro Maeda",
      "Norimichi Ukita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09116"
  },
  {
    "id": "arXiv:2203.09118",
    "title": "Time and the Value of Data",
    "abstract": "Managers often believe that collecting more data will continually improve the\naccuracy of their machine learning models. However, we argue in this paper that\nwhen data lose relevance over time, it may be optimal to collect a limited\namount of recent data instead of keeping around an infinite supply of older\n(less relevant) data. In addition, we argue that increasing the stock of data\nby including older datasets may, in fact, damage the model's accuracy.\nExpectedly, the model's accuracy improves by increasing the flow of data\n(defined as data collection rate); however, it requires other tradeoffs in\nterms of refreshing or retraining machine learning models more frequently.\nUsing these results, we investigate how the business value created by machine\nlearning models scales with data and when the stock of data establishes a\nsustainable competitive advantage. We argue that data's time-dependency weakens\nthe barrier to entry that the stock of data creates. As a result, a competing\nfirm equipped with a limited (yet sufficient) amount of recent data can develop\nmore accurate models. This result, coupled with the fact that older datasets\nmay deteriorate models' accuracy, suggests that created business value doesn't\nscale with the stock of available data unless the firm offloads less relevant\ndata from its data repository. Consequently, a firm's growth policy should\nincorporate a balance between the stock of historical data and the flow of new\ndata.\nWe complement our theoretical results with an experiment. In the experiment,\nwe empirically measure the loss in the accuracy of a next word prediction model\ntrained on datasets from various time periods. Our empirical measurements\nconfirm the economic significance of the value decline over time. For example,\n100MB of text data, after seven years, becomes as valuable as 50MB of current\ndata for the next word prediction task.",
    "descriptor": "\nComments: 43 Pages, 8 Figures, Harvard Business School Working Paper 21-016\n",
    "authors": [
      "Ehsan Valavi",
      "Joel Hestness",
      "Newsha Ardalani",
      "Marco Iansiti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2203.09118"
  },
  {
    "id": "arXiv:2203.09119",
    "title": "False Negative Awareness in Indicator-based Caching Systems",
    "abstract": "Distributed caching systems such as content distribution networks often\nadvertise their content via lightweight approximate indicators (e.g., Bloom\nfilters) to efficiently inform clients where each datum is likely cached. While\nfalse-positive indications are necessary and well understood, most existing\nworks assume no false-negative indications. Our work illustrates practical\nscenarios where false-negatives are unavoidable and ignoring them significantly\nimpacts system performance. Specifically, we focus on false-negatives induced\nby indicator staleness, which arises whenever the system advertises the\nindicator only periodically, rather than immediately reporting every change in\nthe cache. Such scenarios naturally occur, e.g., in bandwidth-constraint\nenvironments or when latency impedes each client's ability to obtain an updated\nindicator. Our work introduces novel false-negative aware access policies that\ncontinuously estimate the false-negative ratio and sometimes access caches\ndespite negative indications. We present optimal policies for homogeneous\nsettings and provide approximation guarantees for our algorithms in\nheterogeneous environments. We further perform an extensive simulation study\nwith multiple real system traces. We show that our false-negative aware\nalgorithms incur a significantly lower access cost than existing approaches or\nmatch the cost of these approaches while requiring an order of magnitude fewer\nresources (e.g., caching capacity or bandwidth).",
    "descriptor": "",
    "authors": [
      "Itamar Cohen",
      "Gil Einziger",
      "Gabriel Scalosub"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.09119"
  },
  {
    "id": "arXiv:2203.09121",
    "title": "DRAG: Dynamic Region-Aware GCN for Privacy-Leaking Image Detection",
    "abstract": "The daily practice of sharing images on social media raises a severe issue\nabout privacy leakage. To address the issue, privacy-leaking image detection is\nstudied recently, with the goal to automatically identify images that may leak\nprivacy. Recent advance on this task benefits from focusing on crucial objects\nvia pretrained object detectors and modeling their correlation. However, these\nmethods have two limitations: 1) they neglect other important elements like\nscenes, textures, and objects beyond the capacity of pretrained object\ndetectors; 2) the correlation among objects is fixed, but a fixed correlation\nis not appropriate for all the images. To overcome the limitations, we propose\nthe Dynamic Region-Aware Graph Convolutional Network (DRAG) that dynamically\nfinds out crucial regions including objects and other important elements, and\nmodels their correlation adaptively for each input image. To find out crucial\nregions, we cluster spatially-correlated feature channels into several\nregion-aware feature maps. Further, we dynamically model the correlation with\nthe self-attention mechanism and explore the interaction among the regions with\na graph convolutional network. The DRAG achieved an accuracy of 87% on the\nlargest dataset for privacy-leaking image detection, which is 10 percentage\npoints higher than the state of the art. The further case study demonstrates\nthat it found out crucial regions containing not only objects but other\nimportant elements like textures.",
    "descriptor": "\nComments: Accepted to AAAI-22, 9 pages\n",
    "authors": [
      "Guang Yang",
      "Juan Cao",
      "Qiang Sheng",
      "Peng Qi",
      "Xirong Li",
      "Jintao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09121"
  },
  {
    "id": "arXiv:2203.09123",
    "title": "Improving the Transferability of Targeted Adversarial Examples through  Object-Based Diverse Input",
    "abstract": "The transferability of adversarial examples allows the deception on black-box\nmodels, and transfer-based targeted attacks have attracted a lot of interest\ndue to their practical applicability. To maximize the transfer success rate,\nadversarial examples should avoid overfitting to the source model, and image\naugmentation is one of the primary approaches for this. However, prior works\nutilize simple image transformations such as resizing, which limits input\ndiversity. To tackle this limitation, we propose the object-based diverse input\n(ODI) method that draws an adversarial image on a 3D object and induces the\nrendered image to be classified as the target class. Our motivation comes from\nthe humans' superior perception of an image printed on a 3D object. If the\nimage is clear enough, humans can recognize the image content in a variety of\nviewing conditions. Likewise, if an adversarial example looks like the target\nclass to the model, the model should also classify the rendered image of the 3D\nobject as the target class. The ODI method effectively diversifies the input by\nleveraging an ensemble of multiple source objects and randomizing viewing\nconditions. In our experimental results on the ImageNet-Compatible dataset,\nthis method boosts the average targeted attack success rate from 28.3% to 47.0%\ncompared to the state-of-the-art methods. We also demonstrate the applicability\nof the ODI method to adversarial examples on the face verification task and its\nsuperior performance improvement. Our code is available at\nhttps://github.com/dreamflake/ODI.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Junyoung Byun",
      "Seungju Cho",
      "Myung-Joon Kwon",
      "Hee-Seon Kim",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09123"
  },
  {
    "id": "arXiv:2203.09125",
    "title": "Are Vision Transformers Robust to Spurious Correlations?",
    "abstract": "Deep neural networks may be susceptible to learning spurious correlations\nthat hold on average but not in atypical test samples. As with the recent\nemergence of vision transformer (ViT) models, it remains underexplored how\nspurious correlations are manifested in such architectures. In this paper, we\nsystematically investigate the robustness of vision transformers to spurious\ncorrelations on three challenging benchmark datasets and compare their\nperformance with popular CNNs. Our study reveals that when pre-trained on a\nsufficiently large dataset, ViT models are more robust to spurious correlations\nthan CNNs. Key to their success is the ability to generalize better from the\nexamples where spurious correlations do not hold. Further, we perform extensive\nablations and experiments to understand the role of the self-attention\nmechanism in providing robustness under spuriously correlated environments. We\nhope that our work will inspire future research on further understanding the\nrobustness of ViT models.",
    "descriptor": "",
    "authors": [
      "Soumya Suvra Ghosal",
      "Yifei Ming",
      "Yixuan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09125"
  },
  {
    "id": "arXiv:2203.09126",
    "title": "Conversational Recommendation: A Grand AI Challenge",
    "abstract": "Animated avatars, which look and talk like humans, are iconic visions of the\nfuture of AI-powered systems. Through many sci-fi movies we are acquainted with\nthe idea of speaking to such virtual personalities as if they were humans.\nToday, we talk more and more to machines like Apple's Siri, e.g., to ask them\nfor the weather forecast. However, when asked for recommendations, e.g., for a\nrestaurant to go to, the limitations of such devices quickly become obvious.\nThey do not engage in a conversation to find out what we might prefer, they\noften do not provide explanations for what they recommend, and they may have\ndifficulties remembering what was said one minute earlier. Conversational\nrecommender systems promise to address these limitations. In this paper, we\nreview existing approaches to build such systems, which developments we observe\ntoday, which challenges are still open and why the development of\nconversational recommenders represents one of the next grand challenges of AI.",
    "descriptor": "",
    "authors": [
      "Dietmar Jannach",
      "Li Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.09126"
  },
  {
    "id": "arXiv:2203.09127",
    "title": "POLARIS: A Geographic Pre-trained Model and its Applications in Baidu  Maps",
    "abstract": "Pre-trained models (PTMs) have become a fundamental backbone for downstream\ntasks in natural language processing and computer vision. Despite initial gains\nthat were obtained by applying generic PTMs to geo-related tasks at Baidu Maps,\na clear performance plateau over time was observed. One of the main reasons for\nthis plateau is the lack of readily available geographic knowledge in generic\nPTMs. To address this problem, in this paper, we present POLARIS, which is a\ngeographic pre-trained model designed and developed for improving the\ngeo-related tasks at Baidu Maps. POLARIS is elaborately designed to learn a\nuniversal representation of geography-language by pre-training on large-scale\ndata generated from a heterogeneous graph that contains abundant geographic\nknowledge. Extensive quantitative and qualitative experiments conducted on\nlarge-scale real-world datasets demonstrate the superiority and effectiveness\nof POLARIS. POLARIS has already been deployed in production at Baidu Maps since\nApril 2021, which significantly benefits the performance of a wide range of\ndownstream tasks. This demonstrates that POLARIS can serve as a fundamental\nbackbone for geo-related tasks.",
    "descriptor": "\nComments: Submitted to KDD 2022 ADS Track\n",
    "authors": [
      "Huang Jizhou",
      "Wang Haifeng",
      "Sun Yibo",
      "Shi Yunsheng",
      "Huang Zhengjie",
      "Zhuo An",
      "Feng Shikun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09127"
  },
  {
    "id": "arXiv:2203.09128",
    "title": "Time Dependency, Data Flow, and Competitive Advantage",
    "abstract": "Data is fundamental to machine learning-based products and services and is\nconsidered strategic due to its externalities for businesses, governments,\nnon-profits, and more generally for society. It is renowned that the value of\norganizations (businesses, government agencies and programs, and even\nindustries) scales with the volume of available data. What is often less\nappreciated is that the data value in making useful organizational predictions\nwill range widely and is prominently a function of data characteristics and\nunderlying algorithms.\nIn this research, our goal is to study how the value of data changes over\ntime and how this change varies across contexts and business areas (e.g. next\nword prediction in the context of history, sports, politics). We focus on data\nfrom Reddit.com and compare the value's time-dependency across various Reddit\ntopics (Subreddits). We make this comparison by measuring the rate at which\nuser-generated text data loses its relevance to the algorithmic prediction of\nconversations. We show that different subreddits have different rates of\nrelevance decline over time.\nRelating the text topics to various business areas of interest, we argue that\ncompeting in a business area in which data value decays rapidly alters\nstrategies to acquire competitive advantage. When data value decays rapidly,\naccess to a continuous flow of data will be more valuable than access to a\nfixed stock of data. In this kind of setting, improving user engagement and\nincreasing user-base help creating and maintaining a competitive advantage.",
    "descriptor": "\nComments: 24 Pages\n",
    "authors": [
      "Ehsan Valavi",
      "Joel Hestness",
      "Marco Iansiti",
      "Newsha Ardalani",
      "Feng Zhu",
      "Karim R. Lakhani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2203.09128"
  },
  {
    "id": "arXiv:2203.09129",
    "title": "Contrastive Learning with Positive-Negative Frame Mask for Music  Representation",
    "abstract": "Self-supervised learning, especially contrastive learning, has made an\noutstanding contribution to the development of many deep learning research\nfields. Recently, researchers in the acoustic signal processing field noticed\nits success and leveraged contrastive learning for better music representation.\nTypically, existing approaches maximize the similarity between two distorted\naudio segments sampled from the same music. In other words, they ensure a\nsemantic agreement at the music level. However, those coarse-grained methods\nneglect some inessential or noisy elements at the frame level, which may be\ndetrimental to the model to learn the effective representation of music.\nTowards this end, this paper proposes a novel Positive-nEgative frame mask for\nMusic Representation based on the contrastive learning framework, abbreviated\nas PEMR. Concretely, PEMR incorporates a Positive-Negative Mask Generation\nmodule, which leverages transformer blocks to generate frame masks on the\nLog-Mel spectrogram. We can generate self-augmented negative and positive\nsamples by masking important components or inessential components,\nrespectively. We devise a novel contrastive learning objective to accommodate\nboth self-augmented positives/negatives sampled from the same music. We conduct\nexperiments on four public datasets. The experimental results of two\nmusic-related downstream tasks, music classification, and cover song\nidentification, demonstrate the generalization ability and transferability of\nmusic representation learned by PEMR.",
    "descriptor": "\nComments: Accepted by WWW2022\n",
    "authors": [
      "Dong Yao",
      "Zhou Zhao",
      "Shengyu Zhang",
      "Jieming Zhu",
      "Yudong Zhu",
      "Rui Zhang",
      "Xiuqiang He"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.09129"
  },
  {
    "id": "arXiv:2203.09134",
    "title": "An Empirical Study of Bugs in Eclipse Stable Internal Interfaces",
    "abstract": "The Eclipse framework is a popular and widely used framework that has been\nevolving for over a decade. The framework provides both stable interfaces\n(APIs) and unstable interfaces (non-APIs). Despite being discouraged by\nEclipse, application developers often use non-APIs which cause their systems to\nfail when ported to new framework releases. Previous studies showed that\napplications using relatively old non-APIs are more likely to be compatible\nwith new releases compared to the ones that used newly introduced non-APIs.\nFurthermore, from our previous study about the stability of Eclipse internal\ninterfaces, we discovered that there exist 327K stable non-API methods as the\nEclipse framework evolves. In the same study, we recommended that 327K stable\nnon-API methods can be used by Eclipse interface providers as possible\ncandidates for promotion to stable interfaces. However since non-APIs are\nunsupported and considered to be immature i.e. can contain bugs, to this end\nthere exist a need to first investigate the stable non-APIs for possible bugs\nbefore they can be promoted to APIs. In this study, we empirically investigated\nthe stable non-API for possible bugs using Sonarqube software quality tool. We\ndiscovered that over 79.8% classes containing old stable non-APIs methods have\nzero bugs. These results can be used by both interface providers and users as a\nstarting point to analyze which interfaces are well tested and also estimate\nhow much work could be involved when performing bug fixing for a given eclipse\nrelease.",
    "descriptor": "",
    "authors": [
      "Simon Kawuma",
      "Evarist Nabaasa"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.09134"
  },
  {
    "id": "arXiv:2203.09135",
    "title": "Mutual Generative Transformer Learning for Cross-view Geo-localization",
    "abstract": "Cross-view geo-localization (CVGL), which aims to estimate the geographical\nlocation of the ground-level camera by matching against enormous geo-tagged\naerial (e.g., satellite) images, remains extremely challenging due to the\ndrastic appearance differences across views. Existing methods mainly employ\nSiamese-like CNNs to extract global descriptors without examining the mutual\nbenefits between the two modes. In this paper, we present a novel approach\nusing cross-modal knowledge generative tactics in combination with transformer,\nnamely mutual generative transformer learning (MGTL), for CVGL. Specifically,\nMGTL develops two separate generative modules--one for aerial-like knowledge\ngeneration from ground-level semantic information and vice versa--and fully\nexploits their mutual benefits through the attention mechanism. Experiments on\nchallenging public benchmarks, CVACT and CVUSA, demonstrate the effectiveness\nof the proposed method compared to the existing state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Jianwei Zhao",
      "Qiang Zhai",
      "Rui Huang",
      "Hong Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09135"
  },
  {
    "id": "arXiv:2203.09136",
    "title": "Type-Driven Multi-Turn Corrections for Grammatical Error Correction",
    "abstract": "Grammatical Error Correction (GEC) aims to automatically detect and correct\ngrammatical errors. In this aspect, dominant models are trained by\none-iteration learning while performing multiple iterations of corrections\nduring inference. Previous studies mainly focus on the data augmentation\napproach to combat the exposure bias, which suffers from two drawbacks. First,\nthey simply mix additionally-constructed training instances and original ones\nto train models, which fails to help models be explicitly aware of the\nprocedure of gradual corrections. Second, they ignore the interdependence\nbetween different types of corrections. In this paper, we propose a Type-Driven\nMulti-Turn Corrections approach for GEC. Using this approach, from each\ntraining instance, we additionally construct multiple training instances, each\nof which involves the correction of a specific type of errors. Then, we use\nthese additionally-constructed training instances and the original one to train\nthe model in turn. Experimental results and in-depth analysis show that our\napproach significantly benefits the model training. Particularly, our enhanced\nmodel achieves state-of-the-art single-model performance on English GEC\nbenchmarks. We release our code at Github.",
    "descriptor": "\nComments: Findings of ACL2022\n",
    "authors": [
      "Shaopeng Lai",
      "Qingyu Zhou",
      "Jiali Zeng",
      "Zhongli Li",
      "Chao Li",
      "Yunbo Cao",
      "Jinsong Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09136"
  },
  {
    "id": "arXiv:2203.09137",
    "title": "Global Convergence of MAML and Theory-Inspired Neural Architecture  Search for Few-Shot Learning",
    "abstract": "Model-agnostic meta-learning (MAML) and its variants have become popular\napproaches for few-shot learning. However, due to the non-convexity of deep\nneural nets (DNNs) and the bi-level formulation of MAML, the theoretical\nproperties of MAML with DNNs remain largely unknown. In this paper, we first\nprove that MAML with over-parameterized DNNs is guaranteed to converge to\nglobal optima at a linear rate. Our convergence analysis indicates that MAML\nwith over-parameterized DNNs is equivalent to kernel regression with a novel\nclass of kernels, which we name as Meta Neural Tangent Kernels (MetaNTK). Then,\nwe propose MetaNTK-NAS, a new training-free neural architecture search (NAS)\nmethod for few-shot learning that uses MetaNTK to rank and select\narchitectures. Empirically, we compare our MetaNTK-NAS with previous NAS\nmethods on two popular few-shot learning benchmarks, miniImageNet, and\ntieredImageNet. We show that the performance of MetaNTK-NAS is comparable or\nbetter than the state-of-the-art NAS method designed for few-shot learning\nwhile enjoying more than 100x speedup. We believe the efficiency of MetaNTK-NAS\nmakes itself more practical for many real-world tasks.",
    "descriptor": "\nComments: Accepted at CVPR 2022. The code will be released at this https URL Authors' note: This work has an overlap with our previous tech report, arXiv:2006.14606\n",
    "authors": [
      "Haoxiang Wang",
      "Yite Wang",
      "Ruoyu Sun",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09137"
  },
  {
    "id": "arXiv:2203.09138",
    "title": "MuKEA: Multimodal Knowledge Extraction and Accumulation for  Knowledge-based Visual Question Answering",
    "abstract": "Knowledge-based visual question answering requires the ability of associating\nexternal knowledge for open-ended cross-modal scene understanding. One\nlimitation of existing solutions is that they capture relevant knowledge from\ntext-only knowledge bases, which merely contain facts expressed by first-order\npredicates or language descriptions while lacking complex but indispensable\nmultimodal knowledge for visual understanding. How to construct vision-relevant\nand explainable multimodal knowledge for the VQA scenario has been less\nstudied. In this paper, we propose MuKEA to represent multimodal knowledge by\nan explicit triplet to correlate visual objects and fact answers with implicit\nrelations. To bridge the heterogeneous gap, we propose three objective losses\nto learn the triplet representations from complementary views: embedding\nstructure, topological relation and semantic space. By adopting a pre-training\nand fine-tuning learning strategy, both basic and domain-specific multimodal\nknowledge are progressively accumulated for answer prediction. We outperform\nthe state-of-the-art by 3.35% and 6.08% respectively on two challenging\nknowledge-required datasets: OK-VQA and KRVQA. Experimental results prove the\ncomplementary benefits of the multimodal knowledge with existing knowledge\nbases and the advantages of our end-to-end framework over the existing pipeline\nmethods. The code is available at https://github.com/AndersonStra/MuKEA.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Yang Ding",
      "Jing Yu",
      "Bang Liu",
      "Yue Hu",
      "Mingxin Cui",
      "Qi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.09138"
  },
  {
    "id": "arXiv:2203.09140",
    "title": "Harmonic Pole Placement",
    "abstract": "In this paper, we propose a method to design state feedback harmonic control\nlaws that assign the closed loop poles of a linear harmonic model to some\ndesired locations. The procedure is based on the solution of an\ninfinite-dimensional harmonic Sylvester equation under an invertibility\nconstraint. We provide a sufficient condition to ensure this invertibility and\nshow how this infinite-dimensional Sylvester equation can be solved up to an\narbitrary small error. The results are illustrated on an unstable linear\nperiodic system. We also provide a counterexample to illustrate the fact that,\nunlike the classical finite dimensional case, the solution of the Sylvester\nequation may not be invertible in the infinite dimensional case even if an\nobservability condition is satisfied.",
    "descriptor": "",
    "authors": [
      "Pierre Riedinger",
      "Jamal Daafouz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.09140"
  },
  {
    "id": "arXiv:2203.09141",
    "title": "Graph Representation Learning with Individualization and Refinement",
    "abstract": "Graph Neural Networks (GNNs) have emerged as prominent models for\nrepresentation learning on graph structured data. GNNs follow an approach of\nmessage passing analogous to 1-dimensional Weisfeiler Lehman (1-WL) test for\ngraph isomorphism and consequently are limited by the distinguishing power of\n1-WL. More expressive higher-order GNNs which operate on k-tuples of nodes need\nincreased computational resources in order to process higher-order tensors.\nInstead of the WL approach, in this work, we follow the classical approach of\nIndividualization and Refinement (IR), a technique followed by most practical\nisomorphism solvers. Individualization refers to artificially distinguishing a\nnode in the graph and refinement is the propagation of this information to\nother nodes through message passing. We learn to adaptively select nodes to\nindividualize and to aggregate the resulting graphs after refinement to help\nhandle the complexity. Our technique lets us learn richer node embeddings while\nkeeping the computational complexity manageable. Theoretically, we show that\nour procedure is more expressive than the 1-WL test. Experiments show that our\nmethod outperforms prominent 1-WL GNN models as well as competitive\nhigher-order baselines on several benchmark synthetic and real datasets.\nFurthermore, our method opens new doors for exploring the paradigm of learning\non graph structures with individualization and refinement.",
    "descriptor": "",
    "authors": [
      "Mohammed Haroon Dupty",
      "Wee Sun Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09141"
  },
  {
    "id": "arXiv:2203.09142",
    "title": "Covid19 Reproduction Number: Credibility Intervals by Blockwise Proximal  Monte Carlo Samplers",
    "abstract": "Monitoring the Covid19 pandemic constitutes a critical societal stake that\nreceived considerable research efforts. The intensity of the pandemic on a\ngiven territory is efficiently measured by the reproduction number, quantifying\nthe rate of growth of daily new infections. Recently, estimates for the time\nevolution of the reproduction number were produced using an inverse problem\nformulation with a nonsmooth functional minimization. While it was designed to\nbe robust to the limited quality of the Covid19 data (outliers, missing\ncounts), the procedure lacks the ability to output credibility interval based\nestimates. This remains a severe limitation for practical use in actual\npandemic monitoring by epidemiologists that the present work aims to overcome\nby use of Monte Carlo sampling. After interpretation of the functional into a\nBayesian framework, several sampling schemes are tailored to adjust the\nnonsmooth nature of the resulting posterior distribution. The originality of\nthe devised algorithms stems from combining a Langevin Monte Carlo sampling\nscheme with Proximal operators. Performance of the new algorithms in producing\nrelevant credibility intervals for the reproduction number estimates and\ndenoised counts are compared. Assessment is conducted on real daily new\ninfection counts made available by the Johns Hopkins University. The interest\nof the devised monitoring tools are illustrated on Covid19 data from several\ndifferent countries.",
    "descriptor": "",
    "authors": [
      "Gersende Fort",
      "Barbara Pascal",
      "Patrice Abry",
      "Nelly Pustelnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09142"
  },
  {
    "id": "arXiv:2203.09148",
    "title": "Prediction of speech intelligibility with DNN-based performance measures",
    "abstract": "This paper presents a speech intelligibility model based on automatic speech\nrecognition (ASR), combining phoneme probabilities from deep neural networks\n(DNN) and a performance measure that estimates the word error rate from these\nprobabilities. This model does not require the clean speech reference nor the\nword labels during testing as the ASR decoding step, which finds the most\nlikely sequence of words given phoneme posterior probabilities, is omitted. The\nmodel is evaluated via the root-mean-squared error between the predicted and\nobserved speech reception thresholds from eight normal-hearing listeners. The\nrecognition task consists of identifying noisy words from a German matrix\nsentence test. The speech material was mixed with eight noise maskers covering\ndifferent modulation types, from speech-shaped stationary noise to a\nsingle-talker masker. The prediction performance is compared to five\nestablished models and an ASR-model using word labels. Two combinations of\nfeatures and networks were tested. Both include temporal information either at\nthe feature level (amplitude modulation filterbanks and a feed-forward network)\nor captured by the architecture (mel-spectrograms and a time-delay deep neural\nnetwork, TDNN). The TDNN model is on par with the DNN while reducing the number\nof parameters by a factor of 37; this optimization allows parallel streams on\ndedicated hearing aid hardware as a forward-pass can be computed within the\n10ms of each frame. The proposed model performs almost as well as the\nlabel-based model and produces more accurate predictions than the baseline\nmodels.",
    "descriptor": "",
    "authors": [
      "Angel Mario Castro Martinez",
      "Constantin Spille",
      "Jana Ro\u00dfbach",
      "Birger Kollmeier",
      "Bernd T. Meyer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.09148"
  },
  {
    "id": "arXiv:2203.09149",
    "title": "Active Visuo-Haptic Object Shape Completion",
    "abstract": "Recent advancements in object shape completion have enabled impressive object\nreconstructions using only visual input. However, due to self-occlusion, the\nreconstructions have high uncertainty in the occluded object parts, which\nnegatively impacts the performance of downstream robotic tasks such as\ngrasping. In this work, we propose an active visuo-haptic shape completion\nmethod called Act-VH that actively computes where to touch the objects based on\nthe reconstruction uncertainty. Act-VH reconstructs objects from point clouds\nand calculates the reconstruction uncertainty using IGR, a recent\nstate-of-the-art implicit surface deep neural network. We experimentally\nevaluate the reconstruction accuracy of Act-VH against five baselines in\nsimulation and in the real world. We also propose a new simulation environment\nfor this purpose. The results show that Act-VH outperforms all baselines and\nthat an uncertainty-driven haptic exploration policy leads to higher\nreconstruction accuracy than a random policy and a policy driven by Gaussian\nProcess Implicit Surfaces. As a final experiment, we evaluate Act-VH and the\nbest reconstruction baseline on grasping 10 novel objects. The results show\nthat Act-VH reaches a significantly higher grasp success rate than the baseline\non all objects. Together, this work opens up the door for using active\nvisuo-haptic shape completion in more complex cluttered scenes.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Lukas Rustler",
      "Jens Lundell",
      "Jan Kristof Behrens",
      "Ville Kyrki",
      "Matej Hoffmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09149"
  },
  {
    "id": "arXiv:2203.09151",
    "title": "Optimal Rejection Function Meets Character Recognition Tasks",
    "abstract": "In this paper, we propose an optimal rejection method for rejecting ambiguous\nsamples by a rejection function. This rejection function is trained together\nwith a classification function under the framework of Learning-with-Rejection\n(LwR). The highlights of LwR are: (1) the rejection strategy is not heuristic\nbut has a strong background from a machine learning theory, and (2) the\nrejection function can be trained on an arbitrary feature space which is\ndifferent from the feature space for classification. The latter suggests we can\nchoose a feature space that is more suitable for rejection. Although the past\nresearch on LwR focused only on its theoretical aspect, we propose to utilize\nLwR for practical pattern classification tasks. Moreover, we propose to use\nfeatures from different CNN layers for classification and rejection. Our\nextensive experiments of notMNIST classification and character/non-character\nclassification demonstrate that the proposed method achieves better performance\nthan traditional rejection strategies.",
    "descriptor": "",
    "authors": [
      "Xiaotong Ji",
      "Yuchen Zheng",
      "Daiki Suehiro",
      "Seiichi Uchida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09151"
  },
  {
    "id": "arXiv:2203.09155",
    "title": "AdaSplats: Adaptative Splats from Semantic Point Cloud for Fast and  High-Fidelity LiDAR Simulation",
    "abstract": "LiDAR sensors provide rich 3D information about surrounding scenes and are\nbecoming increasingly important for autonomous vehicles' tasks, such as\nsemantic segmentation, object detection, and tracking. Being able to simulate a\nLiDAR sensor will accelerate the testing, validation, and deployment of\nautonomous vehicles while reducing the cost and eliminating the risks of\ntesting in real-world scenarios. To tackle the issue of simulating LiDAR data\nwith high fidelity, we present a pipeline that leverages real-world point\nclouds acquired by mobile mapping systems. Point-based geometry\nrepresentations, more specifically splats, have proven their ability to\naccurately model the underlying surface in very large point clouds. Showing the\nlimits of basic splatting, we introduce an adaptative splats generation method\nthat accurately models the underlying 3D geometry, especially for thin\nstructures. We have also developed a LiDAR simulation that is 200 times\nfaster-than-real-time by ray casting on GPU while focusing on efficiently\nhandling large point clouds. We test our LiDAR simulation in real-world\nconditions, showing qualitative and quantitative results against basic\nsplatting and meshing, demonstrating the superiority of our modeling technique.",
    "descriptor": "\nComments: 6 pages, 3 figures, 1 table\n",
    "authors": [
      "Jean Pierre Richa",
      "Jean-Emmanuel Deschaud",
      "Fran\u00e7ois Goulette",
      "Nicolas Dalmasso"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09155"
  },
  {
    "id": "arXiv:2203.09159",
    "title": "EMAKG: An Enhanced Version Of The Microsoft Academic Knowledge Graph",
    "abstract": "Scholarly knowledge graphs are valuable sources of information in several\nresearch fields. Despite the number of existing datasets related to\npublications and researchers, resource quality, coverage and accessibility are\nstill limited. This article presents the Enhanced Microsoft Academic Knowledge\nGraph, a large dataset of information about scientific publications and\ninvolved entities, and the methods developed to build it. Data includes\ngeographical information, researchers' collaborative networks and movements\nbetween institutions, academic-related metrics, and linguistic features. The\ndataset merges information from several data sources and has high temporal and\nspatial 7 coverage, allowing several use cases.",
    "descriptor": "",
    "authors": [
      "Laura Pollacci"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2203.09159"
  },
  {
    "id": "arXiv:2203.09160",
    "title": "Biasing Like Human: A Cognitive Bias Framework for Scene Graph  Generation",
    "abstract": "Scene graph generation is a sophisticated task because there is no specific\nrecognition pattern (e.g., \"looking at\" and \"near\" have no conspicuous\ndifference concerning vision, whereas \"near\" could occur between entities with\ndifferent morphology). Thus some scene graph generation methods are trapped\ninto most frequent relation predictions caused by capricious visual features\nand trivial dataset annotations. Therefore, recent works emphasized the\n\"unbiased\" approaches to balance predictions for a more informative scene\ngraph. However, human's quick and accurate judgments over relations between\nnumerous objects should be attributed to \"bias\" (i.e., experience and\nlinguistic knowledge) rather than pure vision. To enhance the model capability,\ninspired by the \"cognitive bias\" mechanism, we propose a novel 3-paradigms\nframework that simulates how humans incorporate the label linguistic features\nas guidance of vision-based representations to better mine hidden relation\npatterns and alleviate noisy visual propagation. Our framework is\nmodel-agnostic to any scene graph model. Comprehensive experiments prove our\nframework outperforms baseline modules in several metrics with minimum\nparameters increment and achieves new SOTA performance on Visual Genome\ndataset.",
    "descriptor": "",
    "authors": [
      "Xiaoguang Chang",
      "Teng Wang",
      "Changyin Sun",
      "Wenzhe Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09160"
  },
  {
    "id": "arXiv:2203.09161",
    "title": "How Many Data Samples is an Additional Instruction Worth?",
    "abstract": "Recently introduced instruction-paradigm empowers non-expert users to\nleverage NLP resources by defining a new task in natural language.\nInstruction-tuned models have significantly outperformed multitask learning\nmodels (without instruction); however they are far from state of the art task\nspecific models. Conventional approaches to improve model performance via\ncreating large datasets with lots of task instances or architectural/training\nchanges in model may not be feasible for non-expert users. However, they can\nwrite alternate instructions to represent an instruction task. Is\nInstruction-augumentation helpful? We augment a subset of tasks in NATURAL\nINSTRUCTIONS with additional instructions and find that these significantly\nimprove model performance (upto 35%) specially in low-data regime. Our results\nindicate that an additional instruction can be equivalent to ~40 instances on\naverage across our evaluation tasks.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Ravsehaj Singh Puri",
      "Swaroop Mishra",
      "Mihir Parmar",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09161"
  },
  {
    "id": "arXiv:2203.09163",
    "title": "Modeling Dual Read/Write Paths for Simultaneous Machine Translation",
    "abstract": "Simultaneous machine translation (SiMT) outputs the translation while reading\nthe source sentence and hence requires a policy to determine whether to wait\nfor the next source word (READ) or generate a target word (WRITE), the actions\nof which form a read/write path. Although the read/write path is essential to\nSiMT performance, there is no direct supervision given to the path in the\nexisting methods. In this paper, we propose a method of Dual Path SiMT which\nintroduces duality constraints to guide the read/write path. According to\nduality constraints, the read/write paths in source-to-target and\ntarget-to-source SiMT models can be mapped to each other. Therefore, the SiMT\nmodels in two directions are jointly optimized by forcing their read/write\npaths to satisfy the mapping relation. Experiments on En-Vi and De-En SiMT\ntasks show that our method can outperform strong baselines under all latency.",
    "descriptor": "\nComments: Accept to ACL 2022 main conference. 18 pages, 12 figures\n",
    "authors": [
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09163"
  },
  {
    "id": "arXiv:2203.09164",
    "title": "A Survey on Brain-Computer Interface and Related Applications",
    "abstract": "BCI systems are able to communicate directly between the brain and computer\nusing neural activity measurements without the involvement of muscle movements.\nFor BCI systems to be widely used by people with severe disabilities, long-term\nstudies of their real-world use are needed, along with effective and feasible\ndissemination models. In addition, the robustness of the BCI systems'\nperformance should be improved so they reach the same level of robustness as\nnatural muscle-based health monitoring. In this chapter, we review the recent\nBCI related studies, followed by the most relevant applications of BCI systems.\nWe also present the key issues and challenges which exist in regard to the BCI\nsystems and also provide future directions.",
    "descriptor": "",
    "authors": [
      "Krishna Pai",
      "Rakhee Kallimani",
      "Sridhar Iyer",
      "B.Uma Maheswari",
      "Rajashri Khanai",
      "Dattaprasad Torse"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.09164"
  },
  {
    "id": "arXiv:2203.09167",
    "title": "UWED: Unsigned Distance Field for Accurate 3D Scene Representation and  Completion",
    "abstract": "Scene Completion is the task of completing missing geometry from a partial\nscan of a scene. The majority of previous methods compute an implicit\nrepresentation from range data using a Truncated Signed Distance Function\n(TSDF) on a 3D grid as input to neural networks. The truncation limits but does\nnot remove the ambiguous cases introduced by the sign for non-closed surfaces.\nAs an alternative, we present an Unsigned Distance Function (UDF) called\nUnsigned Weighted Euclidean Distance (UWED) as input to the scene completion\nneural networks. UWED is simple and efficient as a surface representation, and\ncan be computed on any noisy point cloud without normals. To obtain the\nexplicit geometry, we present a method for extracting a point cloud from\ndiscretized UDF values on a regular grid. We compare different SDFs and UDFs\nfor the scene completion task on indoor and outdoor point clouds collected from\nRGB-D and LiDAR sensors and show improved completion using the proposed UWED\nfunction.",
    "descriptor": "\nComments: 14 pages, 6 figures, 2 tables\n",
    "authors": [
      "Jean Pierre Richa",
      "Jean-Emmanuel Deschaud",
      "Fran\u00e7ois Goulette",
      "Nicolas Dalmasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09167"
  },
  {
    "id": "arXiv:2203.09168",
    "title": "On the Pitfalls of Heteroscedastic Uncertainty Estimation with  Probabilistic Neural Networks",
    "abstract": "Capturing aleatoric uncertainty is a critical part of many machine learning\nsystems. In deep learning, a common approach to this end is to train a neural\nnetwork to estimate the parameters of a heteroscedastic Gaussian distribution\nby maximizing the logarithm of the likelihood function under the observed data.\nIn this work, we examine this approach and identify potential hazards\nassociated with the use of log-likelihood in conjunction with gradient-based\noptimizers. First, we present a synthetic example illustrating how this\napproach can lead to very poor but stable parameter estimates. Second, we\nidentify the culprit to be the log-likelihood loss, along with certain\nconditions that exacerbate the issue. Third, we present an alternative\nformulation, termed $\\beta$-NLL, in which each data point's contribution to the\nloss is weighted by the $\\beta$-exponentiated variance estimate. We show that\nusing an appropriate $\\beta$ largely mitigates the issue in our illustrative\nexample. Fourth, we evaluate this approach on a range of domains and tasks and\nshow that it achieves considerable improvements and performs more robustly\nconcerning hyperparameters, both in predictive RMSE and log-likelihood\ncriteria.",
    "descriptor": "\nComments: ICLR 2022 camera-ready version. Code available at this http URL\n",
    "authors": [
      "Maximilian Seitzer",
      "Arash Tavakoli",
      "Dimitrije Antic",
      "Georg Martius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09168"
  },
  {
    "id": "arXiv:2203.09170",
    "title": "Recurrent Neural Networks for Forecasting Time Series with Multiple  Seasonality: A Comparative Study",
    "abstract": "This paper compares recurrent neural networks (RNNs) with different types of\ngated cells for forecasting time series with multiple seasonality. The cells we\ncompare include classical long short term memory (LSTM), gated recurrent unit\n(GRU), modified LSTM with dilation, and two new cells we proposed recently,\nwhich are equipped with dilation and attention mechanisms. To model the\ntemporal dependencies of different scales, our RNN architecture has multiple\ndilated recurrent layers stacked with hierarchical dilations. The proposed RNN\nproduces both point forecasts and predictive intervals (PIs) for them. An\nempirical study concerning short-term electrical load forecasting for 35\nEuropean countries confirmed that the new gated cells with dilation and\nattention performed best.",
    "descriptor": "",
    "authors": [
      "Grzegorz Dudek",
      "Slawek Smyl",
      "Pawe\u0142 Pe\u0142ka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09170"
  },
  {
    "id": "arXiv:2203.09173",
    "title": "On Vision Features in Multimodal Machine Translation",
    "abstract": "Previous work on multimodal machine translation (MMT) has focused on the way\nof incorporating vision features into translation but little attention is on\nthe quality of vision models. In this work, we investigate the impact of vision\nmodels on MMT. Given the fact that Transformer is becoming popular in computer\nvision, we experiment with various strong models (such as Vision Transformer)\nand enhanced features (such as object-detection and image captioning). We\ndevelop a selective attention model to study the patch-level contribution of an\nimage in MMT. On detailed probing tasks, we find that stronger vision models\nare helpful for learning translation from the visual modality. Our results also\nsuggest the need of carefully examining MMT models, especially when current\nbenchmarks are small-scale and biased. Our code could be found at\n\\url{https://github.com/libeineu/fairseq_mmt}.",
    "descriptor": "\nComments: Long paper accepted by ACL2022 main conference\n",
    "authors": [
      "Bei Li",
      "Chuanhao Lv",
      "Zefan Zhou",
      "Tao Zhou",
      "Tong Xiao",
      "Anxiang Ma",
      "JingBo Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09173"
  },
  {
    "id": "arXiv:2203.09174",
    "title": "Nearest Neighbor Classifier with Margin Penalty for Active Learning",
    "abstract": "As deep learning becomes the mainstream in the field of natural language\nprocessing, the need for suitable active learning method are becoming\nunprecedented urgent. Active Learning (AL) methods based on nearest neighbor\nclassifier are proposed and demonstrated superior results. However, existing\nnearest neighbor classifier are not suitable for classifying mutual exclusive\nclasses because inter-class discrepancy cannot be assured by nearest neighbor\nclassifiers. As a result, informative samples in the margin area can not be\ndiscovered and AL performance are damaged. To this end, we propose a novel\nNearest neighbor Classifier with Margin penalty for Active Learning(NCMAL).\nFirstly, mandatory margin penalty are added between classes, therefore both\ninter-class discrepancy and intra-class compactness are both assured. Secondly,\na novel sample selection strategy are proposed to discover informative samples\nwithin the margin area. To demonstrate the effectiveness of the methods, we\nconduct extensive experiments on for datasets with other state-of-the-art\nmethods. The experimental results demonstrate that our method achieves better\nresults with fewer annotated samples than all baseline methods.",
    "descriptor": "",
    "authors": [
      "Yuan Cao",
      "Zhiqiao Gao",
      "Jie Hu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09174"
  },
  {
    "id": "arXiv:2203.09175",
    "title": "Generalized Classification of Satellite Image Time Series with Thermal  Positional Encoding",
    "abstract": "Large-scale crop type classification is a task at the core of remote sensing\nefforts with applications of both economic and ecological importance. Current\nstate-of-the-art deep learning methods are based on self-attention and use\nsatellite image time series (SITS) to discriminate crop types based on their\nunique growth patterns. However, existing methods generalize poorly to regions\nnot seen during training mainly due to not being robust to temporal shifts of\nthe growing season caused by variations in climate. To this end, we propose\nThermal Positional Encoding (TPE) for attention-based crop classifiers. Unlike\nprevious positional encoding based on calendar time (e.g. day-of-year), TPE is\nbased on thermal time, which is obtained by accumulating daily average\ntemperatures over the growing season. Since crop growth is directly related to\nthermal time, but not calendar time, TPE addresses the temporal shifts between\ndifferent regions to improve generalization. We propose multiple TPE\nstrategies, including learnable methods, to further improve results compared to\nthe common fixed positional encodings. We demonstrate our approach on a crop\nclassification task across four different European regions, where we obtain\nstate-of-the-art generalization results.",
    "descriptor": "\nComments: In review\n",
    "authors": [
      "Joachim Nyborg",
      "Charlotte Pelletier",
      "Ira Assent"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09175"
  },
  {
    "id": "arXiv:2203.09176",
    "title": "ODE Transformer: An Ordinary Differential Equation-Inspired Model for  Sequence Generation",
    "abstract": "Residual networks are an Euler discretization of solutions to Ordinary\nDifferential Equations (ODE). This paper explores a deeper relationship between\nTransformer and numerical ODE methods. We first show that a residual block of\nlayers in Transformer can be described as a higher-order solution to ODE.\nInspired by this, we design a new architecture, {\\it ODE Transformer}, which is\nanalogous to the Runge-Kutta method that is well motivated in ODE. As a natural\nextension to Transformer, ODE Transformer is easy to implement and efficient to\nuse. Experimental results on the large-scale machine translation, abstractive\nsummarization, and grammar error correction tasks demonstrate the high\ngenericity of ODE Transformer. It can gain large improvements in model\nperformance over strong baselines (e.g., 30.77 and 44.11 BLEU scores on the\nWMT'14 English-German and English-French benchmarks) at a slight cost in\ninference efficiency.",
    "descriptor": "\nComments: Long paper accepted by ACL2022 main conference\n",
    "authors": [
      "Bei Li",
      "Quan Du",
      "Tao Zhou",
      "Yi Jing",
      "Shuhan Zhou",
      "Xin Zeng",
      "Tong Xiao",
      "JingBo Zhu",
      "Xuebo Liu",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09176"
  },
  {
    "id": "arXiv:2203.09178",
    "title": "Multilingual Detection of Personal Employment Status on Twitter",
    "abstract": "Detecting disclosures of individuals' employment status on social media can\nprovide valuable information to match job seekers with suitable vacancies,\noffer social protection, or measure labor market flows. However, identifying\nsuch personal disclosures is a challenging task due to their rarity in a sea of\nsocial media content and the variety of linguistic forms used to describe them.\nHere, we examine three Active Learning (AL) strategies in real-world settings\nof extreme class imbalance, and identify five types of disclosures about\nindividuals' employment status (e.g. job loss) in three languages using\nBERT-based classification models. Our findings show that, even under extreme\nimbalance settings, a small number of AL iterations is sufficient to obtain\nlarge and significant gains in precision, recall, and diversity of results\ncompared to a supervised baseline with the same number of labels. We also find\nthat no AL strategy consistently outperforms the rest. Qualitative analysis\nsuggests that AL helps focus the attention mechanism of BERT on core terms and\nadjust the boundaries of semantic expansion, highlighting the importance of\ninterpretable models to provide greater control and visibility into this\ndynamic learning process.",
    "descriptor": "\nComments: ACL 2022 main conference. Data and models available at this https URL\n",
    "authors": [
      "Manuel Tonneau",
      "Dhaval Adjodah",
      "Jo\u00e3o Palotti",
      "Nir Grinberg",
      "Samuel Fraiberger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09178"
  },
  {
    "id": "arXiv:2203.09181",
    "title": "An Interactive Explanatory AI System for Industrial Quality Control",
    "abstract": "Machine learning based image classification algorithms, such as deep neural\nnetwork approaches, will be increasingly employed in critical settings such as\nquality control in industry, where transparency and comprehensibility of\ndecisions are crucial. Therefore, we aim to extend the defect detection task\ntowards an interactive human-in-the-loop approach that allows us to integrate\nrich background knowledge and the inference of complex relationships going\nbeyond traditional purely data-driven approaches. We propose an approach for an\ninteractive support system for classifications in an industrial quality control\nsetting that combines the advantages of both (explainable) knowledge-driven and\ndata-driven machine learning methods, in particular inductive logic programming\nand convolutional neural networks, with human expertise and control. The\nresulting system can assist domain experts with decisions, provide transparent\nexplanations for results, and integrate feedback from users; thus reducing\nworkload for humans while both respecting their expertise and without removing\ntheir agency or accountability.",
    "descriptor": "\nComments: to be published in AAAI 2022\n",
    "authors": [
      "Dennis M\u00fcller",
      "Michael M\u00e4rz",
      "Stephan Scheele",
      "Ute Schmid"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.09181"
  },
  {
    "id": "arXiv:2203.09183",
    "title": "RoMe: A Robust Metric for Evaluating Natural Language Generation",
    "abstract": "Evaluating Natural Language Generation (NLG) systems is a challenging task.\nFirstly, the metric should ensure that the generated hypothesis reflects the\nreference's semantics. Secondly, it should consider the grammatical quality of\nthe generated sentence. Thirdly, it should be robust enough to handle various\nsurface forms of the generated sentence. Thus, an effective evaluation metric\nhas to be multifaceted. In this paper, we propose an automatic evaluation\nmetric incorporating several core aspects of natural language understanding\n(language competence, syntactic and semantic variation). Our proposed metric,\nRoMe, is trained on language features such as semantic similarity combined with\ntree edit distance and grammatical acceptability, using a self-supervised\nneural network to assess the overall quality of the generated sentence.\nMoreover, we perform an extensive robustness analysis of the state-of-the-art\nmethods and RoMe. Empirical results suggest that RoMe has a stronger\ncorrelation to human judgment over state-of-the-art metrics in evaluating\nsystem-generated sentences across several NLG tasks.",
    "descriptor": "\nComments: Accepted by the Association for Computational Linguistics (ACL) 2022\n",
    "authors": [
      "Md Rashad Al Hasan Rony",
      "Liubov Kovriguina",
      "Debanjan Chaudhuri",
      "Ricardo Usbeck",
      "Jens Lehmann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09183"
  },
  {
    "id": "arXiv:2203.09185",
    "title": "Phase Optimization for Massive IRS-aided Two-way Relay Network",
    "abstract": "In this paper, with the help of an intelligent reflecting surface (IRS), the\nsource (S) and destination (D) exchange information through the two-way\ndecode-and-forward relay (TW-DFR). We mainly focus on the phase optimization of\nIRS to improve the system rate performance. Firstly, a maximizing receive power\nsum (Max-RPS) method is proposed via eigenvalue decomposition (EVD) with an\nappreciable rate enhancement, which is called Max-RPS-EVD. To further achieve a\nhigher rate, a method of maximizing minimum rate (Max-Min-R) is proposed with\nhigh complexity. To reduce its complexity, a low-complexity method of\nmaximizing the sum rate (Max-SR) via general power iterative (GPI) is proposed,\nwhich is called Max-SR-GPI. Simulation results show that the proposed three\nmethods outperform the case of random phase method, especially the proposed\nMax-SR-GPI method is the best one achieving at least 20\\% rate gain over random\nphase. Additionally, it is also proved the optimal rate can be achieved when\nTW-DFR and IRS are located in the middle of S and D.",
    "descriptor": "\nComments: 5 pages,4 figures\n",
    "authors": [
      "Peng Zhang",
      "Xuehui Wang",
      "Siling Feng",
      "Zhongwen Sun",
      "Feng Shu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.09185"
  },
  {
    "id": "arXiv:2203.09191",
    "title": "Abstract Interpretation on E-Graphs",
    "abstract": "Recent e-graph applications have typically considered concrete semantics of\nexpressions, where the notion of equivalence stems from concrete interpretation\nof expressions. However, equivalences that hold over one interpretation may not\nhold in an alternative interpretation. Such an observation can be exploited. We\nconsider the application of abstract interpretation to e-graphs, and show that\nwithin an e-graph, the lattice meet operation associated with the abstract\ndomain has a natural interpretation for an e-class, leading to improved\nprecision in over-approximation. In this extended abstract, we use Interval\nArithmetic (IA) to illustrate this point.",
    "descriptor": "",
    "authors": [
      "Samuel Coward",
      "George A. Constantinides",
      "Theo Drane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09191"
  },
  {
    "id": "arXiv:2203.09192",
    "title": "Entropy-based Attention Regularization Frees Unintended Bias Mitigation  from Lists",
    "abstract": "Natural Language Processing (NLP) models risk overfitting to specific terms\nin the training data, thereby reducing their performance, fairness, and\ngeneralizability. E.g., neural hate speech detection models are strongly\ninfluenced by identity terms like gay, or women, resulting in false positives,\nsevere unintended bias, and lower performance. Most mitigation techniques use\nlists of identity terms or samples from the target domain during training.\nHowever, this approach requires a-priori knowledge and introduces further bias\nif important terms are neglected. Instead, we propose a knowledge-free\nEntropy-based Attention Regularization (EAR) to discourage overfitting to\ntraining-specific terms. An additional objective function penalizes tokens with\nlow self-attention entropy. We fine-tune BERT via EAR: the resulting model\nmatches or exceeds state-of-the-art performance for hate speech classification\nand bias metrics on three benchmark corpora in English and Italian. EAR also\nreveals overfitting terms, i.e., terms most likely to induce bias, to help\nidentify their effect on the model, task, and predictions.",
    "descriptor": "\nComments: Accepted to Findings of ACL 2022\n",
    "authors": [
      "Giuseppe Attanasio",
      "Debora Nozza",
      "Dirk Hovy",
      "Elena Baralis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09192"
  },
  {
    "id": "arXiv:2203.09193",
    "title": "DISMISS: Database of Indian Social Media Influencers (Snowballed  Sequentially) on Twitter",
    "abstract": "Databases of highly networked individuals have been indispensable in studying\nnarratives and influence on social media. To support studies on Twitter in\nIndia, we present a systematically categorised database of accounts of\ninfluence on Twitter in India, identified and annotated through an iterative\nprocess of friends, networks, and self-described profile information, verified\nmanually. We built an initial set of accounts based on the friend network of a\nseed set of accounts based on real-world renown in various fields, and then\nsnowballed \"friends of friends\" multiple times, and rank ordered individuals\nbased on the number of in-group connections, and overall followers. We then\nmanually classified identified accounts under the categories of entertainment,\nsports, business, government, institutions, journalism, civil society accounts\nthat have independent standing outside of social media, as well as a category\nof \"digital first\" referring to accounts that derive their primary influence\nfrom online activity. Overall, we annotated 11580 unique accounts across all\ncategories. The database is useful studying various questions related to the\nrole of influencers in polarisation, misinformation, extreme speech, political\ndiscourse etc.",
    "descriptor": "\nComments: 7 pages (incl. references), 2 figures, 3 tables\n",
    "authors": [
      "Arshia Arya",
      "Soham De",
      "Dibyendu Mishra",
      "Gazal Shekhawat",
      "Ankur Sharma",
      "Anmol Panda",
      "Faisal Lalani",
      "Parantak Singh",
      "Ramaravind Kommiya Mothilal",
      "Rynaa Grover",
      "Sachita Nishal",
      "Saloni Dash",
      "Shehla Shora",
      "Syeda Zainab Akbar",
      "Joyojeet Pal"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.09193"
  },
  {
    "id": "arXiv:2203.09195",
    "title": "Details or Artifacts: A Locally Discriminative Learning Approach to  Realistic Image Super-Resolution",
    "abstract": "Single image super-resolution (SISR) with generative adversarial networks\n(GAN) has recently attracted increasing attention due to its potentials to\ngenerate rich details. However, the training of GAN is unstable, and it often\nintroduces many perceptually unpleasant artifacts along with the generated\ndetails. In this paper, we demonstrate that it is possible to train a GAN-based\nSISR model which can stably generate perceptually realistic details while\ninhibiting visual artifacts. Based on the observation that the local statistics\n(e.g., residual variance) of artifact areas are often different from the areas\nof perceptually friendly details, we develop a framework to discriminate\nbetween GAN-generated artifacts and realistic details, and consequently\ngenerate an artifact map to regularize and stabilize the model training\nprocess. Our proposed locally discriminative learning (LDL) method is simple\nyet effective, which can be easily plugged in off-the-shelf SISR methods and\nboost their performance. Experiments demonstrate that LDL outperforms the\nstate-of-the-art GAN based SISR methods, achieving not only higher\nreconstruction accuracy but also superior perceptual quality on both synthetic\nand real-world datasets. Codes and models are available at\nhttps://github.com/csjliang/LDL.",
    "descriptor": "\nComments: To appear at CVPR 2022\n",
    "authors": [
      "Jie Liang",
      "Hui Zeng",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09195"
  },
  {
    "id": "arXiv:2203.09204",
    "title": "Investigation of Physics-Informed Deep Learning for the Prediction of  Parametric, Three-Dimensional Flow Based on Boundary Data",
    "abstract": "The placement of temperature sensitive and safety-critical components is\ncrucial in the automotive industry. It is therefore inevitable, even at the\ndesign stage of new vehicles that these components are assessed for potential\nsafety issues. However, with increasing number of design proposals, risk\nassessment quickly becomes expensive. We therefore present a parameterized\nsurrogate model for the prediction of three-dimensional flow fields in\naerothermal vehicle simulations. The proposed physics-informed neural network\n(PINN) design is aimed at learning families of flow solutions according to a\ngeometric variation. In scope of this work, we could show that our\nnondimensional, multivariate scheme can be efficiently trained to predict the\nvelocity and pressure distribution for different design scenarios and geometric\nscales. The proposed algorithm is based on a parametric minibatch training\nwhich enables the utilization of large datasets necessary for the\nthree-dimensional flow modeling. Further, we introduce a continuous resampling\nalgorithm that allows to operate on one static dataset. Every feature of our\nmethodology is tested individually and verified against conventional CFD\nsimulations. Finally, we apply our proposed method in context of an exemplary\nreal-world automotive application.",
    "descriptor": "\nComments: Reference to code and dataset are DOIs.The DOIs will be activated when article is reviewed. Until then please contact Philip Heger or Daniel Hilger if you wish for code and datasets\n",
    "authors": [
      "Philip Heger",
      "Markus Full",
      "Daniel Hilger",
      "Norbert Hosters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.09204"
  },
  {
    "id": "arXiv:2203.09205",
    "title": "SoK: Differential Privacy on Graph-Structured Data",
    "abstract": "In this work, we study the applications of differential privacy (DP) in the\ncontext of graph-structured data. We discuss the formulations of DP applicable\nto the publication of graphs and their associated statistics as well as machine\nlearning on graph-based data, including graph neural networks (GNNs). The\nformulation of DP in the context of graph-structured data is difficult, as\nindividual data points are interconnected (often non-linearly or sparsely).\nThis connectivity complicates the computation of individual privacy loss in\ndifferentially private learning. The problem is exacerbated by an absence of a\nsingle, well-established formulation of DP in graph settings. This issue\nextends to the domain of GNNs, rendering private machine learning on\ngraph-structured data a challenging task. A lack of prior systematisation work\nmotivated us to study graph-based learning from a privacy perspective. In this\nwork, we systematise different formulations of DP on graphs, discuss challenges\nand promising applications, including the GNN domain. We compare and separate\nworks into graph analysis tasks and graph learning tasks with GNNs. Finally, we\nconclude our work with a discussion of open questions and potential directions\nfor further research in this area.",
    "descriptor": "",
    "authors": [
      "Tamara T. Mueller",
      "Dmitrii Usynin",
      "Johannes C. Paetzold",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09205"
  },
  {
    "id": "arXiv:2203.09208",
    "title": "Neural Compression-Based Feature Learning for Video Restoration",
    "abstract": "How to efficiently utilize the temporal features is crucial, yet challenging,\nfor video restoration. The temporal features usually contain various noisy and\nuncorrelated information, and they may interfere with the restoration of the\ncurrent frame. This paper proposes learning noise-robust feature\nrepresentations to help video restoration. We are inspired by that the neural\ncodec is a natural denoiser. In neural codec, the noisy and uncorrelated\ncontents which are hard to predict but cost lots of bits are more inclined to\nbe discarded for bitrate saving. Therefore, we design a neural compression\nmodule to filter the noise and keep the most useful information in features for\nvideo restoration. To achieve robustness to noise, our compression module\nadopts a spatial-channel-wise quantization mechanism to adaptively determine\nthe quantization step size for each position in the latent. Experiments show\nthat our method can significantly boost the performance on video denoising,\nwhere we obtain 0.13 dB improvement over BasicVSR++ with only 0.23x FLOPs.\nMeanwhile, our method also obtains SOTA results on video deraining and\ndehazing.",
    "descriptor": "\nComments: Accpedted by CVPR 2022\n",
    "authors": [
      "Cong Huang",
      "Jiahao Li",
      "Bin Li",
      "Dong Liu",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09208"
  },
  {
    "id": "arXiv:2203.09210",
    "title": "Universal Conditional Masked Language Pre-training for Neural Machine  Translation",
    "abstract": "Pre-trained sequence-to-sequence models have significantly improved Neural\nMachine Translation (NMT). Different from prior works where pre-trained models\nusually adopt an unidirectional decoder, this paper demonstrates that\npre-training a sequence-to-sequence model but with a bidirectional decoder can\nproduce notable performance gains for both Autoregressive and\nNon-autoregressive NMT. Specifically, we propose CeMAT, a conditional masked\nlanguage model pre-trained on large-scale bilingual and monolingual corpora in\nmany languages. We also introduce two simple but effective methods to enhance\nthe CeMAT, aligned code-switching & masking and dynamic dual-masking. We\nconduct extensive experiments and show that our CeMAT can achieve significant\nperformance improvement for all scenarios from low to extremely high resource,\ni.e., up to 14.4 BLEU on low resource and 7.9 BLEU improvements on average for\nAutoregressive NMT. For Non-autoregressive NMT, we demonstrate it can also\nproduce consistent performance gains, i.e., up to 5.3 BLEU. As far as we know,\nthis is the first work to pre-train a unified model for fine-tuning on both NMT\ntasks. Code, data, and pre-trained models are available at\nhttps://github.com/huawei-noah/Pretrained-Language-Model/CeMAT",
    "descriptor": "\nComments: Accepted to ACL 2022 Main conference\n",
    "authors": [
      "Pengfei Li",
      "Liangyou Li",
      "Meng Zhang",
      "Minghao Wu",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09210"
  },
  {
    "id": "arXiv:2203.09214",
    "title": "Obtaining Smoothly Navigable Approximation Sets in Bi-Objective  Multi-Modal Optimization",
    "abstract": "Even if a Multi-modal Multi-Objective Evolutionary Algorithm (MMOEA) is\ndesigned to find all locally optimal approximation sets of a Multi-modal\nMulti-objective Optimization Problem (MMOP), there is a risk that the found\napproximation sets are not smoothly navigable because the solutions belong to\nvarious niches, reducing the insight for decision makers. Moreover, when the\nmulti-modality of MMOPs increases, this risk grows and the trackability of\nfinding all locally optimal approximation sets decreases. To tackle these\nissues, two new MMOEAs are proposed: Multi-Modal B\\'ezier Evolutionary\nAlgorithm (MM-BezEA) and Set B\\'ezier Evolutionary Algorithm (Set-BezEA). Both\nMMOEAs produce approximation sets that cover individual niches and exhibit\ninherent decision-space smoothness as they are parameterized by B\\'ezier\ncurves. MM-BezEA combines the concepts behind the recently introduced BezEA and\nMO-HillVallEA to find all locally optimal approximation sets. Set-BezEA employs\na novel multi-objective fitness function formulation to find limited numbers of\ndiverse, locally optimal, approximation sets for MMOPs of high multi-modality.\nBoth algorithms, but especially MM-BezEA, are found to outperform the MMOEAs\nMO_Ring_PSO_SCD and MO-HillVallEA on MMOPs of moderate multi-modality with\nlinear Pareto sets. Moreover, for MMOPs of high multi-modality, Set-BezEA is\nfound to indeed be able to produce high-quality approximation sets, each\npertaining to a single niche.",
    "descriptor": "",
    "authors": [
      "Renzo J. Scholman",
      "Anton Bouter",
      "Leah R.M. Dickhoff",
      "Tanja Alderliesten",
      "Peter A.N. Bosman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.09214"
  },
  {
    "id": "arXiv:2203.09215",
    "title": "HSC4D: Human-centered 4D Scene Capture in Large-scale Indoor-outdoor  Space Using Wearable IMUs and LiDAR",
    "abstract": "We propose Human-centered 4D Scene Capture (HSC4D) to accurately and\nefficiently create a dynamic digital world, containing large-scale\nindoor-outdoor scenes, diverse human motions, and rich interactions between\nhumans and environments. Using only body-mounted IMUs and LiDAR, HSC4D is\nspace-free without any external devices' constraints and map-free without\npre-built maps. Considering that IMUs can capture human poses but always drift\nfor long-period use, while LiDAR is stable for global localization but rough\nfor local positions and orientations, HSC4D makes both sensors complement each\nother by a joint optimization and achieves promising results for long-term\ncapture. Relationships between humans and environments are also explored to\nmake their interaction more realistic. To facilitate many down-stream tasks,\nlike AR, VR, robots, autonomous driving, etc., we propose a dataset containing\nthree large scenes (1k-5k $m^2$) with accurate dynamic human motions and\nlocations. Diverse scenarios (climbing gym, multi-story building, slope, etc.)\nand challenging human activities (exercising, walking up/down stairs, climbing,\netc.) demonstrate the effectiveness and the generalization ability of HSC4D.\nThe dataset and code is available at https://github.com/climbingdaily/HSC4D.",
    "descriptor": "",
    "authors": [
      "Yudi Dai",
      "Yitai Lin",
      "Chenglu Wen",
      "Siqi Shen",
      "Lan Xu",
      "Jingyi Yu",
      "Yuexin Ma",
      "Cheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09215"
  },
  {
    "id": "arXiv:2203.09218",
    "title": "A Mixed Finite Element Method for a Class of Evolution Differential  Equations with $p$-Laplacian and Memory",
    "abstract": "We present a new mixed finite element method for a class of parabolic\nequations with $p$-Laplacian and nonlinear memory. The applicability, stability\nand convergence of the method are studied. First, the problem is written in a\nmixed formulation as a system of one parabolic equation and a Volterra\nequation. Then, the system is discretized in the space variable using the\nfinite element method with Lagrangian basis of degree $r\\geq1$. Finally, the\nCranck-Nicolson method with the trapezoidal quadrature is applied to discretize\nthe time variable. For each method, we establish existence, uniqueness and\nregularity of the solutions. The convergence order is found to be dependent on\nthe parameter $p$ on the $p$-Laplacian in the sense that it decreases as $p$\nincreases.",
    "descriptor": "",
    "authors": [
      "Rui M.P. Almeida",
      "Jos\u00e9 C.M. Duque",
      "Belchior C.X. M\u00e1rio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.09218"
  },
  {
    "id": "arXiv:2203.09219",
    "title": "Centrality Measures in multi-layer Knowledge Graphs",
    "abstract": "Knowledge graphs play a central role for linking different data which leads\nto multiple layers. Thus, they are widely used in big data integration,\nespecially for connecting data from different domains. Few studies have\ninvestigated the questions how multiple layers within graphs impact methods and\nalgorithms developed for single-purpose networks, for example social networks.\nThis manuscript investigates the impact of multiple layers on centrality\nmeasures compared to single-purpose graph. In particular, (a) we develop an\nexperimental environment to (b) evaluate two different centrality measures -\ndegree and betweenness centrality - on random graphs inspired by social network\nanalysis: small-world and scale-free networks. The presented approach (c) shows\nthat the graph structures and topology has a great impact on its robustness for\nadditional data stored. Although the experimental analysis of random graphs\nallows us to make some basic observations we will (d) make suggestions for\nadditional research on particular graph structures that have a great impact on\nthe stability of networks.",
    "descriptor": "",
    "authors": [
      "Jens D\u00f6rpinghaus",
      "Vera Weil",
      "Carsten D\u00fcing",
      "Martin W. Sommer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.09219"
  },
  {
    "id": "arXiv:2203.09225",
    "title": "Neighbourhood semantics and axioms for strategic fragment of classical  stit logic",
    "abstract": "STIT (sees to it that) semantics is one of the most prominent tools in modal\nlogic of agency, widely used among both philosophers and responsible AI\nscholars. STIT logic surveys the properties of agents seeing to it that some\nstate of affairs holds without specifying concrete actions by which that state\nof affairs is guaranteed. In comparison with other multi-agent modal logics,\nthe main advantage of STIT theories is expressive power. STIT logic allows to\nstudy not only statements about agents abilities to perform certain actions (as\nit is in variations of Coalition Logic or Propositional Dynamic Logic), but\nabout what choices they make and what they de-facto achieve as well.\nNevertheless, in some occasions such expressivity may be redundant. This\npaper surveys a specific fragment of classical STIT logic, which has only\nstrategic modal operator, standing for the fact that agent has an ability to\nsee to it that some state of affairs holds. The neighbourhood semantics for the\nfragment is presented, accompanied with the soundness, canoniciy hence strong\ncompleteness results. Furthermore, the paper presents basic considerations on\nepistemic extension of the presented fragment.",
    "descriptor": "",
    "authors": [
      "Daniil Khaitovich"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.09225"
  },
  {
    "id": "arXiv:2203.09226",
    "title": "Efficient and certified solution of parametrized one-way coupled  problems through DEIM-based data projection across non-conforming interfaces",
    "abstract": "One of the major challenges of coupled problems is to manage nonconforming\nmeshes at the interface between two models and/or domains, due to different\nnumerical schemes or domains discretizations employed. Moreover, very often\ncomplex submodels depend on (e.g., physical or geometrical) parameters.\nUnderstanding how outputs of interest are affected by parameter variations thus\nplays a key role to gain useful insights on the problem's physics; however,\nexpensive repeated solutions of the problem using high-fidelity, full-order\nmodels are often unaffordable. In this paper, we propose a parametric reduced\norder modeling (ROM) technique for parametrized one-way coupled problems made\nby a first independent model, the master model, and a second model, the slave\nmodel, that depends on the master model through Dirichlet interface conditions.\nWe combine a reduced basis (RB) method, applied to each subproblems, with the\ndiscretized empirical interpolation method (DEIM) to efficiently interpolate or\nproject Dirichlet data across conforming and non-conforming meshes at the\ndomains interface, building a low-dimensional representation of the overall\ncoupled problem. The proposed technique is then numerically verified by\nconsidering a series of test cases involving both steady and unsteady problems,\nand deriving a-posteriori error estimates on the solution of the coupled\nproblem in both cases. This work arises from the need to solve staggered\ncardiac electrophysiological models and represents the first step towards the\nsetting of ROM techniques for the more general two-way Dirichlet-Neumann\ncoupled problems solved with domain decomposition sub-structuring methods, when\ninterface non-conformity is involved.",
    "descriptor": "\nComments: 36 pages, 23 figures, 4 tables\n",
    "authors": [
      "Elena Zappon",
      "Andrea Manzoni",
      "Alfio Quarteroni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.09226"
  },
  {
    "id": "arXiv:2203.09227",
    "title": "Non-Elitist Selection among Survivor Configurations can Improve the  Performance of Irace",
    "abstract": "Modern optimization strategies such as evolutionary algorithms, ant colony\nalgorithms, Bayesian optimization techniques, etc.~come with several parameters\nthat steer their behavior during the optimization process. To obtain\nhigh-performing algorithm instances, automated algorithm configuration\ntechniques have been developed. One of the most popular tools is irace, which\nevaluates configurations in sequential races, at the end of which a statistical\ntest is used to determine the set of survivor configurations. It then selects\nup to five elite configurations from this set, via greedy truncation selection.\nWe demonstrate that an alternative selection of the elites can improve the\nperformance of irace. Our strategy keeps the best survivor and selects the\nremaining configurations uniformly at random from the set of survivors. We\napply this alternative selection method to tune ant colony optimization\nalgorithms for traveling salesperson problems and to configure an exact tree\nsearch solver for satisfiability problems.\nWe also experiment with two non-elitist selection criteria, based on entropy\nand Gower's distance, respectively. Both methods provide more diverse\nconfigurations than irace, making them an interesting approach for exploring a\nwide range of solutions and understanding algorithms' performance. Moreover,\nthe entropy-based selection performs better on our benchmarks than the default\nselection of irace.",
    "descriptor": "\nComments: submitted to GECCO 2022\n",
    "authors": [
      "Furong Ye",
      "Diederick L. Vermetten",
      "Carola Doerr",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.09227"
  },
  {
    "id": "arXiv:2203.09228",
    "title": "Re-shaping Post-COVID-19 Teaching and Learning: A Blueprint of  Virtual-Physical Blended Classrooms in the Metaverse Era",
    "abstract": "During the COVID-19 pandemic, most countries have experienced some form of\nremote education through video conferencing software platforms. However, these\nsoftware platforms present significant limitations that reduce immersion and\nfail to replicate the classroom experience. The currently emerging Metaverse\naddresses many of such limitations by offering blended physical-digital\nenvironments. This paper aims to assess how the Metaverse can support and\nimprove e-learning. We first survey the latest applications of blended\nenvironments in education and highlight the primary challenges and\nopportunities. Accordingly, we derive our proposal for a virtual-physical\nblended classroom configuration that brings students and teachers into a shared\neducational Metaverse. We focus on the system architecture of the Metaverse\nclassroom to achieve real-time synchronization of a large number of\nparticipants and activities across physical (mixed reality classrooms) and\nvirtual (remote virtual reality platform) learning spaces. Our proposal\nattempts to transform the traditional physical classroom into virtual-physical\ncyberspace as a new social network of learners and educators connected at an\nunprecedented scale.",
    "descriptor": "\nComments: 6 pages, 3 figures, conference\n",
    "authors": [
      "Yuyang Wang",
      "Lik-Hang Lee",
      "Tristan Braud",
      "Pan Hui"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.09228"
  },
  {
    "id": "arXiv:2203.09230",
    "title": "Surgical Workflow Recognition: from Analysis of Challenges to  Architectural Study",
    "abstract": "Algorithmic surgical workflow recognition is an ongoing research field and\ncan be divided into laparoscopic (Internal) and operating room (External)\nanalysis. So far many different works for the internal analysis have been\nproposed with the combination of a frame-level and an additional temporal model\nto address the temporal ambiguities between different workflow phases. For the\nExternal recognition task, Clip-level methods are in the focus of researchers\ntargeting the local ambiguities present in the OR scene. In this work we\nevaluate combinations of different model architectures for the task of surgical\nworkflow recognition to provide a fair comparison of the methods for both\nInternal and External analysis. We show that methods designed for the Internal\nanalysis can be transferred to the external task with comparable performance\ngains for different architectures.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Tobias Czempiel",
      "Aidean Sharghi",
      "Magdalini Paschali",
      "Omid Mohareri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09230"
  },
  {
    "id": "arXiv:2203.09231",
    "title": "Speaker recognition using residual signal of linear and nonlinear  prediction models",
    "abstract": "This Paper discusses the usefulness of the residual signal for speaker\nrecognition. It is shown that the combination of both a measure defined over\nLPCC coefficients and a measure defined over the energy of the residual signal\ngives rise to an improvement over the classical method which considers only the\nLPCC coefficients. If the residual signal is obtained from a linear prediction\nanalysis, the improvement is 2.63% (error rate drops from 6.31% to 3.68%) and\nif it is computed through a nonlinear predictive neural nets based model, the\nimprovement is 3.68%.",
    "descriptor": "\nComments: 4 pages, published in 5th International Conference on spoken language processing. Vol.2 pp.121-124. ICSLP 1998. ISBN 1-876346-17-5\n",
    "authors": [
      "Marcos Faundez-Zanuy",
      "Daniel Rodr\u00edguez-Porcheron"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.09231"
  },
  {
    "id": "arXiv:2203.09233",
    "title": "On the Complexity of Techniques That Make Transition Systems  Implementable by Boolean Nets",
    "abstract": "Synthesis consists in deciding whether a given labeled transition system (TS)\n$A$ can be implemented by a net $N$ of type $\\tau$. In case of a negative\ndecision, it may be possible to convert $A$ into an implementable TS $B$ by\napplying various modification techniques, like relabeling edges that previously\nhad the same label, suppressing edges/states/events, etc. It may however be\nuseful to limit the number of such modifications to stay close to the original\nproblem, or optimize the technique. In this paper, we show that most of the\ncorresponding problems are NP-complete if $\\tau$ corresponds to the type of\nflip-flop nets or some flip-flop net derivatives.",
    "descriptor": "",
    "authors": [
      "Raymond Devillers",
      "Ronny Tredup"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.09233"
  },
  {
    "id": "arXiv:2203.09236",
    "title": "Weighing the techniques for data optimization in a database",
    "abstract": "A set of preferred records can be obtained from a large database in a\nmulti-criteria setting using various computational methods which either depend\non the concept of dominance or on the concept of utility or scoring function\nbased on the attributes of the database record. A skyline approach relies on\nthe dominance relationship between different data points to discover\ninteresting data from a huge database. On the other hand, ranking queries make\nuse of specific scoring functions to rank tuples in a database. An experimental\nevaluation of datasets can provides us with information on the effectiveness of\neach of these methods.",
    "descriptor": "",
    "authors": [
      "Anagha Radhakrishnan"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.09236"
  },
  {
    "id": "arXiv:2203.09242",
    "title": "Depth-aware Neural Style Transfer using Instance Normalization",
    "abstract": "Neural Style Transfer (NST) is concerned with the artistic stylization of\nvisual media. It can be described as the process of transferring the style of\nan artistic image onto an ordinary photograph. Recently, a number of studies\nhave considered the enhancement of the depth-preserving capabilities of the NST\nalgorithms to address the undesired effects that occur when the input content\nimages include numerous objects at various depths. Our approach uses a deep\nresidual convolutional network with instance normalization layers that utilizes\nan advanced depth prediction network to integrate depth preservation as an\nadditional loss function to content and style. We demonstrate results that are\neffective in retaining the depth and global structure of content images. Three\ndifferent evaluation processes show that our system is capable of preserving\nthe structure of the stylized results while exhibiting style-capture\ncapabilities and aesthetic qualities comparable or superior to state-of-the-art\nmethods.",
    "descriptor": "\nComments: 16 pages, 7 figures, submitted to European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Eleftherios Ioannou",
      "Steve Maddock"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.09242"
  },
  {
    "id": "arXiv:2203.09243",
    "title": "On the Properties of Adversarially-Trained CNNs",
    "abstract": "Adversarial Training has proved to be an effective training paradigm to\nenforce robustness against adversarial examples in modern neural network\narchitectures. Despite many efforts, explanations of the foundational\nprinciples underpinning the effectiveness of Adversarial Training are limited\nand far from being widely accepted by the Deep Learning community. In this\npaper, we describe surprising properties of adversarially-trained models,\nshedding light on mechanisms through which robustness against adversarial\nattacks is implemented. Moreover, we highlight limitations and failure modes\naffecting these models that were not discussed by prior works. We conduct\nextensive analyses on a wide range of architectures and datasets, performing a\ndeep comparison between robust and natural models.",
    "descriptor": "",
    "authors": [
      "Mattia Carletti",
      "Matteo Terzi",
      "Gian Antonio Susto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09243"
  },
  {
    "id": "arXiv:2203.09249",
    "title": "Fine-tuning Global Model via Data-Free Knowledge Distillation for  Non-IID Federated Learning",
    "abstract": "Federated Learning (FL) is an emerging distributed learning paradigm under\nprivacy constraint. Data heterogeneity is one of the main challenges in FL,\nwhich results in slow convergence and degraded performance. Most existing\napproaches only tackle the heterogeneity challenge by restricting the local\nmodel update in client, ignoring the performance drop caused by direct global\nmodel aggregation. Instead, we propose a data-free knowledge distillation\nmethod to fine-tune the global model in the server (FedFTG), which relieves the\nissue of direct model aggregation. Concretely, FedFTG explores the input space\nof local models through a generator, and uses it to transfer the knowledge from\nlocal models to the global model. Besides, we propose a hard sample mining\nscheme to achieve effective knowledge distillation throughout the training. In\naddition, we develop customized label sampling and class-level ensemble to\nderive maximum utilization of knowledge, which implicitly mitigates the\ndistribution discrepancy across clients. Extensive experiments show that our\nFedFTG significantly outperforms the state-of-the-art (SOTA) FL algorithms and\ncan serve as a strong plugin for enhancing FedAvg, FedProx, FedDyn, and\nSCAFFOLD.",
    "descriptor": "\nComments: This paper is accepted by CVPR2022\n",
    "authors": [
      "Lin Zhang",
      "Li Shen",
      "Liang Ding",
      "Dacheng Tao",
      "Ling-Yu Duan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09249"
  },
  {
    "id": "arXiv:2203.09251",
    "title": "Near Instance-Optimal PAC Reinforcement Learning for Deterministic MDPs",
    "abstract": "In probably approximately correct (PAC) reinforcement learning (RL), an agent\nis required to identify an $\\epsilon$-optimal policy with probability\n$1-\\delta$. While minimax optimal algorithms exist for this problem, its\ninstance-dependent complexity remains elusive in episodic Markov decision\nprocesses (MDPs). In this paper, we propose the first (nearly) matching upper\nand lower bounds on the sample complexity of PAC RL in deterministic episodic\nMDPs with finite state and action spaces. In particular, our bounds feature a\nnew notion of sub-optimality gap for state-action pairs that we call the\ndeterministic return gap. While our instance-dependent lower bound is written\nas a linear program, our algorithms are very simple and do not require solving\nsuch an optimization problem during learning. Their design and analyses employ\nnovel ideas, including graph-theoretical concepts such as minimum flows and\nmaximum cuts, which we believe to shed new light on this problem.",
    "descriptor": "",
    "authors": [
      "Andrea Tirinzoni",
      "Aymen Al-Marjani",
      "Emilie Kaufmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09251"
  },
  {
    "id": "arXiv:2203.09253",
    "title": "Visualizing Riemannian data with Rie-SNE",
    "abstract": "Faithful visualizations of data residing on manifolds must take the\nunderlying geometry into account when producing a flat planar view of the data.\nIn this paper, we extend the classic stochastic neighbor embedding (SNE)\nalgorithm to data on general Riemannian manifolds. We replace standard Gaussian\nassumptions with Riemannian diffusion counterparts and propose an efficient\napproximation that only requires access to calculations of Riemannian distances\nand volumes. We demonstrate that the approach also allows for mapping data from\none manifold to another, e.g. from a high-dimensional sphere to a\nlow-dimensional one.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Andri Bergsson",
      "S\u00f8ren Hauberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.09253"
  },
  {
    "id": "arXiv:2203.09255",
    "title": "On the Spectral Bias of Convolutional Neural Tangent and Gaussian  Process Kernels",
    "abstract": "We study the properties of various over-parametrized convolutional neural\narchitectures through their respective Gaussian process and neural tangent\nkernels. We prove that, with normalized multi-channel input and ReLU\nactivation, the eigenfunctions of these kernels with the uniform measure are\nformed by products of spherical harmonics, defined over the channels of the\ndifferent pixels. We next use hierarchical factorizable kernels to bound their\nrespective eigenvalues. We show that the eigenvalues decay polynomially,\nquantify the rate of decay, and derive measures that reflect the composition of\nhierarchical features in these networks. Our results provide concrete\nquantitative characterization of over-parameterized convolutional network\narchitectures.",
    "descriptor": "",
    "authors": [
      "Amnon Geifman",
      "Meirav Galun",
      "David Jacobs",
      "Ronen Basri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09255"
  },
  {
    "id": "arXiv:2203.09257",
    "title": "Contrastive Learning for Cross-Domain Open World Recognition",
    "abstract": "The ability to evolve is fundamental for any valuable autonomous agent whose\nknowledge cannot remain limited to that injected by the manufacturer. Consider\nfor example a home assistant robot: it should be able to incrementally learn\nnew object categories when requested, but also to recognize the same objects in\ndifferent environments (rooms) and poses (hand-held/on the floor/above\nfurniture), while rejecting unknown ones. Despite its importance, this scenario\nhas started to raise interest in the robotic community only recently and the\nrelated research is still in its infancy, with existing experimental testbeds\nbut no tailored methods. With this work, we propose the first learning approach\nthat deals with all the previously mentioned challenges at once by exploiting a\nsingle contrastive objective. We show how it learns a feature space perfectly\nsuitable to incrementally include new classes and is able to capture knowledge\nwhich generalizes across a variety of visual domains. Our method is endowed\nwith a tailored effective stopping criterion for each learning episode and\nexploits a novel self-paced thresholding strategy that provides the classifier\nwith a reliable rejection option. Both these contributions are based on the\nobservation of the data statistics and do not need manual tuning. An extensive\nexperimental analysis confirms the effectiveness of the proposed approach\nestablishing the new state-of-the-art. The code is available at\nhttps://github.com/FrancescoCappio/Contrastive_Open_World.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Francesco Cappio Borlino",
      "Silvia Bucci",
      "Tatiana Tommasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09257"
  },
  {
    "id": "arXiv:2203.09258",
    "title": "Explainability in Graph Neural Networks: An Experimental Survey",
    "abstract": "Graph neural networks (GNNs) have been extensively developed for graph\nrepresentation learning in various application domains. However, similar to all\nother neural networks models, GNNs suffer from the black-box problem as people\ncannot understand the mechanism underlying them. To solve this problem, several\nGNN explainability methods have been proposed to explain the decisions made by\nGNNs. In this survey, we give an overview of the state-of-the-art GNN\nexplainability methods and how they are evaluated. Furthermore, we propose a\nnew evaluation metric and conduct thorough experiments to compare GNN\nexplainability methods on real world datasets. We also suggest future\ndirections for GNN explainability.",
    "descriptor": "",
    "authors": [
      "Peibo Li",
      "Yixing Yang",
      "Maurice Pagnucco",
      "Yang Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09258"
  },
  {
    "id": "arXiv:2203.09271",
    "title": "A flexible solution to embrace Ranking and Skyline queries approaches",
    "abstract": "The multi-objective optimization problem has always been the main objective\nof the principal traditional approaches, such as Ranking queries and Skyline\nqueries. The conventional idea was to either use one or the other, trying to\nexploit both ranking queries advantages when it comes to taking into account\nuser preferences, and skyline queries points of strength when the main\nobjective was to obtain interesting results from a dataset in a simple, yet\neffective fashion, both of them showing limitations when entering specific\nfields of interest.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Simone Censuales"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.09271"
  },
  {
    "id": "arXiv:2203.09275",
    "title": "ART-SS: An Adaptive Rejection Technique for Semi-Supervised restoration  for adverse weather-affected images",
    "abstract": "In recent years, convolutional neural network-based single image adverse\nweather removal methods have achieved significant performance improvements on\nmany benchmark datasets. However, these methods require large amounts of\nclean-weather degraded image pairs for training, which is often difficult to\nobtain in practice. Although various weather degradation synthesis methods\nexist in the literature, the use of synthetically generated weather degraded\nimages often results in sub-optimal performance on the real weather degraded\nimages due to the domain gap between synthetic and real-world images. To deal\nwith this problem, various semi-supervised restoration (SSR) methods have been\nproposed for deraining or dehazing which learn to restore the clean image using\nsynthetically generated datasets while generalizing better using unlabeled\nreal-world images. The performance of a semi-supervised method is essentially\nbased on the quality of the unlabeled data. In particular, if the unlabeled\ndata characteristics are very different from that of the labeled data, then the\nperformance of a semi-supervised method degrades significantly. We\ntheoretically study the effect of unlabeled data on the performance of an SSR\nmethod and develop a technique that rejects the unlabeled images that degrade\nthe performance. Extensive experiments and ablation study show that the\nproposed sample rejection method increases the performance of existing SSR\nderaining and dehazing methods significantly. Code is available at\n:https://github.com/rajeevyasarla/ART-SS",
    "descriptor": "",
    "authors": [
      "Rajeev Yasarla",
      "Carey E. Priebe",
      "Vishal Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09275"
  },
  {
    "id": "arXiv:2203.09276",
    "title": "Stochastic and Private Nonconvex Outlier-Robust PCA",
    "abstract": "We develop theoretically guaranteed stochastic methods for outlier-robust\nPCA. Outlier-robust PCA seeks an underlying low-dimensional linear subspace\nfrom a dataset that is corrupted with outliers. We are able to show that our\nmethods, which involve stochastic geodesic gradient descent over the\nGrassmannian manifold, converge and recover an underlying subspace in various\nregimes through the development of a novel convergence analysis. The main\napplication of this method is an effective differentially private algorithm for\noutlier-robust PCA that uses a Gaussian noise mechanism within the stochastic\ngradient method. Our results emphasize the advantages of the nonconvex methods\nover another convex approach to solving this problem in the differentially\nprivate setting. Experiments on synthetic and stylized data verify these\nresults.",
    "descriptor": "\nComments: 34 pages, 9 figures\n",
    "authors": [
      "Tyler Maunu",
      "Chenyu Yu",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.09276"
  },
  {
    "id": "arXiv:2203.09277",
    "title": "Beauty and the beast: A case study on performance prototyping of  data-intensive containerized cloud applications",
    "abstract": "Data-intensive container-based cloud applications have become popular with\nthe increased use cases in the Internet of Things domain. Challenges arise when\nengineering such applications to meet quality requirements, both classical ones\nlike performance and emerging ones like elasticity and resilience. There is a\nlack of reference use cases, applications, and experiences when prototyping\nsuch applications that could benefit the research community. Moreover, it is\nhard to generate realistic and reliable workloads that exercise the resources\naccording to a specification. Hence, designing reference applications that\nwould exhibit similar performance behavior in such environments is hard. In\nthis paper, we present a work in progress towards a reference use case and\napplication for data-intensive containerized cloud applications having an\nindustrial motivation. Moreover, to generate reliable CPU workloads we make use\nof ProtoCom, a well-known library for the generation of resource demands, and\nreport the performance under various quality requirements in a Kubernetes\ncluster of moderate size. Finally, we present the scalability of the current\nsolution assuming a particular autoscaling policy. Results of the calibration\nshow high variability of the ProtoCom library when executed in a cloud\nenvironment. We observe a moderate association between the occupancy of node\nand the relative variability of execution time.",
    "descriptor": "",
    "authors": [
      "Floriment Klinaku",
      "Martina Rapp",
      "J\u00f6rg Henss",
      "Stephan Rhode"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.09277"
  },
  {
    "id": "arXiv:2203.09278",
    "title": "Confidence Calibration for Intent Detection via Hyperspherical Space and  Rebalanced Accuracy-Uncertainty Loss",
    "abstract": "Data-driven methods have achieved notable performance on intent detection,\nwhich is a task to comprehend user queries. Nonetheless, they are controversial\nfor over-confident predictions. In some scenarios, users do not only care about\nthe accuracy but also the confidence of model. Unfortunately, mainstream neural\nnetworks are poorly calibrated, with a large gap between accuracy and\nconfidence. To handle this problem defined as confidence calibration, we\npropose a model using the hyperspherical space and rebalanced\naccuracy-uncertainty loss. Specifically, we project the label vector onto\nhyperspherical space uniformly to generate a dense label representation matrix,\nwhich mitigates over-confident predictions due to overfitting sparce one-hot\nlabel matrix. Besides, we rebalance samples of different accuracy and\nuncertainty to better guide model training. Experiments on the open datasets\nverify that our model outperforms the existing calibration methods and achieves\na significant improvement on the calibration metric.",
    "descriptor": "",
    "authors": [
      "Yantao Gong",
      "Cao Liu",
      "Fan Yang",
      "Xunliang Cai",
      "Guanglu Wan",
      "Jiansong Chen",
      "Weipeng Zhang",
      "Houfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09278"
  },
  {
    "id": "arXiv:2203.09279",
    "title": "Transfer learning for cross-modal demand prediction of bike-share and  public transit",
    "abstract": "The urban transportation system is a combination of multiple transport modes,\nand the interdependencies across those modes exist. This means that the travel\ndemand across different travel modes could be correlated as one mode may\nreceive demand from or create demand for another mode, not to mention natural\ncorrelations between different demand time series due to general demand flow\npatterns across the network. It is expectable that cross-modal ripple effects\nbecome more prevalent, with Mobility as a Service. Therefore, by propagating\ndemand data across modes, a better demand prediction could be obtained. To this\nend, this study explores various machine learning models and transfer learning\nstrategies for cross-modal demand prediction. The trip data of bike-share,\nmetro, and taxi are processed as the station-level passenger flows, and then\nthe proposed prediction method is tested in the large-scale case studies of\nNanjing and Chicago. The results suggest that prediction models with transfer\nlearning perform better than unimodal prediction models. Furthermore, stacked\nLong Short-Term Memory model performs particularly well in cross-modal demand\nprediction. These results verify our combined method's forecasting improvement\nover existing benchmarks and demonstrate the good transferability for\ncross-modal demand prediction in multiple cities.",
    "descriptor": "\nComments: 27 pages, 4 figures\n",
    "authors": [
      "Mingzhuang Hua",
      "Francisco Camara Pereira",
      "Yu Jiang",
      "Xuewu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09279"
  },
  {
    "id": "arXiv:2203.09280",
    "title": "Knowledge Graph Embedding Methods for Entity Alignment: An Experimental  Review",
    "abstract": "In recent years, we have witnessed the proliferation of knowledge graphs (KG)\nin various domains, aiming to support applications like question answering,\nrecommendations, etc. A frequent task when integrating knowledge from different\nKGs is to find which subgraphs refer to the same real-world entity. Recently,\nembedding methods have been used for entity alignment tasks, that learn a\nvector-space representation of entities which preserves their similarity in the\noriginal KGs. A wide variety of supervised, unsupervised, and semi-supervised\nmethods have been proposed that exploit both factual (attribute based) and\nstructural information (relation based) of entities in the KGs. Still, a\nquantitative assessment of their strengths and weaknesses in real-world KGs\naccording to different performance metrics and KG characteristics is missing\nfrom the literature. In this work, we conduct the first meta-level analysis of\npopular embedding methods for entity alignment, based on a statistically sound\nmethodology. Our analysis reveals statistically significant correlations of\ndifferent embedding methods with various meta-features extracted by KGs and\nrank them in a statistically significant way according to their effectiveness\nacross all real-world KGs of our testbed. Finally, we study interesting\ntrade-offs in terms of methods' effectiveness and efficiency.",
    "descriptor": "\nComments: pre-print under review at a journal\n",
    "authors": [
      "Nikolaos Fanourakis",
      "Vasilis Efthymiou",
      "Dimitris Kotzinos",
      "Vassilis Christophides"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09280"
  },
  {
    "id": "arXiv:2203.09283",
    "title": "PanoFormer: Panorama Transformer for Indoor 360\u00b0 Depth Estimation",
    "abstract": "Existing panoramic depth estimation methods based on convolutional neural\nnetworks (CNNs) focus on removing panoramic distortions, failing to perceive\npanoramic structures efficiently due to the fixed receptive field in CNNs. This\npaper proposes the panorama transformer (named PanoFormer) to estimate the\ndepth in panorama images, with tangent patches from spherical domain, learnable\ntoken flows, and panorama specific metrics. In particular, we divide patches on\nthe spherical tangent domain into tokens to reduce the negative effect of\npanoramic distortions. Since the geometric structures are essential for depth\nestimation, a self-attention module is redesigned with an additional learnable\ntoken flow. In addition, considering the characteristic of the spherical\ndomain, we present two panorama-specific metrics to comprehensively evaluate\nthe panoramic depth estimation models' performance. Extensive experiments\ndemonstrate that our approach significantly outperforms the state-of-the-art\n(SOTA) methods. Furthermore, the proposed method can be effectively extended to\nsolve semantic panorama segmentation, a similar pixel2pixel task. Code will be\navailable.",
    "descriptor": "",
    "authors": [
      "Zhijie Shen",
      "Chunyu Lin",
      "Kang Liao",
      "Lang Nie",
      "Zishuo Zheng",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09283"
  },
  {
    "id": "arXiv:2203.09284",
    "title": "FUSED-PAGERANK: Loop-Fusion based Approximate PageRank",
    "abstract": "PageRank is a graph centrality metric that gives the importance of each node\nin a given graph. The PageRank algorithm provides important insights to\nunderstand the behavior of nodes through the connections they form with other\nnodes. It is an iterative algorithm that ranks the nodes in each iteration\nuntil all the node values converge. The PageRank algorithm is implemented using\nsparse storage format, which results in irregular memory accesses in the code.\nThis key feature inhibits optimizations to improve its performance, and makes\noptimizing the PageRank algorithm a non-trivial problem. In this work we\nimprove the performance of PageRank algorithm by reducing its irregular memory\naccesses. In this paper, we propose FUSED-PAGERANK algorithm, a compiler\noptimization oriented approximate technique that reduces the number of\nirregular memory accesses in the PageRank algorithm, improving its locality\nwhile making the convergence of the algorithm faster with better accuracy in\nresults. In particular, we propose an approximate PageRank algorithm using\nLoop-Fusion. We believe that ours is the first work that formally applies\ntraditional compiler optimization techniques for irregular memory access in the\nPageRank algorithm. We have verified our method by performing experiments on a\nvariety of datasets: LAW graphs, SNAP datasets and synthesized datasets. On\nthese benchmarks, we have achieved a maximum speedup (vs. -O3 optimization) of\n2.05X, 2.23X, 1.74X with sequential version, and ~4.4X, ~2.61X, ~4.22X with\nparallel version of FUSED-PAGERANK algorithm in comparison with Edge-centric\nversion of PageRank algorithm.",
    "descriptor": "",
    "authors": [
      "Shalini Jain",
      "Rahul Utkoor",
      "Hemalatha Eedi",
      "Sathya Peri",
      "Ramakrishna Upadrasta"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.09284"
  },
  {
    "id": "arXiv:2203.09286",
    "title": "How to Write Beautiful Process-and-Data-Science Papers?",
    "abstract": "After 25 years of PhD supervision, the author noted typical recurring\nproblems that make papers look sloppy, difficult to read, and incoherent. The\ngoal is not to write a paper for the sake of writing a paper, but to convey a\nvaluable message that is clear and precise. The goal is to write papers that\nhave an impact and are still understandable a couple of decades later. Our\nmission should be to create papers of high quality that people want to read and\nthat can stand the test of time. We use Dijkstra's adagium \"Beauty Is Our\nBusiness\" to stress the importance of simplicity, correctness, and cleanness.",
    "descriptor": "\nComments: 17 pages. 1 figure\n",
    "authors": [
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2203.09286"
  },
  {
    "id": "arXiv:2203.09287",
    "title": "HybridCap: Inertia-aid Monocular Capture of Challenging Human Motions",
    "abstract": "Monocular 3D motion capture (mocap) is beneficial to many applications. The\nuse of a single camera, however, often fails to handle occlusions of different\nbody parts and hence it is limited to capture relatively simple movements. We\npresent a light-weight, hybrid mocap technique called HybridCap that augments\nthe camera with only 4 Inertial Measurement Units (IMUs) in a\nlearning-and-optimization framework. We first employ a weakly-supervised and\nhierarchical motion inference module based on cooperative Gated Recurrent Unit\n(GRU) blocks that serve as limb, body and root trackers as well as an inverse\nkinematics solver. Our network effectively narrows the search space of\nplausible motions via coarse-to-fine pose estimation and manages to tackle\nchallenging movements with high efficiency. We further develop a hybrid\noptimization scheme that combines inertial feedback and visual cues to improve\ntracking accuracy. Extensive experiments on various datasets demonstrate\nHybridCap can robustly handle challenging movements ranging from fitness\nactions to Latin dance. It also achieves real-time performance up to 60 fps\nwith state-of-the-art accuracy.",
    "descriptor": "",
    "authors": [
      "Han Liang",
      "Yannan He",
      "Chengfeng Zhao",
      "Mutian Li",
      "Jingya Wang",
      "Jingyi Yu",
      "Lan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09287"
  },
  {
    "id": "arXiv:2203.09288",
    "title": "Efficiently Enumerating Answers to Ontology-Mediated Queries",
    "abstract": "We study the enumeration of answers to ontology-mediated queries (OMQs) where\nthe ontology is a set of guarded TGDs or formulated in the description logic\nELI and the query is a conjunctive query (CQ). In addition to the traditional\nnotion of an answer, we propose and study two novel notions of partial answers\nthat can take into account nulls generated by existential quantifiers in the\nontology. Our main result is that enumeration of the traditional complete\nanswers and of both kinds of partial answers is possible with linear-time\npreprocessing and constant delay for OMQs that are both acyclic and free-connex\nacyclic. We also provide partially matching lower bounds. Similar results are\nobtained for the related problems of testing a single answer in linear time and\nof testing multiple answers in constant time after linear time preprocessing.\nIn both cases, the border between tractability and intractability is\ncharacterized by similar, but slightly different acyclicity properties.",
    "descriptor": "",
    "authors": [
      "Carsten Lutz",
      "Marcin Przyby\u0142ko"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.09288"
  },
  {
    "id": "arXiv:2203.09289",
    "title": "PiDAn: A Coherence Optimization Approach for Backdoor Attack Detection  and Mitigation in Deep Neural Networks",
    "abstract": "Backdoor attacks impose a new threat in Deep Neural Networks (DNNs), where a\nbackdoor is inserted into the neural network by poisoning the training dataset,\nmisclassifying inputs that contain the adversary trigger. The major challenge\nfor defending against these attacks is that only the attacker knows the secret\ntrigger and the target class. The problem is further exacerbated by the recent\nintroduction of \"Hidden Triggers\", where the triggers are carefully fused into\nthe input, bypassing detection by human inspection and causing backdoor\nidentification through anomaly detection to fail. To defend against such\nimperceptible attacks, in this work we systematically analyze how\nrepresentations, i.e., the set of neuron activations for a given DNN when using\nthe training data as inputs, are affected by backdoor attacks. We propose\nPiDAn, an algorithm based on coherence optimization purifying the poisoned\ndata. Our analysis shows that representations of poisoned data and authentic\ndata in the target class are still embedded in different linear subspaces,\nwhich implies that they show different coherence with some latent spaces. Based\non this observation, the proposed PiDAn algorithm learns a sample-wise weight\nvector to maximize the projected coherence of weighted samples, where we\ndemonstrate that the learned weight vector has a natural \"grouping effect\" and\nis distinguishable between authentic data and poisoned data. This enables the\nsystematic detection and mitigation of backdoor attacks. Based on our\ntheoretical analysis and experimental results, we demonstrate the effectiveness\nof PiDAn in defending against backdoor attacks that use different settings of\npoisoned samples on GTSRB and ILSVRC2012 datasets. Our PiDAn algorithm can\ndetect more than 90% infected classes and identify 95% poisoned samples.",
    "descriptor": "",
    "authors": [
      "Yue Wang",
      "Wenqing Li",
      "Esha Sarkar",
      "Muhammad Shafique",
      "Michail Maniatakos",
      "Saif Eddin Jabari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.09289"
  },
  {
    "id": "arXiv:2203.09292",
    "title": "A domain specific language for data-centric infographics: technical  report",
    "abstract": "The production process of data-centric infographics entails problems related\nto a disconnection between the supporting software environments. We investigate\nthose problems and redesigns this process following the model-driven paradigm.\nWe have designed a domain-specific language to model infographics, and\nimplemented an interpreter that generates the infographics automatically. To\ninform the engineering of the DSL and interpreter, we have analysed 58\ninfographics reporting on ethical, social and environmental accounting, and 10\ninfographic design tools. We then have tested our proposal by means of\nmodelling a sample of 10 infographics and generating them. We have also\nconducted a controlled experiment to assess the extent to which the generated\ninfograhics are as visually attractive as the original ones and whether the\nparticipants can identify whether the infographic they see is original or\ngenerated. This report provides the details of this research project:\nconceptual model, collected data, analysis, and supporting instruments.",
    "descriptor": "\nComments: 180 pages, 38 tables, 112 figures\n",
    "authors": [
      "Sergio Espa\u00f1a",
      "Vijanti Ramautar",
      "Sietse Overbeek",
      "Tijmen Derikx"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.09292"
  },
  {
    "id": "arXiv:2203.09293",
    "title": "PreTR: Spatio-Temporal Non-Autoregressive Trajectory Prediction  Transformer",
    "abstract": "Nowadays, our mobility systems are evolving into the era of intelligent\nvehicles that aim to improve road safety. Due to their vulnerability,\npedestrians are the users who will benefit the most from these developments.\nHowever, predicting their trajectory is one of the most challenging concerns.\nIndeed, accurate prediction requires a good understanding of multi-agent\ninteractions that can be complex. Learning the underlying spatial and temporal\npatterns caused by these interactions is even more of a competitive and open\nproblem that many researchers are tackling. In this paper, we introduce a model\ncalled PRediction Transformer (PReTR) that extracts features from the\nmulti-agent scenes by employing a factorized spatio-temporal attention module.\nIt shows less computational needs than previously studied models with\nempirically better results. Besides, previous works in motion prediction suffer\nfrom the exposure bias problem caused by generating future sequences\nconditioned on model prediction samples rather than ground-truth samples. In\norder to go beyond the proposed solutions, we leverage encoder-decoder\nTransformer networks for parallel decoding a set of learned object queries.\nThis non-autoregressive solution avoids the need for iterative conditioning and\narguably decreases training and testing computational time. We evaluate our\nmodel on the ETH/UCY datasets, a publicly available benchmark for pedestrian\ntrajectory prediction. Finally, we justify our usage of the parallel decoding\ntechnique by showing that the trajectory prediction task can be better solved\nas a non-autoregressive task.",
    "descriptor": "",
    "authors": [
      "Lina Achaji",
      "Thierno Barry",
      "Thibault Fouqueray",
      "Julien Moreau",
      "Francois Aioun",
      "Francois Charpillet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.09293"
  },
  {
    "id": "arXiv:2203.09294",
    "title": "A Differentiable Two-stage Alignment Scheme for Burst Image  Reconstruction with Large Shift",
    "abstract": "Denoising and demosaicking are two essential steps to reconstruct a clean\nfull-color image from the raw data. Recently, joint denoising and demosaicking\n(JDD) for burst images, namely JDD-B, has attracted much attention by using\nmultiple raw images captured in a short time to reconstruct a single\nhigh-quality image. One key challenge of JDD-B lies in the robust alignment of\nimage frames. State-of-the-art alignment methods in feature domain cannot\neffectively utilize the temporal information of burst images, where large\nshifts commonly exist due to camera and object motion. In addition, the higher\nresolution (e.g., 4K) of modern imaging devices results in larger displacement\nbetween frames. To address these challenges, we design a differentiable\ntwo-stage alignment scheme sequentially in patch and pixel level for effective\nJDD-B. The input burst images are firstly aligned in the patch level by using a\ndifferentiable progressive block matching method, which can estimate the offset\nbetween distant frames with small computational cost. Then we perform implicit\npixel-wise alignment in full-resolution feature domain to refine the alignment\nresults. The two stages are jointly trained in an end-to-end manner. Extensive\nexperiments demonstrate the significant improvement of our method over existing\nJDD-B methods. Codes are available at https://github.com/GuoShi28/2StageAlign.",
    "descriptor": "",
    "authors": [
      "Shi Guo",
      "Xi Yang",
      "Jianqi Ma",
      "Gaofeng Ren",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09294"
  },
  {
    "id": "arXiv:2203.09295",
    "title": "Assessing Progress of Parkinson s Disease Using Acoustic Analysis of  Phonation",
    "abstract": "This paper deals with a complex acoustic analysis of phonation in patients\nwith Parkinson's disease (PD) with a special focus on estimation of disease\nprogress that is described by 7 different clinical scales ,e. g. Unified\nParkinson's disease rating scale or Beck depression inventory. The analysis is\nbased on parametrization of 5 Czech vowels pronounced by 84 PD patients. Using\nclassification and regression trees we estimated all clinical scores with\nmaximal error lower or equal to 13 %. Best estimation was observed in the case\nof Mini-mental state examination (MAE = 0.77, estimation error 5.50 %. Finally,\nwe proposed a binary classification based on random forests that is able to\nidentify Parkinson's disease with sensitivity SEN = 92.86 % (SPE = 85.71 %).\nThe parametrization process was based on extraction of 107 speech features\nquantifying different clinical signs of hypokinetic dysarthria present in PD.",
    "descriptor": "\nComments: 8 pages published in the 4th IEEE IWOBI 2015, pp. 115-122, 10-12 June, 2015 Donostia-San Sebastian. ISBN: 978-84-606-8733-7\n",
    "authors": [
      "Jiri Mekyska",
      "Zoltan Galaz",
      "Zdenek Mzourek",
      "Zdenek Smekal",
      "Irena Rektorova",
      "Ilona Eliasova",
      "Milena Kostalova",
      "Martina Mrackova",
      "Dagmar Berankov",
      "Marcos Faundez-Zanuy",
      "Karmele Lopez-de-Ipi\u00f1a",
      "Jesus B. Alonso-Hernandez"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.09295"
  },
  {
    "id": "arXiv:2203.09299",
    "title": "Proceedings Fifth Workshop on Models for Formal Analysis of Real Systems",
    "abstract": "This volume contains the proceedings of MARS 2022, the fifth workshop on\nModels for Formal Analysis of Real Systems, held as part of ETAPS 2022, the\nEuropean Joint Conferences on Theory and Practice of Software. The MARS\nworkshops bring together researchers from different communities who are\ndeveloping formal models of real systems in areas where complex models occur,\nsuch as networks, cyber-physical systems, hardware/software co-design, biology,\netc. The motivation and aim for MARS stem from the following two observations:\n* Large case studies are essential to show that specification formalisms and\nmodelling techniques are applicable to real systems, whereas many research\npapers only consider toy examples or tiny case studies.\n* Developing an accurate model of a real system takes a large amount of time,\noften months or years. In most scientific papers, however, salient details of\nthe model need to be skipped due to lack of space, and to leave room for formal\nverification methodologies and results.\nThe MARS workshops aim at remedying these issues, emphasising modelling over\nverification, so as to retain lessons learnt from formal modelling, which are\nnot usually discussed elsewhere.",
    "descriptor": "",
    "authors": [
      "Clemens Dubslaff",
      "Bas Luttik"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.09299"
  },
  {
    "id": "arXiv:2203.09301",
    "title": "One-Shot Adaptation of GAN in Just One CLIP",
    "abstract": "There are many recent research efforts to fine-tune a pre-trained generator\nwith a few target images to generate images of a novel domain. Unfortunately,\nthese methods often suffer from overfitting or under-fitting when fine-tuned\nwith a single target image. To address this, here we present a novel\nsingle-shot GAN adaptation method through unified CLIP space manipulations.\nSpecifically, our model employs a two-step training strategy: reference image\nsearch in the source generator using a CLIP-guided latent optimization,\nfollowed by generator fine-tuning with a novel loss function that imposes CLIP\nspace consistency between the source and adapted generators. To further improve\nthe adapted model to produce spatially consistent samples with respect to the\nsource generator, we also propose contrastive regularization for patchwise\nrelationships in the CLIP space. Experimental results show that our model\ngenerates diverse outputs with the target texture and outperforms the baseline\nmodels both qualitatively and quantitatively. Furthermore, we show that our\nCLIP space manipulation strategy allows more effective attribute editing.",
    "descriptor": "",
    "authors": [
      "Gihyun Kwon",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09301"
  },
  {
    "id": "arXiv:2203.09303",
    "title": "Video Prediction at Multiple Scales with Hierarchical Recurrent Networks",
    "abstract": "Autonomous systems not only need to understand their current environment, but\nshould also be able to predict future actions conditioned on past states, for\ninstance based on captured camera frames. For certain tasks, detailed\npredictions such as future video frames are required in the near future,\nwhereas for others it is beneficial to also predict more abstract\nrepresentations for longer time horizons. However, existing video prediction\nmodels mainly focus on forecasting detailed possible outcomes for short\ntime-horizons, hence being of limited use for robot perception and spatial\nreasoning. We propose Multi-Scale Hierarchical Prediction (MSPred), a novel\nvideo prediction model able to forecast future possible outcomes of different\nlevels of granularity at different time-scales simultaneously. By combining\nspatial and temporal downsampling, MSPred is able to efficiently predict\nabstract representations such as human poses or object locations over long time\nhorizons, while still maintaining a competitive performance for video frame\nprediction. In our experiments, we demonstrate that our proposed model\naccurately predicts future video frames as well as other representations (e.g.\nkeypoints or positions) on various scenarios, including bin-picking scenes or\naction recognition datasets, consistently outperforming popular approaches for\nvideo frame prediction. Furthermore, we conduct an ablation study to\ninvestigate the importance of the different modules and design choices in\nMSPred. In the spirit of reproducible research, we open-source VP-Suite, a\ngeneral framework for deep-learning-based video prediction, as well as\npretrained models to reproduce our results.",
    "descriptor": "",
    "authors": [
      "Ani Karapetyan",
      "Angel Villar-Corrales",
      "Andreas Boltres",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09303"
  },
  {
    "id": "arXiv:2203.09306",
    "title": "Finding Structural Knowledge in Multimodal-BERT",
    "abstract": "In this work, we investigate the knowledge learned in the embeddings of\nmultimodal-BERT models. More specifically, we probe their capabilities of\nstoring the grammatical structure of linguistic data and the structure learned\nover objects in visual data. To reach that goal, we first make the inherent\nstructure of language and visuals explicit by a dependency parse of the\nsentences that describe the image and by the dependencies between the object\nregions in the image, respectively. We call this explicit visual structure the\n\\textit{scene tree}, that is based on the dependency tree of the language\ndescription. Extensive probing experiments show that the multimodal-BERT models\ndo not encode these scene trees.Code available at\n\\url{https://github.com/VSJMilewski/multimodal-probes}.",
    "descriptor": "\nComments: Accepted at ACL 2022\n",
    "authors": [
      "Victor Milewski",
      "Miryam de Lhoneux",
      "Marie-Francine Moens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09306"
  },
  {
    "id": "arXiv:2203.09308",
    "title": "Few-Shot Learning on Graphs: A Survey",
    "abstract": "Graph representation learning has attracted tremendous attention due to its\nremarkable performance in many real-world applications. However, prevailing\n(semi-)supervised graph representation learning models for specific tasks often\nsuffer from label sparsity issue as data labeling is always time and resource\nconsuming. In light of this, few-shot learning on graphs (FSLG), which combines\nthe strengths of graph representation learning and few-shot learning together,\nhas been proposed to tackle the performance degradation in face of limited\nannotated data challenge. There have been many studies working on FSLG\nrecently. In this paper, we comprehensively survey these work in the form of a\nseries of methods and applications. Specifically, we first introduce FSLG\nchallenges and bases, then categorize and summarize existing work of FSLG in\nterms of three major graph mining tasks at different granularity levels, i.e.,\nnode, edge, and graph. Finally, we share our thoughts on some future research\ndirections of FSLG. The authors of this survey have contributed significantly\nto the AI literature on FSLG over the last few years.",
    "descriptor": "",
    "authors": [
      "Chuxu Zhang",
      "Kaize Ding",
      "Jundong Li",
      "Xiangliang Zhang",
      "Yanfang Ye",
      "Nitesh V. Chawla",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09308"
  },
  {
    "id": "arXiv:2203.09311",
    "title": "A recursive function coding number theoretic functions",
    "abstract": "We show that there exists a fixed recursive function $e$ such that for all\nfunctions $h\\colon \\mathbb{N}\\to \\mathbb{N}$, there exists an injective\nfunction $c_h\\colon \\mathbb{N}\\to \\mathbb{N}$ such that $c_h(h(n))=e(c_h(n))$,\ni.e., $h=c_h^{-1}ec_h$.",
    "descriptor": "",
    "authors": [
      "Vesa Halava",
      "Tero Harju",
      "Teemu Pirttim\u00e4ki"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.09311"
  },
  {
    "id": "arXiv:2203.09312",
    "title": "Certifiably Optimal Mutual Localization with Anonymous Bearing  Measurements",
    "abstract": "Mutual localization is essential for coordination and cooperation in\nmulti-robot systems. Previous works have tackled this problem by assuming\navailable correspondences between measurements and received odometry\nestimations, which are difficult to acquire, especially for unified robot\nteams. Furthermore, most local optimization methods ask for initial guesses and\nare sensitive to their quality. In this paper, we present a certifiably optimal\nalgorithm that uses only anonymous bearing measurements to formulate a novel\nmixed-integer quadratically constrained quadratic problem (MIQCQP). Then, we\nrelax the original nonconvex problem into a semidefinite programming (SDP)\nproblem and obtain a certifiably global optimum using with off-the-shelf\nsolvers. As a result, our method can determine bearing-pose correspondences and\nfurthermore recover the initial relative poses between robots under a certain\ncondition. We compare the performance with local optimization methods on\nextensive simulations under different noise levels to show our advantage in\nglobal optimality and robustness. Real-world experiments are conducted to show\nthe practicality and robustness.",
    "descriptor": "",
    "authors": [
      "Yingjian Wang",
      "Xiangyong Wen",
      "Longji Yin",
      "Chao Xu",
      "Yanjun Cao",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09312"
  },
  {
    "id": "arXiv:2203.09313",
    "title": "EVA2.0: Investigating Open-Domain Chinese Dialogue Systems with  Large-Scale Pre-Training",
    "abstract": "Large-scale pre-training has shown remarkable performance in building\nopen-domain dialogue systems. However, previous works mainly focus on showing\nand evaluating the conversational performance of the released dialogue model,\nignoring the discussion of some key factors towards a powerful human-like\nchatbot, especially in Chinese scenarios. In this paper, we conduct extensive\nexperiments to investigate these under-explored factors, including data quality\ncontrol, model architecture designs, training approaches, and decoding\nstrategies. We propose EVA2.0, a large-scale pre-trained open-domain Chinese\ndialogue model with 2.8 billion parameters, and make our models and code\npublicly available. To our knowledge, EVA2.0 is the largest open-source Chinese\ndialogue model. Automatic and human evaluations show that our model\nsignificantly outperforms other open-source counterparts. We also discuss the\nlimitations of this work by presenting some failure cases and pose some future\ndirections.",
    "descriptor": "\nComments: 12 pages, 5 figures. The code and pre-trained models are publicly available at this https URL\n",
    "authors": [
      "Yuxian Gu",
      "Jiaxin Wen",
      "Hao Sun",
      "Yi Song",
      "Pei Ke",
      "Chujie Zheng",
      "Zheng Zhang",
      "Jianzhu Yao",
      "Xiaoyan Zhu",
      "Jie Tang",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09313"
  },
  {
    "id": "arXiv:2203.09314",
    "title": "The Sparse Grids Matlab kit -- a Matlab implementation of sparse grids  for high-dimensional function approximation and uncertainty quantification",
    "abstract": "The Sparse Grids Matlab kit is a collection of Matlab functions for\nhigh-dimensional interpolation and quadrature, based on the combination\ntechnique form of sparse grids. It is lightweight, high-level and easy to use,\ngood for quick prototyping and teaching. It is somehow geared towards\nUncertainty Quantification (UQ), but it is flexible enough for other purposes.\nThe goal of this paper is to give an overview of the implementation structure\nof the Sparse Grids Matlab kit and to showcase its potentialities, guided by\nsome illustrative tests and a final comprehensive example on forward and\ninverse UQ analysis.",
    "descriptor": "",
    "authors": [
      "Chiara Piazzola",
      "Lorenzo Tamellini"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.09314"
  },
  {
    "id": "arXiv:2203.09318",
    "title": "A New Analytical Approximation of the Fluid Antenna System Channel",
    "abstract": "Fluid antenna systems (FAS) are an emerging technology that promises a\nsignificant diversity gain even in the smallest spaces. Motivated by the\ngroundbreaking potentials of liquid antennas, researchers in the wireless\ncommunication community are investigating a novel antenna system where a single\nantenna can freely switch positions along a small linear space to pick the\nstrongest received signal. However, the FAS positions do not necessarily follow\nthe ever-existing rule separating them by at least half the radiation\nwavelength. Previous work in the literature parameterized the channels of the\nFAS ports simply enough to provide a single-integral expression of the\nprobability of outage and various insights on the achievable performance.\nNevertheless, this channel model may not accurately capture the correlation\nbetween the ports, given by Jake's model. This work builds on the\nstate-of-the-art and accurately approximates the FAS channel while maintaining\nanalytical tractability. The approximation is performed in two stages. The\nfirst stage approximation considerably reduces the number of multi-fold\nintegrals in the probability of outage expression, while the second stage\napproximation provides a single integral representation of the FAS probability\nof outage. Further, the performance of such innovative technology is\ninvestigated under a less-idealized correlation model. Numerical results\nvalidate our approximations of the FAS channel model and demonstrate a limited\nperformance gain under realistic assumptions. Further, our work opens the door\nfor future research to investigate scenarios in which the FAS provides a\nperformance gain compared to the current multiple antennas solutions.",
    "descriptor": "",
    "authors": [
      "Malek Khammassi",
      "Abla Kammoun",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.09318"
  },
  {
    "id": "arXiv:2203.09321",
    "title": "Non-commutative propositional logic with short-circuited biconditional  and NAND",
    "abstract": "Short-circuit evaluation denotes the semantics of propositional connectives\nin which the second argument is evaluated only if the first argument does not\nsuffice to determine the value of the expression. In programming, short-circuit\nevaluation is widely used, with left-sequential conjunction and disjunction as\nprimitive connectives. We consider left-sequential, non-commutative\npropositional logic, also known as MSCL (memorising short-circuit logic), and\nstart from a previously published, equational axiomatisation. First, we extend\nthis logic with a left-sequential version of the biconditional connective,\nwhich allows for an elegant axiomatisation of MSCL. Next, we consider a\nleft-sequential version of the NAND operator (the Sheffer stroke) and again\ngive a complete, equational axiomatisation of the corresponding variant of\nMSCL. Finally, we consider these logical systems in a three-valued setting with\na constant for `undefined', and again provide completeness results.",
    "descriptor": "\nComments: 21 pages, 6 tables\n",
    "authors": [
      "Dalia Papuc",
      "Alban Ponse"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.09321"
  },
  {
    "id": "arXiv:2203.09324",
    "title": "Localizing Visual Sounds the Easy Way",
    "abstract": "Unsupervised audio-visual source localization aims at localizing visible\nsound sources in a video without relying on ground-truth localization for\ntraining. Previous works often seek high audio-visual similarities for likely\npositive (sounding) regions and low similarities for likely negative regions.\nHowever, accurately distinguishing between sounding and non-sounding regions is\nchallenging without manual annotations. In this work, we propose a simple yet\neffective approach for Easy Visual Sound Localization, namely EZ-VSL, without\nrelying on the construction of positive and/or negative regions during\ntraining. Instead, we align audio and visual spaces by seeking audio-visual\nrepresentations that are aligned in, at least, one location of the associated\nimage, while not matching other images, at any location. We also introduce a\nnovel object guided localization scheme at inference time for improved\nprecision. Our simple and effective framework achieves state-of-the-art\nperformance on two popular benchmarks, Flickr SoundNet and VGG-Sound Source. In\nparticular, we improve the CIoU of the Flickr SoundNet test set from 76.80% to\n83.94%, and on the VGG-Sound Source dataset from 34.60% to 38.85%. The code is\navailable at https://github.com/stoneMo/EZ-VSL.",
    "descriptor": "",
    "authors": [
      "Shentong Mo",
      "Pedro Morgado"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.09324"
  },
  {
    "id": "arXiv:2203.09325",
    "title": "Application of Data Collected by Endpoint Detection and Response Systems  for Implementation of a Network Security System based on Zero Trust  Principles and the EigenTrust Algorithm",
    "abstract": "Traditionally, security systems for enterprises have implicit access based on\nstrong cryptography, authentication and key sharing, wherein access control is\nbased on Role Based Access Control (RBAC), in which roles such as manager,\naccountant and so on provide a way of deciding a subject's authority. However,\nyears of post-attack analysis on enterprise networks has shown that a majority\nof times, security breaches occur intentionally or accidently due to implicitly\ntrusted people of an enterprise itself. Zero Trust Architecture works on the\nprinciple of never granting trust implicitly, but rather continuously\nevaluating the trust parameters for each resource access request and has a\nstrict, but not rigid, set of protocols for access control of a subject to\nresources. Endpoint Detection and Response (EDR) systems are tools that collect\na large number of attributes in and around machines within an enterprise\nnetwork to have close visibility into sophisticated intrusion. In our work, we\nseek to deploy EDR systems and build trust algorithms using tactical provenance\nanalysis, threshold cryptography and reputation management to continuously\nrecord data, evaluate trust of a subject, and simultaneously analyze them\nagainst a database of known threat vectors to provide conditional access\ncontrol. However, EDR tools generate a high volume of data that leads to false\nalarms, misdetections and correspondingly a high backlog of tasks that makes it\ninfeasible, which is addressed using tactical provenance analysis and\ninformation theory.",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "Nitesh Kumar",
      "Gaurav S. Kasbekar",
      "D. Manjunath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.09325"
  },
  {
    "id": "arXiv:2203.09326",
    "title": "Combining Static and Contextualised Multilingual Embeddings",
    "abstract": "Static and contextual multilingual embeddings have complementary strengths.\nStatic embeddings, while less expressive than contextual language models, can\nbe more straightforwardly aligned across multiple languages. We combine the\nstrengths of static and contextual models to improve multilingual\nrepresentations. We extract static embeddings for 40 languages from XLM-R,\nvalidate those embeddings with cross-lingual word retrieval, and then align\nthem using VecMap. This results in high-quality, highly multilingual static\nembeddings. Then we apply a novel continued pre-training approach to XLM-R,\nleveraging the high quality alignment of our static embeddings to better align\nthe representation space of XLM-R. We show positive results for multiple\ncomplex semantic tasks. We release the static embeddings and the continued\npre-training code. Unlike most previous work, our continued pre-training\napproach does not require parallel text.",
    "descriptor": "\nComments: Accepted to Findings of ACL 2022\n",
    "authors": [
      "Katharina H\u00e4mmerl",
      "Jind\u0159ich Libovick\u00fd",
      "Alexander Fraser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09326"
  },
  {
    "id": "arXiv:2203.09327",
    "title": "A Pricing Mechanism for Balancing the Charging of Ride-Hailing Electric  Vehicle Fleets",
    "abstract": "Both ride-hailing services and electric vehicles are becoming increasingly\npopular and it is likely that charging management of the ride-hailing vehicles\nwill be a significant part of the ride-hailing company's operation in the near\nfuture. Motivated by this, we propose a game theoretic model for charging\nmanagement, where we assume that it is the fleet-operator that wants to\nminimize its operational cost, which among others include the price of\ncharging. To avoid overcrowded charging stations, a central authority will\ndesign pricing policies to incentivize the vehicles to spread out among the\ncharging stations, in a setting where several ride-hailing companies compete\nabout the resources. We show that it is possible to construct pricing policies\nthat make the Nash-equilibrium between the companies follow the central\nauthority's target value when the desired load is feasible. Moreover, we\nprovide a decentralized algorithm for computation of the equilibrium and\nconclude the paper with a numerical example illustrating the results.",
    "descriptor": "\nComments: Extended version of the paper accepted to the European Control Conference 2022\n",
    "authors": [
      "Marko Maljkovic",
      "Gustav Nilsson",
      "Nikolas Geroliminis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.09327"
  },
  {
    "id": "arXiv:2203.09332",
    "title": "Machine Learning for Encrypted Malicious Traffic Detection: Approaches,  Datasets and Comparative Study",
    "abstract": "As people's demand for personal privacy and data security becomes a priority,\nencrypted traffic has become mainstream in the cyber world. However, traffic\nencryption is also shielding malicious and illegal traffic introduced by\nadversaries, from being detected. This is especially so in the post-COVID-19\nenvironment where malicious traffic encryption is growing rapidly. Common\nsecurity solutions that rely on plain payload content analysis such as deep\npacket inspection are rendered useless. Thus, machine learning based approaches\nhave become an important direction for encrypted malicious traffic detection.\nIn this paper, we formulate a universal framework of machine learning based\nencrypted malicious traffic detection techniques and provided a systematic\nreview. Furthermore, current research adopts different datasets to train their\nmodels due to the lack of well-recognized datasets and feature sets. As a\nresult, their model performance cannot be compared and analyzed reliably.\nTherefore, in this paper, we analyse, process and combine datasets from 5\ndifferent sources to generate a comprehensive and fair dataset to aid future\nresearch in this field. On this basis, we also implement and compare 10\nencrypted malicious traffic detection algorithms. We then discuss challenges\nand propose future directions of research.",
    "descriptor": "",
    "authors": [
      "Zihao Wang",
      "Kar-Wai Fok",
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.09332"
  },
  {
    "id": "arXiv:2203.09333",
    "title": "Modulated Contrast for Versatile Image Synthesis",
    "abstract": "Perceiving the similarity between images has been a long-standing and\nfundamental problem underlying various visual generation tasks. Predominant\napproaches measure the inter-image distance by computing pointwise absolute\ndeviations, which tends to estimate the median of instance distributions and\nleads to blurs and artifacts in the generated images. This paper presents\nMoNCE, a versatile metric that introduces image contrast to learn a calibrated\nmetric for the perception of multifaceted inter-image distances. Unlike vanilla\ncontrast which indiscriminately pushes negative samples from the anchor\nregardless of their similarity, we propose to re-weight the pushing force of\nnegative samples adaptively according to their similarity to the anchor, which\nfacilitates the contrastive learning from informative negative samples. Since\nmultiple patch-level contrastive objectives are involved in image distance\nmeasurement, we introduce optimal transport in MoNCE to modulate the pushing\nforce of negative samples collaboratively across multiple contrastive\nobjectives. Extensive experiments over multiple image translation tasks show\nthat the proposed MoNCE outperforms various prevailing metrics substantially.\nThe code is available at https://github.com/fnzhan/MoNCE.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Fangneng Zhan",
      "Jiahui Zhang",
      "Yingchen Yu",
      "Rongliang Wu",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09333"
  },
  {
    "id": "arXiv:2203.09334",
    "title": "Stronger 3SUM-Indexing Lower Bounds",
    "abstract": "The $3$SUM-Indexing problem was introduced as a data structure version of the\n$3$SUM problem, with the goal of proving strong conditional lower bounds for\nstatic data structures via reductions. Ideally, the conjectured hardness of\n$3$SUM-Indexing should be replaced by an unconditional lower bound.\nUnfortunately, we are far from proving this, with the strongest current lower\nbound being a logarithmic query time lower bound by Golovnev et al. from\nSTOC'20. Moreover, their lower bound holds only for non-adaptive data\nstructures and they explicitly asked for a lower bound for adaptive data\nstructures. Our main contribution is precisely such a lower bound against\nadaptive data structures. As a secondary result, we also strengthen the\nnon-adaptive lower bound of Golovnev et al. and prove strong lower bounds for\n$2$-bit-probe non-adaptive $3$SUM-Indexing data structures via a completely new\napproach that we find interesting in its own right.",
    "descriptor": "",
    "authors": [
      "Eldon Chung",
      "Kasper Green Larsen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.09334"
  },
  {
    "id": "arXiv:2203.09337",
    "title": "cRoK: A Composable Robotics Benchmark",
    "abstract": "Selecting an optimal robot and configuring it for a given task is currently\nmostly done by human expertise or trial and error. To evaluate automatic\nselection and adaptation of robots to specific tasks, we introduce a benchmark\nsuite encompassing a common format for robots, environments, and task\ndescriptions. Our benchmark suite is especially useful for modular robots,\nwhere the creation of the robots themselves creates a host of additional\nparameters to optimize. The benchmark defines this optimization and facilitates\nthe comparison of solution algorithms. All benchmarks are accessible through a\nwebsite to conveniently share, reference, and compare solutions.",
    "descriptor": "\nComments: Under review for IROS'22\n",
    "authors": [
      "Matthias Mayer",
      "Jonathan K\u00fclz",
      "Matthias Althoff"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09337"
  },
  {
    "id": "arXiv:2203.09338",
    "title": "Object Localization under Single Coarse Point Supervision",
    "abstract": "Point-based object localization (POL), which pursues high-performance object\nsensing under low-cost data annotation, has attracted increased attention.\nHowever, the point annotation mode inevitably introduces semantic variance for\nthe inconsistency of annotated points. Existing POL methods heavily reply on\naccurate key-point annotations which are difficult to define. In this study, we\npropose a POL method using coarse point annotations, relaxing the supervision\nsignals from accurate key points to freely spotted points. To this end, we\npropose a coarse point refinement (CPR) approach, which to our best knowledge\nis the first attempt to alleviate semantic variance from the perspective of\nalgorithm. CPR constructs point bags, selects semantic-correlated points, and\nproduces semantic center points through multiple instance learning (MIL). In\nthis way, CPR defines a weakly supervised evolution procedure, which ensures\ntraining high-performance object localizer under coarse point supervision.\nExperimental results on COCO, DOTA and our proposed SeaPerson dataset validate\nthe effectiveness of the CPR approach. The dataset and code will be available\nat https://github.com/ucas-vg/PointTinyBenchmark/.",
    "descriptor": "\nComments: accepted by CVPR2022\n",
    "authors": [
      "Xuehui Yu",
      "Pengfei Chen",
      "Di Wu",
      "Najmul Hassan",
      "Guorong Li",
      "Junchi Yan",
      "Humphrey Shi",
      "Qixiang Ye",
      "Zhenjun Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09338"
  },
  {
    "id": "arXiv:2203.09343",
    "title": "CYBORGS: Contrastively Bootstrapping Object Representations by Grounding  in Segmentation",
    "abstract": "Many recent approaches in contrastive learning have worked to close the gap\nbetween pretraining on iconic images like ImageNet and pretraining on complex\nscenes like COCO. This gap exists largely because commonly used random crop\naugmentations obtain semantically inconsistent content in crowded scene images\nof diverse objects. Previous works use preprocessing pipelines to localize\nsalient objects for improved cropping, but an end-to-end solution is still\nelusive. In this work, we propose a framework which accomplishes this goal via\njoint learning of representations and segmentation. We leverage segmentation\nmasks to train a model with a mask-dependent contrastive loss, and use the\npartially trained model to bootstrap better masks. By iterating between these\ntwo components, we ground the contrastive updates in segmentation information,\nand simultaneously improve segmentation throughout pretraining. Experiments\nshow our representations transfer robustly to downstream tasks in\nclassification, detection and segmentation.",
    "descriptor": "\nComments: 18 pages, with appendix\n",
    "authors": [
      "Renhao Wang",
      "Hang Zhao",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09343"
  },
  {
    "id": "arXiv:2203.09346",
    "title": "Error estimates for physics informed neural networks approximating the  Navier-Stokes equations",
    "abstract": "We prove rigorous bounds on the errors resulting from the approximation of\nthe incompressible Navier-Stokes equations with (extended) physics informed\nneural networks. We show that the underlying PDE residual can be made\narbitrarily small for tanh neural networks with two hidden layers. Moreover,\nthe total error can be estimated in terms of the training error, network size\nand number of quadrature points. The theory is illustrated with numerical\nexperiments.",
    "descriptor": "",
    "authors": [
      "Tim De Ryck",
      "Ameya D. Jagtap",
      "Siddhartha Mishra"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09346"
  },
  {
    "id": "arXiv:2203.09353",
    "title": "Batched matrix operations on distributed GPUs with application in  theoretical physics",
    "abstract": "One of the most important and commonly used operations in many linear algebra\nfunctions is matrix-matrix multiplication (GEMM), which is also a key component\nin obtaining high performance of many scientific codes. It is a computationally\nintensive function requiring $O(n^3)$ operations, and its high computational\nintensity makes it well-suited to be significantly accelerated with GPUs.\nToday, many research problems require solving a very large number of relatively\nsmall GEMM operations that cannot utilise the entire GPU. To overcome this\nbottleneck, special functions have been developed that pack several GEMM\noperations into one and then compute them simultaneously on a GPU, which is\ncalled a batch operation. In this research work, we have proposed a different\napproach based on linking multiple GEMM operations to MPI ranks and then\nbinding multiple MPI ranks to a single GPU. To increase GPU utilisation, more\nMPI ranks (i.e. GEMM operations) are added. We implement and test this approach\nin the field of theoretical physics to compute entanglement properties through\nsimulated annealing Monte Carlo simulation of quantum spin chains. For the\nspecific use case, we were able to simulate a much larger spin system and\nachieve a speed-up of up to $35\\times$ compared to the parallel CPU-only\nversion.",
    "descriptor": "",
    "authors": [
      "Nenad Miji\u0107",
      "Davor Davidovi\u0107"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.09353"
  },
  {
    "id": "arXiv:2203.09354",
    "title": "Context-Dependent Anomaly Detection with Knowledge Graph Embedding  Models",
    "abstract": "Increasing the semantic understanding and contextual awareness of machine\nlearning models is important for improving robustness and reducing\nsusceptibility to data shifts. In this work, we leverage contextual awareness\nfor the anomaly detection problem. Although graphed-based anomaly detection has\nbeen widely studied, context-dependent anomaly detection is an open problem and\nwithout much current research. We develop a general framework for converting a\ncontext-dependent anomaly detection problem to a link prediction problem,\nallowing well-established techniques from this domain to be applied. We\nimplement a system based on our framework that utilizes knowledge graph\nembedding models and demonstrates the ability to detect outliers using context\nprovided by a semantic knowledge base. We show that our method can detect\ncontext-dependent anomalies with a high degree of accuracy and show that\ncurrent object detectors can detect enough classes to provide the needed\ncontext for good performance within our example domain.",
    "descriptor": "",
    "authors": [
      "Nathan Vaska",
      "Victoria Helus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09354"
  },
  {
    "id": "arXiv:2203.09358",
    "title": "Low-rank Wasserstein polynomial chaos expansions in the framework of  optimal transport",
    "abstract": "A unsupervised learning approach for the computation of an explicit\nfunctional representation of a random vector $Y$ is presented, which only\nrelies on a finite set of samples with unknown distribution. Motivated by\nrecent advances with computational optimal transport for estimating Wasserstein\ndistances, we develop a new \\textit{Wasserstein multi-element polynomial chaos\nexpansion} (WPCE). It relies on the minimization of a regularized empirical\nWasserstein metric known as debiased Sinkhorn divergence.\nAs a requirement for an efficient polynomial basis expansion, a suitable\n(minimal) stochastic coordinate system $X$ has to be determined with the aim to\nidentify ideally independent random variables. This approach generalizes\nrepresentations through diffeomorphic transport maps to the case of\nnon-continuous and non-injective model classes $\\mathcal{M}$ with different\ninput and output dimension, yielding the relation $Y=\\mathcal{M}(X)$ in\ndistribution. Moreover, since the used PCE grows exponentially in the number of\nrandom coordinates of $X$, we introduce an appropriate low-rank format given as\nstacks of tensor trains, which alleviates the curse of dimensionality, leading\nto only linear dependence on the input dimension. By the choice of the model\nclass $\\mathcal{M}$ and the smooth loss function, higher order optimization\nschemes become possible. It is shown that the relaxation to a discontinuous\nmodel class is necessary to explain multimodal distributions. Moreover, the\nproposed framework is applied to a numerical upscaling task, considering a\ncomputationally challenging microscopic random non-periodic composite material.\nThis leads to tractable effective macroscopic random field in adopted\nstochastic coordinates.",
    "descriptor": "",
    "authors": [
      "Robert Gruhlke",
      "Martin Eigel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.09358"
  },
  {
    "id": "arXiv:2203.09360",
    "title": "Behavior-aware Account De-anonymization on Ethereum Interaction Graph",
    "abstract": "Blockchain technology has the characteristics of decentralization,\ntraceability and tamper-proof, which creates a reliable decentralized trust\nmechanism, further accelerating the development of blockchain finance. However,\nthe anonymization of blockchain hinders market regulation, resulting in\nincreasing illegal activities such as money laundering, gambling and phishing\nfraud on blockchain financial platforms. Thus financial security has become a\ntop priority in the blockchain ecosystem, calling for effective market\nregulation. In this paper, we consider identifying Ethereum accounts from a\ngraph classification perspective, and propose an end-to-end graph neural\nnetwork framework named Ethident, to characterize the behavior patterns of\naccounts and further achieve account de-anonymization. Specifically, we first\nconstruct an Account Interaction Graph (AIG) using raw Ethereum data. Then we\ndesign a hierarchical graph attention encoder named HGATE as the backbone of\nour framework, which can effectively characterize the node-level account\nfeatures and subgraph-level behavior patterns. For alleviating account label\nsparsity, we further introduce contrastive self-supervision mechanism as\nregularization to jointly train our framework. Comprehensive experiments on\nEthereum datasets demonstrate that our framework achieves superior performance\nin account identification, yielding 1.13% - 4.93% relative improvement over\nprevious state-of-the-art. Furthermore, detailed analyses illustrate the\neffectiveness of Ethident in identifying and understanding the behavior of\nknown participants in Ethereum (e.g. exchanges, miners, etc.), as well as that\nof the lawbreakers (e.g. phishing scammers, hackers, etc.), which may aid in\nrisk assessment and market regulation.",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Jiajun Zhou",
      "Chenkai Hu",
      "Jianlei Chi",
      "Jiajing Wu",
      "Meng Shen",
      "Qi Xuan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.09360"
  },
  {
    "id": "arXiv:2203.09361",
    "title": "Expressivity of Planning with Horn Description Logic Ontologies  (Technical Report)",
    "abstract": "State constraints in AI Planning globally restrict the legal environment\nstates. Standard planning languages make closed-domain and closed-world\nassumptions. Here we address open-world state constraints formalized by\nplanning over a description logic (DL) ontology. Previously, this combination\nof DL and planning has been investigated for the light-weight DL DL-Lite. Here\nwe propose a novel compilation scheme into standard PDDL with derived\npredicates, which applies to more expressive DLs and is based on the\nrewritability of DL queries into Datalog with stratified negation. We also\nprovide a new rewritability result for the DL Horn-ALCHOIQ, which allows us to\napply our compilation scheme to quite expressive ontologies. In contrast, we\nshow that in the slight extension Horn-SROIQ no such compilation is possible\nunless the weak exponential hierarchy collapses. Finally, we show that our\napproach can outperform previous work on existing benchmarks for planning with\nDL ontologies, and is feasible on new benchmarks taking advantage of more\nexpressive ontologies. That is an extended version of a paper accepted at AAAI\n22.",
    "descriptor": "\nComments: 16 pages with appendix\n",
    "authors": [
      "Stefan Borgwardt",
      "J\u00f6rg Hoffmann",
      "Alisa Kovtunova",
      "Markus Kr\u00f6tzsch",
      "Bernhard Nebel",
      "Marcel Steinmetz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.09361"
  },
  {
    "id": "arXiv:2203.09362",
    "title": "Fine Detailed Texture Learning for 3D Meshes with Generative Models",
    "abstract": "This paper presents a method to reconstruct high-quality textured 3D models\nfrom both multi-view and single-view images. The reconstruction is posed as an\nadaptation problem and is done progressively where in the first stage, we focus\non learning accurate geometry, whereas in the second stage, we focus on\nlearning the texture with a generative adversarial network. In the generative\nlearning pipeline, we propose two improvements. First, since the learned\ntextures should be spatially aligned, we propose an attention mechanism that\nrelies on the learnable positions of pixels. Secondly, since discriminator\nreceives aligned texture maps, we augment its input with a learnable embedding\nwhich improves the feedback to the generator. We achieve significant\nimprovements on multi-view sequences from Tripod dataset as well as on\nsingle-view image datasets, Pascal 3D+ and CUB. We demonstrate that our method\nachieves superior 3D textured models compared to the previous works. Please\nvisit our web-page for 3D visuals.",
    "descriptor": "",
    "authors": [
      "Aysegul Dundar",
      "Jun Gao",
      "Andrew Tao",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09362"
  },
  {
    "id": "arXiv:2203.09364",
    "title": "Interacting Attention Graph for Single Image Two-Hand Reconstruction",
    "abstract": "Graph convolutional network (GCN) has achieved great success in single hand\nreconstruction task, while interacting two-hand reconstruction by GCN remains\nunexplored. In this paper, we present Interacting Attention Graph Hand\n(IntagHand), the first graph convolution based network that reconstructs two\ninteracting hands from a single RGB image. To solve occlusion and interaction\nchallenges of two-hand reconstruction, we introduce two novel attention based\nmodules in each upsampling step of the original GCN. The first module is the\npyramid image feature attention (PIFA) module, which utilizes multiresolution\nfeatures to implicitly obtain vertex-to-image alignment. The second module is\nthe cross hand attention (CHA) module that encodes the coherence of interacting\nhands by building dense cross-attention between two hand vertices. As a result,\nour model outperforms all existing two-hand reconstruction methods by a large\nmargin on InterHand2.6M benchmark. Moreover, ablation studies verify the\neffectiveness of both PIFA and CHA modules for improving the reconstruction\naccuracy. Results on in-the-wild images further demonstrate the generalization\nability of our network. Our code is available at\nhttps://github.com/Dw1010/IntagHand.",
    "descriptor": "\nComments: To appear in CVPR 2022\n",
    "authors": [
      "Mengcheng Li",
      "Liang An",
      "Hongwen Zhang",
      "Lianpeng Wu",
      "Feng Chen",
      "Tao Yu",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09364"
  },
  {
    "id": "arXiv:2203.09365",
    "title": "Semi-Markov Offline Reinforcement Learning for Healthcare",
    "abstract": "Reinforcement learning (RL) tasks are typically framed as Markov Decision\nProcesses (MDPs), assuming that decisions are made at fixed time intervals.\nHowever, many applications of great importance, including healthcare, do not\nsatisfy this assumption, yet they are commonly modelled as MDPs after an\nartificial reshaping of the data. In addition, most healthcare (and similar)\nproblems are offline by nature, allowing for only retrospective studies. To\naddress both challenges, we begin by discussing the Semi-MDP (SMDP) framework,\nwhich formally handles actions of variable timings. We next present a formal\nway to apply SMDP modifications to nearly any given value-based offline RL\nmethod. We use this theory to introduce three SMDP-based offline RL algorithms,\nnamely, SDQN, SDDQN, and SBCQ. We then experimentally demonstrate that these\nSMDP-based algorithms learn the optimal policy in these variable-time\nenvironments, whereas un-directed modifications of MDP modelling lead to\nsub-optimal policies. Finally, we apply our new algorithms to a real-world\noffline dataset pertaining to warfarin dosing for stroke prevention and\ndemonstrate similar results.",
    "descriptor": "\nComments: Published at Conference on Health, Inference, and Learning (CHIL) 2022\n",
    "authors": [
      "Mehdi Fatemi",
      "Mary Wu",
      "Jeremy Petch",
      "Walter Nelson",
      "Stuart J. Connolly",
      "Alexander Benz",
      "Anthony Carnicelli",
      "Marzyeh Ghassemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09365"
  },
  {
    "id": "arXiv:2203.09367",
    "title": "Admission Control and Resource Reservation for Prioritized Slice  Requests with Guaranteed SLA under Uncertainties",
    "abstract": "Network slicing has emerged as a key concept in 5G systems, allowing Mobile\nNetwork Operators (MNOs) to build isolated logical networks (slices) on top of\nshared infrastructure networks managed by Infrastructure Providers (InP).\nNetwork slicing requires the assignment of infrastructure network resources to\nvirtual network components at slice activation time and the adjustment of\nresources for slices under operation. Performing these operations just-in-time,\non a best-effort basis, comes with no guarantee on the availability of enough\ninfrastructure resources to meet slice requirements.\nThis paper proposes a prioritized admission control mechanism for concurrent\nslices based on an infrastructure resource reservation approach. The\nreservation accounts for the dynamic nature of slice requests while being\nrobust to uncertainties in slice resource demands. Adopting the perspective of\nan InP, reservation schemes are proposed that maximize the number of slices for\nwhich infrastructure resources can be granted while minimizing the costs\ncharged to the MNOs. This requires the solution of a max-min optimization\nproblem with a non-linear cost function and non-linear constraints induced by\nthe robustness to uncertainties of demands and the limitation of the impact of\nreservation on background services. The cost and the constraints are linearized\nand several reduced-complexity strategies are proposed to solve the slice\nadmission control and resource reservation problem. Simulations show that the\nproportion of admitted slices of different priority levels can be adjusted by a\ndifferentiated selection of the delay between the reception and the processing\ninstants of a slice resource request.",
    "descriptor": "\nComments: Accepted to be published in IEEE Transactions on Network and Service Management\n",
    "authors": [
      "Quang-Trung Luu",
      "Sylvaine Kerboeuf",
      "Michel Kieffer"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.09367"
  },
  {
    "id": "arXiv:2203.09371",
    "title": "Transforming Gait: Video-Based Spatiotemporal Gait Analysis",
    "abstract": "Human pose estimation from monocular video is a rapidly advancing field that\noffers great promise to human movement science and rehabilitation. This\npotential is tempered by the smaller body of work ensuring the outputs are\nclinically meaningful and properly calibrated. Gait analysis, typically\nperformed in a dedicated lab, produces precise measurements including\nkinematics and step timing. Using over 7000 monocular video from an\ninstrumented gait analysis lab, we trained a neural network to map 3D joint\ntrajectories and the height of individuals onto interpretable biomechanical\noutputs including gait cycle timing and sagittal plane joint kinematics and\nspatiotemporal trajectories. This task specific layer produces accurate\nestimates of the timing of foot contact and foot off events. After parsing the\nkinematic outputs into individual gait cycles, it also enables accurate\ncycle-by-cycle estimates of cadence, step time, double and single support time,\nwalking speed and step length.",
    "descriptor": "",
    "authors": [
      "R. James Cotton",
      "Emoonah McClerklin",
      "Anthony Cimorelli",
      "Ankit Patel",
      "Tasos Karakostas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2203.09371"
  },
  {
    "id": "arXiv:2203.09374",
    "title": "A Systematic Study of Android Non-SDK (Hidden) Service API Security",
    "abstract": "Android allows apps to communicate with its system services via system\nservice helpers so that these apps can use various functions provided by the\nsystem services. Meanwhile, the system services rely on their service helpers\nto enforce security checks for protection. Unfortunately, the security checks\nin the service helpers may be bypassed via directly exploiting the non-SDK\n(hidden) APIs, degrading the stability and posing severe security threats such\nas privilege escalation, automatic function execution without users'\ninteractions, crashes, and DoS attacks. Google has proposed various approaches\nto address this problem, e.g., case-by-case fixing the bugs or even proposing a\nblacklist to block all the non-SDK APIs. However, the developers can still\nfigure out new ways of exploiting these hidden APIs to evade the non-SDKs\nrestrictions.\nIn this paper, we systematically study the vulnerabilities due to the hidden\nAPI exploitation and analyze the effectiveness of Google's countermeasures. We\naim to answer if there are still vulnerable hidden APIs that can be exploited\nin the newest Android 12. We develop a static analysis tool called ServiceAudit\nto automatically mine the inconsistent security enforcement between service\nhelper classes and the hidden service APIs. We apply ServiceAudit to Android\n6~12. Our tool discovers 112 vulnerabilities in Android 6 with higher precision\nthan existing approaches. Moreover, in Android 11 and 12, we identify more than\n25 hidden APIs with inconsistent protections; however, only one of the\nvulnerable APIs can lead to severe security problems in Android 11, and none of\nthem work on Android 12.",
    "descriptor": "",
    "authors": [
      "Yi He",
      "Yacong Gu",
      "Purui Su",
      "Kun Sun",
      "Yajin Zhou",
      "Zhi Wang",
      "Qi Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.09374"
  },
  {
    "id": "arXiv:2203.09375",
    "title": "Neural Part Priors: Learning to Optimize Part-Based Object Completion in  RGB-D Scans",
    "abstract": "3D object recognition has seen significant advances in recent years, showing\nimpressive performance on real-world 3D scan benchmarks, but lacking in object\npart reasoning, which is fundamental to higher-level scene understanding such\nas inter-object similarities or object functionality. Thus, we propose to\nleverage large-scale synthetic datasets of 3D shapes annotated with part\ninformation to learn Neural Part Priors (NPPs), optimizable spaces\ncharacterizing geometric part priors. Crucially, we can optimize over the\nlearned part priors in order to fit to real-world scanned 3D scenes at test\ntime, enabling robust part decomposition of the real objects in these scenes\nthat also estimates the complete geometry of the object while fitting\naccurately to the observed real geometry. Moreover, this enables global\noptimization over geometrically similar detected objects in a scene, which\noften share strong geometric commonalities, enabling scene-consistent part\ndecompositions. Experiments on the ScanNet dataset demonstrate that NPPs\nsignificantly outperforms state of the art in part decomposition and object\ncompletion in real-world scenes.",
    "descriptor": "",
    "authors": [
      "Alexey Bokhovkin",
      "Angela Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09375"
  },
  {
    "id": "arXiv:2203.09378",
    "title": "Revealing the determinants of gender inequality in urban cycling with  large-scale data",
    "abstract": "Cycling is an outdoor activity with massive health benefits, and an effective\nsolution towards sustainable urban transport. Despite these benefits and the\nrecent rising popularity of cycling, most countries still have a negligible\nuptake. This uptake is especially low for women: there is a largely\nunexplained, persistent gender gap in cycling. To understand the determinants\nof this gender gap in cycling at scale, here we use massive,\nautomatically-collected data from the tracking application Strava on outdoor\ncycling for 61 cities across the United States, the United Kingdom, Italy and\nthe Benelux area. Leveraging the associated gender and usage information, we\nfirst quantify the emerging gender gap in recreational cycling at city-level. A\ncomparison of cycling rates of women across cities within similar geographical\nareas unveils a broad range of gender gaps. On a macroscopic level, we link\nthis heterogeneity to a variety of urban indicators and provide evidence for\ntraditional hypotheses on the determinants of the gender-cycling-gap. We find a\npositive association between female cycling rate and urban road safety. On a\nmicroscopic level, we identify female preferences for street-specific features\nin the city of New York. Enhancing the quality of the dedicated cycling\ninfrastructure may be a way to make urban environments more accessible for\nwomen, thereby making urban transport more sustainable for everyone.",
    "descriptor": "",
    "authors": [
      "Alice Battiston",
      "Ludovico Napoli",
      "Paolo Bajardi",
      "Andr\u00e9 Panisson",
      "Alan Perotti",
      "Michael Szell",
      "Rossano Schifanella"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.09378"
  },
  {
    "id": "arXiv:2203.09379",
    "title": "Analysis of Arbitrary Content on Blockchain-Based Systems using BigQuery",
    "abstract": "Blockchain-based systems have gained immense popularity as enablers of\nindependent asset transfers and smart contract functionality. They have also,\nsince as early as the first Bitcoin blocks, been used for storing arbitrary\ncontents such as texts and images. On-chain data storage functionality is\nuseful for a variety of legitimate use cases. It does, however, also pose a\nsystematic risk. If abused, for example by posting illegal contents on a public\nblockchain, data storage functionality can lead to legal consequences for\noperators and users that need to store and distribute the blockchain, thereby\nthreatening the operational availability of entire blockchain ecosystems. In\nthis paper, we develop and apply a cloud-based approach for quickly discovering\nand classifying content on public blockchains. Our method can be adapted to\ndifferent blockchain systems and offers insights into content-related usage\npatterns and potential cases of abuse. We apply our method on the two most\nprominent public blockchain systems - Bitcoin and Ethereum - and discuss our\nresults. To the best of our knowledge, the presented study is the first to\nsystematically analyze non-financial content stored on the Ethereum blockchain\nand the first to present a side-by-side comparison between different\nblockchains in terms of the quality and quantity of stored data.",
    "descriptor": "\nComments: Accepted at 1st International Cryptoasset Analytics Workshop (CAAW), ACM TheWebConf 2022\n",
    "authors": [
      "Marcel Gregoriadis",
      "Robert Muth",
      "Martin Florian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.09379"
  },
  {
    "id": "arXiv:2203.09382",
    "title": "Euler State Networks",
    "abstract": "Inspired by the numerical solution of ordinary differential equations, in\nthis paper we propose a novel Reservoir Computing (RC) model, called the Euler\nState Network (EuSN). The introduced approach makes use of forward Euler\ndiscretization and antisymmetric recurrent matrices to design reservoir\ndynamics that are both stable and non-dissipative by construction.\nOur mathematical analysis shows that the resulting model is biased towards\nunitary effective spectral radius and zero local Lyapunov exponents,\nintrinsically operating at the edge of stability. Experiments on synthetic\ntasks indicate the marked superiority of the proposed approach, compared to\nstandard RC models, in tasks requiring long-term memorization skills.\nFurthermore, results on real-world time series classification benchmarks point\nout that EuSN is capable of matching (or even surpassing) the level of accuracy\nof trainable Recurrent Neural Networks, while allowing up to 100-fold savings\nin computation time and energy consumption.",
    "descriptor": "\nComments: paper submitted to journal\n",
    "authors": [
      "Claudio Gallicchio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09382"
  },
  {
    "id": "arXiv:2203.09384",
    "title": "Benchmarking a Proof-of-Concept Performance Portable SYCL-based Fast  Fourier Transformation Library",
    "abstract": "In this paper, we present an early version of a SYCL-based FFT library,\ncapable of running on all major vendor hardware, including CPUs and GPUs from\nAMD, ARM, Intel and NVIDIA. Although preliminary, the aim of this work is to\nseed further developments for a rich set of features for calculating FFTs. It\nhas the advantage over existing portable FFT libraries in that it is\nsingle-source, and therefore removes the complexities that arise due to\nabundant use of pre-process macros and auto-generated kernels to target\ndifferent architectures. We exercise two SYCL-enabled compilers, Codeplay\nComputeCpp and Intel's open-source LLVM project, to evaluate performance\nportability of our SYCL-based FFT on various heterogeneous architectures. The\ncurrent limitations of our library is it supports single-dimension FFTs up to\n$2^{11}$ in length and base-2 input sequences. We compare our results with\nhighly optimized vendor specific FFT libraries and provide a detailed analysis\nto demonstrate a fair level of performance, as well as potential sources of\nperformance bottlenecks.",
    "descriptor": "\nComments: 12 pages, 6 figures, submitted to IWOCL 2022\n",
    "authors": [
      "Vincent R. Pascuzzi",
      "Mehdi Goli"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Mathematical Software (cs.MS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.09384"
  },
  {
    "id": "arXiv:2203.09385",
    "title": "DXQ-Net: Differentiable LiDAR-Camera Extrinsic Calibration Using  Quality-aware Flow",
    "abstract": "Accurate LiDAR-camera extrinsic calibration is a precondition for many\nmulti-sensor systems in mobile robots. Most calibration methods rely on\nlaborious manual operations and calibration targets. While working online, the\ncalibration methods should be able to extract information from the environment\nto construct the cross-modal data association. Convolutional neural networks\n(CNNs) have powerful feature extraction ability and have been used for\ncalibration. However, most of the past methods solve the extrinsic as a\nregression task, without considering the geometric constraints involved. In\nthis paper, we propose a novel end-to-end extrinsic calibration method named\nDXQ-Net, using a differentiable pose estimation module for generalization. We\nformulate a probabilistic model for LiDAR-camera calibration flow, yielding a\nprediction of uncertainty to measure the quality of LiDAR-camera data\nassociation. Testing experiments illustrate that our method achieves a\ncompetitive with other methods for the translation component and\nstate-of-the-art performance for the rotation component. Generalization\nexperiments illustrate that the generalization performance of our method is\nsignificantly better than other deep learning-based methods.",
    "descriptor": "",
    "authors": [
      "Xin Jing",
      "Xiaqing Ding",
      "Rong Xiong",
      "Huanjun Deng",
      "Yue Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09385"
  },
  {
    "id": "arXiv:2203.09387",
    "title": "One-Stage Deep Edge Detection Based on Dense-Scale Feature Fusion and  Pixel-Level Imbalance Learning",
    "abstract": "Edge detection, a basic task in the field of computer vision, is an important\npreprocessing operation for the recognition and understanding of a visual\nscene. In conventional models, the edge image generated is ambiguous, and the\nedge lines are also very thick, which typically necessitates the use of\nnon-maximum suppression (NMS) and morphological thinning operations to generate\nclear and thin edge images. In this paper, we aim to propose a one-stage neural\nnetwork model that can generate high-quality edge images without\npostprocessing. The proposed model adopts a classic encoder-decoder framework\nin which a pre-trained neural model is used as the encoder and a\nmulti-feature-fusion mechanism that merges the features of each level with each\nother functions as a learnable decoder. Further, we propose a new loss function\nthat addresses the pixel-level imbalance in the edge image by suppressing the\nfalse positive (FP) edge information near the true positive (TP) edge and the\nfalse negative (FN) non-edge. The results of experiments conducted on several\nbenchmark datasets indicate that the proposed method achieves state-of-the-art\nresults without using NMS and morphological thinning operations.",
    "descriptor": "\nComments: 15,6,41\n",
    "authors": [
      "Dawei Dai",
      "Chunjie Wang",
      "Shuyin Xia",
      "Yingge Liu",
      "Guoyin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09387"
  },
  {
    "id": "arXiv:2203.09388",
    "title": "A Text Attention Network for Spatial Deformation Robust Scene Text Image  Super-resolution",
    "abstract": "Scene text image super-resolution aims to increase the resolution and\nreadability of the text in low-resolution images. Though significant\nimprovement has been achieved by deep convolutional neural networks (CNNs), it\nremains difficult to reconstruct high-resolution images for spatially deformed\ntexts, especially rotated and curve-shaped ones. This is because the current\nCNN-based methods adopt locality-based operations, which are not effective to\ndeal with the variation caused by deformations. In this paper, we propose a CNN\nbased Text ATTention network (TATT) to address this problem. The semantics of\nthe text are firstly extracted by a text recognition module as text prior\ninformation. Then we design a novel transformer-based module, which leverages\nglobal attention mechanism, to exert the semantic guidance of text prior to the\ntext reconstruction process. In addition, we propose a text structure\nconsistency loss to refine the visual appearance by imposing structural\nconsistency on the reconstructions of regular and deformed texts. Experiments\non the benchmark TextZoom dataset show that the proposed TATT not only achieves\nstate-of-the-art performance in terms of PSNR/SSIM metrics, but also\nsignificantly improves the recognition accuracy in the downstream text\nrecognition task, particularly for text instances with multi-orientation and\ncurved shapes. Code is available at https://github.com/mjq11302010044/TATT.",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Jianqi Ma",
      "Zhetong Liang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09388"
  },
  {
    "id": "arXiv:2203.09390",
    "title": "A Cube Algebra with Comparative Operations: Containment, Overlap,  Distance and Usability",
    "abstract": "In this paper, we provide a comprehensive rigorous modeling for\nmultidimensional spaces with hierarchically structured dimensions in several\nlayers of abstractions and data cubes that live in such spaces. We model cube\nqueries and their semantics and define typical OLAP operators like Selections,\nRoll-Up, Drill-Down, etc. The model serves as the basis to offer the main\ncontribution of this paper which includes theorems and algorithms for being\nable to associate data cube queries via comparative operations that are\nevaluated only on the syntax of the queries involved. Specifically, these\noperations include: (a) foundational containment, referring to the coverage of\ncommon parts of the most detailed level of aggregation of the multidimensional\nspace, (b/c) same-level containment and intersection, referring to the\ninclusion/existence of common parts of the multidimensional space in two query\nresults of the same aggregation levels, (d) query distance, referring to being\nable to assess the similarity of two queries in the same multidimensional\nspace, and, (e) cube usability, i.e., the possibility of computing a new cube\nfrom a previous one, defined at a different level of abstraction.",
    "descriptor": "",
    "authors": [
      "Panos Vassiliadis"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.09390"
  },
  {
    "id": "arXiv:2203.09391",
    "title": "When Chosen Wisely, More Data Is What You Need: A Universal  Sample-Efficient Strategy For Data Augmentation",
    "abstract": "Data Augmentation (DA) is known to improve the generalizability of deep\nneural networks. Most existing DA techniques naively add a certain number of\naugmented samples without considering the quality and the added computational\ncost of these samples. To tackle this problem, a common strategy, adopted by\nseveral state-of-the-art DA methods, is to adaptively generate or re-weight\naugmented samples with respect to the task objective during training. However,\nthese adaptive DA methods: (1) are computationally expensive and not\nsample-efficient, and (2) are designed merely for a specific setting. In this\nwork, we present a universal DA technique, called Glitter, to overcome both\nissues. Glitter can be plugged into any DA method, making training\nsample-efficient without sacrificing performance. From a pre-generated pool of\naugmented samples, Glitter adaptively selects a subset of worst-case samples\nwith maximal loss, analogous to adversarial DA. Without altering the training\nstrategy, the task objective can be optimized on the selected subset. Our\nthorough experiments on the GLUE benchmark, SQuAD, and HellaSwag in three\nwidely used training setups including consistency training, self-distillation\nand knowledge distillation reveal that Glitter is substantially faster to train\nand achieves a competitive performance, compared to strong baselines.",
    "descriptor": "\nComments: ACL 2022 Findings\n",
    "authors": [
      "Ehsan Kamalloo",
      "Mehdi Rezagholizadeh",
      "Ali Ghodsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09391"
  },
  {
    "id": "arXiv:2203.09397",
    "title": "Coloring the Blank Slate: Pre-training Imparts a Hierarchical Inductive  Bias to Sequence-to-sequence Models",
    "abstract": "Relations between words are governed by hierarchical structure rather than\nlinear ordering. Sequence-to-sequence (seq2seq) models, despite their success\nin downstream NLP applications, often fail to generalize in a\nhierarchy-sensitive manner when performing syntactic transformations - for\nexample, transforming declarative sentences into questions. However, syntactic\nevaluations of seq2seq models have only observed models that were not\npre-trained on natural language data before being trained to perform syntactic\ntransformations, in spite of the fact that pre-training has been found to\ninduce hierarchical linguistic generalizations in language models; in other\nwords, the syntactic capabilities of seq2seq models may have been greatly\nunderstated. We address this gap using the pre-trained seq2seq models T5 and\nBART, as well as their multilingual variants mT5 and mBART. We evaluate whether\nthey generalize hierarchically on two transformations in two languages:\nquestion formation and passivization in English and German. We find that\npre-trained seq2seq models generalize hierarchically when performing syntactic\ntransformations, whereas models trained from scratch on syntactic\ntransformations do not. This result presents evidence for the learnability of\nhierarchical syntactic information from non-annotated natural language text\nwhile also demonstrating that seq2seq models are capable of syntactic\ngeneralization, though only after exposure to much more language data than\nhuman learners receive.",
    "descriptor": "\nComments: Accepted to Findings of ACL 2022\n",
    "authors": [
      "Aaron Mueller",
      "Robert Frank",
      "Tal Linzen",
      "Luheng Wang",
      "Sebastian Schuster"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09397"
  },
  {
    "id": "arXiv:2203.09402",
    "title": "Robust and Complex Approach of Pathological Speech Signal Analysis",
    "abstract": "This paper presents a study of the approaches in the state-of-the-art in the\nfield of pathological speech signal analysis with a special focus on\nparametrization techniques. It provides a description of 92 speech features\nwhere some of them are already widely used in this field of science and some of\nthem have not been tried yet (they come from different areas of speech signal\nprocessing like speech recognition or coding). As an original contribution,\nthis work introduces 36 completely new pathological voice measures based on\nmodulation spectra, inferior colliculus coefficients, bicepstrum, sample and\napproximate entropy and empirical mode decomposition. The significance of these\nfeatures was tested on 3 (English, Spanish and Czech) pathological voice\ndatabases with respect to classification accuracy, sensitivity and specificity.",
    "descriptor": "\nComments: 41 pages, published in Neurocomputing, Volume 167, 2015, Pages 94-111, ISSN 0925-2312\n",
    "authors": [
      "Jiri Mekyska",
      "Eva Janousova",
      "Pedro Gomez-Vilda",
      "Zdenek Smekal",
      "Irena Rektorova",
      "Ilona Eliasova",
      "Milena Kostalova",
      "Martina Mrackova",
      "Jesus B. Alonso-Hernandez",
      "Marcos Faundez-Zanuy",
      "Karmele L\u00f3pez-de-Ipi\u00f1a"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.09402"
  },
  {
    "id": "arXiv:2203.09414",
    "title": "Medium Transmission Map Matters for Learning to Restore Real-World  Underwater Images",
    "abstract": "Underwater visual perception is essentially important for underwater\nexploration, archeology, ecosystem and so on. The low illumination, light\nreflections, scattering, absorption and suspended particles inevitably lead to\nthe critically degraded underwater image quality, which causes great challenges\non recognizing the objects from the underwater images. The existing underwater\nenhancement methods that aim to promote the underwater visibility, heavily\nsuffer from the poor image restoration performance and generalization ability.\nTo reduce the difficulty of underwater image enhancement, we introduce the\nmedia transmission map as guidance to assist in image enhancement. We formulate\nthe interaction between the underwater visual images and the transmission map\nto obtain better enhancement results. Even with simple and lightweight network\nconfiguration, the proposed method can achieve advanced results of 22.6 dB on\nthe challenging Test-R90 with an impressive 30 times faster than the existing\nmodels. Comprehensive experimental results have demonstrated the superiority\nand potential on underwater perception. Paper's code is privoded on:\nhttps://github.com/GroupG-yk/MTUR-Net",
    "descriptor": "",
    "authors": [
      "Yan Kai",
      "Liang Lanyue",
      "Zheng Ziqiang",
      "Wang Guoqing",
      "Yang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09414"
  },
  {
    "id": "arXiv:2203.09416",
    "title": "Bi-directional Object-context Prioritization Learning for Saliency  Ranking",
    "abstract": "The saliency ranking task is recently proposed to study the visual behavior\nthat humans would typically shift their attention over different objects of a\nscene based on their degrees of saliency. Existing approaches focus on learning\neither object-object or object-scene relations. Such a strategy follows the\nidea of object-based attention in Psychology, but it tends to favor those\nobjects with strong semantics (e.g., humans), resulting in unrealistic saliency\nranking. We observe that spatial attention works concurrently with object-based\nattention in the human visual recognition system. During the recognition\nprocess, the human spatial attention mechanism would move, engage, and\ndisengage from region to region (i.e., context to context). This inspires us to\nmodel the region-level interactions, in addition to the object-level reasoning,\nfor saliency ranking. To this end, we propose a novel bi-directional method to\nunify spatial attention and object-based attention for saliency ranking. Our\nmodel includes two novel modules: (1) a selective object saliency (SOS) module\nthat models objectbased attention via inferring the semantic representation of\nthe salient object, and (2) an object-context-object relation (OCOR) module\nthat allocates saliency ranks to objects by jointly modeling the object-context\nand context-object interactions of the salient objects. Extensive experiments\nshow that our approach outperforms existing state-of-theart methods. Our code\nand pretrained model are available at https://github.com/GrassBro/OCOR.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Xin Tian",
      "Ke Xu",
      "Xin Yang",
      "Lin Du",
      "Baocai Yin",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09416"
  },
  {
    "id": "arXiv:2203.09418",
    "title": "ZebraPose: Coarse to Fine Surface Encoding for 6DoF Object Pose  Estimation",
    "abstract": "Establishing correspondences from image to 3D has been a key task of 6DoF\nobject pose estimation for a long time. To predict pose more accurately, deeply\nlearned dense maps replaced sparse templates. Dense methods also improved pose\nestimation in the presence of occlusion. More recently researchers have shown\nimprovements by learning object fragments as segmentation. In this work, we\npresent a discrete descriptor, which can represent the object surface densely.\nBy incorporating a hierarchical binary grouping, we can encode the object\nsurface very efficiently. Moreover, we propose a coarse to fine training\nstrategy, which enables fine-grained correspondence prediction. Finally, by\nmatching predicted codes with object surface and using a PnP solver, we\nestimate the 6DoF pose. Results on the public LM-O and YCB-V datasets show\nmajor improvement over the state of the art w.r.t. ADD(-S) metric, even\nsurpassing RGB-D based methods in some cases.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Yongzhi Su",
      "Mahdi Saleh",
      "Torben Fetzer",
      "Jason Rambach",
      "Nassir Navab",
      "Benjamin Busam",
      "Didier Stricker",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09418"
  },
  {
    "id": "arXiv:2203.09420",
    "title": "Deep Unsupervised Hashing with Latent Semantic Components",
    "abstract": "Deep unsupervised hashing has been appreciated in the regime of image\nretrieval. However, most prior arts failed to detect the semantic components\nand their relationships behind the images, which makes them lack discriminative\npower. To make up the defect, we propose a novel Deep Semantic Components\nHashing (DSCH), which involves a common sense that an image normally contains a\nbunch of semantic components with homology and co-occurrence relationships.\nBased on this prior, DSCH regards the semantic components as latent variables\nunder the Expectation-Maximization framework and designs a two-step iterative\nalgorithm with the objective of maximum likelihood of training data. Firstly,\nDSCH constructs a semantic component structure by uncovering the fine-grained\nsemantics components of images with a Gaussian Mixture Modal~(GMM), where an\nimage is represented as a mixture of multiple components, and the semantics\nco-occurrence are exploited. Besides, coarse-grained semantics components, are\ndiscovered by considering the homology relationships between fine-grained\ncomponents, and the hierarchy organization is then constructed. Secondly, DSCH\nmakes the images close to their semantic component centers at both fine-grained\nand coarse-grained levels, and also makes the images share similar semantic\ncomponents close to each other. Extensive experiments on three benchmark\ndatasets demonstrate that the proposed hierarchical semantic components indeed\nfacilitate the hashing model to achieve superior performance.",
    "descriptor": "\nComments: 9 pages, 15 figures\n",
    "authors": [
      "Qinghong Lin",
      "Xiaojun Chen",
      "Qin Zhang",
      "Shaotian Cai",
      "Wenzhe Zhao",
      "Hongfa Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09420"
  },
  {
    "id": "arXiv:2203.09424",
    "title": "elBERto: Self-supervised Commonsense Learning for Question Answering",
    "abstract": "Commonsense question answering requires reasoning about everyday situations\nand causes and effects implicit in context. Typically, existing approaches\nfirst retrieve external evidence and then perform commonsense reasoning using\nthese evidence. In this paper, we propose a Self-supervised Bidirectional\nEncoder Representation Learning of Commonsense (elBERto) framework, which is\ncompatible with off-the-shelf QA model architectures. The framework comprises\nfive self-supervised tasks to force the model to fully exploit the additional\ntraining signals from contexts containing rich commonsense. The tasks include a\nnovel Contrastive Relation Learning task to encourage the model to distinguish\nbetween logically contrastive contexts, a new Jigsaw Puzzle task that requires\nthe model to infer logical chains in long contexts, and three classic SSL tasks\nto maintain pre-trained models language encoding ability. On the representative\nWIQA, CosmosQA, and ReClor datasets, elBERto outperforms all other methods,\nincluding those utilizing explicit graph reasoning and external knowledge\nretrieval. Moreover, elBERto achieves substantial improvements on\nout-of-paragraph and no-effect questions where simple lexical similarity\ncomparison does not help, indicating that it successfully learns commonsense\nand is able to leverage it when given dynamic context.",
    "descriptor": "",
    "authors": [
      "Xunlin Zhan",
      "Yuan Li",
      "Xiao Dong",
      "Xiaodan Liang",
      "Zhiting Hu",
      "Lawrence Carin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09424"
  },
  {
    "id": "arXiv:2203.09430",
    "title": "Mutual Learning for Domain Adaptation: Self-distillation Image Dehazing  Network with Sample-cycle",
    "abstract": "Deep learning-based methods have made significant achievements for image\ndehazing. However, most of existing dehazing networks are concentrated on\ntraining models using simulated hazy images, resulting in generalization\nperformance degradation when applied on real-world hazy images because of\ndomain shift. In this paper, we propose a mutual learning dehazing framework\nfor domain adaption. Specifically, we first devise two siamese networks: a\nteacher network in the synthetic domain and a student network in the real\ndomain, and then optimize them in a mutual learning manner by leveraging EMA\nand joint loss. Moreover, we design a sample-cycle strategy based on density\naugmentation (HDA) module to introduce pseudo real-world image pairs provided\nby the student network into training for further improving the generalization\nperformance. Extensive experiments on both synthetic and real-world dataset\ndemonstrate that the propose mutual learning framework outperforms\nstate-of-the-art dehazing techniques in terms of subjective and objective\nevaluation.",
    "descriptor": "",
    "authors": [
      "Tian Ye",
      "Yun Liu",
      "Yunchen Zhang",
      "Sixiang Chen",
      "Erkang Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09430"
  },
  {
    "id": "arXiv:2203.09435",
    "title": "Expanding Pretrained Models to Thousands More Languages via  Lexicon-based Adaptation",
    "abstract": "The performance of multilingual pretrained models is highly dependent on the\navailability of monolingual or parallel text present in a target language.\nThus, the majority of the world's languages cannot benefit from recent progress\nin NLP as they have no or limited textual data. To expand possibilities of\nusing NLP technology in these under-represented languages, we systematically\nstudy strategies that relax the reliance on conventional language resources\nthrough the use of bilingual lexicons, an alternative resource with much better\nlanguage coverage. We analyze different strategies to synthesize textual or\nlabeled data using lexicons, and how this data can be combined with monolingual\nor parallel text when available. For 19 under-represented languages across 3\ntasks, our methods lead to consistent improvements of up to 5 and 15 points\nwith and without extra monolingual text respectively. Overall, our study\nhighlights how NLP methods can be adapted to thousands more languages that are\nunder-served by current technology",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Xinyi Wang",
      "Sebastian Ruder",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09435"
  },
  {
    "id": "arXiv:2203.09438",
    "title": "An Explainable Stacked Ensemble Model for Static Route-Free Estimation  of Time of Arrival",
    "abstract": "To compare alternative taxi schedules and to compute them, as well as to\nprovide insights into an upcoming taxi trip to drivers and passengers, the\nduration of a trip or its Estimated Time of Arrival (ETA) is predicted. To\nreach a high prediction precision, machine learning models for ETA are state of\nthe art. One yet unexploited option to further increase prediction precision is\nto combine multiple ETA models into an ensemble. While an increase of\nprediction precision is likely, the main drawback is that the predictions made\nby such an ensemble become less transparent due to the sophisticated ensemble\narchitecture. One option to remedy this drawback is to apply eXplainable\nArtificial Intelligence (XAI). The contribution of this paper is three-fold.\nFirst, we combine multiple machine learning models from our previous work for\nETA into a two-level ensemble model - a stacked ensemble model - which on its\nown is novel; therefore, we can outperform previous state-of-the-art static\nroute-free ETA approaches. Second, we apply existing XAI methods to explain the\nfirst- and second-level models of the ensemble. Third, we propose three joining\nmethods for combining the first-level explanations with the second-level ones.\nThose joining methods enable us to explain stacked ensembles for regression\ntasks. An experimental evaluation shows that the ETA models correctly learned\nthe importance of those input features driving the prediction.",
    "descriptor": "",
    "authors": [
      "S\u00f6ren Schleibaum",
      "J\u00f6rg P. M\u00fcller",
      "Monika Sester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09438"
  },
  {
    "id": "arXiv:2203.09440",
    "title": "TO-Scene: A Large-scale Dataset for Understanding 3D Tabletop Scenes",
    "abstract": "Many basic indoor activities such as eating or writing are always conducted\nupon different tabletops (e.g., coffee tables, writing desks). It is\nindispensable to understanding tabletop scenes in 3D indoor scene parsing\napplications. Unfortunately, it is hard to meet this demand by directly\ndeploying data-driven algorithms, since 3D tabletop scenes are rarely available\nin current datasets. To remedy this defect, we introduce TO-Scene, a\nlarge-scale dataset focusing on tabletop scenes, which contains 20,740 scenes\nwith three variants. To acquire the data, we design an efficient and scalable\nframework, where a crowdsourcing UI is developed to transfer CAD objects onto\ntables from ScanNet. Then the output tabletop scenes are simulated into real\nscans and annotated automatically.\nFurther, we propose a tabletop-aware learning strategy for better perceiving\nthe small-sized tabletop instances. Notably, we also provide a real scanned\ntest set TO-Real to verify the practical value of TO-Scene. Experiments show\nthat the algorithms trained on TO-Scene indeed work on the realistic test data,\nand our proposed tabletop-aware learning strategy greatly improves the\nstate-of-the-art results on both 3D semantic segmentation and object detection\ntasks. TO-Scene and TO-Real, plus Web UI, will all be publicly available.",
    "descriptor": "",
    "authors": [
      "Mutian Xu",
      "Pei Chen",
      "Haolin Liu",
      "Xiaoguang Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09440"
  },
  {
    "id": "arXiv:2203.09441",
    "title": "Learning of Structurally Unambiguous Probabilistic Grammars",
    "abstract": "The problem of identifying a probabilistic context free grammar has two\naspects: the first is determining the grammar's topology (the rules of the\ngrammar) and the second is estimating probabilistic weights for each rule.\nGiven the hardness results for learning context-free grammars in general, and\nprobabilistic grammars in particular, most of the literature has concentrated\non the second problem. In this work we address the first problem. We restrict\nattention to structurally unambiguous weighted context-free grammars (SUWCFG)\nand provide a query learning algorithm for \\structurally unambiguous\nprobabilistic context-free grammars (SUPCFG). We show that SUWCFG can be\nrepresented using \\emph{co-linear multiplicity tree automata} (CMTA), and\nprovide a polynomial learning algorithm that learns CMTAs. We show that the\nlearned CMTA can be converted into a probabilistic grammar, thus providing a\ncomplete algorithm for learning a structurally unambiguous probabilistic\ncontext free grammar (both the grammar topology and the probabilistic weights)\nusing structured membership queries and structured equivalence queries. A\nsummarized version of this work was published at AAAI 21.",
    "descriptor": "",
    "authors": [
      "Dana Fisman",
      "Dolav Nitay",
      "Michal Ziv-Ukelson"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09441"
  },
  {
    "id": "arXiv:2203.09445",
    "title": "Image Super-Resolution With Deep Variational Autoencoders",
    "abstract": "Image super-resolution (SR) techniques are used to generate a high-resolution\nimage from a low-resolution image. Until now, deep generative models such as\nautoregressive models and Generative Adversarial Networks (GANs) have proven to\nbe effective at modelling high-resolution images. Models based on Variational\nAutoencoders (VAEs) have often been criticized for their feeble generative\nperformance, but with new advancements such as VDVAE (very deep VAE), there is\nnow strong evidence that deep VAEs have the potential to outperform current\nstate-of-the-art models for high-resolution image generation. In this paper, we\nintroduce VDVAE-SR, a new model that aims to exploit the most recent deep VAE\nmethodologies to improve upon image super-resolution using transfer learning on\npretrained VDVAEs. Through qualitative and quantitative evaluations, we show\nthat the proposed model is competitive with other state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Darius Chira",
      "Ilian Haralampiev",
      "Ole Winther",
      "Andrea Dittadi",
      "Valentin Li\u00e9vin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.09445"
  },
  {
    "id": "arXiv:2203.09446",
    "title": "Vox2Cortex: Fast Explicit Reconstruction of Cortical Surfaces from 3D  MRI Scans with Geometric Deep Neural Networks",
    "abstract": "The reconstruction of cortical surfaces from brain magnetic resonance imaging\n(MRI) scans is essential for quantitative analyses of cortical thickness and\nsulcal morphology. Although traditional and deep learning-based algorithmic\npipelines exist for this purpose, they have two major drawbacks: lengthy\nruntimes of multiple hours (traditional) or intricate post-processing, such as\nmesh extraction and topology correction (deep learning-based). In this work, we\naddress both of these issues and propose Vox2Cortex, a deep learning-based\nalgorithm that directly yields topologically correct, three-dimensional meshes\nof the boundaries of the cortex. Vox2Cortex leverages convolutional and graph\nconvolutional neural networks to deform an initial template to the densely\nfolded geometry of the cortex represented by an input MRI scan. We show in\nextensive experiments on three brain MRI datasets that our meshes are as\naccurate as the ones reconstructed by state-of-the-art methods in the field,\nwithout the need for time- and resource-intensive post-processing. To\naccurately reconstruct the tightly folded cortex, we work with meshes\ncontaining about 168,000 vertices at test time, scaling deep explicit\nreconstruction methods to a new level.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Fabian Bongratz",
      "Anne-Marie Rickmann",
      "Sebastian P\u00f6lsterl",
      "Christian Wachinger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09446"
  },
  {
    "id": "arXiv:2203.09450",
    "title": "Continual Learning Based on OOD Detection and Task Masking",
    "abstract": "Existing continual learning techniques focus on either task incremental\nlearning (TIL) or class incremental learning (CIL) problem, but not both. CIL\nand TIL differ mainly in that the task-id is provided for each test sample\nduring testing for TIL, but not provided for CIL. Continual learning methods\nintended for one problem have limitations on the other problem. This paper\nproposes a novel unified approach based on out-of-distribution (OOD) detection\nand task masking, called CLOM, to solve both problems. The key novelty is that\neach task is trained as an OOD detection model rather than a traditional\nsupervised learning model, and a task mask is trained to protect each task to\nprevent forgetting. Our evaluation shows that CLOM outperforms existing\nstate-of-the-art baselines by large margins. The average TIL/CIL accuracy of\nCLOM over six experiments is 87.6/67.9% while that of the best baselines is\nonly 82.4/55.0%.",
    "descriptor": "",
    "authors": [
      "Gyuhak Kim",
      "Sepideh Esmaeilpour",
      "Changnan Xiao",
      "Bing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09450"
  },
  {
    "id": "arXiv:2203.09452",
    "title": "Automated Transpilation of Imperative to Functional Code using  Neural-Guided Program Synthesis (Extended Version)",
    "abstract": "While many mainstream languages such as Java, Python, and C# increasingly\nincorporate functional APIs to simplify programming and improve\nparallelization/performance, there are no effective techniques that can be used\nto automatically translate existing imperative code to functional variants\nusing these APIs. Motivated by this problem, this paper presents a\ntranspilation approach based on inductive program synthesis for modernizing\nexisting code. Our method is based on the observation that the overwhelming\nmajority of source/target programs in this setting satisfy an assumption that\nwe call trace-compatibility: not only do the programs share syntactically\nidentical low-level expressions, but these expressions also take the same\nvalues in corresponding execution traces. Our method leverages this observation\nto design a new neural-guided synthesis algorithm that (1) uses a novel neural\narchitecture called cognate grammar network (CGN) and (2) leverages a form of\nconcolic execution to prune partial programs based on intermediate values that\narise during a computation. We have implemented our approach in a tool called\nNGST2 and use it to translate imperative Java and Python code to functional\nvariants that use the Stream and functools APIs respectively. Our experiments\nshow that NGST2 significantly outperforms several baselines and that our\nproposed neural architecture and pruning techniques are vital for achieving\ngood results.",
    "descriptor": "",
    "authors": [
      "Benjamin Mariano",
      "Yanju Chen",
      "Yu Feng",
      "Greg Durrett",
      "Isil Dillig"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.09452"
  },
  {
    "id": "arXiv:2203.09453",
    "title": "Computing confined elasticae",
    "abstract": "A numerical scheme for computing arc-length parametrized curves of low\nbending energy that are confined to convex domains is devised. The convergence\nof the discrete formulations to a continuous model and the unconditional\nstability of an iterative scheme are addressed. Numerical simulations confirm\nthe theoretical results and lead to a classification of observed optimal curves\nwithin spheres.",
    "descriptor": "",
    "authors": [
      "S\u00f6ren Bartels",
      "Pascal Weyer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.09453"
  },
  {
    "id": "arXiv:2203.09454",
    "title": "Synthetic-to-Real Domain Adaptation using Contrastive Unpaired  Translation",
    "abstract": "The usefulness of deep learning models in robotics is largely dependent on\nthe availability of training data. Manual annotation of training data is often\ninfeasible. Synthetic data is a viable alternative, but suffers from domain\ngap. We propose a multi-step method to obtain training data without manual\nannotation effort: From 3D object meshes, we generate images using a modern\nsynthesis pipeline. We utilize a state-of-the-art image-to-image translation\nmethod to adapt the synthetic images to the real domain, minimizing the domain\ngap in a learned manner. The translation network is trained from unpaired\nimages, i.e. just requires an un-annotated collection of real images. The\ngenerated and refined images can then be used to train deep learning models for\na particular task. We also propose and evaluate extensions to the translation\nmethod that further increase performance, such as patch-based training, which\nshortens training time and increases global consistency. We evaluate our method\nand demonstrate its effectiveness on two robotic datasets. We finally give\ninsight into the learned refinement operations.",
    "descriptor": "",
    "authors": [
      "Benedikt T. Imbusch",
      "Max Schwarz",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09454"
  },
  {
    "id": "arXiv:2203.09457",
    "title": "Look Outside the Room: Synthesizing A Consistent Long-Term 3D Scene  Video from A Single Image",
    "abstract": "Novel view synthesis from a single image has recently attracted a lot of\nattention, and it has been primarily advanced by 3D deep learning and rendering\ntechniques. However, most work is still limited by synthesizing new views\nwithin relatively small camera motions. In this paper, we propose a novel\napproach to synthesize a consistent long-term video given a single scene image\nand a trajectory of large camera motions. Our approach utilizes an\nautoregressive Transformer to perform sequential modeling of multiple frames,\nwhich reasons the relations between multiple frames and the corresponding\ncameras to predict the next frame. To facilitate learning and ensure\nconsistency among generated frames, we introduce a locality constraint based on\nthe input cameras to guide self-attention among a large number of patches\nacross space and time. Our method outperforms state-of-the-art view synthesis\napproaches by a large margin, especially when synthesizing long-term future in\nindoor 3D scenes. Project page at https://xrenaa.github.io/look-outside-room/.",
    "descriptor": "\nComments: Accepted to CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Xuanchi Ren",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09457"
  },
  {
    "id": "arXiv:2203.09463",
    "title": "FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression  Recognition in Videos",
    "abstract": "Current benchmarks for facial expression recognition (FER) mainly focus on\nstatic images, while there are limited datasets for FER in videos. It is still\nambiguous to evaluate whether performances of existing methods remain\nsatisfactory in real-world application-oriented scenes. For example, the\n\"Happy\" expression with high intensity in Talk-Show is more discriminating than\nthe same expression with low intensity in Official-Event. To fill this gap, we\nbuild a large-scale multi-scene dataset, coined as FERV39k. We analyze the\nimportant ingredients of constructing such a novel dataset in three aspects:\n(1) multi-scene hierarchy and expression class, (2) generation of candidate\nvideo clips, (3) trusted manual labelling process. Based on these guidelines,\nwe select 4 scenarios subdivided into 22 scenes, annotate 86k samples\nautomatically obtained from 4k videos based on the well-designed workflow, and\nfinally build 38,935 video clips labeled with 7 classic expressions. Experiment\nbenchmarks on four kinds of baseline frameworks were also provided and further\nanalysis on their performance across different scenes and some challenges for\nfuture research were given. Besides, we systematically investigate key\ncomponents of DFER by ablation studies. The baseline framework and our project\nare available on url.",
    "descriptor": "\nComments: Accepted for CVPR2022\n",
    "authors": [
      "Yan Wang",
      "Yixuan Sun",
      "Yiwen Huang",
      "Zhongying Liu",
      "Shuyong Gao",
      "Wei Zhang",
      "Weifeng Ge",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09463"
  },
  {
    "id": "arXiv:2203.09474",
    "title": "Self-Normalized Density Map (SNDM) for Counting Microbiological Objects",
    "abstract": "The statistical properties of the density map (DM) approach to counting\nmicrobiological objects on images are studied in detail. The DM is given by\nU$^2$-Net. Two statistical methods for deep neural networks are utilized: the\nbootstrap and the Monte Carlo (MC) dropout. The detailed analysis of the\nuncertainties for the DM predictions leads to a deeper understanding of the DM\nmodel's deficiencies. Based on our investigation, we propose a\nself-normalization module in the network. The improved network model, called\nSelf-Normalized Density Map (SNDM), can correct its output density map by\nitself to accurately predict the total number of objects in the image. The SNDM\narchitecture outperforms the original model. Moreover, both statistical\nframeworks -- bootstrap and MC dropout -- have consistent statistical results\nfor SNDM, which were not observed in the original model.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Krzysztof M. Graczyk",
      "Jaros\u0142aw Paw\u0142owski",
      "Sylwia Majchrowska",
      "Tomasz Golan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09474"
  },
  {
    "id": "arXiv:2203.09475",
    "title": "CaRTS: Causality-driven Robot Tool Segmentation from Vision and  Kinematics Data",
    "abstract": "Vision-based segmentation of the robotic tool during robot-assisted surgery\nenables downstream applications, such as augmented reality feedback, while\nallowing for inaccuracies in robot kinematics. With the introduction of deep\nlearning, many methods were presented to solve instrument segmentation directly\nand solely from images. While these approaches made remarkable progress on\nbenchmark datasets, fundamental challenges pertaining to their robustness\nremain. We present CaRTS, a causality-driven robot tool segmentation algorithm,\nthat is designed based on a complementary causal model of the robot tool\nsegmentation task. Rather than directly inferring segmentation masks from\nobserved images, CaRTS iteratively aligns tool models with image observations\nby updating the initially incorrect robot kinematic parameters through forward\nkinematics and differentiable rendering to optimize image feature similarity\nend-to-end. We benchmark CaRTS with competing techniques on both synthetic as\nwell as real data from the dVRK, generated in precisely controlled scenarios to\nallow for counterfactual synthesis. On training-domain test data, CaRTS\nachieves a Dice score of 93.4 that is preserved well (Dice score of 91.8) when\ntested on counterfactual altered test data, exhibiting low brightness, smoke,\nblood, and altered background patterns. This compares favorably to Dice scores\nof 95.0 and 62.8, respectively, of a purely image-based method trained and\ntested on the same data. Future work will involve accelerating CaRTS to achieve\nvideo framerate and estimating the impact occlusion has in practice. Despite\nthese limitations, our results are promising: In addition to achieving high\nsegmentation accuracy, CaRTS provides estimates of the true robot kinematics,\nwhich may benefit applications such as force estimation.",
    "descriptor": "",
    "authors": [
      "Hao Ding",
      "Jintan Zhang",
      "Peter Kazanzides",
      "Jieying Wu",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09475"
  },
  {
    "id": "arXiv:2203.09476",
    "title": "Uncertainty with UAV Search of Multiple Goal-oriented Targets",
    "abstract": "This paper considers the complex problem of a team of UAVs searching targets\nunder uncertainty. The goal of the UAV team is to find all of the moving\ntargets as quickly as possible before they arrive at their selected goal. The\nuncertainty considered is threefold: First, the UAVs do not know the targets'\nlocations and destinations. Second, the sensing capabilities of the UAVs are\nnot perfect. Third, the targets' movement model is unknown. We suggest a\nreal-time algorithmic framework for the UAVs, combining entropy and\nstochastic-temporal belief, that aims at optimizing the probability of a quick\nand successful detection of all of the targets. We have empirically evaluated\nthe algorithmic framework, and have shown its efficiency and significant\nperformance improvement compared to other solutions. Furthermore, we have\nevaluated our framework using Peer Designed Agents (PDAs), which are computer\nagents that simulate targets and show that our algorithmic framework\noutperforms other solutions in this scenario.",
    "descriptor": "",
    "authors": [
      "Mor Sinay",
      "Noa Agmon",
      "Oleg Maksimov",
      "Aviad Fux",
      "Sarit Kraus"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09476"
  },
  {
    "id": "arXiv:2203.09479",
    "title": "Computer Vision Algorithm for Predicting the Welding Efficiency of  Friction Stir Welded Copper Joints from its Microstructures",
    "abstract": "Friction Stir Welding is a robust joining process, and numerous AI-based\nalgorithms are being developed in this field to enhance mechanical and\nmicrostructure properties. Convolutional Neural Networks (CNNs) are Artificial\nNeural Networks that use image data as input. Identical to Artificial Neural\nNetworks, they are composed of weights that are determined throughout learning,\nneurons (activated functions), and a goal (loss function). CNN is utilized in a\nvariety of applications, including image recognition, semantic segmentation,\nimage recognition, and localization. Utilizing training on 3000 microstructure\npictures and new tests on 300 microstructure photographs, the current work\ninvestigates the predictions of Friction Stir Welded joint effectiveness using\nmicrostructure images.",
    "descriptor": "",
    "authors": [
      "Akshansh Mishra",
      "Asmita Suman",
      "Devarrishi Dixit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09479"
  },
  {
    "id": "arXiv:2203.09480",
    "title": "Causality issue in the heat balance method for calculating the design  heating and cooling load",
    "abstract": "Heating and cooling load calculation based on dynamic models is widely used\nin simulation software and it is the method recommended by ASHRAE and CEN. The\nprinciple is to make the heat balance for the air volume of a room space\nconsidered at uniform temperature and to calculate from this equation the load,\ni.e. the power needed to obtain the required indoor temperature. The problem is\nthat, by doing so, the physical causality is not respected. If the model is\napproximated by a piecewise linear dynamical system, this procedure results in\nan improper transfer function. In order to point out this problem, a method to\nobtain state space and transfer function models from thermal networks is\nintroduced. Then, the transfer function representation is employed to show that\nchanging the physical causality results in an improper transfer function. The\npractical consequence is that when the space temperature has a step variation,\nthe calculated load tends to infinity if the simulation time step tends to\nzero. The issue of causality may be a problem in equation-based simulation\nsoftware, such as MODELICA, in which the equations do not represent causal\nrelations: a wrong choice of the causality in a balance equation may result in\nimproper transfer functions.",
    "descriptor": "",
    "authors": [
      "Christian Ghiaus"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.09480"
  },
  {
    "id": "arXiv:2203.09481",
    "title": "Diffusion Probabilistic Modeling for Video Generation",
    "abstract": "Denoising diffusion probabilistic models are a promising new class of\ngenerative models that are competitive with GANs on perceptual metrics. In this\npaper, we explore their potential for sequentially generating video. Inspired\nby recent advances in neural video compression, we use denoising diffusion\nmodels to stochastically generate a residual to a deterministic next-frame\nprediction. We compare this approach to two sequential VAE and two GAN\nbaselines on four datasets, where we test the generated frames for perceptual\nquality and forecasting accuracy against ground truth frames. We find\nsignificant improvements in terms of perceptual quality on all data and\nimprovements in terms of frame forecasting for complex high-resolution videos.",
    "descriptor": "\nComments: This work has been submitted to the ECCV for possible publication\n",
    "authors": [
      "Ruihan Yang",
      "Prakhar Srivastava",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09481"
  },
  {
    "id": "arXiv:2203.09484",
    "title": "Distributed formation control of networked mechanical systems",
    "abstract": "This paper investigates a distributed formation tracking control law for\nlarge-scale networks of mechanical systems. In particular, the formation\nnetwork is represented by a directed communication graph with leaders and\nfollowers, where each agent is described as a port-Hamiltonian system with a\nconstant mass matrix. Moreover, we adopt a distributed parameter approach to\nprove the scalable asymptotic stability of the network formation, i.e., the\nscalability with respect to the network size and the specific formation\npreservation. A simulation case illustrates the effectiveness of the proposed\ncontrol approach.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "N. Javanmardi",
      "P. Borja",
      "M. J. Yazdanpanah",
      "J. M. A. Scherpen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.09484"
  },
  {
    "id": "arXiv:2203.09486",
    "title": "An Imitation Learning Curriculum for Text Editing with  Non-Autoregressive Models",
    "abstract": "We propose a framework for training non-autoregressive sequence-to-sequence\nmodels for editing tasks, where the original input sequence is iteratively\nedited to produce the output. We show that the imitation learning algorithms\ndesigned to train such models for machine translation introduces mismatches\nbetween training and inference that lead to undertraining and poor\ngeneralization in editing scenarios. We address this issue with two\ncomplementary strategies: 1) a roll-in policy that exposes the model to\nintermediate training sequences that it is more likely to encounter during\ninference, 2) a curriculum that presents easy-to-learn edit operations first,\ngradually increasing the difficulty of training samples as the model becomes\ncompetent. We show the efficacy of these strategies on two challenging English\nediting tasks: controllable text simplification and abstractive summarization.\nOur approach significantly improves output quality on both tasks and controls\noutput complexity better on the simplification task.",
    "descriptor": "\nComments: To appear in ACL 2022\n",
    "authors": [
      "Sweta Agrawal",
      "Marine Carpuat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09486"
  },
  {
    "id": "arXiv:2203.09493",
    "title": "Modellieren mit Heraklit",
    "abstract": "Heraklit is an infrastructure for modelling large, computer-integrated\nsystems. We discuss the central requirements for such models (hierarchies, user\nview, transfer of informal into formal ideas, schematic models, equal treatment\nof digital and person-bound processes) and explain how Heraklit supports these\nrequirements. A case study shows the usability of Heraklit in practice.",
    "descriptor": "\nComments: 15 pages, 10 figures, in German, submitted to Modellierung 2022\n",
    "authors": [
      "Peter Fettke",
      "Wolfgang Reisig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.09493"
  },
  {
    "id": "arXiv:2203.09494",
    "title": "Transframer: Arbitrary Frame Prediction with Generative Models",
    "abstract": "We present a general-purpose framework for image modelling and vision tasks\nbased on probabilistic frame prediction. Our approach unifies a broad range of\ntasks, from image segmentation, to novel view synthesis and video\ninterpolation. We pair this framework with an architecture we term Transframer,\nwhich uses U-Net and Transformer components to condition on annotated context\nframes, and outputs sequences of sparse, compressed image features. Transframer\nis the state-of-the-art on a variety of video generation benchmarks, is\ncompetitive with the strongest models on few-shot view synthesis, and can\ngenerate coherent 30 second videos from a single image without any explicit\ngeometric information. A single generalist Transframer simultaneously produces\npromising results on 8 tasks, including semantic segmentation, image\nclassification and optical flow prediction with no task-specific architectural\ncomponents, demonstrating that multi-task computer vision can be tackled using\nprobabilistic image models. Our approach can in principle be applied to a wide\nrange of applications that require learning the conditional structure of\nannotated image-formatted data.",
    "descriptor": "",
    "authors": [
      "Charlie Nash",
      "Jo\u00e3o Carreira",
      "Jacob Walker",
      "Iain Barr",
      "Andrew Jaegle",
      "Mateusz Malinowski",
      "Peter Battaglia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09494"
  },
  {
    "id": "arXiv:2203.09498",
    "title": "The Frost Hollow Experiments: Pavlovian Signalling as a Path to  Coordination and Communication Between Agents",
    "abstract": "Learned communication between agents is a powerful tool when approaching\ndecision-making problems that are hard to overcome by any single agent in\nisolation. However, continual coordination and communication learning between\nmachine agents or human-machine partnerships remains a challenging open\nproblem. As a stepping stone toward solving the continual communication\nlearning problem, in this paper we contribute a multi-faceted study into what\nwe term Pavlovian signalling -- a process by which learned, temporally extended\npredictions made by one agent inform decision-making by another agent with\ndifferent perceptual access to their shared environment. We seek to establish\nhow different temporal processes and representational choices impact Pavlovian\nsignalling between learning agents. To do so, we introduce a partially\nobservable decision-making domain we call the Frost Hollow. In this domain a\nprediction learning agent and a reinforcement learning agent are coupled into a\ntwo-part decision-making system that seeks to acquire sparse reward while\navoiding time-conditional hazards. We evaluate two domain variations: 1)\nmachine prediction and control learning in a linear walk, and 2) a prediction\nlearning machine interacting with a human participant in a virtual reality\nenvironment. Our results showcase the speed of learning for Pavlovian\nsignalling, the impact that different temporal representations do (and do not)\nhave on agent-agent coordination, and how temporal aliasing impacts agent-agent\nand human-agent interactions differently. As a main contribution, we establish\nPavlovian signalling as a natural bridge between fixed signalling paradigms and\nfully adaptive communication learning. Our results therefore point to an\nactionable, constructivist path towards continual communication learning\nbetween reinforcement learning agents, with potential impact in a range of\nreal-world settings.",
    "descriptor": "\nComments: 54 pages, 29 figures, 4 tables\n",
    "authors": [
      "Patrick M. Pilarski",
      "Andrew Butcher",
      "Elnaz Davoodi",
      "Michael Bradley Johanson",
      "Dylan J. A. Brenneis",
      "Adam S. R. Parker",
      "Leslie Acker",
      "Matthew M. Botvinick",
      "Joseph Modayil",
      "Adam White"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.09498"
  },
  {
    "id": "arXiv:2203.09501",
    "title": "A Coinductive Reformulation of Milner's Proof System for Regular  Expressions Modulo Bisimilarity",
    "abstract": "Milner (1984) defined an operational semantics for regular expressions as\nfinite-state processes. In order to axiomatize bisimilarity of regular\nexpressions under this process semantics, he adapted Salomaa's proof system\nthat is complete for equality of regular expressions under the language\nsemantics. Apart from most equational axioms, Milner's system Mil inherits from\nSalomaa's system a non-algebraic rule for solving single fixed-point equations.\nRecognizing distinctive properties of the process semantics that render\nSalomaa's proof strategy inapplicable, Milner posed completeness of the system\nMil as an open question.\nAs a proof-theoretic approach to this problem we characterize the\nderivational power that the fixed-point rule adds to the purely equational part\nMil$^-$ of Mil. We do so by means of a coinductive rule that permits cyclic\nderivations that consist of a finite process graph with empty steps that\nsatisfies the layered loop existence and elimination property LLEE, and two of\nits Mil$^{-}$-provable solutions. With this rule as replacement for the\nfixed-point rule in Mil, we define the coinductive reformulation cMil as an\nextension of Mil$^{-}$. In order to show that cMil and Mil are theorem\nequivalent we develop effective proof transformations from Mil to cMil, and\nvice versa. Since it is located half-way in between bisimulations and proofs in\nMilner's system Mil, cMil may become a beachhead for a completeness proof of\nMil.\nThis article extends our contribution to the CALCO 2022 proceedings. Here we\nrefine the proof transformations by framing them as eliminations of derivable\nand admissible rules, and we link coinductive proofs to a coalgebraic\nformulation of solutions of process graphs.",
    "descriptor": "",
    "authors": [
      "Clemens Grabmayer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.09501"
  },
  {
    "id": "arXiv:2203.09505",
    "title": "Visualizing Global Explanations of Point Cloud DNNs",
    "abstract": "In the field of autonomous driving and robotics, point clouds are showing\ntheir excellent real-time performance as raw data from most of the mainstream\n3D sensors. Therefore, point cloud neural networks have become a popular\nresearch direction in recent years. So far, however, there has been little\ndiscussion about the explainability of deep neural networks for point clouds.\nIn this paper, we propose a point cloud-applicable explainability approach\nbased on a local surrogate model-based method to show which components\ncontribute to the classification. Moreover, we propose quantitative fidelity\nvalidations for generated explanations that enhance the persuasive power of\nexplainability and compare the plausibility of different existing point\ncloud-applicable explainability methods. Our new explainability approach\nprovides a fairly accurate, more semantically coherent and widely applicable\nexplanation for point cloud classification tasks. Our code is available at\nhttps://github.com/Explain3D/LIME-3D",
    "descriptor": "",
    "authors": [
      "Hanxiao Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09505"
  },
  {
    "id": "arXiv:2203.09507",
    "title": "Towards Data-Efficient Detection Transformers",
    "abstract": "Detection Transformers have achieved competitive performance on the\nsample-rich COCO dataset. However, we show most of them suffer from significant\nperformance drops on small-size datasets, like Cityscapes. In other words, the\ndetection transformers are generally data-hungry. To tackle this problem, we\nempirically analyze the factors that affect data efficiency, through a\nstep-by-step transition from a data-efficient RCNN variant to the\nrepresentative DETR. The empirical results suggest that sparse feature sampling\nfrom local image areas holds the key. Based on this observation, we alleviate\nthe data-hungry issue of existing detection transformers by simply alternating\nhow key and value sequences are constructed in the cross-attention layer, with\nminimum modifications to the original models. Besides, we introduce a simple\nyet effective label augmentation method to provide richer supervision and\nimprove data efficiency. Experiments show that our method can be readily\napplied to different detection transformers and improve their performance on\nboth small-size and sample-rich datasets. Code will be made publicly available\nat \\url{https://github.com/encounter1997/DE-DETRs}.",
    "descriptor": "",
    "authors": [
      "Wen Wang",
      "Jing Zhang",
      "Yang Cao",
      "Yongliang Shen",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09507"
  },
  {
    "id": "arXiv:2203.09508",
    "title": "DCarbonX Decentralised Application: Carbon Market Case Study",
    "abstract": "Decentralized applications developed using blockchain technology provide\ninnovative business models to serve the human race and solve existing\nchallenges. Climate change is one of the biggest problems humanity is facing\nand there is a dearth of solutions in tackling this grave impediment to the\nlong-term sustainability of our planet. Accountability, greenwashing,\ntraceability, impact assessment and trading of carbon credits are unresolved\nissues in the ESG sector. In this paper, we present a novel decentralized\napplication software, DCarbonX, that solves the enumerated problems using NFTs\non the blockchain platform, through smart contracts. The paper describes the\nfunctional architecture of DCarbonX, while elaborating on its salient features\nand utility in sustainable finance, in particular green sukuk. DCarbonX is a\npioneering software providing an exchange for trading of carbon credits. The\nsoftware facilitates logging of impact and traceable transactions in a carbon\nmarket, that would help to prevent duplication of records and greenwashing. The\npaper discusses the efforts being undertaken to achieve the climate goals as\nper the Paris Agreement and also highlights the pivotal obstacles to achieving\ncarbon neutrality by 2050, as per COP26. The paper also encompasses a study on\nthe applications of dapps in DeFi, Web 3.0 and ESG, among other areas and gives\na comparative analysis of blockchain platforms for dapp development. The paper\nis also a pioneer in highlighting the challenges that plague dapp development,\ndeployment and usage.",
    "descriptor": "\nComments: DCarbonX software has been registered in the Benelux region with the i-DEPOT number 134516\n",
    "authors": [
      "Nida Khan",
      "Tabrez Ahmad"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.09508"
  },
  {
    "id": "arXiv:2203.09509",
    "title": "ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and  Implicit Hate Speech Detection",
    "abstract": "Toxic language detection systems often falsely flag text that contains\nminority group mentions as toxic, as those groups are often the targets of\nonline hate. Such over-reliance on spurious correlations also causes systems to\nstruggle with detecting implicitly toxic language. To help mitigate these\nissues, we create ToxiGen, a new large-scale and machine-generated dataset of\n274k toxic and benign statements about 13 minority groups. We develop a\ndemonstration-based prompting framework and an adversarial\nclassifier-in-the-loop decoding method to generate subtly toxic and benign text\nwith a massive pretrained language model. Controlling machine generation in\nthis way allows ToxiGen to cover implicitly toxic text at a larger scale, and\nabout more demographic groups, than previous resources of human-written text.\nWe conduct a human evaluation on a challenging subset of ToxiGen and find that\nannotators struggle to distinguish machine-generated text from human-written\nlanguage. We also find that 94.5% of toxic examples are labeled as hate speech\nby human annotators. Using three publicly-available datasets, we show that\nfinetuning a toxicity classifier on our data improves its performance on\nhuman-written data substantially. We also demonstrate that ToxiGen can be used\nto fight machine-generated toxicity as finetuning improves the classifier\nsignificantly on our evaluation subset.",
    "descriptor": "",
    "authors": [
      "Thomas Hartvigsen",
      "Saadia Gabriel",
      "Hamid Palangi",
      "Maarten Sap",
      "Dipankar Ray",
      "Ece Kamar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09509"
  },
  {
    "id": "arXiv:2203.09510",
    "title": "DetMatch: Two Teachers are Better Than One for Joint 2D and 3D  Semi-Supervised Object Detection",
    "abstract": "While numerous 3D detection works leverage the complementary relationship\nbetween RGB images and point clouds, developments in the broader framework of\nsemi-supervised object recognition remain uninfluenced by multi-modal fusion.\nCurrent methods develop independent pipelines for 2D and 3D semi-supervised\nlearning despite the availability of paired image and point cloud frames.\nObserving that the distinct characteristics of each sensor cause them to be\nbiased towards detecting different objects, we propose DetMatch, a flexible\nframework for joint semi-supervised learning on 2D and 3D modalities. By\nidentifying objects detected in both sensors, our pipeline generates a cleaner,\nmore robust set of pseudo-labels that both demonstrates stronger performance\nand stymies single-modality error propagation. Further, we leverage the richer\nsemantics of RGB images to rectify incorrect 3D class predictions and improve\nlocalization of 3D boxes. Evaluating on the challenging KITTI and Waymo\ndatasets, we improve upon strong semi-supervised learning methods and observe\nhigher quality pseudo-labels. Code will be released at\nhttps://github.com/Divadi/DetMatch",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Jinhyung Park",
      "Chenfeng Xu",
      "Yiyang Zhou",
      "Masayoshi Tomizuka",
      "Wei Zhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09510"
  },
  {
    "id": "arXiv:2203.09513",
    "title": "On Multi-Domain Long-Tailed Recognition, Generalization and Beyond",
    "abstract": "Real-world data often exhibit imbalanced label distributions. Existing\nstudies on data imbalance focus on single-domain settings, i.e., samples are\nfrom the same data distribution. However, natural data can originate from\ndistinct domains, where a minority class in one domain could have abundant\ninstances from other domains. We formalize the task of Multi-Domain Long-Tailed\nRecognition (MDLT), which learns from multi-domain imbalanced data, addresses\nlabel imbalance, domain shift, and divergent label distributions across\ndomains, and generalizes to all domain-class pairs. We first develop the\ndomain-class transferability graph, and show that such transferability governs\nthe success of learning in MDLT. We then propose BoDA, a theoretically grounded\nlearning strategy that tracks the upper bound of transferability statistics,\nand ensures balanced alignment and calibration across imbalanced domain-class\ndistributions. We curate five MDLT benchmarks based on widely-used multi-domain\ndatasets, and compare BoDA to twenty algorithms that span different learning\nstrategies. Extensive and rigorous experiments verify the superior performance\nof BoDA. Further, as a byproduct, BoDA establishes new state-of-the-art on\nDomain Generalization benchmarks, improving generalization to unseen domains.\nCode and data are available at\nhttps://github.com/YyzHarry/multi-domain-imbalance.",
    "descriptor": "\nComments: Code and data are available at this https URL\n",
    "authors": [
      "Yuzhe Yang",
      "Hao Wang",
      "Dina Katabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09513"
  },
  {
    "id": "arXiv:2203.09516",
    "title": "AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation",
    "abstract": "Powerful priors allow us to perform inference with insufficient information.\nIn this paper, we propose an autoregressive prior for 3D shapes to solve\nmultimodal 3D tasks such as shape completion, reconstruction, and generation.\nWe model the distribution over 3D shapes as a non-sequential autoregressive\ndistribution over a discretized, low-dimensional, symbolic grid-like latent\nrepresentation of 3D shapes. This enables us to represent distributions over 3D\nshapes conditioned on information from an arbitrary set of spatially anchored\nquery locations and thus perform shape completion in such arbitrary settings\n(e.g., generating a complete chair given only a view of the back leg). We also\nshow that the learned autoregressive prior can be leveraged for conditional\ntasks such as single-view reconstruction and language-based generation. This is\nachieved by learning task-specific naive conditionals which can be approximated\nby light-weight models trained on minimal paired data. We validate the\neffectiveness of the proposed method using both quantitative and qualitative\nevaluation and show that the proposed method outperforms the specialized\nstate-of-the-art methods trained for individual tasks. The project page with\ncode and video visualizations can be found at\nhttps://yccyenchicheng.github.io/AutoSDF/.",
    "descriptor": "\nComments: In CVPR 2022. The first two authors contributed equally to this work. Project: this https URL\n",
    "authors": [
      "Paritosh Mittal",
      "Yen-Chi Cheng",
      "Maneesh Singh",
      "Shubham Tulsiani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09516"
  },
  {
    "id": "arXiv:2203.09517",
    "title": "TensoRF: Tensorial Radiance Fields",
    "abstract": "We present TensoRF, a novel approach to model and reconstruct radiance\nfields. Unlike NeRF that purely uses MLPs, we model the radiance field of a\nscene as a 4D tensor, which represents a 3D voxel grid with per-voxel\nmulti-channel features. Our central idea is to factorize the 4D scene tensor\ninto multiple compact low-rank tensor components. We demonstrate that applying\ntraditional CP decomposition -- that factorizes tensors into rank-one\ncomponents with compact vectors -- in our framework leads to improvements over\nvanilla NeRF. To further boost performance, we introduce a novel vector-matrix\n(VM) decomposition that relaxes the low-rank constraints for two modes of a\ntensor and factorizes tensors into compact vector and matrix factors. Beyond\nsuperior rendering quality, our models with CP and VM decompositions lead to a\nsignificantly lower memory footprint in comparison to previous and concurrent\nworks that directly optimize per-voxel features. Experimentally, we demonstrate\nthat TensoRF with CP decomposition achieves fast reconstruction (<30 min) with\nbetter rendering quality and even a smaller model size (<4 MB) compared to\nNeRF. Moreover, TensoRF with VM decomposition further boosts rendering quality\nand outperforms previous state-of-the-art methods, while reducing the\nreconstruction time (<10 min) and retaining a compact model size (<75 MB).",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Anpei Chen",
      "Zexiang Xu",
      "Andreas Geiger",
      "Jingyi Yu",
      "Hao Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09517"
  },
  {
    "id": "arXiv:2203.08161",
    "title": "Sensitivity Estimation for Dark Matter Subhalos in Synthetic Gaia DR2  using Deep Learning",
    "abstract": "The abundance of dark matter subhalos orbiting a host galaxy is a generic\nprediction of the cosmological framework. It is a promising way to constrain\nthe nature of dark matter. Here we describe the challenges of detecting stars\nwhose phase-space distribution may be perturbed by the passage of dark matter\nsubhalos using a machine learning approach. The training data are three Milky\nWay-like galaxies and nine synthetic Gaia DR2 surveys derived from these. We\nfirst quantify the magnitude of the perturbations in the simulated galaxies\nusing an anomaly detection algorithm. We also estimate the feasibility of this\napproach in the Gaia DR2-like catalogues by comparing the anomaly detection\nbased approach with a supervised classification. We find that a classification\nalgorithm optimized on about half a billion synthetic star observables exhibits\nmild but nonzero sensitivity. This classification-based approach is not\nsufficiently sensitive to pinpoint the exact locations of subhalos in the\nsimulation, as would be expected from the very limited number of subhalos in\nthe detectable region. The enormous size of the Gaia dataset motivates the\nfurther development of scalable and accurate computational methods that could\nbe used to select potential regions of interest for dark matter searches to\nultimately constrain the Milky Way's subhalo mass function.",
    "descriptor": "\nComments: 17 pages, 8 figures, 1 table. Comments are welcome!\n",
    "authors": [
      "Abdullah Bazarov",
      "Mar\u00eda Benito",
      "Gert H\u00fctsi",
      "Rain Kipper",
      "Joosep Pata",
      "Sven P\u00f5der"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08161"
  },
  {
    "id": "arXiv:2203.08802",
    "title": "Physics-Informed Neural Networks with Adaptive Localized Artificial  Viscosity",
    "abstract": "Physics-informed Neural Network (PINN) is a promising tool that has been\napplied in a variety of physical phenomena described by partial differential\nequations (PDE). However, it has been observed that PINNs are difficult to\ntrain in certain \"stiff\" problems, which include various nonlinear hyperbolic\nPDEs that display shocks in their solutions. Recent studies added a diffusion\nterm to the PDE, and an artificial viscosity (AV) value was manually tuned to\nallow PINNs to solve these problems. In this paper, we propose three approaches\nto address this problem, none of which rely on an a priori definition of the\nartificial viscosity value. The first method learns a global AV value, whereas\nthe other two learn localized AV values around the shocks, by means of a\nparametrized AV map or a residual-based AV map. We applied the proposed methods\nto the inviscid Burgers equation and the Buckley-Leverett equation, the latter\nbeing a classical problem in Petroleum Engineering. The results show that the\nproposed methods are able to learn both a small AV value and the accurate shock\nlocation and improve the approximation error over a nonadaptive global AV\nalternative method.",
    "descriptor": "",
    "authors": [
      "E.J.R. Coutinho",
      "M. Dall'Aqua",
      "L. McClenny",
      "M. Zhong",
      "U. Braga-Neto",
      "E. Gildin"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08802"
  },
  {
    "id": "arXiv:2203.08806",
    "title": "New directions for surrogate models and differentiable programming for  High Energy Physics detector simulation",
    "abstract": "The computational cost for high energy physics detector simulation in future\nexperimental facilities is going to exceed the current available resources. To\novercome this challenge, new ideas on surrogate models using machine learning\nmethods are being explored to replace computationally expensive components.\nAdditionally, differentiable programming has been proposed as a complementary\napproach, providing controllable and scalable simulation routines. In this\ndocument, new and ongoing efforts for surrogate models and differential\nprogramming applied to detector simulation are discussed in the context of the\n2021 Particle Physics Community Planning Exercise (`Snowmass').",
    "descriptor": "\nComments: contribution to Snowmass 2021\n",
    "authors": [
      "Andreas Adelmann",
      "Walter Hopkins",
      "Evangelos Kourlitis",
      "Michael Kagan",
      "Gregor Kasieczka",
      "Claudius Krause",
      "David Shih",
      "Vinicius Mikuni",
      "Benjamin Nachman",
      "Kevin Pedro",
      "Daniel Winklehner"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Computational Physics (physics.comp-ph)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2203.08806"
  },
  {
    "id": "arXiv:2203.08807",
    "title": "Disparities in Dermatology AI Performance on a Diverse, Curated Clinical  Image Set",
    "abstract": "Access to dermatological care is a major issue, with an estimated 3 billion\npeople lacking access to care globally. Artificial intelligence (AI) may aid in\ntriaging skin diseases. However, most AI models have not been rigorously\nassessed on images of diverse skin tones or uncommon diseases. To ascertain\npotential biases in algorithm performance in this context, we curated the\nDiverse Dermatology Images (DDI) dataset-the first publicly available, expertly\ncurated, and pathologically confirmed image dataset with diverse skin tones.\nUsing this dataset of 656 images, we show that state-of-the-art dermatology AI\nmodels perform substantially worse on DDI, with receiver operator curve area\nunder the curve (ROC-AUC) dropping by 27-36 percent compared to the models'\noriginal test results. All the models performed worse on dark skin tones and\nuncommon diseases, which are represented in the DDI dataset. Additionally, we\nfind that dermatologists, who typically provide visual labels for AI training\nand test datasets, also perform worse on images of dark skin tones and uncommon\ndiseases compared to ground truth biopsy annotations. Finally, fine-tuning AI\nmodels on the well-characterized and diverse DDI images closed the performance\ngap between light and dark skin tones. Moreover, algorithms fine-tuned on\ndiverse skin tones outperformed dermatologists on identifying malignancy on\nimages of dark skin tones. Our findings identify important weaknesses and\nbiases in dermatology AI that need to be addressed to ensure reliable\napplication to diverse patients and diseases.",
    "descriptor": "",
    "authors": [
      "Roxana Daneshjou",
      "Kailas Vodrahalli",
      "Roberto A Novoa",
      "Melissa Jenkins",
      "Weixin Liang",
      "Veronica Rotemberg",
      "Justin Ko",
      "Susan M Swetter",
      "Elizabeth E Bailey",
      "Olivier Gevaert",
      "Pritam Mukherjee",
      "Michelle Phung",
      "Kiana Yekrang",
      "Bradley Fong",
      "Rachna Sahasrabudhe",
      "Johan A. C. Allerup",
      "Utako Okata-Karigane",
      "James Zou",
      "Albert Chiou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08807"
  },
  {
    "id": "arXiv:2203.08810",
    "title": "Semi-FedSER: Semi-supervised Learning for Speech Emotion Recognition On  Federated Learning using Multiview Pseudo-Labeling",
    "abstract": "Speech Emotion Recognition (SER) application is frequently associated with\nprivacy concerns as it often acquires and transmits speech data at the\nclient-side to remote cloud platforms for further processing. These speech data\ncan reveal not only speech content and affective information but the speaker's\nidentity, demographic traits, and health status. Federated learning (FL) is a\ndistributed machine learning algorithm that coordinates clients to train a\nmodel collaboratively without sharing local data. This algorithm shows enormous\npotential for SER applications as sharing raw speech or speech features from a\nuser's device is vulnerable to privacy attacks. However, a major challenge in\nFL is limited availability of high-quality labeled data samples. In this work,\nwe propose a semi-supervised federated learning framework, Semi-FedSER, that\nutilizes both labeled and unlabeled data samples to address the challenge of\nlimited labeled data samples in FL. We show that our Semi-FedSER can generate\ndesired SER performance even when the local label rate l=20 using two SER\nbenchmark datasets: IEMOCAP and MSP-Improv.",
    "descriptor": "\nComments: This paper was submitted to Insterspeech 2022 for review\n",
    "authors": [
      "Tiantian Feng",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.08810"
  },
  {
    "id": "arXiv:2203.08812",
    "title": "Self-Supervised Deep Learning to Enhance Breast Cancer Detection on  Screening Mammography",
    "abstract": "A major limitation in applying deep learning to artificial intelligence (AI)\nsystems is the scarcity of high-quality curated datasets. We investigate strong\naugmentation based self-supervised learning (SSL) techniques to address this\nproblem. Using breast cancer detection as an example, we first identify a\nmammogram-specific transformation paradigm and then systematically compare four\nrecent SSL methods representing a diversity of approaches. We develop a method\nto convert a pretrained model from making predictions on uniformly tiled\npatches to whole images, and an attention-based pooling method that improves\nthe classification performance. We found that the best SSL model substantially\noutperformed the baseline supervised model. The best SSL model also improved\nthe data efficiency of sample labeling by nearly 4-fold and was highly\ntransferrable from one dataset to another. SSL represents a major breakthrough\nin computer vision and may help the AI for medical imaging field to shift away\nfrom supervised learning and dependency on scarce labels.",
    "descriptor": "",
    "authors": [
      "John D. Miller",
      "Vignesh A. Arasu",
      "Albert X. Pu",
      "Laurie R. Margolies",
      "Weiva Sieh",
      "Li Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08812"
  },
  {
    "id": "arXiv:2203.08819",
    "title": "Hierarchical Clustering and Matrix Completion for the Reconstruction of  World Input-Output Tables",
    "abstract": "World Input-Output (I/O) matrices provide the networks of within- and\ncross-country economic relations. In the context of I/O analysis, the\nmethodology adopted by national statistical offices in data collection raises\nthe issue of obtaining reliable data in a timely fashion and it makes the\nreconstruction of (part of) the I/O matrices of particular interest. In this\nwork, we propose a method combining hierarchical clustering and Matrix\nCompletion (MC) with a LASSO-like nuclear norm penalty, to impute missing\nentries of a partially unknown I/O matrix. Through simulations based on\nsynthetic matrices we study the effectiveness of the proposed method to predict\nmissing values from both previous years data and current data related to\ncountries similar to the one for which current data are obscured. To show the\nusefulness of our method, an application based on World Input-Output Database\n(WIOD) tables - which are an example of industry-by-industry I/O tables - is\nprovided. Strong similarities in structure between WIOD and other I/O tables\nare also found, which make the proposed approach easily generalizable to them.",
    "descriptor": "",
    "authors": [
      "Rodolfo Metulini",
      "Giorgio Gnecco",
      "Francesco Biancalani",
      "Massimo Riccaboni"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08819"
  },
  {
    "id": "arXiv:2203.08820",
    "title": "DePS: An improved deep learning model for de novo peptide sequencing",
    "abstract": "De novo peptide sequencing from mass spectrometry data is an important method\nfor protein identification. Recently, various deep learning approaches were\napplied for de novo peptide sequencing and DeepNovoV2 is one of the\nrepresetative models. In this study, we proposed an enhanced model, DePS, which\ncan improve the accuracy of de novo peptide sequencing even with missing signal\npeaks or large number of noisy peaks in tandem mass spectrometry data. It is\nshowed that, for the same test set of DeepNovoV2, the DePS model achieved\nexcellent results of 74.22%, 74.21% and 41.68% for amino acid recall, amino\nacid precision and peptide recall respectively. Furthermore, the results\nsuggested that DePS outperforms DeepNovoV2 on the cross species dataset.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Cheng Ge",
      "Yi Lu",
      "Jia Qu",
      "Liangxu Xie",
      "Feng Wang",
      "Hong Zhang",
      "Ren Kong",
      "Shan Chang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08820"
  },
  {
    "id": "arXiv:2203.08827",
    "title": "Discovering the building blocks of dark matter halo density profiles  with neural networks",
    "abstract": "The density profiles of dark matter halos are typically modeled using\nempirical formulae fitted to the density profiles of relaxed halo populations.\nWe present a neural network model that is trained to learn the mapping from the\nraw density field containing each halo to the dark matter density profile. We\nshow that the model recovers the widely-used Navarro-Frenk-White (NFW) profile\nout to the virial radius, and can additionally describe the variability in the\nouter profile of the halos. The neural network architecture consists of a\nsupervised encoder-decoder framework, which first compresses the density inputs\ninto a low-dimensional latent representation, and then outputs $\\rho(r)$ for\nany desired value of radius $r$. The latent representation contains all the\ninformation used by the model to predict the density profiles. This allows us\nto interpret the latent representation by quantifying the mutual information\nbetween the representation and the halos' ground-truth density profiles. A\ntwo-dimensional representation is sufficient to accurately model the density\nprofiles up to the virial radius; however, a three-dimensional representation\nis required to describe the outer profiles beyond the virial radius. The\nadditional dimension in the representation contains information about the\ninfalling material in the outer profiles of dark matter halos, thus discovering\nthe splashback boundary of halos without prior knowledge of the halos'\ndynamical history.",
    "descriptor": "\nComments: 12 pages, 6 figures, comments welcome\n",
    "authors": [
      "Luisa Lucie-Smith",
      "Hiranya V. Peiris",
      "Andrew Pontzen",
      "Brian Nord",
      "Jeyan Thiyagalingam",
      "Davide Piras"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08827"
  },
  {
    "id": "arXiv:2203.08857",
    "title": "Noisy Tensor Completion via Low-rank Tensor Ring",
    "abstract": "Tensor completion is a fundamental tool for incomplete data analysis, where\nthe goal is to predict missing entries from partial observations. However,\nexisting methods often make the explicit or implicit assumption that the\nobserved entries are noise-free to provide a theoretical guarantee of exact\nrecovery of missing entries, which is quite restrictive in practice. To remedy\nsuch drawbacks, this paper proposes a novel noisy tensor completion model,\nwhich complements the incompetence of existing works in handling the\ndegeneration of high-order and noisy observations. Specifically, the tensor\nring nuclear norm (TRNN) and least-squares estimator are adopted to regularize\nthe underlying tensor and the observed entries, respectively. In addition, a\nnon-asymptotic upper bound of estimation error is provided to depict the\nstatistical performance of the proposed estimator. Two efficient algorithms are\ndeveloped to solve the optimization problem with convergence guarantee, one of\nwhich is specially tailored to handle large-scale tensors by replacing the\nminimization of TRNN of the original tensor equivalently with that of a much\nsmaller one in a heterogeneous tensor decomposition framework. Experimental\nresults on both synthetic and real-world data demonstrate the effectiveness and\nefficiency of the proposed model in recovering noisy incomplete tensor data\ncompared with state-of-the-art tensor completion models.",
    "descriptor": "",
    "authors": [
      "Yuning Qiu",
      "Guoxu Zhou",
      "Qibin Zhao",
      "Shengli Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08857"
  },
  {
    "id": "arXiv:2203.08858",
    "title": "A Real-Time Region Tracking Algorithm Tailored to Endoscopic Video with  Open-Source Implementation",
    "abstract": "With a video data source, such as multispectral video acquired during\nadministration of fluorescent tracers, extraction of time-resolved data\ntypically requires the compensation of motion. While this can be done manually,\nwhich is arduous, or using off-the-shelf object tracking software, which often\nyields unsatisfactory performance, we present an algorithm which is simple and\nperformant. Most importantly, we provide an open-source implementation, with an\neasy-to-use interface for researchers not inclined to write their own code, as\nwell as Python modules that can be used programmatically.",
    "descriptor": "\nComments: Submitted to MICCAI 2022. Code can be found at this https URL\n",
    "authors": [
      "Jonathan P. Epperlein",
      "Sergiy Zhuk"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08858"
  },
  {
    "id": "arXiv:2203.08887",
    "title": "On Redundancy and Diversity in Cell-based Neural Architecture Search",
    "abstract": "Searching for the architecture cells is a dominant paradigm in NAS. However,\nlittle attention has been devoted to the analysis of the cell-based search\nspaces even though it is highly important for the continual development of NAS.\nIn this work, we conduct an empirical post-hoc analysis of architectures from\nthe popular cell-based search spaces and find that the existing search spaces\ncontain a high degree of redundancy: the architecture performance is minimally\nsensitive to changes at large parts of the cells, and universally adopted\ndesigns, like the explicit search for a reduction cell, significantly increase\nthe complexities but have very limited impact on the performance. Across\narchitectures found by a diverse set of search strategies, we consistently find\nthat the parts of the cells that do matter for architecture performance often\nfollow similar and simple patterns. By explicitly constraining cells to include\nthese patterns, randomly sampled architectures can match or even outperform the\nstate of the art. These findings cast doubts into our ability to discover truly\nnovel architectures in the existing cell-based search spaces, and inspire our\nsuggestions for improvement to guide future NAS research. Code is available at\nhttps://github.com/xingchenwan/cell-based-NAS-analysis.",
    "descriptor": "\nComments: ICLR 2022. 10 pages, 10 figures, 2 tables (25 pages, 34 figures, 3 tables including references and appendices)\n",
    "authors": [
      "Xingchen Wan",
      "Binxin Ru",
      "Pedro M. Esperan\u00e7a",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08887"
  },
  {
    "id": "arXiv:2203.08898",
    "title": "Neural network processing of holographic images",
    "abstract": "HOLODEC, an airborne cloud particle imager, captures holographic images of a\nfixed volume of cloud to characterize the types and sizes of cloud particles,\nsuch as water droplets and ice crystals. Cloud particle properties include\nposition, diameter, and shape. We present a hologram processing algorithm,\nHolodecML, that utilizes a neural segmentation model, GPUs, and computational\nparallelization. HolodecML is trained using synthetically generated holograms\nbased on a model of the instrument, and predicts masks around particles found\nwithin reconstructed images. From these masks, the position and size of the\ndetected particles can be characterized in three dimensions. In order to\nsuccessfully process real holograms, we find we must apply a series of image\ncorrupting transformations and noise to the synthetic images used in training.\nIn this evaluation, HolodecML had comparable position and size estimation\nperformance to the standard processing method, but improved particle detection\nby nearly 20\\% on several thousand manually labeled HOLODEC images. However,\nthe improvement only occurred when image corruption was performed on the\nsimulated images during training, thereby mimicking non-ideal conditions in the\nactual probe. The trained model also learned to differentiate artifacts and\nother impurities in the HOLODEC images from the particles, even though no such\nobjects were present in the training data set, while the standard processing\nmethod struggled to separate particles from artifacts. The novelty of the\ntraining approach, which leveraged noise as a means for parameterizing\nnon-ideal aspects of the HOLODEC detector, could be applied in other domains\nwhere the theoretical model is incapable of fully describing the real-world\noperation of the instrument and accurate truth data required for supervised\nlearning cannot be obtained from real-world observations.",
    "descriptor": "\nComments: 38 pages, 15 figures. Submitted to Atmospheric Measurement Techniques\n",
    "authors": [
      "John S. Schreck",
      "Gabrielle Gantos",
      "Matthew Hayman",
      "Aaron Bensemer",
      "David John Gagne"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2203.08898"
  },
  {
    "id": "arXiv:2203.08933",
    "title": "The Digital Divide in Canada and the Role of LEO Satellites in Bridging  the Gap",
    "abstract": "Overcoming the digital divide in rural and remote areas has always been a big\nchallenge for Canada with its huge geographical area. In 2016, the Canadian\nRadio-television and Telecommunications Commission announced broadband Internet\nas a basic service available for all Canadians. However, approximately one\nmillion Canadians still do not have access to broadband services as of 2020.\nThe COVID-19 pandemic has made the situation more challenging, as social,\neconomic, and educational activities have increasingly been transferred online.\nThe condition is more unfavorable for Indigenous communities. A key challenge\nin deploying rural and remote broadband Internet is to plan and implement\nhigh-capacity backbones, which are now available only in denser urban areas.\nFor any Internet provider, it is almost impossible to make a viable business\nproposal in these areas. For example, the vast land of the Northwest\nTerritories, Yukon, and Nunavuts diverse geographical features present\nobstacles for broadband infrastructure. In this paper, we investigate the\ndigital divide in Canada with a focus on rural and remote areas. In so doing,\nwe highlight two potential solutions using low Earth orbit (LEO) constellations\nto deliver broadband Internet in rural and remote areas to address the access\ninequality and the digital divide. The first solution involves integrating LEO\nconstellations as a backbone for the existing 4G/5G telecommunications network.\nThis solution uses satellites in a LEO constellation to provide a backhaul\nnetwork connecting the 4G/5G access network to its core network. The 3rd\nGeneration Partnership Project already specifies how to integrate LEO satellite\nnetworks into the 4G/5G network, and the Canadian satellite operator Telesat\nhas already showcased this solution with one terrestrial operator, TIM Brasil,\nin their 4G network.",
    "descriptor": "\nComments: Accepted for publication in IEEE Communications Magazine, Total 7 pages, 5 figures, 1 table\n",
    "authors": [
      "Tuheen Ahmmed",
      "Afsoon Alidadi",
      "Zichao Zhang",
      "Aizaz U. Chaudhry",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "General Economics (econ.GN)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08933"
  },
  {
    "id": "arXiv:2203.08948",
    "title": "CapsNet for Medical Image Segmentation",
    "abstract": "Convolutional Neural Networks (CNNs) have been successful in solving tasks in\ncomputer vision including medical image segmentation due to their ability to\nautomatically extract features from unstructured data. However, CNNs are\nsensitive to rotation and affine transformation and their success relies on\nhuge-scale labeled datasets capturing various input variations. This network\nparadigm has posed challenges at scale because acquiring annotated data for\nmedical segmentation is expensive, and strict privacy regulations. Furthermore,\nvisual representation learning with CNNs has its own flaws, e.g., it is\narguable that the pooling layer in traditional CNNs tends to discard positional\ninformation and CNNs tend to fail on input images that differ in orientations\nand sizes. Capsule network (CapsNet) is a recent new architecture that has\nachieved better robustness in representation learning by replacing pooling\nlayers with dynamic routing and convolutional strides, which has shown\npotential results on popular tasks such as classification, recognition,\nsegmentation, and natural language processing. Different from CNNs, which\nresult in scalar outputs, CapsNet returns vector outputs, which aim to preserve\nthe part-whole relationships. In this work, we first introduce the limitations\nof CNNs and fundamentals of CapsNet. We then provide recent developments of\nCapsNet for the task of medical image segmentation. We finally discuss various\neffective network architectures to implement a CapsNet for both 2D images and\n3D volumetric medical image segmentation.",
    "descriptor": "\nComments: Deep Learning for Medical Image Analysis, Elsevier/Academic Press (accepted)\n",
    "authors": [
      "Minh Tran",
      "Viet-Khoa Vo-Ho",
      "Kyle Quinn",
      "Hien Nguyen",
      "Khoa Luu",
      "Ngan Le"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08948"
  },
  {
    "id": "arXiv:2203.08980",
    "title": "Stochastic Simulation Uncertainty Analysis to Accelerate Flexible  Biomanufacturing Process Development",
    "abstract": "Motivated by critical challenges and needs from biopharmaceuticals\nmanufacturing, we propose a general metamodel-assisted stochastic simulation\nuncertainty analysis framework to accelerate the development of a simulation\nmodel or digital twin with modular design for flexible production processes.\nSince we often face very limited observations and complex biomanufacturing\nprocesses with high inherent stochasticity, there exist both simulation and\nmodel uncertainties in the system performance estimates. In biopharmaceutical\nmanufacturing, model uncertainty often dominates. The proposed framework can\nproduce a confidence interval that accounts for simulation and model\nuncertainties by using a metamodel-assisted bootstrapping approach.\nFurthermore, a variance decomposition is utilized to estimate the relative\ncontributions from each source of model uncertainty, as well as simulation\nuncertainty. This information can efficiently guide digital twin development.\nAsymptotic analysis provides theoretical support for our approach, while the\nempirical study demonstrates that it has good finite-sample performance.",
    "descriptor": "\nComments: 30 pages, 3 figures\n",
    "authors": [
      "Wei Xie",
      "Russell R. Barton",
      "Barry L. Nelson",
      "Keqi Wang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08980"
  },
  {
    "id": "arXiv:2203.09046",
    "title": "Memristive deep belief neural network by silicon synapses",
    "abstract": "Memristor-based neuromorphic computing systems address the memory-wall issue\nin von Neumann architecture that prevents the efficient training of deep neural\nnetworks (DNNs). Nevertheless, emerging memristor devices, with the existence\nof several non-idealities, such as poor yield and limited number of reliable\nconductance states, are still not mature for practical neuromorphic systems. At\nthe same time, the mainstream neuromorphic DNNs utilize the error\nbackpropagation-based gradient descent algorithm, requiring ideal synaptic\nbehavior of the memristive devices and complex neural circuits. To address this\nchallenge, we demonstrate the training of a memristive restricted Boltzmann\nmachine (memristive RBM) and deep belief neural network (memristive DBN) that\nemploy memristor devices fabricated in a commercial complementary\nmetal-oxide-semiconductor process as artificial synapses and utilize the\ngradient descent algorithm based on contrastive divergence (CD). The memristor\ndevices are based on the floating gate (FG) principle, showing analog\ntunability, high endurance, long retention time, predictable cycling\ndegradation, moderate device-to-device variations, high yield, and two orders\nof magnitude higher energy efficiency for multiply-accumulate operations than\ntoday's graphical processing units. The CD-based gradient descent algorithm\nhighly relaxes both the requirements of the synaptic behavior for the memristor\ndevices and the complexity of the neuron circuits. Two 12-by-8 arrays of FG\nmemristors are utilized to demonstrate the training of an RBM intended for\npattern recognition. We then benchmark an extrapolated memristive DBN\nconsisting of three memristive RBMs for the MNIST dataset, showing a\nrecognition accuracy up to 97.05%. The designed memristive RBM and DBN have\nminimal neuron circuits where no digital-to-analog and analog-to-digital\nconverters are needed.",
    "descriptor": "",
    "authors": [
      "Wei Wang",
      "Loai Danial",
      "Yang Li",
      "Eric Herbelin",
      "Evgeny Pikhay",
      "Yakov Roizin",
      "Barak Hoffer",
      "Zhongrui Wang",
      "Shahar Kvatinsky"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2203.09046"
  },
  {
    "id": "arXiv:2203.09079",
    "title": "On the convergence of decentralized gradient descent with diminishing  stepsize, revisited",
    "abstract": "Distributed optimization has received a lot of interest in recent years due\nto its wide applications in various fields. In this work, we revisit the\nconvergence property of the decentralized gradient descent [A.\nNedi{\\'c}-A.Ozdaglar (2009)] on the whole space given by $$ x_i(t+1) =\n\\sum^m_{j=1}w_{ij}x_j(t) - \\alpha(t) \\nabla f_i(x_i(t)), $$ where the stepsize\n$\\alpha (t) = \\frac{a}{(t+w)^p}$ with $0< p\\leq 1$. Under the strongly\nconvexity assumption on the total cost function $f$ with local cost functions\n$f_i$ not necessarily being convex, we show that the sequence converges to the\noptimizer with rate $O(t^{-p})$ when the values of $a>0$ and $w>0$ are suitably\nchosen.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Woocheol Choi",
      "Jimyeong Kim"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.09079"
  },
  {
    "id": "arXiv:2203.09179",
    "title": "Maximum Likelihood Estimation in Gaussian Process Regression is  Ill-Posed",
    "abstract": "Gaussian process regression underpins countless academic and industrial\napplications of machine learning and statistics, with maximum likelihood\nestimation routinely used to select appropriate parameters for the covariance\nkernel. However, it remains an open problem to establish the circumstances in\nwhich maximum likelihood estimation is well-posed. That is, when the\npredictions of the regression model are continuous (or insensitive to small\nperturbations) in the training data. This article presents a rigorous proof\nthat the maximum likelihood estimator fails to be well-posed in Hellinger\ndistance in a scenario where the data are noiseless. The failure case occurs\nfor any Gaussian process with a stationary covariance function whose\nlengthscale parameter is estimated using maximum likelihood. Although the\nfailure of maximum likelihood estimation is informally well-known, these\ntheoretical results appear to be the first of their kind, and suggest that\nwell-posedness may need to be assessed post-hoc, on a case-by-case basis, when\nmaximum likelihood estimation is used to train a Gaussian process model.",
    "descriptor": "",
    "authors": [
      "Toni Karvonen",
      "Chris J. Oates"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09179"
  },
  {
    "id": "arXiv:2203.09180",
    "title": "A Novel End-To-End Network for Reconstruction of Non-Regularly Sampled  Image Data Using Locally Fully Connected Layers",
    "abstract": "Quarter sampling and three-quarter sampling are novel sensor concepts that\nenable the acquisition of higher resolution images without increasing the\nnumber of pixels. This is achieved by non-regularly covering parts of each\npixel of a low-resolution sensor such that only one quadrant or three quadrants\nof the sensor area of each pixel is sensitive to light. Combining a properly\ndesigned mask and a high-quality reconstruction algorithm, a higher image\nquality can be achieved than using a low-resolution sensor and subsequent\nupsampling. For the latter case, the image quality can be further enhanced\nusing super resolution algorithms such as the very deep super resolution\nnetwork (VDSR). In this paper, we propose a novel end-to-end neural network to\nreconstruct high resolution images from non-regularly sampled sensor data. The\nnetwork is a concatenation of a locally fully connected reconstruction network\n(LFCR) and a standard VDSR network. Altogether, using a three-quarter sampling\nsensor with our novel neural network layout, the image quality in terms of PSNR\nfor the Urban100 dataset can be increased by 2.96 dB compared to the\nstate-of-the-art approach. Compared to a low-resolution sensor with VDSR, a\ngain of 1.11 dB is achieved.",
    "descriptor": "\nComments: 6 pages, 5 figures, 2 tables, IEEE 23rd International Workshop on Multimedia Signal Processing (MMSP)\n",
    "authors": [
      "Simon Grosche",
      "Fabian Brand",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09180"
  },
  {
    "id": "arXiv:2203.09199",
    "title": "Unified inverse correspondence for DLE-Logics",
    "abstract": "By exploiting the algebraic and order theoretic mechanisms behind Sahlqvist\ncorrespondence, the theory of unified correspondence provides powerful tools\nfor correspondence and canonicity across different semantics and signatures,\ncovering all the logics whose algebraic semantics are given by normal\n(distributive) lattice expansions (referred to as (D)LEs). In particular, the\nalgorithm ALBA, parametric in each (D)LE, effectively computes the first order\ncorrespondents of (D)LE-inductive formulas. We present an algorithm that makes\nuse of ALBA's rules and algebraic language to invert its steps in the DLE\nsetting; therefore effectively computing an inductive formula starting from its\nfirst order correspondent.",
    "descriptor": "",
    "authors": [
      "Willem Conradie",
      "Andrea De Domenico",
      "Giuseppe Greco",
      "Alessandra Palmigiano",
      "Mattia Panettiere",
      "Apostolos Tzimoulis"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.09199"
  },
  {
    "id": "arXiv:2203.09200",
    "title": "Novel Consistency Check For Fast Recursive Reconstruction Of  Non-Regularly Sampled Video Data",
    "abstract": "Quarter sampling is a novel sensor design that allows for an acquisition of\nhigher resolution images without increasing the number of pixels. When being\nused for video data, one out of four pixels is measured in each frame.\nEffectively, this leads to a non-regular spatio-temporal sub-sampling. Compared\nto purely spatial or temporal sub-sampling, this allows for an increased\nreconstruction quality, as aliasing artifacts can be reduced. For the fast\nreconstruction of such sensor data with a fixed mask, recursive variant of\nfrequency selective reconstruction (FSR) was proposed. Here, pixels measured in\nprevious frames are projected into the current frame to support its\nreconstruction. In doing so, the motion between the frames is computed using\ntemplate matching. Since some of the motion vectors may be erroneous, it is\nimportant to perform a proper consistency checking. In this paper, we propose\nfaster consistency checking methods as well as a novel recursive FSR that uses\nthe projected pixels different than in literature and can handle dynamic masks.\nAltogether, we are able to significantly increase the reconstruction quality by\n+ 1.01 dB compared to the state-of-the-art recursive reconstruction method\nusing a fixed mask. Compared to a single frame reconstruction, an average gain\nof about + 1.52 dB is achieved for dynamic masks. At the same time, the\ncomputational complexity of the consistency checks is reduced by a factor of 13\ncompared to the literature algorithm.",
    "descriptor": "\nComments: 5 pages, 5 figures, 3 tables, IEEE International Conference on Image Processing (ICIP)\n",
    "authors": [
      "Simon Grosche",
      "J\u00fcrgen Seiler",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09200"
  },
  {
    "id": "arXiv:2203.09207",
    "title": "Simulation-Driven Training of Vision Transformers Enabling Metal  Segmentation in X-Ray Images",
    "abstract": "In several image acquisition and processing steps of X-ray radiography,\nknowledge of the existence of metal implants and their exact position is highly\nbeneficial (e.g. dose regulation, image contrast adjustment). Another\napplication which would benefit from an accurate metal segmentation is cone\nbeam computed tomography (CBCT) which is based on 2D X-ray projections. Due to\nthe high attenuation of metals, severe artifacts occur in the 3D X-ray\nacquisitions. The metal segmentation in CBCT projections usually serves as a\nprerequisite for metal artifact avoidance and reduction algorithms. Since the\ngeneration of high quality clinical training is a constant challenge, this\nstudy proposes to generate simulated X-ray images based on CT data sets\ncombined with self-designed computer aided design (CAD) implants and make use\nof convolutional neural network (CNN) and vision transformer (ViT) for metal\nsegmentation. Model test is performed on accurately labeled X-ray test datasets\nobtained from specimen scans. The CNN encoder-based network like U-Net has\nlimited performance on cadaver test data with an average dice score below 0.30,\nwhile the metal segmentation transformer with dual decoder (MST-DD) shows high\nrobustness and generalization on the segmentation task, with an average dice\nscore of 0.90. Our study indicates that the CAD model-based data generation has\nhigh flexibility and could be a way to overcome the problem of shortage in\nclinical data sampling and labelling. Furthermore, the MST-DD approach\ngenerates a more reliable neural network in case of training on simulated data.",
    "descriptor": "",
    "authors": [
      "Fuxin Fan",
      "Ludwig Ritschl",
      "Marcel Beister",
      "Ramyar Biniazan",
      "Bj\u00f6rn Kreher",
      "Tristan M. Gottschalk",
      "Steffen Kappler",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09207"
  },
  {
    "id": "arXiv:2203.09250",
    "title": "Symmetry-Based Representations for Artificial and Biological General  Intelligence",
    "abstract": "Biological intelligence is remarkable in its ability to produce complex\nbehaviour in many diverse situations through data efficient, generalisable and\ntransferable skill acquisition. It is believed that learning \"good\" sensory\nrepresentations is important for enabling this, however there is little\nagreement as to what a good representation should look like. In this review\narticle we are going to argue that symmetry transformations are a fundamental\nprinciple that can guide our search for what makes a good representation. The\nidea that there exist transformations (symmetries) that affect some aspects of\nthe system but not others, and their relationship to conserved quantities has\nbecome central in modern physics, resulting in a more unified theoretical\nframework and even ability to predict the existence of new particles. Recently,\nsymmetries have started to gain prominence in machine learning too, resulting\nin more data efficient and generalisable algorithms that can mimic some of the\ncomplex behaviours produced by biological intelligence. Finally, first\ndemonstrations of the importance of symmetry transformations for representation\nlearning in the brain are starting to arise in neuroscience. Taken together,\nthe overwhelming positive effect that symmetries bring to these disciplines\nsuggest that they may be an important general framework that determines the\nstructure of the universe, constrains the nature of natural tasks and\nconsequently shapes both biological and artificial intelligence.",
    "descriptor": "",
    "authors": [
      "Irina Higgins",
      "S\u00e9bastien Racani\u00e8re",
      "Danilo Rezende"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09250"
  },
  {
    "id": "arXiv:2203.09268",
    "title": "Progressive Subsampling for Oversampled Data -- Application to  Quantitative MRI",
    "abstract": "We present PROSUB: PROgressive SUBsampling, a deep learning based, automated\nmethodology that subsamples an oversampled data set (e.g. multi-channeled 3D\nimages) with minimal loss of information. We build upon a recent dual-network\napproach that won the MICCAI MUlti-DIffusion (MUDI) quantitative MRI\nmeasurement sampling-reconstruction challenge, but suffers from deep learning\ntraining instability, by subsampling with a hard decision boundary. PROSUB uses\nthe paradigm of recursive feature elimination (RFE) and progressively\nsubsamples measurements during deep learning training, improving optimization\nstability. PROSUB also integrates a neural architecture search (NAS) paradigm,\nallowing the network architecture hyperparameters to respond to the subsampling\nprocess. We show PROSUB outperforms the winner of the MUDI MICCAI challenge,\nproducing large improvements >18% MSE on the MUDI challenge sub-tasks and\nqualitative improvements on downstream processes useful for clinical\napplications. We also show the benefits of incorporating NAS and analyze the\neffect of PROSUB's components. As our method generalizes to other problems\nbeyond MRI measurement selection-reconstruction, our code is\nhttps://github.com/sbb-gh/PROSUB",
    "descriptor": "",
    "authors": [
      "Stefano B. Blumberg",
      "Hongxiang Lin",
      "Francesco Grussu",
      "Yukun Zhou",
      "Matteo Figini",
      "Daniel C. Alexander"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2203.09268"
  },
  {
    "id": "arXiv:2203.09270",
    "title": "Mixing Up Contrastive Learning: Self-Supervised Representation Learning  for Time Series",
    "abstract": "The lack of labeled data is a key challenge for learning useful\nrepresentation from time series data. However, an unsupervised representation\nframework that is capable of producing high quality representations could be of\ngreat value. It is key to enabling transfer learning, which is especially\nbeneficial for medical applications, where there is an abundance of data but\nlabeling is costly and time consuming. We propose an unsupervised contrastive\nlearning framework that is motivated from the perspective of label smoothing.\nThe proposed approach uses a novel contrastive loss that naturally exploits a\ndata augmentation scheme in which new samples are generated by mixing two data\nsamples with a mixing component. The task in the proposed framework is to\npredict the mixing component, which is utilized as soft targets in the loss\nfunction. Experiments demonstrate the framework's superior performance compared\nto other representation learning approaches on both univariate and multivariate\ntime series and illustrate its benefits for transfer learning for clinical time\nseries.",
    "descriptor": "\nComments: Published in Journal of Pattern Recognition Letters: this https URL Code available at: this https URL\n",
    "authors": [
      "Kristoffer Wickstr\u00f8m",
      "Michael Kampffmeyer",
      "Karl \u00d8yvind Mikalsen",
      "Robert Jenssen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09270"
  },
  {
    "id": "arXiv:2203.09281",
    "title": "Ranking of Communities in Multiplex Spatiotemporal Models of Brain  Dynamics",
    "abstract": "As a relatively new field, network neuroscience has tended to focus on\naggregate behaviours of the brain averaged over many successive experiments or\nover long recordings in order to construct robust brain models. These models\nare limited in their ability to explain dynamic state changes in the brain\nwhich occurs spontaneously as a result of normal brain function. Hidden Markov\nModels (HMMs) trained on neuroimaging time series data have since arisen as a\nmethod to produce dynamical models that are easy to train but can be difficult\nto fully parametrise or analyse. We propose an interpretation of these neural\nHMMs as multiplex brain state graph models we term Hidden Markov Graph Models\n(HMGMs). This interpretation allows for dynamic brain activity to be analysed\nusing the full repertoire of network analysis techniques. Furthermore, we\npropose a general method for selecting HMM hyperparameters in the absence of\nexternal data, based on the principle of maximum entropy, and use this to\nselect the number of layers in the multiplex model. We produce a new tool for\ndetermining important communities of brain regions using a spatiotemporal\nrandom walk-based procedure that takes advantage of the underlying Markov\nstructure of the model. Our analysis of real multi-subject fMRI data provides\nnew results that corroborate the modular processing hypothesis of the brain at\nrest as well as contributing new evidence of functional overlap between and\nwithin dynamic brain state communities. Our analysis pipeline provides a way to\ncharacterise dynamic network activity of the brain under novel behaviours or\nconditions.",
    "descriptor": "\nComments: Part of the Special Issue on Community Structure in Networks 2021 (35 Pages, first 22 for main text)\n",
    "authors": [
      "James B. Wilsenach",
      "Catherine E. Warnaby",
      "Charlotte M. Deane",
      "Gesine D. Reinert"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09281"
  },
  {
    "id": "arXiv:2203.09347",
    "title": "Dimensionality Reduction and Wasserstein Stability for Kernel Regression",
    "abstract": "In a high-dimensional regression framework, we study consequences of the\nnaive two-step procedure where first the dimension of the input variables is\nreduced and second, the reduced input variables are used to predict the output\nvariable. More specifically we combine principal component analysis (PCA) with\nkernel regression. In order to analyze the resulting regression errors, a novel\nstability result of kernel regression with respect to the Wasserstein distance\nis derived. This allows us to bound errors that occur when perturbed input data\nis used to fit a kernel function. We combine the stability result with known\nestimates from the literature on both principal component analysis and kernel\nregression to obtain convergence rates for the two-step procedure.",
    "descriptor": "",
    "authors": [
      "Stephan Eckstein",
      "Armin Iske",
      "Mathias Trabs"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2203.09347"
  },
  {
    "id": "arXiv:2203.09348",
    "title": "POSTER: Diagnosis of COVID-19 through Transfer Learning Techniques on CT  Scans: A Comparison of Deep Learning Models",
    "abstract": "The novel coronavirus disease (COVID-19) constitutes a public health\nemergency globally. It is a deadly disease which has infected more than 230\nmillion people worldwide. Therefore, early and unswerving detection of COVID-19\nis necessary. Evidence of this virus is most commonly being tested by RT-PCR\ntest. This test is not 100% reliable as it is known to give false positives and\nfalse negatives. Other methods like X-Ray images or CT scans show the detailed\nimaging of lungs and have been proven more reliable. This paper compares\ndifferent deep learning models used to detect COVID-19 through transfer\nlearning technique on CT scan dataset. VGG-16 outperforms all the other models\nachieving an accuracy of 85.33% on the dataset.",
    "descriptor": "",
    "authors": [
      "Aeyan Ashraf",
      "Asad Malik",
      "Zahid Khan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09348"
  },
  {
    "id": "arXiv:2203.09372",
    "title": "Using the Order of Tomographic Slices as a Prior for Neural Networks  Pre-Training",
    "abstract": "The technical advances in Computed Tomography (CT) allow to obtain immense\namounts of 3D data. For such datasets it is very costly and time-consuming to\nobtain the accurate 3D segmentation markup to train neural networks. The\nannotation is typically done for a limited number of 2D slices, followed by an\ninterpolation. In this work, we propose a pre-training method SortingLoss. It\nperforms pre-training on slices instead of volumes, so that a model could be\nfine-tuned on a sparse set of slices, without the interpolation step. Unlike\ngeneral methods (e.g. SimCLR or Barlow Twins), the task specific methods (e.g.\nTransferable Visual Words) trade broad applicability for quality benefits by\nimposing stronger assumptions on the input data. We propose a relatively mild\nassumption -- if we take several slices along some axis of a volume, structure\nof the sample presented on those slices, should give a strong clue to\nreconstruct the correct order of those slices along the axis. Many biomedical\ndatasets fulfill this requirement due to the specific anatomy of a sample and\npre-defined alignment of the imaging setup. We examine the proposed method on\ntwo datasets: medical CT of lungs affected by COVID-19 disease, and\nhigh-resolution synchrotron-based full-body CT of model organisms (Medaka\nfish). We show that the proposed method performs on par with SimCLR, while\nworking 2x faster and requiring 1.5x less memory. In addition, we present the\nbenefits in terms of practical scenarios, especially the applicability to the\npre-training of large models and the ability to localize samples within volumes\nin an unsupervised setup.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Yaroslav Zharov",
      "Alexey Ershov",
      "Tilo Baumbach",
      "Vincent Heuveline"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09372"
  },
  {
    "id": "arXiv:2203.09376",
    "title": "Gaussian initializations help deep variational quantum circuits escape  from the barren plateau",
    "abstract": "Variational quantum circuits have been widely employed in quantum simulation\nand quantum machine learning in recent years. However, quantum circuits with\nrandom structures have poor trainability due to the exponentially vanishing\ngradient with respect to the circuit depth and the qubit number. This result\nleads to a general belief that deep quantum circuits will not be feasible for\npractical tasks. In this work, we propose an initialization strategy with\ntheoretical guarantees for the vanishing gradient problem in general deep\ncircuits. Specifically, we prove that under proper Gaussian initialized\nparameters, the norm of the gradient decays at most polynomially when the qubit\nnumber and the circuit depth increase. Our theoretical results hold for both\nthe local and the global observable cases, where the latter was believed to\nhave vanishing gradients even for shallow circuits. Experimental results verify\nour theoretical findings in the quantum simulation and quantum chemistry.",
    "descriptor": "\nComments: Comments welcome!\n",
    "authors": [
      "Kaining Zhang",
      "Min-Hsiu Hsieh",
      "Liu Liu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09376"
  },
  {
    "id": "arXiv:2203.09410",
    "title": "A Framework and Benchmark for Deep Batch Active Learning for Regression",
    "abstract": "We study the performance of different pool-based Batch Mode Deep Active\nLearning (BMDAL) methods for regression on tabular data, focusing on methods\nthat do not require to modify the network architecture and training. Our\ncontributions are three-fold: First, we present a framework for constructing\nBMDAL methods out of kernels, kernel transformations and selection methods,\nshowing that many of the most popular BMDAL methods fit into our framework.\nSecond, we propose new components, leading to a new BMDAL method. Third, we\nintroduce an open-source benchmark with 15 large tabular data sets, which we\nuse to compare different BMDAL methods. Our benchmark results show that a\ncombination of our novel components yields new state-of-the-art results in\nterms of RMSE and is computationally efficient. We provide open-source code\nthat includes efficient implementations of all kernels, kernel transformations,\nand selection methods, and can be used for reproducing our results.",
    "descriptor": "\nComments: Accompanying code can be found at this https URL\n",
    "authors": [
      "David Holzm\u00fcller",
      "Viktor Zaverkin",
      "Johannes K\u00e4stner",
      "Ingo Steinwart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.09410"
  },
  {
    "id": "arXiv:2203.09413",
    "title": "Stability and Risk Bounds of Iterative Hard Thresholding",
    "abstract": "In this paper, we analyze the generalization performance of the Iterative\nHard Thresholding (IHT) algorithm widely used for sparse recovery problems. The\nparameter estimation and sparsity recovery consistency of IHT has long been\nknown in compressed sensing. From the perspective of statistical learning,\nanother fundamental question is how well the IHT estimation would predict on\nunseen data. This paper makes progress towards answering this open question by\nintroducing a novel sparse generalization theory for IHT under the notion of\nalgorithmic stability. Our theory reveals that: 1) under natural conditions on\nthe empirical risk function over $n$ samples of dimension $p$, IHT with\nsparsity level $k$ enjoys an $\\mathcal{\\tilde\nO}(n^{-1/2}\\sqrt{k\\log(n)\\log(p)})$ rate of convergence in sparse excess risk;\n2) a tighter $\\mathcal{\\tilde O}(n^{-1/2}\\sqrt{\\log(n)})$ bound can be\nestablished by imposing an additional iteration stability condition on a\nhypothetical IHT procedure invoked to the population risk; and 3) a fast rate\nof order $\\mathcal{\\tilde O}\\left(n^{-1}k(\\log^3(n)+\\log(p))\\right)$ can be\nderived for strongly convex risk function under proper strong-signal\nconditions. The results have been substantialized to sparse linear regression\nand sparse logistic regression models to demonstrate the applicability of our\ntheory. Preliminary numerical evidence is provided to confirm our theoretical\npredictions.",
    "descriptor": "",
    "authors": [
      "Xiao-Tong Yuan",
      "Ping Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.09413"
  },
  {
    "id": "arXiv:2203.09427",
    "title": "An inverse problem for a semi-linear wave equation: a numerical study",
    "abstract": "We consider an inverse problem of recovering a potential associated to a\nsemi-linear wave equation with a quadratic nonlinearity in $1 + 1$ dimensions.\nWe develop a numerical scheme to determine the potential from a noisy\nDirichlet-to-Neumann map on the lateral boundary. The scheme is based on the\nrecent higher order linearization method [20]. We also present an approach to\nnumerically estimating two-dimensional derivatives of noisy data via Tikhonov\nregularization. The methods are tested using synthetic noisy measurements of\nthe Dirichlet-to-Neumann map. Various examples of reconstructions of the\npotential functions are given.",
    "descriptor": "\nComments: 23 pages, 11 figures, 1 table\n",
    "authors": [
      "Matti Lassas",
      "Tony Liimatainen",
      "Leyter Potenciano-Machado",
      "Teemu Tyni"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.09427"
  },
  {
    "id": "arXiv:2203.09436",
    "title": "A Stochastic Halpern Iteration with Variance Reduction for Stochastic  Monotone Inclusion Problems",
    "abstract": "We study stochastic monotone inclusion problems, which widely appear in\nmachine learning applications, including robust regression and adversarial\nlearning. We propose novel variants of stochastic Halpern iteration with\nrecursive variance reduction. In the cocoercive -- and more generally\nLipschitz-monotone -- setup, our algorithm attains $\\epsilon$ norm of the\noperator with $\\mathcal{O}(\\frac{1}{\\epsilon^3})$ stochastic operator\nevaluations, which significantly improves over state of the art\n$\\mathcal{O}(\\frac{1}{\\epsilon^4})$ stochastic operator evaluations required\nfor existing monotone inclusion solvers applied to the same problem classes. We\nfurther show how to couple one of the proposed variants of stochastic Halpern\niteration with a scheduled restart scheme to solve stochastic monotone\ninclusion problems with ${\\mathcal{O}}(\\frac{\\log(1/\\epsilon)}{\\epsilon^2})$\nstochastic operator evaluations under additional sharpness or strong\nmonotonicity assumptions. Finally, we argue via reductions between different\nproblem classes that our stochastic oracle complexity bounds are tight up to\nlogarithmic factors in terms of their $\\epsilon$-dependence.",
    "descriptor": "",
    "authors": [
      "Xufeng Cai",
      "Chaobing Song",
      "Crist\u00f3bal Guzm\u00e1n",
      "Jelena Diakonikolas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09436"
  },
  {
    "id": "arXiv:2203.09456",
    "title": "MolNet: A Chemically Intuitive Graph Neural Network for Prediction of  Molecular Properties",
    "abstract": "The graph neural network (GNN) has been a powerful deep-learning tool in\nchemistry domain, due to its close connection with molecular graphs. Most GNN\nmodels collect and update atom and molecule features from the fed atom (and, in\nsome cases, bond) features, which are basically based on the two-dimensional\n(2D) graph representation of 3D molecules. Correspondingly, the adjacency\nmatrix, containing the information on covalent bonds, or equivalent data\nstructures (e.g., lists) have been the main core in the feature-updating\nprocesses, such as graph convolution. However, the 2D-based models do not\nfaithfully represent 3D molecules and their physicochemical properties,\nexemplified by the overlooked field effect that is a \"through-space\" effect,\nnot a \"through-bond\" effect. The GNN model proposed herein, denoted as MolNet,\nis chemically intuitive, accommodating the 3D non-bond information in a\nmolecule, with a noncovalent adjacency matrix $\\bf{\\bar A}$, and also\nbond-strength information from a weighted bond matrix $\\bf{B}$. The noncovalent\natoms, not directly bonded to a given atom in a molecule, are identified within\n5 $\\unicode{x212B}$ of cut-off range for the construction of $\\bf{\\bar A}$, and\n$\\bf{B}$ has edge weights of 1, 1.5, 2, and 3 for single, aromatic, double, and\ntriple bonds, respectively. Comparative studies show that MolNet outperforms\nvarious baseline GNN models and gives a state-of-the-art performance in the\nclassification task of BACE dataset and regression task of ESOL dataset. This\nwork suggests a future direction of deep-learning chemistry in the construction\nof deep-learning models that are chemically intuitive and comparable with the\nexisting chemistry concepts and tools.",
    "descriptor": "\nComments: 25 pages including 6-page Supporting Information\n",
    "authors": [
      "Yeji Kim",
      "Yoonho Jeong",
      "Jihoo Kim",
      "Eok Kyun Lee",
      "Won June Kim",
      "Insung S. Choi"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09456"
  },
  {
    "id": "arXiv:2203.09477",
    "title": "A Decomposition-Based Hybrid Ensemble CNN Framework for Improving  Cross-Subject EEG Decoding Performance",
    "abstract": "Electroencephalogram (EEG) signals are complex, non-linear, and\nnon-stationary in nature. However, previous studies that applied decomposition\nto minimize the complexity mainly exploited the hand-engineering features,\nlimiting the information learned in EEG decoding. Therefore, extracting\nadditional primary features from different disassembled components to improve\nthe EEG-based recognition performance remains challenging. On the other hand,\nattempts have been made to use a single model to learn the hand-engineering\nfeatures. Less work has been done to improve the generalization ability through\nensemble learning. In this work, we propose a novel decomposition-based hybrid\nensemble convolutional neural network (CNN) framework to enhance the capability\nof decoding EEG signals. CNNs, in particular, automatically learn the primary\nfeatures from raw disassembled components but not handcraft features. The first\noption is to fuse the obtained score before the Softmax layer and execute\nback-propagation on the entire ensemble network, whereas the other is to fuse\nthe probability output of the Softmax layer. Moreover, a component-specific\nbatch normalization (CSBN) layer is employed to reduce subject variability.\nAgainst the challenging cross-subject driver fatigue-related situation\nawareness (SA) recognition task, eight models are proposed under the framework,\nwhich all showed superior performance than the strong baselines. The\nperformance of different decomposition methods and ensemble modes were further\ncompared. Results indicated that discrete wavelet transform (DWT)-based\nensemble CNN achieves the best 82.11% among the proposed models. Our framework\ncan be simply extended to any CNN architecture and applied in any EEG-related\nsectors, opening the possibility of extracting more preliminary information\nfrom complex EEG data.",
    "descriptor": "",
    "authors": [
      "Ruilin Li",
      "Ruobin Gao",
      "P. N. Suganthan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09477"
  },
  {
    "id": "arXiv:2203.09487",
    "title": "Defending Against Adversarial Attack in ECG Classification with  Adversarial Distillation Training",
    "abstract": "In clinics, doctors rely on electrocardiograms (ECGs) to assess severe\ncardiac disorders. Owing to the development of technology and the increase in\nhealth awareness, ECG signals are currently obtained by using medical and\ncommercial devices. Deep neural networks (DNNs) can be used to analyze these\nsignals because of their high accuracy rate. However, researchers have found\nthat adversarial attacks can significantly reduce the accuracy of DNNs. Studies\nhave been conducted to defend ECG-based DNNs against traditional adversarial\nattacks, such as projected gradient descent (PGD), and smooth adversarial\nperturbation (SAP) which targets ECG classification; however, to the best of\nour knowledge, no study has completely explored the defense against adversarial\nattacks targeting ECG classification. Thus, we did different experiments to\nexplore the effects of defense methods against white-box adversarial attack and\nblack-box adversarial attack targeting ECG classification, and we found that\nsome common defense methods performed well against these attacks. Besides, we\nproposed a new defense method called Adversarial Distillation Training (ADT)\nwhich comes from defensive distillation and can effectively improve the\ngeneralization performance of DNNs. The results show that our method performed\nmore effectively against adversarial attacks targeting on ECG classification\nthan the other baseline methods, namely, adversarial training, defensive\ndistillation, Jacob regularization, and noise-to-signal ratio regularization.\nFurthermore, we found that our method performed better against PGD attacks with\nlow noise levels, which means that our method has stronger robustness.",
    "descriptor": "",
    "authors": [
      "Jiahao Shao",
      "Shijia Geng",
      "Zhaoji Fu",
      "Weilun Xu",
      "Tong Liu",
      "Shenda Hong"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09487"
  },
  {
    "id": "arXiv:2203.09496",
    "title": "Optimal schemes for combinatorial query problems with integer feedback",
    "abstract": "A query game is a pair of a set $Q$ of queries and a set $\\mathcal{F}$ of\nfunctions, or code words $f:Q\\rightarrow\\mathbb{Z}$. We think of this as a\ntwo-player game. One player, Codemaker, picks a hidden code word\n$f\\in\\mathcal{F}$. The other player, Codebreaker, then tries to determine $f$\nby asking a sequence of queries $q\\in Q$, after each of which Codemaker must\nrespond with the value $f(q)$. The goal of Codebreaker is to achieve this using\nas few queries as possible. Two classical examples of such games are\ncoin-weighing with a spring scale, and Mastermind, which are of interest both\nas recreational games and for their connection to information theory.\nIn this paper, we will present a general framework for finding short\nsolutions to query games. As applications, we give new self-contained proofs of\nthe query complexity of variations of the coin-weighing problems, and prove new\nresults that the deterministic query complexity of Mastermind is $\\Theta(n \\log\nk/ \\log n + k)$ if only black-peg information is provided, and $\\Theta(n \\log k\n/ \\log n + k/n)$ if both black- and white-peg information is provided. In the\ndeterministic setting, these are the first up to constant factor optimal\nsolutions to Mastermind known for any $k\\geq n^{1-o(1)}$.",
    "descriptor": "\nComments: 29 pages, no figures\n",
    "authors": [
      "Anders Martinsson"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.09496"
  },
  {
    "id": "arXiv:1812.07844",
    "title": "Beyond z=0. The Deutsch-Jozsa decided monochromatic languages",
    "abstract": "Comments: I have discovered an inconsistency that invalidates the conclusion of having monochromatic output states",
    "descriptor": "\nComments: I have discovered an inconsistency that invalidates the conclusion of having monochromatic output states\n",
    "authors": [
      "Eraldo Pereira Marinho"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/1812.07844"
  },
  {
    "id": "arXiv:1905.02050",
    "title": "Analyzing Code Comments to Boost Program Comprehension",
    "abstract": "Analyzing Code Comments to Boost Program Comprehension",
    "descriptor": "",
    "authors": [
      "Yusuke Shinyama",
      "Yoshitaka Arahori",
      "Katsuhiko Gondow"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/1905.02050"
  },
  {
    "id": "arXiv:1908.02202",
    "title": "Generalized Lens Categories via functors $\\mathcal{C}^{\\rm  op}\\to\\mathsf{Cat}$",
    "abstract": "Comments: 10 pages. (This version: fix some typos)",
    "descriptor": "\nComments: 10 pages. (This version: fix some typos)\n",
    "authors": [
      "David I. Spivak"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1908.02202"
  },
  {
    "id": "arXiv:1912.06113",
    "title": "Error bounds for model reduction of feedback-controlled linear  stochastic dynamics on Hilbert spaces",
    "abstract": "Comments: comments welcome",
    "descriptor": "\nComments: comments welcome\n",
    "authors": [
      "Simon Becker",
      "Carsten Hartmann",
      "Martin Redmann",
      "Lorenz Richter"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1912.06113"
  },
  {
    "id": "arXiv:2002.05299",
    "title": "Depth Descent Synchronization in $\\mathrm{SO}(D)$",
    "abstract": "Comments: 22 pages, 3 figures",
    "descriptor": "\nComments: 22 pages, 3 figures\n",
    "authors": [
      "Tyler Maunu",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2002.05299"
  },
  {
    "id": "arXiv:2002.08648",
    "title": "Adaptive Graph Auto-Encoder for General Data Clustering",
    "abstract": "Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Xuelong Li",
      "Hongyuan Zhang",
      "Rui Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.08648"
  },
  {
    "id": "arXiv:2002.11503",
    "title": "Wavelet-based Temporal Models of Human Activity for Anomaly Detection in  Smart Robot-assisted Environments",
    "abstract": "Comments: 14 pages, 6 figures",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Manuel Fernandez-Carmona",
      "Nicola Bellotto"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2002.11503"
  },
  {
    "id": "arXiv:2003.12447",
    "title": "Anchor Attention for Hybrid Crowd Forecasts Aggregation",
    "abstract": "Anchor Attention for Hybrid Crowd Forecasts Aggregation",
    "descriptor": "",
    "authors": [
      "Yuzhong Huang",
      "Andres Abeliuk",
      "Fred Morstatter",
      "Pavel Atanasov",
      "Aram Galstyan"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2003.12447"
  },
  {
    "id": "arXiv:2005.08644",
    "title": "Intracranial Hemorrhage Detection Using Neural Network Based Methods  With Federated Learning",
    "abstract": "Comments: 3 pages",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "Utkarsh Chandra Srivastava",
      "Anshuman Singh",
      "Dr. K. Sree Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2005.08644"
  },
  {
    "id": "arXiv:2006.06853",
    "title": "Bandit Labor Training",
    "abstract": "Comments: 58 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: 58 pages, 5 figures, 2 tables\n",
    "authors": [
      "Eren Ozbay",
      "Vijay Kamble"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.06853"
  },
  {
    "id": "arXiv:2006.14192",
    "title": "On a three dimensional Compton scattering tomography system with fixed  source",
    "abstract": "Comments: The algorithm for discrete spherical harmonic expansion is available on github (see the text)",
    "descriptor": "\nComments: The algorithm for discrete spherical harmonic expansion is available on github (see the text)\n",
    "authors": [
      "Javier Cebeiro",
      "Cecilia Tarpau",
      "Marcela Morvidone",
      "Diana Rubio",
      "Mai Nguyen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.14192"
  },
  {
    "id": "arXiv:2007.06920",
    "title": "A Practical Algorithm with Performance Guarantees for the Art Gallery  Problem",
    "abstract": "Comments: 48 pages main body, 21 figures",
    "descriptor": "\nComments: 48 pages main body, 21 figures\n",
    "authors": [
      "Simon Hengeveld",
      "Tillmann Miltzow"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2007.06920"
  },
  {
    "id": "arXiv:2008.07343",
    "title": "Artificial Intelligence in the Battle against Coronavirus (COVID-19): A  Survey and Future Research Directions",
    "abstract": "Artificial Intelligence in the Battle against Coronavirus (COVID-19): A  Survey and Future Research Directions",
    "descriptor": "",
    "authors": [
      "Thanh Thi Nguyen",
      "Quoc Viet Hung Nguyen",
      "Dung Tien Nguyen",
      "Samuel Yang",
      "Peter W. Eklund",
      "Thien Huynh-The",
      "Thanh Tam Nguyen",
      "Quoc-Viet Pham",
      "Imran Razzak",
      "Edbert B. Hsu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.07343"
  },
  {
    "id": "arXiv:2008.10362",
    "title": "Fast Approximate Dynamic Programming for Input-Affine Dynamics",
    "abstract": "Fast Approximate Dynamic Programming for Input-Affine Dynamics",
    "descriptor": "",
    "authors": [
      "M. A. S. Kolarijani",
      "P. Mohajerin Esfahani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.10362"
  },
  {
    "id": "arXiv:2009.05602",
    "title": "Semantic-preserving Reinforcement Learning Attack Against Graph Neural  Networks for Malware Detection",
    "abstract": "Semantic-preserving Reinforcement Learning Attack Against Graph Neural  Networks for Malware Detection",
    "descriptor": "",
    "authors": [
      "Lan Zhang",
      "Peng Liu",
      "Yoon-Ho Choi",
      "Ping Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.05602"
  },
  {
    "id": "arXiv:2009.06884",
    "title": "Towards Equivalent Transformation of User Preferences in Cross Domain  Recommendation",
    "abstract": "Comments: Accepted by ACM Transactions on Information Systems (TOIS), 2022",
    "descriptor": "\nComments: Accepted by ACM Transactions on Information Systems (TOIS), 2022\n",
    "authors": [
      "Xu Chen",
      "Ya Zhang",
      "Ivor Tsang",
      "Yuangang Pan",
      "Jingchao Su"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2009.06884"
  },
  {
    "id": "arXiv:2009.13819",
    "title": "The Shapley Value of Inconsistency Measures for Functional Dependencies",
    "abstract": "The Shapley Value of Inconsistency Measures for Functional Dependencies",
    "descriptor": "",
    "authors": [
      "Ester Livshits",
      "Benny Kimelfeld"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2009.13819"
  },
  {
    "id": "arXiv:2011.13203",
    "title": "Everyone Knows that Everyone Knows: Gossip Protocols for Super Experts",
    "abstract": "Everyone Knows that Everyone Knows: Gossip Protocols for Super Experts",
    "descriptor": "",
    "authors": [
      "Hans van Ditmarsch",
      "Malvin Gattinger",
      "Rahim Ramezanian"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.13203"
  },
  {
    "id": "arXiv:2012.05858",
    "title": "SPAA: Stealthy Projector-based Adversarial Attacks on Deep Image  Classifiers",
    "abstract": "SPAA: Stealthy Projector-based Adversarial Attacks on Deep Image  Classifiers",
    "descriptor": "",
    "authors": [
      "Bingyao Huang",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.05858"
  },
  {
    "id": "arXiv:2012.05896",
    "title": "Encoding Classical Information in Gauge Subsystems of Quantum Codes",
    "abstract": "Comments: 22 pages, 2 figures",
    "descriptor": "\nComments: 22 pages, 2 figures\n",
    "authors": [
      "Andrew Nemec",
      "Andreas Klappenecker"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.05896"
  },
  {
    "id": "arXiv:2012.15511",
    "title": "Towards Understanding Asynchronous Advantage Actor-critic: Convergence  and Linear Speedup",
    "abstract": "Towards Understanding Asynchronous Advantage Actor-critic: Convergence  and Linear Speedup",
    "descriptor": "",
    "authors": [
      "Han Shen",
      "Kaiqing Zhang",
      "Mingyi Hong",
      "Tianyi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2012.15511"
  },
  {
    "id": "arXiv:2101.00036",
    "title": "KART: Parameterization of Privacy Leakage Scenarios from Pre-trained  Language Models",
    "abstract": "KART: Parameterization of Privacy Leakage Scenarios from Pre-trained  Language Models",
    "descriptor": "",
    "authors": [
      "Yuta Nakamura",
      "Shouhei Hanaoka",
      "Yukihiro Nomura",
      "Naoto Hayashi",
      "Osamu Abe",
      "Shuntaro Yada",
      "Shoko Wakamiya",
      "Eiji Aramaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00036"
  },
  {
    "id": "arXiv:2101.01648",
    "title": "Nonlinear Filter for Simultaneous Localization and Mapping on a Matrix  Lie Group using IMU and Feature Measurements",
    "abstract": "Nonlinear Filter for Simultaneous Localization and Mapping on a Matrix  Lie Group using IMU and Feature Measurements",
    "descriptor": "",
    "authors": [
      "Hashim A. Hashim",
      "Abdelrahman E. E. Eltoukhy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.01648"
  },
  {
    "id": "arXiv:2101.05467",
    "title": "Tackling Instance-Dependent Label Noise via a Universal Probabilistic  Model",
    "abstract": "Tackling Instance-Dependent Label Noise via a Universal Probabilistic  Model",
    "descriptor": "",
    "authors": [
      "Qizhou Wang",
      "Bo Han",
      "Tongliang Liu",
      "Gang Niu",
      "Jian Yang",
      "Chen Gong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.05467"
  },
  {
    "id": "arXiv:2102.02611",
    "title": "CKConv: Continuous Kernel Convolution For Sequential Data",
    "abstract": "CKConv: Continuous Kernel Convolution For Sequential Data",
    "descriptor": "",
    "authors": [
      "David W. Romero",
      "Anna Kuzina",
      "Erik J. Bekkers",
      "Jakub M. Tomczak",
      "Mark Hoogendoorn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02611"
  },
  {
    "id": "arXiv:2102.07258",
    "title": "A Glimpse of Physical Layer Decision Mechanisms: Facts, Challenges, and  Remedies",
    "abstract": "A Glimpse of Physical Layer Decision Mechanisms: Facts, Challenges, and  Remedies",
    "descriptor": "",
    "authors": [
      "Selen Gecgel",
      "Caner Goztepe",
      "Gunes Karabulut Kurt",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.07258"
  },
  {
    "id": "arXiv:2102.07835",
    "title": "Topological Graph Neural Networks",
    "abstract": "Topological Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Max Horn",
      "Edward De Brouwer",
      "Michael Moor",
      "Yves Moreau",
      "Bastian Rieck",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.07835"
  },
  {
    "id": "arXiv:2102.08146",
    "title": "Nominal Unification and Matching of Higher Order Expressions with  Recursive Let",
    "abstract": "Comments: 35 pages, 9 figures, This paper is an extended version of the conference publication: Manfred Schmidt-Schau{\\ss} and Temur Kutsia and Jordi Levy and Mateu Villaret and Yunus Kutz, Nominal Unification of Higher Order Expressions with Recursive Let, LOPSTR-16, Lecture Notes in Computer Science 10184, Springer, p 328 -344, 2016. arXiv admin note: text overlap with arXiv:1608.03771",
    "descriptor": "\nComments: 35 pages, 9 figures, This paper is an extended version of the conference publication: Manfred Schmidt-Schau{\\ss} and Temur Kutsia and Jordi Levy and Mateu Villaret and Yunus Kutz, Nominal Unification of Higher Order Expressions with Recursive Let, LOPSTR-16, Lecture Notes in Computer Science 10184, Springer, p 328 -344, 2016. arXiv admin note: text overlap with arXiv:1608.03771\n",
    "authors": [
      "Manfred Schmidt-Schau\u00df",
      "Temur Kutsia",
      "Jordi Levy",
      "Mateu Villaret",
      "Yunus Kutz"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.08146"
  },
  {
    "id": "arXiv:2102.08880",
    "title": "Fast Approximate Dynamic Programming for Infinite-Horizon Markov  Decision Processes",
    "abstract": "Fast Approximate Dynamic Programming for Infinite-Horizon Markov  Decision Processes",
    "descriptor": "",
    "authors": [
      "M. A. S. Kolarijani",
      "G. F. Max",
      "P. Mohajerin Esfahani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.08880"
  },
  {
    "id": "arXiv:2103.00710",
    "title": "Towards Personalized Federated Learning",
    "abstract": "Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Alysa Ziying Tan",
      "Han Yu",
      "Lizhen Cui",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2103.00710"
  },
  {
    "id": "arXiv:2103.08361",
    "title": "BLOWN: A Blockchain Protocol for Single-Hop Wireless Networks under  Adversarial SINR",
    "abstract": "Comments: 18 pages, 11 figures, journal paper",
    "descriptor": "\nComments: 18 pages, 11 figures, journal paper\n",
    "authors": [
      "Minghui Xu",
      "Feng Zhao",
      "Yifei Zou",
      "Chunchi Liu",
      "Xiuzhen Cheng",
      "Falko Dressler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.08361"
  },
  {
    "id": "arXiv:2103.08573",
    "title": "RoRD: Rotation-Robust Descriptors and Orthographic Views for Local  Feature Matching",
    "abstract": "Comments: Accepted to IROS 2021. Project Page: this https URL",
    "descriptor": "\nComments: Accepted to IROS 2021. Project Page: this https URL\n",
    "authors": [
      "Udit Singh Parihar",
      "Aniket Gujarathi",
      "Kinal Mehta",
      "Satyajit Tourani",
      "Sourav Garg",
      "Michael Milford",
      "K. Madhava Krishna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.08573"
  },
  {
    "id": "arXiv:2103.09488",
    "title": "Revisiting the Loss Weight Adjustment in Object Detection",
    "abstract": "Comments: Incorrect description of content",
    "descriptor": "\nComments: Incorrect description of content\n",
    "authors": [
      "Wenxin Yu",
      "Xueling Shen",
      "Jiajie Hu",
      "Dong Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.09488"
  },
  {
    "id": "arXiv:2103.09716",
    "title": "Quantitative Performance Assessment of CNN Units via Topological Entropy  Calculation",
    "abstract": "Comments: Conference paper at ICLR 2022",
    "descriptor": "\nComments: Conference paper at ICLR 2022\n",
    "authors": [
      "Yang Zhao",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.09716"
  },
  {
    "id": "arXiv:2103.10360",
    "title": "GLM: General Language Model Pretraining with Autoregressive Blank  Infilling",
    "abstract": "Comments: to be published in ACL 2022. 16 pages, 4 figures",
    "descriptor": "\nComments: to be published in ACL 2022. 16 pages, 4 figures\n",
    "authors": [
      "Zhengxiao Du",
      "Yujie Qian",
      "Xiao Liu",
      "Ming Ding",
      "Jiezhong Qiu",
      "Zhilin Yang",
      "Jie Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10360"
  },
  {
    "id": "arXiv:2103.13389",
    "title": "Generating Novel Scene Compositions from Single Images and Videos",
    "abstract": "Comments: Code repository: this https URL",
    "descriptor": "\nComments: Code repository: this https URL\n",
    "authors": [
      "Vadim Sushko",
      "Dan Zhang",
      "Juergen Gall",
      "Anna Khoreva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.13389"
  },
  {
    "id": "arXiv:2103.15443",
    "title": "A Function Field Approach Toward Good Polynomials for Further Results on  Optimal LRC Codes",
    "abstract": "A Function Field Approach Toward Good Polynomials for Further Results on  Optimal LRC Codes",
    "descriptor": "",
    "authors": [
      "Ruikai Chen",
      "Sihem Mesnager"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.15443"
  },
  {
    "id": "arXiv:2104.07176",
    "title": "Accelerated Optimization on Riemannian Manifolds via Discrete  Constrained Variational Integrators",
    "abstract": "Comments: 24 pages, 1 figure",
    "descriptor": "\nComments: 24 pages, 1 figure\n",
    "authors": [
      "Valentin Duruisseaux",
      "Melvin Leok"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.07176"
  },
  {
    "id": "arXiv:2104.07429",
    "title": "First the worst: Finding better gender translations during beam search",
    "abstract": "Comments: Findings of ACL (2022). 5 pages with 2 pages of appendices",
    "descriptor": "\nComments: Findings of ACL (2022). 5 pages with 2 pages of appendices\n",
    "authors": [
      "Danielle Saunders",
      "Rosie Sallis",
      "Bill Byrne"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.07429"
  },
  {
    "id": "arXiv:2104.08664",
    "title": "Characterizing Idioms: Conventionality and Contingency",
    "abstract": "Characterizing Idioms: Conventionality and Contingency",
    "descriptor": "",
    "authors": [
      "Michaela Socolof",
      "Jackie Chi Kit Cheung",
      "Michael Wagner",
      "Timothy J. O'Donnell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08664"
  },
  {
    "id": "arXiv:2104.08726",
    "title": "AmericasNLI: Evaluating Zero-shot Natural Language Understanding of  Pretrained Multilingual Models in Truly Low-resource Languages",
    "abstract": "Comments: Accepted to ACL 2022",
    "descriptor": "\nComments: Accepted to ACL 2022\n",
    "authors": [
      "Abteen Ebrahimi",
      "Manuel Mager",
      "Arturo Oncevay",
      "Vishrav Chaudhary",
      "Luis Chiruzzo",
      "Angela Fan",
      "John Ortega",
      "Ricardo Ramos",
      "Annette Rios",
      "Ivan Meza-Ruiz",
      "Gustavo A. Gim\u00e9nez-Lugo",
      "Elisabeth Mager",
      "Graham Neubig",
      "Alexis Palmer",
      "Rolando Coto-Solano",
      "Ngoc Thang Vu",
      "Katharina Kann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08726"
  },
  {
    "id": "arXiv:2104.09993",
    "title": "Fine-grained Anomaly Detection via Multi-task Self-Supervision",
    "abstract": "Fine-grained Anomaly Detection via Multi-task Self-Supervision",
    "descriptor": "",
    "authors": [
      "Loic Jezequel",
      "Ngoc-Son Vu",
      "Jean Beaudet",
      "Aymeric Histace"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.09993"
  },
  {
    "id": "arXiv:2104.11324",
    "title": "Isolating Functions at the Hardware Limit with Virtines",
    "abstract": "Comments: In Proceedings of the 17th European Conference on Computer Systems (EuroSys '22), April 5-8, 2022, Rennes, France",
    "descriptor": "\nComments: In Proceedings of the 17th European Conference on Computer Systems (EuroSys '22), April 5-8, 2022, Rennes, France\n",
    "authors": [
      "Nicholas C. Wanninger",
      "Joshua J. Bowden",
      "Kirtankumar Shetty",
      "Ayush Garg",
      "Kyle C. Hale"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2104.11324"
  },
  {
    "id": "arXiv:2104.12837",
    "title": "Unsupervised Instance Selection with Low-Label, Supervised Learning for  Outlier Detection",
    "abstract": "Comments: 16 pages, 4 figures",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Trent J. Bradberry",
      "Christopher H. Hase",
      "LeAnna Kent",
      "Joel A. G\u00f3ngora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.12837"
  },
  {
    "id": "arXiv:2104.14856",
    "title": "Decidability of Two Truly Concurrent Equivalences for Finite Bounded  Petri Nets",
    "abstract": "Decidability of Two Truly Concurrent Equivalences for Finite Bounded  Petri Nets",
    "descriptor": "",
    "authors": [
      "Arnaldo Cesco",
      "Roberto Gorrieri"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.14856"
  },
  {
    "id": "arXiv:2105.03363",
    "title": "Model-based Multi-agent Policy Optimization with Adaptive Opponent-wise  Rollouts",
    "abstract": "Comments: Paper accepted at IJCAI 2021",
    "descriptor": "\nComments: Paper accepted at IJCAI 2021\n",
    "authors": [
      "Weinan Zhang",
      "Xihuai Wang",
      "Jian Shen",
      "Ming Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.03363"
  },
  {
    "id": "arXiv:2105.06679",
    "title": "Dynamic Multi-Branch Layers for On-Device Neural Machine Translation",
    "abstract": "Comments: Source code is available at this https URL",
    "descriptor": "\nComments: Source code is available at this https URL\n",
    "authors": [
      "Zhixing Tan",
      "Zeyuan Yang",
      "Meng Zhang",
      "Qun Liu",
      "Maosong Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.06679"
  },
  {
    "id": "arXiv:2105.07122",
    "title": "Premise-based Multimodal Reasoning: Conditional Inference on Joint  Textual and Visual Clues",
    "abstract": "Comments: ACL 2022 Main conference (Long Paper)",
    "descriptor": "\nComments: ACL 2022 Main conference (Long Paper)\n",
    "authors": [
      "Qingxiu Dong",
      "Ziwei Qin",
      "Heming Xia",
      "Tian Feng",
      "Shoujie Tong",
      "Haoran Meng",
      "Lin Xu",
      "Weidong Zhan",
      "Sujian Li",
      "Zhongyu Wei",
      "Tianyu Liu",
      "Zuifang Sui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.07122"
  },
  {
    "id": "arXiv:2106.02695",
    "title": "Meta-Learning with Fewer Tasks through Task Interpolation",
    "abstract": "Comments: Accepted by ICLR 2022 (Oral)",
    "descriptor": "\nComments: Accepted by ICLR 2022 (Oral)\n",
    "authors": [
      "Huaxiu Yao",
      "Linjun Zhang",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02695"
  },
  {
    "id": "arXiv:2106.02773",
    "title": "GLSD: The Global Large-Scale Ship Database and Baseline Evaluations",
    "abstract": "Comments: 11 pages, 7 figures",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Zhenfeng Shao",
      "Jiaming Wang",
      "Lianbing Deng",
      "Xiao Huang",
      "Tao Lu",
      "Fang Luo",
      "Ruiqian Zhang",
      "Xianwei Lv",
      "Chaoya Dang",
      "Qing Ding",
      "Zhiqiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02773"
  },
  {
    "id": "arXiv:2106.02885",
    "title": "Category Contrast for Unsupervised Domain Adaptation in Visual Tasks",
    "abstract": "Comments: CVPR2022 version",
    "descriptor": "\nComments: CVPR2022 version\n",
    "authors": [
      "Jiaxing Huang",
      "Dayan Guan",
      "Aoran Xiao",
      "Shijian Lu",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02885"
  },
  {
    "id": "arXiv:2106.06304",
    "title": "Automated Configuration of Genetic Algorithms by Tuning for Anytime  Performance",
    "abstract": "Automated Configuration of Genetic Algorithms by Tuning for Anytime  Performance",
    "descriptor": "",
    "authors": [
      "Furong Ye",
      "Carola Doerr",
      "Hao Wang",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.06304"
  },
  {
    "id": "arXiv:2106.07138",
    "title": "Self-Supervised Metric Learning in Multi-View Data: A Downstream Task  Perspective",
    "abstract": "Self-Supervised Metric Learning in Multi-View Data: A Downstream Task  Perspective",
    "descriptor": "",
    "authors": [
      "Shulei Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.07138"
  },
  {
    "id": "arXiv:2106.07904",
    "title": "Probabilistic Margins for Instance Reweighting in Adversarial Training",
    "abstract": "Comments: 17 pages, 4 figures",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "Qizhou Wang",
      "Feng Liu",
      "Bo Han",
      "Tongliang Liu",
      "Chen Gong",
      "Gang Niu",
      "Mingyuan Zhou",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07904"
  },
  {
    "id": "arXiv:2106.09369",
    "title": "Wavelet-Packets for Deepfake Image Analysis and Detection",
    "abstract": "Comments: Source code is available at this https URL and this https URL",
    "descriptor": "\nComments: Source code is available at this https URL and this https URL\n",
    "authors": [
      "Moritz Wolter",
      "Felix Blanke",
      "Raoul Heese",
      "Jochen Garcke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09369"
  },
  {
    "id": "arXiv:2106.09686",
    "title": "How Low Can We Go: Trading Memory for Error in Low-Precision Training",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Chengrun Yang",
      "Ziyang Wu",
      "Jerry Chee",
      "Christopher De Sa",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09686"
  },
  {
    "id": "arXiv:2106.10199",
    "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based  Masked Language-models",
    "abstract": "Comments: Accepted at ACL 2022 main conference",
    "descriptor": "\nComments: Accepted at ACL 2022 main conference\n",
    "authors": [
      "Elad Ben Zaken",
      "Shauli Ravfogel",
      "Yoav Goldberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10199"
  },
  {
    "id": "arXiv:2106.10601",
    "title": "ReGO: Reference-Guided Outpainting for Scenery Image",
    "abstract": "Comments: Image outpainting, 13 pages",
    "descriptor": "\nComments: Image outpainting, 13 pages\n",
    "authors": [
      "Yaxiong Wang",
      "Yunchao Wei",
      "Xueming Qian",
      "Li Zhu",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10601"
  },
  {
    "id": "arXiv:2106.12034",
    "title": "Pure Exploration in Kernel and Neural Bandits",
    "abstract": "Pure Exploration in Kernel and Neural Bandits",
    "descriptor": "",
    "authors": [
      "Yinglun Zhu",
      "Dongruo Zhou",
      "Ruoxi Jiang",
      "Quanquan Gu",
      "Rebecca Willett",
      "Robert Nowak"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12034"
  },
  {
    "id": "arXiv:2106.15524",
    "title": "Fully Dynamic Four-Vertex Subgraph Counting",
    "abstract": "Comments: A short version is to appear at SAND'22",
    "descriptor": "\nComments: A short version is to appear at SAND'22\n",
    "authors": [
      "Kathrin Hanauer",
      "Monika Henzinger",
      "Qi Cheng Hua"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.15524"
  },
  {
    "id": "arXiv:2107.00204",
    "title": "Markov Decision Process modeled with Bandits for Sequential Decision  Making in Linear-flow",
    "abstract": "Comments: Accepted by 2021 KDD Multi-Armed Bandits and Reinforcement Learning Workshop: this https URL",
    "descriptor": "\nComments: Accepted by 2021 KDD Multi-Armed Bandits and Reinforcement Learning Workshop: this https URL\n",
    "authors": [
      "Wenjun Zeng",
      "Yi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00204"
  },
  {
    "id": "arXiv:2107.00520",
    "title": "Out-of-distribution Generalization in the Presence of Nuisance-Induced  Spurious Correlations",
    "abstract": "Out-of-distribution Generalization in the Presence of Nuisance-Induced  Spurious Correlations",
    "descriptor": "",
    "authors": [
      "Aahlad Puli",
      "Lily H. Zhang",
      "Eric K. Oermann",
      "Rajesh Ranganath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00520"
  },
  {
    "id": "arXiv:2107.01691",
    "title": "Bag of Instances Aggregation Boosts Self-supervised Distillation",
    "abstract": "Comments: Published at ICLR 2022",
    "descriptor": "\nComments: Published at ICLR 2022\n",
    "authors": [
      "Haohang Xu",
      "Jiemin Fang",
      "Xiaopeng Zhang",
      "Lingxi Xie",
      "Xinggang Wang",
      "Wenrui Dai",
      "Hongkai Xiong",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01691"
  },
  {
    "id": "arXiv:2107.03158",
    "title": "A Survey on Data Augmentation for Text Classification",
    "abstract": "Comments: 42 pages, 6 figures, 8 tables",
    "descriptor": "\nComments: 42 pages, 6 figures, 8 tables\n",
    "authors": [
      "Markus Bayer",
      "Marc-Andr\u00e9 Kaufhold",
      "Christian Reuter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.03158"
  },
  {
    "id": "arXiv:2107.03250",
    "title": "Understanding Intrinsic Robustness Using Label Uncertainty",
    "abstract": "Comments: ICLR 2022; 23 pages, 8 figures, 1 table",
    "descriptor": "\nComments: ICLR 2022; 23 pages, 8 figures, 1 table\n",
    "authors": [
      "Xiao Zhang",
      "David Evans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.03250"
  },
  {
    "id": "arXiv:2107.03282",
    "title": "Gross polluters and vehicles' emissions reduction",
    "abstract": "Comments: Version to be published in Nature Sustainability. Minor changes due to the last round of reviews",
    "descriptor": "\nComments: Version to be published in Nature Sustainability. Minor changes due to the last round of reviews\n",
    "authors": [
      "Matteo B\u00f6hm",
      "Mirco Nanni",
      "Luca Pappalardo"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2107.03282"
  },
  {
    "id": "arXiv:2107.05446",
    "title": "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature  Restoration",
    "abstract": "Comments: ICLR 2022 (Spotlight)",
    "descriptor": "\nComments: ICLR 2022 (Spotlight)\n",
    "authors": [
      "Cian Eastwood",
      "Ian Mason",
      "Christopher K. I. Williams",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05446"
  },
  {
    "id": "arXiv:2107.08225",
    "title": "On Constraints in First-Order Optimization: A View from Non-Smooth  Dynamical Systems",
    "abstract": "Comments: 46 pages, 11 figures",
    "descriptor": "\nComments: 46 pages, 11 figures\n",
    "authors": [
      "Michael Muehlebach",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.08225"
  },
  {
    "id": "arXiv:2107.08323",
    "title": "Agent-Environment Network for Temporal Action Proposal Generation",
    "abstract": "Comments: Accepted in ICASSP 2021",
    "descriptor": "\nComments: Accepted in ICASSP 2021\n",
    "authors": [
      "Viet-Khoa Vo-Ho",
      "Ngan Le",
      "Kashu Yamazaki",
      "Akihiro Sugimoto",
      "Minh-Triet Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.08323"
  },
  {
    "id": "arXiv:2107.08391",
    "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision",
    "abstract": "Comments: Accepted by ICLR2022",
    "descriptor": "\nComments: Accepted by ICLR2022\n",
    "authors": [
      "Dongze Lian",
      "Zehao Yu",
      "Xing Sun",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.08391"
  },
  {
    "id": "arXiv:2107.10314",
    "title": "Small-Text: Active Learning for Text Classification in Python",
    "abstract": "Comments: Fix title case",
    "descriptor": "\nComments: Fix title case\n",
    "authors": [
      "Christopher Schr\u00f6der",
      "Lydia M\u00fcller",
      "Andreas Niekler",
      "Martin Potthast"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.10314"
  },
  {
    "id": "arXiv:2108.04585",
    "title": "Recurrent Neural Network-based Internal Model Control design for stable  nonlinear systems",
    "abstract": "Comments: Copyright 2022. This manuscript version is made available under the CC-BY-NC-ND 4.0 license. This manuscript has been published at Elsevier European Journal of Control. Published article available at DOI 10.1016/j.ejcon.2022.100632",
    "descriptor": "\nComments: Copyright 2022. This manuscript version is made available under the CC-BY-NC-ND 4.0 license. This manuscript has been published at Elsevier European Journal of Control. Published article available at DOI 10.1016/j.ejcon.2022.100632\n",
    "authors": [
      "Fabio Bonassi",
      "Riccardo Scattolini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.04585"
  },
  {
    "id": "arXiv:2108.04879",
    "title": "Excited state, non-adiabatic dynamics of large photoswitchable molecules  using a chemically transferable machine learning potential",
    "abstract": "Excited state, non-adiabatic dynamics of large photoswitchable molecules  using a chemically transferable machine learning potential",
    "descriptor": "",
    "authors": [
      "Simon Axelrod",
      "Eugene Shakhnovich",
      "Rafael G\u00f3mez-Bombarelli"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04879"
  },
  {
    "id": "arXiv:2108.10904",
    "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision",
    "abstract": "Comments: Published at ICLR 2022",
    "descriptor": "\nComments: Published at ICLR 2022\n",
    "authors": [
      "Zirui Wang",
      "Jiahui Yu",
      "Adams Wei Yu",
      "Zihang Dai",
      "Yulia Tsvetkov",
      "Yuan Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.10904"
  },
  {
    "id": "arXiv:2109.00402",
    "title": "Chronic Pain and Language: A Topic Modelling Approach to Personal Pain  Descriptions",
    "abstract": "Comments: 9 pages, 5 figures, 6 tables",
    "descriptor": "\nComments: 9 pages, 5 figures, 6 tables\n",
    "authors": [
      "Diogo A. P. Nunes",
      "Joana Ferreira Gomes",
      "Fani Neto",
      "David Martins de Matos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2109.00402"
  },
  {
    "id": "arXiv:2109.05131",
    "title": "Near Instance Optimal Model Selection for Pure Exploration Linear  Bandits",
    "abstract": "Near Instance Optimal Model Selection for Pure Exploration Linear  Bandits",
    "descriptor": "",
    "authors": [
      "Yinglun Zhu",
      "Julian Katz-Samuels",
      "Robert Nowak"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05131"
  },
  {
    "id": "arXiv:2109.06016",
    "title": "On the Optimal Memory-Load Tradeoff of Coded Caching for Location-Based  Content",
    "abstract": "Comments: Accepted for publication in the IEEE Transactions on Communications",
    "descriptor": "\nComments: Accepted for publication in the IEEE Transactions on Communications\n",
    "authors": [
      "Kai Wan",
      "Minquan Cheng",
      "Mari Kobayashi",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06016"
  },
  {
    "id": "arXiv:2109.06082",
    "title": "xGQA: Cross-Lingual Visual Question Answering",
    "abstract": "Comments: Findings of ACL 2022",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Jonas Pfeiffer",
      "Gregor Geigle",
      "Aishwarya Kamath",
      "Jan-Martin O. Steitz",
      "Stefan Roth",
      "Ivan Vuli\u0107",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06082"
  },
  {
    "id": "arXiv:2109.06590",
    "title": "High-Fidelity GAN Inversion for Image Attribute Editing",
    "abstract": "Comments: CVPR 2022; Project Page is at this https URL",
    "descriptor": "\nComments: CVPR 2022; Project Page is at this https URL\n",
    "authors": [
      "Tengfei Wang",
      "Yong Zhang",
      "Yanbo Fan",
      "Jue Wang",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06590"
  },
  {
    "id": "arXiv:2109.07133",
    "title": "Combining Context Awareness and Planning to Learn Behavior Trees from  Demonstration",
    "abstract": "Comments: Submitted to RO-MAN 2022",
    "descriptor": "\nComments: Submitted to RO-MAN 2022\n",
    "authors": [
      "Oscar Gustavsson",
      "Matteo Iovino",
      "Jonathan Styrud",
      "Christian Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07133"
  },
  {
    "id": "arXiv:2109.07775",
    "title": "Fast-Replanning Motion Control for Non-Holonomic Vehicles with Aborting  A*",
    "abstract": "Comments: Submitted to IROS 22",
    "descriptor": "\nComments: Submitted to IROS 22\n",
    "authors": [
      "Marcell Missura",
      "Arindam Roychoudhury",
      "Maren Bennewitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07775"
  },
  {
    "id": "arXiv:2109.11661",
    "title": "Deep Reinforcement Learning-Based Long-Range Autonomous Valet Parking  for Smart Cities",
    "abstract": "Comments: 6 Figures, 1 Table",
    "descriptor": "\nComments: 6 Figures, 1 Table\n",
    "authors": [
      "Muhammad Khalid",
      "Liang Wang",
      "Kezhi Wang",
      "Cunhua Pan",
      "Nauman Aslam",
      "Yue Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.11661"
  },
  {
    "id": "arXiv:2109.12405",
    "title": "CoMeT: An Integrated Interval Thermal Simulation Toolchain for 2D, 2.5D,  and 3D Processor-Memory Systems",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Lokesh Siddhu",
      "Rajesh Kedia",
      "Shailja Pandey",
      "Martin Rapp",
      "Anuj Pathania",
      "J\u00f6rg Henkel",
      "Preeti Ranjan Panda"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2109.12405"
  },
  {
    "id": "arXiv:2109.13407",
    "title": "CRANE: a 10 Degree-of-Freedom, Tele-surgical System for Dexterous  Manipulation within Imaging Bores",
    "abstract": "Comments: 6+2 pages, 8 figures, ICRA 2022",
    "descriptor": "\nComments: 6+2 pages, 8 figures, ICRA 2022\n",
    "authors": [
      "Dimitri A. Schreiber",
      "Zhaowei Yu",
      "Hanpeng Jiang",
      "Taylor Henderson",
      "Guosong Li",
      "Julie Yu",
      "Renjie Zhu",
      "Alexander M. Norbash",
      "Michael C. Yip"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.13407"
  },
  {
    "id": "arXiv:2110.02337",
    "title": "A Reactive Power Market for the Future Grid",
    "abstract": "Comments: 21 pages, 7 figures, 2 tables",
    "descriptor": "\nComments: 21 pages, 7 figures, 2 tables\n",
    "authors": [
      "Adam Potter",
      "Rabab Haider",
      "Giulio Ferro",
      "Michela Robba",
      "Anuradha M. Annaswamy"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "General Economics (econ.GN)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02337"
  },
  {
    "id": "arXiv:2110.02910",
    "title": "Equivariant Subgraph Aggregation Networks",
    "abstract": "Comments: Published at ICLR 2022, Spotlight. 46 pages",
    "descriptor": "\nComments: Published at ICLR 2022, Spotlight. 46 pages\n",
    "authors": [
      "Beatrice Bevilacqua",
      "Fabrizio Frasca",
      "Derek Lim",
      "Balasubramaniam Srinivasan",
      "Chen Cai",
      "Gopinath Balamurugan",
      "Michael M. Bronstein",
      "Haggai Maron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02910"
  },
  {
    "id": "arXiv:2110.04504",
    "title": "An Isotropy Analysis in the Multilingual BERT Embedding Space",
    "abstract": "Comments: To appear in the findings of ACL 2022",
    "descriptor": "\nComments: To appear in the findings of ACL 2022\n",
    "authors": [
      "Sara Rajaee",
      "Mohammad Taher Pilehvar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04504"
  },
  {
    "id": "arXiv:2110.04962",
    "title": "Uplink Performance of Cell-Free Massive MIMO with Multi-Antenna Users  Over Jointly-Correlated Rayleigh Fading Channels",
    "abstract": "Comments: 32 pages, 11 figures, to appear in IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: 32 pages, 11 figures, to appear in IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Zhe Wang",
      "Jiayi Zhang",
      "Bo Ai",
      "Chau Yuen",
      "M\u00e9rouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04962"
  },
  {
    "id": "arXiv:2110.06178",
    "title": "TAda! Temporally-Adaptive Convolutions for Video Understanding",
    "abstract": "Comments: Accepted to ICLR 2022. Project page: this https URL",
    "descriptor": "\nComments: Accepted to ICLR 2022. Project page: this https URL\n",
    "authors": [
      "Ziyuan Huang",
      "Shiwei Zhang",
      "Liang Pan",
      "Zhiwu Qing",
      "Mingqian Tang",
      "Ziwei Liu",
      "Marcelo H. Ang Jr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06178"
  },
  {
    "id": "arXiv:2110.06306",
    "title": "Fine-grained style control in Transformer-based Text-to-speech Synthesis",
    "abstract": "Comments: Accepted in ICASSP 2022",
    "descriptor": "\nComments: Accepted in ICASSP 2022\n",
    "authors": [
      "Li-Wei Chen",
      "Alexander Rudnicky"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.06306"
  },
  {
    "id": "arXiv:2110.06609",
    "title": "MSP: Multi-Stage Prompting for Making Pre-trained Language Models Better  Translators",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Zhixing Tan",
      "Xiangwen Zhang",
      "Shuo Wang",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06609"
  },
  {
    "id": "arXiv:2110.06836",
    "title": "CasSeqGCN: Combining Network Structure and Temporal Sequence to Predict  Information Cascades",
    "abstract": "CasSeqGCN: Combining Network Structure and Temporal Sequence to Predict  Information Cascades",
    "descriptor": "",
    "authors": [
      "Yansong Wang",
      "Xiaomeng Wang",
      "Rados\u0142aw Michalski",
      "Yijun Ran",
      "Tao Jia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.06836"
  },
  {
    "id": "arXiv:2110.07342",
    "title": "FILM: Following Instructions in Language with Modular Methods",
    "abstract": "Comments: Published as a conference paper at International Conference on Learning Representations (ICLR) 2022",
    "descriptor": "\nComments: Published as a conference paper at International Conference on Learning Representations (ICLR) 2022\n",
    "authors": [
      "So Yeon Min",
      "Devendra Singh Chaplot",
      "Pradeep Ravikumar",
      "Yonatan Bisk",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07342"
  },
  {
    "id": "arXiv:2110.07904",
    "title": "SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer",
    "abstract": "Comments: Accepted as a main conference paper at ACL 2022, 21 pages, 8 figures, 7 tables",
    "descriptor": "\nComments: Accepted as a main conference paper at ACL 2022, 21 pages, 8 figures, 7 tables\n",
    "authors": [
      "Tu Vu",
      "Brian Lester",
      "Noah Constant",
      "Rami Al-Rfou",
      "Daniel Cer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.07904"
  },
  {
    "id": "arXiv:2110.08059",
    "title": "FlexConv: Continuous Kernel Convolutions with Differentiable Kernel  Sizes",
    "abstract": "Comments: First two authors contributed equally to this work",
    "descriptor": "\nComments: First two authors contributed equally to this work\n",
    "authors": [
      "David W. Romero",
      "Robert-Jan Bruintjes",
      "Jakub M. Tomczak",
      "Erik J. Bekkers",
      "Mark Hoogendoorn",
      "Jan C. van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08059"
  },
  {
    "id": "arXiv:2110.08207",
    "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization",
    "abstract": "Comments: ICLR 2022 Spotlight (with extended discussion)",
    "descriptor": "\nComments: ICLR 2022 Spotlight (with extended discussion)\n",
    "authors": [
      "Victor Sanh",
      "Albert Webson",
      "Colin Raffel",
      "Stephen H. Bach",
      "Lintang Sutawika",
      "Zaid Alyafeai",
      "Antoine Chaffin",
      "Arnaud Stiegler",
      "Teven Le Scao",
      "Arun Raja",
      "Manan Dey",
      "M Saiful Bari",
      "Canwen Xu",
      "Urmish Thakker",
      "Shanya Sharma Sharma",
      "Eliza Szczechla",
      "Taewoon Kim",
      "Gunjan Chhablani",
      "Nihal Nayak",
      "Debajyoti Datta",
      "Jonathan Chang",
      "Mike Tian-Jian Jiang",
      "Han Wang",
      "Matteo Manica",
      "Sheng Shen",
      "Zheng Xin Yong",
      "Harshit Pandey",
      "Rachel Bawden",
      "Thomas Wang",
      "Trishala Neeraj",
      "Jos Rozen",
      "Abheesht Sharma",
      "Andrea Santilli",
      "Thibault Fevry",
      "Jason Alan Fries",
      "Ryan Teehan",
      "Tali Bers",
      "Stella Biderman",
      "Leo Gao",
      "Thomas Wolf",
      "Alexander M. Rush"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08207"
  },
  {
    "id": "arXiv:2110.08387",
    "title": "Generated Knowledge Prompting for Commonsense Reasoning",
    "abstract": "Comments: ACL 2022 main conference",
    "descriptor": "\nComments: ACL 2022 main conference\n",
    "authors": [
      "Jiacheng Liu",
      "Alisa Liu",
      "Ximing Lu",
      "Sean Welleck",
      "Peter West",
      "Ronan Le Bras",
      "Yejin Choi",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08387"
  },
  {
    "id": "arXiv:2110.08450",
    "title": "Accelerating Training and Inference of Graph Neural Networks with Fast  Sampling and Pipelining",
    "abstract": "Comments: MLSys 2022. Code is available at this https URL",
    "descriptor": "\nComments: MLSys 2022. Code is available at this https URL\n",
    "authors": [
      "Tim Kaler",
      "Nickolas Stathas",
      "Anne Ouyang",
      "Alexandros-Stavros Iliopoulos",
      "Tao B. Schardl",
      "Charles E. Leiserson",
      "Jie Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.08450"
  },
  {
    "id": "arXiv:2110.08465",
    "title": "A Heterogeneous Graph Based Framework for Multimodal Neuroimaging Fusion  Learning",
    "abstract": "A Heterogeneous Graph Based Framework for Multimodal Neuroimaging Fusion  Learning",
    "descriptor": "",
    "authors": [
      "Gen Shi",
      "Yifan Zhu",
      "Wenjin Liu",
      "Xuesong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.08465"
  },
  {
    "id": "arXiv:2110.08486",
    "title": "Understanding Multimodal Procedural Knowledge by Sequencing Multimodal  Instructional Manuals",
    "abstract": "Comments: In Proceedings of the Conference of the 60th Annual Meeting of the Association for Computational Linguistics (ACL), 2022",
    "descriptor": "\nComments: In Proceedings of the Conference of the 60th Annual Meeting of the Association for Computational Linguistics (ACL), 2022\n",
    "authors": [
      "Te-Lin Wu",
      "Alex Spangher",
      "Pegah Alipoormolabashi",
      "Marjorie Freedman",
      "Ralph Weischedel",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08486"
  },
  {
    "id": "arXiv:2110.08499",
    "title": "PRIMERA: Pyramid-based Masked Sentence Pre-training for Multi-document  Summarization",
    "abstract": "Comments: 19 pages, accepted at the main conference of ACL 2022",
    "descriptor": "\nComments: 19 pages, accepted at the main conference of ACL 2022\n",
    "authors": [
      "Wen Xiao",
      "Iz Beltagy",
      "Giuseppe Carenini",
      "Arman Cohan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08499"
  },
  {
    "id": "arXiv:2110.08840",
    "title": "Online Facility Location with Predictions",
    "abstract": "Online Facility Location with Predictions",
    "descriptor": "",
    "authors": [
      "Shaofeng H.-C. Jiang",
      "Erzhi Liu",
      "You Lyu",
      "Zhihao Gavin Tang",
      "Yubo Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08840"
  },
  {
    "id": "arXiv:2110.08893",
    "title": "Temporally stable video segmentation without video annotations",
    "abstract": "Temporally stable video segmentation without video annotations",
    "descriptor": "",
    "authors": [
      "Aharon Azulay",
      "Tavi Halperin",
      "Orestis Vantzos",
      "Nadav Borenstein",
      "Ofir Bibi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08893"
  },
  {
    "id": "arXiv:2110.10863",
    "title": "Deep Generative Models in Engineering Design: A Review",
    "abstract": "Deep Generative Models in Engineering Design: A Review",
    "descriptor": "",
    "authors": [
      "Lyle Regenwetter",
      "Amin Heyrani Nobari",
      "Faez Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10863"
  },
  {
    "id": "arXiv:2110.12435",
    "title": "Contact Information Flow and Design of Compliance",
    "abstract": "Comments: On review, video: this https URL",
    "descriptor": "\nComments: On review, video: this https URL\n",
    "authors": [
      "Kevin Haninger",
      "Marcel Radke",
      "Richard Hartisch",
      "J\u00f6rg Kr\u00fcger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12435"
  },
  {
    "id": "arXiv:2110.14369",
    "title": "ConAM: Confidence Attention Module for Convolutional Neural Networks",
    "abstract": "Comments: There are certain problems with the experiments and conclusions of this paper",
    "descriptor": "\nComments: There are certain problems with the experiments and conclusions of this paper\n",
    "authors": [
      "Yu Xue",
      "Ziming Yuan",
      "Ferrante Neri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14369"
  },
  {
    "id": "arXiv:2110.14731",
    "title": "Vision Transformer for Classification of Breast Ultrasound Images",
    "abstract": "Comments: 5 pages, 2 figures, Under review in EMBC",
    "descriptor": "\nComments: 5 pages, 2 figures, Under review in EMBC\n",
    "authors": [
      "Behnaz Gheflati",
      "Hassan Rivaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14731"
  },
  {
    "id": "arXiv:2110.15237",
    "title": "Time-Delayed Data Informed Reinforcement Learning for Approximate  Optimal Tracking Control",
    "abstract": "Time-Delayed Data Informed Reinforcement Learning for Approximate  Optimal Tracking Control",
    "descriptor": "",
    "authors": [
      "Cong Li",
      "Yongchao Wang",
      "Fangzhou Liu",
      "Weichao Sun",
      "Martin Buss"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.15237"
  },
  {
    "id": "arXiv:2110.15277",
    "title": "A Novel Sleep Stage Classification Using CNN Generated by an Efficient  Neural Architecture Search with a New Data Processing Trick",
    "abstract": "Comments: There are certain problems with the experiments and conclusions of this paper",
    "descriptor": "\nComments: There are certain problems with the experiments and conclusions of this paper\n",
    "authors": [
      "Yu Xue",
      "Ziming Yuan",
      "Adam Slowik"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15277"
  },
  {
    "id": "arXiv:2111.00678",
    "title": "Latent Structure Mining with Contrastive Modality Fusion for Multimedia  Recommendation",
    "abstract": "Comments: 14 pages; in submission to IEEE TKDE",
    "descriptor": "\nComments: 14 pages; in submission to IEEE TKDE\n",
    "authors": [
      "Jinghao Zhang",
      "Yanqiao Zhu",
      "Qiang Liu",
      "Mengqi Zhang",
      "Shu Wu",
      "Liang Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.00678"
  },
  {
    "id": "arXiv:2111.02165",
    "title": "Realtime Trajectory Smoothing with Neural Nets",
    "abstract": "Comments: Accepted to ICRA2022",
    "descriptor": "\nComments: Accepted to ICRA2022\n",
    "authors": [
      "Shohei Fujii",
      "Quang-Cuong Pham"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.02165"
  },
  {
    "id": "arXiv:2111.04706",
    "title": "Bayesian Framework for Gradient Leakage",
    "abstract": "Bayesian Framework for Gradient Leakage",
    "descriptor": "",
    "authors": [
      "Mislav Balunovi\u0107",
      "Dimitar I. Dimitrov",
      "Robin Staab",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.04706"
  },
  {
    "id": "arXiv:2111.07683",
    "title": "Reachability analysis of neural networks using mixed monotonicity",
    "abstract": "Reachability analysis of neural networks using mixed monotonicity",
    "descriptor": "",
    "authors": [
      "Pierre-Jean Meyer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.07683"
  },
  {
    "id": "arXiv:2111.07865",
    "title": "Achievable Rates for Short-Reach Fiber-Optic Channels with Direct  Detection",
    "abstract": "Comments: Submitted to J. Lightw. Technol. on November 15, 2021; revised January 7, 2022; accepted January 22, 2022",
    "descriptor": "\nComments: Submitted to J. Lightw. Technol. on November 15, 2021; revised January 7, 2022; accepted January 22, 2022\n",
    "authors": [
      "Daniel Plabst",
      "Tobias Prinz",
      "Thomas Wiegart",
      "Talha Rahman",
      "Neboj\u0161a Stojanovi\u0107",
      "Stefano Calabr\u00f2",
      "Norbert Hanik",
      "Gerhard Kramer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.07865"
  },
  {
    "id": "arXiv:2111.09360",
    "title": "Personalized Federated Learning through Local Memorization",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Othmane Marfoq",
      "Giovanni Neglia",
      "Laetitia Kameni",
      "Richard Vidal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.09360"
  },
  {
    "id": "arXiv:2111.11867",
    "title": "Quantum Analogue of Entropy Based DDoS Detection",
    "abstract": "Comments: Revised version, 5 pages main text, 3 pages supplementary material",
    "descriptor": "\nComments: Revised version, 5 pages main text, 3 pages supplementary material\n",
    "authors": [
      "Del Rajan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.11867"
  },
  {
    "id": "arXiv:2111.12040",
    "title": "Generating Tree Structures for Hyperbolic Tessellations",
    "abstract": "Generating Tree Structures for Hyperbolic Tessellations",
    "descriptor": "",
    "authors": [
      "Dorota Celi\u0144ska-Kopczy\u0144ska",
      "Eryk Kopczy\u0144ski"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computational Geometry (cs.CG)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ],
    "url": "https://arxiv.org/abs/2111.12040"
  },
  {
    "id": "arXiv:2111.12852",
    "title": "RLIBM-PROG: Progressive Polynomial Approximations for Fast Correctly  Rounded Math Libraries",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Mridul Aanjaneya",
      "Jay P. Lim",
      "Santosh Nagarakatte"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2111.12852"
  },
  {
    "id": "arXiv:2111.13485",
    "title": "Learning Long-Term Reward Redistribution via Randomized Return  Decomposition",
    "abstract": "Comments: Tenth International Conference on Learning Representations (ICLR 2022 Spotlight)",
    "descriptor": "\nComments: Tenth International Conference on Learning Representations (ICLR 2022 Spotlight)\n",
    "authors": [
      "Zhizhou Ren",
      "Ruihan Guo",
      "Yuan Zhou",
      "Jian Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.13485"
  },
  {
    "id": "arXiv:2111.14173",
    "title": "CDGNet: Class Distribution Guided Network for Human Parsing",
    "abstract": "Comments: Accepted at CVPR 2022",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Kunliang Liu",
      "Ouk Choi",
      "Jianming Wang",
      "Wonjun Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14173"
  },
  {
    "id": "arXiv:2112.01206",
    "title": "Local Citation Recommendation with Hierarchical-Attention Text Encoder  and SciBERT-based Reranking",
    "abstract": "Comments: Accepted by ECIR 2022: this https URL",
    "descriptor": "\nComments: Accepted by ECIR 2022: this https URL\n",
    "authors": [
      "Nianlong Gu",
      "Yingqiang Gao",
      "Richard H.R. Hahnloser"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01206"
  },
  {
    "id": "arXiv:2112.01530",
    "title": "StyleMesh: Style Transfer for Indoor 3D Scene Reconstructions",
    "abstract": "Comments: Accepted to CVPR2022; project page: this https URL ; video: this https URL ; code: this https URL",
    "descriptor": "\nComments: Accepted to CVPR2022; project page: this https URL ; video: this https URL ; code: this https URL\n",
    "authors": [
      "Lukas H\u00f6llein",
      "Justin Johnson",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01530"
  },
  {
    "id": "arXiv:2112.01971",
    "title": "Dynamic fracture of a bicontinuously nanostructured copolymer: A  deep-learning analysis of big-data-generating experiment",
    "abstract": "Comments: Submitted for Review in Journal of the Mechanics and Physics of Solids (JMPS)",
    "descriptor": "\nComments: Submitted for Review in Journal of the Mechanics and Physics of Solids (JMPS)\n",
    "authors": [
      "Hanxun Jin",
      "Tong Jiao",
      "Rodney J. Clifton",
      "Kyung-Suk Kim"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01971"
  },
  {
    "id": "arXiv:2112.02380",
    "title": "On Complexity of Computing Bottleneck and Lexicographic Optimal Cycles  in a Homology Class",
    "abstract": "On Complexity of Computing Bottleneck and Lexicographic Optimal Cycles  in a Homology Class",
    "descriptor": "",
    "authors": [
      "Erin Wolf Chambers",
      "Salman Parsa",
      "Hannah Schreiber"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.02380"
  },
  {
    "id": "arXiv:2112.02612",
    "title": "Training Structured Neural Networks Through Manifold Identification and  Variance Reduction",
    "abstract": "Training Structured Neural Networks Through Manifold Identification and  Variance Reduction",
    "descriptor": "",
    "authors": [
      "Zih-Syuan Huang",
      "Ching-pei Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.02612"
  },
  {
    "id": "arXiv:2112.02618",
    "title": "LIGS: Learnable Intrinsic-Reward Generation Selection for Multi-Agent  Learning",
    "abstract": "LIGS: Learnable Intrinsic-Reward Generation Selection for Multi-Agent  Learning",
    "descriptor": "",
    "authors": [
      "David Henry Mguni",
      "Taher Jafferjee",
      "Jianhong Wang",
      "Oliver Slumbers",
      "Nicolas Perez-Nieves",
      "Feifei Tong",
      "Li Yang",
      "Jiangcheng Zhu",
      "Yaodong Yang",
      "Jun Wang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.02618"
  },
  {
    "id": "arXiv:2112.05329",
    "title": "FaceFormer: Speech-Driven 3D Facial Animation with Transformers",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Yingruo Fan",
      "Zhaojiang Lin",
      "Jun Saito",
      "Wenping Wang",
      "Taku Komura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.05329"
  },
  {
    "id": "arXiv:2112.09081",
    "title": "CrossLoc: Scalable Aerial Localization Assisted by Multimodal Synthetic  Data",
    "abstract": "Comments: CVPR 2022. Our code is available at this https URL",
    "descriptor": "\nComments: CVPR 2022. Our code is available at this https URL\n",
    "authors": [
      "Qi Yan",
      "Jianhao Zheng",
      "Simon Reding",
      "Shanci Li",
      "Iordan Doytchinov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.09081"
  },
  {
    "id": "arXiv:2112.09686",
    "title": "Efficient Visual Tracking with Exemplar Transformers",
    "abstract": "Comments: Main Paper: 8 pages, 5 figures, 5 tables Supplementary: 4 pages, 3 figures, 3 tables",
    "descriptor": "\nComments: Main Paper: 8 pages, 5 figures, 5 tables Supplementary: 4 pages, 3 figures, 3 tables\n",
    "authors": [
      "Philippe Blatter",
      "Menelaos Kanakis",
      "Martin Danelljan",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09686"
  },
  {
    "id": "arXiv:2112.11177",
    "title": "Generalizable Cross-modality Medical Image Segmentation via Style  Augmentation and Dual Normalization",
    "abstract": "Comments: accepted by CVPR 2022",
    "descriptor": "\nComments: accepted by CVPR 2022\n",
    "authors": [
      "Ziqi Zhou",
      "Lei Qi",
      "Xin Yang",
      "Dong Ni",
      "Yinghuan Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11177"
  },
  {
    "id": "arXiv:2112.12535",
    "title": "FourierMask: Instance Segmentation using Fourier Mapping in Implicit  Neural Networks",
    "abstract": "FourierMask: Instance Segmentation using Fourier Mapping in Implicit  Neural Networks",
    "descriptor": "",
    "authors": [
      "Hamd ul Moqeet Riaz",
      "Nuri Benbarka",
      "Timon Hoefer",
      "Andreas Zell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12535"
  },
  {
    "id": "arXiv:2112.12782",
    "title": "SeMask: Semantically Masked Transformers for Semantic Segmentation",
    "abstract": "Comments: Updated experiments with Mix-Transformer (MiT) on ADE20K and added an analysis section",
    "descriptor": "\nComments: Updated experiments with Mix-Transformer (MiT) on ADE20K and added an analysis section\n",
    "authors": [
      "Jitesh Jain",
      "Anukriti Singh",
      "Nikita Orlov",
      "Zilong Huang",
      "Jiachen Li",
      "Steven Walton",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12782"
  },
  {
    "id": "arXiv:2112.13485",
    "title": "An efficient mining scheme for high utility itemsets",
    "abstract": "Comments: Since teh R-Miner algorithm extracts patterns based on the minimum utility threshold, it is susceptible to missing out on extracting some patterns when the user defined threshold value is high. This problem occurs because the total utility of a single item cannot be used as a upper bound. The algorithm is under revision and shall be updated again, once it is appropriately corrected",
    "descriptor": "\nComments: Since teh R-Miner algorithm extracts patterns based on the minimum utility threshold, it is susceptible to missing out on extracting some patterns when the user defined threshold value is high. This problem occurs because the total utility of a single item cannot be used as a upper bound. The algorithm is under revision and shall be updated again, once it is appropriately corrected\n",
    "authors": [
      "Pushp",
      "Satish Chand"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.13485"
  },
  {
    "id": "arXiv:2201.03327",
    "title": "TiltedBERT: Resource Adjustable Version of BERT",
    "abstract": "TiltedBERT: Resource Adjustable Version of BERT",
    "descriptor": "",
    "authors": [
      "Sajjad Kachuee",
      "Mohammad Sharifkhani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.03327"
  },
  {
    "id": "arXiv:2201.04266",
    "title": "Safe Equilibrium",
    "abstract": "Safe Equilibrium",
    "descriptor": "",
    "authors": [
      "Sam Ganzfried"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2201.04266"
  },
  {
    "id": "arXiv:2201.04584",
    "title": "ECONet: Efficient Convolutional Online Likelihood Network for  Scribble-based Interactive Segmentation",
    "abstract": "Comments: Accepted at MIDL 2022",
    "descriptor": "\nComments: Accepted at MIDL 2022\n",
    "authors": [
      "Muhammad Asad",
      "Lucas Fidon",
      "Tom Vercauteren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.04584"
  },
  {
    "id": "arXiv:2201.04850",
    "title": "Bridging Video-text Retrieval with Multiple Choice Questions",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Yuying Ge",
      "Yixiao Ge",
      "Xihui Liu",
      "Dian Li",
      "Ying Shan",
      "Xiaohu Qie",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.04850"
  },
  {
    "id": "arXiv:2201.07323",
    "title": "A Multi-factor Multi-level and Interaction based (M2I) Authentication  Framework for Internet of Things (IoT) Applications",
    "abstract": "A Multi-factor Multi-level and Interaction based (M2I) Authentication  Framework for Internet of Things (IoT) Applications",
    "descriptor": "",
    "authors": [
      "Salem AlJanah",
      "Ning Zhang",
      "Siok Wah Tay"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.07323"
  },
  {
    "id": "arXiv:2201.08657",
    "title": "Enhancing Pseudo Label Quality for Semi-Supervised Domain-Generalized  Medical Image Segmentation",
    "abstract": "Comments: Accepted by AAAI 2022",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Huifeng Yao",
      "Xiaowei Hu",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08657"
  },
  {
    "id": "arXiv:2201.12769",
    "title": "MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale  Point Clouds",
    "abstract": "MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale  Point Clouds",
    "descriptor": "",
    "authors": [
      "Chuanyu Luo",
      "Xiaohan Li",
      "Nuo Cheng",
      "Han Li",
      "Shengguang Lei",
      "Pu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12769"
  },
  {
    "id": "arXiv:2202.00100",
    "title": "Calibration of P-values for calibration and for deviation of a  subpopulation from the full population",
    "abstract": "Comments: 21 pages, 8 figures",
    "descriptor": "\nComments: 21 pages, 8 figures\n",
    "authors": [
      "Mark Tygert"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.00100"
  },
  {
    "id": "arXiv:2202.02113",
    "title": "From Discrimination to Generation: Knowledge Graph Completion with  Generative Transformer",
    "abstract": "Comments: Accepted by WWW 2022 Poster",
    "descriptor": "\nComments: Accepted by WWW 2022 Poster\n",
    "authors": [
      "Xin Xie",
      "Ningyu Zhang",
      "Zhoubo Li",
      "Shumin Deng",
      "Hui Chen",
      "Feiyu Xiong",
      "Mosha Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02113"
  },
  {
    "id": "arXiv:2202.02887",
    "title": "Monte Carlo Methods for Estimating the Diagonal of a Real Symmetric  Matrix",
    "abstract": "Monte Carlo Methods for Estimating the Diagonal of a Real Symmetric  Matrix",
    "descriptor": "",
    "authors": [
      "Eric Hallman",
      "Ilse C.F. Ipsen",
      "Arvind Saibaba"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.02887"
  },
  {
    "id": "arXiv:2202.05146",
    "title": "EquiBind: Geometric Deep Learning for Drug Binding Structure Prediction",
    "abstract": "Comments: Under review. 18 pages, 15 figures",
    "descriptor": "\nComments: Under review. 18 pages, 15 figures\n",
    "authors": [
      "Hannes St\u00e4rk",
      "Octavian-Eugen Ganea",
      "Lagnajit Pattanaik",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05146"
  },
  {
    "id": "arXiv:2202.06541",
    "title": "Pathway: a protocol for algorithmic pricing of a DAO governance token",
    "abstract": "Pathway: a protocol for algorithmic pricing of a DAO governance token",
    "descriptor": "",
    "authors": [
      "Aleksei Pupyshev",
      "Ilya Sapranidi",
      "Shamil Khalilov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.06541"
  },
  {
    "id": "arXiv:2202.07191",
    "title": "Improving Human Sperm Head Morphology Classification with Unsupervised  Anatomical Feature Distillation",
    "abstract": "Comments: Accepted to ISBI 2022 proceedings",
    "descriptor": "\nComments: Accepted to ISBI 2022 proceedings\n",
    "authors": [
      "Yejia Zhang",
      "Jingjing Zhang",
      "Xiaomin Zha",
      "Yiru Zhou",
      "Yunxia Cao",
      "Danny Z. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07191"
  },
  {
    "id": "arXiv:2202.09339",
    "title": "A reliability measure for smart surveillance systems",
    "abstract": "Comments: 8 pages, 9 figures, minor edits",
    "descriptor": "\nComments: 8 pages, 9 figures, minor edits\n",
    "authors": [
      "Anj Simmons"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09339"
  },
  {
    "id": "arXiv:2202.09556",
    "title": "HDAM: Heuristic Difference Attention Module for Convolutional Neural  Networks",
    "abstract": "Comments: There are certain problems with the experiments and conclusions of this paper",
    "descriptor": "\nComments: There are certain problems with the experiments and conclusions of this paper\n",
    "authors": [
      "Yu Xue",
      "Ziming Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09556"
  },
  {
    "id": "arXiv:2202.10290",
    "title": "Speaker Adaptation Using Spectro-Temporal Deep Features for Dysarthric  and Elderly Speech Recognition",
    "abstract": "Comments: In submission to IEEE/ACM Transactions on Audio Speech and Language Processing",
    "descriptor": "\nComments: In submission to IEEE/ACM Transactions on Audio Speech and Language Processing\n",
    "authors": [
      "Mengzhe Geng",
      "Xurong Xie",
      "Zi Ye",
      "Tianzi Wang",
      "Guinan Li",
      "Shujie Hu",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.10290"
  },
  {
    "id": "arXiv:2202.10379",
    "title": "(Dis)assortative Partitions on Random Regular Graphs",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Freya Behrens",
      "Gabriel Arpino",
      "Yaroslav Kivva",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.10379"
  },
  {
    "id": "arXiv:2202.10418",
    "title": "Composite Anomaly Detection via Hierarchical Dynamic Search",
    "abstract": "Composite Anomaly Detection via Hierarchical Dynamic Search",
    "descriptor": "",
    "authors": [
      "Benjamin Wolff",
      "Tomer Gafni",
      "Guy Revach",
      "Nir Shlezinger",
      "Kobi Cohen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.10418"
  },
  {
    "id": "arXiv:2202.10726",
    "title": "The duo Fenchel-Young divergence",
    "abstract": "Comments: 21 pages, 7 figures",
    "descriptor": "\nComments: 21 pages, 7 figures\n",
    "authors": [
      "Frank Nielsen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.10726"
  },
  {
    "id": "arXiv:2202.11009",
    "title": "Computing Multiple Image Reconstructions with a Single Hypernetwork",
    "abstract": "Computing Multiple Image Reconstructions with a Single Hypernetwork",
    "descriptor": "",
    "authors": [
      "Alan Q. Wang",
      "Adrian V. Dalca",
      "Mert R. Sabuncu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11009"
  },
  {
    "id": "arXiv:2202.12499",
    "title": "PromDA: Prompt-based Data Augmentation for Low-Resource NLU Tasks",
    "abstract": "Comments: Accepted to ACL 2022 Main Conference, Camera-Ready Version",
    "descriptor": "\nComments: Accepted to ACL 2022 Main Conference, Camera-Ready Version\n",
    "authors": [
      "Yufei Wang",
      "Can Xu",
      "Qingfeng Sun",
      "Huang Hu",
      "Chongyang Tao",
      "Xiubo Geng",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12499"
  },
  {
    "id": "arXiv:2202.13663",
    "title": "Confidence Based Bidirectional Global Context Aware Training Framework  for Neural Machine Translation",
    "abstract": "Comments: Pre-print version; Accepted at ACL 2022 as a long paper of main conference",
    "descriptor": "\nComments: Pre-print version; Accepted at ACL 2022 as a long paper of main conference\n",
    "authors": [
      "Chulun Zhou",
      "Fandong Meng",
      "Jie Zhou",
      "Min Zhang",
      "Hongji Wang",
      "Jinsong Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.13663"
  },
  {
    "id": "arXiv:2202.13664",
    "title": "Neural Adaptive SCEne Tracing",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Rui Li",
      "Darius R\u00fcckert",
      "Yuanhao Wang",
      "Ramzi Idoughi",
      "Wolfgang Heidrich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.13664"
  },
  {
    "id": "arXiv:2203.00172",
    "title": "Enhancing Local Feature Learning for 3D Point Cloud Processing using  Unary-Pairwise Attention",
    "abstract": "Comments: BMVC 2021",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Haoyi Xiu",
      "Xin Liu",
      "Weimin Wang",
      "Kyoung-Sook Kim",
      "Takayuki Shinohara",
      "Qiong Chang",
      "Masashi Matsuoka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.00172"
  },
  {
    "id": "arXiv:2203.02433",
    "title": "The Machine Learning for Combinatorial Optimization Competition (ML4CO):  Results and Insights",
    "abstract": "Comments: Neurips 2021 competition. arXiv admin note: text overlap with arXiv:2112.12251 by other authors",
    "descriptor": "\nComments: Neurips 2021 competition. arXiv admin note: text overlap with arXiv:2112.12251 by other authors\n",
    "authors": [
      "Maxime Gasse",
      "Quentin Cappart",
      "Jonas Charfreitag",
      "Laurent Charlin",
      "Didier Ch\u00e9telat",
      "Antonia Chmiela",
      "Justin Dumouchelle",
      "Ambros Gleixner",
      "Aleksandr M. Kazachkov",
      "Elias Khalil",
      "Pawel Lichocki",
      "Andrea Lodi",
      "Miles Lubin",
      "Chris J. Maddison",
      "Christopher Morris",
      "Dimitri J. Papageorgiou",
      "Augustin Parjadis",
      "Sebastian Pokutta",
      "Antoine Prouvost",
      "Lara Scavuzzo",
      "Giulia Zarpellon",
      "Linxin Yang",
      "Sha Lai",
      "Akang Wang",
      "Xiaodong Luo",
      "Xiang Zhou",
      "Haohan Huang",
      "Shengcheng Shao",
      "Yuanming Zhu",
      "Dong Zhang",
      "Tao Quan",
      "Zixuan Cao",
      "Yang Xu",
      "Zhewei Huang",
      "Shuchang Zhou",
      "Chen Binbin",
      "He Minggui",
      "Hao Hao",
      "Zhang Zhiyu",
      "An Zhiwu",
      "Mao Kun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.02433"
  },
  {
    "id": "arXiv:2203.03622",
    "title": "Deep-ASPECTS: A Segmentation-Assisted Model for Stroke Severity  Measurement",
    "abstract": "Comments: We found a major mistake with ASPECTS definition in the paper. Therefore, we would like to withdraw the recent version of paper",
    "descriptor": "\nComments: We found a major mistake with ASPECTS definition in the paper. Therefore, we would like to withdraw the recent version of paper\n",
    "authors": [
      "Ujjwal Upadhyay",
      "Mukul Ranjan",
      "Satish Golla",
      "Swetha Tanamala",
      "Preetham Sreenivas",
      "Sasank Chilamkurthy",
      "Jeyaraj Pandian",
      "Jason Tarpley"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.03622"
  },
  {
    "id": "arXiv:2203.04036",
    "title": "StyleHEAT: One-Shot High-Resolution Editable Talking Face Generation via  Pre-trained StyleGAN",
    "abstract": "Comments: Project Page is at this http URL",
    "descriptor": "\nComments: Project Page is at this http URL\n",
    "authors": [
      "Fei Yin",
      "Yong Zhang",
      "Xiaodong Cun",
      "Mingdeng Cao",
      "Yanbo Fan",
      "Xuan Wang",
      "Qingyan Bai",
      "Baoyuan Wu",
      "Jue Wang",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04036"
  },
  {
    "id": "arXiv:2203.04593",
    "title": "Small Errors Imply Large Instabilities",
    "abstract": "Small Errors Imply Large Instabilities",
    "descriptor": "",
    "authors": [
      "Robert Schaback"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.04593"
  },
  {
    "id": "arXiv:2203.04737",
    "title": "P2M: A Processing-in-Pixel-in-Memory Paradigm for Resource-Constrained  TinyML Applications",
    "abstract": "Comments: 15 pages, 8 figures",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Gourav Datta",
      "Souvik Kundu",
      "Zihan Yin",
      "Ravi Teja Lakkireddy",
      "Joe Mathai",
      "Ajey Jacob",
      "Peter A. Beerel",
      "Akhilesh R. Jaiswal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04737"
  },
  {
    "id": "arXiv:2203.04771",
    "title": "Multiscale Transformer for Hyperspectral Image Classification",
    "abstract": "Comments: 8 pages, 26 figures, conference paper",
    "descriptor": "\nComments: 8 pages, 26 figures, conference paper\n",
    "authors": [
      "Sen Jia",
      "Yifan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04771"
  },
  {
    "id": "arXiv:2203.05117",
    "title": "Optimal Methods for Risk Averse Distributed Optimization",
    "abstract": "Optimal Methods for Risk Averse Distributed Optimization",
    "descriptor": "",
    "authors": [
      "Guanghui Lan",
      "Zhe Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05117"
  },
  {
    "id": "arXiv:2203.05294",
    "title": "Domain Generalisation for Object Detection",
    "abstract": "Domain Generalisation for Object Detection",
    "descriptor": "",
    "authors": [
      "Karthik Seemakurthy",
      "Charles Fox",
      "Erchan Aptoula",
      "Petra Bosilj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05294"
  },
  {
    "id": "arXiv:2203.05412",
    "title": "OneRel:Joint Entity and Relation Extraction with One Module in One Step",
    "abstract": "Comments: AAAI-2022 Accepted",
    "descriptor": "\nComments: AAAI-2022 Accepted\n",
    "authors": [
      "Yu-Ming Shang",
      "Heyan Huang",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05412"
  },
  {
    "id": "arXiv:2203.05709",
    "title": "Towards Bi-directional Skip Connections in Encoder-Decoder Architectures  and Beyond",
    "abstract": "Comments: Medical Image Analysis 2022",
    "descriptor": "\nComments: Medical Image Analysis 2022\n",
    "authors": [
      "Tiange Xiang",
      "Chaoyi Zhang",
      "Xinyi Wang",
      "Yang Song",
      "Dongnan Liu",
      "Heng Huang",
      "Weidong Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05709"
  },
  {
    "id": "arXiv:2203.05998",
    "title": "Adaptive POD-DEIM correction for Turing pattern approximation in  reaction-diffusion PDE systems",
    "abstract": "Adaptive POD-DEIM correction for Turing pattern approximation in  reaction-diffusion PDE systems",
    "descriptor": "",
    "authors": [
      "Alessandro Alla",
      "Angela Monti",
      "Ivonne Sgura"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.05998"
  },
  {
    "id": "arXiv:2203.06245",
    "title": "Predatory Medicine: Exploring and Measuring the Vulnerability of Medical  AI to Predatory Science",
    "abstract": "Comments: Conference on Health, Inference, and Learning (CHIL) 2022 - Invited non-archival presentation",
    "descriptor": "\nComments: Conference on Health, Inference, and Learning (CHIL) 2022 - Invited non-archival presentation\n",
    "authors": [
      "Shalini Saini",
      "Nitesh Saxena"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.06245"
  },
  {
    "id": "arXiv:2203.06250",
    "title": "Learning from humans: combining imitation and deep reinforcement  learning to accomplish human-level performance on a virtual foraging task",
    "abstract": "Comments: 24 pages, 15 figures",
    "descriptor": "\nComments: 24 pages, 15 figures\n",
    "authors": [
      "Vittorio Giammarino",
      "Matthew F Dunne",
      "Kylie N Moore",
      "Michael E Hasselmo",
      "Chantal E Stern",
      "Ioannis Ch. Paschalidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.06250"
  },
  {
    "id": "arXiv:2203.06578",
    "title": "Symbolic Learning to Optimize: Towards Interpretability and Scalability",
    "abstract": "Comments: Published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Wenqing Zheng",
      "Tianlong Chen",
      "Ting-Kuei Hu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.06578"
  },
  {
    "id": "arXiv:2203.06647",
    "title": "QUAD: A Quality Aware Multi-Unit Double Auction Framework for IoT-Based  Mobile Crowdsensing in Strategic Setting",
    "abstract": "Comments: 36 pages, 8 figures, 2 tables",
    "descriptor": "\nComments: 36 pages, 8 figures, 2 tables\n",
    "authors": [
      "Vikash Kumar Singh",
      "Anjani Samhitha Jasti",
      "Sunil Kumar Singh",
      "Sanket Mishra"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.06647"
  },
  {
    "id": "arXiv:2203.06696",
    "title": "Training Protocol Matters: Towards Accurate Scene Text Recognition via  Training Protocol Searching",
    "abstract": "Training Protocol Matters: Towards Accurate Scene Text Recognition via  Training Protocol Searching",
    "descriptor": "",
    "authors": [
      "Xiaojie Chu",
      "Yongtao Wang",
      "Chunhua Shen",
      "Jingdong Chen",
      "Wei Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06696"
  },
  {
    "id": "arXiv:2203.06717",
    "title": "Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Xiaohan Ding",
      "Xiangyu Zhang",
      "Yizhuang Zhou",
      "Jungong Han",
      "Guiguang Ding",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06717"
  },
  {
    "id": "arXiv:2203.06850",
    "title": "Efficient Language Modeling with Sparse all-MLP",
    "abstract": "Efficient Language Modeling with Sparse all-MLP",
    "descriptor": "",
    "authors": [
      "Ping Yu",
      "Mikel Artetxe",
      "Myle Ott",
      "Sam Shleifer",
      "Hongyu Gong",
      "Ves Stoyanov",
      "Xian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.06850"
  },
  {
    "id": "arXiv:2203.06915",
    "title": "SimMatch: Semi-supervised Learning with Similarity Matching",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Mingkai Zheng",
      "Shan You",
      "Lang Huang",
      "Fei Wang",
      "Chen Qian",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06915"
  },
  {
    "id": "arXiv:2203.07026",
    "title": "Extracting associations and meanings of objects depicted in artworks  through bi-modal deep networks",
    "abstract": "Comments: Accepted at Computer Vision and Image Analysis of Art (CVAA) conference 2022",
    "descriptor": "\nComments: Accepted at Computer Vision and Image Analysis of Art (CVAA) conference 2022\n",
    "authors": [
      "Gregory Kell",
      "Ryan-Rhys Griffiths",
      "Anthony Bourached",
      "David G. Stork"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07026"
  },
  {
    "id": "arXiv:2203.07171",
    "title": "Orchestrated Value Mapping for Reinforcement Learning",
    "abstract": "Comments: Published at ICLR 2022",
    "descriptor": "\nComments: Published at ICLR 2022\n",
    "authors": [
      "Mehdi Fatemi",
      "Arash Tavakoli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07171"
  },
  {
    "id": "arXiv:2203.07264",
    "title": "Show Me More Details: Discovering Hierarchies of Procedures from  Semi-structured Web Data",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Shuyan Zhou",
      "Li Zhang",
      "Yue Yang",
      "Qing Lyu",
      "Pengcheng Yin",
      "Chris Callison-Burch",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07264"
  },
  {
    "id": "arXiv:2203.07519",
    "title": "Leveraging Visual Knowledge in Language Tasks: An Empirical Study on  Intermediate Pre-training for Cross-modal Knowledge Transfer",
    "abstract": "Comments: Accepted to ACL 2022, 13 pages, 4 figures",
    "descriptor": "\nComments: Accepted to ACL 2022, 13 pages, 4 figures\n",
    "authors": [
      "Woojeong Jin",
      "Dong-Ho Lee",
      "Chenguang Zhu",
      "Jay Pujara",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07519"
  },
  {
    "id": "arXiv:2203.07561",
    "title": "Toward the Detection of Polyglot Files",
    "abstract": "Toward the Detection of Polyglot Files",
    "descriptor": "",
    "authors": [
      "Luke Koch",
      "Sean Oesch",
      "Mary Adkisson",
      "Sam Erwin",
      "Brian Weber",
      "Amul Chaulagain"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07561"
  },
  {
    "id": "arXiv:2203.07858",
    "title": "A Survey of Non-Rigid 3D Registration",
    "abstract": "Comments: Accepted to Eurographics 2022 State-of-the-Art Reports",
    "descriptor": "\nComments: Accepted to Eurographics 2022 State-of-the-Art Reports\n",
    "authors": [
      "Bailin Deng",
      "Yuxin Yao",
      "Roberto M. Dyke",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07858"
  },
  {
    "id": "arXiv:2203.07918",
    "title": "GPV-Pose: Category-level Object Pose Estimation via Geometry-guided  Point-wise Voting",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Yan Di",
      "Ruida Zhang",
      "Zhiqiang Lou",
      "Fabian Manhardt",
      "Xiangyang Ji",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07918"
  },
  {
    "id": "arXiv:2203.07933",
    "title": "Threat Detection for General Social Engineering Attack Using Machine  Learning Techniques",
    "abstract": "Threat Detection for General Social Engineering Attack Using Machine  Learning Techniques",
    "descriptor": "",
    "authors": [
      "Zuoguang Wang",
      "Yimo Ren",
      "Hongsong Zhu",
      "Limin Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07933"
  },
  {
    "id": "arXiv:2203.07967",
    "title": "Intrinsic Neural Fields: Learning Functions on Manifolds",
    "abstract": "Intrinsic Neural Fields: Learning Functions on Manifolds",
    "descriptor": "",
    "authors": [
      "Lukas Koestler",
      "Daniel Grittner",
      "Michael Moeller",
      "Daniel Cremers",
      "Zorah L\u00e4hner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07967"
  },
  {
    "id": "arXiv:2203.07993",
    "title": "RotateQVS: Representing Temporal Information as Rotations in Quaternion  Vector Space for Temporal Knowledge Graph Completion",
    "abstract": "Comments: To appear in ACL 2022 main conference",
    "descriptor": "\nComments: To appear in ACL 2022 main conference\n",
    "authors": [
      "Kai Chen",
      "Ye Wang",
      "Yitong Li",
      "Aiping Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07993"
  },
  {
    "id": "arXiv:2203.08067",
    "title": "Practical data monitoring in the internet-services domain",
    "abstract": "Practical data monitoring in the internet-services domain",
    "descriptor": "",
    "authors": [
      "Nikhil Galagali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.08067"
  },
  {
    "id": "arXiv:2203.08069",
    "title": "DISTAL: The Distributed Tensor Algebra Compiler",
    "abstract": "DISTAL: The Distributed Tensor Algebra Compiler",
    "descriptor": "",
    "authors": [
      "Rohan Yadav",
      "Alex Aiken",
      "Fredrik Kjolstad"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.08069"
  },
  {
    "id": "arXiv:2203.08327",
    "title": "Motif Mining: Finding and Summarizing Remixed Image Content",
    "abstract": "Comments: 41 pages, 21 figures",
    "descriptor": "\nComments: 41 pages, 21 figures\n",
    "authors": [
      "William Theisen",
      "Daniel Gonzalez Cedre",
      "Zachariah Carmichael",
      "Daniel Moreira",
      "Tim Weninger",
      "Walter Scheirer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.08327"
  },
  {
    "id": "arXiv:2203.08394",
    "title": "Bridging the Data Gap between Training and Inference for Unsupervised  Neural Machine Translation",
    "abstract": "Comments: 13 pages, ACL 2022",
    "descriptor": "\nComments: 13 pages, ACL 2022\n",
    "authors": [
      "Zhiwei He",
      "Xing Wang",
      "Rui Wang",
      "Shuming Shi",
      "Zhaopeng Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08394"
  },
  {
    "id": "arXiv:2203.08448",
    "title": "Playing with blocks: Toward re-usable deep learning models for  side-channel profiled attacks",
    "abstract": "Playing with blocks: Toward re-usable deep learning models for  side-channel profiled attacks",
    "descriptor": "",
    "authors": [
      "Servio Paguada",
      "Lejla Batina",
      "Ileana Buhan",
      "Igor Armendariz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08448"
  },
  {
    "id": "arXiv:2203.08451",
    "title": "Estimate Analysis of a Fully Discrete Mixed Finite Element Scheme for  Stochastic Incompressible Navier-Stokes Equations with Multiplicative Noise",
    "abstract": "Estimate Analysis of a Fully Discrete Mixed Finite Element Scheme for  Stochastic Incompressible Navier-Stokes Equations with Multiplicative Noise",
    "descriptor": "",
    "authors": [
      "Hailong Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08451"
  },
  {
    "id": "arXiv:2203.08459",
    "title": "KinyaBERT: a Morphology-aware Kinyarwanda Language Model",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Antoine Nzeyimana",
      "Andre Niyongabo Rubungo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08459"
  },
  {
    "id": "arXiv:2203.08479",
    "title": "Data Efficient 3D Learner via Knowledge Transferred from 2D Model",
    "abstract": "Data Efficient 3D Learner via Knowledge Transferred from 2D Model",
    "descriptor": "",
    "authors": [
      "Ping-Chung Yu",
      "Cheng Sun",
      "Min Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08479"
  },
  {
    "id": "arXiv:2203.08528",
    "title": "Physical Inertial Poser (PIP): Physics-aware Real-time Human Motion  Tracking from Sparse Inertial Sensors",
    "abstract": "Comments: Accepted by CVPR 2022 with 3 strong accepts. Project page: this https URL",
    "descriptor": "\nComments: Accepted by CVPR 2022 with 3 strong accepts. Project page: this https URL\n",
    "authors": [
      "Xinyu Yi",
      "Yuxiao Zhou",
      "Marc Habermann",
      "Soshi Shimada",
      "Vladislav Golyanik",
      "Christian Theobalt",
      "Feng Xu"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.08528"
  },
  {
    "id": "arXiv:2203.08532",
    "title": "An introduction to POD-Greedy-Galerkin reduced basis method",
    "abstract": "An introduction to POD-Greedy-Galerkin reduced basis method",
    "descriptor": "",
    "authors": [
      "Pierfrancesco Siena",
      "Michele Girfoglio",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08532"
  },
  {
    "id": "arXiv:2203.08645",
    "title": "The Structured Abstain Problem and the Lov\u00e1sz Hinge",
    "abstract": "Comments: Fixed small typo in metadata",
    "descriptor": "\nComments: Fixed small typo in metadata\n",
    "authors": [
      "Jessie Finocchiaro",
      "Rafael Frongillo",
      "Enrique Nueve"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08645"
  },
  {
    "id": "arXiv:2203.08650",
    "title": "Complexity Reduction of Learned In-Loop Filtering in Video Coding",
    "abstract": "Comments: 5 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables\n",
    "authors": [
      "Woody Bayliss",
      "Luka Murn",
      "Ebroul Izquierdo",
      "Qianni Zhang",
      "Marta Mrak"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08650"
  },
  {
    "id": "arXiv:2203.08667",
    "title": "Graph Flow: Cross-layer Graph Flow Distillation for Dual-Efficient  Medical Image Segmentation",
    "abstract": "Graph Flow: Cross-layer Graph Flow Distillation for Dual-Efficient  Medical Image Segmentation",
    "descriptor": "",
    "authors": [
      "Wenxuan Zou",
      "Muyi Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08667"
  }
]
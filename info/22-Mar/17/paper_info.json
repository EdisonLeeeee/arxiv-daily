[
  {
    "id": "arXiv:2203.08145",
    "title": "Learning Transient Partial Differential Equations with Local Neural  Operators",
    "abstract": "In decades, enormous computational resources are poured into solving the\ntransient partial differential equations for multifarious physical fields. The\nlatest artificial intelligence has shown great potential in accelerating these\ncomputations, but its road to wide applications is hindered by the variety of\ncomputational domains and boundary conditions. Here, we overcome this obstacle\nby constructing a learning framework capable of purely representing the\ntransient PDEs with local neural operators (LNOs). This framework is\ndemonstrated in learning several transient PDEs, especially the Navier-Stokes\nequations, and successfully applied to solve problems with quite different\ndomains and boundaries, including the internal flow, the external flow, and\nremarkably, the flow across the cascade of airfoils. In these applications, our\nLNOs are faster than the conventional numerical solver by over 1000 times,\nwhich could be significant for scientific computations and engineering\nsimulations.",
    "descriptor": "\nComments: 31 pages, 14 figures\n",
    "authors": [
      "Ximeng Ye",
      "Hongyu Li",
      "Peng Jiang",
      "Tiejun Wang",
      "Guoliang Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.08145"
  },
  {
    "id": "arXiv:2203.08146",
    "title": "The Design and Implementation of a Broadly Applicable Algorithm for  Optimizing Intra-Day Surgical Scheduling",
    "abstract": "Surgical scheduling optimization is an active area of research. However, few\nalgorithms to optimize surgical scheduling are implemented and see sustained\nuse. An algorithm is more likely to be implemented, if it allows for surgeon\nautonomy, i.e., requires only limited scheduling centralization, and functions\nin the limited technical infrastructure of widely used electronic medical\nrecords (EMRs). In order for an algorithm to see sustained use, it must be\ncompatible with changes to hospital capacity, patient volumes, and scheduling\npractices. To meet these objectives, we developed the BEDS (better elective day\nof surgery) algorithm, a greedy heuristic for smoothing unit-specific surgical\nadmissions across days. We implemented BEDS in the EMR of a large pediatric\nacademic medical center.\nThe use of BEDS was associated with a reduction in the variability in the\nnumber of admissions. BEDS is freely available as a dashboard in Tableau, a\ncommercial software used by numerous hospitals. BEDS is readily implementable\nwith the limited tools available to most hospitals, does not require reductions\nto surgeon autonomy or centralized scheduling, and is compatible with changes\nto hospital capacity or patient volumes. We present a general algorithmic\nframework from which BEDS is derived based on a particular choice of objectives\nand constraints. We argue that algorithms generated by this framework retain\nmany of the desirable characteristics of BEDS while being compatible with a\nwide range of objectives and constraints.",
    "descriptor": "",
    "authors": [
      "Jin Xie",
      "Teng Zhang",
      "Jose Blanchet",
      "Peter Glynn",
      "Matthew Randolph",
      "David Scheinker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08146"
  },
  {
    "id": "arXiv:2203.08147",
    "title": "Energy-Latency Attacks via Sponge Poisoning",
    "abstract": "Sponge examples are test-time inputs carefully-optimized to increase energy\nconsumption and latency of neural networks when deployed on hardware\naccelerators. In this work, we demonstrate that sponge attacks can also be\nimplanted at training time, when model training is outsourced to a third party,\nvia an attack that we call sponge poisoning. This attack allows one to increase\nthe energy consumption and latency of machine-learning models indiscriminately\non each test-time input. We present a novel formalization for sponge poisoning,\novercoming the limitations related to the optimization of test-time sponge\nexamples, and show that this attack is possible even if the attacker only\ncontrols a few poisoning samples and model updates. Our extensive experimental\nanalysis, involving two deep learning architectures and three datasets, shows\nthat sponge poisoning can almost completely vanish the effect of such hardware\naccelerators. Finally, we analyze activations of the resulting sponge models,\nidentifying the module components that are more sensitive to this\nvulnerability.",
    "descriptor": "\nComments: Preprint;15 pages\n",
    "authors": [
      "Antonio Emanuele Cin\u00e0",
      "Ambra Demontis",
      "Battista Biggio",
      "Fabio Roli",
      "Marcello Pelillo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08147"
  },
  {
    "id": "arXiv:2203.08148",
    "title": "RES-HD: Resilient Intelligent Fault Diagnosis Against Adversarial  Attacks Using Hyper-Dimensional Computing",
    "abstract": "Industrial Internet of Things (I-IoT) enables fully automated production\nsystems by continuously monitoring devices and analyzing collected data.\nMachine learning methods are commonly utilized for data analytics in such\nsystems. Cyber-attacks are a grave threat to I-IoT as they can manipulate\nlegitimate inputs, corrupting ML predictions and causing disruptions in the\nproduction systems. Hyper-dimensional computing (HDC) is a brain-inspired\nmachine learning method that has been shown to be sufficiently accurate while\nbeing extremely robust, fast, and energy-efficient. In this work, we use HDC\nfor intelligent fault diagnosis against different adversarial attacks. Our\nblack-box adversarial attacks first train a substitute model and create\nperturbed test instances using this trained model. These examples are then\ntransferred to the target models. The change in the classification accuracy is\nmeasured as the difference before and after the attacks. This change measures\nthe resiliency of a learning method. Our experiments show that HDC leads to a\nmore resilient and lightweight learning solution than the state-of-the-art deep\nlearning methods. HDC has up to 67.5% higher resiliency compared to the\nstate-of-the-art methods while being up to 25.1% faster to train.",
    "descriptor": "",
    "authors": [
      "Onat Gungor",
      "Tajana Rosing",
      "Baris Aksanli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08148"
  },
  {
    "id": "arXiv:2203.08150",
    "title": "A physics and data co-driven surrogate modeling approach for temperature  field prediction on irregular geometric domain",
    "abstract": "In the whole aircraft structural optimization loop, thermal analysis plays a\nvery important role. But it faces a severe computational burden when directly\napplying traditional numerical analysis tools, especially when each\noptimization involves repetitive parameter modification and thermal analysis\nfollowed. Recently, with the fast development of deep learning, several\nConvolutional Neural Network (CNN) surrogate models have been introduced to\novercome this obstacle. However, for temperature field prediction on irregular\ngeometric domains (TFP-IGD), CNN can hardly be competent since most of them\nstem from processing for regular images. To alleviate this difficulty, we\npropose a novel physics and data co-driven surrogate modeling method. First,\nafter adapting the Bezier curve in geometric parameterization, a body-fitted\ncoordinate mapping is introduced to generate coordinate transforms between the\nirregular physical plane and regular computational plane. Second, a\nphysics-driven CNN surrogate with partial differential equation (PDE) residuals\nas a loss function is utilized for fast meshing (meshing surrogate); then, we\npresent a data-driven surrogate model based on the multi-level reduced-order\nmethod, aiming to learn solutions of temperature field in the above regular\ncomputational plane (thermal surrogate). Finally, combining the grid position\ninformation provided by the meshing surrogate with the scalar temperature field\ninformation provided by the thermal surrogate (combined model), we reach an\nend-to-end surrogate model from geometric parameters to temperature field\nprediction on an irregular geometric domain. Numerical results demonstrate that\nour method can significantly improve accuracy prediction on a smaller dataset\nwhile reducing the training time when compared with other CNN methods.",
    "descriptor": "",
    "authors": [
      "Kairui Bao",
      "Wen Yao",
      "Xiaoya Zhang",
      "Wei Peng",
      "Yu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08150"
  },
  {
    "id": "arXiv:2203.08174",
    "title": "Towards understanding deep learning with the natural clustering prior",
    "abstract": "The prior knowledge (a.k.a. priors) integrated into the design of a machine\nlearning system strongly influences its generalization abilities. In the\nspecific context of deep learning, some of these priors are poorly understood\nas they implicitly emerge from the successful heuristics and tentative\napproximations of biological brains involved in deep learning design. Through\nthe lens of supervised image classification problems, this thesis investigates\nthe implicit integration of a natural clustering prior composed of three\nstatements: (i) natural images exhibit a rich clustered structure, (ii) image\nclasses are composed of multiple clusters and (iii) each cluster contains\nexamples from a single class. The decomposition of classes into multiple\nclusters implies that supervised deep learning systems could benefit from\nunsupervised clustering to define appropriate decision boundaries. Hence, this\nthesis attempts to identify implicit clustering abilities, mechanisms and\nhyperparameters in deep learning systems and evaluate their relevance for\nexplaining the generalization abilities of these systems. We do so through an\nextensive empirical study of the training dynamics as well as the neuron- and\nlayer-level representations of deep neural networks. The resulting collection\nof experiments provides preliminary evidence for the relevance of the natural\nclustering prior for understanding deep learning.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Simon Carbonnelle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08174"
  },
  {
    "id": "arXiv:2203.08176",
    "title": "SemiPFL: Personalized Semi-Supervised Federated Learning Framework for  Edge Intelligence",
    "abstract": "Recent advances in wearable devices and Internet-of-Things (IoT) have led to\nmassive growth in sensor data generated in edge devices. Labeling such massive\ndata for classification tasks has proven to be challenging. In addition, data\ngenerated by different users bear various personal attributes and edge\nheterogeneity, rendering it impractical to develop a global model that adapts\nwell to all users. Concerns over data privacy and communication costs also\nprohibit centralized data accumulation and training. This paper proposes a\nnovel personalized semi-supervised federated learning (SemiPFL) framework to\nsupport edge users having no label or limited labeled datasets and a sizable\namount of unlabeled data that is insufficient to train a well-performing model.\nIn this work, edge users collaborate to train a hyper-network in the server,\ngenerating personalized autoencoders for each user. After receiving updates\nfrom edge users, the server produces a set of base models for each user, which\nthe users locally aggregate them using their own labeled dataset. We\ncomprehensively evaluate our proposed framework on various public datasets and\ndemonstrate that SemiPFL outperforms state-of-art federated learning frameworks\nunder the same assumptions. We also show that the solution performs well for\nusers without labeled datasets or having limited labeled datasets and\nincreasing performance for increased labeled data and number of users,\nsignifying the effectiveness of SemiPFL for handling edge heterogeneity and\nlimited annotation. By leveraging personalized semi-supervised learning,\nSemiPFL dramatically reduces the need for annotating data and preserving\nprivacy in a wide range of application scenarios, from wearable health to IoT.",
    "descriptor": "",
    "authors": [
      "Arvin Tashakori",
      "Wenwen Zhang",
      "Z. Jane Wang",
      "Peyman Servati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.08176"
  },
  {
    "id": "arXiv:2203.08180",
    "title": "Tethered Power Supply for Quadcopters: Architecture, Analysis and  Experiments",
    "abstract": "Tethered quadcopters are used for extended flight operations where the\nnecessary power to the system is provided through the tether from an external\npower source on the ground. In this work, we study the design factors such as\nthe tether mass, electrical resistance, voltage conversion efficiency, etc.\nthat influence the power requirements. We present analytical formulations to\npredict the power requirement for a given setup. Additionally, we show the\nexistence of a critical hover height for a single-quadcopter tether system,\nbeyond which it is physically (electrically) impossible for the quadcopter to\nhover. We then present experimental results for single and two-quadcopter\ntethered systems. Power supply readings from the experiments in various\nconfigurations are consistent with the predictions from the analysis (within\n5%), which experimentally validates the presented analysis. A two-quadcopter\nsystem powered via a single tether is flown through a corridor to demonstrate\none of the applications of having multiple quadcopters on the same tether.",
    "descriptor": "\nComments: 8 pages; submitted to IROS 2022\n",
    "authors": [
      "Karan P. Jain",
      "Prasanth Kotaru",
      "Massimiliano de Sa",
      "Mark W. Mueller",
      "Koushil Sreenath"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08180"
  },
  {
    "id": "arXiv:2203.08182",
    "title": "DSOL: A Fast Direct Sparse Odometry Scheme",
    "abstract": "In this paper, we describe Direct Sparse Odometry Lite (DSOL), an improved\nversion of Direct Sparse Odometry (DSO). We propose several algorithmic and\nimplementation enhancements which speed up computation by a significant factor\n(on average 5x) even on resource constrained platforms. The increase in speed\nallows us to process images at higher frame rates, which in turn provides\nbetter results on rapid motions. Our open-source implementation is available at\nhttps://github.com/versatran01/dsol.",
    "descriptor": "",
    "authors": [
      "Chao Qu",
      "Shreyas S. Shivakumar",
      "Ian D. Miller",
      "Camillo J. Taylor"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08182"
  },
  {
    "id": "arXiv:2203.08184",
    "title": "Reconfigurable Intelligent Surfaces Relying on Non-Diagonal Phase Shift  Matrices",
    "abstract": "Reconfigurable intelligent surfaces (RIS) have been actively researched as a\npotential technique for future wireless communications, which intelligently\nameliorate the signal propagation environment. In the conventional design, each\nRIS element configures and reflects its received signal independently of all\nother RIS elements, which results in a diagonal phase shift matrix. By\ncontrast, we propose a novel RIS architecture, where the incident signal\nimpinging on one element can be reflected from another element after an\nappropriate phase shift adjustment, which increases the flexibility in the\ndesign of RIS phase shifts, hence, potentially improving the system\nperformance. The resultant RIS phase shift matrix also has off-diagonal\nelements, as opposed to the pure diagonal structure of the conventional design.\nCompared to the state-of-art fully-connected/group-connected RIS structures,\nour proposed RIS architecture has lower complexity, while attaining a higher\nchannel gain than the group-connected RIS structure, and approaching that of\nthe fully-connected RIS structure. We formulate and solve the problem of\nmaximizing the achievable rate of our proposed RIS architecture by jointly\noptimizing the transmit beamforming and the non-diagonal phase shift matrix\nbased on alternating optimization and semi-define relaxation (SDR) methods.\nMoreover, the closed-form expressions of the channel gain, the outage\nprobability and bit error ratio (BER) are derived. Simulation results\ndemonstrate that our proposed RIS architecture results in an improved\nperformance in terms of the achievable rate compared to the conventional\narchitecture, both in single-user as well as in multi-user scenarios.",
    "descriptor": "",
    "authors": [
      "Qingchao Li",
      "Mohammed El-Hajjar",
      "Ibrahim Hemadeh",
      "Arman Shojaeifard",
      "Alain A. M. Mourad",
      "Bruno Clerckx",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.08184"
  },
  {
    "id": "arXiv:2203.08189",
    "title": "Fiber Bundle Morphisms as a Framework for Modeling Many-to-Many Maps",
    "abstract": "While it is not generally reflected in the `nice' datasets used for\nbenchmarking machine learning algorithms, the real-world is full of processes\nthat would be best described as many-to-many. That is, a single input can\npotentially yield many different outputs (whether due to noise, imperfect\nmeasurement, or intrinsic stochasticity in the process) and many different\ninputs can yield the same output (that is, the map is not injective). For\nexample, imagine a sentiment analysis task where, due to linguistic ambiguity,\na single statement can have a range of different sentiment interpretations\nwhile at the same time many distinct statements can represent the same\nsentiment. When modeling such a multivalued function $f: X \\rightarrow Y$, it\nis frequently useful to be able to model the distribution on $f(x)$ for\nspecific input $x$ as well as the distribution on fiber $f^{-1}(y)$ for\nspecific output $y$. Such an analysis helps the user (i) better understand the\nvariance intrinsic to the process they are studying and (ii) understand the\nrange of specific input $x$ that can be used to achieve output $y$. Following\nexisting work which used a fiber bundle framework to better model many-to-one\nprocesses, we describe how morphisms of fiber bundles provide a template for\nbuilding models which naturally capture the structure of many-to-many\nprocesses.",
    "descriptor": "",
    "authors": [
      "Elizabeth Coda",
      "Nico Courts",
      "Colby Wight",
      "Loc Truong",
      "WoongJo Choi",
      "Charles Godfrey",
      "Tegan Emerson",
      "Keerti Kappagantula",
      "Henry Kvinge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08189"
  },
  {
    "id": "arXiv:2203.08193",
    "title": "Point Separation and Obstacle Removal by Finding and Hitting Odd Cycles",
    "abstract": "Suppose we are given a pair of points $s, t$ and a set $S$ of $n$ geometric\nobjects in the plane, called obstacles. We show that in polynomial time one can\nconstruct an auxiliary (multi-)graph $G$ with vertex set $S$ and every edge\nlabeled from $\\{0, 1\\}$, such that a set $S_d \\subseteq S$ of obstacles\nseparates $s$ from $t$ if and only if $G[S_d]$ contains a cycle whose sum of\nlabels is odd. Using this structural characterization of separating sets of\nobstacles we obtain the following algorithmic results.\nIn the Obstacle-Removal problem the task is to find a curve in the plane\nconnecting s to t intersecting at most q obstacles. We give a\n$2.3146^qn^{O(1)}$ algorithm for Obstacle-Removal, significantly improving upon\nthe previously best known $q^{O(q^3)} n^{O(1)}$ algorithm of Eiben and\nLokshtanov (SoCG'20). We also obtain an alternative proof of a constant factor\napproximation algorithm for Obstacle-Removal, substantially simplifying the\narguments of Kumar et al. (SODA'21).\nIn the Generalized Points-Separation problem, the input consists of the set S\nof obstacles, a point set A of k points and p pairs $(s_1, t_1),... (s_p, t_p)$\nof points from A. The task is to find a minimum subset $S_r \\subseteq S$ such\nthat for every $i$, every curve from $s_i$ to $t_i$ intersects at least one\nobstacle in $S_r$. We obtain $2^{O(p)} n^{O(k)}$-time algorithm for Generalized\nPoints-Separation problem. This resolves an open problem of Cabello and\nGiannopoulos (SoCG'13), who asked about the existence of such an algorithm for\nthe special case where $(s_1, t_1), ... (s_p, t_p)$ contains all the pairs of\npoints in A. Finally, we improve the running time of our algorithm to $f(p,k)\nn^{O(\\sqrt{k})}$ when the obstacles are unit disks, where $f(p,k) = 2^O(p)\nk^{O(k)}$, and show that, assuming the Exponential Time Hypothesis (ETH), the\nrunning time dependence on $k$ of our algorithms is essentially optimal.",
    "descriptor": "\nComments: Short version of this paper will appear in SoCG'2022\n",
    "authors": [
      "Neeraj Kumar",
      "Daniel Lokshtanov",
      "Saket Saurabh",
      "Subhash Suri",
      "Jie Xue"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.08193"
  },
  {
    "id": "arXiv:2203.08195",
    "title": "DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection",
    "abstract": "Lidars and cameras are critical sensors that provide complementary\ninformation for 3D detection in autonomous driving. While prevalent multi-modal\nmethods simply decorate raw lidar point clouds with camera features and feed\nthem directly to existing 3D detection models, our study shows that fusing\ncamera features with deep lidar features instead of raw points, can lead to\nbetter performance. However, as those features are often augmented and\naggregated, a key challenge in fusion is how to effectively align the\ntransformed features from two modalities. In this paper, we propose two novel\ntechniques: InverseAug that inverses geometric-related augmentations, e.g.,\nrotation, to enable accurate geometric alignment between lidar points and image\npixels, and LearnableAlign that leverages cross-attention to dynamically\ncapture the correlations between image and lidar features during fusion. Based\non InverseAug and LearnableAlign, we develop a family of generic multi-modal 3D\ndetection models named DeepFusion, which is more accurate than previous\nmethods. For example, DeepFusion improves PointPillars, CenterPoint, and 3D-MAN\nbaselines on Pedestrian detection for 6.7, 8.9, and 6.2 LEVEL_2 APH,\nrespectively. Notably, our models achieve state-of-the-art performance on Waymo\nOpen Dataset, and show strong model robustness against input corruptions and\nout-of-distribution data. Code will be publicly available at\nhttps://github.com/tensorflow/lingvo/tree/master/lingvo/.",
    "descriptor": "\nComments: CVPR 2022. 1st rank 3D detection method on Waymo Challenge Leaderboard: this https URL&challenge=DETECTION_3D&emailId=5451f123-a0ea\n",
    "authors": [
      "Yingwei Li",
      "Adams Wei Yu",
      "Tianjian Meng",
      "Ben Caine",
      "Jiquan Ngiam",
      "Daiyi Peng",
      "Junyang Shen",
      "Bo Wu",
      "Yifeng Lu",
      "Denny Zhou",
      "Quoc V. Le",
      "Alan Yuille",
      "Mingxing Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08195"
  },
  {
    "id": "arXiv:2203.08199",
    "title": "(Re)Politicizing Digital Well-Being: Beyond User Engagements",
    "abstract": "The psychological costs of the attention economy are often considered through\nthe binary of harmful design and healthy use, with digital well-being chiefly\ncharacterised as a matter of personal responsibility. This article adopts an\ninterdisciplinary approach to highlight the empirical, ideological, and\npolitical limits of embedding this individualised perspective in computational\ndiscourses and designs of digital well-being measurement. We will reveal\nwell-being to be a culturally specific and environmentally conditioned concept\nand will problematize user engagement as a universal proxy for well-being.\nInstead, the contributing factors of user well-being will be located in\nenvironing social, cultural, and political conditions far beyond the control of\nindividual users alone. In doing so, we hope to reinvigorate the issue of\ndigital well-being measurement as a nexus point of political concern, through\nwhich multiple disciplines can study experiences of digital ill as symptomatic\nof wider social inequalities and (capitalist) relations of power.",
    "descriptor": "\nComments: Published in Proceedings of CHI '22\n",
    "authors": [
      "Niall Docherty",
      "Asia J. Biega"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.08199"
  },
  {
    "id": "arXiv:2203.08205",
    "title": "Learning Deep Implicit Fourier Neural Operators (IFNOs) with  Applications to Heterogeneous Material Modeling",
    "abstract": "Constitutive modeling based on continuum mechanics theory has been a\nclassical approach for modeling the mechanical responses of materials. However,\nwhen constitutive laws are unknown or when defects and/or high degrees of\nheterogeneity are present, these classical models may become inaccurate. In\nthis work, we propose to use data-driven modeling, which directly utilizes\nhigh-fidelity simulation and/or experimental measurements to predict a\nmaterial's response without using conventional constitutive models.\nSpecifically, the material response is modeled by learning the implicit\nmappings between loading conditions and the resultant displacement and/or\ndamage fields, with the neural network serving as a surrogate for a solution\noperator. To model the complex responses due to material heterogeneity and\ndefects, we develop a novel deep neural operator architecture, which we coin as\nthe Implicit Fourier Neural Operator (IFNO). In the IFNO, the increment between\nlayers is modeled as an integral operator to capture the long-range\ndependencies in the feature space. As the network gets deeper, the limit of\nIFNO becomes a fixed point equation that yields an implicit neural operator and\nnaturally mimics the displacement/damage fields solving procedure in material\nmodeling problems. We demonstrate the performance of our proposed method for a\nnumber of examples, including hyperelastic, anisotropic and brittle materials.\nAs an application, we further employ the proposed approach to learn the\nmaterial models directly from digital image correlation (DIC) tracking\nmeasurements, and show that the learned solution operators substantially\noutperform the conventional constitutive models in predicting displacement\nfields.",
    "descriptor": "",
    "authors": [
      "Huaiqian You",
      "Quinn Zhang",
      "Colton J. Ross",
      "Chung-Hao Lee",
      "Yue Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2203.08205"
  },
  {
    "id": "arXiv:2203.08207",
    "title": "SocialVAE: Human Trajectory Prediction using Timewise Latents",
    "abstract": "Predicting pedestrian movement is critical for human behavior analysis and\nalso for safe and efficient human-agent interactions. However, despite\nsignificant advancements, it is still challenging for existing approaches to\ncapture the uncertainty and multimodality of human navigation decision making.\nIn this paper, we propose SocialVAE, a novel approach for human trajectory\nprediction. The core of SocialVAE is a timewise variational autoencoder\narchitecture that exploits stochastic recurrent neural networks to perform\nprediction, combined with a social attention mechanism and backward posterior\napproximation to allow for better extraction of pedestrian navigation\nstrategies. We show that SocialVAE improves current state-of-the-art\nperformance on several pedestrian trajectory prediction benchmarks, including\nthe ETH/UCY benchmark, the Stanford Drone Dataset and SportVU NBA movement\ndataset. Code is available at: {\\tt https://github.com/xupei0610/SocialVAE}.",
    "descriptor": "",
    "authors": [
      "Pei Xu",
      "Jean-Bernard Hayet",
      "Ioannis Karamouzas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08207"
  },
  {
    "id": "arXiv:2203.08209",
    "title": "A Differentiable Approach to Combinatorial Optimization using Dataless  Neural Networks",
    "abstract": "The success of machine learning solutions for reasoning about discrete\nstructures has brought attention to its adoption within combinatorial\noptimization algorithms. Such approaches generally rely on supervised learning\nby leveraging datasets of the combinatorial structures of interest drawn from\nsome distribution of problem instances. Reinforcement learning has also been\nemployed to find such structures. In this paper, we propose a radically\ndifferent approach in that no data is required for training the neural networks\nthat produce the solution. In particular, we reduce the combinatorial\noptimization problem to a neural network and employ a dataless training scheme\nto refine the parameters of the network such that those parameters yield the\nstructure of interest. We consider the combinatorial optimization problems of\nfinding maximum independent sets and maximum cliques in a graph. In principle,\nsince these problems belong to the NP-hard complexity class, our proposed\napproach can be used to solve any other NP-hard problem. Additionally, we\npropose a universal graph reduction procedure to handle large scale graphs. The\nreduction exploits community detection for graph partitioning and is applicable\nto any graph type and/or density. Experimental evaluation on both synthetic\ngraphs and real-world benchmarks demonstrates that our method performs on par\nwith or outperforms state-of-the-art heuristic, reinforcement learning, and\nmachine learning based methods without requiring any data.",
    "descriptor": "",
    "authors": [
      "Ismail R. Alkhouri",
      "George K. Atia",
      "Alvaro Velasquez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08209"
  },
  {
    "id": "arXiv:2203.08212",
    "title": "AUTOMATA: Gradient Based Data Subset Selection for Compute-Efficient  Hyper-parameter Tuning",
    "abstract": "Deep neural networks have seen great success in recent years; however,\ntraining a deep model is often challenging as its performance heavily depends\non the hyper-parameters used. In addition, finding the optimal hyper-parameter\nconfiguration, even with state-of-the-art (SOTA) hyper-parameter optimization\n(HPO) algorithms, can be time-consuming, requiring multiple training runs over\nthe entire dataset for different possible sets of hyper-parameters. Our central\ninsight is that using an informative subset of the dataset for model training\nruns involved in hyper-parameter optimization, allows us to find the optimal\nhyper-parameter configuration significantly faster. In this work, we propose\nAUTOMATA, a gradient-based subset selection framework for hyper-parameter\ntuning. We empirically evaluate the effectiveness of AUTOMATA in\nhyper-parameter tuning through several experiments on real-world datasets in\nthe text, vision, and tabular domains. Our experiments show that using\ngradient-based data subsets for hyper-parameter tuning achieves significantly\nfaster turnaround times and speedups of 3$\\times$-30$\\times$ while achieving\ncomparable performance to the hyper-parameters found using the entire dataset.",
    "descriptor": "",
    "authors": [
      "Krishnateja Killamsetty",
      "Guttu Sai Abhishek",
      "Aakriti",
      "Alexandre V. Evfimievski",
      "Lucian Popa",
      "Ganesh Ramakrishnan",
      "Rishabh Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08212"
  },
  {
    "id": "arXiv:2203.08215",
    "title": "Auto-Gait: Automatic Ataxia Risk Assessment with Computer Vision on Gait  Task Videos",
    "abstract": "In this paper, we investigated whether we can 1) detect participants with\nataxia-specific gait characteristics (risk-prediction), and 2) assess severity\nof ataxia from gait (severity-assessment). We collected 155 videos from 89\nparticipants, 24 controls and 65 diagnosed with (or are pre-manifest)\nspinocerebellar ataxias (SCAs), performing the gait task of the Scale for the\nAssessment and Rating of Ataxia (SARA) from 11 medical sites located in 8\ndifferent states in the United States. We developed a method to separate the\nparticipants from their surroundings and constructed several features to\ncapture gait characteristics like step width, step length, swing, stability,\nspeed, etc. Our risk-prediction model achieves 83.06% accuracy and an 80.23% F1\nscore. Similarly, our severity-assessment model achieves a mean absolute error\n(MAE) score of 0.6225 and a Pearson's correlation coefficient score of 0.7268.\nOur models still performed competitively when evaluated on data from sites not\nused during training. Furthermore, through feature importance analysis, we\nfound that our models associate wider steps, decreased walking speed, and\nincreased instability with greater ataxia severity, which is consistent with\npreviously established clinical knowledge. Our models create possibilities for\nremote ataxia assessment in non-clinical settings in the future, which could\nsignificantly improve accessibility of ataxia care. Furthermore, our underlying\ndataset was assembled from a geographically diverse cohort, highlighting its\npotential to further increase equity. The code used in this study is open to\nthe public, and the anonymized body pose landmark dataset could be released\nupon approval from our Institutional Review Board (IRB).",
    "descriptor": "",
    "authors": [
      "Wasifur Rahman",
      "Masum Hasan",
      "Md Saiful Islam",
      "Titilayo Olubajo",
      "Jeet Thaker",
      "Abdelrahman Abdelkader",
      "Phillip Yang",
      "Tetsuo Ashizawa",
      "Ehsan Hoque"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08215"
  },
  {
    "id": "arXiv:2203.08216",
    "title": "Interactive Portrait Harmonization",
    "abstract": "Current image harmonization methods consider the entire background as the\nguidance for harmonization. However, this may limit the capability for user to\nchoose any specific object/person in the background to guide the harmonization.\nTo enable flexible interaction between user and harmonization, we introduce\ninteractive harmonization, a new setting where the harmonization is performed\nwith respect to a selected \\emph{region} in the reference image instead of the\nentire background. A new flexible framework that allows users to pick certain\nregions of the background image and use it to guide the harmonization is\nproposed. Inspired by professional portrait harmonization users, we also\nintroduce a new luminance matching loss to optimally match the color/luminance\nconditions between the composite foreground and select reference region. This\nframework provides more control to the image harmonization pipeline achieving\nvisually pleasing portrait edits. Furthermore, we also introduce a new dataset\ncarefully curated for validating portrait harmonization. Extensive experiments\non both synthetic and real-world datasets show that the proposed approach is\nefficient and robust compared to previous harmonization baselines, especially\nfor portraits. Project Webpage at\n\\href{https://jeya-maria-jose.github.io/IPH-web/}{https://jeya-maria-jose.github.io/IPH-web/}",
    "descriptor": "",
    "authors": [
      "Jeya Maria Jose Valanarasu",
      "He Zhang",
      "Jianming Zhang",
      "Yilin Wang",
      "Zhe Lin",
      "Jose Echevarria",
      "Yinglan Ma",
      "Zijun Wei",
      "Kalyan Sunkavalli",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08216"
  },
  {
    "id": "arXiv:2203.08217",
    "title": "A Wearables-Driven Attack on Examination Proctoring",
    "abstract": "Multiple choice questions are at the heart of many standardized tests and\nexaminations at academic institutions allover the world. In this paper, we\nargue that recent advancements in sensing and human-computer interaction expose\nthese types of questions to highly effective attacks that today's proctor's are\nsimply not equipped to detect. We design one such attack based on a protocol of\ncarefully orchestrated wrist movements combined with haptic and visual feedback\nmechanisms designed for stealthiness. The attack is done through collaboration\nbetween a knowledgeable student (i.e., a mercenary) and a weak student (i.e.,\nthe beneficiary) who depends on the mercenary for solutions. Through a\ncombination of experiments and theoretical modeling, we show the attack to be\nhighly effective. The paper makes the case for an outright ban on all tech\ngadgets inside examination rooms, irrespective of whether their usage appears\nbenign to the plain eye.",
    "descriptor": "\nComments: Published in 2021 18th International Conference on Privacy, Security and Trust (PST)\n",
    "authors": [
      "Tasnia Ashrafi Heya",
      "Abdul Serwadda",
      "Isaac Griswold-Steiner",
      "Richard Matovu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.08217"
  },
  {
    "id": "arXiv:2203.08219",
    "title": "CrowdMLP: Weakly-Supervised Crowd Counting via Multi-Granularity MLP",
    "abstract": "Existing state-of-the-art crowd counting algorithms rely excessively on\nlocation-level annotations, which are burdensome to acquire. When only\ncount-level (weak) supervisory signals are available, it is arduous and\nerror-prone to regress total counts due to the lack of explicit spatial\nconstraints. To address this issue, a novel and efficient counter (referred to\nas CrowdMLP) is presented, which probes into modelling global dependencies of\nembeddings and regressing total counts by devising a multi-granularity MLP\nregressor. In specific, a locally-focused pre-trained frontend is cascaded to\nextract crude feature maps with intrinsic spatial cues, which prevent the model\nfrom collapsing into trivial outcomes. The crude embeddings, along with raw\ncrowd scenes, are tokenized at different granularity levels. The\nmulti-granularity MLP then proceeds to mix tokens at the dimensions of\ncardinality, channel, and spatial for mining global information. An effective\nproxy task, namely Split-Counting, is also proposed to evade the barrier of\nlimited samples and the shortage of spatial hints in a self-supervised manner.\nExtensive experiments demonstrate that CrowdMLP significantly outperforms\nexisting weakly-supervised counting algorithms and performs on par with\nstate-of-the-art location-level supervised approaches.",
    "descriptor": "",
    "authors": [
      "Mingjie Wang",
      "Jun Zhou",
      "Hao Cai",
      "Minglun Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08219"
  },
  {
    "id": "arXiv:2203.08220",
    "title": "Power-Based Side-Channel Attack for AES Key Extraction on the ATMega328  Microcontroller",
    "abstract": "We demonstrate the extraction of an AES secret key from flash memory on the\nATMega328 microcontroller (the microcontroller used on the popular Arduino\nGenuino/Uno board). We loaded a standard AVR-architecture AES-128\nimplementation onto the chip and encrypted randomly chosen plaintexts with\nseveral different keys. We measured the chip's power consumption during\nencryption, correlated observed power consumption with the expected power\nconsumption of the plaintexts with every possible key, and ultimately extracted\nthe 128-bit key used during AES. We describe here our test infrastructure for\nautomated power trace collection, an overview of our correlation attack,\nsanitization of the traces and stumbling blocks encountered during data\ncollection and analysis, and results of our attack.",
    "descriptor": "\nComments: MIT 6.858 Class Project\n",
    "authors": [
      "Utsav Banerjee",
      "Lisa Ho",
      "Skanda Koppula"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.08220"
  },
  {
    "id": "arXiv:2203.08221",
    "title": "Development of Decision Support System for Effective COVID-19 Management",
    "abstract": "This paper discusses a Decision Support System (DSS) for cases prediction,\nallocation of resources, and lockdown management for managing COVID-19 at\ndifferent levels of a government authority. Algorithms incorporated in the DSS\nare based on a data-driven modeling approach and independent of physical\nparameters of the region, and hence the proposed DSS is applicable to any area.\nBased on predicted active cases, the demand of lower-level units and total\navailability, allocation, and lockdown decision is made. A MATLAB-based GUI is\ndeveloped based on the proposed DSS and could be implemented by the local\nauthority.",
    "descriptor": "\nComments: 5th world Congress on Disaster Management, IIT Delhi, New Delhi, India\n",
    "authors": [
      "shuvrangshu Jana",
      "Rudrashis Majumder",
      "Aashay Bhise",
      "Nobin Paul",
      "Stuti Garg",
      "Debasish Ghose"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08221"
  },
  {
    "id": "arXiv:2203.08222",
    "title": "Zipfian environments for Reinforcement Learning",
    "abstract": "As humans and animals learn in the natural world, they encounter\ndistributions of entities, situations and events that are far from uniform.\nTypically, a relatively small set of experiences are encountered frequently,\nwhile many important experiences occur only rarely. The highly-skewed,\nheavy-tailed nature of reality poses particular learning challenges that humans\nand animals have met by evolving specialised memory systems. By contrast, most\npopular RL environments and benchmarks involve approximately uniform variation\nof properties, objects, situations or tasks. How will RL algorithms perform in\nworlds (like ours) where the distribution of environment features is far less\nuniform? To explore this question, we develop three complementary RL\nenvironments where the agent's experience varies according to a Zipfian\n(discrete power law) distribution. On these benchmarks, we find that standard\nDeep RL architectures and algorithms acquire useful knowledge of common\nsituations and tasks, but fail to adequately learn about rarer ones. To\nunderstand this failure better, we explore how different aspects of current\napproaches may be adjusted to help improve performance on rare events, and show\nthat the RL objective function, the agent's memory system and self-supervised\nlearning objectives can all influence an agent's ability to learn from uncommon\nexperiences. Together, these results show that learning robustly from skewed\nexperience is a critical challenge for applying Deep RL methods beyond\nsimulations or laboratories, and our Zipfian environments provide a basis for\nmeasuring future progress towards this goal.",
    "descriptor": "",
    "authors": [
      "Stephanie C. Y. Chan",
      "Andrew K. Lampinen",
      "Pierre H. Richemond",
      "Felix Hill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08222"
  },
  {
    "id": "arXiv:2203.08227",
    "title": "Sex Trouble: Common pitfalls in incorporating sex/gender in medical  machine learning and how to avoid them",
    "abstract": "False assumptions about sex and gender are deeply embedded in the medical\nsystem, including that they are binary, static, and concordant. Machine\nlearning researchers must understand the nature of these assumptions in order\nto avoid perpetuating them. In this perspectives piece, we identify three\ncommon mistakes that researchers make when dealing with sex/gender data: \"sex\nconfusion\", the failure to identity what sex in a dataset does or doesn't mean;\n\"sex obsession\", the belief that sex, specifically sex assigned at birth, is\nthe relevant variable for most applications; and \"sex/gender slippage\", the\nconflation of sex and gender even in contexts where only one or the other is\nknown. We then discuss how these pitfalls show up in machine learning studies\nbased on electronic health record data, which is commonly used for everything\nfrom retrospective analysis of patient outcomes to the development of\nalgorithms to predict risk and administer care. Finally, we offer a series of\nrecommendations about how machine learning researchers can produce both\nresearch and algorithms that more carefully engage with questions of\nsex/gender, better serving all patients, including transgender people.",
    "descriptor": "\nComments: submitted to Cell Patterns as a perspective article\n",
    "authors": [
      "Kendra Albert",
      "Maggie Delano"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08227"
  },
  {
    "id": "arXiv:2203.08235",
    "title": "A Deep Dive into Dataset Imbalance and Bias in Face Identification",
    "abstract": "As the deployment of automated face recognition (FR) systems proliferates,\nbias in these systems is not just an academic question, but a matter of public\nconcern. Media portrayals often center imbalance as the main source of bias,\ni.e., that FR models perform worse on images of non-white people or women\nbecause these demographic groups are underrepresented in training data. Recent\nacademic research paints a more nuanced picture of this relationship. However,\nprevious studies of data imbalance in FR have focused exclusively on the face\nverification setting, while the face identification setting has been largely\nignored, despite being deployed in sensitive applications such as law\nenforcement. This is an unfortunate omission, as 'imbalance' is a more complex\nmatter in identification; imbalance may arise in not only the training data,\nbut also the testing data, and furthermore may affect the proportion of\nidentities belonging to each demographic group or the number of images\nbelonging to each identity. In this work, we address this gap in the research\nby thoroughly exploring the effects of each kind of imbalance possible in face\nidentification, and discuss other factors which may impact bias in this\nsetting.",
    "descriptor": "",
    "authors": [
      "Valeriia Cherepanova",
      "Steven Reich",
      "Samuel Dooley",
      "Hossein Souri",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08235"
  },
  {
    "id": "arXiv:2203.08242",
    "title": "Data Contamination: From Memorization to Exploitation",
    "abstract": "Pretrained language models are typically trained on massive web-based\ndatasets, which are often \"contaminated\" with downstream test sets. It is not\nclear to what extent models exploit the contaminated data for downstream tasks.\nWe present a principled method to study this question. We pretrain BERT models\non joint corpora of Wikipedia and labeled downstream datasets, and fine-tune\nthem on the relevant task. Comparing performance between samples seen and\nunseen during pretraining enables us to define and quantify levels of\nmemorization and exploitation. Experiments with two models and three downstream\ntasks show that exploitation exists in some cases, but in others the models\nmemorize the contaminated data, but do not exploit it. We show that these two\nmeasures are affected by different factors such as the number of duplications\nof the contaminated data and the model size. Our results highlight the\nimportance of analyzing massive web-scale datasets to verify that progress in\nNLP is obtained by better language understanding and not better data\nexploitation.",
    "descriptor": "\nComments: Accepted to ACL 2022\n",
    "authors": [
      "Inbal Magar",
      "Roy Schwartz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08242"
  },
  {
    "id": "arXiv:2203.08243",
    "title": "Unified Visual Transformer Compression",
    "abstract": "Vision transformers (ViTs) have gained popularity recently. Even without\ncustomized image operators such as convolutions, ViTs can yield competitive\nperformance when properly trained on massive data. However, the computational\noverhead of ViTs remains prohibitive, due to stacking multi-head self-attention\nmodules and else. Compared to the vast literature and prevailing success in\ncompressing convolutional neural networks, the study of Vision Transformer\ncompression has also just emerged, and existing works focused on one or two\naspects of compression. This paper proposes a unified ViT compression framework\nthat seamlessly assembles three effective techniques: pruning, layer skipping,\nand knowledge distillation. We formulate a budget-constrained, end-to-end\noptimization framework, targeting jointly learning model weights, layer-wise\npruning ratios/masks, and skip configurations, under a distillation loss. The\noptimization problem is then solved using the primal-dual algorithm.\nExperiments are conducted with several ViT variants, e.g. DeiT and T2T-ViT\nbackbones on the ImageNet dataset, and our approach consistently outperforms\nrecent competitors. For example, DeiT-Tiny can be trimmed down to 50\\% of the\noriginal FLOPs almost without losing accuracy. Codes are available\nonline:~\\url{https://github.com/VITA-Group/UVC}.",
    "descriptor": "\nComments: Accepted by ICLR'22\n",
    "authors": [
      "Shixing Yu",
      "Tianlong Chen",
      "Jiayi Shen",
      "Huan Yuan",
      "Jianchao Tan",
      "Sen Yang",
      "Ji Liu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08243"
  },
  {
    "id": "arXiv:2203.08244",
    "title": "Toward Improving Attentive Neural Networks in Legal Text Processing",
    "abstract": "In recent years, thanks to breakthroughs in neural network techniques\nespecially attentive deep learning models, natural language processing has made\nmany impressive achievements. However, automated legal word processing is still\na difficult branch of natural language processing. Legal sentences are often\nlong and contain complicated legal terminologies. Hence, models that work well\non general documents still face challenges in dealing with legal documents. We\nhave verified the existence of this problem with our experiments in this work.\nIn this dissertation, we selectively present the main achievements in improving\nattentive neural networks in automatic legal document processing. Language\nmodels tend to grow larger and larger, though, without expert knowledge, these\nmodels can still fail in domain adaptation, especially for specialized fields\nlike law.",
    "descriptor": "\nComments: Doctoral Dissertation\n",
    "authors": [
      "Ha-Thanh Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08244"
  },
  {
    "id": "arXiv:2203.08245",
    "title": "Reconstructing Missing EHRs Using Time-Aware Within- and Cross-Visit  Information for Septic Shock Early Prediction",
    "abstract": "Real-world Electronic Health Records (EHRs) are often plagued by a high rate\nof missing data. In our EHRs, for example, the missing rates can be as high as\n90% for some features, with an average missing rate of around 70% across all\nfeatures. We propose a Time-Aware Dual-Cross-Visit missing value imputation\nmethod, named TA-DualCV, which spontaneously leverages multivariate\ndependencies across features and longitudinal dependencies both within- and\ncross-visit to maximize the information extracted from limited observable\nrecords in EHRs. Specifically, TA-DualCV captures the latent structure of\nmissing patterns across measurements of different features and it also\nconsiders the time continuity and capture the latent temporal missing patterns\nbased on both time-steps and irregular time-intervals. TA-DualCV is evaluated\nusing three large real-world EHRs on two types of tasks: an unsupervised\nimputation task by varying mask rates up to 90% and a supervised 24-hour early\nprediction of septic shock using Long Short-Term Memory (LSTM). Our results\nshow that TA-DualCV performs significantly better than all of the existing\nstate-of-the-art imputation baselines, such as DETROIT and TAME, on both types\nof tasks.",
    "descriptor": "\nComments: 12 pages, accepted at IEEE ICHI'22\n",
    "authors": [
      "Ge Gao",
      "Farzaneh Khoshnevisan",
      "Min Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.08245"
  },
  {
    "id": "arXiv:2203.08248",
    "title": "Non-Linear Reinforcement Learning in Large Action Spaces: Structural  Conditions and Sample-efficiency of Posterior Sampling",
    "abstract": "Provably sample-efficient Reinforcement Learning (RL) with rich observations\nand function approximation has witnessed tremendous recent progress,\nparticularly when the underlying function approximators are linear. In this\nlinear regime, computationally and statistically efficient methods exist where\nthe potentially infinite state and action spaces can be captured through a\nknown feature embedding, with the sample complexity scaling with the\n(intrinsic) dimension of these features. When the action space is finite,\nsignificantly more sophisticated results allow non-linear function\napproximation under appropriate structural constraints on the underlying RL\nproblem, permitting for instance, the learning of good features instead of\nassuming access to them. In this work, we present the first result for\nnon-linear function approximation which holds for general action spaces under a\nlinear embeddability condition, which generalizes all linear and finite action\nsettings. We design a novel optimistic posterior sampling strategy, TS^3 for\nsuch problems, and show worst case sample complexity guarantees that scale with\na rank parameter of the RL problem, the linear embedding dimension introduced\nin this work and standard measures of the function class complexity.",
    "descriptor": "",
    "authors": [
      "Alekh Agarwal",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08248"
  },
  {
    "id": "arXiv:2203.08251",
    "title": "Flash: Fast and Light Motion Prediction for Autonomous Driving with  Bayesian Inverse Planning and Learned Motion Profiles",
    "abstract": "Motion prediction of road users in traffic scenes is critical for autonomous\ndriving systems that must take safe and robust decisions in complex dynamic\nenvironments. We present a novel motion prediction system for autonomous\ndriving. Our system is based on the Bayesian inverse planning framework, which\nefficiently orchestrates map-based goal extraction, a classical control-based\ntrajectory generator and an ensemble of light-weight neural networks\nspecialised in motion profile prediction. In contrast to many alternative\nmethods, this modularity helps isolate performance factors and better interpret\nresults, without compromising performance. This system addresses multiple\naspects of interest, namely multi-modality, motion profile uncertainty and\ntrajectory physical feasibility. We report on several experiments with the\npopular highway dataset NGSIM, demonstrating state-of-the-art performance in\nterms of trajectory error. We also perform a detailed analysis of our system's\ncomponents, along with experiments that stratify the data based on behaviours,\nsuch as change lane versus follow lane, to provide insights into the challenges\nin this domain. Finally, we present a qualitative analysis to show other\nbenefits of our approach, such as the ability to interpret the outputs.",
    "descriptor": "",
    "authors": [
      "Morris Antonello",
      "Mihai Dobre",
      "Stefano V. Albrecht",
      "John Redford",
      "Subramanian Ramamoorthy"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08251"
  },
  {
    "id": "arXiv:2203.08253",
    "title": "Integrated System Models for Networks with Generators & Inverters",
    "abstract": "Synchronous generators and inverter-based resources are complex systems with\ndynamics that cut across multiple intertwined physical domains and control\nloops. Modeling individual generators and inverters is, in itself, a very\ninvolved activity and has attracted dedicated attention from power engineers\nand control theorists over the years. Control and stability challenges\nassociated with increasing penetration of grid-following inverters have\ngenerated tremendous interest in grid-forming inverter technology. The\nenvisioned coexistence of inverter technologies alongside rotating machines\ncall for modeling frameworks that can accurately describe networked dynamics of\ninterconnected generators and inverters across timescales. We put forth a\ncomprehensive integrated system model for such a setting by: i) adopting a\ncombination of circuit- and system-theoretic constructs, ii) unifying\nrepresentations of three-phase signals across reference-frame transformations\nand phasor types, and iii) leveraging domain-level knowledge, engineering\ninsights, and reasonable approximations. A running theme through our effort is\nto offer a clear distinction between physics-based models and the task of\nmodeling. Among several insights spanning the spectrum from analytical to\npractical, we highlight how differential-algebraic-equation models and\nalgebraic power-flow phasor models fall out of the detailed originating\nelectromagnetic transient models.",
    "descriptor": "",
    "authors": [
      "D. Venkatramanan",
      "Manish K. Singh",
      "Olaolu Ajala",
      "Alejandro Dominguez-Garcia",
      "Sairaj Dhople"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.08253"
  },
  {
    "id": "arXiv:2203.08257",
    "title": "Differentiable Multi-Agent Actor-Critic for Multi-Step Radiology Report  Summarization",
    "abstract": "The IMPRESSIONS section of a radiology report about an imaging study is a\nsummary of the radiologist's reasoning and conclusions, and it also aids the\nreferring physician in confirming or excluding certain diagnoses. A cascade of\ntasks are required to automatically generate an abstractive summary of the\ntypical information-rich radiology report. These tasks include acquisition of\nsalient content from the report and generation of a concise, easily consumable\nIMPRESSIONS section. Prior research on radiology report summarization has\nfocused on single-step end-to-end models -- which subsume the task of salient\ncontent acquisition. To fully explore the cascade structure and explainability\nof radiology report summarization, we introduce two innovations. First, we\ndesign a two-step approach: extractive summarization followed by abstractive\nsummarization. Second, we additionally break down the extractive part into two\nindependent tasks: extraction of salient (1) sentences and (2) keywords.\nExperiments on a publicly available radiology report dataset show our novel\napproach leads to a more precise summary compared to single-step and to\ntwo-step-with-single-extractive-process baselines with an overall improvement\nin F1 score Of 3-4%.",
    "descriptor": "\nComments: Accepted at 60th Annual Meeting of the Association for Computational Linguistics 2022 Main Conference\n",
    "authors": [
      "Sanjeev Kumar Karn",
      "Ning Liu",
      "Hinrich Schuetze",
      "Oladimeji Farri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08257"
  },
  {
    "id": "arXiv:2203.08259",
    "title": "Better Quality Estimation for Low Resource Corpus Mining",
    "abstract": "Quality Estimation (QE) models have the potential to change how we evaluate\nand maybe even train machine translation models. However, these models still\nlack the robustness to achieve general adoption. We show that State-of-the-art\nQE models, when tested in a Parallel Corpus Mining (PCM) setting, perform\nunexpectedly bad due to a lack of robustness to out-of-domain examples. We\npropose a combination of multitask training, data augmentation and contrastive\nlearning to achieve better and more robust QE performance. We show that our\nmethod improves QE performance significantly in the MLQE challenge and the\nrobustness of QE models when tested in the Parallel Corpus Mining setup. We\nincrease the accuracy in PCM by more than 0.80, making it on par with\nstate-of-the-art PCM methods that use millions of sentence pairs to train their\nmodels. In comparison, we use a thousand times less data, 7K parallel sentences\nin total, and propose a novel low resource PCM method.",
    "descriptor": "\nComments: To be published in: Findigs of ACL2022. 9 Pages + Appendix\n",
    "authors": [
      "Muhammed Yusuf Kocyigit",
      "Jiho Lee",
      "Derry Wijaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08259"
  },
  {
    "id": "arXiv:2203.08263",
    "title": "Performance Comparison of Python Translators for a Multi-threaded  CPU-bound Application",
    "abstract": "Currently, Python is one of the most widely used languages in various\napplication areas. However, it has limitations when it comes to optimizing and\nparallelizing applications due to the nature of its official CPython\ninterpreter, especially for CPU-bound applications. To solve this problem,\nseveral alternative translators have emerged, each with a different approach\nand its own cost-performance ratio. Due to the absence of comparative studies,\nwe have carried out a performance comparison of these translators using N-Body\nas a case study (a well-known problem with high computational demand). The\nresults obtained show that CPython and PyPy presented poor performance due to\ntheir limitations when it comes to parallelizing algorithms; while Numba and\nCython achieved significantly higher performance, proving to be viable options\nto speed up numerical algorithms.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9s Milla",
      "Enzo Rucci"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.08263"
  },
  {
    "id": "arXiv:2203.08264",
    "title": "Neural RF SLAM for unsupervised positioning and mapping with channel  state information",
    "abstract": "We present a neural network architecture for jointly learning user locations\nand environment mapping up to isometry, in an unsupervised way, from channel\nstate information (CSI) values with no location information. The model is based\non an encoder-decoder architecture. The encoder network maps CSI values to the\nuser location. The decoder network models the physics of propagation by\nparametrizing the environment using virtual anchors. It aims at reconstructing,\nfrom the encoder output and virtual anchor location, the set of time of flights\n(ToFs) that are extracted from CSI using super-resolution methods. The neural\nnetwork task is set prediction and is accordingly trained end-to-end. The\nproposed model learns an interpretable latent, i.e., user location, by just\nenforcing a physics-based decoder. It is shown that the proposed model achieves\nsub-meter accuracy on synthetic ray tracing based datasets with single anchor\nSISO setup while recovering the environment map up to 4cm median error in a 2D\nenvironment and 15cm in a 3D environment",
    "descriptor": "\nComments: Accepted at IEEE International Conference on Communications 2022. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other work\n",
    "authors": [
      "Shreya Kadambi",
      "Arash Behboodi",
      "Joseph B. Soriaga",
      "Max Welling",
      "Roohollah Amiri",
      "Srinivas Yerramalli",
      "Taesang Yoo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.08264"
  },
  {
    "id": "arXiv:2203.08267",
    "title": "2-speed network ensemble for efficient classification of incremental  land-use/land-cover satellite image chips",
    "abstract": "The ever-growing volume of satellite imagery data presents a challenge for\nindustry and governments making data-driven decisions based on the timely\nanalysis of very large data sets. Commonly used deep learning algorithms for\nautomatic classification of satellite images are time and resource-intensive to\ntrain. The cost of retraining in the context of Big Data presents a practical\nchallenge when new image data and/or classes are added to a training corpus.\nRecognizing the need for an adaptable, accurate, and scalable satellite image\nchip classification scheme, in this research we present an ensemble of: i) a\nslow to train but high accuracy vision transformer; and ii) a fast to train,\nlow-parameter convolutional neural network. The vision transformer model\nprovides a scalable and accurate foundation model. The high-speed CNN provides\nan efficient means of incorporating newly labelled data into analysis, at the\nexpense of lower accuracy. To simulate incremental data, the very large\n(~400,000 images) So2Sat LCZ42 satellite image chip dataset is divided into\nfour intervals, with the high-speed CNN retrained every interval and the vision\ntransformer trained every half interval. This experimental setup mimics an\nincrease in data volume and diversity over time. For the task of automated\nland-cover/land-use classification, the ensemble models for each data increment\noutperform each of the component models, with best accuracy of 65% against a\nholdout test partition of the So2Sat dataset. The proposed ensemble and\nstaggered training schedule provide a scalable and cost-effective satellite\nimage classification scheme that is optimized to process very large volumes of\nsatellite data.",
    "descriptor": "\nComments: 24 pages, 9 figures, 5 tables\n",
    "authors": [
      "Michael James Horry",
      "Subrata Chakraborty",
      "Biswajeet Pradhan",
      "Nagesh Shukla",
      "Sanjoy Paul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08267"
  },
  {
    "id": "arXiv:2203.08272",
    "title": "Active Exploration for Neural Global Illumination of Variable Scenes",
    "abstract": "Neural rendering algorithms introduce a fundamentally new approach for\nphotorealistic rendering, typically by learning a neural representation of\nillumination on large numbers of ground truth images. When training for a given\nvariable scene, i.e., changing objects, materials, lights and viewpoint, the\nspace D of possible training data instances quickly becomes unmanageable as the\ndimensions of variable parameters increase. We introduce a novel Active\nExploration method using Markov Chain Monte Carlo, which explores D, generating\nsamples (i.e., ground truth renderings) that best help training and interleaves\ntraining and on-the-fly sample data generation. We introduce a self-tuning\nsample reuse strategy to minimize the expensive step of rendering training\nsamples. We apply our approach on a neural generator that learns to render\nnovel scene instances given an explicit parameterization of the scene\nconfiguration. Our results show that Active Exploration trains our network much\nmore efficiently than uniformly sampling, and together with our resolution\nenhancement approach, achieves better quality than uniform sampling at\nconvergence. Our method allows interactive rendering of hard light transport\npaths (e.g., complex caustics) -- that require very high samples counts to be\ncaptured -- and provides dynamic scene navigation and manipulation, after\ntraining for 5-18 hours depending on required quality and variations.",
    "descriptor": "\nComments: Project page: this http URL\n",
    "authors": [
      "Stavros Diolatzis",
      "Julien Philip",
      "George Drettakis"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.08272"
  },
  {
    "id": "arXiv:2203.08274",
    "title": "Non-neural Models Matter: A Re-evaluation of Neural Referring Expression  Generation Systems",
    "abstract": "In recent years, neural models have often outperformed rule-based and classic\nMachine Learning approaches in NLG. These classic approaches are now often\ndisregarded, for example when new neural models are evaluated. We argue that\nthey should not be overlooked, since, for some tasks, well-designed non-neural\napproaches achieve better performance than neural ones. In this paper, the task\nof generating referring expressions in linguistic context is used as an\nexample. We examined two very different English datasets (WEBNLG and WSJ), and\nevaluated each algorithm using both automatic and human evaluations. Overall,\nthe results of these evaluations suggest that rule-based systems with simple\nrule sets achieve on-par or better performance on both datasets compared to\nstate-of-the-art neural REG systems. In the case of the more realistic dataset,\nWSJ, a machine learning-based system with well-designed linguistic features\nperformed best. We hope that our work can encourage researchers to consider\nnon-neural models in future.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Fahime Same",
      "Guanyi Chen",
      "Kees van Deemter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08274"
  },
  {
    "id": "arXiv:2203.08277",
    "title": "Bi-Manual Manipulation and Attachment via Sim-to-Real Reinforcement  Learning",
    "abstract": "Most successes in robotic manipulation have been restricted to single-arm\nrobots, which limits the range of solvable tasks to pick-and-place, insertion,\nand objects rearrangement. In contrast, dual and multi arm robot platforms\nunlock a rich diversity of problems that can be tackled, such as laundry\nfolding and executing cooking skills. However, developing controllers for\nmulti-arm robots is complexified by a number of unique challenges, such as the\nneed for coordinated bimanual behaviors, and collision avoidance amongst\nrobots. Given these challenges, in this work we study how to solve bi-manual\ntasks using reinforcement learning (RL) trained in simulation, such that the\nresulting policies can be executed on real robotic platforms. Our RL approach\nresults in significant simplifications due to using real-time (4Hz) joint-space\ncontrol and directly passing unfiltered observations to neural networks\npolicies. We also extensively discuss modifications to our simulated\nenvironment which lead to effective training of RL policies. In addition to\ndesigning control algorithms, a key challenge is how to design fair evaluation\ntasks for bi-manual robots that stress bimanual coordination, while removing\northogonal complicating factors such as high-level perception. In this work, we\ndesign a Connect Task, where the aim is for two robot arms to pick up and\nattach two blocks with magnetic connection points. We validate our approach\nwith two xArm6 robots and 3D printed blocks with magnetic attachments, and find\nthat our system has 100% success rate at picking up blocks, and 65% success\nrate at the Connect Task.",
    "descriptor": "\nComments: Our accompanying project webpage can be found at: this https URL\n",
    "authors": [
      "Satoshi Kataoka",
      "Seyed Kamyar Seyed Ghasemipour",
      "Daniel Freeman",
      "Igor Mordatch"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08277"
  },
  {
    "id": "arXiv:2203.08280",
    "title": "Data Transfer and Network Services management for Domain Science  Workflows",
    "abstract": "This paper describes a vision and work in progress to elevate network\nresources and data transfer management to the same level as compute and storage\nin the context of services access, scheduling, life cycle management, and\norchestration. While domain science workflows often include active compute\nresource allocation and management, the data transfers and associated network\nresource coordination is not handled in a similar manner. As a result data\ntransfers can introduce a degree of uncertainty in workflow operations, and the\nassociated lack of network information does not allow for either the workflow\noperations or the network use to be optimized. The net result is that domain\nscience workflow processes are forced to view the network as an opaque\ninfrastructure into which they inject data and hope that it emerges at the\ndestination with an acceptable Quality of Experience. There is little ability\nfor applications to interact with the network to exchange information,\nnegotiate performance parameters, discover expected performance metrics, or\nreceive status/troubleshooting information in real time. Developing mechanisms\nto allow an application workflow to obtain information regarding the network\nservices, capabilities, and options, to a degree similar to what is possible\nfor compute resources is the primary motivation for this work. The initial\nfocus is on the Open Science Grid (OSG)/Compact Muon Solenoid (CMS) Large\nHadron Collider (LHC) workflows with Rucio/FTS/XRootD based data transfers and\nthe interoperation with the ESnet SENSE (Software-Defined Network for\nEnd-to-end Networked Science at the Exascale) system.",
    "descriptor": "\nComments: contribution to Snowmass 2022\n",
    "authors": [
      "Tom Lehman",
      "Xi Yang",
      "Chin Guok",
      "Frank Wuerthwein",
      "Igor Sfiligoi",
      "John Graham",
      "Aashay Arora",
      "Dima Mishin",
      "Diego Davila",
      "Jonathan Guiang",
      "Tom Hutton",
      "Harvey Newman",
      "Justas Balcas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.08280"
  },
  {
    "id": "arXiv:2203.08284",
    "title": "A Personal Computer for a Distrustful World",
    "abstract": "Personal computer owners often want to be able to run security-critical\nprograms on the same machine as other untrusted and potentially malicious\nprograms. While ostensibly trivial, this requires users to trust hardware and\nsystem software to correctly sandbox malicious programs, trust that is often\nmisplaced. Our goal is to minimize the number and complexity of hardware and\nsoftware components that a computer owner needs to trust to withstand\nadversarial inputs. We present a hardware design, called the split-trust\nmachine model, which is composed of statically-partitioned, physically-isolated\ntrust domains. We introduce a few simple, formally-verified hardware components\nto enable a program to gain provably exclusive and simultaneous access to both\ncomputation and I/O on a temporary basis. To manage this hardware, we present\nOctopOS, an OS composed of mutually distrustful subsystems.\nWe present a prototype of this machine (hardware and OS) on a CPU-FPGA board\nand show that it incurs a small hardware cost compared to modern SoCs. For\nsecurity-critical programs, we show that this machine significantly reduces the\nrequired trust compared to mainstream TEEs, and for normal programs, we show\nthat it achieves similar performance as a legacy machine.",
    "descriptor": "",
    "authors": [
      "Zhihao Yao",
      "Seyed Mohammadjavad Seyed Talebi",
      "Mingyi Chen",
      "Ardalan Amiri Sani",
      "Thomas Anderson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2203.08284"
  },
  {
    "id": "arXiv:2203.08287",
    "title": "LPV sequential loop closing for high-precision motion systems",
    "abstract": "Increasingly stringent throughput requirements in the industry necessitate\nthe need for lightweight design of high-precision motion systems to allow for\nhigh accelerations, while still achieving accurate positioning of the\nmoving-body. The presence of position dependent dynamics in such motion systems\nseverely limits achievable position tracking performance using conventional\nsequential loop closing (SLC) control design strategies. This paper presents a\nnovel extension of the conventional SLC design framework towards\nlinear-parameter-varying systems, which allows to circumvent limitations that\nare introduced by position dependent effects in high-precision motion systems.\nAdvantages of the proposed control design approach are demonstrated in\nsimulation using a high-fidelity model of a moving-magnet planar actuator\nsystem, which exhibits position dependency in both actuation and sensing.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Yorick Broens",
      "Hans Butler",
      "Roland T\u00f3th"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08287"
  },
  {
    "id": "arXiv:2203.08289",
    "title": "Driving Anomaly Detection Using Conditional Generative Adversarial  Network",
    "abstract": "Anomaly driving detection is an important problem in advanced driver\nassistance systems (ADAS). It is important to identify potential hazard\nscenarios as early as possible to avoid potential accidents. This study\nproposes an unsupervised method to quantify driving anomalies using a\nconditional generative adversarial network (GAN). The approach predicts\nupcoming driving scenarios by conditioning the models on the previously\nobserved signals. The system uses the difference of the output from the\ndiscriminator between the predicted and actual signals as a metric to quantify\nthe anomaly degree of a driving segment. We take a driver-centric approach,\nconsidering physiological signals from the driver and controller area\nnetwork-Bus (CAN-Bus) signals from the vehicle. The approach is implemented\nwith convolutional neural networks (CNNs) to extract discriminative feature\nrepresentations, and with long short-term memory (LSTM) cells to capture\ntemporal information. The study is implemented and evaluated with the driving\nanomaly dataset (DAD), which includes 250 hours of naturalistic recordings\nmanually annotated with driving events. The experimental results reveal that\nrecordings annotated with events that are likely to be anomalous, such as\navoiding on-road pedestrians and traffic rule violations, have higher anomaly\nscores than recordings without any event annotation. The results are validated\nwith perceptual evaluations, where annotators are asked to assess the risk and\nfamiliarity of the videos detected with high anomaly scores. The results\nindicate that the driving segments with higher anomaly scores are more risky\nand less regularly seen on the road than other driving segments, validating the\nproposed unsupervised approach.",
    "descriptor": "\nComments: 15 pages, 14 figures, 6 tables\n",
    "authors": [
      "Yuning Qiu",
      "Teruhisa Misu",
      "Carlos Busso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08289"
  },
  {
    "id": "arXiv:2203.08295",
    "title": "Self-Distribution Distillation: Efficient Uncertainty Estimation",
    "abstract": "Deep learning is increasingly being applied in safety-critical domains. For\nthese scenarios it is important to know the level of uncertainty in a model's\nprediction to ensure appropriate decisions are made by the system. Deep\nensembles are the de-facto standard approach to obtaining various measures of\nuncertainty. However, ensembles often significantly increase the resources\nrequired in the training and/or deployment phases. Approaches have been\ndeveloped that typically address the costs in one of these phases. In this work\nwe propose a novel training approach, self-distribution distillation (S2D),\nwhich is able to efficiently train a single model that can estimate\nuncertainties. Furthermore it is possible to build ensembles of these models\nand apply hierarchical ensemble distillation approaches. Experiments on\nCIFAR-100 showed that S2D models outperformed standard models and Monte-Carlo\ndropout. Additional out-of-distribution detection experiments on LSUN, Tiny\nImageNet, SVHN showed that even a standard deep ensemble can be outperformed\nusing S2D based ensembles and novel distilled models.",
    "descriptor": "\nComments: 17 pages, 3 figures, 17 tables, submitted to UAI 2022\n",
    "authors": [
      "Yassir Fathullah",
      "Mark J. F. Gales"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08295"
  },
  {
    "id": "arXiv:2203.08299",
    "title": "FastKASSIM: A Fast Tree Kernel-Based Syntactic Similarity Metric",
    "abstract": "Syntax is a fundamental component of language, yet few metrics have been\nemployed to capture syntactic similarity or coherence at the utterance- and\ndocument-level. The existing standard document-level syntactic similarity\nmetric is computationally expensive and performs inconsistently when faced with\nsyntactically dissimilar documents. To address these challenges, we present\nFastKASSIM, a metric for utterance- and document-level syntactic similarity\nwhich pairs and averages the most similar dependency parse trees between a pair\nof documents based on tree kernels. FastKASSIM is more robust to syntactic\ndissimilarities and differences in length, and runs up to to 5.2 times faster\nthan our baseline method over the documents in the r/ChangeMyView corpus.",
    "descriptor": "\nComments: 12 pages, 7 figures. code will be shared at this https URL\n",
    "authors": [
      "Maximillian Chen",
      "Caitlyn Chen",
      "Xiao Yu",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08299"
  },
  {
    "id": "arXiv:2203.08302",
    "title": "SoK: Why Have Defenses against Social Engineering Attacks Achieved  Limited Success?",
    "abstract": "Social engineering attacks are a major cyber threat because they often serve\nas a first step for an attacker to break into an otherwise well-defended\nnetwork, steal victims' credentials, and cause financial losses. The problem\nhas received due amount of attention with many publications proposing defenses\nagainst them. Despite this, the situation has not improved. In this SoK paper,\nwe aim to understand and explain this phenomenon by looking into the root cause\nof the problem. To this end, we examine the literature on attacks and defenses\nthrough a unique lens we propose -- {\\em psychological factors (PFs) and\ntechniques (PTs)}. We find that there is a big discrepancy between attacks and\ndefenses: Attacks have deliberately exploited PFs by leveraging PTs, but\ndefenses rarely take either of these into consideration, preferring technical\nsolutions. This explains why existing defenses have achieved limited success.\nThis prompts us to propose a roadmap for a more systematic approach towards\ndesigning effective defenses against social engineering attacks.",
    "descriptor": "",
    "authors": [
      "Theodore Longtchi",
      "Rosana Monta\u00f1ez Rodriguez",
      "Laith Al-Shawaf",
      "Adham Atyabi",
      "Shouhuai Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.08302"
  },
  {
    "id": "arXiv:2203.08303",
    "title": "Pinning Fault Mode Modeling for DWM Shifting",
    "abstract": "Extreme scaling for purposes of achieving higher density and lower energy\ncontinues to increase the probability of memory faults. For domain wall (DW)\nmemories, misalignment faults arise when aligning domains with access points. A\npreviously understudied type of shifting fault, a pinning fault may occur due\nto non-uniform pinning potential distribution caused by notches with\nfabrication imperfections. This non-uniformity can pin a wall during\ncurrent-induced DW motion. This paper provides a model of geometric variations\nvarying width, depth, and curvature variations of a notch, their impacts on the\ncritical shift current, and a study of the resulting impact on fault rates of\nDW memory systems. An increase in the effective critical shift current due to\n5% variation predicts a pinning fault rate on the order of $10^{-8}$ per shift,\nwhich results in a mean-time-to-failure of circa 2s for a DW memory system.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Kawsher Roxy",
      "Stephen Longofono",
      "Sebastien Olliver",
      "Sanjukta Bhanja",
      "Alex K. Jones"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.08303"
  },
  {
    "id": "arXiv:2203.08304",
    "title": "Hyperdecoders: Instance-specific decoders for multi-task NLP",
    "abstract": "We investigate input-conditioned hypernetworks for multi-tasking in NLP,\ngenerating parameter-efficient adaptations for a decoder using a hypernetwork\nconditioned on the output of an encoder. This approach produces a unique\ndecoder for every input instance, allowing the network a larger degree of\nflexibility than prior work that specializes the decoder for each task. We\napply our method to sequence classification tasks, extractive QA, and\nsummarisation and find that it often outperforms fully finetuning the\nunderlying model and surpasses previous parameter efficient fine-tuning\nmethods. Gains are particularly large when evaluated out-of-domain on the MRQA\nbenchmark. In addition, as the pretrained model is frozen, our method\neliminates negative interference among unrelated tasks, a common failure mode\nin fully fine-tuned approaches. An analysis of the embeddings produced by our\nmodel suggests that a large benefit of our approach is allowing the encoder\nmore effective control over the decoder, allowing mapping from hidden\nrepresentations to a final text-based label without interference from other\ntasks' output formats or labels.",
    "descriptor": "",
    "authors": [
      "Hamish Ivison",
      "Matthew E. Peters"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08304"
  },
  {
    "id": "arXiv:2203.08307",
    "title": "Improving Word Translation via Two-Stage Contrastive Learning",
    "abstract": "Word translation or bilingual lexicon induction (BLI) is a key cross-lingual\ntask, aiming to bridge the lexical gap between different languages. In this\nwork, we propose a robust and effective two-stage contrastive learning\nframework for the BLI task. At Stage C1, we propose to refine standard\ncross-lingual linear maps between static word embeddings (WEs) via a\ncontrastive learning objective; we also show how to integrate it into the\nself-learning procedure for even more refined cross-lingual maps. In Stage C2,\nwe conduct BLI-oriented contrastive fine-tuning of mBERT, unlocking its word\ntranslation capability. We also show that static WEs induced from the\n`C2-tuned' mBERT complement static WEs from Stage C1. Comprehensive experiments\non standard BLI datasets for diverse languages and different experimental\nsetups demonstrate substantial gains achieved by our framework. While the BLI\nmethod from Stage C1 already yields substantial gains over all state-of-the-art\nBLI methods in our comparison, even stronger improvements are met with the full\ntwo-stage framework: e.g., we report gains for 112/112 BLI setups, spanning 28\nlanguage pairs.",
    "descriptor": "\nComments: ACL 2022 Main\n",
    "authors": [
      "Yaoyiran Li",
      "Fangyu Liu",
      "Nigel Collier",
      "Anna Korhonen",
      "Ivan Vuli\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08307"
  },
  {
    "id": "arXiv:2203.08308",
    "title": "Multilingual Generative Language Models for Zero-Shot Cross-Lingual  Event Argument Extraction",
    "abstract": "We present a study on leveraging multilingual pre-trained generative language\nmodels for zero-shot cross-lingual event argument extraction (EAE). By\nformulating EAE as a language generation task, our method effectively encodes\nevent structures and captures the dependencies between arguments. We design\nlanguage-agnostic templates to represent the event argument structures, which\nare compatible with any language, hence facilitating the cross-lingual\ntransfer. Our proposed model finetunes multilingual pre-trained generative\nlanguage models to generate sentences that fill in the language-agnostic\ntemplate with arguments extracted from the input passage. The model is trained\non source languages and is then directly applied to target languages for event\nargument extraction. Experiments demonstrate that the proposed model\noutperforms the current state-of-the-art models on zero-shot cross-lingual EAE.\nComprehensive studies and error analyses are presented to better understand the\nadvantages and the current limitations of using generative language models for\nzero-shot cross-lingual transfer EAE.",
    "descriptor": "\nComments: ACL 2022. Our code is available at this https URL\n",
    "authors": [
      "Kuan-Hao Huang",
      "I-Hung Hsu",
      "Premkumar Natarajan",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08308"
  },
  {
    "id": "arXiv:2203.08314",
    "title": "Cicero: A Declarative Grammar for Responsive Visualization",
    "abstract": "Designing responsive visualizations can be cast as applying transformations\nto a source view to render it suitable for a different screen size. However,\ndesigning responsive visualizations is often tedious as authors must manually\napply and reason about candidate transformations. We present Cicero, a\ndeclarative grammar for concisely specifying responsive visualization\ntransformations which paves the way for more intelligent responsive\nvisualization authoring tools. Cicero's flexible specifier syntax allows\nauthors to select visualization elements to transform, independent of the\nsource view's structure. Cicero encodes a concise set of actions to encode a\ndiverse set of transformations in both desktop-first and mobile-first design\nprocesses. Authors can ultimately reuse design-agnostic transformations across\ndifferent visualizations. To demonstrate the utility of Cicero, we develop a\ncompiler to an extended version of Vega-Lite, and provide principles for our\ncompiler. We further discuss the incorporation of Cicero into responsive\nvisualization authoring tools, such as a design recommender.",
    "descriptor": "\nComments: 14 pages, 15 figures, accepted to CHI 2022\n",
    "authors": [
      "Hyeok Kim",
      "Ryan Rossi",
      "Fan Du",
      "Eunyee Koh",
      "Shunan Guo",
      "Jessica Hullman",
      "Jane Hoffswell"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.08314"
  },
  {
    "id": "arXiv:2203.08320",
    "title": "Two Approaches to Survival Analysis of Open Source Python Projects",
    "abstract": "A recent study applied frequentist survival analysis methods to a subset of\nthe Software Heritage Graph and determined which attributes of an OSS project\ncontribute to its health. This paper serves as an exact replication of that\nstudy. In addition, Bayesian survival analysis methods were applied to the same\ndataset, and an additional project attribute was studied to serve as a\nconceptual replication. Both analyses focus on the effects of certain\nattributes on the survival of open-source software projects as measured by\ntheir revision activity. Methods such as the Kaplan-Meier estimator, Cox\nProportional-Hazards model, and the visualization of posterior survival\nfunctions were used for each of the project attributes. The results show that\nprojects which publish major releases, have repositories on multiple hosting\nservices, possess a large team of developers, and make frequent revisions have\na higher likelihood of survival in the long run. The findings were similar to\nthe original study; however, a deeper look revealed quantitative\ninconsistencies.",
    "descriptor": "\nComments: 9 pages, 5 figures, to be published at ICPC 2022\n",
    "authors": [
      "Derek Robinson",
      "Keanelek Enns",
      "Neha Koulecar",
      "Manish Sihag"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.08320"
  },
  {
    "id": "arXiv:2203.08321",
    "title": "ADATIME: A Benchmarking Suite for Domain Adaptation on Time Series Data",
    "abstract": "Unsupervised domain adaptation methods aim to generalize well on unlabeled\ntest data that may have a different (shifted) distribution from the training\ndata. Such methods are typically developed on image data, and their application\nto time series data is less explored. Existing works on time series domain\nadaptation suffer from inconsistencies in evaluation schemes, datasets, and\nbackbone neural network architectures. Moreover, labeled target data are\nusually employed for model selection, which violates the fundamental assumption\nof unsupervised domain adaptation. To address these issues, we develop a\nbenchmarking evaluation suite (ADATIME) to systematically and fairly evaluate\ndifferent domain adaptation methods on time series data. Specifically, we\nstandardize the backbone neural network architectures and benchmarking\ndatasets, while also exploring more realistic model selection approaches that\ncan work with no labeled data or just few labeled samples. Our evaluation\nincludes adapting state-of-the-art visual domain adaptation methods to time\nseries data in addition to the recent methods specifically developed for time\nseries data. We conduct extensive experiments to evaluate 10 state-of-the-art\nmethods on four representative datasets spanning 20 cross-domain scenarios. Our\nresults suggest that with careful selection of hyper-parameters, visual domain\nadaptation methods are competitive with methods proposed for time series domain\nadaptation. In addition, we find that hyper-parameters could be selected based\non realistic model selection approaches. Our work unveils practical insights\nfor applying domain adaptation methods on time series data and builds a solid\nfoundation for future works in the field. The code is available at\n\\href{https://github.com/emadeldeen24/AdaTime}{github.com/emadeldeen24/AdaTime}.",
    "descriptor": "\nComments: Under Review. The main paper is 16 pages, and the supplementary is 9 pages\n",
    "authors": [
      "Mohamed Ragab",
      "Emadeldeen Eldele",
      "Wee Ling Tan",
      "Chuan-Sheng Foo",
      "Zhenghua Chen",
      "Min Wu",
      "Chee-Keong Kwoh",
      "Xiaoli Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08321"
  },
  {
    "id": "arXiv:2203.08327",
    "title": "Motif Mining: Finding and Summarizing Remixed Image Content",
    "abstract": "On the internet, images are no longer static; they have become dynamic\ncontent. Thanks to the availability of smartphones with cameras and easy-to-use\nediting software, images can be remixed (i.e., redacted, edited, and recombined\nwith other content) on-the-fly and with a world-wide audience that can repeat\nthe process. From digital art to memes, the evolution of images through time is\nnow an important topic of study for digital humanists, social scientists, and\nmedia forensics specialists. However, because typical data sets in computer\nvision are composed of static content, the development of automated algorithms\nto analyze remixed content has been limited. In this paper, we introduce the\nidea of Motif Mining - the process of finding and summarizing remixed image\ncontent in large collections of unlabeled and unsorted data. In this paper,\nthis idea is formalized and a reference implementation is introduced.\nExperiments are conducted on three meme-style data sets, including a newly\ncollected set associated with the information war in the Russo-Ukrainian\nconflict. The proposed motif mining approach is able to identify related\nremixed content that, when compared to similar approaches, more closely aligns\nwith the preferences and expectations of human observers.",
    "descriptor": "\nComments: 41 pages, 21 figures\n",
    "authors": [
      "William Theisen",
      "Daniel Gonzalez",
      "Zachariah Carmichael",
      "Daniel Moreira",
      "Tim Weninger",
      "Walter Scheirer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.08327"
  },
  {
    "id": "arXiv:2203.08328",
    "title": "Tight Lower Bounds for Approximate & Exact $k$-Center in $\\mathbb{R}^d$",
    "abstract": "In the discrete $k$-center problem, we are given a metric space\n$(P,\\texttt{dist})$ where $|P|=n$ and the goal is to select a set $C\\subseteq\nP$ of $k$ centers which minimizes the maximum distance of a point in $P$ from\nits nearest center. For any $\\epsilon>0$, Agarwal and Procopiuc [SODA '98,\nAlgorithmica '02] designed an $(1+\\epsilon)$-approximation algorithm for this\nproblem in $d$-dimensional Euclidean space which runs in $O(dn\\log k) +\n\\left(\\dfrac{k}{\\epsilon}\\right)^{O\\left(k^{1-1/d}\\right)}\\cdot n^{O(1)}$ time.\nIn this paper we show that their algorithm is essentially optimal: if for some\n$d\\geq 2$ and some computable function $f$, there is an $f(k)\\cdot\n\\left(\\dfrac{1}{\\epsilon}\\right)^{o\\left(k^{1-1/d}\\right)} \\cdot\nn^{o\\left(k^{1-1/d}\\right)}$ time algorithm for $(1+\\epsilon)$-approximating\nthe discrete $k$-center on $n$ points in $d$-dimensional Euclidean space then\nthe Exponential Time Hypothesis (ETH) fails.\nWe obtain our lower bound by designing a gap reduction from a $d$-dimensional\nconstraint satisfaction problem (CSP) defined by Marx and Sidiropoulos [SoCG\n'14] to discrete $d$-dimensional $k$-center. As a byproduct of our reduction,\nwe also obtain that the exact algorithm of Agarwal and Procopiuc [SODA '98,\nAlgorithmica '02] which runs in $n^{O\\left(d\\cdot k^{1-1/d}\\right)}$ time for\ndiscrete $k$-center on $n$ points in $d$-dimensional Euclidean space is\nasymptotically optimal. Formally, we show that if for some $d\\geq 2$ and some\ncomputable function $f$, there is an $f(k)\\cdot n^{o\\left(k^{1-1/d}\\right)}$\ntime exact algorithm for the discrete $k$-center problem on $n$ points in\n$d$-dimensional Euclidean space then the Exponential Time Hypothesis (ETH)\nfails. Previously, such a lower bound was only known for $d=2$ and was implicit\nin the work of Marx [IWPEC '06].\n[see paper for full abstract]",
    "descriptor": "\nComments: Extended abstract in SoCG 2022\n",
    "authors": [
      "Rajesh Chitnis",
      "Nitin Saurabh"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.08328"
  },
  {
    "id": "arXiv:2203.08332",
    "title": "WeakM3D: Towards Weakly Supervised Monocular 3D Object Detection",
    "abstract": "Monocular 3D object detection is one of the most challenging tasks in 3D\nscene understanding. Due to the ill-posed nature of monocular imagery, existing\nmonocular 3D detection methods highly rely on training with the manually\nannotated 3D box labels on the LiDAR point clouds. This annotation process is\nvery laborious and expensive. To dispense with the reliance on 3D box labels,\nin this paper we explore the weakly supervised monocular 3D detection.\nSpecifically, we first detect 2D boxes on the image. Then, we adopt the\ngenerated 2D boxes to select corresponding RoI LiDAR points as the weak\nsupervision. Eventually, we adopt a network to predict 3D boxes which can\ntightly align with associated RoI LiDAR points. This network is learned by\nminimizing our newly-proposed 3D alignment loss between the 3D box estimates\nand the corresponding RoI LiDAR points. We will illustrate the potential\nchallenges of the above learning problem and resolve these challenges by\nintroducing several effective designs into our method. Codes will be available\nat https://github.com/SPengLiang/WeakM3D.",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Liang Peng",
      "Senbo Yan",
      "Boxi Wu",
      "Zheng Yang",
      "Xiaofei He",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08332"
  },
  {
    "id": "arXiv:2203.08334",
    "title": "Arithmetic Averages of Viscosity Coefficient are Sufficient for  Second-Order Finite-Volume Viscous Discretization on Unstructured Grids",
    "abstract": "In this short note, we discuss the use of arithmetic averages for the\nevaluation of viscous coefficients such as temperature and velocity components\nat a face as required in a cell-centered finite-volume viscous discretization\non unstructured grids, and show that second-order accuracy can be achieved even\nwhen the arithmetic average is not linearly-exact second-order reconstruction\nat a face center (e.g., the face center is not located exactly halfway between\ntwo adjacent cell centroids) as typical in unstructured grids. Unlike inviscid\ndiscretizations, where the solution has to be reconstructed in a linearly exact\nmanner to the face center for second-order accuracy, the viscous discretization\ndoes not require the linear exactness for computing viscous coefficients at a\nface. There are two requirements for second-order accuracy, and the arithmetic\naverage satisfies both of them. Second-order accuracy is numerically\ndemonstrated for a simple one-dimensional nonlinear diffusion problem and for a\nthree-dimensional viscous problem based on methods of manufactured solutions.",
    "descriptor": "",
    "authors": [
      "Hiroaki Nishikawa",
      "Boris Diskin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.08334"
  },
  {
    "id": "arXiv:2203.08339",
    "title": "NURD: Negative-Unlabeled Learning for Online Datacenter Straggler  Prediction",
    "abstract": "Datacenters execute large computational jobs, which are composed of smaller\ntasks. A job completes when all its tasks finish, so stragglers -- rare, yet\nextremely slow tasks -- are a major impediment to datacenter performance.\nAccurately predicting stragglers would enable proactive intervention, allowing\ndatacenter operators to mitigate stragglers before they delay a job. While much\nprior work applies machine learning to predict computer system performance,\nthese approaches rely on complete labels -- i.e., sufficient examples of all\npossible behaviors, including straggling and non-straggling -- or strong\nassumptions about the underlying latency distributions -- e.g., whether\nGaussian or not. Within a running job, however, none of this information is\navailable until stragglers have revealed themselves when they have already\ndelayed the job. To predict stragglers accurately and early without labeled\npositive examples or assumptions on latency distributions, this paper presents\nNURD, a novel Negative-Unlabeled learning approach with Reweighting and\nDistribution-compensation that only trains on negative and unlabeled streaming\ndata. The key idea is to train a predictor using finished tasks of\nnon-stragglers to predict latency for unlabeled running tasks, and then\nreweight each unlabeled task's prediction based on a weighting function of its\nfeature space. We evaluate NURD on two production traces from Google and\nAlibaba, and find that compared to the best baseline approach, NURD produces\n2--11 percentage point increases in the F1 score in terms of prediction\naccuracy, and 4.7--8.8 percentage point improvements in job completion time.",
    "descriptor": "",
    "authors": [
      "Yi Ding",
      "Avinash Rao",
      "Hyebin Song",
      "Rebecca Willett",
      "Henry Hoffmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.08339"
  },
  {
    "id": "arXiv:2203.08340",
    "title": "Adaptive Noisy Matrix Completion",
    "abstract": "Low-rank matrix completion has been studied extensively under various type of\ncategories. The problem could be categorized as noisy completion or exact\ncompletion, also active or passive completion algorithms. In this paper we\nfocus on adaptive matrix completion with bounded type of noise. We assume that\nthe matrix $\\mathbf{M}$ we target to recover is composed as low-rank matrix\nwith addition of bounded small noise. The problem has been previously studied\nby \\cite{nina}, in a fixed sampling model. Here, we study this problem in\nadaptive setting that, we continuously estimate an upper bound for the angle\nwith the underlying low-rank subspace and noise-added subspace. Moreover, the\nmethod suggested here, could be shown requires much smaller observation than\naforementioned method.",
    "descriptor": "",
    "authors": [
      "Ilqar Ramazanli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08340"
  },
  {
    "id": "arXiv:2203.08343",
    "title": "Design and Evaluation of an Augmented Reality Head-Mounted Display  Interface for Human Robot Teams Collaborating in Physically Shared  Manufacturing Tasks",
    "abstract": "We provide an experimental evaluation of a wearable augmented reality (AR)\nsystem we have developed for human-robot teams working on tasks requiring\ncollaboration in shared physical workspace. Recent advances in AR technology\nhave facilitated the development of more intuitive user interfaces for many\nhuman-robot interaction applications. While it has been anticipated that AR can\nprovided a more intuitive interface to robot assistants helping human workers\nin various manufacturing scenarios, existing studies in robotics have been\nlargely limited to teleoperation and programming. Industry 5.0 envisions\ncooperation between human and robot working in teams. Indeed, there exist many\nindustrial task that can benefit from human-robot collaboration. A prime\nexample is high-value composite manufacturing. Working with our industry\npartner towards this example application, we evaluated our AR interface design\nfor shared physical workspace collaboration in human-robot teams. We conducted\na multi-dimensional analysis of our interface using establish metrics. Results\nfrom our user study (n=26) show that subjectively, the AR interface feels more\nnovel and a standard joystick interface feels more dependable to users.\nHowever, the AR interface was found to reduce physical demand and task\ncompletion time, while increasing robot utilization. Furthermore, user's\nfreedom of choice to collaborate with the robot may also affect the perceived\nusability of the system.",
    "descriptor": "",
    "authors": [
      "Wesley P Chan",
      "Geoffrey Hanks",
      "Maram Sakr",
      "Haomiao Zhang",
      "Tiger Zuo",
      "H F Machiel Van der Loos",
      "Elizabeth Croft"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08343"
  },
  {
    "id": "arXiv:2203.08344",
    "title": "Domain Adaptive Hand Keypoint and Pixel Localization in the Wild",
    "abstract": "We aim to improve the performance of regressing hand keypoints and segmenting\npixel-level hand masks under new imaging conditions (e.g., outdoors) when we\nonly have labeled images taken under very different conditions (e.g., indoors).\nIn the real world, it is important that the model trained for both tasks works\nunder various imaging conditions. However, their variation covered by existing\nlabeled hand datasets is limited. Thus, it is necessary to adapt the model\ntrained on the labeled images (source) to unlabeled images (target) with unseen\nimaging conditions. While self-training domain adaptation methods (i.e.,\nlearning from the unlabeled target images in a self-supervised manner) have\nbeen developed for both tasks, their training may degrade performance when the\npredictions on the target images are noisy. To avoid this, it is crucial to\nassign a low importance (confidence) weight to the noisy predictions during\nself-training. In this paper, we propose to utilize the divergence of two\npredictions to estimate the confidence of the target image for both tasks.\nThese predictions are given from two separate networks, and their divergence\nhelps identify the noisy predictions. To integrate our proposed confidence\nestimation into self-training, we propose a teacher-student framework where the\ntwo networks (teachers) provide supervision to a network (student) for\nself-training, and the teachers are learned from the student by knowledge\ndistillation. Our experiments show its superiority over state-of-the-art\nmethods in adaptation settings with different lighting, grasping objects,\nbackgrounds, and camera viewpoints. Our method improves by 4% the multi-task\nscore on HO3D compared to the latest adversarial adaptation method. We also\nvalidate our method on Ego4D, egocentric videos with rapid changes in imaging\nconditions outdoors.",
    "descriptor": "",
    "authors": [
      "Takehiko Ohkawa",
      "Yu-Jhe Li",
      "Qichen Fu",
      "Rosuke Furuta",
      "Kris M. Kitani",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08344"
  },
  {
    "id": "arXiv:2203.08345",
    "title": "Gradient Correction beyond Gradient Descent",
    "abstract": "The great success neural networks have achieved is inseparable from the\napplication of gradient-descent (GD) algorithms. Based on GD, many variant\nalgorithms have emerged to improve the GD optimization process. The gradient\nfor back-propagation is apparently the most crucial aspect for the training of\na neural network. The quality of the calculated gradient can be affected by\nmultiple aspects, e.g., noisy data, calculation error, algorithm limitation,\nand so on. To reveal gradient information beyond gradient descent, we introduce\na framework (\\textbf{GCGD}) to perform gradient correction. GCGD consists of\ntwo plug-in modules: 1) inspired by the idea of gradient prediction, we propose\na \\textbf{GC-W} module for weight gradient correction; 2) based on Neural ODE,\nwe propose a \\textbf{GC-ODE} module for hidden states gradient correction.\nExperiment results show that our gradient correction framework can effectively\nimprove the gradient quality to reduce training epochs by $\\sim$ 20\\% and also\nimprove the network performance.",
    "descriptor": "",
    "authors": [
      "Zefan Li",
      "Bingbing Ni",
      "Teng Li",
      "WenJun Zhang",
      "Wen Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08345"
  },
  {
    "id": "arXiv:2203.08351",
    "title": "Towards Afrocentric NLP for African Languages: Where We Are and Where We  Can Go",
    "abstract": "Aligning with ACL 2022 special Theme on \"Language Diversity: from Low\nResource to Endangered Languages\", we discuss the major linguistic and\nsociopolitical challenges facing development of NLP technologies for African\nlanguages. Situating African languages in a typological framework, we discuss\nhow the particulars of these languages can be harnessed. To facilitate future\nresearch, we also highlight current efforts, communities, venues, datasets, and\ntools. Our main objective is to motivate and advocate for an Afrocentric\napproach to technology development. With this in mind, we recommend\n\\textit{what} technologies to build and \\textit{how} to build, evaluate, and\ndeploy them based on the needs of local African communities.",
    "descriptor": "\nComments: Submitted to Main Conference of ACL 2022\n",
    "authors": [
      "Ife Adebara",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08351"
  },
  {
    "id": "arXiv:2203.08354",
    "title": "Represent, Compare, and Learn: A Similarity-Aware Framework for  Class-Agnostic Counting",
    "abstract": "Class-agnostic counting (CAC) aims to count all instances in a query image\ngiven few exemplars. A standard pipeline is to extract visual features from\nexemplars and match them with query images to infer object counts. Two\nessential components in this pipeline are feature representation and similarity\nmetric. Existing methods either adopt a pretrained network to represent\nfeatures or learn a new one, while applying a naive similarity metric with\nfixed inner product. We find this paradigm leads to noisy similarity matching\nand hence harms counting performance. In this work, we propose a\nsimilarity-aware CAC framework that jointly learns representation and\nsimilarity metric. We first instantiate our framework with a naive baseline\ncalled Bilinear Matching Network (BMNet), whose key component is a learnable\nbilinear similarity metric. To further embody the core of our framework, we\nextend BMNet to BMNet+ that models similarity from three aspects: 1)\nrepresenting the instances via their self-similarity to enhance feature\nrobustness against intra-class variations; 2) comparing the similarity\ndynamically to focus on the key patterns of each exemplar; 3) learning from a\nsupervision signal to impose explicit constraints on matching results.\nExtensive experiments on a recent CAC dataset FSC147 show that our models\nsignificantly outperform state-of-the-art CAC approaches. In addition, we also\nvalidate the cross-dataset generality of BMNet and BMNet+ on a car counting\ndataset CARPK. Code is at tiny.one/BMNet",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Min Shi",
      "Hao Lu",
      "Chen Feng",
      "Chengxin Liu",
      "Zhiguo Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08354"
  },
  {
    "id": "arXiv:2203.08355",
    "title": "Metaverse Native Communication: A Blockchain and Spectrum Prospective",
    "abstract": "Metaverse depicts a vista of constructing a virtual environment parallel to\nthe real world so people can communicate with others and objects through\ndigital entities. In the real world, communication relies on identities and\naddresses that are recognized by authorities, no matter the link is established\nvia post, email, mobile phone, or landline. Metaverse, however, is different\nfrom the real world, which requires a single identity belongs to the\nindividual. This identity can be an encrypted virtual address in the metaverse\nbut no one can trace or verify it. In order to achieve such addresses to hide\nindividuals in the metaverse, re-mapping the virtual address to the\nindividual's identity and a specific spectrum to support the address-based\ncommunication for the metaverse are needed. Therefore, metaverse native or\nmeta-native communications based on blockchain could be a promising solution to\ndirectly connect entities with their native encrypted addresses that gets rid\nof the existing network services based on IP, cellular, HTTP, etc. This paper\nproposes a vision of blockchain, encrypted address and address-based access\nmodel for all users, devices, services, etc. to contribute to the metaverse.\nFurthermore, the allocation architecture of a designated spectrum for the\nmetaverse is proposed to remove the barrier to access to the\nmetaverse/blockchain in response to the initiatives of metaverse and\ndecentralized Internet.",
    "descriptor": "",
    "authors": [
      "Hao Xu",
      "Zihao Li",
      "Zongyao Li",
      "Xiaoshuai Zhang",
      "Yao Sun",
      "Lei Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.08355"
  },
  {
    "id": "arXiv:2203.08356",
    "title": "Hardness for Triangle Problems under Even More Believable Hypotheses:  Reductions from Real APSP, Real 3SUM, and OV",
    "abstract": "The $3$SUM hypothesis, the APSP hypothesis and SETH are the three main\nhypotheses in fine-grained complexity. So far, within the area, the first two\nhypotheses have mainly been about integer inputs in the Word RAM model of\ncomputation. The \"Real APSP\" and \"Real $3$SUM\" hypotheses, which assert that\nthe APSP and $3$SUM hypotheses hold for real-valued inputs in a reasonable\nversion of the Real RAM model, are even more believable than their integer\ncounterparts.\nUnder the very believable hypothesis that at least one of the Integer $3$SUM\nhypothesis, Integer APSP hypothesis or SETH is true, Abboud, Vassilevska W. and\nYu [STOC 2015] showed that a problem called Triangle Collection requires\n$n^{3-o(1)}$ time on an $n$-node graph.\nOur main result is a nontrivial lower bound for a slight generalization of\nTriangle Collection, called All-Color-Pairs Triangle Collection, under the even\nmore believable hypothesis that at least one of the Real $3$SUM, the Real APSP,\nand the OV hypotheses is true. Combined with slight modifications of prior\nreductions, we obtain polynomial conditional lower bounds for problems such as\nthe (static) ST-Max Flow problem and dynamic Max Flow, now under the new weaker\nhypothesis.\nOur main result is built on the following two lines of reductions.\n* Real APSP and Real $3$SUM hardness for the All-Edges Sparse Triangle\nproblem. Prior reductions only worked from the integer variants of these\nproblems.\n* Real APSP and OV hardness for a variant of the Boolean Matrix\nMultiplication problem.\nAlong the way we show that Triangle Collection is equivalent to a simpler\nrestricted version of the problem, simplifying prior work. Our techniques also\nhave other interesting implications, such as a super-linear lower bound of\nInteger All-Numbers $3$SUM based on the Real $3$SUM hypothesis, and a tight\nlower bound for a string matching problem based on the OV hypothesis.",
    "descriptor": "\nComments: To appear at STOC'22. Abstract shortened to fit arXiv requirements\n",
    "authors": [
      "Timothy M. Chan",
      "Virginia Vassilevska Williams",
      "Yinzhan Xu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.08356"
  },
  {
    "id": "arXiv:2203.08359",
    "title": "GOMP-ST: Grasp Optimized Motion Planning for Suction Transport",
    "abstract": "Suction cup grasping is very common in industry, but moving too quickly can\ncause suction cups to detach, causing drops or damage. Maintaining a suction\ngrasp throughout a high-speed motion requires balancing suction forces against\ninertial forces while the suction cups deform under strain. In this paper, we\nconsider Grasp Optimized Motion Planning for Suction Transport (GOMP-ST), an\nalgorithm that combines deep learning with optimization to decrease transport\ntime while avoiding suction cup failure. GOMP-ST first repeatedly moves a\nphysical robot, vacuum gripper, and a sample object, while measuring pressure\nwith a solid-state sensor to learn critical failure conditions. Then, these are\nintegrated as constraints on the accelerations at the end-effector into a\ntime-optimizing motion planner. The resulting plans incorporate real-world\neffects such as suction cup deformation that are difficult to model\nanalytically. In GOMP-ST, the learned constraint, modeled with a neural\nnetwork, is linearized using Autograd and integrated into a sequential\nquadratic program optimization. In 420 experiments with a physical UR5\ntransporting objects ranging from 1.3 to 1.7 kg, we compare GOMP-ST to baseline\noptimizing motion planners. Results suggest that GOMP-ST can avoid suction cup\nfailure while decreasing transport times from 16% to 58%. For code, video, and\ndatasets, see https://sites.google.com/view/gomp-st.",
    "descriptor": "\nComments: Yahav Avigal and Jeffrey Ichnowski contributed equally. 18 pages, 8 figures\n",
    "authors": [
      "Yahav Avigal",
      "Jeffrey Ichnowski",
      "Max Yiye Cao",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08359"
  },
  {
    "id": "arXiv:2203.08360",
    "title": "Synthesis of the Supremal Covert Attacker Against Unknown Supervisors by  Using Observations",
    "abstract": "In this paper, we consider the problem of synthesizing the supremal covert\ndamage-reachable attacker under the normality assumption, in the setup where\nthe model of the supervisor is unknown to the adversary but the adversary has\nrecorded a (prefix-closed) finite set of observations of the runs of the\nclosed-loop system. The synthesized attacker needs to ensure both the\ndamage-reachability and the covertness against all the supervisors which are\nconsistent with the given set of observations. There is a gap between the de\nfacto supremality, assuming the model of the supervisor is known, and the\nsupremality that can be attained with a limited knowledge of the model of the\nsupervisor, from the adversary's point of view. We consider the setup where the\nattacker can exercise sensor replacement/deletion attacks and actuator\nenablement/disablement attacks. The solution methodology proposed in this work\nis to reduce the synthesis of the supremal covert damage-reachable attacker,\ngiven the model of the plant and the finite set of observations, to the\nsynthesis of the supremal safe supervisor for certain transformed plant, which\nshows the decidability of the observation-assisted covert attacker synthesis\nproblem. The effectiveness of our approach is illustrated on a water tank\nexample adapted from the literature.",
    "descriptor": "",
    "authors": [
      "Ruochen Tai",
      "Liyong Lin",
      "Yuting Zhu",
      "Rong Su"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08360"
  },
  {
    "id": "arXiv:2203.08362",
    "title": "Spot the Difference: A Cooperative Object-Referring Game in  Non-Perfectly Co-Observable Scene",
    "abstract": "Visual dialog has witnessed great progress after introducing various\nvision-oriented goals into the conversation, especially such as GuessWhich and\nGuessWhat, where the only image is visible by either and both of the questioner\nand the answerer, respectively. Researchers explore more on visual dialog tasks\nin such kind of single- or perfectly co-observable visual scene, while somewhat\nneglect the exploration on tasks of non perfectly co-observable visual scene,\nwhere the images accessed by two agents may not be exactly the same, often\noccurred in practice. Although building common ground in non-perfectly\nco-observable visual scene through conversation is significant for advanced\ndialog agents, the lack of such dialog task and corresponding large-scale\ndataset makes it impossible to carry out in-depth research. To break this\nlimitation, we propose an object-referring game in non-perfectly co-observable\nvisual scene, where the goal is to spot the difference between the similar\nvisual scenes through conversing in natural language. The task addresses\nchallenges of the dialog strategy in non-perfectly co-observable visual scene\nand the ability of categorizing objects. Correspondingly, we construct a\nlarge-scale multimodal dataset, named SpotDiff, which contains 87k Virtual\nReality images and 97k dialogs generated by self-play. Finally, we give\nbenchmark models for this task, and conduct extensive experiments to evaluate\nits performance as well as analyze its main challenges.",
    "descriptor": "",
    "authors": [
      "Duo Zheng",
      "Fandong Meng",
      "Qingyi Si",
      "Hairun Fan",
      "Zipeng Xu",
      "Jie Zhou",
      "Fangxiang Feng",
      "Xiaojie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08362"
  },
  {
    "id": "arXiv:2203.08364",
    "title": "Minimum Height Drawings of Ordered Trees in Polynomial Time: Homotopy  Height of Tree Duals",
    "abstract": "We consider drawings of graphs in the plane in which vertices are assigned\ndistinct points in the plane and edges are drawn as simple curves connecting\nthe vertices and such that the edges intersect only at their common endpoints.\nThere is an intuitive quality measure for drawings of a graph that measures the\nheight of a drawing $\\phi : G \\rightarrow \\mathbb{R}^2$ as follows. For a\nvertical line $\\ell$ in $\\mathbb{R}^2$, let the height of $\\ell$ be the\ncardinality of the set $\\ell \\cap \\phi(G)$. The height of a drawing of $G$ is\nthe maximum height over all vertical lines. In this paper, instead of abstract\ngraphs, we fix a drawing and consider plane graphs. In other words, we are\nlooking for a homeomorphism of the plane that minimizes the height of the\nresulting drawing. This problem is equivalent to the homotopy height problem in\nthe plane, and the homotopic Fr\\'echet distance problem. These problems were\nrecently shown to lie in NP, but no polynomial-time algorithm or NP-hardness\nproof has been found since their formulation in 2009. We present the first\npolynomial-time algorithm for drawing trees with optimal height. This\ncorresponds to a polynomial-time algorithm for the homotopy height where the\ntriangulation has only one vertex (that is, a set of loops incident to a single\nvertex), so that its dual is a tree.",
    "descriptor": "",
    "authors": [
      "Salman Parsa",
      "Tim Ophelders"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.08364"
  },
  {
    "id": "arXiv:2203.08368",
    "title": "Mixed-Precision Neural Network Quantization via Learned Layer-wise  Importance",
    "abstract": "The exponentially large discrete search space in mixed-precision quantization\n(MPQ) makes it hard to determine the optimal bit-width for each layer. Previous\nworks usually resort to iterative search methods on the training set, which\nconsume hundreds or even thousands of GPU-hours. In this study, we reveal that\nsome unique learnable parameters in quantization, namely the scale factors in\nthe quantizer, can serve as importance indicators of a layer, reflecting the\ncontribution of that layer to the final accuracy at certain bit-widths. These\nimportance indicators naturally perceive the numerical transformation during\nquantization-aware training, which can precisely and correctly provide\nquantization sensitivity metrics of layers. However, a deep network always\ncontains hundreds of such indicators, and training them one by one would lead\nto an excessive time cost. To overcome this issue, we propose a joint training\nscheme that can obtain all indicators at once. It considerably speeds up the\nindicators training process by parallelizing the original sequential training\nprocesses. With these learned importance indicators, we formulate the MPQ\nsearch problem as a one-time integer linear programming (ILP) problem. That\navoids the iterative search and significantly reduces search time without\nlimiting the bit-width search space. For example, MPQ search on ResNet18 with\nour indicators takes only 0.06 seconds. Also, extensive experiments show our\napproach can achieve SOTA accuracy on ImageNet for far-ranging models with\nvarious constraints (e.g., BitOps, compress rate).",
    "descriptor": "",
    "authors": [
      "Chen Tang",
      "Kai Ouyang",
      "Zhi Wang",
      "Yifei Zhu",
      "Yaowei Wang",
      "Wen Ji",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08368"
  },
  {
    "id": "arXiv:2203.08370",
    "title": "Physical Layer Security of RIS-Assisted Communications under  Electromagnetic Interference",
    "abstract": "This work investigates the impact of the ever-present electromagnetic\ninterference (EMI) on the achievable secrecy performance of reconfigurable\nintelligent surface (RIS)-aided communication systems. We characterize the\nend-to-end RIS channel by considering key practical aspects such as spatial\ncorrelation, transmit beamforming vector, phase-shift noise, the coexistence of\ndirect and indirect channels, and the presence of strong/mild EMI on the\nreceiver sides. We show that the effect of EMI on secrecy performance strongly\ndepends on the ability of the eavesdropper to cancel such interference; this\nputs forth the potential of EMI-based attacks to degrade physical layer\nsecurity in RIS-aided communications.",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 David Vega S\u00e1nchez",
      "Georges Kaddoum",
      "F. Javier L\u00f3pez-Mart\u00ednez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.08370"
  },
  {
    "id": "arXiv:2203.08371",
    "title": "Real Robot Challenge 2021: Cartesian Position Control with Triangle  Grasp and Trajectory Interpolation",
    "abstract": "We present our runner-up approach for the Real Robot Challenge 2021. We build\nupon our previous approach used in Real Robot Challenge 2020. To solve the task\nof sequential goal-reaching we focus on two aspects to achieving near-optimal\ntrajectory: Grasp stability and Controller performance. In the RRC 2021\nsimulated challenge, our method relied on a hand-designed Pinch grasp combined\nwith Trajectory Interpolation for better stability during the motion for fast\ngoal-reaching. In Stage 1, we observe reverting to a Triangular grasp to\nprovide a more stable grasp when combined with Trajectory Interpolation,\npossibly due to the sim2real gap. The video demonstration for our approach is\navailable at https://youtu.be/dlOueoaRWrM. The code is publicly available at\nhttps://github.com/madan96/benchmark-rrc.",
    "descriptor": "",
    "authors": [
      "Rishabh Madan",
      "Harshit Sikchi",
      "Ethan K. Gordon",
      "Siddhartha Srinivasa",
      "Tapomayukh Bhattacharjee"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08371"
  },
  {
    "id": "arXiv:2203.08372",
    "title": "Multi-View Document Representation Learning for Open-Domain Dense  Retrieval",
    "abstract": "Dense retrieval has achieved impressive advances in first-stage retrieval\nfrom a large-scale document collection, which is built on bi-encoder\narchitecture to produce single vector representation of query and document.\nHowever, a document can usually answer multiple potential queries from\ndifferent views. So the single vector representation of a document is hard to\nmatch with multi-view queries, and faces a semantic mismatch problem. This\npaper proposes a multi-view document representation learning framework, aiming\nto produce multi-view embeddings to represent documents and enforce them to\nalign with different queries. First, we propose a simple yet effective method\nof generating multiple embeddings through viewers. Second, to prevent\nmulti-view embeddings from collapsing to the same one, we further propose a\nglobal-local loss with annealed temperature to encourage the multiple viewers\nto better align with different potential queries. Experiments show our method\noutperforms recent works and achieves state-of-the-art results.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Shunyu Zhang",
      "Yaobo Liang",
      "Ming Gong",
      "Daxin Jiang",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.08372"
  },
  {
    "id": "arXiv:2203.08373",
    "title": "Are you aware of what you are watching? Role of machine heuristic in  online content recommendations",
    "abstract": "Since recommender systems have been created and developed to automate the\nrecommendation process, users can easily consume their desired video content on\nonline platforms. In this line, several content recommendation algorithms are\nintroduced and employed to allow users to encounter content of their interests,\neffectively. However, the recommendation systems sometimes regrettably\nrecommend inappropriate content, including misinformation or fake news. To make\nit worse, people would unreservedly accept such content due to their cognitive\nheuristic, machine heuristic, which is the rule of thumb that machines are more\naccurate and trustworthy than humans. In this study, we designed and conducted\na web-based experiment where the participants are invoked machine heuristic by\nexperiencing the whole process of machine or human recommendation system. The\nresults demonstrated that participants (N = 89) showed a more positive attitude\ntoward a machine recommender than a human recommender, even the recommended\nvideos contain inappropriate content. While participants who have a high level\nof trust in machines exhibited a negative attitude toward recommendations.\nBased on these results, we suggest that a phenomenon known as algorithm\naversion might be simultaneously considered with machine heuristic in\ninvestigating human interaction with a machine.",
    "descriptor": "",
    "authors": [
      "Soyoung Oh",
      "Eunil Park"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.08373"
  },
  {
    "id": "arXiv:2203.08377",
    "title": "RIS Partitioning Based Scalable Beamforming Design for Large-Scale MIMO:  Asymptotic Analysis and Optimization",
    "abstract": "In next-generation wireless networks, reconfigurable intelligent surface\n(RIS)-assisted multiple-input multiple-output (MIMO) systems are foreseeable to\nsupport a large number of antennas at the transceiver as well as a large number\nof reflecting elements at the RIS. To fully unleash the potential of RIS, the\nphase shifts of RIS elements should be carefully designed, resulting in a\nhigh-dimensional non-convex optimization problem that is hard to solve with\naffordable computational complexity. In this paper, we address this scalability\nissue by partitioning RIS into sub-surfaces, so as to optimize the phase shifts\nin sub-surface levels to reduce complexity. Specifically, each sub-surface\nemploys a linear phase variation structure to anomalously reflect the incident\nsignal to a desired direction, and the sizes of sub-surfaces can be adaptively\nadjusted according to channel conditions. We formulate the achievable rate\nmaximization problem by jointly optimizing the transmit covariance matrix and\nthe RIS phase shifts. Then, we characterize the asymptotic behavior of the\nsystem with an infinitely large number of transceiver antennas and RIS\nelements. The asymptotic analysis provides useful insights on the understanding\nof the fundamental performance-complexity tradeoff in RIS partitioning design.\nWe show that the achievable rate maximization problem has a rather simple form\nin the asymptotic regime, and we develop an efficient algorithm to find the\noptimal solution via one-dimensional (1D) search. Moreover, we discuss the\ninsights and impacts of the asymptotically optimal solution on finite-size\nsystem design. By applying the asymptotic result to a finite-size system with\nnecessary modifications, we show by numerical results that the proposed design\nachieves a favorable tradeoff between system performance and computational\ncomplexity.",
    "descriptor": "\nComments: 30 pages, 6 figures\n",
    "authors": [
      "Chang Cai",
      "Xiaojun Yuan",
      "Ying-Jun Angela Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.08377"
  },
  {
    "id": "arXiv:2203.08378",
    "title": "Transforming Sequence Tagging Into A Seq2Seq Task",
    "abstract": "Pretrained, large, generative language models (LMs) have had great success in\na wide range of sequence tagging and structured prediction tasks. Casting a\nsequence tagging task as a Seq2Seq one requires deciding the formats of the\ninput and output sequences. However, we lack a principled understanding of the\ntrade-offs associated with these formats (such as the effect on model accuracy,\nsequence length, multilingual generalization, hallucination). In this paper, we\nrigorously study different formats one could use for casting input text\nsentences and their output labels into the input and target (i.e., output) of a\nSeq2Seq model. Along the way, we introduce a new format, which we show to not\nonly be simpler but also more effective. Additionally the new format\ndemonstrates significant gains in the multilingual settings -- both zero-shot\ntransfer learning and joint training. Lastly, we find that the new format is\nmore robust and almost completely devoid of hallucination -- an issue we find\ncommon in existing formats. With well over a 1000 experiments studying 14\ndifferent formats, over 7 diverse public benchmarks -- including 3 multilingual\ndatasets spanning 7 languages -- we believe our findings provide a strong\nempirical basis in understanding how we should tackle sequence tagging tasks.",
    "descriptor": "",
    "authors": [
      "Karthik Raman",
      "Iftekhar Naim",
      "Jiecao Chen",
      "Kazuma Hashimoto",
      "Kiran Yalasangi",
      "Krishna Srinivasan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08378"
  },
  {
    "id": "arXiv:2203.08380",
    "title": "Fast operator splitting methods for obstacle problems",
    "abstract": "The obstacle problem is a class of free boundary problems which finds\napplications in many disciplines such as porous media, financial mathematics\nand optimal control. In this paper, we propose two operator-splitting methods\nto solve the linear and nonlinear obstacle problems. The proposed methods have\nthree ingredients: (i) Utilize an indicator function to formularize the\nconstrained problem as an unconstrained problem, and associate it to an initial\nvalue problem. The obstacle problem is then converted to solving for the steady\nstate solution of an initial value problem. (ii) An operator-splitting strategy\nto time discretize the initial value problem. After splitting, a heat equation\nwith obstacles is solved and other subproblems either have explicit solutions\nor can be solved efficiently. (iii) A new constrained alternating direction\nexplicit method, a fully explicit method, to solve heat equations with\nobstacles. The proposed methods are easy to implement, do not require to solve\nany linear systems and are more efficient than existing numerical methods while\nkeeping similar accuracy. Extensions of the proposed methods to related free\nboundary problems are also discussed.",
    "descriptor": "",
    "authors": [
      "Hao Liu",
      "Dong Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08380"
  },
  {
    "id": "arXiv:2203.08381",
    "title": "Optimization of ARQ Distribution for HARQ Strategies in Delay-Bounded  Networks",
    "abstract": "Inspired by several delay-bounded mission-critical applications, optimizing\nthe end-to-end reliability of multi-hop networks is an important problem\nsubject to end-to-end delay constraints on the packets. Towards that direction,\nAutomatic Repeat Request (ARQ) based strategies have been recently proposed\nwherein the problem statement is to distribute a certain total number of ARQs\n(that capture end-to-end delay) across the nodes such that the end-to-end\nreliability is optimized. Although such strategies provide a fine control to\ntrade end-to-end delay with end-to-end reliability, their performance degrades\nin slowly-varying channel conditions. Pointing at this drawback, in this work,\nwe propose a Chase Combing Hybrid ARQ (CC-HARQ) based multi-hop network\naddressing the problem statement of how to distribute a certain total number of\nARQs such that the end-to-end reliability is optimized. Towards solving the\nproblem, first we identify that the objective function of the optimization\nproblem is intractable due to the presence of Marcum-Q functions in it. As a\nresult, we propose an approximation on the objective function and then prove a\nset of necessary and sufficient conditions on the near-optimal ARQ\ndistribution. Subsequently, we propose a low-complexity algorithm to solve the\nproblem for any network size. We show that CC-HARQ based strategies are\nparticularly appealing in slow-fading channels wherein the existing ARQ\nstrategies fail.",
    "descriptor": "\nComments: 7 pages with 4 figures\n",
    "authors": [
      "Jaya Goel",
      "J. Harshan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.08381"
  },
  {
    "id": "arXiv:2203.08382",
    "title": "Dual Diffusion Implicit Bridges for Image-to-Image Translation",
    "abstract": "Common image-to-image translation methods rely on joint training over data\nfrom both source and target domains. This excludes cases where domain data is\nprivate (e.g., in a federated setting), and often means that a new model has to\nbe trained for a new pair of domains. We present Dual Diffusion Implicit\nBridges (DDIBs), an image translation method based on diffusion models, that\ncircumvents training on domain pairs. DDIBs allow translations between\narbitrary pairs of source-target domains, given independently trained diffusion\nmodels on the respective domains. Image translation with DDIBs is a two-step\nprocess: DDIBs first obtain latent encodings for source images with the source\ndiffusion model, and next decode such encodings using the target model to\nconstruct target images. Moreover, DDIBs enable cycle-consistency by default\nand is theoretically connected to optimal transport. Experimentally, we apply\nDDIBs on a variety of synthetic and high-resolution image datasets,\ndemonstrating their utility in example-guided color transfer, image-to-image\ntranslation as well as their connections to optimal transport methods.",
    "descriptor": "",
    "authors": [
      "Xuan Su",
      "Jiaming Song",
      "Chenlin Meng",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08382"
  },
  {
    "id": "arXiv:2203.08383",
    "title": "Shepherd Pre-trained Language Models to Develop a Train of Thought: An  Iterative Prompting Approach",
    "abstract": "While Pre-trained Language Models (PLMs) internalize a great amount of world\nknowledge, they have been shown incapable of recalling these knowledge to solve\ntasks requiring complex & multi-step inference procedures. Similar to how\nhumans develop a \"train of thought\" for these tasks, how can we equip PLMs with\nsuch abilities? In this work, we explore an iterative prompting framework, a\nnew prompting paradigm which progressively elicits relevant knowledge from PLMs\nfor multi-step inference tasks. We identify key limitations of existing\nprompting methods, namely they are either restricted to queries with a single\nidentifiable relation/predicate, or being agnostic to input contexts, which\nmakes it difficult to capture variabilities across different inference steps.\nWe propose an iterative context-aware prompter, which addresses these\nlimitations by learning to dynamically synthesize prompts conditioned on the\ncurrent step's contexts. Experiments on three datasets involving multi-step\ninference show the effectiveness of the iterative scheme and our proposed\nprompter design.",
    "descriptor": "\nComments: Our code will be available at this https URL\n",
    "authors": [
      "Boshi Wang",
      "Xiang Deng",
      "Huan Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08383"
  },
  {
    "id": "arXiv:2203.08388",
    "title": "MCoNaLa: A Benchmark for Code Generation from Multiple Natural Languages",
    "abstract": "While there has been a recent burgeoning of applications at the intersection\nof natural and programming languages, such as code generation and code\nsummarization, these applications are usually English-centric. This creates a\nbarrier for program developers who are not proficient in English. To mitigate\nthis gap in technology development across languages, we propose a multilingual\ndataset, MCoNaLa, to benchmark code generation from natural language commands\nextending beyond English. Modeled off of the methodology from the English\nCode/Natural Language Challenge (CoNaLa) dataset, we annotated a total of 896\nNL-code pairs in three languages: Spanish, Japanese, and Russian. We present a\nquantitative evaluation of performance on the MCoNaLa dataset by testing with\nstate-of-the-art code generation systems. While the difficulties vary across\nthese three languages, all systems lag significantly behind their English\ncounterparts, revealing the challenges in adapting code generation to new\nlanguages.",
    "descriptor": "",
    "authors": [
      "Zhiruo Wang",
      "Grace Cuenca",
      "Shuyan Zhou",
      "Frank F. Xu",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08388"
  },
  {
    "id": "arXiv:2203.08390",
    "title": "Reducing Flipping Errors in Deep Neural Networks",
    "abstract": "Deep neural networks (DNNs) have been widely applied in various domains in\nartificial intelligence including computer vision and natural language\nprocessing. A DNN is typically trained for many epochs and then a validation\ndataset is used to select the DNN in an epoch (we simply call this epoch \"the\nlast epoch\") as the final model for making predictions on unseen samples, while\nit usually cannot achieve a perfect accuracy on unseen samples. An interesting\nquestion is \"how many test (unseen) samples that a DNN misclassifies in the\nlast epoch were ever correctly classified by the DNN before the last epoch?\".\nIn this paper, we empirically study this question and find on several benchmark\ndatasets that the vast majority of the misclassified samples in the last epoch\nwere ever classified correctly before the last epoch, which means that the\npredictions for these samples were flipped from \"correct\" to \"wrong\". Motivated\nby this observation, we propose to restrict the behavior changes of a DNN on\nthe correctly-classified samples so that the correct local boundaries can be\nmaintained and the flipping error on unseen samples can be largely reduced.\nExtensive experiments on different benchmark datasets with different modern\nnetwork architectures demonstrate that the proposed flipping error reduction\n(FER) approach can substantially improve the generalization, the robustness,\nand the transferability of DNNs without introducing any additional network\nparameters or inference cost, only with a negligible training overhead.",
    "descriptor": "",
    "authors": [
      "Xiang Deng",
      "Yun Xiao",
      "Bo Long",
      "Zhongfei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08390"
  },
  {
    "id": "arXiv:2203.08392",
    "title": "Patch-Fool: Are Vision Transformers Always Robust Against Adversarial  Perturbations?",
    "abstract": "Vision transformers (ViTs) have recently set off a new wave in neural\narchitecture design thanks to their record-breaking performance in various\nvision tasks. In parallel, to fulfill the goal of deploying ViTs into\nreal-world vision applications, their robustness against potential malicious\nattacks has gained increasing attention. In particular, recent works show that\nViTs are more robust against adversarial attacks as compared with convolutional\nneural networks (CNNs), and conjecture that this is because ViTs focus more on\ncapturing global interactions among different input/feature patches, leading to\ntheir improved robustness to local perturbations imposed by adversarial\nattacks. In this work, we ask an intriguing question: \"Under what kinds of\nperturbations do ViTs become more vulnerable learners compared to CNNs?\" Driven\nby this question, we first conduct a comprehensive experiment regarding the\nrobustness of both ViTs and CNNs under various existing adversarial attacks to\nunderstand the underlying reason favoring their robustness. Based on the drawn\ninsights, we then propose a dedicated attack framework, dubbed Patch-Fool, that\nfools the self-attention mechanism by attacking its basic component (i.e., a\nsingle patch) with a series of attention-aware optimization techniques.\nInterestingly, our Patch-Fool framework shows for the first time that ViTs are\nnot necessarily more robust than CNNs against adversarial perturbations. In\nparticular, we find that ViTs are more vulnerable learners compared with CNNs\nagainst our Patch-Fool attack which is consistent across extensive experiments,\nand the observations from Sparse/Mild Patch-Fool, two variants of Patch-Fool,\nindicate an intriguing insight that the perturbation density and strength on\neach patch seem to be the key factors that influence the robustness ranking\nbetween ViTs and CNNs.",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Yonggan Fu",
      "Shunyao Zhang",
      "Shang Wu",
      "Cheng Wan",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08392"
  },
  {
    "id": "arXiv:2203.08394",
    "title": "Bridging the Data Gap between Training and Inference for Unsupervised  Neural Machine Translation",
    "abstract": "Back-translation is a critical component of Unsupervised Neural Machine\nTranslation (UNMT), which generates pseudo parallel data from target\nmonolingual data. A UNMT model is trained on the pseudo parallel data with\ntranslated source, and translates natural source sentences in inference. The\nsource discrepancy between training and inference hinders the translation\nperformance of UNMT models. By carefully designing experiments, we identify two\nrepresentative characteristics of the data gap in source: (1) style gap (i.e.,\ntranslated vs. natural text style) that leads to poor generalization\ncapability; (2) content gap that induces the model to produce hallucination\ncontent biased towards the target language. To narrow the data gap, we propose\nan online self-training approach, which simultaneously uses the pseudo parallel\ndata {natural source, translated target} to mimic the inference scenario.\nExperimental results on several widely-used language pairs show that our\napproach outperforms two strong baselines (XLM and MASS) by remedying the style\nand content gaps.",
    "descriptor": "\nComments: ACL 2022 (long paper, main conference)\n",
    "authors": [
      "Zhiwei He",
      "Xing Wang",
      "Rui Wang",
      "Shuming Shi",
      "Zhaopeng Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08394"
  },
  {
    "id": "arXiv:2203.08395",
    "title": "Concurrent CPU-GPU Task Programming using Modern C++",
    "abstract": "In this paper, we introduce Heteroflow, a new C++ library to help developers\nquickly write parallel CPU-GPU programs using task dependency graphs.\nHeteroflow leverages the power of modern C++ and task-based approaches to\nenable efficient implementations of heterogeneous decomposition strategies. Our\nnew CPU-GPU programming model allows users to express a problem in a way that\nadapts to effective separation of concerns and expertise encapsulation.\nCompared with existing libraries, Heteroflow is more cost-efficient in\nperformance scaling, programming productivity, and solution generality. We have\nevaluated Heteroflow on two real applications in VLSI design automation and\ndemonstrated the performance scalability across different CPU-GPU numbers and\nproblem sizes. At a particular example of VLSI timing analysis with\nmillion-scale tasking, Heteroflow achieved 7.7x runtime speed-up (99 vs 13\nminutes) over a baseline on a machine of 40 CPU cores and 4 GPUs.",
    "descriptor": "",
    "authors": [
      "Tsung-Wei Huang",
      "Yibo Lin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.08395"
  },
  {
    "id": "arXiv:2203.08396",
    "title": "Towards Formalizing HRI Data Collection Processes",
    "abstract": "Within the human-robot interaction (HRI) community, many researchers have\nfocused on the careful design of human-subjects studies. However, other parts\nof the community, e.g., the technical advances community, also need to do\nhuman-subjects studies to collect data to train their models, in ways that\nrequire user studies but without a strict experimental design. The design of\nsuch data collection is an underexplored area worthy of more attention. In this\nwork, we contribute a clearly defined process to collect data with three steps\nfor machine learning modeling purposes, grounded in recent literature, and\ndetail an use of this process to facilitate the collection of a corpus of\nreferring expressions. Specifically, we discuss our data collection goal and\nhow we worked to encourage well-covered and abundant participant responses,\nthrough our design of the task environment, the task itself, and the study\nprocedure. We hope this work would lead to more data collection formalism\nefforts in the HRI community and a fruitful discussion during the workshop.",
    "descriptor": "\nComments: 5 pages, The 4th Annual Workshop on Novel and Emerging Test Methods & Metrics for Effective HRI at HRI 2022. Paper webpage: this https URL\n",
    "authors": [
      "Zhao Han",
      "Tom Williams"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.08396"
  },
  {
    "id": "arXiv:2203.08398",
    "title": "COPA: Certifying Robust Policies for Offline Reinforcement Learning  against Poisoning Attacks",
    "abstract": "As reinforcement learning (RL) has achieved near human-level performance in a\nvariety of tasks, its robustness has raised great attention. While a vast body\nof research has explored test-time (evasion) attacks in RL and corresponding\ndefenses, its robustness against training-time (poisoning) attacks remains\nlargely unanswered. In this work, we focus on certifying the robustness of\noffline RL in the presence of poisoning attacks, where a subset of training\ntrajectories could be arbitrarily manipulated. We propose the first\ncertification framework, COPA, to certify the number of poisoning trajectories\nthat can be tolerated regarding different certification criteria. Given the\ncomplex structure of RL, we propose two certification criteria: per-state\naction stability and cumulative reward bound. To further improve the\ncertification, we propose new partition and aggregation protocols to train\nrobust policies. We further prove that some of the proposed certification\nmethods are theoretically tight and some are NP-Complete problems. We leverage\nCOPA to certify three RL environments trained with different algorithms and\nconclude: (1) The proposed robust aggregation protocols such as temporal\naggregation can significantly improve the certifications; (2) Our certification\nfor both per-state action stability and cumulative reward bound are efficient\nand tight; (3) The certification for different training algorithms and\nenvironments are different, implying their intrinsic robustness properties. All\nexperimental results are available at https://copa-leaderboard.github.io.",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Fan Wu",
      "Linyi Li",
      "Chejian Xu",
      "Huan Zhang",
      "Bhavya Kailkhura",
      "Krishnaram Kenthapadi",
      "Ding Zhao",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08398"
  },
  {
    "id": "arXiv:2203.08399",
    "title": "Privacy-preserving Online AutoML for Domain-Specific Face Detection",
    "abstract": "Despite the impressive progress of general face detection, the tuning of\nhyper-parameters and architectures is still critical for the performance of a\ndomain-specific face detector. Though existing AutoML works can speedup such\nprocess, they either require tuning from scratch for a new scenario or do not\nconsider data privacy. To scale up, we derive a new AutoML setting from a\nplatform perspective. In such setting, new datasets sequentially arrive at the\nplatform, where an architecture and hyper-parameter configuration is\nrecommended to train the optimal face detector for each dataset. This, however,\nbrings two major challenges: (1) how to predict the best configuration for any\ngiven dataset without touching their raw images due to the privacy concern? and\n(2) how to continuously improve the AutoML algorithm from previous tasks and\noffer a better warm-up for future ones? We introduce \"HyperFD\", a new\nprivacy-preserving online AutoML framework for face detection. At its core\npart, a novel meta-feature representation of a dataset as well as its learning\nparadigm is proposed. Thanks to HyperFD, each local task (client) is able to\neffectively leverage the learning \"experience\" of previous tasks without\nuploading raw images to the platform; meanwhile, the meta-feature extractor is\ncontinuously learned to better trade off the bias and variance. Extensive\nexperiments demonstrate the effectiveness and efficiency of our design.",
    "descriptor": "\nComments: Accepted to CVPR 2022. Code will be available soon\n",
    "authors": [
      "Chenqian Yan",
      "Yuge Zhang",
      "Quanlu Zhang",
      "Yaming Yang",
      "Xinyang Jiang",
      "Yuqing Yang",
      "Baoyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08399"
  },
  {
    "id": "arXiv:2203.08402",
    "title": "Gradual Tensor Shape Checking",
    "abstract": "Tensor shape mismatch is a common source of bugs in deep learning programs.\nMost of the studies conducted to solve this problem use the whole-program\nanalysis approach, which lacks compositionality. A type-based approach is\ndesirable in this respect, but since the problem of shape inference is\nundecidable in general, fully automated shape inference is bound to be either\nunsound or too conservative.\nWe propose a type-based approach to detect tensor shape mismatches that works\npractically under such limitations. One of the main features of our approach is\nthe best-effort shape inference. Because of the undecidability of shape\ninference, our procedure performs it only in a best-effort manner. The\ninference result may be too imprecise to statically guarantee the absence of\nthe shape inconsistencies, and in such cases, dynamic checks are inserted into\nthe program. Another main feature is gradual typing. Users can improve the\nprecision of the inference by adding appropriate type annotations to the\nprogram.\nWe formalize our approach and prove that it satisfies the criteria of gradual\ntyping proposed by Siek et al. in 2015. We implement a prototype shape checking\ntool based on our approach and evaluate its effectiveness by applying it to\nsome deep neural network programs.",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "Momoko Hattori",
      "Naoki Kobayashi",
      "Ryosuke Sato"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.08402"
  },
  {
    "id": "arXiv:2203.08403",
    "title": "Precise Onboard Aicraft Cabin Localization using UWB and ML",
    "abstract": "Precise indoor positioning systems (IPSs) are key to perform a set of tasks\nmore efficiently during aircraft production, operation and maintenance. For\ninstance, IPSs can overcome the tedious task of configuring (wireless) sensor\nnodes in an aircraft cabin. Although various solutions based on technologies of\nestablished consumer goods, e.g., Bluetooth or WiFi, have been proposed and\ntested, the published accuracy results fail to make these technologies relevant\nfor practical use cases. This stems from the challenging environments for\npositioning, especially in aircraft cabins, which is mainly due to the\ngeometries, many obstacles, and highly reflective materials. To address these\nissues, we propose to evaluate in this work an Ultra-Wideband (UWB)-based IPS\nvia a measurement campaign performed in a real aircraft cabin. We first\nillustrate the difficulties that an IPS faces in an aircraft cabin, by studying\nthe signal propagation effects which were measured. We then investigate the\nranging and localization accuracies of our IPS. Finally, we also introduce\nvarious methods based on machine learning (ML) for correcting the ranging\nmeasurements and demonstrate that we are able to localize a node with respect\nto an aircraft seat with a measured likelihood of 97%.",
    "descriptor": "",
    "authors": [
      "Fabien Geyer",
      "Dominic Schupke"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.08403"
  },
  {
    "id": "arXiv:2203.08404",
    "title": "RBC: Rectifying the Biased Context in Continual Semantic Segmentation",
    "abstract": "Recent years have witnessed a great development of Convolutional Neural\nNetworks in semantic segmentation, where all classes of training images are\nsimultaneously available. In practice, new images are usually made available in\na consecutive manner, leading to a problem called Continual Semantic\nSegmentation (CSS). Typically, CSS faces the forgetting problem since previous\ntraining images are unavailable, and the semantic shift problem of the\nbackground class. Considering the semantic segmentation as a context-dependent\npixel-level classification task, we explore CSS from a new perspective of\ncontext analysis in this paper. We observe that the context of old-class pixels\nin the new images is much more biased on new classes than that in the old\nimages, which can sharply aggravate the old-class forgetting and new-class\noverfitting. To tackle the obstacle, we propose a biased-context-rectified CSS\nframework with a context-rectified image-duplet learning scheme and a\nbiased-context-insensitive consistency loss. Furthermore, we propose an\nadaptive re-weighting class-balanced learning strategy for the biased class\ndistribution. Our approach outperforms state-of-the-art methods by a large\nmargin in existing CSS scenarios.",
    "descriptor": "",
    "authors": [
      "Hanbin Zhao",
      "Fengyu Yang",
      "Xinghe Fu",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08404"
  },
  {
    "id": "arXiv:2203.08406",
    "title": "Levenberg-Marquardt Method Based Cooperative Source Localization in SIMO  Molecular Communication via Diffusion Systems",
    "abstract": "Molecular communication underpins nano-scale communications in\nnanotechnology. The combination of multinanomachines to form nano-networks is\none of the main enabling methods. Due to the importance of source localization\nin establishing nano-networks, this paper proposes a cooperative source\nlocalization method for Molecular Communication via Diffusion (MCvD) systems\nusing multiple spherical absorption receivers. Since there is no exact\nmathematical expression of the channel impulse response for multiple absorbing\nreceivers, we adopt an empirical expression and use Levenberg-Marquardt method\nto estimate the distance of the transmitter to each receiver, based on which\nthe location of the transmitter is obtained using an iterative scheme where the\ninitial point is obtained using a multi-point localization method. Particle\nbased simulation is carried out to evaluate the performance of the proposed\nmethod. Simulation results show that the proposed method can accurately\nestimate the location of transmitter in short to medium communication ranges.",
    "descriptor": "",
    "authors": [
      "Yuqi Miao",
      "Wence Zhang",
      "Xu Bao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.08406"
  },
  {
    "id": "arXiv:2203.08408",
    "title": "Multi-Scale Context-Guided Lumbar Spine Disease Identification with  Coarse-to-fine Localization and Classification",
    "abstract": "Accurate and efficient lumbar spine disease identification is crucial for\nclinical diagnosis. However, existing deep learning models with millions of\nparameters often fail to learn with only hundreds or dozens of medical images.\nThese models also ignore the contextual relationship between adjacent objects,\nsuch as between vertebras and intervertebral discs. This work introduces a\nmulti-scale context-guided network with coarse-to-fine localization and\nclassification, named CCF-Net, for lumbar spine disease identification.\nSpecifically, in learning, we divide the localization objective into two\nparallel tasks, coarse and fine, which are more straightforward and effectively\nreduce the number of parameters and computational cost. The experimental\nresults show that the coarse-to-fine design presents the potential to achieve\nhigh performance with fewer parameters and data requirements. Moreover, the\nmulti-scale context-guided module can significantly improve the performance by\n6.45% and 5.51% with ResNet18 and ResNet50, respectively. Our code is available\nat https://github.com/czifan/CCFNet.pytorch.",
    "descriptor": "\nComments: Accepted at ISBI 2022\n",
    "authors": [
      "Zifan Chen",
      "Jie Zhao",
      "Hao Yu",
      "Yue Zhang",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08408"
  },
  {
    "id": "arXiv:2203.08409",
    "title": "How to Learn from Risk: Explicit Risk-Utility Reinforcement Learning for  Efficient and Safe Driving Strategies",
    "abstract": "Autonomous driving has the potential to revolutionize mobility and is hence\nan active area of research. In practice, the behavior of autonomous vehicles\nmust be acceptable, i.e., efficient, safe, and interpretable. While vanilla\nreinforcement learning (RL) finds performant behavioral strategies, they are\noften unsafe and uninterpretable. Safety is introduced through Safe RL\napproaches, but they still mostly remain uninterpretable as the learned\nbehaviour is jointly optimized for safety and performance without modeling them\nseparately. Interpretable machine learning is rarely applied to RL. This paper\nproposes SafeDQN, which allows to make the behavior of autonomous vehicles safe\nand interpretable while still being efficient. SafeDQN offers an\nunderstandable, semantic trade-off between the expected risk and the utility of\nactions while being algorithmically transparent. We show that SafeDQN finds\ninterpretable and safe driving policies for a variety of scenarios and\ndemonstrate how state-of-the-art saliency techniques can help to assess both\nrisk and utility.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Lukas M. Schmidt",
      "Sebastian Rietsch",
      "Axel Plinge",
      "Bjoern M. Eskofier",
      "Christopher Mutschler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08409"
  },
  {
    "id": "arXiv:2203.08410",
    "title": "Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again",
    "abstract": "The strong few-shot in-context learning capability of large pre-trained\nlanguage models (PLMs) such as GPT-3 is highly appealing for biomedical\napplications where data annotation is particularly costly. In this paper, we\npresent the first systematic and comprehensive study to compare the few-shot\nperformance of GPT-3 in-context learning with fine-tuning smaller (i.e.,\nBERT-sized) PLMs on two highly representative biomedical information extraction\ntasks, named entity recognition and relation extraction. We follow the true\nfew-shot setting to avoid overestimating models' few-shot performance by model\nselection over a large validation set. We also optimize GPT-3's performance\nwith known techniques such as contextual calibration and dynamic in-context\nexample retrieval. However, our results show that GPT-3 still significantly\nunderperforms compared with simply fine-tuning a smaller PLM using the same\nsmall training set. Moreover, what is equally important for practical\napplications is that adding more labeled data would reliably yield an\nimprovement in model performance. While that is the case when fine-tuning small\nPLMs, GPT-3's performance barely improves when adding more data. In-depth\nanalyses further reveal issues of the in-context learning setting that may be\ndetrimental to information extraction tasks in general. Given the high cost of\nexperimenting with GPT-3, we hope our study provides guidance for biomedical\nresearchers and practitioners towards more promising directions such as\nfine-tuning GPT-3 or small PLMs.",
    "descriptor": "",
    "authors": [
      "Bernal Jim\u00e9nez Guti\u00e9rrez",
      "Nikolas McNeal",
      "Clay Washington",
      "You Chen",
      "Lang Li",
      "Huan Sun",
      "Yu Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.08410"
  },
  {
    "id": "arXiv:2203.08411",
    "title": "FormNet: Structural Encoding beyond Sequential Modeling in Form Document  Information Extraction",
    "abstract": "Sequence modeling has demonstrated state-of-the-art performance on natural\nlanguage and document understanding tasks. However, it is challenging to\ncorrectly serialize tokens in form-like documents in practice due to their\nvariety of layout patterns. We propose FormNet, a structure-aware sequence\nmodel to mitigate the suboptimal serialization of forms. First, we design Rich\nAttention that leverages the spatial relationship between tokens in a form for\nmore precise attention score calculation. Second, we construct Super-Tokens for\neach word by embedding representations from their neighboring tokens through\ngraph convolutions. FormNet therefore explicitly recovers local syntactic\ninformation that may have been lost during serialization. In experiments,\nFormNet outperforms existing methods with a more compact model size and less\npre-training data, establishing new state-of-the-art performance on CORD, FUNSD\nand Payment benchmarks.",
    "descriptor": "\nComments: Accepted to ACL 2022\n",
    "authors": [
      "Chen-Yu Lee",
      "Chun-Liang Li",
      "Timothy Dozat",
      "Vincent Perot",
      "Guolong Su",
      "Nan Hua",
      "Joshua Ainslie",
      "Renshen Wang",
      "Yasuhisa Fujii",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08411"
  },
  {
    "id": "arXiv:2203.08412",
    "title": "CTDS: Centralized Teacher with Decentralized Student for Multi-Agent  Reinforcement Learning",
    "abstract": "Due to the partial observability and communication constraints in many\nmulti-agent reinforcement learning (MARL) tasks, centralized training with\ndecentralized execution (CTDE) has become one of the most widely used MARL\nparadigms. In CTDE, centralized information is dedicated to learning the\nallocation of the team reward with a mixing network, while the learning of\nindividual Q-values is usually based on local observations. The insufficient\nutility of global observation will degrade performance in challenging\nenvironments. To this end, this work proposes a novel Centralized Teacher with\nDecentralized Student (CTDS) framework, which consists of a teacher model and a\nstudent model. Specifically, the teacher model allocates the team reward by\nlearning individual Q-values conditioned on global observation, while the\nstudent model utilizes the partial observations to approximate the Q-values\nestimated by the teacher model. In this way, CTDS balances the full utilization\nof global observation during training and the feasibility of decentralized\nexecution for online inference. Our CTDS framework is generic which is ready to\nbe applied upon existing CTDE methods to boost their performance. We conduct\nexperiments on a challenging set of StarCraft II micromanagement tasks to test\nthe effectiveness of our method and the results show that CTDS outperforms the\nexisting value-based MARL methods.",
    "descriptor": "",
    "authors": [
      "Jian Zhao",
      "Xunhan Hu",
      "Mingyu Yang",
      "Wengang Zhou",
      "Jiangcheng Zhu",
      "Houqiang Li"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08412"
  },
  {
    "id": "arXiv:2203.08414",
    "title": "Unsupervised Semantic Segmentation by Distilling Feature Correspondences",
    "abstract": "Unsupervised semantic segmentation aims to discover and localize semantically\nmeaningful categories within image corpora without any form of annotation. To\nsolve this task, algorithms must produce features for every pixel that are both\nsemantically meaningful and compact enough to form distinct clusters. Unlike\nprevious works which achieve this with a single end-to-end framework, we\npropose to separate feature learning from cluster compactification.\nEmpirically, we show that current unsupervised feature learning frameworks\nalready generate dense features whose correlations are semantically consistent.\nThis observation motivates us to design STEGO ($\\textbf{S}$elf-supervised\n$\\textbf{T}$ransformer with $\\textbf{E}$nergy-based $\\textbf{G}$raph\n$\\textbf{O}$ptimization), a novel framework that distills unsupervised features\ninto high-quality discrete semantic labels. At the core of STEGO is a novel\ncontrastive loss function that encourages features to form compact clusters\nwhile preserving their relationships across the corpora. STEGO yields a\nsignificant improvement over the prior state of the art, on both the CocoStuff\n($\\textbf{+14 mIoU}$) and Cityscapes ($\\textbf{+9 mIoU}$) semantic segmentation\nchallenges.",
    "descriptor": "",
    "authors": [
      "Mark Hamilton",
      "Zhoutong Zhang",
      "Bharath Hariharan",
      "Noah Snavely",
      "William T. Freeman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08414"
  },
  {
    "id": "arXiv:2203.08416",
    "title": "On Higher-Order Reachability Games vs May Reachability",
    "abstract": "We consider the reachability problem for higher-order functional programs and\nstudy the relationship between reachability games (i.e., the reachability\nproblem for programs with angelic and demonic nondeterminism) and\nmay-reachability (i.e., the reachability problem for programs with only angelic\nnondeterminism). We show that reachability games for order-n programs can be\nreduced to may-reachability for order-(n+1) programs, and vice versa. We\nformalize the reductions by using higher-order fixpoint logic and prove their\ncorrectness. We also discuss applications of the reductions to higher-order\nprogram verification.",
    "descriptor": "",
    "authors": [
      "Kazuyuki Asada",
      "Hiroyuki Katsura",
      "Naoki Kobayashi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.08416"
  },
  {
    "id": "arXiv:2203.08417",
    "title": "On the Use of Fine-grained Vulnerable Code Statements for Software  Vulnerability Assessment Models",
    "abstract": "Many studies have developed Machine Learning (ML) approaches to detect\nSoftware Vulnerabilities (SVs) in functions and fine-grained code statements\nthat cause such SVs. However, there is little work on leveraging such detection\noutputs for data-driven SV assessment to give information about exploitability,\nimpact, and severity of SVs. The information is important to understand SVs and\nprioritize their fixing. Using large-scale data from 1,782 functions of 429 SVs\nin 200 real-world projects, we investigate ML models for automating\nfunction-level SV assessment tasks, i.e., predicting seven Common Vulnerability\nScoring System (CVSS) metrics. We particularly study the value and use of\nvulnerable statements as inputs for developing the assessment models because\nSVs in functions are originated in these statements. We show that vulnerable\nstatements are 5.8 times smaller in size, yet exhibit 7.5-114.5% stronger\nassessment performance (Matthews Correlation Coefficient (MCC)) than\nnon-vulnerable statements. Incorporating context of vulnerable statements\nfurther increases the performance by up to 8.9% (0.64 MCC and 0.75 F1-Score).\nOverall, we provide the initial yet promising ML-based baselines for\nfunction-level SV assessment, paving the way for further research in this\ndirection.",
    "descriptor": "\nComments: Accepted as a full paper in the technical track at the 19th International Conference on Mining Software Repositories (MSR) 2022\n",
    "authors": [
      "Triet H. M. Le",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08417"
  },
  {
    "id": "arXiv:2203.08420",
    "title": "How do you Converse with an Analytical Chatbot? Revisiting Gricean  Maxims for Designing Analytical Conversational Behavior",
    "abstract": "Chatbots have garnered interest as conversational interfaces for a variety of\ntasks. While general design guidelines exist for chatbot interfaces, little\nwork explores analytical chatbots that support conversing with data. We explore\nGricean Maxims to help inform the basic design of effective conversational\ninteraction. We also draw inspiration from natural language interfaces for data\nexploration to support ambiguity and intent handling. We ran Wizard of Oz\nstudies with 30 participants to evaluate user expectations for text and voice\nchatbot design variants. Results identified preferences for intent\ninterpretation and revealed variations in user expectations based on the\ninterface affordances. We subsequently conducted an exploratory analysis of\nthree analytical chatbot systems (text + chart, voice + chart, voice-only) that\nimplement these preferred design variants. Empirical evidence from a second\n30-participant study informs implications specific to data-driven conversation\nsuch as interpreting intent, data orientation, and establishing trust through\nappropriate system responses.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Vidya Setlur",
      "Melanie Tory"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.08420"
  },
  {
    "id": "arXiv:2203.08421",
    "title": "WegFormer: Transformers for Weakly Supervised Semantic Segmentation",
    "abstract": "Although convolutional neural networks (CNNs) have achieved remarkable\nprogress in weakly supervised semantic segmentation (WSSS), the effective\nreceptive field of CNN is insufficient to capture global context information,\nleading to sub-optimal results. Inspired by the great success of Transformers\nin fundamental vision areas, this work for the first time introduces\nTransformer to build a simple and effective WSSS framework, termed WegFormer.\nUnlike existing CNN-based methods, WegFormer uses Vision Transformer (ViT) as a\nclassifier to produce high-quality pseudo segmentation masks. To this end, we\nintroduce three tailored components in our Transformer-based framework, which\nare (1) a Deep Taylor Decomposition (DTD) to generate attention maps, (2) a\nsoft erasing module to smooth the attention maps, and (3) an efficient\npotential object mining (EPOM) to filter noisy activation in the background.\nWithout any bells and whistles, WegFormer achieves state-of-the-art 70.5% mIoU\non the PASCAL VOC dataset, significantly outperforming the previous best\nmethod. We hope WegFormer provides a new perspective to tap the potential of\nTransformer in weakly supervised semantic segmentation. Code will be released.",
    "descriptor": "\nComments: Tech Report\n",
    "authors": [
      "Chunmeng Liu",
      "Enze Xie",
      "Wenjia Wang",
      "Wenhai Wang",
      "Guangyao Li",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08421"
  },
  {
    "id": "arXiv:2203.08422",
    "title": "Attribute Group Editing for Reliable Few-shot Image Generation",
    "abstract": "Few-shot image generation is a challenging task even using the\nstate-of-the-art Generative Adversarial Networks (GANs). Due to the unstable\nGAN training process and the limited training data, the generated images are\noften of low quality and low diversity. In this work, we propose a new\nediting-based method, i.e., Attribute Group Editing (AGE), for few-shot image\ngeneration. The basic assumption is that any image is a collection of\nattributes and the editing direction for a specific attribute is shared across\nall categories. AGE examines the internal representation learned in GANs and\nidentifies semantically meaningful directions. Specifically, the class\nembedding, i.e., the mean vector of the latent codes from a specific category,\nis used to represent the category-relevant attributes, and the\ncategory-irrelevant attributes are learned globally by Sparse Dictionary\nLearning on the difference between the sample embedding and the class\nembedding. Given a GAN well trained on seen categories, diverse images of\nunseen categories can be synthesized through editing category-irrelevant\nattributes while keeping category-relevant attributes unchanged. Without\nre-training the GAN, AGE is capable of not only producing more realistic and\ndiverse images for downstream visual applications with limited data but\nachieving controllable image editing with interpretable category-irrelevant\ndirections.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Guanqi Ding",
      "Xinzhe Han",
      "Shuhui Wang",
      "Shuzhe Wu",
      "Xin Jin",
      "Dandan Tu",
      "Qingming Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08422"
  },
  {
    "id": "arXiv:2203.08423",
    "title": "On-The-Go Robot-to-Human Handovers with a Mobile Manipulator",
    "abstract": "Existing approaches to direct robot-to-human handovers are typically\nimplemented on fixed-base robot arms, or on mobile manipulators that come to a\nfull stop before performing the handover. We propose \"on-the-go\" handovers\nwhich permit a moving mobile manipulator to hand over an object to a human\nwithout stopping. The on-the-go handover motion is generated with a reactive\ncontroller that allows simultaneous control of the base and the arm. In a user\nstudy, human receivers subjectively assessed on-the-go handovers to be more\nefficient, predictable, natural, better timed and safer than handovers that\nimplemented a \"stop-and-deliver\" behavior.",
    "descriptor": "\nComments: 6 pages, 7 figures, 2 tables, submitted to RO-MAN 2022\n",
    "authors": [
      "Kerry He",
      "Pradeepsundar Simini",
      "Wesley Chan",
      "Dana Kuli\u0107",
      "Elizabeth Croft",
      "Akansel Cosgun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08423"
  },
  {
    "id": "arXiv:2203.08424",
    "title": "A Language-Independent Analysis Platform for Source Code",
    "abstract": "In this paper, we present the CPG analysis platform, which enables the\ntranslation of source code into a programming language-independent\nrepresentation, based on a code property graph. This allows security experts\nand developers to capture language level semantics for security analyses or\nidentify patterns with respect to code compliance. Through the use of fuzzy\nparsing, also incomplete or non-compilable code, written in different\nprogramming languages, can be analyzed. The platform comprises an analysis\nlibrary and interfaces to query, interact with or visualize source code graphs.\nThis set of CPG tools allows finding common weaknesses in heterogeneous\nsoftware environments, independently of the underlying programming language.",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Konrad Weiss",
      "Christian Banse"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08424"
  },
  {
    "id": "arXiv:2203.08426",
    "title": "Survey on Internet of Things enabled by 6G Wireless Networks",
    "abstract": "The 6G wireless technology is visualized to revolutionize multiple customer\nservices with the Internet of Things (IoT), thereby contributing to a\nubiquitous intelligent society comprising autonomous systems. In this chapter,\nwe conduct a detailed survey on the IoT networks with 6G wireless networks and\ninvestigate the trending possibilities provided by the 6G technology within the\nIoT networks and the related utilization; Firstly, we detail the breakthrough\nIoT technologies and the technological drivers which are anticipated to\nstrengthen IoT networks in future. Next, we present the relevant use cases\ndetailing the discussion on the role of the 6G technology within a broad\nspectrum of IoT potential applications. Lastly, we highlight the several\nresearch scope and challenges and list the potential research needs and\nencourage further research within the thrust area of IoT enabled by 6G\nnetworks.",
    "descriptor": "",
    "authors": [
      "Sridhar Iyer",
      "Rahul Jashvantbhai Pandya",
      "Rakhee Kallimani",
      "Krishna Pai",
      "Rajashri Khanai",
      "Dattaprasad Torse",
      "Swati Mavinkattimath"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.08426"
  },
  {
    "id": "arXiv:2203.08429",
    "title": "A Survey of Machine Learning Algorithms for 6G Wireless Networks",
    "abstract": "The primary focus of Artificial Intelligence/Machine Learning (AI/ML)\nintegration within the wireless technology is to reduce capital expenditures,\noptimize network performance, and build new revenue streams. Replacing\ntraditional algorithms with deep learning AI techniques have dramatically\nreduced the power consumption and improved the system performance. Further,\nimplementation of ML algorithms also enables the wireless network service\nproviders to (i) offer high automation levels from distributed AI/ML\narchitectures applicable at the network edge, (ii) implement application-based\ntraffic steering across the access networks, (iii) enable dynamic network\nslicing for addressing different scenarios with varying quality of service\nrequirements, and (iv) enable ubiquitous connectivity across the various 6G\ncommunication platforms.\nIn this chapter, we review/survey the ML techniques which are applicable to\nthe 6G wireless networks. and also list the open problems of research which\nrequire timely solutions.",
    "descriptor": "",
    "authors": [
      "Anita Patil",
      "Sridhar Iyer",
      "Rahul Jashvantbhai Pandya"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.08429"
  },
  {
    "id": "arXiv:2203.08430",
    "title": "Cross-Lingual Ability of Multilingual Masked Language Models: A Study of  Language Structure",
    "abstract": "Multilingual pre-trained language models, such as mBERT and XLM-R, have shown\nimpressive cross-lingual ability. Surprisingly, both of them use multilingual\nmasked language model (MLM) without any cross-lingual supervision or aligned\ndata. Despite the encouraging results, we still lack a clear understanding of\nwhy cross-lingual ability could emerge from multilingual MLM. In our work, we\nargue that cross-language ability comes from the commonality between languages.\nSpecifically, we study three language properties: constituent order,\ncomposition and word co-occurrence. First, we create an artificial language by\nmodifying property in source language. Then we study the contribution of\nmodified property through the change of cross-language transfer results on\ntarget language. We conduct experiments on six languages and two cross-lingual\nNLP tasks (textual entailment, sentence retrieval). Our main conclusion is that\nthe contribution of constituent order and word co-occurrence is limited, while\nthe composition is more crucial to the success of cross-linguistic transfer.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Yuan Chai",
      "Yaobo Liang",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08430"
  },
  {
    "id": "arXiv:2203.08435",
    "title": "DiFT: Differentiable Differential Feature Transform for Multi-View  Stereo",
    "abstract": "We present a novel framework to automatically learn to transform the\ndifferential cues from a stack of images densely captured with a rotational\nmotion into spatially discriminative and view-invariant per-pixel features at\neach view. These low-level features can be directly fed to any existing\nmulti-view stereo technique for enhanced 3D reconstruction. The lighting\ncondition during acquisition can also be jointly optimized in a differentiable\nfashion. We sample from a dozen of pre-scanned objects with a wide variety of\ngeometry and reflectance to synthesize a large amount of high-quality training\ndata. The effectiveness of our features is demonstrated on a number of\nchallenging objects acquired with a lightstage, comparing favorably with\nstate-of-the-art techniques. Finally, we explore additional applications of\ngeometric detail visualization and computational stylization of complex\nappearance.",
    "descriptor": "",
    "authors": [
      "Kaizhang Kang",
      "Chong Zeng",
      "Hongzhi Wu",
      "Kun Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08435"
  },
  {
    "id": "arXiv:2203.08436",
    "title": "Don't Say What You Don't Know: Improving the Consistency of Abstractive  Summarization by Constraining Beam Search",
    "abstract": "Abstractive summarization systems today produce fluent and relevant output,\nbut often \"hallucinate\" statements not supported by the source text. We analyze\nthe connection between hallucinations and training data, and find evidence that\nmodels hallucinate because they train on target summaries that are unsupported\nby the source. Based on our findings, we present PINOCCHIO, a new decoding\nmethod that improves the consistency of a transformer-based abstractive\nsummarizer by constraining beam search to avoid hallucinations. Given the model\nstates and outputs at a given step, PINOCCHIO detects likely model\nhallucinations based on various measures of attribution to the source text.\nPINOCCHIO backtracks to find more consistent output, and can opt to produce no\nsummary at all when no consistent generation can be found. In experiments, we\nfind that PINOCCHIO improves the consistency of generation (in terms of F1) by\nan average of~67% on two abstractive summarization datasets.",
    "descriptor": "\nComments: 16 pages, 2 figures, 7 tables\n",
    "authors": [
      "Daniel King",
      "Zejiang Shen",
      "Nishant Subramani",
      "Daniel S. Weld",
      "Iz Beltagy",
      "Doug Downey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08436"
  },
  {
    "id": "arXiv:2203.08437",
    "title": "General form of almost instantaneous fixed-to-variable-length codes and  optimal code tree construction",
    "abstract": "A general class of the almost instantaneous fixed-to-variable-length (AIFV)\ncodes is proposed, which contains every possible binary code we can make when\nallowing finite bits of decoding delay. The proposed codes, N-bit-delay AIFV\ncodes, are represented by multiple code trees with high flexibility. The paper\nguarantees them to be uniquely decodable and present a code-tree construction\nalgorithm under a reasonable condition. The presented algorithm provides us\nwith a set of code trees, which achieves minimum expected code length, among a\nsubset of N-bit-delay AIFV codes for an arbitrary source. The experiments show\nthat the proposed codes can perform more efficiently compared to the\nconventional AIFV-m and Huffman codes. Additionally, in some reasonable cases,\nthe proposed codes even outperform the 32-bit-precision range codes. The\ntheoretical and experimental results in this paper are expected to be very\nuseful for further study on AIFV codes.",
    "descriptor": "\nComments: submitted to IEEE Transactions on Information Theory\n",
    "authors": [
      "Ryosuke Sugiura",
      "Yutaka Kamamoto",
      "Takehiro Moriya"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.08437"
  },
  {
    "id": "arXiv:2203.08439",
    "title": "Instance-level loss based multiple-instance learning for acoustic scene  classification",
    "abstract": "In acoustic scene classification (ASC) task, an acoustic scene consists of\ndiverse attributes and is inferred by identifying combinations of some distinct\nattributes among them. This study aims to extract and cluster these attributes\neffectively using a multiple-instance learning (MIL) framework for ASC. MIL,\nknown as one of the weakly supervised learning methods, is a way to extract\ninstances from input data and infer a scene corresponding to the input data\nwith those unlabeled instances. We develop the MIL framework more suitable for\nASC systems, adopting instance-level labels and instance-level loss, which are\neffective in extracting and clustering instances. As a result, the witness rate\nincreases significantly compared to the framework without instance-level loss\nand labels. Also in several MIL-based ASC systems, the classification accuracy\nimproves by about 5 to 11% than without instance-level loss. In addition, we\ndesigned a fully separated convolutional module which is a low-complexity\nneural network consisting of pointwise, frequency-sided depthwise, and\ntemporal-sided depthwise convolutional filters. Considering both complexity and\nperformance, our proposed system is more practical compared to previous systems\non the DCASE 2019 challenge task 1-A leader board. We surpassed the third-place\nmodel by achieving a performance of 82.3\\% with only the model complexity of\n417K, which is at least 40 times fewer than other systems.",
    "descriptor": "",
    "authors": [
      "Won-Gook Choi",
      "Joon-Hyuk Chang",
      "Jae-Mo Yang",
      "Han-Gil Moon"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.08439"
  },
  {
    "id": "arXiv:2203.08441",
    "title": "Open Set Recognition using Vision Transformer with an Additional  Detection Head",
    "abstract": "Deep neural networks have demonstrated prominent capacities for image\nclassification tasks in a closed set setting, where the test data come from the\nsame distribution as the training data. However, in a more realistic open set\nscenario, traditional classifiers with incomplete knowledge cannot tackle test\ndata that are not from the training classes. Open set recognition (OSR) aims to\naddress this problem by both identifying unknown classes and distinguishing\nknown classes simultaneously. In this paper, we propose a novel approach to OSR\nthat is based on the vision transformer (ViT) technique. Specifically, our\napproach employs two separate training stages. First, a ViT model is trained to\nperform closed set classification. Then, an additional detection head is\nattached to the embedded features extracted by the ViT, trained to force the\nrepresentations of known data to class-specific clusters compactly. Test\nexamples are identified as known or unknown based on their distance to the\ncluster centers. To the best of our knowledge, this is the first time to\nleverage ViT for the purpose of OSR, and our extensive evaluation against\nseveral OSR benchmark datasets reveals that our approach significantly\noutperforms other baseline methods and obtains new state-of-the-art\nperformance.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Feiyang Cai",
      "Zhenkai Zhang",
      "Jie Liu",
      "Xenofon Koutsoukos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08441"
  },
  {
    "id": "arXiv:2203.08442",
    "title": "Understanding and Improving Sequence-to-Sequence Pretraining for Neural  Machine Translation",
    "abstract": "In this paper, we present a substantial step in better understanding the SOTA\nsequence-to-sequence (Seq2Seq) pretraining for neural machine\ntranslation~(NMT). We focus on studying the impact of the jointly pretrained\ndecoder, which is the main difference between Seq2Seq pretraining and previous\nencoder-based pretraining approaches for NMT. By carefully designing\nexperiments on three language pairs, we find that Seq2Seq pretraining is a\ndouble-edged sword: On one hand, it helps NMT models to produce more diverse\ntranslations and reduce adequacy-related translation errors. On the other hand,\nthe discrepancies between Seq2Seq pretraining and NMT finetuning limit the\ntranslation quality (i.e., domain discrepancy) and induce the over-estimation\nissue (i.e., objective discrepancy). Based on these observations, we further\npropose simple and effective strategies, named in-domain pretraining and input\nadaptation to remedy the domain and objective discrepancies, respectively.\nExperimental results on several language pairs show that our approach can\nconsistently improve both translation performance and model robustness upon\nSeq2Seq pretraining.",
    "descriptor": "\nComments: Accepted by ACL 2022 main conference\n",
    "authors": [
      "Wenxuan Wang",
      "Wenxiang Jiao",
      "Yongchang Hao",
      "Xing Wang",
      "Shuming Shi",
      "Zhaopeng Tu",
      "Michael Lyu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08442"
  },
  {
    "id": "arXiv:2203.08444",
    "title": "Panini-Net: GAN Prior Based Degradation-Aware Feature Interpolation for  Face Restoration",
    "abstract": "Emerging high-quality face restoration (FR) methods often utilize pre-trained\nGAN models (\\textit{i.e.}, StyleGAN2) as GAN Prior. However, these methods\nusually struggle to balance realness and fidelity when facing various\ndegradation levels. Besides, there is still a noticeable visual quality gap\ncompared with pre-trained GAN models. In this paper, we propose a novel GAN\nPrior based degradation-aware feature interpolation network, dubbed Panini-Net,\nfor FR tasks by explicitly learning the abstract representations to distinguish\nvarious degradations. Specifically, an unsupervised degradation representation\nlearning (UDRL) strategy is first developed to extract degradation\nrepresentations (DR) of the input degraded images. Then, a degradation-aware\nfeature interpolation (DAFI) module is proposed to dynamically fuse the two\ntypes of informative features (\\textit{i.e.}, features from input images and\nfeatures from GAN Prior) with flexible adaption to various degradations based\non DR. Ablation studies reveal the working mechanism of DAFI and its potential\nfor editable FR. Extensive experiments demonstrate that our Panini-Net achieves\nstate-of-the-art performance for multi-degradation face restoration and face\nsuper-resolution. The source code is available at\nhttps://github.com/jianzhangcs/panini.",
    "descriptor": "\nComments: Accepted by AAAI2022\n",
    "authors": [
      "Yinhuai Wang",
      "Yujie Hu",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08444"
  },
  {
    "id": "arXiv:2203.08445",
    "title": "Structurally Diverse Sampling Reduces Spurious Correlations in Semantic  Parsing Datasets",
    "abstract": "A rapidly growing body of research has demonstrated the inability of NLP\nmodels to generalize compositionally and has tried to alleviate it through\nspecialized architectures, training schemes, and data augmentation, among other\napproaches. In this work, we study a different relatively under-explored\napproach: sampling diverse train sets that encourage compositional\ngeneralization. We propose a novel algorithm for sampling a structurally\ndiverse set of instances from a labeled instance pool with structured outputs.\nEvaluating on 5 semantic parsing datasets of varying complexity, we show that\nour algorithm performs competitively with or better than prior algorithms in\nnot only compositional template splits but also traditional IID splits of all\nbut the least structurally diverse datasets. In general, we find that diverse\ntrain sets lead to better generalization than random training sets of the same\nsize in 9 out of 10 dataset-split pairs, with over 10% absolute improvement in\n5, providing further evidence to their sample efficiency. Moreover, we show\nthat structural diversity also makes for more comprehensive test sets that\nrequire diverse training to succeed on. Finally, we use information theory to\nshow that reduction in spurious correlations between substructures may be one\nreason why diverse training sets improve generalization.",
    "descriptor": "",
    "authors": [
      "Shivanshu Gupta",
      "Sameer Singh",
      "Matt Gardner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08445"
  },
  {
    "id": "arXiv:2203.08448",
    "title": "Playing with blocks: Toward re-usable deep learning models for  side-channel profiled attacks",
    "abstract": "This paper introduces a deep learning modular network for side-channel\nanalysis. Our deep learning approach features the capability to exchange part\nof it (modules) with others networks. We aim to introduce reusable trained\nmodules into side-channel analysis instead of building architectures for each\nevaluation, reducing the body of work when conducting those. Our experiments\ndemonstrate that our architecture feasibly assesses a side-channel evaluation\nsuggesting that learning transferability is possible with the network we\npropose in this paper.",
    "descriptor": "",
    "authors": [
      "Servio Paguada",
      "Lejla Batina",
      "Ileana Buhan",
      "Igor Armendariz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08448"
  },
  {
    "id": "arXiv:2203.08450",
    "title": "The Devil Is in the Details: Window-based Attention for Image  Compression",
    "abstract": "Learned image compression methods have exhibited superior rate-distortion\nperformance than classical image compression standards. Most existing learned\nimage compression models are based on Convolutional Neural Networks (CNNs).\nDespite great contributions, a main drawback of CNN based model is that its\nstructure is not designed for capturing local redundancy, especially the\nnon-repetitive textures, which severely affects the reconstruction quality.\nTherefore, how to make full use of both global structure and local texture\nbecomes the core problem for learning-based image compression. Inspired by\nrecent progresses of Vision Transformer (ViT) and Swin Transformer, we found\nthat combining the local-aware attention mechanism with the global-related\nfeature learning could meet the expectation in image compression. In this\npaper, we first extensively study the effects of multiple kinds of attention\nmechanisms for local features learning, then introduce a more straightforward\nyet effective window-based local attention block. The proposed window-based\nattention is very flexible which could work as a plug-and-play component to\nenhance CNN and Transformer models. Moreover, we propose a novel Symmetrical\nTransFormer (STF) framework with absolute transformer blocks in the\ndown-sampling encoder and up-sampling decoder. Extensive experimental\nevaluations have shown that the proposed method is effective and outperforms\nthe state-of-the-art methods. The code is publicly available at\nhttps://github.com/Googolxx/STF.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Renjie Zou",
      "Chunfeng Song",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08450"
  },
  {
    "id": "arXiv:2203.08451",
    "title": "Estimate Analysis of a Fully Discrete Mixed Finite Element Scheme for  Stochastic Incompressible Navier-Stokes Equations with Multiplicative Noise",
    "abstract": "This paper is concerned with stochastic incompressible Navier-Stokes\nequations with multiplicative noise in two dimensions with respect to periodic\nboundary conditions. Based on the Helmholtz decomposition of the multiplicative\nnoise, semi-discrete and fully discrete time-stepping algorithms are proposed.\nThe convergence rates for mixed finite element methods based space-time\napproximation with respect to convergence in probability for the velocity and\nthe pressure are obtained. By using the negative norm technique, the $L^2$\nconvergence of this scheme for the velocity is derived.",
    "descriptor": "",
    "authors": [
      "Hailong Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08451"
  },
  {
    "id": "arXiv:2203.08452",
    "title": "Can Pre-trained Language Models Interpret Similes as Smart as Human?",
    "abstract": "Simile interpretation is a crucial task in natural language processing.\nNowadays, pre-trained language models (PLMs) have achieved state-of-the-art\nperformance on many tasks. However, it remains under-explored whether PLMs can\ninterpret similes or not. In this paper, we investigate the ability of PLMs in\nsimile interpretation by designing a novel task named Simile Property Probing,\ni.e., to let the PLMs infer the shared properties of similes. We construct our\nsimile property probing datasets from both general textual corpora and\nhuman-designed questions, containing 1,633 examples covering seven main\ncategories. Our empirical study based on the constructed datasets shows that\nPLMs can infer similes' shared properties while still underperforming humans.\nTo bridge the gap with human performance, we additionally design a\nknowledge-enhanced training objective by incorporating the simile knowledge\ninto PLMs via knowledge embedding methods. Our method results in a gain of\n8.58% in the probing task and 1.37% in the downstream task of sentiment\nclassification. The datasets and code are publicly available at\nhttps://github.com/Abbey4799/PLMs-Interpret-Simile.",
    "descriptor": "\nComments: Accepted at ACL 2022 main conference\n",
    "authors": [
      "Qianyu He",
      "Sijie Cheng",
      "Zhixu Li",
      "Rui Xie",
      "Yanghua Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08452"
  },
  {
    "id": "arXiv:2203.08454",
    "title": "Coach-assisted Multi-Agent Reinforcement Learning Framework for  Unexpected Crashed Agents",
    "abstract": "Multi-agent reinforcement learning is difficult to be applied in practice,\nwhich is partially due to the gap between the simulated and real-world\nscenarios. One reason for the gap is that the simulated systems always assume\nthat the agents can work normally all the time, while in practice, one or more\nagents may unexpectedly \"crash\" during the coordination process due to\ninevitable hardware or software failures. Such crashes will destroy the\ncooperation among agents, leading to performance degradation. In this work, we\npresent a formal formulation of a cooperative multi-agent reinforcement\nlearning system with unexpected crashes. To enhance the robustness of the\nsystem to crashes, we propose a coach-assisted multi-agent reinforcement\nlearning framework, which introduces a virtual coach agent to adjust the crash\nrate during training. We design three coaching strategies and the re-sampling\nstrategy for our coach agent. To the best of our knowledge, this work is the\nfirst to study the unexpected crashes in the multi-agent system. Extensive\nexperiments on grid-world and StarCraft II micromanagement tasks demonstrate\nthe efficacy of adaptive strategy compared with the fixed crash rate strategy\nand curriculum learning strategy. The ablation study further illustrates the\neffectiveness of our re-sampling strategy.",
    "descriptor": "",
    "authors": [
      "Jian Zhao",
      "Youpeng Zhao",
      "Weixun Wang",
      "Mingyu Yang",
      "Xunhan Hu",
      "Wengang Zhou",
      "Jianye Hao",
      "Houqiang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.08454"
  },
  {
    "id": "arXiv:2203.08455",
    "title": "Low-rank Parareal: a low-rank parallel-in-time integrator",
    "abstract": "The Parareal algorithm of Lions, Maday, and Turinici is a well-known time\nparallel algorithm for evolution problems. It is based on a Newton-like\niteration, with cheap coarse corrections performed sequentially, and expensive\nfine solves performed in parallel. In this work, we apply Parareal to evolution\nproblems that admit good low-rank approximations and for which the dynamical\nlow-rank approximation (DLRA), proposed by Koch and Lubich, can be used as time\nstepper. Many discrete integrators for DLRA have recently been proposed, based\non splitting the projected vector field or by applying projected Runge--Kutta\nmethods. The cost and accuracy of these methods are mostly governed by the rank\nchosen for the approximation. We want to use these properties in a new method,\nthat we call low-rank Parareal, in order to obtain a time-parallel DLRA solver\nfor evolution problems. We propose an analysis of the algorithm on affine\nlinear problems and illustrate our results numerically.",
    "descriptor": "\nComments: 18 pages, 24 figures\n",
    "authors": [
      "Benjamin Carrel",
      "Martin J. Gander",
      "Bart Vandereycken"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08455"
  },
  {
    "id": "arXiv:2203.08456",
    "title": "PPCD-GAN: Progressive Pruning and Class-Aware Distillation for  Large-Scale Conditional GANs Compression",
    "abstract": "We push forward neural network compression research by exploiting a novel\nchallenging task of large-scale conditional generative adversarial networks\n(GANs) compression. To this end, we propose a gradually shrinking GAN\n(PPCD-GAN) by introducing progressive pruning residual block (PP-Res) and\nclass-aware distillation. The PP-Res is an extension of the conventional\nresidual block where each convolutional layer is followed by a learnable mask\nlayer to progressively prune network parameters as training proceeds. The\nclass-aware distillation, on the other hand, enhances the stability of training\nby transferring immense knowledge from a well-trained teacher model through\ninstructive attention maps. We train the pruning and distillation processes\nsimultaneously on a well-known GAN architecture in an end-to-end manner. After\ntraining, all redundant parameters as well as the mask layers are discarded,\nyielding a lighter network while retaining the performance. We comprehensively\nillustrate, on ImageNet 128x128 dataset, PPCD-GAN reduces up to 5.2x (81%)\nparameters against state-of-the-arts while keeping better performance.",
    "descriptor": "\nComments: accepted at WACV 2022\n",
    "authors": [
      "Duc Minh Vo",
      "Akihiro Sugimoto",
      "Hideki Nakayama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08456"
  },
  {
    "id": "arXiv:2203.08457",
    "title": "A distributionally robust optimization approach to two-sided chance  constrained stochastic model predictive control with unknown noise  distribution",
    "abstract": "In this work, we propose a distributionally robust stochastic model\npredictive control (DR-SMPC) algorithm to address the problem of two-sided\nchance constrained discrete-time linear system corrupted by additive noise. The\nprevalent mechanism to cope with two-sided chance constraints is the so-called\nrisk allocation approach, which conservatively approximates the two-sided\nchance constraints with two single chance constraints by applying the Boole's\ninequality. In this proposed DR-SMPC framework, an exact tractable second-order\ncone (SOC) approach is adopted to abstract the two-sided chance constraints by\nconsidering the first and second moments of the noise. The proposed DR-SMPC\nalgorithm is able to guarantee that the worst-case probability of violating\nboth the upper and lower limits of safety constraints is within the\npre-specified maximum probability (PsMP). By flexibly adjusting this PsMP, the\nfeasible region of the initial states can be increased for the SMPC problem.\nThe recursive feasibility and convergence of the proposed DR-SMPC are\nestablished rigorously by introducing binary initialization strategy of nominal\nstate. Simulation studies of two practical cases are conducted to demonstrate\nthe effectiveness of the proposed DR-SMPC algorithm.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Yuan Tan",
      "Jun Yang",
      "Wen-Hua Chen",
      "Shihua Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08457"
  },
  {
    "id": "arXiv:2203.08459",
    "title": "KinyaBERT: a Morphology-aware Kinyarwanda Language Model",
    "abstract": "Pre-trained language models such as BERT have been successful at tackling\nmany natural language processing tasks. However, the unsupervised sub-word\ntokenization methods commonly used in these models (e.g., byte-pair encoding -\nBPE) are sub-optimal at handling morphologically rich languages. Even given a\nmorphological analyzer, naive sequencing of morphemes into a standard BERT\narchitecture is inefficient at capturing morphological compositionality and\nexpressing word-relative syntactic regularities. We address these challenges by\nproposing a simple yet effective two-tier BERT architecture that leverages a\nmorphological analyzer and explicitly represents morphological\ncompositionality. Despite the success of BERT, most of its evaluations have\nbeen conducted on high-resource languages, obscuring its applicability on\nlow-resource languages. We evaluate our proposed method on the low-resource\nmorphologically rich Kinyarwanda language, naming the proposed model\narchitecture KinyaBERT. A robust set of experimental results reveal that\nKinyaBERT outperforms solid baselines by 2% F1 score on a named entity\nrecognition task and by 4.3% average score of a machine-translated GLUE\nbenchmark. KinyaBERT fine-tuning has better convergence and achieves more\nrobust results on multiple tasks even in the presence of translation noise.",
    "descriptor": "\nComments: To be published in Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL 2022)\n",
    "authors": [
      "Antoine Nzeyimana",
      "Andre Niyongabo Rubungo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08459"
  },
  {
    "id": "arXiv:2203.08462",
    "title": "A Meshless Solution of a Small-Strain Plasticity Problem",
    "abstract": "Plasticity is a branch of solid mechanics, which deals with materials that\nupon sufficient deformation do not return to their original shape once the\ndeforming force is released.Several plasticity models describing the yield\ncondition exist, e.g. von Mises, Tresca, etc. Plasticity problems are usually\nsolved by assuming an elastic deformation under the applied load, and\ncorrecting the stress-strain field iteratively, should the local yield\ncriterion be violated. Traditionally the finite element method (FEM) is the\nnumerical tool of choice for engineers who are solving such problems. In this\nwork, however, we present the implementation of the von Mises plasticity model\nwith non-linear isotropic hardening in our in-house developed MEDUSA library,\nutilizing radial basis function-generated finite differences (RBF-FD), which is\nbeneficial compared to FEM, as it does not require a meshing step to discretize\nthe domain. We define a simple plane stress case, where a 2D block is fixed at\none edge, and a tensile force, which causes the block to deform, is applied to\nit at the opposite edge. Results are in good agreement with solutions obtained\nby Abaqus FEA, a commercial FEM solver.",
    "descriptor": "\nComments: MIPRO 2022, conference paper\n",
    "authors": [
      "Filip Strni\u0161a",
      "Mitja Jan\u010di\u010d",
      "Gregor Kosec"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08462"
  },
  {
    "id": "arXiv:2203.08465",
    "title": "Building AI Innovation Labs together with Companies",
    "abstract": "In the future, most companies will be confronted with the topic of Artificial\nIntelligence (AI) and will have to decide on their strategy in this regards.\nCurrently, a lot of companies are thinking about whether and how AI and the\nusage of data will impact their business model and what potential use cases\ncould look like. One of the biggest challenges lies in coming up with\ninnovative solution ideas with a clear business value. This requires business\ncompetencies on the one hand and technical competencies in AI and data\nanalytics on the other hand. In this article, we present the concept of AI\ninnovation labs and demonstrate a comprehensive framework, from coming up with\nthe right ideas to incrementally implementing and evaluating them regarding\ntheir business value and their feasibility based on a company's capabilities.\nThe concept is the result of nine years of working on data-driven innovations\nwith companies from various domains. Furthermore, we share some lessons learned\nfrom its practical applications. Even though a lot of technical publications\ncan be found in the literature regarding the development of AI models and many\nconsultancy companies provide corresponding services for building AI\ninnovations, we found very few publications sharing details about what an\nend-to-end framework could look like.",
    "descriptor": "",
    "authors": [
      "Jens Heidrich",
      "Andreas Jedlitschka",
      "Adam Trendowicz",
      "Anna Maria Vollmer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08465"
  },
  {
    "id": "arXiv:2203.08472",
    "title": "Fusing Local Similarities for Retrieval-based 3D Orientation Estimation  of Unseen Objects",
    "abstract": "In this paper, we tackle the task of estimating the 3D orientation of\npreviously-unseen objects from monocular images. This task contrasts with the\none considered by most existing deep learning methods which typically assume\nthat the testing objects have been observed during training. To handle the\nunseen objects, we follow a retrieval-based strategy and prevent the network\nfrom learning object-specific features by computing multi-scale local\nsimilarities between the query image and synthetically-generated reference\nimages. We then introduce an adaptive fusion module that robustly aggregates\nthe local similarities into a global similarity score of pairwise images.\nFurthermore, we speed up the retrieval process by developing a fast\nclustering-based retrieval strategy. Our experiments on the LineMOD,\nLineMOD-Occluded, and T-LESS datasets show that our method yields a\nsignificantly better generalization to unseen objects than previous works.",
    "descriptor": "",
    "authors": [
      "Chen Zhao",
      "Yinlin Hu",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08472"
  },
  {
    "id": "arXiv:2203.08479",
    "title": "Data Efficient 3D Learner via Knowledge Transferred from 2D Model",
    "abstract": "Collecting and labeling the registered 3D point cloud is costly. As a result,\n3D resources for training are typically limited in quantity compared to the 2D\nimages counterpart. In this work, we deal with the data scarcity challenge of\n3D tasks by transferring knowledge from strong 2D models via RGB-D images.\nSpecifically, we utilize a strong and well-trained semantic segmentation model\nfor 2D images to augment RGB-D images with pseudo-label. The augmented dataset\ncan then be used to pre-train 3D models. Finally, by simply fine-tuning on a\nfew labeled 3D instances, our method already outperforms existing\nstate-of-the-art that is tailored for 3D label efficiency. We also show that\nthe results of mean-teacher and entropy minimization can be improved by our\npre-training, suggesting that the transferred knowledge is helpful in\nsemi-supervised setting. We verify the effectiveness of our approach on two\npopular 3D models and three different tasks. On ScanNet official evaluation, we\nestablish new state-of-the-art semantic segmentation results on the\ndata-efficient track.",
    "descriptor": "",
    "authors": [
      "Ping-Chung Yu",
      "Cheng Sun",
      "Min Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08479"
  },
  {
    "id": "arXiv:2203.08480",
    "title": "E-KAR: A Benchmark for Rationalizing Natural Language Analogical  Reasoning",
    "abstract": "The ability to recognize analogies is fundamental to human cognition.\nExisting benchmarks to test word analogy do not reveal the underneath process\nof analogical reasoning of neural models. Holding the belief that models\ncapable of reasoning should be right for the right reasons, we propose a\nfirst-of-its-kind Explainable Knowledge-intensive Analogical Reasoning\nbenchmark (E-KAR). Our benchmark consists of 1,655 (in Chinese) and 1,251 (in\nEnglish) problems sourced from the Civil Service Exams, which require intensive\nbackground knowledge to solve. More importantly, we design a free-text\nexplanation scheme to explain whether an analogy should be drawn, and manually\nannotate them for each and every question and candidate answer. Empirical\nresults suggest that this benchmark is very challenging for some\nstate-of-the-art models for both explanation generation and analogical question\nanswering tasks, which invites further research in this area.",
    "descriptor": "\nComments: Accepted to ACL 2022 (Findings)\n",
    "authors": [
      "Jiangjie Chen",
      "Rui Xu",
      "Ziquan Fu",
      "Wei Shi",
      "Zhongqiao Li",
      "Xinbo Zhang",
      "Changzhi Sun",
      "Lei Li",
      "Yanghua Xiao",
      "Hao Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08480"
  },
  {
    "id": "arXiv:2203.08481",
    "title": "Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding",
    "abstract": "Visual grounding, i.e., localizing objects in images according to natural\nlanguage queries, is an important topic in visual language understanding. The\nmost effective approaches for this task are based on deep learning, which\ngenerally require expensive manually labeled image-query or patch-query pairs.\nTo eliminate the heavy dependence on human annotations, we present a novel\nmethod, named Pseudo-Q, to automatically generate pseudo language queries for\nsupervised training. Our method leverages an off-the-shelf object detector to\nidentify visual objects from unlabeled images, and then language queries for\nthese objects are obtained in an unsupervised fashion with a pseudo-query\ngeneration module. Then, we design a task-related query prompt module to\nspecifically tailor generated pseudo language queries for visual grounding\ntasks. Further, in order to fully capture the contextual relationships between\nimages and language queries, we develop a visual-language model equipped with\nmulti-level cross-modality attention mechanism. Extensive experimental results\ndemonstrate that our method has two notable benefits: (1) it can reduce human\nannotation costs significantly, e.g., 31% on RefCOCO without degrading original\nmodel's performance under the fully supervised setting, and (2) without bells\nand whistles, it achieves superior or comparable performance compared to\nstate-of-the-art weakly-supervised visual grounding methods on all the five\ndatasets we have experimented. Code is available at\nhttps://github.com/LeapLabTHU/Pseudo-Q.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Haojun Jiang",
      "Yuanze Lin",
      "Dongchen Han",
      "Shiji Song",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08481"
  },
  {
    "id": "arXiv:2203.08483",
    "title": "QS-Attn: Query-Selected Attention for Contrastive Learning in I2I  Translation",
    "abstract": "Unpaired image-to-image (I2I) translation often requires to maximize the\nmutual information between the source and the translated images across\ndifferent domains, which is critical for the generator to keep the source\ncontent and prevent it from unnecessary modifications. The self-supervised\ncontrastive learning has already been successfully applied in the I2I. By\nconstraining features from the same location to be closer than those from\ndifferent ones, it implicitly ensures the result to take content from the\nsource. However, previous work uses the features from random locations to\nimpose the constraint, which may not be appropriate since some locations\ncontain less information of source domain. Moreover, the feature itself does\nnot reflect the relation with others. This paper deals with these problems by\nintentionally selecting significant anchor points for contrastive learning. We\ndesign a query-selected attention (QS-Attn) module, which compares feature\ndistances in the source domain, giving an attention matrix with a probability\ndistribution in each row. Then we select queries according to their measurement\nof significance, computed from the distribution. The selected ones are regarded\nas anchors for contrastive loss. At the same time, the reduced attention matrix\nis employed to route features in both domains, so that source relations\nmaintain in the synthesis. We validate our proposed method in three different\nI2I datasets, showing that it increases the image quality without adding\nlearnable parameters.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Xueqi Hu",
      "Xinyue Zhou",
      "Qiusheng Huang",
      "Zhengyi Shi",
      "Li Sun",
      "Qingli Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08483"
  },
  {
    "id": "arXiv:2203.08485",
    "title": "PointAttN: You Only Need Attention for Point Cloud Completion",
    "abstract": "Point cloud completion referring to completing 3D shapes from partial 3D\npoint clouds is a fundamental problem for 3D point cloud analysis tasks.\nBenefiting from the development of deep neural networks, researches on point\ncloud completion have made great progress in recent years. However, the\nexplicit local region partition like kNNs involved in existing methods makes\nthem sensitive to the density distribution of point clouds. Moreover, it serves\nlimited receptive fields that prevent capturing features from long-range\ncontext information. To solve the problems, we leverage the cross-attention and\nself-attention mechanisms to design novel neural network for processing point\ncloud in a per-point manner to eliminate kNNs. Two essential blocks Geometric\nDetails Perception (GDP) and Self-Feature Augment (SFA) are proposed to\nestablish the short-range and long-range structural relationships directly\namong points in a simple yet effective way via attention mechanism. Then based\non GDP and SFA, we construct a new framework with popular encoder-decoder\narchitecture for point cloud completion. The proposed framework, namely\nPointAttN, is simple, neat and effective, which can precisely capture the\nstructural information of 3D shapes and predict complete point clouds with\nhighly detailed geometries. Experimental results demonstrate that our PointAttN\noutperforms state-of-the-art methods by a large margin on popular benchmarks\nlike Completion3D and PCN. Code is available at:\nhttps://github.com/ohhhyeahhh/PointAttN",
    "descriptor": "",
    "authors": [
      "Jun Wang",
      "Ying Cui",
      "Dongyan Guo",
      "Junxia Li",
      "Qingshan Liu",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08485"
  },
  {
    "id": "arXiv:2203.08490",
    "title": "Learning Audio Representations with MLPs",
    "abstract": "In this paper, we propose an efficient MLP-based approach for learning audio\nrepresentations, namely timestamp and scene-level audio embeddings. We use an\nencoder consisting of sequentially stacked gated MLP blocks, which accept 2D\nMFCCs as inputs. In addition, we also provide a simple temporal\ninterpolation-based algorithm for computing scene-level embeddings from\ntimestamp embeddings. The audio representations generated by our method are\nevaluated across a diverse set of benchmarks at the Holistic Evaluation of\nAudio Representations (HEAR) challenge, hosted at the NeurIPS 2021 competition\ntrack. We achieved first place on the Speech Commands (full), Speech Commands\n(5 hours), and the Mridingham Tonic benchmarks. Furthermore, our approach is\nalso the most resource-efficient among all the submitted methods, in terms of\nboth the number of model parameters and the time required to compute\nembeddings.",
    "descriptor": "\nComments: In submission to Proceedings of Machine Learning Research (PMLR): NeurIPS 2021 Competition Track\n",
    "authors": [
      "Mashrur M. Morshed",
      "Ahmad Omar Ahsan",
      "Hasan Mahmud",
      "Md. Kamrul Hasan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.08490"
  },
  {
    "id": "arXiv:2203.08491",
    "title": "Deepchecks: A Library for Testing and Validating Machine Learning Models  and Data",
    "abstract": "This paper presents Deepchecks, a Python library for comprehensively\nvalidating machine learning models and data. Our goal is to provide an\neasy-to-use library comprising of many checks related to various types of\nissues, such as model predictive performance, data integrity, data distribution\nmismatches, and more. The package is distributed under the GNU Affero General\nPublic License (AGPL) and relies on core libraries from the scientific Python\necosystem: scikit-learn, PyTorch, NumPy, pandas, and SciPy. Source code,\ndocumentation, examples, and an extensive user guide can be found at\n\\url{https://github.com/deepchecks/deepchecks} and\n\\url{https://docs.deepchecks.com/}.",
    "descriptor": "",
    "authors": [
      "Shir Chorev",
      "Philip Tannor",
      "Dan Ben Israel",
      "Noam Bressler",
      "Itay Gabbay",
      "Nir Hutnik",
      "Jonatan Liberman",
      "Matan Perlmutter",
      "Yurii Romanyshyn",
      "Lior Rokach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.08491"
  },
  {
    "id": "arXiv:2203.08492",
    "title": "Resilient Neural Forecasting Systems",
    "abstract": "Industrial machine learning systems face data challenges that are often\nunder-explored in the academic literature. Common data challenges are data\ndistribution shifts, missing values and anomalies. In this paper, we discuss\ndata challenges and solutions in the context of a Neural Forecasting\napplication on labor planning.We discuss how to make this forecasting system\nresilient to these data challenges. We address changes in data distribution\nwith a periodic retraining scheme and discuss the critical importance of model\nstability in this setting. Furthermore, we show how our deep learning model\ndeals with missing values natively without requiring imputation. Finally, we\ndescribe how we detect anomalies in the input data and mitigate their effect\nbefore they impact the forecasts. This results in a fully autonomous\nforecasting system that compares favorably to a hybrid system consisting of the\nalgorithm and human overrides.",
    "descriptor": "\nComments: Published at: DEEM 20, June 14, 2020, Portland, OR, USA\n",
    "authors": [
      "Michael Bohlke-Schneider",
      "Shubham Kapoor",
      "Tim Januschowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08492"
  },
  {
    "id": "arXiv:2203.08496",
    "title": "Dynamic Grass Color Scale Display Technique Based on Grass Length for  Green Landscape-Friendly Animation Display",
    "abstract": "Recently, public displays such as liquid crystal displays (LCDs) are often\nused in urban green spaces, however, the display devices can spoil green\nlandscape of urban green spaces because they look like artificial materials. We\npreviously proposed a green landscape-friendly grass animation display method\nby controlling a pixel-by-pixel grass color dynamically. The grass color can be\nchanged by moving a green grass length in yellow grass, and the grass animation\ndisplay can play simple animations using grayscale images. In the previous\nresearch, the color scale was mapped to the green grass length subjectively,\nhowever, this method has not achieved displaying the grass colors corresponding\nto the color scale based on objective evaluations. Here, we introduce a dynamic\ngrass color scale display technique based on a grass length. In this paper, we\ndeveloped a grass color scale setting procedure to map the grass length to the\ncolor scale with five levels through image processing. Through the outdoor\nexperiment of the grass color scale setting procedure, the color scale can\ncorrespond to the green grass length based on a viewpoint. After the\nexperiments, we demonstrated a grass animation display to show the animations\nwith the color scale using the experiment results.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Kojiro Tanaka",
      "Yuichi Kato",
      "Masahiko Mikawa",
      "Makoto Fujisawa"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.08496"
  },
  {
    "id": "arXiv:2203.08498",
    "title": "Convergence Acceleration of Preconditioned CG Solver Based on Error  Vector Sampling for a Sequence of Linear Systems",
    "abstract": "In this paper, we focus on solving a sequence of linear systems with an\nidentical (or similar) coefficient matrix. For this type of problems, we\ninvestigate the subspace correction and deflation methods, which use an\nauxiliary matrix (subspace) to accelerate the convergence of the iterative\nmethod. In practical simulations, these acceleration methods typically work\nwell when the range of the auxiliary matrix contains eigenspaces corresponding\nto small eigenvalues of the coefficient matrix. We have developed a new\nalgebraic auxiliary matrix construction method based on error vector sampling,\nin which eigenvectors with small eigenvalues are efficiently identified in a\nsolution process. The generated auxiliary matrix is used for the convergence\nacceleration in the following solution step. Numerical tests confirm that both\nsubspace correction and deflation methods with the auxiliary matrix can\naccelerate the solution process of the iterative solver. Furthermore, we\nexamine the applicability of our technique to the estimation of the condition\nnumber of the coefficient matrix. The algorithm of preconditioned conjugate\ngradient (PCG) method with the condition number estimation is also shown.",
    "descriptor": "",
    "authors": [
      "Takeshi Iwashita",
      "Kota Ikehara",
      "Takeshi Fukaya",
      "Takeshi Mifune"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.08498"
  },
  {
    "id": "arXiv:2203.08500",
    "title": "HeterMPC: A Heterogeneous Graph Neural Network for Response Generation  in Multi-Party Conversations",
    "abstract": "Recently, various response generation models for two-party conversations have\nachieved impressive improvements, but less effort has been paid to multi-party\nconversations (MPCs) which are more practical and complicated. Compared with a\ntwo-party conversation where a dialogue context is a sequence of utterances,\nbuilding a response generation model for MPCs is more challenging, since there\nexist complicated context structures and the generated responses heavily rely\non both interlocutors (i.e., speaker and addressee) and history utterances. To\naddress these challenges, we present HeterMPC, a heterogeneous graph-based\nneural network for response generation in MPCs which models the semantics of\nutterances and interlocutors simultaneously with two types of nodes in a graph.\nBesides, we also design six types of meta relations with\nnode-edge-type-dependent parameters to characterize the heterogeneous\ninteractions within the graph. Through multi-hop updating, HeterMPC can\nadequately utilize the structural knowledge of conversations for response\ngeneration. Experimental results on the Ubuntu Internet Relay Chat (IRC)\nchannel benchmark show that HeterMPC outperforms various baseline models for\nresponse generation in MPCs.",
    "descriptor": "\nComments: Accepted by ACL 2022\n",
    "authors": [
      "Jia-Chen Gu",
      "Chao-Hong Tan",
      "Chongyang Tao",
      "Zhen-Hua Ling",
      "Huang Hu",
      "Xiubo Geng",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08500"
  },
  {
    "id": "arXiv:2203.08501",
    "title": "Monte Carlo PINNs: deep learning approach for forward and inverse  problems involving high dimensional fractional partial differential equations",
    "abstract": "We introduce a sampling based machine learning approach, Monte Carlo physics\ninformed neural networks (MC-PINNs), for solving forward and inverse fractional\npartial differential equations (FPDEs). As a generalization of physics informed\nneural networks (PINNs), our method relies on deep neural network surrogates in\naddition to a stochastic approximation strategy for computing the fractional\nderivatives of the DNN outputs. A key ingredient in our MC-PINNs is to\nconstruct an unbiased estimation of the physical soft constraints in the loss\nfunction. Our directly sampling approach can yield less overall computational\ncost compared to fPINNs proposed in \\cite{pang2019fpinns} and thus provide an\nopportunity for solving high dimensional fractional PDEs. We validate the\nperformance of MC-PINNs method via several examples that include high\ndimensional integral fractional Laplacian equations, parametric identification\nof time-space fractional PDEs, and fractional diffusion equation with random\ninputs. The results show that MC-PINNs is flexible and promising to tackle\nhigh-dimensional FPDEs.",
    "descriptor": "",
    "authors": [
      "Ling Guo",
      "Hao Wu",
      "Xiaochen Yu",
      "Tao Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08501"
  },
  {
    "id": "arXiv:2203.08504",
    "title": "A Survey of Historical Document Image Datasets",
    "abstract": "This paper presents a systematic literature review of image datasets for\ndocument image analysis, focusing on historical documents, such as handwritten\nmanuscripts and early prints. Finding appropriate datasets for historical\ndocument analysis is a crucial prerequisite to facilitate research using\ndifferent machine learning algorithms. However, because of the very large\nvariety of the actual data (e.g., scripts, tasks, dates, support systems, and\namount of deterioration), the different formats for data and label\nrepresentation, and the different evaluation processes and benchmarks, finding\nappropriate datasets is a difficult task. This work fills this gap, presenting\na meta-study on existing datasets. After a systematic selection process\n(according to PRISMA guidelines), we select 56 studies that are chosen based on\ndifferent factors, such as the year of publication, number of methods\nimplemented in the article, reliability of the chosen algorithms, dataset size,\nand journal outlet. We summarize each study by assigning it to one of three\npre-defined tasks: document classification, layout structure, or semantic\nanalysis. We present the statistics, document type, language, tasks, input\nvisual aspects, and ground truth information for every dataset. In addition, we\nprovide the benchmark tasks and results from these papers or recent\ncompetitions. We further discuss gaps and challenges in this domain. We\nadvocate for providing conversion tools to common formats (e.g., COCO format\nfor computer vision tasks) and always providing a set of evaluation metrics,\ninstead of just one, to make results comparable across studies.",
    "descriptor": "\nComments: 37 pages, 2 figures\n",
    "authors": [
      "Konstantina Nikolaidou",
      "Mathias Seuret",
      "Hamam Mokayed",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08504"
  },
  {
    "id": "arXiv:2203.08507",
    "title": "Personal Knowledge Graphs: Use Cases in e-learning Platforms",
    "abstract": "Personal Knowledge Graphs (PKGs) are introduced by the semantic web community\nas small-sized user-centric knowledge graphs (KGs). PKGs fill the gap of\npersonalised representation of user data and interests on the top of big,\nwell-established encyclopedic KGs, such as DBpedia. Inspired by the widely\nrecent usage of PKGs in the medical domain to represent patient data, this PhD\nproposal aims to adopt a similar technique in the educational domain in\ne-learning platforms by deploying PKGs to represent users and learners. We\npropose a novel PKG development that relies on ontology and interlinks to\nLinked Open Data. Hence, adding the dimension of personalisation and\nexplainability in users' featured data while respecting privacy. This research\ndesign is developed in two use cases: a collaborative search learning platform\nand an e-learning platform. Our preliminary results show that e-learning\nplatforms can get benefited from our approach by providing personalised\nrecommendations and more user and group-specific data.",
    "descriptor": "",
    "authors": [
      "Eleni Ilkou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.08507"
  },
  {
    "id": "arXiv:2203.08508",
    "title": "Semantics-Aware Source Coding in Status Update Systems",
    "abstract": "We consider a communication system in which the destination receives status\nupdates from an information source that observes a physical process. The\ntransmitter performs semantics-empowered filtering as a means to send only the\nmost \"important\" samples to the receiver in a timely manner. As a first step,\nwe explore a simple policy where the transmitter selects to encode only a\nfraction of the most likely realizations of the observed random phenomenon,\ntreating the remaining ones as not important. For this timely source coding\nproblem, we derive the optimal codeword lengths in the sense of maximizing a\nsemantics-aware utility function and minimizing a quadratic average length\ncost. Our numerical results show the optimal number of updates to transmit for\ndifferent arrival rates and encoding costs and corroborate that semantic\nfiltering results in higher performance in terms of timely delivery of\nimportant updates.",
    "descriptor": "\nComments: Accepted for conference publication\n",
    "authors": [
      "Pouya Agheli",
      "Nikolaos Pappas",
      "Marios Kountouris"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.08508"
  },
  {
    "id": "arXiv:2203.08509",
    "title": "Differentiable DAG Sampling",
    "abstract": "We propose a new differentiable probabilistic model over DAGs (DP-DAG).\nDP-DAG allows fast and differentiable DAG sampling suited to continuous\noptimization. To this end, DP-DAG samples a DAG by successively (1) sampling a\nlinear ordering of the node and (2) sampling edges consistent with the sampled\nlinear ordering. We further propose VI-DP-DAG, a new method for DAG learning\nfrom observational data which combines DP-DAG with variational inference.\nHence,VI-DP-DAG approximates the posterior probability over DAG edges given the\nobserved data. VI-DP-DAG is guaranteed to output a valid DAG at any time during\ntraining and does not require any complex augmented Lagrangian optimization\nscheme in contrast to existing differentiable DAG learning approaches. In our\nextensive experiments, we compare VI-DP-DAG to other differentiable DAG\nlearning baselines on synthetic and real datasets. VI-DP-DAG significantly\nimproves DAG structure and causal mechanism learning while training faster than\ncompetitors.",
    "descriptor": "",
    "authors": [
      "Bertrand Charpentier",
      "Simon Kibler",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08509"
  },
  {
    "id": "arXiv:2203.08512",
    "title": "ConTinTin: Continual Learning from Task Instructions",
    "abstract": "The mainstream machine learning paradigms for NLP often work with two\nunderlying presumptions. First, the target task is predefined and static, a\nsystem just needs to learn to solve it exclusively. Second, the supervision of\na task mainly comes from a set of labeled examples. A question arises: how to\nbuild a system that can keep learning new tasks from their instructions? This\nwork defines a new learning paradigm ConTinTin (Continual Learning from Task\nInstructions), in which a system should learn a sequence of new tasks one by\none, each task is explained by a piece of textual instruction. The system is\nrequired to (i) generate the expected outputs of a new task by learning from\nits instruction, (ii) transfer the knowledge acquired from upstream tasks to\nhelp solve downstream tasks (i.e, forward-transfer), and (iii) retain or even\nimprove the performance on earlier tasks after learning new tasks (i.e.,\nbackward-transfer). This new problem is studied on a stream of more than 60\ntasks, each equipped with an instruction. Technically, our method\nInstructionSpeak contains two strategies that make full use of task\ninstructions to improve forward-transfer and backward-transfer: one is to learn\nfrom the negative output, the other is to re-visit instructions of prior tasks.\nTo our knowledge, this is the first time to study ConTinTin in NLP. In addition\nto the problem formulation and our promising approach, this work also\ncontributes to providing rich analyses for the community to better understand\nthis novel learning problem.",
    "descriptor": "\nComments: ACL'2022 camera-ready\n",
    "authors": [
      "Wenpeng Yin",
      "Jia Li",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08512"
  },
  {
    "id": "arXiv:2203.08513",
    "title": "Multi-focus thermal image fusion",
    "abstract": "This paper proposes a novel algorithm for multi-focus thermal image fusion.\nThe algorithm is based on local activity analysis and advanced pre-selection of\nimages into fusion process. The algorithm improves the object temperature\nmeasurement error up to 5 Celsius degrees. The proposed algorithm is evaluated\nby half total error rate, root mean squared error, cross correlation and visual\ninspection. To the best of our knowledge, this is the first work devoted to\nmulti-focus thermal image fusion. For testing of proposed algorithm we acquire\nsix thermal image set with objects at different focal depth.",
    "descriptor": "\nComments: 16 pages, published in Pattern Recognition Letters, Volume 34, Issue 5, 2013, Pages 536-544, ISSN 0167-8655\n",
    "authors": [
      "Radek Benes",
      "Pavel Dvorak",
      "Marcos Faundez-Zanuy",
      "Virginia Espinosa-Duro",
      "Jiri Mekyska"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08513"
  },
  {
    "id": "arXiv:2203.08515",
    "title": "DRT-based modelling framework for Li-ion cells",
    "abstract": "The correct assessment of battery states is essential to maximize battery\npack performances while ensuring reliable and safe operation. This work\nintroduces EIS2MOD, a novel modelling framework for Li-ion cells based on\nDistribution of Relaxation Time (DRT). A physically based Electric Circuit\nModel (ECM) is developed starting from Electrochemical Impedance Spectroscopy\n(EIS) and Open Circuit Voltage (OCV) measurements. DRT is applied to deconvolve\nthe electrochemical phenomena from the EIS. The presented methodology is based\non: i) DRT calculation from EIS, ii) DRT analysis for ECM configuration and\niii) Model parameters extraction and fitting. The proposed framework is applied\nto large format Li-ion pouch cells, which are tested over the whole State of\nCharge (SoC) range and a wide temperature range (-10{\\deg}C to 35{\\deg}C).\nDifferent current profiles have been tested to validate the model, showing its\nhigh accuracy in reproducing the battery cell behavior (e.g. RMSE on the\nbattery terminals voltage lower than 1.50% for driving cycle simulations at\nvariable temperature and SoC). An additional advantage of EIS2MOD is its light\ncomputational load thus offering an attractive framework for battery management\nsystem implementation.",
    "descriptor": "\nComments: 11 pages, 10 figures\n",
    "authors": [
      "Pietro Iurilli",
      "Claudio Brivio",
      "Rafael E. Carrillo",
      "Vanessa Wood"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08515"
  },
  {
    "id": "arXiv:2203.08516",
    "title": "Fantastic Style Channels and Where to Find Them: A Submodular Framework  for Discovering Diverse Directions in GANs",
    "abstract": "The discovery of interpretable directions in the latent spaces of pre-trained\nGAN models has recently become a popular topic. In particular, StyleGAN2 has\nenabled various image generation and manipulation tasks due to its rich and\ndisentangled latent spaces. The discovery of such directions is typically done\neither in a supervised manner, which requires annotated data for each desired\nmanipulation or in an unsupervised manner, which requires a manual effort to\nidentify the directions. As a result, existing work typically finds only a\nhandful of directions in which controllable edits can be made. In this study,\nwe design a novel submodular framework that finds the most representative and\ndiverse subset of directions in the latent space of StyleGAN2. Our approach\ntakes advantage of the latent space of channel-wise style parameters, so-called\nstylespace, in which we cluster channels that perform similar manipulations\ninto groups. Our framework promotes diversity by using the notion of clusters\nand can be efficiently solved with a greedy optimization scheme. We evaluate\nour framework with qualitative and quantitative experiments and show that our\nmethod finds more diverse and disentangled directions. Our project page can be\nfound at this http URL",
    "descriptor": "",
    "authors": [
      "Enis Simsar",
      "Umut Kocasari",
      "Ezgi G\u00fclperi Er",
      "Pinar Yanardag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08516"
  },
  {
    "id": "arXiv:2203.08517",
    "title": "TegTok: Augmenting Text Generation via Task-specific and Open-world  Knowledge",
    "abstract": "Generating natural and informative texts has been a long-standing problem in\nNLP. Much effort has been dedicated into incorporating pre-trained language\nmodels (PLMs) with various open-world knowledge, such as knowledge graphs or\nwiki pages. However, their ability to access and manipulate the task-specific\nknowledge is still limited on downstream tasks, as this type of knowledge is\nusually not well covered in PLMs and is hard to acquire. To address the\nproblem, we propose augmenting TExt Generation via Task-specific and Open-world\nKnowledge (TegTok) in a unified framework. Our model selects knowledge entries\nfrom two types of knowledge sources through dense retrieval and then injects\nthem into the input encoding and output decoding stages respectively on the\nbasis of PLMs. With the help of these two types of knowledge, our model can\nlearn what and how to generate. Experiments on two text generation tasks of\ndialogue generation and question generation, and on two datasets show that our\nmethod achieves better performance than various baseline models.",
    "descriptor": "\nComments: Accepted by Findings of ACL 2022\n",
    "authors": [
      "Chao-Hong Tan",
      "Jia-Chen Gu",
      "Chongyang Tao",
      "Zhen-Hua Ling",
      "Can Xu",
      "Huang Hu",
      "Xiubo Geng",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08517"
  },
  {
    "id": "arXiv:2203.08519",
    "title": "Towards Practical Certifiable Patch Defense with Vision Transformer",
    "abstract": "Patch attacks, one of the most threatening forms of physical attack in\nadversarial examples, can lead networks to induce misclassification by\nmodifying pixels arbitrarily in a continuous region. Certifiable patch defense\ncan guarantee robustness that the classifier is not affected by patch attacks.\nExisting certifiable patch defenses sacrifice the clean accuracy of classifiers\nand only obtain a low certified accuracy on toy datasets. Furthermore, the\nclean and certified accuracy of these methods is still significantly lower than\nthe accuracy of normal classification networks, which limits their application\nin practice. To move towards a practical certifiable patch defense, we\nintroduce Vision Transformer (ViT) into the framework of Derandomized Smoothing\n(DS). Specifically, we propose a progressive smoothed image modeling task to\ntrain Vision Transformer, which can capture the more discriminable local\ncontext of an image while preserving the global semantic information. For\nefficient inference and deployment in the real world, we innovatively\nreconstruct the global self-attention structure of the original ViT into\nisolated band unit self-attention. On ImageNet, under 2% area patch attacks our\nmethod achieves 41.70% certified accuracy, a nearly 1-fold increase over the\nprevious best method (26.00%). Simultaneously, our method achieves 78.58% clean\naccuracy, which is quite close to the normal ResNet-101 accuracy. Extensive\nexperiments show that our method obtains state-of-the-art clean and certified\naccuracy with inferring efficiently on CIFAR-10 and ImageNet.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Zhaoyu Chen",
      "Bo Li",
      "Jianghe Xu",
      "Shuang Wu",
      "Shouhong Ding",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08519"
  },
  {
    "id": "arXiv:2203.08524",
    "title": "New Converse Bounds on the Mismatched Reliability Function and the  Mismatch Capacity Using an Auxiliary Genie Receiver",
    "abstract": "We develop a novel framework for proving converse theorems for channel coding\nwhich is based on introducing a \"genie-aided-genie\" to the analysis technique\nof multicast transmission to an auxiliary receiver. This technique is used to\nderive upper bounds on the reliability function of the discrete memoryless\nchannel with a mismatched decoding metric and on the mismatch capacity. Unlike\nprevious works, our bounding technique exploits also the inherent symmetric\nrequirement from all of the hypothesized codewords, leading to these new upper\nbounds which are tighter. Since the computations of most of the known bounds on\nthe mismatch capacity are rather complicated, we further present a method to\nobtain relaxed bounds that are easier to compute. We conclude by presenting\nsimpler bounds on the reliability function, and provide sufficient conditions\nfor their tightness in certain ranges of rates.",
    "descriptor": "",
    "authors": [
      "Anelia Somekh-Baruch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.08524"
  },
  {
    "id": "arXiv:2203.08527",
    "title": "Morphological Reinflection with Multiple Arguments: An Extended  Annotation schema and a Georgian Case Study",
    "abstract": "In recent years, a flurry of morphological datasets had emerged, most notably\nUniMorph, a multi-lingual repository of inflection tables. However, the flat\nstructure of the current morphological annotation schemas makes the treatment\nof some languages quirky, if not impossible, specifically in cases of\npolypersonal agreement. In this paper we propose a general solution for such\ncases and expand the UniMorph annotation schema to naturally address this\nphenomenon, in which verbs agree with multiple arguments using true affixes. We\napply this extended schema to one such language, Georgian, and provide a\nhuman-verified, accurate and balanced morphological dataset for Georgian verbs.\nThe dataset has 4 times more tables and 6 times more verb forms compared to the\nexisting UniMorph dataset, covering all possible variants of argument marking,\ndemonstrating the adequacy of our proposed scheme. Experiments with a standard\nreinflection model show that generalization is easy when the data is split at\nthe form level, but extremely hard when splitting along lemma lines. Expanding\nthe other languages in UniMorph to this schema is expected to improve both the\ncoverage, consistency and interpretability of this benchmark.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "David Guriel",
      "Omer Goldman",
      "Reut Tsarfaty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08527"
  },
  {
    "id": "arXiv:2203.08528",
    "title": "Physical Inertial Poser (PIP): Physics-aware Real-time Human Motion  Tracking from Sparse Inertial Sensors",
    "abstract": "Motion capture from sparse inertial sensors has shown great potential\ncompared to image-based approaches since occlusions do not lead to a reduced\ntracking quality and the recording space is not restricted to be within the\nviewing frustum of the camera. However, capturing the motion and global\nposition only from a sparse set of inertial sensors is inherently ambiguous and\nchallenging. In consequence, recent state-of-the-art methods can barely handle\nvery long period motions, and unrealistic artifacts are common due to the\nunawareness of physical constraints. To this end, we present the first method\nwhich combines a neural kinematics estimator and a physics-aware motion\noptimizer to track body motions with only 6 inertial sensors. The kinematics\nmodule first regresses the motion status as a reference, and then the physics\nmodule refines the motion to satisfy the physical constraints. Experiments\ndemonstrate a clear improvement over the state of the art in terms of capture\naccuracy, temporal stability, and physical correctness.",
    "descriptor": "\nComments: Accepted by CVPR 2022 with 3 strong accepts. Project page: this https URL\n",
    "authors": [
      "Xinyu Yi",
      "Yuxiao Zhou",
      "Marc Habermann",
      "Soshi Shimada",
      "Vladislav Golyanik",
      "Christian Theobalt",
      "Feng Xu"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.08528"
  },
  {
    "id": "arXiv:2203.08532",
    "title": "An introduction to POD-Greedy-Galerkin reduced basis method",
    "abstract": "Partial differential equations can be used to model many problems in several\nfields of application including, e.g., fluid mechanics, heat and mass transfer,\nand electromagnetism. Accurate discretization methods (e.g., finite element or\nfinite volume methods, the so-called full order models) are widely used to\nnumerically solve these problems. However, when many physical and/or\ngeometrical parameters are involved, the computational cost required by full\norder models becomes prohibitively expensive and this is not acceptable for\nreal-time computations that are becoming more and more popular for rapid\nprototyping. Therefore, there is the need to introduce reduced order methods\n(also referred to as reduced basis methods) able to provide, as the input\nparameters change, fast and reliable solutions at a reduced computational cost.",
    "descriptor": "",
    "authors": [
      "Pierfrancesco Siena",
      "Michele Girfoglio",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08532"
  },
  {
    "id": "arXiv:2203.08534",
    "title": "Capturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape  Estimation from Monocular Video",
    "abstract": "Learning to capture human motion is essential to 3D human pose and shape\nestimation from monocular video. However, the existing methods mainly rely on\nrecurrent or convolutional operation to model such temporal information, which\nlimits the ability to capture non-local context relations of human motion. To\naddress this problem, we propose a motion pose and shape network (MPS-Net) to\neffectively capture humans in motion to estimate accurate and temporally\ncoherent 3D human pose and shape from a video. Specifically, we first propose a\nmotion continuity attention (MoCA) module that leverages visual cues observed\nfrom human motion to adaptively recalibrate the range that needs attention in\nthe sequence to better capture the motion continuity dependencies. Then, we\ndevelop a hierarchical attentive feature integration (HAFI) module to\neffectively combine adjacent past and future feature representations to\nstrengthen temporal correlation and refine the feature representation of the\ncurrent frame. By coupling the MoCA and HAFI modules, the proposed MPS-Net\nexcels in estimating 3D human pose and shape in the video. Though conceptually\nsimple, our MPS-Net not only outperforms the state-of-the-art methods on the\n3DPW, MPI-INF-3DHP, and Human3.6M benchmark datasets, but also uses fewer\nnetwork parameters. The video demos can be found at\nhttps://mps-net.github.io/MPS-Net/.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Wen-Li Wei",
      "Jen-Chun Lin",
      "Tyng-Luh Liu",
      "Hong-Yuan Mark Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08534"
  },
  {
    "id": "arXiv:2203.08537",
    "title": "Scribble-Supervised LiDAR Semantic Segmentation",
    "abstract": "Densely annotating LiDAR point clouds remains too expensive and\ntime-consuming to keep up with the ever growing volume of data. While current\nliterature focuses on fully-supervised performance, developing efficient\nmethods that take advantage of realistic weak supervision have yet to be\nexplored. In this paper, we propose using scribbles to annotate LiDAR point\nclouds and release ScribbleKITTI, the first scribble-annotated dataset for\nLiDAR semantic segmentation. Furthermore, we present a pipeline to reduce the\nperformance gap that arises when using such weak annotations. Our pipeline\ncomprises of three stand-alone contributions that can be combined with any\nLiDAR semantic segmentation model to achieve up to 95.7% of the\nfully-supervised performance while using only 8% labeled points. Our scribble\nannotations and code are available at github.com/ouenal/scribblekitti.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Ozan Unal",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08537"
  },
  {
    "id": "arXiv:2203.08542",
    "title": "Lazy-MDPs: Towards Interpretable Reinforcement Learning by Learning When  to Act",
    "abstract": "Traditionally, Reinforcement Learning (RL) aims at deciding how to act\noptimally for an artificial agent. We argue that deciding when to act is\nequally important. As humans, we drift from default, instinctive or memorized\nbehaviors to focused, thought-out behaviors when required by the situation. To\nenhance RL agents with this aptitude, we propose to augment the standard Markov\nDecision Process and make a new mode of action available: being lazy, which\ndefers decision-making to a default policy. In addition, we penalize non-lazy\nactions in order to encourage minimal effort and have agents focus on critical\ndecisions only. We name the resulting formalism lazy-MDPs. We study the\ntheoretical properties of lazy-MDPs, expressing value functions and\ncharacterizing optimal solutions. Then we empirically demonstrate that policies\nlearned in lazy-MDPs generally come with a form of interpretability: by\nconstruction, they show us the states where the agent takes control over the\ndefault policy. We deem those states and corresponding actions important since\nthey explain the difference in performance between the default and the new,\nlazy policy. With suboptimal policies as default (pretrained or random), we\nobserve that agents are able to get competitive performance in Atari games\nwhile only taking control in a limited subset of states.",
    "descriptor": "\nComments: AAMAS 2022 (14 pages extended version, added Sec. 7.4 and appendix K)\n",
    "authors": [
      "Alexis Jacq",
      "Johan Ferret",
      "Olivier Pietquin",
      "Matthieu Geist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08542"
  },
  {
    "id": "arXiv:2203.08543",
    "title": "Integrating Language Guidance into Vision-based Deep Metric Learning",
    "abstract": "Deep Metric Learning (DML) proposes to learn metric spaces which encode\nsemantic similarities as embedding space distances. These spaces should be\ntransferable to classes beyond those seen during training. Commonly, DML\nmethods task networks to solve contrastive ranking tasks defined over binary\nclass assignments. However, such approaches ignore higher-level semantic\nrelations between the actual classes. This causes learned embedding spaces to\nencode incomplete semantic context and misrepresent the semantic relation\nbetween classes, impacting the generalizability of the learned metric space. To\ntackle this issue, we propose a language guidance objective for visual\nsimilarity learning. Leveraging language embeddings of expert- and\npseudo-classnames, we contextualize and realign visual representation spaces\ncorresponding to meaningful language semantics for better semantic consistency.\nExtensive experiments and ablations provide a strong motivation for our\nproposed approach and show language guidance offering significant,\nmodel-agnostic improvements for DML, achieving competitive and state-of-the-art\nresults on all benchmarks. Code available at\nhttps://github.com/ExplainableML/LanguageGuidance_for_DML.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Karsten Roth",
      "Oriol Vinyals",
      "Zeynep Akata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08543"
  },
  {
    "id": "arXiv:2203.08546",
    "title": "Subgame-perfect Equilibria in Mean-payoff Games (journal version)",
    "abstract": "In this paper, we provide an effective characterization of all the\nsubgame-perfect equilibria in infinite duration games played on finite graphs\nwith mean-payoff objectives. To this end, we introduce the notion of\nrequirement, and the notion of negotiation function. We establish that the\nplays that are supported by SPEs are exactly those that are consistent with a\nfixed point of the negotiation function. Finally, we use that characterization\nto prove that the SPE threshold problem, who status was left open in the\nliterature, is decidable.",
    "descriptor": "",
    "authors": [
      "L\u00e9onard Brice",
      "Marie van den Bogaard",
      "JEan-Fran\u00e7ois Raskin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.08546"
  },
  {
    "id": "arXiv:2203.08547",
    "title": "Non-isotropy Regularization for Proxy-based Deep Metric Learning",
    "abstract": "Deep Metric Learning (DML) aims to learn representation spaces on which\nsemantic relations can simply be expressed through predefined distance metrics.\nBest performing approaches commonly leverage class proxies as sample stand-ins\nfor better convergence and generalization. However, these proxy-methods solely\noptimize for sample-proxy distances. Given the inherent non-bijectiveness of\nused distance functions, this can induce locally isotropic sample\ndistributions, leading to crucial semantic context being missed due to\ndifficulties resolving local structures and intraclass relations between\nsamples. To alleviate this problem, we propose non-isotropy regularization\n($\\mathbb{NIR}$) for proxy-based Deep Metric Learning. By leveraging\nNormalizing Flows, we enforce unique translatability of samples from their\nrespective class proxies. This allows us to explicitly induce a non-isotropic\ndistribution of samples around a proxy to optimize for. In doing so, we equip\nproxy-based objectives to better learn local structures. Extensive experiments\nhighlight consistent generalization benefits of $\\mathbb{NIR}$ while achieving\ncompetitive and state-of-the-art performance on the standard benchmarks\nCUB200-2011, Cars196 and Stanford Online Products. In addition, we find the\nsuperior convergence properties of proxy-based methods to still be retained or\neven improved, making $\\mathbb{NIR}$ very attractive for practical usage. Code\navailable at https://github.com/ExplainableML/NonIsotropicProxyDML.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Karsten Roth",
      "Oriol Vinyals",
      "Zeynep Akata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08547"
  },
  {
    "id": "arXiv:2203.08548",
    "title": "SoK: TEE-assisted Confidential Smart Contract",
    "abstract": "The blockchain-based smart contract lacks privacy since the contract state\nand instruction code are exposed to the public. Combining smart-contract\nexecution with Trusted Execution Environments (TEEs) provides an efficient\nsolution, called TEE-assisted smart contracts, for protecting the\nconfidentiality of contract states. However, the combination approaches are\nvaried, and a systematic study is absent. Newly released systems may fail to\ndraw upon the experience learned from existing protocols, such as repeating\nknown design mistakes or applying TEE technology in insecure ways. In this\npaper, we first investigate and categorize the existing systems into two types:\nthe layer-one solution and layer-two solution. Then, we establish an analysis\nframework to capture their common lights, covering the desired properties (for\ncontract services), threat models, and security considerations (for underlying\nsystems). Based on our taxonomy, we identify their ideal functionalities and\nuncover the fundamental flaws and reasons for the challenges in each\nspecification design. We believe that this work would provide a guide for the\ndevelopment of TEE-assisted smart contracts, as well as a framework to evaluate\nfuture TEE-assisted confidential contract systems.",
    "descriptor": "\nComments: Accepted by PETs 2022\n",
    "authors": [
      "Rujia Li",
      "Qin Wang",
      "Qi Wang",
      "David Galindo",
      "Mark Ryan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08548"
  },
  {
    "id": "arXiv:2203.08549",
    "title": "Is it all a cluster game? -- Exploring Out-of-Distribution Detection  based on Clustering in the Embedding Space",
    "abstract": "It is essential for safety-critical applications of deep neural networks to\ndetermine when new inputs are significantly different from the training\ndistribution. In this paper, we explore this out-of-distribution (OOD)\ndetection problem for image classification using clusters of semantically\nsimilar embeddings of the training data and exploit the differences in distance\nrelationships to these clusters between in- and out-of-distribution data. We\nstudy the structure and separation of clusters in the embedding space and find\nthat supervised contrastive learning leads to well-separated clusters while its\nself-supervised counterpart fails to do so. In our extensive analysis of\ndifferent training methods, clustering strategies, distance metrics, and\nthresholding approaches, we observe that there is no clear winner. The optimal\napproach depends on the model architecture and selected datasets for in- and\nout-of-distribution. While we could reproduce the outstanding results for\ncontrastive training on CIFAR-10 as in-distribution data, we find standard\ncross-entropy paired with cosine similarity outperforms all contrastive\ntraining methods when training on CIFAR-100 instead. Cross-entropy provides\ncompetitive results as compared to expensive contrastive training methods.",
    "descriptor": "",
    "authors": [
      "Poulami Sinhamahapatra",
      "Rajat Koner",
      "Karsten Roscher",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08549"
  },
  {
    "id": "arXiv:2203.08550",
    "title": "Biomimetic Evaluation of an Underwater Soft Hand Through Deep  Learning-based 3D Pose Reconstruction",
    "abstract": "Soft robotic hand shows considerable promise for various grasping\napplications. However, the sensing and reconstruction of the robot pose will\ncause limitation during the design and fabrication. In this work, we present a\nnovel 3D pose reconstruction approach to analyze the grasping motion of a\nbidirectional soft robotic hand using experiment videos. The images from top,\nfront, back, left, right view were collected using an\none-camera-multiple-mirror imaging device. The coordinate and orientation\ninformation of soft fingers are detected based on deep learning methods. Faster\nRCNN model is used to detect the position of fingertips, while U-Net model is\napplied to calculate the side boundary of the fingers. Based on the kinematics,\nthe corresponding coordinate and orientation databases are established. The 3D\npose reconstructed result presents a satisfactory performance and good\naccuracy. Using efficacy coefficient method, the finger contribution of the\nbending angle and distance between fingers of soft robot hand is analyzed by\ncompared with that of human hand. The results show that the soft robot hand\nperform a human-like motion in both single-direction and bidirectional\ngrasping.",
    "descriptor": "",
    "authors": [
      "Haihang Wang",
      "He Xu",
      "Yihan Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08550"
  },
  {
    "id": "arXiv:2203.08552",
    "title": "Multilingual Pre-training with Language and Task Adaptation for  Multilingual Text Style Transfer",
    "abstract": "We exploit the pre-trained seq2seq model mBART for multilingual text style\ntransfer. Using machine translated data as well as gold aligned English\nsentences yields state-of-the-art results in the three target languages we\nconsider. Besides, in view of the general scarcity of parallel data, we propose\na modular approach for multilingual formality transfer, which consists of two\ntraining strategies that target adaptation to both language and task. Our\napproach achieves competitive performance without monolingual task-specific\nparallel data and can be applied to other style transfer tasks as well as to\nother languages.",
    "descriptor": "\nComments: Accepted to ACL 2022\n",
    "authors": [
      "Huiyuan Lai",
      "Antonio Toral",
      "Malvina Nissim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08552"
  },
  {
    "id": "arXiv:2203.08553",
    "title": "PMIC: Improving Multi-Agent Reinforcement Learning with Progressive  Mutual Information Collaboration",
    "abstract": "Learning to collaborate is critical in multi-agent reinforcement learning\n(MARL). A number of previous works promote collaboration by maximizing the\ncorrelation of agents' behaviors, which is typically characterised by mutual\ninformation (MI) in different forms. However, in this paper, we reveal that\nstrong correlation can emerge from sub-optimal collaborative behaviors, and\nsimply maximizing the MI can, surprisingly, hinder the learning towards better\ncollaboration. To address this issue, we propose a novel MARL framework, called\nProgressive Mutual Information Collaboration (PMIC), for more effective\nMI-driven collaboration. In PMIC, we use a new collaboration criterion measured\nby the MI between global states and joint actions. Based on the criterion, the\nkey idea of PMIC is maximizing the MI associated with superior collaborative\nbehaviors and minimizing the MI associated with inferior ones. The two MI\nobjectives play complementary roles by facilitating learning towards better\ncollaborations while avoiding falling into sub-optimal ones. Specifically, PMIC\nstores and progressively maintains sets of superior and inferior interaction\nexperiences, from which dual MI neural estimators are established. Experiments\non a wide range of MARL benchmarks show the superior performance of PMIC\ncompared with other algorithms.",
    "descriptor": "\nComments: A preliminary version has been accepted on the Cooperative AI Workshop at 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Pengyi Li",
      "Hongyao Tang",
      "Tianpei Yang",
      "Xiaotian Hao",
      "Tong Sang",
      "Yan Zheng",
      "Jianye Hao",
      "Matthew E.Taylor",
      "Zhen Wang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08553"
  },
  {
    "id": "arXiv:2203.08555",
    "title": "Zero-Shot Dependency Parsing with Worst-Case Aware Automated Curriculum  Learning",
    "abstract": "Large multilingual pretrained language models such as mBERT and XLM-RoBERTa\nhave been found to be surprisingly effective for cross-lingual transfer of\nsyntactic parsing models (Wu and Dredze 2019), but only between related\nlanguages. However, source and training languages are rarely related, when\nparsing truly low-resource languages. To close this gap, we adopt a method from\nmulti-task learning, which relies on automated curriculum learning, to\ndynamically optimize for parsing performance on outlier languages. We show that\nthis approach is significantly better than uniform and size-proportional\nsampling in the zero-shot setting.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Miryam de Lhoneux",
      "Sheng Zhang",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08555"
  },
  {
    "id": "arXiv:2203.08556",
    "title": "LEVEN: A Large-Scale Chinese Legal Event Detection Dataset",
    "abstract": "Recognizing facts is the most fundamental step in making judgments, hence\ndetecting events in the legal documents is important to legal case analysis\ntasks. However, existing Legal Event Detection (LED) datasets only concern\nincomprehensive event types and have limited annotated data, which restricts\nthe development of LED methods and their downstream applications. To alleviate\nthese issues, we present LEVEN a large-scale Chinese LEgal eVENt detection\ndataset, with 8,116 legal documents and 150,977 human-annotated event mentions\nin 108 event types. Not only charge-related events, LEVEN also covers general\nevents, which are critical for legal case understanding but neglected in\nexisting LED datasets. To our knowledge, LEVEN is the largest LED dataset and\nhas dozens of times the data scale of others, which shall significantly promote\nthe training and evaluation of LED methods. The results of extensive\nexperiments indicate that LED is challenging and needs further effort.\nMoreover, we simply utilize legal events as side information to promote\ndownstream applications. The method achieves improvements of average 2.2 points\nprecision in low-resource judgment prediction, and 1.5 points mean average\nprecision in unsupervised case retrieval, which suggests the fundamentality of\nLED. The source code and dataset can be obtained from\nhttps://github.com/thunlp/LEVEN.",
    "descriptor": "\nComments: Accepted to ACL2022 Findings\n",
    "authors": [
      "Feng Yao",
      "Chaojun Xiao",
      "Xiaozhi Wang",
      "Zhiyuan Liu",
      "Lei Hou",
      "Cunchao Tu",
      "Juanzi Li",
      "Yun Liu",
      "Weixing Shen",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08556"
  },
  {
    "id": "arXiv:2203.08557",
    "title": "How darknet market users learned to worry more and love PGP: Analysis of  security advice on darknet marketplaces",
    "abstract": "Darknet marketplaces, accessible through, Tor are where users can buy illicit\ngoods, and learn to hide from law enforcement. We surveyed the advice on these\nmarkets and found valid security advice mixed up with paranoid threat models\nand a reliance on privacy tools dismissed as unusable by the mainstream.",
    "descriptor": "",
    "authors": [
      "Andrew C. Dwyer",
      "Joseph Hallett",
      "Claudia Peersman",
      "Matthew Edwards",
      "Brittany I. Davidson",
      "Awais Rashid"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08557"
  },
  {
    "id": "arXiv:2203.08559",
    "title": "Learning to Generate Synthetic Training Data using Gradient Matching and  Implicit Differentiation",
    "abstract": "Using huge training datasets can be costly and inconvenient. This article\nexplores various data distillation techniques that can reduce the amount of\ndata required to successfully train deep networks. Inspired by recent ideas, we\nsuggest new data distillation techniques based on generative teaching networks,\ngradient matching, and the Implicit Function Theorem. Experiments with the\nMNIST image classification problem show that the new methods are\ncomputationally more efficient than previous ones and allow to increase the\nperformance of models trained on distilled data.",
    "descriptor": "",
    "authors": [
      "Dmitry Medvedev",
      "Alexander D'yakonov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08559"
  },
  {
    "id": "arXiv:2203.08563",
    "title": "MonoJSG: Joint Semantic and Geometric Cost Volume for Monocular 3D  Object Detection",
    "abstract": "Due to the inherent ill-posed nature of 2D-3D projection, monocular 3D object\ndetection lacks accurate depth recovery ability. Although the deep neural\nnetwork (DNN) enables monocular depth-sensing from high-level learned features,\nthe pixel-level cues are usually omitted due to the deep convolution mechanism.\nTo benefit from both the powerful feature representation in DNN and pixel-level\ngeometric constraints, we reformulate the monocular object depth estimation as\na progressive refinement problem and propose a joint semantic and geometric\ncost volume to model the depth error. Specifically, we first leverage neural\nnetworks to learn the object position, dimension, and dense normalized 3D\nobject coordinates. Based on the object depth, the dense coordinates patch\ntogether with the corresponding object features is reprojected to the image\nspace to build a cost volume in a joint semantic and geometric error manner.\nThe final depth is obtained by feeding the cost volume to a refinement network,\nwhere the distribution of semantic and geometric error is regularized by direct\ndepth supervision. Through effectively mitigating depth error by the refinement\nframework, we achieve state-of-the-art results on both the KITTI and Waymo\ndatasets.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Qing Lian",
      "Peiliang Li",
      "Xiaozhi Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08563"
  },
  {
    "id": "arXiv:2203.08565",
    "title": "Geographic Adaptation of Pretrained Language Models",
    "abstract": "Geographic linguistic features are commonly used to improve the performance\nof pretrained language models (PLMs) on NLP tasks where geographic knowledge is\nintuitively beneficial (e.g., geolocation prediction and dialect feature\nprediction). Existing work, however, leverages such geographic information in\ntask-specific fine-tuning, failing to incorporate it into PLMs' geo-linguistic\nknowledge, which would make it transferable across different tasks. In this\nwork, we introduce an approach to task-agnostic geoadaptation of PLMs that\nforces the PLM to learn associations between linguistic phenomena and\ngeographic locations. More specifically, geoadaptation is an intermediate\ntraining step that couples masked language modeling and geolocation prediction\nin a dynamic multitask learning setup. In our experiments, we geoadapt BERTi\\'c\n-- a PLM for Bosnian, Croatian, Montenegrin, and Serbian (BCMS) -- using a\ncorpus of geotagged BCMS tweets. Evaluation on three different tasks, namely\nunsupervised (zero-shot) and supervised geolocation prediction and\n(unsupervised) prediction of dialect features, shows that our geoadaptation\napproach is very effective: e.g., we obtain new state-of-the-art performance in\nsupervised geolocation prediction and report massive gains over geographically\nuninformed PLMs on zero-shot geolocation prediction.",
    "descriptor": "",
    "authors": [
      "Valentin Hofmann",
      "Goran Glava\u0161",
      "Nikola Ljube\u0161i\u0107",
      "Janet B. Pierrehumbert",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08565"
  },
  {
    "id": "arXiv:2203.08566",
    "title": "EDTER: Edge Detection with Transformer",
    "abstract": "Convolutional neural networks have made significant progresses in edge\ndetection by progressively exploring the context and semantic features.\nHowever, local details are gradually suppressed with the enlarging of receptive\nfields. Recently, vision transformer has shown excellent capability in\ncapturing long-range dependencies. Inspired by this, we propose a novel\ntransformer-based edge detector, \\emph{Edge Detection TransformER (EDTER)}, to\nextract clear and crisp object boundaries and meaningful edges by exploiting\nthe full image context information and detailed local cues simultaneously.\nEDTER works in two stages. In Stage I, a global transformer encoder is used to\ncapture long-range global context on coarse-grained image patches. Then in\nStage II, a local transformer encoder works on fine-grained patches to excavate\nthe short-range local cues. Each transformer encoder is followed by an\nelaborately designed Bi-directional Multi-Level Aggregation decoder to achieve\nhigh-resolution features. Finally, the global context and local cues are\ncombined by a Feature Fusion Module and fed into a decision head for edge\nprediction. Extensive experiments on BSDS500, NYUDv2, and Multicue demonstrate\nthe superiority of EDTER in comparison with state-of-the-arts.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Mengyang Pu",
      "Yaping Huang",
      "Yuming Liu",
      "Qingji Guan",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08566"
  },
  {
    "id": "arXiv:2203.08568",
    "title": "In-Context Learning for Few-Shot Dialogue State Tracking",
    "abstract": "Collecting and annotating task-oriented dialogues is time-consuming and\ncostly. Thus, few-shot learning for dialogue tasks presents an exciting\nopportunity. In this work, we propose an in-context (IC) learning framework for\nfew-shot dialogue state tracking (DST), where a large pre-trained language\nmodel (LM) takes a test instance and a few annotated examples as input, and\ndirectly decodes the dialogue states without any parameter updates. This makes\nthe LM more flexible and scalable compared to prior few-shot DST work when\nadapting to new domains and scenarios. We study ways to formulate dialogue\ncontext into prompts for LMs and propose an efficient approach to retrieve\ndialogues as exemplars given a test instance and a selection pool of few-shot\nexamples. To better leverage the pre-trained LMs, we also reformulate DST into\na text-to-SQL problem. Empirical results on MultiWOZ 2.1 and 2.4 show that our\nmethod IC-DST outperforms previous fine-tuned state-of-the-art models in\nfew-shot settings.",
    "descriptor": "",
    "authors": [
      "Yushi Hu",
      "Chia-Hsuan Lee",
      "Tianbao Xie",
      "Tao Yu",
      "Noah A. Smith",
      "Mari Ostendorf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08568"
  },
  {
    "id": "arXiv:2203.08569",
    "title": "PMAL: Open Set Recognition via Robust Prototype Mining",
    "abstract": "Open Set Recognition (OSR) has been an emerging topic. Besides recognizing\npredefined classes, the system needs to reject the unknowns. Prototype learning\nis a potential manner to handle the problem, as its ability to improve\nintra-class compactness of representations is much needed in discrimination\nbetween the known and the unknowns. In this work, we propose a novel Prototype\nMining And Learning (PMAL) framework. It has a prototype mining mechanism\nbefore the phase of optimizing embedding space, explicitly considering two\ncrucial properties, namely high-quality and diversity of the prototype set.\nConcretely, a set of high-quality candidates are firstly extracted from\ntraining samples based on data uncertainty learning, avoiding the interference\nfrom unexpected noise. Considering the multifarious appearance of objects even\nin a single category, a diversity-based strategy for prototype set filtering is\nproposed. Accordingly, the embedding space can be better optimized to\ndiscriminate therein the predefined classes and between known and unknowns.\nExtensive experiments verify the two good characteristics (i.e., high-quality\nand diversity) embraced in prototype mining, and show the remarkable\nperformance of the proposed framework compared to state-of-the-arts.",
    "descriptor": "\nComments: accepted by AAAI2021\n",
    "authors": [
      "Jing Lu",
      "Yunxu Xu",
      "Hao Li",
      "Zhanzhan Cheng",
      "Yi Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08569"
  },
  {
    "id": "arXiv:2203.08570",
    "title": "Undersmoothing Causal Estimators with Generative Trees",
    "abstract": "Inferring individualised treatment effects from observational data can unlock\nthe potential for targeted interventions. It is, however, hard to infer these\neffects from observational data. One major problem that can arise is covariate\nshift where the data (outcome) conditional distribution remains the same but\nthe covariate (input) distribution changes between the training and test set.\nIn an observational data setting, this problem is materialised in control and\ntreated units coming from different distributions. A common solution is to\naugment learning methods through reweighing schemes (e.g. propensity scores).\nThese are needed due to model misspecification, but might hurt performance in\nthe individual case. In this paper, we explore a novel generative tree based\napproach that tackles model misspecification directly, helping downstream\nestimators achieve better robustness. We show empirically that the choice of\nmodel class can indeed significantly affect the final performance and that\nreweighing methods can struggle in individualised effect estimation. Our\nproposed approach is competitive with reweighing methods on average treatment\neffects while performing significantly better on individualised treatment\neffects.",
    "descriptor": "\nComments: 9 pages, 1 figure\n",
    "authors": [
      "Damian Machlanski",
      "Spyros Samothrakis",
      "Paul Clarke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.08570"
  },
  {
    "id": "arXiv:2203.08578",
    "title": "Whither the Priors for (Vocal) Interactivity?",
    "abstract": "Voice-based communication is often cited as one of the most `natural' ways in\nwhich humans and robots might interact, and the recent availability of accurate\nautomatic speech recognition and intelligible speech synthesis has enabled\nresearchers to integrate advanced off-the-shelf spoken language technology\ncomponents into their robot platforms. Despite this, the resulting interactions\nare anything but `natural'. It transpires that simply giving a robot a voice\ndoesn't mean that a user will know how (or when) to talk to it, and the\nresulting `conversations' tend to be stilted, one-sided and short. On the\nsurface, these difficulties might appear to be fairly trivial consequences of\nusers' unfamiliarity with robots (and \\emph{vice versa}), and that any problems\nwould be mitigated by long-term use by the human, coupled with `deep learning'\nby the robot. However, it is argued here that such communication failures are\nindicative of a deeper malaise: a fundamental lack of basic principles --\n\\emph{priors} -- underpinning not only speech-based interaction in particular,\nbut (vocal) interactivity in general. This is evidenced not only by the fact\nthat contemporary spoken language systems already require training data sets\nthat are orders-of-magnitude greater than that experienced by a young child,\nbut also by the lack of design principles for creating effective communicative\nhuman-robot interaction. This short position paper identifies some of the key\nareas where theoretical insights might help overcome these shortfalls.",
    "descriptor": "\nComments: Accepted for the THEORIA Workshop \"Towards a Common Understanding and Vision for Theory-Grounded Human-Robot Interaction\" at HRI-2022, 7 March 2022\n",
    "authors": [
      "Roger K. Moore"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.08578"
  },
  {
    "id": "arXiv:2203.08579",
    "title": "Oversampling is a necessity for RBF-collocation method of lines",
    "abstract": "We study a radial basis functions least-squares (RBF-LS), a.k.a. kernel-based\nLS, collocation method of lines [arXiv:2109.03409] for solving surface\ndiffusion problems. Our convergence analysis requires that collocation points\nhas to be sufficiently dense with respect to the RBF centers. In this paper, we\nfurther study how oversampling ratio, which is the numbers of collocation\npoints over that of RBF centers for quasi-uniform sets, affects eigenvalue\nstability, time stepping sizes taken by Runge-Kutta methods, and accuracy.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Meng Chen",
      "Leevan Ling"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08579"
  },
  {
    "id": "arXiv:2203.08580",
    "title": "Maintainable Log Datasets for Evaluation of Intrusion Detection Systems",
    "abstract": "Intrusion detection systems (IDS) monitor system logs and network traffic to\nrecognize malicious activities in computer networks. Evaluating and comparing\nIDSs with respect to their detection accuracies is thereby essential for their\nselection in specific use-cases. Despite a great need, hardly any labeled\nintrusion detection datasets are publicly available. As a consequence,\nevaluations are often carried out on datasets from real infrastructures, where\nanalysts cannot control system parameters or generate a reliable ground truth,\nor private datasets that prevent reproducibility of results. As a solution, we\npresent a collection of maintainable log datasets collected in a testbed\nrepresenting a small enterprise. Thereby, we employ extensive state machines to\nsimulate normal user behavior and inject a multi-step attack. For scalable\ntestbed deployment, we use concepts from model-driven engineering that enable\nautomatic generation and labeling of an arbitrary number of datasets that\ncomprise repetitions of attack executions with variations of parameters. In\ntotal, we provide 8 datasets containing 20 distinct types of log files, of\nwhich we label 8 files for 10 unique attack steps. We publish the labeled log\ndatasets and code for testbed setup and simulation online as open-source to\nenable others to reproduce and extend our results.",
    "descriptor": "",
    "authors": [
      "Max Landauer",
      "Florian Skopik",
      "Maximilian Frank",
      "Wolfgang Hotwagner",
      "Markus Wurzenberger",
      "Andreas Rauber"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08580"
  },
  {
    "id": "arXiv:2203.08581",
    "title": "A Survey on Infrared Image and Video Sets",
    "abstract": "In this survey, we compile a list of publicly available infrared image and\nvideo sets for artificial intelligence and computer vision researchers. We\nmainly focus on IR image and video sets which are collected and labelled for\ncomputer vision applications such as object detection, object segmentation,\nclassification, and motion detection. We categorize 92 different publicly\navailable or private sets according to their sensor types, image resolution,\nand scale. We describe each and every set in detail regarding their collection\npurpose, operation environment, optical system properties, and area of\napplication. We also cover a general overview of fundamental concepts that\nrelate to IR imagery, such as IR radiation, IR detectors, IR optics and\napplication fields. We analyse the statistical significance of the entire\ncorpus from different perspectives. We believe that this survey will be a\nguideline for computer vision and artificial intelligence researchers that are\ninterested in working with the spectra beyond the visible domain.",
    "descriptor": "",
    "authors": [
      "Kevser Irem Danaci",
      "Erdem Akagunduz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08581"
  },
  {
    "id": "arXiv:2203.08586",
    "title": "Deep vanishing point detection: Geometric priors make dataset variations  vanish",
    "abstract": "Deep learning has improved vanishing point detection in images. Yet, deep\nnetworks require expensive annotated datasets trained on costly hardware and do\nnot generalize to even slightly different domains, and minor problem variants.\nHere, we address these issues by injecting deep vanishing point detection\nnetworks with prior knowledge. This prior knowledge no longer needs to be\nlearned from data, saving valuable annotation efforts and compute, unlocking\nrealistic few-sample scenarios, and reducing the impact of domain changes.\nMoreover, the interpretability of the priors allows to adapt deep networks to\nminor problem variations such as switching between Manhattan and non-Manhattan\nworlds. We seamlessly incorporate two geometric priors: (i) Hough Transform --\nmapping image pixels to straight lines, and (ii) Gaussian sphere -- mapping\nlines to great circles whose intersections denote vanishing points.\nExperimentally, we ablate our choices and show comparable accuracy to existing\nmodels in the large-data setting. We validate our model's improved data\nefficiency, robustness to domain changes, adaptability to non-Manhattan\nsettings.",
    "descriptor": "\nComments: CVPR2022, code available at this https URL\n",
    "authors": [
      "Yancong Lin",
      "Ruben Wiersma",
      "Silvia L. Pintea",
      "Klaus Hildebrandt",
      "Elmar Eisemann",
      "Jan C. van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08586"
  },
  {
    "id": "arXiv:2203.08588",
    "title": "MIMO-GAN: Generative MIMO Channel Modeling",
    "abstract": "We propose generative channel modeling to learn statistical channel models\nfrom channel input-output measurements. Generative channel models can learn\nmore complicated distributions and represent the field data more faithfully.\nThey are tractable and easy to sample from, which can potentially speed up the\nsimulation rounds. To achieve this, we leverage advances in GAN, which helps us\nlearn an implicit distribution over stochastic MIMO channels from observed\nmeasurements. In particular, our approach MIMO-GAN implicitly models the\nwireless channel as a distribution of time-domain band-limited impulse\nresponses. We evaluate MIMO-GAN on 3GPP TDL MIMO channels and observe\nhigh-consistency in capturing power, delay and spatial correlation statistics\nof the underlying channel. In particular, we observe MIMO-GAN achieve errors of\nunder 3.57 ns average delay and -18.7 dB power.",
    "descriptor": "\nComments: Accepted at IEEE ICC 2022. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Tribhuvanesh Orekondy",
      "Arash Behboodi",
      "Joseph B. Soriaga"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.08588"
  },
  {
    "id": "arXiv:2203.08594",
    "title": "Towards a Roadmap on Software Engineering for Responsible AI",
    "abstract": "Although AI is transforming the world, there are serious concerns about its\nability to behave and make decisions responsibly. Many ethical regulations,\nprinciples, and frameworks for responsible AI have been issued recently.\nHowever, they are high level and difficult to put into practice. On the other\nhand, most AI researchers focus on algorithmic solutions, while the responsible\nAI challenges actually crosscut the entire engineering lifecycle and components\nof AI systems. To close the gap in operationalizing responsible AI, this paper\naims to develop a roadmap on software engineering for responsible AI. The\nroadmap focuses on (i) establishing multi-level governance for responsible AI\nsystems, (ii) setting up the development processes incorporating\nprocess-oriented practices for responsible AI systems, and (iii) building\nresponsible-AI-by-design into AI systems through system-level architectural\nstyle, patterns and techniques.",
    "descriptor": "",
    "authors": [
      "Qinghua Lu",
      "Liming Zhu",
      "Xiwei Xu",
      "Jon Whittle",
      "Zhenchang Xing"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08594"
  },
  {
    "id": "arXiv:2203.08597",
    "title": "Less is More: Summary of Long Instructions is Better for Program  Synthesis",
    "abstract": "Despite the success of large pre-trained language models (LMs) such as Codex,\nthey show below-par performance on the larger and more complicated programming\nrelated questions. We show that LMs benefit from the summarized version of\ncomplicated questions. Our findings show that superfluous information often\npresent in problem description such as human characters, background stories,\nnames (which are included to help humans in understanding a task) does not help\nmodels in understanding a task. To this extent, we create a meta-dataset from\nthe frequently used APPS dataset for the program synthesis task. Our\nmeta-dataset consists of human and synthesized summary of the long and\ncomplicated programming questions. Experimental results on Codex show that our\nproposed approach outperforms baseline by 8.13% on an average in terms of\nstrict accuracy. Our analysis shows that summary significantly improve\nperformance for introductory (9.86%) and interview (11.48%) related programming\nquestions. However, it shows improvement by a small margin (~2%) for\ncompetitive programming questions, implying the scope for future research\ndirection.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Kirby Kuznia",
      "Swaroop Mishra",
      "Mihir Parmar",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08597"
  },
  {
    "id": "arXiv:2203.08600",
    "title": "NELA-Local: A Dataset of U.S. Local News Articles for the Study of  County-level News Ecosystems",
    "abstract": "In this paper, we present a dataset of over 1.4M online news articles from\n313 local U.S. news outlets published over 20 months (between April 4th, 2020\nand December 31st, 2021). These outlets cover a geographically diverse set of\ncommunities across the United States. In order to estimate characteristics of\nthe local audience, included with this news article data is a wide range of\ncounty-level metadata, including demographics, 2020 Presidential Election vote\nshares, and community resilience estimates from the U.S. Census Bureau. The\nNELA-Local dataset can be found at:\nhttps://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/GFE66K.",
    "descriptor": "\nComments: Published at ICWSM 2022\n",
    "authors": [
      "Benjamin D. Horne",
      "Maur\u00edcio Gruppi",
      "Kenneth Joseph",
      "Jon Green",
      "John P. Wihbey",
      "Sibel Adal\u0131"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Multimedia (cs.MM)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.08600"
  },
  {
    "id": "arXiv:2203.08601",
    "title": "Sparsification Lower Bound for Linear Spanners in Directed Graphs",
    "abstract": "For $\\alpha \\ge 1$, $\\beta \\ge 0$, and a graph $G$, a spanning subgraph $H$\nof $G$ is said to be an $(\\alpha, \\beta)$-spanner if $\\dist(u, v, H) \\le \\alpha\n\\cdot \\dist(u, v, G) + \\beta$ holds for any pair of vertices $u$ and $v$. These\ntype of spanners, called \\emph{linear spanners}, generalizes \\emph{additive\nspanners} and \\emph{multiplicative spanners}. Recently, Fomin, Golovach,\nLochet, Misra, Saurabh, and Sharma initiated the study of additive and\nmultiplicative spanners for directed graphs (IPEC $2020$). In this article, we\ncontinue this line of research and prove that \\textsc{Directed Linear Spanner}\nparameterized by the number of vertices $n$ admits no polynomial compression of\nsize $\\calO(n^{2 - \\epsilon})$ for any $\\epsilon > 0$ unless $\\NP \\subseteq\n\\coNP/poly$. We show that similar results hold for \\textsc{Directed Additive\nSpanner} and \\textsc{Directed Multiplicative Spanner} problems. This\nsparsification lower bound holds even when the input is a directed acyclic\ngraph and $\\alpha, \\beta$ are \\emph{any} computable functions of the distance\nbeing approximated.",
    "descriptor": "",
    "authors": [
      "Prafullkumar Tale"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.08601"
  },
  {
    "id": "arXiv:2203.08606",
    "title": "A Reachability Index for Recursive Label-Concatenated Graph Queries",
    "abstract": "Reachability queries checking the existence of a path from a source node to a\ntarget node are fundamental operators for querying and processing graph data.\nCurrent approaches for index-based evaluation of reachability queries either\nfocus on plain reachability or constraint-based reachability with alternation\nonly. In this paper, for the first time we study the problem of index-based\nprocessing for recursive label-concatenated reachability queries, referred to\nas RLC queries. These queries check the existence of a path that can satisfy\nthe constraint defined by a concatenation of at most k edge labels under the\nKleene plus. Many practical graph database and network analysis applications\nexhibit RLC queries. However, their evaluation remains prohibitive in current\ngraph database engines.\nWe introduce the RLC index, the first reachability index to efficiently\nprocess RLC queries. The RLC index checks whether the source vertex can reach\nan intermediate vertex that can also reach the target vertex under a recursive\nlabel-concatenated constraint. We propose an indexing algorithm to build the\nRLC index, which guarantees the soundness and the completeness of query\nexecution and avoids recording redundant index entries. Comprehensive\nexperiments on real-world graphs show that the RLC index can significantly\nreduce both the offline processing cost and the memory overhead of transitive\nclosure while improving query processing up to six orders of magnitude over\nonline traversals. Finally, our open-source implementation of the RLC index\nsignificantly outperforms current mainstream graph engines for evaluating RLC\nqueries.",
    "descriptor": "",
    "authors": [
      "Chao Zhang",
      "Angela Bonifati",
      "Hugo Kapp",
      "Vlad Ioan Haprian",
      "Jean-Pierre Lozi"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.08606"
  },
  {
    "id": "arXiv:2203.08612",
    "title": "CtlGAN: Few-shot Artistic Portraits Generation with Contrastive Transfer  Learning",
    "abstract": "Generating artistic portraits is a challenging problem in computer vision.\nExisting portrait stylization models that generate good quality results are\nbased on Image-to-Image Translation and require abundant data from both source\nand target domains. However, without enough data, these methods would result in\noverfitting. In this work, we propose CtlGAN, a new few-shot artistic portraits\ngeneration model with a novel contrastive transfer learning strategy. We adapt\na pretrained StyleGAN in the source domain to a target artistic domain with no\nmore than 10 artistic faces. To reduce overfitting to the few training\nexamples, we introduce a novel Cross-Domain Triplet loss which explicitly\nencourages the target instances generated from different latent codes to be\ndistinguishable. We propose a new encoder which embeds real faces into Z+ space\nand proposes a dual-path training strategy to better cope with the adapted\ndecoder and eliminate the artifacts. Extensive qualitative, quantitative\ncomparisons and a user study show our method significantly outperforms\nstate-of-the-arts under 10-shot and 1-shot settings and generates high quality\nartistic portraits. The code will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Yue Wang",
      "Ran Yi",
      "Ying Tai",
      "Chengjie Wang",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.08612"
  },
  {
    "id": "arXiv:2203.08615",
    "title": "Scientific and Technological Information Oriented Semantics-adversarial  and Media-adversarial Cross-media Retrieval",
    "abstract": "Cross-media retrieval of scientific and technological information is one of\nthe important tasks in the cross-media study. Cross-media scientific and\ntechnological information retrieval obtain target information from massive\nmulti-source and heterogeneous scientific and technological resources, which\nhelps to design applications that meet users' needs, including scientific and\ntechnological information recommendation, personalized scientific and\ntechnological information retrieval, etc. The core of cross-media retrieval is\nto learn a common subspace, so that data from different media can be directly\ncompared with each other after being mapped into this subspace. In subspace\nlearning, existing methods often focus on modeling the discrimination of\nintra-media data and the invariance of inter-media data after mapping; however,\nthey ignore the semantic consistency of inter-media data before and after\nmapping and media discrimination of intra-semantics data, which limit the\nresult of cross-media retrieval. In light of this, we propose a scientific and\ntechnological information oriented Semantics-adversarial and Media-adversarial\nCross-media Retrieval method (SMCR) to find an effective common subspace.\nSpecifically, SMCR minimizes the loss of inter-media semantic consistency in\naddition to modeling intra-media semantic discrimination, to preserve semantic\nsimilarity before and after mapping. Furthermore, SMCR constructs a basic\nfeature mapping network and a refined feature mapping network to jointly\nminimize the media discriminative loss within semantics, so as to enhance the\nfeature mapping network's ability to confuse the media discriminant network.\nExperimental results on two datasets demonstrate that the proposed SMCR\noutperforms state-of-the-art methods in cross-media retrieval.",
    "descriptor": "\nComments: 9 pages,2 figures\n",
    "authors": [
      "Ang Li",
      "Junping Du",
      "Feifei Kou",
      "Zhe Xue",
      "Xin Xu",
      "Mingying Xu",
      "Yang Jiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08615"
  },
  {
    "id": "arXiv:2203.08616",
    "title": "Generic Lithography Modeling with Dual-band Optics-Inspired Neural  Networks",
    "abstract": "Lithography simulation is a critical step in VLSI design and optimization for\nmanufacturability. Existing solutions for highly accurate lithography\nsimulation with rigorous models are computationally expensive and slow, even\nwhen equipped with various approximation techniques. Recently, machine learning\nhas provided alternative solutions for lithography simulation tasks such as\ncoarse-grained edge placement error regression and complete contour prediction.\nHowever, the impact of these learning-based methods has been limited due to\nrestrictive usage scenarios or low simulation accuracy. To tackle these\nconcerns, we introduce an dual-band optics-inspired neural network design that\nconsiders the optical physics underlying lithography. To the best of our\nknowledge, our approach yields the first published via/metal layer contour\nsimulation at 1nm^2/pixel resolution with any tile size. Compared to previous\nmachine learning based solutions, we demonstrate that our framework can be\ntrained much faster and offers a significant improvement on efficiency and\nimage quality with 20X smaller model size. We also achieve 85X simulation\nspeedup over traditional lithography simulator with 1% accuracy loss.",
    "descriptor": "\nComments: 9 pages, 9 figures; accepted at 59th Design Automation Conference\n",
    "authors": [
      "Haoyu Yang",
      "Zongyi Li",
      "Kumara Sastry",
      "Saumyadip Mukhopadhyay",
      "Mark Kilgard",
      "Anima Anandkumar",
      "Brucek Khailany",
      "Vivek Singh",
      "Haoxing Ren"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08616"
  },
  {
    "id": "arXiv:2203.08617",
    "title": "Conditional Measurement Density Estimation in Sequential Monte Carlo via  Normalizing Flow",
    "abstract": "Tuning of measurement models is challenging in real-world applications of\nsequential Monte Carlo methods. Recent advances in differentiable particle\nfilters have led to various efforts to learn measurement models through neural\nnetworks. But existing approaches in the differentiable particle filter\nframework do not admit valid probability densities in constructing measurement\nmodels, leading to incorrect quantification of the measurement uncertainty\ngiven state information. We propose to learn expressive and valid probability\ndensities in measurement models through conditional normalizing flows, to\ncapture the complex likelihood of measurements given states. We show that the\nproposed approach leads to improved estimation performance and faster training\nconvergence in a visual tracking experiment.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Xiongjie Chen",
      "Yunpeng Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08617"
  },
  {
    "id": "arXiv:2203.08619",
    "title": "An Independently Learnable Hierarchical Model for Bilateral  Control-Based Imitation Learning Applications",
    "abstract": "Recently, motion generation by machine learning has been actively researched\nto automate various tasks. Imitation learning is one such method that learns\nmotions from data collected in advance. However, executing long-term tasks\nremains challenging. Therefore, a novel framework for imitation learning is\nproposed to solve this problem. The proposed framework comprises upper and\nlower layers, where the upper layer model, whose timescale is long, and lower\nlayer model, whose timescale is short, can be independently trained. In this\nmodel, the upper layer learns long-term task planning, and the lower layer\nlearns motion primitives. The proposed method was experimentally compared to\nhierarchical RNN-based methods to validate its effectiveness. Consequently, the\nproposed method showed a success rate equal to or greater than that of\nconventional methods. In addition, the proposed method required less than 1/20\nof the training time compared to conventional methods. Moreover, it succeeded\nin executing unlearned tasks by reusing the trained lower layer.",
    "descriptor": "",
    "authors": [
      "Kazuki Hayashi",
      "Sho Sakaino",
      "Toshiaki Tsuji"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08619"
  },
  {
    "id": "arXiv:2203.08630",
    "title": "Extended vehicle energy dataset (eVED): an enhanced large-scale dataset  for deep learning on vehicle trip energy consumption",
    "abstract": "This work presents an extended version of the Vehicle Energy Dataset (VED),\nwhich is a openly released large-scale dataset for vehicle energy consumption\nanalysis. Compared with its original version, the extended VED (eVED) dataset\nis enhanced with accurate vehicle trip GPS coordinates, serving as a basis to\nassociate the VED trip records with external information, e.g., road speed\nlimit and intersections, from accessible map services to accumulate attributes\nthat is essential in analyzing vehicle energy consumption. In particularly, we\ncalibrate all the GPS trace records in the original VED data, upon which we\nassociated the VED data with attributes extracted from the Geographic\nInformation System (QGIS), the Overpass API, the Open Street Map API, and\nGoogle Maps API. The associated attributes include 12,609,170 records of road\nelevation, 12,203,044 of speed limit, 12,281,719 of speed limit with direction\n(in case the road is bi-directional), 584,551 of intersections, 429,638 of bus\nstop, 312,196 of crossings, 195,856 of traffic signals, 29,397 of stop signs,\n5,848 of turning loops, 4,053 of railway crossings (level crossing), 3,554 of\nturning circles, and 2,938 of motorway junctions. With the accurate GPS\ncoordinates and enriched features of the vehicle trip record, the obtained eVED\ndataset can provide a precise and abundant medium to feed a learning engine,\nespecially a deep learning engine that is more demanding on data sufficiency\nand richness. Moreover, our software work for data calibration and enrichment\ncan be reused to generate further vehicle trip datasets for specific user\ncases, contributing to deep insights into vehicle behaviors and traffic\ndynamics analyses. We anticipate that the eVED dataset and our data enrichment\nsoftware can serve the academic and industrial automotive section as apparatus\nin developing future technologies.",
    "descriptor": "",
    "authors": [
      "Shiliang Zhang",
      "Dyako Fatih",
      "Fahmi Abdulqadir",
      "Tobias Schwarz",
      "Xuehui Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08630"
  },
  {
    "id": "arXiv:2203.08632",
    "title": "Coverage Optimization of Camera Network for Continuous Deformable Object",
    "abstract": "In this paper, a deformable object is considered for cameras deployment with\nthe aim of visual coverage. The object contour is discretized into sampled\npoints as meshes, and the deformation is represented as continuous trajectories\nfor the sampled points. To reduce the computational complexity, some feature\npoints are carefully selected representing the continuous deformation process,\nand the visual coverage for the deformable object is transferred to cover the\nspecific feature points. In particular, the vertexes of a rectangle that can\ncontain the entire deformation trajectory of every sampled point on the object\ncontour are chosen as the feature points. An improved wolf pack algorithm is\nthen proposed to solve the optimization problem. Finally, simulation results\nare given to demonstrate the effectiveness of the proposed deployment method of\ncamera network.",
    "descriptor": "",
    "authors": [
      "Chang Li",
      "Xi Chen",
      "Li Chai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08632"
  },
  {
    "id": "arXiv:2203.08633",
    "title": "A Frequency-Agnostic RIS-based solution to control the Smart Radio  Propagation Environment",
    "abstract": "The disruptive reconfigurable intelligent surface (RIS) technology is\nsteadily gaining relevance as a key element in future 6G networks. However, a\none-size-fits-all RIS hardware design is yet to be defined due to many\npractical considerations. A major roadblock for currently available RISs is\ntheir inability to concurrently operate at multiple carrier frequencies, which\nwould lead to redundant installations to support multiple radio access\ntechnologies (RATs). In this paper, we introduce FABRIS, a novel and practical\nmulti-frequency RIS design. FABRIS is able to dynamically operate across\ndifferent radio frequencies (RFs) by means of frequency-tunable antennas as\nunit cells with virtually no performance degradation when conventional\napproaches to RIS design and optimization fail. Remarkably, our design\npreserves a sufficiently narrow beamwidth as to avoid generating signal leakage\nin unwanted directions and a sufficiently high antenna efficiency in terms of\nscattering parameters. Indeed, FABRIS selects the RIS configuration that\nmaximizes the signal at the intended target user equipment (UE) while\nminimizing leakage to non-intended neighboring UEs. Numerical results and\nfull-wave simulations validate our proposed approach against a naive\nimplementation that does not consider signal leakage resulting from\nmulti-frequency antenna arrays.",
    "descriptor": "",
    "authors": [
      "Fabio Maresca",
      "Antonio Albanese",
      "Placido Mursia",
      "Vincenzo Sciancalepore",
      "Xavier Costa-P\u00e9rez"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2203.08633"
  },
  {
    "id": "arXiv:2203.08637",
    "title": "Adversarial Learned Fair Representations using Dampening and Stacking",
    "abstract": "As more decisions in our daily life become automated, the need to have\nmachine learning algorithms that make fair decisions increases. In fair\nrepresentation learning we are tasked with finding a suitable representation of\nthe data in which a sensitive variable is censored. Recent work aims to learn\nfair representations through adversarial learning. This paper builds upon this\nwork by introducing a novel algorithm which uses dampening and stacking to\nlearn adversarial fair representations. Results show that that our algorithm\nimproves upon earlier work in both censoring and reconstruction.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Max Knobbout"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.08637"
  },
  {
    "id": "arXiv:2203.08638",
    "title": "Building Domain-Specific Machine Learning Workflows: A Conceptual  Framework for the State-of-the-Practice",
    "abstract": "Domain experts are increasingly employing machine learning to solve their\ndomain-specific problems. This article presents six key challenges that a\ndomain expert faces in transforming their problem into a computational\nworkflow, and then into an executable implementation. These challenges arise\nout of our conceptual framework which presents the \"route\" of options that a\ndomain expert may choose to take while developing their solution.\nTo ground our conceptual framework in the state-of-the-practice, this article\ndiscusses a selection of available textual and graphical workflow systems and\ntheir support for these six challenges. Case studies from the literature in\nvarious domains are also examined to highlight the tools used by the domain\nexperts as well as a classification of the domain-specificity and machine\nlearning usage of their problem, workflow, and implementation.\nThe state-of-the-practice informs our discussion of the six key challenges,\nwhere we identify which challenges are not sufficiently addressed by available\ntools. We also suggest possible research directions for software engineering\nresearchers to increase the automation of these tools and disseminate\nbest-practice techniques between software engineering and various scientific\ndomains.",
    "descriptor": "\nComments: 33 pages 14 figures\n",
    "authors": [
      "Bentley James Oakes",
      "Michalis Famelis",
      "Houari Sahraoui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.08638"
  },
  {
    "id": "arXiv:2203.08642",
    "title": "Work-in-Progress -- Understanding motivations and characteristics of  financially-motivated cybercriminals",
    "abstract": "Background: Cyber offences, such as hacking, malware creation and\ndistribution, and online fraud, present a substantial threat to organizations\nattempting to safeguard their data and information. By understanding the\nevolving characteristics and motivations of individuals involved in these\nactivities, and the threats that they may pose, cyber security practitioners\nwill be better placed to understand and assess current threats to their systems\nand the range of socio-technical mitigations that may best reduce these. Aim:\nThe reported work-in-progress aims to explore the extent to which findings from\nprior academic literature regarding the characteristics and motivations of\noffenders engaging in financially-motivated, cyber-dependent crime are\nsupported by the contemporary experiences and perspectives of practitioners\ncurrently working in the cyber crime field. Method: A targeted, online survey\nwas developed consisting of both closed and open-ended questions relating to\ncurrent cyber threats and the characteristics and motivations of offenders\nengaged in these activities. Sixteen practitioners working in law\nenforcement-related domains in the cyber crime field completed the survey,\nproviding a combination of qualitative and quantitative data for analysis.",
    "descriptor": "",
    "authors": [
      "Claudia Peersman",
      "Emma Williams",
      "Matthew Edwards",
      "Awais Rashid"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08642"
  },
  {
    "id": "arXiv:2203.08645",
    "title": "The Structured Abstain Problem and the Lov\u00e1sz Hinge",
    "abstract": "The Lov\\'asz hinge is a convex surrogate recently proposed for structured\nbinary classification, in which $k$ binary predictions are made simultaneously\nand the error is judged by a submodular set function. Despite its wide usage in\nimage segmentation and related problems, its consistency has remained open. We\nresolve this open question, showing that the Lov\\'asz hinge is inconsistent for\nits desired target unless the set function is modular. Leveraging a recent\nembedding framework, we instead derive the target loss for which the Lov\\'asz\nhinge is consistent. This target, which we call the structured abstain problem,\nallows one to abstain on any subset of the $k$ predictions. We derive two link\nfunctions, each of which are consistent for all submodular set functions\nsimultaneously.",
    "descriptor": "",
    "authors": [
      "Jessie Finocchiaro",
      "Rafael Frongilo",
      "Enrique Nueve"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08645"
  },
  {
    "id": "arXiv:2203.08648",
    "title": "Artificial Intelligence Enables Real-Time and Intuitive Control of  Prostheses via Nerve Interface",
    "abstract": "Objective: The next generation prosthetic hand that moves and feels like a\nreal hand requires a robust neural interconnection between the human minds and\nmachines. Methods: Here we present a neuroprosthetic system to demonstrate that\nprinciple by employing an artificial intelligence (AI) agent to translate the\namputee's movement intent through a peripheral nerve interface. The AI agent is\ndesigned based on the recurrent neural network (RNN) and could simultaneously\ndecode six degree-of-freedom (DOF) from multichannel nerve data in real-time.\nThe decoder's performance is characterized in motor decoding experiments with\nthree human amputees. Results: First, we show the AI agent enables amputees to\nintuitively control a prosthetic hand with individual finger and wrist\nmovements up to 97-98% accuracy. Second, we demonstrate the AI agent's\nreal-time performance by measuring the reaction time and information throughput\nin a hand gesture matching task. Third, we investigate the AI agent's long-term\nuses and show the decoder's robust predictive performance over a 16-month\nimplant duration. Conclusion & significance: Our study demonstrates the\npotential of AI-enabled nerve technology, underling the next generation of\ndexterous and intuitive prosthetic hands.",
    "descriptor": "",
    "authors": [
      "Diu Khue Luu",
      "Anh Tuan Nguyen",
      "Ming Jiang",
      "Markus W. Drealan",
      "Jian Xu",
      "Tong Wu",
      "Wing-kin Tam",
      "Wenfeng Zhao",
      "Brian Z. H. Lim",
      "Cynthia K. Overstreet",
      "Qi Zhao",
      "Jonathan Cheng",
      "Edward W. Keefer",
      "Zhi Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2203.08648"
  },
  {
    "id": "arXiv:2203.08649",
    "title": "Modeling the obsolescence of research literature in disciplinary  journals through the age of their cited references",
    "abstract": "There are different citation habits in the research fields that influence the\nobsolescence of the research literature. We analyze the distinctive\nobsolescence of research literature in disciplinary journals in eight\nscientific subfields based on cited references distribution, as a synchronous\napproach. We use both Negative Binomial (NB) and Poisson distributions to\ncapture this obsolescence. The corpus being examined is published in 2019 and\ncovers 22,559 papers citing 872,442 references. Moreover, three measures to\nanalyze the tail of the distribution are proposed: (i) cited reference survival\nrate, (ii) cited reference mortality rate, and (iii) cited reference\npercentile. These measures are interesting because the tail of the distribution\ncollects the behavior of the citations at the time when the document starts to\nget obsolete in the sense that it is little cited (used). As main conclusion,\nthe differences observed in obsolescence are so important even between\ndisciplinary journals in the same subfield, that it would be necessary to use\nsome measure for the tail of the citation distribution, such as those proposed\nin this paper, when analyzing in an appropriate way the long time impact of a\njournal.",
    "descriptor": "\nComments: 33 pages, 3 figures, 9 tables\n",
    "authors": [
      "Pablo Dorta-Gonz\u00e1lez",
      "Emilio G\u00f3mez-D\u00e9niz"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.08649"
  },
  {
    "id": "arXiv:2203.08651",
    "title": "A Necessary and Sufficient Condition for ISS of Impulsive Systems via a  Time-Varying Lyapunov Function",
    "abstract": "We propose a time-varying ISS-Lyapunov function for impulsive systems over\nBanach spaces which provides a necessary and sufficient condition for ISS. Our\nresult applies to a broad class of impulsive systems including simultaneous\nunstable continuous and discrete dynamics.",
    "descriptor": "",
    "authors": [
      "Patrick Bachmann",
      "Saeed Ahmed"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08651"
  },
  {
    "id": "arXiv:2203.08652",
    "title": "Topology-Preserving Shape Reconstruction and Registration via Neural  Diffeomorphic Flow",
    "abstract": "Deep Implicit Functions (DIFs) represent 3D geometry with continuous signed\ndistance functions learned through deep neural nets. Recently DIFs-based\nmethods have been proposed to handle shape reconstruction and dense point\ncorrespondences simultaneously, capturing semantic relationships across shapes\nof the same class by learning a DIFs-modeled shape template. These methods\nprovide great flexibility and accuracy in reconstructing 3D shapes and\ninferring correspondences. However, the point correspondences built from these\nmethods do not intrinsically preserve the topology of the shapes, unlike\nmesh-based template matching methods. This limits their applications on 3D\ngeometries where underlying topological structures exist and matter, such as\nanatomical structures in medical images. In this paper, we propose a new model\ncalled Neural Diffeomorphic Flow (NDF) to learn deep implicit shape templates,\nrepresenting shapes as conditional diffeomorphic deformations of templates,\nintrinsically preserving shape topologies. The diffeomorphic deformation is\nrealized by an auto-decoder consisting of Neural Ordinary Differential Equation\n(NODE) blocks that progressively map shapes to implicit templates. We conduct\nextensive experiments on several medical image organ segmentation datasets to\nevaluate the effectiveness of NDF on reconstructing and aligning shapes. NDF\nachieves consistently state-of-the-art organ shape reconstruction and\nregistration results in both accuracy and quality. The source code is publicly\navailable at https://github.com/Siwensun/Neural_Diffeomorphic_Flow--NDF.",
    "descriptor": "",
    "authors": [
      "Shanlin Sun",
      "Kun Han",
      "Deying Kong",
      "Hao Tang",
      "Xiangyi Yan",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08652"
  },
  {
    "id": "arXiv:2203.08653",
    "title": "Counterfactual Inference of Second Opinions",
    "abstract": "Automated decision support systems that are able to infer second opinions\nfrom experts can potentially facilitate a more efficient allocation of\nresources; they can help decide when and from whom to seek a second opinion. In\nthis paper, we look at the design of this type of support systems from the\nperspective of counterfactual inference. We focus on a multiclass\nclassification setting and first show that, if experts make predictions on\ntheir own, the underlying causal mechanism generating their predictions needs\nto satisfy a desirable set invariant property. Further, we show that, for any\ncausal mechanism satisfying this property, there exists an equivalent mechanism\nwhere the predictions by each expert are generated by independent\nsub-mechanisms governed by a common noise. This motivates the design of a set\ninvariant Gumbel-Max structural causal model where the structure of the noise\ngoverning the sub-mechanisms underpinning the model depends on an intuitive\nnotion of similarity between experts which can be estimated from data.\nExperiments on both synthetic and real data show that our model can be used to\ninfer second opinions more accurately than its non-causal counterpart.",
    "descriptor": "",
    "authors": [
      "Nina Corvelo Benz",
      "Manuel Gomez Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.08653"
  },
  {
    "id": "arXiv:2203.08654",
    "title": "Graph Neural Networks for Multiparallel Word Alignment",
    "abstract": "After a period of decrease, interest in word alignments is increasing again\nfor their usefulness in domains such as typological research, cross-lingual\nannotation projection, and machine translation. Generally, alignment algorithms\nonly use bitext and do not make use of the fact that many parallel corpora are\nmultiparallel. Here, we compute high-quality word alignments between multiple\nlanguage pairs by considering all language pairs together. First, we create a\nmultiparallel word alignment graph, joining all bilingual word alignment pairs\nin one graph. Next, we use graph neural networks (GNNs) to exploit the graph\nstructure. Our GNN approach (i) utilizes information about the meaning,\nposition, and language of the input words, (ii) incorporates information from\nmultiple parallel sentences, (iii) adds and removes edges from the initial\nalignments, and (iv) yields a prediction model that can generalize beyond the\ntraining sentences. We show that community detection provides valuable\ninformation for multiparallel word alignment. Our method outperforms previous\nwork on three word-alignment datasets and on a downstream task.",
    "descriptor": "",
    "authors": [
      "Ayyoob Imani",
      "L\u00fctfi Kerem \u015eenel",
      "Masoud Jalili Sabet",
      "Fran\u00e7ois Yvon",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08654"
  },
  {
    "id": "arXiv:2203.08655",
    "title": "Unraveled Multilevel Transformation Networks for Predicting  Sparsely-Observed Spatiotemporal Dynamics",
    "abstract": "In this paper, we address the problem of predicting complex, nonlinear\nspatiotemporal dynamics when available data is recorded at irregularly-spaced\nsparse spatial locations. Most of the existing deep learning models for\nmodeling spatiotemporal dynamics are either designed for data in a regular grid\nor struggle to uncover the spatial relations from sparse and irregularly-spaced\ndata sites. We propose a deep learning model that learns to predict unknown\nspatiotemporal dynamics using data from sparsely-distributed data sites. We\nbase our approach on Radial Basis Function (RBF) collocation method which is\noften used for meshfree solution of partial differential equations (PDEs). The\nRBF framework allows us to unravel the observed spatiotemporal function and\nlearn the spatial interactions among data sites on the RBF-space. The learned\nspatial features are then used to compose multilevel transformations of the raw\nobservations and predict its evolution in future time steps. We demonstrate the\nadvantage of our approach using both synthetic and real-world climate data.",
    "descriptor": "\nComments: 16 pages, 7 figures. This manuscript has been accepted for publication in Philosophical Transactions of the Royal Society A\n",
    "authors": [
      "Priyabrata Saha",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08655"
  },
  {
    "id": "arXiv:2203.08656",
    "title": "Learning Representation for Bayesian Optimization with Collision-free  Regularization",
    "abstract": "Bayesian optimization has been challenged by datasets with large-scale,\nhigh-dimensional, and non-stationary characteristics, which are common in\nreal-world scenarios. Recent works attempt to handle such input by applying\nneural networks ahead of the classical Gaussian process to learn a latent\nrepresentation. We show that even with proper network design, such learned\nrepresentation often leads to collision in the latent space: two points with\nsignificantly different observations collide in the learned latent space,\nleading to degraded optimization performance. To address this issue, we propose\nLOCo, an efficient deep Bayesian optimization framework which employs a novel\nregularizer to reduce the collision in the learned latent space and encourage\nthe mapping from the latent space to the objective value to be Lipschitz\ncontinuous. LOCo takes in pairs of data points and penalizes those too close in\nthe latent space compared to their target space distance. We provide a rigorous\ntheoretical justification for LOCo by inspecting the regret of this\ndynamic-embedding-based Bayesian optimization algorithm, where the neural\nnetwork is iteratively retrained with the regularizer. Our empirical results\ndemonstrate the effectiveness of LOCo on several synthetic and real-world\nbenchmark Bayesian optimization tasks.",
    "descriptor": "\nComments: 28 pages, 24 figures\n",
    "authors": [
      "Fengxue Zhang",
      "Brian Nord",
      "Yuxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08656"
  },
  {
    "id": "arXiv:2203.08657",
    "title": "Occlusion Fields: An Implicit Representation for Non-Line-of-Sight  Surface Reconstruction",
    "abstract": "Non-line-of-sight reconstruction (NLoS) is a novel indirect imaging modality\nthat aims to recover objects or scene parts outside the field of view from\nmeasurements of light that is indirectly scattered off a directly visible,\ndiffuse wall. Despite recent advances in acquisition and reconstruction\ntechniques, the well-posedness of the problem at large, and the recoverability\nof objects and their shapes in particular, remains an open question. The\ncommonly employed Fermat path criterion is rather conservative with this\nregard, as it classifies some surfaces as unrecoverable, although they\ncontribute to the signal.\nIn this paper, we use a simpler necessary criterion for an opaque surface\npatch to be recoverable. Such piece of surface must be directly visible from\nsome point on the wall, and it must occlude the space behind itself. Inspired\nby recent advances in neural implicit representations, we devise a new\nrepresentation and reconstruction technique for NLoS scenes that unifies the\ntreatment of recoverability with the reconstruction itself. Our approach, which\nwe validate on various synthetic and experimental datasets, exhibits\ninteresting properties. Unlike memory-inefficient volumetric representations,\nours allows to infer adaptively tessellated surfaces from time-of-flight\nmeasurements of moderate resolution. It can further recover features beyond the\nFermat path criterion, and it is robust to significant amounts of\nself-occlusion. We believe that this is the first time that these properties\nhave been achieved in one system that, as an additional benefit, is trainable\nand hence suited for data-driven approaches.",
    "descriptor": "",
    "authors": [
      "Javier Grau",
      "Markus Plack",
      "Patrick Haehn",
      "Michael Weinmann",
      "Matthias Hullin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08657"
  },
  {
    "id": "arXiv:2203.08667",
    "title": "Graph Flow: Cross-layer Graph Flow Distillation for Dual-Efficient  Medical Image Segmentation",
    "abstract": "With the development of deep convolutional neural networks, medical image\nsegmentation has achieved a series of breakthroughs in recent years. However,\nthe higher-performance convolutional neural networks always mean numerous\nparameters and expensive computation costs, which will hinder the applications\nin clinical scenario. Meanwhile, the scarceness of large-scale annotated\nmedical image datasets further impedes the application of high-performance\nnetworks. To tackle these problems, we propose Graph Flow, a novel\ncomprehensive knowledge distillation method, to exploit the cross-layer graph\nflow knowledge for both network-efficient and annotation-efficient medical\nimage segmentation.Specifically, our Graph Flow Distillation constructs a\nvariation graph which is employed to measure the flow of channel-wise salience\nfeatures between different layers. Next, the knowledge included in the\nvariation graph is transferred from a well-trained cumbersome teacher network\nto a non-trained compact student network.In addition, an unsupervised\nParaphraser Module is designed to refine the knowledge of the teacher network,\nwhich is also beneficial for the stabilization of training\nprocedure.Furthermore, we build a unified distillation framework by integrating\nthe adversarial distillation and the vanilla logits distillation, which can\nfurther promote the final performance respectively. As a result, extensive\nexperiments conducted on Gastric Cancer Segmentation Dataset and Synapse\nMulti-organ Segmentation Dataset demonstrate the prominent ability of our\nmethod which achieves state-of-the-art performance on these different-modality\nand multi-category medical image data. Moreover, we demonstrates the\neffectiveness of our Graph Flow through a new semi-supervised paradigm for\ndual-efficient medical image segmentation.",
    "descriptor": "",
    "authors": [
      "Wenxuan Zou",
      "Muyi Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08667"
  },
  {
    "id": "arXiv:2203.08669",
    "title": "MPAF: Model Poisoning Attacks to Federated Learning based on Fake  Clients",
    "abstract": "Existing model poisoning attacks to federated learning assume that an\nattacker has access to a large fraction of compromised genuine clients.\nHowever, such assumption is not realistic in production federated learning\nsystems that involve millions of clients. In this work, we propose the first\nModel Poisoning Attack based on Fake clients called MPAF. Specifically, we\nassume the attacker injects fake clients to a federated learning system and\nsends carefully crafted fake local model updates to the cloud server during\ntraining, such that the learnt global model has low accuracy for many\nindiscriminate test inputs. Towards this goal, our attack drags the global\nmodel towards an attacker-chosen base model that has low accuracy.\nSpecifically, in each round of federated learning, the fake clients craft fake\nlocal model updates that point to the base model and scale them up to amplify\ntheir impact before sending them to the cloud server. Our experiments show that\nMPAF can significantly decrease the test accuracy of the global model, even if\nclassical defenses and norm clipping are adopted, highlighting the need for\nmore advanced defenses.",
    "descriptor": "",
    "authors": [
      "Xiaoyu Cao",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08669"
  },
  {
    "id": "arXiv:2203.08670",
    "title": "Measuring Fairness of Text Classifiers via Prediction Sensitivity",
    "abstract": "With the rapid growth in language processing applications, fairness has\nemerged as an important consideration in data-driven solutions. Although\nvarious fairness definitions have been explored in the recent literature, there\nis lack of consensus on which metrics most accurately reflect the fairness of a\nsystem. In this work, we propose a new formulation : ACCUMULATED PREDICTION\nSENSITIVITY, which measures fairness in machine learning models based on the\nmodel's prediction sensitivity to perturbations in input features. The metric\nattempts to quantify the extent to which a single prediction depends on a\nprotected attribute, where the protected attribute encodes the membership\nstatus of an individual in a protected group. We show that the metric can be\ntheoretically linked with a specific notion of group fairness (statistical\nparity) and individual fairness. It also correlates well with humans'\nperception of fairness. We conduct experiments on two text classification\ndatasets : JIGSAW TOXICITY, and BIAS IN BIOS, and evaluate the correlations\nbetween metrics and manual annotations on whether the model produced a fair\noutcome. We observe that the proposed fairness metric based on prediction\nsensitivity is statistically significantly more correlated with human\nannotation than the existing counterfactual fairness metric.",
    "descriptor": "",
    "authors": [
      "Satyapriya Krishna",
      "Rahul Gupta",
      "Apurv Verma",
      "Jwala Dhamala",
      "Yada Pruksachatkun",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.08670"
  },
  {
    "id": "arXiv:2203.08674",
    "title": "Know your sensORs $\\unicode{x2013}$ A Modality Study For Surgical Action  Classification",
    "abstract": "The surgical operating room (OR) presents many opportunities for automation\nand optimization. Videos from various sources in the OR are becoming\nincreasingly available. The medical community seeks to leverage this wealth of\ndata to develop automated methods to advance interventional care, lower costs,\nand improve overall patient outcomes. Existing datasets from OR room cameras\nare thus far limited in size or modalities acquired, leaving it unclear which\nsensor modalities are best suited for tasks such as recognizing surgical action\nfrom videos. This study demonstrates that surgical action recognition\nperformance can vary depending on the image modalities used. We perform a\nmethodical analysis on several commonly available sensor modalities, presenting\ntwo fusion approaches that improve classification performance. The analyses are\ncarried out on a set of multi-view RGB-D video recordings of 18 laparoscopic\nprocedures.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Lennart Bastian",
      "Tobias Czempiel",
      "Christian Heiliger",
      "Konrad Karcz",
      "Ulrich Eck",
      "Benjamin Busam",
      "Nassir Navab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08674"
  },
  {
    "id": "arXiv:2203.08679",
    "title": "Decoupled Knowledge Distillation",
    "abstract": "State-of-the-art distillation methods are mainly based on distilling deep\nfeatures from intermediate layers, while the significance of logit distillation\nis greatly overlooked. To provide a novel viewpoint to study logit\ndistillation, we reformulate the classical KD loss into two parts, i.e., target\nclass knowledge distillation (TCKD) and non-target class knowledge distillation\n(NCKD). We empirically investigate and prove the effects of the two parts: TCKD\ntransfers knowledge concerning the \"difficulty\" of training samples, while NCKD\nis the prominent reason why logit distillation works. More importantly, we\nreveal that the classical KD loss is a coupled formulation, which (1)\nsuppresses the effectiveness of NCKD and (2) limits the flexibility to balance\nthese two parts. To address these issues, we present Decoupled Knowledge\nDistillation (DKD), enabling TCKD and NCKD to play their roles more efficiently\nand flexibly. Compared with complex feature-based methods, our DKD achieves\ncomparable or even better results and has better training efficiency on\nCIFAR-100, ImageNet, and MS-COCO datasets for image classification and object\ndetection tasks. This paper proves the great potential of logit distillation,\nand we hope it will be helpful for future research. The code is available at\nhttps://github.com/megvii-research/mdistiller.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Borui Zhao",
      "Quan Cui",
      "Renjie Song",
      "Yiyu Qiu",
      "Jiajun Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08679"
  },
  {
    "id": "arXiv:2203.08680",
    "title": "GPU-Accelerated Parallel Gene-pool Optimal Mixing in a Gray-Box  Optimization Setting",
    "abstract": "In a Gray-Box Optimization (GBO) setting that allows for partial evaluations,\nthe fitness of an individual can be updated efficiently after a subset of its\nvariables has been modified. This enables more efficient evolutionary\noptimization with the Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA)\ndue to its key strength: Gene-pool Optimal Mixing (GOM). For each solution, GOM\nperforms variation for many (small) sets of variables. To improve efficiency\neven further, parallel computing can be leveraged. For EAs, typically, this\ncomprises population-wise parallelization. However, unless population sizes are\nlarge, this offers limited gains. For large GBO problems, parallelizing\nGOM-based variation holds greater speed-up potential, regardless of population\nsize. However, this potential cannot be directly exploited because of\ndependencies between variables. We show how graph coloring can be used to group\nsets of variables that can undergo variation in parallel without violating\ndependencies. We test the performance of a CUDA implementation of parallel GOM\non a Graphics Processing Unit (GPU) for the Max-Cut problem, a well-known\nproblem for which the dependency structure can be controlled. We find that, for\nsufficiently large graphs with limited connectivity, finding high-quality\nsolutions can be achieved up to 100 times faster, showcasing the great\npotential of our approach.",
    "descriptor": "",
    "authors": [
      "Anton Bouter",
      "Peter A.N. Bosman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.08680"
  },
  {
    "id": "arXiv:2203.08685",
    "title": "A Feasibility Study of Answer-Unaware Question Generation for Education",
    "abstract": "We conduct a feasibility study into the applicability of answer-unaware\nquestion generation models to textbook passages. We show that a significant\nportion of errors in such systems arise from asking irrelevant or\nuninterpretable questions and that such errors can be ameliorated by providing\nsummarized input. We find that giving these models human-written summaries\ninstead of the original text results in a significant increase in acceptability\nof generated questions (33% $\\rightarrow$ 83%) as determined by expert\nannotators. We also find that, in the absence of human-written summaries,\nautomatic summarization can serve as a good middle ground.",
    "descriptor": "\nComments: To be published in 60th Annual Meeting of the Association for Computational Linguistics (ACL 2022)\n",
    "authors": [
      "Liam Dugan",
      "Eleni Miltsakaki",
      "Shriyash Upadhyay",
      "Etan Ginsberg",
      "Hannah Gonzalez",
      "Dayheon Choi",
      "Chuning Yuan",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.08685"
  },
  {
    "id": "arXiv:2203.08688",
    "title": "Learning video retrieval models with relevance-aware online mining",
    "abstract": "Due to the amount of videos and related captions uploaded every hour, deep\nlearning-based solutions for cross-modal video retrieval are attracting more\nand more attention. A typical approach consists in learning a joint text-video\nembedding space, where the similarity of a video and its associated caption is\nmaximized, whereas a lower similarity is enforced with all the other captions,\ncalled negatives. This approach assumes that only the video and caption pairs\nin the dataset are valid, but different captions - positives - may also\ndescribe its visual contents, hence some of them may be wrongly penalized. To\naddress this shortcoming, we propose the Relevance-Aware Negatives and\nPositives mining (RANP) which, based on the semantics of the negatives,\nimproves their selection while also increasing the similarity of other valid\npositives. We explore the influence of these techniques on two video-text\ndatasets: EPIC-Kitchens-100 and MSR-VTT. By using the proposed techniques, we\nachieve considerable improvements in terms of nDCG and mAP, leading to\nstate-of-the-art results, e.g. +5.3% nDCG and +3.0% mAP on EPIC-Kitchens-100.\nWe share code and pretrained models at\n\\url{https://github.com/aranciokov/ranp}.",
    "descriptor": "\nComments: Accepted at 21st International Conference on Image Analysis and Processing (ICIAP 2021)\n",
    "authors": [
      "Alex Falcon",
      "Giuseppe Serra",
      "Oswald Lanz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08688"
  },
  {
    "id": "arXiv:2203.08689",
    "title": "Client-Wise Targeted Backdoor in Federated Learning",
    "abstract": "Federated Learning (FL) emerges from the privacy concerns traditional machine\nlearning raised. FL trains decentralized models by averaging them without\ncompromising clients' datasets. Ongoing research has found that FL is also\nprone to security and privacy violations. Recent studies established that FL\nleaks information by exploiting inference attacks, reconstructing a data piece\nused during training, or extracting information. Additionally, poisoning\nattacks and backdoors corrupt FL security by inserting poisoned data into\nclients' datasets or directly modifying the model, degrading every client's\nmodel performance.\nOur proposal utilizes these attacks in combination for performing a\nclient-wise targeted backdoor, where a single victim client is backdoored while\nthe rest remains unaffected. Our results establish the viability of the\npresented attack, achieving a 100% attack success rate downgrading the target\nlabel accuracy up to 0%. Our code will be publicly available after acceptance.",
    "descriptor": "",
    "authors": [
      "Gorka Abad",
      "Servio Paguada",
      "Stjepan Picek",
      "V\u00edctor Julio Ram\u00edrez-Dur\u00e1n",
      "Aitor Urbieta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08689"
  },
  {
    "id": "arXiv:2203.08694",
    "title": "Turning Stocks into Memes: A Dataset for Understanding How Social  Communities Can Drive Wall Street",
    "abstract": "Who actually expresses an intent to buy GameStop shares on Reddit? What\nconvinces people to buy stocks? Are people convinced to support a coordinated\nplan to adversely impact Wall Street investors? Existing literature on\nunderstanding intent has mainly relied on surveys and self reporting; however\nthere are limitations to these methodologies. Hence, in this paper, we develop\nan annotated dataset of communications centered on the GameStop phenomenon to\nanalyze the subscriber intentions behaviors within the r/WallStreetBets\ncommunity to buy (or not buy) stocks. Likewise, we curate a dataset to better\nunderstand how intent interacts with a user's general support towards the\ncoordinated actions of the community for GameStop. Overall, our dataset can\nprovide insight to social scientists on the persuasive power to buy into social\nmovements online by adopting common language and narrative. WARNING: This paper\ncontains offensive language that commonly appears on Reddit's r/WallStreetBets\nsubreddit.",
    "descriptor": "\nComments: Accepted to ICWSM 2022\n",
    "authors": [
      "Richard Alvarez",
      "Paras Bhatt",
      "Xingmeng Zhao",
      "Anthony Rios"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.08694"
  },
  {
    "id": "arXiv:2203.08698",
    "title": "Architectures and Synchronization Techniques for Distributed Satellite  Systems: A Survey",
    "abstract": "Cohesive Distributed Satellite Systems (CDSS) is a key enabling technology\nfor the future of remote sensing and communication missions. However, they have\nto meet strict synchronization requirements before their use is generalized.\nWhen clock or local oscillator signals are generated locally at each of the\ndistributed nodes, achieving exact synchronization in absolute phase,\nfrequency, and time is a complex problem. In addition, satellite systems have\nsignificant resource constraints, especially for small satellites, which are\nenvisioned to be part of the future CDSS. Thus, the development of precise,\nrobust, and resource-efficient synchronization techniques is essential for the\nadvancement of future CDSS. In this context, this survey aims to summarize and\ncategorize the most relevant results on synchronization techniques for DSS.\nFirst, some important architecture and system concepts are defined. Then, the\nsynchronization methods reported in the literature are reviewed and\ncategorized. This article also provides an extensive list of applications and\nexamples of synchronization techniques for DSS in addition to the most\nsignificant advances in other operations closely related to synchronization,\nsuch as inter-satellite ranging and relative position. The survey also provides\na discussion on emerging data-driven synchronization techniques based on ML.\nFinally, a compilation of current research activities and potential research\ntopics is proposed, identifying problems and open challenges that can be useful\nfor researchers in the field.",
    "descriptor": "\nComments: submitted to IEEE Access\n",
    "authors": [
      "Liz Martinez Marrero",
      "Juan C. Merlano Duncan",
      "Jorge Querol",
      "Sumit Kumar",
      "Jevgenij Krivochiza",
      "Shree Krishna Sharma",
      "Symeon Chatzinotas",
      "Adriano Camps",
      "Bjorn Otterstern"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.08698"
  },
  {
    "id": "arXiv:2203.08702",
    "title": "On the evolution and impact of Architectural Smells -- An industrial  case study",
    "abstract": "Architectural smells (AS) are notorious for their long-term impact on the\nMaintainability and Evolvability of software systems. The majority of research\nwork has investigated this topic by mining software repositories of open source\nJava systems, making it hard to generalise and apply them to an industrial\ncontext and other programming languages. To address this research gap, we\nconducted an embedded multiple-case case study, in collaboration with a large\nindustry partner, to study how AS evolve in industrial embedded systems. We\ndetect and track AS in 9 C/C++ projects with over 30 releases for each project\nthat span over two years of development, with over 20 millions lines of code in\nthe last release only. In addition to these quantitative results, we also\ninterview 12 among the developers and architects working on these projects,\ncollecting over six hours of qualitative data about the usefulness of AS\nanalysis and the issues they experienced while maintaining and evolving\nartefacts affected by AS. Our quantitative findings show how individual smell\ninstances evolve over time, how long they typically survive within the system,\nhow they overlap with instances of other smell types, and finally what the\nintroduction order of smell types is when they overlap. Our qualitative\nfindings, instead, provide insights on the effects of AS on the long-term\nmaintainability and evolvability of the system, supported by several excerpts\nfrom our interviews. Practitioners also mention what parts of the AS analysis\nactually provide actionable insights that they can use to plan refactoring\nactivities.",
    "descriptor": "",
    "authors": [
      "Darius Sas",
      "Paris Avgeriou",
      "Umut Uyumaz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.08702"
  },
  {
    "id": "arXiv:2203.08713",
    "title": "DeciWatch: A Simple Baseline for 10x Efficient 2D and 3D Pose Estimation",
    "abstract": "This paper proposes a simple baseline framework for video-based 2D/3D human\npose estimation that can achieve 10 times efficiency improvement over existing\nworks without any performance degradation, named DeciWatch. Unlike current\nsolutions that estimate each frame in a video, DeciWatch introduces a simple\nyet effective sample-denoise-recover framework that only watches sparsely\nsampled frames, taking advantage of the continuity of human motions and the\nlightweight pose representation. Specifically, DeciWatch uniformly samples less\nthan 10% video frames for detailed estimation, denoises the estimated 2D/3D\nposes with an efficient Transformer architecture, and then accurately recovers\nthe rest of the frames using another Transformer-based network. Comprehensive\nexperimental results on three video-based human pose estimation and body mesh\nrecovery tasks with four datasets validate the efficiency and effectiveness of\nDeciWatch.",
    "descriptor": "\nComments: The project page can be found at this https URL\n",
    "authors": [
      "Ailing Zeng",
      "Xuan Ju",
      "Lei Yang",
      "Ruiyuan Gao",
      "Xizhou Zhu",
      "Bo Dai",
      "Qiang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08713"
  },
  {
    "id": "arXiv:2203.08715",
    "title": "Multiscale Sensor Fusion and Continuous Control with Neural CDEs",
    "abstract": "Though robot learning is often formulated in terms of discrete-time Markov\ndecision processes (MDPs), physical robots require near-continuous multiscale\nfeedback control. Machines operate on multiple asynchronous sensing modalities,\neach with different frequencies, e.g., video frames at 30Hz, proprioceptive\nstate at 100Hz, force-torque data at 500Hz, etc. While the classic approach is\nto batch observations into fixed-time windows then pass them through\nfeed-forward encoders (e.g., with deep networks), we show that there exists a\nmore elegant approach -- one that treats policy learning as modeling latent\nstate dynamics in continuous-time. Specifically, we present 'InFuser', a\nunified architecture that trains continuous time-policies with Neural\nControlled Differential Equations (CDEs). InFuser evolves a single latent state\nrepresentation over time by (In)tegrating and (Fus)ing multi-sensory\nobservations (arriving at different frequencies), and inferring actions in\ncontinuous-time. This enables policies that can react to multi-frequency multi\nsensory feedback for truly end-to-end visuomotor control, without discrete-time\nassumptions. Behavior cloning experiments demonstrate that InFuser learns\nrobust policies for dynamic tasks (e.g., swinging a ball into a cup) notably\noutperforming several baselines in settings where observations from one sensing\nmodality can arrive at much sparser intervals than others.",
    "descriptor": "\nComments: Submitted to IEEE IROS 2022\n",
    "authors": [
      "Sumeet Singh",
      "Francis McCann Ramirez",
      "Jacob Varley",
      "Andy Zeng",
      "Vikas Sindhwani"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.08715"
  },
  {
    "id": "arXiv:2203.08717",
    "title": "Relational Self-Supervised Learning",
    "abstract": "Self-supervised Learning (SSL) including the mainstream contrastive learning\nhas achieved great success in learning visual representations without data\nannotations. However, most methods mainly focus on the instance level\ninformation (\\ie, the different augmented images of the same instance should\nhave the same feature or cluster into the same class), but there is a lack of\nattention on the relationships between different instances. In this paper, we\nintroduce a novel SSL paradigm, which we term as relational self-supervised\nlearning (ReSSL) framework that learns representations by modeling the\nrelationship between different instances. Specifically, our proposed method\nemploys sharpened distribution of pairwise similarities among different\ninstances as \\textit{relation} metric, which is thus utilized to match the\nfeature embeddings of different augmentations. To boost the performance, we\nargue that weak augmentations matter to represent a more reliable relation, and\nleverage momentum strategy for practical efficiency. The designed asymmetric\npredictor head and an InfoNCE warm-up strategy enhance the robustness to\nhyper-parameters and benefit the resulting performance. Experimental results\nshow that our proposed ReSSL substantially outperforms the state-of-the-art\nmethods across different network architectures, including various lightweight\nnetworks (\\eg, EfficientNet and MobileNet).",
    "descriptor": "\nComments: Extended version of NeurIPS 2021 paper\n",
    "authors": [
      "Mingkai Zheng",
      "Shan You",
      "Fei Wang",
      "Chen Qian",
      "Changshui Zhang",
      "Xiaogang Wang",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08717"
  },
  {
    "id": "arXiv:2203.08725",
    "title": "Attacking deep networks with surrogate-based adversarial black-box  methods is easy",
    "abstract": "A recent line of work on black-box adversarial attacks has revived the use of\ntransfer from surrogate models by integrating it into query-based search.\nHowever, we find that existing approaches of this type underperform their\npotential, and can be overly complicated besides. Here, we provide a short and\nsimple algorithm which achieves state-of-the-art results through a search which\nuses the surrogate network's class-score gradients, with no need for other\npriors or heuristics. The guiding assumption of the algorithm is that the\nstudied networks are in a fundamental sense learning similar functions, and\nthat a transfer attack from one to the other should thus be fairly \"easy\". This\nassumption is validated by the extremely low query counts and failure rates\nachieved: e.g. an untargeted attack on a VGG-16 ImageNet network using a\nResNet-152 as the surrogate yields a median query count of 6 at a success rate\nof 99.9%. Code is available at https://github.com/fiveai/GFCS.",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Nicholas A. Lord",
      "Romain Mueller",
      "Luca Bertinetto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08725"
  },
  {
    "id": "arXiv:2203.08728",
    "title": "An Error-State Model Predictive Control on Connected Matrix Lie Groups  for Legged Robot Control",
    "abstract": "This paper reports on a new error-state Model Predictive Control (MPC)\napproach on connected matrix Lie groups for robot control. The linearized\ntracking error dynamics and the linearized equations of motion are derived in\nthe Lie algebra. Moreover, given an initial condition, the linearized tracking\nerror dynamics and equations of motion are globally valid and evolve\nindependently of the system trajectory. By exploiting the symmetry of the\nproblem, the proposed approach shows faster convergence of rotation and\nposition simultaneously than the state-of-the-art geometric variational MPC\nbased on variational-based linearization. Numerical simulation on tracking\ncontrol of a fully-actuated 3D rigid body dynamics confirms the benefits of the\nproposed approach compared to the baselines. Furthermore, the proposed MPC is\nalso verified in pose control and locomotion experiments on a quadrupedal robot\nMIT Mini Cheetah.",
    "descriptor": "\nComments: Submitted to the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Sangli Teng",
      "Dianhao Chen",
      "William Clark",
      "Maani Ghaffari"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08728"
  },
  {
    "id": "arXiv:2203.08729",
    "title": "Input Influence Matrix Design for MIMO Discrete-Time Ultra-Local Model",
    "abstract": "Ultra-Local Models (ULM) have been applied to perform model-free control of\nnonlinear systems with unknown or partially known dynamics. Unfortunately,\nextending these methods to MIMO systems requires designing a dense input\ninfluence matrix which is challenging. This paper presents guidelines for\ndesigning an input influence matrix for discrete-time, control-affine MIMO\nsystems using an ULM-based controller. This paper analyzes the case that uses\nULM and a model-free control scheme: the H\\\"older-continuous Finite-Time Stable\n(FTS) control. By comparing the ULM with the actual system dynamics, the paper\ndescribes how to extract the input-dependent part from the lumped ULM dynamics\nand finds that the tracking and state estimation error are coupled. The\nstability of the ULM-FTS error dynamics is affected by the eigenvalues of the\ndifference (defined by matrix multiplication) between the actual and designed\ninput influence matrix. Finally, the paper shows that a wide range of input\ninfluence matrix designs can keep the ULM-FTS error dynamics (at least locally)\nasymptotically stable. A numerical simulation is included to verify the result.\nThe analysis can also be extended to other ULM-based controllers.",
    "descriptor": "\nComments: Accepted to 2022 American Control Conference (ACC)\n",
    "authors": [
      "Sangli Teng",
      "Amit K. Sanyal",
      "Ram Vasudevan",
      "Anthony Bloch",
      "Maani Ghaffari"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08729"
  },
  {
    "id": "arXiv:2203.08731",
    "title": "Tangles and Hierarchical Clustering",
    "abstract": "We establish a connection between tangles, a concept from structural graph\ntheory that plays a central role in Robertson and Seymour's graph minor\nproject, and hierarchical clustering. Tangles cannot only be defined for\ngraphs, but in fact for arbitrary connectivity functions, which are functions\ndefined on the subsets of some finite universe. In typical clustering\napplications these universes consist of points in some metric space.\nConnectivity functions are usually required to be submodular. It is our first\ncontribution to show that the central duality theorem connecting tangles with\nhierarchical decompositions (so-called branch decompositions) also holds if\nsubmodularity is replaced by a different property that we call\nmaximum-submodular. We then define a connectivity function on finite data sets\nin an arbitrary metric space and prove that its tangles are in one-to-one\ncorrespondence with the clusters obtained by applying the well-known single\nlinkage clustering algorithms to the same data set. Lastly we generalize this\ncorrespondence for any hierarchical clustering. We show that the data structure\nthat represents hierarchical clustering results, called dendograms, are\nequivalent to maximum-submodular connectivity functions and their tangles. The\nidea of viewing tangles as clusters has first been proposed by Diestel and\nWhittle in 2016 as an approach to image segmentation. To the best of our\nknowledge, our result is the first that establishes a precise technical\nconnection between tangles and clusters.",
    "descriptor": "\nComments: An extended abstract that contains some of the results has appeared at MFCS 2019\n",
    "authors": [
      "Eva Fluck"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.08731"
  },
  {
    "id": "arXiv:2203.08733",
    "title": "A Note on the Outliers Theorem",
    "abstract": "An outlier is a datapoint set apart from a sample population. This outlier\ncould be due to sampling errors or contamination from other populations. The\noutliers theorem in algorithmic information theory states given a computable\nsampling method, outliers have to appear in samples. In this paper we present a\nplain complexity variant to the outliers theorem. This variant achieves better\nerror bounds than the original prefix-free Kolmogorov complexity version.",
    "descriptor": "",
    "authors": [
      "Samuel Epstein"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.08733"
  },
  {
    "id": "arXiv:2203.08734",
    "title": "Learning Where To Look -- Generative NAS is Surprisingly Efficient",
    "abstract": "The efficient, automated search for well-performing neural architectures\n(NAS) has drawn increasing attention in the recent past. Thereby, the\npredominant research objective is to reduce the necessity of costly evaluations\nof neural architectures while efficiently exploring large search spaces. To\nthis aim, surrogate models embed architectures in a latent space and predict\ntheir performance, while generative models for neural architectures enable\noptimization-based search within the latent space the generator draws from.\nBoth, surrogate and generative models, have the aim of facilitating\nquery-efficient search in a well-structured latent space. In this paper, we\nfurther improve the trade-off between query-efficiency and promising\narchitecture generation by leveraging advantages from both, efficient surrogate\nmodels and generative design. To this end, we propose a generative model,\npaired with a surrogate predictor, that iteratively learns to generate samples\nfrom increasingly promising latent subspaces. This approach leads to very\neffective and efficient architecture search, while keeping the query amount\nlow. In addition, our approach allows in a straightforward manner to jointly\noptimize for multiple objectives such as accuracy and hardware latency. We show\nthe benefit of this approach not only w.r.t. the optimization of architectures\nfor highest classification accuracy but also in the context of hardware\nconstraints and outperform state-of-the art methods on several NAS benchmarks\nfor single and multiple objectives. We also achieve state-of-the-art\nperformance on ImageNet.",
    "descriptor": "",
    "authors": [
      "Jovita Lukasik",
      "Steffen Jung",
      "Margret Keuper"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08734"
  },
  {
    "id": "arXiv:2203.08737",
    "title": "Hardware Approximate Techniques for Deep Neural Network Accelerators: A  Survey",
    "abstract": "Deep Neural Networks (DNNs) are very popular because of their high\nperformance in various cognitive tasks in Machine Learning (ML). Recent\nadvancements in DNNs have brought beyond human accuracy in many tasks, but at\nthe cost of high computational complexity. To enable efficient execution of DNN\ninference, more and more research works, therefore, exploit the inherent error\nresilience of DNNs and employ Approximate Computing (AC) principles to address\nthe elevated energy demands of DNN accelerators. This article provides a\ncomprehensive survey and analysis of hardware approximation techniques for DNN\naccelerators. First, we analyze the state of the art and by identifying\napproximation families, we cluster the respective works with respect to the\napproximation type. Next, we analyze the complexity of the performed\nevaluations (with respect to the dataset and DNN size) to assess the\nefficiency, the potential, and limitations of approximate DNN accelerators.\nMoreover, a broad discussion is provided, regarding error metrics that are more\nsuitable for designing approximate units for DNN accelerators as well as\naccuracy recovery approaches that are tailored to DNN inference. Finally, we\npresent how Approximate Computing for DNN accelerators can go beyond energy\nefficiency and address reliability and security issues, as well.",
    "descriptor": "\nComments: This paper has been accepted by ACM Computing Surveys (CSUR), 2022\n",
    "authors": [
      "Giorgos Armeniakos",
      "Georgios Zervakis",
      "Dimitrios Soudris",
      "J\u00f6rg Henkel"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08737"
  },
  {
    "id": "arXiv:2203.08739",
    "title": "What Do Adversarially trained Neural Networks Focus: A Fourier  Domain-based Study",
    "abstract": "Although many fields have witnessed the superior performance brought about by\ndeep learning, the robustness of neural networks remains an open issue.\nSpecifically, a small adversarial perturbation on the input may cause the model\nto produce a completely different output. Such poor robustness implies many\npotential hazards, especially in security-critical applications, e.g.,\nautonomous driving and mobile robotics. This work studies what information the\nadversarially trained model focuses on. Empirically, we notice that the\ndifferences between the clean and adversarial data are mainly distributed in\nthe low-frequency region. We then find that an adversarially-trained model is\nmore robust than its naturally-trained counterpart due to the reason that the\nformer pays more attention to learning the dominant information in\nlow-frequency components. In addition, we consider two common ways to improve\nmodel robustness, namely, by data augmentation and by using stronger network\narchitectures, and understand these techniques from a frequency-domain\nperspective. We are hopeful this work can shed light on the design of more\nrobust neural networks.",
    "descriptor": "",
    "authors": [
      "Binxiao Huang",
      "Chaofan Tao",
      "Rui Lin",
      "Ngai Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08739"
  },
  {
    "id": "arXiv:2203.08745",
    "title": "Multi-Stage Prompting for Knowledgeable Dialogue Generation",
    "abstract": "Existing knowledge-grounded dialogue systems typically use finetuned versions\nof a pretrained language model (LM) and large-scale knowledge bases. These\nmodels typically fail to generalize on topics outside of the knowledge base,\nand require maintaining separate potentially large checkpoints each time\nfinetuning is needed. In this paper, we aim to address these limitations by\nleveraging the inherent knowledge stored in the pretrained LM as well as its\npowerful generation ability. We propose a multi-stage prompting approach to\ngenerate knowledgeable responses from a single pretrained LM. We first prompt\nthe LM to generate knowledge based on the dialogue context. Then, we further\nprompt it to generate responses based on the dialogue context and the\npreviously generated knowledge. Results show that our knowledge generator\noutperforms the state-of-the-art retrieval-based model by 5.8% when combining\nknowledge relevance and correctness. In addition, our multi-stage prompting\noutperforms the finetuning-based dialogue model in terms of response\nknowledgeability and engagement by up to 10% and 5%, respectively. Furthermore,\nwe scale our model up to 530 billion parameters and show that larger LMs\nimprove the generation correctness score by up to 10%, and response relevance,\nknowledgeability and engagement by up to 10%. Our code is available at:\nhttps://github.com/NVIDIA/Megatron-LM.",
    "descriptor": "",
    "authors": [
      "Zihan Liu",
      "Mostofa Patwary",
      "Ryan Prenger",
      "Shrimai Prabhumoye",
      "Wei Ping",
      "Mohammad Shoeybi",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08745"
  },
  {
    "id": "arXiv:2203.08746",
    "title": "CLUE-AI: A Convolutional Three-stream Anomaly Identification Framework  for Robot Manipulation",
    "abstract": "Robot safety has been a prominent research topic in recent years since robots\nare more involved in daily tasks. It is crucial to devise the required safety\nmechanisms to enable service robots to be aware of and react to anomalies\n(i.e., unexpected deviations from intended outcomes) that arise during the\nexecution of these tasks. Detection and identification of these anomalies is an\nessential step towards fulfilling these requirements. Although several\narchitectures are proposed for anomaly detection, identification is not yet\nthoroughly investigated. This task is challenging since indicators may appear\nlong before anomalies are detected. In this paper, we propose a ConvoLUtional\nthreE-stream Anomaly Identification (CLUE-AI) framework to address this\nproblem. The framework fuses visual, auditory and proprioceptive data streams\nto identify everyday object manipulation anomalies. A stream of 2D images\ngathered through an RGB-D camera placed on the head of the robot is processed\nwithin a self-attention enabled visual stage to capture visual anomaly\nindicators. The auditory modality provided by the microphone placed on the\nrobot's lower torso is processed within a designed convolutional neural network\n(CNN) in the auditory stage. Last, the force applied by the gripper and the\ngripper state are processed within a CNN to obtain proprioceptive features.\nThese outputs are then combined with a late fusion scheme. Our novel\nthree-stream framework design is analyzed on everyday object manipulation tasks\nwith a Baxter humanoid robot in a semi-structured setting. The results indicate\nthat the framework achieves an f-score of 94% outperforming the other baselines\nin classifying anomalies that arise during runtime.",
    "descriptor": "\nComments: 22 pages, 10 figures, under review\n",
    "authors": [
      "Dogan Altan",
      "Sanem Sariel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08746"
  },
  {
    "id": "arXiv:2203.08753",
    "title": "Behaviour in social media for floods and heat waves in disaster response  via Artificial Intelligence",
    "abstract": "This paper analyses social media data in multiple disaster-related\ncollections of floods and heat waves in the UK. The proposed method uses\nmachine learning classifiers based on deep bidirectional neural networks\ntrained on benchmark datasets of disaster responses and extreme events. The\nresulting models are applied to perform sentiment and qualitative analysis of\ninferred topics in text data. We further analyse a set of behavioural\nindicators and match them with climate variables via decoding synoptical\nrecords to analyse thermal comfort. We highlight the advantages of aligning\nbehavioural indicators along with climate variables to provide with additional\nvaluable information to be considered especially in different phases of a\ndisaster and applicable to extreme weather periods. The positiveness of\nmessages is around 8% for disaster, 1% for disaster and medical response, 7%\nfor disaster and humanitarian related messages. This shows the reliability of\nsuch data for our case studies. We show the transferability of this approach to\nbe applied to any social media data collection.",
    "descriptor": "\nComments: 36 pages, 12 figures\n",
    "authors": [
      "Victor Ponce-L\u00f3pez",
      "Catalina Spataru"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.08753"
  },
  {
    "id": "arXiv:2203.08757",
    "title": "Sample, Translate, Recombine: Leveraging Audio Alignments for Data  Augmentation in End-to-end Speech Translation",
    "abstract": "End-to-end speech translation relies on data that pair source-language speech\ninputs with corresponding translations into a target language. Such data are\nnotoriously scarce, making synthetic data augmentation by back-translation or\nknowledge distillation a necessary ingredient of end-to-end training. In this\npaper, we present a novel approach to data augmentation that leverages audio\nalignments, linguistic properties, and translation. First, we augment a\ntranscription by sampling from a suffix memory that stores text and audio data.\nSecond, we translate the augmented transcript. Finally, we recombine\nconcatenated audio segments and the generated translation. Besides training an\nMT-system, we only use basic off-the-shelf components without fine-tuning.\nWhile having similar resource demands as knowledge distillation, adding our\nmethod delivers consistent improvements of up to 0.9 and 1.1 BLEU points on\nfive language pairs on CoVoST 2 and on two language pairs on Europarl-ST,\nrespectively.",
    "descriptor": "\nComments: Accepted at ACL 2022\n",
    "authors": [
      "Tsz Kin Lam",
      "Shigehiko Schamoni",
      "Stefan Riezler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.08757"
  },
  {
    "id": "arXiv:2203.08759",
    "title": "UnseenNet: Fast Training Detector for Any Unseen Concept",
    "abstract": "Training of object detection models using less data is currently the focus of\nexisting N-shot learning models in computer vision. Such methods use\nobject-level labels and takes hours to train on unseen classes. There are many\ncases where we have large amount of image-level labels available for training\nbut cannot be utilized by few shot object detection models for training. There\nis a need for a machine learning framework that can be used for training any\nunseen class and can become useful in real-time situations. In this paper, we\nproposed an \"Unseen Class Detector\" that can be trained within a very short\ntime for any possible unseen class without bounding boxes with competitive\naccuracy. We build our approach on \"Strong\" and \"Weak\" baseline detectors,\nwhich we trained on existing object detection and image classification\ndatasets, respectively. Unseen concepts are fine-tuned on the strong baseline\ndetector using only image-level labels and further adapted by transferring the\nclassifier-detector knowledge between baselines. We use semantic as well as\nvisual similarities to identify the source class (i.e. Sheep) for the\nfine-tuning and adaptation of unseen class (i.e. Goat). Our model (UnseenNet)\nis trained on the ImageNet classification dataset for unseen classes and tested\non an object detection dataset (OpenImages). UnseenNet improves the mean\naverage precision (mAP) by 10% to 30% over existing baselines (semi-supervised\nand few-shot) of object detection on different unseen class splits. Moreover,\ntraining time of our model is <10 min for each unseen class. Qualitative\nresults demonstrate that UnseenNet is suitable not only for few classes of\nPascal VOC but for unseen classes of any dataset or web. Code is available at\nhttps://github.com/Asra-Aslam/UnseenNet.",
    "descriptor": "",
    "authors": [
      "Asra Aslam",
      "Edward Curry"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08759"
  },
  {
    "id": "arXiv:2203.08760",
    "title": "Incorporating Multi-Agent Systems Technology in Power and Energy Systems  of Bangladesh: A Feasibility Study",
    "abstract": "The power sector of Bangladesh is presently experiencing essential changes as\ndemand for power services is increasing with rising population and economic\ndevelopment. With a gradual shift from a rigidly centralized structure to a\nmore decentralized and fluid setup, fundamentally because of the enormous\nadvancement of distributed renewable energy sources, the future power system of\nthe nation requires new control strategies to work efficiently and sustainably\nin the face of evolving conditions and constraints. Multi-Agent Systems (MAS)\ntechnology has attributes that meet these prerequisites of modern power systems\nand has been shown to be effective in dealing with its distributed and complex\nnature. This is a literature-based feasibility study to explore whether MAS\ntechnology is suited to be applied in the context of Bangladesh. For this\npreliminary paper, we look at the topic from a holistic perspective and conduct\na meta-review to curate common applications of Multi-Agent System-based\nconcepts, tools and algorithms on the power and energy sector. We also identify\nthe top challenges of this domain in Bangladesh and connect the potential\nMAS-based solutions to address each challenge. Our qualitative assessment is\nmotivated to provide a starting point for local researchers eager to experiment\nwith MAS technology for application in Bangladesh.",
    "descriptor": "",
    "authors": [
      "Syed Redwan Md Hassan",
      "Nazmul Hasan",
      "Mohammad Ali Siddique",
      "K.M Solaiman Fahim",
      "Rummana Rahman",
      "Lamia Iftekhar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.08760"
  },
  {
    "id": "arXiv:2203.08764",
    "title": "X-Learner: Learning Cross Sources and Tasks for Universal Visual  Representation",
    "abstract": "In computer vision, pre-training models based on largescale supervised\nlearning have been proven effective over the past few years. However, existing\nworks mostly focus on learning from individual task with single data source\n(e.g., ImageNet for classification or COCO for detection). This restricted form\nlimits their generalizability and usability due to the lack of vast semantic\ninformation from various tasks and data sources. Here, we demonstrate that\njointly learning from heterogeneous tasks and multiple data sources contributes\nto universal visual representation, leading to better transferring results of\nvarious downstream tasks. Thus, learning how to bridge the gaps among different\ntasks and data sources is the key, but it still remains an open question. In\nthis work, we propose a representation learning framework called X-Learner,\nwhich learns the universal feature of multiple vision tasks supervised by\nvarious sources, with expansion and squeeze stage: 1) Expansion Stage:\nX-Learner learns the task-specific feature to alleviate task interference and\nenrich the representation by reconciliation layer. 2) Squeeze Stage: X-Learner\ncondenses the model to a reasonable size and learns the universal and\ngeneralizable representation for various tasks transferring. Extensive\nexperiments demonstrate that X-Learner achieves strong performance on different\ntasks without extra annotations, modalities and computational costs compared to\nexisting representation learning methods. Notably, a single X-Learner model\nshows remarkable gains of 3.0%, 3.3% and 1.8% over current pretrained models on\n12 downstream datasets for classification, object detection and semantic\nsegmentation.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Yinan He",
      "Gengshi Huang",
      "Siyu Chen",
      "Jianing Teng",
      "Wang Kun",
      "Zhenfei Yin",
      "Lu Sheng",
      "Ziwei Liu",
      "Yu Qiao",
      "Jing Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08764"
  },
  {
    "id": "arXiv:2203.08765",
    "title": "Efficient conditioned face animation using frontally-viewed embedding",
    "abstract": "As the quality of few shot facial animation from landmarks increases, new\napplications become possible, such as ultra low bandwidth video chat\ncompression with a high degree of realism. However, there are some important\nchallenges to tackle in order to improve the experience in real world\nconditions. In particular, the current approaches fail to represent profile\nviews without distortions, while running in a low compute regime. We focus on\nthis key problem by introducing a multi-frames embedding dubbed Frontalizer to\nimprove profile views rendering. In addition to this core improvement, we\nexplore the learning of a latent code conditioning generations along with\nlandmarks to better convey facial expressions. Our dense models achieves 22% of\nimprovement in perceptual quality and 73% reduction of landmark error over the\nfirst order model baseline on a subset of DFDC videos containing head\nmovements. Declined with mobile architectures, our models outperform the\nprevious state-of-the-art (improving perceptual quality by more than 16% and\nreducing landmark error by more than 47% on two datasets) while running on real\ntime on iPhone 8 with very low bandwidth requirements.",
    "descriptor": "",
    "authors": [
      "Maxime Oquab",
      "Daniel Haziza",
      "Ludovic Schwartz",
      "Tao Xu",
      "Katayoun Zand",
      "Rui Wang",
      "Peirong Liu",
      "Camille Couprie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08765"
  },
  {
    "id": "arXiv:2203.08773",
    "title": "Training Data is More Valuable than You Think: A Simple and Effective  Method by Retrieving from Training Data",
    "abstract": "Retrieval-based methods have been shown to be effective in NLP tasks via\nintroducing external knowledge. However, the indexing and retrieving of\nlarge-scale corpora bring considerable computational cost. Surprisingly, we\nfound that REtrieving from the traINing datA (REINA) only can lead to\nsignificant gains on multiple NLG and NLU tasks. We retrieve the labeled\ntraining instances most similar to the input text and then concatenate them\nwith the input to feed into the model to generate the output. Experimental\nresults show that this simple method can achieve significantly better\nperformance on a variety of NLU and NLG tasks, including summarization, machine\ntranslation, language modeling, and question answering tasks. For instance, our\nproposed method achieved state-of-the-art results on XSum, BigPatent, and\nCommonsenseQA. Our code is released, https://github.com/microsoft/REINA .",
    "descriptor": "\nComments: Accept to ACL 2022 main conference\n",
    "authors": [
      "Shuohang Wang",
      "Yichong Xu",
      "Yuwei Fang",
      "Yang Liu",
      "Siqi Sun",
      "Ruochen Xu",
      "Chenguang Zhu",
      "Michael Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.08773"
  },
  {
    "id": "arXiv:2203.08774",
    "title": "CUE Vectors: Modular Training of Language Models Conditioned on Diverse  Contextual Signals",
    "abstract": "We propose a framework to modularize the training of neural language models\nthat use diverse forms of sentence-external context (including metadata) by\neliminating the need to jointly train sentence-external and within-sentence\nencoders. Our approach, contextual universal embeddings (CUE), trains LMs on\none set of context, such as date and author, and adapts to novel metadata\ntypes, such as article title, or previous sentence. The model consists of a\npretrained neural sentence LM, a BERT-based context encoder, and a masked\ntransformer decoder that estimates LM probabilities using sentence-internal and\nsentence-external information. When context or metadata are unavailable, our\nmodel learns to combine contextual and sentence-internal information using\nnoisy oracle unigram embeddings as a proxy. Real contextual information can be\nintroduced later and used to adapt a small number of parameters that map\ncontextual data into the decoder's embedding space. We validate the CUE\nframework on a NYTimes text corpus with multiple metadata types, for which the\nLM perplexity can be lowered from 36.6 to 27.4 by conditioning on context.\nBootstrapping a contextual LM with only a subset of the context/metadata during\ntraining retains 85\\% of the achievable gain. Training the model initially with\nproxy context retains 67% of the perplexity gain after adapting to real\ncontext. Furthermore, we can swap one type of pretrained sentence LM for\nanother without retraining the context encoders, by only adapting the decoder\nmodel. Overall, we obtain a modular framework that allows incremental, scalable\ntraining of context-enhanced LMs.",
    "descriptor": "\nComments: To appear in Findings of ACL 2022\n",
    "authors": [
      "Scott Novotney",
      "Sreeparna Mukherjee",
      "Zeeshan Ahmed",
      "Andreas Stolcke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08774"
  },
  {
    "id": "arXiv:2203.08777",
    "title": "Object discovery and representation networks",
    "abstract": "The promise of self-supervised learning (SSL) is to leverage large amounts of\nunlabeled data to solve complex tasks. While there has been excellent progress\nwith simple, image-level learning, recent methods have shown the advantage of\nincluding knowledge of image structure. However, by introducing hand-crafted\nimage segmentations to define regions of interest, or specialized augmentation\nstrategies, these methods sacrifice the simplicity and generality that makes\nSSL so powerful. Instead, we propose a self-supervised learning paradigm that\ndiscovers the structure encoded in these priors by itself. Our method, Odin,\ncouples object discovery and representation networks to discover meaningful\nimage segmentations without any supervision. The resulting learning paradigm is\nsimpler, less brittle, and more general, and achieves state-of-the-art transfer\nlearning results for object detection and instance segmentation on COCO, and\nsemantic segmentation on PASCAL and Cityscapes, while strongly surpassing\nsupervised pre-training for video segmentation on DAVIS.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Olivier J. H\u00e9naff",
      "Skanda Koppula",
      "Evan Shelhamer",
      "Daniel Zoran",
      "Andrew Jaegle",
      "Andrew Zisserman",
      "Jo\u00e3o Carreira",
      "Relja Arandjelovi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08777"
  },
  {
    "id": "arXiv:2203.08781",
    "title": "GLASS: A Citizen-Centric Distributed Data-Sharing Model within an  e-Governance Architecture",
    "abstract": "E-governance is a process that aims to enhance a government's ability to\nsimplify all the processes that may involve government, citizens, businesses,\nand so on. The rapid evolution of digital technologies has often created the\nnecessity for the establishment of an e-Governance model. There is often a need\nfor an inclusive e-governance model with integrated multiactor governance\nservices and where a single market approach can be adopted. e-Governance often\naims to minimise bureaucratic processes, while at the same time including a\ndigital-by-default approach to public services. This aims at administrative\nefficiency and the reduction of bureaucratic processes. It can also improve\ngovernment capabilities, and enhances trust and security, which brings\nconfidence in governmental transactions. However, solid implementations of a\ndistributed data sharing model within an e-governance architecture is far from\na reality; hence, citizens of European countries often go through the tedious\nprocess of having their confidential information verified. This paper focuses\non the sinGLe sign-on e-GovernAnce Paradigm based on a distributed\nfile-exchange network for security, transparency, cost-effectiveness and trust\n(GLASS) model, which aims to ensure that a citizen can control their\nrelationship with governmental agencies. The paper thus proposes an approach\nthat integrates a permissioned blockchain with the InterPlanetary File System\n(IPFS). This method demonstrates how we may encrypt and store verifiable\ncredentials of the GLASS ecosystem, such as academic awards, ID documents and\nso on, within IPFS in a secure manner and thus only allow trusted users to read\na blockchain record, and obtain the encryption key. This allows for the\ndecryption of a given verifiable credential that stored on IPFS. This paper\noutlines the creation of a demonstrator that proves the principles of the GLASS\napproach.",
    "descriptor": "\nComments: Sensors 2022, 22(6), 2291; this https URL\n",
    "authors": [
      "Owen Lo",
      "William J. Buchanan",
      "Sarwar Sayeed",
      "Pavlos Papadopoulos",
      "Nikolaos Pitropakis",
      "Christos Chrysoulas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.08781"
  },
  {
    "id": "arXiv:2203.08787",
    "title": "Exploring Variational Graph Auto-Encoders for Extract Class Refactoring  Recommendation",
    "abstract": "The code smell is a sign of design and development flaws in a software system\nthat reduces the reusability and maintainability of the system. Refactoring is\ndone as an ongoing practice to remove the code smell from the program code.\nAmong different code smells, the God class or Blob is one of the most common\ncode smells. A god class contains too many responsibilities, violating\nobject-oriented programming design's low coupling and high cohesiveness\nprinciples. This paper proposes an automatic approach to extracting a God class\ninto multiple smaller classes with more specific responsibilities. To do this,\nwe first construct a graph of methods (as nodes) for the concerning god class.\nThe edge between any two methods is determined by their structural similarity,\nand the feature for each method is initialized using different semantic\nrepresentation methods. Then, the variational graph auto-encoder is used to\nlearn a vector representation for each method. Finally, the learned vectors are\nused to cluster methods into different groups to be recommended as refactored\nclasses. We assessed the proposed framework using three different class\ncohesion metrics on sixteen actual God Classes collected from two well-known\nopen-source systems. We also conducted a comparative study of our approach with\na similar existing approach and found that the proposed approach generated\nbetter results for almost all the God Classes used in the experiment.",
    "descriptor": "",
    "authors": [
      "Pritom Saha Akash"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08787"
  },
  {
    "id": "arXiv:2203.08788",
    "title": "Are Shortest Rationales the Best Explanations for Human Understanding?",
    "abstract": "Existing self-explaining models typically favor extracting the shortest\npossible rationales - snippets of an input text \"responsible for\" corresponding\noutput - to explain the model prediction, with the assumption that shorter\nrationales are more intuitive to humans. However, this assumption has yet to be\nvalidated. Is the shortest rationale indeed the most human-understandable? To\nanswer this question, we design a self-explaining model, LimitedInk, which\nallows users to extract rationales at any target length. Compared to existing\nbaselines, LimitedInk achieves compatible end-task performance and\nhuman-annotated rationale agreement, making it a suitable representation of the\nrecent class of self-explaining models. We use LimitedInk to conduct a user\nstudy on the impact of rationale length, where we ask human judges to predict\nthe sentiment label of documents based only on LimitedInk-generated rationales\nwith different lengths. We show rationales that are too short do not help\nhumans predict labels better than randomly masked text, suggesting the need for\nmore careful design of the best human rationales.",
    "descriptor": "\nComments: To appear in ACL 2022 main conference\n",
    "authors": [
      "Hua Shen",
      "Tongshuang Wu",
      "Wenbo Guo",
      "Ting-Hao 'Kenneth' Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08788"
  },
  {
    "id": "arXiv:2203.08792",
    "title": "PosePipe: Open-Source Human Pose Estimation Pipeline for Clinical  Research",
    "abstract": "There has been significant progress in machine learning algorithms for human\npose estimation that may provide immense value in rehabilitation and movement\nsciences. However, there remain several challenges to routine use of these\ntools for clinical practice and translational research, including: 1) high\ntechnical barrier to entry, 2) rapidly evolving space of algorithms, 3)\nchallenging algorithmic interdependencies, and 4) complex data management\nrequirements between these components. To mitigate these barriers, we developed\na human pose estimation pipeline that facilitates running state-of-the-art\nalgorithms on data acquired in clinical context. Our system allows for running\ndifferent implementations of several classes of algorithms and handles their\ninterdependencies easily. These algorithm classes include subject\nidentification and tracking, 2D keypoint detection, 3D joint location\nestimation, and estimating the pose of body models. The system uses a database\nto manage videos, intermediate analyses, and data for computations at each\nstage. It also provides tools for data visualization, including generating\nvideo overlays that also obscure faces to enhance privacy. Our goal in this\nwork is not to train new algorithms, but to advance the use of cutting-edge\nhuman pose estimation algorithms for clinical and translation research. We show\nthat this tool facilitates analyzing large numbers of videos of human movement\nranging from gait laboratories analyses, to clinic and therapy visits, to\npeople in the community. We also highlight limitations of these algorithms when\napplied to clinical populations in a rehabilitation setting.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "R. James Cotton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Software Engineering (cs.SE)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2203.08792"
  },
  {
    "id": "arXiv:2203.08795",
    "title": "Zero Pixel Directional Boundary by Vector Transform",
    "abstract": "Boundaries are among the primary visual cues used by human and computer\nvision systems. One of the key problems in boundary detection is the label\nrepresentation, which typically leads to class imbalance and, as a consequence,\nto thick boundaries that require non-differential post-processing steps to be\nthinned. In this paper, we re-interpret boundaries as 1-D surfaces and\nformulate a one-to-one vector transform function that allows for training of\nboundary prediction completely avoiding the class imbalance issue.\nSpecifically, we define the boundary representation at any point as the unit\nvector pointing to the closest boundary surface. Our problem formulation leads\nto the estimation of direction as well as richer contextual information of the\nboundary, and, if desired, the availability of zero-pixel thin boundaries also\nat training time. Our method uses no hyper-parameter in the training loss and a\nfixed stable hyper-parameter at inference. We provide theoretical\njustification/discussions of the vector transform representation. We evaluate\nthe proposed loss method using a standard architecture and show the excellent\nperformance over other losses and representations on several datasets.",
    "descriptor": "\nComments: Published at the Tenth International Conference on Learning Representations (ICLR 2022)\n",
    "authors": [
      "Edoardo Mello Rella",
      "Ajad Chhatkuli",
      "Yun Liu",
      "Ender Konukoglu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08795"
  },
  {
    "id": "arXiv:2203.08796",
    "title": "A Continual Learning Framework for Adaptive Defect Classification and  Inspection",
    "abstract": "Machine-vision-based defect classification techniques have been widely\nadopted for automatic quality inspection in manufacturing processes. This\narticle describes a general framework for classifying defects from high volume\ndata batches with efficient inspection of unlabelled samples. The concept is to\nconstruct a detector to identify new defect types, send them to the inspection\nstation for labelling, and dynamically update the classifier in an efficient\nmanner that reduces both storage and computational needs imposed by data\nsamples of previously observed batches. Both a simulation study on image\nclassification and a case study on surface defect detection via 3D point clouds\nare performed to demonstrate the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Wenbo Sun",
      "Raed Al Kontar",
      "Judy Jin",
      "Tzyy-Shuh Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08796"
  },
  {
    "id": "arXiv:2203.08797",
    "title": "An asynchronous variational integrator for the phase field approach to  dynamic fracture",
    "abstract": "The phase field approach is widely used to model fracture behaviors due to\nthe absence of the need to track the crack topology and the ability to predict\ncrack nucleation and branching. In this work, the asynchronous variational\nintegrators (AVI) is adapted for the phase field approach of dynamic brittle\nfractures. The AVI is derived from Hamilton's principle and allows each element\nin the mesh to have its own local time step that may be different from others'.\nWhile the displacement field is explicitly updated, the phase field is\nimplicitly solved, with upper and lower bounds strictly and conveniently\nenforced. In particular, the AT1 and AT2 variants are equally easily\nimplemented. Three benchmark problems are used to study the performances of\nboth AT1 and AT2 models and the results show that AVI for phase field approach\nsignificantly speeds up the computational efficiency and successfully captures\nthe complicated dynamic fracture behavior.",
    "descriptor": "",
    "authors": [
      "Zongwu Niu",
      "Vahid Ziaei-Rad",
      "Zongyuan Wu",
      "Yongxing Shen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08797"
  },
  {
    "id": "arXiv:2203.08143",
    "title": "HiSA-SMFM: Historical and Sentiment Analysis based Stock Market  Forecasting Model",
    "abstract": "One of the pillars to build a country's economy is the stock market. Over the\nyears, people are investing in stock markets to earn as much profit as possible\nfrom the amount of money that they possess. Hence, it is vital to have a\nprediction model which can accurately predict future stock prices. With the\nhelp of machine learning, it is not an impossible task as the various machine\nlearning techniques if modeled properly may be able to provide the best\nprediction values. This would enable the investors to decide whether to buy,\nsell or hold the share. The aim of this paper is to predict the future of the\nfinancial stocks of a company with improved accuracy. In this paper, we have\nproposed the use of historical as well as sentiment data to efficiently predict\nstock prices by applying LSTM. It has been found by analyzing the existing\nresearch in the area of sentiment analysis that there is a strong correlation\nbetween the movement of stock prices and the publication of news articles.\nTherefore, in this paper, we have integrated these factors to predict the stock\nprices more accurately.",
    "descriptor": "",
    "authors": [
      "Ishu Gupta",
      "Tarun Kumar Madan",
      "Sukhman Singh",
      "Ashutosh Kumar Singh"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08143"
  },
  {
    "id": "arXiv:2203.08144",
    "title": "DeepTrust: A Reliable Financial Knowledge Retrieval Framework For  Explaining Extreme Pricing Anomalies",
    "abstract": "Extreme pricing anomalies may occur unexpectedly without a trivial cause, and\nequity traders typically experience a meticulous process to source disparate\ninformation and analyze its reliability before integrating it into the trusted\nknowledge base. We introduce DeepTrust, a reliable financial knowledge\nretrieval framework on Twitter to explain extreme price moves at speed, while\nensuring data veracity using state-of-the-art NLP techniques. Our proposed\nframework consists of three modules, specialized for anomaly detection,\ninformation retrieval and reliability assessment. The workflow starts with\nidentifying anomalous asset price changes using machine learning models trained\nwith historical pricing data, and retrieving correlated unstructured data from\nTwitter using enhanced queries with dynamic search conditions. DeepTrust\nextrapolates information reliability from tweet features, traces of generative\nlanguage model, argumentation structure, subjectivity and sentiment signals,\nand refine a concise collection of credible tweets for market insights. The\nframework is evaluated on two self-annotated financial anomalies, i.e., Twitter\nand Facebook stock price on 29 and 30 April 2021. The optimal setup outperforms\nthe baseline classifier by 7.75% and 15.77% on F0.5-scores, and 10.55% and\n18.88% on precision, respectively, proving its capability in screening\nunreliable information precisely. At the same time, information retrieval and\nreliability assessment modules are analyzed individually on their effectiveness\nand causes of limitations, with identified subjective and objective factors\nthat influence the performance. As a collaborative project with Refinitiv, this\nframework paves a promising path towards building a scalable commercial\nsolution that assists traders to reach investment decisions on pricing\nanomalies with authenticated knowledge from social media platforms in\nreal-time.",
    "descriptor": "\nComments: 72 pages\n",
    "authors": [
      "Pok Wah Chan"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.08144"
  },
  {
    "id": "arXiv:2203.08149",
    "title": "MoReL: Multi-omics Relational Learning",
    "abstract": "Multi-omics data analysis has the potential to discover hidden molecular\ninteractions, revealing potential regulatory and/or signal transduction\npathways for cellular processes of interest when studying life and disease\nsystems. One of critical challenges when dealing with real-world multi-omics\ndata is that they may manifest heterogeneous structures and data quality as\noften existing data may be collected from different subjects under different\nconditions for each type of omics data. We propose a novel deep Bayesian\ngenerative model to efficiently infer a multi-partite graph encoding molecular\ninteractions across such heterogeneous views, using a fused Gromov-Wasserstein\n(FGW) regularization between latent representations of corresponding views for\nintegrative analysis. With such an optimal transport regularization in the deep\nBayesian generative model, it not only allows incorporating view-specific side\ninformation, either with graph-structured or unstructured data in different\nviews, but also increases the model flexibility with the distribution-based\nregularization. This allows efficient alignment of heterogeneous latent\nvariable distributions to derive reliable interaction predictions compared to\nthe existing point-based graph embedding methods. Our experiments on several\nreal-world datasets demonstrate enhanced performance of MoReL in inferring\nmeaningful interactions compared to existing baselines.",
    "descriptor": "",
    "authors": [
      "Arman Hasanzadeh",
      "Ehsan Hajiramezanali",
      "Nick Duffield",
      "Xiaoning Qian"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08149"
  },
  {
    "id": "arXiv:2203.08194",
    "title": "UNet Architectures in Multiplanar Volumetric Segmentation -- Validated  on Three Knee MRI Cohorts",
    "abstract": "UNet has become the gold standard method for segmenting 2D medical images\nthat any new method must be validated against. However, in recent years,\nseveral variations of the seminal UNet have been proposed with promising\nresults. However, there is no clear consensus on the generalisability of these\narchitectures, and UNet currently remains the methodological gold standard. The\npurpose of this study was to evaluate some of the most promising UNet-inspired\narchitectures for 3D segmentation. For the segmentation of 3D scans,\nUNet-inspired methods are also dominant, but there is a larger variety across\napplications. By evaluating the architectures in a different dimensionality,\nembedded in a different method, and for a different task, we aimed to evaluate\nif any of these UNet-alternatives are promising as a new gold standard that\ngeneralizes even better than UNet. Specifically, we investigated the\narchitectures as the central 2D segmentation core in the Multi-Planar Unet 3D\nsegmentation method that previously demonstrated excellent generalization in\nthe MICCAI Segmentation Decathlon. Generalisability can be demonstrated if a\npromising UNet-variant consistently outperforms UNet in this setting. For this\npurpose, we evaluated four architectures for cartilage segmentation from three\ndifferent cohorts with knee MRIs.",
    "descriptor": "",
    "authors": [
      "Sandeep Singh Sengara",
      "Christopher Meulengrachtb",
      "Mikael Ploug Boesenb",
      "Anders F\u00f8hrby Overgaardb",
      "Henrik Gudbergsenb",
      "Janus Damm Nybingb",
      "Erik Bj\u00f8rnager Dam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08194"
  },
  {
    "id": "arXiv:2203.08196",
    "title": "Optimal Damping with Hierarchical Adaptive Quadrature for Efficient  Fourier Pricing of Multi-Asset Options in L\u00e9vy Models",
    "abstract": "Efficient pricing of multi-asset options is a challenging problem in\nquantitative finance. When the Fourier transform of the density function is\navailable, Fourier-based pricing methods become very competitive compared to\nalternative techniques because the integrand in the frequency space has often\nhigher regularity than in the physical space. However, when designing a\nnumerical quadrature method for most of these Fourier pricing approaches, two\nkey aspects affecting the numerical complexity should be carefully considered:\n(i) the choice of the damping parameters that ensure integrability and control\nthe regularity class of the integrand and (ii) the effective treatment of the\nhigh dimensionality of the integration problem. To address these challenges,\nbased on the extension of the one-dimensional Fourier valuation formula to the\nmultivariate case, we propose an efficient numerical method for pricing\nEuropean multi-asset options based on two complementary ideas. First, we smooth\nthe Fourier integrand via an optimized choice of damping parameters based on a\nproposed heuristic optimization rule. Second, we use the adaptive sparse grid\nquadrature based on sparsification and dimension-adaptivity techniques to\naccelerate the convergence of the numerical quadrature in high dimensions.\nThrough an extensive numerical study on the basket and rainbow options under\nthe multivariate geometric Brownian motion and some multivariate L\\'evy models,\nwe demonstrate the advantages of adaptivity and our damping parameter rule on\nthe numerical complexity of the quadrature methods. Moreover, we reveal that\nour approach achieves substantial computational gains compared to the Monte\nCarlo method for different dimensions and parameter constellations.",
    "descriptor": "",
    "authors": [
      "Christian Bayer",
      "Chiheb Ben Hammouda",
      "Antonis Papapantoleon",
      "Michael Samet",
      "Ra\u00fal Tempone"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Numerical Analysis (math.NA)",
      "Pricing of Securities (q-fin.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.08196"
  },
  {
    "id": "arXiv:2203.08213",
    "title": "HUMUS-Net: Hybrid unrolled multi-scale network architecture for  accelerated MRI reconstruction",
    "abstract": "In accelerated MRI reconstruction, the anatomy of a patient is recovered from\na set of under-sampled and noisy measurements. Deep learning approaches have\nbeen proven to be successful in solving this ill-posed inverse problem and are\ncapable of producing very high quality reconstructions. However, current\narchitectures heavily rely on convolutions, that are content-independent and\nhave difficulties modeling long-range dependencies in images. Recently,\nTransformers, the workhorse of contemporary natural language processing, have\nemerged as powerful building blocks for a multitude of vision tasks. These\nmodels split input images into non-overlapping patches, embed the patches into\nlower-dimensional tokens and utilize a self-attention mechanism that does not\nsuffer from the aforementioned weaknesses of convolutional architectures.\nHowever, Transformers incur extremely high compute and memory cost when 1) the\ninput image resolution is high and 2) when the image needs to be split into a\nlarge number of patches to preserve fine detail information, both of which are\ntypical in low-level vision problems such as MRI reconstruction, having a\ncompounding effect. To tackle these challenges, we propose HUMUS-Net, a hybrid\narchitecture that combines the beneficial implicit bias and efficiency of\nconvolutions with the power of Transformer blocks in an unrolled and\nmulti-scale network. HUMUS-Net extracts high-resolution features via\nconvolutional blocks and refines low-resolution features via a novel\nTransformer-based multi-scale feature extractor. Features from both levels are\nthen synthesized into a high-resolution output reconstruction. Our network\nestablishes new state of the art on the largest publicly available MRI dataset,\nthe fastMRI dataset. We further demonstrate the performance of HUMUS-Net on two\nother popular MRI datasets and perform fine-grained ablation studies to\nvalidate our design.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Zalan Fabian",
      "Mahdi Soltanolkotabi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08213"
  },
  {
    "id": "arXiv:2203.08252",
    "title": "Wind energy forecasting with missing values within a fully conditional  specification framework",
    "abstract": "Wind power forecasting is essential to power system operation and electricity\nmarkets. As abundant data became available thanks to the deployment of\nmeasurement infrastructures and the democratization of meteorological\nmodelling, extensive data-driven approaches have been developed within both\npoint and probabilistic forecasting frameworks. These models usually assume\nthat the dataset at hand is complete and overlook missing value issues that\noften occur in practice. In contrast to that common approach, we rigorously\nconsider here the wind power forecasting problem in the presence of missing\nvalues, by jointly accommodating imputation and forecasting tasks. Our approach\nallows inferring the joint distribution of input features and target variables\nat the model estimation stage based on incomplete observations only. We place\nemphasis on a fully conditional specification method owing to its desirable\nproperties, e.g., being assumption-free when it comes to these joint\ndistributions. Then, at the operational forecasting stage, with available\nfeatures at hand, one can issue forecasts by implicitly imputing all missing\nentries. The approach is applicable to both point and probabilistic\nforecasting, while yielding competitive forecast quality within both simulation\nand real-world case studies. It confirms that by using a powerful universal\nimputation method like fully conditional specification, the proposed approach\nis superior to the common approach, especially in the context of probabilistic\nforecasting.",
    "descriptor": "\nComments: submitted to International Journal of Forecasting\n",
    "authors": [
      "Honglin Wen",
      "Pierre Pinson",
      "Jie Gu",
      "Zhijian Jin"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08252"
  },
  {
    "id": "arXiv:2203.08312",
    "title": "An explainability framework for cortical surface-based deep learning",
    "abstract": "The emergence of explainability methods has enabled a better comprehension of\nhow deep neural networks operate through concepts that are easily understood\nand implemented by the end user. While most explainability methods have been\ndesigned for traditional deep learning, some have been further developed for\ngeometric deep learning, in which data are predominantly represented as graphs.\nThese representations are regularly derived from medical imaging data,\nparticularly in the field of neuroimaging, in which graphs are used to\nrepresent brain structural and functional wiring patterns (brain connectomes)\nand cortical surface models are used to represent the anatomical structure of\nthe brain. Although explainability techniques have been developed for\nidentifying important vertices (brain areas) and features for graph\nclassification, these methods are still lacking for more complex tasks, such as\nsurface-based modality transfer (or vertex-wise regression). Here, we address\nthe need for surface-based explainability approaches by developing a framework\nfor cortical surface-based deep learning, providing a transparent system for\nmodality transfer tasks. First, we adapted a perturbation-based approach for\nuse with surface data. Then, we applied our perturbation-based method to\ninvestigate the key features and vertices used by a geometric deep learning\nmodel developed to predict brain function from anatomy directly on a cortical\nsurface model. We show that our explainability framework is not only able to\nidentify important features and their spatial location but that it is also\nreliable and valid.",
    "descriptor": "",
    "authors": [
      "Fernanda L. Ribeiro",
      "Steffen Bollmann",
      "Ross Cunnington",
      "Alexander M. Puckett"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2203.08312"
  },
  {
    "id": "arXiv:2203.08317",
    "title": "TAKDE: Temporal Adaptive Kernel Density Estimator for Real-Time Dynamic  Density Estimation",
    "abstract": "Real-time density estimation is ubiquitous in many applications, including\ncomputer vision and signal processing. Kernel density estimation is arguably\none of the most commonly used density estimation techniques, and the use of\n\"sliding window\" mechanism adapts kernel density estimators to dynamic\nprocesses. In this paper, we derive the asymptotic mean integrated squared\nerror (AMISE) upper bound for the \"sliding window\" kernel density estimator.\nThis upper bound provides a principled guide to devise a novel estimator, which\nwe name the temporal adaptive kernel density estimator (TAKDE). Compared to\nheuristic approaches for \"sliding window\" kernel density estimator, TAKDE is\ntheoretically optimal in terms of the worst-case AMISE. We provide numerical\nexperiments using synthetic and real-world datasets, showing that TAKDE\noutperforms other state-of-the-art dynamic density estimators (including those\noutside of kernel family). In particular, TAKDE achieves a superior test\nlog-likelihood with a smaller runtime.",
    "descriptor": "",
    "authors": [
      "Yinsong Wang",
      "Yu Ding",
      "Shahin Shahrampour"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.08317"
  },
  {
    "id": "arXiv:2203.08349",
    "title": "A Multi-parameter Updating Fourier Online Gradient Descent Algorithm for  Large-scale Nonlinear Classification",
    "abstract": "Large scale nonlinear classification is a challenging task in the field of\nsupport vector machine. Online random Fourier feature map algorithms are very\nimportant methods for dealing with large scale nonlinear classification\nproblems. The main shortcomings of these methods are as follows: (1) Since only\nthe hyperplane vector is updated during learning while the random directions\nare fixed, there is no guarantee that these online methods can adapt to the\nchange of data distribution when the data is coming one by one. (2) The\ndimension of the random direction is often higher for obtaining better\nclassification accuracy, which results in longer test time. In order to\novercome these shortcomings, a multi-parameter updating Fourier online gradient\ndescent algorithm (MPU-FOGD) is proposed for large-scale nonlinear\nclassification problems based on a novel random feature map. In the proposed\nmethod, the suggested random feature map has lower dimension while the\nmulti-parameter updating strategy can guarantee the learning model can better\nadapt to the change of data distribution when the data is coming one by one.\nTheoretically, it is proved that compared with the existing random Fourier\nfeature maps, the proposed random feature map can give a tighter error bound.\nEmpirical studies on several benchmark data sets demonstrate that compared with\nthe state-of-the-art online random Fourier feature map methods, the proposed\nMPU-FOGD can obtain better test accuracy.",
    "descriptor": "",
    "authors": [
      "Yigying Chen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08349"
  },
  {
    "id": "arXiv:2203.08350",
    "title": "A Squeeze-and-Excitation and Transformer based Cross-task System for  Environmental Sound Recognition",
    "abstract": "Environmental sound recognition (ESR) is an emerging research topic in audio\npattern recognition. Many tasks are presented to resort to computational\nsystems for ESR in real-life applications. However, current systems are usually\ndesigned for individual tasks, and are not robust and applicable to other\ntasks. Cross-task systems, which promote unified knowledge modeling across\nvarious tasks, have not been thoroughly investigated. In this paper, we propose\na cross-task system for three different tasks of ESR: acoustic scene\nclassification, urban sound tagging, and anomalous sound detection. An\narchitecture named SE-Trans is presented that uses attention mechanism-based\nSqueeze-and-Excitation and Transformer encoder modules to learn channel-wise\nrelationship and temporal dependencies of the acoustic features. FMix is\nemployed as the data augmentation method that improves the performance of ESR.\nEvaluations for the three tasks are conducted on the recent databases of DCASE\nchallenges. The experimental results show that the proposed cross-task system\nachieves state-of-the-art performance on all tasks. Further analysis\ndemonstrates that the proposed cross-task system can effectively utilize\nacoustic knowledge across different ESR tasks.",
    "descriptor": "",
    "authors": [
      "Jisheng Bai",
      "Jianfeng Chen",
      "Mou Wang",
      "Muhammad Saad Ayub"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.08350"
  },
  {
    "id": "arXiv:2203.08415",
    "title": "Sinkhorn MPC: Model predictive optimal transport over dynamical systems",
    "abstract": "We consider the optimal control problem of steering an agent population to a\ndesired distribution over an infinite horizon. This is an optimal transport\nproblem over a dynamical system, which is challenging due to its high\ncomputational cost. In this paper, we propose Sinkhorn MPC, which is a\ndynamical transport algorithm combining model predictive control and the\nso-called Sinkhorn algorithm. The notable feature of the proposed method is\nthat it achieves cost-effective transport in real time by performing control\nand transport planning simultaneously. In particular, for linear systems with\nan energy cost, we reveal the fundamental properties of Sinkhorn MPC such as\nultimate boundedness and asymptotic stability.",
    "descriptor": "\nComments: 6 pages, 2 figures, accepted to the 2022 American Control Conference\n",
    "authors": [
      "Kaito Ito",
      "Kenji Kashima"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08415"
  },
  {
    "id": "arXiv:2203.08434",
    "title": "Deep Residual Error and Bag-of-Tricks Learning for Gravitational Wave  Surrogate Modeling",
    "abstract": "Deep learning methods have been employed in gravitational-wave astronomy to\naccelerate the construction of surrogate waveforms for the inspiral of\nspin-aligned black hole binaries, among other applications. We demonstrate,\nthat the residual error of an artificial neural network that models the\ncoefficients of the surrogate waveform expansion (especially those of the phase\nof the waveform) has sufficient structure to be learnable by a second network.\nAdding this second network, we were able to reduce the maximum mismatch for\nwaveforms in a validation set by more than an order of magnitude. We also\nexplored several other ideas for improving the accuracy of the surrogate model,\nsuch as the exploitation of similarities between waveforms, the augmentation of\nthe training set, the dissection of the input space, using dedicated networks\nper output coefficient and output augmentation. In several cases, small\nimprovements can be observed, but the most significant improvement still comes\nfrom the addition of a second network that models the residual error. Since the\nresidual error for more general surrogate waveform models (when e.g.\neccentricity is included) may also have a specific structure, one can expect\nour method to be applicable to cases where the gain in accuracy could lead to\nsignificant gains in computational time.",
    "descriptor": "",
    "authors": [
      "Styliani-Christina Fragkouli",
      "Paraskevi Nousi",
      "Nikolaos Passalis",
      "Panagiotis Iosif",
      "Nikolaos Stergioulas",
      "Anastasios Tefas"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2203.08434"
  },
  {
    "id": "arXiv:2203.08447",
    "title": "Characterization and modeling of the influence of initial microstructure  on recrystallization of zircaloy-4 during hot forming",
    "abstract": "The present article proposes a detailed study of recrystallization of\nzircaloy-4 under hot forming conditions by means of experimental and numerical\ntools. Thermomechanical tests and characterization campaigns that have been\nnecessary for this work are described. Then, the different microstructure\nevolution mechanisms are characterized, from the simplest one to the most\ncomplex. Grain growth kinetics is quantified and the influence of second phase\nparticle population is analyzed. Then, a complete study of dynamic and\npost-dynamic recrystallization is provided. The occurrence of a continuous\nmechanism is confirmed and the influence of thermomechanical conditions upon\nrecrystallization is assessed. Later, the numerical framework used to simulate\ngrain growth, continuous and post-dynamic recrystallization is presented. After\nhaving successfully reproduced the grain coarsening kinetics with and without\nsecond phase particles, the model is used to describe continuous dynamic\nrecrystallization and post-dynamic recrystallization from an initial equiaxed\nand fully recrystallized microstructure. The agreement between experimental and\nnumerical results is assessed in detail. Finally, post-dynamic\nrecrystallization is simulated, starting from two deformed microstructures\ncharacterized by electron back-scattered diffraction technique and immersed\ninto simulations. This allows to discuss and reproduce the influence of initial\nmicrostructure.",
    "descriptor": "",
    "authors": [
      "Victor Grand",
      "Baptiste Flipon",
      "Alexis Gaillac",
      "Marc Bernacki"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.08447"
  },
  {
    "id": "arXiv:2203.08471",
    "title": "Direct laser printing of high-resolution physically unclonable  anti-counterfeit labels",
    "abstract": "Security labels combining facile structural color readout and physically\nunclonable one-way function (PUF) approach provide promising strategy for\nfighting against forgery of marketable products. Here, we justify direct\nfemtosecond-laser printing, a simple and scalable technology, for fabrication\nof high-resolution (12500 dots per inch) and durable PUF labels with a\nsubstantially large encoding capacity of 10$^{895}$ and a simple\nspectroscopy-free optical signal readout. The proposed tags are comprised of\nlaser-printed plasmonic nanostructures exhibiting unique light scattering\nbehavior and unclonable 3D geometry. Uncontrollable stochastic variation of the\nnanostructure geometry in the process of their spot-by-spot printing results in\nrandom and broadband variation of the scattering color of each laser printed\n\"pixel\", making laser-printed patterns unique and suitable for PUF labeling.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Vasily Lapidas",
      "Alexey Zhizhchenko",
      "Eugeny Pustovalov",
      "Dmitry Storozhenko",
      "Aleksandr Kuchmizhak"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08471"
  },
  {
    "id": "arXiv:2203.08488",
    "title": "Raw waveform speaker verification for supervised and self-supervised  learning",
    "abstract": "Speaker verification models that directly operate upon raw waveforms are\nreceiving growing attention. However, their performances are less competitive\nthan the state-of-the-art handcrafted feature-based counterparts, demonstrating\nequal error rates under 1% on the benchmark VoxCeleb1 evaluation protocol. In\naddition, they have yet not been explored with self-supervised learning\nframeworks. This paper proposes a new raw waveform speaker verification model\nthat incorporates techniques proven effective for speaker verification,\nincluding the Res2Net backbone module and the aggregation method considering\nboth context and channels. Under the best performing configuration, the model\nshows an equal error rate of 0.89%, competitive with state-of-the-art models.\nWe also explore the proposed model with a self-supervised learning framework\nand show the state-of-the-art performance in this line of research. Finally, we\nshow that leveraging the model trained with self-supervision successfully\nserves as a pre-trained model under the semi-supervised scenario where it is\nassumed that only a limited amount of data has a ground truth label and a\nbigger data has no label.",
    "descriptor": "\nComments: submitted to INTERSPEECH 2022 as a conference paper. 5 pages, 2 figures, 5 tables\n",
    "authors": [
      "Jee-weon Jung",
      "You Jin Kim",
      "Hee-Soo Heo",
      "Bong-Jin Lee",
      "Youngki Kwon",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08488"
  },
  {
    "id": "arXiv:2203.08564",
    "title": "An elementary analysis of ridge regression with random design",
    "abstract": "In this short note, we present an elementary analysis of the prediction error\nof ridge regression with random design. The proof is short and self-contained.\nIn particular, it avoids matrix concentration or control of empirical\nprocesses, by using a simple combination of exchangeability arguments, matrix\nidentities and operator convexity.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Jaouad Mourtada",
      "Lorenzo Rosasco"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08564"
  },
  {
    "id": "arXiv:2203.08571",
    "title": "Morse Theoretic Signal Compression and Reconstruction on Chain Complexes",
    "abstract": "At the intersection of Topological Data Analysis (TDA) and machine learning,\nthe field of cellular signal processing has advanced rapidly in recent years.\nIn this context, each signal on the cells of a complex is processed using the\ncombinatorial Laplacian, and the resultant Hodge decomposition. Meanwhile,\ndiscrete Morse theory has been widely used to speed up computations by reducing\nthe size of complexes while preserving their global topological properties. In\nthis paper, we provide an approach to signal compression and reconstruction on\nchain complexes that leverages the tools of algebraic discrete Morse theory.\nThe main goal is to reduce and reconstruct a based chain complex together with\na set of signals on its cells via deformation retracts, preserving as much as\npossible the global topological structure of both the complex and the signals.\nWe first prove that any deformation retract of real degree-wise\nfinite-dimensional based chain complexes is equivalent to a Morse matching. We\nwill then study how the signal changes under particular types of Morse\nmatching, showing its reconstruction error is trivial on specific components of\nthe Hodge decomposition. Furthermore, we provide an algorithm to compute Morse\nmatchings with minimal reconstruction error.",
    "descriptor": "",
    "authors": [
      "Stefania Ebli",
      "Celia Hacker",
      "Kelly Maggs"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.08571"
  },
  {
    "id": "arXiv:2203.08592",
    "title": "On the complexity of the word problem of the R. Thompson group V",
    "abstract": "We analyze the proof by Lehnert and Schweitzer that the word problem of the\nThompson group V is co-context-free, and we show that this word problem is the\ncomplement of the cyclic closure of a union of reverse deterministic\ncontext-free languages. For certain finite generating sets, this word problem\nis the complement of the cyclic closure of the union of four deterministic\ncontext-free languages. It follows that the deterministic time-complexity of\nthe word problem of $V$ is at most quadratic.",
    "descriptor": "\nComments: 14 p\n",
    "authors": [
      "J.C. Birget"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.08592"
  },
  {
    "id": "arXiv:2203.08614",
    "title": "A Model of Job Parallelism for Latency Reduction in Large-Scale Systems",
    "abstract": "Processing computation-intensive jobs at multiple processing cores in\nparallel is essential in many real-world applications. In this paper, we\nconsider an idealised model for job parallelism in which a job can be served\nsimultaneously by $d$ distinct servers. The job is considered complete when the\ntotal amount of work done on it by the $d$ servers equals its size. We study\nthe effect of parallelism on the average delay of jobs. Specifically, we\nanalyze a system consisting of $n$ parallel processor sharing servers in which\njobs arrive according to a Poisson process of rate $n \\lambda$ ($\\lambda <1$)\nand each job brings an exponentially distributed amount of work with unit mean.\nUpon arrival, a job selects $d$ servers uniformly at random and joins all the\nchosen servers simultaneously. We show by a mean-field analysis that, for fixed\n$d \\geq 2$ and large $n$, the average occupancy of servers is $O(\\log\n(1/(1-\\lambda)))$ as $\\lambda \\to 1$ in comparison to $O(1/(1-\\lambda))$\naverage occupancy for $d=1$. Thus, we obtain an exponential reduction in the\nresponse time of jobs through parallelism. We make significant progress towards\nrigorously justifying the mean-field analysis.",
    "descriptor": "",
    "authors": [
      "Ayalvadi Ganesh",
      "Arpan Mukhopadhyay"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.08614"
  },
  {
    "id": "arXiv:2203.08644",
    "title": "Context-Aware Drift Detection",
    "abstract": "When monitoring machine learning systems, two-sample tests of homogeneity\nform the foundation upon which existing approaches to drift detection build.\nThey are used to test for evidence that the distribution underlying recent\ndeployment data differs from that underlying the historical reference data.\nOften, however, various factors such as time-induced correlation mean that\nbatches of recent deployment data are not expected to form an i.i.d. sample\nfrom the historical data distribution. Instead we may wish to test for\ndifferences in the distributions conditional on \\textit{context} that is\npermitted to change. To facilitate this we borrow machinery from the causal\ninference domain to develop a more general drift detection framework built upon\na foundation of two-sample tests for conditional distributional treatment\neffects. We recommend a particular instantiation of the framework based on\nmaximum conditional mean discrepancies. We then provide an empirical study\ndemonstrating its effectiveness for various drift detection problems of\npractical interest, such as detecting drift in the distributions underlying\nsubpopulations of data in a manner that is insensitive to their respective\nprevalences. The study additionally demonstrates applicability to\nImageNet-scale vision problems.",
    "descriptor": "\nComments: 25 pages, 26 figures\n",
    "authors": [
      "Oliver Cobb",
      "Arnaud Van Looveren"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08644"
  },
  {
    "id": "arXiv:2203.08650",
    "title": "Complexity Reduction of Learned In-Loop Filtering in Video Coding",
    "abstract": "In video coding, in-loop filters are applied on reconstructed video frames to\nenhance their perceptual quality, before storing the frames for output.\nConventional in? loop filters are obtained by hand-crafted methods. Recently,\nlearned filters based on convolutional neural networks that utilize attention\nmechanisms have been shown to improve upon traditional techniques. However,\nthese solutions are typically significantly more computationally expensive,\nlimiting their potential for practical applications. The proposed method uses a\nnovel combination of sparsity and structured pruning for complexity reduction\nof learned in-loop filters. This is done through a three-step training process\nof magnitude-guidedweight pruning, insignificant neuron identification and\nremoval, and fine-tuning. Through initial tests we find that network parameters\ncan be significantly reduced with a minimal impact on network performance.",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables\n",
    "authors": [
      "Woody Bayliss",
      "Luka Murn",
      "Ebroul Izquierdo",
      "Qianni Zhang",
      "Marta Mrak"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08650"
  },
  {
    "id": "arXiv:2203.08659",
    "title": "On optimal coordinated dispatch for heterogeneous storage fleets with  partial availability",
    "abstract": "This paper addresses the problem of optimal scheduling of an aggregated power\nprofile (during a coordinated discharging or charging operation) by means of a\nheterogeneous fleet of storage devices subject to availability constraints.\nDevices have heterogeneous initial levels of energy, power ratings and\nefficiency; moreover, the fleet operates without cross-charging of the units.\nAn explicit feedback policy is proposed to compute a feasible schedule whenever\none exists and scalable design procedures to achieve maximum time to failure or\nminimal unserved energy in the case of unfeasible aggregated demand profiles.\nFinally, a time-domain characterization of the set of feasible demand profiles\nusing aggregate constraints is proposed, suitable for optimization problems\nwhere the aggregate population behaviour is of interest.",
    "descriptor": "",
    "authors": [
      "David Angeli",
      "Zihang Dong",
      "Goran Strbac"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08659"
  },
  {
    "id": "arXiv:2203.08709",
    "title": "High dimensional change-point detection: a complete graph approach",
    "abstract": "The aim of online change-point detection is for a accurate, timely discovery\nof structural breaks. As data dimension outgrows the number of data in\nobservation, online detection becomes challenging. Existing methods typically\ntest only the change of mean, which omit the practical aspect of change of\nvariance. We propose a complete graph-based, change-point detection algorithm\nto detect change of mean and variance from low to high-dimensional online data\nwith a variable scanning window. Inspired by complete graph structure, we\nintroduce graph-spanning ratios to map high-dimensional data into metrics, and\nthen test statistically if a change of mean or change of variance occurs.\nTheoretical study shows that our approach has the desirable pivotal property\nand is powerful with prescribed error probabilities. We demonstrate that this\nframework outperforms other methods in terms of detection power. Our approach\nhas high detection power with small and multiple scanning window, which allows\ntimely detection of change-point in the online setting. Finally, we applied the\nmethod to financial data to detect change-points in S&P 500 stocks.",
    "descriptor": "",
    "authors": [
      "Yang-Wen Sun",
      "Katerina Papagiannouli",
      "Vladimir Spokoiny"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.08709"
  },
  {
    "id": "arXiv:2203.08727",
    "title": "Linear slices of hyperbolic polynomials and positivity of symmetric  polynomial functions",
    "abstract": "A real univariate polynomial of degree $n$ is called hyperbolic if all of its\n$n$ roots are on the real line. We study families of hyperbolic polynomials\ndefined by $k$ linear conditions on the coefficients. We show that the\npolynomials corresponding to local extreme points of such families have at most\n$k$ distinct roots. Furthermore, we find that generically the convex hull of\nsuch a family is a polyhedron. Building on these results, we give consequences\nof our results to the study of symmetric real varieties and symmetric\nsemi-algebraic sets. Here, we show that sets defined by symmetric polynomials\nwhich can be expressed sparsely in terms of elementary symmetric polynomials\ncan be sampled on points with few distinct coordinates. This in turn allows for\nalgorithmic simplifications, for example to verify that such polynomials are\nnon-negative or that a semi-algebraic set defined by such polynomials is empty.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Cordian Riener",
      "Robin Schabert"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Symbolic Computation (cs.SC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.08727"
  },
  {
    "id": "arXiv:2203.08767",
    "title": "The Degree-Rips Complexes of an Annulus with Outliers",
    "abstract": "The degree-Rips bifiltration is the most computable of the parameter-free,\ndensity-sensitive bifiltrations in topological data analysis. It is known that\nthis construction is stable to small perturbations of the input data, but its\nrobustness to outliers is not well understood. In recent work, Blumberg-Lesnick\nprove a result in this direction using the Prokhorov distance and homotopy\ninterleavings. Based on experimental evaluation, they argue that a more refined\napproach is desirable, and suggest the framework of homology inference.\nMotivated by these experiments, we consider a probability measure that is\nuniform with high density on an annulus, and uniform with low density on the\ndisc inside the annulus. We compute the degree-Rips complexes of this\nprobability space up to homotopy type, using the Adamaszek-Adams computation of\nthe Vietoris-Rips complexes of the circle. These degree-Rips complexes are the\nlimit objects for the Blumberg-Lesnick experiments. We argue that the homology\ninference approach has strong explanatory power in this case, and suggest\nstudying the limit objects directly as a strategy for further work.",
    "descriptor": "\nComments: 14 pages, 3 figures. To appear in SoCG 2022. Comments welcome\n",
    "authors": [
      "Alexander Rolle"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.08767"
  },
  {
    "id": "arXiv:2203.08775",
    "title": "Practical Conditional Neural Processes Via Tractable Dependent  Predictions",
    "abstract": "Conditional Neural Processes (CNPs; Garnelo et al., 2018a) are meta-learning\nmodels which leverage the flexibility of deep learning to produce\nwell-calibrated predictions and naturally handle off-the-grid and missing data.\nCNPs scale to large datasets and train with ease. Due to these features, CNPs\nappear well-suited to tasks from environmental sciences or healthcare.\nUnfortunately, CNPs do not produce correlated predictions, making them\nfundamentally inappropriate for many estimation and decision making tasks.\nPredicting heat waves or floods, for example, requires modelling dependencies\nin temperature or precipitation over time and space. Existing approaches which\nmodel output dependencies, such as Neural Processes (NPs; Garnelo et al.,\n2018b) or the FullConvGNP (Bruinsma et al., 2021), are either complicated to\ntrain or prohibitively expensive. What is needed is an approach which provides\ndependent predictions, but is simple to train and computationally tractable. In\nthis work, we present a new class of Neural Process models that make correlated\npredictions and support exact maximum likelihood training that is simple and\nscalable. We extend the proposed models by using invertible output\ntransformations, to capture non-Gaussian output distributions. Our models can\nbe used in downstream estimation tasks which require dependent function\nsamples. By accounting for output dependencies, our models show improved\npredictive performance on a range of experiments with synthetic and real data.",
    "descriptor": "\nComments: 23 pages; accepted to the 10th International Conference on Learning Representations (ICLR 2022)\n",
    "authors": [
      "Stratis Markou",
      "James Requeima",
      "Wessel P. Bruinsma",
      "Anna Vaughan",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08775"
  },
  {
    "id": "arXiv:1805.03253",
    "title": "Efficient Shortest Paths in Scale-Free Networks with Underlying  Hyperbolic Geometry",
    "abstract": "Efficient Shortest Paths in Scale-Free Networks with Underlying  Hyperbolic Geometry",
    "descriptor": "",
    "authors": [
      "Thomas Bl\u00e4sius",
      "Cedric Freiberger",
      "Tobias Friedrich",
      "Maximilian Katzmann",
      "Felix Montenegro-Retana",
      "Marianne Thieffry"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/1805.03253"
  },
  {
    "id": "arXiv:1809.07744",
    "title": "Guaranteed Globally Optimal Planar Pose Graph and Landmark SLAM via  Sparse-Bounded Sums-of-Squares Programming",
    "abstract": "Comments: 12 pages, 5 figures, Original Version Published in IEEE International Conference on Robotics and Automation",
    "descriptor": "\nComments: 12 pages, 5 figures, Original Version Published in IEEE International Conference on Robotics and Automation\n",
    "authors": [
      "Joshua G. Mangelson",
      "Jinsun Liu",
      "Ryan M. Eustice",
      "Ram Vasudevan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1809.07744"
  },
  {
    "id": "arXiv:1908.01308",
    "title": "Theme-Aware Aesthetic Distribution Prediction With Full-Resolution  Photographs",
    "abstract": "Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Gengyun Jia",
      "Peipei Li",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1908.01308"
  },
  {
    "id": "arXiv:1912.10230",
    "title": "A Survey on Deep Learning-based Architectures for Semantic Segmentation  on 2D images",
    "abstract": "Comments: published in the J. of Applied Artificial Intelligence (09 Feb 2022)",
    "descriptor": "\nComments: published in the J. of Applied Artificial Intelligence (09 Feb 2022)\n",
    "authors": [
      "Irem Ulku",
      "Erdem Akagunduz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1912.10230"
  },
  {
    "id": "arXiv:2002.02390",
    "title": "Regret analysis of the Piyavskii-Shubert algorithm for global Lipschitz  optimization",
    "abstract": "Regret analysis of the Piyavskii-Shubert algorithm for global Lipschitz  optimization",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Bouttier",
      "Tommaso Cesari",
      "M\u00e9lanie Ducoffe",
      "S\u00e9bastien Gerchinovitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.02390"
  },
  {
    "id": "arXiv:2004.13424",
    "title": "Boundary element methods for Helmholtz problems with weakly imposed  boundary conditions",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Timo Betcke",
      "Erik Burman",
      "Matthew W. Scroggs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2004.13424"
  },
  {
    "id": "arXiv:2006.06897",
    "title": "MCMC Should Mix: Learning Energy-Based Model with Neural Transport  Latent Space MCMC",
    "abstract": "MCMC Should Mix: Learning Energy-Based Model with Neural Transport  Latent Space MCMC",
    "descriptor": "",
    "authors": [
      "Erik Nijkamp",
      "Ruiqi Gao",
      "Pavel Sountsov",
      "Srinivas Vasudevan",
      "Bo Pang",
      "Song-Chun Zhu",
      "Ying Nian Wu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.06897"
  },
  {
    "id": "arXiv:2006.10598",
    "title": "Neural Parameter Allocation Search",
    "abstract": "Comments: Accepted at ICLR 2022",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Bryan A. Plummer",
      "Nikoli Dryden",
      "Julius Frost",
      "Torsten Hoefler",
      "Kate Saenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10598"
  },
  {
    "id": "arXiv:2006.11654",
    "title": "Counterfactually Guided Off-policy Transfer in Clinical Settings",
    "abstract": "Comments: Will be published at the Conference for Health, Inference and Learning (CHIL) 2022, Camera Ready Version",
    "descriptor": "\nComments: Will be published at the Conference for Health, Inference and Learning (CHIL) 2022, Camera Ready Version\n",
    "authors": [
      "Taylor W. Killian",
      "Marzyeh Ghassemi",
      "Shalmali Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.11654"
  },
  {
    "id": "arXiv:2006.12687",
    "title": "Accurate Parameter Estimation for Risk-aware Autonomous Systems",
    "abstract": "Accurate Parameter Estimation for Risk-aware Autonomous Systems",
    "descriptor": "",
    "authors": [
      "Arnab Sarker",
      "Peter Fisher",
      "Joseph E. Gaudio",
      "Anuradha M. Annaswamy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.12687"
  },
  {
    "id": "arXiv:2007.07124",
    "title": "Failure Modes of Variational Autoencoders and Their Effects on  Downstream Tasks",
    "abstract": "Comments: Accepted at the International Conference on Machine Learning (ICML) Workshop on Uncertainty and Robustness in Deep Learning (UDL) 2020",
    "descriptor": "\nComments: Accepted at the International Conference on Machine Learning (ICML) Workshop on Uncertainty and Robustness in Deep Learning (UDL) 2020\n",
    "authors": [
      "Yaniv Yacoby",
      "Weiwei Pan",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.07124"
  },
  {
    "id": "arXiv:2007.07131",
    "title": "Irregular Accesses Reorder Unit: Improving GPGPU Memory Coalescing for  Graph-Based Workloads",
    "abstract": "Irregular Accesses Reorder Unit: Improving GPGPU Memory Coalescing for  Graph-Based Workloads",
    "descriptor": "",
    "authors": [
      "Albert Segura",
      "Jose-Maria Arnau",
      "Antonio Gonzalez"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2007.07131"
  },
  {
    "id": "arXiv:2007.12928",
    "title": "Video Super Resolution Based on Deep Learning: A Comprehensive Survey",
    "abstract": "Comments: 33 pages, 41 figures, accepted by Artificial Intelligence Review, 2022",
    "descriptor": "\nComments: 33 pages, 41 figures, accepted by Artificial Intelligence Review, 2022\n",
    "authors": [
      "Hongying Liu",
      "Zhubo Ruan",
      "Peng Zhao",
      "Chao Dong",
      "Fanhua Shang",
      "Yuanyuan Liu",
      "Linlin Yang",
      "Radu Timofte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2007.12928"
  },
  {
    "id": "arXiv:2009.02970",
    "title": "Modelling Gossip Interactions in Open Multi-Agent Systems",
    "abstract": "Comments: 8 pages, 4 figures, submitted to IEEE Transactions on Automatic Control (ITAC)",
    "descriptor": "\nComments: 8 pages, 4 figures, submitted to IEEE Transactions on Automatic Control (ITAC)\n",
    "authors": [
      "Charles Monnoyer de Galland",
      "Samuel Martin",
      "Julien M. Hendrickx"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2009.02970"
  },
  {
    "id": "arXiv:2009.11782",
    "title": "Neural Identification for Control",
    "abstract": "Comments: Copyright 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: Copyright 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Priyabrata Saha",
      "Magnus Egerstedt",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2009.11782"
  },
  {
    "id": "arXiv:2010.02033",
    "title": "Single-stage gradient-based stellarator coil design: Optimization for  near-axis quasi-symmetry",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Andrew Giuliani",
      "Florian Wechsung",
      "Antoine Cerfon",
      "Georg Stadler",
      "Matt Landreman"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2010.02033"
  },
  {
    "id": "arXiv:2010.03533",
    "title": "Gradient Flow in Sparse Neural Networks and How Lottery Tickets Win",
    "abstract": "Comments: Published in AAAI 2022. Code can be found at this https URL",
    "descriptor": "\nComments: Published in AAAI 2022. Code can be found at this https URL\n",
    "authors": [
      "Utku Evci",
      "Yani A. Ioannou",
      "Cem Keskin",
      "Yann Dauphin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.03533"
  },
  {
    "id": "arXiv:2011.05382",
    "title": "Wayback Machine: A tool to capture the evolutionary behaviour of the bug  reports and their triage process in open-source software systems",
    "abstract": "Comments: 43 Pages - Accepted for the Journal of Systems & Software",
    "descriptor": "\nComments: 43 Pages - Accepted for the Journal of Systems & Software\n",
    "authors": [
      "Hadi Jahanshahi",
      "Mucahit Cevik",
      "Jos\u00e9 Navas-S\u00fa",
      "Ay\u015fe Ba\u015far",
      "Antonio Gonz\u00e1lez-Torres"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2011.05382"
  },
  {
    "id": "arXiv:2011.08181",
    "title": "A Random Matrix Theory Approach to Damping in Deep Learning",
    "abstract": "A Random Matrix Theory Approach to Damping in Deep Learning",
    "descriptor": "",
    "authors": [
      "Diego Granziol",
      "Nicholas Baskerville"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.08181"
  },
  {
    "id": "arXiv:2011.08908",
    "title": "SHIELD: Defending Textual Neural Networks against Multiple Black-Box  Adversarial Attacks with Stochastic Multi-Expert Patcher",
    "abstract": "Comments: Accepted to the 60th Annual Meeting of the Association for Computational Linguistics (ACL'22)",
    "descriptor": "\nComments: Accepted to the 60th Annual Meeting of the Association for Computational Linguistics (ACL'22)\n",
    "authors": [
      "Thai Le",
      "Noseong Park",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.08908"
  },
  {
    "id": "arXiv:2101.05339",
    "title": "Accelerating amorphous polymer electrolyte screening by learning to  reduce errors in molecular dynamics simulated properties",
    "abstract": "Comments: 29 pages, 6 figures + supplementary information",
    "descriptor": "\nComments: 29 pages, 6 figures + supplementary information\n",
    "authors": [
      "Tian Xie",
      "Arthur France-Lanord",
      "Yanming Wang",
      "Jeffrey Lopez",
      "Michael Austin Stolberg",
      "Megan Hill",
      "Graham Michael Leverick",
      "Rafael Gomez-Bombarelli",
      "Jeremiah A. Johnson",
      "Yang Shao-Horn",
      "Jeffrey C. Grossman"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.05339"
  },
  {
    "id": "arXiv:2101.05467",
    "title": "Tackling Instance-Dependent Label Noise via a Universal Probabilistic  Model",
    "abstract": "Tackling Instance-Dependent Label Noise via a Universal Probabilistic  Model",
    "descriptor": "",
    "authors": [
      "Qizhou Wang",
      "Bo Han",
      "Tongliang Liu",
      "Gang Niu",
      "Jian Yang",
      "Chen Gong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.05467"
  },
  {
    "id": "arXiv:2101.06223",
    "title": "LIME: Learning Inductive Bias for Primitives of Mathematical Reasoning",
    "abstract": "Comments: Published as a conference paper at ICML 2021 (16 pages)",
    "descriptor": "\nComments: Published as a conference paper at ICML 2021 (16 pages)\n",
    "authors": [
      "Yuhuai Wu",
      "Markus Rabe",
      "Wenda Li",
      "Jimmy Ba",
      "Roger Grosse",
      "Christian Szegedy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.06223"
  },
  {
    "id": "arXiv:2101.07295",
    "title": "The Surprising Positive Knowledge Transfer in Continual 3D Object Shape  Reconstruction",
    "abstract": "The Surprising Positive Knowledge Transfer in Continual 3D Object Shape  Reconstruction",
    "descriptor": "",
    "authors": [
      "Anh Thai",
      "Stefan Stojanov",
      "Zixuan Huang",
      "Isaac Rehg",
      "James M. Rehg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.07295"
  },
  {
    "id": "arXiv:2102.06203",
    "title": "Proof Artifact Co-training for Theorem Proving with Language Models",
    "abstract": "Proof Artifact Co-training for Theorem Proving with Language Models",
    "descriptor": "",
    "authors": [
      "Jesse Michael Han",
      "Jason Rute",
      "Yuhuai Wu",
      "Edward W. Ayers",
      "Stanislas Polu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.06203"
  },
  {
    "id": "arXiv:2102.06571",
    "title": "Bayesian Neural Network Priors Revisited",
    "abstract": "Comments: Accepted at ICLR 2022",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Vincent Fortuin",
      "Adri\u00e0 Garriga-Alonso",
      "Sebastian W. Ober",
      "Florian Wenzel",
      "Gunnar R\u00e4tsch",
      "Richard E. Turner",
      "Mark van der Wilk",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06571"
  },
  {
    "id": "arXiv:2102.06593",
    "title": "Pareto Optimal Model Selection in Linear Bandits",
    "abstract": "Pareto Optimal Model Selection in Linear Bandits",
    "descriptor": "",
    "authors": [
      "Yinglun Zhu",
      "Robert Nowak"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06593"
  },
  {
    "id": "arXiv:2103.00370",
    "title": "Axiomatic Explanations for Visual Search, Retrieval, and Similarity  Learning",
    "abstract": "Axiomatic Explanations for Visual Search, Retrieval, and Similarity  Learning",
    "descriptor": "",
    "authors": [
      "Mark Hamilton",
      "Scott Lundberg",
      "Lei Zhang",
      "Stephanie Fu",
      "William T. Freeman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2103.00370"
  },
  {
    "id": "arXiv:2103.11784",
    "title": "Towards Ultra-Resolution Neural Style Transfer via Thumbnail Instance  Normalization",
    "abstract": "Comments: Accepted to AAAI 2022",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Zhe Chen",
      "Wenhai Wang",
      "Enze Xie",
      "Tong Lu",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.11784"
  },
  {
    "id": "arXiv:2103.12407",
    "title": "Detecting Hate Speech with GPT-3",
    "abstract": "Comments: 28 pages, 1 figure, 23 tables",
    "descriptor": "\nComments: 28 pages, 1 figure, 23 tables\n",
    "authors": [
      "Ke-Li Chiu",
      "Annie Collins",
      "Rohan Alexander"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.12407"
  },
  {
    "id": "arXiv:2103.15241",
    "title": "Online Flocking Control of UAVs with Mean-Field Approximation",
    "abstract": "Comments: Accepted to IEEE International Conference on Robotics and Automation (ICRA), 2021",
    "descriptor": "\nComments: Accepted to IEEE International Conference on Robotics and Automation (ICRA), 2021\n",
    "authors": [
      "Malintha Fernando"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.15241"
  },
  {
    "id": "arXiv:2104.00567",
    "title": "Text to Image Generation with Semantic-Spatial Aware GAN",
    "abstract": "Comments: code available, accepted to CVPR 2022",
    "descriptor": "\nComments: code available, accepted to CVPR 2022\n",
    "authors": [
      "Wentong Liao",
      "Kai Hu",
      "Michael Ying Yang",
      "Bodo Rosenhahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.00567"
  },
  {
    "id": "arXiv:2104.03547",
    "title": "Seeing Thru Walls: Visualizing Mobile Robots in Augmented Reality",
    "abstract": "Comments: Accepted at RO-MAN 2021 \"30th IEEE International Conference on Robot and Human Interactive Communication\", 6 pages, 5 figures, 5 Tables",
    "descriptor": "\nComments: Accepted at RO-MAN 2021 \"30th IEEE International Conference on Robot and Human Interactive Communication\", 6 pages, 5 figures, 5 Tables\n",
    "authors": [
      "Morris Gu",
      "Akansel Cosgun",
      "Wesley P. Chan",
      "Tom Drummond",
      "Elizabeth Croft"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.03547"
  },
  {
    "id": "arXiv:2104.05565",
    "title": "Survey on reinforcement learning for language processing",
    "abstract": "Survey on reinforcement learning for language processing",
    "descriptor": "",
    "authors": [
      "Victor Uc-Cetina",
      "Nicolas Navarro-Guerrero",
      "Anabel Martin-Gonzalez",
      "Cornelius Weber",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.05565"
  },
  {
    "id": "arXiv:2104.07232",
    "title": "Iterative Alignment Flows",
    "abstract": "Iterative Alignment Flows",
    "descriptor": "",
    "authors": [
      "Zeyu Zhou",
      "Ziyu Gong",
      "Pradeep Ravikumar",
      "David I. Inouye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.07232"
  },
  {
    "id": "arXiv:2104.07389",
    "title": "Do Deep Neural Networks Forget Facial Action Units? -- Exploring the  Effects of Transfer Learning in Health Related Facial Expression Recognition",
    "abstract": "Comments: The 5th International Workshop on Health Intelligence (W3PHIAI-21)",
    "descriptor": "\nComments: The 5th International Workshop on Health Intelligence (W3PHIAI-21)\n",
    "authors": [
      "Pooja Prajod",
      "Dominik Schiller",
      "Tobias Huber",
      "Elisabeth Andr\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07389"
  },
  {
    "id": "arXiv:2104.07642",
    "title": "Bilingual alignment transfers to multilingual alignment for unsupervised  parallel text mining",
    "abstract": "Comments: To be published at ACL 2022. 11 pages, 2 figures",
    "descriptor": "\nComments: To be published at ACL 2022. 11 pages, 2 figures\n",
    "authors": [
      "Chih-chan Tien",
      "Shane Steinert-Threlkeld"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.07642"
  },
  {
    "id": "arXiv:2104.10895",
    "title": "On convergence rates of adaptive ensemble Kalman inversion for linear  ill-posed problems",
    "abstract": "On convergence rates of adaptive ensemble Kalman inversion for linear  ill-posed problems",
    "descriptor": "",
    "authors": [
      "Fabian Parzer",
      "Otmar Scherzer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.10895"
  },
  {
    "id": "arXiv:2104.13450",
    "title": "Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and  Extracting Them from 2D Renderings",
    "abstract": "Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and  Extracting Them from 2D Renderings",
    "descriptor": "",
    "authors": [
      "Innfarn Yoo",
      "Huiwen Chang",
      "Xiyang Luo",
      "Ondrej Stava",
      "Ce Liu",
      "Peyman Milanfar",
      "Feng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.13450"
  },
  {
    "id": "arXiv:2105.04444",
    "title": "Continual Learning via Bit-Level Information Preserving",
    "abstract": "Comments: CVPR2021",
    "descriptor": "\nComments: CVPR2021\n",
    "authors": [
      "Yujun Shi",
      "Li Yuan",
      "Yunpeng Chen",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04444"
  },
  {
    "id": "arXiv:2105.04471",
    "title": "Natural Posterior Network: Deep Bayesian Uncertainty for Exponential  Family Distributions",
    "abstract": "Natural Posterior Network: Deep Bayesian Uncertainty for Exponential  Family Distributions",
    "descriptor": "",
    "authors": [
      "Bertrand Charpentier",
      "Oliver Borchert",
      "Daniel Z\u00fcgner",
      "Simon Geisler",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04471"
  },
  {
    "id": "arXiv:2105.07122",
    "title": "Premise-based Multimodal Reasoning: A Human-like Cognitive Process",
    "abstract": "Comments: ACL 2022 Main conference (Long Paper)",
    "descriptor": "\nComments: ACL 2022 Main conference (Long Paper)\n",
    "authors": [
      "Qingxiu Dong",
      "Ziwei Qin",
      "Heming Xia",
      "Tian Feng",
      "Shoujie Tong",
      "Haoran Meng",
      "Lin Xu",
      "Weidong Zhan",
      "Sujian Li",
      "Zhongyu Wei",
      "Tianyu Liu",
      "Zuifang Sui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.07122"
  },
  {
    "id": "arXiv:2105.07470",
    "title": "On Complementing Unambiguous Automata and Graphs With Many Cliques and  Cocliques",
    "abstract": "Comments: version implementing referees' suggestions",
    "descriptor": "\nComments: version implementing referees' suggestions\n",
    "authors": [
      "Emil Indzhev",
      "Stefan Kiefer"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.07470"
  },
  {
    "id": "arXiv:2105.08621",
    "title": "Zorro: Valid, Sparse, and Stable Explanations in Graph Neural Networks",
    "abstract": "Zorro: Valid, Sparse, and Stable Explanations in Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Thorben Funke",
      "Megha Khosla",
      "Mandeep Rathee",
      "Avishek Anand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.08621"
  },
  {
    "id": "arXiv:2105.11589",
    "title": "VISITRON: Visual Semantics-Aligned Interactively Trained  Object-Navigator",
    "abstract": "Comments: Accepted at Findings of the Annual Meeting of the Association for Computational Linguistics (ACL) 2022, previous version accepted at Visually Grounded Interaction and Language (ViGIL) Workshop at NAACL 2021",
    "descriptor": "\nComments: Accepted at Findings of the Annual Meeting of the Association for Computational Linguistics (ACL) 2022, previous version accepted at Visually Grounded Interaction and Language (ViGIL) Workshop at NAACL 2021\n",
    "authors": [
      "Ayush Shrivastava",
      "Karthik Gopalakrishnan",
      "Yang Liu",
      "Robinson Piramuthu",
      "Gokhan T\u00fcr",
      "Devi Parikh",
      "Dilek Hakkani-T\u00fcr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.11589"
  },
  {
    "id": "arXiv:2105.11827",
    "title": "Narwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus",
    "abstract": "Narwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus",
    "descriptor": "",
    "authors": [
      "George Danezis",
      "Eleftherios Kokoris Kogias",
      "Alberto Sonnino",
      "Alexander Spiegelman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.11827"
  },
  {
    "id": "arXiv:2105.14488",
    "title": "REAM$\\sharp$: An Enhancement Approach to Reference-based Evaluation  Metrics for Open-domain Dialog Generation",
    "abstract": "Comments: ACL Findings 2021",
    "descriptor": "\nComments: ACL Findings 2021\n",
    "authors": [
      "Jun Gao",
      "Wei Bi",
      "Ruifeng Xu",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14488"
  },
  {
    "id": "arXiv:2105.14686",
    "title": "Fully Hyperbolic Neural Networks",
    "abstract": "Comments: ACL 2022 Main Conference",
    "descriptor": "\nComments: ACL 2022 Main Conference\n",
    "authors": [
      "Weize Chen",
      "Xu Han",
      "Yankai Lin",
      "Hexu Zhao",
      "Zhiyuan Liu",
      "Peng Li",
      "Maosong Sun",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14686"
  },
  {
    "id": "arXiv:2106.01006",
    "title": "SocAoG: Incremental Graph Parsing for Social Relation Inference in  Dialogues",
    "abstract": "Comments: Long paper (oral) accepted by ACL-IJCNLP 2021",
    "descriptor": "\nComments: Long paper (oral) accepted by ACL-IJCNLP 2021\n",
    "authors": [
      "Liang Qiu",
      "Yuan Liang",
      "Yizhou Zhao",
      "Pan Lu",
      "Baolin Peng",
      "Zhou Yu",
      "Ying Nian Wu",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01006"
  },
  {
    "id": "arXiv:2106.01613",
    "title": "NODE-GAM: Neural Generalized Additive Model for Interpretable Deep  Learning",
    "abstract": "Comments: 2022 ICLR Spotlight paper",
    "descriptor": "\nComments: 2022 ICLR Spotlight paper\n",
    "authors": [
      "Chun-Hao Chang",
      "Rich Caruana",
      "Anna Goldenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01613"
  },
  {
    "id": "arXiv:2106.02193",
    "title": "Cross-Trajectory Representation Learning for Zero-Shot Generalization in  RL",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Bogdan Mazoure",
      "Ahmed M. Ahmed",
      "Patrick MacAlpine",
      "R Devon Hjelm",
      "Andrey Kolobov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02193"
  },
  {
    "id": "arXiv:2106.02938",
    "title": "Energy-Based Learning for Cooperative Games, with Applications to  Valuation Problems in Machine Learning",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Yatao Bian",
      "Yu Rong",
      "Tingyang Xu",
      "Jiaxiang Wu",
      "Andreas Krause",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02938"
  },
  {
    "id": "arXiv:2106.03982",
    "title": "Expressivity of Emergent Language is a Trade-off between Contextual  Complexity and Unpredictability",
    "abstract": "Comments: 22 pages, 12 figures, 5 tables",
    "descriptor": "\nComments: 22 pages, 12 figures, 5 tables\n",
    "authors": [
      "Shangmin Guo",
      "Yi Ren",
      "Kory Mathewson",
      "Simon Kirby",
      "Stefano V. Albrecht",
      "Kenny Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.03982"
  },
  {
    "id": "arXiv:2106.04427",
    "title": "On the relation between statistical learning and perceptual distances",
    "abstract": "On the relation between statistical learning and perceptual distances",
    "descriptor": "",
    "authors": [
      "Alexander Hepburn",
      "Valero Laparra",
      "Raul Santos-Rodriguez",
      "Johannes Ball\u00e9",
      "Jes\u00fas Malo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.04427"
  },
  {
    "id": "arXiv:2106.05258",
    "title": "Generative Models as a Data Source for Multiview Representation Learning",
    "abstract": "Generative Models as a Data Source for Multiview Representation Learning",
    "descriptor": "",
    "authors": [
      "Ali Jahanian",
      "Xavier Puig",
      "Yonglong Tian",
      "Phillip Isola"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05258"
  },
  {
    "id": "arXiv:2106.06042",
    "title": "FedBABU: Towards Enhanced Representation for Federated Image  Classification",
    "abstract": "Comments: Published at ICLR 2022",
    "descriptor": "\nComments: Published at ICLR 2022\n",
    "authors": [
      "Jaehoon Oh",
      "Sangmook Kim",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06042"
  },
  {
    "id": "arXiv:2106.06409",
    "title": "Real-time thermoacoustic data assimilation",
    "abstract": "Comments: 38 pages, 26 figures",
    "descriptor": "\nComments: 38 pages, 26 figures\n",
    "authors": [
      "Andrea N\u00f3voa",
      "Luca Magri"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.06409"
  },
  {
    "id": "arXiv:2106.06848",
    "title": "Guaranteed Fixed-Confidence Best Arm Identification in Multi-Armed  Bandits: Simple Sequential Elimination Algorithms",
    "abstract": "Guaranteed Fixed-Confidence Best Arm Identification in Multi-Armed  Bandits: Simple Sequential Elimination Algorithms",
    "descriptor": "",
    "authors": [
      "MohammadJavad Azizi",
      "Sheldon M Ross",
      "Zhengyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06848"
  },
  {
    "id": "arXiv:2106.06920",
    "title": "Multi-modal Scene-compliant User Intention Estimation in Navigation",
    "abstract": "Comments: Published in 2021 IROS",
    "descriptor": "\nComments: Published in 2021 IROS\n",
    "authors": [
      "Kavindie Katuwandeniya",
      "Stefan H. Kiss",
      "Lei Shi",
      "Jaime Valls Miro"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06920"
  },
  {
    "id": "arXiv:2106.07214",
    "title": "Backdoor Learning Curves: Explaining Backdoor Poisoning Beyond Influence  Functions",
    "abstract": "Comments: preprint; 28 pages",
    "descriptor": "\nComments: preprint; 28 pages\n",
    "authors": [
      "Antonio Emanuele Cin\u00e0",
      "Kathrin Grosse",
      "Sebastiano Vascon",
      "Ambra Demontis",
      "Battista Biggio",
      "Fabio Roli",
      "Marcello Pelillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.07214"
  },
  {
    "id": "arXiv:2106.07250",
    "title": "Unified Interpretation of Softmax Cross-Entropy and Negative Sampling:  With Case Study for Knowledge Graph Embedding",
    "abstract": "Comments: Accepted at ACL-IJCNLP 2021",
    "descriptor": "\nComments: Accepted at ACL-IJCNLP 2021\n",
    "authors": [
      "Hidetaka Kamigaito",
      "Katsuhiko Hayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07250"
  },
  {
    "id": "arXiv:2106.08190",
    "title": "Question Answering Infused Pre-training of General-Purpose  Contextualized Representations",
    "abstract": "Comments: Findings of ACL 2022",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Robin Jia",
      "Mike Lewis",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08190"
  },
  {
    "id": "arXiv:2106.09292",
    "title": "CROP: Certifying Robust Policies for Reinforcement Learning through  Functional Smoothing",
    "abstract": "Comments: Published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Fan Wu",
      "Linyi Li",
      "Zijian Huang",
      "Yevgeniy Vorobeychik",
      "Ding Zhao",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09292"
  },
  {
    "id": "arXiv:2106.09848",
    "title": "PAC Prediction Sets Under Covariate Shift",
    "abstract": "Comments: Accepted to ICLR 2022",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "Sangdon Park",
      "Edgar Dobriban",
      "Insup Lee",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09848"
  },
  {
    "id": "arXiv:2106.11688",
    "title": "Group mixing drives inequality in face-to-face gatherings",
    "abstract": "Comments: 27 pages; 5 figures",
    "descriptor": "\nComments: 27 pages; 5 figures\n",
    "authors": [
      "Marcos Oliveira",
      "Fariba Karimi",
      "Maria Zens",
      "Johann Schaible",
      "Mathieu G\u00e9nois",
      "Markus Strohmaier"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.11688"
  },
  {
    "id": "arXiv:2106.11692",
    "title": "A Reduction-Based Framework for Conservative Bandits and Reinforcement  Learning",
    "abstract": "A Reduction-Based Framework for Conservative Bandits and Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "Yunchang Yang",
      "Tianhao Wu",
      "Han Zhong",
      "Evrard Garcelon",
      "Matteo Pirotta",
      "Alessandro Lazaric",
      "Liwei Wang",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11692"
  },
  {
    "id": "arXiv:2106.12112",
    "title": "Bregman Gradient Policy Optimization",
    "abstract": "Comments: Published in ICLR 2022",
    "descriptor": "\nComments: Published in ICLR 2022\n",
    "authors": [
      "Feihu Huang",
      "Shangqian Gao",
      "Heng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.12112"
  },
  {
    "id": "arXiv:2106.14282",
    "title": "A Closer Look at How Fine-tuning Changes BERT",
    "abstract": "Comments: Camera ready for ACL 2022",
    "descriptor": "\nComments: Camera ready for ACL 2022\n",
    "authors": [
      "Yichu Zhou",
      "Vivek Srikumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.14282"
  },
  {
    "id": "arXiv:2106.15147",
    "title": "SCARF: Self-Supervised Contrastive Learning using Random Feature  Corruption",
    "abstract": "Comments: ICLR 2022 Spotlight",
    "descriptor": "\nComments: ICLR 2022 Spotlight\n",
    "authors": [
      "Dara Bahri",
      "Heinrich Jiang",
      "Yi Tay",
      "Donald Metzler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15147"
  },
  {
    "id": "arXiv:2106.15754",
    "title": "Looking Outside the Window: Wide-Context Transformer for the Semantic  Segmentation of High-Resolution Remote Sensing Images",
    "abstract": "Looking Outside the Window: Wide-Context Transformer for the Semantic  Segmentation of High-Resolution Remote Sensing Images",
    "descriptor": "",
    "authors": [
      "Lei Ding",
      "Dong Lin",
      "Shaofu Lin",
      "Jing Zhang",
      "Xiaojie Cui",
      "Yuebin Wang",
      "Hao Tang",
      "Lorenzo Bruzzone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15754"
  },
  {
    "id": "arXiv:2106.15844",
    "title": "Bounded rationality for relaxing best response and mutual consistency:  The Quantal Hierarchy model of decision-making",
    "abstract": "Comments: 33 pages, 14 figures",
    "descriptor": "\nComments: 33 pages, 14 figures\n",
    "authors": [
      "Benjamin Patrick Evans",
      "Mikhail Prokopenko"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2106.15844"
  },
  {
    "id": "arXiv:2106.15893",
    "title": "Fast whole-slide cartography in colon cancer histology using superpixels  and CNN classification",
    "abstract": "Comments: 28 pages, 17 figures, 5 tables, published in SPIE Journal of Medical Imaging",
    "descriptor": "\nComments: 28 pages, 17 figures, 5 tables, published in SPIE Journal of Medical Imaging\n",
    "authors": [
      "Frauke Wilm",
      "Michaela Benz",
      "Volker Bruns",
      "Serop Baghdadlian",
      "Jakob Dexl",
      "David Hartmann",
      "Petr Kuritcyn",
      "Martin Weidenfeller",
      "Thomas Wittenberg",
      "Susanne Merkel",
      "Arndt Hartmann",
      "Markus Eckstein",
      "Carol I. Geppert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15893"
  },
  {
    "id": "arXiv:2107.00110",
    "title": "Classical Planning in Deep Latent Space",
    "abstract": "Comments: Under review at Journal of Artificial Intelligence Research (JAIR)",
    "descriptor": "\nComments: Under review at Journal of Artificial Intelligence Research (JAIR)\n",
    "authors": [
      "Masataro Asai",
      "Hiroshi Kajino",
      "Alex Fukunaga",
      "Christian Muise"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00110"
  },
  {
    "id": "arXiv:2107.00753",
    "title": "An Investigation of the (In)effectiveness of Counterfactually Augmented  Data",
    "abstract": "Comments: ACL 2022 (v3: Toy theoretical example updated)",
    "descriptor": "\nComments: ACL 2022 (v3: Toy theoretical example updated)\n",
    "authors": [
      "Nitish Joshi",
      "He He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00753"
  },
  {
    "id": "arXiv:2107.00986",
    "title": "Blind Image Super-resolution with Elaborate Degradation Modeling on  Noise and Kernel",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Zongsheng Yue",
      "Qian Zhao",
      "Jianwen Xie",
      "Lei Zhang",
      "Deyu Meng",
      "Kwan-Yee K. Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00986"
  },
  {
    "id": "arXiv:2107.02168",
    "title": "DPPIN: A Biological Repository of Dynamic Protein-Protein Interaction  Network Data",
    "abstract": "DPPIN: A Biological Repository of Dynamic Protein-Protein Interaction  Network Data",
    "descriptor": "",
    "authors": [
      "Dongqi Fu",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02168"
  },
  {
    "id": "arXiv:2107.05253",
    "title": "Reasoning about Reconfigurations of Distributed Systems",
    "abstract": "Reasoning about Reconfigurations of Distributed Systems",
    "descriptor": "",
    "authors": [
      "Emma Ahrens",
      "Marius Bozga",
      "Radu Iosif",
      "Joost-Pieter Katoen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.05253"
  },
  {
    "id": "arXiv:2107.06626",
    "title": "Optimality of the Johnson-Lindenstrauss Dimensionality Reduction for  Practical Measures",
    "abstract": "Optimality of the Johnson-Lindenstrauss Dimensionality Reduction for  Practical Measures",
    "descriptor": "",
    "authors": [
      "Yair Bartal",
      "Ora Nova Fandina",
      "Kasper Green Larsen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06626"
  },
  {
    "id": "arXiv:2107.07905",
    "title": "Unsupervised Discovery of Object Radiance Fields",
    "abstract": "Comments: ICLR 2022. Project page: this https URL",
    "descriptor": "\nComments: ICLR 2022. Project page: this https URL\n",
    "authors": [
      "Hong-Xing Yu",
      "Leonidas J. Guibas",
      "Jiajun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07905"
  },
  {
    "id": "arXiv:2107.08929",
    "title": "MemSum: Extractive Summarization of Long Documents Using Multi-Step  Episodic Markov Decision Processes",
    "abstract": "Comments: This paper was accepted by ACL 2022",
    "descriptor": "\nComments: This paper was accepted by ACL 2022\n",
    "authors": [
      "Nianlong Gu",
      "Elliott Ash",
      "Richard H.R. Hahnloser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.08929"
  },
  {
    "id": "arXiv:2107.10339",
    "title": "Finding minimum bounded and homologous chains in simplicial complexes  with bounded-treewidth 1-skeleton",
    "abstract": "Comments: In v2, we replaced an incorrect theorem in Section 7. Versions v1 and v2 contained an algorithm for finding subcomplexes that are homeomorphic to surfaces in simplicial complexes. In version v3, this material has been moved to arXiv:2203.07566. The split into two papers reflects new lower bounds on finding surfaces and a change in authorship",
    "descriptor": "\nComments: In v2, we replaced an incorrect theorem in Section 7. Versions v1 and v2 contained an algorithm for finding subcomplexes that are homeomorphic to surfaces in simplicial complexes. In version v3, this material has been moved to arXiv:2203.07566. The split into two papers reflects new lower bounds on finding surfaces and a change in authorship\n",
    "authors": [
      "Mitchell Black",
      "Amir Nayyeri"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2107.10339"
  },
  {
    "id": "arXiv:2107.10724",
    "title": "Reproducibility of COVID-19 pre-prints",
    "abstract": "Comments: 17 pages, 15 tables, 4 figures 2021-12-08 replacement fixes a few incorrect references and adds reference to some additional papers 2021-03-16 replacement contains major revisions",
    "descriptor": "\nComments: 17 pages, 15 tables, 4 figures 2021-12-08 replacement fixes a few incorrect references and adds reference to some additional papers 2021-03-16 replacement contains major revisions\n",
    "authors": [
      "Annie Collins",
      "Rohan Alexander"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)",
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.10724"
  },
  {
    "id": "arXiv:2107.11637",
    "title": "Group-based Motion Prediction for Navigation in Crowded Environments",
    "abstract": "Comments: 5th Annual Conference on Robot Learning. 2021",
    "descriptor": "\nComments: 5th Annual Conference on Robot Learning. 2021\n",
    "authors": [
      "Allan Wang",
      "Christoforos Mavrogiannis",
      "Aaron Steinfeld"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.11637"
  },
  {
    "id": "arXiv:2107.13296",
    "title": "Predicting Patch Correctness Based on the Similarity of Failing Test  Cases",
    "abstract": "Predicting Patch Correctness Based on the Similarity of Failing Test  Cases",
    "descriptor": "",
    "authors": [
      "Haoye Tian",
      "Yinghua Li",
      "Weiguo Pian",
      "Abdoul Kader Kabor\u00e9",
      "Kui Liu",
      "Andrew Habib",
      "Jacques Klein",
      "Tegawend\u00e9 F. Bissyande"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.13296"
  },
  {
    "id": "arXiv:2107.14795",
    "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs",
    "abstract": "Comments: ICLR 2022 camera ready. Code: this https URL",
    "descriptor": "\nComments: ICLR 2022 camera ready. Code: this https URL\n",
    "authors": [
      "Andrew Jaegle",
      "Sebastian Borgeaud",
      "Jean-Baptiste Alayrac",
      "Carl Doersch",
      "Catalin Ionescu",
      "David Ding",
      "Skanda Koppula",
      "Daniel Zoran",
      "Andrew Brock",
      "Evan Shelhamer",
      "Olivier H\u00e9naff",
      "Matthew M. Botvinick",
      "Andrew Zisserman",
      "Oriol Vinyals",
      "Jo\u0101o Carreira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.14795"
  },
  {
    "id": "arXiv:2108.01224",
    "title": "Rapid Elastic Architecture Search under Specialized Classes and Resource  Constraints",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Jing Liu",
      "Bohan Zhuang",
      "Mingkui Tan",
      "Xu Liu",
      "Dinh Phung",
      "Yuanqing Li",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.01224"
  },
  {
    "id": "arXiv:2108.01513",
    "title": "SphereFace2: Binary Classification is All You Need for Deep Face  Recognition",
    "abstract": "Comments: ICLR 2022 Spotlight (15 pages, 10 figures)",
    "descriptor": "\nComments: ICLR 2022 Spotlight (15 pages, 10 figures)\n",
    "authors": [
      "Yandong Wen",
      "Weiyang Liu",
      "Adrian Weller",
      "Bhiksha Raj",
      "Rita Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.01513"
  },
  {
    "id": "arXiv:2108.02327",
    "title": "PI3NN: Out-of-distribution-aware prediction intervals from three neural  networks",
    "abstract": "PI3NN: Out-of-distribution-aware prediction intervals from three neural  networks",
    "descriptor": "",
    "authors": [
      "Siyan Liu",
      "Pei Zhang",
      "Dan Lu",
      "Guannan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.02327"
  },
  {
    "id": "arXiv:2108.04433",
    "title": "Deep Learning Enhanced Dynamic Mode Decomposition",
    "abstract": "Comments: 22 pages, 6 figures; Added detail to section 2, typos corrected, made naming consistent; Updated authors and affiliations, updated figures 2-6, updated abstract; Added new results section, updated figures, 16 figures, 1 table",
    "descriptor": "\nComments: 22 pages, 6 figures; Added detail to section 2, typos corrected, made naming consistent; Updated authors and affiliations, updated figures 2-6, updated abstract; Added new results section, updated figures, 16 figures, 1 table\n",
    "authors": [
      "Daniel J. Alford-Lago",
      "Christopher W. Curtis",
      "Alexander T. Ihler",
      "Opal Issan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.04433"
  },
  {
    "id": "arXiv:2108.06869",
    "title": "FedChain: Chained Algorithms for Near-Optimal Communication Cost in  Federated Learning",
    "abstract": "FedChain: Chained Algorithms for Near-Optimal Communication Cost in  Federated Learning",
    "descriptor": "",
    "authors": [
      "Charlie Hou",
      "Kiran K. Thekumparampil",
      "Giulia Fanti",
      "Sewoong Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.06869"
  },
  {
    "id": "arXiv:2108.06987",
    "title": "Uniformly accurate schemes for drift--oscillatory stochastic  differential equations",
    "abstract": "Uniformly accurate schemes for drift--oscillatory stochastic  differential equations",
    "descriptor": "",
    "authors": [
      "Ibrahim Almuslimani",
      "Philippe Chartier",
      "Mohammed Lemou",
      "Florian M\u00e9hats"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.06987"
  },
  {
    "id": "arXiv:2108.09509",
    "title": "Hop-by-hop Accounting and Rewards for Packet dIspAtching",
    "abstract": "Hop-by-hop Accounting and Rewards for Packet dIspAtching",
    "descriptor": "",
    "authors": [
      "Caciano Machado",
      "Renan R. S. dos Santos",
      "Carla Merkle Westphall"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.09509"
  },
  {
    "id": "arXiv:2108.13048",
    "title": "ASR-GLUE: A New Multi-task Benchmark for ASR-Robust Natural Language  Understanding",
    "abstract": "ASR-GLUE: A New Multi-task Benchmark for ASR-Robust Natural Language  Understanding",
    "descriptor": "",
    "authors": [
      "Lingyun Feng",
      "Jianwei Yu",
      "Deng Cai",
      "Songxiang Liu",
      "Haitao Zheng",
      "Yan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2108.13048"
  },
  {
    "id": "arXiv:2108.13750",
    "title": "Suboptimal nonlinear moving horizon estimation",
    "abstract": "Suboptimal nonlinear moving horizon estimation",
    "descriptor": "",
    "authors": [
      "Julian D. Schiller",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13750"
  },
  {
    "id": "arXiv:2109.00356",
    "title": "The University of California San Francisco Preoperative Diffuse Glioma  MRI (UCSF-PDGM) Dataset",
    "abstract": "Comments: 7 pages, 2 figures, 2 tables",
    "descriptor": "\nComments: 7 pages, 2 figures, 2 tables\n",
    "authors": [
      "Evan Calabrese",
      "Javier E. Villanueva-Meyer",
      "Jeffrey D. Rudie",
      "Andreas M. Rauschecker",
      "Ujjwal Baid",
      "Spyridon Bakas",
      "Soonmee Cha",
      "John T. Mongan",
      "Christopher P. Hess"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.00356"
  },
  {
    "id": "arXiv:2109.01780",
    "title": "A rate of convergence of Physics Informed Neural Networks for the linear  second order elliptic PDEs",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2103.13330",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.13330\n",
    "authors": [
      "Yuling Jiao",
      "Yanming Lai",
      "Dingwei Li",
      "Xiliang Lu",
      "Fengru Wang",
      "Yang Wang",
      "Jerry Zhijian Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.01780"
  },
  {
    "id": "arXiv:2109.02707",
    "title": "Text-to-Table: A New Way of Information Extraction",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Xueqing Wu",
      "Jiacheng Zhang",
      "Hang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.02707"
  },
  {
    "id": "arXiv:2109.03127",
    "title": "Rare Tokens Degenerate All Tokens: Improving Neural Text Generation via  Adaptive Gradient Gating for Rare Token Embeddings",
    "abstract": "Comments: ACL 2022 Main Conference",
    "descriptor": "\nComments: ACL 2022 Main Conference\n",
    "authors": [
      "Sangwon Yu",
      "Jongyoon Song",
      "Heeseung Kim",
      "Seong-min Lee",
      "Woo-Jong Ryu",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03127"
  },
  {
    "id": "arXiv:2109.04314",
    "title": "Variational Latent-State GPT for Semi-supervised Task-Oriented Dialog  Systems",
    "abstract": "Variational Latent-State GPT for Semi-supervised Task-Oriented Dialog  Systems",
    "descriptor": "",
    "authors": [
      "Hong Liu",
      "Yucheng Cai",
      "Zhenru Lin",
      "Zhijian Ou",
      "Yi Huang",
      "Junlan Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04314"
  },
  {
    "id": "arXiv:2109.04504",
    "title": "Bootstrapped Meta-Learning",
    "abstract": "Comments: Published at ICLR 2022. 37 pages, 19 figures, 9 tables",
    "descriptor": "\nComments: Published at ICLR 2022. 37 pages, 19 figures, 9 tables\n",
    "authors": [
      "Sebastian Flennerhag",
      "Yannick Schroecker",
      "Tom Zahavy",
      "Hado van Hasselt",
      "David Silver",
      "Satinder Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04504"
  },
  {
    "id": "arXiv:2109.05490",
    "title": "HyAR: Addressing Discrete-Continuous Action Reinforcement Learning via  Hybrid Action Representation",
    "abstract": "Comments: Accepted on ICLR 2022",
    "descriptor": "\nComments: Accepted on ICLR 2022\n",
    "authors": [
      "Boyan Li",
      "Hongyao Tang",
      "Yan Zheng",
      "Jianye Hao",
      "Pengyi Li",
      "Zhen Wang",
      "Zhaopeng Meng",
      "Li Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.05490"
  },
  {
    "id": "arXiv:2109.05565",
    "title": "SphereFace Revived: Unifying Hyperspherical Face Recognition",
    "abstract": "Comments: Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Weiyang Liu",
      "Yandong Wen",
      "Bhiksha Raj",
      "Rita Singh",
      "Adrian Weller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05565"
  },
  {
    "id": "arXiv:2109.07117",
    "title": "Non-Asymptotic Analysis of Stochastic Approximation Algorithms for  Streaming Data",
    "abstract": "Non-Asymptotic Analysis of Stochastic Approximation Algorithms for  Streaming Data",
    "descriptor": "",
    "authors": [
      "Antoine Godichon-Baggioni",
      "Nicklas Werge",
      "Olivier Wintenberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.07117"
  },
  {
    "id": "arXiv:2109.07830",
    "title": "Reframing Instructional Prompts to GPTk's Language",
    "abstract": "Comments: ACL 2022 Findings",
    "descriptor": "\nComments: ACL 2022 Findings\n",
    "authors": [
      "Swaroop Mishra",
      "Daniel Khashabi",
      "Chitta Baral",
      "Yejin Choi",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07830"
  },
  {
    "id": "arXiv:2109.09659",
    "title": "A QUBO Formulation for Minimum Loss Spanning Tree Reconfiguration  Problems in Electric Power Networks",
    "abstract": "Comments: 21 pages, 9 figures. v2: Added new sections on model scaling and validation. Minor editorial changes",
    "descriptor": "\nComments: 21 pages, 9 figures. v2: Added new sections on model scaling and validation. Minor editorial changes\n",
    "authors": [
      "Filipe F. C. Silva",
      "Pedro M. S. Carvalho",
      "Luis A. F. M. Ferreira",
      "Yasser Omar"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.09659"
  },
  {
    "id": "arXiv:2109.11071",
    "title": "Learning to Downsample for Segmentation of Ultra-High Resolution Images",
    "abstract": "Comments: 19 pages, 17 figures",
    "descriptor": "\nComments: 19 pages, 17 figures\n",
    "authors": [
      "Chen Jin",
      "Ryutaro Tanno",
      "Thomy Mertzanidou",
      "Eleftheria Panagiotaki",
      "Daniel C. Alexander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.11071"
  },
  {
    "id": "arXiv:2109.12249",
    "title": "A general alternating-direction implicit framework with Gaussian process  regression parameter prediction for large sparse linear systems",
    "abstract": "A general alternating-direction implicit framework with Gaussian process  regression parameter prediction for large sparse linear systems",
    "descriptor": "",
    "authors": [
      "Kai Jiang",
      "Xuehong Su",
      "Juan Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.12249"
  },
  {
    "id": "arXiv:2109.12405",
    "title": "CoMeT: An Integrated Interval Thermal Simulation Toolchain for 2D, 2.5D,  and 3D Processor-Memory Systems",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Lokesh Siddhu",
      "Rajesh Kedia",
      "Shailja Pandey",
      "Martin Rapp",
      "Anuj Pathania",
      "J\u00f6rg Henkel",
      "Preeti Ranjan Panda"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2109.12405"
  },
  {
    "id": "arXiv:2109.12720",
    "title": "On the Feasibility of Learning Finger-gaiting In-hand Manipulation with  Intrinsic Sensing",
    "abstract": "Comments: 7 pages, 9 figures, accepted at ICRA 2022",
    "descriptor": "\nComments: 7 pages, 9 figures, accepted at ICRA 2022\n",
    "authors": [
      "Gagan Khandate",
      "Maxmillian Haas-Heger",
      "Matei Ciocarlie"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.12720"
  },
  {
    "id": "arXiv:2110.02034",
    "title": "Dropout Q-Functions for Doubly Efficient Reinforcement Learning",
    "abstract": "Comments: ICLR 2022. Source code: this https URL Poster: this https URL Slides: this https URL",
    "descriptor": "\nComments: ICLR 2022. Source code: this https URL Poster: this https URL Slides: this https URL\n",
    "authors": [
      "Takuya Hiraoka",
      "Takahisa Imagawa",
      "Taisei Hashimoto",
      "Takashi Onishi",
      "Yoshimasa Tsuruoka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02034"
  },
  {
    "id": "arXiv:2110.02096",
    "title": "Top-N: Equivariant set and graph generation without exchangeability",
    "abstract": "Comments: 9 pages of main text, 17 pages total Accepted to ICLR 2022",
    "descriptor": "\nComments: 9 pages of main text, 17 pages total Accepted to ICLR 2022\n",
    "authors": [
      "Clement Vignac",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02096"
  },
  {
    "id": "arXiv:2110.02442",
    "title": "PoNet: Pooling Network for Efficient Token Mixing in Long Sequences",
    "abstract": "Comments: Accepted by ICLR 2022",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Chao-Hong Tan",
      "Qian Chen",
      "Wen Wang",
      "Qinglin Zhang",
      "Siqi Zheng",
      "Zhen-Hua Ling"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02442"
  },
  {
    "id": "arXiv:2110.02865",
    "title": "Spike-inspired Rank Coding for Fast and Accurate Recurrent Neural  Networks",
    "abstract": "Comments: Spotlight paper at ICLR 2022",
    "descriptor": "\nComments: Spotlight paper at ICLR 2022\n",
    "authors": [
      "Alan Jeffares",
      "Qinghai Guo",
      "Pontus Stenetorp",
      "Timoleon Moraitis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.02865"
  },
  {
    "id": "arXiv:2110.03336",
    "title": "Frame Averaging for Invariant and Equivariant Network Design",
    "abstract": "Frame Averaging for Invariant and Equivariant Network Design",
    "descriptor": "",
    "authors": [
      "Omri Puny",
      "Matan Atzmon",
      "Heli Ben-Hamu",
      "Ishan Misra",
      "Aditya Grover",
      "Edward J. Smith",
      "Yaron Lipman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03336"
  },
  {
    "id": "arXiv:2110.04135",
    "title": "Revisiting Design Choices in Offline Model-Based Reinforcement Learning",
    "abstract": "Comments: Spotlight @ ICLR 2022; Spotlight @ RL4RealLife Workshop ICML2021",
    "descriptor": "\nComments: Spotlight @ ICLR 2022; Spotlight @ RL4RealLife Workshop ICML2021\n",
    "authors": [
      "Cong Lu",
      "Philip J. Ball",
      "Jack Parker-Holder",
      "Michael A. Osborne",
      "Stephen J. Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04135"
  },
  {
    "id": "arXiv:2110.04334",
    "title": "Using Subobservers to Synthesize Opacity-Enforcing Supervisors",
    "abstract": "Comments: 26 pages, 7 figures, submitted to Discrete Event Dynamic Systems",
    "descriptor": "\nComments: 26 pages, 7 figures, submitted to Discrete Event Dynamic Systems\n",
    "authors": [
      "Richard Hugh Moulton",
      "Behnam Behinaein Hamgini",
      "Zahra Abedi Khouzani",
      "R\u00f4mulo Meira-G\u00f3es",
      "Fei Wang",
      "Karen Rudie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04334"
  },
  {
    "id": "arXiv:2110.04375",
    "title": "Neural Link Prediction with Walk Pooling",
    "abstract": "Neural Link Prediction with Walk Pooling",
    "descriptor": "",
    "authors": [
      "Liming Pan",
      "Cheng Shi",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.04375"
  },
  {
    "id": "arXiv:2110.05357",
    "title": "Graph-Guided Network for Irregularly Sampled Multivariate Time Series",
    "abstract": "Comments: Accepted by ICLR 2022; this https URL",
    "descriptor": "\nComments: Accepted by ICLR 2022; this https URL\n",
    "authors": [
      "Xiang Zhang",
      "Marko Zeman",
      "Theodoros Tsiligkaridis",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05357"
  },
  {
    "id": "arXiv:2110.06021",
    "title": "Embedded-model flows: Combining the inductive biases of model-free deep  learning and explicit probabilistic modeling",
    "abstract": "Embedded-model flows: Combining the inductive biases of model-free deep  learning and explicit probabilistic modeling",
    "descriptor": "",
    "authors": [
      "Gianluigi Silvestri",
      "Emily Fertig",
      "Dave Moore",
      "Luca Ambrogioni"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06021"
  },
  {
    "id": "arXiv:2110.06381",
    "title": "Meta Learning Low Rank Covariance Factors for Energy-Based Deterministic  Uncertainty",
    "abstract": "Meta Learning Low Rank Covariance Factors for Energy-Based Deterministic  Uncertainty",
    "descriptor": "",
    "authors": [
      "Jeffrey Willette",
      "Hae Beom Lee",
      "Juho Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06381"
  },
  {
    "id": "arXiv:2110.06843",
    "title": "Compositional Generalization in Dependency Parsing",
    "abstract": "Comments: 12 pages 7 figures",
    "descriptor": "\nComments: 12 pages 7 figures\n",
    "authors": [
      "Emily Goodwin",
      "Siva Reddy",
      "Timothy J. O'Donnell",
      "Dzmitry Bahdanau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06843"
  },
  {
    "id": "arXiv:2110.07152",
    "title": "DeepSSM: A Blueprint for Image-to-Shape Deep Learning Models",
    "abstract": "Comments: pre-print",
    "descriptor": "\nComments: pre-print\n",
    "authors": [
      "Riddhish Bhalodia",
      "Shireen Elhabian",
      "Jadie Adams",
      "Wenzheng Tao",
      "Ladislav Kavan",
      "Ross Whitaker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07152"
  },
  {
    "id": "arXiv:2110.07961",
    "title": "Tracing Origins: Coreference-aware Machine Reading Comprehension",
    "abstract": "Comments: Accepted by ACL 2022",
    "descriptor": "\nComments: Accepted by ACL 2022\n",
    "authors": [
      "Baorong Huang",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.07961"
  },
  {
    "id": "arXiv:2110.08193",
    "title": "BBQ: A Hand-Built Bias Benchmark for Question Answering",
    "abstract": "Comments: Accepted to ACL 2022 Findings. 20 pages, 10 figures",
    "descriptor": "\nComments: Accepted to ACL 2022 Findings. 20 pages, 10 figures\n",
    "authors": [
      "Alicia Parrish",
      "Angelica Chen",
      "Nikita Nangia",
      "Vishakh Padmakumar",
      "Jason Phang",
      "Jana Thompson",
      "Phu Mon Htut",
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08193"
  },
  {
    "id": "arXiv:2110.08294",
    "title": "Coherence boosting: When your pretrained language model is not paying  enough attention",
    "abstract": "Comments: ACL 2022; code: this https URL",
    "descriptor": "\nComments: ACL 2022; code: this https URL\n",
    "authors": [
      "Nikolay Malkin",
      "Zhen Wang",
      "Nebojsa Jojic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08294"
  },
  {
    "id": "arXiv:2110.08486",
    "title": "Understanding Procedural Knowledge by Sequencing Multimodal  Instructional Manuals",
    "abstract": "Comments: In Proceedings of the Conference of the 60th Annual Meeting of the Association for Computational Linguistics (ACL), 2022",
    "descriptor": "\nComments: In Proceedings of the Conference of the 60th Annual Meeting of the Association for Computational Linguistics (ACL), 2022\n",
    "authors": [
      "Te-Lin Wu",
      "Alex Spangher",
      "Pegah Alipoormolabashi",
      "Marjorie Freedman",
      "Ralph Weischedel",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08486"
  },
  {
    "id": "arXiv:2110.08529",
    "title": "Sharpness-Aware Minimization Improves Language Model Generalization",
    "abstract": "Comments: ACL 2022 Main Conference",
    "descriptor": "\nComments: ACL 2022 Main Conference\n",
    "authors": [
      "Dara Bahri",
      "Hossein Mobahi",
      "Yi Tay"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08529"
  },
  {
    "id": "arXiv:2110.08840",
    "title": "Online Facility Location with Predictions",
    "abstract": "Online Facility Location with Predictions",
    "descriptor": "",
    "authors": [
      "Shaofeng H.-C. Jiang",
      "Erzhi Liu",
      "You Lyu",
      "Zhihao Gavin Tang",
      "Yubo Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08840"
  },
  {
    "id": "arXiv:2110.12894",
    "title": "The Efficiency Misnomer",
    "abstract": "The Efficiency Misnomer",
    "descriptor": "",
    "authors": [
      "Mostafa Dehghani",
      "Anurag Arnab",
      "Lucas Beyer",
      "Ashish Vaswani",
      "Yi Tay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12894"
  },
  {
    "id": "arXiv:2110.14216",
    "title": "What Do We Mean by Generalization in Federated Learning?",
    "abstract": "Comments: Accepted to ICLR 2022. Code repository see this https URL",
    "descriptor": "\nComments: Accepted to ICLR 2022. Code repository see this https URL\n",
    "authors": [
      "Honglin Yuan",
      "Warren Morningstar",
      "Lin Ning",
      "Karan Singhal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14216"
  },
  {
    "id": "arXiv:2110.14334",
    "title": "Spectral splitting method for nonlinear Schr\u00f6dinger equations with  quadratic potential",
    "abstract": "Comments: 20 pages, 3 figures",
    "descriptor": "\nComments: 20 pages, 3 figures\n",
    "authors": [
      "Andrea Sacchetti"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.14334"
  },
  {
    "id": "arXiv:2110.15326",
    "title": "GOMP-FIT: Grasp-Optimized Motion Planning for Fast Inertial Transport",
    "abstract": "Comments: Accepted for ICRA 2022. 7 pages, 6 figures",
    "descriptor": "\nComments: Accepted for ICRA 2022. 7 pages, 6 figures\n",
    "authors": [
      "Jeffrey Ichnowski",
      "Yahav Avigal",
      "Yi Liu",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.15326"
  },
  {
    "id": "arXiv:2111.00537",
    "title": "A network-based approach to QAnon user dynamics and topic diversity  during the COVID-19 infodemic",
    "abstract": "Comments: accepted by APSIPA Transactions on Signal and Information Processing, 2022",
    "descriptor": "\nComments: accepted by APSIPA Transactions on Signal and Information Processing, 2022\n",
    "authors": [
      "Wentao Xu",
      "Kazutoshi Sasahara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.00537"
  },
  {
    "id": "arXiv:2111.00998",
    "title": "PDE-READ: Human-readable Partial Differential Equation Discovery using  Deep Learning",
    "abstract": "Comments: 39 pages, 18 figures",
    "descriptor": "\nComments: 39 pages, 18 figures\n",
    "authors": [
      "Robert Stephany",
      "Christopher Earls"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00998"
  },
  {
    "id": "arXiv:2111.01270",
    "title": "Deep learning of multi-resolution X-Ray micro-CT images for multi-scale  modelling",
    "abstract": "Comments: 21 pages, 9 figures",
    "descriptor": "\nComments: 21 pages, 9 figures\n",
    "authors": [
      "Samuel J. Jackson",
      "Yufu Niu",
      "Sojwal Manoorkar",
      "Peyman Mostaghimi",
      "Ryan T. Armstrong"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2111.01270"
  },
  {
    "id": "arXiv:2111.01906",
    "title": "A trained humanoid robot can perform human-like crossmodal social  attention and conflict resolution",
    "abstract": "Comments: 14 pages, 5 figures, journal article",
    "descriptor": "\nComments: 14 pages, 5 figures, journal article\n",
    "authors": [
      "Di Fu",
      "Fares Abawi",
      "Hugo Carneiro",
      "Matthias Kerzel",
      "Ziwei Chen",
      "Erik Strahl",
      "Xun Liu",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.01906"
  },
  {
    "id": "arXiv:2111.02246",
    "title": "Brain-inspired Cognition in Next Generation Racetrack Memories",
    "abstract": "Comments: Preprint, accepted for publication, ACM Transactions on Embedded Computing Systems",
    "descriptor": "\nComments: Preprint, accepted for publication, ACM Transactions on Embedded Computing Systems\n",
    "authors": [
      "Asif Ali Khan",
      "Sebastien Ollivier",
      "Stephen Longofono",
      "Gerald Hempel",
      "Jeronimo Castrillon",
      "Alex K. Jones"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.02246"
  },
  {
    "id": "arXiv:2111.03781",
    "title": "Monotonic Safety for Scalable and Data-Efficient Probabilistic Safety  Analysis",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Matthew Cleaveland",
      "Ivan Ruchkin",
      "Oleg Sokolsky",
      "Insup Lee"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.03781"
  },
  {
    "id": "arXiv:2111.09046",
    "title": "Motion Planning of Multi-Robots Object Transport with Deformable Sheet",
    "abstract": "Comments: 8 pages, 10 figures, a Submission for RAL and CASE 2022",
    "descriptor": "\nComments: 8 pages, 10 figures, a Submission for RAL and CASE 2022\n",
    "authors": [
      "Jiawei Hu",
      "Wenhang Liu",
      "Heng Zhang",
      "Jingang Yi",
      "Zhenhua Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.09046"
  },
  {
    "id": "arXiv:2111.09337",
    "title": "Temporally Consistent Online Depth Estimation in Dynamic Scenes",
    "abstract": "Temporally Consistent Online Depth Estimation in Dynamic Scenes",
    "descriptor": "",
    "authors": [
      "Zhaoshuo Li",
      "Wei Ye",
      "Dilin Wang",
      "Francis X. Creighton",
      "Russell H. Taylor",
      "Ganesh Venkatesh",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09337"
  },
  {
    "id": "arXiv:2111.11124",
    "title": "Mesa: A Memory-saving Training Framework for Transformers",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Zizheng Pan",
      "Peng Chen",
      "Haoyu He",
      "Jing Liu",
      "Jianfei Cai",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11124"
  },
  {
    "id": "arXiv:2111.11146",
    "title": "On the Existence of Universal Lottery Tickets",
    "abstract": "Comments: Accepted for publication at The Tenth International Conference on Learning Representations (ICLR 2022)",
    "descriptor": "\nComments: Accepted for publication at The Tenth International Conference on Learning Representations (ICLR 2022)\n",
    "authors": [
      "Rebekka Burkholz",
      "Nilanjana Laha",
      "Rajarshi Mukherjee",
      "Alkis Gotovos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.11146"
  },
  {
    "id": "arXiv:2111.11187",
    "title": "PointMixer: MLP-Mixer for Point Cloud Understanding",
    "abstract": "PointMixer: MLP-Mixer for Point Cloud Understanding",
    "descriptor": "",
    "authors": [
      "Jaesung Choe",
      "Chunghyun Park",
      "Francois Rameau",
      "Jaesik Park",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11187"
  },
  {
    "id": "arXiv:2111.11632",
    "title": "Lossless Compression with Probabilistic Circuits",
    "abstract": "Lossless Compression with Probabilistic Circuits",
    "descriptor": "",
    "authors": [
      "Anji Liu",
      "Stephan Mandt",
      "Guy Van den Broeck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.11632"
  },
  {
    "id": "arXiv:2111.11802",
    "title": "Pruning Self-attentions into Convolutional Layers in Single Path",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Haoyu He",
      "Jing Liu",
      "Zizheng Pan",
      "Jianfei Cai",
      "Jing Zhang",
      "Dacheng Tao",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11802"
  },
  {
    "id": "arXiv:2111.12221",
    "title": "Source-free unsupervised domain adaptation for cross-modality abdominal  multi-organ segmentation",
    "abstract": "Source-free unsupervised domain adaptation for cross-modality abdominal  multi-organ segmentation",
    "descriptor": "",
    "authors": [
      "Jin Hong",
      "Yu-Dong Zhang",
      "Weitian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12221"
  },
  {
    "id": "arXiv:2111.12273",
    "title": "Sharpness-aware Quantization for Deep Neural Networks",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Jing Liu",
      "Jianfei Cai",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12273"
  },
  {
    "id": "arXiv:2111.12855",
    "title": "Robust Equivariant Imaging: a fully unsupervised framework for learning  to image from noisy and partial measurements",
    "abstract": "Comments: CVPR 2022. Code: this https URL",
    "descriptor": "\nComments: CVPR 2022. Code: this https URL\n",
    "authors": [
      "Dongdong Chen",
      "Juli\u00e1n Tachella",
      "Mike E. Davies"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.12855"
  },
  {
    "id": "arXiv:2111.13662",
    "title": "Modular Information Flow through Ownership",
    "abstract": "Comments: Published at PLDI 2022",
    "descriptor": "\nComments: Published at PLDI 2022\n",
    "authors": [
      "Will Crichton",
      "Marco Patrignani",
      "Maneesh Agrawala",
      "Pat Hanrahan"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.13662"
  },
  {
    "id": "arXiv:2111.14522",
    "title": "Understanding over-squashing and bottlenecks on graphs via curvature",
    "abstract": "Understanding over-squashing and bottlenecks on graphs via curvature",
    "descriptor": "",
    "authors": [
      "Jake Topping",
      "Francesco Di Giovanni",
      "Benjamin Paul Chamberlain",
      "Xiaowen Dong",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14522"
  },
  {
    "id": "arXiv:2111.14837",
    "title": "p2pGNN: A Decentralized Graph Neural Network for Node Classification in  Peer-to-Peer Networks",
    "abstract": "Comments: 12 pages, 4 figures, 2 tables, accepted manuscript, IEEE Access",
    "descriptor": "\nComments: 12 pages, 4 figures, 2 tables, accepted manuscript, IEEE Access\n",
    "authors": [
      "Emmanouil Krasanakis",
      "Symeon Papadopoulos",
      "Ioannis Kompatsiaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.14837"
  },
  {
    "id": "arXiv:2112.00503",
    "title": "Zero-Shot Cross-Lingual Machine Reading Comprehension via Inter-sentence  Dependency Graph",
    "abstract": "Comments: Accepted to AAAI 2022",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Liyan Xu",
      "Xuchao Zhang",
      "Bo Zong",
      "Yanchi Liu",
      "Wei Cheng",
      "Jingchao Ni",
      "Haifeng Chen",
      "Liang Zhao",
      "Jinho D. Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00503"
  },
  {
    "id": "arXiv:2112.02213",
    "title": "Node-wise Hardware Trojan Detection Based on Graph Learning",
    "abstract": "Node-wise Hardware Trojan Detection Based on Graph Learning",
    "descriptor": "",
    "authors": [
      "Kento Hasegawa",
      "Kazuki Yamashita",
      "Seira Hidano",
      "Kazuhide Fukushima",
      "Kazuo Hashimoto",
      "Nozomu Togawa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.02213"
  },
  {
    "id": "arXiv:2112.03126",
    "title": "Label-Efficient Semantic Segmentation with Diffusion Models",
    "abstract": "Comments: ICLR'2022; v3: camera ready",
    "descriptor": "\nComments: ICLR'2022; v3: camera ready\n",
    "authors": [
      "Dmitry Baranchuk",
      "Ivan Rubachev",
      "Andrey Voynov",
      "Valentin Khrulkov",
      "Artem Babenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03126"
  },
  {
    "id": "arXiv:2112.05423",
    "title": "On the Security & Privacy in Federated Learning",
    "abstract": "On the Security & Privacy in Federated Learning",
    "descriptor": "",
    "authors": [
      "Gorka Abad",
      "Stjepan Picek",
      "V\u00edctor Julio Ram\u00edrez-Dur\u00e1n",
      "Aitor Urbieta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.05423"
  },
  {
    "id": "arXiv:2112.08766",
    "title": "CODER: An efficient framework for improving retrieval through COntextual  Document Embedding Reranking",
    "abstract": "CODER: An efficient framework for improving retrieval through COntextual  Document Embedding Reranking",
    "descriptor": "",
    "authors": [
      "George Zerveas",
      "Navid Rekabsaz",
      "Daniel Cohen",
      "Carsten Eickhoff"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08766"
  },
  {
    "id": "arXiv:2112.08772",
    "title": "Sharpness-Aware Minimization with Dynamic Reweighting",
    "abstract": "Sharpness-Aware Minimization with Dynamic Reweighting",
    "descriptor": "",
    "authors": [
      "Wenxuan Zhou",
      "Fangyu Liu",
      "Muhao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08772"
  },
  {
    "id": "arXiv:2112.09237",
    "title": "Relation Leakage in Elicited Natural Language Inference Datasets",
    "abstract": "Comments: 9 pages, 2 figures, 3 tables",
    "descriptor": "\nComments: 9 pages, 2 figures, 3 tables\n",
    "authors": [
      "Michael Saxon",
      "Xinyi Wang",
      "Wenda Xu",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.09237"
  },
  {
    "id": "arXiv:2112.11592",
    "title": "Neural Echo State Network using oscillations of gas bubbles in water",
    "abstract": "Comments: 5 pages, 3 figures",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Ivan S. Maksymov",
      "Andrey Pototsky",
      "Sergey A. Suslov"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2112.11592"
  },
  {
    "id": "arXiv:2112.11593",
    "title": "AdaptPose: Cross-Dataset Adaptation for 3D Human Pose Estimation by  Learnable Motion Generation",
    "abstract": "AdaptPose: Cross-Dataset Adaptation for 3D Human Pose Estimation by  Learnable Motion Generation",
    "descriptor": "",
    "authors": [
      "Mohsen Gholami",
      "Bastian Wandt",
      "Helge Rhodin",
      "Rabab Ward",
      "Z. Jane Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11593"
  },
  {
    "id": "arXiv:2112.15421",
    "title": "Representation Learning via Consistent Assignment of Views to Clusters",
    "abstract": "Comments: Pre-print. 37th ACM/SIGAPP Symposium on Applied Computing (SAC'22). Code at this https URL",
    "descriptor": "\nComments: Pre-print. 37th ACM/SIGAPP Symposium on Applied Computing (SAC'22). Code at this https URL\n",
    "authors": [
      "Thalles Silva",
      "Ad\u00edn Ram\u00edrez Rivera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15421"
  },
  {
    "id": "arXiv:2201.01251",
    "title": "Multi-Stage Episodic Control for Strategic Exploration in Text Games",
    "abstract": "Comments: ICLR 2022 (Spotlight) - this https URL",
    "descriptor": "\nComments: ICLR 2022 (Spotlight) - this https URL\n",
    "authors": [
      "Jens Tuyls",
      "Shunyu Yao",
      "Sham Kakade",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.01251"
  },
  {
    "id": "arXiv:2201.01849",
    "title": "Approximation Algorithms for Maximum Matchings in Geometric Intersection  Graphs",
    "abstract": "Approximation Algorithms for Maximum Matchings in Geometric Intersection  Graphs",
    "descriptor": "",
    "authors": [
      "Sariel Har-Peled",
      "Everett Yang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2201.01849"
  },
  {
    "id": "arXiv:2201.02639",
    "title": "MERLOT Reserve: Neural Script Knowledge through Vision and Language and  Sound",
    "abstract": "Comments: CVPR 2022. Project page at this https URL",
    "descriptor": "\nComments: CVPR 2022. Project page at this https URL\n",
    "authors": [
      "Rowan Zellers",
      "Jiasen Lu",
      "Ximing Lu",
      "Youngjae Yu",
      "Yanpeng Zhao",
      "Mohammadreza Salehi",
      "Aditya Kusupati",
      "Jack Hessel",
      "Ali Farhadi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.02639"
  },
  {
    "id": "arXiv:2201.06009",
    "title": "Memory-assisted prompt editing to improve GPT-3 after deployment",
    "abstract": "Memory-assisted prompt editing to improve GPT-3 after deployment",
    "descriptor": "",
    "authors": [
      "Aman Madaan",
      "Niket Tandon",
      "Peter Clark",
      "Yiming Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.06009"
  },
  {
    "id": "arXiv:2201.06578",
    "title": "Collapse by Conditioning: Training Class-conditional GANs with Limited  Data",
    "abstract": "Collapse by Conditioning: Training Class-conditional GANs with Limited  Data",
    "descriptor": "",
    "authors": [
      "Mohamad Shahbazi",
      "Martin Danelljan",
      "Danda Pani Paudel",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.06578"
  },
  {
    "id": "arXiv:2201.08812",
    "title": "DeepMix: Mobility-aware, Lightweight, and Hybrid 3D Object Detection for  Headsets",
    "abstract": "DeepMix: Mobility-aware, Lightweight, and Hybrid 3D Object Detection for  Headsets",
    "descriptor": "",
    "authors": [
      "Yongjie Guan",
      "Xueyu Hou",
      "Nan Wu",
      "Bo Han",
      "Tao Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08812"
  },
  {
    "id": "arXiv:2201.08845",
    "title": "Point-NeRF: Point-based Neural Radiance Fields",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Qiangeng Xu",
      "Zexiang Xu",
      "Julien Philip",
      "Sai Bi",
      "Zhixin Shu",
      "Kalyan Sunkavalli",
      "Ulrich Neumann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08845"
  },
  {
    "id": "arXiv:2201.09415",
    "title": "Sub-Block Rearranged Staircase Codes",
    "abstract": "Comments: Extended version, 35 pages, 8 figures, 2 tables",
    "descriptor": "\nComments: Extended version, 35 pages, 8 figures, 2 tables\n",
    "authors": [
      "Min Qiu",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.09415"
  },
  {
    "id": "arXiv:2201.10248",
    "title": "HoneyTop90: A 90-line MATLAB code for topology optimization using  honeycomb tessellation",
    "abstract": "Comments: In press",
    "descriptor": "\nComments: In press\n",
    "authors": [
      "Prabhat Kumar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.10248"
  },
  {
    "id": "arXiv:2201.10927",
    "title": "Pair-Level Supervised Contrastive Learning for Natural Language  Inference",
    "abstract": "Comments: Accepted at ICASSP 2022",
    "descriptor": "\nComments: Accepted at ICASSP 2022\n",
    "authors": [
      "Shu'ang Li",
      "Xuming Hu",
      "Li Lin",
      "Lijie Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.10927"
  },
  {
    "id": "arXiv:2201.11748",
    "title": "Reducing COVID-19 Cases and Deaths by Applying Blockchain in Vaccination  Rollout Management",
    "abstract": "Comments: Peer reviewed",
    "descriptor": "\nComments: Peer reviewed\n",
    "authors": [
      "Jorge Medina",
      "Roberto Rojas-Cessa",
      "Vatcharapan Umpaichitra"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.11748"
  },
  {
    "id": "arXiv:2201.11898",
    "title": "Indicative Image Retrieval: Turning Blackbox Learning into Grey",
    "abstract": "Indicative Image Retrieval: Turning Blackbox Learning into Grey",
    "descriptor": "",
    "authors": [
      "Xulu Zhang",
      "Zhenqun Yang",
      "Hao Tian",
      "Qing Li",
      "Xiaoyong Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.11898"
  },
  {
    "id": "arXiv:2201.12755",
    "title": "HGCN: Harmonic gated compensation network for speech enhancement",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Tianrui Wang",
      "Weibin Zhu",
      "Yingying Gao",
      "Junlan Feng",
      "Shilei Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2201.12755"
  },
  {
    "id": "arXiv:2201.12787",
    "title": "GRPE: Relative Positional Encoding for Graph Transformer",
    "abstract": "GRPE: Relative Positional Encoding for Graph Transformer",
    "descriptor": "",
    "authors": [
      "Wonpyo Park",
      "Woonggi Chang",
      "Donggeon Lee",
      "Juntae Kim",
      "Seung-won Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12787"
  },
  {
    "id": "arXiv:2202.01011",
    "title": "Auto-Transfer: Learning to Route Transferrable Representations",
    "abstract": "Comments: Camera ready ICLR 2022",
    "descriptor": "\nComments: Camera ready ICLR 2022\n",
    "authors": [
      "Keerthiram Murugesan",
      "Vijay Sadashivaiah",
      "Ronny Luss",
      "Karthikeyan Shanmugam",
      "Pin-Yu Chen",
      "Amit Dhurandhar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01011"
  },
  {
    "id": "arXiv:2202.01147",
    "title": "Improving Screening Processes via Calibrated Subset Selection",
    "abstract": "Improving Screening Processes via Calibrated Subset Selection",
    "descriptor": "",
    "authors": [
      "Lequn Wang",
      "Thorsten Joachims",
      "Manuel Gomez Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01147"
  },
  {
    "id": "arXiv:2202.01919",
    "title": "Theoretical Exploration of Solutions of Feedforward ReLU networks",
    "abstract": "Comments: v2,v3:hyperlink mode modified; v4,v5:typos corrected",
    "descriptor": "\nComments: v2,v3:hyperlink mode modified; v4,v5:typos corrected\n",
    "authors": [
      "Changcun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01919"
  },
  {
    "id": "arXiv:2202.01950",
    "title": "Reasoning on the Air: An Implicit Semantic Communication Architecture",
    "abstract": "Comments: IEEE ICC Workshop, Seoul, South Korea, May 2022",
    "descriptor": "\nComments: IEEE ICC Workshop, Seoul, South Korea, May 2022\n",
    "authors": [
      "Yong Xiao",
      "Yingyu Li",
      "Guangming Shi",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.01950"
  },
  {
    "id": "arXiv:2202.01952",
    "title": "Life-long Learning for Reasoning-based Semantic Communication",
    "abstract": "Comments: Accepted at IEEE ICC Workshop, Seoul, South Korea, May 2022",
    "descriptor": "\nComments: Accepted at IEEE ICC Workshop, Seoul, South Korea, May 2022\n",
    "authors": [
      "Jingming Liang",
      "Yong Xiao",
      "Yingyu Li",
      "Guangming Shi",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.01952"
  },
  {
    "id": "arXiv:2202.03058",
    "title": "Non-traditional intervals and their use. Which ones really make sense?",
    "abstract": "Comments: 15 pages, no figures",
    "descriptor": "\nComments: 15 pages, no figures\n",
    "authors": [
      "Sergey P. Shary"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03058"
  },
  {
    "id": "arXiv:2202.03956",
    "title": "From Generalisation Error to Transportation-cost Inequalities and Back",
    "abstract": "Comments: Submitted to ISIT 2022",
    "descriptor": "\nComments: Submitted to ISIT 2022\n",
    "authors": [
      "Amedeo Roberto Esposito",
      "Michael Gastpar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.03956"
  },
  {
    "id": "arXiv:2202.05531",
    "title": "Cyclical Curriculum Learning",
    "abstract": "Comments: Added references, corrected typos",
    "descriptor": "\nComments: Added references, corrected typos\n",
    "authors": [
      "H. Toprak Kesgin",
      "M. Fatih Amasyali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05531"
  },
  {
    "id": "arXiv:2202.06823",
    "title": "Development and Comparison of Scoring Functions in Curriculum Learning",
    "abstract": "Comments: Added references, corrected typos",
    "descriptor": "\nComments: Added references, corrected typos\n",
    "authors": [
      "H. Toprak Kesgin",
      "M. Fatih Amasyali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.06823"
  },
  {
    "id": "arXiv:2202.07145",
    "title": "GAN-generated Faces Detection: A Survey and New Perspectives (2022)",
    "abstract": "GAN-generated Faces Detection: A Survey and New Perspectives (2022)",
    "descriptor": "",
    "authors": [
      "Xin Wang",
      "Hui Guo",
      "Shu Hu",
      "Ming-Ching Chang",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07145"
  },
  {
    "id": "arXiv:2202.08904",
    "title": "SGPT: GPT Sentence Embeddings for Semantic Search",
    "abstract": "Comments: 17 pages, 3 figures, 13 tables. v2 corrects a misreported nDCG@10 number for the SGPT-BE-5.8B model. v3 updates SGPT-BE-5.8B scores based on retrained models with larger batch sizes",
    "descriptor": "\nComments: 17 pages, 3 figures, 13 tables. v2 corrects a misreported nDCG@10 number for the SGPT-BE-5.8B model. v3 updates SGPT-BE-5.8B scores based on retrained models with larger batch sizes\n",
    "authors": [
      "Niklas Muennighoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.08904"
  },
  {
    "id": "arXiv:2202.09019",
    "title": "DARL1N: Distributed multi-Agent Reinforcement Learning with One-hop  Neighbors",
    "abstract": "DARL1N: Distributed multi-Agent Reinforcement Learning with One-hop  Neighbors",
    "descriptor": "",
    "authors": [
      "Baoqian Wang",
      "Junfei Xie",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09019"
  },
  {
    "id": "arXiv:2202.09518",
    "title": "Distributed Out-of-Memory NMF of Dense and Sparse Data on CPU/GPU  Architectures with Automatic Model Selection for Exascale Data",
    "abstract": "Comments: Submitted to IEEE TKDE",
    "descriptor": "\nComments: Submitted to IEEE TKDE\n",
    "authors": [
      "Ismael Boureima",
      "Manish Bhattarai",
      "Maksim Eren",
      "Erik Skau",
      "Philip Romero",
      "Stephan Eidenbenz",
      "Boian Alexandrov"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09518"
  },
  {
    "id": "arXiv:2202.10525",
    "title": "A Probabilistic Approach to The Perfect Sum Problem",
    "abstract": "Comments: 14 pages, 6 figures",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Kristof Pusztai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.10525"
  },
  {
    "id": "arXiv:2202.11298",
    "title": "Is Global Asymptotic Stability Necessarily Uniform for Time-Delay  Systems?",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Iasson Karafyllis",
      "Pierdomenico Pepe",
      "Antoine Chaillet",
      "Yuan Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.11298"
  },
  {
    "id": "arXiv:2202.11512",
    "title": "Using Deep Reinforcement Learning with Automatic Curriculum Learning for  Mapless Navigation in Intralogistics",
    "abstract": "Using Deep Reinforcement Learning with Automatic Curriculum Learning for  Mapless Navigation in Intralogistics",
    "descriptor": "",
    "authors": [
      "Honghu Xue",
      "Benedikt Hein",
      "Mohamed Bakr",
      "Georg Schildbach",
      "Bengt Abel",
      "Elmar Rueckert"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11512"
  },
  {
    "id": "arXiv:2202.12378",
    "title": "Deep Learning to advance the Eigenspace Perturbation Method for  Turbulence Model Uncertainty Quantification",
    "abstract": "Deep Learning to advance the Eigenspace Perturbation Method for  Turbulence Model Uncertainty Quantification",
    "descriptor": "",
    "authors": [
      "Khashayar Nobarani",
      "Seyed Esmaeil Razavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.12378"
  },
  {
    "id": "arXiv:2202.13036",
    "title": "New error bounds for the extended vertical LCP",
    "abstract": "New error bounds for the extended vertical LCP",
    "descriptor": "",
    "authors": [
      "Shiliang Wu",
      "Hehui Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.13036"
  },
  {
    "id": "arXiv:2202.13093",
    "title": "Exploring the Impact of Negative Samples of Contrastive Learning: A Case  Study of Sentence Embedding",
    "abstract": "Comments: 16 pages, 13 figures, accepted to appear in the Findings of ACL 2022",
    "descriptor": "\nComments: 16 pages, 13 figures, accepted to appear in the Findings of ACL 2022\n",
    "authors": [
      "Rui Cao",
      "Yihao Wang",
      "Yuxin Liang",
      "Ling Gao",
      "Jie Zheng",
      "Jie Ren",
      "Zheng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.13093"
  },
  {
    "id": "arXiv:2202.13972",
    "title": "The impact of lexical and grammatical processing on generating code from  natural language",
    "abstract": "Comments: Article accepted to the Findings of Association for Computational Linguistics 2022",
    "descriptor": "\nComments: Article accepted to the Findings of Association for Computational Linguistics 2022\n",
    "authors": [
      "Nathana\u00ebl Beau",
      "Beno\u00eet Crabb\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.13972"
  },
  {
    "id": "arXiv:2203.00073",
    "title": "Structure Extraction in Task-Oriented Dialogues with Slot Clustering",
    "abstract": "Structure Extraction in Task-Oriented Dialogues with Slot Clustering",
    "descriptor": "",
    "authors": [
      "Liang Qiu",
      "Chien-Sheng Wu",
      "Wenhao Liu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.00073"
  },
  {
    "id": "arXiv:2203.00783",
    "title": "Synthesizing Fine-Grained Synchronization Protocols for Implicit  Monitors (Extended Version)",
    "abstract": "Comments: Change title to include \"(Extended Version)\"",
    "descriptor": "\nComments: Change title to include \"(Extended Version)\"\n",
    "authors": [
      "Kostas Ferles",
      "Benjamin Sepanski",
      "Rahul Krishnan",
      "James Bornholt",
      "Isil Dillig"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.00783"
  },
  {
    "id": "arXiv:2203.00867",
    "title": "Incremental Transformer Structure Enhanced Image Inpainting with Masking  Positional Encoding",
    "abstract": "Comments: This paper has been accepted in CVPR2022",
    "descriptor": "\nComments: This paper has been accepted in CVPR2022\n",
    "authors": [
      "Qiaole Dong",
      "Chenjie Cao",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.00867"
  },
  {
    "id": "arXiv:2203.01215",
    "title": "Mukayese: Turkish NLP Strikes Back",
    "abstract": "Comments: Accepted at Findings of ACL 2022 (Camera Ready)",
    "descriptor": "\nComments: Accepted at Findings of ACL 2022 (Camera Ready)\n",
    "authors": [
      "Ali Safaya",
      "Emirhan Kurtulu\u015f",
      "Arda G\u00f6kto\u011fan",
      "Deniz Yuret"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.01215"
  },
  {
    "id": "arXiv:2203.01723",
    "title": "Debiased Batch Normalization via Gaussian Process for Generalizable  Person Re-Identification",
    "abstract": "Comments: 9 pages, 2 figures, AAAI 2022",
    "descriptor": "\nComments: 9 pages, 2 figures, AAAI 2022\n",
    "authors": [
      "Jiawei Liu",
      "Zhipeng Huang",
      "Liang Li",
      "Kecheng Zheng",
      "Zheng-Jun Zha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01723"
  },
  {
    "id": "arXiv:2203.01735",
    "title": "Modality-Adaptive Mixup and Invariant Decomposition for RGB-Infrared  Person Re-Identification",
    "abstract": "Comments: 9 pages, 2 figures, AAAI 2022",
    "descriptor": "\nComments: 9 pages, 2 figures, AAAI 2022\n",
    "authors": [
      "Zhipeng Huang",
      "Jiawei Liu",
      "Liang Li",
      "Kecheng Zheng",
      "Zheng-Jun Zha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01735"
  },
  {
    "id": "arXiv:2203.01914",
    "title": "Playable Environments: Video Manipulation in Space and Time",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Willi Menapace",
      "St\u00e9phane Lathuili\u00e8re",
      "Aliaksandr Siarohin",
      "Christian Theobalt",
      "Sergey Tulyakov",
      "Vladislav Golyanik",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.01914"
  },
  {
    "id": "arXiv:2203.02113",
    "title": "FS-COCO: Towards Understanding of Freehand Sketches of Common Objects in  Context",
    "abstract": "Comments: Project Page: this http URL",
    "descriptor": "\nComments: Project Page: this http URL\n",
    "authors": [
      "Pinaki Nath Chowdhury",
      "Aneeshan Sain",
      "Yulia Gryaditskaya",
      "Ayan Kumar Bhunia",
      "Tao Xiang",
      "Yi-Zhe Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02113"
  },
  {
    "id": "arXiv:2203.02295",
    "title": "Evaluating Local Model-Agnostic Explanations of Learning to Rank Models  with Decision Paths",
    "abstract": "Comments: 16 pages, 6 Figures, 3 Tables, Submitted to ECML PKDD 2022",
    "descriptor": "\nComments: 16 pages, 6 Figures, 3 Tables, Submitted to ECML PKDD 2022\n",
    "authors": [
      "Amir Hossein Akhavan Rahnama",
      "Judith Butepage"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.02295"
  },
  {
    "id": "arXiv:2203.03004",
    "title": "Low-Complexity Beamforming Design for IRS-Aided NOMA Communication  System with Imperfect CSI",
    "abstract": "Low-Complexity Beamforming Design for IRS-Aided NOMA Communication  System with Imperfect CSI",
    "descriptor": "",
    "authors": [
      "Yasaman Omid",
      "S. M. Mahdi Shahabi",
      "Cunhua Pan",
      "Yansha Deng",
      "Arumugam Nallanathan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.03004"
  },
  {
    "id": "arXiv:2203.03192",
    "title": "Dynamic Pricing for Client Recruitment in Federated Learning",
    "abstract": "Comments: 12 pages, 6 figures, 1 table",
    "descriptor": "\nComments: 12 pages, 6 figures, 1 table\n",
    "authors": [
      "Xuehe Wang",
      "Shensheng Zheng",
      "Lingjie Duan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.03192"
  },
  {
    "id": "arXiv:2203.03376",
    "title": "Spatio-temporal Gait Feature with Adaptive Distance Alignment",
    "abstract": "Spatio-temporal Gait Feature with Adaptive Distance Alignment",
    "descriptor": "",
    "authors": [
      "Yifan Chen",
      "Yang Zhao",
      "Xuelong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03376"
  },
  {
    "id": "arXiv:2203.03802",
    "title": "Understanding Iterative Revision from Human-Written Text",
    "abstract": "Comments: To appear in ACL2022",
    "descriptor": "\nComments: To appear in ACL2022\n",
    "authors": [
      "Wanyu Du",
      "Vipul Raheja",
      "Dhruv Kumar",
      "Zae Myung Kim",
      "Melissa Lopez",
      "Dongyeop Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.03802"
  },
  {
    "id": "arXiv:2203.03831",
    "title": "Deep Rectangling for Image Stitching: A Learning Baseline",
    "abstract": "Comments: Accepted by CVPR2022; Codes and dataset: this https URL",
    "descriptor": "\nComments: Accepted by CVPR2022; Codes and dataset: this https URL\n",
    "authors": [
      "Lang Nie",
      "Chunyu Lin",
      "Kang Liao",
      "Shuaicheng Liu",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03831"
  },
  {
    "id": "arXiv:2203.04531",
    "title": "Computing Continuous Dynamic Time Warping of Time Series in Polynomial  Time",
    "abstract": "Comments: To appear in SoCG 2022",
    "descriptor": "\nComments: To appear in SoCG 2022\n",
    "authors": [
      "Kevin Buchin",
      "Andr\u00e9 Nusser",
      "Sampson Wong"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2203.04531"
  },
  {
    "id": "arXiv:2203.04814",
    "title": "Text-DIAE: Degradation Invariant Autoencoders for Text Recognition and  Document Enhancement",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Mohamed Ali Souibgui",
      "Sanket Biswas",
      "Andres Mafla",
      "Ali Furkan Biten",
      "Alicia Forn\u00e9s",
      "Yousri Kessentini",
      "Josep Llad\u00f3s",
      "Lluis Gomez",
      "Dimosthenis Karatzas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04814"
  },
  {
    "id": "arXiv:2203.05556",
    "title": "On Embeddings for Numerical Features in Tabular Deep Learning",
    "abstract": "Comments: Code: this https URL (v2: minor fixes)",
    "descriptor": "\nComments: Code: this https URL (v2: minor fixes)\n",
    "authors": [
      "Yury Gorishniy",
      "Ivan Rubachev",
      "Artem Babenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05556"
  },
  {
    "id": "arXiv:2203.06359",
    "title": "Self-Sustaining Representation Expansion for Non-Exemplar  Class-Incremental Learning",
    "abstract": "Comments: Camera_Ready Version for CVPR 2022",
    "descriptor": "\nComments: Camera_Ready Version for CVPR 2022\n",
    "authors": [
      "Kai Zhu",
      "Wei Zhai",
      "Yang Cao",
      "Jiebo Luo",
      "Zheng-Jun Zha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06359"
  },
  {
    "id": "arXiv:2203.06498",
    "title": "The worst of both worlds: A comparative analysis of errors in learning  from data in psychology and machine learning",
    "abstract": "The worst of both worlds: A comparative analysis of errors in learning  from data in psychology and machine learning",
    "descriptor": "",
    "authors": [
      "Jessica Hullman",
      "Sayash Kapoor",
      "Priyanka Nanayakkara",
      "Andrew Gelman",
      "Arvind Narayanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06498"
  },
  {
    "id": "arXiv:2203.06517",
    "title": "SA-SASV: An End-to-End Spoof-Aggregated Spoofing-Aware Speaker  Verification System",
    "abstract": "Comments: Update results from CM protocol to ASV protocol",
    "descriptor": "\nComments: Update results from CM protocol to ASV protocol\n",
    "authors": [
      "Zhongwei Teng",
      "Quchen Fu",
      "Jules White",
      "Maria E. Powell",
      "Douglas C. Schmidt"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.06517"
  },
  {
    "id": "arXiv:2203.06691",
    "title": "Privacy-friendly Synthetic Data for the Development of Face Morphing  Attack Detectors",
    "abstract": "Privacy-friendly Synthetic Data for the Development of Face Morphing  Attack Detectors",
    "descriptor": "",
    "authors": [
      "Naser Damer",
      "C\u00e9sar Augusto Fontanillo L\u00f3pez",
      "Meiling Fang",
      "No\u00e9mie Spiller",
      "Minh Vu Pham",
      "Fadi Boutros"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06691"
  },
  {
    "id": "arXiv:2203.06989",
    "title": "Identifying the root cause of cable network problems with machine  learning",
    "abstract": "Identifying the root cause of cable network problems with machine  learning",
    "descriptor": "",
    "authors": [
      "Georg Heiler",
      "Thassilo Gadermaier",
      "Thomas Haider",
      "Allan Hanbury",
      "Peter Filzmoser"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06989"
  },
  {
    "id": "arXiv:2203.07098",
    "title": "A Two-Block RNN-based Trajectory Prediction from Incomplete Trajectory",
    "abstract": "Comments: Accepted by IEEE Access",
    "descriptor": "\nComments: Accepted by IEEE Access\n",
    "authors": [
      "Ryo Fujii",
      "Jayakorn Vongkulbhisal",
      "Ryo Hachiuma",
      "Hideo Saito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07098"
  },
  {
    "id": "arXiv:2203.07179",
    "title": "MDNet: Learning Monaural Speech Enhancement from Deep Prior Gradient",
    "abstract": "Comments: Submitted to Interspeech2022",
    "descriptor": "\nComments: Submitted to Interspeech2022\n",
    "authors": [
      "Andong Li",
      "Chengshi Zheng",
      "Ziyang Zhang",
      "Xiaodong Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.07179"
  },
  {
    "id": "arXiv:2203.07195",
    "title": "TaylorBeamformer: Learning All-Neural Beamformer for Multi-Channel  Speech Enhancement from Taylor's Approximation Theory",
    "abstract": "Comments: Submitted to Interspeech2022",
    "descriptor": "\nComments: Submitted to Interspeech2022\n",
    "authors": [
      "Andong Li",
      "Guochen Yu",
      "Chengshi Zheng",
      "Xiaodong Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.07195"
  },
  {
    "id": "arXiv:2203.07378",
    "title": "Dawn of the transformer era in speech emotion recognition: closing the  valence gap",
    "abstract": "Dawn of the transformer era in speech emotion recognition: closing the  valence gap",
    "descriptor": "",
    "authors": [
      "Johannes Wagner",
      "Andreas Triantafyllopoulos",
      "Hagen Wierstorf",
      "Maximilian Schmitt",
      "Felix Burkhardt",
      "Florian Eyben",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.07378"
  },
  {
    "id": "arXiv:2203.07433",
    "title": "Characterizing Reddit Participation of Users Who Engage in the QAnon  Conspiracy Theories",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Kristen Engel",
      "Yiqing Hua",
      "Taixiang Zeng",
      "Mor Naaman"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.07433"
  },
  {
    "id": "arXiv:2203.07512",
    "title": "Don't fear the unlabelled: safe deep semi-supervised learning via simple  debiasing",
    "abstract": "Don't fear the unlabelled: safe deep semi-supervised learning via simple  debiasing",
    "descriptor": "",
    "authors": [
      "Hugo Schmutz",
      "Olivier Humbert",
      "Pierre-Alexandre Mattei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.07512"
  },
  {
    "id": "arXiv:2203.07523",
    "title": "Sense Embeddings are also Biased--Evaluating Social Biases in Static and  Contextualised Sense Embeddings",
    "abstract": "Comments: Accepted to ACL 2022",
    "descriptor": "\nComments: Accepted to ACL 2022\n",
    "authors": [
      "Yi Zhou",
      "Masahiro Kaneko",
      "Danushka Bollegala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07523"
  },
  {
    "id": "arXiv:2203.07637",
    "title": "Lifelong Matrix Completion with Sparsity-Number",
    "abstract": "Lifelong Matrix Completion with Sparsity-Number",
    "descriptor": "",
    "authors": [
      "Ilqar Ramazanli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07637"
  },
  {
    "id": "arXiv:2203.07657",
    "title": "Seamlessly Integrating Factual Information and Social Content with  Persuasive Dialogue",
    "abstract": "Comments: 12 pages, 2 figures",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Maximillian Chen",
      "Weiyan Shi",
      "Feifan Yan",
      "Ryan Hou",
      "Jingwen Zhang",
      "Saurav Sahay",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.07657"
  },
  {
    "id": "arXiv:2203.07682",
    "title": "Rich CNN-Transformer Feature Aggregation Networks for Super-Resolution",
    "abstract": "Comments: 19 pages, 11 figures, preprint",
    "descriptor": "\nComments: 19 pages, 11 figures, preprint\n",
    "authors": [
      "Jinsu Yoo",
      "Taehoon Kim",
      "Sihaeng Lee",
      "Seung Hwan Kim",
      "Honglak Lee",
      "Tae Hyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07682"
  },
  {
    "id": "arXiv:2203.07694",
    "title": "Implicit field supervision for robust non-rigid shape matching",
    "abstract": "Implicit field supervision for robust non-rigid shape matching",
    "descriptor": "",
    "authors": [
      "Ramana Sundararaman",
      "Gautam Pai",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07694"
  },
  {
    "id": "arXiv:2203.07697",
    "title": "Distribution-Aware Single-Stage Models for Multi-Person 3D Pose  Estimation",
    "abstract": "Comments: To appear in CVPR 2022. Code will be released",
    "descriptor": "\nComments: To appear in CVPR 2022. Code will be released\n",
    "authors": [
      "Zitian Wang",
      "Xuecheng Nie",
      "Xiaochao Qu",
      "Yunpeng Chen",
      "Si Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07697"
  },
  {
    "id": "arXiv:2203.07735",
    "title": "Augmenting Document Representations for Dense Retrieval with  Interpolation and Perturbation",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Soyeong Jeong",
      "Jinheon Baek",
      "Sukmin Cho",
      "Sung Ju Hwang",
      "Jong C. Park"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07735"
  },
  {
    "id": "arXiv:2203.07898",
    "title": "Dynamic Time Warping Under Translation: Approximation Guided by  Space-Filling Curves",
    "abstract": "Comments: Full version of SoCG '22 paper",
    "descriptor": "\nComments: Full version of SoCG '22 paper\n",
    "authors": [
      "Karl Bringmann",
      "S\u00e1ndor Kisfaludi-Bak",
      "Marvin K\u00fcnnemann",
      "D\u00e1niel Marx",
      "Andr\u00e9 Nusser"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.07898"
  },
  {
    "id": "arXiv:2203.07980",
    "title": "Object Detection as Probabilistic Set Prediction",
    "abstract": "Object Detection as Probabilistic Set Prediction",
    "descriptor": "",
    "authors": [
      "Georg Hess",
      "Christoffer Petersson",
      "Lennart Svensson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07980"
  },
  {
    "id": "arXiv:2203.08049",
    "title": "On Hyperbolic Embeddings in 2D Object Detection",
    "abstract": "Comments: I need to put the publication on hold until I receive the approval of a supervisor",
    "descriptor": "\nComments: I need to put the publication on hold until I receive the approval of a supervisor\n",
    "authors": [
      "Christopher Lang",
      "Alexander Braun",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08049"
  },
  {
    "id": "arXiv:2203.08115",
    "title": "Analysis of the competition among viral strains using a temporal  interaction-driven contagion model",
    "abstract": "Analysis of the competition among viral strains using a temporal  interaction-driven contagion model",
    "descriptor": "",
    "authors": [
      "Alex Abbey",
      "Yuval Shahar",
      "Osnat Mokryn"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.08115"
  },
  {
    "id": "arXiv:2203.08138",
    "title": "CryoAI: Amortized Inference of Poses for Ab Initio Reconstruction of 3D  Molecular Volumes from Real Cryo-EM Images",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Axel Levy",
      "Fr\u00e9d\u00e9ric Poitevin",
      "Julien Martel",
      "Youssef Nashed",
      "Ariana Peck",
      "Nina Miolane",
      "Daniel Ratner",
      "Mike Dunne",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2203.08138"
  }
]
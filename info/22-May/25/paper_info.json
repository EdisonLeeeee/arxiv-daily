[
  {
    "id": "arXiv:2205.11511",
    "title": "Exploring Concept Contribution Spatially: Hidden Layer Interpretation  with Spatial Activation Concept Vector",
    "abstract": "To interpret deep learning models, one mainstream is to explore the learned\nconcepts by networks. Testing with Concept Activation Vector (TCAV) presents a\npowerful tool to quantify the contribution of query concepts (represented by\nuser-defined guidance images) to a target class. For example, we can\nquantitatively evaluate whether and to what extent concept striped contributes\nto model prediction zebra with TCAV. Therefore, TCAV whitens the reasoning\nprocess of deep networks. And it has been applied to solve practical problems\nsuch as diagnosis. However, for some images where the target object only\noccupies a small fraction of the region, TCAV evaluation may be interfered with\nby redundant background features because TCAV calculates concept contribution\nto a target class based on a whole hidden layer. To tackle this problem, based\non TCAV, we propose Spatial Activation Concept Vector (SACV) which identifies\nthe relevant spatial locations to the query concept while evaluating their\ncontributions to the model prediction of the target class. Experiment shows\nthat SACV generates a more fine-grained explanation map for a hidden layer and\nquantifies concepts' contributions spatially. Moreover, it avoids interference\nfrom background features. The code is available on\nhttps://github.com/AntonotnaWang/Spatial-Activation-Concept-Vector.",
    "descriptor": "\nComments: Accepted by CVPR 2022 Workshop XAI4CV\n",
    "authors": [
      "Andong Wang",
      "Wei-Ning Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11511"
  },
  {
    "id": "arXiv:2205.11513",
    "title": "Data-Driven Learning of Safety-Critical Control with Stochastic Control  Barrier Functions",
    "abstract": "Control barrier functions are widely used to synthesize safety-critical\ncontrols. The existence of Gaussian-type noise may lead to unsafe actions and\nresult in severe consequences. While studies are widely done in safety-critical\ncontrol for stochastic systems, in many real-world applications, we do not have\nthe knowledge of the stochastic component of the dynamics. In this paper, we\nstudy safety-critical control of stochastic systems with an unknown diffusion\npart and propose a data-driven method to handle these scenarios. More\nspecifically, we propose a data-driven stochastic control barrier function\n(DDSCBF) framework and use supervised learning to learn the unknown stochastic\ndynamics via the DDSCBF scheme. Under some reasonable assumptions, we provide\nguarantees that the DDSCBF scheme can approximate the It\\^{o} derivative of the\nstochastic control barrier function (SCBF) under partially unknown dynamics\nusing the universal approximation theorem. We also show that we can achieve the\nsame safety guarantee using the DDSCBF scheme as with SCBF in previous work\nwithout requiring the knowledge of stochastic dynamics. We use two non-linear\nstochastic systems to validate our theory in simulations.",
    "descriptor": "",
    "authors": [
      "Chuanzheng Wang",
      "Yiming Meng",
      "Stephen L. Smith",
      "Jun Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.11513"
  },
  {
    "id": "arXiv:2205.11514",
    "title": "A Non-Habituating Configurable Audio Visual Animal Deterrent System to  Mitigate Roadkill",
    "abstract": "Growth economies continue to be more reliant on roadways than ever before.\nOver 30,000 miles of road are added yearly to the already enormous road system\nthat exists in the United States. As roads segment habitats, animals have no\noption but to walk across them for food, water and companionship. In this\nprocess they end up becoming roadkill. Wherever wildlife habitat and roadways\noverlap, death and destruction seem impossible to control. These animal deaths\nhave a direct impact on the biodiversity and dynamics of an ecosystem and\nroadkill poses a threat to many species that are fighting extinction. Vehicles\ncolliding with animals results in human fatalities, life changing injuries and\nextensive property damage. Current methods of handling roadkill are primarily\npassive and do not utilize the animal's natural instincts. This paper presents\nan alternative approach by actively involving the animal, warning them of an\noncoming vehicle and triggering their survival instincts. Making the animal an\nintegral part of the solution, augmenting their sensory perception with science\nand technology and utilizing their heightened reflexes and survival instincts\nprovides a better chance at mitigating the problem of roadkill. The results\nshow that this solution is able to provide animals a warning of an oncoming\nvehicle, consistently, reliably and in a wide range of testing conditions.",
    "descriptor": "\nComments: 5 pages, 2 figures, 1 table\n",
    "authors": [
      "Vedant Malolan Srinivas"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2205.11514"
  },
  {
    "id": "arXiv:2205.11518",
    "title": "Privacy-preserving Data Filtering in Federated Learning Using Influence  Approximation",
    "abstract": "Federated Learning by nature is susceptible to low-quality, corrupted, or\neven malicious data that can severely degrade the quality of the learned model.\nTraditional techniques for data valuation cannot be applied as the data is\nnever revealed. We present a novel technique for filtering, and scoring data\nbased on a practical influence approximation that can be implemented in a\nprivacy-preserving manner. Each agent uses his own data to evaluate the\ninfluence of another agent's batch, and reports to the center an obfuscated\nscore using differential privacy. Our technique allows for almost perfect\n($>92\\%$ recall) filtering of corrupted data in a variety of applications using\nreal-data. Importantly, the accuracy does not degrade significantly, even under\nreally strong privacy guarantees ($\\varepsilon \\leq 1$), especially under\nrealistic percentages of mislabeled data (for $15\\%$ mislabeled data we only\nlose $10\\%$ in accuracy).",
    "descriptor": "",
    "authors": [
      "Ljubomir Rokvic",
      "Panayiotis Danassis",
      "Boi Faltings"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11518"
  },
  {
    "id": "arXiv:2205.11519",
    "title": "FedSA: Accelerating Intrusion Detection in Collaborative Environments  with Federated Simulated Annealing",
    "abstract": "Fast identification of new network attack patterns is crucial for improving\nnetwork security. Nevertheless, identifying an ongoing attack in a\nheterogeneous network is a non-trivial task. Federated learning emerges as a\nsolution to collaborative training for an Intrusion Detection System (IDS). The\nfederated learning-based IDS trains a global model using local machine learning\nmodels provided by federated participants without sharing local data. However,\noptimization challenges are intrinsic to federated learning. This paper\nproposes the Federated Simulated Annealing (FedSA) metaheuristic to select the\nhyperparameters and a subset of participants for each aggregation round in\nfederated learning. FedSA optimizes hyperparameters linked to the global model\nconvergence. The proposal reduces aggregation rounds and speeds up convergence.\nThus, FedSA accelerates learning extraction from local models, requiring fewer\nIDS updates. The proposal assessment shows that the FedSA global model\nconverges in less than ten communication rounds. The proposal requires up to\n50% fewer aggregation rounds to achieve approximately 97% accuracy in attack\ndetection than the conventional aggregation approach.",
    "descriptor": "",
    "authors": [
      "Helio N. Cunha Neto",
      "Ivana Dusparic",
      "Diogo M. F. Mattos",
      "Natalia C. Fernandes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11519"
  },
  {
    "id": "arXiv:2205.11551",
    "title": "Learning to Ignore Adversarial Attacks",
    "abstract": "Despite the strong performance of current NLP models, they can be brittle\nagainst adversarial attacks. To enable effective learning against adversarial\ninputs, we introduce the use of rationale models that can explicitly learn to\nignore attack tokens. We find that the rationale models can successfully ignore\nover 90\\% of attack tokens. This approach leads to consistent sizable\nimprovements ($\\sim$10\\%) over baseline models in robustness on three datasets\nfor both BERT and RoBERTa, and also reliably outperforms data augmentation with\nadversarial examples alone. In many cases, we find that our method is able to\nclose the gap between model performance on a clean test set and an attacked\ntest set and hence reduce the effect of adversarial attacks.",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Yiming Zhang",
      "Yangqiaoyu Zhou",
      "Samuel Carton",
      "Chenhao Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11551"
  },
  {
    "id": "arXiv:2205.11558",
    "title": "Using Natural Language and Program Abstractions to Instill Human  Inductive Biases in Machines",
    "abstract": "Strong inductive biases are a key component of human intelligence, allowing\npeople to quickly learn a variety of tasks. Although meta-learning has emerged\nas an approach for endowing neural networks with useful inductive biases,\nagents trained by meta-learning may acquire very different strategies from\nhumans. We show that co-training these agents on predicting representations\nfrom natural language task descriptions and from programs induced to generate\nsuch tasks guides them toward human-like inductive biases. Human-generated\nlanguage descriptions and program induction with library learning both result\nin more human-like behavior in downstream meta-reinforcement learning agents\nthan less abstract controls (synthetic language descriptions, program induction\nwithout library learning), suggesting that the abstraction supported by these\nrepresentations is key.",
    "descriptor": "",
    "authors": [
      "Sreejan Kumar",
      "Carlos G. Correa",
      "Ishita Dasgupta",
      "Raja Marjieh",
      "Michael Y. Hu",
      "Robert D. Hawkins",
      "Nathaniel D. Daw",
      "Jonathan D. Cohen",
      "Karthik Narasimhan",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11558"
  },
  {
    "id": "arXiv:2205.11563",
    "title": "Accelerating the creation of instance segmentation training sets through  bounding box annotation",
    "abstract": "Collecting image annotations remains a significant burden when deploying CNN\nin a specific applicative context. This is especially the case when the\nannotation consists in binary masks covering object instances. Our work\nproposes to delineate instances in three steps, based on a semi-automatic\napproach: (1) the extreme points of an object (left-most, right-most, top,\nbottom pixels) are manually defined, thereby providing the object bounding-box,\n(2) a universal automatic segmentation tool like Deep Extreme Cut is used to\nturn the bounded object into a segmentation mask that matches the extreme\npoints; and (3) the predicted mask is manually corrected. Various strategies\nare then investigated to balance the human manual annotation resources between\nbounding-box definition and mask correction, including when the correction of\ninstance masks is prioritized based on their overlap with other instance\nbounding-boxes, or the outcome of an instance segmentation model trained on a\npartially annotated dataset. Our experimental study considers a teamsport\nplayer segmentation task, and measures how the accuracy of the Panoptic-Deeplab\ninstance segmentation model depends on the human annotation resources\nallocation strategy. It reveals that the sole definition of extreme points\nresults in a model accuracy that would require up to 10 times more resources if\nthe masks were defined through fully manual delineation of instances. When\ntargeting higher accuracies, prioritizing the mask correction among the\ntraining set instances is also shown to save up to 80\\% of correction\nannotation resources compared to a systematic frame by frame correction of\ninstances, for a same trained instance segmentation model accuracy.",
    "descriptor": "",
    "authors": [
      "Niels Sayez",
      "Christophe De Vleeschouwer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11563"
  },
  {
    "id": "arXiv:2205.11566",
    "title": "A network compression approach for quantifying the importance of  temporal contact chronology",
    "abstract": "Studies of dynamics on temporal networks often look at the overall impact of\ntemporal structural changes, falling back on static networks when the changes\nare slow, or on average annealed networks when the changes are fast. In between\nthese limits, we propose a method to quantify the importance of chronology in\ntemporal network data by using an epidemic spreading approach and looking at\nthe commutative property of consecutive snapshots. We use this method to reduce\nthe number of snapshots in real sequences of contact data by algorithmically\ncompressing consecutive snapshots. We find that the framework succeeds in\nmimicking the fully temporal dynamics, and can also be used to assess the\nsensitivity of the data to temporal variations.",
    "descriptor": "",
    "authors": [
      "Andrea J. Allen",
      "Cristopher Moore",
      "Laurent H\u00e9bert-Dufresne"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.11566"
  },
  {
    "id": "arXiv:2205.11567",
    "title": "VPAIR -- Aerial Visual Place Recognition and Localization in Large-scale  Outdoor Environments",
    "abstract": "Visual Place Recognition and Visual Localization are essential components in\nnavigation and mapping for autonomous vehicles especially in GNSS-denied\nnavigation scenarios. Recent work has focused on ground or close to ground\napplications such as self-driving cars or indoor-scenarios and low-altitude\ndrone flights. However, applications such as Urban Air Mobility require\noperations in large-scale outdoor environments at medium to high altitudes. We\npresent a new dataset named VPAIR. The dataset was recorded on board a light\naircraft flying at an altitude of more than 300 meters above ground capturing\nimages with a downwardfacing camera. Each image is paired with a high\nresolution reference render including dense depth information and 6-DoF\nreference poses. The dataset covers a more than one hundred kilometers long\ntrajectory over various types of challenging landscapes, e.g. urban, farmland\nand forests. Experiments on this dataset illustrate the challenges introduced\nby the change in perspective to a bird's eye view such as in-plane rotations.",
    "descriptor": "\nComments: ICRA 2022 AERIAL ROBOTICS WORKSHOP\n",
    "authors": [
      "Michael Schleiss",
      "Fahmi Rouatbi",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11567"
  },
  {
    "id": "arXiv:2205.11574",
    "title": "Windowed Green function method for wave scattering by periodic arrays of  2D obstacles",
    "abstract": "This paper introduces a novel boundary integral equation (BIE) method for the\nnumerical solution of problems of planewave scattering by periodic line arrays\nof two-dimensional penetrable obstacles. Our approach is built upon a direct\nBIE formulation that leverages the simplicity of the free-space Green function\nbut in turn entails evaluation of integrals over the unit-cell boundaries. Such\nintegrals are here treated via the window Green function method. The windowing\napproximation together with a finite-rank operator correction -- used to\nproperly impose the Rayleigh radiation condition -- yield a robust second-kind\nBIE that produces super-algebraically convergent solutions throughout the\nspectrum, including at the challenging Rayleigh-Wood anomalies. The corrected\nwindowed BIE can be discretized by means of off-the-shelf Nystr\\\"om and\nboundary element methods, and it leads to linear systems suitable for iterative\nlinear-algebra solvers as well as standard fast matrix-vector product\nalgorithms. A variety of numerical examples demonstrate the accuracy and\nrobustness of the proposed methodology",
    "descriptor": "",
    "authors": [
      "Thomas Strauszer-Caussade",
      "Luiz M. Faria",
      "Agust\u00edn Fernandez-Lado",
      "Carlos P\u00e9rez-Arancibia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2205.11574"
  },
  {
    "id": "arXiv:2205.11580",
    "title": "On Computing Coercivity Constants in Linear Variational Problems Through  Eigenvalue Analysis",
    "abstract": "In this work, we investigate the convergence of numerical approximations to\ncoercivity constants of variational problems. These constants are essential\ncomponents of rigorous error bounds for reduced-order modeling; extension of\nthese bounds to the error with respect to exact solutions requires an\nunderstanding of convergence rates for discrete coercivity constants. The\nresults are obtained by characterizing the coercivity constant as a spectral\nvalue of a self-adjoint linear operator; for several differential equations, we\nshow that the coercivity constant is related to the eigenvalue of a compact\noperator. For these applications, convergence rates are derived and verified\nwith numerical examples.",
    "descriptor": "\nComments: 29 pages, 3 figures\n",
    "authors": [
      "Peter Sentz",
      "Jehanzeb Hameed Chaudhry",
      "Luke N. Olson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.11580"
  },
  {
    "id": "arXiv:2205.11582",
    "title": "Scalable Infrastructure for Workload Characterization of Cluster Traces",
    "abstract": "In the recent past, characterizing workloads has been attempted to gain a\nfoothold in the emerging serverless cloud market, especially in the large\nproduction cloud clusters of Google, AWS, and so forth. While analyzing and\ncharacterizing real workloads from a large production cloud cluster benefits\ncloud providers, researchers, and daily users, analyzing the workload traces of\nthese clusters has been an arduous task due to the heterogeneous nature of\ndata. This article proposes a scalable infrastructure based on Google's\ndataproc for analyzing the workload traces of cloud environments. We evaluated\nthe functioning of the proposed infrastructure using the workload traces of\nGoogle cloud cluster-usage-traces-v3. We perform the workload characterization\non this dataset, focusing on the heterogeneity of the workload, the variations\nin job durations, aspects of resources consumption, and the overall\navailability of resources provided by the cluster. The findings reported in the\npaper will be beneficial for cloud infrastructure providers and users while\nmanaging the cloud computing resources, especially serverless platforms.",
    "descriptor": "\nComments: 9 pages, CLOSER 2022\n",
    "authors": [
      "Thomas van Loo",
      "Anshul Jindal",
      "Shajulin Benedict",
      "Mohak Chadha",
      "Michael Gerndt"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.11582"
  },
  {
    "id": "arXiv:2205.11584",
    "title": "PrivFairFL: Privacy-Preserving Group Fairness in Federated Learning",
    "abstract": "Group fairness ensures that the outcome of machine learning (ML) based\ndecision making systems are not biased towards a certain group of people\ndefined by a sensitive attribute such as gender or ethnicity. Achieving group\nfairness in Federated Learning (FL) is challenging because mitigating bias\ninherently requires using the sensitive attribute values of all clients, while\nFL is aimed precisely at protecting privacy by not giving access to the\nclients' data. As we show in this paper, this conflict between fairness and\nprivacy in FL can be resolved by combining FL with Secure Multiparty\nComputation (MPC) and Differential Privacy (DP). In doing so, we propose a\nmethod for training group-fair ML models in cross-device FL under complete and\nformal privacy guarantees, without requiring the clients to disclose their\nsensitive attribute values.",
    "descriptor": "",
    "authors": [
      "Sikha Pentyala",
      "Nicola Neophytou",
      "Anderson Nascimento",
      "Martine De Cock",
      "Golnoosh Farnadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.11584"
  },
  {
    "id": "arXiv:2205.11585",
    "title": "An intelligent controller for underactuated mechanical systems",
    "abstract": "This paper presents an intelligent controller for uncertain underactuated\nnonlinear systems. The adopted approach is based on sliding mode control and\nenhanced by an artificial neural network to cope with modeling inaccuracies and\nexternal disturbances that can arise. The sliding surfaces are defined as a\nlinear combination of both actuated and unactuated variables. A radial basis\nfunction is added to compensate the performance drop when, in order to avoid\nthe chattering phenomenon, the sign function is substituted by a saturation\nfunction in the conventional sliding mode controller. An application of the\nproposed scheme is introduced for an inverted pendulum, in order to illustrate\nthe controller design method, and numerical results are presented to\ndemonstrate the improved performance of the resulting intelligent controller.",
    "descriptor": "",
    "authors": [
      "Josiane Maria de Macedo Fernande",
      "Marcelo Costa Tanaka",
      "Wallace Moreira Bessa",
      "Edwin Kreuzer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11585"
  },
  {
    "id": "arXiv:2205.11588",
    "title": "Simple Recurrence Improves Masked Language Models",
    "abstract": "In this work, we explore whether modeling recurrence into the Transformer\narchitecture can both be beneficial and efficient, by building an extremely\nsimple recurrent module into the Transformer. We compare our model to baselines\nfollowing the training and evaluation recipe of BERT. Our results confirm that\nrecurrence can indeed improve Transformer models by a consistent margin,\nwithout requiring low-level performance optimizations, and while keeping the\nnumber of parameters constant. For example, our base model achieves an absolute\nimprovement of 2.1 points averaged across 10 tasks and also demonstrates\nincreased stability in fine-tuning over a range of learning rates.",
    "descriptor": "",
    "authors": [
      "Tao Lei",
      "Ran Tian",
      "Jasmijn Bastings",
      "Ankur P. Parikh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11588"
  },
  {
    "id": "arXiv:2205.11589",
    "title": "Explaining Causal Models with Argumentation: the Case of Bi-variate  Reinforcement",
    "abstract": "Causal models are playing an increasingly important role in machine learning,\nparticularly in the realm of explainable AI. We introduce a conceptualisation\nfor generating argumentation frameworks (AFs) from causal models for the\npurpose of forging explanations for the models' outputs. The conceptualisation\nis based on reinterpreting desirable properties of semantics of AFs as\nexplanation moulds, which are means for characterising the relations in the\ncausal model argumentatively. We demonstrate our methodology by reinterpreting\nthe property of bi-variate reinforcement as an explanation mould to forge\nbipolar AFs as explanations for the outputs of causal models. We perform a\ntheoretical evaluation of these argumentative explanations, examining whether\nthey satisfy a range of desirable explanatory and argumentative properties.",
    "descriptor": "\nComments: 6 pages, 1 figure (to appear at KR 2022)\n",
    "authors": [
      "Antonio Rago",
      "Pietro Baroni",
      "Francesca Toni"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11589"
  },
  {
    "id": "arXiv:2205.11590",
    "title": "Forecasting Argumentation Frameworks",
    "abstract": "We introduce Forecasting Argumentation Frameworks (FAFs), a novel\nargumentation-based methodology for forecasting informed by recent judgmental\nforecasting research. FAFs comprise update frameworks which empower (human or\nartificial) agents to argue over time about the probability of outcomes, e.g.\nthe winner of a political election or a fluctuation in inflation rates, whilst\nflagging perceived irrationality in the agents' behaviour with a view to\nimproving their forecasting accuracy. FAFs include five argument types,\namounting to standard pro/con arguments, as in bipolar argumentation, as well\nas novel proposal arguments and increase/decrease amendment arguments. We adapt\nan existing gradual semantics for bipolar argumentation to determine the\naggregated dialectical strength of proposal arguments and define irrational\nbehaviour. We then give a simple aggregation function which produces a final\ngroup forecast from rational agents' individual forecasts. We identify and\nstudy properties of FAFs and conduct an empirical evaluation which signals\nFAFs' potential to increase the forecasting accuracy of participants.",
    "descriptor": "\nComments: 9 pages, 2 figures (to appear at KR 2022)\n",
    "authors": [
      "Benjamin Irwin",
      "Antonio Rago",
      "Francesca Toni"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11590"
  },
  {
    "id": "arXiv:2205.11594",
    "title": "A framework for the development of intelligent mechanical systems",
    "abstract": "From autonomous vacuum cleaners to self-driving cars, intelligent mechanical\nsystems are becoming an intrinsic part of our daily lives. In this work, a\nframework for the development of intelligent mechanical systems is\npresented.Considering that in this scenario the adopted control approach plays\nan essential role, I show that the proposed scheme should be able to not only\nadapt itself to changes in the environment, but also learn from its own\nexperience.",
    "descriptor": "",
    "authors": [
      "Wallace M. Bessa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11594"
  },
  {
    "id": "arXiv:2205.11596",
    "title": "On trajectories of complex-valued interior transmission eigenvalues",
    "abstract": "This paper investigates properties of complex-valued eigenvalue trajectories\nfor the interior transmission problem parametrized by the index of refraction\nfor homogeneous media. Our theoretical analysis for the unit disk shows that\nthe only intersection points with the real axis, as well as the unique\ntrajectorial limit points as the refractive index tends to infinity, are\nDirichlet eigenvalues of the Laplacian. Complementing numerical experiments\neven give rise to an underlying one-to-one correspondence between Dirichlet\neigenvalues of the Laplacian and complex-valued interior transmission\neigenvalue trajectories. We also examine other scatterers than the disk for\nwhich similar numerical observations can be made. We summarize our results in a\nconjecture for general simply-connected scatterers.",
    "descriptor": "\nComments: 22 pages, 8 figures\n",
    "authors": [
      "Lukas Pieronek",
      "Andreas Kleefeld"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.11596"
  },
  {
    "id": "arXiv:2205.11597",
    "title": "Wiser: Increasing Throughput in Payment Channel Networks with  Transaction Aggregation",
    "abstract": "Payment channel networks (PCNs) are one of the most prominent solutions to\nthe limited transaction throughput of blockchains. Nevertheless, PCNs suffer\nthemselves from a throughput limitation due to the capital constraints of their\nchannels. A similar dependence on high capital is also found in inter-bank\npayment settlements, where the so-called netting technique is used to mitigate\nliquidity demands.\nIn this work, we alleviate this limitation by introducing the notion of\ntransaction aggregation: instead of executing transactions sequentially through\na PCN, we enable senders to aggregate multiple transactions and execute them\nsimultaneously to benefit from several amounts that may \"cancel out\". Two\ndirect advantages of our proposal is the decrease in intermediary fees paid by\nsenders as well as the obfuscation of the transaction data from the\nintermediaries.\nWe formulate the transaction aggregation as a computational problem, a\ngeneralization of the Bank Clearing Problem. We present a generic framework for\nthe transaction aggregation execution, and thereafter we propose Wiser as an\nimplementation of this framework in a specific hub-based setting. To overcome\nthe NP-hardness of the transaction aggregation problem, in Wiser we propose a\nfixed-parameter linear algorithm for a special case of transaction aggregation\nas well as the Bank Clearing Problem. Wiser can also be seen as a modern\nvariant of the Hawala money transfer system, as well as a decentralized\nimplementation of the overseas remittance service of Wise.",
    "descriptor": "",
    "authors": [
      "Samarth Tiwari",
      "Michelle Yeo",
      "Zeta Avarikioti",
      "Iosif Salem",
      "Krzysztof Pietrzak",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.11597"
  },
  {
    "id": "arXiv:2205.11601",
    "title": "Challenges in Measuring Bias via Open-Ended Language Generation",
    "abstract": "Researchers have devised numerous ways to quantify social biases vested in\npretrained language models. As some language models are capable of generating\ncoherent completions given a set of textual prompts, several prompting datasets\nhave been proposed to measure biases between social groups -- posing language\ngeneration as a way of identifying biases. In this opinion paper, we analyze\nhow specific choices of prompt sets, metrics, automatic tools and sampling\nstrategies affect bias results. We find out that the practice of measuring\nbiases through text completion is prone to yielding contradicting results under\ndifferent experiment settings. We additionally provide recommendations for\nreporting biases in open-ended language generation for a more complete outlook\nof biases exhibited by a given language model. Code to reproduce the results is\nreleased under https://github.com/feyzaakyurek/bias-textgen.",
    "descriptor": "\nComments: 4th Workshop on Gender Bias in Natural Language Processing. NAACL, 2022\n",
    "authors": [
      "Afra Feyza Aky\u00fcrek",
      "Muhammed Yusuf Kocyigit",
      "Sejin Paik",
      "Derry Wijaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.11601"
  },
  {
    "id": "arXiv:2205.11602",
    "title": "Seeded Hierarchical Clustering for Expert-Crafted Taxonomies",
    "abstract": "Practitioners from many disciplines (e.g., political science) use\nexpert-crafted taxonomies to make sense of large, unlabeled corpora. In this\nwork, we study Seeded Hierarchical Clustering (SHC): the task of automatically\nfitting unlabeled data to such taxonomies using only a small set of labeled\nexamples. We propose HierSeed, a novel weakly supervised algorithm for this\ntask that uses only a small set of labeled seed examples. It is both data and\ncomputationally efficient. HierSeed assigns documents to topics by weighing\ndocument density against topic hierarchical structure. It outperforms both\nunsupervised and supervised baselines for the SHC task on three real-world\ndatasets.",
    "descriptor": "",
    "authors": [
      "Anish Saha",
      "Amith Ananthram",
      "Emily Allaway",
      "Heng Ji",
      "Kathleen McKeown"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11602"
  },
  {
    "id": "arXiv:2205.11603",
    "title": "Improving language models fine-tuning with representation consistency  targets",
    "abstract": "Fine-tuning contextualized representations learned by pre-trained language\nmodels has become a standard practice in the NLP field. However, pre-trained\nrepresentations are prone to degradation (also known as representation\ncollapse) during fine-tuning, which leads to instability, suboptimal\nperformance, and weak generalization. In this paper, we propose a novel\nfine-tuning method that avoids representation collapse during fine-tuning by\ndiscouraging undesirable changes in the representations. We show that our\napproach matches or exceeds the performance of the existing\nregularization-based fine-tuning methods across 13 language understanding tasks\n(GLUE benchmark and six additional datasets). We also demonstrate its\neffectiveness in low-data settings and robustness to label perturbation.\nFurthermore, we extend previous studies of representation collapse and propose\nseveral metrics to quantify it. Using these metrics and previously proposed\nexperiments, we show that our approach obtains significant improvements in\nretaining the expressive power of representations.",
    "descriptor": "\nComments: 32 pages, 3 figures\n",
    "authors": [
      "Anastasia Razdaibiedina",
      "Vivek Madan",
      "Zohar Karnin",
      "Ashish Khetan",
      "Vishaal Kapoor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11603"
  },
  {
    "id": "arXiv:2205.11605",
    "title": "On Measuring Social Biases in Prompt-Based Multi-Task Learning",
    "abstract": "Large language models trained on a mixture of NLP tasks that are converted\ninto a text-to-text format using prompts, can generalize into novel forms of\nlanguage and handle novel tasks. A large body of work within prompt engineering\nattempts to understand the effects of input forms and prompts in achieving\nsuperior performance. We consider an alternative measure and inquire whether\nthe way in which an input is encoded affects social biases promoted in outputs.\nIn this paper, we study T0, a large-scale multi-task text-to-text language\nmodel trained using prompt-based learning. We consider two different forms of\nsemantically equivalent inputs: question-answer format and premise-hypothesis\nformat. We use an existing bias benchmark for the former BBQ and create the\nfirst bias benchmark in natural language inference BBNLI with hand-written\nhypotheses while also converting each benchmark into the other form. The\nresults on two benchmarks suggest that given two different formulations of\nessentially the same input, T0 conspicuously acts more biased in question\nanswering form, which is seen during training, compared to premise-hypothesis\nform which is unlike its training examples. Code and data are released under\nhttps://github.com/feyzaakyurek/bbnli.",
    "descriptor": "\nComments: Findings of NAACL 2022\n",
    "authors": [
      "Afra Feyza Aky\u00fcrek",
      "Sejin Paik",
      "Muhammed Yusuf Kocyigit",
      "Seda Akbiyik",
      "\u015eerife Leman Runyun",
      "Derry Wijaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.11605"
  },
  {
    "id": "arXiv:2205.11606",
    "title": "Discriminative Feature Learning through Feature Distance Loss",
    "abstract": "Convolutional neural networks have shown remarkable ability to learn\ndiscriminative semantic features in image recognition tasks. Though, for\nclassification they often concentrate on specific regions in images. This work\nproposes a novel method that combines variant rich base models to concentrate\non different important image regions for classification. A feature distance\nloss is implemented while training an ensemble of base models to force them to\nlearn discriminative feature concepts. The experiments on benchmark\nconvolutional neural networks (VGG16, ResNet, AlexNet), popular datasets\n(Cifar10, Cifar100, miniImageNet, NEU, BSD, TEX), and different training\nsamples (3, 5, 10, 20, 50, 100 per class) show our methods effectiveness and\ngeneralization ability. Our method outperforms ensemble versions of the base\nmodels without feature distance loss, and the Class Activation Maps explicitly\nproves the ability to learn different discriminative feature concepts.",
    "descriptor": "",
    "authors": [
      "Tobias Schlagenhauf",
      "Yiwen Lin",
      "Benjamin Noack"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11606"
  },
  {
    "id": "arXiv:2205.11607",
    "title": "Low-Complexity Block Coordinate Descend Based Multiuser Detection for  Uplink Grant-Free NOMA",
    "abstract": "Grant-free non-orthogonal multiple access (NOMA) scheme is considered as a\npromising candidate for the enabling of massive connectivity and reduced\nsignalling overhead for Internet of Things (IoT) applications in massive\nmachine-type communication (mMTC) networks. Exploiting the inherent nature of\nsporadic transmissions in the grant-free NOMA systems, compressed sensing based\nmultiuser detection (CS-MUD) has been deemed as a powerful solution to user\nactivity detection (UAD) and data detection (DD). In this paper, block\ncoordinate descend (BCD) method is employed in CS-MUD to reduce the\ncomputational complexity. We propose two modified BCD based algorithms, called\nenhanced BCD (EBCD) and complexity reduction enhanced BCD (CR-EBCD),\nrespectively. To be specific, by incorporating a novel candidate set pruning\nmechanism into the original BCD framework, our proposed EBCD algorithm achieves\nremarkable CS-MUD performance improvement. In addition, the proposed CR-EBCD\nalgorithm further ameliorates the proposed EBCD by eliminating the redundant\nmatrix multiplications during the iteration process. As a consequence, compared\nwith the proposed EBCD algorithm, our proposed CR-EBCD algorithm enjoys two\norders of magnitude complexity saving without any CS-MUD performance\ndegradation, rendering it a viable solution for future mMTC scenarios.\nExtensive simulation results demonstrate the bound-approaching performance as\nwell as ultra-low computational complexity.",
    "descriptor": "",
    "authors": [
      "Pengyu Gao",
      "Zilong Liu",
      "Pei Xiao",
      "Chuan Heng Foh",
      "Jing Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11607"
  },
  {
    "id": "arXiv:2205.11609",
    "title": "A fuzzy feedback linearization scheme applied to vibration control of a  smart structure",
    "abstract": "Smart structures are usually designed with a stimulus-response mechanism to\nmimic the autoregulatory process of living systems. In this work, in order to\nsimulate this natural and self-adjustable behavior, a fuzzy feedback\nlinearization scheme is applied to a shape memory two-bar truss. This\nstructural system exhibits both constitutive and geometrical nonlinearities\npresenting the snap-through behavior and chaotic dynamics. On this basis, a\nnonlinear controller is employed for vibration suppression in the chaotic smart\ntruss. The control scheme is primarily based on feedback linearization and\nenhanced by a fuzzy inference system to cope with modeling inaccuracies and\nexternal disturbances. The overall control system performance is evaluated by\nmeans of numerical simulations, promoting vibration reduction and avoiding\nsnap-through behavior.",
    "descriptor": "",
    "authors": [
      "Roberta Varela de Albuquerque Her\u00f4ncio",
      "Jo\u00e3o Deodato Batista dos Santos",
      "Wallace Moreira Bessa",
      "Aline Souza de Paula",
      "Marcelo Amorim Savi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11609"
  },
  {
    "id": "arXiv:2205.11610",
    "title": "uGLAD: Sparse graph recovery by optimizing deep unrolled networks",
    "abstract": "Probabilistic Graphical Models (PGMs) are generative models of complex\nsystems. They rely on conditional independence assumptions between variables to\nlearn sparse representations which can be visualized in a form of a graph. Such\nmodels are used for domain exploration and structure discovery in poorly\nunderstood domains. This work introduces a novel technique to perform sparse\ngraph recovery by optimizing deep unrolled networks. Assuming that the input\ndata $X\\in\\mathbb{R}^{M\\times D}$ comes from an underlying multivariate\nGaussian distribution, we apply a deep model on $X$ that outputs the precision\nmatrix $\\Theta$, which can also be interpreted as the adjacency matrix. Our\nmodel, uGLAD, builds upon and extends the state-of-the-art model GLAD to the\nunsupervised setting. The key benefits of our model are (1) uGLAD automatically\noptimizes sparsity-related regularization parameters leading to better\nperformance than existing algorithms. (2) We introduce multi-task learning\nbased `consensus' strategy for robust handling of missing data in an\nunsupervised setting. We evaluate model results on synthetic Gaussian data,\nnon-Gaussian data generated from Gene Regulatory Networks, and present a case\nstudy in anaerobic digestion.",
    "descriptor": "",
    "authors": [
      "Harsh Shrivastava",
      "Urszula Chajewska",
      "Robin Abraham",
      "Xinshi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.11610"
  },
  {
    "id": "arXiv:2205.11611",
    "title": "A Contrario multi-scale anomaly detection method for industrial quality  inspection",
    "abstract": "Anomalies can be defined as any non-random structure which deviates from\nnormality. Anomaly detection methods reported in the literature are numerous\nand diverse, as what is considered anomalous usually varies depending on\nparticular scenarios and applications. In this work we propose an a contrario\nframework to detect anomalies in images applying statistical analysis to\nfeature maps obtained via convolutions. We evaluate filters learned from the\nimage under analysis via patch PCA, Gabor filters and the feature maps obtained\nfrom a pre-trained deep neural network (Resnet). The proposed method is\nmulti-scale and fully unsupervised and is able to detect anomalies in a wide\nvariety of scenarios. While the end goal of this work is the detection of\nsubtle defects in leather samples for the automotive industry, we show that the\nsame algorithm achieves state-of-the-art results in public anomalies datasets.",
    "descriptor": "\nComments: 12 pages, 8 figures, 4 tables. arXiv admin note: substantial text overlap with arXiv:2110.02407\n",
    "authors": [
      "Mat\u00edas Tailanian",
      "Pablo Mus\u00e9",
      "\u00c1lvaro Pardo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11611"
  },
  {
    "id": "arXiv:2205.11613",
    "title": "How do people incorporate advice from artificial agents when making  physical judgments?",
    "abstract": "How do people build up trust with artificial agents? Here, we study a key\ncomponent of interpersonal trust: people's ability to evaluate the competence\nof another agent across repeated interactions. Prior work has largely focused\non appraisal of simple, static skills; in contrast, we probe competence\nevaluations in a rich setting with agents that learn over time. Participants\nplayed a video game involving physical reasoning paired with one of four\nartificial agents that suggested moves each round. We measure participants'\ndecisions to accept or revise their partner's suggestions to understand how\npeople evaluated their partner's ability. Overall, participants collaborated\nsuccessfully with their agent partners; however, when revising their partner's\nsuggestions, people made sophisticated inferences about the competence of their\npartner from prior behavior. Results provide a quantitative measure of how\npeople integrate a partner's competence into their own decisions and may help\nfacilitate better coordination between humans and artificial agents.",
    "descriptor": "",
    "authors": [
      "Erik Brockbank",
      "Haoliang Wang",
      "Justin Yang",
      "Suvir Mirchandani",
      "Erdem B\u0131y\u0131k",
      "Dorsa Sadigh",
      "Judith E. Fan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.11613"
  },
  {
    "id": "arXiv:2205.11614",
    "title": "Trust, Professional Vision and Diagnostic Work",
    "abstract": "In this paper we consider some empirical materials from our ongoing research\ninto forms of everyday detection and diagnosis work in healthcare settings, and\nhow these relate to issues of trust; trust in people, in technology, processes\nand in data.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Mark Rouncefield",
      "Rob Procter",
      "Peter Tolmie"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.11614"
  },
  {
    "id": "arXiv:2205.11616",
    "title": "Utilizing Language-Image Pretraining for Efficient and Robust Bilingual  Word Alignment",
    "abstract": "Word translation without parallel corpora has become feasible, rivaling the\nperformance of supervised methods. Recent findings have shown that the accuracy\nand robustness of unsupervised word translation (UWT) can be improved by making\nuse of visual observations, which are universal representations across\nlanguages. In this work, we investigate the potential of using not only visual\nobservations but also pretrained language-image models for enabling a more\nefficient and robust UWT. Specifically, we develop a novel UWT method dubbed\nWord Alignment using Language-Image Pretraining (WALIP), which leverages visual\nobservations via the shared embedding space of images and texts provided by\nCLIP models (Radford et al., 2021). WALIP has a two-step procedure. First, we\nretrieve word pairs with high confidences of similarity, computed using our\nproposed image-based fingerprints, which define the initial pivot for the word\nalignment. Second, we apply our robust Procrustes algorithm to estimate the\nlinear mapping between two embedding spaces, which iteratively corrects and\nrefines the estimated alignment. Our extensive experiments show that WALIP\nimproves upon the state-of-the-art performance of bilingual word alignment for\na few language pairs across different word embeddings and displays great\nrobustness to the dissimilarity of language pairs or training corpora for two\nword embeddings.",
    "descriptor": "\nComments: 13 pages, 7 figures, 3 tables\n",
    "authors": [
      "Tuan Dinh",
      "Jy-yong Sohn",
      "Shashank Rajput",
      "Timothy Ossowski",
      "Yifei Ming",
      "Junjie Hu",
      "Dimitris Papailiopoulos",
      "Kangwook Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11616"
  },
  {
    "id": "arXiv:2205.11622",
    "title": "SparseLNR: Accelerating Sparse Tensor Computations Using Loop Nest  Restructuring",
    "abstract": "Sparse tensor algebra computations have become important in many real-world\napplications like machine learning, scientific simulations, and data mining.\nHence, automated code generation and performance optimizations for tensor\nalgebra kernels are paramount. Recent advancements such as the Tensor Algebra\nCompiler (TACO) greatly generalize and automate the code generation for tensor\nalgebra expressions. However, the code generated by TACO for many important\ntensor computations remains suboptimal due to the absence of a scheduling\ndirective to support transformations such as distribution/fusion.\nThis paper extends TACO's scheduling space to support kernel\ndistribution/loop fusion in order to reduce asymptotic time complexity and\nimprove locality of complex tensor algebra computations. We develop an\nintermediate representation (IR) for tensor operations called branched\niteration graph which specifies breakdown of the computation into smaller ones\n(kernel distribution) and then fuse (loop fusion) outermost dimensions of the\nloop nests, while the innermost dimensions are distributed, to increase data\nlocality. We describe exchanges of intermediate results between space iteration\nspaces, transformation in the IR, and its programmatic invocation. Finally, we\nshow that the transformation can be used to optimize sparse tensor kernels. Our\nresults show that this new transformation significantly improves the\nperformance of several real-world tensor algebra computations compared to\nTACO-generated code.",
    "descriptor": "\nComments: Accepted at International Conference on Supercomputing (ICS) '22\n",
    "authors": [
      "Adhitha Dias",
      "Kirshanthan Sundararajah",
      "Charitha Saumya",
      "Milind Kulkarni"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.11622"
  },
  {
    "id": "arXiv:2205.11624",
    "title": "Effectively Incorporating Weighted Cost-to-go Heuristic in Suboptimal  CBS",
    "abstract": "Conflict-Based Search (CBS) is a popular multi-agent path finding (MAPF)\nsolver that employs a low-level single agent planner and a high-level\nconstraint tree to resolve conflicts. The vast majority of modern MAPF solvers\nfocus on improving CBS by reducing the size of this tree through various\nstrategies with few methods modifying the low level planner. All low level\nplanners in existing CBS methods use an unweighted cost-to-go heuristic, with\nsuboptimal CBS methods also using a conflict heuristic to help the high level\nsearch. Contrary to prevailing beliefs, we show that the cost-to-go heuristic\ncan be used significantly more effectively by weighting it in a specific manner\nalongside the conflict heuristic. We introduce two variants of doing so and\ndemonstrate that this change can lead to 2-100x speedups in certain scenarios.\nAdditionally, to the best of our knowledge, we show the first theoretical\nrelation of prioritized planning and bounded suboptimal CBS and demonstrate\nthat our methods are their natural generalization.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Rishi Veerapaneni",
      "Tushar Kusnar",
      "Maxim Likhachev"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.11624"
  },
  {
    "id": "arXiv:2205.11631",
    "title": "Towards Opening the Black Box of Neural Machine Translation: Source and  Target Interpretations of the Transformer",
    "abstract": "In Neural Machine Translation (NMT), each token prediction is conditioned on\nthe source sentence and the target prefix (what has been previously translated\nat a decoding step). However, previous work on interpretability in NMT has\nfocused solely on source sentence tokens attributions. Therefore, we lack a\nfull understanding of the influences of every input token (source sentence and\ntarget prefix) in the model predictions. In this work, we propose an\ninterpretability method that tracks complete input token attributions. Our\nmethod, which can be extended to any encoder-decoder Transformer-based model,\nallows us to better comprehend the inner workings of current NMT models. We\napply the proposed method to both bilingual and multilingual Transformers and\npresent insights into their behaviour.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Javier Ferrando",
      "Gerard I. G\u00e1llego",
      "Belen Alastruey",
      "Carlos Escolano",
      "Marta R. Costa-juss\u00e0"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11631"
  },
  {
    "id": "arXiv:2205.11632",
    "title": "Evolution of biomedical innovation quantified via billions of distinct  article-level MeSH keyword combinations",
    "abstract": "We develop a systematic approach to measuring combinatorial innovation in the\nbiomedical sciences based upon the comprehensive ontology of Medical Subject\nHeadings (MeSH). This approach leverages an expert-defined knowledge ontology\nthat features both breadth (27,875 MeSH analyzed across 25 million articles\nindexed by PubMed from 1902 onwards) and depth (we differentiate between Major\nand Minor MeSH terms to identify differences in the knowledge network\nrepresentation constructed from primary research topics only). With this level\nof uniform resolution we differentiate between three different modes of\ninnovation contributing to the combinatorial knowledge network: (i) conceptual\ninnovation associated with the emergence of new concepts and entities (measured\nas the entry of new MeSH); and (ii) recombinant innovation, associated with the\nemergence of new combinations, which itself consists of two types: peripheral\n(i.e., combinations involving new knowledge) and core (combinations comprised\nof pre-existing knowledge only). Another relevant question we seek to address\nis whether examining triplet and quartet combinations, in addition to the more\ntraditional dyadic or pairwise combinations, provide evidence of any new\nphenomena associated with higher-order combinations. Analysis of the size,\ngrowth, and coverage of combinatorial innovation yield results that are largely\nindependent of the combination order, thereby suggesting that the common dyadic\napproach is sufficient to capture essential phenomena. Our main results are\ntwofold: (a) despite the persistent addition of new MeSH terms, the network is\ndensifying over time meaning that scholars are increasingly exploring and\nrealizing the vast space of all knowledge combinations; and (b) conceptual\ninnovation is increasingly concentrated within single research articles, a\nharbinger of the recent paradigm shift towards convergence science.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Alexander M. Petersen"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2205.11632"
  },
  {
    "id": "arXiv:2205.11634",
    "title": "TransforMatcher: Match-to-Match Attention for Semantic Correspondence",
    "abstract": "Establishing correspondences between images remains a challenging task,\nespecially under large appearance changes due to different viewpoints or\nintra-class variations. In this work, we introduce a strong semantic image\nmatching learner, dubbed TransforMatcher, which builds on the success of\ntransformer networks in vision domains. Unlike existing convolution- or\nattention-based schemes for correspondence, TransforMatcher performs global\nmatch-to-match attention for precise match localization and dynamic refinement.\nTo handle a large number of matches in a dense correlation map, we develop a\nlight-weight attention architecture to consider the global match-to-match\ninteractions. We also propose to utilize a multi-channel correlation map for\nrefinement, treating the multi-level scores as features instead of a single\nscore to fully exploit the richer layer-wise semantics. In experiments,\nTransforMatcher sets a new state of the art on SPair-71k while performing on\npar with existing SOTA methods on the PF-PASCAL dataset.",
    "descriptor": "\nComments: Accepted to CVPR 2022 (poster presentation)\n",
    "authors": [
      "Seungwook Kim",
      "Juhong Min",
      "Minsu Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11634"
  },
  {
    "id": "arXiv:2205.11636",
    "title": "Forecasting of Non-Stationary Sales Time Series Using Deep Learning",
    "abstract": "The paper describes the deep learning approach for forecasting non-stationary\ntime series with using time trend correction in a neural network model. Along\nwith the layers for predicting sales values, the neural network model includes\na subnetwork block for the prediction weight for a time trend term which is\nadded to a predicted sales value. The time trend term is considered as a\nproduct of the predicted weight value and normalized time value. The results\nshow that the forecasting accuracy can be essentially improved for\nnon-stationary sales with time trends using the trend correction block in the\ndeep learning model.",
    "descriptor": "",
    "authors": [
      "Bohdan M. Pavlyshenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.11636"
  },
  {
    "id": "arXiv:2205.11638",
    "title": "DOGE-Train: Discrete Optimization on GPU with End-to-end Training",
    "abstract": "We present a fast, scalable, data-driven approach for solving linear\nrelaxations of 0-1 integer linear programs using a graph neural network. Our\nsolver is based on the Lagrange decomposition based algorithm FastDOG (Abbas et\nal. (2022)). We make the algorithm differentiable and perform backpropagation\nthrough the dual update scheme for end-to-end training of its algorithmic\nparameters. This allows to preserve the algorithm's theoretical properties\nincluding feasibility and guaranteed non-decrease in the lower bound. Since\nFastDOG can get stuck in suboptimal fixed points, we provide additional freedom\nto our graph neural network to predict non-parametric update steps for escaping\nsuch points while maintaining dual feasibility. For training of the graph\nneural network we use an unsupervised loss and perform experiments on\nlarge-scale real world datasets. We train on smaller problems and test on\nlarger ones showing strong generalization performance with a graph neural\nnetwork comprising only around 10k parameters. Our solver achieves\nsignificantly faster performance and better dual objectives than its\nnon-learned version. In comparison to commercial solvers our learned solver\nachieves close to optimal objective values of LP relaxations and is faster by\nup to an order of magnitude on very large problems from structured prediction\nand on selected combinatorial optimization problems.",
    "descriptor": "\nComments: Alert before printing: pg. 18-25 only contain per instance results, can possibly be skipped\n",
    "authors": [
      "Ahmed Abbas",
      "Paul Swoboda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11638"
  },
  {
    "id": "arXiv:2205.11641",
    "title": "Machine Learning for Electricity Market Clearing",
    "abstract": "This paper seeks to design a machine learning twin of the optimal power flow\n(OPF) optimization, which is used in market-clearing procedures by wholesale\nelectricity markets. The motivation for the proposed approach stems from the\nneed to obtain the digital twin, which is much faster than the original, while\nalso being sufficiently accurate and producing consistent generation dispatches\nand locational marginal prices (LMPs), which are primal and dual solutions of\nthe OPF optimization, respectively. Availability of market-clearing tools based\non this approach will enable computationally tractable evaluation of multiple\ndispatch scenarios under a given unit commitment. Rather than direct solution\nof OPF, the Karush-Kuhn-Tucker (KKT) conditions for the OPF problem in question\nmay be written, and in parallel the LMPs of generators and loads may be\nexpressed in terms of the OPF Lagrangian multipliers. Also, taking advantage of\nthe practical fact that many of the Lagrangian multipliers associated with\nlines will be zero (thermal limits are not binding), we build and train an ML\nscheme which maps flexible resources (loads and renewables) to the binding\nlines, and supplement it with an efficient power-grid aware linear map to\noptimal dispatch and LMPs. The scheme is validated and illustrated on IEEE\nmodels. We also report a trade of analysis between quality of the\nreconstruction and number of samples needed to train the model.",
    "descriptor": "\nComments: Accepted for presentation in 11th Bulk Power Systems Dynamics Sympsium (IREP 2022), July 25-30, 2022, Banff, Canada\n",
    "authors": [
      "Laurent Pagnier",
      "Robert Ferrando",
      "Yury Dvorkin",
      "Michael Chertkov"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11641"
  },
  {
    "id": "arXiv:2205.11644",
    "title": "Visual and unplugged coding lessons with smart toys",
    "abstract": "Our Computer science k-12 education research group and the educational toy\ncompany Quercetti have been collaborating together to design and manufacture\ntoys that help stimulate and consolidate so-called computational thinking. This\napproach is inspired by methods already consolidated in the literature and\nwidespread worldwide such as the Bebras tasks and CS-Unplugged. This paper\ndescribes two smart toys, their design process, educational activities that can\nbe proposed by teachers exploiting the two toys, the evaluation's results from\nsome teachers, and finally feedback and reviews from buyers. The main\nactivities proposed by these toys leverage visual coding through small colored\nphysical items (e.g., pegs and balls) to deliver the unplugged activities to\nyoung users.",
    "descriptor": "\nComments: Extented version of the short paper accepted at AVI 2022 (Visual and unplugged coding with smart toys)\n",
    "authors": [
      "Sara Capecchi",
      "Cristina Gena",
      "Ilaria Lombardi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.11644"
  },
  {
    "id": "arXiv:2205.11648",
    "title": "Deep Representations for Time-varying Brain Datasets",
    "abstract": "Finding an appropriate representation of dynamic activities in the brain is\ncrucial for many downstream applications. Due to its highly dynamic nature,\ntemporally averaged fMRI (functional magnetic resonance imaging) can only\nprovide a narrow view of underlying brain activities. Previous works lack the\nability to learn and interpret the latent dynamics in brain architectures. This\npaper builds an efficient graph neural network model that incorporates both\nregion-mapped fMRI sequences and structural connectivities obtained from DWI\n(diffusion-weighted imaging) as inputs. We find good representations of the\nlatent brain dynamics through learning sample-level adaptive adjacency matrices\nand performing a novel multi-resolution inner cluster smoothing. These modules\ncan be easily adapted to and are potentially useful for other applications\noutside the neuroscience domain. We also attribute inputs with integrated\ngradients, which enables us to infer (1) highly involved brain connections and\nsubnetworks for each task, (2) temporal keyframes of imaging sequences that\ncharacterize tasks, and (3) subnetworks that discriminate between individual\nsubjects. This ability to identify critical subnetworks that characterize\nsignal states across heterogeneous tasks and individuals is of great importance\nto neuroscience and other scientific domains. Extensive experiments and\nablation studies demonstrate our proposed method's superiority and efficiency\nin spatial-temporal graph signal modeling with insightful interpretations of\nbrain dynamics.",
    "descriptor": "",
    "authors": [
      "Sikun Lin",
      "Shuyun Tang",
      "Scott Grafton",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2205.11648"
  },
  {
    "id": "arXiv:2205.11651",
    "title": "A Natural Language Processing Pipeline for Detecting Informal Data  References in Academic Literature",
    "abstract": "Discovering authoritative links between publications and the datasets that\nthey use can be a labor-intensive process. We introduce a natural language\nprocessing pipeline that retrieves and reviews publications for informal\nreferences to research datasets, which complements the work of data librarians.\nWe first describe the components of the pipeline and then apply it to expand an\nauthoritative bibliography linking thousands of social science studies to the\ndata-related publications in which they are used. The pipeline increases recall\nfor literature to review for inclusion in data-related collections of\npublications and makes it possible to detect informal data references at scale.\nWe contribute (1) a novel Named Entity Recognition (NER) model that reliably\ndetects informal data references and (2) a dataset connecting items from social\nscience literature with datasets they reference. Together, these contributions\nenable future work on data reference, data citation networks, and data reuse.",
    "descriptor": "\nComments: 13 pages, 7 figures, 3 tables\n",
    "authors": [
      "Sara Lafia",
      "Lizhou Fan",
      "Libby Hemphill"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11651"
  },
  {
    "id": "arXiv:2205.11652",
    "title": "It's not easy to relax: liveness in chained BFT protocols",
    "abstract": "Modern $\\textit{chained}$ Byzantine Fault Tolerant (BFT) protocols leverage a\ncombination of pipelining and leader rotation to maximize both efficiency and\nfairness. Unfortunately, this approach compromises liveness. We observe that\neven simple leader failures such as crashes can prevent the system from making\nprogress, both theoretically, and practically. The root cause is simple: these\nprotocols require a sequence of three or four consecutive honest leaders to\ncommit operations. This paper makes two contributions: first, we show that, in\nthe presence of arbitrary failures, consecutive honest leaders are\n$\\textit{necessary}$. When nodes fail by omission however, one can do better.\nAs second contribution, we thus propose Siesta, a novel chained BFT protocol\nthat successfully commit blocks that span multiple non-consecutive leaders.\nSiesta reduces the expected commit latency of Hotstuff by a factor of three\nunder failures, and the worst-case latency by a factor of eight.",
    "descriptor": "",
    "authors": [
      "Ittai Abraham",
      "Natacha Crooks",
      "Neil Giridharan",
      "Heidi Howard",
      "Florian Suri-Payer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.11652"
  },
  {
    "id": "arXiv:2205.11655",
    "title": "Attitudes, willingness, and resources to cover Article Publishing  Charges (APC): the influence of age, position, income level country,  discipline and open access habits",
    "abstract": "The rise of open access (OA) publishing has been followed by the expansion of\nthe Article Publishing Charges (APC) that moves the financial burden of\nscholarly journal publishing from readers to authors. We introduce the results\nof an international randomly selected sampled survey (N=3,422) that explores\nattitudes towards this pay-to-publish or Gold OA model among scholars. We test\nthe predictor role of age, professional position, discipline, and income-level\ncountry in this regard. We found that APCs are perceived more as a global\nthreat to Science than a deterrent to personal professional careers. Academics\nin low and lower-middle income level countries hold the most unfavorable\nopinions about the APC system. The less experimental disciplines held more\nnegative perceptions of APC compared to STEM and the Life Sciences. Age and\naccess to external funding stood as negative predictors of refusal to pay to\npublish. Commitment to OA self-archiving predicted the negative global\nperception of the APC. We conclude that access to external research funds\ninfluences the acceptance and the particular perception of the pay to publish\nmodel, remarking the economic dimension of the problem and warning about issues\nin the inequality between center and periphery.",
    "descriptor": "",
    "authors": [
      "Francisco Segado-Boj",
      "Juan-Jose Prieto-Guti\u00e9rrez",
      "Juan Mart\u00edn-Quevedo"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2205.11655"
  },
  {
    "id": "arXiv:2205.11656",
    "title": "FlexiBERT: Are Current Transformer Architectures too Homogeneous and  Rigid?",
    "abstract": "The existence of a plethora of language models makes the problem of selecting\nthe best one for a custom task challenging. Most state-of-the-art methods\nleverage transformer-based models (e.g., BERT) or their variants. Training such\nmodels and exploring their hyperparameter space, however, is computationally\nexpensive. Prior work proposes several neural architecture search (NAS) methods\nthat employ performance predictors (e.g., surrogate models) to address this\nissue; however, analysis has been limited to homogeneous models that use fixed\ndimensionality throughout the network. This leads to sub-optimal architectures.\nTo address this limitation, we propose a suite of heterogeneous and flexible\nmodels, namely FlexiBERT, that have varied encoder layers with a diverse set of\npossible operations and different hidden dimensions. For better-posed surrogate\nmodeling in this expanded design space, we propose a new graph-similarity-based\nembedding scheme. We also propose a novel NAS policy, called BOSHNAS, that\nleverages this new scheme, Bayesian modeling, and second-order optimization, to\nquickly train and use a neural surrogate model to converge to the optimal\narchitecture. A comprehensive set of experiments shows that the proposed\npolicy, when applied to the FlexiBERT design space, pushes the performance\nfrontier upwards compared to traditional models. FlexiBERT-Mini, one of our\nproposed models, has 3% fewer parameters than BERT-Mini and achieves 8.9%\nhigher GLUE score. A FlexiBERT model with equivalent performance as the best\nhomogeneous model achieves 2.6x smaller size. FlexiBERT-Large, another proposed\nmodel, achieves state-of-the-art results, outperforming the baseline models by\nat least 5.7% on the GLUE benchmark.",
    "descriptor": "\nComments: Preprint. In review\n",
    "authors": [
      "Shikhar Tuli",
      "Bhishma Dedhia",
      "Shreshth Tuli",
      "Niraj K. Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11656"
  },
  {
    "id": "arXiv:2205.11658",
    "title": "Penguins Don't Fly: Reasoning about Generics through Instantiations and  Exceptions",
    "abstract": "Generics express generalizations about the world (e.g., \"birds can fly\").\nHowever, they are not universally true -- while sparrows and penguins are both\nbirds, only sparrows can fly and penguins cannot. Commonsense knowledge bases,\nwhich are used extensively in many NLP tasks as a source of world-knowledge,\ncan often encode generic knowledge but, by-design, cannot encode such\nexceptions. Therefore, it is crucial to realize the specific instances when a\ngeneric statement is true or false. In this work, we present a novel framework\nto generate pragmatically relevant true and false instances of a generic. We\nuse pre-trained language models, constraining the generation based on insights\nfrom linguistic theory, and produce ${\\sim}20k$ exemplars for ${\\sim}650$\ngenerics. Our system outperforms few-shot generation from GPT-3 (by 12.5\nprecision points) and our analysis highlights the importance of constrained\ndecoding for this task and the implications of generics exemplars for language\ninference tasks.",
    "descriptor": "",
    "authors": [
      "Emily Allaway",
      "Jena D. Hwang",
      "Chandra Bhagavatula",
      "Kathleen McKeown",
      "Doug Downey",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11658"
  },
  {
    "id": "arXiv:2205.11659",
    "title": "Fast GPU bounding boxes on tree-structured scenes",
    "abstract": "Computation of bounding boxes is a fundamental problem in high performance\nrendering, as it is an input to visibility culling and binning operations. In a\nscene description structured as a tree, clip nodes and blend nodes entail\nintersection and union of bounding boxes, respectively. These are\nstraightforward to compute on the CPU using a sequential algorithm, but an\nefficient, parallel GPU algorithm is more elusive. This paper presents a fast\nand practical solution, with a new algorithm for the classic parentheses\nmatching problem at its core. The core algorithm is presented abstractly (in\nterms of a PRAM abstraction), then with a concrete mapping to the thread,\nworkgroup, and dispatch levels of real GPU hardware. The algorithm is\nimplemented portably using compute shaders, and performance results show a\ndramatic speedup over a sequential CPU version, and indeed a reasonable\nfraction of maximum theoretical throughput of the GPU hardware. The immediate\nmotivating application is 2D rendering, but the algorithms generalize to other\ndomains, and the core parentheses matching problem has other applications\nincluding parsing.",
    "descriptor": "",
    "authors": [
      "Raph Levien"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.11659"
  },
  {
    "id": "arXiv:2205.11660",
    "title": "A Taxonomy of Schema Changes for NoSQL Databases",
    "abstract": "Schema evolution is a crucial aspect in database management. The proposed\ntaxonomies of schema changes have neglected the set of operations that involves\nrelationships between entity types: aggregation and references, as well as the\npossible existence of structural variations for schema types, as most of NoSQL\nsystems are schemaless. The distinction between entity types and relationship\ntypes, which is typical of graph schemas, is also not taken into account in the\npublished works. Moreover, NoSQL schema evolution poses the challenge of having\ndifferent data models, and no standard specification exists for them. In this\npaper, a generic approach for evolving NoSQL and relational schemas is\npresented, which is based on the U-Schema unified data model that includes\naggregation and reference relationships, and structural variations. For this\ndata model, we introduce a taxonomy of schema changes for all the U-Schema\nelements, which is implemented by creating the Orion database-independent\nlanguage. We will show how Orion can be used to automatically generate\nevolution scripts for a set of NoSQL databases, and the feasibility of each\nschema operation will be analyzed through the performance results obtained. The\ntaxonomy has been formally validated by means of Alloy, and two case studies\nshow the application of Orion.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Alberto Hern\u00e1ndez Chill\u00f3n",
      "Meike Klettke",
      "Diego Sevilla Ruiz",
      "Jes\u00fas Garc\u00eda Molina"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.11660"
  },
  {
    "id": "arXiv:2205.11664",
    "title": "Towards Model Generalization for Monocular 3D Object Detection",
    "abstract": "Monocular 3D object detection (Mono3D) has achieved tremendous improvements\nwith emerging large-scale autonomous driving datasets and the rapid development\nof deep learning techniques. However, caused by severe domain gaps (e.g., the\nfield of view (FOV), pixel size, and object size among datasets), Mono3D\ndetectors have difficulty in generalization, leading to drastic performance\ndegradation on unseen domains. To solve these issues, we combine the\nposition-invariant transform and multi-scale training with the pixel-size depth\nstrategy to construct an effective unified camera-generalized paradigm (CGP).\nIt fully considers discrepancies in the FOV and pixel size of images captured\nby different cameras. Moreover, we further investigate the obstacle in\nquantitative metrics when cross-dataset inference through an exhaustive\nsystematic study. We discern that the size bias of prediction leads to a\ncolossal failure. Hence, we propose the 2D-3D geometry-consistent object\nscaling strategy (GCOS) to bridge the gap via an instance-level augment. Our\nmethod called DGMono3D achieves remarkable performance on all evaluated\ndatasets and surpasses the SoTA unsupervised domain adaptation scheme even\nwithout utilizing data on the target domain.",
    "descriptor": "",
    "authors": [
      "Zhenyu Li",
      "Zehui Chen",
      "Ang Li",
      "Liangji Fang",
      "Qinhong Jiang",
      "Xianming Liu",
      "Junjun Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11664"
  },
  {
    "id": "arXiv:2205.11666",
    "title": "Algorithm Development for Controlling Movement of a Robotic Platform by  Digital Image Processing",
    "abstract": "The following work shows an algorithm that can process images digitally with\nthe goal of control the movement of a mobile robotic platform in a certain\nenvironment. The platform is identified with a specific color, and displacement\nenvironment of the platform shift has identified obstacles with different\ncolors, for both cases it worked with the RGB color scale. To obtain the\ncontrol's movement of the robotic platform, the algorithm was developed in C\nprogramming language, and used the Open CV libraries for processing images\ncaptured by a video camera on the Dev-platform C + +. The video camera was\npreviously calibrated using ZHANG technique where parameters were obtained\nfocal length and tilt focal pixel. In the algorithm histogram analysis and\nsegmentation of the image were developed, allowing to determine exactly the\nrelative position of the platform with respect to the obstacles and movement\nstrategy to follow.",
    "descriptor": "\nComments: 6 figures,5 pages, in Spanish language\n",
    "authors": [
      "Benjamin Andres Huerfano Zapata",
      "Humberto Numpaque Lopez",
      "Cindy Lorena Diaz Murillo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11666"
  },
  {
    "id": "arXiv:2205.11668",
    "title": "TIC como apoyo del soporte social al enfermo cr\u00f3nico y su cuidador :  Aproximaci\u00f3n al estado del Arte",
    "abstract": "The current approach is carried out in order to have an overview of the level\nof inclusion and the participation of ICTs in social support and support for\nvulnerable populations suffering from chronic diseases. The inclusion was made\nthrough a bibliographic review, this being the basis for the collection of data\nand pertinent information. The argumentative study that was carried out clearly\nand concisely identified the advantages and disadvantages of the use of ICT in\nsocial support from a psychoeducational and engineering point of view. The\nregions were characterized by the highest concentration of ICT use in the\nsocial support literature, based on previously studied content and analyzing\nthe results of this use.",
    "descriptor": "\nComments: 7 pages, in Spanish language, 5 figures, and 35 direct references\n",
    "authors": [
      "Benjamin A. Huerfano Z.",
      "Andres F Ardila",
      "Pedro L Cifuentes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.11668"
  },
  {
    "id": "arXiv:2205.11673",
    "title": "PCA-Boosted Autoencoders for Nonlinear Dimensionality Reduction in Low  Data Regimes",
    "abstract": "Autoencoders (AE) provide a useful method for nonlinear dimensionality\nreduction but are ill-suited for low data regimes. Conversely, Principal\nComponent Analysis (PCA) is data-efficient but is limited to linear\ndimensionality reduction, posing a problem when data exhibits inherent\nnonlinearity. This presents a challenge in various scientific and engineering\ndomains such as the nanophotonic component design, where data exhibits\nnonlinear features while being expensive to obtain due to costly real\nmeasurements or resource-consuming solutions of partial differential equations.\nTo address this difficulty, we propose a technique that harnesses the best of\nboth worlds: an autoencoder that leverages PCA to perform well on scarce\nnonlinear data. Specifically, we outline a numerically robust PCA-based\ninitialization of AE, which, together with the parameterized ReLU activation\nfunction, allows the training process to start from an exact PCA solution and\nimprove upon it. A synthetic example is presented first to study the effects of\ndata nonlinearity and size on the performance of the proposed method. We then\nevaluate our method on several nanophotonic component design problems where\nobtaining useful data is expensive. To demonstrate universality, we also apply\nit to tasks in other scientific domains: a benchmark breast cancer dataset and\na gene expression dataset.\nWe show that our proposed approach is substantially better than both PCA and\nrandomly initialized AE in the majority of low-data regime cases we consider,\nor at least is comparable to the best of either of the other two methods.",
    "descriptor": "",
    "authors": [
      "Muhammad Al-Digeil",
      "Yuri Grinberg",
      "Daniele Melati3",
      "Mohsen Kamandar Dezfouli",
      "Jens H. Schmid",
      "Pavel Cheben",
      "Siegfried Janz",
      "Dan-Xia Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11673"
  },
  {
    "id": "arXiv:2205.11678",
    "title": "Compressing Deep Graph Neural Networks via Adversarial Knowledge  Distillation",
    "abstract": "Deep graph neural networks (GNNs) have been shown to be expressive for\nmodeling graph-structured data. Nevertheless, the over-stacked architecture of\ndeep graph models makes it difficult to deploy and rapidly test on mobile or\nembedded systems. To compress over-stacked GNNs, knowledge distillation via a\nteacher-student architecture turns out to be an effective technique, where the\nkey step is to measure the discrepancy between teacher and student networks\nwith predefined distance functions. However, using the same distance for graphs\nof various structures may be unfit, and the optimal distance formulation is\nhard to determine. To tackle these problems, we propose a novel Adversarial\nKnowledge Distillation framework for graph models named GraphAKD, which\nadversarially trains a discriminator and a generator to adaptively detect and\ndecrease the discrepancy. Specifically, noticing that the well-captured\ninter-node and inter-class correlations favor the success of deep GNNs, we\npropose to criticize the inherited knowledge from node-level and class-level\nviews with a trainable discriminator. The discriminator distinguishes between\nteacher knowledge and what the student inherits, while the student GNN works as\na generator and aims to fool the discriminator. To our best knowledge, GraphAKD\nis the first to introduce adversarial training to knowledge distillation in\ngraph domains. Experiments on node-level and graph-level classification\nbenchmarks demonstrate that GraphAKD improves the student performance by a\nlarge margin. The results imply that GraphAKD can precisely transfer knowledge\nfrom a complicated teacher GNN to a compact student GNN.",
    "descriptor": "\nComments: Accepted to KDD 2022\n",
    "authors": [
      "Huarui He",
      "Jie Wang",
      "Zhanqiu Zhang",
      "Feng Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11678"
  },
  {
    "id": "arXiv:2205.11680",
    "title": "HiPAL: A Deep Framework for Physician Burnout Prediction Using Activity  Logs in Electronic Health Records",
    "abstract": "Burnout is a significant public health concern affecting nearly half of the\nhealthcare workforce. This paper presents the first end-to-end deep learning\nframework for predicting physician burnout based on clinician activity logs,\ndigital traces of their work activities, available in any electronic health\nrecord (EHR) system. In contrast to prior approaches that exclusively relied on\nsurveys for burnout measurement, our framework directly learns deep workload\nrepresentations from large-scale clinician activity logs to predict burnout. We\npropose the Hierarchical burnout Prediction based on Activity Logs (HiPAL),\nfeaturing a pre-trained time-dependent activity embedding mechanism tailored\nfor activity logs and a hierarchical predictive model, which mirrors the\nnatural hierarchical structure of clinician activity logs and captures\nphysician's evolving workload patterns at both short-term and long-term levels.\nTo utilize the large amount of unlabeled activity logs, we propose a\nsemi-supervised framework that learns to transfer knowledge extracted from\nunlabeled clinician activities to the HiPAL-based prediction model. The\nexperiment on over 15 million clinician activity logs collected from the EHR at\na large academic medical center demonstrates the advantages of our proposed\nframework in predictive performance of physician burnout and training\nefficiency over state of the art approaches.",
    "descriptor": "\nComments: 11 pages including appendices. Accepted by KDD'22\n",
    "authors": [
      "Hanyang Liu",
      "Sunny S. Lou",
      "Benjamin C. Warner",
      "Derek R. Harford",
      "Thomas Kannampallil",
      "Chenyang Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11680"
  },
  {
    "id": "arXiv:2205.11685",
    "title": "A Dataset for Sentence Retrieval for Open-Ended Dialogues",
    "abstract": "We address the task of sentence retrieval for open-ended dialogues. The goal\nis to retrieve sentences from a document corpus that contain information useful\nfor generating the next turn in a given dialogue. Prior work on dialogue-based\nretrieval focused on specific types of dialogues: either conversational QA or\nconversational search. To address a broader scope of this task where any type\nof dialogue can be used, we constructed a dataset that includes open-ended\ndialogues from Reddit, candidate sentences from Wikipedia for each dialogue and\nhuman annotations for the sentences. We report the performance of several\nretrieval baselines, including neural retrieval models, over the dataset. To\nadapt neural models to the types of dialogues in the dataset, we explored an\napproach to induce a large-scale weakly supervised training data from Reddit.\nUsing this training set significantly improved the performance over training on\nthe MS MARCO dataset.",
    "descriptor": "",
    "authors": [
      "Itay Harel",
      "Hagai Taitelbaum",
      "Idan Szpektor",
      "Oren Kurland"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.11685"
  },
  {
    "id": "arXiv:2205.11686",
    "title": "On Advances in Text Generation from Images Beyond Captioning: A Case  Study in Self-Rationalization",
    "abstract": "Integrating vision and language has gained notable attention following the\nsuccess of pretrained language models. Despite that, a fraction of emerging\nmultimodal models is suitable for text generation conditioned on images. This\nminority is typically developed and evaluated for image captioning, a text\ngeneration task conditioned solely on images with the goal to describe what is\nexplicitly visible in an image. In this paper, we take a step back and ask: How\ndo these models work for more complex generative tasks, conditioned on both\ntext and images? Are models based on joint multimodal pretraining, visually\nadapted pretrained language models, or models that combine these two\napproaches, more promising for such tasks? We address these questions in the\ncontext of self-rationalization (jointly generating task labels/answers and\nfree-text explanations) of three tasks: (i) visual question answering in VQA-X,\n(ii) visual commonsense reasoning in VCR, and (iii) visual-textual entailment\nin E-SNLI-VE. We show that recent advances in each modality, CLIP image\nrepresentations and scaling of language models, do not consistently improve\nmultimodal self-rationalization of tasks with multimodal inputs. We also\nobserve that no model type works universally the best across tasks/datasets and\nfinetuning data sizes. Our findings call for a backbone modelling approach that\ncan be built on to advance text generation from images and text beyond image\ncaptioning.",
    "descriptor": "",
    "authors": [
      "Shruti Palaskar",
      "Akshita Bhagia",
      "Yonatan Bisk",
      "Florian Metze",
      "Alan W Black",
      "Ana Marasovic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11686"
  },
  {
    "id": "arXiv:2205.11690",
    "title": "Workflow Discovery from Dialogues in the Low Data Regime",
    "abstract": "Text-based dialogues are now widely used to solve real-world problems. In\ncases where solution strategies are already known, they can sometimes be\ncodified into workflows and used to guide humans or artificial agents through\nthe task of helping clients. We are interested in the situation where a formal\nworkflow may not yet exist, but we wish to discover the steps of actions that\nhave been taken to resolve problems. We examine a novel transformer-based\napproach for this situation and we present experiments where we summarize\ndialogues in the Action-Based Conversations Dataset (ABCD) with workflows.\nSince the ABCD dialogues were generated using known workflows to guide agents\nwe can evaluate our ability to extract such workflows using ground truth\nsequences of action steps, organized as workflows. We propose and evaluate an\napproach that conditions models on the set of allowable action steps and we\nshow that using this strategy we can improve workflow discovery (WD)\nperformance. Our conditioning approach also improves zero-shot and few-shot WD\nperformance when transferring learned models to entirely new domains (i.e. the\nMultiWOZ setting). Further, a modified variant of our architecture achieves\nstate-of-the-art performance on the related but different problems of Action\nState Tracking (AST) and Cascading Dialogue Success (CDS) on the ABCD.",
    "descriptor": "",
    "authors": [
      "Amine El Hattami",
      "Stefania Raimondo",
      "Issam Laradji",
      "David Vazquez",
      "Pau Rodriguez",
      "Chris Pal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11690"
  },
  {
    "id": "arXiv:2205.11691",
    "title": "High-Order Pooling for Graph Neural Networks with Tensor Decomposition",
    "abstract": "Graph Neural Networks (GNNs) are attracting growing attention due to their\neffectiveness and flexibility in modeling a variety of graph-structured data.\nExiting GNN architectures usually adopt simple pooling operations (e.g., sum,\naverage, max) when aggregating messages from a local neighborhood for updating\nnode representation or pooling node representations from the entire graph to\ncompute the graph representation. Though simple and effective, these linear\noperations do not model high-order non-linear interactions among nodes. We\npropose the Tensorized Graph Neural Network (tGNN), a highly expressive GNN\narchitecture relying on tensor decomposition to model high-order non-linear\nnode interactions. tGNN leverages the symmetric CP decomposition to efficiently\nparameterize permutation-invariant multilinear maps for modeling node\ninteractions. Theoretical and empirical analysis on both node and graph\nclassification tasks show the superiority of tGNN over competitive baselines.\nIn particular, tGNN achieves state-of-the-art results on two OGB node\nclassification datasets and one OGB graph classification dataset.",
    "descriptor": "",
    "authors": [
      "Chenqing Hua",
      "Guillaume Rabusseau",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11691"
  },
  {
    "id": "arXiv:2205.11692",
    "title": "TAILOR: Teaching with Active and Incremental Learning for Object  Registration",
    "abstract": "When deploying a robot to a new task, one often has to train it to detect\nnovel objects, which is time-consuming and labor-intensive. We present TAILOR\n-- a method and system for object registration with active and incremental\nlearning. When instructed by a human teacher to register an object, TAILOR is\nable to automatically select viewpoints to capture informative images by\nactively exploring viewpoints, and employs a fast incremental learning\nalgorithm to learn new objects without potential forgetting of previously\nlearned objects. We demonstrate the effectiveness of our method with a KUKA\nrobot to learn novel objects used in a real-world gearbox assembly task through\nnatural interactions.",
    "descriptor": "\nComments: 5 pages, 4 figures, AAAI conference\n",
    "authors": [
      "Qianli Xu",
      "Nicolas Gauthier",
      "Wenyu Liang",
      "Fen Fang",
      "Hui Li Tan",
      "Ying Sun",
      "Yan Wu",
      "Liyuan Li",
      "Joo-Hwee Lim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11692"
  },
  {
    "id": "arXiv:2205.11693",
    "title": "RCC-GAN: Regularized Compound Conditional GAN for Large-Scale Tabular  Data Synthesis",
    "abstract": "This paper introduces a novel generative adversarial network (GAN) for\nsynthesizing large-scale tabular databases which contain various features such\nas continuous, discrete, and binary. Technically, our GAN belongs to the\ncategory of class-conditioned generative models with a predefined conditional\nvector. However, we propose a new formulation for deriving such a vector\nincorporating both binary and discrete features simultaneously. We refer to\nthis noble definition as compound conditional vector and employ it for training\nthe generator network. The core architecture of this network is a three-layered\ndeep residual neural network with skip connections. For improving the stability\nof such complex architecture, we present a regularization scheme towards\nlimiting unprecedented variations on its weight vectors during training. This\nregularization approach is quite compatible with the nature of adversarial\ntraining and it is not computationally prohibitive in runtime. Furthermore, we\nconstantly monitor the variation of the weight vectors for identifying any\npotential instabilities or irregularities to measure the strength of our\nproposed regularizer. Toward this end, we also develop a new metric for\ntracking sudden perturbation on the weight vectors using the singular value\ndecomposition theory. Finally, we evaluate the performance of our proposed\nsynthesis approach on six benchmarking tabular databases, namely Adult, Census,\nHCDR, Cabs, News, and King. The achieved results corroborate that for the\nmajority of the cases, our proposed RccGAN outperforms other conventional and\nmodern generative models in terms of accuracy, stability, and reliability.",
    "descriptor": "\nComments: Paper submitted to IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Mohammad Esmaeilpour",
      "Nourhene Chaalia",
      "Adel Abusitta",
      "Francois-Xavier Devailly",
      "Wissem Maazoun",
      "Patrick Cardinal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.11693"
  },
  {
    "id": "arXiv:2205.11694",
    "title": "All Prime Numbers Have Primitive Roots",
    "abstract": "If p is a prime, then the numbers 1, 2, ..., p-1 form a group under\nmultiplication modulo p. A number g that generates this group is called a\nprimitive root of p; i.e., g is such that every number between 1 and p-1 can be\nwritten as a power of g modulo p. Building on prior work in the ACL2 community,\nthis paper describes a constructive proof that every prime number has a\nprimitive root.",
    "descriptor": "\nComments: In Proceedings ACL2 2022, arXiv:2205.11103\n",
    "authors": [
      "Ruben Gamboa",
      "Woodrow Gamboa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.11694"
  },
  {
    "id": "arXiv:2205.11695",
    "title": "Using ACL2 To Teach Students About Software Testing",
    "abstract": "We report on our experience using ACL2 in the classroom to teach students\nabout software testing. The course COSC2300 at the University of Wyoming is a\nmostly traditional Discrete Mathematics course, but with a clear focus on\ncomputer science applications. For instance, the section on logic and proofs is\nmotivated by the desire to write proofs about computer software. We emphasize\nthat the importance of software correctness falls along a spectrum with casual\nprograms on one end and mission-critical ones on the other. Corresponding to\nthis spectrum is a variety of tools, ranging from unit tests, randomized\ntesting of properties, and even formal proofs. In this paper, we describe one\nof the major activities, in which students use the ACL2 Sedan's counter-example\ngeneration facility to investigate properties of various existing checksum\nalgorithms used in error detection. Students are challenged to state the\nrelevant properties correctly, so that the counter-example generation tool is\nused effectively in all cases, and ACL2 can find formal proofs automatically in\nsome of those.",
    "descriptor": "\nComments: In Proceedings ACL2 2022, arXiv:2205.11103\n",
    "authors": [
      "Ruben Gamboa",
      "Alicia Thoney"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.11695"
  },
  {
    "id": "arXiv:2205.11697",
    "title": "A Mechanized Proof of Bounded Convergence Time for the Distributed  Perimeter Surveillance System (DPSS) Algorithm A",
    "abstract": "The decentralized perimeter surveillance system (DPSS) seeks to provide a\ndecentralized protocol for evenly distributing surveillance of a perimeter over\ntime across an ensemble of unmanned aerial vehicles (UAVs) whose members may\ncommunicate only when in close proximity to each other. The protocol must also\nconverge to an even distribution of the perimeter in bounded time. Two versions\nof the DPSS protocol presented in the original paper seem to converge in\nbounded time but only informal proofs and arguments are given. A later\napplication of model checking to these protocols found an error in one of the\nkey lemmas, invalidating the informal proof for one and casting doubt on the\nother. Therefore, a new hand proof of the convergence time for the simpler\nversion of the DPSS protocol or algorithm, Algorithm A or DPSS-A, was developed\nby Jeremy Avigad and Floris van Doorn. This paper describes a mechanization of\nthat hand proof in the logic of ACL2 and discusses three specific ACL2\nutilities that proved useful for expressing and reasoning about the DPSS model.",
    "descriptor": "\nComments: In Proceedings ACL2 2022, arXiv:2205.11103\n",
    "authors": [
      "David Greve",
      "Jennifer Davis",
      "Laura Humphrey"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.11697"
  },
  {
    "id": "arXiv:2205.11698",
    "title": "VWSIM: A Circuit Simulator",
    "abstract": "VWSIM is a circuit simulator for rapid, single-flux, quantum (RSFQ) circuits.\nThe simulator is designed to model and simulate primitive-circuit devices such\nas capacitors, inductors, Josephson Junctions, and can be extended to simulate\nother circuit families, such as CMOS. Circuit models can be provided in the\nnative VWSIM netlist format or as SPICE-compatible netlists, which are\nflattened and transformed into symbolic equations that can be manipulated and\nsimulated. Written in the ACL2 logic, VWSIM provides logical guarantees about\neach of the circuit models it simulates. Note, our matrix solving and\nevaluation routines use Common Lisp floating-point numbers, and work is ongoing\nto admit these models into ACL2. We currently use VWSIM to help us design\nself-timed, RSFQ-based circuits. Our eventual goal is to prove properties of\nRSFQ circuit models. The ACL2-based definition of the VWSIM simulator offers a\npath for specifying and verifying RSFQ circuit models.",
    "descriptor": "\nComments: In Proceedings ACL2 2022, arXiv:2205.11103\n",
    "authors": [
      "Warren A. Hunt Jr.",
      "Vivek Ramanathan",
      "J Strother Moore"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Mathematical Software (cs.MS)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2205.11698"
  },
  {
    "id": "arXiv:2205.11699",
    "title": "A Free Group of Rotations of Rank 2",
    "abstract": "One of the key steps in the proof of the Banach-Tarski Theorem is the\nintroduction of a free group of rotations. First, a free group of reduced words\nis generated where each element of the set is represented as an ACL2 list. Then\nwe demonstrate that there is a one-to-one relation between the set of reduced\nwords and a set of 3D rotations. In this paper we present a way to generate\nthis set of reduced words and we prove group properties for this set. Then, we\nshow a way to generate a set of 3D matrices using the set of reduced words.\nFinally we show a formalization of 3D rotations and prove that every element of\nthe 3D matrices set is a rotation.",
    "descriptor": "\nComments: In Proceedings ACL2 2022, arXiv:2205.11103\n",
    "authors": [
      "Jagadish Bapanapally",
      "Ruben Gamboa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.11699"
  },
  {
    "id": "arXiv:2205.11700",
    "title": "Modeling Asymptotic Complexity Using ACL2",
    "abstract": "The theory of asymptotic complexity provides an approach to characterizing\nthe behavior of programs in terms of bounds on the number of computational\nsteps executed or use of computational resources. We describe work using ACL2\nto prove complexity properties of programs implemented in a simple imperative\nprogramming language embedding via an operational semantics in ACL2. We\nsimultaneously prove functional properties of a program and its complexity. We\nillustrate our approach by describing proofs about a binary search algorithm,\nproving both that it implements binary search on a sorted list and that it is\nO(log(n)), where n is the length of the list.",
    "descriptor": "\nComments: In Proceedings ACL2 2022, arXiv:2205.11103\n",
    "authors": [
      "William D. Young"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.11700"
  },
  {
    "id": "arXiv:2205.11702",
    "title": "Functional Network: A Novel Framework for Interpretability of Deep  Neural Networks",
    "abstract": "The layered structure of deep neural networks hinders the use of numerous\nanalysis tools and thus the development of its interpretability. Inspired by\nthe success of functional brain networks, we propose a novel framework for\ninterpretability of deep neural networks, that is, the functional network. We\nconstruct the functional network of fully connected networks and explore its\nsmall-worldness. In our experiments, the mechanisms of regularization methods,\nnamely, batch normalization and dropout, are revealed using graph theoretical\nanalysis and topological data analysis. Our empirical analysis shows the\nfollowing: (1) Batch normalization enhances model performance by increasing the\nglobal e ciency and the number of loops but reduces adversarial robustness by\nlowering the fault tolerance. (2) Dropout improves generalization and\nrobustness of models by improving the functional specialization and fault\ntolerance. (3) The models with dierent regularizations can be clustered\ncorrectly according to their functional topological dierences, re ecting the\ngreat potential of the functional network and topological data analysis in\ninterpretability.",
    "descriptor": "",
    "authors": [
      "Ben Zhang",
      "Zhetong Dong",
      "Junsong Zhang",
      "Hongwei Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11702"
  },
  {
    "id": "arXiv:2205.11703",
    "title": "Verified Implementation of an Efficient Term-Rewriting Algorithm for  Multiplier Verification on ACL2",
    "abstract": "Automatic and efficient verification of multiplier designs, especially\nthrough a provably correct method, is a difficult problem. We show how to\nutilize a theorem prover, ACL2, to implement an efficient rewriting algorithm\nfor multiplier design verification. Through a basic understanding of the\nfeatures and data structures of ACL2, we created a verified program that can\nautomatically verify various multiplier designs much faster than the other\nstate-of-the-art tools. Additionally, users of our system have the flexibility\nto change the specification for the target design to verify variations of\nmultipliers. We discuss the challenges we tackled during the development of\nthis program as well as key implementation details for efficiency and\nverifiability. Those who plan to implement an efficient program on a theorem\nprover or those who wish to implement our multiplier verification methodology\non a different system may benefit from the discussions in this paper.",
    "descriptor": "\nComments: In Proceedings ACL2 2022, arXiv:2205.11103\n",
    "authors": [
      "Mertcan Temel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.11703"
  },
  {
    "id": "arXiv:2205.11704",
    "title": "ACL2s Systems Programming",
    "abstract": "ACL2 provides a systems programming capability that allows one to write code\nthat uses and extends ACL2 inside of ACL2. However, for soundness reasons, ACL2\nbars the unrestricted use of certain kinds of programming constructs, like\ndestructive updates, higher-order functions, eval, and arbitrary macros. We\ndevised a methodology for writing code in Common Lisp that allows one to access\nACL2, ACL2s, and Common Lisp functionality in a unified way. We arrived at this\nmethodology in the process of developing the ACL2 Sedan (ACL2s) and using it as\na key component in formal-methods-enabled projects relating to gamified\nverification, education, proof checking, interfacing with external theorem\nprovers and security. The methodology includes a library for performing ACL2\nqueries from Common Lisp, as well as guidelines and utilities that help address\ncommon needs. We call this methodology \"ACL2s systems programming,\" to\ndistinguish it from ACL2 systems programming. We show how our methodology makes\nit possible to easily develop tools that interface with ACL2 and ACL2s, and\ndescribe our experience using it in our research.",
    "descriptor": "\nComments: In Proceedings ACL2 2022, arXiv:2205.11103\n",
    "authors": [
      "Andrew T. Walter",
      "Panagiotis Manolios"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.11704"
  },
  {
    "id": "arXiv:2205.11705",
    "title": "M6-Fashion: High-Fidelity Multi-modal Image Generation and Editing",
    "abstract": "The fashion industry has diverse applications in multi-modal image generation\nand editing. It aims to create a desired high-fidelity image with the\nmulti-modal conditional signal as guidance. Most existing methods learn\ndifferent condition guidance controls by introducing extra models or ignoring\nthe style prior knowledge, which is difficult to handle multiple signal\ncombinations and faces a low-fidelity problem. In this paper, we adapt both\nstyle prior knowledge and flexibility of multi-modal control into one unified\ntwo-stage framework, M6-Fashion, focusing on the practical AI-aided Fashion\ndesign. It decouples style codes in both spatial and semantic dimensions to\nguarantee high-fidelity image generation in the first stage. M6-Fashion\nutilizes self-correction for the non-autoregressive generation to improve\ninference speed, enhance holistic consistency, and support various signal\ncontrols. Extensive experiments on a large-scale clothing dataset M2C-Fashion\ndemonstrate superior performances on various image generation and editing\ntasks. M6-Fashion model serves as a highly potential AI designer for the\nfashion industry.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.14211\n",
    "authors": [
      "Zhikang Li",
      "Huiling Zhou",
      "Shuai Bai",
      "Peike Li",
      "Chang Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2205.11705"
  },
  {
    "id": "arXiv:2205.11706",
    "title": "Syntheto: A Surface Language for APT and ACL2",
    "abstract": "Syntheto is a surface language for carrying out formally verified program\nsynthesis by transformational refinement in ACL2 using the APT toolkit.\nSyntheto aims at providing more familiarity and automation, in order to make\nthis technology more widely usable. Syntheto is a strongly statically typed\nfunctional language that includes both executable and non-executable\nconstructs, including facilities to state and prove theorems and facilities to\napply proof-generating transformations. Syntheto is integrated into an IDE with\na notebook-style, interactive interface that translates Syntheto to ACL2\ndefinitions and APT transformation invocations, and back-translates the\nprover's results to Syntheto; the bidirectional translation happens behind the\nscenes, with the user interacting solely with Syntheto.",
    "descriptor": "\nComments: In Proceedings ACL2 2022, arXiv:2205.11103\n",
    "authors": [
      "Alessandro Coglio",
      "Eric McCarthy",
      "Stephen Westfold",
      "Daniel Balasubramanian",
      "Abhishek Dubey",
      "Gabor Karsai"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.11706"
  },
  {
    "id": "arXiv:2205.11707",
    "title": "A Complex Java Code Generator for ACL2 Based on a Shallow Embedding of  ACL2 in Java",
    "abstract": "This paper describes a code generator that translates ACL2 constructs to\ncorresponding Java constructs, according to a shallow embedding of ACL2 in\nJava. Starting from purely functional ACL2 code, the generated Java code\nexhibits imperative and object-oriented features like destructive updates,\nloops, and overloading. The overall translation from ACL2 to Java is fairly\nelaborate, consisting of several ACL2-to-ACL2 pre-translation steps, an\nACL2-to-Java proper translation step, and several Java-to-Java post-translation\nsteps. Experiments suggest that the generated Java code is not much slower than\nthe ACL2 code. The code generator can also recognize, and translate to Java,\nACL2 representations of certain Java constructs, forerunning a code generation\napproach based on a shallow embedding of Java in ACL2 (i.e. going the other\nway). This code generator builds upon, and significantly extends, a simple Java\ncode generator for ACL2 based on a deep embedding of ACL2 in Java.",
    "descriptor": "\nComments: In Proceedings ACL2 2022, arXiv:2205.11103\n",
    "authors": [
      "Alessandro Coglio"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.11707"
  },
  {
    "id": "arXiv:2205.11708",
    "title": "A Proof-Generating C Code Generator for ACL2 Based on a Shallow  Embedding of C in ACL2",
    "abstract": "This paper describes a C code generator for ACL2 that recognizes ACL2\nrepresentations of C constructs, according to a shallow embedding of C in ACL2,\nand translates those representations to the represented C constructs. The code\ngenerator also generates ACL2 theorems asserting the correctness of the C code\nwith respect to the ACL2 code. The code generator currently supports a limited\nbut growing subset of C that already suffices for some interesting programs.\nThis paper also offers a general perspective on language embedding and code\ngeneration.",
    "descriptor": "\nComments: In Proceedings ACL2 2022, arXiv:2205.11103\n",
    "authors": [
      "Alessandro Coglio"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.11708"
  },
  {
    "id": "arXiv:2205.11709",
    "title": "Hardware/Software Co-Assurance using the Rust Programming Language and  ACL2",
    "abstract": "The Rust programming language has garnered significant interest and use as a\nmodern, type-safe, memory-safe, and potentially formally analyzable programming\nlanguage. Our interest in Rust stems from its potential as a hardware/software\nco-assurance language, with application to critical systems such as autonomous\nvehicles. We report on the first known use of Rust as a High-Level Synthesis\n(HLS) language. Most incumbent HLS languages are a subset of C. A Rust-based\nHLS brings a single modern, type-safe, and memory-safe expression language for\nboth hardware and software realizations with high assurance. As a a study of\nthe suitability of Rust as an HLS, we have crafted a Rust subset, inspired by\nRussinoff's Restricted Algorithmic C (RAC), which we have imaginatively named\nRestricted Algorithmic Rust, or RAR. In our first implementation of a RAR\ntoolchain, we simply transpile the RAR source into RAC. By so doing, we\nleverage a number of existing hardware/software co-assurance tools with a\nminimum investment of time and effort. In this paper, we describe the RAR Rust\nsubset, detail our prototype RAR toolchain, and describe the implementation and\nverification of several representative algorithms and data structures written\nin RAR, with proofs of correctness conducted using the ACL2 theorem prover.",
    "descriptor": "\nComments: In Proceedings ACL2 2022, arXiv:2205.11103\n",
    "authors": [
      "David Hardin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.11709"
  },
  {
    "id": "arXiv:2205.11710",
    "title": "SCVRL: Shuffled Contrastive Video Representation Learning",
    "abstract": "We propose SCVRL, a novel contrastive-based framework for self-supervised\nlearning for videos. Differently from previous contrast learning based methods\nthat mostly focus on learning visual semantics (e.g., CVRL), SCVRL is capable\nof learning both semantic and motion patterns. For that, we reformulate the\npopular shuffling pretext task within a modern contrastive learning paradigm.\nWe show that our transformer-based network has a natural capacity to learn\nmotion in self-supervised settings and achieves strong performance,\noutperforming CVRL on four benchmarks.",
    "descriptor": "\nComments: CVPR 2022 - L3DIVU workshop\n",
    "authors": [
      "Michael Dorkenwald",
      "Fanyi Xiao",
      "Biagio Brattoli",
      "Joseph Tighe",
      "Davide Modolo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11710"
  },
  {
    "id": "arXiv:2205.11713",
    "title": "Thalamus: a brain-inspired algorithm for biologically-plausible  continual learning and disentangled representations",
    "abstract": "Animals thrive in a constantly changing environment and leverage the temporal\nstructure to learn well-factorized causal representations. In contrast,\ntraditional neural networks suffer from forgetting in changing environments and\nmany methods have been proposed to limit forgetting with different trade-offs.\nInspired by the brain thalamocortical circuit, we introduce a simple algorithm\nthat uses optimization at inference time to generate internal representations\nof temporal context and to infer current context dynamically, allowing the\nagent to parse the stream of temporal experience into discrete events and\norganize learning about them. We show that a network trained on a series of\ntasks using traditional weight updates can infer tasks dynamically using\ngradient descent steps in the latent task embedding space (latent updates). We\nthen alternate between the weight updates and the latent updates to arrive at\nThalamus, a task-agnostic algorithm capable of discovering disentangled\nrepresentations in a stream of unlabeled tasks using simple gradient descent.\nOn a continual learning benchmark, it achieves competitive end average accuracy\nand demonstrates knowledge transfer. After learning a subset of tasks it can\ngeneralize to unseen tasks as they become reachable within the well-factorized\nlatent space, through one-shot latent updates. The algorithm meets many of the\ndesiderata of an ideal continually learning agent in open-ended environments,\nand its simplicity suggests fundamental computations in circuits with abundant\nfeedback control loops such as the thalamocortical circuits in the brain.",
    "descriptor": "\nComments: Submitted to NeurIPS 2022\n",
    "authors": [
      "Ali Hummos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.11713"
  },
  {
    "id": "arXiv:2205.11716",
    "title": "Randomly Initialized One-Layer Neural Networks Make Data Linearly  Separable",
    "abstract": "Recently, neural networks have been shown to perform exceptionally well in\ntransforming two arbitrary sets into two linearly separable sets. Doing this\nwith a randomly initialized neural network is of immense interest because the\nassociated computation is cheaper than using fully trained networks. In this\npaper, we show that, with sufficient width, a randomly initialized one-layer\nneural network transforms two sets into two linearly separable sets with high\nprobability. Furthermore, we provide explicit bounds on the required width of\nthe neural network for this to occur. Our first bound is exponential in the\ninput dimension and polynomial in all other parameters, while our second bound\nis independent of the input dimension, thereby overcoming the curse of\ndimensionality. We also perform an experimental study comparing the separation\ncapacity of randomly initialized one-layer and two-layer neural networks. With\ncorrectly chosen biases, our study shows for low-dimensional data, the\ntwo-layer neural network outperforms the one-layer network. However, the\nopposite is observed for higher-dimensional data.",
    "descriptor": "",
    "authors": [
      "Promit Ghosal",
      "Srinath Mahankali",
      "Yihang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.11716"
  },
  {
    "id": "arXiv:2205.11718",
    "title": "Semi-Parametric Deep Neural Networks in Linear Time and Memory",
    "abstract": "Recent advances in deep learning have been driven by large-scale parametric\nmodels, which can be computationally expensive and lack interpretability.\nSemi-parametric methods query the training set at inference time and can be\nmore compact, although they typically have quadratic computational complexity.\nHere, we introduce SPIN, a general-purpose semi-parametric neural architecture\nwhose computational cost is linear in the size and dimensionality of the data.\nOur architecture is inspired by inducing point methods and relies on a novel\napplication of cross-attention between datapoints. At inference time, its\ncomputational cost is constant in the training set size as the data gets\ndistilled into a fixed number of inducing points. We find that our method\nreduces the computational requirements of existing semi-parametric models by up\nto an order of magnitude across a range of datasets and improves\nstate-of-the-art performance on an important practical problem, genotype\nimputation.",
    "descriptor": "",
    "authors": [
      "Richa Rastogi",
      "Yuntian Deng",
      "Ian Lee",
      "Mert R. Sabuncu",
      "Volodymyr Kuleshov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11718"
  },
  {
    "id": "arXiv:2205.11719",
    "title": "Safe, Occlusion-Aware Manipulation for Online Object Reconstruction in  Confined Spaces",
    "abstract": "Recent work in robotic manipulation focuses on object retrieval in cluttered\nspace under occlusion. Nevertheless, the majority of efforts lack an analysis\nof conditions for the completeness of the approaches or the methods apply only\nwhen objects can be removed from the workspace. This work formulates the\ngeneral, occlusion-aware manipulation task, and focuses on safe object\nreconstruction in a confined space with in-place relocation. A framework that\nensures safety with completeness guarantees is proposed. Furthermore, an\nalgorithm, which is an instantiation of this framework for monotone instances,\nis developed and evaluated empirically by comparing against a random and a\ngreedy baseline on randomly generated experiments in simulation. Even for\ncluttered scenes with realistic objects, the proposed algorithm significantly\noutperforms the baselines and maintains a high success rate across experimental\nconditions.",
    "descriptor": "",
    "authors": [
      "Yinglong Miao",
      "Rui Wang",
      "Kostas Bekris"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.11719"
  },
  {
    "id": "arXiv:2205.11720",
    "title": "Embedding Neighborhoods Simultaneously t-SNE (ENS-t-SNE)",
    "abstract": "We propose an algorithm for visualizing a dataset by embedding it in\n3-dimensional Euclidean space based on various given distances between the same\npairs of datapoints. Its aim is to find an Embedding which preserves\nNeighborhoods Simultaneously for all given distances by generalizing the\nt-Stochastic Neighborhood Embedding approach (ENS-t-SNE). We illustrate the\nutility of ENS-t-SNE by demonstrating its use in three applications. First, to\nvisualize different notions of clusters and groups within the same\nhigh-dimensional dataset with one 3-dimensional embedding, as opposed to\nproviding different embeddings of the same data and trying to match the\ncorresponding points. Second, to illustrate the effects of different\nhyper-parameters of the classical t-SNE. Third, by considering multiple\ndifferent notions of clustering in data, ENS-t-SNE can generate an alternative\nembedding than the classic t-SNE. We provide an extensive quantitative\nevaluation with real-world and synthetic datasets of different sizes and using\ndifferent numbers of projections.",
    "descriptor": "",
    "authors": [
      "Vahan Huroyan",
      "Raymundo Navarrete",
      "Md Iqbal Hossain",
      "Stephen Kobourov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.11720"
  },
  {
    "id": "arXiv:2205.11721",
    "title": "Delayed Coding Scheme for Channels with Insertion, Deletion, and  Substitution Errors",
    "abstract": "We propose a new coding scheme, called the delayed coding (DC) scheme, for\nchannels with insertion, deletion, and substitution (IDS) errors. The proposed\nscheme employs delayed encoding and non-iterative detection and decoding\nstrategies to manage the transmission of multiple codewords in a linear code.\nIn the DC scheme, a channel input sequence consists of subblocks of multiple\ncodewords from the previous to current time instances. At the receiver side,\nthe maximum a posteriori detection applies to the received sequences that\ncontain information of the codeword at the current time instance, where priorly\ndecoded codewords aid the detection. The channel code decoding is then\nperformed, and extrinsic messages are exploited for the codeword estimations of\nthe following time instances. We show that the rate achievable with the DC\nscheme over the IDS channel approaches the symmetric information rate of the\nchannel. Moreover, we show the excellent asymptotic and finite-length\nperformances of the DC scheme in conjunction with low-density parity-check\ncodes.",
    "descriptor": "\nComments: Submitted to IEEE conference\n",
    "authors": [
      "Ryo Shibata",
      "Hiroyuki Yashima"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.11721"
  },
  {
    "id": "arXiv:2205.11722",
    "title": "Deep Geometric Moment",
    "abstract": "Deep networks for image classification often rely more on texture information\nthan object shape. While efforts have been made to make deep-models\nshape-aware, it is often difficult to make such models simple, interpretable,\nor rooted in known mathematical definitions of shape. This paper presents a\ndeep-learning model inspired by geometric moments, a classically well\nunderstood approach to measure shape-related properties. The proposed method\nconsists of a trainable network for generating coordinate bases and affine\nparameters for making the features geometrically invariant, yet in a\ntask-specific manner. The proposed model improves the final feature's\ninterpretation. We demonstrate the effectiveness of our method on standard\nimage classification datasets. The proposed model achieves higher\nclassification performance as compared to the baseline and standard ResNet\nmodels while substantially improving interpretability.",
    "descriptor": "",
    "authors": [
      "Rajhans Singh",
      "Ankita Shukla",
      "Pavan Turaga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11722"
  },
  {
    "id": "arXiv:2205.11725",
    "title": "A Survey on Neural Open Information Extraction: Current Status and  Future Directions",
    "abstract": "Open Information Extraction (OpenIE) facilitates domain-independent discovery\nof relational facts from large corpora. The technique well suits many\nopen-world natural language understanding scenarios, such as automatic\nknowledge base construction, open-domain question answering, and explicit\nreasoning. Thanks to the rapid development in deep learning technologies,\nnumerous neural OpenIE architectures have been proposed and achieve\nconsiderable performance improvement. In this survey, we provide an extensive\noverview of the-state-of-the-art neural OpenIE models, their key design\ndecisions, strengths and weakness. Then, we discuss limitations of current\nsolutions and the open issues in OpenIE problem itself. Finally we list recent\ntrends that could help expand its scope and applicability, setting up promising\ndirections for future research in OpenIE. To our best knowledge, this paper is\nthe first review on this specific topic.",
    "descriptor": "\nComments: Accepted by IJCAI22 survey track\n",
    "authors": [
      "Shaowen Zhou",
      "Bowen Yu",
      "Aixin Sun",
      "Cheng Long",
      "Jingyang Li",
      "Jian Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11725"
  },
  {
    "id": "arXiv:2205.11726",
    "title": "On the Role of Bidirectionality in Language Model Pre-Training",
    "abstract": "Prior work on language model pre-training has explored different\narchitectures and learning objectives, but differences in data, hyperparameters\nand evaluation make a principled comparison difficult. In this work, we focus\non bidirectionality as a key factor that differentiates existing approaches,\nand present a comprehensive study of its role in next token prediction, text\ninfilling, zero-shot priming and fine-tuning. We propose a new framework that\ngeneralizes prior approaches, including fully unidirectional models like GPT,\nfully bidirectional models like BERT, and hybrid models like CM3 and prefix LM.\nOur framework distinguishes between two notions of bidirectionality\n(bidirectional context and bidirectional attention) and allows us to control\neach of them separately. We find that the optimal configuration is largely\napplication-dependent (e.g., bidirectional attention is beneficial for\nfine-tuning and infilling, but harmful for next token prediction and zero-shot\npriming). We train models with up to 6.7B parameters, and find differences to\nremain consistent at scale. While prior work on scaling has focused on\nleft-to-right autoregressive models, our results suggest that this approach\ncomes with some trade-offs, and it might be worthwhile to develop very large\nbidirectional models.",
    "descriptor": "",
    "authors": [
      "Mikel Artetxe",
      "Jingfei Du",
      "Naman Goyal",
      "Luke Zettlemoyer",
      "Ves Stoyanov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11726"
  },
  {
    "id": "arXiv:2205.11728",
    "title": "ItemSage: Learning Product Embeddings for Shopping Recommendations at  Pinterest",
    "abstract": "Learned embeddings for products are an important building block for web-scale\ne-commerce recommendation systems. At Pinterest, we build a single set of\nproduct embeddings called ItemSage to provide relevant recommendations in all\nshopping use cases including user, image and search based recommendations. This\napproach has led to significant improvements in engagement and conversion\nmetrics, while reducing both infrastructure and maintenance cost. While most\nprior work focuses on building product embeddings from features coming from a\nsingle modality, we introduce a transformer-based architecture capable of\naggregating information from both text and image modalities and show that it\nsignificantly outperforms single modality baselines. We also utilize multi-task\nlearning to make ItemSage optimized for several engagement types, leading to a\ncandidate generation system that is efficient for all of the engagement\nobjectives of the end-to-end recommendation system. Extensive offline\nexperiments are conducted to illustrate the effectiveness of our approach and\nresults from online A/B experiments show substantial gains in key business\nmetrics (up to +7% gross merchandise value/user and +11% click volume).",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Paul Baltescu",
      "Haoyu Chen",
      "Nikil Pancha",
      "Andrew Zhai",
      "Jure Leskovec",
      "Charles Rosenberg"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11728"
  },
  {
    "id": "arXiv:2205.11729",
    "title": "From Easy to Hard: Two-stage Selector and Reader for Multi-hop Question  Answering",
    "abstract": "Multi-hop question answering (QA) is a challenging task requiring QA systems\nto perform complex reasoning over multiple documents and provide supporting\nfacts together with the exact answer. Existing works tend to utilize\ngraph-based reasoning and question decomposition to obtain the reasoning chain,\nwhich inevitably introduces additional complexity and cumulative error to the\nsystem. To address the above issue, we propose a simple yet effective novel\nframework, From Easy to Hard (FE2H), to remove distracting information and\nobtain better contextual representations for the multi-hop QA task. Inspired by\nthe iterative document selection process and the progressive learning custom of\nhumans, FE2H divides both the document selector and reader into two stages\nfollowing an easy-to-hard manner. Specifically, we first select the document\nmost relevant to the question and then utilize the question together with this\ndocument to select other pertinent documents. As for the QA phase, our reader\nis first trained on a single-hop QA dataset and then transferred into the\nmulti-hop QA task. We comprehensively evaluate our model on the popular\nmulti-hop QA benchmark HotpotQA. Experimental results demonstrate that our\nmethod ourperforms all other methods in the leaderboard of HotpotQA (distractor\nsetting).",
    "descriptor": "",
    "authors": [
      "Xin-Yi Li",
      "Wei-Jun Lei",
      "Yu-Bin Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11729"
  },
  {
    "id": "arXiv:2205.11733",
    "title": "Single-View View Synthesis in the Wild with Learned Adaptive Multiplane  Images",
    "abstract": "This paper deals with the challenging task of synthesizing novel views for\nin-the-wild photographs. Existing methods have shown promising results\nleveraging monocular depth estimation and color inpainting with layered depth\nrepresentations. However, these methods still have limited capability to handle\nscenes with complex 3D geometry. We propose a new method based on the\nmultiplane image (MPI) representation. To accommodate diverse scene layouts in\nthe wild and tackle the difficulty in producing high-dimensional MPI contents,\nwe design a network structure that consists of two novel modules, one for plane\ndepth adjustment and another for depth-aware color prediction. The former\nadjusts the initial plane positions using the RGBD context feature and an\nattention mechanism. Given adjusted depth values, the latter predicts the color\nand density for each plane separately with proper inter-plane interactions\nachieved via a feature masking strategy. To train our method, we construct\nlarge-scale stereo training data using only unconstrained single-view image\ncollections by a simple yet effective warp-back strategy. The experiments on\nboth synthetic and real datasets demonstrate that our trained model works\nremarkably well and achieves state-of-the-art results.",
    "descriptor": "\nComments: ACM SIGGRAPH 2022. Project page: this https URL\n",
    "authors": [
      "Yuxuan Han",
      "Ruicheng Wang",
      "Jiaolong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.11733"
  },
  {
    "id": "arXiv:2205.11736",
    "title": "Towards a Defense against Backdoor Attacks in Continual Federated  Learning",
    "abstract": "Backdoor attacks are a major concern in federated learning (FL) pipelines\nwhere training data is sourced from untrusted clients over long periods of time\n(i.e., continual learning). Preventing such attacks is difficult because\ndefenders in FL do not have access to raw training data. Moreover, in a\nphenomenon we call backdoor leakage, models trained continuously eventually\nsuffer from backdoors due to cumulative errors in backdoor defense mechanisms.\nWe propose a novel framework for defending against backdoor attacks in the\nfederated continual learning setting. Our framework trains two models in\nparallel: a backbone model and a shadow model. The backbone is trained without\nany defense mechanism to obtain good performance on the main task. The shadow\nmodel combines recent ideas from robust covariance estimation-based filters\nwith early-stopping to control the attack success rate even as the data\ndistribution changes. We provide theoretical motivation for this design and\nshow experimentally that our framework significantly improves upon existing\ndefenses against backdoor attacks.",
    "descriptor": "",
    "authors": [
      "Shuaiqi Wang",
      "Jonathan Hayase",
      "Giulia Fanti",
      "Sewoong Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.11736"
  },
  {
    "id": "arXiv:2205.11737",
    "title": "PERT: A New Solution to Pinyin to Character Conversion Task",
    "abstract": "Pinyin to Character conversion (P2C) task is the key task of Input Method\nEngine (IME) in commercial input software for Asian languages, such as Chinese,\nJapanese, Thai language and so on. It's usually treated as sequence labelling\ntask and resolved by language model, i.e. n-gram or RNN. However, the low\ncapacity of the n-gram or RNN limits its performance. This paper introduces a\nnew solution named PERT which stands for bidirectional Pinyin Encoder\nRepresentations from Transformers. It achieves significant improvement of\nperformance over baselines. Furthermore, we combine PERT with n-gram under a\nMarkov framework, and improve performance further. Lastly, the external lexicon\nis incorporated into PERT so as to resolve the OOD issue of IME.",
    "descriptor": "",
    "authors": [
      "Jinghui Xiao",
      "Qun Liu",
      "Xin Jiang",
      "Yuanfeng Xiong",
      "Haiteng Wu",
      "Zhe Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11737"
  },
  {
    "id": "arXiv:2205.11738",
    "title": "Adaptive Few-Shot Learning Algorithm for Rare Sound Event Detection",
    "abstract": "Sound event detection is to infer the event by understanding the surrounding\nenvironmental sounds. Due to the scarcity of rare sound events, it becomes\nchallenging for the well-trained detectors which have learned too much prior\nknowledge. Meanwhile, few-shot learning methods promise a good generalization\nability when facing a new limited-data task. Recent approaches have achieved\npromising results in this field. However, these approaches treat each support\nexample independently, ignoring the information of other examples from the\nwhole task. Because of this, most of previous methods are constrained to\ngenerate a same feature embedding for all test-time tasks, which is not\nadaptive to each inputted data. In this work, we propose a novel task-adaptive\nmodule which is easy to plant into any metric-based few-shot learning\nframeworks. The module could identify the task-relevant feature dimension.\nIncorporating our module improves the performance considerably on two datasets\nover baseline methods, especially for the transductive propagation network.\nSuch as +6.8% for 5-way 1-shot accuracy on ESC-50, and +5.9% on noiseESC-50. We\ninvestigate our approach in the domain-mismatch setting and also achieve better\nresults than previous methods.",
    "descriptor": "\nComments: Accepted to IJCNN 2022. arXiv admin note: text overlap with arXiv:2110.04474 by other authors\n",
    "authors": [
      "Chendong Zhao",
      "Jianzong Wang",
      "Leilai Li",
      "Xiaoyang Qu",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.11738"
  },
  {
    "id": "arXiv:2205.11739",
    "title": "Deep Learning Meets Software Engineering: A Survey on Pre-Trained Models  of Source Code",
    "abstract": "Recent years have seen the successful application of deep learning to\nsoftware engineering (SE). In particular, the development and use of\npre-trained models of source code has enabled state-of-the-art results to be\nachieved on a wide variety of SE tasks. This paper provides an overview of this\nrapidly advancing field of research and reflects on future research directions.",
    "descriptor": "\nComments: IJCAI 2022: Survey Track\n",
    "authors": [
      "Changan Niu",
      "Chuanyi Li",
      "Bin Luo",
      "Vincent Ng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11739"
  },
  {
    "id": "arXiv:2205.11740",
    "title": "Trends in Workplace Wearable Technologies and Connected-Worker Solutions  for Next-Generation Occupational Safety, Health, and Productivity",
    "abstract": "The workplace influences the safety, health, and productivity of workers at\nmultiple levels. To protect and promote total worker health, smart hardware,\nand software tools have emerged for the identification, elimination,\nsubstitution, and control of occupational hazards. Wearable devices enable\nconstant monitoring of individual workers and the environment, whereas\nconnected worker solutions provide contextual information and decision support.\nHere, the recent trends in commercial workplace technologies to monitor and\nmanage occupational risks, injuries, accidents, and diseases are reviewed.\nWorkplace safety wearables for safe lifting, ergonomics, hazard identification,\nsleep monitoring, fatigue management, and heat and cold stress are discussed.\nExamples of workplace productivity wearables for asset tracking, augmented\nreality, gesture and motion control, brain wave sensing, and work stress\nmanagement are given. Workplace health wearables designed for work-related\nmusculoskeletal disorders, functional movement disorders, respiratory hazards,\ncardiovascular health, outdoor sun exposure, and continuous glucose monitoring\nare shown. Connected worker platforms are discussed with information about the\narchitecture, system modules, intelligent operations, and industry\napplications. Predictive analytics provide contextual information about\noccupational safety risks, resource allocation, equipment failure, and\npredictive maintenance. Altogether, these examples highlight the ground-level\nbenefits of real-time visibility about frontline workers, work environment,\ndistributed assets, workforce efficiency, and safety compliance",
    "descriptor": "",
    "authors": [
      "Vishal Patel",
      "Austin Chesmore",
      "Christopher M. Legner",
      "Santosh Pandey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11740"
  },
  {
    "id": "arXiv:2205.11743",
    "title": "Demand Response Method Considering Multiple Types of Flexible Loads in  Industrial Parks",
    "abstract": "With the rapid development of the energy internet, the proportion of flexible\nloads in smart grid is getting much higher than before. It is highly important\nto model flexible loads based on demand response. Therefore, a new demand\nresponse method considering multiple flexible loads is proposed in this paper\nto character the integrated demand response (IDR) resources. Firstly, a\nphysical process analytical deduction (PPAD) model is proposed to improve the\nclassification of flexible loads in industrial parks. Scenario generation, data\npoint augmentation, and smooth curves under various operating conditions are\nconsidered to enhance the applicability of the model. Secondly, in view of the\nstrong volatility and poor modeling effect of Wasserstein-generative\nadversarial networks (WGAN), an improved WGAN-gradient penalty (IWGAN-GP) model\nis developed to get a faster convergence speed than traditional WGAN and\ngenerate a higher quality samples. Finally, the PPAD and IWGAN-GP models are\njointly implemented to reveal the degree of correlation between flexible loads.\nMeanwhile, an intelligent offline database is built to deal with the impact of\nnonlinear factors in different response scenarios. Numerical examples have been\nperformed with the results proving that the proposed method is significantly\nbetter than the existing technologies in reducing load modeling deviation and\nimproving the responsiveness of park loads.",
    "descriptor": "\nComments: Submitted to Expert Systems with Applications\n",
    "authors": [
      "Jia Cui",
      "Mingze Gao",
      "Xiaoming Zhou",
      "Yang Li",
      "Wei Liu",
      "Jiazheng Tian",
      "Ximing Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11743"
  },
  {
    "id": "arXiv:2205.11744",
    "title": "Alleviating Robust Overfitting of Adversarial Training With Consistency  Regularization",
    "abstract": "Adversarial training (AT) has proven to be one of the most effective ways to\ndefend Deep Neural Networks (DNNs) against adversarial attacks. However, the\nphenomenon of robust overfitting, i.e., the robustness will drop sharply at a\ncertain stage, always exists during AT. It is of great importance to decrease\nthis robust generalization gap in order to obtain a robust model. In this\npaper, we present an in-depth study towards the robust overfitting from a new\nangle. We observe that consistency regularization, a popular technique in\nsemi-supervised learning, has a similar goal as AT and can be used to alleviate\nrobust overfitting. We empirically validate this observation, and find a\nmajority of prior solutions have implicit connections to consistency\nregularization. Motivated by this, we introduce a new AT solution, which\nintegrates the consistency regularization and Mean Teacher (MT) strategy into\nAT. Specifically, we introduce a teacher model, coming from the average weights\nof the student models over the training steps. Then we design a consistency\nloss function to make the prediction distribution of the student models over\nadversarial examples consistent with that of the teacher model over clean\nsamples. Experiments show that our proposed method can effectively alleviate\nrobust overfitting and improve the robustness of DNN models against common\nadversarial attacks.",
    "descriptor": "",
    "authors": [
      "Shudong Zhang",
      "Haichang Gao",
      "Tianwei Zhang",
      "Yunyi Zhou",
      "Zihui Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11744"
  },
  {
    "id": "arXiv:2205.11747",
    "title": "BabyBear: Cheap inference triage for expensive language models",
    "abstract": "Transformer language models provide superior accuracy over previous models\nbut they are computationally and environmentally expensive. Borrowing the\nconcept of model cascading from computer vision, we introduce BabyBear, a\nframework for cascading models for natural language processing (NLP) tasks to\nminimize cost. The core strategy is inference triage, exiting early when the\nleast expensive model in the cascade achieves a sufficiently high-confidence\nprediction. We test BabyBear on several open source data sets related to\ndocument classification and entity recognition. We find that for common NLP\ntasks a high proportion of the inference load can be accomplished with cheap,\nfast models that have learned by observing a deep learning model. This allows\nus to reduce the compute cost of large-scale classification jobs by more than\n50% while retaining overall accuracy. For named entity recognition, we save 33%\nof the deep learning compute while maintaining an F1 score higher than 95% on\nthe CoNLL benchmark.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Leila Khalili",
      "Yao You",
      "John Bohannon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.11747"
  },
  {
    "id": "arXiv:2205.11748",
    "title": "Deep Learning-based automated classification of Chinese Speech Sound  Disorders",
    "abstract": "This article describes a system for analyzing acoustic data in order to\nassist in the diagnosis and classification of children's speech disorders using\na computer. The analysis concentrated on identifying and categorizing four\ndistinct types of Chinese misconstructions. The study collected and generated a\nspeech corpus containing 2540 Stopping, Velar, Consonant-vowel, and Affricate\nsamples from 90 children aged 3-6 years with normal or pathological\narticulatory features. Each recording was accompanied by a detailed annotation\nfrom the field of speech therapy. Classification of the speech samples was\naccomplished using three well-established neural network models for image\nclassification. The feature maps are created using three sets of MFCC\nparameters extracted from speech sounds and aggregated into a three-dimensional\ndata structure as model input. We employ six techniques for data augmentation\nin order to augment the available dataset while avoiding over-simulation. The\nexperiments examine the usability of four different categories of Chinese\nphrases and characters. Experiments with different data subsets demonstrate the\nsystem's ability to accurately detect the analyzed pronunciation disorders.",
    "descriptor": "\nComments: 12 pages, 9 figures, journal\n",
    "authors": [
      "Yao-Ming Kuo",
      "Shanq-Jang Ruan",
      "Yu-Chin Chen",
      "Ya-Wen Tu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.11748"
  },
  {
    "id": "arXiv:2205.11753",
    "title": "Efficient LSM-Tree Key-Value Data Management on Hybrid SSD/HDD Zoned  Storage",
    "abstract": "Zoned storage devices, such as zoned namespace (ZNS) solid-state drives\n(SSDs) and host-managed shingled magnetic recording (HM-SMR) hard-disk drives\n(HDDs), expose interfaces for host-level applications to support fine-grained,\nhigh-performance storage management. Combining ZNS SSDs and HM-SMR HDDs into a\nunified hybrid storage system is a natural direction to scale zoned storage at\nlow cost, yet how to effectively incorporate zoned storage awareness into\nhybrid storage is a non-trivial issue. We make a case for key-value (KV) stores\nbased on log-structured merge trees (LSM-trees) as host-level applications, and\npresent HHZS, a middleware system that bridges an LSM-tree KV store with hybrid\nzoned storage devices based on hints. HHZS leverages hints issued by the\nflushing, compaction, and caching operations of the LSM-tree KV store to manage\nKV objects in placement, migration, and caching in hybrid ZNS SSD and HM-SMR\nHDD zoned storage. Experiments show that our HHZS prototype, when running on\nreal ZNS SSD and HM-SMR HDD devices, achieves the highest throughput compared\nwith all baselines under various settings.",
    "descriptor": "",
    "authors": [
      "Jinhong Li",
      "Qiuping Wang",
      "Patrick P. C. Lee"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.11753"
  },
  {
    "id": "arXiv:2205.11755",
    "title": "MOSPAT: AutoML based Model Selection and Parameter Tuning for Time  Series Anomaly Detection",
    "abstract": "Organizations leverage anomaly and changepoint detection algorithms to detect\nchanges in user behavior or service availability and performance. Many\noff-the-shelf detection algorithms, though effective, cannot readily be used in\nlarge organizations where thousands of users monitor millions of use cases and\nmetrics with varied time series characteristics and anomaly patterns. The\nselection of algorithm and parameters needs to be precise for each use case:\nmanual tuning does not scale, and automated tuning requires ground truth, which\nis rarely available.\nIn this paper, we explore MOSPAT, an end-to-end automated machine learning\nbased approach for model and parameter selection, combined with a generative\nmodel to produce labeled data. Our scalable end-to-end system allows individual\nusers in large organizations to tailor time-series monitoring to their specific\nuse case and data characteristics, without expert knowledge of anomaly\ndetection algorithms or laborious manual labeling. Our extensive experiments on\nreal and synthetic data demonstrate that this method consistently outperforms\nusing any single algorithm.",
    "descriptor": "\nComments: 10 pages, submitted originally to KDD'22\n",
    "authors": [
      "Sourav Chatterjee",
      "Rohan Bopardikar",
      "Marius Guerard",
      "Uttam Thakore",
      "Xiaodong Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11755"
  },
  {
    "id": "arXiv:2205.11756",
    "title": "UMSNet: An Universal Multi-sensor Network for Human Activity Recognition",
    "abstract": "Human activity recognition (HAR) based on multimodal sensors has become a\nrapidly growing branch of biometric recognition and artificial intelligence.\nHowever, how to fully mine multimodal time series data and effectively learn\naccurate behavioral features has always been a hot topic in this field.\nPractical applications also require a well-generalized framework that can\nquickly process a variety of raw sensor data and learn better feature\nrepresentations. This paper proposes a universal multi-sensor network (UMSNet)\nfor human activity recognition. In particular, we propose a new lightweight\nsensor residual block (called LSR block), which improves the performance by\nreducing the number of activation function and normalization layers, and adding\ninverted bottleneck structure and grouping convolution. Then, the Transformer\nis used to extract the relationship of series features to realize the\nclassification and recognition of human activities. Our framework has a clear\nstructure and can be directly applied to various types of multi-modal Time\nSeries Classification (TSC) tasks after simple specialization. Extensive\nexperiments show that the proposed UMSNet outperforms other state-of-the-art\nmethods on two popular multi-sensor human activity recognition datasets (i.e.\nHHAR dataset and MHEALTH dataset).",
    "descriptor": "",
    "authors": [
      "Jialiang Wang",
      "Haotian Wei",
      "Yi Wang",
      "Shu Yang",
      "Chi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11756"
  },
  {
    "id": "arXiv:2205.11757",
    "title": "Robotic agricultural instrument for automated extraction of nematode  cysts and eggs from soil to improve integrated pest management",
    "abstract": "Soybeans are an important crop for global food security. Every year, soybean\nyields are reduced by numerous soybean diseases, particularly the soybean cyst\nnematode (SCN). It is difficult to visually identify the presence of SCN in the\nfield, let alone its population densities or numbers, as there are no obvious\naboveground disease symptoms. The only definitive way to assess SCN population\ndensities is to directly extract the SCN cysts from soil and then extract the\neggs from cysts and count them. Extraction is typically conducted in commercial\nsoil analysis laboratories and university plant diagnostic clinics and involves\nrepeated steps of sieving, washing, collecting, grinding, and cleaning. Here we\npresent a robotic instrument to reproduce and automate the functions of the\nconventional methods to extract nematode cysts from soil and subsequently\nextract eggs from the recovered nematode cysts. We incorporated mechanisms to\nactuate the stage system, manipulate positions of individual sieves using the\ngripper, recover cysts and cyst-sized objects from soil suspended in water, and\ngrind the cysts to release their eggs. All system functions are controlled and\noperated by a touchscreen interface software. The performance of the robotic\ninstrument is evaluated using soil samples infested with SCN from two farms at\ndifferent locations and results were comparable to the conventional technique.\nOur new technology brings the benefits of automation to SCN soil diagnostics, a\nstep towards long-term integrated pest management of this serious soybean pest.",
    "descriptor": "",
    "authors": [
      "Christopher M. Legner",
      "Gregory L. Tylka",
      "Santosh Pandey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11757"
  },
  {
    "id": "arXiv:2205.11758",
    "title": "Analyzing the Mono- and Cross-Lingual Pretraining Dynamics of  Multilingual Language Models",
    "abstract": "The emergent cross-lingual transfer seen in multilingual pretrained models\nhas sparked significant interest in studying their behavior. However, because\nthese analyses have focused on fully trained multilingual models, little is\nknown about the dynamics of the multilingual pretraining process. We\ninvestigate when these models acquire their in-language and cross-lingual\nabilities by probing checkpoints taken from throughout XLM-R pretraining, using\na suite of linguistic tasks. Our analysis shows that the model achieves high\nin-language performance early on, with lower-level linguistic skills acquired\nbefore more complex ones. In contrast, when the model learns to transfer\ncross-lingually depends on the language pair. Interestingly, we also observe\nthat, across many languages and tasks, the final, converged model checkpoint\nexhibits significant performance degradation and that no one checkpoint\nperforms best on all languages. Taken together with our other findings, these\ninsights highlight the complexity and interconnectedness of multilingual\npretraining.",
    "descriptor": "",
    "authors": [
      "Terra Blevins",
      "Hila Gonen",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11758"
  },
  {
    "id": "arXiv:2205.11761",
    "title": "Ranking-Based Siamese Visual Tracking",
    "abstract": "Current Siamese-based trackers mainly formulate the visual tracking into two\nindependent subtasks, including classification and localization. They learn the\nclassification subnetwork by processing each sample separately and neglect the\nrelationship among positive and negative samples. Moreover, such tracking\nparadigm takes only the classification confidence of proposals for the final\nprediction, which may yield the misalignment between classification and\nlocalization. To resolve these issues, this paper proposes a ranking-based\noptimization algorithm to explore the relationship among different proposals.\nTo this end, we introduce two ranking losses, including the classification one\nand the IoU-guided one, as optimization constraints. The classification ranking\nloss can ensure that positive samples rank higher than hard negative ones,\ni.e., distractors, so that the trackers can select the foreground samples\nsuccessfully without being fooled by the distractors. The IoU-guided ranking\nloss aims to align classification confidence scores with the Intersection over\nUnion(IoU) of the corresponding localization prediction for positive samples,\nenabling the well-localized prediction to be represented by high classification\nconfidence. Specifically, the proposed two ranking losses are compatible with\nmost Siamese trackers and incur no additional computation for inference.\nExtensive experiments on seven tracking benchmarks, including OTB100, UAV123,\nTC128, VOT2016, NFS30, GOT-10k and LaSOT, demonstrate the effectiveness of the\nproposed ranking-based optimization algorithm. The code and raw results are\navailable at https://github.com/sansanfree/RBO.",
    "descriptor": "\nComments: To appear in CVPR2022\n",
    "authors": [
      "Feng Tang",
      "Qiang Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11761"
  },
  {
    "id": "arXiv:2205.11764",
    "title": "D4: a Chinese Dialogue Dataset for Depression-Diagnosis-Oriented Chat",
    "abstract": "In a depression-diagnosis-directed clinical session, doctors initiate a\nconversation with ample emotional support that guides the patients to expose\ntheir symptoms based on clinical diagnosis criteria. Such a dialog is a\ncombination of task-oriented and chitchat, different from traditional\nsingle-purpose human-machine dialog systems. However, due to the social stigma\nassociated with mental illness, the dialogue data related to depression\nconsultation and diagnosis are rarely disclosed. Though automatic\ndialogue-based diagnosis foresees great application potential, data sparsity\nhas become one of the major bottlenecks restricting research on such\ntask-oriented chat dialogues. Based on clinical depression diagnostic criteria\nICD-11 and DSM-5, we construct the D$^4$: a Chinese Dialogue Dataset for\nDepression-Diagnosis-Oriented Chat which simulates the dialogue between doctors\nand patients during the diagnosis of depression, including diagnosis results\nand symptom summary given by professional psychiatrists for each\ndialogue.Finally, we finetune on state-of-the-art pre-training models and\nrespectively present our dataset baselines on four tasks including response\ngeneration, topic prediction, dialog summary, and severity classification of\ndepressive episode and suicide risk. Multi-scale evaluation results demonstrate\nthat a more empathy-driven and diagnostic-accurate consultation dialogue system\ntrained on our dataset can be achieved compared to rule-based bots.",
    "descriptor": "",
    "authors": [
      "Binwei Yao",
      "Chao Shi",
      "Likai Zou",
      "Lingfeng Dai",
      "Mengyue Wu",
      "Lu Chen",
      "Zhen Wang",
      "Kai Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11764"
  },
  {
    "id": "arXiv:2205.11765",
    "title": "Byzantine-Robust Federated Learning with Optimal Statistical Rates and  Privacy Guarantees",
    "abstract": "We propose Byzantine-robust federated learning protocols with nearly optimal\nstatistical rates. In contrast to prior work, our proposed protocols improve\nthe dimension dependence and achieve a tight statistical rate in terms of all\nthe parameters for strongly convex losses. We benchmark against competing\nprotocols and show the empirical superiority of the proposed protocols.\nFinally, we remark that our protocols with bucketing can be naturally combined\nwith privacy-guaranteeing procedures to introduce security against a\nsemi-honest server. The code for evaluation is provided in\nhttps://github.com/wanglun1996/secure-robust-federated-learning.",
    "descriptor": "",
    "authors": [
      "Banghua Zhu",
      "Lun Wang",
      "Qi Pang",
      "Shuai Wang",
      "Jiantao Jiao",
      "Dawn Song",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.11765"
  },
  {
    "id": "arXiv:2205.11771",
    "title": "Learning Context-Aware Service Representation for Service Recommendation  in Workflow Composition",
    "abstract": "As increasingly more software services have been published onto the Internet,\nit remains a significant challenge to recommend suitable services to facilitate\nscientific workflow composition. This paper proposes a novel NLP-inspired\napproach to recommending services throughout a workflow development process,\nbased on incrementally learning latent service representation from workflow\nprovenance. A workflow composition process is formalized as a step-wise,\ncontext-aware service generation procedure, which is mapped to next-word\nprediction in a natural language sentence. Historical service dependencies are\nextracted from workflow provenance to build and enrich a knowledge graph. Each\npath in the knowledge graph reflects a scenario in a data analytics experiment,\nwhich is analogous to a sentence in a conversation. All paths are thus\nformalized as composable service sequences and are mined, using various\npatterns, from the established knowledge graph to construct a corpus. Service\nembeddings are then learned by applying deep learning model from the NLP field.\nExtensive experiments on the real-world dataset demonstrate the effectiveness\nand efficiency of the approach.",
    "descriptor": "\nComments: 10 pages, 15 figures, 1 table\n",
    "authors": [
      "Xihao Xie",
      "Jia Zhang",
      "Rahul Ramachandran",
      "Tsengdar J. Lee",
      "Seungwon Lee"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11771"
  },
  {
    "id": "arXiv:2205.11772",
    "title": "Multi-Augmentation for Efficient Visual Representation Learning for  Self-supervised Pre-training",
    "abstract": "In recent years, self-supervised learning has been studied to deal with the\nlimitation of available labeled-dataset. Among the major components of\nself-supervised learning, the data augmentation pipeline is one key factor in\nenhancing the resulting performance. However, most researchers manually\ndesigned the augmentation pipeline, and the limited collections of\ntransformation may cause the lack of robustness of the learned feature\nrepresentation. In this work, we proposed Multi-Augmentations for\nSelf-Supervised Representation Learning (MA-SSRL), which fully searched for\nvarious augmentation policies to build the entire pipeline to improve the\nrobustness of the learned feature representation. MA-SSRL successfully learns\nthe invariant feature representation and presents an efficient, effective, and\nadaptable data augmentation pipeline for self-supervised pre-training on\ndifferent distribution and domain datasets. MA-SSRL outperforms the previous\nstate-of-the-art methods on transfer and semi-supervised benchmarks while\nrequiring fewer training epochs.",
    "descriptor": "",
    "authors": [
      "Van-Nhiem Tran",
      "Chi-En Huang",
      "Shen-Hsuan Liu",
      "Kai-Lin Yang",
      "Timothy Ko",
      "Yung-Hui Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11772"
  },
  {
    "id": "arXiv:2205.11773",
    "title": "Constrained Error Pattern Generation for GRAND",
    "abstract": "Maximum-likelihood (ML) decoding can be used to obtain the optimal\nperformance of error correction codes. However, the size of the search space\nand consequently the decoding complexity grows exponentially, making it\nimpractical to be employed for long codes. In this paper, we propose an\napproach to constrain the search space for error patterns under a recently\nintroduced near ML decoding scheme called guessing random additive noise\ndecoding (GRAND). In this approach, the syndrome-based constraints which divide\nthe search space into disjoint sets are progressively evaluated. By employing\n$p$ constraints extracted from the parity check matrix, the average number of\nqueries reduces by a factor of $2^p$ while the error correction performance\nremains intact.",
    "descriptor": "\nComments: 6 pages, 5 figures, to appear in the proceedings of ISIT 2022\n",
    "authors": [
      "Mohammad Rowshan",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11773"
  },
  {
    "id": "arXiv:2205.11775",
    "title": "Constrained Monotonic Neural Networks",
    "abstract": "Deep neural networks are becoming increasingly popular in approximating\narbitrary functions from noisy data. But wider adoption is being hindered by\nthe need to explain such models and to impose additional constraints on them.\nMonotonicity constraint is one of the most requested properties in real-world\nscenarios and is the focus of this paper. One of the oldest ways to construct a\nmonotonic fully connected neural network is to constrain its weights to be\nnon-negative while employing a monotonic activation function. Unfortunately,\nthis construction does not work with popular non-saturated activation functions\nsuch as ReLU, ELU, SELU etc, as it can only approximate convex functions. We\nshow this shortcoming can be fixed by employing the original activation\nfunction for a part of the neurons in the layer, and employing its point\nreflection for the other part. Our experiments show this approach of building\nmonotonic deep neural networks have matching or better accuracy when compared\nto other state-of-the-art methods such as deep lattice networks or monotonic\nnetworks obtained by heuristic regularization. This method is the simplest one\nin the sense of having the least number of parameters, not requiring any\nmodifications to the learning procedure or steps post-learning steps.",
    "descriptor": "",
    "authors": [
      "Davor Runje",
      "Sharath M. Shankaranarayana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11775"
  },
  {
    "id": "arXiv:2205.11779",
    "title": "Wireless Ad Hoc Federated Learning: A Fully Distributed Cooperative  Machine Learning",
    "abstract": "Federated learning has allowed training of a global model by aggregating\nlocal models trained on local nodes. However, it still takes client-server\nmodel, which can be further distributed, fully decentralized, or even partially\nconnected, or totally opportunistic. In this paper, we propose a wireless ad\nhoc federated learning (WAFL) -- a fully distributed cooperative machine\nlearning organized by the nodes physically nearby. Here, each node has a\nwireless interface and can communicate with each other when they are within the\nradio range. The nodes are expected to move with people, vehicles, or robots,\nproducing opportunistic contacts with each other. In WAFL, each node trains a\nmodel individually with the local data it has. When a node encounter with\nothers, they exchange their trained models, and generate new aggregated models,\nwhich are expected to be more general compared to the locally trained models on\nNon-IID data. For evaluation, we have prepared four static communication\nnetworks and two types of dynamic and opportunistic communication networks\nbased on random waypoint mobility and community-structured environment, and\nthen studied the training process of a fully connected neural network with 90%\nNon-IID MNIST dataset. The evaluation results indicate that WAFL allowed the\nconvergence of model parameters among the nodes toward generalization, even\nwith opportunistic node contact scenarios -- whereas in self-training (or\nlonely training) case, they have diverged. This WAFL's model generalization\ncontributed to achieving higher accuracy 94.7-96.2% to the testing IID dataset\ncompared to the self-training case 84.7%.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Hideya Ochiai",
      "Yuwei Sun",
      "Qingzhe Jin",
      "Nattanon Wongwiwatchai",
      "Hiroshi Esaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.11779"
  },
  {
    "id": "arXiv:2205.11781",
    "title": "Attributing AUC-ROC to Analyze Binary Classifier Performance",
    "abstract": "Area Under the Receiver Operating Characteristic Curve (AUC-ROC) is a popular\nevaluation metric for binary classifiers. In this paper, we discuss techniques\nto segment the AUC-ROC along human-interpretable dimensions. AUC-ROC is not an\nadditive/linear function over the data samples, therefore such segmenting the\noverall AUC-ROC is different from tabulating the AUC-ROC of data segments. To\nsegment the overall AUC-ROC, we must first solve an \\emph{attribution} problem\nto identify credit for individual examples.\nWe observe that AUC-ROC, though non-linear over examples, is linear over\n\\emph{pairs} of examples. This observation leads to a simple, efficient\nattribution technique for examples (example attributions), and for pairs of\nexamples (pair attributions). We automatically slice these attributions using\ndecision trees by making the tree predict the attributions; we use the notion\nof honest estimates along with a t-test to mitigate false discovery.\nOur experiments with the method show that an inferior model can outperform a\nsuperior model (trained to optimize a different training objective) on the\ninferior model's own training objective, a manifestation of Goodhart's Law. In\ncontrast, AUC attributions enable a reasonable comparison. Example attributions\ncan be used to slice this comparison. Pair attributions are used to categorize\npairs of items -- one positively labeled and one negatively -- that the model\nhas trouble separating. These categories identify the decision boundary of the\nclassifier and the headroom to improve AUC.",
    "descriptor": "",
    "authors": [
      "Arya Tafvizi",
      "Besim Avci",
      "Mukund Sundararajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11781"
  },
  {
    "id": "arXiv:2205.11782",
    "title": "Fine-grained Poisoning Attacks to Local Differential Privacy Protocols  for Mean and Variance Estimation",
    "abstract": "Local differential privacy (LDP) protects individual data contributors\nagainst privacy-probing data aggregation and analytics. Recent work has shown\nthat LDP for some specific data types is vulnerable to data poisoning attacks,\nwhich enable the attacker to alter analytical results by injecting\ncarefully-crafted bogus data. In this work, we focus on applying data poisoning\nattack to unexplored statistical tasks, i.e. mean and variance estimations. In\ncontrast to prior work that aims for overall LDP performance degradation or\nstraightforward attack gain maximization, our attacker can fine-tune the LDP\nestimated mean/variance to the desired target values and simultaneously\nmanipulate them. To accomplish this goal, we propose two types of data\npoisoning attacks: input poisoning attack (IPA) and output poisoning attack\n(OPA). The former is independent of LDP while the latter utilizes the\ncharacteristics of LDP, thus being more effective. More intriguingly, we\nobserve a security-privacy consistency where a small $\\epsilon$ enhances the\nsecurity of LDP contrary to the previous conclusion of a security-privacy\ntrade-off. We further study the consistency and reveal a more holistic view of\nthe threat landscape of LDP in the presence of data poisoning attacks. We\ncomprehensively evaluate the attacks on three real-world datasets and report\ntheir effectiveness for achieving the target values. We also explore defense\nmechanisms and provide insights into the secure LDP design.",
    "descriptor": "",
    "authors": [
      "Xiaoguang Li",
      "Neil Zhenqiang Gong",
      "Ninghui Li",
      "Wenhai Sun",
      "Hui Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.11782"
  },
  {
    "id": "arXiv:2205.11783",
    "title": "Smart Grid: Cyber Attacks, Critical Defense Approaches, and Digital Twin",
    "abstract": "As a national critical infrastructure, the smart grid has attracted\nwidespread attention for its cybersecurity issues. The development towards an\nintelligent, digital, and Internetconnected smart grid has attracted external\nadversaries for malicious activities. It is necessary to enhance its\ncybersecurity by either improving the existing defense approaches or\nintroducing novel developed technologies to the smart grid context. As an\nemerging technology, digital twin (DT) is considered as an enabler for enhanced\nsecurity. However, the practical implementation is quite challenging. This is\ndue to the knowledge barriers among smart grid designers, security experts, and\nDT developers. Each single domain is a complicated system covering various\ncomponents and technologies. As a result, works are needed to sort out relevant\ncontents so that DT can be better embedded in the security architecture design\nof smart grid. In order to meet this demand, our paper covers the above three\ndomains, i.e., smart grid, cybersecurity, and DT. Specifically, the paper i)\nintroduces the background of the smart grid; ii) reviews external cyber attacks\nfrom attack incidents and attack methods; iii) introduces critical defense\napproaches in industrial cyber systems, which include device identification,\nvulnerability discovery, intrusion detection systems (IDSs), honeypots,\nattribution, and threat intelligence (TI); iv) reviews the relevant content of\nDT, including its basic concepts, applications in the smart grid, and how DT\nenhances the security. In the end, the paper puts forward our security\nconsiderations on the future development of DT-based smart grid. The survey is\nexpected to help developers break knowledge barriers among smart grid,\ncybersecurity, and DT, and provide guidelines for future security design of\nDT-based smart grid.",
    "descriptor": "",
    "authors": [
      "Tianming Zheng",
      "Ming Liu",
      "Deepak Puthal",
      "Ping Yi",
      "Yue Wu",
      "Xiangjian He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.11783"
  },
  {
    "id": "arXiv:2205.11784",
    "title": "LOCUS 2.0: Robust and Computationally Efficient Lidar Odometry for  Real-Time Underground 3D Mapping",
    "abstract": "Lidar odometry has attracted considerable attention as a robust localization\nmethod for autonomous robots operating in complex GNSS-denied environments.\nHowever, achieving reliable and efficient performance on heterogeneous\nplatforms in large-scale environments remains an open challenge due to the\nlimitations of onboard computation and memory resources needed for autonomous\noperation. In this work, we present LOCUS 2.0, a robust and\ncomputationally-efficient \\lidar odometry system for real-time underground 3D\nmapping. LOCUS 2.0 includes a novel normals-based \\morrell{Generalized\nIterative Closest Point (GICP)} formulation that reduces the computation time\nof point cloud alignment, an adaptive voxel grid filter that maintains the\ndesired computation load regardless of the environment's geometry, and a\nsliding-window map approach that bounds the memory consumption. The proposed\napproach is shown to be suitable to be deployed on heterogeneous robotic\nplatforms involved in large-scale explorations under severe computation and\nmemory constraints. We demonstrate LOCUS 2.0, a key element of the CoSTAR\nteam's entry in the DARPA Subterranean Challenge, across various underground\nscenarios.\nWe release LOCUS 2.0 as an open-source library and also release a\n\\lidar-based odometry dataset in challenging and large-scale underground\nenvironments. The dataset features legged and wheeled platforms in multiple\nenvironments including fog, dust, darkness, and geometrically degenerate\nsurroundings with a total of $11~h$ of operations and $16~km$ of distance\ntraveled.",
    "descriptor": "",
    "authors": [
      "Andrzej Reinke",
      "Matteo Palieri",
      "Benjamin Morrell",
      "Yun Chang",
      "Kamak Ebadi",
      "Luca Carlone",
      "Ali-akbar Agha-mohammadi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.11784"
  },
  {
    "id": "arXiv:2205.11785",
    "title": "AFNet-M: Adaptive Fusion Network with Masks for 2D+3D Facial Expression  Recognition",
    "abstract": "2D+3D facial expression recognition (FER) can effectively cope with\nillumination changes and pose variations by simultaneously merging 2D texture\nand more robust 3D depth information. Most deep learning-based approaches\nemploy the simple fusion strategy that concatenates the multimodal features\ndirectly after fully-connected layers, without considering the different\ndegrees of significance for each modality. Meanwhile, how to focus on both 2D\nand 3D local features in salient regions is still a great challenge. In this\nletter, we propose the adaptive fusion network with masks (AFNet-M) for 2D+3D\nFER. To enhance 2D and 3D local features, we take the masks annotating salient\nregions of the face as prior knowledge and design the mask attention module\n(MA) which can automatically learn two modulation vectors to adjust the feature\nmaps. Moreover, we introduce a novel fusion strategy that can perform adaptive\nfusion at convolutional layers through the designed importance weights\ncomputing module (IWC). Experimental results demonstrate that our AFNet-M\nachieves the state-of-the-art performance on BU-3DFE and Bosphorus datasets and\nrequires fewer parameters in comparison with other models.",
    "descriptor": "\nComments: 6 pages, 6 figures, 4 tables\n",
    "authors": [
      "Mingzhe Sui",
      "Hanting Li",
      "Zhaoqing Zhu",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11785"
  },
  {
    "id": "arXiv:2205.11786",
    "title": "Transition to Linearity of General Neural Networks with Directed Acyclic  Graph Architecture",
    "abstract": "In this paper we show that feedforward neural networks corresponding to\narbitrary directed acyclic graphs undergo transition to linearity as their\n\"width\" approaches infinity. The width of these general networks is\ncharacterized by the minimum in-degree of their neurons, except for the input\nand first layers. Our results identify the mathematical structure underlying\ntransition to linearity and generalize a number of recent works aimed at\ncharacterizing transition to linearity or constancy of the Neural Tangent\nKernel for standard architectures.",
    "descriptor": "",
    "authors": [
      "Libin Zhu",
      "Chaoyue Liu",
      "Mikhail Belkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11786"
  },
  {
    "id": "arXiv:2205.11787",
    "title": "Quadratic models for understanding neural network dynamics",
    "abstract": "In this work, we propose using a quadratic model as a tool for understanding\nproperties of wide neural networks in both optimization and generalization. We\nshow analytically that certain deep learning phenomena such as the \"catapult\nphase\" from [Lewkowycz et al. 2020], which cannot be captured by linear models,\nare manifested in the quadratic model for shallow ReLU networks. Furthermore,\nour empirical results indicate that the behaviour of quadratic models parallels\nthat of neural networks in generalization, especially in the large learning\nrate regime. We expect that quadratic models will serve as a useful tool for\nanalysis of neural networks.",
    "descriptor": "",
    "authors": [
      "Libin Zhu",
      "Chaoyue Liu",
      "Adityanarayanan Radhakrishnan",
      "Mikhail Belkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11787"
  },
  {
    "id": "arXiv:2205.11788",
    "title": "Meta Policy Learning for Cold-Start Conversational Recommendation",
    "abstract": "Conversational recommender systems (CRS) explicitly solicit users'\npreferences for improved recommendations on the fly. Most existing CRS\nsolutions employ reinforcement learning methods to train a single policy for a\npopulation of users. However, for users new to the system, such a global policy\nbecomes ineffective to produce conversational recommendations, i.e., the\ncold-start challenge.\nIn this paper, we study CRS policy learning for cold-start users via meta\nreinforcement learning. We propose to learn a meta policy and adapt it to new\nusers with only a few trials of conversational recommendations. To facilitate\npolicy adaptation, we design three synergetic components. First is a\nmeta-exploration policy dedicated to identify user preferences via exploratory\nconversations. Second is a Transformer-based state encoder to model a user's\nboth positive and negative feedback during the conversation. And third is an\nadaptive item recommender based on the embedded states. Extensive experiments\non three datasets demonstrate the advantage of our solution in serving new\nusers, compared with a rich set of state-of-the-art CRS solutions.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Zhendong Chu",
      "Hongning Wang",
      "Yun Xiao",
      "Bo Long",
      "Lingfei Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.11788"
  },
  {
    "id": "arXiv:2205.11790",
    "title": "Hierarchical Planning Through Goal-Conditioned Offline Reinforcement  Learning",
    "abstract": "Offline Reinforcement learning (RL) has shown potent in many safe-critical\ntasks in robotics where exploration is risky and expensive. However, it still\nstruggles to acquire skills in temporally extended tasks. In this paper, we\nstudy the problem of offline RL for temporally extended tasks. We propose a\nhierarchical planning framework, consisting of a low-level goal-conditioned RL\npolicy and a high-level goal planner. The low-level policy is trained via\noffline RL. We improve the offline training to deal with out-of-distribution\ngoals by a perturbed goal sampling process. The high-level planner selects\nintermediate sub-goals by taking advantages of model-based planning methods. It\nplans over future sub-goal sequences based on the learned value function of the\nlow-level policy. We adopt a Conditional Variational Autoencoder to sample\nmeaningful high-dimensional sub-goal candidates and to solve the high-level\nlong-term strategy optimization problem. We evaluate our proposed method in\nlong-horizon driving and robot navigation tasks. Experiments show that our\nmethod outperforms baselines with different hierarchical designs and other\nregular planners without hierarchy in these complex tasks.",
    "descriptor": "",
    "authors": [
      "Jinning Li",
      "Chen Tang",
      "Masayoshi Tomizuka",
      "Wei Zhan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.11790"
  },
  {
    "id": "arXiv:2205.11795",
    "title": "Influence of perspective taking through robotic virtual agents on  prosocial behavior",
    "abstract": "Perspective taking, which allows people to imagine another's thinking and\ngoals, is known to be an effective method for promoting prosocial behaviors in\nhuman-computer interactions. However, most of the previous studies have focused\non simulating human-human interactions in the real world by offering\nparticipants experiences related to various moral tasks through the use of\nhuman-like virtual agents. In this study, we investigated whether taking the\nperspective of a different robot in a robot-altruistic task would influence the\nsocial behaviors of participants in a dictator game. Our findings showed that\nparticipants who watched the help-receiver view exhibited more altruistic\nbehaviors toward a robot than those who watched the help-provider view. We also\nfound that, after watching robots from two different viewpoints in the task,\nparticipants did not change their behavior toward another participant.",
    "descriptor": "",
    "authors": [
      "Chenlin Hang",
      "Tetsuo Ono",
      "Seiji Yamada"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.11795"
  },
  {
    "id": "arXiv:2205.11796",
    "title": "G-Rep: Gaussian Representation for Arbitrary-Oriented Object Detection",
    "abstract": "Arbitrary-oriented object representations contain the oriented bounding box\n(OBB), quadrilateral bounding box (QBB), and point set (PointSet). Each\nrepresentation encounters problems that correspond to its characteristics, such\nas the boundary discontinuity, square-like problem, representation ambiguity,\nand isolated points, which lead to inaccurate detection. Although many\neffective strategies have been proposed for various representations, there is\nstill no unified solution. Current detection methods based on Gaussian modeling\nhave demonstrated the possibility of breaking this dilemma; however, they\nremain limited to OBB. To go further, in this paper, we propose a unified\nGaussian representation called G-Rep to construct Gaussian distributions for\nOBB, QBB, and PointSet, which achieves a unified solution to various\nrepresentations and problems. Specifically, PointSet or QBB-based objects are\nconverted into Gaussian distributions, and their parameters are optimized using\nthe maximum likelihood estimation algorithm. Then, three optional Gaussian\nmetrics are explored to optimize the regression loss of the detector because of\ntheir excellent parameter optimization mechanisms. Furthermore, we also use\nGaussian metrics for sampling to align label assignment and regression loss.\nExperimental results on several public available datasets, DOTA, HRSC2016,\nUCAS-AOD, and ICDAR2015 show the excellent performance of the proposed method\nfor arbitrary-oriented object detection. The code has been open sourced at\nhttps://github.com/open-mmlab/mmrotate.",
    "descriptor": "\nComments: 14 pages, 6 figures, 8 tables, the code has been open sourced at this https URL\n",
    "authors": [
      "Liping Hou",
      "Ke Lu",
      "Xue Yang",
      "Yuqiu Li",
      "Jian Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11796"
  },
  {
    "id": "arXiv:2205.11798",
    "title": "Symbolic Expression Transformer: A Computer Vision Approach for Symbolic  Regression",
    "abstract": "Symbolic Regression (SR) is a type of regression analysis to automatically\nfind the mathematical expression that best fits the data. Currently, SR still\nbasically relies on various searching strategies so that a sample-specific\nmodel is required to be optimized for every expression, which significantly\nlimits the model's generalization and efficiency. Inspired by the fact that\nhuman beings can infer a mathematical expression based on the curve of it, we\npropose Symbolic Expression Transformer (SET), a sample-agnostic model from the\nperspective of computer vision for SR. Specifically, the collected data is\nrepresented as images and an image caption model is employed for translating\nimages to symbolic expressions. A large-scale dataset without overlap between\ntraining and testing sets in the image domain is released. Our results\ndemonstrate the effectiveness of SET and suggest the promising direction of\nimage-based model for solving the challenging SR problem.",
    "descriptor": "",
    "authors": [
      "Jiachen Li",
      "Ye Yuan",
      "Hong-Bin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11798"
  },
  {
    "id": "arXiv:2205.11799",
    "title": "Formulating Few-shot Fine-tuning Towards Language Model Pre-training: A  Pilot Study on Named Entity Recognition",
    "abstract": "Fine-tuning pre-trained language models has recently become a common practice\nin building NLP models for various tasks, especially few-shot tasks. We argue\nthat under the few-shot setting, formulating fine-tuning closer to the\npre-training objectives shall be able to unleash more benefits from the\npre-trained language models. In this work, we take few-shot named entity\nrecognition (NER) for a pilot study, where existing fine-tuning strategies are\nmuch different from pre-training. We propose a novel few-shot fine-tuning\nframework for NER, FFF-NER. Specifically, we introduce three new types of\ntokens, \"is-entity\", \"which-type\" and bracket, so we can formulate the NER\nfine-tuning as (masked) token prediction or generation, depending on the choice\nof pre-trained language models. In our experiments, we apply FFF-NER to\nfine-tune both BERT and BART for few-shot NER on several benchmark datasets and\nobserve significant improvements over existing fine-tuning strategies,\nincluding sequence labeling, prototype meta-learning, and prompt-based\napproaches. We further perform a series of ablation studies, showing few-shot\nNER performance is strongly correlated with the similarity between fine-tuning\nand pre-training.",
    "descriptor": "",
    "authors": [
      "Zihan Wang",
      "Kewen Zhao",
      "Zilong Wang",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11799"
  },
  {
    "id": "arXiv:2205.11803",
    "title": "WeDef: Weakly Supervised Backdoor Defense for Text Classification",
    "abstract": "Existing backdoor defense methods are only effective for limited trigger\ntypes. To defend different trigger types at once, we start from the\nclass-irrelevant nature of the poisoning process and propose a novel weakly\nsupervised backdoor defense framework WeDef. Recent advances in weak\nsupervision make it possible to train a reasonably accurate text classifier\nusing only a small number of user-provided, class-indicative seed words. Such\nseed words shall be considered independent of the triggers. Therefore, a weakly\nsupervised text classifier trained by only the poisoned documents without their\nlabels will likely have no backdoor. Inspired by this observation, in WeDef, we\ndefine the reliability of samples based on whether the predictions of the weak\nclassifier agree with their labels in the poisoned training set. We further\nimprove the results through a two-phase sanitization: (1) iteratively refine\nthe weak classifier based on the reliable samples and (2) train a binary poison\nclassifier by distinguishing the most unreliable samples from the most reliable\nsamples. Finally, we train the sanitized model on the samples that the poison\nclassifier predicts as benign. Extensive experiments show that WeDefis\neffective against popular trigger-based attacks (e.g., words, sentences, and\nparaphrases), outperforming existing defense methods.",
    "descriptor": "",
    "authors": [
      "Lesheng Jin",
      "Zihan Wang",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11803"
  },
  {
    "id": "arXiv:2205.11804",
    "title": "Package Theft Detection from Smart Home Security Cameras",
    "abstract": "Package theft detection has been a challenging task mainly due to lack of\ntraining data and a wide variety of package theft cases in reality. In this\npaper, we propose a new Global and Local Fusion Package Theft Detection\nEmbedding (GLF-PTDE) framework to generate package theft scores for each\nsegment within a video to fulfill the real-world requirements on package theft\ndetection. Moreover, we construct a novel Package Theft Detection dataset to\nfacilitate the research on this task. Our method achieves 80% AUC performance\non the newly proposed dataset, showing the effectiveness of the proposed\nGLF-PTDE framework and its robustness in different real scenes for package\ntheft detection.",
    "descriptor": "",
    "authors": [
      "Hung-Min Hsu",
      "Xinyu Yuan",
      "Baohua Zhu",
      "Zhongwei Cheng",
      "Lin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11804"
  },
  {
    "id": "arXiv:2205.11805",
    "title": "Hybrid Manufacturing Process Planning for Arbitrary Part and Tool Shapes",
    "abstract": "Hybrid manufacturing (HM) technologies combine additive and subtractive\nmanufacturing (AM/SM) capabilities in multi-modal process plans that leverage\nthe strengths of each. Despite the growing interest in HM technologies,\nsoftware tools for process planning have not caught up with advances in\nhardware and typically impose restrictions that limit the design and\nmanufacturing engineers' ability to systematically explore the full design and\nprocess planning spaces. We present a general framework for identifying AM/SM\nactions that make up an HM process plan based on accessibility and support\nrequirements, using morphological operations that allow for arbitrary part and\ntool geometries to be considered. To take advantage of multi-modality, we\ndefine the actions to allow for temporary excessive material deposition or\nremoval, with an understanding that subsequent actions can correct for them,\nunlike the case in unimodal (AM-only or SM-only) process plans that are\nmonotonic. We use this framework to generate a combinatorial space of valid,\npotentially non-monotonic, process plans for a given part of arbitrary shape, a\ncollection of AM/SM tools of arbitrary shapes, and a set of relative rotations\n(fixed for each action) between them, representing build/fixturing directions\non $3-$axis machines. Finally, we use define a simple objective function\nquantifying the cost of materials and operating time in terms of\ndeposition/removal volumes and use a search algorithm to explore the\nexponentially large space of valid process plans to find \"cost-optimal\"\nsolutions. We demonstrate the effectiveness of our method on 3D examples.",
    "descriptor": "\nComments: Special Issue on symposium on Solid and Physical Modeling (SPM'2022)\n",
    "authors": [
      "George P. Harabin",
      "Morad Behandish"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.11805"
  },
  {
    "id": "arXiv:2205.11807",
    "title": "NFL: Robust Learned Index via Distribution Transformation",
    "abstract": "Recent works on learned index open a new direction for the indexing field.\nThe key insight of the learned index is to approximate the mapping between keys\nand positions with piece-wise linear functions. Such methods require\npartitioning key space for a better approximation. Although lots of heuristics\nare proposed to improve the approximation quality, the bottleneck is that the\nsegmentation overheads could hinder the overall performance. This paper tackles\nthe approximation problem by applying a \\textit{distribution transformation} to\nthe keys before constructing the learned index. A two-stage\nNormalizing-Flow-based Learned index framework (NFL) is proposed, which first\ntransforms the original complex key distribution into a near-uniform\ndistribution, then builds a learned index leveraging the transformed keys. For\neffective distribution transformation, we propose a Numerical Normalizing Flow\n(Numerical NF). Based on the characteristics of the transformed keys, we\npropose a robust After-Flow Learned Index (AFLI). To validate the performance,\ncomprehensive evaluations are conducted on both synthetic and real-world\nworkloads, which shows that the proposed NFL produces the highest throughput\nand the lowest tail latency compared to the state-of-the-art learned indexes.",
    "descriptor": "",
    "authors": [
      "Shangyu Wu",
      "Yufei Cui",
      "Jinghuan Yu",
      "Xuan Sun",
      "Tei-Wei Kuo",
      "Chun Jason Xue"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11807"
  },
  {
    "id": "arXiv:2205.11808",
    "title": "Increasing Cellular Network Energy Efficiency for Railway Corridors",
    "abstract": "Modern trains act as Faraday cages making it challenging to provide high\ncellular data capacities to passengers. A solution is the deployment of linear\ncells along railway tracks, forming a cellular corridor. To provide a\nsufficiently high data capacity, many cell sites need to be installed at\nregular distances. However, such cellular corridors with high power sites in\nshort distance intervals are not sustainable due to the infrastructure power\nconsumption. To render railway connectivity more sustainable, we propose to\ndeploy fewer high-power radio units with intermediate low-power support\nrepeater nodes. We show that these repeaters consume only 5 % of the energy of\na regular cell site and help to maintain the same data capacity in the trains.\nIn a further step, we introduce a sleep mode for the repeater nodes that\nenables autonomous solar powering and even eases installation because no cables\nto the relays are needed.",
    "descriptor": "\nComments: 6 pages; published as shortened 4-page version in: 2022 Design, Automation & Test in Europe Conference & Exhibition (DATE), 14-23 March 2022\n",
    "authors": [
      "Adrian Schumacher",
      "Ruben Merz",
      "Andreas Burg"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11808"
  },
  {
    "id": "arXiv:2205.11809",
    "title": "Learning to Assemble Geometric Shapes",
    "abstract": "Assembling parts into an object is a combinatorial problem that arises in a\nvariety of contexts in the real world and involves numerous applications in\nscience and engineering. Previous related work tackles limited cases with\nidentical unit parts or jigsaw-style parts of textured shapes, which greatly\nmitigate combinatorial challenges of the problem. In this work, we introduce\nthe more challenging problem of shape assembly, which involves textureless\nfragments of arbitrary shapes with indistinctive junctions, and then propose a\nlearning-based approach to solving it. We demonstrate the effectiveness on\nshape assembly tasks with various scenarios, including the ones with abnormal\nfragments (e.g., missing and distorted), the different number of fragments, and\ndifferent rotation discretization.",
    "descriptor": "\nComments: 11 pages, 9 figures, 9 tables. Accepted at the 31st International Joint Conference on Artificial Intelligence (IJCAI 2022). J. Lee and J. Kim equally contributed\n",
    "authors": [
      "Jinhwi Lee",
      "Jungtaek Kim",
      "Hyunsoo Chung",
      "Jaesik Park",
      "Minsu Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11809"
  },
  {
    "id": "arXiv:2205.11811",
    "title": "Sensing Performance of Multi-Channel RFID-based Finger Augmentation  Devices for Tactile Internet",
    "abstract": "Radiofrequency finger augmentation devices (R-FADs) are a recently introduced\nclass of epidermal radiofrequency identification (RFID) sensor-tags attached to\nthe fingers, communicating with a body-worn reader. These devices are promising\ncandidates to enable Tactile Internet (TI) applications in the short term.\nR-FAD based on auto-tuning RFID microchips can be used as dielectric probes for\nthe material of touched objects. However, due to the nearly unpredictable\nintrinsic variability of finger-object interaction, a single sensorized finger\n(single-channel device) is not enough to guarantee reliable data sampling.\nThese limitations can be overcome by exploiting a multi-channel R-FAD\nsensorizing multiple fingers of the hand. In this paper, the dielectric-sensing\nperformance of a multi-channel R-FAD, composed of sensors encapsulated into\nsoft elastomers, is numerically and experimentally characterized, involving a\nset of volunteers. The inter-sensor coupling is negligible, thus enabling\nsimultaneous independent dielectric measurements. The multi-sensor\nconfiguration allows for 100% reliability of the on-hand communication link for\ntouched objects in a wide range of permittivity. Experiments moreover\ndemonstrate that multi-channel measurements can halve the measurement\nuncertainty of the single-channel case. The achievable precision is suitable to\ndiscriminate among low-, medium-, and high-permittivity materials.",
    "descriptor": "\nComments: Accepted for publication in \"IEEE Journal on Radio Frequency Identification\"\n",
    "authors": [
      "Federica Naccarata",
      "Giulio Maria Bianco",
      "Gaetano Marrocco"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.11811"
  },
  {
    "id": "arXiv:2205.11812",
    "title": "HoSIM: Higher-order Structural Importance based Method for Multiple  Local Community Detection",
    "abstract": "Local community detection has attracted much research attention recently, and\nmany methods have been proposed for the single local community detection that\nfinds a community containing the given set of query nodes. However, nodes may\nbelong to several communities in the network, and detecting all the communities\nfor the query node set, termed as the multiple local community detection\n(MLCD), is more important as it could uncover more potential information. MLCD\nis also more challenging because when a query node belongs to multiple\ncommunities, it always locates in the complicated overlapping region and the\nmarginal region of communities. Accordingly, detecting multiple communities for\nsuch nodes by applying seed expansion methods is insufficient.\nIn this work, we address the MLCD based on higher-order structural importance\n(HoSI). First, to effectively estimate the influence of higher-order\nstructures, we propose a new variant of random walk called Active Random Walk\nto measure the HoSI score between nodes. Then, we propose two new metrics to\nevaluate the HoSI score of a subgraph to a node and the HoSI score of a node,\nrespectively. Based on the proposed metrics, we present a novel algorithm\ncalled HoSIM to detect multiple local communities for a single query node.\nHoSIM enforces a three-stage processing, namely subgraph sampling, core member\nidentification, and local community detection. The key idea is utilizing HoSI\nto find and identify the core members of communities relevant to the query node\nand optimize the generated communities. Extensive experiments illustrate the\neffectiveness of HoSIM.",
    "descriptor": "",
    "authors": [
      "Boyu Li",
      "Meng Wang",
      "John E. Hopcroft",
      "Kun He"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.11812"
  },
  {
    "id": "arXiv:2205.11814",
    "title": "Penalized Proximal Policy Optimization for Safe Reinforcement Learning",
    "abstract": "Safe reinforcement learning aims to learn the optimal policy while satisfying\nsafety constraints, which is essential in real-world applications. However,\ncurrent algorithms still struggle for efficient policy updates with hard\nconstraint satisfaction. In this paper, we propose Penalized Proximal Policy\nOptimization (P3O), which solves the cumbersome constrained policy iteration\nvia a single minimization of an equivalent unconstrained problem. Specifically,\nP3O utilizes a simple-yet-effective penalty function to eliminate cost\nconstraints and removes the trust-region constraint by the clipped surrogate\nobjective. We theoretically prove the exactness of the proposed method with a\nfinite penalty factor and provide a worst-case analysis for approximate error\nwhen evaluated on sample trajectories. Moreover, we extend P3O to more\nchallenging multi-constraint and multi-agent scenarios which are less studied\nin previous work. Extensive experiments show that P3O outperforms\nstate-of-the-art algorithms with respect to both reward improvement and\nconstraint satisfaction on a set of constrained locomotive tasks.",
    "descriptor": "\nComments: IJCAI2022\n",
    "authors": [
      "Linrui zhang",
      "Li Shen",
      "Long Yang",
      "Shixiang Chen",
      "Bo Yuan",
      "Xueqian Wang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11814"
  },
  {
    "id": "arXiv:2205.11817",
    "title": "Singer Identification for Metaverse with Timbral and Middle-Level  Perceptual Features",
    "abstract": "Metaverse is an interactive world that combines reality and virtuality, where\nparticipants can be virtual avatars. Anyone can hold a concert in a virtual\nconcert hall, and users can quickly identify the real singer behind the virtual\nidol through the singer identification. Most singer identification methods are\nprocessed using the frame-level features. However, expect the singer's timbre,\nthe music frame includes music information, such as melodiousness, rhythm, and\ntonal. It means the music information is noise for using frame-level features\nto identify the singers. In this paper, instead of only the frame-level\nfeatures, we propose to use another two features that address this problem.\nMiddle-level feature, which represents the music's melodiousness, rhythmic\nstability, and tonal stability, and is able to capture the perceptual features\nof music. The timbre feature, which is used in speaker identification,\nrepresents the singers' voice features. Furthermore, we propose a convolutional\nrecurrent neural network (CRNN) to combine three features for singer\nidentification. The model firstly fuses the frame-level feature and timbre\nfeature and then combines middle-level features to the mix features. In\nexperiments, the proposed method achieves comparable performance on an average\nF1 score of 0.81 on the benchmark dataset of Artist20, which significantly\nimproves related works.",
    "descriptor": "\nComments: Accepted by IJCNN2022 (The 2022 International Joint Conference on Neural Networks). arXiv admin note: text overlap with arXiv:2002.06817 by other authors\n",
    "authors": [
      "Xulong Zhang",
      "Jianzong Wang",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.11817"
  },
  {
    "id": "arXiv:2205.11819",
    "title": "Quarantine: Sparsity Can Uncover the Trojan Attack Trigger for Free",
    "abstract": "Trojan attacks threaten deep neural networks (DNNs) by poisoning them to\nbehave normally on most samples, yet to produce manipulated results for inputs\nattached with a particular trigger. Several works attempt to detect whether a\ngiven DNN has been injected with a specific trigger during the training. In a\nparallel line of research, the lottery ticket hypothesis reveals the existence\nof sparse subnetworks which are capable of reaching competitive performance as\nthe dense network after independent training. Connecting these two dots, we\ninvestigate the problem of Trojan DNN detection from the brand new lens of\nsparsity, even when no clean training data is available. Our crucial\nobservation is that the Trojan features are significantly more stable to\nnetwork pruning than benign features. Leveraging that, we propose a novel\nTrojan network detection regime: first locating a \"winning Trojan lottery\nticket\" which preserves nearly full Trojan information yet only chance-level\nperformance on clean inputs; then recovering the trigger embedded in this\nalready isolated subnetwork. Extensive experiments on various datasets, i.e.,\nCIFAR-10, CIFAR-100, and ImageNet, with different network architectures, i.e.,\nVGG-16, ResNet-18, ResNet-20s, and DenseNet-100 demonstrate the effectiveness\nof our proposal. Codes are available at\nhttps://github.com/VITA-Group/Backdoor-LTH.",
    "descriptor": "",
    "authors": [
      "Tianlong Chen",
      "Zhenyu Zhang",
      "Yihua Zhang",
      "Shiyu Chang",
      "Sijia Liu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.11819"
  },
  {
    "id": "arXiv:2205.11821",
    "title": "MetaSID: Singer Identification with Domain Adaptation for Metaverse",
    "abstract": "Metaverse has stretched the real world into unlimited space. There will be\nmore live concerts in Metaverse. The task of singer identification is to\nidentify the song belongs to which singer. However, there has been a tough\nproblem in singer identification, which is the different live effects. The\nstudio version is different from the live version, the data distribution of the\ntraining set and the test set are different, and the performance of the\nclassifier decreases. This paper proposes the use of the domain adaptation\nmethod to solve the live effect in singer identification. Three methods of\ndomain adaptation combined with Convolutional Recurrent Neural Network (CRNN)\nare designed, which are Maximum Mean Discrepancy (MMD), gradient reversal\n(Revgrad), and Contrastive Adaptation Network (CAN). MMD is a distance-based\nmethod, which adds domain loss. Revgrad is based on the idea that learned\nfeatures can represent different domain samples. CAN is based on class\nadaptation, it takes into account the correspondence between the categories of\nthe source domain and target domain. Experimental results on the public dataset\nof Artist20 show that CRNN-MMD leads to an improvement over the baseline CRNN\nby 0.14. The CRNN-RevGrad outperforms the baseline by 0.21. The CRNN-CAN\nachieved state of the art with the F1 measure value of 0.83 on album split.",
    "descriptor": "\nComments: Accepted by IJCNN2022 (The 2022 International Joint Conference on Neural Networks)\n",
    "authors": [
      "Xulong Zhang",
      "Jianzong Wang",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.11821"
  },
  {
    "id": "arXiv:2205.11822",
    "title": "Maieutic Prompting: Logically Consistent Reasoning with Recursive  Explanations",
    "abstract": "Despite their impressive capabilities, large pre-trained language models\n(LMs) struggle with consistent reasoning; recently, prompting LMs to generate\nexplanations that self-guide the inference has emerged as a promising direction\nto amend this. However, these approaches are fundamentally bounded by the\ncorrectness of explanations, which themselves are often noisy and inconsistent.\nIn this work, we develop Maieutic Prompting, which infers a correct answer to a\nquestion even from the noisy and inconsistent generations of LM. Maieutic\nPrompting induces a tree of explanations abductively (e.g. X is true, because\n...) and recursively, then frames the inference as a satisfiability problem\nover these explanations and their logical relations. We test Maieutic Prompting\nfor true/false QA on three challenging benchmarks that require complex\ncommonsense reasoning. Maieutic Prompting achieves up to 20% better accuracy\nthan state-of-the-art prompting methods, and as a fully unsupervised approach,\nperforms competitively with supervised models. We also show that Maieutic\nPrompting improves robustness in inference while providing interpretable\nrationales.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Jaehun Jung",
      "Lianhui Qin",
      "Sean Welleck",
      "Faeze Brahman",
      "Chandra Bhagavatula",
      "Ronan Le Bras",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11822"
  },
  {
    "id": "arXiv:2205.11823",
    "title": "Thunder: Thumbnail based Fast Lightweight Image Denoising Network",
    "abstract": "To achieve promising results on removing noise from real-world images, most\nof existing denoising networks are formulated with complex network structure,\nmaking them impractical for deployment. Some attempts focused on reducing the\nnumber of filters and feature channels but suffered from large performance\nloss, and a more practical and lightweight denoising network with fast\ninference speed is of high demand.\nTo this end, a \\textbf{Thu}mb\\textbf{n}ail based \\textbf{D}\\textbf{e}noising\nNetwo\\textbf{r}k dubbed Thunder, is proposed and implemented as a lightweight\nstructure for fast restoration without comprising the denoising capabilities.\nSpecifically, the Thunder model contains two newly-established modules:\n(1) a wavelet-based Thumbnail Subspace Encoder (TSE) which can leverage\nsub-bands correlation to provide an approximate thumbnail based on the\nlow-frequent feature; (2) a Subspace Projection based Refine Module (SPR) which\ncan restore the details for thumbnail progressively based on the subspace\nprojection approach.\nExtensive experiments have been carried out on two real-world denoising\nbenchmarks, demonstrating that the proposed Thunder outperforms the existing\nlightweight models and achieves competitive performance on PSNR and SSIM when\ncompared with the complex designs.",
    "descriptor": "",
    "authors": [
      "Yifeng Zhou",
      "Xing Xu",
      "Shuaicheng Liu",
      "Guoqing Wang",
      "Huimin Lu",
      "Heng Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.11823"
  },
  {
    "id": "arXiv:2205.11824",
    "title": "TDASS: Target Domain Adaptation Speech Synthesis Framework for  Multi-speaker Low-Resource TTS",
    "abstract": "Recently, synthesizing personalized speech by text-to-speech (TTS)\napplication is highly demanded. But the previous TTS models require a mass of\ntarget speaker speeches for training. It is a high-cost task, and hard to\nrecord lots of utterances from the target speaker. Data augmentation of the\nspeeches is a solution but leads to the low-quality synthesis speech problem.\nSome multi-speaker TTS models are proposed to address the issue. But the\nquantity of utterances of each speaker imbalance leads to the voice similarity\nproblem. We propose the Target Domain Adaptation Speech Synthesis Network\n(TDASS) to address these issues. Based on the backbone of the Tacotron2 model,\nwhich is the high-quality TTS model, TDASS introduces a self-interested\nclassifier for reducing the non-target influence. Besides, a special gradient\nreversal layer with different operations for target and non-target is added to\nthe classifier. We evaluate the model on a Chinese speech corpus, the\nexperiments show the proposed method outperforms the baseline method in terms\nof voice quality and voice similarity.",
    "descriptor": "\nComments: Accepted by IJCNN2022 (The 2022 International Joint Conference on Neural Networks)\n",
    "authors": [
      "Xulong Zhang",
      "Jianzong Wang",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.11824"
  },
  {
    "id": "arXiv:2205.11825",
    "title": "A Rate Control Algorithm for Video-based Point Cloud Compression",
    "abstract": "Video-based point cloud compression (V-PCC) has been an emerging compression\ntechnology that projects the 3D point cloud into a 2D plane and uses high\nefficiency video coding (HEVC) to encode the projected 2D videos (geometry\nvideo and color video). In this work, we propose a rate control algorithm for\nthe all-intra (AI) configuration of V-PCC. Specifically, based on the\nquality-dependency existing in the projected videos, we develop an optimization\nformulation to allocate target bits between the geometry video and the color\nvideo. Furthermore, we design a two-pass method for HEVC to adapt to the new\ncharacteristics of projected videos, which significantly improves the accuracy\nof rate control. Experimental results demonstrate that our algorithm\noutperforms V-PCC without rate control in R-D performance with just 0.43%\nbitrate error.",
    "descriptor": "\nComments: 5 pages, 3 figures, 4 tables\n",
    "authors": [
      "Fangyu Shen",
      "Wei Gao"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2205.11825"
  },
  {
    "id": "arXiv:2205.11826",
    "title": "Lack of Fluency is Hurting Your Translation Model",
    "abstract": "Many machine translation models are trained on bilingual corpus, which\nconsist of aligned sentence pairs from two different languages with same\nsemantic. However, there is a qualitative discrepancy between train and test\nset in bilingual corpus. While the most train sentences are created via\nautomatic techniques such as crawling and sentence-alignment methods, the test\nsentences are annotated with the consideration of fluency by human. We suppose\nthis discrepancy in training corpus will yield performance drop of translation\nmodel. In this work, we define \\textit{fluency noise} to determine which parts\nof train sentences cause them to seem unnatural. We show that \\textit{fluency\nnoise} can be detected by simple gradient-based method with pre-trained\nclassifier. By removing \\textit{fluency noise} in train sentences, our final\nmodel outperforms the baseline on WMT-14 DE$\\rightarrow$EN and\nRU$\\rightarrow$EN. We also show the compatibility with back-translation\naugmentation, which has been commonly used to improve the fluency of the\ntranslation model. At last, the qualitative analysis of \\textit{fluency noise}\nprovides the insight of what points we should focus on.",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Jaehyo Yoo",
      "Jaewoo Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11826"
  },
  {
    "id": "arXiv:2205.11827",
    "title": "Advanced Manufacturing Configuration by Sample-efficient Batch Bayesian  Optimization",
    "abstract": "We propose a framework for the configuration and operation of\nexpensive-to-evaluate advanced manufacturing methods, based on Bayesian\noptimization. The framework unifies a tailored acquisition function, a parallel\nacquisition procedure, and the integration of process information providing\ncontext to the optimization procedure. The novel acquisition function is\ndemonstrated and analyzed on benchmark illustrative problems. We apply the\noptimization approach to atmospheric plasma spraying in simulation and\nexperiments. Our results demonstrate that the proposed framework can\nefficiently find input parameters that produce the desired outcome and minimize\nthe process cost.",
    "descriptor": "\nComments: 8 pages, 5 figures. Submitted to IEEE RA-L. arXiv admin note: substantial text overlap with arXiv:2103.13881\n",
    "authors": [
      "Xavier Guidetti",
      "Alisa Rupenyan",
      "Lutz Fassl",
      "Majid Nabavi",
      "John Lygeros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.11827"
  },
  {
    "id": "arXiv:2205.11829",
    "title": "Unsupervised Difference Learning for Noisy Rigid Image Alignment",
    "abstract": "Rigid image alignment is a fundamental task in computer vision, while the\ntraditional algorithms are either too sensitive to noise or time-consuming.\nRecent unsupervised image alignment methods developed based on spatial\ntransformer networks show an improved performance on clean images but will not\nachieve satisfactory performance on noisy images due to its heavy reliance on\npixel value comparations. To handle such challenging applications, we report a\nnew unsupervised difference learning (UDL) strategy and apply it to rigid image\nalignment. UDL exploits the quantitative properties of regression tasks and\nconverts the original unsupervised problem to pseudo supervised problem. Under\nthe new UDL-based image alignment pipeline, rotation can be accurately\nestimated on both clean and noisy images and translations can then be easily\nsolved. Experimental results on both nature and cryo-EM images demonstrate the\nefficacy of our UDL-based unsupervised rigid image alignment method.",
    "descriptor": "",
    "authors": [
      "Yu-Xuan Chen",
      "Dagan Feng",
      "Hong-Bin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11829"
  },
  {
    "id": "arXiv:2205.11830",
    "title": "TraCon: A novel dataset for real-time traffic cones detection using deep  learning",
    "abstract": "Substantial progress has been made in the field of object detection in road\nscenes. However, it is mainly focused on vehicles and pedestrians. To this end,\nwe investigate traffic cone detection, an object category crucial for road\neffects and maintenance. In this work, the YOLOv5 algorithm is employed, in\norder to find a solution for the efficient and fast detection of traffic cones.\nThe YOLOv5 can achieve a high detection accuracy with the score of IoU up to\n91.31%. The proposed method is been applied to an RGB roadwork image dataset,\ncollected from various sources.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Iason Katsamenis",
      "Eleni Eirini Karolou",
      "Agapi Davradou",
      "Eftychios Protopapadakis",
      "Anastasios Doulamis",
      "Nikolaos Doulamis",
      "Dimitris Kalogeras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11830"
  },
  {
    "id": "arXiv:2205.11833",
    "title": "Diverse Lottery Tickets Boost Ensemble from a Single Pretrained Model",
    "abstract": "Ensembling is a popular method used to improve performance as a last resort.\nHowever, ensembling multiple models finetuned from a single pretrained model\nhas been not very effective; this could be due to the lack of diversity among\nensemble members. This paper proposes Multi-Ticket Ensemble, which finetunes\ndifferent subnetworks of a single pretrained model and ensembles them. We\nempirically demonstrated that winning-ticket subnetworks produced more diverse\npredictions than dense networks, and their ensemble outperformed the standard\nensemble on some tasks.",
    "descriptor": "\nComments: Workshop on Challenges & Perspectives in Creating Large Language Models (BigScience) 2022\n",
    "authors": [
      "Sosuke Kobayashi",
      "Shun Kiyono",
      "Jun Suzuki",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11833"
  },
  {
    "id": "arXiv:2205.11836",
    "title": "Charon: a FrameNet Annotation Tool for Multimodal Corpora",
    "abstract": "This paper presents Charon, a web tool for annotating multimodal corpora with\nFrameNet categories. Annotation can be made for corpora containing both static\nimages and video sequences paired - or not - with text sequences. The pipeline\nfeatures, besides the annotation interface, corpus import and pre-processing\ntools.",
    "descriptor": "\nComments: Accepted submission for the The Sixteenth Linguistic Annotation Workshop (LAW-XVI 2022)\n",
    "authors": [
      "Frederico Belcavello",
      "Marcelo Viridiano",
      "Ely Edison Matos",
      "Tiago Timponi Torrent"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11836"
  },
  {
    "id": "arXiv:2205.11837",
    "title": "Testing interval arithmetic libraries, including their IEEE-1788  compliance",
    "abstract": "As developers of libraries implementing interval arithmetic, we faced the\nsame difficulties when it came to testing our libraries. What must be tested?\nHow can we devise relevant test cases for unit testing? How can we ensure a\nhigh (and possibly 100%) test coverage? In this paper we list the different\naspects that, in our opinion, must be tested, giving indications on the choice\nof test cases. Then we examine how several interval arithmetic libraries\nactually perform tests. Next, we introduce two frameworks developed\nspecifically to gather test cases and to incorporate easily new libraries in\norder to test them, namely JInterval and ITF1788. Not every important aspects\nof our libraries fit in these frameworks and we list extra tests that we deem\nimportant, but not easy, to perform.",
    "descriptor": "",
    "authors": [
      "Nathalie Revol",
      "Luis Benet",
      "Luca Ferranti",
      "Sergei Zhilin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.11837"
  },
  {
    "id": "arXiv:2205.11838",
    "title": "Model-Based and Graph-Based Priors for Group Testing",
    "abstract": "The goal of the group testing problem is to identify a set of defective items\nwithin a larger set of items, using suitably-designed tests whose outcomes\nindicate whether any defective item is present. In this paper, we study how the\nnumber of tests can be significantly decreased by leveraging the structural\ndependencies between the items, i.e., by incorporating prior information. To do\nso, we pursue two different perspectives: (i) As a generalization of the\nuniform combinatorial prior, we consider the case that the defective set is\nuniform over a \\emph{subset} of all possible sets of a given size, and study\nhow this impacts the information-theoretic limits on the number of tests for\napproximate recovery; (ii) As a generalization of the i.i.d.~prior, we\nintroduce a new class of priors based on the Ising model, where the associated\ngraph represents interactions between items. We show that this naturally leads\nto an Integer Quadratic Program decoder, which can be converted to an Integer\nLinear Program and/or relaxed to a non-integer variant for improved\ncomputational complexity, while maintaining strong empirical recovery\nperformance.",
    "descriptor": "",
    "authors": [
      "Ivan Lau",
      "Jonathan Scarlett",
      "Yang Sun"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11838"
  },
  {
    "id": "arXiv:2205.11840",
    "title": "Lutma: a Frame-Making Tool for Collaborative FrameNet Development",
    "abstract": "This paper presents Lutma, a collaborative, semi-constrained, tutorial-based\ntool for contributing frames and lexical units to the Global FrameNet\ninitiative. The tool parameterizes the process of frame creation, avoiding\nconsistency violations and promoting the integration of frames contributed by\nthe community with existing frames. Lutma is structured in a wizard-like\nfashion so as to provide users with text and video tutorials relevant for each\nstep in the frame creation process. We argue that this tool will allow for a\nsensible expansion of FrameNet coverage in terms of both languages and cultural\nperspectives encoded by them, positioning frames as a viable alternative for\nrepresenting perspective in language models.",
    "descriptor": "\nComments: Accepted submission for the 1st Workshop on Perspectivist Approaches to NLP (NLPerspectives)\n",
    "authors": [
      "Tiago Timponi Torrent",
      "Arthur Lorenzi",
      "Ely Edison da Silva Matos",
      "Frederico Belcavello",
      "Marcelo Viridiano",
      "Maucha Andrade Gamonal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11840"
  },
  {
    "id": "arXiv:2205.11841",
    "title": "SUSing: SU-net for Singing Voice Synthesis",
    "abstract": "Singing voice synthesis is a generative task that involves multi-dimensional\ncontrol of the singing model, including lyrics, pitch, and duration, and\nincludes the timbre of the singer and singing skills such as vibrato. In this\npaper, we proposed SU-net for singing voice synthesis named SUSing.\nSynthesizing singing voice is treated as a translation task between lyrics and\nmusic score and spectrum. The lyrics and music score information is encoded\ninto a two-dimensional feature representation through the convolution layer.\nThe two-dimensional feature and its frequency spectrum are mapped to the target\nspectrum in an autoregressive manner through a SU-net network. Within the\nSU-net the stripe pooling method is used to replace the alternate global\npooling method to learn the vertical frequency relationship in the spectrum and\nthe changes of frequency in the time domain. The experimental results on the\npublic dataset Kiritan show that the proposed method can synthesize more\nnatural singing voices.",
    "descriptor": "\nComments: Accepted by IJCNN2022 (The 2022 International Joint Conference on Neural Networks)\n",
    "authors": [
      "Xulong Zhang",
      "Jianzong Wang",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.11841"
  },
  {
    "id": "arXiv:2205.11843",
    "title": "Beam Aware Stochastic Multihop Routing for Flying Ad-hoc Networks",
    "abstract": "Routing is a crucial component in the design of Flying Ad-Hoc Networks\n(FANETs). State of the art routing solutions exploit the position of Unmanned\nAerial Vehicles (UAVs) and their mobility information to determine the\nexistence of links between them, but this information is often unreliable, as\nthe topology of FANETs can change quickly and unpredictably. In order to\nimprove the tracking performance, the uncertainty introduced by imperfect\nmeasurements and tracking algorithms needs to be accounted for in the routing.\nAnother important element to consider is beamforming, which can reduce\ninterference, but requires accurate channel and position information to work.\nIn this work, we present the Beam Aware Stochastic Multihop Routing for FANETs\n(BA-SMURF), a Software-Defined Networking (SDN) routing scheme that takes into\naccount the positioning uncertainty and beamforming design to find the most\nreliable routes in a FANET. Our simulation results show that joint\nconsideration of the beamforming and routing can provide a 5% throughput\nimprovement with respect to the state of the art.",
    "descriptor": "",
    "authors": [
      "Anay Ajit Deshpande",
      "Roberto Pereira",
      "Federico Chiariotti",
      "Adriano Pastore",
      "Xavier Mestre",
      "Andrea Zanella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11843"
  },
  {
    "id": "arXiv:2205.11845",
    "title": "CDFKD-MFS: Collaborative Data-free Knowledge Distillation via  Multi-level Feature Sharing",
    "abstract": "Recently, the compression and deployment of powerful deep neural networks\n(DNNs) on resource-limited edge devices to provide intelligent services have\nbecome attractive tasks. Although knowledge distillation (KD) is a feasible\nsolution for compression, its requirement on the original dataset raises\nprivacy concerns. In addition, it is common to integrate multiple pretrained\nmodels to achieve satisfactory performance. How to compress multiple models\ninto a tiny model is challenging, especially when the original data are\nunavailable. To tackle this challenge, we propose a framework termed\ncollaborative data-free knowledge distillation via multi-level feature sharing\n(CDFKD-MFS), which consists of a multi-header student module, an asymmetric\nadversarial data-free KD module, and an attention-based aggregation module. In\nthis framework, the student model equipped with a multi-level feature-sharing\nstructure learns from multiple teacher models and is trained together with a\ngenerator in an asymmetric adversarial manner. When some real samples are\navailable, the attention module adaptively aggregates predictions of the\nstudent headers, which can further improve performance. We conduct extensive\nexperiments on three popular computer visual datasets. In particular, compared\nwith the most competitive alternative, the accuracy of the proposed framework\nis 1.18\\% higher on the CIFAR-100 dataset, 1.67\\% higher on the Caltech-101\ndataset, and 2.99\\% higher on the mini-ImageNet dataset.",
    "descriptor": "",
    "authors": [
      "Zhiwei Hao",
      "Yong Luo",
      "Zhi Wang",
      "Han Hu",
      "Jianping An"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11845"
  },
  {
    "id": "arXiv:2205.11849",
    "title": "Collaborative 3D Object Detection for Automatic Vehicle Systems via  Learnable Communications",
    "abstract": "Accurate detection of objects in 3D point clouds is a key problem in\nautonomous driving systems. Collaborative perception can incorporate\ninformation from spatially diverse sensors and provide significant benefits for\nimproving the perception accuracy of autonomous driving systems. In this work,\nwe consider that the autonomous vehicle uses local point cloud data and\ncombines information from neighboring infrastructures through wireless links\nfor cooperative 3D object detection. However, information sharing among vehicle\nand infrastructures in predefined communication schemes may result in\ncommunication congestion and/or bring limited performance improvement. To this\nend, we propose a novel collaborative 3D object detection framework that\nconsists of three components: feature learning networks that map point clouds\ninto feature maps; an efficient communication block that propagates compact and\nfine-grained query feature maps from vehicle to support infrastructures and\noptimizes attention weights between query and key to refine support feature\nmaps; a region proposal network that fuses local feature maps and weighted\nsupport feature maps for 3D object detection. We evaluate the performance of\nthe proposed framework using a synthetic cooperative dataset created in two\ncomplex driving scenarios: a roundabout and a T-junction. Experiment results\nand bandwidth usage analysis demonstrate that our approach can save\ncommunication and computation costs and significantly improve detection\nperformance under different detection difficulties in all scenarios.",
    "descriptor": "",
    "authors": [
      "Junyong Wang",
      "Yuan Zeng",
      "Yi Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11849"
  },
  {
    "id": "arXiv:2205.11850",
    "title": "Faithful Explanations for Deep Graph Models",
    "abstract": "This paper studies faithful explanations for Graph Neural Networks (GNNs).\nFirst, we provide a new and general method for formally characterizing the\nfaithfulness of explanations for GNNs. It applies to existing explanation\nmethods, including feature attributions and subgraph explanations. Second, our\nanalytical and empirical results demonstrate that feature attribution methods\ncannot capture the nonlinear effect of edge features, while existing subgraph\nexplanation methods are not faithful. Third, we introduce \\emph{k-hop\nExplanation with a Convolutional Core} (KEC), a new explanation method that\nprovably maximizes faithfulness to the original GNN by leveraging information\nabout the graph structure in its adjacency matrix and its \\emph{k-th} power.\nLastly, our empirical results over both synthetic and real-world datasets for\nclassification and anomaly detection tasks with GNNs demonstrate the\neffectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Zifan Wang",
      "Yuhang Yao",
      "Chaoran Zhang",
      "Han Zhang",
      "Youjie Kang",
      "Carlee Joe-Wong",
      "Matt Fredrikson",
      "Anupam Datta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11850"
  },
  {
    "id": "arXiv:2205.11853",
    "title": "Real-Time Trajectory Planning for Autonomous Driving with Gaussian  Process and Incremental Refinement",
    "abstract": "Real-time kinodynamic trajectory planning in dynamic environments is critical\nyet challenging for autonomous driving. In this letter, we propose an efficient\ntrajectory planning system for autonomous driving in complex dynamic scenarios\nthrough iterative and incremental path-speed optimization. Exploiting the\ndecoupled structure of the planning problem, a path planner based on Gaussian\nprocess first generates a continuous arc-length parameterized path in the\nFren\\'{e}t frame, considering static obstacle avoidance and curvature\nconstraints. We theoretically prove that it is a good generalization of the\nwell-known jerk optimal solution. An efficient s-t graph search method is\nintroduced to find a speed profile along the generated path to deal with\ndynamic environments. Finally, the path and speed are optimized incrementally\nand iteratively to ensure kinodynamic feasibility. Various simulated scenarios\nwith both static obstacles and dynamic agents verify the effectiveness and\nrobustness of our proposed method. Experimental results show that our method\ncan run at 20 Hz. The source code is released as an open-source package.",
    "descriptor": "\nComments: ICRA2022, longer version, code this https URL\n",
    "authors": [
      "Cheng Jie",
      "Chen Yingbing",
      "Zhang Qingwen",
      "Gan Lu",
      "Liu Ming"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.11853"
  },
  {
    "id": "arXiv:2205.11854",
    "title": "Multi-Agent Collaborative Inference via DNN Decoupling: Intermediate  Feature Compression and Edge Learning",
    "abstract": "Recently, deploying deep neural network (DNN) models via collaborative\ninference, which splits a pre-trained model into two parts and executes them on\nuser equipment (UE) and edge server respectively, becomes attractive. However,\nthe large intermediate feature of DNN impedes flexible decoupling, and existing\napproaches either focus on the single UE scenario or simply define tasks\nconsidering the required CPU cycles, but ignore the indivisibility of a single\nDNN layer. In this paper, we study the multi-agent collaborative inference\nscenario, where a single edge server coordinates the inference of multiple UEs.\nOur goal is to achieve fast and energy-efficient inference for all UEs. To\nachieve this goal, we first design a lightweight autoencoder-based method to\ncompress the large intermediate feature. Then we define tasks according to the\ninference overhead of DNNs and formulate the problem as a Markov decision\nprocess (MDP). Finally, we propose a multi-agent hybrid proximal policy\noptimization (MAHPPO) algorithm to solve the optimization problem with a hybrid\naction space. We conduct extensive experiments with different types of\nnetworks, and the results show that our method can reduce up to 56\\% of\ninference latency and save up to 72\\% of energy consumption.",
    "descriptor": "",
    "authors": [
      "Zhiwei Hao",
      "Guanyu Xu",
      "Yong Luo",
      "Han Hu",
      "Jianping An",
      "Shiwen Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11854"
  },
  {
    "id": "arXiv:2205.11857",
    "title": "Comprehensive Privacy Analysis on Federated Recommender System against  Attribute Inference Attacks",
    "abstract": "In recent years, recommender systems are crucially important for the delivery\nof personalized services that satisfy users' preferences. With personalized\nrecommendation services, users can enjoy a variety of recommendations such as\nmovies, books, ads, restaurants, and more. Despite the great benefits,\npersonalized recommendations typically require the collection of personal data\nfor user modelling and analysis, which can make users susceptible to attribute\ninference attacks. Specifically, the vulnerability of existing centralized\nrecommenders under attribute inference attacks leaves malicious attackers a\nbackdoor to infer users' private attributes, as the systems remember\ninformation of their training data (i.e., interaction data and side\ninformation). An emerging practice is to implement recommender systems in the\nfederated setting, which enables all user devices to collaboratively learn a\nshared global recommender while keeping all the training data on device.\nHowever, the privacy issues in federated recommender systems have been rarely\nexplored. In this paper, we first design a novel attribute inference attacker\nto perform a comprehensive privacy analysis of the state-of-the-art federated\nrecommender models. The experimental results show that the vulnerability of\neach model component against attribute inference attack is varied, highlighting\nthe need for new defense approaches. Therefore, we propose a novel adaptive\nprivacy-preserving approach to protect users' sensitive data in the presence of\nattribute inference attacks and meanwhile maximize the recommendation accuracy.\nExtensive experimental results on two real-world datasets validate the superior\nperformance of our model on both recommendation effectiveness and resistance to\ninference attacks.",
    "descriptor": "",
    "authors": [
      "Shijie Zhang",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.11857"
  },
  {
    "id": "arXiv:2205.11859",
    "title": "Stability in data-driven MPC: an inherent robustness perspective",
    "abstract": "Data-driven model predictive control (DD-MPC) based on Willems' Fundamental\nLemma has received much attention in recent years, allowing to control systems\ndirectly based on an implicit data-dependent system description. The literature\ncontains many successful practical applications as well as theoretical results\non closed-loop stability and robustness. In this paper, we provide a tutorial\nintroduction to DD-MPC for unknown linear time-invariant (LTI) systems with\nfocus on (robust) closed-loop stability. We first address the scenario of\nnoise-free data, for which we present a DD-MPC scheme with terminal equality\nconstraints and derive closed-loop properties. In case of noisy data, we\nintroduce a simple yet powerful approach to analyze robust stability of DD-MPC\nby combining continuity of DD-MPC w.r.t. noise with inherent robustness of\nmodel-based MPC, i.e., robustness of nominal MPC w.r.t. small disturbances.\nMoreover, we discuss how the presented proof technique allows to show\nclosed-loop stability of a variety of DD-MPC schemes with noisy data, as long\nas the corresponding model-based MPC is inherently robust.",
    "descriptor": "",
    "authors": [
      "Julian Berberich",
      "Johannes K\u00f6hler",
      "Matthias A. M\u00fcller",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11859"
  },
  {
    "id": "arXiv:2205.11861",
    "title": "Deep Reinforcement Learning for Radio Resource Allocation in NOMA-based  Remote State Estimation",
    "abstract": "Remote state estimation, where many sensors send their measurements of\ndistributed dynamic plants to a remote estimator over shared wireless\nresources, is essential for mission-critical applications of Industry 4.0. Most\nof the existing works on remote state estimation assumed orthogonal multiple\naccess and the proposed dynamic radio resource allocation algorithms can only\nwork for very small-scale settings. In this work, we consider a remote\nestimation system with non-orthogonal multiple access. We formulate a novel\ndynamic resource allocation problem for achieving the minimum overall long-term\naverage estimation mean-square error. Both the estimation quality state and the\nchannel quality state are taken into account for decision making at each time.\nThe problem has a large hybrid discrete and continuous action space for joint\nchannel assignment and power allocation. We propose a novel action-space\ncompression method and develop an advanced deep reinforcement learning\nalgorithm to solve the problem. Numerical results show that our algorithm\nsolves the resource allocation problem effectively, presents much better\nscalability than the literature, and provides significant performance gain\ncompared to some benchmarks.",
    "descriptor": "\nComments: Paper submitted to IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Gaoyang Pang",
      "Wanchun Liu",
      "Yonghui Li",
      "Branka Vucetic"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.11861"
  },
  {
    "id": "arXiv:2205.11863",
    "title": "Overview of STEM Science as Process, Method, Material, and Data Named  Entities",
    "abstract": "We are faced with an unprecedented production in scholarly publications\nworldwide. Stakeholders in the digital libraries posit that the document-based\npublishing paradigm has reached the limits of adequacy. Instead, structured,\nmachine-interpretable, fine-grained scholarly knowledge publishing as Knowledge\nGraphs (KG) is strongly advocated. In this work, we develop and analyze a\nlarge-scale structured dataset of STEM articles across 10 different\ndisciplines, viz. Agriculture, Astronomy, Biology, Chemistry, Computer Science,\nEarth Science, Engineering, Material Science, Mathematics, and Medicine. Our\nanalysis is defined over a large-scale corpus comprising 60K abstracts\nstructured as four scientific entities process, method, material, and data.\nThus our study presents, for the first-time, an analysis of a large-scale\nmultidisciplinary corpus under the construct of four named entity labels that\nare specifically defined and selected to be domain-independent as opposed to\ndomain-specific. The work is then inadvertently a feasibility test of\ncharacterizing multidisciplinary science with domain-independent concepts.\nFurther, to summarize the distinct facets of scientific knowledge per concept\nper discipline, a set of word cloud visualizations are offered. The\nSTEM-NER-60k corpus, created in this work, comprises over 1M extracted entities\nfrom 60k STEM articles obtained from a major publishing platform and is\npublicly released https://github.com/jd-coderepos/stem-ner-60k.",
    "descriptor": "\nComments: 9 pages, 17 figures, In Review submission at Queer in AI @ NAACL 2022 Research Symposia (this https URL)\n",
    "authors": [
      "Jennifer D'Souza"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.11863"
  },
  {
    "id": "arXiv:2205.11867",
    "title": "Building a Dialogue Corpus Annotated with Expressed and Experienced  Emotions",
    "abstract": "In communication, a human would recognize the emotion of an interlocutor and\nrespond with an appropriate emotion, such as empathy and comfort. Toward\ndeveloping a dialogue system with such a human-like ability, we propose a\nmethod to build a dialogue corpus annotated with two kinds of emotions. We\ncollect dialogues from Twitter and annotate each utterance with the emotion\nthat a speaker put into the utterance (expressed emotion) and the emotion that\na listener felt after listening to the utterance (experienced emotion). We\nbuilt a dialogue corpus in Japanese using this method, and its statistical\nanalysis revealed the differences between expressed and experienced emotions.\nWe conducted experiments on recognition of the two kinds of emotions. The\nexperimental results indicated the difficulty in recognizing experienced\nemotions and the effectiveness of multi-task learning of the two kinds of\nemotions. We hope that the constructed corpus will facilitate the study on\nemotion recognition in a dialogue and emotion-aware dialogue response\ngeneration.",
    "descriptor": "\nComments: ACL Student Research Workshop (SRW) 2022\n",
    "authors": [
      "Tatsuya Ide",
      "Daisuke Kawahara"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11867"
  },
  {
    "id": "arXiv:2205.11874",
    "title": "Approximation speed of quantized vs. unquantized ReLU neural networks  and beyond",
    "abstract": "We consider general approximation families encompassing ReLU neural networks.\nOn the one hand, we introduce a new property, that we call\n$\\infty$-encodability, which lays a framework that we use (i) to guarantee that\nReLU networks can be uniformly quantized and still have approximation speeds\ncomparable to unquantized ones, and (ii) to prove that ReLU networks share a\ncommon limitation with many other approximation families: the approximation\nspeed of a set C is bounded from above by an encoding complexity of C (a\ncomplexity well-known for many C's). The property of $\\infty$-encodability\nallows us to unify and generalize known results in which it was implicitly\nused. On the other hand, we give lower and upper bounds on the Lipschitz\nconstant of the mapping that associates the weights of a network to the\nfunction they represent in L^p. It is given in terms of the width, the depth of\nthe network and a bound on the weight's norm, and it is based on well-known\nupper bounds on the Lipschitz constants of the functions represented by ReLU\nnetworks. This allows us to recover known results, to establish new bounds on\ncovering numbers, and to characterize the accuracy of naive uniform\nquantization of ReLU networks.",
    "descriptor": "",
    "authors": [
      "Antoine Gonon",
      "Nicolas Brisebarre",
      "R\u00e9mi Gribonval",
      "Elisa Riccietti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.11874"
  },
  {
    "id": "arXiv:2205.11876",
    "title": "Unsupervised Misaligned Infrared and Visible Image Fusion via  Cross-Modality Image Generation and Registration",
    "abstract": "Recent learning-based image fusion methods have marked numerous progress in\npre-registered multi-modality data, but suffered serious ghosts dealing with\nmisaligned multi-modality data, due to the spatial deformation and the\ndifficulty narrowing cross-modality discrepancy. To overcome the obstacles, in\nthis paper, we present a robust cross-modality generation-registration paradigm\nfor unsupervised misaligned infrared and visible image fusion (IVIF).\nSpecifically, we propose a Cross-modality Perceptual Style Transfer Network\n(CPSTN) to generate a pseudo infrared image taking a visible image as input.\nBenefiting from the favorable geometry preservation ability of the CPSTN, the\ngenerated pseudo infrared image embraces a sharp structure, which is more\nconducive to transforming cross-modality image alignment into mono-modality\nregistration coupled with the structure-sensitive of the infrared image. In\nthis case, we introduce a Multi-level Refinement Registration Network (MRRN) to\npredict the displacement vector field between distorted and pseudo infrared\nimages and reconstruct registered infrared image under the mono-modality\nsetting. Moreover, to better fuse the registered infrared images and visible\nimages, we present a feature Interaction Fusion Module (IFM) to adaptively\nselect more meaningful features for fusion in the Dual-path Interaction Fusion\nNetwork (DIFN). Extensive experimental results suggest that the proposed method\nperforms superior capability on misaligned cross-modality image fusion.",
    "descriptor": "",
    "authors": [
      "Di Wang",
      "Jinyuan Liu",
      "Xin Fan",
      "Risheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11876"
  },
  {
    "id": "arXiv:2205.11878",
    "title": "Distributed Randomness from Approximate Agreement",
    "abstract": "Randomisation is a critical tool in designing distributed systems. The common\ncoin primitive, enabling the system members to agree on an unpredictable random\nnumber, has proven to be particularly useful. We observe, however, that it is\nimpossible to implement a truly random common coin protocol in a fault-prone\nasynchronous system.\nTo circumvent this impossibility, we introduce two relaxations of the perfect\ncommon coin: (1) approximate common coin generating random numbers that are\nclose to each other; and (2) Monte Carlo common coin generating a common random\nnumber with an arbitrarily small, but non-zero, probability of failure.\nBuilding atop the approximate agreement primitive, we obtain efficient\nasynchronous implementations of the two abstractions, tolerating up to one\nthird of Byzantine processes. Our protocols do not assume trusted setup or\npublic key infrastructure and converge to the perfect coin exponentially fast\nin the protocol running time.\nBy plugging one of our protocols for Monte Carlo common coin in a well-known\nconsensus algorithm, we manage to get a binary Byzantine agreement protocol\nwith $O(n^3 \\log n)$ communication complexity, resilient against an adaptive\nadversary, and tolerating the optimal number $f<n/3$ of failures without\ntrusted setup or PKI. To the best of our knowledge, the best communication\ncomplexity for binary Byzantine agreement achieved so far in this setting is\n$O(n^4)$. We also show how the approximate common coin, combined with a variant\nof Gray code, can be used to solve an interesting problem of Intersecting\nRandom Subsets, which we introduce in this paper.",
    "descriptor": "",
    "authors": [
      "Luciano Freitas",
      "Petr Kuznetsov",
      "Andrei Tonkikh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.11878"
  },
  {
    "id": "arXiv:2205.11880",
    "title": "Hierarchical Vectorization for Portrait Images",
    "abstract": "Aiming at developing intuitive and easy-to-use portrait editing tools, we\npropose a novel vectorization method that can automatically convert raster\nimages into a 3-tier hierarchical representation. The base layer consists of a\nset of sparse diffusion curves (DC) which characterize salient geometric\nfeatures and low-frequency colors and provide means for semantic color transfer\nand facial expression editing. The middle level encodes specular highlights and\nshadows to large and editable Poisson regions (PR) and allows the user to\ndirectly adjust illumination via tuning the strength and/or changing shape of\nPR. The top level contains two types of pixel-sized PRs for high-frequency\nresiduals and fine details such as pimples and pigmentation. We also train a\ndeep generative model that can produce high-frequency residuals automatically.\nThanks to the meaningful organization of vector primitives, editing portraits\nbecomes easy and intuitive. In particular, our method supports color transfer,\nfacial expression editing, highlight and shadow editing and automatic\nretouching. Thanks to the linearity of the Laplace operator, we introduce alpha\nblending, linear dodge and linear burn to vector editing and show that they are\neffective in editing highlights and shadows. To quantitatively evaluate the\nresults, we extend the commonly used FLIP metric (which measures differences\nbetween two images) by considering illumination. The new metric, called\nillumination-sensitive FLIP or IS-FLIP, can effectively capture the salient\nchanges in color transfer results, and is more consistent with human perception\nthan FLIP and other quality measures on portrait images. We evaluate our method\non the FFHQR dataset and show that our method is effective for common portrait\nediting tasks, such as retouching, light editing, color transfer and expression\nediting. We will make the code and trained models publicly available.",
    "descriptor": "",
    "authors": [
      "Qian Fu",
      "Linlin Liu",
      "Fei Hou",
      "Ying He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.11880"
  },
  {
    "id": "arXiv:2205.11887",
    "title": "Accuracy on In-Domain Samples Matters When Building Out-of-Domain  detectors: A Reply to Marek et al. (2021)",
    "abstract": "We have noticed that Marek et al. (2021) try to re-implement our paper Zheng\net al. (2020a) in their work \"OodGAN: Generative Adversarial Network for\nOut-of-Domain Data Generation\". Our paper proposes a model to generate pseudo\nOOD samples that are akin to IN-Domain (IND) input utterances. These pseudo OOD\nsamples can be used to improve the OOD detection performance by optimizing an\nentropy regularization term when building the IND classifier. Marek et al.\n(2021) report a large gap between their re-implemented results and ours on the\nCLINC150 dataset (Larson et al., 2019). This paper discusses some key\nobservations that may have led to such a large gap. Most of these observations\noriginate from our experiments because Marek et al. (2021) have not released\ntheir codes1. One of the most important observations is that stronger IND\nclassifiers usually exhibit a more robust ability to detect OOD samples. We\nhope these observations help other researchers, including Marek et al. (2021),\nto develop better OOD detectors in their applications.",
    "descriptor": "\nComments: 4 pages, code available at this https URL\n",
    "authors": [
      "Yinhe Zheng",
      "Guanyi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11887"
  },
  {
    "id": "arXiv:2205.11888",
    "title": "Mind The Gap: Alleviating Local Imbalance for Unsupervised  Cross-Modality Medical Image Segmentation",
    "abstract": "Unsupervised cross-modality medical image adaptation aims to alleviate the\nsevere domain gap between different imaging modalities without using the target\ndomain label. A key in this campaign relies upon aligning the distributions of\nsource and target domain. One common attempt is to enforce the global alignment\nbetween two domains, which, however, ignores the fatal local-imbalance domain\ngap problem, i.e., some local features with larger domain gap are harder to\ntransfer. Recently, some methods conduct alignment focusing on local regions to\nimprove the efficiency of model learning. While this operation may cause a\ndeficiency of critical information from contexts. To tackle this limitation, we\npropose a novel strategy to alleviate the domain gap imbalance considering the\ncharacteristics of medical images, namely Global-Local Union Alignment.\nSpecifically, a feature-disentanglement style-transfer module first synthesizes\nthe target-like source-content images to reduce the global domain gap. Then, a\nlocal feature mask is integrated to reduce the 'inter-gap' for local features\nby prioritizing those discriminative features with larger domain gap. This\ncombination of global and local alignment can precisely localize the crucial\nregions in segmentation target while preserving the overall semantic\nconsistency. We conduct a series of experiments with two cross-modality\nadaptation tasks, i,e. cardiac substructure and abdominal multi-organ\nsegmentation. Experimental results indicate that our method exceeds the SOTA\nmethods by 3.92% Dice score in MRI-CT cardiac segmentation and 3.33% in the\nreverse direction.",
    "descriptor": "",
    "authors": [
      "Zixian Su",
      "Kai Yao",
      "Xi Yang",
      "Qiufeng Wang",
      "Yuyao Yan",
      "Kaizhu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11888"
  },
  {
    "id": "arXiv:2205.11894",
    "title": "Learning Interacting Dynamical Systems with Latent Gaussian Process ODEs",
    "abstract": "We study for the first time uncertainty-aware modeling of continuous-time\ndynamics of interacting objects. We introduce a new model that decomposes\nindependent dynamics of single objects accurately from their interactions. By\nemploying latent Gaussian process ordinary differential equations, our model\ninfers both independent dynamics and their interactions with reliable\nuncertainty estimates. In our formulation, each object is represented as a\ngraph node and interactions are modeled by accumulating the messages coming\nfrom neighboring objects. We show that efficient inference of such a complex\nnetwork of variables is possible with modern variational sparse Gaussian\nprocess inference techniques. We empirically demonstrate that our model\nimproves the reliability of long-term predictions over neural network based\nalternatives and it successfully handles missing dynamic or static information.\nFurthermore, we observe that only our model can successfully encapsulate\nindependent dynamics and interaction information in distinct functions and show\nthe benefit from this disentanglement in extrapolation scenarios.",
    "descriptor": "",
    "authors": [
      "\u00c7a\u011fatay Y\u0131ld\u0131z",
      "Melih Kandemir",
      "Barbara Rakitsch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.11894"
  },
  {
    "id": "arXiv:2205.11895",
    "title": "Efficient and Lightweight In-memory Computing Architecture for Hardware  Security",
    "abstract": "The paper proposes in-memory computing (IMC) solution for the design and\nimplementation of the Advanced Encryption Standard (AES) based cryptographic\nalgorithm. This research aims at increasing the cyber security of autonomous\ndriverless cars or robotic autonomous vehicles. The memristor (MR) designs are\nproposed in order to emulate the AES algorithm phases for efficient in-memory\nprocessing. The main features of this work are the following: a memristor 4bit\nstate element is developed and used for implementing different arithmetic\noperations for AES hardware prototype; A pipeline AES design for massive\nparallelism and compatibility targeting MR integration; An FPGA implementation\nof AES-IMC based architecture with MR emulator. The AES-IMC outperforms\nexisting architectures in both higher throughput, and energy efficiency.\nCompared with the conventional AES hardware, AES-IMC shows ~30% power\nenhancement with comparable throughput. As for state-of-the-art AES based NVM\nengines, AES-IMC has comparable power dissipation, and ~62% increased\nthroughput. By enabling the cost-effective real-time deployment of the AES, the\nIMC architecture will prevent unintended accidents with unmanned devices caused\nby malicious attacks, including hijacking and unauthorized robot control.",
    "descriptor": "\nComments: 14 pages, 18 figures, 4 tables, submitted to the IEEE Transactions on Information Forensics and Security Journal\n",
    "authors": [
      "Hala Ajmi",
      "Fakhreddine Zayer",
      "Amira Hadj Fredj",
      "Belgacem Hamdi",
      "Baker Mohammad",
      "Naoufel Werghi",
      "Jorge Dias"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2205.11895"
  },
  {
    "id": "arXiv:2205.11898",
    "title": "Automatic Verification of Sound Abstractions for Generalized Planning",
    "abstract": "Generalized planning studies the computation of general solutions for a set\nof planning problems. Computing general solutions with correctness guarantee\nhas long been a key issue in generalized planning. Abstractions are widely used\nto solve generalized planning problems. Solutions of sound abstractions are\nthose with correctness guarantees for generalized planning problems. Recently,\nCui et al. proposed a uniform abstraction framework for generalized planning.\nThey gave the model-theoretic definitions of sound and complete abstractions\nfor generalized planning problems. In this paper, based on Cui et al.'s work,\nwe explore automatic verification of sound abstractions for generalized\nplanning. We firstly present the proof-theoretic characterization for sound\nabstraction. Then, based on the characterization, we give a sufficient\ncondition for sound abstractions which is first-order verifiable. To implement\nit, we exploit regression extensions, and develop methods to handle counting\nand transitive closure. Finally, we implement a sound abstraction verification\nsystem and report experimental results on several domains.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Zhenhe Cui",
      "Weidu Kuang",
      "Yongmei Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11898"
  },
  {
    "id": "arXiv:2205.11902",
    "title": "Aerosense: A Self-Sustainable And Long-Range Bluetooth Wireless Sensor  Node for Aerodynamic and Aeroacoustic Monitoring on Wind Turbines",
    "abstract": "This paper presents a low-power, self-sustainable, and modular wireless\nsensor node for aerodynamic and acoustic measurements on wind turbines and\nother industrial structures. It includes 40 high-accuracy barometers, 10\nmicrophones, 5 differential pressure sensors, and implements a lossy and a\nlossless on-board data compression algorithm to decrease the transmission\nenergy cost. The wireless transmitter is based on Bluetooth Low Energy 5.1\ntuned for long-range and high throughput while maintaining adequate per-bit\nenergy efficiency (80 nJ). Moreover, we field-assessed the node capability to\ncollect precise and accurate aerodynamic data. Outdoor experimental tests\nrevealed that the system can acquire and sustain a data rate of 850 kbps over\n438 m. The power consumption while collecting and streaming all measured data\nis 120 mW, enabling self-sustainability and long-term in-situ monitoring with a\n111 cm^2 photovoltaic panel.",
    "descriptor": "\nComments: 9 pages, 4 figures, 3 tables, IEEE Journal\n",
    "authors": [
      "Tommaso Polonelli",
      "Hanna M\u00fcller",
      "Weikang Kong",
      "Raphael Fischer",
      "Luca Benini",
      "Michele Magno"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.11902"
  },
  {
    "id": "arXiv:2205.11908",
    "title": "An interpretation of the final fully connected layer",
    "abstract": "In recent years neural networks have achieved state-of-the-art accuracy for\nvarious tasks but the the interpretation of the generated outputs still remains\ndifficult. In this work we attempt to provide a method to understand the learnt\nweights in the final fully connected layer in image classification models. We\nmotivate our method by drawing a connection between the policy gradient\nobjective in RL and supervised learning objective. We suggest that the commonly\nused cross entropy based supervised learning objective can be regarded as a\nspecial case of the policy gradient objective. Using this insight we propose a\nmethod to find the most discriminative and confusing parts of an image. Our\nmethod does not make any prior assumption about neural network achitecture and\nhas low computational cost. We apply our method on publicly available\npre-trained models and report the generated results.",
    "descriptor": "",
    "authors": [
      "Siddhartha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11908"
  },
  {
    "id": "arXiv:2205.11911",
    "title": "Evaluating the Effect of Enhanced Text-Visualization Integration on  Combating Misinformation in Data Story",
    "abstract": "Misinformation has disruptive effects on our lives. Many researchers have\nlooked into means to identify and combat misinformation in text or data\nvisualization. However, there is still a lack of understanding of how\nmisinformation can be introduced when text and visualization are combined to\ntell data stories, not to mention how to improve the lay public's awareness of\npossible misperceptions about facts in narrative visualization. In this paper,\nwe first analyze where misinformation could possibly be injected into the\nproduction-consumption process of data stories through a literature survey.\nThen, as a first step towards combating misinformation in data stories, we\nexplore possible defensive design methods to enhance the reader's awareness of\ninformation misalignment when data facts are scripted and visualized. More\nspecifically, we conduct a between-subjects crowdsourcing study to investigate\nthe impact of two design methods enhancing text-visualization integration,\ni.e., explanatory annotation and interactive linking, on users' awareness of\nmisinformation in data stories. The study results show that although most\nparticipants still can not find misinformation, the two design methods can\nsignificantly lower the perceived credibility of the text or visualizations.\nOur work informs the possibility of fighting an infodemic through defensive\ndesign methods.",
    "descriptor": "\nComments: Accepted at PacificVis2022\n",
    "authors": [
      "Chengbo Zheng",
      "Xiaojuan Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.11911"
  },
  {
    "id": "arXiv:2205.11912",
    "title": "Physics-Embedded Neural Networks:  $\\boldsymbol{\\mathrm{E}(n)}$-Equivariant Graph Neural PDE Solvers",
    "abstract": "Graph neural network (GNN) is a promising approach to learning and predicting\nphysical phenomena described in boundary value problems, such as partial\ndifferential equations (PDEs) with boundary conditions. However, existing\nmodels inadequately treat boundary conditions essential for the reliable\nprediction of such problems. In addition, because of the locally connected\nnature of GNNs, it is difficult to accurately predict the state after a long\ntime, where interaction between vertices tends to be global. We present our\napproach termed physics-embedded neural networks that considers boundary\nconditions and predicts the state after a long time using an implicit method.\nIt is built based on an $\\mathrm{E}(n)$-equivariant GNN, resulting in high\ngeneralization performance on various shapes. We demonstrate that our model\nlearns flow phenomena in complex shapes and outperforms a well-optimized\nclassical solver and a state-of-the-art machine learning model in\nspeed-accuracy trade-off. Therefore, our model can be a useful standard for\nrealizing reliable, fast, and accurate GNN-based PDE solvers.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Masanobu Horie",
      "Naoto Mitsume"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.11912"
  },
  {
    "id": "arXiv:2205.11913",
    "title": "Deep Learning Workload Scheduling in GPU Datacenters: Taxonomy,  Challenges and Vision",
    "abstract": "Deep learning (DL) shows its prosperity in a wide variety of fields. The\ndevelopment of a DL model is a time-consuming and resource-intensive procedure.\nHence, dedicated GPU accelerators have been collectively constructed into a GPU\ndatacenter. An efficient scheduler design for such GPU datacenter is crucially\nimportant to reduce the operational cost and improve resource utilization.\nHowever, traditional approaches designed for big data or high performance\ncomputing workloads can not support DL workloads to fully utilize the GPU\nresources. Recently, substantial schedulers are proposed to tailor for DL\nworkloads in GPU datacenters. This paper surveys existing research efforts for\nboth training and inference workloads. We primarily present how existing\nschedulers facilitate the respective workloads from the scheduling objectives\nand resource consumption features. Finally, we prospect several promising\nfuture research directions. More detailed summary with the surveyed paper and\ncode links can be found at our project website:\nhttps://github.com/S-Lab-SystemGroup/Awesome-DL-Scheduling-Papers",
    "descriptor": "\nComments: Submitted to ACM Computing Surveys\n",
    "authors": [
      "Wei Gao",
      "Qinghao Hu",
      "Zhisheng Ye",
      "Peng Sun",
      "Xiaolin Wang",
      "Yingwei Luo",
      "Tianwei Zhang",
      "Yonggang Wen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11913"
  },
  {
    "id": "arXiv:2205.11914",
    "title": "An Adaptive Contrastive Learning Model for Spike Sorting",
    "abstract": "Brain-computer interfaces (BCIs), is ways for electronic devices to\ncommunicate directly with the brain. For most medical-type brain-computer\ninterface tasks, the activity of multiple units of neurons or local field\npotentials is sufficient for decoding. But for BCIs used in neuroscience\nresearch, it is important to separate out the activity of individual neurons.\nWith the development of large-scale silicon technology and the increasing\nnumber of probe channels, artificially interpreting and labeling spikes is\nbecoming increasingly impractical. In this paper, we propose a novel modeling\nframework: Adaptive Contrastive Learning Model that learns representations from\nspikes through contrastive learning based on the maximizing mutual information\nloss function as a theoretical basis. Based on the fact that data with similar\nfeatures share the same labels whether they are multi-classified or\nbinary-classified. With this theoretical support, we simplify the\nmulti-classification problem into multiple binary-classification, improving\nboth the accuracy and the runtime efficiency. Moreover, we also introduce a\nseries of enhancements for the spikes, while solving the problem that the\nclassification effect is affected because of the overlapping spikes.",
    "descriptor": "",
    "authors": [
      "Lang Qian",
      "Shengjie Zheng",
      "Chunshan Deng",
      "Cheng Yang",
      "Xiaojian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2205.11914"
  },
  {
    "id": "arXiv:2205.11915",
    "title": "Building an Effective Automated Assessment System for C/C++ Introductory  Programming Courses in ODL Environment",
    "abstract": "Assessments help in evaluating the knowledge gained by a learner at any\nspecific point as well as in continuous improvement of the curriculum design\nand the whole learning process. However, with the increase in students'\nenrollment at University level in either conventional or distance education\nenvironment, traditional ways of assessing students' work are becoming\ninsufficient in terms of both time and effort. In distance education\nenvironment, such assessments become additionally more challenging in terms of\nhefty remuneration for hiring large number of tutors. The availability of\nautomated tools to assist the evaluation of students' work and providing\nstudents with appropriate and timely feedback can really help in overcoming\nthese problems. We believe that building such tools for assessing students'\nwork for all kinds of courses in not yet possible. However, courses that\ninvolve some formal language of expression can be automated, such as,\nprogramming courses in Computer Science (CS) discipline. Instructors provide\nvarious practical exercises to students as assignments to build these skills.\nUsually, instructors manually grade and provide feedbacks on these assignments.\nAlthough in literature, various tools have been reported to automate this\nprocess, but most of these tools have been developed by the host institutions\nthemselves for their own use. We at COMSATS Institute of Information\nTechnology, Lahore are conducting a pioneer effort in Pakistan to automate the\nmarking of assignments of introductory programming courses that involve C or\nC++ languages with the capability of associating appropriate feedbacks for\nstudents. In this paper, we basically identify different components that we\nbelieve are necessary in building an effective automated assessment system in\nthe context of introductory programming courses that involve C/C++ programming.",
    "descriptor": "\nComments: Studies and Practices for Advancement in Open and Distance Education, edited by: Kam Cheong Li and Kin Sun Yuen, published by: Open University of Hong Kong. Pages: 222-234. Standard: 978-988-8238-13-2\n",
    "authors": [
      "Muhammad Salman Khan",
      "Adnan Ahmad",
      "Muhammad Humayoun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11915"
  },
  {
    "id": "arXiv:2205.11916",
    "title": "Large Language Models are Zero-Shot Reasoners",
    "abstract": "Pretrained large language models (LLMs) are widely used in many sub-fields of\nnatural language processing (NLP) and generally known as excellent few-shot\nlearners with task-specific exemplars. Notably, chain of thought (CoT)\nprompting, a recent technique for eliciting complex multi-step reasoning\nthrough step-by-step answer examples, achieved the state-of-the-art\nperformances in arithmetics and symbolic reasoning, difficult system-2 tasks\nthat do not follow the standard scaling laws for LLMs. While these successes\nare often attributed to LLMs' ability for few-shot learning, we show that LLMs\nare decent zero-shot reasoners by simply adding ``Let's think step by step''\nbefore each answer. Experimental results demonstrate that our Zero-shot-CoT,\nusing the same single prompt template, significantly outperforms zero-shot LLM\nperformances on diverse benchmark reasoning tasks including arithmetics\n(MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin\nFlip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled\nObjects), without any hand-crafted few-shot examples, e.g. increasing the\naccuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with\nan off-the-shelf 175B parameter model. The versatility of this single prompt\nacross very diverse reasoning tasks hints at untapped and understudied\nfundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task\nbroad cognitive capabilities may be extracted through simple prompting. We hope\nour work not only serves as the minimal strongest zero-shot baseline for the\nchallenging reasoning benchmarks, but also highlights the importance of\ncarefully exploring and analyzing the enormous zero-shot knowledge hidden\ninside LLMs before crafting finetuning datasets or few-shot exemplars.",
    "descriptor": "",
    "authors": [
      "Takeshi Kojima",
      "Shixiang Shane Gu",
      "Machel Reid",
      "Yutaka Matsuo",
      "Yusuke Iwasawa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11916"
  },
  {
    "id": "arXiv:2205.11917",
    "title": "Community Question Answering Entity Linking via Leveraging Auxiliary  Data",
    "abstract": "Community Question Answering (CQA) platforms contain plenty of CQA texts\n(i.e., questions and answers corresponding to the question) where named\nentities appear ubiquitously. In this paper, we define a new task of CQA entity\nlinking (CQAEL) as linking the textual entity mentions detected from CQA texts\nwith their corresponding entities in a knowledge base. This task can facilitate\nmany downstream applications including expert finding and knowledge base\nenrichment. Traditional entity linking methods mainly focus on linking entities\nin news documents, and are suboptimal over this new task of CQAEL since they\ncannot effectively leverage various informative auxiliary data involved in the\nCQA platform to aid entity linking, such as parallel answers and two types of\nmeta-data (i.e., topic tags and users). To remedy this crucial issue, we\npropose a novel transformer-based framework to effectively harness the\nknowledge delivered by different kinds of auxiliary data to promote the linking\nperformance. We validate the superiority of our framework through extensive\nexperiments over a newly released CQAEL data set against state-of-the-art\nentity linking methods.",
    "descriptor": "\nComments: Accepted by IJCAI2022\n",
    "authors": [
      "Yuhan Li",
      "Wei Shen",
      "Jianbo Gao",
      "Yadong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11917"
  },
  {
    "id": "arXiv:2205.11921",
    "title": "Compression-aware Training of Neural Networks using Frank-Wolfe",
    "abstract": "Many existing Neural Network pruning approaches either rely on retraining to\ncompensate for pruning-caused performance degradation or they induce strong\nbiases to converge to a specific sparse solution throughout training. A third\nparadigm obtains a wide range of compression ratios from a single dense\ntraining run while also avoiding retraining. Recent work of Pokutta et al.\n(2020) and Miao et al. (2022) suggests that the Stochastic Frank-Wolfe (SFW)\nalgorithm is particularly suited for training state-of-the-art models that are\nrobust to compression. We propose leveraging $k$-support norm ball constraints\nand demonstrate significant improvements over the results of Miao et al. (2022)\nin the case of unstructured pruning. We also extend these ideas to the\nstructured pruning domain and propose novel approaches to both ensure\nrobustness to the pruning of convolutional filters as well as to low-rank\ntensor decompositions of convolutional layers. In the latter case, our approach\nperforms on-par with nuclear-norm regularization baselines while requiring only\nhalf of the computational resources. Our findings also indicate that the\nrobustness of SFW-trained models largely depends on the gradient rescaling of\nthe learning rate and we establish a theoretical foundation for that practice.",
    "descriptor": "\nComments: 9 pages, 10 pages appendix, 9 figures, and 2 tables\n",
    "authors": [
      "Max Zimmer",
      "Christoph Spiegel",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11921"
  },
  {
    "id": "arXiv:2205.11925",
    "title": "Robust 3D Object Detection in Cold Weather Conditions",
    "abstract": "Adverse weather conditions can negatively affect LiDAR-based object\ndetectors. In this work, we focus on the phenomenon of vehicle gas exhaust\ncondensation in cold weather conditions. This everyday effect can influence the\nestimation of object sizes, orientations and introduce ghost object detections,\ncompromising the reliability of the state of the art object detectors. We\npropose to solve this problem by using data augmentation and a novel training\nloss term. To effectively train deep neural networks, a large set of labeled\ndata is needed. In case of adverse weather conditions, this process can be\nextremely laborious and expensive. We address this issue in two steps: First,\nwe present a gas exhaust data generation method based on 3D surface\nreconstruction and sampling which allows us to generate large sets of gas\nexhaust clouds from a small pool of labeled data. Second, we introduce a point\ncloud augmentation process that can be used to add gas exhaust to datasets\nrecorded in good weather conditions. Finally, we formulate a new training loss\nterm that leverages the augmented point cloud to increase object detection\nrobustness by penalizing predictions that include noise. In contrast to other\nworks, our method can be used with both grid-based and point-based detectors.\nMoreover, since our approach does not require any network architecture changes,\ninference times remain unchanged. Experimental results on real data show that\nour proposed method greatly increases robustness to gas exhaust and noisy data.",
    "descriptor": "",
    "authors": [
      "Aldi Piroli",
      "Vinzenz Dallabetta",
      "Marc Walessa",
      "Daniel Meissner",
      "Johannes Kopp",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11925"
  },
  {
    "id": "arXiv:2205.11927",
    "title": "Image Trinarization Using a Partial Differential Equations: A Novel  Approach to Automatic Sperm Image Analysis",
    "abstract": "Partial differential equations have recently garnered substantial attention\nas an image processing framework due to their extensibility, the ability to\nrigorously engineer and analyse the governing dynamics as well as the ease of\nimplementation using numerical methods. This paper explores a novel approach to\nimage trinarization with a concrete real-world application of classifying\nregions of sperm images used in the automatic analysis of sperm morphology. The\nproposed methodology engineers a diffusion equation with non-linear source\nterm, exhibiting three steady-states. The model is implemented as an image\nprocessor using a standard finite difference method to illustrate the efficacy\nof the proposed approach. The performance of the proposed approach is\nbenchmarked against standard image clustering/segmentation methods and shown to\nbe highly effective.",
    "descriptor": "",
    "authors": [
      "B. A. Jacobs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11927"
  },
  {
    "id": "arXiv:2205.11930",
    "title": "How Human is Human Evaluation? Improving the Gold Standard for NLG with  Utility Theory",
    "abstract": "Human ratings are treated as the gold standard in NLG evaluation. The\nstandard protocol is to collect ratings of generated text, average across\nannotators, and then rank NLG systems by their average scores. However, little\nconsideration has been given as to whether this approach faithfully captures\nhuman preferences. In this work, we analyze this standard protocol through the\nlens of utility theory in economics. We first identify the implicit assumptions\nit makes about annotators and find that these assumptions are often violated in\npractice, in which case annotator ratings become an unfaithful reflection of\ntheir preferences. The most egregious violations come from using Likert scales,\nwhich provably reverse the direction of the true preference in certain cases.\nWe suggest improvements to the standard protocol to make it more theoretically\nsound, but even in its improved form, it cannot be used to evaluate open-ended\ntasks like story generation. For the latter, we propose a new evaluation\nprotocol called $\\textit{system-level probabilistic assessment}$ (SPA). In our\nexperiments, we find that according to SPA, annotators prefer larger GPT-3\nvariants to smaller ones -- as expected -- with all comparisons being\nstatistically significant. In contrast, the standard protocol only yields\nsignificant results half the time.",
    "descriptor": "",
    "authors": [
      "Kawin Ethayarajh",
      "Dan Jurafsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11930"
  },
  {
    "id": "arXiv:2205.11934",
    "title": "Pynblint: a Static Analyzer for Python Jupyter Notebooks",
    "abstract": "Jupyter Notebook is the tool of choice of many data scientists in the early\nstages of ML workflows. The notebook format, however, has been criticized for\ninducing bad programming practices; indeed, researchers have already shown that\nopen-source repositories are inundated by poor-quality notebooks. Low-quality\noutput from the prototypical stages of ML workflows constitutes a clear\nbottleneck towards the productization of ML models. To foster the creation of\nbetter notebooks, we developed Pynblint, a static analyzer for Jupyter\nnotebooks written in Python. The tool checks the compliance of notebooks (and\nsurrounding repositories) with a set of empirically validated best practices\nand provides targeted recommendations when violations are detected.",
    "descriptor": "\nComments: 2 pages\n",
    "authors": [
      "Luigi Quaranta",
      "Fabio Calefato",
      "Filippo Lanubile"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11934"
  },
  {
    "id": "arXiv:2205.11935",
    "title": "CryptoTL: Private, efficient and secure transfer learning",
    "abstract": "Big data has been a pervasive catchphrase in recent years, but dealing with\ndata scarcity has become a crucial question for many real-world deep learning\n(DL) applications. A popular methodology to efficiently enable the training of\nDL models to perform tasks in scenarios where only a small dataset is available\nis transfer learning (TL). TL allows knowledge transfer from a general domain\nto a specific target one; however, such a knowledge transfer may put privacy at\nrisk when it comes to sensitive or private data. With CryptoTL we introduce a\nsolution to this problem, and show for the first time a cryptographic\nprivacy-preserving TL approach based on homomorphic encryption that is\nefficient and feasible for real-world use cases. We demonstrate this by\nfocusing on classification tasks with small datasets and show the applicability\nof our approach for sentiment analysis. Additionally we highlight how our\napproach can be combined with differential privacy to further increase the\nsecurity guarantees. Our extensive benchmarks show that using CryptoTL leads to\nhigh accuracy while still having practical fine-tuning and classification\nruntimes despite using homomorphic encryption. Concretely, one forward-pass\nthrough the encrypted layers of our setup takes roughly 1s on a notebook CPU.",
    "descriptor": "",
    "authors": [
      "Roman Walch",
      "Samuel Sousa",
      "Lukas Helminger",
      "Stefanie Lindstaedt",
      "Christian Rechberger",
      "Andreas Tr\u00fcgler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.11935"
  },
  {
    "id": "arXiv:2205.11939",
    "title": "On Hedonic Games with Common Ranking Property",
    "abstract": "Hedonic games are a prominent model of coalition formation, in which each\nagent's utility only depends on the coalition she resides. The subclass of\nhedonic games that models the formation of general partnerships, where output\nis shared equally among affiliates, is referred to as hedonic games with common\nranking property (HGCRP). Aside from their economic motivation, HGCRP came into\nprominence since they are guaranteed to have core stable solutions that can be\nfound efficiently. We improve upon existing results by proving that every\ninstance of HGCRP has a solution that is Pareto optimal, core stable and\nindividually stable. The economic significance of this result is that\nefficiency is not to be totally sacrificed for the sake of stability in HGCRP.\nWe establish that finding such a solution is {\\bf NP-hard} even if the sizes of\nthe coalitions are bounded above by $3$; however, it is polynomial time\nsolvable if the sizes of the coalitions are bounded above by $2$. We show that\nthe gap between the total utility of a core stable solution and that of the\nsocially-optimal solution (OPT) is bounded above by $n$, where $n$ is the\nnumber of agents, and that this bound is tight. Our investigations reveal that\ncomputing OPT is inapproximable within better than $O(n^{1-\\epsilon})$ for any\nfixed $\\epsilon > 0$, and that this inapproximability lower bound is\npolynomially tight. However, OPT can be computed in polynomial time if the\nsizes of the coalitions are bounded above by $2$.",
    "descriptor": "",
    "authors": [
      "Bugra Caskurlu",
      "Fatih Erdem Kizilkaya"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2205.11939"
  },
  {
    "id": "arXiv:2205.11941",
    "title": "Assessing the Quality of Computational Notebooks for a Frictionless  Transition from Exploration to Production",
    "abstract": "The massive trend of integrating data-driven AI capabilities into traditional\nsoftware systems is rising new intriguing challenges. One of such challenges is\nachieving a smooth transition from the explorative phase of Machine Learning\nprojects - in which data scientists build prototypical models in the lab - to\ntheir production phase - in which software engineers translate prototypes into\nproduction-ready AI components. To narrow down the gap between these two\nphases, tools and practices adopted by data scientists might be improved by\nincorporating consolidated software engineering solutions. In particular,\ncomputational notebooks have a prominent role in determining the quality of\ndata science prototypes. In my research project, I address this challenge by\nstudying the best practices for collaboration with computational notebooks and\nproposing proof-of-concept tools to foster guidelines compliance.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Luigi Quaranta"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11941"
  },
  {
    "id": "arXiv:2205.11945",
    "title": "GraSens: A Gabor Residual Anti-aliasing Sensing Framework for Action  Recognition using WiFi",
    "abstract": "WiFi-based human action recognition (HAR) has been regarded as a promising\nsolution in applications such as smart living and remote monitoring due to the\npervasive and unobtrusive nature of WiFi signals. However, the efficacy of WiFi\nsignals is prone to be influenced by the change in the ambient environment and\nvaries over different sub-carriers. To remedy this issue, we propose an\nend-to-end Gabor residual anti-aliasing sensing network (GraSens) to directly\nrecognize the actions using the WiFi signals from the wireless devices in\ndiverse scenarios. In particular, a new Gabor residual block is designed to\naddress the impact of the changing surrounding environment with a focus on\nlearning reliable and robust temporal-frequency representations of WiFi\nsignals. In each block, the Gabor layer is integrated with the anti-aliasing\nlayer in a residual manner to gain the shift-invariant features. Furthermore,\nfractal temporal and frequency self-attention are proposed in a joint effort to\nexplicitly concentrate on the efficacy of WiFi signals and thus enhance the\nquality of output features scattered in different subcarriers. Experimental\nresults throughout our wireless-vision action recognition dataset (WVAR) and\nthree public datasets demonstrate that our proposed GraSens scheme outperforms\nstate-of-the-art methods with respect to recognition accuracy.",
    "descriptor": "",
    "authors": [
      "Yanling Hao",
      "Zhiyuan Shi",
      "Xidong Mu",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11945"
  },
  {
    "id": "arXiv:2205.11947",
    "title": "Causal Influences Decouple From Their Underlying Network Structure In  Echo State Networks",
    "abstract": "Echo State Networks (ESN) are versatile recurrent neural network models in\nwhich the hidden layer remains unaltered during training. Interactions among\nnodes of this static backbone produce diverse representations of the given\nstimuli that are harnessed by a read-out mechanism to perform computations\nneeded for solving a given task. ESNs are accessible models of neuronal\ncircuits, since they are relatively inexpensive to train. Therefore, ESNs have\nbecome attractive for neuroscientists studying the relationship between neural\nstructure, function, and behavior. For instance, it is not yet clear how\ndistinctive connectivity patterns of brain networks support effective\ninteractions among their nodes and how these patterns of interactions give rise\nto computation. To address this question, we employed an ESN with a\nbiologically inspired structure and used a systematic multi-site lesioning\nframework to quantify the causal contribution of each node to the network's\noutput, thus providing a causal link between network structure and behavior. We\nthen focused on the structure-function relationship and decomposed the causal\ninfluence of each node on all other nodes, using the same lesioning framework.\nWe found that nodes in a properly engineered ESN interact largely irrespective\nof the network's underlying structure. However, in a network with the same\ntopology and a non-optimal parameter set, the underlying connectivity patterns\ndetermine the node interactions. Our results suggest that causal\nstructure-function relations in ESNs can be decomposed into two components,\ndirect and indirect interactions. The former are based on influences relying on\nstructural connections. The latter describe the effective communication between\nany two nodes through other intermediate nodes. These widely distributed\nindirect interactions may crucially contribute to the efficient performance of\nESNs.",
    "descriptor": "\nComments: This paper was accepted for oral presentation in IEEE WCCI 2022 + IJCNN 2022, special session on Reservoir Computing: algorithms, implementations and applications\n",
    "authors": [
      "Kayson Fakhar",
      "Fatemeh Hadaeghi",
      "Claus C. Hilgetag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2205.11947"
  },
  {
    "id": "arXiv:2205.11948",
    "title": "SHARP: Shape-Aware Reconstruction of People in Loose Clothing",
    "abstract": "Recent advancements in deep learning have enabled 3D human body\nreconstruction from a monocular image, which has broad applications in multiple\ndomains. In this paper, we propose SHARP (SHape Aware Reconstruction of People\nin loose clothing), a novel end-to-end trainable network that accurately\nrecovers the 3D geometry and appearance of humans in loose clothing from a\nmonocular image. SHARP uses a sparse and efficient fusion strategy to combine\nparametric body prior with a non-parametric 2D representation of clothed\nhumans. The parametric body prior enforces geometrical consistency on the body\nshape and pose, while the non-parametric representation models loose clothing\nand handle self-occlusions as well. We also leverage the sparseness of the\nnon-parametric representation for faster training of our network while using\nlosses on 2D maps. Another key contribution is 3DHumans, our new life-like\ndataset of 3D human body scans with rich geometrical and textural details. We\nevaluate SHARP on 3DHumans and other publicly available datasets and show\nsuperior qualitative and quantitative performance than existing\nstate-of-the-art methods.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Sai Sagar Jinka",
      "Astitva Srivastava",
      "Chandradeep Pokhariya",
      "Avinash Sharma",
      "P.J. Narayanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11948"
  },
  {
    "id": "arXiv:2205.11951",
    "title": "Diffuse Map Guiding Unsupervised Generative Adversarial Network for  SVBRDF Estimation",
    "abstract": "Reconstructing materials in the real world has always been a difficult\nproblem in computer graphics. Accurately reconstructing the material in the\nreal world is critical in the field of realistic rendering. Traditionally,\nmaterials in computer graphics are mapped by an artist, then mapped onto a\ngeometric model by coordinate transformation, and finally rendered with a\nrendering engine to get realistic materials. For opaque objects, the industry\ncommonly uses physical-based bidirectional reflectance distribution function\n(BRDF) rendering models for material modeling. The commonly used physical-based\nrendering models are Cook-Torrance BRDF, Disney BRDF. In this paper, we use the\nCook-Torrance model to reconstruct the materials. The SVBRDF material\nparameters include Normal, Diffuse, Specular and Roughness. This paper presents\na Diffuse map guiding material estimation method based on the Generative\nAdversarial Network(GAN). This method can predict plausible SVBRDF maps with\nglobal features using only a few pictures taken by the mobile phone. The main\ncontributions of this paper are: 1) We preprocess a small number of input\npictures to produce a large number of non-repeating pictures for training to\nreduce over-fitting. 2) We use a novel method to directly obtain the guessed\ndiffuse map with global characteristics, which provides more prior information\nfor the training process. 3) We improve the network architecture of the\ngenerator so that it can generate fine details of normal maps and reduce the\npossibility to generate over-flat normal maps. The method used in this paper\ncan obtain prior knowledge without using dataset training, which greatly\nreduces the difficulty of material reconstruction and saves a lot of time to\ngenerate and calibrate datasets.",
    "descriptor": "",
    "authors": [
      "Zhiyao Luo",
      "Hongnan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.11951"
  },
  {
    "id": "arXiv:2205.11957",
    "title": "Comparison of Fractional-Order and Integer-Order H-infinty Control of a  Non-Collocated Two-Mass Oscillator",
    "abstract": "We consider the robust control of a two-mass oscillator with a dominant input\ndelay. Our aim is to compare a fractional-order tuning approach including the\npartial compensation of non-minimum phase zeros with a classical H-infinity\nloop-shaping design, since both these designs lead to a relatively high\ncontroller order. First of all a detailed physical model is derived and\nvalidated using measurement data. Based on the linearized model both\ncontrollers are designed to be comparable, i.e. they show a similar crossover\nfrequency in the open loop and the final controller order is reduced to the\nsame range for both designs. The major differences between both are the\ndifferent methods how the feed-forward action is included. The loop-shaping\napproach with fractional-order elements relies on the plant inverse using a\nflat output, whereas the H-infinty design incorporates a two-degree of freedom\ncontrol, i.e. the reference signal is included into the known inputs of the\ngeneralized plant. Each controller is tested in simulation and experiment. As\nboth open-loops are nearly identical in the frequency range of interest, the\nresults from an input disturbance experiment show no major difference. The\ndifferent design approaches of the feed-forward path are clearly visible in the\ntracking experiment.",
    "descriptor": "",
    "authors": [
      "Benjamin Vo\u00df",
      "Michael Ruderman",
      "Christoph Weise",
      "Johann Reger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.11957"
  },
  {
    "id": "arXiv:2205.11961",
    "title": "Attentional Mixtures of Soft Prompt Tuning for Parameter-efficient  Multi-task Knowledge Sharing",
    "abstract": "This work introduces ATTEMPT (Attentional Mixture of Prompt Tuning), a new\nmodular, multi-task, and parameter-efficient language model (LM) tuning\napproach that combines knowledge transferred across different tasks via a\nmixture of soft prompts while keeping original LM unchanged. ATTEMPT\ninterpolates a set of prompts trained on large-scale source tasks and a newly\ninitialized target task prompt using instance-wise attention computed by a\nlightweight sub-network trained on multiple target tasks. ATTEMPT is\nparameter-efficient (e.g., updates 1,600 times fewer parameters than\nfine-tuning) and enables multi-task learning and flexible extensions;\nimportantly, it is also more interpretable because it demonstrates which source\ntasks affect the final model decision on target tasks. Experimental results\nacross 17 diverse datasets show that ATTEMPT improves prompt tuning by up to a\n22% absolute performance gain and outperforms or matches fully fine-tuned or\nother parameter-efficient tuning approaches that use over ten times more\nparameters.",
    "descriptor": "\nComments: 18 pages; 8 gigures. Preprint\n",
    "authors": [
      "Akari Asai",
      "Mohammadreza Salehi",
      "Matthew E. Peters",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11961"
  },
  {
    "id": "arXiv:2205.11962",
    "title": "A Wireless-Vision Dataset for Privacy Preserving Human Activity  Recognition",
    "abstract": "Human Activity Recognition (HAR) has recently received remarkable attention\nin numerous applications such as assisted living and remote monitoring.\nExisting solutions based on sensors and vision technologies have obtained\nachievements but still suffering from considerable limitations in the\nenvironmental requirement. Wireless signals like WiFi-based sensing have\nemerged as a new paradigm since it is convenient and not restricted in the\nenvironment. In this paper, a new WiFi-based and video-based neural network\n(WiNN) is proposed to improve the robustness of activity recognition where the\nsynchronized video serves as the supplement for the wireless data. Moreover, a\nwireless-vision benchmark (WiVi) is collected for 9 class actions recognition\nin three different visual conditions, including the scenes without occlusion,\nwith partial occlusion, and with full occlusion. Both machine learning methods\n- support vector machine (SVM) as well as deep learning methods are used for\nthe accuracy verification of the data set. Our results show that WiVi data set\nsatisfies the primary demand and all three branches in the proposed pipeline\nkeep more than $80\\%$ of activity recognition accuracy over multiple action\nsegmentation from 1s to 3s. In particular, WiNN is the most robust method in\nterms of all the actions on three action segmentation compared to the others.",
    "descriptor": "",
    "authors": [
      "Yanling Hao",
      "Zhiyuan Shi",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11962"
  },
  {
    "id": "arXiv:2205.11963",
    "title": "The Data-Production Dispositif",
    "abstract": "Machine learning (ML) depends on data to train and verify models. Very often,\norganizations outsource processes related to data work (i.e., generating and\nannotating data and evaluating outputs) through business process outsourcing\n(BPO) companies and crowdsourcing platforms. This paper investigates outsourced\nML data work in Latin America by studying three platforms in Venezuela and a\nBPO in Argentina. We lean on the Foucauldian notion of dispositif to define the\ndata-production dispositif as an ensemble of discourses, actions, and objects\nstrategically disposed to (re)produce power/knowledge relations in data and\nlabor. Our dispositif analysis comprises the examination of 210 data work\ninstruction documents, 55 interviews with data workers, managers, and\nrequesters, and participant observation. Our findings show that discourses\nencoded in instructions reproduce and normalize the worldviews of requesters.\nPrecarious working conditions and economic dependency alienate workers, making\nthem obedient to instructions. Furthermore, discourses and social contexts\nmaterialize in artifacts, such as interfaces and performance metrics, limiting\nworkers' agency and normalizing specific ways of interpreting data. We conclude\nby stressing the importance of counteracting the data-production dispositif by\nfighting alienation and precarization, and empowering data workers to become\nassets in the quest for high-quality data.",
    "descriptor": "\nComments: Accepted for publication at CSCW 2022. Forthcoming in the Proceedings of the ACM on Human-Computer Interaction\n",
    "authors": [
      "Milagros Miceli",
      "Julian Posada"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11963"
  },
  {
    "id": "arXiv:2205.11966",
    "title": "Benchmark Data and Evaluation Framework for Intent Discovery Around  COVID-19 Vaccine Hesitancy",
    "abstract": "The COVID-19 pandemic has made a huge global impact and cost millions of\nlives. As COVID-19 vaccines were rolled out, they were quickly met with\nwidespread hesitancy. To address the concerns of hesitant people, we launched\nVIRA, a public dialogue system aimed at addressing questions and concerns\nsurrounding the COVID-19 vaccines. Here, we release VIRADialogs, a dataset of\nover 8k dialogues conducted by actual users with VIRA, providing a unique\nreal-world conversational dataset. In light of rapid changes in users' intents,\ndue to updates in guidelines or as a response to new information, we highlight\nthe important task of intent discovery in this use-case. We introduce a novel\nautomatic evaluation framework for intent discovery, leveraging the existing\nintent classifier of a given dialogue system. We use this framework to report\nbaseline intent-discovery results over VIRADialogs, that highlight the\ndifficulty of this task.",
    "descriptor": "",
    "authors": [
      "Shai Gretz",
      "Assaf Toledo",
      "Roni Friedman",
      "Dan Lahav",
      "Rose Weeks",
      "Naor Bar-Zeev",
      "Jo\u00e3o Sedoc",
      "Pooja Sangha",
      "Yoav Katz",
      "Noam Slonim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11966"
  },
  {
    "id": "arXiv:2205.11973",
    "title": "Exploiting Dynamic and Fine-grained Semantic Scope for Extreme  Multi-label Text Classification",
    "abstract": "Extreme multi-label text classification (XMTC) refers to the problem of\ntagging a given text with the most relevant subset of labels from a large label\nset. A majority of labels only have a few training instances due to large label\ndimensionality in XMTC. To solve this data sparsity issue, most existing XMTC\nmethods take advantage of fixed label clusters obtained in early stage to\nbalance performance on tail labels and head labels. However, such label\nclusters provide static and coarse-grained semantic scope for every text, which\nignores distinct characteristics of different texts and has difficulties\nmodelling accurate semantics scope for texts with tail labels. In this paper,\nwe propose a novel framework TReaderXML for XMTC, which adopts dynamic and\nfine-grained semantic scope from teacher knowledge for individual text to\noptimize text conditional prior category semantic ranges. TReaderXML\ndynamically obtains teacher knowledge for each text by similar texts and\nhierarchical label information in training sets to release the ability of\ndistinctly fine-grained label-oriented semantic scope. Then, TReaderXML\nbenefits from a novel dual cooperative network that firstly learns features of\na text and its corresponding label-oriented semantic scope by parallel Encoding\nModule and Reading Module, secondly embeds two parts by Interaction Module to\nregularize the text's representation by dynamic and fine-grained label-oriented\nsemantic scope, and finally find target labels by Prediction Module.\nExperimental results on three XMTC benchmark datasets show that our method\nachieves new state-of-the-art results and especially performs well for severely\nimbalanced and sparse datasets.",
    "descriptor": "",
    "authors": [
      "Yuan Wang",
      "Huiling Song",
      "Peng Huo",
      "Tao Xu",
      "Jucheng Yang",
      "Yarui Chen",
      "Tingting Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11973"
  },
  {
    "id": "arXiv:2205.11976",
    "title": "Universal Dependency Treebank for Odia Language",
    "abstract": "This paper presents the first publicly available treebank of Odia, a\nmorphologically rich low resource Indian language. The treebank contains\napprox. 1082 tokens (100 sentences) in Odia selected from \"Samantar\", the\nlargest available parallel corpora collection for Indic languages. All the\nselected sentences are manually annotated following the ``Universal Dependency\n(UD)\" guidelines. The morphological analysis of the Odia treebank was performed\nusing machine learning techniques. The Odia annotated treebank will enrich the\nOdia language resource and will help in building language technology tools for\ncross-lingual learning and typological research. We also build a preliminary\nOdia parser using a machine learning approach. The accuracy of the parser is\n86.6% Tokenization, 64.1% UPOS, 63.78% XPOS, 42.04% UAS and 21.34% LAS.\nFinally, the paper briefly discusses the linguistic analysis of the Odia UD\ntreebank.",
    "descriptor": "\nComments: To be appear in 6th Workshop on Indian Language Data: Resources and Evaluation (WILDRE-6) @ LREC 2022\n",
    "authors": [
      "Shantipriya Parida",
      "Kalyanamalini Sahoo",
      "Atul Kr. Ojha",
      "Saraswati Sahoo",
      "Satya Ranjan Dash",
      "Bijayalaxmi Dash"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11976"
  },
  {
    "id": "arXiv:2205.11981",
    "title": "OPOM: Customized Invisible Cloak towards Face Privacy Protection",
    "abstract": "While convenient in daily life, face recognition technologies also raise\nprivacy concerns for regular users on the social media since they could be used\nto analyze face images and videos, efficiently and surreptitiously without any\nsecurity restrictions. In this paper, we investigate the face privacy\nprotection from a technology standpoint based on a new type of customized\ncloak, which can be applied to all the images of a regular user, to prevent\nmalicious face recognition systems from uncovering their identity.\nSpecifically, we propose a new method, named one person one mask (OPOM), to\ngenerate person-specific (class-wise) universal masks by optimizing each\ntraining sample in the direction away from the feature subspace of the source\nidentity. To make full use of the limited training images, we investigate\nseveral modeling methods, including affine hulls, class centers, and convex\nhulls, to obtain a better description of the feature subspace of source\nidentities. The effectiveness of the proposed method is evaluated on both\ncommon and celebrity datasets against black-box face recognition models with\ndifferent loss functions and network architectures. In addition, we discuss the\nadvantages and potential problems of the proposed method. In particular, we\nconduct an application study on the privacy protection of a video dataset,\nSherlock, to demonstrate the potential practical usage of the proposed method.\nDatasets and code are available at https://github.com/zhongyy/OPOM.",
    "descriptor": "\nComments: This article has been accepted by IEEE Transactions on Pattern Analysis & Machine Intelligence. Datasets and code are available at this https URL\n",
    "authors": [
      "Yaoyao Zhong",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11981"
  },
  {
    "id": "arXiv:2205.11982",
    "title": "Linear random generation of Motzkin trees",
    "abstract": "Motzkin trees are also called unary-binary trees. This paper proposes a\nlinear algorithm for uniform random generation of Motzkin trees. The algorithm\nuses the same paradigm as this of R{\\'e}my's linear algorithm for random\ngeneration of binary trees and is based on a preliminary computation.",
    "descriptor": "",
    "authors": [
      "Pierre Lescanne"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.11982"
  },
  {
    "id": "arXiv:2205.11987",
    "title": "Word-order typology in Multilingual BERT: A case study in  subordinate-clause detection",
    "abstract": "The capabilities and limitations of BERT and similar models are still unclear\nwhen it comes to learning syntactic abstractions, in particular across\nlanguages. In this paper, we use the task of subordinate-clause detection\nwithin and across languages to probe these properties. We show that this task\nis deceptively simple, with easy gains offset by a long tail of harder cases,\nand that BERT's zero-shot performance is dominated by word-order effects,\nmirroring the SVO/VSO/SOV typology.",
    "descriptor": "\nComments: Accepted for publication in the proceedings of SIGTYP workshop 2022\n",
    "authors": [
      "Dmitry Nikolaev",
      "Sebastian Pad\u00f3"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11987"
  },
  {
    "id": "arXiv:2205.11991",
    "title": "Learning Stabilizing Policies in Stochastic Control Systems",
    "abstract": "In this work, we address the problem of learning provably stable neural\nnetwork policies for stochastic control systems. While recent work has\ndemonstrated the feasibility of certifying given policies using martingale\ntheory, the problem of how to learn such policies is little explored. Here, we\nstudy the effectiveness of jointly learning a policy together with a martingale\ncertificate that proves its stability using a single learning algorithm. We\nobserve that the joint optimization problem becomes easily stuck in local\nminima when starting from a randomly initialized policy. Our results suggest\nthat some form of pre-training of the policy is required for the joint\noptimization to repair and verify the policy successfully.",
    "descriptor": "\nComments: ICLR 2022 Workshop on Socially Responsible Machine Learning (SRML)\n",
    "authors": [
      "\u0110or\u0111e \u017dikeli\u0107",
      "Mathias Lechner",
      "Krishnendu Chatterjee",
      "Thomas A. Henzinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11991"
  },
  {
    "id": "arXiv:2205.11992",
    "title": "Co-optimization of Battery Routing and Load Restoration for Microgrids  with Mobile Energy Storage Systems",
    "abstract": "Mobile energy storage systems (MESS) offer great operational flexibility to\nenhance the resiliency of distribution systems in an emergency condition. The\noptimal placement and sizing of those units are pivotal for quickly restoring\nthe curtailed loads. In this paper, we propose a model for load restoration in\na microgrid while concurrently optimizing the MESS routes required for the\nsame. The model is formulated as a mixed integer second order cone program by\nconsidering the state of charge and evolution of the lower and upper bounds of\nbattery capacities. Simulation results tested on the IEEE 123- bus benchmark\nsystem demonstrate the efficacy of the proposed model.",
    "descriptor": "\nComments: PRES GM 2022 Conference\n",
    "authors": [
      "Shourya Bose",
      "Sifat Chowdhury",
      "Yu Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.11992"
  },
  {
    "id": "arXiv:2205.11993",
    "title": "Highly Accurate FMRI ADHD Classification using time distributed multi  modal 3D CNNs",
    "abstract": "This work proposes an algorithm for fMRI data analysis for the classification\nof ADHD disorders. There have been several breakthroughs in the analysis of\nfMRI via 3D convolutional neural networks (CNNs). With these new techniques it\nis possible to preserve the 3D spatial data of fMRI data. Additionally there\nhave been recent advances in the use of 3D generative adversarial neural\nnetworks (GANs) for the generation of normal MRI data. This work utilizes multi\nmodal 3D CNNs with data augmentation from 3D GAN for ADHD prediction from fMRI.\nBy leveraging a 3D-GAN it would be possible to use deepfake data to enhance the\naccuracy of 3D CNN classification of brain disorders. A comparison will be made\nbetween a time distributed single modal 3D CNN model for classification and the\nmodified multi modal model with MRI data as well.",
    "descriptor": "\nComments: 8 pages, 5 Figures, 1 Table\n",
    "authors": [
      "Christopher Sims"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.11993"
  },
  {
    "id": "arXiv:2205.11995",
    "title": "Deep Low-Density Separation for Semi-Supervised Classification",
    "abstract": "Given a small set of labeled data and a large set of unlabeled data,\nsemi-supervised learning (SSL) attempts to leverage the location of the\nunlabeled datapoints in order to create a better classifier than could be\nobtained from supervised methods applied to the labeled training set alone.\nEffective SSL imposes structural assumptions on the data, e.g. that neighbors\nare more likely to share a classification or that the decision boundary lies in\nan area of low density. For complex and high-dimensional data, neural networks\ncan learn feature embeddings to which traditional SSL methods can then be\napplied in what we call hybrid methods.\nPreviously-developed hybrid methods iterate between refining a latent\nrepresentation and performing graph-based SSL on this representation. In this\npaper, we introduce a novel hybrid method that instead applies low-density\nseparation to the embedded features. We describe it in detail and discuss why\nlow-density separation may be better suited for SSL on neural network-based\nembeddings than graph-based algorithms. We validate our method using in-house\ncustomer survey data and compare it to other state-of-the-art learning methods.\nOur approach effectively classifies thousands of unlabeled users from a\nrelatively small number of hand-classified examples.",
    "descriptor": "",
    "authors": [
      "Michael C. Burkhart",
      "Kyle Shan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11995"
  },
  {
    "id": "arXiv:2205.11998",
    "title": "Multi-Level Modeling Units for End-to-End Mandarin Speech Recognition",
    "abstract": "The choice of modeling units affects the performance of the acoustic modeling\nand plays an important role in automatic speech recognition (ASR). In mandarin\nscenarios, the Chinese characters represent meaning but are not directly\nrelated to the pronunciation. Thus only considering the writing of Chinese\ncharacters as modeling units is insufficient to capture speech features. In\nthis paper, we present a novel method involves with multi-level modeling units,\nwhich integrates multi-level information for mandarin speech recognition.\nSpecifically, the encoder block considers syllables as modeling units, and the\ndecoder block deals with character modeling units. During inference, the input\nfeature sequences are converted into syllable sequences by the encoder block\nand then converted into Chinese characters by the decoder block. This process\nis conducted by a unified end-to-end model without introducing additional\nconversion models. By introducing InterCE auxiliary task, our method achieves\ncompetitive results with CER of 4.1%/4.6% and 4.6%/5.2% on the widely used\nAISHELL-1 benchmark without a language model, using the Conformer and the\nTransformer backbones respectively.",
    "descriptor": "\nComments: Submitted to INTERSPEECH2022\n",
    "authors": [
      "Yuting Yang",
      "Binbin Du",
      "Yuke Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.11998"
  },
  {
    "id": "arXiv:2205.12002",
    "title": "GMM-based Codebook Construction and Feedback Encoding in FDD Systems",
    "abstract": "We propose a precoder codebook construction and feedback encoding scheme\nwhich is based on Gaussian mixture models (GMMs). In an offline phase, the base\nstation (BS) first fits a GMM to uplink (UL) training samples. Thereafter, it\ndesigns a codebook in an unsupervised manner by exploiting the GMM's clustering\ncapability. We design one codebook entry per GMM component. After offloading\nthe GMM-but not the codebook-to the mobile terminal (MT) in the online phase,\nthe MT utilizes the GMM to determine the best fitting codebook entry. To this\nend, no channel estimation is necessary at the MT. Instead, the MT's observed\nsignal is used to evaluate how responsible each component of the GMM is for the\nsignal. The feedback consists of the index of the GMM component with the\nhighest responsibility and the BS then employs the corresponding codebook\nentry. Simulation results show that the proposed codebook design and feedback\nencoding scheme outperforms conventional Lloyd clustering based codebook design\nalgorithms, especially in configurations with reduced pilot overhead.",
    "descriptor": "",
    "authors": [
      "Nurettin Turan",
      "Michael Koller",
      "Benedikt Fesl",
      "Samer Bazzi",
      "Wen Xu",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.12002"
  },
  {
    "id": "arXiv:2205.12005",
    "title": "mPLUG: Effective and Efficient Vision-Language Learning by Cross-modal  Skip-connections",
    "abstract": "Large-scale pretrained foundation models have been an emerging paradigm for\nbuilding artificial intelligence (AI) systems, which can be quickly adapted to\na wide range of downstream tasks. This paper presents mPLUG, a new\nvision-language foundation model for both cross-modal understanding and\ngeneration. Most existing pre-trained models suffer from the problems of low\ncomputational efficiency and information asymmetry brought by the long visual\nsequence in cross-modal alignment. To address these problems, mPLUG introduces\nan effective and efficient vision-language architecture with novel cross-modal\nskip-connections, which creates inter-layer shortcuts that skip a certain\nnumber of layers for time-consuming full self-attention on the vision side.\nmPLUG is pre-trained end-to-end on large-scale image-text pairs with both\ndiscriminative and generative objectives. It achieves state-of-the-art results\non a wide range of vision-language downstream tasks, such as image captioning,\nimage-text retrieval, visual grounding and visual question answering. mPLUG\nalso demonstrates strong zero-shot transferability when directly transferred to\nmultiple video-language tasks.",
    "descriptor": "",
    "authors": [
      "Chenliang Li",
      "Haiyang Xu",
      "Junfeng Tian",
      "Wei Wang",
      "Ming Yan",
      "Bin Bi",
      "Jiabo Ye",
      "Hehong Chen",
      "Guohai Xu",
      "Zheng Cao",
      "Ji Zhang",
      "Songfang Huang",
      "Fei Huang",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12005"
  },
  {
    "id": "arXiv:2205.12008",
    "title": "Core-shell enhanced single particle model for LiFePO$_4$ batteries",
    "abstract": "In this paper, a novel electrochemical model for LiFePO$_4$ battery cells\nthat accounts for the positive particle lithium intercalation and\ndeintercalation dynamics is proposed. Starting from the enhanced single\nparticle model, mass transport and balance equations along with suitable\nboundary conditions are introduced to model the phase transformation phenomena\nduring lithiation and delithiation in the positive electrode material. The\nlithium-poor and lithium-rich phases are modeled using the core-shell\nprinciple, where a core composition is encapsulated with a shell composition.\nThe coupled partial differential equations describing the phase transformation\nare discretized using the finite difference method, from which a system of\nordinary differential equations written in state-space representation is\nobtained. Finally, model parameter identification is performed using\nexperimental data from a 49Ah LFP pouch cell.",
    "descriptor": "",
    "authors": [
      "Aki Takahashi",
      "Gabriele Pozzato",
      "Anirudh Allam",
      "Vahid Azimi",
      "Xueyan Li",
      "Donghoon Lee",
      "Johan Ko",
      "Simona Onori"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.12008"
  },
  {
    "id": "arXiv:2205.12009",
    "title": "Graph Convolutional Reinforcement Learning for Collaborative Queuing  Agents",
    "abstract": "In this paper, we explore the use of multi-agent deep learning as well as\nlearning to cooperate principles to meet stringent service level agreements, in\nterms of throughput and end-to-end delay, for a set of classified network\nflows. We consider agents built on top of a weighted fair queuing algorithm\nthat continuously set weights for three flow groups: gold, silver, and bronze.\nWe rely on a novel graph-convolution based, multi-agent reinforcement learning\napproach known as DGN. As benchmarks, we propose centralized and distributed\ndeep Q-network approaches and evaluate their performances in different network,\ntraffic, and routing scenarios, highlighting the effectiveness of our proposals\nand the importance of agent cooperation. We show that our DGN-based approach\nmeets stringent throughput and delay requirements across all scenarios.",
    "descriptor": "",
    "authors": [
      "Hassan Fawaz",
      "Julien Lesca",
      "Pham Tran Anh Quang",
      "J\u00e9r\u00e9mie Leguay",
      "Djamal Zeghlache",
      "Paolo Medagliani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12009"
  },
  {
    "id": "arXiv:2205.12010",
    "title": "SFace: Sigmoid-Constrained Hypersphere Loss for Robust Face Recognition",
    "abstract": "Deep face recognition has achieved great success due to large-scale training\ndatabases and rapidly developing loss functions. The existing algorithms devote\nto realizing an ideal idea: minimizing the intra-class distance and maximizing\nthe inter-class distance. However, they may neglect that there are also low\nquality training images which should not be optimized in this strict way.\nConsidering the imperfection of training databases, we propose that intra-class\nand inter-class objectives can be optimized in a moderate way to mitigate\noverfitting problem, and further propose a novel loss function, named\nsigmoid-constrained hypersphere loss (SFace). Specifically, SFace imposes\nintra-class and inter-class constraints on a hypersphere manifold, which are\ncontrolled by two sigmoid gradient re-scale functions respectively. The sigmoid\ncurves precisely re-scale the intra-class and inter-class gradients so that\ntraining samples can be optimized to some degree. Therefore, SFace can make a\nbetter balance between decreasing the intra-class distances for clean examples\nand preventing overfitting to the label noise, and contributes more robust deep\nface recognition models. Extensive experiments of models trained on\nCASIA-WebFace, VGGFace2, and MS-Celeb-1M databases, and evaluated on several\nface recognition benchmarks, such as LFW, MegaFace and IJB-C databases, have\ndemonstrated the superiority of SFace.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Yaoyao Zhong",
      "Weihong Deng",
      "Jiani Hu",
      "Dongyue Zhao",
      "Xian Li",
      "Dongchao Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12010"
  },
  {
    "id": "arXiv:2205.12012",
    "title": "Analysing the Greek Parliament Records with Emotion Classification",
    "abstract": "In this project, we tackle emotion classification for the Greek language,\npresenting and releasing a new dataset in Greek. We fine-tune and assess\nTransformer-based masked language models that were pre-trained on monolingual\nand multilingual resources, and we present the results per emotion and by\naggregating at the sentiment and subjectivity level. The potential of the\npresented resources is investigated by detecting and studying the emotion of\n`disgust' in the Greek Parliament records. We: (a) locate the months with the\nhighest values from 1989 to present, (b) rank the Greek political parties based\non the presence of this emotion in their speeches, and (c) study the emotional\ncontext shift of words used to stigmatise people.",
    "descriptor": "",
    "authors": [
      "John Pavlopoulos",
      "Vanessa Lislevand"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12012"
  },
  {
    "id": "arXiv:2205.12013",
    "title": "Naive Few-Shot Learning: Sequence Consistency Evaluation",
    "abstract": "Cognitive psychologists often use the term $\\textit{fluid intelligence}$ to\ndescribe the ability of humans to solve novel tasks without any prior training.\nIn contrast to humans, deep neural networks can perform cognitive tasks only\nafter extensive (pre-)training with a large number of relevant examples.\nMotivated by fluid intelligence research in the cognitive sciences, we built a\nbenchmark task which we call sequence consistency evaluation (SCE) that can be\nused to address this gap. Solving the SCE task requires the ability to extract\nsimple rules from sequences, a basic computation that is required for solving\nvarious intelligence tests in humans. We tested $\\textit{untrained}$ (naive)\ndeep learning models in the SCE task. Specifically, we compared Relation\nNetworks (RN) and Contrastive Predictive Coding (CPC), two models that can\nextract simple rules from sequences, and found that the latter, which imposes a\nstructure on the predictable rule does better. We further found that simple\nnetworks fare better in this task than complex ones. Finally, we show that this\napproach can be used for security camera anomaly detection without any prior\ntraining.",
    "descriptor": "",
    "authors": [
      "Tomer Barak",
      "Yonatan Loewenstein"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.12013"
  },
  {
    "id": "arXiv:2205.12019",
    "title": "Economic Topology Optimization of District Heating Networks using a  SIMP-like Multi-Material Penalization Approach",
    "abstract": "In the presented study, a multi-material 'Solid Isotropic Material with\nPenalization' (SIMP)-like penalization approach for the economic topology\noptimization of District Heating Networks is proposed. For District Heating\nNetworks, an important technology for carbon-neutral space heating, the upfront\ninvestment is a crucial factor for the rollout of this technology. Today, the\npipe routing is usually designed relying on a linearization of the underlying\nheat transport problem. This study proposes to solve the optimal pipe routing\nproblem as a non-linear topology optimization problem, drawing inspiration from\nPDE-constrained topology optimization. The optimization problem is formulated\naround a non-linear heat transport model and minimizes a detailed net present\nvalue representation of the heating network cost. A discrete network topology\nand near-discrete pipe design is achieved by using a pipe penalization\nstrategy. For a realistic test case, the proposed algorithm achieves a discrete\nnetwork topology and near-discrete pipe design that outperforms simple\npost-processing steps.",
    "descriptor": "",
    "authors": [
      "Yannick Wack",
      "Martine Baelmans",
      "Robbe Salenbien",
      "Maarten Blommaert"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.12019"
  },
  {
    "id": "arXiv:2205.12020",
    "title": "Concurrent Credit Assignment for Data-efficient Reinforcement Learning",
    "abstract": "The capability to widely sample the state and action spaces is a key\ningredient toward building effective reinforcement learning algorithms. The\nvariational optimization principles exposed in this paper emphasize the\nimportance of an occupancy model to synthesizes the general distribution of the\nagent's environmental states over which it can act (defining a virtual\n``territory''). The occupancy model is the subject of frequent updates as the\nexploration progresses and that new states are undisclosed during the course of\nthe training. By making a uniform prior assumption, the resulting objective\nexpresses a balance between two concurrent tendencies, namely the widening of\nthe occupancy space and the maximization of the rewards, reminding of the\nclassical exploration/exploitation trade-off. Implemented on an actor-critic\noff-policy on classic continuous action benchmarks, it is shown to provide\nsignificant increase in the sampling efficacy, that is reflected in a reduced\ntraining time and higher returns, in both the dense and the sparse rewards\ncases.",
    "descriptor": "\nComments: IJCNN 2022 conference\n",
    "authors": [
      "Emmanuel Dauc\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.12020"
  },
  {
    "id": "arXiv:2205.12021",
    "title": "PatchNR: Learning from Small Data by Patch Normalizing Flow  Regularization",
    "abstract": "Learning neural networks using only a small amount of data is an important\nongoing research topic with tremendous potential for applications. In this\npaper, we introduce a regularizer for the variational modeling of inverse\nproblems in imaging based on normalizing flows. Our regularizer, called\npatchNR, involves a normalizing flow learned on patches of very few images. The\nsubsequent reconstruction method is completely unsupervised and the same\nregularizer can be used for different forward operators acting on the same\nclass of images. By investigating the distribution of patches versus those of\nthe whole image class, we prove that our variational model is indeed a MAP\napproach. Our model can be generalized to conditional patchNRs, if additional\nsupervised information is available. Numerical examples for low-dose CT,\nlimited-angle CT and superresolution of material images demonstrate that our\nmethod provides high quality results among unsupervised methods, but requires\nonly few data.",
    "descriptor": "",
    "authors": [
      "Fabian Altekr\u00fcger",
      "Alexander Denker",
      "Paul Hagemann",
      "Johannes Hertrich",
      "Peter Maass",
      "Gabriele Steidl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2205.12021"
  },
  {
    "id": "arXiv:2205.12022",
    "title": "Improving Human Image Synthesis with Residual Fast Fourier  Transformation and Wasserstein Distance",
    "abstract": "With the rapid development of the Metaverse, virtual humans have emerged, and\nhuman image synthesis and editing techniques, such as pose transfer, have\nrecently become popular. Most of the existing techniques rely on GANs, which\ncan generate good human images even with large variants and occlusions. But\nfrom our best knowledge, the existing state-of-the-art method still has the\nfollowing problems: the first is that the rendering effect of the synthetic\nimage is not realistic, such as poor rendering of some regions. And the second\nis that the training of GAN is unstable and slow to converge, such as model\ncollapse. Based on the above two problems, we propose several methods to solve\nthem. To improve the rendering effect, we use the Residual Fast Fourier\nTransform Block to replace the traditional Residual Block. Then, spectral\nnormalization and Wasserstein distance are used to improve the speed and\nstability of GAN training. Experiments demonstrate that the methods we offer\nare effective at solving the problems listed above, and we get state-of-the-art\nscores in LPIPS and PSNR.",
    "descriptor": "",
    "authors": [
      "Jianhan Wu",
      "Shijing Si",
      "Jianzong Wang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12022"
  },
  {
    "id": "arXiv:2205.12023",
    "title": "A divergence preserving cut finite element method for Darcy flow",
    "abstract": "We study cut finite element discretizations of a Darcy interface problem\nbased on the mixed finite element pairs $\\textbf{RT}_0\\times\\text{P}_0$,\n$\\textbf{BDM}_1\\times \\text{P}_0$, and $\\textbf{RT}_1\\times \\text{P}_1$. We\nshow that the standard ghost penalty stabilization, often added in the weak\nforms of cut finite element methods for stability and control of the condition\nnumber of the resulting linear system matrix, pollutes the computed velocity\nfield so the divergence-free property of the considered elements is lost.\n%optimal approximation of the divergence is lost. Therefore, we propose two\ncorrections to the standard stabilization strategy; using macro-elements and\nnew stabilization terms for the pressure. By decomposing the computational mesh\ninto macro-elements and applying ghost penalty terms only on interior edges of\nmacro-elements, stabilization is active only where needed. By modifying the\nstandard stabilization terms for the pressure we recover the optimal\napproximation of the divergence without losing control of the condition number\nof the linear system matrix. Numerical experiments indicate that with the new\nstabilization terms the unfitted finite element discretization, for the given\nelement pairs, results in 1) optimal rates of convergence of the approximate\nvelocity and pressure; 2) well-posed linear systems where the condition number\nof the system matrix scales as for fitted finite element discretizations; 3)\noptimal rates of convergence of the approximate divergence with pointwise\ndivergence-free approximations of solenoidal velocity fields. All three\nproperties hold independently of how the interface is positioned relative the\ncomputational mesh.",
    "descriptor": "",
    "authors": [
      "Thomas Frachon",
      "Peter Hansbo",
      "Erik Nilsson",
      "Sara Zahedi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.12023"
  },
  {
    "id": "arXiv:2205.12027",
    "title": "Generalized Multi-cluster Game under Partial-decision Information with  Applications to Management of Energy Internet",
    "abstract": "The decision making and management of many engineering networks involves\nmultiple parties with conflicting interests, while each party is constituted\nwith multiple agents. Such problems can be casted as a multi-cluster game. Each\ncluster is treated as a self-interested player in a non-cooperative game where\nagents in the same cluster cooperate together to optimize the payoff function\nof the cluster. In a large-scale network, the information of agents in a\ncluster can not be available immediately for agents beyond this cluster, which\nraise challenges to the existing Nash equilibrium seeking algorithms. Hence, we\nconsider a partial-decision information scenario in generalized Nash\nequilibrium seeking for multi-cluster games in a distributed manner. We\nreformulate the problem as finding zeros of the sum of preconditioned monotone\noperators by the primal-dual analysis and graph Laplacian matrix. Then a\ndistributed generalized Nash equilibrium seeking algorithm is proposed without\nrequiring fully awareness of its opponent clusters' decisions based on a\nforward-backward-forward method. With the algorithm, each agent estimates the\nstrategies of all the other clusters by communicating with neighbors via an\nundirected network. We show that the derived operators can be monotone when the\ncommunication strength parameter is sufficiently large. We prove the algorithm\nconvergence resorting to the fixed point theory by providing a sufficient\ncondition. We discuss its potential application in Energy Internet with\nnumerical studies.",
    "descriptor": "",
    "authors": [
      "Yue Chen",
      "Peng Yi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.12027"
  },
  {
    "id": "arXiv:2205.12028",
    "title": "Effect of Gender, Pose and Camera Distance on Human Body Dimensions  Estimation",
    "abstract": "Human Body Dimensions Estimation (HBDE) is a task that an intelligent agent\ncan perform to attempt to determine human body information from images (2D) or\npoint clouds or meshes (3D). More specifically, if we define the HBDE problem\nas inferring human body measurements from images, then HBDE is a difficult,\ninverse, multi-task regression problem that can be tackled with machine\nlearning techniques, particularly convolutional neural networks (CNN). Despite\nthe community's tremendous effort to advance human shape analysis, there is a\nlack of systematic experiments to assess CNNs estimation of human body\ndimensions from images. Our contribution lies in assessing a CNN estimation\nperformance in a series of controlled experiments. To that end, we augment our\nrecently published neural anthropometer dataset by rendering images with\ndifferent camera distance. We evaluate the network inference absolute and\nrelative mean error between the estimated and actual HBDs. We train and\nevaluate the CNN in four scenarios: (1) training with subjects of a specific\ngender, (2) in a specific pose, (3) sparse camera distance and (4) dense camera\ndistance. Not only our experiments demonstrate that the network can perform the\ntask successfully, but also reveal a number of relevant facts that contribute\nto better understand the task of HBDE.",
    "descriptor": "\nComments: Accepted to the workshop \"Towards a Complete Analysis of People: From Face and Body to Clothes\" (TCAP 2021) at the 21st International Conference on Image Analysis and Processing, May 23-27, 2022, Lecce, Italy\n",
    "authors": [
      "Yansel G\u00f3nzalez Tejeda",
      "Helmut A. Mayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12028"
  },
  {
    "id": "arXiv:2205.12029",
    "title": "VLCDoC: Vision-Language Contrastive Pre-Training Model for Cross-Modal  Document Classification",
    "abstract": "Multimodal learning from document data has achieved great success lately as\nit allows to pre-train semantically meaningful features as a prior into a\nlearnable downstream approach. In this paper, we approach the document\nclassification problem by learning cross-modal representations through language\nand vision cues, considering intra- and inter-modality relationships. Instead\nof merging features from different modalities into a common representation\nspace, the proposed method exploits high-level interactions and learns relevant\nsemantic information from effective attention flows within and across\nmodalities. The proposed learning objective is devised between intra- and\ninter-modality alignment tasks, where the similarity distribution per task is\ncomputed by contracting positive sample pairs while simultaneously contrasting\nnegative ones in the common feature representation space}. Extensive\nexperiments on public document classification datasets demonstrate the\neffectiveness and the generalization capacity of our model on both low-scale\nand large-scale datasets.",
    "descriptor": "\nComments: Preprint submitted to Pattern Recognition\n",
    "authors": [
      "Souhail Bakkali",
      "Zuheng Ming",
      "Mickael Coustaty",
      "Mar\u00e7al Rusi\u00f1ol",
      "Oriol Ramos Terrades"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12029"
  },
  {
    "id": "arXiv:2205.12031",
    "title": "Efficient Deviation Types and Learning for Hindsight Rationality in  Extensive-Form Games: Corrections",
    "abstract": "Hindsight rationality is an approach to playing general-sum games that\nprescribes no-regret learning dynamics for individual agents with respect to a\nset of deviations, and further describes jointly rational behavior among\nmultiple agents with mediated equilibria. To develop hindsight rational\nlearning in sequential decision-making settings, we formalize behavioral\ndeviations as a general class of deviations that respect the structure of\nextensive-form games. Integrating the idea of time selection into\ncounterfactual regret minimization (CFR), we introduce the extensive-form\nregret minimization (EFR) algorithm that achieves hindsight rationality for any\ngiven set of behavioral deviations with computation that scales closely with\nthe complexity of the set. We identify behavioral deviation subsets, the\npartial sequence deviation types, that subsume previously studied types and\nlead to efficient EFR instances in games with moderate lengths. In addition, we\npresent a thorough empirical analysis of EFR instantiated with different\ndeviation types in benchmark games, where we find that stronger types typically\ninduce better performance.",
    "descriptor": "\nComments: This is a version of arXiv:2102.06973 showing corrections to the official version published at ICML 2021. 45 pages and 6 figures\n",
    "authors": [
      "Dustin Morrill",
      "Ryan D'Orazio",
      "Marc Lanctot",
      "James R. Wright",
      "Michael Bowling",
      "Amy R. Greenwald"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12031"
  },
  {
    "id": "arXiv:2205.12035",
    "title": "RetroMAE: Pre-training Retrieval-oriented Transformers via Masked  Auto-Encoder",
    "abstract": "Pre-trained models have demonstrated superior power on many important tasks.\nHowever, it is still an open problem of designing effective pre-training\nstrategies so as to promote the models' usability on dense retrieval. In this\npaper, we propose a novel pre-training framework for dense retrieval based on\nthe Masked Auto-Encoder, known as RetroMAE. Our proposed framework is\nhighlighted for the following critical designs: 1) a MAE based pre-training\nworkflow, where the input sentence is polluted on both encoder and decoder side\nwith different masks, and original sentence is reconstructed based on both\nsentence embedding and masked sentence; 2) asymmetric model architectures, with\na large-scale expressive transformer for sentence encoding and a extremely\nsimplified transformer for sentence reconstruction; 3) asymmetric masking\nratios, with a moderate masking on the encoder side (15%) and an aggressive\nmasking ratio on the decoder side (50~90%). We pre-train a BERT like encoder on\nEnglish Wikipedia and BookCorpus, where it notably outperforms the existing\npre-trained models on a wide range of dense retrieval benchmarks, like MS\nMARCO, Open-domain Question Answering, and BEIR.",
    "descriptor": "",
    "authors": [
      "Zheng Liu",
      "Yingxia Shao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12035"
  },
  {
    "id": "arXiv:2205.12038",
    "title": "FedEntropy: Efficient Device Grouping for Federated Learning Using  Maximum Entropy Judgment",
    "abstract": "Along with the popularity of Artificial Intelligence (AI) and\nInternet-of-Things (IoT), Federated Learning (FL) has attracted steadily\nincreasing attentions as a promising distributed machine learning paradigm,\nwhich enables the training of a central model on for numerous decentralized\ndevices without exposing their privacy. However, due to the biased data\ndistributions on involved devices, FL inherently suffers from low\nclassification accuracy in non-IID scenarios. Although various device grouping\nmethod have been proposed to address this problem, most of them neglect both i)\ndistinct data distribution characteristics of heterogeneous devices, and ii)\ncontributions and hazards of local models, which are extremely important in\ndetermining the quality of global model aggregation. In this paper, we present\nan effective FL method named FedEntropy with a novel dynamic device grouping\nscheme, which makes full use of the above two factors based on our proposed\nmaximum entropy judgement heuristic.Unlike existing FL methods that directly\naggregate local models returned from all the selected devices, in one FL round\nFedEntropy firstly makes a judgement based on the pre-collected soft labels of\nselected devices and then only aggregates the local models that can maximize\nthe overall entropy of these soft labels. Without collecting local models that\nare harmful for aggregation, FedEntropy can effectively improve global model\naccuracy while reducing the overall communication overhead. Comprehensive\nexperimental results on well-known benchmarks show that, FedEntropy not only\noutperforms state-of-the-art FL methods in terms of model accuracy and\ncommunication overhead, but also can be integrated into them to enhance their\nclassification performance.",
    "descriptor": "",
    "authors": [
      "Zhiwei Ling",
      "Zhihao Yue",
      "Jun Xia",
      "Ming Hu",
      "Ting Wang",
      "Mingsong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.12038"
  },
  {
    "id": "arXiv:2205.12041",
    "title": "Privacy-Preserving Image Classification Using Vision Transformer",
    "abstract": "In this paper, we propose a privacy-preserving image classification method\nthat is based on the combined use of encrypted images and the vision\ntransformer (ViT). The proposed method allows us not only to apply images\nwithout visual information to ViT models for both training and testing but to\nalso maintain a high classification accuracy. ViT utilizes patch embedding and\nposition embedding for image patches, so this architecture is shown to reduce\nthe influence of block-wise image transformation. In an experiment, the\nproposed method for privacy-preserving image classification is demonstrated to\noutperform state-of-the-art methods in terms of classification accuracy and\nrobustness against various attacks.",
    "descriptor": "",
    "authors": [
      "Zheng Qi",
      "AprilPyone MaungMaung",
      "Yuma Kinoshita",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12041"
  },
  {
    "id": "arXiv:2205.12042",
    "title": "HCFRec: Hash Collaborative Filtering via Normalized Flow with Structural  Consensus for Efficient Recommendation",
    "abstract": "The ever-increasing data scale of user-item interactions makes it challenging\nfor an effective and efficient recommender system. Recently, hash-based\ncollaborative filtering (Hash-CF) approaches employ efficient Hamming distance\nof learned binary representations of users and items to accelerate\nrecommendations. However, Hash-CF often faces two challenging problems, i.e.,\noptimization on discrete representations and preserving semantic information in\nlearned representations. To address the above two challenges, we propose\nHCFRec, a novel Hash-CF approach for effective and efficient recommendations.\nSpecifically, HCFRec not only innovatively introduces normalized flow to learn\nthe optimal hash code by efficiently fit a proposed approximate mixture\nmultivariate normal distribution, a continuous but approximately discrete\ndistribution, but also deploys a cluster consistency preserving mechanism to\npreserve the semantic structure in representations for more accurate\nrecommendations. Extensive experiments conducted on six real-world datasets\ndemonstrate the superiority of our HCFRec compared to the state-of-art methods\nin terms of effectiveness and efficiency.",
    "descriptor": "",
    "authors": [
      "Fan Wang",
      "Weiming Liu",
      "Chaochao Chen",
      "Mengying Zhu",
      "Xiaolin Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12042"
  },
  {
    "id": "arXiv:2205.12050",
    "title": "Training Efficient CNNS: Tweaking the Nuts and Bolts of Neural Networks  for Lighter, Faster and Robust Models",
    "abstract": "Deep Learning has revolutionized the fields of computer vision, natural\nlanguage understanding, speech recognition, information retrieval and more.\nMany techniques have evolved over the past decade that made models lighter,\nfaster, and robust with better generalization. However, many deep learning\npractitioners persist with pre-trained models and architectures trained mostly\non standard datasets such as Imagenet, MS-COCO, IMDB-Wiki Dataset, and\nKinetics-700 and are either hesitant or unaware of redesigning the architecture\nfrom scratch that will lead to better performance. This scenario leads to\ninefficient models that are not suitable on various devices such as mobile,\nedge, and fog. In addition, these conventional training methods are of concern\nas they consume a lot of computing power. In this paper, we revisit various\nSOTA techniques that deal with architecture efficiency (Global Average Pooling,\ndepth-wise convolutions & squeeze and excitation, Blurpool), learning rate\n(Cyclical Learning Rate), data augmentation (Mixup, Cutout), label manipulation\n(label smoothing), weight space manipulation (stochastic weight averaging), and\noptimizer (sharpness aware minimization). We demonstrate how an efficient deep\nconvolution network can be built in a phased manner by sequentially reducing\nthe number of training parameters and using the techniques mentioned above. We\nachieved a SOTA accuracy of 99.2% on MNIST data with just 1500 parameters and\nan accuracy of 86.01% with just over 140K parameters on the CIFAR-10 dataset.",
    "descriptor": "\nComments: Accepted at Machine Learning Developers Summit-2022, Bangalore, India\n",
    "authors": [
      "Sabeesh Ethiraj",
      "Bharath Kumar Bolla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12050"
  },
  {
    "id": "arXiv:2205.12052",
    "title": "On statistic alignment for domain adaptation in structural health  monitoring",
    "abstract": "The practical application of structural health monitoring (SHM) is often\nlimited by the availability of labelled data. Transfer learning - specifically\nin the form of domain adaptation (DA) - gives rise to the possibility of\nleveraging information from a population of physical or numerical structures,\nby inferring a mapping that aligns the feature spaces. Typical DA methods rely\non nonparametric distance metrics, which require sufficient data to perform\ndensity estimation. In addition, these methods can be prone to performance\ndegradation under class imbalance. To address these issues, statistic alignment\n(SA) is discussed, with a demonstration of how these methods can be made robust\nto class imbalance, including a special case of class imbalance called a\npartial DA scenario. SA is demonstrated to facilitate damage localisation with\nno target labels in a numerical case study, outperforming other\nstate-of-the-art DA methods. It is then shown to be capable of aligning the\nfeature spaces of a real heterogeneous population, the Z24 and KW51 bridges,\nwith only 220 samples used from the KW51 bridge. Finally, in scenarios where\nmore complex mappings are required for knowledge transfer, SA is shown to be a\nvital pre-processing tool, increasing the performance of established DA\nmethods.",
    "descriptor": "",
    "authors": [
      "Jack Poole",
      "Paul Gardner",
      "Nikolaos Dervilis",
      "Lawrence Bull",
      "Keith Worden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12052"
  },
  {
    "id": "arXiv:2205.12054",
    "title": "EventMix: An Efficient Augmentation Strategy for Event-Based Data",
    "abstract": "High-quality and challenging event stream datasets play an important role in\nthe design of an efficient event-driven mechanism that mimics the brain.\nAlthough event cameras can provide high dynamic range and low-energy event\nstream data, the scale is smaller and more difficult to obtain than traditional\nframe-based data, which restricts the development of neuromorphic computing.\nData augmentation can improve the quantity and quality of the original data by\nprocessing more representations from the original data. This paper proposes an\nefficient data augmentation strategy for event stream data: EventMix. We\ncarefully design the mixing of different event streams by Gaussian Mixture\nModel to generate random 3D masks and achieve arbitrary shape mixing of event\nstreams in the spatio-temporal dimension. By computing the relative distances\nof event streams, we propose a more reasonable way to assign labels to the\nmixed samples. The experimental results on multiple neuromorphic datasets have\nshown that our strategy can improve its performance on neuromorphic datasets\nboth for ANNs and SNNs, and we have achieved state-of-the-art performance on\nDVS-CIFAR10, N-Caltech101, N-CARS, and DVS-Gesture datasets.",
    "descriptor": "",
    "authors": [
      "Guobin Shen",
      "Dongcheng Zhao",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.12054"
  },
  {
    "id": "arXiv:2205.12059",
    "title": "The Laplacian Paradigm in the Broadcast Congested Clique",
    "abstract": "In this paper, we bring the main tools of the Laplacian paradigm to the\nBroadcast Congested Clique. We introduce an algorithm to compute spectral\nsparsifiers in a polylogarithmic number of rounds, which directly leads to an\nefficient Laplacian solver. Based on this primitive, we consider the linear\nprogram solver of Lee and Sidford (FOCS 2014). We show how to solve certain\nlinear programs up to additive error $\\epsilon$ with $n$ constraints on an\n$n$-vertex Broadcast Congested Clique network in $\\tilde\nO(\\sqrt{n}\\log(1/\\epsilon))$ rounds. Using this, we show how to find an exact\nsolution to the minimum cost flow problem in $\\tilde O(\\sqrt{n})$ rounds.",
    "descriptor": "\nComments: To be presented at: the 41st ACM Symposium on Principles of Distributed Computing (PODC 2022)\n",
    "authors": [
      "Sebastian Forster",
      "Tijn de Vos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.12059"
  },
  {
    "id": "arXiv:2205.12061",
    "title": "C-AND: Mixed Writing Scheme for Disturb Reduction in 1T Ferroelectric  FET Memory",
    "abstract": "Ferroelectric field effect transistor (FeFET) memory has shown the potential\nto meet the requirements of the growing need for fast, dense, low-power, and\nnon-volatile memories. In this paper, we propose a memory architecture named\ncrossed-AND (C-AND), in which each storage cell consists of a single\nferroelectric transistor. The write operation is performed using different\nwrite schemes and different absolute voltages, to account for the asymmetric\nswitching voltages of the FeFET. It enables writing an entire wordline in two\nconsecutive cycles and prevents current and power through the channel of the\ntransistor. During the read operation, the current and power are mostly sensed\nat a single selected device in each column. The read scheme additionally\nenables reading an entire word without read errors, even along long bitlines.\nOur Simulations demonstrate that, in comparison to the previously proposed AND\narchitecture, the C-AND architecture diminishes read errors, reduces write\ndisturbs, enables the usage of longer bitlines, and saves up to 2.92X in memory\ncell area.",
    "descriptor": "\nComments: 11 pages, 11 figures\n",
    "authors": [
      "Mor M. Dahan",
      "Evelyn T. Breyer",
      "Stefan Slesazeck",
      "Thomas Mikolajick",
      "Shahar Kvatinsky"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.12061"
  },
  {
    "id": "arXiv:2205.12064",
    "title": "Process Mining Algorithm for Online Intrusion Detection System",
    "abstract": "In this paper, we consider the applications of process mining in intrusion\ndetection. We propose a novel process mining inspired algorithm to be used to\npreprocess data in intrusion detection systems (IDS). The algorithm is designed\nto process the network packet data and it works well in online mode for online\nintrusion detection. To test our algorithm, we used the CSE-CIC-IDS2018 dataset\nwhich contains several common attacks. The packet data was preprocessed with\nthis algorithm and then fed into the detectors. We report on the experiments\nusing the algorithm with different machine learning (ML) models as classifiers\nto verify that our algorithm works as expected; we tested the performance on\nanomaly detection methods as well and reported on the existing preprocessing\ntool CICFlowMeter for the comparison of performance.",
    "descriptor": "\nComments: International Conference on Software Testing, Machine Learning and Complex Process Analysis\n",
    "authors": [
      "Yinzheng Zhong",
      "John Y. Goulermas",
      "Alexei Lisitsa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.12064"
  },
  {
    "id": "arXiv:2205.12066",
    "title": "Context Attention Network for Skeleton Extraction",
    "abstract": "Skeleton extraction is a task focused on providing a simple representation of\nan object by extracting the skeleton from the given binary or RGB image. In\nrecent years many attractive works in skeleton extraction have been made. But\nas far as we know, there is little research on how to utilize the context\ninformation in the binary shape of objects. In this paper, we propose an\nattention-based model called Context Attention Network (CANet), which\nintegrates the context extraction module in a UNet architecture and can\neffectively improve the ability of network to extract the skeleton pixels.\nMeanwhile, we also use some novel techniques including distance transform,\nweight focal loss to achieve good results on the given dataset. Finally,\nwithout model ensemble and with only 80% of the training images, our method\nachieves 0.822 F1 score during the development phase and 0.8507 F1 score during\nthe final phase of the Pixel SkelNetOn Competition, ranking 1st place on the\nleaderboard.",
    "descriptor": "\nComments: Accepted at the Deep Learning for Geometric Computing (DLGC) workshop at CVPR 2022\n",
    "authors": [
      "Zixuan Huang",
      "Yunfeng Wang",
      "Zhiwen Chen",
      "Xin Gao",
      "Ruili Feng",
      "Xiaobo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12066"
  },
  {
    "id": "arXiv:2205.12068",
    "title": "Construction and analysis of the quadratic finite volume methods on  tetrahedral meshes",
    "abstract": "A family of quadratic finite volume method (FVM) schemes are constructed and\nanalyzed over tetrahedral meshes. In order to prove stability and error\nestimate, we propose the minimum V-angle condition on tetrahedral meshes, and\nthe surface and volume orthogonal conditions on dual meshes. Through the\nelement analysis technique, the local stability is equivalent to a positive\ndefiniteness of a $9\\times9$ element matrix, which is difficult to analyze\ndirectly or even numerically. With the help of the surface orthogonal condition\nand congruent transformation, this element matrix is reduced into a block\ndiagonal matrix, then we carry out the stability result under the minimum\nV-angle condition. It is worth mentioning that the minimum V-angle condition of\nthe tetrahedral case is very different from a simple extension of the minimum\nangle condition for triangular meshes, while it is also convenient to use in\npractice. Based on the stability, we prove the optimal $ H^{1} $ and $L^2$\nerror estimates respectively, where the orthogonal conditions play an important\nrole in ensuring optimal $L^2$ convergence rate. Numerical experiments are\npresented to illustrate our theoretical results.",
    "descriptor": "\nComments: 34 pages, 15 figures\n",
    "authors": [
      "Peng Yang",
      "Xiang Wang",
      "Yonghai Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.12068"
  },
  {
    "id": "arXiv:2205.12070",
    "title": "Deep Reinforcement Learning for Multi-class Imbalanced Training",
    "abstract": "With the rapid growth of memory and computing power, datasets are becoming\nincreasingly complex and imbalanced. This is especially severe in the context\nof clinical data, where there may be one rare event for many cases in the\nmajority class. We introduce an imbalanced classification framework, based on\nreinforcement learning, for training extremely imbalanced data sets, and extend\nit for use in multi-class settings. We combine dueling and double deep\nQ-learning architectures, and formulate a custom reward function and\nepisode-training procedure, specifically with the added capability of handling\nmulti-class imbalanced training. Using real-world clinical case studies, we\ndemonstrate that our proposed framework outperforms current state-of-the-art\nimbalanced learning methods, achieving more fair and balanced classification,\nwhile also significantly improving the prediction of minority classes.",
    "descriptor": "",
    "authors": [
      "Jenny Yang",
      "Rasheed El-Bouri",
      "Odhran O'Donoghue",
      "Alexander S. Lachapelle",
      "Andrew A. S. Soltan",
      "David A. Clifton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12070"
  },
  {
    "id": "arXiv:2205.12072",
    "title": "Classification of Phonological Parameters in Sign Languages",
    "abstract": "Signers compose sign language phonemes that enable communication by combining\nphonological parameters such as handshape, orientation, location, movement, and\nnon-manual features. Linguistic research often breaks down signs into their\nconstituent parts to study sign languages and often a lot of effort is invested\ninto the annotation of the videos. In this work we show how a single model can\nbe used to recognise the individual phonological parameters within sign\nlanguages with the aim of either to assist linguistic annotations or to\ndescribe the signs for the sign recognition models. We use Danish Sign Language\ndata set `Ordbog over Dansk Tegnsprog' to generate multiple data sets using\npose estimation model, which are then used for training the multi-label Fast\nR-CNN model to support multi-label modelling. Moreover, we show that there is a\nsignificant co-dependence between the orientation and location phonological\nparameters in the generated data and we incorporate this co-dependence in the\nmodel to achieve better performance.",
    "descriptor": "\nComments: 18 pages, 27 figures\n",
    "authors": [
      "Boris Mocialov",
      "Graham Turner",
      "Helen Hastie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12072"
  },
  {
    "id": "arXiv:2205.12075",
    "title": "Failure Mechanism Traceability and Application in Human System Interface  of Nuclear Power Plants using RESHA",
    "abstract": "In recent years, there has been considerable effort to modernize existing and\nnew nuclear power plants with digital instrumentation and control systems.\nHowever, there has also been considerable concern both by industry and\nregulatory bodies for the risk and consequence analysis of these systems. Of\nconcern are digital common cause failures specifically due to software defects.\nThese failures by the software can occur in both the control and monitoring of\na system. While many methods have been proposed to identify software failure\nmodes, such as Systems Theoretic Process Analysis, Hazard and Consequence\nAnalysis for Digital Systems, etc., these methods are focused primarily on the\ncontrol action pathway of a system. In contrast, the information feedback\npathway lacks Unsafe Control Actions, which are typically related to software\nbasic events; thus, assessment of software basic events in such systems is\nunclear. In this work, we present the idea of intermediate processors and\nUnsafe Information Flow (UIF) to help safety analysts trace failure mechanisms\nin the feedback pathway and how they can be integrated into a fault tree for\nimproved assessment capability. The concepts presented are demonstrated in two\ncomprehensive case studies, a smart sensor integrated platform for unmanned\nautonomous vehicles and another on a representative advanced human system\ninterface for safety critical plant monitoring. The qualitative software basic\nevents are identified, and a fault tree analysis is conducted based on a\nmodified Redundancy guided Systems theoretic Hazard Analysis methodology. The\ncase studies demonstrate the use of UIFs and intermediate processors in the\nfault tree to improve traceability of software failures in highly complex\ndigital instrumentation feedback. The improved method clarifies fault tree\nconstruction when multiple component dependencies are present in the system.",
    "descriptor": "\nComments: 13 pages, 7 figures, 4 tables, conference transaction presented at Probabilistic Safety Assessment and Management 2022\n",
    "authors": [
      "Edward Chen",
      "Han Bao",
      "Tate Shorthill",
      "Carl Elks",
      "Nam Dinh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.12075"
  },
  {
    "id": "arXiv:2205.12076",
    "title": "Ensemble Multi-Relational Graph Neural Networks",
    "abstract": "It is well established that graph neural networks (GNNs) can be interpreted\nand designed from the perspective of optimization objective. With this clear\noptimization objective, the deduced GNNs architecture has sound theoretical\nfoundation, which is able to flexibly remedy the weakness of GNNs. However,\nthis optimization objective is only proved for GNNs with single-relational\ngraph. Can we infer a new type of GNNs for multi-relational graphs by extending\nthis optimization objective, so as to simultaneously solve the issues in\nprevious multi-relational GNNs, e.g., over-parameterization? In this paper, we\npropose a novel ensemble multi-relational GNNs by designing an ensemble\nmulti-relational (EMR) optimization objective. This EMR optimization objective\nis able to derive an iterative updating rule, which can be formalized as an\nensemble message passing (EnMP) layer with multi-relations. We further analyze\nthe nice properties of EnMP layer, e.g., the relationship with multi-relational\npersonalized PageRank. Finally, a new multi-relational GNNs which well\nalleviate the over-smoothing and over-parameterization issues are proposed.\nExtensive experiments conducted on four benchmark datasets well demonstrate the\neffectiveness of the proposed model.",
    "descriptor": "\nComments: 7 pages, 3 figures, published to IJCAI 2022\n",
    "authors": [
      "Yuling Wang",
      "Hao Xu",
      "Yanhua Yu",
      "Mengdi Zhang",
      "Zhenhao Li",
      "Yuji Yang",
      "Wei Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.12076"
  },
  {
    "id": "arXiv:2205.12078",
    "title": "GraphQ IR: Unifying Semantic Parsing of Graph Query Language with  Intermediate Representation",
    "abstract": "Subject to the semantic gap lying between natural and formal language, neural\nsemantic parsing is typically bottlenecked by the paucity and imbalance of\ndata. In this paper, we propose a unified intermediate representation (IR) for\ngraph query languages, namely GraphQ IR. With the IR's natural-language-like\nrepresentation that bridges the semantic gap and its formally defined syntax\nthat maintains the graph structure, neural semantic parser can more effectively\nconvert user queries into our GraphQ IR, which can be later automatically\ncompiled into different downstream graph query languages. Extensive experiments\nshow that our approach can consistently achieve state-of-the-art performance on\nbenchmarks KQA Pro, Overnight and MetaQA. Evaluations under compositional\ngeneralization and few-shot learning settings also validate the promising\ngeneralization ability of GraphQ IR with at most 11% accuracy improvement.",
    "descriptor": "",
    "authors": [
      "Lunyiu Nie",
      "Shulin Cao",
      "Jiaxin Shi",
      "Qi Tian",
      "Lei Hou",
      "Juanzi Li",
      "Jidong Zhai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.12078"
  },
  {
    "id": "arXiv:2205.12080",
    "title": "Application of Orthogonal Defect Classification for Software Reliability  Analysis",
    "abstract": "The modernization of existing and new nuclear power plants with digital\ninstrumentation and control systems (DI&C) is a recent and highly trending\ntopic. However, there lacks strong consensus on best-estimate reliability\nmethodologies by both the United States (U.S.) Nuclear Regulatory Commission\n(NRC) and the industry. In this work, we develop an approach called\nOrthogonal-defect Classification for Assessing Software Reliability (ORCAS) to\nquantify probabilities of various software failure modes in a DI&C system. The\nmethod utilizes accepted industry methodologies for quality assurance that are\nverified by experimental evidence. In essence, the approach combines a semantic\nfailure classification model with a reliability growth model to predict the\nprobability of failure modes of a software system. A case study was conducted\non a representative I&C platform (ChibiOS) running a smart sensor acquisition\nsoftware developed by Virginia Commonwealth University (VCU). The testing and\nevidence collection guidance in ORCAS was applied, and defects were uncovered\nin the software. Qualitative evidence, such as modified condition decision\ncoverage, was used to gauge the completeness and trustworthiness of the\nassessment while quantitative evidence was used to determine the software\nfailure probabilities. The reliability of the software was then estimated and\ncompared to existing operational data of the sensor device. It is demonstrated\nthat by using ORCAS, a semantic reasoning framework can be developed to justify\nif the software is reliable (or unreliable) while still leveraging the strength\nof the existing methods.",
    "descriptor": "\nComments: 12 pages, 3 figures, 4 tables, conference transaction presented at Probabilistic Safety Assessment and Management 2022\n",
    "authors": [
      "Edward Chen",
      "Han Bao",
      "Tate Shorthill",
      "Carl Elks",
      "Athira Varma Jayakumar",
      "Nam Dinh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.12080"
  },
  {
    "id": "arXiv:2205.12085",
    "title": "Information Flow Guided Synthesis (Full Version)",
    "abstract": "Compositional synthesis relies on the discovery of assumptions, i.e.,\nrestrictions on the behavior of the remainder of the system that allow a\ncomponent to realize its specification. In order to avoid losing valid\nsolutions, these assumptions should be necessary conditions for realizability.\nHowever, because there are typically many different behaviors that realize the\nsame specification, necessary behavioral restrictions often do not exist. In\nthis paper, we introduce a new class of assumptions for compositional\nsynthesis, which we call information flow assumptions. Such assumptions capture\nan essential aspect of distributed computing, because components often need to\nact upon information that is available only in other components. The presence\nof a certain flow of information is therefore often a necessary requirement,\nwhile the actual behavior that establishes the information flow is\nunconstrained. In contrast to behavioral assumptions, which are properties of\nindividual computation traces, information flow assumptions are\nhyperproperties, i.e., properties of sets of traces. We present a method for\nthe automatic derivation of information-flow assumptions from a temporal logic\nspecification of the system. We then provide a technique for the automatic\nsynthesis of component implementations based on information flow assumptions.\nThis provides a new compositional approach to the synthesis of distributed\nsystems. We report on encouraging first experiments with the approach, carried\nout with the BoSyHyper synthesis tool.",
    "descriptor": "\nComments: This is the full version of the corresponding CAV22 paper\n",
    "authors": [
      "Bernd Finkbeiner",
      "Niklas Metzger",
      "Yoram Moses"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.12085"
  },
  {
    "id": "arXiv:2205.12089",
    "title": "Sim-To-Real Transfer of Visual Grounding for Human-Aided Ambiguity  Resolution",
    "abstract": "Service robots should be able to interact naturally with non-expert human\nusers, not only to help them in various tasks but also to receive guidance in\norder to resolve ambiguities that might be present in the instruction. We\nconsider the task of visual grounding, where the agent segments an object from\na crowded scene given a natural language description. Modern holistic\napproaches to visual grounding usually ignore language structure and struggle\nto cover generic domains, therefore relying heavily on large datasets.\nAdditionally, their transfer performance in RGB-D datasets suffers due to high\nvisual discrepancy between the benchmark and the target domains. Modular\napproaches marry learning with domain modeling and exploit the compositional\nnature of language to decouple visual representation from language parsing, but\neither rely on external parsers or are trained in an end-to-end fashion due to\nthe lack of strong supervision. In this work, we seek to tackle these\nlimitations by introducing a fully decoupled modular framework for\ncompositional visual grounding of entities, attributes, and spatial relations.\nWe exploit rich scene graph annotations generated in a synthetic domain and\ntrain each module independently. Our approach is evaluated both in simulation\nand in two real RGB-D scene datasets. Experimental results show that the\ndecoupled nature of our framework allows for easy integration with domain\nadaptation approaches for Sim-To-Real visual recognition, offering a\ndata-efficient, robust, and interpretable solution to visual grounding in\nrobotic applications.",
    "descriptor": "\nComments: Accepted CoLLAs 2022\n",
    "authors": [
      "Georgios Tziafas",
      "Hamidreza Kasaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12089"
  },
  {
    "id": "arXiv:2205.12093",
    "title": "Bias Discovery in Machine Learning Models for Mental Health",
    "abstract": "Fairness and bias are crucial concepts in artificial intelligence, yet they\nare relatively ignored in machine learning applications in clinical psychiatry.\nWe computed fairness metrics and present bias mitigation strategies using a\nmodel trained on clinical mental health data. We collected structured data\nrelated to the admission, diagnosis, and treatment of patients in the\npsychiatry department of the University Medical Center Utrecht. We trained a\nmachine learning model to predict future administrations of benzodiazepines on\nthe basis of past data. We found that gender plays an unexpected role in the\npredictions-this constitutes bias. Using the AI Fairness 360 package, we\nimplemented reweighing and discrimination-aware regularization as bias\nmitigation strategies, and we explored their implications for model\nperformance. This is the first application of bias exploration and mitigation\nin a machine learning model trained on real clinical psychiatry data.",
    "descriptor": "",
    "authors": [
      "Pablo Mosteiro",
      "Jesse Kuiper",
      "Judith Masthoff",
      "Floortje Scheepers",
      "Marco Spruit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.12093"
  },
  {
    "id": "arXiv:2205.12094",
    "title": "Towards Better Privacy-preserving Electronic Voting System",
    "abstract": "This paper presents two approaches of privacy-preserving voting system: Blind\nSignature-based Voting (BSV) and Homorphic Encryption Based Voting (HEV). BSV\nis simple, stable, and scalable, but requires additional anonymous property in\nthe communication with the blockchain. HEV simultaneously protects voting\nprivacy against traffic-analysis attacks, prevents cooperation interruption by\nmalicious voters with a high probability, but the scalability is limited. We\nfurther apply sampling to mitigate the scalability problem in HEV and simulate\nthe performance under different voting group size and number of samples.",
    "descriptor": "",
    "authors": [
      "Zipeng Yan",
      "Zichao Jiang",
      "Yiyuan Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.12094"
  },
  {
    "id": "arXiv:2205.12095",
    "title": "DNNAbacus: Toward Accurate Computational Cost Prediction for Deep Neural  Networks",
    "abstract": "Deep learning is attracting interest across a variety of domains, including\nnatural language processing, speech recognition, and computer vision. However,\nmodel training is time-consuming and requires huge computational resources.\nExisting works on the performance prediction of deep neural networks, which\nmostly focus on the training time prediction of a few models, rely on\nanalytical models and result in high relative errors. %Optimizing task\nscheduling and reducing job failures in data centers are essential to improve\nresource utilization and reduce carbon emissions. This paper investigates the\ncomputational resource demands of 29 classical deep neural networks and builds\naccurate models for predicting computational costs. We first analyze the\nprofiling results of typical networks and demonstrate that the computational\nresource demands of models with different inputs and hyperparameters are not\nobvious and intuitive. We then propose a lightweight prediction approach\nDNNAbacus with a novel network structural matrix for network representation.\nDNNAbacus can accurately predict both memory and time cost for PyTorch and\nTensorFlow models, which is also generalized to different hardware\narchitectures and can have zero-shot capability for unseen networks. Our\nexperimental results show that the mean relative error (MRE) is 0.9% with\nrespect to time and 2.8% with respect to memory for 29 classic models, which is\nmuch lower than the state-of-the-art works.",
    "descriptor": "",
    "authors": [
      "Lu Bai",
      "Weixing Ji",
      "Qinyuan Li",
      "Xilai Yao",
      "Wei Xin",
      "Wanyi Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.12095"
  },
  {
    "id": "arXiv:2205.12098",
    "title": "COVID-19: An exploration of consecutive systemic barriers to  pathogen-related data sharing during a pandemic",
    "abstract": "In 2020, the COVID-19 pandemic resulted in a rapid response from governments\nand researchers worldwide. As of May 2022, over 6 million people died as a\nresult of COVID-19 and over 500 million confirmed cases, with many COVID-19\nsurvivors going on to experience long-term effects weeks, months, or years\nafter their illness. Despite this staggering toll, those who work with\npandemic-relevant data often face significant systemic barriers to accessing,\nsharing or re-using this data. In this paper we report results of a study,\nwhere we interviewed data professionals working with COVID-19-relevant data\ntypes including social media, mobility, viral genome, testing, infection,\nhospital admission, and deaths. These data types are variously used for\npandemic spread modelling, healthcare system strain awareness, and devising\ntherapeutic treatments for COVID-19. Barriers to data access, sharing and\nre-use include the cost of access to data (primarily certain healthcare sources\nand mobility data from mobile phone carriers), human throughput bottlenecks,\nunclear pathways to request access to data, unnecessarily strict access\ncontrols and data re-use policies, unclear data provenance, inability to link\nseparate data sources that could collectively create a more complete picture,\npoor adherence to metadata standards, and a lack of computer-suitable data\nformats.",
    "descriptor": "\nComments: 29 pages including references, no figures. To be submitted to Data and Policy\n",
    "authors": [
      "Yo Yehudi",
      "Lukas Hughes-Noehrer",
      "Carole Goble",
      "Caroline Jay"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.12098"
  },
  {
    "id": "arXiv:2205.12101",
    "title": "Empirical Phase Diagram for Three-layer Neural Networks with Infinite  Width",
    "abstract": "Substantial work indicates that the dynamics of neural networks (NNs) is\nclosely related to their initialization of parameters. Inspired by the phase\ndiagram for two-layer ReLU NNs with infinite width (Luo et al., 2021), we make\na step towards drawing a phase diagram for three-layer ReLU NNs with infinite\nwidth. First, we derive a normalized gradient flow for three-layer ReLU NNs and\nobtain two key independent quantities to distinguish different dynamical\nregimes for common initialization methods. With carefully designed experiments\nand a large computation cost, for both synthetic datasets and real datasets, we\nfind that the dynamics of each layer also could be divided into a linear regime\nand a condensed regime, separated by a critical regime. The criteria is the\nrelative change of input weights (the input weight of a hidden neuron consists\nof the weight from its input layer to the hidden neuron and its bias term) as\nthe width approaches infinity during the training, which tends to $0$,\n$+\\infty$ and $O(1)$, respectively. In addition, we also demonstrate that\ndifferent layers can lie in different dynamical regimes in a training process\nwithin a deep NN. In the condensed regime, we also observe the condensation of\nweights in isolated orientations with low complexity. Through experiments under\nthree-layer condition, our phase diagram suggests a complicated dynamical\nregimes consisting of three possible regimes, together with their mixture, for\ndeep NNs and provides a guidance for studying deep NNs in different\ninitialization regimes, which reveals the possibility of completely different\ndynamics emerging within a deep NN for its different layers.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2007.07497\n",
    "authors": [
      "Hanxu Zhou",
      "Qixuan Zhou",
      "Zhenyuan Jin",
      "Tao Luo",
      "Yaoyu Zhang",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12101"
  },
  {
    "id": "arXiv:2205.12102",
    "title": "KQGC: Knowledge Graph Embedding with Smoothing Effects of Graph  Convolutions for Recommendation",
    "abstract": "Leveraging graphs on recommender systems has gained popularity with the\ndevelopment of graph representation learning (GRL). In particular, knowledge\ngraph embedding (KGE) and graph neural networks (GNNs) are representative GRL\napproaches, which have achieved the state-of-the-art performance on several\nrecommendation tasks. Furthermore, combination of KGE and GNNs (KG-GNNs) has\nbeen explored and found effective in many academic literatures. One of the main\ncharacteristics of GNNs is their ability to retain structural properties among\nneighbors in the resulting dense representation, which is usually coined as\nsmoothing. The smoothing is specially desired in the presence of homophilic\ngraphs, such as the ones we find on recommender systems. In this paper, we\npropose a new model for recommender systems named Knowledge Query-based Graph\nConvolution (KQGC). In contrast to exisiting KG-GNNs, KQGC focuses on the\nsmoothing, and leverages a simple linear graph convolution for smoothing KGE. A\npre-trained KGE is fed into KQGC, and it is smoothed by aggregating neighbor\nknowledge queries, which allow entity-embeddings to be aligned on appropriate\nvector points for smoothing KGE effectively. We apply the proposed KQGC to a\nrecommendation task that aims prospective users for specific products.\nExtensive experiments on a real E-commerce dataset demonstrate the\neffectiveness of KQGC.",
    "descriptor": "\nComments: 9pages, 6 figures\n",
    "authors": [
      "Daisuke Kikuta",
      "Toyotaro Suzumura",
      "Md Mostafizur Rahman",
      "Yu Hirate",
      "Satyen Abrol",
      "Manoj Kondapaka",
      "Takuma Ebisu",
      "Pablo Loyola"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12102"
  },
  {
    "id": "arXiv:2205.12105",
    "title": "HiVLP: Hierarchical Vision-Language Pre-Training for Fast Image-Text  Retrieval",
    "abstract": "In the past few years, the emergence of vision-language pre-training (VLP)\nhas brought cross-modal retrieval to a new era. However, due to the latency and\ncomputation demand, it is commonly challenging to apply VLP in a real-time\nonline retrieval system. To alleviate the defect, this paper proposes a\n\\textbf{Hi}erarchical \\textbf{V}ision-\\textbf{}Language \\textbf{P}re-Training\n(\\textbf{HiVLP}) for fast Image-Text Retrieval (ITR). Specifically, we design a\nnovel hierarchical retrieval objective, which uses the representation of\ndifferent dimensions for coarse-to-fine ITR, i.e., using low-dimensional\nrepresentation for large-scale coarse retrieval and high-dimensional\nrepresentation for small-scale fine retrieval. We evaluate our proposed HiVLP\non two popular image-text retrieval benchmarks, i.e., Flickr30k and COCO.\nExtensive experiments demonstrate that our HiVLP not only has fast inference\nspeed but also can be easily scaled to large-scale ITR scenarios. The detailed\nresults show that HiVLP is $1,427$$\\sim$$120,649\\times$ faster than the\nfusion-based model UNITER and 2$\\sim$5 faster than the fastest embedding-based\nmodel LightingDot in different candidate scenarios. It also achieves about +4.9\nAR on COCO and +3.8 AR on Flickr30K than LightingDot and achieves comparable\nperformance with the state-of-the-art (SOTA) fusion-based model METER.",
    "descriptor": "",
    "authors": [
      "Feilong Chen",
      "Xiuyi Chen",
      "Jiaxin Shi",
      "Duzhen Zhang",
      "Jianlong Chang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12105"
  },
  {
    "id": "arXiv:2205.12109",
    "title": "Federated singular value decomposition for high dimensional data",
    "abstract": "Federated learning (FL) is emerging as a privacy-aware alternative to\nclassical cloud-based machine learning. In FL, the sensitive data remains in\ndata silos and only aggregated parameters are exchanged. Hospitals and research\ninstitutions which are not willing to share their data can join a federated\nstudy without breaching confidentiality. In addition to the extreme sensitivity\nof biomedical data, the high dimensionality poses a challenge in the context of\nfederated genome-wide association studies (GWAS). In this article, we present a\nfederated singular value decomposition (SVD) algorithm, suitable for the\nprivacy-related and computational requirements of GWAS. Notably, the algorithm\nhas a transmission cost independent of the number of samples and is only weakly\ndependent on the number of features, because the singular vectors associated\nwith the samples are never exchanged and the vectors associated with the\nfeatures only for a fixed number of iterations. Although motivated by GWAS, the\nalgorithm is generically applicable for both horizontally and vertically\npartitioned data.",
    "descriptor": "\nComments: 36 pages, 7 figures, 5 tables, submitted to Data Mining and Knowledge Discovery\n",
    "authors": [
      "Anne Hartebrodt",
      "Richard R\u00f6ttger",
      "David B. Blumenthal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.12109"
  },
  {
    "id": "arXiv:2205.12113",
    "title": "The Curious Case of Control",
    "abstract": "Children acquiring English make systematic errors on subject control\nsentences even after they have reached near-adult competence (C. Chomsky,\n1969), possibly due to heuristics based on semantic roles (Maratsos, 1974).\nGiven the advanced fluency of large generative language models, we ask whether\nmodel outputs are consistent with these heuristics, and to what degree\ndifferent models are consistent with each other. We find that models can be\ncategorized by behavior into three separate groups, with broad differences\nbetween the groups. The outputs of models in the largest group are consistent\nwith positional heuristics that succeed on subject control but fail on object\ncontrol. This result is surprising, given that object control is orders of\nmagnitude more frequent in the text data used to train such models. We examine\nto what degree the models are sensitive to prompting with agent-patient\ninformation, finding that raising the salience of agent and patient relations\nresults in significant changes in the outputs of most models. Based on this\nobservation, we leverage an existing dataset of semantic proto-role annotations\n(White, et al. 2020) to explore the connections between control and labeling\nevent participants with properties typically associated with agents and\npatients.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Elias Stengel-Eskin",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12113"
  },
  {
    "id": "arXiv:2205.12114",
    "title": "Register Set Automata (Technical Report)",
    "abstract": "We present register set automata (RsAs), a register automaton model over data\nwords where registers can contain sets of data values and the following\noperations are supported: adding values to registers, clearing registers, and\ntesting (non-)membership. We show that the emptiness problem for RsAs is\ndecidable and complete for the $F_\\omega$ class. Moreover, we show that a large\nclass of register automata can be transformed into deterministic RsAs, which\ncan serve as a basis for (i) fast matching of a family of regular expressions\nwith back-references and (ii) language inclusion algorithm for a sub-class of\nregister automata. RsAs are incomparable in expressive power to other popular\nautomata models over data words, such as alternating register automata and\npebble automata.",
    "descriptor": "",
    "authors": [
      "Sab\u00edna Gul\u010d\u00edkov\u00e1",
      "Ond\u0159ej Leng\u00e1l"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.12114"
  },
  {
    "id": "arXiv:2205.12117",
    "title": "Phased Progressive Learning with Coupling-Regulation-Imbalance Loss for  Imbalanced Classification",
    "abstract": "Deep neural networks generally perform poorly with datasets that suffer from\nquantity imbalance and classification difficulty imbalance between different\nclasses. In order to alleviate the problem of dataset bias or domain shift in\nthe existing two-stage approaches, a phased progressive learning schedule was\nproposed for smoothly transferring the training emphasis from representation\nlearning to upper classifier training. This has greater effectivity on datasets\nthat have more severe imbalances or smaller scales. A\ncoupling-regulation-imbalance loss function was designed, coupling a correction\nterm, Focal loss and LDAM loss. Coupling-regulation-imbalance loss can better\ndeal with quantity imbalance and outliers, while regulating focus-of-attention\nof samples with a variety of classification difficulties. Excellent results\nwere achieved on multiple benchmark datasets using these approaches and they\ncan be easily generalized for other imbalanced classification models. Our code\nwill be open source soon.",
    "descriptor": "",
    "authors": [
      "Liang Xu",
      "Yi Cheng",
      "Fan Zhang",
      "Bingxuan Wu",
      "Pengfei Shao",
      "Peng Liu",
      "Shuwei Shen",
      "Peng Yao",
      "Ronald X.Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12117"
  },
  {
    "id": "arXiv:2205.12124",
    "title": "Memory based neural networks for end-to-end autonomous driving",
    "abstract": "Recent works in end-to-end control for autonomous driving have investigated\nthe use of vision-based exteroceptive perception. Inspired by such results, we\npropose a new end-to-end memory-based neural architecture for robot steering\nand throttle control. We describe and compare this architecture with previous\napproaches using fundamental error metrics (MAE, MSE) and several external\nmetrics based on their performance on simulated test circuits. The presented\nwork demonstrates the advantages of using internal memory for better\ngeneralization capabilities of the model and allowing it to drive in a broader\namount of circuits/situations. We analyze the algorithm in a wide range of\nenvironments and conclude that the proposed pipeline is robust to varying\ncamera configurations. All the present work, including datasets, network models\narchitectures, weights, simulator, and comparison software, is open source and\neasy to replicate and extend.",
    "descriptor": "\nComments: 6 pages, 3 figures, Code available: this https URL and this https URL\n",
    "authors": [
      "Sergio Paniego Blanco",
      "Sakshay Mahna",
      "Utkarsh A. Mishra",
      "JoseMaria Canas"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.12124"
  },
  {
    "id": "arXiv:2205.12125",
    "title": "Inference of a Rumor's Source in the Independent Cascade Model",
    "abstract": "We consider the so-called Independent Cascade Model for rumor spreading or\nepidemic processes popularized by Kempe et al.\\ [2003]. In this model, a small\nsubset of nodes from a network are the source of a rumor. In discrete time\nsteps, each informed node \"infects\" each of its uninformed neighbors with\nprobability $p$. While many facets of this process are studied in the\nliterature, less is known about the inference problem: given a number of\ninfected nodes in a network, can we learn the source of the rumor? In the\ncontext of epidemiology this problem is often referred to as patient zero\nproblem. It belongs to a broader class of problems where the goal is to infer\nparameters of the underlying spreading model, see, e.g., Lokhov [NeurIPS'16] or\nMastakouri et al. [NeurIPS'20].\nIn this work we present a maximum likelihood estimator for the rumor's\nsource, given a snapshot of the process in terms of a set of active nodes $X$\nafter $t$ steps. Our results show that, for cycle-free graphs, the likelihood\nestimator undergoes a non-trivial phase transition as a function $t$. We\nprovide a rigorous analysis for two prominent classes of acyclic network,\nnamely $d$-regular trees and Galton-Watson trees, and verify empirically that\nour heuristics work well in various general networks.",
    "descriptor": "",
    "authors": [
      "Petra Berenbrink",
      "Max Hahn-Klimroth",
      "Dominik Kaaser",
      "Lena Krieg",
      "Malin Rau"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12125"
  },
  {
    "id": "arXiv:2205.12128",
    "title": "Learning to Drive Using Sparse Imitation Reinforcement Learning",
    "abstract": "In this paper, we propose Sparse Imitation Reinforcement Learning (SIRL), a\nhybrid end-to-end control policy that combines the sparse expert driving\nknowledge with reinforcement learning (RL) policy for autonomous driving (AD)\ntask in CARLA simulation environment. The sparse expert is designed based on\nhand-crafted rules which is suboptimal but provides a risk-averse strategy by\nenforcing experience for critical scenarios such as pedestrian and vehicle\navoidance, and traffic light detection. As it has been demonstrated, training a\nRL agent from scratch is data-inefficient and time consuming particularly for\nthe urban driving task, due to the complexity of situations stemming from the\nvast size of state space. Our SIRL strategy provides a solution to solve these\nproblems by fusing the output distribution of the sparse expert policy and the\nRL policy to generate a composite driving policy. With the guidance of the\nsparse expert during the early training stage, SIRL strategy accelerates the\ntraining process and keeps the RL exploration from causing a catastrophe\noutcome, and ensures safe exploration. To some extent, the SIRL agent is\nimitating the driving expert's behavior. At the same time, it continuously\ngains knowledge during training therefore it keeps making improvement beyond\nthe sparse expert, and can surpass both the sparse expert and a traditional RL\nagent. We experimentally validate the efficacy of proposed SIRL approach in a\ncomplex urban scenario within the CARLA simulator. Besides, we compare the SIRL\nagent's performance for risk-averse exploration and high learning efficiency\nwith the traditional RL approach. We additionally demonstrate the SIRL agent's\ngeneralization ability to transfer the driving skill to unseen environment.",
    "descriptor": "",
    "authors": [
      "Yuci Han",
      "Alper Yilmaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12128"
  },
  {
    "id": "arXiv:2205.12129",
    "title": "Full-Reference Calibration-Free Image Quality Assessment",
    "abstract": "One major problem of objective Image Quality Assessment (IQA) methods is the\nlack of linearity of their quality estimates with respect to scores expressed\nby human subjects. For this reason, usually IQA metrics undergo a calibration\nprocess based on subjective quality examples. However, example-based training\nmakes generalization problematic, hampering result comparison across different\napplications and operative conditions. In this paper, new Full Reference (FR)\ntechniques, providing estimates linearly correlated with human scores without\nusing calibration are introduced. To reach this objective, these techniques are\ndeeply rooted on principles and theoretical constraints. Restricting the\ninterest on the IQA of the set of natural images, it is first recognized that\napplication of estimation theory and psycho physical principles to images\ndegraded by Gaussian blur leads to a so-called canonical IQA method, whose\nestimates are not only highly linearly correlated to subjective scores, but are\nalso straightforwardly related to the Viewing Distance (VD). Then, it is shown\nthat mainstream IQA methods can be reconducted to the canonical method applying\na preliminary metric conversion based on a unique specimen image. The\napplication of this scheme is then extended to a significant class of degraded\nimages other than Gaussian blur, including noisy and compressed images. The\nresulting calibration-free FR IQA methods are suited for applications where\ncomparability and interoperability across different imaging systems and on\ndifferent VDs is a major requirement. A comparison of their statistical\nperformance with respect to some conventional calibration prone methods is\nfinally provided.",
    "descriptor": "",
    "authors": [
      "Elio D. Di Claudio",
      "Paolo Giannitrapani",
      "Giovanni Jacovitti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.12129"
  },
  {
    "id": "arXiv:2205.12130",
    "title": "Accelerated simulation of Boltzmann-BGK equations near the diffusive  limit with asymptotic-preserving multilevel Monte Carlo",
    "abstract": "Kinetic equations model the position-velocity distribution of particles\nsubject to transport and collision effects. Under a diffusive scaling, these\ncombined effects converge to a diffusion equation for the position density in\nthe limit of an infinite collision rate. Despite this well-defined limit,\nnumerical simulation is expensive when the collision rate is high but finite,\nas small time steps are then required. In this work, we present an\nasymptotic-preserving multilevel Monte Carlo particle scheme that makes use of\nthis diffusive limit to accelerate computations. In this scheme, we first\nsample the diffusive limiting model to compute a biased initial estimate of a\nQuantity of Interest, using large time steps. We then perform a limited number\nof finer simulations with transport and collision dynamics to correct the bias.\nThe efficiency of the multilevel method depends on being able to perform\ncorrelated simulations of particles on a hierarchy of discretization levels. We\npresent a method for correlating particle trajectories and present both an\nanalysis and numerical experiments. We demonstrate that our approach\nsignificantly reduces the cost of particle simulations in high-collisional\nregimes, compared with prior work, indicating significant potential for\nadopting these schemes in various areas of active research.",
    "descriptor": "\nComments: 26 page paper with 5 figures, 5 tables and 2 algorithms, 45 pages of additional supplementary material, submitted for peer review\n",
    "authors": [
      "Emil L\u00f8vbak",
      "Giovanni Samaey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.12130"
  },
  {
    "id": "arXiv:2205.12133",
    "title": "MealRec: A Meal Recommendation Dataset",
    "abstract": "Bundle recommendation systems aim to recommend a bundle of items for a user\nto consider as a whole. They have become a norm in modern life and have been\napplied to many real-world settings, such as product bundle recommendation,\nmusic playlist recommendation and travel package recommendation. However,\ncompared to studies of bundle recommendation approaches in areas such as online\nshopping and digital music services, research on meal recommendations for\nrestaurants in the hospitality industry has made limited progress, due largely\nto the lack of high-quality benchmark datasets. A publicly available dataset\nspecialising in meal recommendation research for the research community is in\nurgent demand. In this paper, we introduce a meal recommendation dataset\n(MealRec) that aims to facilitate future research. MealRec is constructed from\nthe user review records of Allrecipe.com, covering 1,500+ users, 7,200+ recipes\nand 3,800+ meals. Each recipe is described with rich information, such as\ningredients, instructions, pictures, category and tags, etc; and each meal is\nthree-course, consisting of an appetizer, a main dish and a dessert.\nFurthermore, we propose a category-constrained meal recommendation model that\nis evaluated through comparative experiments with several state-of-the-art\nbundle recommendation methods on MealRec. Experimental results confirm the\nsuperiority of our model and demonstrate that MealRec is a promising testbed\nfor meal recommendation related research.\nThe MealRec dataset and the source code of our proposed model are available\nat https://github.com/WUT-IDEA/MealRec for access and reproducibility.",
    "descriptor": "",
    "authors": [
      "Ming Li",
      "Lin Li",
      "Qing Xie",
      "Jingling Yuan",
      "Xiaohui Tao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.12133"
  },
  {
    "id": "arXiv:2205.12134",
    "title": "Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box  Score-Based Query Attacks",
    "abstract": "The score-based query attacks (SQAs) pose practical threats to deep neural\nnetworks by crafting adversarial perturbations within dozens of queries, only\nusing the model's output scores. Nonetheless, we note that if the loss trend of\nthe outputs is slightly perturbed, SQAs could be easily misled and thereby\nbecome much less effective. Following this idea, we propose a novel defense,\nnamely Adversarial Attack on Attackers (AAA), to confound SQAs towards\nincorrect attack directions by slightly modifying the output logits. In this\nway, (1) SQAs are prevented regardless of the model's worst-case robustness;\n(2) the original model predictions are hardly changed, i.e., no degradation on\nclean accuracy; (3) the calibration of confidence scores can be improved\nsimultaneously. Extensive experiments are provided to verify the above\nadvantages. For example, by setting $\\ell_\\infty=8/255$ on CIFAR-10, our\nproposed AAA helps WideResNet-28 secure $80.59\\%$ accuracy under Square attack\n($2500$ queries), while the best prior defense (i.e., adversarial training)\nonly attains $67.44\\%$. Since AAA attacks SQA's general greedy strategy, such\nadvantages of AAA over 8 defenses can be consistently observed on 8\nCIFAR-10/ImageNet models under 6 SQAs, using different attack targets and\nbounds. Moreover, AAA calibrates better without hurting the accuracy. Our code\nwould be released.",
    "descriptor": "",
    "authors": [
      "Sizhe Chen",
      "Zhehao Huang",
      "Qinghua Tao",
      "Yingwen Wu",
      "Cihang Xie",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.12134"
  },
  {
    "id": "arXiv:2205.12135",
    "title": "Improving the Latent Space of Image Style Transfer",
    "abstract": "Existing neural style transfer researches have studied to match statistical\ninformation between the deep features of content and style images, which were\nextracted by a pre-trained VGG, and achieved significant improvement in\nsynthesizing artistic images. However, in some cases, the feature statistics\nfrom the pre-trained encoder may not be consistent with the visual style we\nperceived. For example, the style distance between images of different styles\nis less than that of the same style. In such an inappropriate latent space, the\nobjective function of the existing methods will be optimized in the wrong\ndirection, resulting in bad stylization results. In addition, the lack of\ncontent details in the features extracted by the pre-trained encoder also leads\nto the content leak problem. In order to solve these issues in the latent space\nused by style transfer, we propose two contrastive training schemes to get a\nrefined encoder that is more suitable for this task. The style contrastive loss\npulls the stylized result closer to the same visual style image and pushes it\naway from the content image. The content contrastive loss enables the encoder\nto retain more available details. We can directly add our training scheme to\nsome existing style transfer methods and significantly improve their results.\nExtensive experimental results demonstrate the effectiveness and superiority of\nour methods.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Yunpeng Bai",
      "Cairong Wang",
      "Chun Yuan",
      "Yanbo Fan",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12135"
  },
  {
    "id": "arXiv:2205.12138",
    "title": "A Longitudinal View at the Adoption of Multipath TCP",
    "abstract": "Multipath TCP (MPTCP) extends traditional TCP to enable simultaneous use of\nmultiple connection endpoints at the source and destination. MPTCP has been\nunder active development since its standardization in 2013, and more recently\nin February 2020, MPTCP was upstreamed to the Linux kernel. In this paper, we\nprovide an in-depth analysis of MPTCPv0 in the Internet and the first analysis\nof MPTCPv1 to date. We probe the entire IPv4 address space and an IPv6 hitlist\nto detect MPTCP-enabled systems operational on port 80 and 443. Our scans\nreveal a steady increase in MPTCPv0-capable IPs, reaching 13k+ on IPv4\n(2$\\times$ increase in one year) and 1k on IPv6 (40$\\times$ increase). MPTCPv1\ndeployment is comparatively low with $\\approx$100 supporting hosts in IPv4 and\nIPv6, most of which belong to Apple. We also discover a substantial share of\nseemingly MPTCP-capable hosts, an artifact of middleboxes mirroring TCP\noptions. We conduct targeted HTTP(S) measurements towards select hosts and find\nthat middleboxes can aggressively impact the perceived quality of applications\nutilizing MPTCP. Finally, we analyze two complementary traffic traces from\nCAIDA and MAWI to shed light on the real-world usage of MPTCP. We find that\nwhile MPTCP usage has increased by a factor of 20 over the past few years, its\ntraffic share is still quite low.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.07351\n",
    "authors": [
      "Tanya Shreedhar",
      "Danesh Zeynali",
      "Oliver Gasser",
      "Nitinder Mohan",
      "J\u00f6rg Ott"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.12138"
  },
  {
    "id": "arXiv:2205.12139",
    "title": "Extending the Network Calculus Algorithmic Toolbox for Ultimately  Pseudo-Periodic Functions: Pseudo-Inverse and Composition",
    "abstract": "Network Calculus (NC) is an algebraic theory that represents traffic and\nservice guarantees as curves in a Cartesian plane, in order to compute\nperformance guarantees for flows traversing a network. NC uses transformation\noperations, e.g., min-plus convolution of two curves, to model how the traffic\nprofile changes with the traversal of network nodes. Such operations, while\nmathematically well-defined, can quickly become unmanageable to compute using\nsimple pen and paper for any non-trivial case, hence the need for algorithmic\ndescriptions. Previous work identified the class of piecewise affine functions\nwhich are ultimately pseudo-periodic (UPP) as being closed under the main NC\noperations and able to be described finitely. Algorithms that embody NC\noperations taking as operands UPP curves have been defined and proved correct,\nthus enabling software implementations of these operations. However, recent\nadvancements in NC make use of operations, namely the lower pseudo-inverse,\nupper pseudo-inverse, and composition, that are well defined from an algebraic\nstandpoint, but whose algorithmic aspects have not been addressed yet. In this\npaper, we introduce algorithms for the above operations when operands are UPP\ncurves, thus extending the available algorithmic toolbox for NC. We discuss the\nalgorithmic properties of these operations, providing formal proofs of\ncorrectness.",
    "descriptor": "\nComments: Preprint submitted to Journal of Discrete Event Dynamic Systems\n",
    "authors": [
      "Raffaele Zippo",
      "Paul Nikolaus",
      "Giovanni Stea"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.12139"
  },
  {
    "id": "arXiv:2205.12141",
    "title": "One-Pixel Shortcut: on the Learning Preference of Deep Neural Networks",
    "abstract": "Unlearnable examples (ULEs) aim to protect data from unauthorized usage for\ntraining DNNs. Error-minimizing noise, which is injected to clean data, is one\nof the most successful methods for preventing DNNs from giving correct\npredictions on incoming new data. Nonetheless, under specific training\nstrategies such as adversarial training, the unlearnability of error-minimizing\nnoise will severely degrade. In addition, the transferability of\nerror-minimizing noise is inherently limited by the mismatch between the\ngenerator model and the targeted learner model. In this paper, we investigate\nthe mechanism of unlearnable examples and propose a novel model-free method,\nnamed \\emph{One-Pixel Shortcut}, which only perturbs a single pixel of each\nimage and makes the dataset unlearnable. Our method needs much less\ncomputational cost and obtains stronger transferability and thus can protect\ndata from a wide range of different models. Based on this, we further introduce\nthe first unlearnable dataset called CIFAR-10-S, which is indistinguishable\nfrom normal CIFAR-10 by human observers and can serve as a benchmark for\ndifferent models or training strategies to evaluate their abilities to extract\ncritical features from the disturbance of non-semantic representations. The\noriginal error-minimizing ULEs will lose efficiency under adversarial training,\nwhere the model can get over 83\\% clean test accuracy. Meanwhile, even if\nadversarial training and strong data augmentation like RandAugment are applied\ntogether, the model trained on CIFAR-10-S cannot get over 50\\% clean test\naccuracy.",
    "descriptor": "",
    "authors": [
      "Shutong Wu",
      "Sizhe Chen",
      "Cihang Xie",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.12141"
  },
  {
    "id": "arXiv:2205.12144",
    "title": "Optimizing Performance of Federated Person Re-identification:  Benchmarking and Analysis",
    "abstract": "The increasingly stringent data privacy regulations limit the development of\nperson re-identification (ReID) because person ReID training requires\ncentralizing an enormous amount of data that contains sensitive personal\ninformation. To address this problem, we introduce federated person\nre-identification (FedReID) -- implementing federated learning, an emerging\ndistributed training method, to person ReID. FedReID preserves data privacy by\naggregating model updates, instead of raw data, from clients to a central\nserver. Furthermore, we optimize the performance of FedReID under statistical\nheterogeneity via benchmark analysis. We first construct a benchmark with an\nenhanced algorithm, two architectures, and nine person ReID datasets with large\nvariances to simulate the real-world statistical heterogeneity. The benchmark\nresults present insights and bottlenecks of FedReID under statistical\nheterogeneity, including challenges in convergence and poor performance on\ndatasets with large volumes. Based on these insights, we propose three\noptimization approaches: (1) We adopt knowledge distillation to facilitate the\nconvergence of FedReID by better transferring knowledge from clients to the\nserver; (2) We introduce client clustering to improve the performance of large\ndatasets by aggregating clients with similar data distributions; (3) We propose\ncosine distance weight to elevate performance by dynamically updating the\nweights for aggregation depending on how well models are trained in clients.\nExtensive experiments demonstrate that these approaches achieve satisfying\nconvergence with much better performance on all datasets. We believe that\nFedReID will shed light on implementing and optimizing federated learning on\nmore computer vision applications.",
    "descriptor": "\nComments: TOMM\n",
    "authors": [
      "Weiming Zhuang",
      "Xin Gan",
      "Yonggang Wen",
      "Shuai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.12144"
  },
  {
    "id": "arXiv:2205.12148",
    "title": "Hyper-X: A Unified Hypernetwork for Multi-Task Multilingual Transfer",
    "abstract": "Massively multilingual models are promising for transfer learning across\ntasks and languages. However, existing methods are unable to fully leverage\ntraining data when it is available in different task-language combinations. To\nexploit such heterogeneous supervision we propose Hyper-X, a unified\nhypernetwork that generates weights for parameter-efficient adapter modules\nconditioned on both tasks and language embeddings. By learning to combine task\nand language-specific knowledge our model enables zero-shot transfer for unseen\nlanguages and task-language combinations. Our experiments on a diverse set of\nlanguages demonstrate that Hyper-X achieves the best gain when a mixture of\nmultiple resources is available while performing on par with strong baselines\nin the standard scenario. Finally, Hyper-X consistently produces strong results\nin few-shot scenarios for new languages and tasks showing the effectiveness of\nour approach beyond zero-shot transfer.",
    "descriptor": "",
    "authors": [
      "Ahmet \u00dcst\u00fcn",
      "Arianna Bisazza",
      "Gosse Bouma",
      "Gertjan van Noord",
      "Sebastian Ruder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12148"
  },
  {
    "id": "arXiv:2205.12149",
    "title": "Concurrent Multiscale Damage Analysis with Adaptive Spatiotemporal  Dimension Reduction",
    "abstract": "Concurrent multiscale damage models are often used to quantify the impacts of\nmanufacturing-induced micro porosity on the damage response of macroscopic\nmetallic components. However, these models are challenged by major numerical\nissues including mesh dependency, convergence difficulty, and low accuracy in\nconcentration regions. We make two contributions that collectively aim to\naddress these difficulties. Firstly, we develop a novel adaptive assembly free\nimpl-exp (AAF-IE) temporal integration scheme for nonlinear constitutive\nmodels. This scheme prevents the convergence issues that arise when implicit\nalgorithms are employed to model softening. Our AAF-IE scheme autonomously\nadjusts step sizes to capture intricate history dependent deformations. It also\ndispenses with reassembling the stiffness matrices amid runtime for\nelasto-plasticity and damage models which, in turn, dramatically reduces memory\nfootprints. Secondly, we propose an adaptive clustering-based domain\ndecomposition strategy to dramatically reduce the spatial degrees of freedom by\nagglomerating close-by finite element nodes into a limited number of clusters.\nOur adaptive clustering scheme has static and dynamic stages that are carried\nout during offline and online analyses, respectively. The adaptive strategy\ndetermines the cluster density based on spatial discontinuity and controls\nadaptive clusters via field estimations. As demonstrated by numerical\nexperiments the proposed adaptive method strikes a good balance between\nefficiency and accuracy for fracture simulations. In particular, we use our\nefficient concurrent multiscale model to quantify the significance of spatially\nvarying microscopic porosity on a macrostructural softening behavior.",
    "descriptor": "",
    "authors": [
      "Shiguang Deng",
      "Diran Apelian",
      "Ramin Bostanabad"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.12149"
  },
  {
    "id": "arXiv:2205.12152",
    "title": "Performance analysis of downlink MIMO-NOMA systems over Weibull fading  channels",
    "abstract": "This work analyzes the performance of a downlink multiple-input\nmultiple-output (MIMO) non-orthogonal multiple access (NOMA) multi-user\ncommunications system. To reduce hardware complexity and exploit antenna\ndiversity, we consider a transmit antenna selection (TAS) scheme and equal-gain\ncombining (EGC) receivers operating over independent and identically\ndistributed (i.i.d.) Weibull fading channels. Performance metrics such as the\noutage probability (OP) and the average bit error rate (ABER) are derived in an\nexact manner. An asymptotic analysis for the OP and for the ABER is also\ncarried out. Moreover, we obtain exact expressions for the probability density\nfunction (PDF) and the cumulative distribution function (CDF) of the end-to-end\nsignal-to-noise ratio (SNR). Interestingly, our results indicate that, except\nfor the first user (nearest user), in a high-SNR regime the ABER achieves a\nperformance floor that depends solely on the user's power allocation\ncoefficient and on the type of modulation, and not on the channel statistics or\nthe amount of transmit and receive antennas. To the best of the authors'\nknowledge, no performance analyses have been reported in the literature for the\nconsidered scenario. The validity of all our expressions is confirmed via\nMonte-Carlo simulations.",
    "descriptor": "\nComments: 6 pages, 5 figures, submited to IEEE GLOBECOM 2022\n",
    "authors": [
      "Lenin Patricio Jim\u00e9nez Jim\u00e9nez",
      "Fernando Dar\u00edo Almeida Garc\u00eda",
      "Maria Cecilia Luna Alvarado",
      "Gustavo Fraidenraich",
      "Michel Daoud Yacoub",
      "Jos\u00e9 C\u00e2ndido Silveira Santos Filho",
      "Eduardo Rodrigues de Lima"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.12152"
  },
  {
    "id": "arXiv:2205.12154",
    "title": "Arbitrarily high-order energy-preserving schemes for the  Zakharov-Rubenchik equation",
    "abstract": "In this paper, we present a high-order energy-preserving scheme for solving\nZakharov-Rubenchik equation. The main idea of the method is first to\nreformulate the original system into an equivalent one by introducing an\nquadratic auxiliary variable, and the symplectic Runge-Kutta method, together\nwith the Fourier pseudo-spectral method is then employed to compute the\nsolution of the reformulated system. The main benefit of the proposed method is\nthat it can conserve the three invariants of the original system and achieves\narbitrarily high-order accurate in time. In addition, an efficient fixed-point\niteration is proposed to solve the resulting nonlinear equations of the\nproposed schemes. Several experiments are provided to validate the theoretical\nresults.",
    "descriptor": "\nComments: 21 pages, 14 figures\n",
    "authors": [
      "Gengen Zhang",
      "Chaolong Jiang",
      "Hao Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.12154"
  },
  {
    "id": "arXiv:2205.12157",
    "title": "Data-Driven Calibration of Multi-Fidelity Multiscale Fracture Models",
    "abstract": "Fracture modeling of metallic alloys with microscopic pores relies on\nmultiscale damage simulations which typically ignore the manufacturing-induced\nspatial variabilities in porosity. This simplification is made because of the\nprohibitive computational expenses of explicitly modeling spatially varying\nmicrostructures in a macroscopic part. To address this challenge and open the\ndoors for fracture-aware design of multiscale materials, we propose a\ndata-driven framework that integrates a mechanistic reduced-order model (ROM)\nwith a calibration scheme based on random processes. Our ROM drastically\naccelerates direct numerical simulations (DNS) by using a stabilized damage\nalgorithm and systematically reducing the degrees of freedom via clustering.\nSince clustering affects local strain fields and hence the fracture response,\nwe calibrate the ROM by constructing a multi-fidelity random process based on\nlatent map Gaussian processes (LMGPs). In particular, we use LMGPs to calibrate\nthe damage parameters of an ROM as a function of microstructure and clustering\n(i.e., fidelity) level such that the ROM faithfully surrogates DNS. We\ndemonstrate the application of our framework in predicting the damage behavior\nof a multiscale metallic component with spatially varying porosity. Our results\nindicate that microstructural porosity can significantly affect the performance\nof macro components and hence must be considered in the design process.",
    "descriptor": "",
    "authors": [
      "Shiguang Deng",
      "Carlos Mora",
      "Diran Apelian",
      "Ramin Bostanabad"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.12157"
  },
  {
    "id": "arXiv:2205.12159",
    "title": "Do it Like the Doctor: How We Can Design a Model That Uses Domain  Knowledge to Diagnose Pneumothorax",
    "abstract": "Computer-aided diagnosis for medical imaging is a well-studied field that\naims to provide real-time decision support systems for physicians. These\nsystems attempt to detect and diagnose a plethora of medical conditions across\na variety of image diagnostic technologies including ultrasound, x-ray, MRI,\nand CT. When designing AI models for these systems, we are often limited by\nlittle training data, and for rare medical conditions, positive examples are\ndifficult to obtain. These issues often cause models to perform poorly, so we\nneeded a way to design an AI model in light of these limitations. Thus, our\napproach was to incorporate expert domain knowledge into the design of an AI\nmodel. We conducted two qualitative think-aloud studies with doctors trained in\nthe interpretation of lung ultrasound diagnosis to extract relevant domain\nknowledge for the condition Pneumothorax. We extracted knowledge of key\nfeatures and procedures used to make a diagnosis. With this knowledge, we\nemployed knowledge engineering concepts to make recommendations for an AI model\ndesign to automatically diagnose Pneumothorax.",
    "descriptor": "\nComments: 15 pages, Presented at AAAI Spring Symposium on Machine Learning and Knowledge Engineering 2022\n",
    "authors": [
      "Glen Smith",
      "Qiao Zhang",
      "Christopher MacLellan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12159"
  },
  {
    "id": "arXiv:2205.12168",
    "title": "Competitive Prediction-Aware Online Algorithms for Energy Generation  Scheduling in Microgrids",
    "abstract": "Online decision-making in the presence of uncertain future information is\nabundant in many problem domains. In the critical problem of energy generation\nscheduling for microgrids, one needs to decide when to switch energy supply\nbetween a cheaper local generator with startup cost and the costlier on-demand\nexternal grid, considering intermittent renewable generation and fluctuating\ndemands. Without knowledge of future input, competitive online algorithms are\nappealing as they provide optimality guarantees against the optimal offline\nsolution. In practice, however, future input, e.g., wind generation, is often\npredictable within a limited time window, and can be exploited to further\nimprove the competitiveness of online algorithms. In this paper, we exploit the\nstructure of information in the prediction window to design a novel\nprediction-aware online algorithm for energy generation scheduling in\nmicrogrids. Our algorithm achieves the best competitive ratio to date for this\nimportant problem, which is at most $3-2/(1+\\mathcal{O}(\\frac{1}{w})),$ where\n$w$ is the prediction window size. We also characterize a non-trivial lower\nbound of the competitive ratio and show that the competitive ratio of our\nalgorithm is only $9\\%$ away from the lower bound, when a few hours of\nprediction is available. Simulation results based on real-world traces\ncorroborate our theoretical analysis and highlight the advantage of our new\nprediction-aware design.",
    "descriptor": "\nComments: This paper has been accepted into ACM e-Energy 2022 and will appear in the conference proceedings\n",
    "authors": [
      "Ali Menati",
      "Sid Chi-Kin Chau",
      "Minghua Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.12168"
  },
  {
    "id": "arXiv:2205.12172",
    "title": "Data driven gradient flows",
    "abstract": "We present a framework enabling variational data assimilation for gradient\nflows in general metric spaces, based on the minimizing movement (or\nJordan-Kinderlehrer-Otto) approximation scheme. After discussing stability\nproperties in the most general case, we specialise to the space of probability\nmeasures endowed with the Wasserstein distance. This setting covers many\nnon-linear partial differential equations (PDEs), such as the porous medium\nequation or general drift-diffusion-aggregation equations, which can be treated\nby our methods independent of their respective properties (such as finite speed\nof propagation or blow-up). We then focus on the numerical implementation of\nour approach using an primal-dual algorithm. The strength of our approach lies\nin the fact that by simply changing the driving functional, a wide range of\nPDEs can be treated without the need to adopt the numerical scheme. We conclude\nby presenting detailed numerical examples.",
    "descriptor": "",
    "authors": [
      "Jan-F. Pietschmann",
      "Matthias Schlottbom"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.12172"
  },
  {
    "id": "arXiv:2205.12173",
    "title": "Byzantine Machine Learning Made Easy by Resilient Averaging of Momentums",
    "abstract": "Byzantine resilience emerged as a prominent topic within the distributed\nmachine learning community. Essentially, the goal is to enhance distributed\noptimization algorithms, such as distributed SGD, in a way that guarantees\nconvergence despite the presence of some misbehaving (a.k.a., {\\em Byzantine})\nworkers. Although a myriad of techniques addressing the problem have been\nproposed, the field arguably rests on fragile foundations. These techniques are\nhard to prove correct and rely on assumptions that are (a) quite unrealistic,\ni.e., often violated in practice, and (b) heterogeneous, i.e., making it\ndifficult to compare approaches.\nWe present \\emph{RESAM (RESilient Averaging of Momentums)}, a unified\nframework that makes it simple to establish optimal Byzantine resilience,\nrelying only on standard machine learning assumptions. Our framework is mainly\ncomposed of two operators: \\emph{resilient averaging} at the server and\n\\emph{distributed momentum} at the workers. We prove a general theorem stating\nthe convergence of distributed SGD under RESAM. Interestingly, demonstrating\nand comparing the convergence of many existing techniques become direct\ncorollaries of our theorem, without resorting to stringent assumptions. We also\npresent an empirical evaluation of the practical relevance of RESAM.",
    "descriptor": "\nComments: Accepted at ICML 2022\n",
    "authors": [
      "Sadegh Farhadkhani",
      "Rachid Guerraoui",
      "Nirupam Gupta",
      "Rafael Pinot",
      "John Stephan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.12173"
  },
  {
    "id": "arXiv:2205.12176",
    "title": "A Dynamic, Interpreted CheckList for Meaning-oriented NLG Metric  Evaluation -- through the Lens of Semantic Similarity Rating",
    "abstract": "Evaluating the quality of generated text is difficult, since traditional NLG\nevaluation metrics, focusing more on surface form than meaning, often fail to\nassign appropriate scores. This is especially problematic for AMR-to-text\nevaluation, given the abstract nature of AMR. Our work aims to support the\ndevelopment and improvement of NLG evaluation metrics that focus on meaning, by\ndeveloping a dynamic CheckList for NLG metrics that is interpreted by being\norganized around meaning-relevant linguistic phenomena. Each test instance\nconsists of a pair of sentences with their AMR graphs and a human-produced\ntextual semantic similarity or relatedness score. Our CheckList facilitates\ncomparative evaluation of metrics and reveals strengths and weaknesses of novel\nand traditional metrics. We demonstrate the usefulness of CheckList by\ndesigning a new metric GraCo that computes lexical cohesion graphs over AMR\nconcepts. Our analysis suggests that GraCo presents an interesting NLG metric\nworth future investigation and that meaning-oriented NLG metrics can profit\nfrom graph-based metric components using AMR.",
    "descriptor": "\nComments: to appear in *SEM 2022\n",
    "authors": [
      "Laura Zeidler",
      "Juri Opitz",
      "Anette Frank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12176"
  },
  {
    "id": "arXiv:2205.12177",
    "title": "Reliability Assessment of Neural Networks in GPUs: A Framework For  Permanent Faults Injections",
    "abstract": "Currently, Deep learning and especially Convolutional Neural Networks (CNNs)\nhave become a fundamental computational approach applied in a wide range of\ndomains, including some safety-critical applications (e.g., automotive,\nrobotics, and healthcare equipment). Therefore, the reliability evaluation of\nthose computational systems is mandatory. The reliability evaluation of CNNs is\nperformed by fault injection campaigns at different levels of abstraction, from\nthe application level down to the hardware level. Many works have focused on\nevaluating the reliability of neural networks in the presence of transient\nfaults. However, the effects of permanent faults have been investigated at the\napplication level, only, e.g., targeting the parameters of the network. This\npaper intends to propose a framework, resorting to a binary instrumentation\ntool to perform fault injection campaigns, targeting different components\ninside the GPU, such as the register files and the functional units. This\nenvironment allows for the first time assessing the reliability of CNNs\ndeployed on a GPU considering the presence of permanent faults.",
    "descriptor": "\nComments: Paper accepted to be presented in The 2022 IEEE International Symposium on Industrial Electronics, Anchorage, Alaska, USA, June 1-3, 2022 to be published in the IEEE xplorer after the presentation in the event\n",
    "authors": [
      "Juan-David Guerrero-Balaguera",
      "Luigi Galasso",
      "Robert Limas Sierra",
      "Matteo Sonza Reorda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.12177"
  },
  {
    "id": "arXiv:2205.12179",
    "title": "Evidential Temporal-aware Graph-based Social Event Detection via  Dempster-Shafer Theory",
    "abstract": "The rising popularity of online social network services has attracted lots of\nresearch on mining social media data, especially on mining social events.\nSocial event detection, due to its wide applications, has now become a trivial\ntask. State-of-the-art approaches exploiting Graph Neural Networks (GNNs)\nusually follow a two-step strategy: 1) constructing text graphs based on\nvarious views (\\textit{co-user}, \\textit{co-entities} and\n\\textit{co-hashtags}); and 2) learning a unified text representation by a\nspecific GNN model. Generally, the results heavily rely on the quality of the\nconstructed graphs and the specific message passing scheme. However, existing\nmethods have deficiencies in both aspects: 1) They fail to recognize the noisy\ninformation induced by unreliable views. 2) Temporal information which works as\na vital indicator of events is neglected in most works. To this end, we propose\nETGNN, a novel Evidential Temporal-aware Graph Neural Network. Specifically, we\nconstruct view-specific graphs whose nodes are the texts and edges are\ndetermined by several types of shared elements respectively. To incorporate\ntemporal information into the message passing scheme, we introduce a novel\ntemporal-aware aggregator which assigns weights to neighbours according to an\nadaptive time exponential decay formula. Considering the view-specific\nuncertainty, the representations of all views are converted into mass functions\nthrough evidential deep learning (EDL) neural networks, and further combined\nvia Dempster-Shafer theory (DST) to make the final detection. Experimental\nresults on three real-world datasets demonstrate the effectiveness of ETGNN in\naccuracy, reliability and robustness in social event detection.",
    "descriptor": "\nComments: Accepted by ICWS2022\n",
    "authors": [
      "Jiaqian Ren",
      "Lei Jiang",
      "Hao Peng",
      "Zhiwei Liu",
      "Jia Wu",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12179"
  },
  {
    "id": "arXiv:2205.12181",
    "title": "Partial-input baselines show that NLI models can ignore context, but  they don't",
    "abstract": "When strong partial-input baselines reveal artifacts in crowdsourced NLI\ndatasets, the performance of full-input models trained on such datasets is\noften dismissed as reliance on spurious correlations. We investigate whether\nstate-of-the-art NLI models are capable of overriding default inferences made\nby a partial-input baseline. We introduce an evaluation set of 600 examples\nconsisting of perturbed premises to examine a RoBERTa model's sensitivity to\nedited contexts. Our results indicate that NLI models are still capable of\nlearning to condition on context--a necessary component of inferential\nreasoning--despite being trained on artifact-ridden datasets.",
    "descriptor": "\nComments: NAACL 2022 (Camera-Ready)\n",
    "authors": [
      "Neha Srikanth",
      "Rachel Rudinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12181"
  },
  {
    "id": "arXiv:2205.12183",
    "title": "StylizedNeRF: Consistent 3D Scene Stylization as Stylized NeRF via 2D-3D  Mutual Learning",
    "abstract": "3D scene stylization aims at generating stylized images of the scene from\narbitrary novel views following a given set of style examples, while ensuring\nconsistency when rendered from different views. Directly applying methods for\nimage or video stylization to 3D scenes cannot achieve such consistency. Thanks\nto recently proposed neural radiance fields (NeRF), we are able to represent a\n3D scene in a consistent way. Consistent 3D scene stylization can be\neffectively achieved by stylizing the corresponding NeRF. However, there is a\nsignificant domain gap between style examples which are 2D images and NeRF\nwhich is an implicit volumetric representation. To address this problem, we\npropose a novel mutual learning framework for 3D scene stylization that\ncombines a 2D image stylization network and NeRF to fuse the stylization\nability of 2D stylization network with the 3D consistency of NeRF. We first\npre-train a standard NeRF of the 3D scene to be stylized and replace its color\nprediction module with a style network to obtain a stylized NeRF.It is followed\nby distilling the prior knowledge of spatial consistency from NeRF to the 2D\nstylization network through an introduced consistency loss. We also introduce a\nmimic loss to supervise the mutual learning of the NeRF style module and\nfine-tune the 2D stylization decoder. In order to further make our model handle\nambiguities of 2D stylization results, we introduce learnable latent codes that\nobey the probability distributions conditioned on the style. They are attached\nto training samples as conditional inputs to better learn the style module in\nour novel stylized NeRF. Experimental results demonstrate that our method is\nsuperior to existing approaches in both visual quality and long-range\nconsistency.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Yi-Hua Huang",
      "Yue He",
      "Yu-Jie Yuan",
      "Yu-Kun Lai",
      "Lin Gao"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12183"
  },
  {
    "id": "arXiv:2205.12184",
    "title": "Distributional Hamilton-Jacobi-Bellman Equations for Continuous-Time  Reinforcement Learning",
    "abstract": "Continuous-time reinforcement learning offers an appealing formalism for\ndescribing control problems in which the passage of time is not naturally\ndivided into discrete increments. Here we consider the problem of predicting\nthe distribution of returns obtained by an agent interacting in a\ncontinuous-time, stochastic environment. Accurate return predictions have\nproven useful for determining optimal policies for risk-sensitive control,\nlearning state representations, multiagent coordination, and more. We begin by\nestablishing the distributional analogue of the Hamilton-Jacobi-Bellman (HJB)\nequation for It\\^o diffusions and the broader class of Feller-Dynkin processes.\nWe then specialize this equation to the setting in which the return\ndistribution is approximated by $N$ uniformly-weighted particles, a common\ndesign choice in distributional algorithms. Our derivation highlights\nadditional terms due to statistical diffusivity which arise from the proper\nhandling of distributions in the continuous-time setting. Based on this, we\npropose a tractable algorithm for approximately solving the distributional HJB\nbased on a JKO scheme, which can be implemented in an online control algorithm.\nWe demonstrate the effectiveness of such an algorithm in a synthetic control\nproblem.",
    "descriptor": "\nComments: Proceedings of the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022\n",
    "authors": [
      "Harley Wiltzer",
      "David Meger",
      "Marc G. Bellemare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.12184"
  },
  {
    "id": "arXiv:2205.12186",
    "title": "Learning for Expressive Task-Related Sentence Representations",
    "abstract": "NLP models learn sentence representations for downstream tasks by tuning a\nmodel which is pre-trained by masked language modeling. However, after tuning,\nthe learned sentence representations may be skewed heavily toward label space\nand thus are not expressive enough to represent whole samples, which should\ncontain task-related information of both sentence inputs and labels. In this\nwork, we learn expressive sentence representations for supervised tasks which\n(1). contain task-related information in the sentence inputs, and (2). enable\ncorrect label predictions. To achieve this goal, we first propose a new\nobjective which explicitly points out the label token space in the input, and\npredicts categories of labels via an added [MASK] token. This objective\nencourages fusing the semantic information of both the label and sentence. Then\nwe develop a neighbor attention module, added on a frozen pre-trained model, to\nbuild connections between label/sentence tokens via their neighbors. The\npropagation can be further guided by the regularization on neighborhood\nrepresentations to encourage expressiveness. Experimental results show that,\ndespite tuning only 5% additional parameters over a frozen pre-trained model,\nour model can achieve classification results comparable to the SOTA while\nmaintaining strong expressiveness as well.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Xueying Bai",
      "Jinghuan Shang",
      "Yifan Sun",
      "Niranjan Balasubramanian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12186"
  },
  {
    "id": "arXiv:2205.12191",
    "title": "Rethinking Evaluation Practices in Visual Question Answering: A Case  Study on Out-of-Distribution Generalization",
    "abstract": "Vision-and-language (V&L) models pretrained on large-scale multimodal data\nhave demonstrated strong performance on various tasks such as image captioning\nand visual question answering (VQA). The quality of such models is commonly\nassessed by measuring their performance on unseen data that typically comes\nfrom the same distribution as the training data. However, we observe that these\nmodels exhibit poor out-of-distribution (OOD) generalization on the task of\nVQA. To better understand the underlying causes of poor generalization, we\ncomprehensively investigate performance of two pretrained V&L models under\ndifferent settings (i.e. classification and open-ended text generation) by\nconducting cross-dataset evaluations. We find that these models tend to learn\nto solve the benchmark, rather than learning the high-level skills required by\nthe VQA task. We also argue that in most cases generative models are less\nsusceptible to shifts in data distribution, while frequently performing better\non our tested benchmarks. Moreover, we find that multimodal pretraining\nimproves OOD performance in most settings. Finally, we revisit assumptions\nunderlying the use of automatic VQA evaluation metrics, and empirically show\nthat their stringent nature repeatedly penalizes models for correct responses.",
    "descriptor": "\nComments: Aishwarya, Ivana, Emanuele and Aida had equal first author contributions. Elnaz and Anita had equal contributions. Aida and Aishwarya had equal senior contributions. Paper has 29 pages, 8 figures, 15 tables\n",
    "authors": [
      "Aishwarya Agrawal",
      "Ivana Kaji\u0107",
      "Emanuele Bugliarello",
      "Elnaz Davoodi",
      "Anita Gergely",
      "Phil Blunsom",
      "Aida Nematzadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12191"
  },
  {
    "id": "arXiv:2205.12193",
    "title": "Capacity Bounds for Optical WDM Channels with Peak Power Constraints",
    "abstract": "We investigate optical WDM transmission from the standpoint of an\ninformation-theoretic interference channel. Achievable rates that outperform\ntreating interference as noise are presented and validated using split-step\nFourier method simulations.",
    "descriptor": "\nComments: To appear in SPPCom (Advanced Photonics Congress) 2022\n",
    "authors": [
      "Viswanathan Ramachandran",
      "Gabriele Liga",
      "Astrid Barreiro",
      "Alex Alvarado"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.12193"
  },
  {
    "id": "arXiv:2205.12194",
    "title": "Merkel Podcast Corpus: A Multimodal Dataset Compiled from 16 Years of  Angela Merkel's Weekly Video Podcasts",
    "abstract": "We introduce the Merkel Podcast Corpus, an audio-visual-text corpus in German\ncollected from 16 years of (almost) weekly Internet podcasts of former German\nchancellor Angela Merkel. To the best of our knowledge, this is the first\nsingle speaker corpus in the German language consisting of audio, visual and\ntext modalities of comparable size and temporal extent. We describe the methods\nused with which we have collected and edited the data which involves\ndownloading the videos, transcripts and other metadata, forced alignment,\nperforming active speaker recognition and face detection to finally curate the\nsingle speaker dataset consisting of utterances spoken by Angela Merkel. The\nproposed pipeline is general and can be used to curate other datasets of\nsimilar nature, such as talk show contents. Through various statistical\nanalyses and applications of the dataset in talking face generation and TTS, we\nshow the utility of the dataset. We argue that it is a valuable contribution to\nthe research community, in particular, due to its realistic and challenging\nmaterial at the boundary between prepared and spontaneous speech.",
    "descriptor": "\nComments: Accepted at LREC 2022\n",
    "authors": [
      "Debjoy Saha",
      "Shravan Nayak",
      "Timo Baumann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.12194"
  },
  {
    "id": "arXiv:2205.12197",
    "title": "Absolute Triangulation Algorithms for Space Exploration",
    "abstract": "Images are an important source of information for spacecraft navigation and\nfor three-dimensional reconstruction of observed space objects. Both of these\napplications take the form of a triangulation problem when the camera has a\nknown attitude and the measurements extracted from the image are line of sight\n(LOS) directions. This work provides a comprehensive review of the history and\ntheoretical foundations of triangulation. A variety of classical triangulation\nalgorithms are reviewed, including a number of suboptimal linear methods (many\nLOS measurements) and the optimal method of Hartley and Sturm (only two LOS\nmeasurements). Two new optimal non-iterative triangulation algorithms are\nintroduced that provide the same solution as Hartley and Sturm. The optimal\ntwo-measurement case can be solved as a quadratic equation in many common\nsituations. The optimal many-measurement case may be solved without iteration\nas a linear system using the new Linear Optimal Sine Triangulation (LOST)\nmethod. The various triangulation algorithms are assessed with a few numerical\nexamples, including planetary terrain relative navigation, angles-only optical\nnavigation at Uranus, 3-D reconstruction of Notre-Dame de Paris, and\nangles-only relative navigation.",
    "descriptor": "",
    "authors": [
      "Sebastien Henry",
      "John A. Christian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12197"
  },
  {
    "id": "arXiv:2205.12201",
    "title": "Forecasting Multilinear Data via Transform-Based Tensor Autoregression",
    "abstract": "In the era of big data, there is an increasing demand for new methods for\nanalyzing and forecasting 2-dimensional data. The current research aims to\naccomplish these goals through the combination of time-series modeling and\nmultilinear algebraic systems. We expand previous autoregressive techniques to\nforecast multilinear data, aptly named the L-Transform Tensor autoregressive\n(L-TAR for short). Tensor decompositions and multilinear tensor products have\nallowed for this approach to be a feasible method of forecasting. We achieve\nstatistical independence between the columns of the observations through\ninvertible discrete linear transforms, enabling a divide and conquer approach.\nWe present an experimental validation of the proposed methods on datasets\ncontaining image collections, video sequences, sea surface temperature\nmeasurements, stock prices, and networks.",
    "descriptor": "",
    "authors": [
      "Jackson Cates",
      "Randy C. Hoover",
      "Kyle Caudle",
      "Cagri Ozdemir",
      "Karen Braman",
      "David Machette"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.12201"
  },
  {
    "id": "arXiv:2205.12203",
    "title": "Autonomous Driving From the Sky: Design and End-to-End Performance  Evaluation",
    "abstract": "For autonomous vehicles to operate without human intervention, information\nsharing from local sensors plays a fundamental role. This can be challenging to\nhandle with bandwidth-constrained communication systems, which calls for the\nadoption of new wireless technologies, like in the mmwave bands, to solve\ncapacity issues. Another approach is to exploit uav, able to provide human\nusers and their cars with an aerial bird's-eye view of the scene otherwise\nunavailable, thus offering broader and more centralized observations. In this\narticle we combine both aspects and design a novel framework in which uav,\noperating at mmwave, broadcast sensory information to the ground as a means to\nextend the (local) perception range of vehicles. To do so, we conduct a\nfull-stack end-to-end simulation campaign with ns-3 considering real UAV data\nfrom the Stanford Drone Dataset, and study four scenarios representing\ndifferent uav-to-ground communication strategies. Our results focus on the\ntrade-off between centralized data processing in the sky vs. distributed local\nprocessing on the ground, with considerations related to the throughput,\nlatency and reliability of the communication process.",
    "descriptor": "",
    "authors": [
      "Matteo Bordin",
      "Marco Giordani",
      "Michele Polese",
      "Tommaso Melodia",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.12203"
  },
  {
    "id": "arXiv:2205.12204",
    "title": "Fairness in Selection Problems with Strategic Candidates",
    "abstract": "To better understand discriminations and the effect of affirmative actions in\nselection problems (e.g., college admission or hiring), a recent line of\nresearch proposed a model based on differential variance. This model assumes\nthat the decision-maker has a noisy estimate of each candidate's quality and\nputs forward the difference in the noise variances between different\ndemographic groups as a key factor to explain discrimination. The literature on\ndifferential variance, however, does not consider the strategic behavior of\ncandidates who can react to the selection procedure to improve their outcome,\nwhich is well-known to happen in many domains.\nIn this paper, we study how the strategic aspect affects fairness in\nselection problems. We propose to model selection problems with strategic\ncandidates as a contest game: A population of rational candidates compete by\nchoosing an effort level to increase their quality. They incur a cost-of-effort\nbut get a (random) quality whose expectation equals the chosen effort. A\nBayesian decision-maker observes a noisy estimate of the quality of each\ncandidate (with differential variance) and selects the fraction $\\alpha$ of\nbest candidates based on their posterior expected quality; each selected\ncandidate receives a reward $S$. We characterize the (unique) equilibrium of\nthis game in the different parameters' regimes, both when the decision-maker is\nunconstrained and when they are constrained to respect the fairness notion of\ndemographic parity. Our results reveal important impacts of the strategic\nbehavior on the discrimination observed at equilibrium and allow us to\nunderstand the effect of imposing demographic parity in this context. In\nparticular, we find that, in many cases, the results contrast with the\nnon-strategic setting.",
    "descriptor": "\nComments: Accepted for publication in the proceedings of the Twenty-Third ACM Conference on Economics and Computation (EC'22)\n",
    "authors": [
      "Vitalii Emelianov",
      "Nicolas Gast",
      "Patrick Loiseau"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.12204"
  },
  {
    "id": "arXiv:2205.12206",
    "title": "PoeLM: A Meter- and Rhyme-Controllable Language Model for Unsupervised  Poetry Generation",
    "abstract": "Formal verse poetry imposes strict constraints on the meter and rhyme scheme\nof poems. Most prior work on generating this type of poetry uses existing poems\nfor supervision, which are difficult to obtain for most languages and poetic\nforms. In this work, we propose an unsupervised approach to generate poems\nfollowing any given meter and rhyme scheme, without requiring any poetic text\nfor training. Our method works by splitting a regular, non-poetic corpus into\nphrases, prepending control codes that describe the length and end rhyme of\neach phrase, and training a transformer language model in the augmented corpus.\nDuring inference, we build control codes for the desired meter and rhyme\nscheme, and condition our language model on them to generate formal verse\npoetry. Experiments in Spanish and Basque show that our approach is able to\ngenerate valid poems, which are often comparable in quality to those written by\nhumans.",
    "descriptor": "",
    "authors": [
      "Aitor Ormazabal",
      "Mikel Artetxe",
      "Manex Agirrezabal",
      "Aitor Soroa",
      "Eneko Agirre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12206"
  },
  {
    "id": "arXiv:2205.12209",
    "title": "EdiT5: Semi-Autoregressive Text-Editing with T5 Warm-Start",
    "abstract": "We present EdiT5 - a novel semi-autoregressive text-editing approach designed\nto combine the strengths of non-autoregressive text-editing and autoregressive\ndecoding. EdiT5 is faster at inference times than conventional\nsequence-to-sequence (seq2seq) models, while being capable of modeling flexible\ninput-output transformations.\nThis is achieved by decomposing the generation process into three sub-tasks:\n(1) tagging to decide on the subset of input tokens to be preserved in the\noutput, (2) re-ordering to define their order in the output text, and (3)\ninsertion to infill the missing tokens that are not present in the input. The\ntagging and re-ordering steps, which are responsible for generating the largest\nportion of the output, are non-autoregressive, while the insertion uses an\nautoregressive decoder.\nDepending on the task, EdiT5 requires significantly fewer autoregressive\nsteps demonstrating speedups of up to 25x when compared to classic seq2seq\nmodels. Quality-wise, EdiT5 is initialized with a pre-trained T5 checkpoint\nyielding comparable performance to T5 in high-resource settings and clearly\noutperforms it on low-resource settings when evaluated on three NLG tasks:\nSentence Fusion, Grammatical Error Correction, and Decontextualization.",
    "descriptor": "",
    "authors": [
      "Jonathan Mallinson",
      "Jakub Adamek",
      "Eric Malmi",
      "Aliaksei Severyn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12209"
  },
  {
    "id": "arXiv:2205.12213",
    "title": "Principled Paraphrase Generation with Parallel Corpora",
    "abstract": "Round-trip Machine Translation (MT) is a popular choice for paraphrase\ngeneration, which leverages readily available parallel corpora for supervision.\nIn this paper, we formalize the implicit similarity function induced by this\napproach, and show that it is susceptible to non-paraphrase pairs sharing a\nsingle ambiguous translation. Based on these insights, we design an alternative\nsimilarity metric that mitigates this issue by requiring the entire translation\ndistribution to match, and implement a relaxation of it through the Information\nBottleneck method. Our approach incorporates an adversarial term into MT\ntraining in order to learn representations that encode as much information\nabout the reference translation as possible, while keeping as little\ninformation about the input as possible. Paraphrases can be generated by\ndecoding back to the source from this representation, without having to\ngenerate pivot translations. In addition to being more principled and efficient\nthan round-trip MT, our approach offers an adjustable parameter to control the\nfidelity-diversity trade-off, and obtains better results in our experiments.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Aitor Ormazabal",
      "Mikel Artetxe",
      "Gorka Labaka",
      "Aitor Soroa",
      "Eneko Agirre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12213"
  },
  {
    "id": "arXiv:2205.12215",
    "title": "DivEMT: Neural Machine Translation Post-Editing Effort Across  Typologically Diverse Languages",
    "abstract": "We introduce DivEMT, the first publicly available post-editing study of\nNeural Machine Translation (NMT) over a typologically diverse set of target\nlanguages. Using a strictly controlled setup, 18 professional translators were\ninstructed to translate or post-edit the same set of English documents into\nArabic, Dutch, Italian, Turkish, Ukrainian, and Vietnamese. During the process,\ntheir edits, keystrokes, editing times, pauses, and perceived effort were\nrecorded, enabling an in-depth, cross-lingual evaluation of NMT quality and its\npost-editing process. Using this new dataset, we assess the impact on\ntranslation productivity of two state-of-the-art NMT systems, namely: Google\nTranslate and the open-source multilingual model mBART50. We find that, while\npost-editing is consistently faster than translation from scratch, the\nmagnitude of its contribution varies largely across systems and languages,\nranging from doubled productivity in Dutch and Italian to marginal gains in\nArabic, Turkish and Ukrainian, for some of the evaluated modalities. Moreover,\nthe observed cross-language variability appears to partly reflect source-target\nrelatedness and type of target morphology, while remaining hard to predict even\nbased on state-of-the-art automatic MT quality metrics. We publicly release the\ncomplete dataset, including all collected behavioural data, to foster new\nresearch on the ability of state-of-the-art NMT systems to generate text in\ntypologically diverse languages.",
    "descriptor": "",
    "authors": [
      "Gabriele Sarti",
      "Arianna Bisazza",
      "Ana Guerberof Arenas",
      "Antonio Toral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12215"
  },
  {
    "id": "arXiv:2205.12216",
    "title": "T-Modules: Translation Modules for Zero-Shot Cross-Modal Machine  Translation",
    "abstract": "We present a new approach to perform zero-shot cross-modal transfer between\nspeech and text for translation tasks. Multilingual speech and text are encoded\nin a joint fixed-size representation space. Then, we compare different\napproaches to decode these multimodal and multilingual fixed-size\nrepresentations, enabling zero-shot translation between languages and\nmodalities. All our models are trained without the need of cross-modal labeled\ntranslation data. Despite a fixed-size representation, we achieve very\ncompetitive results on several text and speech translation tasks. In\nparticular, we significantly improve the state-of-the-art for zero-shot speech\ntranslation on Must-C. Incorporating a speech decoder in our framework, we\nintroduce the first results for zero-shot direct speech-to-speech and\ntext-to-speech translation.",
    "descriptor": "",
    "authors": [
      "Paul-Ambroise Duquenne",
      "Hongyu Gong",
      "Beno\u00eet Sagot",
      "Holger Schwenk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12216"
  },
  {
    "id": "arXiv:2205.12219",
    "title": "Aerial Vision-and-Dialog Navigation",
    "abstract": "The ability to converse with humans and follow commands in natural language\nis crucial for intelligent unmanned aerial vehicles (a.k.a. drones). It can\nrelieve people's burden of holding a controller all the time, allow\nmultitasking, and make drone control more accessible for people with\ndisabilities or with their hands occupied. To this end, we introduce Aerial\nVision-and-Dialog Navigation (AVDN), to navigate a drone via natural language\nconversation. We build a drone simulator with a continuous photorealistic\nenvironment and collect a new AVDN dataset of over 3k recorded navigation\ntrajectories with asynchronous human-human dialogs between commanders and\nfollowers. The commander provides initial navigation instruction and further\nguidance by request, while the follower navigates the drone in the simulator\nand asks questions when needed. During data collection, followers' attention on\nthe drone's visual observation is also recorded. Based on the AVDN dataset, we\nstudy the tasks of aerial navigation from (full) dialog history and propose an\neffective Human Attention Aided (HAA) baseline model, which learns to predict\nboth navigation waypoints and human attention. Dataset and code will be\nreleased.",
    "descriptor": "",
    "authors": [
      "Yue Fan",
      "Winson Chen",
      "Tongzhou Jiang",
      "Chun Zhou",
      "Yi Zhang",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12219"
  },
  {
    "id": "arXiv:2205.12221",
    "title": "Beyond Fact Verification: Comparing and Contrasting Claims on  Contentious Topics",
    "abstract": "As the importance of identifying misinformation is increasing, many\nresearchers focus on verifying textual claims on the web. One of the most\npopular tasks to achieve this is fact verification, which retrieves an evidence\nsentence from a large knowledge source such as Wikipedia to either verify or\nrefute each factual claim. However, while such problem formulation is helpful\nfor detecting false claims and fake news, it is not applicable to catching\nsubtle differences in factually consistent claims which still might implicitly\nbias the readers, especially in contentious topics such as political, gender,\nor racial issues. In this study, we propose ClaimDiff, a novel dataset to\ncompare the nuance between claim pairs in both a discriminative and a\ngenerative manner, with the underlying assumption that one is not necessarily\nmore true than the other. This differs from existing fact verification datasets\nthat verify the target sentence with respect to an absolute truth. We hope this\ntask assists people in making more informed decisions among various sources of\nmedia.",
    "descriptor": "",
    "authors": [
      "Miyoung Ko",
      "Ingyu Seong",
      "Hwaran Lee",
      "Joonsuk Park",
      "Minsuk Chang",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12221"
  },
  {
    "id": "arXiv:2205.12225",
    "title": "Psychotic Relapse Prediction in Schizophrenia Patients using A Mobile  Sensing-based Supervised Deep Learning Model",
    "abstract": "Mobile sensing-based modeling of behavioral changes could predict an oncoming\npsychotic relapse in schizophrenia patients for timely interventions. Deep\nlearning models could complement existing non-deep learning models for relapse\nprediction by modeling latent behavioral features relevant to the prediction.\nHowever, given the inter-individual behavioral differences, model\npersonalization might be required for a predictive model. In this work, we\npropose RelapsePredNet, a Long Short-Term Memory (LSTM) neural network-based\nmodel for relapse prediction. The model is personalized for a particular\npatient by training using data from patients most similar to the given patient.\nSeveral demographics and baseline mental health scores were considered as\npersonalization metrics to define patient similarity. We investigated the\neffect of personalization on training dataset characteristics, learned\nembeddings, and relapse prediction performance. We compared RelapsePredNet with\na deep learning-based anomaly detection model for relapse prediction. Further,\nwe investigated if RelapsePredNet could complement ClusterRFModel (a random\nforest model leveraging clustering and template features proposed in prior\nwork) in a fusion model, by identifying latent behavioral features relevant for\nrelapse prediction. The CrossCheck dataset consisting of continuous mobile\nsensing data obtained from 63 schizophrenia patients, each monitored for up to\na year, was used for our evaluations. The proposed RelapsePredNet outperformed\nthe deep learning-based anomaly detection model for relapse prediction. The F2\nscore for prediction were 0.21 and 0.52 in the full test set and the Relapse\nTest Set (consisting of data from patients who have had relapse only),\nrespectively. These corresponded to a 29.4% and 38.8% improvement compared to\nthe existing deep learning-based model for relapse prediction.",
    "descriptor": "",
    "authors": [
      "Bishal Lamichhane",
      "Joanne Zhou",
      "Akane Sano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.12225"
  },
  {
    "id": "arXiv:2205.12228",
    "title": "When More Data Hurts: A Troubling Quirk in Developing Broad-Coverage  Natural Language Understanding Systems",
    "abstract": "In natural language understanding (NLU) production systems, users' evolving\nneeds necessitate the addition of new features over time, indexed by new\nsymbols added to the meaning representation space. This requires additional\ntraining data and results in ever-growing datasets. We present the first\nsystematic investigation into this incremental symbol learning scenario. Our\nanalyses reveal a troubling quirk in building (broad-coverage) NLU systems: as\nthe training dataset grows, more data is needed to learn new symbols, forming a\nvicious cycle. We show that this trend holds for multiple mainstream models on\ntwo common NLU tasks: intent recognition and semantic parsing. Rejecting class\nimbalance as the sole culprit, we reveal that the trend is closely associated\nwith an effect we call source signal dilution, where strong lexical cues for\nthe new symbol become diluted as the training dataset grows. Selectively\ndropping training examples to prevent dilution often reverses the trend,\nshowing the over-reliance of mainstream neural NLU models on simple lexical\ncues and their lack of contextual understanding.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Elias Stengel-Eskin",
      "Emmanouil Antonios Platanios",
      "Adam Pauls",
      "Sam Thomson",
      "Hao Fang",
      "Benjamin Van Durme",
      "Jason Eisner",
      "Yu Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12228"
  },
  {
    "id": "arXiv:2205.12230",
    "title": "Chunk-based Nearest Neighbor Machine Translation",
    "abstract": "Semi-parametric models, which augment generation with retrieval, have led to\nimpressive results in language modeling and machine translation, due to their\nability to leverage information retrieved from a datastore of examples. One of\nthe most prominent approaches, $k$NN-MT, has an outstanding performance on\ndomain adaptation by retrieving tokens from a domain-specific datastore\n\\citep{khandelwal2020nearest}. However, $k$NN-MT requires retrieval for every\nsingle generated token, leading to a very low decoding speed (around 8 times\nslower than a parametric model). In this paper, we introduce a\n\\textit{chunk-based} $k$NN-MT model which retrieves chunks of tokens from the\ndatastore, instead of a single token. We propose several strategies for\nincorporating the retrieved chunks into the generation process, and for\nselecting the steps at which the model needs to search for neighbors in the\ndatastore. Experiments on machine translation in two settings, static domain\nadaptation and ``on-the-fly'' adaptation, show that the chunk-based $k$NN-MT\nmodel leads to a significant speed-up (up to 4 times) with only a small drop in\ntranslation quality.",
    "descriptor": "",
    "authors": [
      "Pedro Henrique Martins",
      "Zita Marinho",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12230"
  },
  {
    "id": "arXiv:2205.12231",
    "title": "ASSET: Autoregressive Semantic Scene Editing with Transformers at High  Resolutions",
    "abstract": "We present ASSET, a neural architecture for automatically modifying an input\nhigh-resolution image according to a user's edits on its semantic segmentation\nmap. Our architecture is based on a transformer with a novel attention\nmechanism. Our key idea is to sparsify the transformer's attention matrix at\nhigh resolutions, guided by dense attention extracted at lower image\nresolutions. While previous attention mechanisms are computationally too\nexpensive for handling high-resolution images or are overly constrained within\nspecific image regions hampering long-range interactions, our novel attention\nmechanism is both computationally efficient and effective. Our sparsified\nattention mechanism is able to capture long-range interactions and context,\nleading to synthesizing interesting phenomena in scenes, such as reflections of\nlandscapes onto water or flora consistent with the rest of the landscape, that\nwere not possible to generate reliably with previous convnets and transformer\napproaches. We present qualitative and quantitative results, along with user\nstudies, demonstrating the effectiveness of our method.",
    "descriptor": "\nComments: SIGGRAPH 2022 - Journal Track\n",
    "authors": [
      "Difan Liu",
      "Sandesh Shetty",
      "Tobias Hinz",
      "Matthew Fisher",
      "Richard Zhang",
      "Taesung Park",
      "Evangelos Kalogerakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.12231"
  },
  {
    "id": "arXiv:2205.12236",
    "title": "A Two-Stage Mechanism for Demand Response Markets",
    "abstract": "We present a two-stage mechanism for creating markets for demand response.\nDemand response involves system operators using incentives to modulate\nelectricity consumption around peak hours or when faced with an incidental\nsupply shortage. However, system operators typically have imperfect information\nabout their customers' counterfactual consumption, that is, their consumption\nhad the incentive been absent. The standard approach to estimate the reduction\nin a customer's electricity consumption then is to estimate their\ncounterfactual baseline. However, this approach is not robust to estimation\nerrors or strategic exploitation by the consumers and can potentially lead to\noverpayments to customers who do not reduce their consumption and underpayments\nto those who do. In addition, the incentive payments are often designed based\non models of consumer behavior or other ad-hoc rules that are only partially\naccurate at best. The two-stage mechanism proposed in this paper circumvents\nthe aforementioned issues. In the day-ahead market, the participating loads\nsubmit the probability distribution of their next-day consumption. In\nreal-time, if and when called upon for demand response, the loads report the\nrealization of their baseline demand and receive credit for reductions below\ntheir reported baseline. The mechanism guarantees ex post incentive\ncompatibility of truthful reporting of the probability distribution in the\nday-ahead market and truthful reporting of the realized baseline demand in\nreal-time. The mechanism can be viewed as an extension of the celebrated\nVickrey-Clarke-Groves mechanism augmented with a carefully crafted second-stage\npenalty for deviations from the day-ahead bids.",
    "descriptor": "",
    "authors": [
      "Bharadwaj Satchidanandan",
      "Mardavij Roozbehani",
      "Munther A. Dahleh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2205.12236"
  },
  {
    "id": "arXiv:2205.12239",
    "title": "Gacs-Korner Common Information Variational Autoencoder",
    "abstract": "We propose a notion of common information that allows one to quantify and\nseparate the information that is shared between two random variables from the\ninformation that is unique to each. Our notion of common information is a\nvariational relaxation of the G\\'acs-K\\\"orner common information, which we\nrecover as a special case, but is more amenable to optimization and can be\napproximated empirically using samples from the underlying distribution. We\nthen provide a method to partition and quantify the common and unique\ninformation using a simple modification of a traditional variational\nauto-encoder. Empirically, we demonstrate that our formulation allows us to\nlearn semantically meaningful common and unique factors of variation even on\nhigh-dimensional data such as images and videos. Moreover, on datasets where\nground-truth latent factors are known, we show that we can accurately quantify\nthe common information between the random variables. Additionally, we show that\nthe auto-encoder that we learn recovers semantically meaningful disentangled\nfactors of variation, even though we do not explicitly optimize for it.",
    "descriptor": "",
    "authors": [
      "Michael Kleinman",
      "Alessandro Achille",
      "Stefano Soatto",
      "Jonathan Kao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.12239"
  },
  {
    "id": "arXiv:2205.12240",
    "title": "VIRATrustData: A Trust-Annotated Corpus of Human-Chatbot Conversations  About COVID-19 Vaccines",
    "abstract": "Public trust in medical information is crucial for successful application of\npublic health policies such as vaccine uptake. This is especially true when the\ninformation is offered remotely, by chatbots, which have become increasingly\npopular in recent years. Here, we explore the challenging task of human-bot\nturn-level trust classification. We rely on a recently released data of\nobservationally-collected (rather than crowdsourced) dialogs with VIRA chatbot,\na COVID-19 Vaccine Information Resource Assistant. These dialogs are centered\naround questions and concerns about COVID-19 vaccines, where trust is\nparticularly acute. We annotated $3k$ VIRA system-user conversational turns for\nLow Institutional Trust or Low Agent Trust vs. Neutral or High Trust. We\nrelease the labeled dataset, VIRATrustData, the first of its kind to the best\nof our knowledge. We demonstrate how this task is non-trivial and compare\nseveral models that predict the different levels of trust.",
    "descriptor": "",
    "authors": [
      "Roni Friedman",
      "Jo\u00e3o Sedoc",
      "Shai Gretz",
      "Assaf Toledo",
      "Rose Weeks",
      "Naor Bar-Zeev",
      "Yoav Katz",
      "Noam Slonim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12240"
  },
  {
    "id": "arXiv:2205.12244",
    "title": "Unsupervised Learning of Hierarchical Conversation Structure",
    "abstract": "Human conversations can evolve in many different ways, creating challenges\nfor automatic understanding and summarization. Goal-oriented conversations\noften have meaningful sub-dialogue structure, but it can be highly\ndomain-dependent. This work introduces an unsupervised approach to learning\nhierarchical conversation structure, including turn and sub-dialogue segment\nlabels, corresponding roughly to dialogue acts and sub-tasks, respectively. The\ndecoded structure is shown to be useful in enhancing neural models of language\nfor three conversation-level understanding tasks. Further, the learned\nfinite-state sub-dialogue network is made interpretable through automatic\nsummarization. Our code and trained models are available at\n\\url{https://github.com/boru-roylu/THETA}.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Bo-Ru Lu",
      "Yushi Hu",
      "Hao Cheng",
      "Noah A. Smith",
      "Mari Ostendorf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12244"
  },
  {
    "id": "arXiv:2205.12245",
    "title": "Asynchronous Neural Networks for Learning in Graphs",
    "abstract": "This paper studies asynchronous message passing (AMP), a new paradigm for\napplying neural network based learning to graphs. Existing graph neural\nnetworks use the synchronous distributed computing model and aggregate their\nneighbors in each round, which causes problems such as oversmoothing and limits\ntheir expressiveness. On the other hand, AMP is based on the asynchronous\nmodel, where nodes react to messages of their neighbors individually. We prove\nthat (i) AMP can simulate synchronous GNNs and that (ii) AMP can theoretically\ndistinguish any pair of graphs. We experimentally validate AMP's\nexpressiveness. Further, we show that AMP might be better suited to propagate\nmessages over large distances in graphs and performs well on several graph\nclassification benchmarks.",
    "descriptor": "",
    "authors": [
      "Lukas Faber",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12245"
  },
  {
    "id": "arXiv:2205.12247",
    "title": "GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained  Language Models",
    "abstract": "Recent work has shown that Pre-trained Language Models (PLMs) have the\nability to store the relational knowledge from pre-training data in their model\nparameters. However, it is not clear up to what extent do PLMs store\ngeo-diverse commonsense knowledge, the knowledge associated with a culture and\nonly shared locally. For instance, the color of bridal dress is white in\nAmerican weddings whereas it is red in Chinese weddings. Here, we wish to probe\nif PLMs can predict red and white as the color of the bridal dress when queried\nfor American and Chinese weddings, respectively. To this end, we introduce a\nframework for geo-diverse commonsense probing on multilingual PLMs (mPLMs) and\nintroduce a corresponding benchmark Geo-diverse Commonsense Multilingual\nLanguage Model Analysis (GeoMLAMA) dataset. GeoMLAMA contains 3125 prompts in\nEnglish, Chinese, Hindi, Persian, and Swahili, with a wide coverage of concepts\nshared by people from American, Chinese, Indian, Iranian and Kenyan cultures.\nWe benchmark 11 standard mPLMs which include variants of mBERT, XLM, mT5, and\nXGLM on GeoMLAMA. Interestingly, we find that 1) larger mPLM variants do not\nnecessarily store geo-diverse concepts better than its smaller variant; 2)\nmPLMs are not intrinsically biased towards knowledge from the Western countries\n(the United States); 3) the native language of a country may not be the best\nlanguage to probe its knowledge and 4) a language may better probe knowledge\nabout a non-native country than its native country.",
    "descriptor": "",
    "authors": [
      "Da Yin",
      "Hritik Bansal",
      "Masoud Monajatipoor",
      "Liunian Harold Li",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12247"
  },
  {
    "id": "arXiv:2205.12248",
    "title": "RevUp: Revise and Update Information Bottleneck for Event Representation",
    "abstract": "In machine learning, latent variables play a key role to capture the\nunderlying structure of data, but they are often unsupervised. When we have\nside knowledge that already has high-level information about the input data, we\ncan use that source to guide latent variables and capture the available\nbackground information in a process called \"parameter injection.\" In that\nregard, we propose a semi-supervised information bottleneck-based model that\nenables the use of side knowledge, even if it is noisy and imperfect, to direct\nthe learning of discrete latent variables. Fundamentally, we introduce an\nauxiliary continuous latent variable as a way to reparameterize the model's\ndiscrete variables with a light-weight hierarchical structure. With this\nreparameterization, the model's discrete latent variables are learned to\nminimize the mutual information between the observed data and optional side\nknowledge that is not already captured by the new, auxiliary variables. We\ntheoretically show that our approach generalizes an existing method of\nparameter injection, and perform an empirical case study of our approach on\nlanguage-based event modeling. We corroborate our theoretical results with\nstrong empirical experiments, showing that the proposed method outperforms\nprevious proposed approaches on multiple datasets.",
    "descriptor": "",
    "authors": [
      "Mehdi Rezaee",
      "Francis Ferraro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12248"
  },
  {
    "id": "arXiv:2205.12249",
    "title": "Competitive Algorithms for Block-Aware Caching",
    "abstract": "We study the block-aware caching problem, a generalization of classic caching\nin which fetching (or evicting) pages from the same block incurs the same cost\nas fetching (or evicting) just one page from the block. Given a cache of size\n$k$, and a sequence of requests from $n$ pages partitioned into given blocks of\nsize $\\beta\\leq k$, the goal is to minimize the total cost of fetching to (or\nevicting from) cache. We show the following results:\n$\\bullet$ For the eviction cost model, we show an $O(\\log k)$-approximate\noffline algorithm, a $k$-competitive deterministic online algorithm, and an\n$O(\\log^2 k)$-competitive randomized online algorithm.\n$\\bullet$ For the fetching cost model, we show an integrality gap of\n$\\Omega(\\beta)$ for the natural LP relaxation of the problem, and an\n$\\Omega(\\beta + \\log k)$ lower bound for randomized online algorithms. The\nstrategy of ignoring the block-structure and running a classical paging\nalgorithm trivially achieves an $O(\\beta)$ approximation and an $O(\\beta \\log\nk)$ competitive ratio respectively for the offline and online-randomized\nsetting.\n$\\bullet$ For both fetching and eviction models, we show improved bounds for\nthe $(h,k)$-bicriteria version of the problem. In particular, when $k=2h$, we\nmatch the performance of classical caching algorithms up to constant factors.\nOur results establish a separation between the tractability of the fetching\nand eviction cost models, which is interesting since fetching/evictions costs\nare the same up to an additive term for classic caching. Previous work only\nstudied online deterministic algorithms for the fetching cost model when $k >\nh$. Our insight is to relax the block-aware caching problem to a submodular\ncovering LP. The main technical challenge is to maintain a competitive\nfractional solution, and to round it with bounded loss, as the constraints of\nthis LP are revealed online.",
    "descriptor": "",
    "authors": [
      "Christian Coester",
      "Roie Levin",
      "Joseph",
      "Naor",
      "Ohad Talmon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.12249"
  },
  {
    "id": "arXiv:2205.12250",
    "title": "Taming the sign problem of explicitly antisymmetrized neural networks  via rough activation functions",
    "abstract": "Explicit antisymmetrization of a two-layer neural network is a potential\ncandidate for a universal function approximator for generic antisymmetric\nfunctions, which are ubiquitous in quantum physics. However, this strategy\nsuffers from a sign problem, namely, due to near exact cancellation of positive\nand negative contributions, the magnitude of the antisymmetrized function may\nbe significantly smaller than that before antisymmetrization. We prove that the\nseverity of the sign problem is directly related to the smoothness of the\nactivation function. For smooth activation functions (e.g., $\\tanh$), the sign\nproblem of the explicitly antisymmetrized two-layer neural network deteriorates\nsuper-polynomially with respect to the system size. On the other hand, for\nrough activation functions (e.g., ReLU), the deterioration rate of the sign\nproblem can be tamed to be at most polynomial with respect to the system size.\nFinally, the cost of a direct implementation of antisymmetrized two-layer\nneural network scales factorially with respect to the system size. We describe\nan efficient algorithm for approximate evaluation of such a network, of which\nthe cost scales polynomially with respect to the system size and inverse\nprecision.",
    "descriptor": "",
    "authors": [
      "Nilin Abrahamsen",
      "Lin Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.12250"
  },
  {
    "id": "arXiv:2205.12253",
    "title": "Evaluating the Impact of Model Scale for Compositional Generalization in  Semantic Parsing",
    "abstract": "Despite their strong performance on many tasks, pre-trained language models\nhave been shown to struggle on out-of-distribution compositional\ngeneralization. Meanwhile, recent work has shown considerable improvements on\nmany NLP tasks from model scaling. Can scaling up model size also improve\ncompositional generalization in semantic parsing? We evaluate encoder-decoder\nmodels up to 11B parameters and decoder-only models up to 540B parameters, and\ncompare model scaling curves for three different methods for transfer learning:\nfine-tuning all parameters, prompt tuning, and in-context learning. We observe\nthat fine-tuning generally has flat or negative scaling curves on\nout-of-distribution compositional generalization in semantic parsing\nevaluations. In-context learning has positive scaling curves, but is generally\noutperformed by much smaller fine-tuned models. Prompt-tuning can outperform\nfine-tuning, suggesting further potential improvements from scaling as it\nexhibits a more positive scaling curve. Additionally, we identify several error\ntrends that vary with model scale. For example, larger models are generally\nbetter at modeling the syntax of the output space, but are also more prone to\ncertain types of overfitting. Overall, our study highlights limitations of\ncurrent techniques for effectively leveraging model scale for compositional\ngeneralization, while our analysis also suggests promising directions for\nfuture work.",
    "descriptor": "",
    "authors": [
      "Linlu Qiu",
      "Peter Shaw",
      "Panupong Pasupat",
      "Tianze Shi",
      "Jonathan Herzig",
      "Emily Pitler",
      "Fei Sha",
      "Kristina Toutanova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12253"
  },
  {
    "id": "arXiv:2205.12254",
    "title": "Interpretation Quality Score for Measuring the Quality of  interpretability methods",
    "abstract": "Machine learning (ML) models have been applied to a wide range of natural\nlanguage processing (NLP) tasks in recent years. In addition to making accurate\ndecisions, the necessity of understanding how models make their decisions has\nbecome apparent in many applications. To that end, many interpretability\nmethods that help explain the decision processes of ML models have been\ndeveloped. Yet, there currently exists no widely-accepted metric to evaluate\nthe quality of explanations generated by these methods. As a result, there\ncurrently is no standard way of measuring to what degree an interpretability\nmethod achieves an intended objective. Moreover, there is no accepted standard\nof performance by which we can compare and rank the current existing\ninterpretability methods. In this paper, we propose a novel metric for\nquantifying the quality of explanations generated by interpretability methods.\nWe compute the metric on three NLP tasks using six interpretability methods and\npresent our results.",
    "descriptor": "",
    "authors": [
      "Yuansheng Xie",
      "Soroush Vosoughi",
      "Saeed Hassanpour"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12254"
  },
  {
    "id": "arXiv:2205.12255",
    "title": "TALM: Tool Augmented Language Models",
    "abstract": "Transformer based language models (LMs) demonstrate increasing performance\nwith scale across a wide variety of tasks. Scale alone however cannot enable\nmodels to solve tasks that require access to ephemeral, changing, or private\ndata that was unavailable at training time. Many useful tasks may also benefit\nfrom LMs being able to access APIs that read or modify state. In this work, we\npresent Tool Augmented Language Models (TALM), combining a text-only approach\nto augment language models with non-differentiable tools, and an iterative\n\"self-play\" technique to bootstrap performance starting from few tool\ndemonstrations. TALM exhibits strong performance on both a knowledge-heavy QA\ntask and a reasoning oriented math task with simple tools. At a given model\nscale, TALM significantly outperforms non-augmented LMs. We further demonstrate\nthat TALM successfully performs out-of-distribution inferences on both QA and\nmath tasks, where non-augmented LMs fail. Our results suggest that Tool\nAugmented Language Models are a promising direction to enrich LMs'\ncapabilities, with less dependence on scale.",
    "descriptor": "",
    "authors": [
      "Aaron Parisi",
      "Yao Zhao",
      "Noah Fiedel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12255"
  },
  {
    "id": "arXiv:2205.12256",
    "title": "Differentiable Dynamics for Articulated 3d Human Motion Reconstruction",
    "abstract": "We introduce DiffPhy, a differentiable physics-based model for articulated 3d\nhuman motion reconstruction from video. Applications of physics-based reasoning\nin human motion analysis have so far been limited, both by the complexity of\nconstructing adequate physical models of articulated human motion, and by the\nformidable challenges of performing stable and efficient inference with physics\nin the loop. We jointly address such modeling and inference challenges by\nproposing an approach that combines a physically plausible body representation\nwith anatomical joint limits, a differentiable physics simulator, and\noptimization techniques that ensure good performance and robustness to\nsuboptimal local optima. In contrast to several recent methods, our approach\nreadily supports full-body contact including interactions with objects in the\nscene. Most importantly, our model connects end-to-end with images, thus\nsupporting direct gradient-based physics optimization by means of image-based\nloss functions. We validate the model by demonstrating that it can accurately\nreconstruct physically plausible 3d human motion from monocular video, both on\npublic benchmarks with available 3d ground-truth, and on videos from the\ninternet.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Erik G\u00e4rtner",
      "Mykhaylo Andriluka",
      "Erwin Coumans",
      "Cristian Sminchisescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12256"
  },
  {
    "id": "arXiv:2205.12257",
    "title": "OnePose: One-Shot Object Pose Estimation without CAD Models",
    "abstract": "We propose a new method named OnePose for object pose estimation. Unlike\nexisting instance-level or category-level methods, OnePose does not rely on CAD\nmodels and can handle objects in arbitrary categories without instance- or\ncategory-specific network training. OnePose draws the idea from visual\nlocalization and only requires a simple RGB video scan of the object to build a\nsparse SfM model of the object. Then, this model is registered to new query\nimages with a generic feature matching network. To mitigate the slow runtime of\nexisting visual localization methods, we propose a new graph attention network\nthat directly matches 2D interest points in the query image with the 3D points\nin the SfM model, resulting in efficient and robust pose estimation. Combined\nwith a feature-based pose tracker, OnePose is able to stably detect and track\n6D poses of everyday household objects in real-time. We also collected a\nlarge-scale dataset that consists of 450 sequences of 150 objects.",
    "descriptor": "\nComments: Accepted to CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Jiaming Sun",
      "Zihao Wang",
      "Siyu Zhang",
      "Xingyi He",
      "Hongcheng Zhao",
      "Guofeng Zhang",
      "Xiaowei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12257"
  },
  {
    "id": "arXiv:2205.12258",
    "title": "History Compression via Language Models in Reinforcement Learning",
    "abstract": "In a partially observable Markov decision process (POMDP), an agent typically\nuses a representation of the past to approximate the underlying MDP. We propose\nto utilize a frozen Pretrained Language Transformer (PLT) for history\nrepresentation and compression to improve sample efficiency. To avoid training\nof the Transformer, we introduce FrozenHopfield, which automatically associates\nobservations with original token embeddings. To form these associations, a\nmodern Hopfield network stores the original token embeddings, which are\nretrieved by queries that are obtained by a random but fixed projection of\nobservations. Our new method, HELM, enables actor-critic network architectures\nthat contain a pretrained language Transformer for history representation as a\nmemory module. Since a representation of the past need not be learned, HELM is\nmuch more sample efficient than competitors. On Minigrid and Procgen\nenvironments HELM achieves new state-of-the-art results. Our code is available\nat https://github.com/ml-jku/helm.",
    "descriptor": "",
    "authors": [
      "Fabian Paischer",
      "Thomas Adler",
      "Vihang Patil",
      "Angela Bitto-Nemling",
      "Markus Holzleitner",
      "Sebastian Lehner",
      "Hamid Eghbal-zadeh",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.12258"
  },
  {
    "id": "arXiv:2205.12259",
    "title": "Policy Compliance Detection via Expression Tree Inference",
    "abstract": "Policy Compliance Detection (PCD) is a task we encounter when reasoning over\ntexts, e.g. legal frameworks. Previous work to address PCD relies heavily on\nmodeling the task as a special case of Recognizing Textual Entailment.\nEntailment is applicable to the problem of PCD, however viewing the policy as a\nsingle proposition, as opposed to multiple interlinked propositions, yields\npoor performance and lacks explainability. To address this challenge, more\nrecent proposals for PCD have argued for decomposing policies into expression\ntrees consisting of questions connected with logic operators. Question\nanswering is used to obtain answers to these questions with respect to a\nscenario. Finally, the expression tree is evaluated in order to arrive at an\noverall solution. However, this work assumes expression trees are provided by\nexperts, thus limiting its applicability to new policies. In this work, we\nlearn how to infer expression trees automatically from policy texts. We ensure\nthe validity of the inferred trees by introducing constrained decoding using a\nfinite state automaton to ensure the generation of valid trees. We determine\nthrough automatic evaluation that 63% of the expression trees generated by our\nconstrained generation model are logically equivalent to gold trees. Human\nevaluation shows that 88% of trees generated by our model are correct.",
    "descriptor": "",
    "authors": [
      "Neema Kotonya",
      "Andreas Vlachos",
      "Majid Yazdani",
      "Lambert Mathias",
      "Marzieh Saeidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12259"
  },
  {
    "id": "arXiv:2205.11515",
    "title": "Cardiomegaly Detection using Deep Convolutional Neural Network with  U-Net",
    "abstract": "Cardiomegaly is indeed a medical disease in which the heart is enlarged.\nCardiomegaly is better to handle if caught early, so early detection is\ncritical. The chest X-ray, being one of the most often used radiography\nexaminations, has been used to detect and visualize abnormalities of human\norgans for decades. X-ray is also a significant medical diagnosis tool for\ncardiomegaly. Even for domain experts, distinguishing the many types of\ndiseases from the X-ray is a difficult and time-consuming task. Deep learning\nmodels are also most effective when used on huge data sets, yet due to privacy\nconcerns, large datasets are rarely available inside the medical industry. A\nDeep learning-based customized retrained U-Net model for detecting Cardiomegaly\ndisease is presented in this research. In the training phase, chest X-ray\nimages from the \"ChestX-ray8\" open source real dataset are used. To reduce\ncomputing time, this model performs data preprocessing, picture improvement,\nimage compression, and classification before moving on to the training step.\nThe work used a chest x-ray image dataset to simulate and produced a diagnostic\naccuracy of 94%, a sensitivity of 96.2 percent, and a specificity of 92.5\npercent, which beats prior pre-trained model findings for identifying\nCardiomegaly disease.",
    "descriptor": "\nComments: 8 pages, 7 figures, submitted in DLDC 2022\n",
    "authors": [
      "Soham S.Sarpotdar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11515"
  },
  {
    "id": "arXiv:2205.11521",
    "title": "From Hours to Seconds: Towards 100x Faster Quantitative Phase Imaging  via Differentiable Microscopy",
    "abstract": "With applications ranging from metabolomics to histopathology, quantitative\nphase microscopy (QPM) is a powerful label-free imaging modality. Despite\nsignificant advances in fast multiplexed imaging sensors and\ndeep-learning-based inverse solvers, the throughput of QPM is currently limited\nby the speed of electronic hardware. Complementarily, to improve throughput\nfurther, here we propose to acquire images in a compressed form such that more\ninformation can be transferred beyond the existing electronic hardware\nbottleneck. To this end, we present a learnable optical\ncompression-decompression framework that learns content-specific features. The\nproposed differentiable optical-electronic quantitative phase microscopy\n($\\partial \\mu$) first uses learnable optical feature extractors as image\ncompressors. The intensity representation produced by these networks is then\ncaptured by the imaging sensor. Finally, a reconstruction network running on\nelectronic hardware decompresses the QPM images. The proposed system achieves\ncompression of $\\times$ 64 while maintaining the SSIM of $\\sim 0.90$ and PSNR\nof $\\sim 30$ dB. The promising results demonstrated by our experiments open up\na new pathway for achieving end-to-end optimized (i.e., optics and electronic)\ncompact QPM systems that provide unprecedented throughput improvements.",
    "descriptor": "",
    "authors": [
      "Udith Haputhanthri",
      "Kithmini Herath",
      "Ramith Hettiarachchi",
      "Hasindu Kariyawasam",
      "Azeem Ahmad",
      "Balpreet S. Ahluwalia",
      "Chamira U. S. Edussooriya",
      "Dushan N. Wadduwage"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Physics (physics.comp-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2205.11521"
  },
  {
    "id": "arXiv:2205.11535",
    "title": "Identifying (anti-)skyrmions while they form",
    "abstract": "We use a Convolutional Neural Network (CNN) to identify the relevant features\nin the thermodynamical phases of a simulated three-dimensional spin-lattice\nsystem with ferromagnetic and Dzyaloshinskii-Moriya (DM) interactions. Such\nfeatures include (anti-)skyrmions, merons, and helical and ferromagnetic\nstates. We use a multi-label classification framework, which is flexible enough\nto accommodate states that mix different features and phases. We then train the\nCNN to predict the features of the final state from snapshots of intermediate\nstates of the simulation. The trained model allows identifying the different\nphases reliably and early in the formation process. Thus, the CNN can\nsignificantly speed up the phase diagram calculations by predicting the final\nphase before the spin-lattice Monte Carlo sampling has converged. We show the\nprowess of this approach by generating phase diagrams with significantly\nshorter simulation times.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Jack Y. Araz",
      "Juan Carlos Criado",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.11535"
  },
  {
    "id": "arXiv:2205.11568",
    "title": "Quasi Black-Box Variational Inference with Natural Gradients for  Bayesian Learning",
    "abstract": "We develop an optimization algorithm suitable for Bayesian learning in\ncomplex models. Our approach relies on natural gradient updates within a\ngeneral black-box framework for efficient training with limited model-specific\nderivations. It applies within the class of exponential-family variational\nposterior distributions, for which we extensively discuss the Gaussian case for\nwhich the updates have a rather simple form. Our Quasi Black-box Variational\nInference (QBVI) framework is readily applicable to a wide class of Bayesian\ninference problems and is of simple implementation as the updates of the\nvariational posterior do not involve gradients with respect to the model\nparameters, nor the prescription of the Fisher information matrix. We develop\nQBVI under different hypotheses for the posterior covariance matrix, discuss\ndetails about its robust and feasible implementation, and provide a number of\nreal-world applications to demonstrate its effectiveness.",
    "descriptor": "",
    "authors": [
      "Martin Magris",
      "Mostafa Shabani",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2205.11568"
  },
  {
    "id": "arXiv:2205.11578",
    "title": "BolT: Fused Window Transformers for fMRI Time Series Analysis",
    "abstract": "Functional magnetic resonance imaging (fMRI) enables examination of\ninter-regional interactions in the brain via functional connectivity (FC)\nanalyses that measure the synchrony between the temporal activations of\nseparate regions. Given their exceptional sensitivity, deep-learning methods\nhave received growing interest for FC analyses of high-dimensional fMRI data.\nIn this domain, models that operate directly on raw time series as opposed to\npre-computed FC features have the potential benefit of leveraging the full\nscale of information present in fMRI data. However, previous models are based\non architectures suboptimal for temporal integration of representations across\nmultiple time scales. Here, we present BolT, blood-oxygen-level-dependent\ntransformer, for analyzing multi-variate fMRI time series. BolT leverages a\ncascade of transformer encoders equipped with a novel fused window attention\nmechanism. Transformer encoding is performed on temporally-overlapped time\nwindows within the fMRI time series to capture short time-scale\nrepresentations. To integrate information across windows, cross-window\nattention is computed between base tokens in each time window and fringe tokens\nfrom neighboring time windows. To transition from local to global\nrepresentations, the extent of window overlap and thereby number of fringe\ntokens is progressively increased across the cascade. Finally, a novel\ncross-window regularization is enforced to align the high-level representations\nof global $CLS$ features across time windows. Comprehensive experiments on\npublic fMRI datasets clearly illustrate the superior performance of BolT\nagainst state-of-the-art methods. Posthoc explanatory analyses to identify\nlandmark time points and regions that contribute most significantly to model\ndecisions corroborate prominent neuroscientific findings from recent fMRI\nstudies.",
    "descriptor": "\nComments: Submitted for NeurIPS 2022\n",
    "authors": [
      "Hasan Atakan Bedel",
      "Irmak \u015e\u0131vg\u0131n",
      "Onat Dalmaz",
      "Salman Ul Hassan Dar",
      "Tolga \u00c7ukur"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11578"
  },
  {
    "id": "arXiv:2205.11627",
    "title": "Identifying Patient-Specific Root Causes of Disease",
    "abstract": "Complex diseases are caused by a multitude of factors that may differ between\npatients. As a result, hypothesis tests comparing all patients to all healthy\ncontrols can detect many significant variables with inconsequential effect\nsizes. A few highly predictive root causes may nevertheless generate disease\nwithin each patient. In this paper, we define patient-specific root causes as\nvariables subject to exogenous \"shocks\" which go on to perturb an otherwise\nhealthy system and induce disease. In other words, the variables are associated\nwith the exogenous errors of a structural equation model (SEM), and these\nerrors predict a downstream diagnostic label. We quantify predictivity using\nsample-specific Shapley values. This derivation allows us to develop a fast\nalgorithm called Root Causal Inference for identifying patient-specific root\ncauses by extracting the error terms of a linear SEM and then computing the\nShapley value associated with each error. Experiments highlight considerable\nimprovements in accuracy because the method uncovers root causes that may have\nlarge effect sizes at the individual level but clinically insignificant effect\nsizes at the group level. An R implementation is available at\ngithub.com/ericstrobl/RCI.",
    "descriptor": "",
    "authors": [
      "Eric V. Strobl",
      "Thomas A. Lasko"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.11627"
  },
  {
    "id": "arXiv:2205.11640",
    "title": "Generalization Gap in Amortized Inference",
    "abstract": "The ability of likelihood-based probabilistic models to generalize to unseen\ndata is central to many machine learning applications such as lossless\ncompression. In this work, we study the generalizations of a popular class of\nprobabilistic models - the Variational Auto-Encoder (VAE). We point out the two\ngeneralization gaps that can affect the generalization ability of VAEs and show\nthat the over-fitting phenomenon is usually dominated by the amortized\ninference network. Based on this observation we propose a new training\nobjective, inspired by the classic wake-sleep algorithm, to improve the\ngeneralizations properties of amortized inference. We also demonstrate how it\ncan improve generalization performance in the context of image modeling and\nlossless compression.",
    "descriptor": "",
    "authors": [
      "Mingtian Zhang",
      "Peter Hayes",
      "David Barber"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11640"
  },
  {
    "id": "arXiv:2205.11649",
    "title": "A Variational Bayesian Perspective on Massive MIMO Detection",
    "abstract": "Optimal data detection in massive multiple-input multiple-output (MIMO)\nsystems requires prohibitive computational complexity. A variety of detection\nalgorithms have been proposed in the literature, offering different trade-offs\nbetween complexity and detection performance. In this paper, we build upon\nvariational Bayes (VB) inference to design low-complexity multiuser detection\nalgorithms for massive MIMO systems. We first examine the massive MIMO\ndetection problem with perfect channel state information at the receiver (CSIR)\nand show that a conventional VB method with known noise variance yields poor\ndetection performance. To address this limitation, we devise two new VB\nalgorithms that use the noise variance and covariance matrix postulated by the\nalgorithms themselves. We further develop the VB framework for massive MIMO\ndetection with imperfect CSIR. Simulation results show that the proposed VB\nmethods achieve significantly lower detection errors compared with existing\nschemes for a wide range of channel models.",
    "descriptor": "\nComments: 14 pages, submitted for publication\n",
    "authors": [
      "Duy H. N. Nguyen",
      "Italo Atzeni",
      "Antti T\u00f6lli",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.11649"
  },
  {
    "id": "arXiv:2205.11672",
    "title": "Throwing Away Data Improves Worst-Class Error in Imbalanced  Classification",
    "abstract": "Class imbalances pervade classification problems, yet their treatment differs\nin theory and practice. On the one hand, learning theory instructs us that\n\\emph{more data is better}, as sample size relates inversely to the average\ntest error over the entire data distribution. On the other hand, practitioners\nhave long developed a plethora of tricks to improve the performance of learning\nmachines over imbalanced data.\nThese include data reweighting and subsampling, synthetic construction of\nadditional samples from minority classes, ensembling expensive one-versus all\narchitectures, and tweaking classification losses and thresholds. All of these\nare efforts to minimize the worst-class error, which is often associated to the\nminority group in the training data, and finds additional motivation in the\nrobustness, fairness, and out-of-distribution literatures.\nHere we take on the challenge of developing learning theory able to describe\nthe worst-class error of classifiers over linearly-separable data when fitted\neither on (i) the full training set, or (ii) a subset where the majority class\nis subsampled to match in size the minority class. We borrow tools from extreme\nvalue theory to show that, under distributions with certain tail properties,\n\\emph{throwing away most data from the majority class leads to better\nworst-class error}.",
    "descriptor": "",
    "authors": [
      "Martin Arjovsky",
      "Kamalika Chaudhuri",
      "David Lopez-Paz"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11672"
  },
  {
    "id": "arXiv:2205.11676",
    "title": "Learning multi-scale functional representations of proteins from  single-cell microscopy data",
    "abstract": "Protein function is inherently linked to its localization within the cell,\nand fluorescent microscopy data is an indispensable resource for learning\nrepresentations of proteins. Despite major developments in molecular\nrepresentation learning, extracting functional information from biological\nimages remains a non-trivial computational task. Current state-of-the-art\napproaches use autoencoder models to learn high-quality features by\nreconstructing images. However, such methods are prone to capturing noise and\nimaging artifacts. In this work, we revisit deep learning models used for\nclassifying major subcellular localizations, and evaluate representations\nextracted from their final layers. We show that simple convolutional networks\ntrained on localization classification can learn protein representations that\nencapsulate diverse functional information, and significantly outperform\nautoencoder-based models. We also propose a robust evaluation strategy to\nassess quality of protein representations across different scales of biological\nfunction.",
    "descriptor": "\nComments: ICLR MLDD 2022\n",
    "authors": [
      "Anastasia Razdaibiedina",
      "Alexander Brechalov"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2205.11676"
  },
  {
    "id": "arXiv:2205.11677",
    "title": "Semi-Supervised Clustering of Sparse Graphs: Crossing the  Information-Theoretic Threshold",
    "abstract": "The stochastic block model is a canonical random graph model for clustering\nand community detection on network-structured data. Decades of extensive study\non the problem have established many profound results, among which the phase\ntransition at the Kesten-Stigum threshold is particularly interesting both from\na mathematical and an applied standpoint. It states that no estimator based on\nthe network topology can perform substantially better than chance on sparse\ngraphs if the model parameter is below certain threshold. Nevertheless, if we\nslightly extend the horizon to the ubiquitous semi-supervised setting, such a\nfundamental limitation will disappear completely. We prove that with arbitrary\nfraction of the labels revealed, the detection problem is feasible throughout\nthe parameter domain. Moreover, we introduce two efficient algorithms, one\ncombinatorial and one based on optimization, to integrate label information\nwith graph structures. Our work brings a new perspective to stochastic model of\nnetworks and semidefinite program research.",
    "descriptor": "\nComments: 40 pages, 8 figures\n",
    "authors": [
      "Junda Sheng",
      "Thomas Strohmer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2205.11677"
  },
  {
    "id": "arXiv:2205.11735",
    "title": "Soft-SVM Regression For Binary Classification",
    "abstract": "The binomial deviance and the SVM hinge loss functions are two of the most\nwidely used loss functions in machine learning. While there are many\nsimilarities between them, they also have their own strengths when dealing with\ndifferent types of data. In this work, we introduce a new exponential family\nbased on a convex relaxation of the hinge loss function using softness and\nclass-separation parameters. This new family, denoted Soft-SVM, allows us to\nprescribe a generalized linear model that effectively bridges between logistic\nregression and SVM classification. This new model is interpretable and avoids\ndata separability issues, attaining good fitting and predictive performance by\nautomatically adjusting for data label separability via the softness parameter.\nThese results are confirmed empirically through simulations and case studies as\nwe compare regularized logistic, SVM, and Soft-SVM regressions and conclude\nthat the proposed model performs well in terms of both classification and\nprediction errors.",
    "descriptor": "\nComments: 13pages,8figures\n",
    "authors": [
      "Man Huang",
      "Luis Carvalho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11735"
  },
  {
    "id": "arXiv:2205.11751",
    "title": "Video Capsule Endoscopy and Ingestible Electronics: Emerging Trends in  Sensors, Circuits, Materials, Telemetry, Optics, and Rapid Reading Software",
    "abstract": "Real-time monitoring of the gastrointestinal tract in a safe and comfortable\nmanner is valuable for the diagnosis and therapy of many diseases. Within this\nrealm, our review captures the trends in ingestible capsule systems with a\nfocus on hardware and software technologies used for capsule endoscopy and\nremote patient monitoring. We introduce the structure and functions of the\ngastrointestinal tract, and the FDA guidelines for ingestible wireless\ntelemetric medical devices. We survey the advanced features incorporated in\ningestible capsule systems, such as microrobotics, closed-loop feedback,\nphysiological sensing, nerve stimulation, sampling and delivery, panoramic\nimaging with adaptive frame rates, and rapid reading software. Examples of\nexperimental and commercialized capsule systems are presented with descriptions\nof their sensors, devices, and circuits for gastrointestinal health monitoring.\nWe also show the recent research in biocompatible materials and batteries,\nedible electronics, and alternative energy sources for ingestible capsule\nsystems. The results from clinical studies are discussed for the assessment of\nkey performance indicators related to the safety and effectiveness of\ningestible capsule procedures. Lastly, the present challenges and outlook are\nsummarized with respect to the risks to health, clinical testing and approval\nprocess, and technology adoption by patients and clinicians.",
    "descriptor": "",
    "authors": [
      "Dylan Miley",
      "Leonardo Bertoncello Machado",
      "Calvin Condo",
      "Albert E. Jergens",
      "Kyoung-Jin Yoon",
      "Santosh Pandey"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.11751"
  },
  {
    "id": "arXiv:2205.11759",
    "title": "UNet#: A UNet-like Redesigning Skip Connections for Medical Image  Segmentation",
    "abstract": "As an essential prerequisite for developing a medical intelligent assistant\nsystem, medical image segmentation has received extensive research and\nconcentration from the neural network community. A series of UNet-like networks\nwith encoder-decoder architecture has achieved extraordinary success, in which\nUNet2+ and UNet3+ redesign skip connections, respectively proposing dense skip\nconnection and full-scale skip connection and dramatically improving compared\nwith UNet in medical image segmentation. However, UNet2+ lacks sufficient\ninformation explored from the full scale, which will affect the learning of\norgans' location and boundary. Although UNet3+ can obtain the full-scale\naggregation feature map, owing to the small number of neurons in the structure,\nit does not satisfy the segmentation of tiny objects when the number of samples\nis small. This paper proposes a novel network structure combining dense skip\nconnections and full-scale skip connections, named UNet-sharp (UNet\\#) for its\nshape similar to symbol \\#. The proposed UNet\\# can aggregate feature maps of\ndifferent scales in the decoder sub-network and capture fine-grained details\nand coarse-grained semantics from the full scale, which benefits learning the\nexact location and accurately segmenting the boundary of organs or lesions. We\nperform deep supervision for model pruning to speed up testing and make it\npossible for the model to run on mobile devices; furthermore, designing two\nclassification-guided modules to reduce false positives achieves more accurate\nsegmentation results. Various experiments of semantic segmentation and instance\nsegmentation on different modalities (EM, CT, MRI) and dimensions (2D, 3D)\ndatasets, including the nuclei, brain tumor, liver, and lung, demonstrate that\nthe proposed method outperforms state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Ledan Qian",
      "Xiao Zhou",
      "Yi Li",
      "Zhongyi Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11759"
  },
  {
    "id": "arXiv:2205.11794",
    "title": "Accelerating Frank-Wolfe via Averaging Step Directions",
    "abstract": "The Frank-Wolfe method is a popular method in sparse constrained\noptimization, due to its fast per-iteration complexity. However, the tradeoff\nis that its worst case global convergence is comparatively slow, and\nimportantly, is fundamentally slower than its flow rate--that is to say, the\nconvergence rate is throttled by discretization error. In this work, we\nconsider a modified Frank-Wolfe where the step direction is a simple weighted\naverage of past oracle calls. This method requires very little memory and\ncomputational overhead, and provably decays this discretization error term.\nNumerically, we show that this method improves the convergence rate over\nseveral problems, especially after the sparse manifold has been detected.\nTheoretically, we show the method has an overall global convergence rate of\n$O(1/k^p)$, where $0< p < 1$; after manifold identification, this rate speeds\nto $O(1/k^{3p/2})$. We also observe that the method achieves this accelerated\nrate from a very early stage, suggesting a promising mode of acceleration for\nthis family of methods.",
    "descriptor": "",
    "authors": [
      "Zhaoyue Chen",
      "Yifan Sun"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11794"
  },
  {
    "id": "arXiv:2205.11801",
    "title": "SepIt Approaching a Single Channel Speech Separation Bound",
    "abstract": "We present an upper bound for the Single Channel Speech Separation task,\nwhich is based on an assumption regarding the nature of short segments of\nspeech. Using the bound, we are able to show that while the recent methods have\nmade significant progress for a few speakers, there is room for improvement for\nfive and ten speakers. We then introduce a Deep neural network, SepIt, that\niteratively improves the different speakers' estimation. At test time, SpeIt\nhas a varying number of iterations per test sample, based on a mutual\ninformation criterion that arises from our analysis. In an extensive set of\nexperiments, SepIt outperforms the state-of-the-art neural networks for 2, 3,\n5, and 10 speakers.",
    "descriptor": "",
    "authors": [
      "Shahar Lutati",
      "Eliya Nachmani",
      "Lior Wolf"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.11801"
  },
  {
    "id": "arXiv:2205.11890",
    "title": "A Quadrature Rule combining Control Variates and Adaptive Importance  Sampling",
    "abstract": "Driven by several successful applications such as in stochastic gradient\ndescent or in Bayesian computation, control variates have become a major tool\nfor Monte Carlo integration. However, standard methods do not allow the\ndistribution of the particles to evolve during the algorithm, as is the case in\nsequential simulation methods. Within the standard adaptive importance sampling\nframework, a simple weighted least squares approach is proposed to improve the\nprocedure with control variates. The procedure takes the form of a quadrature\nrule with adapted quadrature weights to reflect the information brought in by\nthe control variates. The quadrature points and weights do not depend on the\nintegrand, a computational advantage in case of multiple integrands. Moreover,\nthe target density needs to be known only up to a multiplicative constant. Our\nmain result is a non-asymptotic bound on the probabilistic error of the\nprocedure. The bound proves that for improving the estimate's accuracy, the\nbenefits from adaptive importance sampling and control variates can be\ncombined. The good behavior of the method is illustrated empirically on\nsynthetic examples and real-world data for Bayesian linear regression.",
    "descriptor": "",
    "authors": [
      "R\u00e9mi Leluc",
      "Fran\u00e7ois Portier",
      "Johan Segers",
      "Aigerim Zhuman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.11890"
  },
  {
    "id": "arXiv:2205.11900",
    "title": "Flying-Qubit Control via a Three-level Atom with Tunable Waveguide  Couplings",
    "abstract": "The control of flying qubits is at the core of quantum networks. As often\ncarried by single-photon fields, the flying-qubit control involves not only\ntheir logical states but also their shapes. In this paper, we explore a variety\nof flying-qubit control problems using a three-level atom with time-varying\ntunable couplings to two input-output channels. It is shown that one can tune\nthe couplings of a $\\Lambda$-type atom to distribute a single photon into the\ntwo channels with arbitrary shapes, or use a $V$-type atom to catch an\narbitrary-shape distributed single photon. The $\\Lambda$-type atom can also be\ndesigned to transfer a flying qubit from one channel to the other, with both\nthe central frequency and the photon shape being converted. With a $\\Xi$-type\natom, one can use the tunable coupling to shape a pair of correlated photons\nvia cascaded emission. In all cases, analytical formulas are derived for the\ncoupling functions to fulfil these control tasks, and their physical\nlimitations are discussed as well. These results provide useful control\nprotocols for high-fidelity quantum information transmission over complex\nquantum networks.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Wenlong Li",
      "Xue Dong",
      "Guofeng Zhang",
      "Re-Bing Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.11900"
  },
  {
    "id": "arXiv:2205.11923",
    "title": "Quantum Internet: from Medium Access Control to Entanglement Access  Control",
    "abstract": "Multipartite entanglement plays a crucial role for the design of the Quantum\nInternet, due to its potentiality of significantly increasing the network\nperformance. In this paper, we design an entanglement access control protocol\nfor multipartite state, which exhibits several attractive features.\nSpecifically, the designed protocol is able to jointly extract in a distributed\nway an EPR pair from the original multipartite entangled state shared by the\nset of network nodes, and to univocally determines the identities of the\ntransmitter node and the receiver node in charge of using the extracted EPR\npair. Furthermore, the protocol avoids to delegate the signaling arising with\nentanglement access control to the classical network, with the exception of the\nunavoidable classical communications needed for EPR extraction and qubit\nteleportation. Finally, the protocol supports the anonymity of the entanglement\naccessing nodes.",
    "descriptor": "",
    "authors": [
      "Jessica Illiano",
      "Michele Viscardi",
      "Seid Koudia",
      "Marcello Caleffi",
      "Angela Sara Cacciapuoti"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.11923"
  },
  {
    "id": "arXiv:2205.11952",
    "title": "3D helical CT reconstruction with memory efficient invertible Learned  Primal-Dual method",
    "abstract": "Helical acquisition geometry is the most common geometry used in computed\ntomography (CT) scanners for medical imaging. We adapt the invertible Learned\nPrimal-Dual (iLPD) deep neural network architecture so that it can be applied\nto helical 3D CT reconstruction. We achieve this by splitting the geometry and\nthe data in parts that fit the memory and by splitting images into\ncorresponding sub-volumes. The architecture can be applied to images different\nin size along the rotation axis. We perform the experiments on tomographic data\nsimulated from realistic helical geometries.",
    "descriptor": "",
    "authors": [
      "Buda Baji\u0107",
      "Ozan \u00d6ktem",
      "Jevgenija Rudzusika"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11952"
  },
  {
    "id": "arXiv:2205.11956",
    "title": "Bandwidth Selection for Gaussian Kernel Ridge Regression via Jacobian  Control",
    "abstract": "Most machine learning methods depend on the tuning of hyper-parameters. For\nkernel ridge regression (KRR) with the Gaussian kernel, the hyper-parameter is\nthe bandwidth. The bandwidth specifies the length-scale of the kernel and has\nto be carefully selected in order to obtain a model with good generalization.\nThe default method for bandwidth selection is cross-validation, which often\nyields good results, albeit at high computational costs. Furthermore, the\nestimates provided by cross-validation tend to have very high variance,\nespecially when training data are scarce. Inspired by Jacobian regularization,\nwe formulate how the derivatives of the functions inferred by KRR with the\nGaussian kernel depend on the kernel bandwidth. We then use this expression to\npropose a closed-form, computationally feather-light, bandwidth selection\nmethod based on controlling the Jacobian. In addition, the Jacobian expression\nilluminates how the bandwidth selection is a trade-off between the smoothness\nof the inferred function, and the conditioning of the training data kernel\nmatrix. We show on real and synthetic data that compared to cross-validation,\nour method is considerably more stable in terms of bandwidth selection, and,\nfor small data sets, provides better predictions.",
    "descriptor": "",
    "authors": [
      "Oskar Allerbo",
      "Rebecka J\u00f6rnsten"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.11956"
  },
  {
    "id": "arXiv:2205.11967",
    "title": "Generative Models for Reproducible Coronary Calcium Scoring",
    "abstract": "Purpose: Coronary artery calcium (CAC) score, i.e. the amount of CAC\nquantified in CT, is a strong and independent predictor of coronary heart\ndisease (CHD) events. However, CAC scoring suffers from limited interscan\nreproducibility, which is mainly due to the clinical definition requiring\napplication of a fixed intensity level threshold for segmentation of\ncalcifications. This limitation is especially pronounced in\nnon-ECG-synchronized CT where lesions are more impacted by cardiac motion and\npartial volume effects. Therefore, we propose a CAC quantification method that\ndoes not require a threshold for segmentation of CAC. Approach: Our method\nutilizes a generative adversarial network where a CT with CAC is decomposed\ninto an image without CAC and an image showing only CAC. The method, using a\nCycleGAN, was trained using 626 low-dose chest CTs and 514 radiotherapy\ntreatment planning CTs. Interscan reproducibility was compared to clinical\ncalcium scoring in radiotherapy treatment planning CTs of 1,662 patients, each\nhaving two scans. Results: A lower relative interscan difference in CAC mass\nwas achieved by the proposed method: 47% compared to 89% manual clinical\ncalcium scoring. The intraclass correlation coefficient of Agatston scores was\n0.96 for the proposed method compared to 0.91 for automatic clinical calcium\nscoring. Conclusions: The increased interscan reproducibility achieved by our\nmethod may lead to increased reliability of CHD risk categorization and\nimproved accuracy of CHD event prediction.",
    "descriptor": "\nComments: In press\n",
    "authors": [
      "Sanne G.M. van Velzen",
      "Bob D. de Vos",
      "Julia M.H. Noothout",
      "Helena M. Verkooijen",
      "Max A. Viergever",
      "Ivana I\u0161gum"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11967"
  },
  {
    "id": "arXiv:2205.11977",
    "title": "Parameter estimation and system identification for continuously-observed  quantum systems",
    "abstract": "This paper gives an overview of parameter estimation and system\nidentification for quantum input-output systems by continuous observation of\nthe output field. We present recent results on the quantum Fisher information\nof the output with respect to unknown dynamical parameters. We discuss the\nstructure of continuous-time measurements as solutions of the quantum Zakai\nequation, and their relationship to parameter estimation methods. Proceeding\nbeyond parameter estimation, the paper also gives an overview of the emerging\ntopic of quantum system identification for black-box modeling of quantum\nsystems by continuous observation of a traveling wave probe, for the case of\nergodic quantum input-output systems and linear quantum systems. Empirical\nmethods for such black-box modeling are also discussed.",
    "descriptor": "\nComments: 25 pages, to appear in Annual Reviews in Control\n",
    "authors": [
      "Hendra I. Nurdin",
      "Madalin Gu\u0163\u01ce"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.11977"
  },
  {
    "id": "arXiv:2205.11979",
    "title": "Theoretical Analysis of Primal-Dual Algorithm for Non-Convex Stochastic  Decentralized Optimization",
    "abstract": "In recent years, decentralized learning has emerged as a powerful tool not\nonly for large-scale machine learning, but also for preserving privacy. One of\nthe key challenges in decentralized learning is that the data distribution held\nby each node is statistically heterogeneous. To address this challenge, the\nprimal-dual algorithm called the Edge-Consensus Learning (ECL) was proposed and\nwas experimentally shown to be robust to the heterogeneity of data\ndistributions. However, the convergence rate of the ECL is provided only when\nthe objective function is convex, and has not been shown in a standard machine\nlearning setting where the objective function is non-convex. Furthermore, the\nintuitive reason why the ECL is robust to the heterogeneity of data\ndistributions has not been investigated. In this work, we first investigate the\nrelationship between the ECL and Gossip algorithm and show that the update\nformulas of the ECL can be regarded as correcting the local stochastic gradient\nin the Gossip algorithm. Then, we propose the Generalized ECL (G-ECL), which\ncontains the ECL as a special case, and provide the convergence rates of the\nG-ECL in both (strongly) convex and non-convex settings, which do not depend on\nthe heterogeneity of data distributions. Through synthetic experiments, we\ndemonstrate that the numerical results of both the G-ECL and ECL coincide with\nthe convergence rate of the G-ECL.",
    "descriptor": "",
    "authors": [
      "Yuki Takezawa",
      "Kenta Niwa",
      "Makoto Yamada"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11979"
  },
  {
    "id": "arXiv:2205.11989",
    "title": "Realization Theory Of Recurrent Neural ODEs Using Polynomial System  Embeddings",
    "abstract": "In this paper we show that neural ODE analogs of recurrent (ODE-RNN) and Long\nShort-Term Memory (ODE-LSTM) networks can be algorithmically embeddeded into\nthe class of polynomial systems. This embedding preserves input-output behavior\nand can suitably be extended to other neural DE architectures. We then use\nrealization theory of polynomial systems to provide necessary conditions for an\ninput-output map to be realizable by an ODE-LSTM and sufficient conditions for\nminimality of such systems. These results represent the first steps towards\nrealization theory of recurrent neural ODE architectures, which is is expected\nbe useful for model reduction and learning algorithm analysis of recurrent\nneural ODEs.",
    "descriptor": "\nComments: 10 pages. Comments are welcome!\n",
    "authors": [
      "Martin Gonzalez",
      "Thibault Defourneau",
      "Hatem Hajri",
      "Mihaly Petreczky"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11989"
  },
  {
    "id": "arXiv:2205.12004",
    "title": "Quantum Kerr Learning",
    "abstract": "Quantum machine learning is a rapidly evolving area that could facilitate\nimportant applications for quantum computing and significantly impact data\nscience. In our work, we argue that a single Kerr mode might provide some extra\nquantum enhancements when using quantum kernel methods based on various reasons\nfrom complexity theory and physics. Furthermore, we establish an experimental\nprotocol, which we call \\emph{quantum Kerr learning} based on circuit QED. A\ndetailed study using the kernel method, neural tangent kernel theory,\nfirst-order perturbation theory of the Kerr non-linearity, and non-perturbative\nnumerical simulations, shows quantum enhancements could happen in terms of the\nconvergence time and the generalization error, while explicit protocols are\nalso constructed for higher-dimensional input data.",
    "descriptor": "\nComments: 19 pages, many figures\n",
    "authors": [
      "Junyu Liu",
      "Changchun Zhong",
      "Matthew Otten",
      "Cristian L. Cortes",
      "Chaoyang Ti",
      "Stephen K Gray",
      "Xu Han"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.12004"
  },
  {
    "id": "arXiv:2205.12006",
    "title": "Neur2SP: Neural Two-Stage Stochastic Programming",
    "abstract": "Stochastic programming is a powerful modeling framework for decision-making\nunder uncertainty. In this work, we tackle two-stage stochastic programs\n(2SPs), the most widely applied and studied class of stochastic programming\nmodels. Solving 2SPs exactly requires evaluation of an expected value function\nthat is computationally intractable. Additionally, having a mixed-integer\nlinear program (MIP) or a nonlinear program (NLP) in the second stage further\naggravates the problem difficulty. In such cases, solving them can be\nprohibitively expensive even if specialized algorithms that exploit problem\nstructure are employed. Finding high-quality (first-stage) solutions -- without\nleveraging problem structure -- can be crucial in such settings. We develop\nNeur2SP, a new method that approximates the expected value function via a\nneural network to obtain a surrogate model that can be solved more efficiently\nthan the traditional extensive formulation approach. Moreover, Neur2SP makes no\nassumptions about the problem structure, in particular about the second-stage\nproblem, and can be implemented using an off-the-shelf solver and open-source\nlibraries. Our extensive computational experiments on benchmark 2SP datasets\nfrom four problem classes with different structures (containing MIP and NLP\nsecond-stage problems) show the efficiency (time) and efficacy (solution\nquality) of Neur2SP. Specifically, the proposed method takes less than 1.66\nseconds across all problems, achieving high-quality solutions even as the\nnumber of scenarios increases, an ideal property that is difficult to have for\ntraditional 2SP solution techniques. Namely, the most generic baseline method\ntypically requires minutes to hours to find solutions of comparable quality.",
    "descriptor": "",
    "authors": [
      "Justin Dumouchelle",
      "Rahul Patel",
      "Elias B. Khalil",
      "Merve Bodur"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12006"
  },
  {
    "id": "arXiv:2205.12007",
    "title": "PaddleSpeech: An Easy-to-Use All-in-One Speech Toolkit",
    "abstract": "PaddleSpeech is an open-source all-in-one speech toolkit. It aims at\nfacilitating the development and research of speech processing technologies by\nproviding an easy-to-use command-line interface and a simple code structure.\nThis paper describes the design philosophy and core architecture of\nPaddleSpeech to support several essential speech-to-text and text-to-speech\ntasks. PaddleSpeech achieves competitive or state-of-the-art performance on\nvarious speech datasets and implements the most popular methods. It also\nprovides recipes and pretrained models to quickly reproduce the experimental\nresults in this paper. PaddleSpeech is publicly avaiable at\nhttps://github.com/PaddlePaddle/PaddleSpeech.",
    "descriptor": "",
    "authors": [
      "Hui Zhang",
      "Tian Yuan",
      "Junkun Chen",
      "Xintong Li",
      "Renjie Zheng",
      "Yuxin Huang",
      "Xiaojie Chen",
      "Enlei Gong",
      "Zeyu Chen",
      "Xiaoguang Hu",
      "Dianhai Yu",
      "Yanjun Ma",
      "Liang Huang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.12007"
  },
  {
    "id": "arXiv:2205.12032",
    "title": "Defending a Music Recommender Against Hubness-Based Adversarial Attacks",
    "abstract": "Adversarial attacks can drastically degrade performance of recommenders and\nother machine learning systems, resulting in an increased demand for defence\nmechanisms. We present a new line of defence against attacks which exploit a\nvulnerability of recommenders that operate in high dimensional data spaces (the\nso-called hubness problem). We use a global data scaling method, namely Mutual\nProximity (MP), to defend a real-world music recommender which previously was\nsusceptible to attacks that inflated the number of times a particular song was\nrecommended. We find that using MP as a defence greatly increases robustness of\nthe recommender against a range of attacks, with success rates of attacks\naround 44% (before defence) dropping to less than 6% (after defence).\nAdditionally, adversarial examples still able to fool the defended system do so\nat the price of noticeably lower audio quality as shown by a decreased average\nSNR.",
    "descriptor": "\nComments: 6 pages, to be published in Proceedings of the 19th Sound and Music Computing Conference 2022 (SMC-22)\n",
    "authors": [
      "Katharina Hoedt",
      "Arthur Flexer",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.12032"
  },
  {
    "id": "arXiv:2205.12073",
    "title": "Edge Semantic Cognitive Intelligence for 6G Networks: Models, Framework,  and Applications",
    "abstract": "Edge intelligence is anticipated to underlay the pathway to connected\nintelligence for 6G networks, but the organic confluence of edge computing and\nartificial intelligence still needs to be carefully treated. To this end, this\narticle discusses the concepts of edge intelligence from the semantic cognitive\nperspective. Two instructive theoretical models for edge semantic cognitive\nintelligence (ESCI) are first established. Afterwards, the ESCI framework\norchestrating deep learning with semantic communication is discussed. Two\nrepresentative applications are present to shed light on the prospect of ESCI\nin 6G networks. Some open problems are finally listed to elicit the future\nresearch directions of ESCI.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Peihao Dong",
      "Qihui Wu",
      "Xiaofei Zhang",
      "Guoru Ding"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.12073"
  },
  {
    "id": "arXiv:2205.12086",
    "title": "Optimality Conditions and Algorithms for Top-K Arm Identification",
    "abstract": "We consider the top-k arm identification problem for multi-armed bandits with\nrewards belonging to a one-parameter canonical exponential family. The\nobjective is to select the set of k arms with the highest mean rewards by\nsequential allocation of sampling efforts. We propose a unified optimal\nallocation problem that identifies the complexity measures of this problem\nunder the fixed-confidence, fixed-budget settings, and the posterior\nconvergence rate from the Bayesian perspective. We provide the first\ncharacterization of its optimality. We provide the first provably optimal\nalgorithm in the fixed-confidence setting for k>1. We also propose an efficient\nheuristic algorithm for the top-k arm identification problem. Extensive\nnumerical experiments demonstrate superior performance compare to existing\nmethods in all three settings.",
    "descriptor": "",
    "authors": [
      "Zihao Wang",
      "Shuoguang Yang",
      "Wei You"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12086"
  },
  {
    "id": "arXiv:2205.12096",
    "title": "A generalised, multi-phase-field theory for dissolution-driven stress  corrosion cracking and hydrogen embrittlement",
    "abstract": "We present a phase field-based electro-chemo-mechanical formulation for\nmodelling mechanics-enhanced corrosion and hydrogen-assisted cracking in\nelastic-plastic solids. A multi-phase-field approach is used to present, for\nthe first time, a general framework for stress corrosion cracking,\nincorporating both anodic dissolution and hydrogen embrittlement mechanisms. We\nnumerically implement our theory using the finite element method and defining\nas primary kinematic variables the displacement components, the phase field\ncorrosion order parameter, the metal ion concentration, the phase field\nfracture order parameter and the hydrogen concentration. Representative case\nstudies are addressed to showcase the predictive capabilities of the model in\nvarious materials and environments, attaining a promising agreement with\nbenchmark tests and experimental observations. We show that the generalised\nformulation presented can capture, as a function of the environment, the\ninterplay between anodic dissolution- and hydrogen-driven failure mechanisms;\nincluding the transition from one to the other, their synergistic action and\ntheir individual occurrence. Such a generalised framework can bring new insight\ninto environment-material interactions and the understanding of stress\ncorrosion cracking, as demonstrated here by providing the first simulation\nresults for Gruhl's seminal experiments.",
    "descriptor": "",
    "authors": [
      "C. Cui",
      "R. Ma",
      "E. Mart\u00ednez-Pa\u00f1eda"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.12096"
  },
  {
    "id": "arXiv:2205.12131",
    "title": "Detecting Deforestation from Sentinel-1 Data in the Absence of Reliable  Reference Data",
    "abstract": "Forests are vital for the wellbeing of our planet. Large and small scale\ndeforestation across the globe is threatening the stability of our climate,\nforest biodiversity, and therefore the preservation of fragile ecosystems and\nour natural habitat as a whole. With increasing public interest in climate\nchange issues and forest preservation, a large demand for carbon offsetting,\ncarbon footprint ratings, and environmental impact assessments is emerging.\nMost often, deforestation maps are created from optical data such as Landsat\nand MODIS. These maps are not typically available at less than annual intervals\ndue to persistent cloud cover in many parts of the world, especially the\ntropics where most of the world's forest biomass is concentrated. Synthetic\nAperture Radar (SAR) can fill this gap as it penetrates clouds. We propose and\nevaluate a novel method for deforestation detection in the absence of reliable\nreference data which often constitutes the largest practical hurdle. This\nmethod achieves a change detection sensitivity (producer's accuracy) of 96.5%\nin the study area, although false positives lead to a lower user's accuracy of\nabout 75.7%, with a total balanced accuracy of 90.4%. The change detection\naccuracy is maintained when adding up to 20% noise to the reference labels.\nWhile further work is required to reduce the false positive rate, improve\ndetection delay, and validate this method in additional circumstances, the\nresults show that Sentinel-1 data have the potential to advance the timeliness\nof global deforestation monitoring.",
    "descriptor": "",
    "authors": [
      "Johannes N. Hansen",
      "Edward T.A. Mitchard",
      "Stuart King"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12131"
  },
  {
    "id": "arXiv:2205.12142",
    "title": "QPack Scores: Quantitative performance metrics for application-oriented  quantum computer benchmarking",
    "abstract": "This paper presents the benchmark score definitions of QPack, an\napplication-oriented cross-platform benchmarking suite for quantum computers\nand simulators, which makes use of scalable Quantum Approximate Optimization\nAlgorithm and Variational Quantum Eigensolver applications. Using a varied set\nof benchmark applications, an insight of how well a quantum computer or its\nsimulator performs on a general NISQ-era application can be quantitatively\nmade. This paper presents what quantum execution data can be collected and\ntransformed into benchmark scores for application-oriented quantum\nbenchmarking. Definitions are given for an overall benchmark score, as well as\nsub-scores based on runtime, accuracy, scalability and capacity performance.\nUsing these scores, a comparison is made between various quantum computer\nsimulators, running both locally and on vendors' remote cloud services. We also\nuse the QPack benchmark to collect a small set of quantum execution data of the\nIBMQ Nairobi quantum processor. The goal of the QPack benchmark scores is to\ngive a holistic insight into quantum performance and the ability to make easy\nand quick comparisons between different quantum computers",
    "descriptor": "\nComments: 23 pages, 45 figures\n",
    "authors": [
      "Huub Donkers",
      "Koen Mesman",
      "Zaid Al-Ars",
      "Matthias M\u00f6ller"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2205.12142"
  },
  {
    "id": "arXiv:2205.12156",
    "title": "Not too little, not too much: a theoretical analysis of graph  (over)smoothing",
    "abstract": "We analyze graph smoothing with \\emph{mean aggregation}, where each node\nsuccessively receives the average of the features of its neighbors. Indeed, it\nhas quickly been observed that Graph Neural Networks (GNNs), which generally\nfollow some variant of Message-Passing (MP) with repeated aggregation, may be\nsubject to the \\emph{oversmoothing} phenomenon: by performing too many rounds\nof MP, the node features tend to converge to a non-informative limit. In the\ncase of mean aggregation, for connected graphs, the node features become\nconstant across the whole graph. At the other end of the spectrum, it is\nintuitively obvious that \\emph{some} MP rounds are necessary, but existing\nanalyses do not exhibit both phenomena at once: beneficial ``finite'' smoothing\nand oversmoothing in the limit. In this paper, we consider simplified linear\nGNNs, and rigorously analyze two examples for which a finite number of mean\naggregation steps provably improves the learning performance, before\noversmoothing kicks in. We consider a latent space random graph model, where\nnode features are partial observations of the latent variables and the graph\ncontains pairwise relationships between them. We show that graph smoothing\nrestores some of the lost information, up to a certain point, by two\nphenomenon: graph smoothing shrinks non-principal directions in the data faster\nthan principal ones, which is useful for regression, and shrinks nodes within\ncommunities faster than they collapse together, which improves classification.",
    "descriptor": "",
    "authors": [
      "Nicolas Keriven"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12156"
  },
  {
    "id": "arXiv:2205.12158",
    "title": "D$^\\text{2}$UF: Deep Coded Aperture Design and Unrolling Algorithm for  Compressive Spectral Image Fusion",
    "abstract": "Compressive spectral imaging (CSI) has attracted significant attention since\nit employs synthetic apertures to codify spatial and spectral information,\nsensing only 2D projections of the 3D spectral image. However, these optical\narchitectures suffer from a trade-off between the spatial and spectral\nresolution of the reconstructed image due to technology limitations. To\novercome this issue, compressive spectral image fusion (CSIF) employs the\nprojected measurements of two CSI architectures with different resolutions to\nestimate a high-spatial high-spectral resolution. This work presents the fusion\nof the compressive measurements of a low-spatial high-spectral resolution coded\naperture snapshot spectral imager (CASSI) architecture and a high-spatial\nlow-spectral resolution multispectral color filter array (MCFA) system. Unlike\nprevious CSIF works, this paper proposes joint optimization of the sensing\narchitectures and a reconstruction network in an end-to-end (E2E) manner. The\ntrainable optical parameters are the coded aperture (CA) in the CASSI and the\ncolored coded aperture in the MCFA system, employing a sigmoid activation\nfunction and regularization function to encourage binary values on the\ntrainable variables for an implementation purpose. Additionally, an\nunrolling-based network inspired by the alternating direction method of\nmultipliers (ADMM) optimization is formulated to address the reconstruction\nstep and the acquisition systems design jointly. Finally, a spatial-spectral\ninspired loss function is employed at the end of each unrolling layer to\nincrease the convergence of the unrolling network. The proposed method\noutperforms previous CSIF methods, and experimental results validate the method\nwith real measurements.",
    "descriptor": "\nComments: 12 pages, 11 figures\n",
    "authors": [
      "Roman Jacome",
      "Jorge Bacca",
      "Henry Arguello"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.12158"
  },
  {
    "id": "arXiv:2205.12165",
    "title": "Solving Larger Optimization Problems Using Parallel Quantum Annealing",
    "abstract": "Quantum annealing has the potential to find low energy solutions of NP-hard\nproblems that can be expressed as quadratic unconstrained binary optimization\nproblems. However, the hardware of the quantum annealer manufactured by D-Wave\nSystems, which we consider in this work, is sparsely connected and moderately\nsized (on the order of thousands of qubits), thus necessitating a\nminor-embedding of a logical problem onto the physical qubit hardware. The\ncombination of relatively small hardware sizes and the necessity of a\nminor-embedding can mean that solving large optimization problems is not\npossible on current quantum annealers. In this research, we show that a hybrid\napproach combining parallel quantum annealing with graph decomposition allows\none to solve larger optimization problem accurately. We apply the approach on\nthe Maximum Clique problem on graphs with up to 120 nodes and 6395 edges.",
    "descriptor": "",
    "authors": [
      "Elijah Pelofske",
      "Georg Hahn",
      "Hristo N. Djidjev"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2205.12165"
  },
  {
    "id": "arXiv:2205.12207",
    "title": "Rate-Splitting Multiple Access and its Interplay with Intelligent  Reflecting Surfaces",
    "abstract": "Rate-splitting multiple access (RSMA) has recently appeared as a powerful\ntechnique for improving the downlink performance of multiple-input\nmultiple-output (MIMO) systems. By flexibly managing interference, RSMA can\ndeliver high spectral and energy efficiency, as well as robustness to imperfect\nchannel state information (CSI). In another development, an intelligent\nreflecting surface (IRS) has emerged as a method to control the wireless\nenvironment through software-configurable, near-passive, sub-wavelength\nreflecting elements. This article presents the potential of synergy between IRS\nand RSMA. Three important improvements achievable by IRS-RSMA schemes are\nidentified, supported by insightful numerical examples, and mapped to beyond-5G\nuse cases, along with future research directions.",
    "descriptor": "\nComments: IEEE Communications Magazine, May 2022\n",
    "authors": [
      "Arthur S. de Sena",
      "Pedro H. J. Nardelli",
      "Daniel B. da Costa",
      "Petar Popovski",
      "Constantinos B. Papadias"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.12207"
  },
  {
    "id": "arXiv:2205.12224",
    "title": "GLOBUS: GLObal Building heights for Urban Studies",
    "abstract": "Urban weather and climate studies continue to be important as extreme events\ncause economic loss and impact public health. Weather models seek to represent\nurban areas but are oversimplified due to data availability, especially\nbuilding information. This paper introduces a novel Level of Detail-1 (LoD-1)\nbuilding dataset derived from a Deep Neural Network (DNN) called GLObal\nBuilding heights for Urban Studies (GLOBUS). GLOBUS uses open-source datasets\nas predictors: Advanced Land Observation Satellite (ALOS) Digital Surface Model\n(DSM) normalized using Shuttle Radar Topography Mission (SRTM) Digital\nElevation Model (DEM), Landscan population density, and building footprints.\nThe building information from GLOBUS can be ingested in Numerical Weather\nPrediction (NWP) and urban energy-water balance models to study localized\nphenomena such as the Urban Heat Island (UHI) effect. GLOBUS has been trained\nand validated using the United States Geological Survey (USGS) 3DEP Light\nDetection and Ranging (LiDAR) data. We used data from 5 US cities for training\nand the model was validated over 6 cities. Performance metrics are computed at\na spatial resolution of 300-meter. The Root Mean Squared Error (RMSE) and Mean\nAbsolute Percentage Error (MAPE) were 5.15 meters and 28.8 %, respectively. The\nstandard deviation and histogram of building heights over a 300-meter grid are\nwell represented using GLOBUS.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Harsh G. Kamath",
      "Manmeet Singh",
      "Lori A. Magruder",
      "Zong-Liang Yang",
      "Dev Niyogi"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12224"
  },
  {
    "id": "arXiv:2205.12243",
    "title": "EBM Life Cycle: MCMC Strategies for Synthesis, Defense, and Density  Modeling",
    "abstract": "This work presents strategies to learn an Energy-Based Model (EBM) according\nto the desired length of its MCMC sampling trajectories. MCMC trajectories of\ndifferent lengths correspond to models with different purposes. Our experiments\ncover three different trajectory magnitudes and learning outcomes: 1) shortrun\nsampling for image generation; 2) midrun sampling for classifier-agnostic\nadversarial defense; and 3) longrun sampling for principled modeling of image\nprobability densities. To achieve these outcomes, we introduce three novel\nmethods of MCMC initialization for negative samples used in Maximum Likelihood\n(ML) learning. With standard network architectures and an unaltered ML\nobjective, our MCMC initialization methods alone enable significant performance\ngains across the three applications that we investigate. Our results include\nstate-of-the-art FID scores for unnormalized image densities on the CIFAR-10\nand ImageNet datasets; state-of-the-art adversarial defense on CIFAR-10 among\npurification methods and the first EBM defense on ImageNet; and scalable\ntechniques for learning valid probability densities. Code for this project can\nbe found at https://github.com/point0bar1/ebm-life-cycle.",
    "descriptor": "",
    "authors": [
      "Mitch Hill",
      "Jonathan Mitchell",
      "Chu Chen",
      "Yuan Du",
      "Mubarak Shah",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12243"
  },
  {
    "id": "arXiv:1810.09126",
    "title": "Risk-Sensitive Reinforcement Learning via Policy Gradient Search",
    "abstract": "Comments: To appear in \"Foundations and Trends in Machine Learning\"",
    "descriptor": "\nComments: To appear in \"Foundations and Trends in Machine Learning\"\n",
    "authors": [
      "Prashanth L.A.",
      "Michael Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1810.09126"
  },
  {
    "id": "arXiv:1811.02070",
    "title": "Blind Two-Dimensional Super-Resolution and Its Performance Guarantee  (Extended Version)",
    "abstract": "Blind Two-Dimensional Super-Resolution and Its Performance Guarantee  (Extended Version)",
    "descriptor": "",
    "authors": [
      "Mohamed A. Suliman",
      "Wei Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1811.02070"
  },
  {
    "id": "arXiv:1903.11240",
    "title": "Eigenvalue and Generalized Eigenvalue Problems: Tutorial",
    "abstract": "Comments: 8 pages, Tutorial paper. v2: Added additional information",
    "descriptor": "\nComments: 8 pages, Tutorial paper. v2: Added additional information\n",
    "authors": [
      "Benyamin Ghojogh",
      "Fakhri Karray",
      "Mark Crowley"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1903.11240"
  },
  {
    "id": "arXiv:1908.00467",
    "title": "On the existence of paradoxical motions of generically rigid graphs on  the sphere",
    "abstract": "Comments: 42 pages. This is the accepted version of the manuscript; the final version of this work is this https URL",
    "descriptor": "\nComments: 42 pages. This is the accepted version of the manuscript; the final version of this work is this https URL\n",
    "authors": [
      "Matteo Gallet",
      "Georg Grasegger",
      "Jan Legersk\u00fd",
      "Josef Schicho"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Robotics (cs.RO)",
      "Algebraic Geometry (math.AG)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/1908.00467"
  },
  {
    "id": "arXiv:1908.01887",
    "title": "DoorGym: A Scalable Door Opening Environment And Baseline Agent",
    "abstract": "Comments: Accepted to NeurIPS2019 Deep Reinforcement Learning Workshop. Full version",
    "descriptor": "\nComments: Accepted to NeurIPS2019 Deep Reinforcement Learning Workshop. Full version\n",
    "authors": [
      "Yusuke Urakami",
      "Alec Hodgkinson",
      "Casey Carlin",
      "Randall Leu",
      "Luca Rigazio",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1908.01887"
  },
  {
    "id": "arXiv:1909.03862",
    "title": "Out-of-domain Detection for Natural Language Understanding in Dialog  Systems",
    "abstract": "Comments: Accepted by TASLP, Code available at this https URL",
    "descriptor": "\nComments: Accepted by TASLP, Code available at this https URL\n",
    "authors": [
      "Yinhe Zheng",
      "Guanyi Chen",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1909.03862"
  },
  {
    "id": "arXiv:1909.07036",
    "title": "Towards Distributed Logic Programming based on Computability Logic",
    "abstract": "Comments: 5 pages. We discuss an agent programming model with query/knowledgebase duality. This model is quite interesting and promising. This version fixes some bugs from the previous version. arXiv admin note: text overlap with arXiv:1311.6542 by other authors",
    "descriptor": "\nComments: 5 pages. We discuss an agent programming model with query/knowledgebase duality. This model is quite interesting and promising. This version fixes some bugs from the previous version. arXiv admin note: text overlap with arXiv:1311.6542 by other authors\n",
    "authors": [
      "Keehang Kwon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1909.07036"
  },
  {
    "id": "arXiv:1910.00135",
    "title": "Impartial Selection with Additive Approximation Guarantees",
    "abstract": "Comments: 18 pages, 7 figures. A preliminary version appeared in SAGT '19. Corrected a minor bug in Theorem 3 and typos. Theory Comput Syst (2022)",
    "descriptor": "\nComments: 18 pages, 7 figures. A preliminary version appeared in SAGT '19. Corrected a minor bug in Theorem 3 and typos. Theory Comput Syst (2022)\n",
    "authors": [
      "Ioannis Caragiannis",
      "George Christodoulou",
      "Nicos Protopapas"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1910.00135"
  },
  {
    "id": "arXiv:2002.00287",
    "title": "Efficient and Robust Algorithms for Adversarial Linear Contextual  Bandits",
    "abstract": "Efficient and Robust Algorithms for Adversarial Linear Contextual  Bandits",
    "descriptor": "",
    "authors": [
      "Gergely Neu",
      "Julia Olkhovskaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.00287"
  },
  {
    "id": "arXiv:2002.08412",
    "title": "Weakly-supervised Multi-output Regression via Correlated Gaussian  Processes",
    "abstract": "Weakly-supervised Multi-output Regression via Correlated Gaussian  Processes",
    "descriptor": "",
    "authors": [
      "Seokhyun Chung",
      "Raed Al Kontar",
      "Zhenke Wu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.08412"
  },
  {
    "id": "arXiv:2006.11869",
    "title": "Planarity can be Verified by an Approximate Proof Labeling Scheme in  Constant-Time",
    "abstract": "Comments: 18 pages, the title has changed, to appear in Journal of Combinatorial Theory A",
    "descriptor": "\nComments: 18 pages, the title has changed, to appear in Journal of Combinatorial Theory A\n",
    "authors": [
      "G\u00e1bor Elek"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2006.11869"
  },
  {
    "id": "arXiv:2007.10731",
    "title": "MAGMA: Inference and Prediction with Multi-Task Gaussian Processes",
    "abstract": "MAGMA: Inference and Prediction with Multi-Task Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Arthur Leroy",
      "Pierre Latouche",
      "Benjamin Guedj",
      "Servane Gey"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.10731"
  },
  {
    "id": "arXiv:2007.11972",
    "title": "DeepKriging: Spatially Dependent Deep Neural Networks for Spatial  Prediction",
    "abstract": "DeepKriging: Spatially Dependent Deep Neural Networks for Spatial  Prediction",
    "descriptor": "",
    "authors": [
      "Wanfang Chen",
      "Yuxiao Li",
      "Brian J Reich",
      "Ying Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2007.11972"
  },
  {
    "id": "arXiv:2008.07324",
    "title": "Intelligence Primer",
    "abstract": "Comments: 18 pages, 12 Figures",
    "descriptor": "\nComments: 18 pages, 12 Figures\n",
    "authors": [
      "Karl Fezer",
      "Andrew Sloss"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.07324"
  },
  {
    "id": "arXiv:2009.03793",
    "title": "Linear Temporal Public Announcement Logic: a new perspective for  reasoning about the knowledge of multi-classifiers",
    "abstract": "Comments: 27 pages, 1 figures",
    "descriptor": "\nComments: 27 pages, 1 figures\n",
    "authors": [
      "Amirhoshang Hoseinpour Dehkordi",
      "Majid Alizadeh",
      "Ali Movaghar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.03793"
  },
  {
    "id": "arXiv:2010.09215",
    "title": "Analysis of (shifted) piecewise quadratic polynomial collocation for  nonlocal diffusion model",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Minghua Chen",
      "Jiankang Shi",
      "Xiaobo Yin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.09215"
  },
  {
    "id": "arXiv:2010.10508",
    "title": "Polar Deconvolution of Mixed Signals",
    "abstract": "Polar Deconvolution of Mixed Signals",
    "descriptor": "",
    "authors": [
      "Zhenan Fan",
      "Halyun Jeong",
      "Babhru Joshi",
      "Michael P. Friedlander"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2010.10508"
  },
  {
    "id": "arXiv:2010.12122",
    "title": "Quantum Meets Fine-grained Complexity: Sublinear Time Quantum Algorithms  for String Problems",
    "abstract": "Comments: 33 pages; presented at ITCS 2022",
    "descriptor": "\nComments: 33 pages; presented at ITCS 2022\n",
    "authors": [
      "Fran\u00e7ois Le Gall",
      "Saeed Seddighin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.12122"
  },
  {
    "id": "arXiv:2010.12138",
    "title": "Rethinking the competition between detection and ReID in Multi-Object  Tracking",
    "abstract": "Comments: Accepted by TIP",
    "descriptor": "\nComments: Accepted by TIP\n",
    "authors": [
      "Chao Liang",
      "Zhipeng Zhang",
      "Xue Zhou",
      "Bing Li",
      "Shuyuan Zhu",
      "Weiming Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.12138"
  },
  {
    "id": "arXiv:2011.12598",
    "title": "Energy Forecasting in Smart Grid Systems: A Review of the  State-of-the-art Techniques",
    "abstract": "Energy Forecasting in Smart Grid Systems: A Review of the  State-of-the-art Techniques",
    "descriptor": "",
    "authors": [
      "Devinder Kaur",
      "Shama Naz Islam",
      "Md. Apel Mahmud",
      "Md. Enamul Haque",
      "ZhaoYang Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.12598"
  },
  {
    "id": "arXiv:2101.00734",
    "title": "Factor Analysis, Probabilistic Principal Component Analysis, Variational  Inference, and Variational Autoencoder: Tutorial and Survey",
    "abstract": "Comments: To appear as a part of an upcoming textbook on dimensionality reduction and manifold learning. v2: corrected some mathematical typos",
    "descriptor": "\nComments: To appear as a part of an upcoming textbook on dimensionality reduction and manifold learning. v2: corrected some mathematical typos\n",
    "authors": [
      "Benyamin Ghojogh",
      "Ali Ghodsi",
      "Fakhri Karray",
      "Mark Crowley"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.00734"
  },
  {
    "id": "arXiv:2101.11508",
    "title": "Effects of Image Size on Deep Learning",
    "abstract": "Comments: 9 pages, 19 figures, 5 tables",
    "descriptor": "\nComments: 9 pages, 19 figures, 5 tables\n",
    "authors": [
      "Olivier Rukundo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2101.11508"
  },
  {
    "id": "arXiv:2102.05485",
    "title": "On the Properties of Kullback-Leibler Divergence Between Multivariate  Gaussian Distributions",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2002.03328",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2002.03328\n",
    "authors": [
      "Yufeng Zhang",
      "Wanwei Liu",
      "Zhenbang Chen",
      "Ji Wang",
      "Kenli Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.05485"
  },
  {
    "id": "arXiv:2103.06460",
    "title": "Recent Advances on Neural Network Pruning at Initialization",
    "abstract": "Comments: Accepted in IJCAI'22 Survey Track. Code base: this https URL",
    "descriptor": "\nComments: Accepted in IJCAI'22 Survey Track. Code base: this https URL\n",
    "authors": [
      "Huan Wang",
      "Can Qin",
      "Yue Bai",
      "Yulun Zhang",
      "Yun Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2103.06460"
  },
  {
    "id": "arXiv:2103.13608",
    "title": "Arbitrarily high-order conservative schemes for the generalized  Korteweg-de Vries equation",
    "abstract": "Arbitrarily high-order conservative schemes for the generalized  Korteweg-de Vries equation",
    "descriptor": "",
    "authors": [
      "Kai Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2103.13608"
  },
  {
    "id": "arXiv:2104.06641",
    "title": "FDG: A Precise Measurement of Fault Diagnosability Gain of Test Cases",
    "abstract": "Comments: 13 pages, 6 figures (to be published in ISSTA'22)",
    "descriptor": "\nComments: 13 pages, 6 figures (to be published in ISSTA'22)\n",
    "authors": [
      "Gabin An",
      "Shin Yoo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2104.06641"
  },
  {
    "id": "arXiv:2104.09343",
    "title": "Approximated Multi-Agent Fitted Q Iteration",
    "abstract": "Approximated Multi-Agent Fitted Q Iteration",
    "descriptor": "",
    "authors": [
      "Antoine Lesage-Landry",
      "Duncan S. Callaway"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.09343"
  },
  {
    "id": "arXiv:2104.12470",
    "title": "Easy and Efficient Transformer : Scalable Inference Solution For large  NLP model",
    "abstract": "Easy and Efficient Transformer : Scalable Inference Solution For large  NLP model",
    "descriptor": "",
    "authors": [
      "Gongzheng Li",
      "Yadong Xi",
      "Jingzhen Ding",
      "Duan Wang",
      "Bai Liu",
      "Changjie Fan",
      "Xiaoxi Mao",
      "Zeng Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.12470"
  },
  {
    "id": "arXiv:2105.00114",
    "title": "Improved Real-Time Monocular SLAM Using Semantic Segmentation on  Selective Frames",
    "abstract": "Improved Real-Time Monocular SLAM Using Semantic Segmentation on  Selective Frames",
    "descriptor": "",
    "authors": [
      "Jinkyu Lee",
      "Muhyun Back",
      "Sung Soo Hwang",
      "Il Yong Chun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.00114"
  },
  {
    "id": "arXiv:2105.03006",
    "title": "A Recursive Measure of Voting Power that Satisfies Reasonable Postulates",
    "abstract": "Comments: 35 pages",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Arash Abizadeh",
      "Adrian Vetta"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2105.03006"
  },
  {
    "id": "arXiv:2105.05004",
    "title": "Smart Name Lookup for NDN Forwarding Plane via Neural Networks",
    "abstract": "Comments: This paper has been published in IEEE/ACM Transactions on Networking. The final version can be accessed from IEEE Xplore",
    "descriptor": "\nComments: This paper has been published in IEEE/ACM Transactions on Networking. The final version can be accessed from IEEE Xplore\n",
    "authors": [
      "Zhuo Li",
      "Jindian Liu",
      "Liu Yan",
      "Beichuan Zhang",
      "Peng Luo",
      "Kaihua Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.05004"
  },
  {
    "id": "arXiv:2105.13190",
    "title": "Simulation of Conditioned Semimartingales on Riemannian Manifolds",
    "abstract": "Simulation of Conditioned Semimartingales on Riemannian Manifolds",
    "descriptor": "",
    "authors": [
      "Mathias H\u00f8jgaard Jensen",
      "Stefan Sommer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.13190"
  },
  {
    "id": "arXiv:2106.01100",
    "title": "Prediction of the Position of External Markers Using a Recurrent Neural  Network Trained With Unbiased Online Recurrent Optimization for Safe Lung  Cancer Radiotherapy",
    "abstract": "Comments: 24 pages, 16 figures; Fig. 2 and acknowledgments section added, abstract, introduction, section 3.2, and conclusion section updated, formatting issues solved, English language and scientific unit mistakes corrected; accepted manuscript version",
    "descriptor": "\nComments: 24 pages, 16 figures; Fig. 2 and acknowledgments section added, abstract, introduction, section 3.2, and conclusion section updated, formatting issues solved, English language and scientific unit mistakes corrected; accepted manuscript version\n",
    "authors": [
      "Michel Pohl",
      "Mitsuru Uesaka",
      "Hiroyuki Takahashi",
      "Kazuyuki Demachi",
      "Ritu Bhusal Chhatkuli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01100"
  },
  {
    "id": "arXiv:2106.02229",
    "title": "Differentiable Architecture Search for Reinforcement Learning",
    "abstract": "Comments: Published as a conference paper at the first Automated Machine Learning Conference (AutoML-Conf) 2022. Code can be found at this https URL",
    "descriptor": "\nComments: Published as a conference paper at the first Automated Machine Learning Conference (AutoML-Conf) 2022. Code can be found at this https URL\n",
    "authors": [
      "Yingjie Miao",
      "Xingyou Song",
      "John D. Co-Reyes",
      "Daiyi Peng",
      "Summer Yue",
      "Eugene Brevdo",
      "Aleksandra Faust"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02229"
  },
  {
    "id": "arXiv:2106.02797",
    "title": "Neural Distributed Source Coding",
    "abstract": "Neural Distributed Source Coding",
    "descriptor": "",
    "authors": [
      "Jay Whang",
      "Anish Acharya",
      "Hyeji Kim",
      "Alexandros G. Dimakis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02797"
  },
  {
    "id": "arXiv:2106.03065",
    "title": "Semantic-Enhanced Explainable Finetuning for Open-Domain Dialogues",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Yinhe Zheng",
      "Yida Wang",
      "Pei Ke",
      "Zhenyu Yang",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.03065"
  },
  {
    "id": "arXiv:2106.05137",
    "title": "Bayesian Persuasion in Sequential Decision-Making",
    "abstract": "Bayesian Persuasion in Sequential Decision-Making",
    "descriptor": "",
    "authors": [
      "Jiarui Gan",
      "Rupak Majumdar",
      "Goran Radanovic",
      "Adish Singla"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.05137"
  },
  {
    "id": "arXiv:2106.06926",
    "title": "Bellman-consistent Pessimism for Offline Reinforcement Learning",
    "abstract": "Comments: NeurIPS 2021 (Oral)",
    "descriptor": "\nComments: NeurIPS 2021 (Oral)\n",
    "authors": [
      "Tengyang Xie",
      "Ching-An Cheng",
      "Nan Jiang",
      "Paul Mineiro",
      "Alekh Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06926"
  },
  {
    "id": "arXiv:2106.10823",
    "title": "3D Object Detection for Autonomous Driving: A Survey",
    "abstract": "Comments: The manuscript is accepted by Pattern Recognition on 14 May 2022",
    "descriptor": "\nComments: The manuscript is accepted by Pattern Recognition on 14 May 2022\n",
    "authors": [
      "Rui Qian",
      "Xin Lai",
      "Xirong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10823"
  },
  {
    "id": "arXiv:2106.13869",
    "title": "A multi-stage machine learning model on diagnosis of esophageal  manometry",
    "abstract": "A multi-stage machine learning model on diagnosis of esophageal  manometry",
    "descriptor": "",
    "authors": [
      "Wenjun Kou",
      "Dustin A. Carlson",
      "Alexandra J. Baumann",
      "Erica N. Donnan",
      "Jacob M. Schauer",
      "Mozziyar Etemadi",
      "John E. Pandolfino"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13869"
  },
  {
    "id": "arXiv:2106.15556",
    "title": "A modification of the Beavers-Joseph condition for arbitrary flows to  the fluid-porous interface",
    "abstract": "A modification of the Beavers-Joseph condition for arbitrary flows to  the fluid-porous interface",
    "descriptor": "",
    "authors": [
      "Paula Strohbeck",
      "Elissa Eggenweiler",
      "Iryna Rybak"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.15556"
  },
  {
    "id": "arXiv:2107.02671",
    "title": "Nonuniform fast Fourier transforms with nonequispaced spatial and  frequency data and fast sinc transforms",
    "abstract": "Nonuniform fast Fourier transforms with nonequispaced spatial and  frequency data and fast sinc transforms",
    "descriptor": "",
    "authors": [
      "Melanie Kircheis",
      "Daniel Potts",
      "Manfred Tasche"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.02671"
  },
  {
    "id": "arXiv:2107.03220",
    "title": "Joint Embedding of Structural and Functional Brain Networks with Graph  Neural Networks for Mental Illness Diagnosis",
    "abstract": "Comments: Formal version accepted to IEEE EMBC 2022; previously presented at ICML 2021 Workshop on Computational Approaches to Mental Health (no proceedings)",
    "descriptor": "\nComments: Formal version accepted to IEEE EMBC 2022; previously presented at ICML 2021 Workshop on Computational Approaches to Mental Health (no proceedings)\n",
    "authors": [
      "Yanqiao Zhu",
      "Hejie Cui",
      "Lifang He",
      "Lichao Sun",
      "Carl Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2107.03220"
  },
  {
    "id": "arXiv:2107.03277",
    "title": "Linear-time calculation of the expected sum of edge lengths in random  projective linearizations of trees",
    "abstract": "Comments: Correction of minor mistakes",
    "descriptor": "\nComments: Correction of minor mistakes\n",
    "authors": [
      "Llu\u00eds Alemany-Puig",
      "Ramon Ferrer-i-Cancho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.03277"
  },
  {
    "id": "arXiv:2107.04982",
    "title": "Out-of-Distribution Dynamics Detection: RL-Relevant Benchmarks and  Results",
    "abstract": "Comments: ICML 2021 Workshop on Uncertainty and Robustness in Deep Learning",
    "descriptor": "\nComments: ICML 2021 Workshop on Uncertainty and Robustness in Deep Learning\n",
    "authors": [
      "Mohamad H Danesh",
      "Alan Fern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.04982"
  },
  {
    "id": "arXiv:2107.07610",
    "title": "Self-Supervised Contrastive Learning with Adversarial Perturbations for  Defending Word Substitution-based Attacks",
    "abstract": "Comments: In Findings of NAACL 2022",
    "descriptor": "\nComments: In Findings of NAACL 2022\n",
    "authors": [
      "Zhao Meng",
      "Yihan Dong",
      "Mrinmaya Sachan",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.07610"
  },
  {
    "id": "arXiv:2107.09224",
    "title": "From Predictions to Decisions: The Importance of Joint Predictive  Distributions",
    "abstract": "From Predictions to Decisions: The Importance of Joint Predictive  Distributions",
    "descriptor": "",
    "authors": [
      "Zheng Wen",
      "Ian Osband",
      "Chao Qin",
      "Xiuyuan Lu",
      "Morteza Ibrahimi",
      "Vikranth Dwaracherla",
      "Mohammad Asghari",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.09224"
  },
  {
    "id": "arXiv:2107.12408",
    "title": "A pressure-based method for weakly compressible two-phase flows under a  Baer-Nunziato type model with generic equations of state and pressure and  velocity disequilibrium",
    "abstract": "Comments: 49 pages, 27 figures",
    "descriptor": "\nComments: 49 pages, 27 figures\n",
    "authors": [
      "Barbara Re",
      "R\u00e9mi Abgrall"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.12408"
  },
  {
    "id": "arXiv:2107.13260",
    "title": "Deep learning based cough detection camera using enhanced features",
    "abstract": "Comments: 28 pages, 20 figures, and 14 tables",
    "descriptor": "\nComments: 28 pages, 20 figures, and 14 tables\n",
    "authors": [
      "Gyeong-Tae Lee",
      "Hyeonuk Nam",
      "Seong-Hu Kim",
      "Sang-Min Choi",
      "Youngkey Kim",
      "Yong-Hwa Park"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.13260"
  },
  {
    "id": "arXiv:2108.05058",
    "title": "Towards Top-Down Just Noticeable Difference Estimation of Natural Images",
    "abstract": "Comments: 16 pages, 16 figures",
    "descriptor": "\nComments: 16 pages, 16 figures\n",
    "authors": [
      "Qiuping Jiang",
      "Zhentao Liu",
      "Shiqi Wang",
      "Feng Shao",
      "Weisi Lin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.05058"
  },
  {
    "id": "arXiv:2108.08716",
    "title": "NB QC-LDPC Coded QAM Signals with Optimized Mapping: Bounds and  Simulation Results",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2006.12147",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.12147\n",
    "authors": [
      "Irina E. Bocharova",
      "Boris D. Kudryashov",
      "Evgenii P. Ovsyannikov",
      "Vitaly Skachek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.08716"
  },
  {
    "id": "arXiv:2108.09133",
    "title": "Estimation of Convex Polytopes for Automatic Discovery of Charge State  Transitions in Quantum Dot Arrays",
    "abstract": "Estimation of Convex Polytopes for Automatic Discovery of Charge State  Transitions in Quantum Dot Arrays",
    "descriptor": "",
    "authors": [
      "Oswin Krause",
      "Torbj\u00f8rn Rasmussen",
      "Bertram Brovang",
      "Anasua Chatterjee",
      "Ferdinand Kuemmeth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)"
    ],
    "url": "https://arxiv.org/abs/2108.09133"
  },
  {
    "id": "arXiv:2109.06013",
    "title": "Learning to Ground Visual Objects for Visual Dialog",
    "abstract": "Comments: Findings of the Association for Computational Linguistics: EMNLP 2021",
    "descriptor": "\nComments: Findings of the Association for Computational Linguistics: EMNLP 2021\n",
    "authors": [
      "Feilong Chen",
      "Xiuyi Chen",
      "Can Xu",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06013"
  },
  {
    "id": "arXiv:2109.09046",
    "title": "Improving Fairness for Data Valuation in Horizontal Federated Learning",
    "abstract": "Improving Fairness for Data Valuation in Horizontal Federated Learning",
    "descriptor": "",
    "authors": [
      "Zhenan Fan",
      "Huang Fang",
      "Zirui Zhou",
      "Jian Pei",
      "Michael P. Friedlander",
      "Changxin Liu",
      "Yong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.09046"
  },
  {
    "id": "arXiv:2109.11523",
    "title": "How much human-like visual experience do current self-supervised  learning algorithms need in order to achieve human-level object recognition?",
    "abstract": "Comments: v3 adds DINO + robustness scaling experiments",
    "descriptor": "\nComments: v3 adds DINO + robustness scaling experiments\n",
    "authors": [
      "A. Emin Orhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.11523"
  },
  {
    "id": "arXiv:2109.12075",
    "title": "Towards A Measure Of General Machine Intelligence",
    "abstract": "Comments: 31 pages, 15 Figures, 3 Tables; Sample Data and g-index Reference Code at this https URL; g-index toy environment at this https URL; version 2 added a section about the toy environment; version 3 compressed images to reduce file size; version 4 updated description of flatland toy environment",
    "descriptor": "\nComments: 31 pages, 15 Figures, 3 Tables; Sample Data and g-index Reference Code at this https URL; g-index toy environment at this https URL; version 2 added a section about the toy environment; version 3 compressed images to reduce file size; version 4 updated description of flatland toy environment\n",
    "authors": [
      "Gautham Venkatasubramanian",
      "Sibesh Kar",
      "Abhimanyu Singh",
      "Shubham Mishra",
      "Dushyant Yadav",
      "Shreyansh Chandak"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.12075"
  },
  {
    "id": "arXiv:2110.03061",
    "title": "FedTune: Automatic Tuning of Federated Learning Hyper-Parameters from  System Perspective",
    "abstract": "FedTune: Automatic Tuning of Federated Learning Hyper-Parameters from  System Perspective",
    "descriptor": "",
    "authors": [
      "Huanle Zhang",
      "Mi Zhang",
      "Xin Liu",
      "Prasant Mohapatra",
      "Michael DeLucia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03061"
  },
  {
    "id": "arXiv:2110.03215",
    "title": "Towards Continual Knowledge Learning of Language Models",
    "abstract": "Comments: published at ICLR 2022",
    "descriptor": "\nComments: published at ICLR 2022\n",
    "authors": [
      "Joel Jang",
      "Seonghyeon Ye",
      "Sohee Yang",
      "Joongbo Shin",
      "Janghoon Han",
      "Gyeonghun Kim",
      "Stanley Jungkyu Choi",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03215"
  },
  {
    "id": "arXiv:2110.04126",
    "title": "3D Infomax improves GNNs for Molecular Property Prediction",
    "abstract": "Comments: 39th International Conference on Machine Learning (ICML 2022). Also accepted at NeurIPS 2021 ML4PH, AI4S, and SSL workshops and as oral at ELLIS ML4Molecules. 23 pages, 7 figures, 18 tables",
    "descriptor": "\nComments: 39th International Conference on Machine Learning (ICML 2022). Also accepted at NeurIPS 2021 ML4PH, AI4S, and SSL workshops and as oral at ELLIS ML4Molecules. 23 pages, 7 figures, 18 tables\n",
    "authors": [
      "Hannes St\u00e4rk",
      "Dominique Beaini",
      "Gabriele Corso",
      "Prudencio Tossou",
      "Christian Dallago",
      "Stephan G\u00fcnnemann",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2110.04126"
  },
  {
    "id": "arXiv:2110.04660",
    "title": "K-Splits: Improved K-Means Clustering Algorithm to Automatically Detect  the Number of Clusters",
    "abstract": "Comments: 16 pages, 6 figures",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Seyed Omid Mohammadi",
      "Ahmad Kalhor",
      "Hossein Bodaghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.04660"
  },
  {
    "id": "arXiv:2110.06920",
    "title": "Semantics-aware Attention Improves Neural Machine Translation",
    "abstract": "Comments: Accepted to *SEM 2022",
    "descriptor": "\nComments: Accepted to *SEM 2022\n",
    "authors": [
      "Aviv Slobodkin",
      "Leshem Choshen",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06920"
  },
  {
    "id": "arXiv:2110.07205",
    "title": "SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language  Processing",
    "abstract": "Comments: Accepted by ACL 2022 main conference",
    "descriptor": "\nComments: Accepted by ACL 2022 main conference\n",
    "authors": [
      "Junyi Ao",
      "Rui Wang",
      "Long Zhou",
      "Chengyi Wang",
      "Shuo Ren",
      "Yu Wu",
      "Shujie Liu",
      "Tom Ko",
      "Qing Li",
      "Yu Zhang",
      "Zhihua Wei",
      "Yao Qian",
      "Jinyu Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.07205"
  },
  {
    "id": "arXiv:2110.10802",
    "title": "A Data-Centric Optimization Framework for Machine Learning",
    "abstract": "Comments: 13 pages, 12 figures, published at Proceedings of the ACM International Conference on Supercomputing (ICS'22)",
    "descriptor": "\nComments: 13 pages, 12 figures, published at Proceedings of the ACM International Conference on Supercomputing (ICS'22)\n",
    "authors": [
      "Oliver Rausch",
      "Tal Ben-Nun",
      "Nikoli Dryden",
      "Andrei Ivanov",
      "Shigang Li",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.10802"
  },
  {
    "id": "arXiv:2110.10832",
    "title": "Ensemble of Averages: Improving Model Selection and Boosting Performance  in Domain Generalization",
    "abstract": "Ensemble of Averages: Improving Model Selection and Boosting Performance  in Domain Generalization",
    "descriptor": "",
    "authors": [
      "Devansh Arpit",
      "Huan Wang",
      "Yingbo Zhou",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10832"
  },
  {
    "id": "arXiv:2110.11017",
    "title": "Learning Time-Varying Graphs from Online Data",
    "abstract": "Comments: To appear on IEEE Open Journal of Signal Processing",
    "descriptor": "\nComments: To appear on IEEE Open Journal of Signal Processing\n",
    "authors": [
      "Alberto Natali",
      "Elvin Isufi",
      "Mario Coutino",
      "Geert Leus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11017"
  },
  {
    "id": "arXiv:2110.11518",
    "title": "Space-Terrestrial Integrated Internet of Things: Challenges and  Opportunities",
    "abstract": "Space-Terrestrial Integrated Internet of Things: Challenges and  Opportunities",
    "descriptor": "",
    "authors": [
      "Juan A. Fraire",
      "Oana Iova",
      "Fabrice Valois"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.11518"
  },
  {
    "id": "arXiv:2110.14209",
    "title": "Fast Distributed Stochastic Scheduling for A Multi-Energy Industrial  Park",
    "abstract": "Fast Distributed Stochastic Scheduling for A Multi-Energy Industrial  Park",
    "descriptor": "",
    "authors": [
      "Dafeng Zhu",
      "Bo Yang",
      "Zhaojian Wang",
      "Chengbin Ma",
      "Kai Ma",
      "Shanying Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14209"
  },
  {
    "id": "arXiv:2110.14982",
    "title": "A Quasi-Optimal Factorization Preconditioner for Periodic Schr\u00f6dinger  Eigenstates in Anisotropically Expanding Domains",
    "abstract": "Comments: 29 pages, 9 figures, 2 tables",
    "descriptor": "\nComments: 29 pages, 9 figures, 2 tables\n",
    "authors": [
      "Benjamin Stamm",
      "Lambert Theisen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.14982"
  },
  {
    "id": "arXiv:2110.15037",
    "title": "Learning Deep Representation with Energy-Based Self-Expressiveness for  Subspace Clustering",
    "abstract": "Comments: There are some errors in Table 1",
    "descriptor": "\nComments: There are some errors in Table 1\n",
    "authors": [
      "Yanming Li",
      "Changsheng Li",
      "Shiye Wang",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15037"
  },
  {
    "id": "arXiv:2111.04580",
    "title": "Nonnegative Tensor Completion via Integer Optimization",
    "abstract": "Nonnegative Tensor Completion via Integer Optimization",
    "descriptor": "",
    "authors": [
      "Caleb Bugg",
      "Chen Chen",
      "Anil Aswani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.04580"
  },
  {
    "id": "arXiv:2111.07209",
    "title": "An Assessment of the Eye Tracking Signal Quality Captured in the  HoloLens 2",
    "abstract": "Comments: 10 pages, 10 figures",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Samantha D. Aziz",
      "Oleg V. Komogortsev"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.07209"
  },
  {
    "id": "arXiv:2111.09954",
    "title": "MS-nowcasting: Operational Precipitation Nowcasting with Convolutional  LSTMs at Microsoft Weather",
    "abstract": "Comments: Minor updates to reflect final submission to NeurIPS workshop",
    "descriptor": "\nComments: Minor updates to reflect final submission to NeurIPS workshop\n",
    "authors": [
      "Sylwester Klocek",
      "Haiyu Dong",
      "Matthew Dixon",
      "Panashe Kanengoni",
      "Najeeb Kazmi",
      "Pete Luferenko",
      "Zhongjian Lv",
      "Shikhar Sharma",
      "Jonathan Weyn",
      "Siqi Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.09954"
  },
  {
    "id": "arXiv:2111.10039",
    "title": "Spatio-Temporal Modeling for Flash Memory Channels Using Conditional  Generative Nets",
    "abstract": "Spatio-Temporal Modeling for Flash Memory Channels Using Conditional  Generative Nets",
    "descriptor": "",
    "authors": [
      "Simeng Zheng",
      "Chih-Hui Ho",
      "Wenyu Peng",
      "Paul H. Siegel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10039"
  },
  {
    "id": "arXiv:2111.11276",
    "title": "Branching Time Active Inference: empirical study and complexity class  analysis",
    "abstract": "Comments: 39 pages, 11 figures, accepted for publication in Neural Networks",
    "descriptor": "\nComments: 39 pages, 11 figures, accepted for publication in Neural Networks\n",
    "authors": [
      "Th\u00e9ophile Champion",
      "Howard Bowman",
      "Marek Grze\u015b"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.11276"
  },
  {
    "id": "arXiv:2111.11532",
    "title": "The Complexity of Conjunctive Queries with Degree 2",
    "abstract": "The Complexity of Conjunctive Queries with Degree 2",
    "descriptor": "",
    "authors": [
      "Matthias Lanzinger"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.11532"
  },
  {
    "id": "arXiv:2111.12479",
    "title": "Construction and evaluation of PH curves in exponential-polynomial  spaces",
    "abstract": "Construction and evaluation of PH curves in exponential-polynomial  spaces",
    "descriptor": "",
    "authors": [
      "Lucia Romani",
      "Alberto Viscardi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12479"
  },
  {
    "id": "arXiv:2111.13858",
    "title": "Why KDAC? A general activation function for knowledge discovery",
    "abstract": "Comments: Accepted by Neurocomputing",
    "descriptor": "\nComments: Accepted by Neurocomputing\n",
    "authors": [
      "Zhenhua Wang",
      "Dong Gao",
      "Haozhe Liu",
      "Fanglin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.13858"
  },
  {
    "id": "arXiv:2111.14406",
    "title": "Two-scale elastic shape optimization for additive manufacturing",
    "abstract": "Two-scale elastic shape optimization for additive manufacturing",
    "descriptor": "",
    "authors": [
      "Sergio Conti",
      "Martin Rumpf",
      "Stefan Simon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.14406"
  },
  {
    "id": "arXiv:2111.14690",
    "title": "DanceTrack: Multi-Object Tracking in Uniform Appearance and Diverse  Motion",
    "abstract": "Comments: add change log",
    "descriptor": "\nComments: add change log\n",
    "authors": [
      "Peize Sun",
      "Jinkun Cao",
      "Yi Jiang",
      "Zehuan Yuan",
      "Song Bai",
      "Kris Kitani",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14690"
  },
  {
    "id": "arXiv:2112.02803",
    "title": "Multi-User Holographic MIMO Surfaces: Channel Modeling and Spectral  Efficiency Analysis",
    "abstract": "Multi-User Holographic MIMO Surfaces: Channel Modeling and Spectral  Efficiency Analysis",
    "descriptor": "",
    "authors": [
      "Li Wei",
      "Chongwen Huang",
      "George C. Alexandropoulos",
      "Wei E. I. Sha",
      "Zhaoyang Zhang",
      "Merouane Debbah",
      "Chau Yuen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.02803"
  },
  {
    "id": "arXiv:2112.05593",
    "title": "A Review of Indoor Millimeter Wave Device-based Localization and  Device-free Sensing Technologies and Applications",
    "abstract": "Comments: 43 pages, 13 figures. Accepted in IEEE Communications Surveys & Tutorials (IEEE COMST)",
    "descriptor": "\nComments: 43 pages, 13 figures. Accepted in IEEE Communications Surveys & Tutorials (IEEE COMST)\n",
    "authors": [
      "Anish Shastri",
      "Neharika Valecha",
      "Enver Bashirov",
      "Harsh Tataria",
      "Michael Lentmaier",
      "Fredrik Tufvesson",
      "Michele Rossi",
      "Paolo Casari"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.05593"
  },
  {
    "id": "arXiv:2112.06061",
    "title": "OstrichRL: A Musculoskeletal Ostrich Simulation to Study Bio-mechanical  Locomotion",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Vittorio La Barbera",
      "Fabio Pardo",
      "Yuval Tassa",
      "Monica Daley",
      "Christopher Richards",
      "Petar Kormushev",
      "John Hutchinson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06061"
  },
  {
    "id": "arXiv:2112.08544",
    "title": "NewsClaims: A New Benchmark for Claim Detection from News with Attribute  Knowledge",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Revanth Gangi Reddy",
      "Sai Chetan",
      "Zhenhailong Wang",
      "Yi R. Fung",
      "Kathryn Conger",
      "Ahmed Elsayed",
      "Martha Palmer",
      "Preslav Nakov",
      "Eduard Hovy",
      "Kevin Small",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08544"
  },
  {
    "id": "arXiv:2112.08804",
    "title": "CrossSum: Beyond English-Centric Cross-Lingual Abstractive Text  Summarization for 1500+ Language Pairs",
    "abstract": "CrossSum: Beyond English-Centric Cross-Lingual Abstractive Text  Summarization for 1500+ Language Pairs",
    "descriptor": "",
    "authors": [
      "Abhik Bhattacharjee",
      "Tahmid Hasan",
      "Wasi Uddin Ahmad",
      "Yuan-Fang Li",
      "Yong-Bin Kang",
      "Rifat Shahriyar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08804"
  },
  {
    "id": "arXiv:2112.08808",
    "title": "Simple Questions Generate Named Entity Recognition Datasets",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Hyunjae Kim",
      "Jaehyo Yoo",
      "Seunghyun Yoon",
      "Jinhyuk Lee",
      "Jaewoo Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08808"
  },
  {
    "id": "arXiv:2112.10065",
    "title": "Efficient Strong Scaling Through Burst Parallel Training",
    "abstract": "Comments: MLSys'22",
    "descriptor": "\nComments: MLSys'22\n",
    "authors": [
      "Seo Jin Park",
      "Joshua Fried",
      "Sunghyun Kim",
      "Mohammad Alizadeh",
      "Adam Belay"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.10065"
  },
  {
    "id": "arXiv:2112.10354",
    "title": "Systematic Literature Review on Cyber Situational Awareness  Visualizations",
    "abstract": "Systematic Literature Review on Cyber Situational Awareness  Visualizations",
    "descriptor": "",
    "authors": [
      "Liuyue Jiang",
      "Asangi Jayatilaka",
      "Mehwish Nasim",
      "Marthie Grobler",
      "Mansooreh Zahedi",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.10354"
  },
  {
    "id": "arXiv:2112.10807",
    "title": "Surprise-Guided Search for Learning Task Specifications from  Demonstrations",
    "abstract": "Surprise-Guided Search for Learning Task Specifications from  Demonstrations",
    "descriptor": "",
    "authors": [
      "Marcell Vazquez-Chanlatte",
      "Ameesh Shah",
      "Gil Lederman",
      "Sanjit A. Seshia"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2112.10807"
  },
  {
    "id": "arXiv:2112.11879",
    "title": "Lifting C Semantics for Dataflow Optimization",
    "abstract": "Lifting C Semantics for Dataflow Optimization",
    "descriptor": "",
    "authors": [
      "Alexandru Calotoiu",
      "Tal Ben-Nun",
      "Grzegorz Kwasniewski",
      "Johannes de Fine Licht",
      "Timo Schneider",
      "Philipp Schaad",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.11879"
  },
  {
    "id": "arXiv:2201.00520",
    "title": "Vision Transformer with Deformable Attention",
    "abstract": "Comments: Accepted by CVPR2022 (12 pages, 7 figures)",
    "descriptor": "\nComments: Accepted by CVPR2022 (12 pages, 7 figures)\n",
    "authors": [
      "Zhuofan Xia",
      "Xuran Pan",
      "Shiji Song",
      "Li Erran Li",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.00520"
  },
  {
    "id": "arXiv:2201.00565",
    "title": "Swift and Sure: Hardness-aware Contrastive Learning for Low-dimensional  Knowledge Graph Embeddings",
    "abstract": "Comments: 11 pages, accepted by the Web Conference 2022",
    "descriptor": "\nComments: 11 pages, accepted by the Web Conference 2022\n",
    "authors": [
      "Kai Wang",
      "Yu Liu",
      "Quan Z. Sheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.00565"
  },
  {
    "id": "arXiv:2201.00719",
    "title": "PowerGraph: Using neural networks and principal components to determine  multivariate statistical power trade-offs",
    "abstract": "Comments: Submitted to AI4Science (ICML workshop). Not published yet",
    "descriptor": "\nComments: Submitted to AI4Science (ICML workshop). Not published yet\n",
    "authors": [
      "Ajinkya K Mulay",
      "Sean Lane",
      "Erin Hennes"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.00719"
  },
  {
    "id": "arXiv:2201.06204",
    "title": "Defeating Eavesdroppers with Ambient Backscatter Communications",
    "abstract": "Defeating Eavesdroppers with Ambient Backscatter Communications",
    "descriptor": "",
    "authors": [
      "Nguyen Van Huynh",
      "Nguyen Quang Hieu",
      "Nam H. Chu",
      "Diep N. Nguyen",
      "Dinh Thai Hoang",
      "Eryk Dutkiewicz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.06204"
  },
  {
    "id": "arXiv:2201.06463",
    "title": "Bayesian Calibration of imperfect computer models using Physics-informed  priors",
    "abstract": "Comments: 23 pages, 15 figures",
    "descriptor": "\nComments: 23 pages, 15 figures\n",
    "authors": [
      "Michail Spitieris",
      "Ingelin Steinsland"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2201.06463"
  },
  {
    "id": "arXiv:2201.06499",
    "title": "RuMedBench: A Russian Medical Language Understanding Benchmark",
    "abstract": "Comments: 11 pages, code available at this https URL; Published in the proceedings of 20th International Conference on Artificial Intelligence in Medicine, Halifax, Canada; code available at this https URL",
    "descriptor": "\nComments: 11 pages, code available at this https URL; Published in the proceedings of 20th International Conference on Artificial Intelligence in Medicine, Halifax, Canada; code available at this https URL\n",
    "authors": [
      "Pavel Blinov",
      "Arina Reshetnikova",
      "Aleksandr Nesterov",
      "Galina Zubkova",
      "Vladimir Kokh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06499"
  },
  {
    "id": "arXiv:2201.06543",
    "title": "The Power Word Problem in Graph Products",
    "abstract": "The Power Word Problem in Graph Products",
    "descriptor": "",
    "authors": [
      "Florian Stober",
      "Armin Wei\u00df"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.06543"
  },
  {
    "id": "arXiv:2201.07546",
    "title": "Welfare vs. Representation in Participatory Budgeting",
    "abstract": "Welfare vs. Representation in Participatory Budgeting",
    "descriptor": "",
    "authors": [
      "Roy Fairstein",
      "Reshef Meir",
      "Dan Vilenchik",
      "Kobi Gal"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.07546"
  },
  {
    "id": "arXiv:2201.09113",
    "title": "Predicting Physics in Mesh-reduced Space with Temporal Attention",
    "abstract": "Predicting Physics in Mesh-reduced Space with Temporal Attention",
    "descriptor": "",
    "authors": [
      "Xu Han",
      "Han Gao",
      "Tobias Pffaf",
      "Jian-Xun Wang",
      "Li-Ping Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09113"
  },
  {
    "id": "arXiv:2201.09686",
    "title": "Balanced Graph Structure Learning for Multivariate Time Series  Forecasting",
    "abstract": "Comments: 16 pages, in submission to ECML-PKDD2022",
    "descriptor": "\nComments: 16 pages, in submission to ECML-PKDD2022\n",
    "authors": [
      "Weijun Chen",
      "Yanze Wang",
      "Chengshuo Du",
      "Zhenglong Jia",
      "Feng Liu",
      "Ran Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09686"
  },
  {
    "id": "arXiv:2201.10036",
    "title": "Carbon Explorer: A Holistic Approach for Designing Carbon Aware  Datacenters",
    "abstract": "Carbon Explorer: A Holistic Approach for Designing Carbon Aware  Datacenters",
    "descriptor": "",
    "authors": [
      "Bilge Acun",
      "Benjamin Lee",
      "Fiodar Kazhamiaka",
      "Kiwan Maeng",
      "Manoj Chakkaravarthy",
      "Udit Gupta",
      "David Brooks",
      "Carole-Jean Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.10036"
  },
  {
    "id": "arXiv:2201.10602",
    "title": "Jacobian Computation for Cumulative B-Splines on SE(3) and Application  to Continuous-Time Object Tracking",
    "abstract": "Comments: Accepted at IEEE Robotics and Automation Letters",
    "descriptor": "\nComments: Accepted at IEEE Robotics and Automation Letters\n",
    "authors": [
      "Javier Tirado",
      "Javier Civera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.10602"
  },
  {
    "id": "arXiv:2201.11104",
    "title": "Combining optimal path search with task-dependent learning in a neural  network",
    "abstract": "Combining optimal path search with task-dependent learning in a neural  network",
    "descriptor": "",
    "authors": [
      "Tomas Kulvicius",
      "Minija Tamosiunaite",
      "Florentin W\u00f6rg\u00f6tter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11104"
  },
  {
    "id": "arXiv:2201.12114",
    "title": "Rethinking Attention-Model Explainability through Faithfulness Violation  Test",
    "abstract": "Comments: Accepted to ICML 2022",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Yibing Liu",
      "Haoliang Li",
      "Yangyang Guo",
      "Chenqi Kong",
      "Jing Li",
      "Shiqi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12114"
  },
  {
    "id": "arXiv:2201.12724",
    "title": "Stochastic Neural Networks with Infinite Width are Deterministic",
    "abstract": "Stochastic Neural Networks with Infinite Width are Deterministic",
    "descriptor": "",
    "authors": [
      "Liu Ziyin",
      "Hanlin Zhang",
      "Xiangming Meng",
      "Yuting Lu",
      "Eric Xing",
      "Masahito Ueda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12724"
  },
  {
    "id": "arXiv:2201.13132",
    "title": "On the identifiability of mixtures of ranking models",
    "abstract": "Comments: 44 pages. Comments are very welcome",
    "descriptor": "\nComments: 44 pages. Comments are very welcome\n",
    "authors": [
      "Xiaomin Zhang",
      "Xucheng Zhang",
      "Po-Ling Loh",
      "Yingyu Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Geometry (math.AG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.13132"
  },
  {
    "id": "arXiv:2201.13329",
    "title": "Can Adversarial Training Be Manipulated By Non-Robust Features?",
    "abstract": "Can Adversarial Training Be Manipulated By Non-Robust Features?",
    "descriptor": "",
    "authors": [
      "Lue Tao",
      "Lei Feng",
      "Hongxin Wei",
      "Jinfeng Yi",
      "Sheng-Jun Huang",
      "Songcan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.13329"
  },
  {
    "id": "arXiv:2202.00009",
    "title": "Identifying Dementia Subtypes with Electronic Health Records",
    "abstract": "Comments: ACM Conference on Bioinformatics, Computational Biology, and Health Informatics 13 pages, 7 figures, 3 tables",
    "descriptor": "\nComments: ACM Conference on Bioinformatics, Computational Biology, and Health Informatics 13 pages, 7 figures, 3 tables\n",
    "authors": [
      "Sayantan Kumar",
      "Zachary Abrams",
      "Suzanne Schindler",
      "Nupur Ghoshal",
      "Philip Payne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00009"
  },
  {
    "id": "arXiv:2202.00373",
    "title": "Improving BERT-based Query-by-Document Retrieval with Multi-Task  Optimization",
    "abstract": "Comments: Accepted for publication in the 44th European Conference on Information Retrieval (ECIR2022)",
    "descriptor": "\nComments: Accepted for publication in the 44th European Conference on Information Retrieval (ECIR2022)\n",
    "authors": [
      "Amin Abolghasemi",
      "Suzan Verberne",
      "Leif Azzopardi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.00373"
  },
  {
    "id": "arXiv:2202.02625",
    "title": "Training Differentially Private Models with Secure Multiparty  Computation",
    "abstract": "Training Differentially Private Models with Secure Multiparty  Computation",
    "descriptor": "",
    "authors": [
      "Sikha Pentyala",
      "Davis Railsback",
      "Ricardo Maia",
      "Rafael Dowsley",
      "David Melanson",
      "Anderson Nascimento",
      "Martine De Cock"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02625"
  },
  {
    "id": "arXiv:2202.03580",
    "title": "Convolutional Neural Networks on Graphs with Chebyshev Approximation,  Revisited",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Mingguo He",
      "Zhewei Wei",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03580"
  },
  {
    "id": "arXiv:2202.03989",
    "title": "The amazing mixed polynomial closure and its applications to  two-variable first-order logic",
    "abstract": "The amazing mixed polynomial closure and its applications to  two-variable first-order logic",
    "descriptor": "",
    "authors": [
      "Thomas Place"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.03989"
  },
  {
    "id": "arXiv:2202.04058",
    "title": "PrivFair: a Library for Privacy-Preserving Fairness Auditing",
    "abstract": "PrivFair: a Library for Privacy-Preserving Fairness Auditing",
    "descriptor": "",
    "authors": [
      "Sikha Pentyala",
      "David Melanson",
      "Martine De Cock",
      "Golnoosh Farnadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04058"
  },
  {
    "id": "arXiv:2202.05339",
    "title": "Closure operators: Complexity and applications to classification and  decision-making",
    "abstract": "Closure operators: Complexity and applications to classification and  decision-making",
    "descriptor": "",
    "authors": [
      "Hamed Hamze Bajgiran",
      "Federico Echenique"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05339"
  },
  {
    "id": "arXiv:2202.07206",
    "title": "Impact of Pretraining Term Frequencies on Few-Shot Reasoning",
    "abstract": "Impact of Pretraining Term Frequencies on Few-Shot Reasoning",
    "descriptor": "",
    "authors": [
      "Yasaman Razeghi",
      "Robert L. Logan IV",
      "Matt Gardner",
      "Sameer Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07206"
  },
  {
    "id": "arXiv:2202.07416",
    "title": "The Membership Problem for Hypergeometric Sequences with Rational  Parameters",
    "abstract": "The Membership Problem for Hypergeometric Sequences with Rational  Parameters",
    "descriptor": "",
    "authors": [
      "Klara Nosan",
      "Amaury Pouly",
      "Mahsa Shirmohammadi",
      "James Worrell"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.07416"
  },
  {
    "id": "arXiv:2202.07511",
    "title": "Pessimistic Minimax Value Iteration: Provably Efficient Equilibrium  Learning from Offline Datasets",
    "abstract": "Pessimistic Minimax Value Iteration: Provably Efficient Equilibrium  Learning from Offline Datasets",
    "descriptor": "",
    "authors": [
      "Han Zhong",
      "Wei Xiong",
      "Jiyuan Tan",
      "Liwei Wang",
      "Tong Zhang",
      "Zhaoran Wang",
      "Zhuoran Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07511"
  },
  {
    "id": "arXiv:2202.07626",
    "title": "Random Feature Amplification: Feature Learning and Generalization in  Neural Networks",
    "abstract": "Comments: 41 pages; updated references and presentation",
    "descriptor": "\nComments: 41 pages; updated references and presentation\n",
    "authors": [
      "Spencer Frei",
      "Niladri S. Chatterji",
      "Peter L. Bartlett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07626"
  },
  {
    "id": "arXiv:2202.08417",
    "title": "Retrieval-Augmented Reinforcement Learning",
    "abstract": "Retrieval-Augmented Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Anirudh Goyal",
      "Abram L. Friesen",
      "Andrea Banino",
      "Theophane Weber",
      "Nan Rosemary Ke",
      "Adria Puigdomenech Badia",
      "Arthur Guez",
      "Mehdi Mirza",
      "Peter C. Humphreys",
      "Ksenia Konyushkova",
      "Laurent Sifre",
      "Michal Valko",
      "Simon Osindero",
      "Timothy Lillicrap",
      "Nicolas Heess",
      "Charles Blundell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08417"
  },
  {
    "id": "arXiv:2202.08935",
    "title": "A Formal Safety Characterization of Advanced Driver Assist Systems in  the Car-Following Regime with Scenario-Sampling",
    "abstract": "A Formal Safety Characterization of Advanced Driver Assist Systems in  the Car-Following Regime with Scenario-Sampling",
    "descriptor": "",
    "authors": [
      "Bowen Weng",
      "Minghao Zhu",
      "Keith Redmill"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08935"
  },
  {
    "id": "arXiv:2202.09587",
    "title": "Evaluation of Open-source Tools for Differential Privacy",
    "abstract": "Evaluation of Open-source Tools for Differential Privacy",
    "descriptor": "",
    "authors": [
      "Shiliang Zhang",
      "Anton Hagermalm",
      "Sanjin Slavnic",
      "Elad Michael Schiller",
      "Magnus Almgren"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.09587"
  },
  {
    "id": "arXiv:2202.11908",
    "title": "Learning Program Synthesis for Integer Sequences from Scratch",
    "abstract": "Learning Program Synthesis for Integer Sequences from Scratch",
    "descriptor": "",
    "authors": [
      "Thibault Gauthier",
      "Josef Urban"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.11908"
  },
  {
    "id": "arXiv:2202.13758",
    "title": "Logical Fallacy Detection",
    "abstract": "Logical Fallacy Detection",
    "descriptor": "",
    "authors": [
      "Zhijing Jin",
      "Abhinav Lalwani",
      "Tejas Vaidhya",
      "Xiaoyu Shen",
      "Yiwen Ding",
      "Zhiheng Lyu",
      "Mrinmaya Sachan",
      "Rada Mihalcea",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.13758"
  },
  {
    "id": "arXiv:2203.04058",
    "title": "A Fast Hardware Pseudorandom Number Generator Based on xoroshiro128",
    "abstract": "Comments: Under review for IEEE Transactions on Computers",
    "descriptor": "\nComments: Under review for IEEE Transactions on Computers\n",
    "authors": [
      "James Hanlon",
      "Stephen Felix"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.04058"
  },
  {
    "id": "arXiv:2203.04580",
    "title": "Equilibrium-Independent Stability Analysis for Distribution Systems with  Lossy Transmission Lines",
    "abstract": "Equilibrium-Independent Stability Analysis for Distribution Systems with  Lossy Transmission Lines",
    "descriptor": "",
    "authors": [
      "Wenqi Cui",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.04580"
  },
  {
    "id": "arXiv:2203.08118",
    "title": "Representation Learning for Resource-Constrained Keyphrase Generation",
    "abstract": "Representation Learning for Resource-Constrained Keyphrase Generation",
    "descriptor": "",
    "authors": [
      "Di Wu",
      "Wasi Uddin Ahmad",
      "Sunipa Dev",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08118"
  },
  {
    "id": "arXiv:2203.10174",
    "title": "Are We Ready for Radar to Replace Lidar in All-Weather Mapping and  Localization?",
    "abstract": "Comments: Version 2: Submitted to RA-L/IROS 2022",
    "descriptor": "\nComments: Version 2: Submitted to RA-L/IROS 2022\n",
    "authors": [
      "Keenan Burnett",
      "Yuchen Wu",
      "David J. Yoon",
      "Angela P. Schoellig",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.10174"
  },
  {
    "id": "arXiv:2203.10232",
    "title": "DuReader_retrieval: A Large-scale Chinese Benchmark for Passage  Retrieval from Web Search Engine",
    "abstract": "DuReader_retrieval: A Large-scale Chinese Benchmark for Passage  Retrieval from Web Search Engine",
    "descriptor": "",
    "authors": [
      "Yifu Qiu",
      "Hongyu Li",
      "Yingqi Qu",
      "Ying Chen",
      "Qiaoqiao She",
      "Jing Liu",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.10232"
  },
  {
    "id": "arXiv:2203.11085",
    "title": "Telling Stories from Computational Notebooks: AI-Assisted Presentation  Slides Creation for Presenting Data Science Work",
    "abstract": "Comments: Accepted at CHI'2022",
    "descriptor": "\nComments: Accepted at CHI'2022\n",
    "authors": [
      "Chengbo Zheng",
      "Dakuo Wang",
      "April Yi Wang",
      "Xiaojuan Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11085"
  },
  {
    "id": "arXiv:2203.12369",
    "title": "MetricGAN+/-: Increasing Robustness of Noise Reduction on Unseen Data",
    "abstract": "Comments: 5 pages, 4 figures, Accepted to EUSIPCO 2022",
    "descriptor": "\nComments: 5 pages, 4 figures, Accepted to EUSIPCO 2022\n",
    "authors": [
      "George Close",
      "Thomas Hain",
      "Stefan Goetze"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.12369"
  },
  {
    "id": "arXiv:2203.12821",
    "title": "On Understanding and Mitigating the Dimensional Collapse of Graph  Contrastive Learning: a Non-Maximum Removal Approach",
    "abstract": "On Understanding and Mitigating the Dimensional Collapse of Graph  Contrastive Learning: a Non-Maximum Removal Approach",
    "descriptor": "",
    "authors": [
      "Jiawei Sun",
      "Ruoxin Chen",
      "Jie Li",
      "Chentao Wu",
      "Yue Ding",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.12821"
  },
  {
    "id": "arXiv:2203.13436",
    "title": "Frame-level Prediction of Facial Expressions, Valence, Arousal and  Action Units for Mobile Devices",
    "abstract": "Comments: accepted at CVPR Workshop ABAW3, 8 pages, 2 figures, 6 tables",
    "descriptor": "\nComments: accepted at CVPR Workshop ABAW3, 8 pages, 2 figures, 6 tables\n",
    "authors": [
      "Andrey V. Savchenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13436"
  },
  {
    "id": "arXiv:2203.14601",
    "title": "Bribes to Miners: Evidence from Ethereum",
    "abstract": "Bribes to Miners: Evidence from Ethereum",
    "descriptor": "",
    "authors": [
      "Xiaotong Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2203.14601"
  },
  {
    "id": "arXiv:2203.16338",
    "title": "Stack operation of tensor networks",
    "abstract": "Comments: 9 pages, 10 figures, close to the online published version, for the code on Github, see this this https URL",
    "descriptor": "\nComments: 9 pages, 10 figures, close to the online published version, for the code on Github, see this this https URL\n",
    "authors": [
      "Tianning Zhang",
      "Tianqi Chen",
      "Erping Li",
      "Bo Yang",
      "L. K. Ang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.16338"
  },
  {
    "id": "arXiv:2203.16894",
    "title": "Analysis and Optimization of A Double-IRS Cooperatively Assisted System  with A Quasi-Static Phase Shift Design",
    "abstract": "Comments: 44 pages, 10 figures. To appear in SPAWC 2022;This work is submitted to IEEE Trans.Wireless Commun. (under major revision)",
    "descriptor": "\nComments: 44 pages, 10 figures. To appear in SPAWC 2022;This work is submitted to IEEE Trans.Wireless Commun. (under major revision)\n",
    "authors": [
      "Gengfa Ding",
      "Feng Yang",
      "Lianghui Ding",
      "Ying Cui"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16894"
  },
  {
    "id": "arXiv:2204.01722",
    "title": "Performance Portable Solid Mechanics via Matrix-Free $p$-Multigrid",
    "abstract": "Performance Portable Solid Mechanics via Matrix-Free $p$-Multigrid",
    "descriptor": "",
    "authors": [
      "Jed Brown",
      "Valeria Barra",
      "Natalie Beams",
      "Leila Ghaffari",
      "Matthew Knepley",
      "William Moses",
      "Rezgar Shakeri",
      "Karen Stengel",
      "Jeremy L. Thompson",
      "Junchao Zhang"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.01722"
  },
  {
    "id": "arXiv:2204.02330",
    "title": "Fast syndrome-based Chase decoding of binary BCH codes through Wu list  decoding",
    "abstract": "Comments: Some improvements in Sec. 5.3.3",
    "descriptor": "\nComments: Some improvements in Sec. 5.3.3\n",
    "authors": [
      "Yaron Shany",
      "Amit Berman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.02330"
  },
  {
    "id": "arXiv:2204.02683",
    "title": "Beyond Separability: Analyzing the Linear Transferability of Contrastive  Representations to Related Subpopulations",
    "abstract": "Beyond Separability: Analyzing the Linear Transferability of Contrastive  Representations to Related Subpopulations",
    "descriptor": "",
    "authors": [
      "Jeff Z. HaoChen",
      "Colin Wei",
      "Ananya Kumar",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02683"
  },
  {
    "id": "arXiv:2204.06115",
    "title": "Integrating Distributed Energy Resources: Optimal Prosumer Decisions and  Impacts of Net Metering Tariffs",
    "abstract": "Comments: 20 pages, 11 figures, 6 tables",
    "descriptor": "\nComments: 20 pages, 11 figures, 6 tables\n",
    "authors": [
      "Ahmed S. Alahmed",
      "Lang Tong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2204.06115"
  },
  {
    "id": "arXiv:2204.07190",
    "title": "Measuring Compositional Consistency for Video Question Answering",
    "abstract": "Comments: To appear in CVPR 2022. 23 pages, 12 figures and 12 tables",
    "descriptor": "\nComments: To appear in CVPR 2022. 23 pages, 12 figures and 12 tables\n",
    "authors": [
      "Mona Gandhi",
      "Mustafa Omer Gul",
      "Eva Prakash",
      "Madeleine Grunde-McLaughlin",
      "Ranjay Krishna",
      "Maneesh Agrawala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07190"
  },
  {
    "id": "arXiv:2204.07262",
    "title": "Imposing Consistency for Optical Flow Estimation",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Jisoo Jeong",
      "Jamie Menjay Lin",
      "Fatih Porikli",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07262"
  },
  {
    "id": "arXiv:2204.07541",
    "title": "Selecting Continuous Life-Like Cellular Automata for Halting  Unpredictability: Evolving for Abiogenesis",
    "abstract": "Comments: Accepted to GECCO 2022",
    "descriptor": "\nComments: Accepted to GECCO 2022\n",
    "authors": [
      "Q. Tyrell Davis",
      "Josh Bongard"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ],
    "url": "https://arxiv.org/abs/2204.07541"
  },
  {
    "id": "arXiv:2204.08499",
    "title": "DeepCore: A Comprehensive Library for Coreset Selection in Deep Learning",
    "abstract": "DeepCore: A Comprehensive Library for Coreset Selection in Deep Learning",
    "descriptor": "",
    "authors": [
      "Chengcheng Guo",
      "Bo Zhao",
      "Yanbing Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08499"
  },
  {
    "id": "arXiv:2204.09481",
    "title": "Unsupervised Ranking and Aggregation of Label Descriptions for Zero-Shot  Classifiers",
    "abstract": "Comments: 6 pages, 2 figures",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Angelo Basile",
      "Marc Franco-Salvador",
      "Paolo Rosso"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.09481"
  },
  {
    "id": "arXiv:2204.10762",
    "title": "Dite-HRNet: Dynamic Lightweight High-Resolution Network for Human Pose  Estimation",
    "abstract": "Comments: Accepted by IJCAI-ECAI 2022",
    "descriptor": "\nComments: Accepted by IJCAI-ECAI 2022\n",
    "authors": [
      "Qun Li",
      "Ziyi Zhang",
      "Fu Xiao",
      "Feng Zhang",
      "Bir Bhanu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.10762"
  },
  {
    "id": "arXiv:2204.10796",
    "title": "DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential  Recommendation",
    "abstract": "DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential  Recommendation",
    "descriptor": "",
    "authors": [
      "Jiayi Chen",
      "Wen Wu",
      "Liye Shi",
      "Yu Ji",
      "Wenxin Hu",
      "Wei Zheng",
      "Liang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.10796"
  },
  {
    "id": "arXiv:2204.11116",
    "title": "Human-Robot Shared Control for Surgical Robot Based on Context-Aware  Sim-to-Real Adaptation",
    "abstract": "Comments: Accepted by ICRA",
    "descriptor": "\nComments: Accepted by ICRA\n",
    "authors": [
      "Dandan Zhang",
      "Zicong Wu",
      "Junhong Chen",
      "Ruiqi Zhu",
      "Adnan Munawar",
      "Bo Xiao",
      "Yuan Guan",
      "Hang Su",
      "Wuzhou Hong",
      "Yao Guo",
      "Gregory S. Fischer",
      "Benny Lo",
      "Guang-Zhong Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.11116"
  },
  {
    "id": "arXiv:2204.12484",
    "title": "ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation",
    "abstract": "Comments: Tech report. 81.1 mAP on MS COCO Keypoint Detection test-dev set. V2: Update Multi-task training results: 92.8 AP on OCHuman, 78.3 AP on CrowdPose, 94.3 PCKh on MPII, and 43.2 AP on AI Challenger",
    "descriptor": "\nComments: Tech report. 81.1 mAP on MS COCO Keypoint Detection test-dev set. V2: Update Multi-task training results: 92.8 AP on OCHuman, 78.3 AP on CrowdPose, 94.3 PCKh on MPII, and 43.2 AP on AI Challenger\n",
    "authors": [
      "Yufei Xu",
      "Jing Zhang",
      "Qiming Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.12484"
  },
  {
    "id": "arXiv:2204.13061",
    "title": "Can deep learning match the efficiency of human visual long-term memory  in storing object details?",
    "abstract": "Comments: v3: mostly stylistic changes, no changes in main content",
    "descriptor": "\nComments: v3: mostly stylistic changes, no changes in main content\n",
    "authors": [
      "A. Emin Orhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2204.13061"
  },
  {
    "id": "arXiv:2204.13170",
    "title": "Minimizing Client Drift in Federated Learning via Adaptive Bias  Estimation",
    "abstract": "Comments: AdaBest",
    "descriptor": "\nComments: AdaBest\n",
    "authors": [
      "Farshid Varno",
      "Marzie Saghayi",
      "Laya Rafiee",
      "Sharut Gupta",
      "Stan Matwin",
      "Mohammad Havaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2204.13170"
  },
  {
    "id": "arXiv:2204.13693",
    "title": "Linear Temporal Logic Modulo Theories over Finite Traces (Extended  Version)",
    "abstract": "Comments: Extended version of a conference paper accepted at the 31st International Joint Conference on Artificial Intelligence (IJCAI-ECAI 2022)",
    "descriptor": "\nComments: Extended version of a conference paper accepted at the 31st International Joint Conference on Artificial Intelligence (IJCAI-ECAI 2022)\n",
    "authors": [
      "Luca Geatti",
      "Alessandro Gianola",
      "Nicola Gigante"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.13693"
  },
  {
    "id": "arXiv:2205.00664",
    "title": "Simple Techniques Work Surprisingly Well for Neural Network Test  Prioritization and Active Learning (Replicability Study)",
    "abstract": "Comments: Accepted at ISSTA 2022",
    "descriptor": "\nComments: Accepted at ISSTA 2022\n",
    "authors": [
      "Michael Weiss",
      "Paolo Tonella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.00664"
  },
  {
    "id": "arXiv:2205.01550",
    "title": "Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution  Neural Network",
    "abstract": "Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution  Neural Network",
    "descriptor": "",
    "authors": [
      "Yunzheng Su",
      "Lei Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.01550"
  },
  {
    "id": "arXiv:2205.02798",
    "title": "Effective poset inequalities",
    "abstract": "Comments: 36 pages, 1 figure. Several typos are fixed, and several references are added to v2",
    "descriptor": "\nComments: 36 pages, 1 figure. Several typos are fixed, and several references are added to v2\n",
    "authors": [
      "Swee Hong Chan",
      "Igor Pak",
      "Greta Panova"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.02798"
  },
  {
    "id": "arXiv:2205.03673",
    "title": "Towards Practical Physics-Informed ML Design and Evaluation for Power  Grid",
    "abstract": "Towards Practical Physics-Informed ML Design and Evaluation for Power  Grid",
    "descriptor": "",
    "authors": [
      "Shimiao Li",
      "Amritanshu Pandey",
      "Larry Pileggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.03673"
  },
  {
    "id": "arXiv:2205.04901",
    "title": "Adjusted Expected Improvement for Cumulative Regret Minimization in  Noisy Bayesian Optimization",
    "abstract": "Adjusted Expected Improvement for Cumulative Regret Minimization in  Noisy Bayesian Optimization",
    "descriptor": "",
    "authors": [
      "Shouri Hu",
      "Haowei Wang",
      "Zhongxiang Dai",
      "Bryan Kian Hsiang Low",
      "Szu Hui Ng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.04901"
  },
  {
    "id": "arXiv:2205.05061",
    "title": "On the Verge of Solving Rocket League using Deep Reinforcement Learning  and Sim-to-sim Transfer",
    "abstract": "Comments: Accepted at IEEE Conference on Games 2022, 8 pages, 6 figures, 3 tables",
    "descriptor": "\nComments: Accepted at IEEE Conference on Games 2022, 8 pages, 6 figures, 3 tables\n",
    "authors": [
      "Marco Pleines",
      "Konstantin Ramthun",
      "Yannik Wegener",
      "Hendrik Meyer",
      "Matthias Pallasch",
      "Sebastian Prior",
      "Jannik Dr\u00f6gem\u00fcller",
      "Leon B\u00fcttinghaus",
      "Thilo R\u00f6themeyer",
      "Alexander Kaschwig",
      "Oliver Chmurzynski",
      "Frederik Rohkr\u00e4hmer",
      "Roman Kalkreuth",
      "Frank Zimmer",
      "Mike Preuss"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05061"
  },
  {
    "id": "arXiv:2205.05512",
    "title": "Is calibration a fairness requirement? An argument from the point of  view of moral philosophy and decision theory",
    "abstract": "Is calibration a fairness requirement? An argument from the point of  view of moral philosophy and decision theory",
    "descriptor": "",
    "authors": [
      "Michele Loi",
      "Christoph Heitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.05512"
  },
  {
    "id": "arXiv:2205.05677",
    "title": "HULC: 3D Human Motion Capture with Pose Manifold Sampling and Dense  Contact Guidance",
    "abstract": "HULC: 3D Human Motion Capture with Pose Manifold Sampling and Dense  Contact Guidance",
    "descriptor": "",
    "authors": [
      "Soshi Shimada",
      "Vladislav Golyanik",
      "Zhi Li",
      "Patrick P\u00e9rez",
      "Weipeng Xu",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.05677"
  },
  {
    "id": "arXiv:2205.05989",
    "title": "AiSocrates: Towards Answering Ethical Quandary Questions",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Yejin Bang",
      "Nayeon Lee",
      "Tiezheng Yu",
      "Leila Khalatbari",
      "Yan Xu",
      "Dan Su",
      "Elham J. Barezi",
      "Andrea Madotto",
      "Hayden Kee",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05989"
  },
  {
    "id": "arXiv:2205.06743",
    "title": "A Comprehensive Survey of Few-shot Learning: Evolution, Applications,  Challenges, and Opportunities",
    "abstract": "A Comprehensive Survey of Few-shot Learning: Evolution, Applications,  Challenges, and Opportunities",
    "descriptor": "",
    "authors": [
      "Yisheng Song",
      "Ting Wang",
      "Subrota K Mondal",
      "Jyoti Prakash Sahoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.06743"
  },
  {
    "id": "arXiv:2205.06947",
    "title": "BronchusNet: Region and Structure Prior Embedded Representation Learning  for Bronchus Segmentation and Classification",
    "abstract": "BronchusNet: Region and Structure Prior Embedded Representation Learning  for Bronchus Segmentation and Classification",
    "descriptor": "",
    "authors": [
      "Wenhao Huang",
      "Haifan Gong",
      "Huan Zhang",
      "Yu Wang",
      "Haofeng Li",
      "Guanbin Li",
      "Hong Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.06947"
  },
  {
    "id": "arXiv:2205.07593",
    "title": "A Parallel Algorithm for $(3 + \\varepsilon)$-Approximate Correlation  Clustering",
    "abstract": "Comments: There is an error in our approximation analysis (lemma 8 to be exact) and the algorithm does not have the claimed approximation guarantee",
    "descriptor": "\nComments: There is an error in our approximation analysis (lemma 8 to be exact) and the algorithm does not have the claimed approximation guarantee\n",
    "authors": [
      "M\u00e9lanie Cambus",
      "Shreyas Pai",
      "Jara Uitto"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.07593"
  },
  {
    "id": "arXiv:2205.07979",
    "title": "The Budge programming language",
    "abstract": "The Budge programming language",
    "descriptor": "",
    "authors": [
      "Boro Sitnikovski"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.07979"
  },
  {
    "id": "arXiv:2205.08451",
    "title": "MAS2HP: A Multi Agent System to predict protein structure in 2D HP model",
    "abstract": "MAS2HP: A Multi Agent System to predict protein structure in 2D HP model",
    "descriptor": "",
    "authors": [
      "Hossein Parineh",
      "Nasser Mozayani"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.08451"
  },
  {
    "id": "arXiv:2205.08897",
    "title": "FiLM: Frequency improved Legendre Memory Model for Long-term Time Series  Forecasting",
    "abstract": "FiLM: Frequency improved Legendre Memory Model for Long-term Time Series  Forecasting",
    "descriptor": "",
    "authors": [
      "Tian Zhou",
      "Ziqing Ma",
      "Xue wang",
      "Qingsong Wen",
      "Liang Sun",
      "Tao Yao",
      "Wotao Yin",
      "Rong Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.08897"
  },
  {
    "id": "arXiv:2205.09058",
    "title": "Minimising Biasing Word Errors for Contextual ASR with the  Tree-Constrained Pointer Generator",
    "abstract": "Comments: This work has been submitted to the IEEE Transactions on Audio, Speech, and Language Processing for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE Transactions on Audio, Speech, and Language Processing for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Guangzhi Sun",
      "Chao Zhang",
      "Philip C Woodland"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.09058"
  },
  {
    "id": "arXiv:2205.09626",
    "title": "BARS: Towards Open Benchmarking for Recommender Systems",
    "abstract": "Comments: Accepted in SIGIR 2022. See the BARS benchmark at this https URL",
    "descriptor": "\nComments: Accepted in SIGIR 2022. See the BARS benchmark at this https URL\n",
    "authors": [
      "Jieming Zhu",
      "Quanyu Dai",
      "Liangcai Su",
      "Rong Ma",
      "Jinyang Liu",
      "Guohao Cai",
      "Xi Xiao",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.09626"
  },
  {
    "id": "arXiv:2205.09853",
    "title": "Masked Conditional Video Diffusion for Prediction, Generation, and  Interpolation",
    "abstract": "Comments: 9 pages, 4 figures, 7 tables",
    "descriptor": "\nComments: 9 pages, 4 figures, 7 tables\n",
    "authors": [
      "Vikram Voleti",
      "Alexia Jolicoeur-Martineau",
      "Christopher Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09853"
  },
  {
    "id": "arXiv:2205.09943",
    "title": "Explainable Supervised Domain Adaptation",
    "abstract": "Comments: Paper planned to be extended",
    "descriptor": "\nComments: Paper planned to be extended\n",
    "authors": [
      "Vidhya Kamakshi",
      "Narayanan C Krishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09943"
  },
  {
    "id": "arXiv:2205.09963",
    "title": "Sample Complexity of Learning Heuristic Functions for Greedy-Best-First  and A* Search",
    "abstract": "Sample Complexity of Learning Heuristic Functions for Greedy-Best-First  and A* Search",
    "descriptor": "",
    "authors": [
      "Shinsaku Sakaue",
      "Taihei Oki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.09963"
  },
  {
    "id": "arXiv:2205.10356",
    "title": "EXPANSE: A Deep Continual / Progressive Learning System for Deep  Transfer Learning",
    "abstract": "Comments: 12 Pages, 2 figures, 4 tables, submitting to NIPS 2022",
    "descriptor": "\nComments: 12 Pages, 2 figures, 4 tables, submitting to NIPS 2022\n",
    "authors": [
      "Mohammadreza Iman",
      "John A. Miller",
      "Khaled Rasheed",
      "Robert M. Branch",
      "Hamid R. Arabnia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.10356"
  },
  {
    "id": "arXiv:2205.10468",
    "title": "Deep Learning for Omnidirectional Vision: A Survey and New Perspectives",
    "abstract": "Comments: 31 pages",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Hao Ai",
      "Zidong Cao",
      "Jinjing Zhu",
      "Haotian Bai",
      "Yucheng Chen",
      "Lin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.10468"
  },
  {
    "id": "arXiv:2205.10505",
    "title": "Deeper vs Wider: A Revisit of Transformer Configuration",
    "abstract": "Deeper vs Wider: A Revisit of Transformer Configuration",
    "descriptor": "",
    "authors": [
      "Fuzhao Xue",
      "Jianghai Chen",
      "Aixin Sun",
      "Xiaozhe Ren",
      "Zangwei Zheng",
      "Xiaoxin He",
      "Xin Jiang",
      "Yang You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.10505"
  },
  {
    "id": "arXiv:2205.10513",
    "title": "Computable Artificial General Intelligence",
    "abstract": "Comments: Experiment code available on TechRxiv: this https URL",
    "descriptor": "\nComments: Experiment code available on TechRxiv: this https URL\n",
    "authors": [
      "Michael Timothy Bennett"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.10513"
  },
  {
    "id": "arXiv:2205.10583",
    "title": "Improving automatically generated code from Codex via Automated Program  Repair",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Zhiyu Fan",
      "Xiang Gao",
      "Abhik Roychoudhury",
      "Shin Hwei Tan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.10583"
  },
  {
    "id": "arXiv:2205.10648",
    "title": "Global reconstruction of initial conditions of nonlinear parabolic  equations via the Carleman-contraction method",
    "abstract": "Global reconstruction of initial conditions of nonlinear parabolic  equations via the Carleman-contraction method",
    "descriptor": "",
    "authors": [
      "Thuy T. Le"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.10648"
  },
  {
    "id": "arXiv:2205.10667",
    "title": "Individual Topology Structure of Eye Movement Trajectories",
    "abstract": "Individual Topology Structure of Eye Movement Trajectories",
    "descriptor": "",
    "authors": [
      "Arsenii Onuchin",
      "Oleg Kachan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10667"
  },
  {
    "id": "arXiv:2205.10710",
    "title": "Phrase-level Textual Adversarial Attack with Label Preservation",
    "abstract": "Comments: NAACL-HLT 2022 Findings (Long), 9 pages + 2 pages references + 8 pages appendix",
    "descriptor": "\nComments: NAACL-HLT 2022 Findings (Long), 9 pages + 2 pages references + 8 pages appendix\n",
    "authors": [
      "Yibin Lei",
      "Yu Cao",
      "Dianqi Li",
      "Tianyi Zhou",
      "Meng Fang",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.10710"
  },
  {
    "id": "arXiv:2205.10714",
    "title": "Interpretable Proof Generation via Iterative Backward Reasoning",
    "abstract": "Comments: NAACL-HLT 2022 (Long), 14 pages (2 page references + 3 page appendix)",
    "descriptor": "\nComments: NAACL-HLT 2022 (Long), 14 pages (2 page references + 3 page appendix)\n",
    "authors": [
      "Hanhao Qu",
      "Yu Cao",
      "Jun Gao",
      "Liang Ding",
      "Ruifeng Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.10714"
  },
  {
    "id": "arXiv:2205.10747",
    "title": "Language Models with Image Descriptors are Strong Few-Shot  Video-Language Learners",
    "abstract": "Language Models with Image Descriptors are Strong Few-Shot  Video-Language Learners",
    "descriptor": "",
    "authors": [
      "Zhenhailong Wang",
      "Manling Li",
      "Ruochen Xu",
      "Luowei Zhou",
      "Jie Lei",
      "Xudong Lin",
      "Shuohang Wang",
      "Ziyi Yang",
      "Chenguang Zhu",
      "Derek Hoiem",
      "Shih-Fu Chang",
      "Mohit Bansal",
      "Heng Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.10747"
  },
  {
    "id": "arXiv:2205.10756",
    "title": "Real Time Detection Free Tracking of Multiple Objects Via Equilibrium  Optimizer",
    "abstract": "Real Time Detection Free Tracking of Multiple Objects Via Equilibrium  Optimizer",
    "descriptor": "",
    "authors": [
      "Djemai Charef-Khodja",
      "Toumi Abida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.10756"
  },
  {
    "id": "arXiv:2205.10803",
    "title": "GraphMAE: Self-Supervised Masked Graph Autoencoders",
    "abstract": "Comments: 11 pages; Accepted to KDD'22",
    "descriptor": "\nComments: 11 pages; Accepted to KDD'22\n",
    "authors": [
      "Zhenyu Hou",
      "Xiao Liu",
      "Yukuo Cen",
      "Yuxiao Dong",
      "Hongxia Yang",
      "Chunjie Wang",
      "Jie Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10803"
  },
  {
    "id": "arXiv:2205.10852",
    "title": "Relphormer: Relational Graph Transformer for Knowledge Graph  Representation",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Zhen Bi",
      "Siyuan Cheng",
      "Ningyu Zhang",
      "Xiaozhuan Liang",
      "Feiyu Xiong",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.10852"
  },
  {
    "id": "arXiv:2205.11028",
    "title": "RCP: Recurrent Closest Point for Scene Flow Estimation on 3D Point  Clouds",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Xiaodong Gu",
      "Chengzhou Tang",
      "Weihao Yuan",
      "Zuozhuo Dai",
      "Siyu Zhu",
      "Ping Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11028"
  },
  {
    "id": "arXiv:2205.11081",
    "title": "BanglaNLG: Benchmarks and Resources for Evaluating Low-Resource Natural  Language Generation in Bangla",
    "abstract": "BanglaNLG: Benchmarks and Resources for Evaluating Low-Resource Natural  Language Generation in Bangla",
    "descriptor": "",
    "authors": [
      "Abhik Bhattacharjee",
      "Tahmid Hasan",
      "Wasi Uddin Ahmad",
      "Rifat Shahriyar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11081"
  },
  {
    "id": "arXiv:2205.11140",
    "title": "Human-in-the-loop: Provably Efficient Preference-based Reinforcement  Learning with General Function Approximation",
    "abstract": "Human-in-the-loop: Provably Efficient Preference-based Reinforcement  Learning with General Function Approximation",
    "descriptor": "",
    "authors": [
      "Xiaoyu Chen",
      "Han Zhong",
      "Zhuoran Yang",
      "Zhaoran Wang",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11140"
  },
  {
    "id": "arXiv:2205.11168",
    "title": "Logarithmic regret bounds for continuous-time average-reward Markov  decision processes",
    "abstract": "Logarithmic regret bounds for continuous-time average-reward Markov  decision processes",
    "descriptor": "",
    "authors": [
      "Xuefeng Gao",
      "Xun Yu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.11168"
  },
  {
    "id": "arXiv:2205.11232",
    "title": "Deep Neural Network approaches for Analysing Videos of Music  Performances",
    "abstract": "Deep Neural Network approaches for Analysing Videos of Music  Performances",
    "descriptor": "",
    "authors": [
      "Foteini Simistira Liwicki",
      "Richa Upadhyay",
      "Prakash Chandra Chhipa",
      "Killian Murphy",
      "Federico Visi",
      "Stefan \u00d6stersj\u00f6",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2205.11232"
  },
  {
    "id": "arXiv:2205.11239",
    "title": "Vision Transformer: Vit and its Derivatives",
    "abstract": "Vision Transformer: Vit and its Derivatives",
    "descriptor": "",
    "authors": [
      "Zujun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11239"
  },
  {
    "id": "arXiv:2205.11245",
    "title": "PASH at TREC 2021 Deep Learning Track: Generative Enhanced Model for  Multi-stage Ranking",
    "abstract": "Comments: TREC 2021",
    "descriptor": "\nComments: TREC 2021\n",
    "authors": [
      "Yixuan Qiao",
      "Hao Chen",
      "Yongquan Lai",
      "Jun Wang",
      "Tuozhen Liu",
      "Xianbin Ye",
      "Rui Fang",
      "Peng Gao",
      "Wenfeng Xie",
      "Guotong Xie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11245"
  },
  {
    "id": "arXiv:2205.11343",
    "title": "Heterogeneous Graph Neural Network for Personalized Session-Based  Recommendation with User-Session Constraints",
    "abstract": "Heterogeneous Graph Neural Network for Personalized Session-Based  Recommendation with User-Session Constraints",
    "descriptor": "",
    "authors": [
      "Minjae Park"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11343"
  },
  {
    "id": "arXiv:2205.11384",
    "title": "Learning Long-Horizon Robot Exploration Strategies for Multi-Object  Search in Continuous Action Spaces",
    "abstract": "Learning Long-Horizon Robot Exploration Strategies for Multi-Object  Search in Continuous Action Spaces",
    "descriptor": "",
    "authors": [
      "Fabian Schmalstieg",
      "Daniel Honerkamp",
      "Tim Welschehold",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.11384"
  },
  {
    "id": "arXiv:2205.11482",
    "title": "Tracing Knowledge in Language Models Back to the Training Data",
    "abstract": "Comments: 14 pages, 5 Tables, 5 Figures",
    "descriptor": "\nComments: 14 pages, 5 Tables, 5 Figures\n",
    "authors": [
      "Ekin Aky\u00fcrek",
      "Tolga Bolukbasi",
      "Frederick Liu",
      "Binbin Xiong",
      "Ian Tenney",
      "Jacob Andreas",
      "Kelvin Guu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.11482"
  }
]